quality_attribute,sentence,source,author,repo,version,id,keyword,matched_word,match_idx,filename,wiki,url,total_similar,target_keywords,target_matched_words
Modifiability,"vent"" is a structure with one float and; three integers and one unsigned integer. You should not assume that the; compiler aligns the elements of a structure without gaps. To avoid; alignment problems, you need to use structures with same length members.; If your structure does not qualify, you need to create one branch for; each element of the structure. The leaf name is NOT used to pick the variable out of the structure, but; is only used as the name for the leaf. This means that the list of; variables needs to be in a structure in the order described in the third; parameter. This third parameter is a string describing the leaf list. Each leaf has; a name and a type separated by a ""/"" and it is separated from the next; leaf by a ""`:`"". ``` {.cpp}; <Variable>/<type>:<Variable>/<type>; ```. The example on the next line has two leafs: a floating-point number; called temp and an integer named `ntrack`. ``` {.cpp}; ""temp/F:ntrack/I:""; ```. The type can be omitted and if no type is given, the same type as the; previous variable is assumed. This leaf list has three integers called; `ntrack`, `nseg`, and `nvtex`. ``` {.cpp}; ""ntrack/I:nseg:nvtex""; ```. There is one more rule: when no type is given for the very first leaf,; it becomes a `float` (F). This leaf list has three floats called `temp`,; `mass`, and `px`. ``` {.cpp}; ""temp:mass:px""; ```. The symbols used for the type are:. - `C`: a character string terminated by the 0 character; - `B`: an 8 bit signed integer; - `b`: an 8 bit unsigned integer; - `S`: a 16 bit signed integer; - `s`: a 16 bit unsigned integer; - `I`: a 32 bit signed integer; - `i`: a 32 bit unsigned integer; - `L`: a 64 bit signed integer; - `l`: a 64 bit unsigned integer; - `G`: a long signed integer, stored as 64 bit; - `g`: a long unsigned integer, stored as 64 bit; - `F`: a 32 bit floating point; - `D`: a 64 bit floating point; - `O`: [the letter 'o', not a zero] a boolean (Bool\_t). The type is used for a byte count to decide how much space to a",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md:20778,variab,variable,20778,documentation/users-guide/Trees.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md,1,['variab'],['variable']
Modifiability,"ver(""fastcgi:9000"");; ```. In fact, the FastCGI interface can run in parallel to http server. One can just call:. ```cpp; serv = new THttpServer(""http:8080"");; serv->CreateEngine(""fastcgi:9000"");; ```. One could specify a debug parameter to be able to adjust the FastCGI configuration on the web server:. ```cpp; serv->CreateEngine(""fastcgi:9000?debug=1"");; ```. By default 10 threads are used to process FastCGI requests. This number can be changed with ""thrds"" url parameter:. ```cpp; serv->CreateEngine(""fastcgi:9000?thrds=20"");; ```. If `thrds=0` parameter specified, the only thread will be use to received and process all requests. All user access will be ruled by the main web server. Authorized account names could be used to configure access restriction in THttpServer. ### Configure fastcgi with Apache2. Since Apache version 2.4 FastCGI is directly supported - there is no need to compile and install external modules any more.; One only need to enable `mod_proxy` and `mod_proxy_fcgi` modules and add following line to **Apache2** configuration file:. ```; ProxyPass ""/root.app/"" ""fcgi://localhost:9000/"" enablereuse=on; ```. More information can be found in [FastCGI proxy docu](https://httpd.apache.org/docs/2.4/mod/mod_proxy_fcgi.html).; After restarting apache server one should be able to open address: `http://apache_host_name/root.app/`.; There are many ways to configure user authentication in Apache. Example of digest auth for FastCGI server:. ```; <Location ""/root.app/"">; AuthType Digest; AuthName ""root""; AuthDigestDomain ""/root.app/"" ""root""; AuthDigestProvider file; AuthUserFile ""/srv/auth/auth.txt""; Require valid-user; </Location>; ```. ### Configure fastcgi with lighttpd. An example of configuration file for **lighttpd** server is:. ```; server.modules += ( ""mod_fastcgi"" ); fastcgi.server = (; ""/root.app"" =>; (( ""host"" => ""192.168.1.11"",; ""port"" => 9000,; ""check-local"" => ""disable"",; ""docroot"" => ""/""; )); ); ```. Be aware, that with *lighttpd* one should specify IP",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/HttpServer/HttpServer.md:11293,config,configuration,11293,documentation/HttpServer/HttpServer.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/HttpServer/HttpServer.md,1,['config'],['configuration']
Modifiability,"ver; - ``clang-dxc`` for the ``dxc`` driver. For example, when calling ``x86_64-pc-linux-gnu-clang-g++``,; the driver will first attempt to use the configuration file named::. x86_64-pc-linux-gnu-clang++.cfg. If this file is not found, it will attempt to use the name found; in the executable instead::. x86_64-pc-linux-gnu-clang-g++.cfg. Note that options such as ``--driver-mode=``, ``--target=``, ``-m32`` affect; the search algorithm. For example, the aforementioned executable called with; ``-m32`` argument will instead search for::. i386-pc-linux-gnu-clang++.cfg. If none of the aforementioned files are found, the driver will instead search; for separate driver and target configuration files and attempt to load both.; The former is named ``<driver>.cfg`` while the latter is named; ``<triple>.cfg``. Similarly to the previous variants, the canonical driver name; will be preferred, and the compiler will fall back to the actual name. For example, ``x86_64-pc-linux-gnu-clang-g++`` will attempt to load two; configuration files named respectively::. clang++.cfg; x86_64-pc-linux-gnu.cfg. with fallback to trying::. clang-g++.cfg; x86_64-pc-linux-gnu.cfg. It is not an error if either of these files is not found. The configuration file consists of command-line options specified on one or; more lines. Lines composed of whitespace characters only are ignored as well as; lines in which the first non-blank character is ``#``. Long options may be split; between several lines by a trailing backslash. Here is example of a; configuration file:. ::. # Several options on line; -c --target=x86_64-unknown-linux-gnu. # Long option split between lines; -I/usr/lib/gcc/x86_64-linux-gnu/5.4.0/../../../../\; include/c++/5.4.0. # other config files may be included; @linux.options. Files included by ``@file`` directives in configuration files are resolved; relative to the including file. For example, if a configuration file; ``~/.llvm/target.cfg`` contains the directive ``@os/linux.opts``, the fil",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:33850,config,configuration,33850,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,1,['config'],['configuration']
Modifiability,versions to non-class prvalues in reference initialization; Not resolved. 2109; CD4; Value dependence underspecified; Unknown. 2110; drafting; Overload resolution for base class conversion and reference/non-reference; Not resolved. 2111; NAD; Array temporaries in reference binding; Unknown. 2112; CD5; new auto{x}; Unknown. 2113; CD4; Incompete specification of types for declarators; Unknown. 2114; CD3; Missing description of incompatibility from aggregate NSDMIs; Unknown. 2115; drafting; Order of implicit destruction vs release of automatic storage; Not resolved. 2116; C++17; Direct or copy initialization for omitted aggregate initializers; Unknown. 2117; drafting; Explicit specializations and constexpr function templates; Not resolved. 2118; open; Stateful metaprogramming via friend injection; Not resolved. 2119; NAD; Disambiguation of multi-level covariant return type; Unknown. 2120; CD4; Array as first non-static data member in standard-layout class; Clang 7. 2121; CD6; More flexible lambda syntax; Unknown. 2122; CD4; Glvalues of void type; Unknown. 2123; open; Omitted constant initialization of local static variables; Not resolved. 2124; CD4; Signature of constructor template; Unknown. 2125; NAD; Copy elision and comma operator; Unknown. 2126; C++20; Lifetime-extended temporaries in constant expressions; Clang 12. 2127; drafting; Partial specialization and nullptr; Not resolved. 2128; drafting; Imprecise rule for reference member initializer; Not resolved. 2129; CD4; Non-object prvalues and constant expressions; Unknown. 2130; CD4; Over-aligned types in new-expressions; Unknown. 2131; drafting; Ambiguity with opaque-enum-declaration; Not resolved. 2132; NAD; Deprecated default generated copy constructors; Unknown. 2133; CD5; Converting std::nullptr_t to bool; Unknown. 2134; NAD; Objectless references to non-static member functions; Unknown. 2135; NAD; mem-initializers for virtual bases of abstract classes; Unknown. 2136; NAD; Argument-dependent lookup and initial,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/cxx_dr_status.html:144466,flexible,flexible,144466,interpreter/llvm-project/clang/www/cxx_dr_status.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/cxx_dr_status.html,2,['flexible'],['flexible']
Modifiability,"verts automatically to an integer, which represents the status code of the fit. If the Fit method is used as before, there is a no visible change for the user.; When using the fit option ""S"", the TFitResultPtr will now contain a pointer to the new TFitResult class. It will behave as a smart pointer to TFitResult,; by using the -> operator the user can call the TFitResult methods or access directly the TFitResult object, by using the de-reference operator * or; TFitResultPtr::Get().; The TFitResult class derives from the ROOT::Math::FitResult, which contains all the result information from a fit and from TNamed. It provides then I/O capabilities for the FitResult object and convenience methods like Print(), Write(), GetCovarianceMatrix() and GetCorrelationMatrix() which return a TMatrixDSym object.; Example of usage:; ; TFitResult r = h->Fit(""myFunc"",""S"");; TMatrixDSym cov = r->GetCovarianceMatrix(); // to access the covariance matrix; Double_t chi2 = r->Chi2(); // to retrieve the fit chi2; Double_t par0 = r->Value(0); // retrieve the value for the parameter 0; Double_t err0 = r->Error(0); // retrieve the error for the parameter 0; r->Print(""V""); // print full information of fit including covariance matrix; r->Write(); // store the result in a file. FitPanel. Added predefined 2D Functions.; Addition of new minimization algorithms from the GSL library and foreseen the addition of; genetic minimizers when will be released.; Fixed up to three bugs from the previous release; Added the Update Button. This way the user can update the content of the fitpanel with all the new objects and functions created in the current ROOT session.; Changed the way the TF1s were being copied internally. Instead of using TObject::Clone, now it's using the TF1 copy constructor. new tutorial rebin.C; This tutorial illustrates how to:. create a variable binwidth histogram with a binning such; that the population per bin is about the same.; rebin a variable binwidth histogram into another one. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/hist/doc/v526/index.html:6396,variab,variable,6396,hist/doc/v526/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/hist/doc/v526/index.html,4,['variab'],['variable']
Modifiability,"via an attribute) default visibility from the; source, including RTTI.; * ``-mdefault-visibility-export-mapping=all``: set XCOFF exported visibility; for all entities with default visibility from any source. This gives a; export behavior similar to ELF platforms where all entities with default; visibility are exported. .. _spir-v:. SPIR-V support; --------------. Clang supports generation of SPIR-V conformant to `the OpenCL Environment; Specification; <https://www.khronos.org/registry/OpenCL/specs/3.0-unified/html/OpenCL_Env.html>`_. To generate SPIR-V binaries, Clang uses the external ``llvm-spirv`` tool from the; `SPIRV-LLVM-Translator repo; <https://github.com/KhronosGroup/SPIRV-LLVM-Translator>`_. Prior to the generation of SPIR-V binary with Clang, ``llvm-spirv``; should be built or installed. Please refer to `the following instructions; <https://github.com/KhronosGroup/SPIRV-LLVM-Translator#build-instructions>`_; for more details. Clang will expect the ``llvm-spirv`` executable to; be present in the ``PATH`` environment variable. Clang uses ``llvm-spirv``; with `the widely adopted assembly syntax package; <https://github.com/KhronosGroup/SPIRV-LLVM-Translator/#build-with-spirv-tools>`_. `The versioning; <https://github.com/KhronosGroup/SPIRV-LLVM-Translator/releases>`_ of; ``llvm-spirv`` is aligned with Clang major releases. The same applies to the; main development branch. It is therefore important to ensure the ``llvm-spirv``; version is in alignment with the Clang version. For troubleshooting purposes; ``llvm-spirv`` can be `tested in isolation; <https://github.com/KhronosGroup/SPIRV-LLVM-Translator#test-instructions>`_. Example usage for OpenCL kernel compilation:. .. code-block:: console. $ clang --target=spirv32 -c test.cl; $ clang --target=spirv64 -c test.cl. Both invocations of Clang will result in the generation of a SPIR-V binary file; `test.o` for 32 bit and 64 bit respectively. This file can be imported; by an OpenCL driver that support SPIR-V consu",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:165995,variab,variable,165995,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,1,['variab'],['variable']
Modifiability,"vides; <https://www.kernel.org/doc/Documentation/arm/kernel_user_helpers.txt>`_ a; function which on older CPUs contains a ""magically-restartable"" atomic sequence; (which looks atomic so long as there's only one CPU), and contains actual atomic; instructions on newer multicore models. This sort of functionality can typically; be provided on any architecture, if all CPUs which are missing atomic; compare-and-swap support are uniprocessor (no SMP). This is almost always the; case. The only common architecture without that property is SPARC -- SPARCV8 SMP; systems were common, yet it doesn't support any sort of compare-and-swap; operation. Some targets (like RISCV) support a ``+forced-atomics`` target feature, which; enables the use of lock-free atomics even if LLVM is not aware of any specific; OS support for them. In this case, the user is responsible for ensuring that; necessary ``__sync_*`` implementations are available. Code using; ``+forced-atomics`` is ABI-incompatible with code not using the feature, if; atomic variables cross the ABI boundary. In either of these cases, the Target in LLVM can claim support for atomics of an; appropriate size, and then implement some subset of the operations via libcalls; to a ``__sync_*`` function. Such functions *must* not use locks in their; implementation, because unlike the ``__atomic_*`` routines used by; AtomicExpandPass, these may be mixed-and-matched with native instructions by the; target lowering. Further, these routines do not need to be shared, as they are stateless. So,; there is no issue with having multiple copies included in one binary. Thus,; typically these routines are implemented by the statically-linked compiler; runtime support library. LLVM will emit a call to an appropriate ``__sync_*`` routine if the target; ISelLowering code has set the corresponding ``ATOMIC_CMPXCHG``, ``ATOMIC_SWAP``,; or ``ATOMIC_LOAD_*`` operation to ""Expand"", and if it has opted-into the; availability of those library functions vi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Atomics.rst:28136,variab,variables,28136,interpreter/llvm-project/llvm/docs/Atomics.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Atomics.rst,1,['variab'],['variables']
Modifiability,"view:. Overview; ________. Taint analysis works by checking for the occurrence of special operations during the symbolic execution of the program.; Taint analysis defines sources, sinks, and propagation rules. It identifies errors by detecting a flow of information that originates from a taint source, reaches a taint sink, and propagates through the program paths via propagation rules.; A source, sink, or an operation that propagates taint is mainly domain-specific knowledge, but there are some built-in defaults provided by :ref:`alpha-security-taint-TaintPropagation`.; It is possible to express that a statement sanitizes tainted values by providing a ``Filters`` section in the external configuration (see :ref:`clangsa-taint-configuration-example` and :ref:`clangsa-taint-filter-details`).; There are no default filters defined in the built-in settings.; The checker's documentation also specifies how to provide a custom taint configuration with command-line options. .. _clangsa-taint-configuration-example:. Example configuration file; __________________________. .. code-block:: yaml. # The entries that specify arguments use 0-based indexing when specifying; # input arguments, and -1 is used to denote the return value. Filters:; # Filter functions; # Taint is sanitized when tainted variables are pass arguments to filters. # Filter function; # void cleanse_first_arg(int* arg); #; # Result example:; # int x; // x is tainted; # cleanse_first_arg(&x); // x is not tainted after the call; - Name: cleanse_first_arg; Args: [0]. Propagations:; # Source functions; # The omission of SrcArgs key indicates unconditional taint propagation,; # which is conceptually what a source does. # Source function; # size_t fread(void *ptr, size_t size, size_t nmemb, FILE * stream); #; # Result example:; # FILE* f = fopen(""file.txt"");; # char buf[1024];; # size_t read = fread(buf, sizeof(buf[0]), sizeof(buf)/sizeof(buf[0]), f);; # // both read and buf are tainted; - Name: fread; DstArgs: [0, -1].",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/user-docs/TaintAnalysisConfiguration.rst:1939,config,configuration-example,1939,interpreter/llvm-project/clang/docs/analyzer/user-docs/TaintAnalysisConfiguration.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/user-docs/TaintAnalysisConfiguration.rst,1,['config'],['configuration-example']
Modifiability,"ving from the; class ``Instruction``. For each ``def`` record, the root object also has a key for the record; name. The corresponding value is a subsidiary object containing the; following fixed keys:. * ``!superclasses``: an array of strings giving the names of all the; classes that this record derives from. * ``!fields``: an array of strings giving the names of all the variables; in this record that were defined with the ``field`` keyword. * ``!name``: a string giving the name of the record. This is always; identical to the key in the JSON root object corresponding to this; record's dictionary. (If the record is anonymous, the name is; arbitrary.). * ``!anonymous``: a boolean indicating whether the record's name was; specified by the TableGen input (if it is ``false``), or invented by; TableGen itself (if ``true``). For each variable defined in a record, the ``def`` object for that; record also has a key for the variable name. The corresponding value; is a translation into JSON of the variable's value, using the; conventions described below. Some TableGen data types are translated directly into the; corresponding JSON type:. * A completely undefined value (e.g. for a variable declared without; initializer in some superclass of this record, and never initialized; by the record itself or any other superclass) is emitted as the JSON; ``null`` value. * ``int`` and ``bit`` values are emitted as numbers. Note that; TableGen ``int`` values are capable of holding integers too large to; be exactly representable in IEEE double precision. The integer; literal in the JSON output will show the full exact integer value.; So if you need to retrieve large integers with full precision, you; should use a JSON reader capable of translating such literals back; into 64-bit integers without losing precision, such as Python's; standard ``json`` module. * ``string`` and ``code`` values are emitted as JSON strings. * ``list<T>`` values, for any element type ``T``, are emitted as JSON; arra",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TableGen/BackEnds.rst:16795,variab,variable,16795,interpreter/llvm-project/llvm/docs/TableGen/BackEnds.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TableGen/BackEnds.rst,1,['variab'],['variable']
Modifiability,"ving<WhenToPreserveLocation>` and; :ref:`merging<WhenToMergeLocation>` debug locations do not apply. The API to; use is ``Instruction::dropLocation()``. The purpose of this rule is to prevent erratic or misleading single-stepping; behavior in situations in which an instruction has no clear, unambiguous; relationship to a source location. To handle an instruction without a location, the DWARF generator; defaults to allowing the last-set location after a label to cascade forward, or; to setting a line 0 location with viable scope information if no previous; location is available. See the discussion in the section about; :ref:`merging locations<WhenToMergeLocation>` for examples of when the rule for; dropping locations applies. Rules for updating debug values; ===============================. Deleting an IR-level Instruction; --------------------------------. When an ``Instruction`` is deleted, its debug uses change to ``undef``. This is; a loss of debug info: the value of one or more source variables becomes; unavailable, starting with the ``llvm.dbg.value(undef, ...)``. When there is no; way to reconstitute the value of the lost instruction, this is the best; possible outcome. However, it's often possible to do better:. * If the dying instruction can be RAUW'd, do so. The; ``Value::replaceAllUsesWith`` API transparently updates debug uses of the; dying instruction to point to the replacement value. * If the dying instruction cannot be RAUW'd, call ``llvm::salvageDebugInfo`` on; it. This makes a best-effort attempt to rewrite debug uses of the dying; instruction by describing its effect as a ``DIExpression``. * If one of the **operands** of a dying instruction would become trivially; dead, use ``llvm::replaceAllDbgUsesWith`` to rewrite the debug uses of that; operand. Consider the following example function:. .. code-block:: llvm. define i16 @foo(i16 %a) {; %b = sext i16 %a to i32; %c = and i32 %b, 15; call void @llvm.dbg.value(metadata i32 %c, ...); %d = trunc i32 %c ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToUpdateDebugInfo.rst:6691,variab,variables,6691,interpreter/llvm-project/llvm/docs/HowToUpdateDebugInfo.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToUpdateDebugInfo.rst,1,['variab'],['variables']
Modifiability,"vironment; r[""df2""]<<df2;; r<<""print(df2)"";; ~~~; Output. ~~~{.sh}; v1 v2 v3; 1 0.1 3 v1; 2 0.2 2 v2; 3 0.3 1 v3; ~~~. ~~~{.cxx}; ///////////////////////////////////////////; //Working with columns between dataframes//; ///////////////////////////////////////////. //passing values from column v3 of df2 to var1 of df1; df2[""v3""]>>df1[""var1""];; //updating df1 in R's environment; r[""df1""]<<df1;; r<<""print(df1)"";; ~~~. Output. ~~~{.sh}; var1 var2 var3 strings var4; 1 v1 0.101 1 v1 -1; 2 v2 0.202 2 v2 -2; 3 v3 0.303 3 v3 -3; ~~~. ## Plotting with R's graphical system.; ROOTR supports an eventloop for R's graphical system which allows plotting using the R functions to the; graphical system or generating images(ps, pdf png, etc).; You can find a demo in Interpolation below in examples section. ## Interactive Mode; The interactive mode lets you get the R's command line within ROOT's command line to run R code with tab completion support.; The variables created in the interactive mode can be passed to ROOT with TRObjectProxy and the method ParseEval?.; To initialize the interactive mode just call Interactive() method and type "".q"" to exit from R's prompt and to go to the ROOT's prompt again. ~~~{.cxx}; [omazapa] [tuxhome] [~]$ root -l; root [0] #include<TRInterface.h>; root [1] ROOT::R::TRInterface &r=ROOT::R::TRInterface::Instance();; root [2] r.Interactive(); [r]:a=seq; seq seq_along seq.Date seq.default seq.int seq_len seq.POSIXt sequence; [r]:a=seq(1,5,0.5); [r]:.q; root [3] TVectorD v=r.ParseEval(""a"");; root [4] v.Print(). Vector (9) is as follows. | 1 |; ------------------; 0 |1; 1 |1.5; 2 |2; 3 |2.5; 4 |3; 5 |3.5; 6 |4; 7 |4.5; 8 |5. root [4]; ~~~. ## Examples; The examples can also be found in `$ROOTSYS/tutorials/r`. ## Creating a Functor; A functor is a class which wraps a function, very useful when states and properties; associated to that function are needed.; In this example I show how to give support to a custom class to be used in R's environment,; which at the ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/r/doc/users-guide/ROOTR_Users_Guide.md:11233,variab,variables,11233,bindings/r/doc/users-guide/ROOTR_Users_Guide.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/r/doc/users-guide/ROOTR_Users_Guide.md,1,['variab'],['variables']
Modifiability,"vm-profdata); set(PGO_OPT -DLLVM_PROFDATA=${LLVM_RUNTIME_OUTPUT_INTDIR}/llvm-profdata); endif(). if(LLVM_BUILD_INSTRUMENTED); add_dependencies(clang-bootstrap-deps generate-profdata); set(PGO_OPT -DLLVM_PROFDATA_FILE=${CMAKE_CURRENT_BINARY_DIR}/utils/perf-training/clang.profdata); # Use the current tools for LTO instead of the instrumented ones; list(APPEND _BOOTSTRAP_DEFAULT_PASSTHROUGH; CMAKE_CXX_COMPILER; CMAKE_C_COMPILER; CMAKE_ASM_COMPILER; CMAKE_AR; CMAKE_RANLIB; DARWIN_LTO_LIBRARY; DYLD_LIBRARY_PATH). set(COMPILER_OPTIONS); set(LTO_LIBRARY); set(LTO_AR); set(LTO_RANLIB); endif(). # Populate the passthrough variables; foreach(variableName ${CLANG_BOOTSTRAP_PASSTHROUGH} ${_BOOTSTRAP_DEFAULT_PASSTHROUGH}); if(DEFINED ${variableName}); if(""${${variableName}}"" STREQUAL """"); set(value """"); else(); string(REPLACE "";"" ""|"" value ""${${variableName}}""); endif(); list(APPEND PASSTHROUGH_VARIABLES; -D${variableName}=${value}); endif(); endforeach(). # Find all variables that start with BOOTSTRAP_ and populate a variable with; # them.; get_cmake_property(variableNames VARIABLES); foreach(variableName ${variableNames}); if(variableName MATCHES ""^BOOTSTRAP_""); string(SUBSTRING ${variableName} 10 -1 varName); string(REPLACE "";"" ""|"" value ""${${variableName}}""); list(APPEND PASSTHROUGH_VARIABLES; -D${varName}=${value}); endif(); if(${variableName} AND variableName MATCHES ""LLVM_EXTERNAL_.*_SOURCE_DIR""); list(APPEND PASSTHROUGH_VARIABLES; -D${variableName}=${${variableName}}); endif(); endforeach(). # Build arguments for native tool used in CMake.; set(build_configuration ""$<CONFIG>""); set(build_tool_args ""${LLVM_EXTERNAL_PROJECT_BUILD_TOOL_ARGS}""); if(NOT build_tool_args STREQUAL """"); string(PREPEND build_tool_args ""-- ""); separate_arguments(build_tool_args UNIX_COMMAND ""${build_tool_args}""); endif(). ExternalProject_Add(${NEXT_CLANG_STAGE}; DEPENDS clang-bootstrap-deps; PREFIX ${NEXT_CLANG_STAGE}; SOURCE_DIR ${CMAKE_SOURCE_DIR}; STAMP_DIR ${STAMP_DIR}; BINARY_DIR ${BINARY_DIR}",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/CMakeLists.txt:27164,variab,variables,27164,interpreter/llvm-project/clang/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/CMakeLists.txt,2,['variab'],"['variable', 'variables']"
Modifiability,"vm.dbg.assign`; intrinsics similarly to `llvm.dbg.declare` intrinsics. Clone the; `llvm.dbg.assign` intrinsics linked to the store, update the FragmentInfo in; the `ValueExpression`, and give the split stores (and cloned intrinsics) new; `DIAssignID` attachments each. In other words, treat the split stores as; separate assignments. For partial DSE (e.g. shortening a memset), we do the; same except that `llvm.dbg.assign` for the dead fragment gets an `Undef`; `Address`. **Promoting** allocas and store/loads: `llvm.dbg.assign` intrinsics implicitly; describe joined values in memory locations at CFG joins, but this is not; necessarily the case after promoting (or partially promoting) the; variable. Passes that promote variables are responsible for inserting; `llvm.dbg.assign` intrinsics after the resultant PHIs generated during; promotion. `mem2reg` already has to do this (with `llvm.dbg.value`) for; `llvm.dbg.declare`s. Where a store has no linked intrinsic, the store is; assumed to represent an assignment for variables stored at the destination; address. #### Debug intrinsic updates. **Moving** a debug intrinsic: avoid moving `llvm.dbg.assign` intrinsics where; possible, as they represent a source-level assignment, whose position in the; program should not be affected by optimization passes. **Deleting** a debug intrinsic: Nothing new to do. Just like for conventional; debug intrinsics, unless it is unreachable, it’s almost always incorrect to; delete a `llvm.dbg.assign` intrinsic. ### Lowering `llvm.dbg.assign` to MIR. To begin with only SelectionDAG ISel will be supported. `llvm.dbg.assign`; intrinsics are lowered to MIR `DBG_INSTR_REF` instructions. Before this happens; we need to decide where it is appropriate to use memory locations and where we; must use a non-memory location (or no location) for each variable. In order to; make those decisions we run a standard fixed-point dataflow analysis that makes; the choice at each instruction, iteratively joining the re",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AssignmentTracking.md:8373,variab,variables,8373,interpreter/llvm-project/llvm/docs/AssignmentTracking.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AssignmentTracking.md,1,['variab'],['variables']
Modifiability,"volatile compound operations; P2327R1; Clang 15. Support for #warning; P2437R1; Yes. Remove non-encodable wide character literals and multicharacter wide character literals; P2362R3; Clang 14. Labels at the end of compound statements; P2324R2; Clang 16. Delimited escape sequences; P2290R3; Clang 15. Named universal character escapes; P2071R2; Clang 15. Relaxing some constexpr restrictions; P2448R2. Clang 17 (Partial); 	 We do not support outside of defaulted special memeber functions the change that constexpr functions no; longer have to be constexpr compatible but rather support a less restricted requirements for constexpr; functions. Which include allowing non-literal types as return values and parameters, allow calling of; non-constexpr functions and constructors.; . Using unknown pointers and references in constant expressions; P2280R4 (DR); No. static operator(); P1169R4; Clang 16. Extended floating-point types and standard names; P1467R9; No. Class template argument deduction from inherited constructors; P2582R1; No. Portable assumptions; P1774R8; No. Support for UTF-8 as a portable source file encoding; P2295R6; Clang 15. char8_t Compatibility and Portability Fix; P2513R3; Clang 16. Relax requirements on wchar_t to match existing practices; P2460R2; Yes. Explicit lifetime management; P2590R2; No. static operator[]; P2589R1; Clang 16. Permitting static constexpr variables in constexpr functions; P2647R1; Clang 16. consteval needs to propagate up; P2564R3 (DR); Clang 17. Lifetime extension in range-based for loops; P2718R0; No. Referencing The Unicode Standard; P2736R2; Yes. C++20 implementation status; Clang has support for some of the features of the; ISO C++ 2020 standard.; You can use Clang in C++20 mode with the -std=c++20 option; (use -std=c++2a in Clang 9 and earlier). List of features and minimum Clang version with support. Language Feature; C++20 Proposal; Available in Clang?. Default member initializers for bit-fields; P0683R1; Clang 6. const&-qualifi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/cxx_status.html:4905,inherit,inherited,4905,interpreter/llvm-project/clang/www/cxx_status.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/cxx_status.html,2,['inherit'],['inherited']
Modifiability,"w is set to highlight as 'llvm', despite that we; have misc.highlighting_failure set?. .. code-block:: text. declare !callback !1 dso_local i32 @pthread_create(ptr, ptr, ptr, ptr). ...; !2 = !{i64 2, i64 3, i1 false}; !1 = !{!2}. Another example is shown below. The callback callee is the second argument of; the ``__kmpc_fork_call`` function (``i64 2``). The callee is given two unknown; values (each identified by a ``i64 -1``) and afterwards all; variadic arguments that are passed to the ``__kmpc_fork_call`` call (due to the; final ``i1 true``). .. FIXME why does the llvm-sphinx-docs builder give a highlighting; error if the below is set to highlight as 'llvm', despite that we; have misc.highlighting_failure set?. .. code-block:: text. declare !callback !0 dso_local void @__kmpc_fork_call(ptr, i32, ptr, ...). ...; !1 = !{i64 2, i64 -1, i64 -1, i1 true}; !0 = !{!1}. '``exclude``' Metadata; ^^^^^^^^^^^^^^^^^^^^^^. ``exclude`` metadata may be attached to a global variable to signify that its; section should not be included in the final executable or shared library. This; option is only valid for global variables with an explicit section targeting ELF; or COFF. This is done using the ``SHF_EXCLUDE`` flag on ELF targets and the; ``IMAGE_SCN_LNK_REMOVE`` and ``IMAGE_SCN_MEM_DISCARDABLE`` flags for COFF; targets. Additionally, this metadata is only used as a flag, so the associated; node must be empty. The explicit section should not conflict with any other; sections that the user does not want removed after linking. .. code-block:: text. @object = private constant [1 x i8] c""\00"", section "".foo"" !exclude !0. ...; !0 = !{}. '``unpredictable``' Metadata; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. ``unpredictable`` metadata may be attached to any branch or switch; instruction. It can be used to express the unpredictability of control; flow. Similar to the llvm.expect intrinsic, it may be used to alter; optimizations related to compare and branch instructions. The metadata; is treated as a ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:291430,variab,variable,291430,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['variab'],['variable']
Modifiability,"w option, *ValidationSize* has been added to the global options for `MethodDL`.; The same option is also available in the `PyKeras` method of `PyMVA`; - The fast tanh implementation from VDT is now used as activation function when training the network on CPU.; - Using `Cblas` from the GSL library is supported for CPU training when no other Blas libraries are found. However, it is strongly recommended, to use an optimized Blas implementation such as `libopenblas`, that is; available in cvmfs.; - Add several performance optimizations for both CPU and GPU versions of `MethodDL`. . ### Other New TMVA Features. - Add a new option to the `DataLoader` to switch off computation of correlation matrix. The new option is called *CalcCorrelations* and it should be used when a large number of input variables are; provided, otherwise TMVA will spend a long time in setting up the data set before training. ; ; - Build configuration:; - Add new cmake flags, `tmva-cpu` and `tmva-gpu`, which can be used to swicth on/off the CPU and GPU (based on CUDA) implementations of the TMVA Deep Learning module. `tmva-cpu` is enabled by; default if a Blas or CBlas library is found in the system. `tmva-gpu` is enabled when the cmake flag `cuda` is enabled and a compatible Cuda library is found. ; enabled if the corre; - Add possibility to independently configure building of optional pymva part of tmva with flag `-Dpymva=ON|OFF`. - New Cross Validation features:; - Add stratified splitting for cross validation.; - New plotting option in cross validation, average ROC curve. - Bugfixes:; - Fix bug in BDT training with imt=on; - Improved handling of large event numbers in cross validation using deterministic splitting. - Documentation:; - Update TMVA Users' guide. ## 2D Graphics Libraries. - Highlight mode is implemented for `TH1` and for `TGraph` classes. When; highlight mode is on, mouse movement over the bin will be represented; graphically. Histograms bins or graph points will be highlighted. Moreo",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v616/index.md:15448,config,configuration,15448,README/ReleaseNotes/v616/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v616/index.md,1,['config'],['configuration']
Modifiability,"w to pass a string or a list of objects. The; TProof::EnablePackage interface has been extended to support this.Optimize; the validation step in the case not all the entries are required. The; validation step is stopped as soon as the requested number of events is; reached. If the parameter ""PROOF_ValidateByFile"" is set to 1, the; number of files is exactly what needed; otherwise the number of files; may exceed the number of files needed by (Number_Of_Workers - 1) .; New directive 'xpd.datadir' to better control the user data directories and their permission settings. In TPacketizerUnit, add the possibility to exactly share the number of cycles between the workers.; See the parameter PROOF_PacketizerFixedNum.Implement; a timer to terminate idle sessions. The timeout value is controlled by; the variable ProofServ.IdleTimeout (value in seconds). This variable; can be set for all sessions in the xproofd config file via the 'xpd.putrc' directive.; Add the possibility to control the use of sub-mergers with; the ROOTrc variable Proof.SubMergers. It has the same meaning of the; parameter 'PROOF_UseMergers'. The capabilities of the latter have been; extended: now -1 means disable the use of submergers (before  negative values were ignored and there was no way for the user to disable the use of submergers). . Packetizer optimizations: improved worked distribution when; the number of files left to be processed is smaller than the number of; workers and at least one file has a number of events significantly; larger than the average; better apply the upper/lower limits on the; expected packet processing time.; Add the possibility to single-out disk partitions in the; packetizer; this works adding the beginning of a path in the name; defining a new TFileNode (e.g. 'host://disk1' instead of 'host' only as; it was so far). These feature can be enabled by defining the rootrc; variable 'Packetizer.Partitions', e.g.;            Packetizer.Partitions  /disk1,/disk2,/disk3; Add to the ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html:6787,variab,variable,6787,proof/doc/v528/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html,2,['variab'],['variable']
Modifiability,"w-tests. List all of the discovered tests and exit. EXIT STATUS; -----------. :program:`lit` will exit with an exit code of 1 if there are any FAIL or XPASS; results. Otherwise, it will exit with the status 0. Other exit codes are used; for non-test related failures (for example a user error or an internal program; error). .. _test-discovery:. TEST DISCOVERY; --------------. The inputs passed to :program:`lit` can be either individual tests, or entire; directories or hierarchies of tests to run. When :program:`lit` starts up, the; first thing it does is convert the inputs into a complete list of tests to run; as part of *test discovery*. In the :program:`lit` model, every test must exist inside some *test suite*.; :program:`lit` resolves the inputs specified on the command line to test suites; by searching upwards from the input path until it finds a :file:`lit.cfg` or; :file:`lit.site.cfg` file. These files serve as both a marker of test suites; and as configuration files which :program:`lit` loads in order to understand; how to find and run the tests inside the test suite. Once :program:`lit` has mapped the inputs into test suites it traverses the; list of inputs adding tests for individual files and recursively searching for; tests in directories. This behavior makes it easy to specify a subset of tests to run, while still; allowing the test suite configuration to control exactly how tests are; interpreted. In addition, :program:`lit` always identifies tests by the test; suite they are in, and their relative path inside the test suite. For; appropriately configured projects, this allows :program:`lit` to provide; convenient and flexible support for out-of-tree builds. .. _test-status-results:. TEST STATUS RESULTS; -------------------. Each test ultimately produces one of the following eight results:. **PASS**. The test succeeded. **FLAKYPASS**. The test succeeded after being re-run more than once. This only applies to; tests containing an ``ALLOW_RETRIES:`` annot",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/lit.rst:11582,config,configuration,11582,interpreter/llvm-project/llvm/docs/CommandGuide/lit.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/lit.rst,1,['config'],['configuration']
Modifiability,"wait await_counter{};; a++; // __int_32_0 is still 43 here!!; std::cout << a << ""\n"";; a++; // Why is __int_32_0 still 43 here?; std::cout << a << ""\n"";; }. When debugging step-by-step, the value of `__int_32_0` seemingly does not; change, despite being frequently incremented, and instead is always `43`.; While this might be surprising, this is a result of the optimizer recognizing; that it can eliminate most of the load/store operations. The above code gets; optimized to the equivalent of:. .. code-block:: c++. static task coro_task(int v) {; store v to __int_32_0 in the frame; co_await await_counter{};; a = load __int_32_0; std::cout << a+1 << ""\n"";; std::cout << a+2 << ""\n"";; std::cout << a+3 << ""\n"";; co_await await_counter{};; a = load __int_32_0; std::cout << a+4 << ""\n"";; std::cout << a+5 << ""\n"";; }. It should now be obvious why the value of `__int_32_0` remains unchanged; throughout the function. It is important to recognize that `__int_32_0`; does not directly correspond to `a`, but is instead a variable generated; to assist the compiler in code generation. The variables in an optimized; coroutine frame should not be thought of as directly representing the; variables in the C++ source. Get the suspended points; ========================. An important requirement for debugging coroutines is to understand suspended; points, which are where the coroutine is currently suspended and awaiting. For simple cases like the above, inspecting the value of the `__coro_index`; variable in the coroutine frame works well. However, it is not quite so simple in really complex situations. In these; cases, it is necessary to use the coroutine libraries to insert the; line-number. For example:. .. code-block:: c++. // For all the promise_type we want:; class promise_type {; ...; + unsigned line_number = 0xffffffff;; };. #include <source_location>. // For all the awaiter types we need:; class awaiter {; ...; template <typename Promise>; void await_suspend(std::coroutine_handle<Pr",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DebuggingCoroutines.rst:10257,variab,variable,10257,interpreter/llvm-project/clang/docs/DebuggingCoroutines.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DebuggingCoroutines.rst,1,['variab'],['variable']
Modifiability,"warn; log();; if (a > b); return a;; return b;; }. int maxClone(int x, int y) { // similar code here; log();; if (x > y); return x;; return y;; }. alpha.core; ^^^^^^^^^^. .. _alpha-core-BoolAssignment:. alpha.core.BoolAssignment (ObjC); """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; Warn about assigning non-{0,1} values to boolean variables. .. code-block:: objc. void test() {; BOOL b = -1; // warn; }. .. _alpha-core-C11Lock:. alpha.core.C11Lock; """"""""""""""""""""""""""""""""""""; Similarly to :ref:`alpha.unix.PthreadLock <alpha-unix-PthreadLock>`, checks for; the locking/unlocking of ``mtx_t`` mutexes. .. code-block:: cpp. mtx_t mtx1;. void bad1(void); {; mtx_lock(&mtx1);; mtx_lock(&mtx1); // warn: This lock has already been acquired; }. .. _alpha-core-CallAndMessageUnInitRefArg:. alpha.core.CallAndMessageUnInitRefArg (C,C++, ObjC); """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; Check for logical errors for function calls and Objective-C; message expressions (e.g., uninitialized arguments, null function pointers, and pointer to undefined variables). .. code-block:: c. void test(void) {; int t;; int &p = t;; int &s = p;; int &q = s;; foo(q); // warn; }. void test(void) {; int x;; foo(&x); // warn; }. .. _alpha-core-CastSize:. alpha.core.CastSize (C); """"""""""""""""""""""""""""""""""""""""""""""; Check when casting a malloc'ed type ``T``, whether the size is a multiple of the size of ``T``. .. code-block:: c. void test() {; int *x = (int *) malloc(11); // warn; }. .. _alpha-core-CastToStruct:. alpha.core.CastToStruct (C, C++); """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; Check for cast from non-struct pointer to struct pointer. .. code-block:: cpp. // C; struct s {};. void test(int *p) {; struct s *ps = (struct s *) p; // warn; }. // C++; class c {};. void test(int *p) {; c *pc = (c *) p; // warn; }. .. _alpha-core-Conversion:. alpha.core.Conversion (C, C++, ObjC); """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; Loss of sign/precision in implicit conversions. .. code-block:: c. void test(unsigned U, signed S) {; if (S > 10) {; if ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/checkers.rst:48025,variab,variables,48025,interpreter/llvm-project/clang/docs/analyzer/checkers.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/checkers.rst,1,['variab'],['variables']
Modifiability,"way, any character can; be used in a name value, even quotes themselves. The ``""\01""`` prefix; can be used on global values to suppress mangling.; #. Unnamed values are represented as an unsigned numeric value with; their prefix. For example, ``%12``, ``@2``, ``%44``.; #. Constants, which are described in the section Constants_ below. LLVM requires that values start with a prefix for two reasons: Compilers; don't need to worry about name clashes with reserved words, and the set; of reserved words may be expanded in the future without penalty.; Additionally, unnamed identifiers allow a compiler to quickly come up; with a temporary variable without having to avoid symbol table; conflicts. Reserved words in LLVM are very similar to reserved words in other; languages. There are keywords for different opcodes ('``add``',; '``bitcast``', '``ret``', etc...), for primitive type names ('``void``',; '``i32``', etc...), and others. These reserved words cannot conflict; with variable names, because none of them start with a prefix character; (``'%'`` or ``'@'``). Here is an example of LLVM code to multiply the integer variable; '``%X``' by 8:. The easy way:. .. code-block:: llvm. %result = mul i32 %X, 8. After strength reduction:. .. code-block:: llvm. %result = shl i32 %X, 3. And the hard way:. .. code-block:: llvm. %0 = add i32 %X, %X ; yields i32:%0; %1 = add i32 %0, %0 ; yields i32:%1; %result = add i32 %1, %1. This last way of multiplying ``%X`` by 8 illustrates several important; lexical features of LLVM:. #. Comments are delimited with a '``;``' and go until the end of line.; #. Unnamed temporaries are created when the result of a computation is; not assigned to a named value.; #. By default, unnamed temporaries are numbered sequentially (using a; per-function incrementing counter, starting with 0). However, when explicitly; specifying temporary numbers, it is allowed to skip over numbers. Note that basic blocks and unnamed function parameters are included in this; number",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:4359,variab,variable,4359,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['variab'],['variable']
Modifiability,"well as the; `>>` operator overloads, are implemented only if you use `ClassDef` and; `ClassImp`. See `$ROOTSYS/include/Rtypes.h` for the definition of; `ClassDef` and `ClassImp`. To exclude a data member from the `Streamer`,; add a `!` as the first character in the comments of the field:. ``` {.cpp}; Int_t fTempValue; //! temporary state value; ```. ### The LinkDef.h File. **Step 3:** The `LinkDef.h` file tells `rootcling` which classes should; be added to the dictionary. ``` {.cpp}; #ifdef __CLING__; #pragma link C++ class SClass;; #endif; ```. Three options can trail the class name:. - `-` : tells `rootcling` **not** to generate the `Streamer` method for; this class. This is necessary for those classes that need a; customized `Streamer` method. ``` {.cpp}; #pragma link C++ class SClass-; // no streamer; ```. - **`!`** : tells `rootcling` **not** to generate the; `operator>>(`**`TBuffer`** `&b,MyClass *&obj)` method for this; class. This is necessary to be able to write pointers to objects of; classes not inheriting from **`TObject`**. ``` {.cpp}; #pragma link C++ class SClass!; // no >> operator; // or; #pragma link C++ class SClass-!; // no streamer, no >> operator; ```. - **+** : in ROOT version 1 and 2 tells `rootcling` to generate a; `Streamer` with extra byte count information. This adds an integer; to each object in the output buffer, but it allows for powerful; error correction in case a `Streamer` method is out of sync with; data in the file. The `+` option is mutual exclusive with both the; `-` and `!` options. IMPORTANT NOTE: In ROOT Version 3 and later, a ""+"" after the class name; tells `rootcling` to use the new I/O system. The byte count check is; always added. The new I/O system has many advantages including support; automatic schema evolution, full support for STL collections and better; run-time performance. We strongly recommend using it. ``` {.cpp}; #pragma link C++ class SClass+; // add byte count; ```. For information on `Streamers` see ""Input/",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/AddingaClass.md:21756,inherit,inheriting,21756,documentation/users-guide/AddingaClass.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/AddingaClass.md,1,['inherit'],['inheriting']
Modifiability,"which return a reference object and a pointer object respectively. ~~~{.cxx}; #include<TRInterface.h>; ROOT::R::TRInterface &r=ROOT::R::TRInterface::Instance();; ~~~. ## Running R code and passing/getting variables.; We have different ways to run R code and pass/obtain data to/from R environment: using the methods Execute(code) and; Eval(code). ~~~{.cxx}; #include<TRInterface.h>. //creating an instance; ROOT::R::TRInterface &r=ROOT::R::TRInterface::Instance();; //executing simple r commands with the operator <<; r<<""print('hello ROOTR')"";; r<<""vec=c(1,2,3)""<<""print(vec)"";. //executing R's code using the method Execute that doesn't return anything; r.Execute(""print('hello ROOTR')"");. //We execute the code using the method Eval which returns an instance of TRObjectProxy; //which can be converted to a ROOTR supported classes; std::vector<Int_t> v=r.Eval(""c(1,2,3)"");; std::cout<<v[0]<<"" ""<<v[1]<<"" ""<<v[2]<<std::endl;. std::vector<Double_t> vd(3);. //obtaining variables from R environment using the operators [] and >>; r[""seq(0,1,0.5)""]>>vd;; std::cout<<vd[0]<<"" ""<<vd[1]<<"" ""<<vd[2]<<std::endl;. std::vector<Int_t> v1(3);; v1[0]=0;; v1[1]=1;; v1[2]=2;. r[""v1""]<<v1;; r<<""print(v1)"";. TMatrixD m(2,2);. //Creating a matrix inside r environment and converting it into a TMatrixD; r<<""mat<-matrix(c(0.1,0.2,0.3,0.4),nrow=2)"";; r[""mat""]>>m;; m.Print();; ~~~; So, working with ROOTR is like working with flows of data to pass, obtain and process data. ## Passing functions from ROOT to R; You can pass functions from ROOT to R using the operators `<<` and `=` or using the class TRFunction, but the arguments and datatypes of the return value cannot be pointers. They must be ROOTR supported datatypes.; So instead of using `*Double_t` you must use `std::vector` and instead of `*Char_t` use TString or `std::string`. For this example we need to create a macro, so save it as fun.C. ~~~{.cxx}; #include<TRInterface.h>; #include<TMath.h>. Double_t myfun(Double_t x); {; return 2*cos(x);; }. Dou",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/r/doc/users-guide/ROOTR_Users_Guide.md:4534,variab,variables,4534,bindings/r/doc/users-guide/ROOTR_Users_Guide.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/r/doc/users-guide/ROOTR_Users_Guide.md,1,['variab'],['variables']
Modifiability,"while `TRandom3` generates only 32 bit random numbers.; * `TRandomRanlux48` - 48 bit Ranlux generator. Note that `TRandom1` is a 24 bit generator. ; * Improve thread safety of `TMinuit` constructor [ROOT-8217]; * Vc has ben removed from the ROOT sources. If the option 'vc' is enabled, the package will be searched (by default),; alternatively the source tarfile can be downloded and build with the option 'builtin_vc'. ## TMVA Libraries. * New `DataLoader` class that allows flexibility in variable and dataset selection. ; * New Deep Neural Network. Three different versions are available, which can be selected with the 'Architecture' option. See also the tutorial`tmva/TMVAClassification.C` for using the new DNN.; * `Architecture=STANDARD` to select the earlier version.; * `Architecture=CPU` to select the newer version for CPU, but designed also for GPU and optimized for speed and with multi-class support. ; * `Architecture=GPU` to select the newer GPU version. Requires configuration of ROOT with CUDA or OpenCL enabled. ; * Support for Cross Validation (see tutorial `tmva/TMVACrossValidation` as an example).; * Support for Hyper-Parameter tuning for BDT and SVM methods.; * New Variable Importance algorithm independent of the MVA method.; * New Loss Function class for regression.; * Improvements in the SVM method: new kernel functions.; * New `ROCCurve` class. ; * New interface to Keras (PyKeras) available in the PyMVA library.; * Support for Jupyter notebooks; * Support for all the functionality available in GUI: preprocessing, variable correlations, classifier output.; * New classifier visualization for BDT, ANN and DNN.; * Interactive training for all methods. ## 2D Graphics Libraries. * In `TColor::SetPalette`, make sure the high quality palettes are defined; only once taking care of transparency. Also `CreateGradientColorTable` has been; simplified.; * New fast constructor for `TColor` avoiding to call `gROOT->GetColor()`. The; normal constructor generated a big slow",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:13062,config,configuration,13062,README/ReleaseNotes/v608/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md,1,['config'],['configuration']
Modifiability,"will cause the caller to gain the attribute. This is intended; to provide a maximally conservative model where the code in a function; annotated with this attribute will always (even after inlining) end up; hardened.; ``speculatable``; This function attribute indicates that the function does not have any; effects besides calculating its result and does not have undefined behavior.; Note that ``speculatable`` is not enough to conclude that along any; particular execution path the number of calls to this function will not be; externally observable. This attribute is only valid on functions; and declarations, not on individual call sites. If a function is; incorrectly marked as speculatable and really does exhibit; undefined behavior, the undefined behavior may be observed even; if the call site is dead code. ``ssp``; This attribute indicates that the function should emit a stack; smashing protector. It is in the form of a ""canary"" --- a random value; placed on the stack before the local variables that's checked upon; return from the function to see if it has been overwritten. A; heuristic is used to determine if a function needs stack protectors; or not. The heuristic used will enable protectors for functions with:. - Character arrays larger than ``ssp-buffer-size`` (default 8).; - Aggregates containing character arrays larger than ``ssp-buffer-size``.; - Calls to alloca() with variable sizes or constant sizes greater than; ``ssp-buffer-size``. Variables that are identified as requiring a protector will be arranged; on the stack such that they are adjacent to the stack protector guard. If a function with an ``ssp`` attribute is inlined into a calling function,; the attribute is not carried over to the calling function. ``sspstrong``; This attribute indicates that the function should emit a stack smashing; protector. This attribute causes a strong heuristic to be used when; determining if a function needs stack protectors. The strong heuristic; will enable protectors f",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:102831,variab,variables,102831,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['variab'],['variables']
Modifiability,"will match only #1. Matcher<Decl>isInstantiated; Matches declarations that are template instantiations or are inside; template instantiations. Given; template<typename T> void A(T t) { T i; }; A(0);; A(0U);; functionDecl(isInstantiated()); matches 'A(int) {...};' and 'A(unsigned) {...}'. Matcher<Decl>isPrivate; Matches private C++ declarations and C++ base specifers that specify private; inheritance. Examples:; class C {; public: int a;; protected: int b;; private: int c; // fieldDecl(isPrivate()) matches 'c'; };. struct Base {};; struct Derived1 : private Base {}; // matches 'Base'; class Derived2 : Base {}; // matches 'Base'. Matcher<Decl>isProtected; Matches protected C++ declarations and C++ base specifers that specify; protected inheritance. Examples:; class C {; public: int a;; protected: int b; // fieldDecl(isProtected()) matches 'b'; private: int c;; };. class Base {};; class Derived : protected Base {}; // matches 'Base'. Matcher<Decl>isPublic; Matches public C++ declarations and C++ base specifers that specify public; inheritance. Examples:; class C {; public: int a; // fieldDecl(isPublic()) matches 'a'; protected: int b;; private: int c;; };. class Base {};; class Derived1 : public Base {}; // matches 'Base'; struct Derived2 : Base {}; // matches 'Base'. Matcher<DesignatedInitExpr>designatorCountIsunsigned N; Matches designated initializer expressions that contain; a specific number of designators. Example: Given; point ptarray[10] = { [2].y = 1.0, [0].x = 1.0 };; point ptarray2[10] = { [2].y = 1.0, [2].x = 0.0, [0].x = 1.0 };; designatorCountIs(2); matches '{ [2].y = 1.0, [0].x = 1.0 }',; but not '{ [2].y = 1.0, [2].x = 0.0, [0].x = 1.0 }'. Matcher<EnumDecl>isScoped; Matches C++11 scoped enum declaration. Example matches Y (matcher = enumDecl(isScoped())); enum X {};; enum class Y {};. Matcher<Expr>isInstantiationDependent; Matches expressions that are instantiation-dependent even if it is; neither type- nor value-dependent. In the following example, the",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LibASTMatchersReference.html:85257,inherit,inheritance,85257,interpreter/llvm-project/clang/docs/LibASTMatchersReference.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LibASTMatchersReference.html,2,['inherit'],['inheritance']
Modifiability,"will not need to change your Makefile. A batch program that does not have a graphic display, which creates,; fills, and saves histograms and trees, only needs to link the core; libraries (`libCore`, `libRIO`), `libHist` and `libTree`.; If ROOT needs access to other libraries, it loads them dynamically.; For example, if the **`TreeViewer`** is used, `libTreePlayer` and all; libraries `libTreePlayer` depends on are loaded also. The dependent; libraries are shown in the ROOT reference guide's library dependency; graph. The difference between reference guide `libHist` and; `libHistPainter` is that the former needs to be explicitly linked and; the latter will be loaded automatically at runtime when ROOT needs it,; by means of the Plugin Manager. plugin manager. In the Figure 1-2, the libraries represented by green boxes outside of; the core are loaded via the plugin manager plugin manager or; equivalent techniques, while the white ones are not. Of course, if one; wants to access a plugin library directly, it has to be explicitly; linked. An example of a plugin library is `libMinuit`. To create and; fill histograms you need to link `libHist.so`. If the code has a call; to fit the histogram, the ""fitter"" will dynamically load libMinuit if; it is not yet loaded. #### Plugins: Runtime Library Dependencies for Linking. plugin manager The Plugin Manager **`TPluginManager`** allows; postponing library dependencies to runtime: a plugin library will only; be loaded when it is needed. Non-plugins will need to be linked, and; are thus loaded at start-up. Plugins are defined by a base class (e.g.; **`TFile`**) that will be implemented in a plugin, a tag used to; identify the plugin (e.g. `^rfio:` as part of the protocol string),; the plugin class of which an object will be created; (e.g. **`TRFIOFile`**), the library to be loaded (in short; `libRFIO.so` to RFIO), and the constructor to be called (e.g.; ""`TRFIOFile()`""). This can be specified in the `.rootrc` which already; contains m",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Introduction.md:18634,plugin,plugin,18634,documentation/users-guide/Introduction.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Introduction.md,1,['plugin'],['plugin']
Modifiability,"wing descriptor for the trampoline function:. .. code-block:: text. !DISubprogram(name: ""sub1_.t0p"", linkageName: ""sub1_.t0p"", scope: !4, file: !4, type: !5, spFlags: DISPFlagLocalToUnit | DISPFlagDefinition, unit: !7, retainedNodes: !24, targetFuncName: ""sub1_""). The targetFuncName field is the name of the function that the trampoline; calls. This descriptor results in the following DWARF tag:. .. code-block:: text. DW_TAG_subprogram; ...; DW_AT_linkage_name	(""sub1_.t0p""); DW_AT_name	(""sub1_.t0p""); DW_AT_trampoline	(""sub1_""). Debugging information format; ============================. Debugging Information Extension for Objective C Properties; ----------------------------------------------------------. Introduction; ^^^^^^^^^^^^. Objective C provides a simpler way to declare and define accessor methods using; declared properties. The language provides features to declare a property and; to let compiler synthesize accessor methods. The debugger lets developer inspect Objective C interfaces and their instance; variables and class variables. However, the debugger does not know anything; about the properties defined in Objective C interfaces. The debugger consumes; information generated by compiler in DWARF format. The format does not support; encoding of Objective C properties. This proposal describes DWARF extensions to; encode Objective C properties, which the debugger can use to let developers; inspect Objective C properties. Proposal; ^^^^^^^^. Objective C properties exist separately from class members. A property can be; defined only by ""setter"" and ""getter"" selectors, and be calculated anew on each; access. Or a property can just be a direct access to some declared ivar.; Finally it can have an ivar ""automatically synthesized"" for it by the compiler,; in which case the property can be referred to in user code directly using the; standard C dereference syntax as well as through the property ""dot"" syntax, but; there is no entry in the ``@interface`` declaration co",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:49537,variab,variables,49537,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,2,['variab'],['variables']
Modifiability,"with GCC 5.4.0] on linux2; >>>> import cppyy_compat, cppyy; >>>>. You may have to set ``LD_LIBRARY_PATH`` appropriately if you get an; ``EnvironmentError`` (it will indicate the needed directory). Note that your python interpreter (whether CPython or ``pypy-c``) may not have; been linked by the C++ compiler.; This can lead to problems during loading of C++ libraries and program shutdown.; In that case, re-linking is highly recommended. Very old versions of PyPy (5.6.0 and earlier) have a built-in ``cppyy`` based; on `Reflex`_, which is less feature-rich and no longer supported.; However, both the :doc:`distribution utilities <utilities>` and user-facing; Python codes are very backwards compatible, making migration straightforward. Precompiled header; ------------------. For performance reasons (reduced memory and CPU usage), a precompiled header; (PCH) of the system and compiler header files will be installed or, failing; that, generated on startup.; Obviously, this PCH is not portable and should not be part of any wheel. Some compiler features, such as AVX, OpenMP, fast math, etc. need to be; active during compilation of the PCH, as they depend both on compiler flags; and system headers (for intrinsics, or API calls).; You can control compiler flags through the ``EXTRA_CLING_ARGS`` envar and thus; what is active in the PCH.; In principle, you can also change the C++ language standard by setting the; appropriate flag on ``EXTRA_CLING_ARGS`` and rebuilding the PCH.; However, if done at this stage, that disables some automatic conversion for; C++ types that were introduced after C++11 (such as ``string_view`` and; ``optional``). If you want multiple PCHs living side-by-side, you can generate them; yourself (note that the given path must be absolute)::. >>> import cppyy_backend.loader as l; >>> l.set_cling_compile_options(True) # adds defaults to EXTRA_CLING_ARGS; >>> install_path = '/full/path/to/target/location/for/PCH'; >>> l.ensure_precompiled_header(install_path).",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst:7727,portab,portable,7727,bindings/pyroot/cppyy/cppyy/doc/source/installation.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst,1,['portab'],['portable']
Modifiability,"with a maximum dimension depending on the; maximum number of parameters are now data members' arrays with a; dynamic dimension such that one can fit very large problems by; simply initializing the **`TMinuit`** constructor with the maximum; number of parameters. - The include file `Minuit.h` has been commented as much as possible; using existing comments in the code or the printed documentation. - The original `Minuit` subroutines are now member functions. - Constructors and destructor have been added. - Instead of passing the `FCN` function in the argument list, the; addresses of this function is stored as pointer in the data; members of the class. This is by far more elegant and flexible in; an interactive environment. The member function `SetFCN` can be; used to define this pointer. - The ROOT static function `Printf` is provided to replace all; format statements and to print on currently defined output file. - The functions `SetObjectFit/GetObjectFit` can be used inside the; `FCN` function to set/get a referenced object instead of using; global variables. - By default `fGraphicsMode` is true. When calling the `Minuit`; functions such as `mncont`, `mnscan`, or any `Minuit` command; invoking `mnplot`, `TMinuit::mnplot()` produces a **`TGraph`**; object pointed by `fPlot`. One can retrieve this object with; **`TMinuit`**`::GetPlot().` For example:. ``` {.cpp}; h->Fit(""gaus"");; gMinuit->Command(""SCAn 1"");; TGraph *gr = (TGraph*)gMinuit->GetPlot();; gr->SetMarkerStyle(21);; gr->Draw(""alp"");; ```. - To set `Minuit` in no graphics mode, call. ``` {.cpp}; gMinuit->SetGraphicsMode(kFALSE);; ```. ### Basic Concepts of Minuit. The `Minuit` package acts on a multi parameter FORTRAN function to; which one must give the generic name `FCN`. In the ROOT; implementation, the function `FCN` is defined via the `Minuit`; `SetFCN` member function when an histogram fitting is invoked. The; value of `FCN` will in general depend on one or more variable; parameters. ### The Transformati",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/FittingHistograms.md:54471,variab,variables,54471,documentation/users-guide/FittingHistograms.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/FittingHistograms.md,1,['variab'],['variables']
Modifiability,"with base classes; P0017R1; Clang 3.9. constexpr lambda expressions; P0170R1; Clang 5. Differing begin and end types in range-based for; P0184R0; Clang 3.9. Lambda capture of *this; P0018R3; Clang 3.9. Direct-list-initialization of enums; P0138R2; Clang 3.9. Hexadecimal floating-point literals; P0245R1; Yes. Using attribute namespaces without repetition; P0028R4; Clang 3.9. Dynamic memory allocation for over-aligned data; P0035R4; Clang 4. Template argument deduction for class templates; P0091R3; Clang 5. ; P0512R0. P0620R0 (DR); Clang 7. P0702R1 (DR); Clang 6. Non-type template parameters with auto type; P0127R2; Clang 4. Guaranteed copy elision; P0135R1; Clang 4. Stricter expression evaluation order; P0145R3; Clang 4 (9). P0400R0. Requirement to ignore unknown attributes; P0283R2; Yes. constexpr if-statements; P0292R2; Clang 3.9. Inline variables; P0386R2; Clang 3.9. Structured bindings; P0217R3; Clang 4. P0961R1 (DR); Clang 8. P0969R0 (DR); Clang 8. Separate variable and condition for if and switch; P0305R1; Clang 3.9. Matching template template parameters to compatible arguments; P0522R0; Partial (10). Removing deprecated dynamic exception specifications; P0003R5; Clang 4. Pack expansions in using-declarations; P0195R2; Clang 4. (8): This is a backwards-incompatible change that is applied to; all language versions that allow type deduction from auto; (per the request of the C++ committee).; In Clang 3.7, a warning is emitted for all cases that would change meaning. (9): Under the MS ABI, function parameters are destroyed from; left to right in the callee. As a result, function parameters in calls to; operator<<, operator>>, operator->*,; operator&&, operator||, and operator,; functions using expression syntax are no longer guaranteed to be destroyed in; reverse construction order in that ABI.; This is not fully supported during constant expression evaluation until Clang 12. (10): Despite being the resolution to a Defect Report, this; feature is disabled by defaul",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/cxx_status.html:11941,variab,variable,11941,interpreter/llvm-project/clang/www/cxx_status.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/cxx_status.html,2,['variab'],['variable']
Modifiability,"with bitcode files; is still supported. .. _`gold linker`: http://sourceware.org/binutils; .. _`GCC LTO`: http://gcc.gnu.org/wiki/LinkTimeOptimization; .. _`gold plugin interface`: http://gcc.gnu.org/wiki/whopr/driver. .. _lto-how-to-build:. How to build it; ===============. You need to have gold with plugin support and build the LLVMgold plugin.; The gold linker is installed as ld.gold. To see whether gold is the default; on your system, run ``/usr/bin/ld -v``. It will report ""GNU; gold"" or else ""GNU ld"" if not. If gold is already installed at; ``/usr/bin/ld.gold``, one option is to simply make that the default by; backing up your existing ``/usr/bin/ld`` and creating a symbolic link; with ``ln -s /usr/bin/ld.gold /usr/bin/ld``. Alternatively, you can build; with clang's ``-fuse-ld=gold`` or add ``-fuse-ld=gold`` to LDFLAGS, which will; cause the clang driver to invoke ``/usr/bin/ld.gold`` directly. If you have gold installed, check for plugin support by running; ``/usr/bin/ld.gold -plugin``. If it complains ""missing argument"" then; you have plugin support. If not, and you get an error such as ""unknown option"",; then you will either need to build gold or install a version with plugin; support. * Download, configure and build gold with plugin support:. .. code-block:: bash. $ git clone --depth 1 git://sourceware.org/git/binutils-gdb.git binutils; $ mkdir build; $ cd build; $ ../binutils/configure --enable-gold --enable-plugins --disable-werror; $ make all-gold. That should leave you with ``build/gold/ld-new`` which supports; the ``-plugin`` option. Running ``make`` will additionally build; ``build/binutils/ar`` and ``nm-new`` binaries supporting plugins. Once you're ready to switch to using gold, backup your existing; ``/usr/bin/ld`` then replace it with ``ld-new``. Alternatively, install; in ``/usr/bin/ld.gold`` and use ``-fuse-ld=gold`` as described earlier. Optionally, add ``--enable-gold=default`` to the above configure invocation; to automatically install the ne",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GoldPlugin.rst:1831,plugin,plugin,1831,interpreter/llvm-project/llvm/docs/GoldPlugin.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GoldPlugin.rst,1,['plugin'],['plugin']
Modifiability,"with certain types of Attributes.; (`#76521 <https://github.com/llvm/llvm-project/issues/76521>`_). Miscellaneous Bug Fixes; ^^^^^^^^^^^^^^^^^^^^^^^. Miscellaneous Clang Crashes Fixed; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; - Fixed a crash when parsing top-level ObjC blocks that aren't properly; terminated. Clang should now also recover better when an @end is missing; between blocks.; `Issue 64065 <https://github.com/llvm/llvm-project/issues/64065>`_; - Fixed a crash when check array access on zero-length element.; `Issue 64564 <https://github.com/llvm/llvm-project/issues/64564>`_; - Fixed a crash when an ObjC ivar has an invalid type. See; (`#68001 <https://github.com/llvm/llvm-project/pull/68001>`_); - Fixed a crash in C when redefined struct is another nested redefinition.; `Issue 41302 <https://github.com/llvm/llvm-project/issues/41302>`_; - Fixed a crash when ``-ast-dump=json`` was used for code using class; template deduction guides.; - Fixed a crash when a lambda marked as ``static`` referenced a captured; variable in an expression.; `Issue 74608 <https://github.com/llvm/llvm-project/issues/74608>`_; - Fixed a crash with modules and a ``constexpr`` destructor.; `Issue 68702 <https://github.com/llvm/llvm-project/issues/68702>`_. OpenACC Specific Changes; ------------------------; - OpenACC Implementation effort is beginning with semantic analysis and parsing; of OpenACC pragmas. The ``-fopenacc`` flag was added to enable these new,; albeit incomplete changes. The ``_OPENACC`` macro is currently defined to; ``1``, as support is too incomplete to update to a standards-required value.; - Added ``-fexperimental-openacc-macro-override``, a command line option to; permit overriding the ``_OPENACC`` macro to be any digit-only value specified; by the user, which permits testing the compiler against existing OpenACC; workloads in order to evaluate implementation progress. Target Specific Changes; -----------------------. AMDGPU Support; ^^^^^^^^^^^^^^; - Use pass-by-refere",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ReleaseNotes.rst:58247,variab,variable,58247,interpreter/llvm-project/clang/docs/ReleaseNotes.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ReleaseNotes.rst,1,['variab'],['variable']
Modifiability,"with constructor/destructors. The (1<<26) bit is set and; functions are generated. The block copy helper function should, for each of the variables of the type; mentioned above, call:. .. code-block:: c. _Block_object_assign(&dst->target, src->target, BLOCK_FIELD_<apropos>);. in the copy helper and:. .. code-block:: c. _Block_object_dispose(->target, BLOCK_FIELD_<apropos>);. in the dispose helper where ``<apropos>`` is:. .. code-block:: c. enum {; BLOCK_FIELD_IS_OBJECT = 3, // id, NSObject, __attribute__((NSObject)), block, ...; BLOCK_FIELD_IS_BLOCK = 7, // a block variable; BLOCK_FIELD_IS_BYREF = 8, // the on stack structure holding the __block variable. BLOCK_FIELD_IS_WEAK = 16, // declared __weak. BLOCK_BYREF_CALLER = 128, // called from byref copy/dispose helpers; };. and of course the constructors/destructors for ``const`` copied C++ objects. The ``block_byref`` data structure similarly requires copy/dispose helpers for; block variables, ``__attribute__((NSObject))`` variables, or C++ ``const``; copied objects with constructor/destructors, and again the (1<<26) bit is set; and functions are generated in the same manner. Under ObjC we allow ``__weak`` as an attribute on ``__block`` variables, and; this causes the addition of ``BLOCK_FIELD_IS_WEAK`` orred onto the; ``BLOCK_FIELD_IS_BYREF`` flag when copying the ``block_byref`` structure in the; ``Block`` copy helper, and onto the ``BLOCK_FIELD_<apropos>`` field within the; ``block_byref`` copy/dispose helper calls. The prototypes, and summary, of the helper functions are:. .. code-block:: c. /* Certain field types require runtime assistance when being copied to the; heap. The following function is used to copy fields of types: blocks,; pointers to byref structures, and objects (including; __attribute__((NSObject)) pointers. BLOCK_FIELD_IS_WEAK is orthogonal to; the other choices which are mutually exclusive. Only in a Block copy; helper will one see BLOCK_FIELD_IS_BYREF.; */; void _Block_object_assign(void *destAd",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Block-ABI-Apple.rst:28943,variab,variables,28943,interpreter/llvm-project/clang/docs/Block-ABI-Apple.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Block-ABI-Apple.rst,2,['variab'],['variables']
Modifiability,"with the abstract and opaque ``SCEV`` class.; Given this analysis, trip counts of loops and other important properties can be; obtained. This analysis is primarily useful for induction variable substitution and; strength reduction. ``scev-aa``: ScalarEvolution-based Alias Analysis; -------------------------------------------------. Simple alias analysis implemented in terms of ``ScalarEvolution`` queries. This differs from traditional loop dependence analysis in that it tests for; dependencies within a single iteration of a loop, rather than dependencies; between different iterations. ``ScalarEvolution`` has a more complete understanding of pointer arithmetic; than ``BasicAliasAnalysis``' collection of ad-hoc analyses. ``stack-safety``: Stack Safety Analysis; ---------------------------------------. The ``StackSafety`` analysis can be used to determine if stack allocated; variables can be considered safe from memory access bugs. This analysis' primary purpose is to be used by sanitizers to avoid unnecessary; instrumentation of safe variables. Transform Passes; ================. This section describes the LLVM Transform Passes. ``adce``: Aggressive Dead Code Elimination; ------------------------------------------. ADCE aggressively tries to eliminate code. This pass is similar to :ref:`DCE; <passes-dce>` but it assumes that values are dead until proven otherwise. This; is similar to :ref:`SCCP <passes-sccp>`, except applied to the liveness of; values. ``always-inline``: Inliner for ``always_inline`` functions; ----------------------------------------------------------. A custom inliner that handles only functions that are marked as ""always; inline"". ``argpromotion``: Promote 'by reference' arguments to scalars; -------------------------------------------------------------. This pass promotes ""by reference"" arguments to be ""by value"" arguments. In; practice, this means looking for internal functions that have pointer; arguments. If it can prove, through the use of ali",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Passes.rst:11696,variab,variables,11696,interpreter/llvm-project/llvm/docs/Passes.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Passes.rst,1,['variab'],['variables']
Modifiability,"with the pointer and the corresponding bounds fields.; Despite this difference in their representations, they are still pointers in; terms of types of operations that are allowed and their semantics. For instance,; a pointer dereference on a ``__bidi_indexable`` pointer will return the; dereferenced value same as plain C pointers, modulo the extra bounds checks; being performed before dereferencing the wide pointer. This means mapping the; wide pointers to struct types with equivalent layout won’t be sufficient. To; represent the wide pointers in Clang AST, we add an extra field in the; PointerType class to indicate the internal bounds of the pointer. This ensures; pointers of different representations are mapped to different canonical types; while they are still treated as pointers. In LLVM IR, wide pointers will be emitted as structs of equivalent; representations. Clang CodeGen will handle them as Aggregate in; ``TypeEvaluationKind (TEK)``. ``AggExprEmitter`` was extended to handle pointer; operations returning wide pointers. Alternatively, a new ``TEK`` and an; expression emitter dedicated to wide pointers could be introduced. Default bounds annotations; ==========================. The model may implicitly add ``__bidi_indexable`` or ``__single`` depending on; the context of the declaration that has the pointer type. ``__bidi_indexable``; implicitly adds to local variables, while ``__single`` implicitly adds to; pointer types specifying struct fields, function parameters, or global; variables. This means the parser may first create the pointer type without any; default pointer attribute and then recreate the type once the parser has the; declaration context and determined the default attribute accordingly. This also requires the parser to reset the type of the declaration with the; newly created type with the right default attribute. Promotion expression; ====================. A new expression will be introduced to represent the conversion from a pointer; with an",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/BoundsSafetyImplPlans.rst:3272,extend,extended,3272,interpreter/llvm-project/clang/docs/BoundsSafetyImplPlans.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/BoundsSafetyImplPlans.rst,1,['extend'],['extended']
Modifiability,"with the; location description of the object since the expression has to need it. A.6 Other Debugging Information; -------------------------------. .. note::. This section provides changes to existing debugger information entry; attributes. These would be incorporated into the corresponding DWARF Version 5; chapter 6 sections. A.6.1 Accelerated Access; ~~~~~~~~~~~~~~~~~~~~~~~~. .. _amdgpu-dwarf-lookup-by-name:. A.6.1.1 Lookup By Name; ++++++++++++++++++++++. A.6.1.1.1 Contents of the Name Index; ####################################. .. note::. The following provides changes to DWARF Version 5 section 6.1.1.1. The rule for debugger information entries included in the name index in the; optional ``.debug_names`` section is extended to also include named; ``DW_TAG_variable`` debugging information entries with a ``DW_AT_location``; attribute that includes a ``DW_OP_LLVM_form_aspace_address`` operation. The name index must contain an entry for each debugging information entry that; defines a named subprogram, label, variable, type, or namespace, subject to the; following rules:. * ``DW_TAG_variable`` debugging information entries with a ``DW_AT_location``; attribute that includes a ``DW_OP_addr``, ``DW_OP_LLVM_form_aspace_address``,; or ``DW_OP_form_tls_address`` operation are included; otherwise, they are; excluded. A.6.1.1.4 Data Representation of the Name Index; ###############################################. .. _amdgpu-dwarf-name-index-section-header:. A.6.1.1.4.1 Section Header; ^^^^^^^^^^^^^^^^^^^^^^^^^^. .. note::. The following provides an addition to DWARF Version 5 section 6.1.1.4.1 item; 14 ``augmentation_string``. A null-terminated UTF-8 vendor specific augmentation string, which provides; additional information about the contents of this index. If provided, the; recommended format for augmentation string is:. | ``[``\ *vendor*\ ``:v``\ *X*\ ``.``\ *Y*\ [\ ``:``\ *options*\ ]\ ``]``\ *. Where *vendor* is the producer, ``vX.Y`` specifies the major X and minor ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:186412,variab,variable,186412,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,1,['variab'],['variable']
Modifiability,wn. more precise aliasing rules via effective type; Unknown; Unknown. restricted pointers; N448; Unknown. variable length arrays; N683; Yes. flexible array members; Unknown; Yes. static and type qualifiers in parameter array declarators; Unknown; Yes. more precise aliasing rules via effective type; Unknown; Unknown. complex and imaginary support in <complex.h>. N620; Unknown. N638; Unknown. N657; Unknown. N694; Unknown. N809; Unknown. type-generic math macros in <tgmath.h>; N693; Yes. the long long int type; N601; Yes. increase minimum translation limits; N590; Unknown. additional floating-point characteristics in <float.h>; Unknown; Unknown. remove implicit int. N635; Yes. N692; Yes. N722; Yes. reliable integer division; N617; Yes. universal character names (\u and \U); Unknown; Yes. extended identifiers; N717; Unknown. hexadecimal floating-point constants; N308. Yes. compound literals; N716; Yes. designated initializers; N494; Yes. // comments; N644; Yes. extended integer types and library functions in <inttypes.h> and <stdint.h>; Unknown. Yes. remove implicit function declaration; N636; Yes. preprocessor arithmetic done in intmax_t/uintmax_t; N736; Yes. mixed declarations and code; N740; Yes. new block scopes for selection and iteration statements; Unknown; Unknown. integer constant type rules; N629; Yes. integer promotion rules; N725; Yes. macros with a variable number of arguments; N707; Yes. IEC 60559 support; Unknown; Unknown. trailing comma allowed in enum declaration; Unknown; Yes. inline functions; N741; Yes. boolean type in <stdbool.h>; N815; Yes. idempotent type qualifiers; N505; Yes. empty macro arguments; N570; Unknown. new structure type compatibility (tag compatibility); N522; Unknown. additional predefined macro names; Unknown; Unknown. _Pragma preprocessing operator; N634. Yes. standard pragmas. N631; Unknown. N696; Unknown. __func__ predefined identifier; N611; Yes. va_copy macro; N671; Yes. LIA compatibility annex; N792; No. remove deprecation of ,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/c_status.html:2550,extend,extended,2550,interpreter/llvm-project/clang/www/c_status.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/c_status.html,2,['extend'],['extended']
Modifiability,"write and; run a Clang Plugin. Introduction; ============. Clang Plugins run FrontendActions over code. See the :doc:`FrontendAction; tutorial <RAVFrontendAction>` on how to write a ``FrontendAction`` using the; ``RecursiveASTVisitor``. In this tutorial, we'll demonstrate how to write a; simple clang plugin. Writing a ``PluginASTAction``; =============================. The main difference from writing normal ``FrontendActions`` is that you can; handle plugin command line options. The ``PluginASTAction`` base class declares; a ``ParseArgs`` method which you have to implement in your plugin. .. code-block:: c++. bool ParseArgs(const CompilerInstance &CI,; const std::vector<std::string>& args) {; for (unsigned i = 0, e = args.size(); i != e; ++i) {; if (args[i] == ""-some-arg"") {; // Handle the command line argument.; }; }; return true;; }. Registering a plugin; ====================. A plugin is loaded from a dynamic library at runtime by the compiler. To; register a plugin in a library, use ``FrontendPluginRegistry::Add<>``:. .. code-block:: c++. static FrontendPluginRegistry::Add<MyPlugin> X(""my-plugin-name"", ""my plugin description"");. Defining pragmas; ================. Plugins can also define pragmas by declaring a ``PragmaHandler`` and; registering it using ``PragmaHandlerRegistry::Add<>``:. .. code-block:: c++. // Define a pragma handler for #pragma example_pragma; class ExamplePragmaHandler : public PragmaHandler {; public:; ExamplePragmaHandler() : PragmaHandler(""example_pragma"") { }; void HandlePragma(Preprocessor &PP, PragmaIntroducer Introducer,; Token &PragmaTok) {; // Handle the pragma; }; };. static PragmaHandlerRegistry::Add<ExamplePragmaHandler> Y(""example_pragma"",""example pragma description"");. Defining attributes; ===================. Plugins can define attributes by declaring a ``ParsedAttrInfo`` and registering; it using ``ParsedAttrInfoRegister::Add<>``:. .. code-block:: c++. class ExampleAttrInfo : public ParsedAttrInfo {; public:; ExampleAttrInfo(",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangPlugins.rst:1168,plugin,plugin,1168,interpreter/llvm-project/clang/docs/ClangPlugins.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangPlugins.rst,1,['plugin'],['plugin']
Modifiability,"write each other. int callee (int32 arg1, int32 arg2);; int caller (int32 arg1, int32 arg2) {; return callee(arg2,arg1);; }. Here we need to push the arguments because they overwrite each; other. //===---------------------------------------------------------------------===//. main (); {; int i = 0;; unsigned long int z = 0;. do {; z -= 0x00004000;; i++;; if (i > 0x00040000); abort ();; } while (z > 0);; exit (0);; }. gcc compiles this to:. _main:; 	subl	$28, %esp; 	xorl	%eax, %eax; 	jmp	L2; L3:; 	cmpl	$262144, %eax; 	je	L10; L2:; 	addl	$1, %eax; 	cmpl	$262145, %eax; 	jne	L3; 	call	L_abort$stub; L10:; 	movl	$0, (%esp); 	call	L_exit$stub. llvm:. _main:; 	subl	$12, %esp; 	movl	$1, %eax; 	movl	$16384, %ecx; LBB1_1:	# bb; 	cmpl	$262145, %eax; 	jge	LBB1_4	# cond_true; LBB1_2:	# cond_next; 	incl	%eax; 	addl	$4294950912, %ecx; 	cmpl	$16384, %ecx; 	jne	LBB1_1	# bb; LBB1_3:	# bb11; 	xorl	%eax, %eax; 	addl	$12, %esp; 	ret; LBB1_4:	# cond_true; 	call	L_abort$stub. 1. LSR should rewrite the first cmp with induction variable %ecx.; 2. DAG combiner should fold; leal 1(%eax), %edx; cmpl $262145, %edx; =>; cmpl $262144, %eax. //===---------------------------------------------------------------------===//. define i64 @test(double %X) {; 	%Y = fptosi double %X to i64; 	ret i64 %Y; }. compiles to:. _test:; 	subl	$20, %esp; 	movsd	24(%esp), %xmm0; 	movsd	%xmm0, 8(%esp); 	fldl	8(%esp); 	fisttpll	(%esp); 	movl	4(%esp), %edx; 	movl	(%esp), %eax; 	addl	$20, %esp; 	#FP_REG_KILL; 	ret. This should just fldl directly from the input stack slot. //===---------------------------------------------------------------------===//. This code:; int foo (int x) { return (x & 65535) | 255; }. Should compile into:. _foo:; movzwl 4(%esp), %eax; orl $255, %eax; ret. instead of:; _foo:; 	movl	$65280, %eax; 	andl	4(%esp), %eax; 	orl	$255, %eax; 	ret. //===---------------------------------------------------------------------===//. We're codegen'ing multiply of long longs inefficiently:. unsigned long long LLM(un",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README.txt:20090,rewrite,rewrite,20090,interpreter/llvm-project/llvm/lib/Target/X86/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README.txt,4,"['rewrite', 'variab']","['rewrite', 'variable']"
Modifiability,"writeback dirty L2 cache; lines if configured to have multiple L2 caches.; * To ensure coherence of local memory writes of CUs in different agents a; ``buffer_wbl2 sc1`` is required. It will writeback dirty L2 cache lines.; * To ensure coherence of local memory reads of CUs with different L1 caches; in the same agent a ``buffer_inv sc1`` is required. It does nothing if the; agent is configured to have a single L2, or will invalidate non-local L2; cache lines if configured to have multiple L2 caches.; * To ensure coherence of local memory reads of CUs in different agents a; ``buffer_inv sc0 sc1`` is required. It will invalidate non-local L2 cache; lines if configured to have multiple L2 caches. * PCIe access from the GPU to the CPU can be kept coherent by using the MTYPE; UC (uncached) which bypasses the L2. Scalar memory operations are only used to access memory that is proven to not; change during the execution of the kernel dispatch. This includes constant; address space and global address space for program scope ``const`` variables.; Therefore, the kernel machine code does not have to maintain the scalar cache to; ensure it is coherent with the vector caches. The scalar and vector caches are; invalidated between kernel dispatches by CP since constant address space data; may change between kernel dispatch executions. See; :ref:`amdgpu-amdhsa-memory-spaces`. The one exception is if scalar writes are used to spill SGPR registers. In this; case the AMDGPU backend ensures the memory location used to spill is never; accessed by vector memory operations at the same time. If scalar writes are used; then a ``s_dcache_wb`` is inserted before the ``s_endpgm`` and before a function; return since the locations may be used for vector memory instructions by a; future wavefront that uses the same scratch area, or a function call that; creates a frame at the same address, respectively. There is no need for a; ``s_dcache_inv`` as all scalar writes are write-before-read in the same",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:290014,variab,variables,290014,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['variab'],['variables']
Modifiability,"ws how we use the LogError routines. When called, this function; expects that the current token is a '(' token, but after parsing the; subexpression, it is possible that there is no ')' waiting. For example,; if the user types in ""(4 x"" instead of ""(4)"", the parser should emit an; error. Because errors can occur, the parser needs a way to indicate that; they happened: in our parser, we return null on an error. 2) Another interesting aspect of this function is that it uses recursion; by calling ``ParseExpression`` (we will soon see that; ``ParseExpression`` can call ``ParseParenExpr``). This is powerful; because it allows us to handle recursive grammars, and keeps each; production very simple. Note that parentheses do not cause construction; of AST nodes themselves. While we could do it this way, the most; important role of parentheses are to guide the parser and provide; grouping. Once the parser constructs the AST, parentheses are not; needed. The next simple production is for handling variable references and; function calls:. .. code-block:: c++. /// identifierexpr; /// ::= identifier; /// ::= identifier '(' expression* ')'; static std::unique_ptr<ExprAST> ParseIdentifierExpr() {; std::string IdName = IdentifierStr;. getNextToken(); // eat identifier. if (CurTok != '(') // Simple variable ref.; return std::make_unique<VariableExprAST>(IdName);. // Call.; getNextToken(); // eat (; std::vector<std::unique_ptr<ExprAST>> Args;; if (CurTok != ')') {; while (true) {; if (auto Arg = ParseExpression()); Args.push_back(std::move(Arg));; else; return nullptr;. if (CurTok == ')'); break;. if (CurTok != ','); return LogError(""Expected ')' or ',' in argument list"");; getNextToken();; }; }. // Eat the ')'.; getNextToken();. return std::make_unique<CallExprAST>(IdName, std::move(Args));; }. This routine follows the same style as the other routines. (It expects; to be called if the current token is a ``tok_identifier`` token). It; also has recursion and error handling. One interes",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl02.rst:9547,variab,variable,9547,interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl02.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl02.rst,1,['variab'],['variable']
Modifiability,"wser is reloaded; - load of widgets code only when really required (shorter startup time for RBrowser). ## Montecarlo Libraries. ## PROOF Libraries. ## Language Bindings. ## JavaScript ROOT. ### Major JSROOT update to version 6. - update all used libraries `d3.js`, `three.js`, `MathJax.js`, openui5; - change to Promise based interface for all async methods, remove call-back arguments; - change scripts names, core scripts name now `JSRoot.core.js`; - unify function/methods naming conventions, many changes in method names; - provide central code loader via `JSROOT.require`, supporting 4 different loading engines; - many nice features and many bug fixes; see JSROOT v6 release notes. ## Tutorials. ## Class Reference Guide. ## Build, Configuration and Testing Infrastructure. - a new cmake variable, `CMAKE_INSTALL_PYTHONDIR`, has been added: it allows customization of the installation directory of ROOT's python modules; - the developer build option `asserts` is introduced to enable/disable asserts via the `NDEBUG` C/CXX flag. Asserts are always enabled for `CMAKE_BUILD_TYPE=Debug` and `dev=ON`. The previous behavior of the builds set via the `CMAKE_BUILD_TYPE` variable has not changed.; - `CMAKE_CXX_STANDARD`, i.e. the C++ standard ROOT is built with, now defaults to the compiler default (or C++11 if the compiler default is older than that) rather than always defaulting to C++11. In turn this means that v6.24 is the first ROOT release for which ROOT's pre-compiled binaries are not compiled with C++11 but with the default standard in use by the default system compiler. On Ubuntu 20.04, for example, the v6.24 pre-compiled binaries are now compiled with C++14 rather than C++11 as it happened for previous ROOT versions. Also see [ROOT-10692](https://sft.its.cern.ch/jira/browse/ROOT-10692). The following builtins have been updated:. - VecCore 0.7.0. ## PyROOT. - Deprecate `TTree.AsMatrix` in this release and mark for removal in v6.26. Please use instead `RDataFrame.AsNumpy`.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v624/index.md:28335,variab,variable,28335,README/ReleaseNotes/v624/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v624/index.md,1,['variab'],['variable']
Modifiability,"x -march=armv8+memtag`` to compilation flags. Implementation; ==============. See `HardwareAssistedAddressSanitizer`_ for a general overview of a; tag-based approach to memory safety. MemTagSanitizer follows a; similar implementation strategy, but with the tag storage (shadow); provided by the hardware. A quick overview of MTE hardware capabilities:. * Every 16 aligned bytes of memory can be assigned a 4-bit Allocation Tag.; * Every pointer can have a 4-bit Address Tag that is in its most significant byte.; * Most memory access instructions generate an exception if Address Tag != Allocation Tag.; * Special instructions are provided for fast tag manipulation. Stack instrumentation; =====================. Stack-based memory errors are detected by updating Allocation Tag for; each local variable to a random value at the start of its lifetime,; and resetting it to the stack pointer Address Tag at the end of; it. Unallocated stack space is expected to match the Address Tag of; SP; this allows to skip tagging of any variable when memory safety can; be statically proven. Allocating a truly random tag for each stack variable in a large; function may incur significant code size overhead, because it means; that each variable's address is an independent, non-rematerializable; value; thus a function with N local variables will have extra N live; values to keep through most of its life time. For this reason MemTagSanitizer generates at most one random tag per; function, called a ""base tag"". Other stack variables, if there are; any, are assigned tags at a fixed offset from the base. Please refer to `this document; <https://github.com/google/sanitizers/wiki/Stack-instrumentation-with-ARM-Memory-Tagging-Extension-(MTE)>`_; for more details about stack instrumentation. Heap tagging; ============. **Note:** this part is not implemented as of Oct 2019. MemTagSanitizer will use :doc:`ScudoHardenedAllocator`; with additional code to update memory tags when. * New memory is obtained from ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MemTagSanitizer.rst:2158,variab,variable,2158,interpreter/llvm-project/llvm/docs/MemTagSanitizer.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MemTagSanitizer.rst,1,['variab'],['variable']
Modifiability,"x i32> @llvm.vp.sext.nxv4i32.nxv4i16 (<vscale x 4 x i16> <op>, <vscale x 4 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". The '``llvm.vp.sext``' intrinsic sign extends its first operand to the return; type. The operation has a mask and an explicit vector length parameter. Arguments:; """""""""""""""""""". The '``llvm.vp.sext``' intrinsic takes a value to cast as its first operand.; The return type is the type to cast the value to. Both types must be vectors of; :ref:`integer <t_integer>` type. The bit size of the value must be smaller than; the bit size of the return type. The second operand is the vector mask. The; return type, the value to cast, and the vector mask have the same number of; elements. The third operand is the explicit vector length of the operation. Semantics:; """""""""""""""""""". The '``llvm.vp.sext``' intrinsic performs a sign extension by copying the sign; bit (highest order bit) of the value until it reaches the size of the return; type. When sign extending from i1, the result will always be either -1 or 0.; The conversion is performed on lane positions below the explicit vector length; and where the vector mask is true. Masked-off lanes are ``poison``. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call <4 x i32> @llvm.vp.sext.v4i32.v4i16(<4 x i16> %a, <4 x i1> %mask, i32 %evl); ;; For all lanes below %evl, %r is lane-wise equivalent to %also.r. %t = sext <4 x i16> %a to <4 x i32>; %also.r = select <4 x i1> %mask, <4 x i32> %t, <4 x i32> poison. .. _int_vp_fptrunc:. '``llvm.vp.fptrunc.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare <16 x float> @llvm.vp.fptrunc.v16f32.v16f64 (<16 x double> <op>, <16 x i1> <mask>, i32 <vector_length>); declare <vscale x 4 x float> @llvm.vp.trunc.nxv4f32.nxv4f64 (<vscale x 4 x double> <op>, <vscale x 4 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". The '``llvm.vp.fptrunc``' intrinsic truncates its first operand to the return; type. The oper",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:800519,extend,extending,800519,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['extend'],['extending']
Modifiability,"x i8]`` | Array of 4 8-bit integer values. |; +------------------+--------------------------------------+. Here are some examples of multidimensional arrays:. +-----------------------------+----------------------------------------------------------+; | ``[3 x [4 x i32]]`` | 3x4 array of 32-bit integer values. |; +-----------------------------+----------------------------------------------------------+; | ``[12 x [10 x float]]`` | 12x10 array of single precision floating-point values. |; +-----------------------------+----------------------------------------------------------+; | ``[2 x [3 x [4 x i16]]]`` | 2x3x4 array of 16-bit integer values. |; +-----------------------------+----------------------------------------------------------+. There is no restriction on indexing beyond the end of the array implied; by a static type (though there are restrictions on indexing beyond the; bounds of an allocated object in some cases). This means that; single-dimension 'variable sized array' addressing can be implemented in; LLVM with a zero length array type. An implementation of 'pascal style; arrays' in LLVM could use the type ""``{ i32, [0 x float]}``"", for; example. .. _t_struct:. Structure Type; """""""""""""""""""""""""""". :Overview:. The structure type is used to represent a collection of data members; together in memory. The elements of a structure may be any type that has; a size. Structures in memory are accessed using '``load``' and '``store``' by; getting a pointer to a field with the '``getelementptr``' instruction.; Structures in registers are accessed using the '``extractvalue``' and; '``insertvalue``' instructions. Structures may optionally be ""packed"" structures, which indicate that; the alignment of the struct is one byte, and that there is no padding; between the elements. In non-packed structs, padding between field types; is inserted as defined by the DataLayout string in the module, which is; required to match what the underlying code generator expects. Structures can e",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:180978,variab,variable,180978,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['variab'],['variable']
Modifiability,"x is defined by the following BNF syntax:. .. code::. <target-id> ::== <processor> ( "":"" <target-feature> ( ""+"" | ""-"" ) )*. Where:. **processor**; Is a the target specific processor or any alternative processor name. **target-feature**; Is a target feature name that is supported by the processor. Each target; feature must appear at most once in a target ID and can have one of three; values:. *Any*; Specified by omitting the target feature from the target ID.; A code object compiled with a target ID specifying the default; value of a target feature can be loaded and executed on a processor; configured with the target feature on or off. *On*; Specified by ``+``, indicating the target feature is enabled. A code; object compiled with a target ID specifying a target feature on; can only be loaded on a processor configured with the target feature on. *Off*; specified by ``-``, indicating the target feature is disabled. A code; object compiled with a target ID specifying a target feature off; can only be loaded on a processor configured with the target feature off. .. _compatibility-target-id:. Compatibility Rules for Target ID; ---------------------------------. A code object compiled for a Target ID is considered compatible for a; target, if:. * Their processor is same.; * Their feature set is compatible as defined above. There are two forms of target ID:. *Non-Canonical Form*; The non-canonical form is used as the input to user commands to allow the user; greater convenience. It allows both the primary and alternative processor name; to be used and the target features may be specified in any order. *Canonical Form*; The canonical form is used for all generated output to allow greater; convenience for tools that consume the information. It is also used for; internal passing of information between tools. Only the primary and not; alternative processor name is used and the target features are specified in; alphabetic order. Command line tools convert non-canonical form to ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangOffloadBundler.rst:12541,config,configured,12541,interpreter/llvm-project/clang/docs/ClangOffloadBundler.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangOffloadBundler.rst,1,['config'],['configured']
Modifiability,"x is {3}; }; // x is ⊤; }; ```. ### Uninitialized variables and ""bottom"" values. When `x` is declared but not initialized, it has no possible values. We; represent this fact symbolically as `⊥` (pronounced ""bottom""). ```c++; void ExampleOfBottom() {; int x; // x is ⊥; x = 42; // x is {42}; print(x);; }; ```. Note that using values read from uninitialized variables is undefined behaviour; in C++. Generally, compilers and static analysis tools can assume undefined; behavior does not happen. We must model uninitialized variables only when we are; implementing a checker that specifically is trying to find uninitialized reads.; In this example we show how to model uninitialized variables only to demonstrate; the concept of ""bottom"", and how it applies to possible value analysis. We; describe an analysis that finds uninitialized reads in a section below. ### A practical lattice that tracks sets of concrete values. Taking into account all corner cases covered above, we can put together a; lattice that we can use in practice to track possible values of integer; variables. This lattice represents sets of integers with 1, 2, or 3 elements, as; well as top and bottom. Here is a Hasse diagram for it:. ![Hasse diagram for a lattice of integer sets](DataFlowAnalysisIntroImages/IntegerSetsFiniteLattice.svg). ### Formalization. Let's consider a slightly more complex example, and think about how we can; compute the sets of possible values algorithmically. ```c++; void Example(int n) {; int x; // x is ⊥; if (n > 0) {; if (n == 42) {; x = 44; // x is {44}; } else {; x = 5; // x is {5}; }; print(x); // x is {44; 5}; } else {; x = n; // x is ⊤; }; print(x); // x is ⊤; }; ```. As humans, we understand the control flow from the program text. We used our; understanding of control flow to find program points where two flows join.; Formally, control flow is represented by a CFG (control flow graph):. ![CFG for the code above](DataFlowAnalysisIntroImages/CFGExample.svg). We can compute sets of",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md:6770,variab,variables,6770,interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md,1,['variab'],['variables']
Modifiability,"x to append to the directory where libraries are to be; installed. On a 64-bit architecture, one could use ``-DLLVM_LIBDIR_SUFFIX=64``; to install libraries to ``/usr/lib64``. **LLVM_PARALLEL_{COMPILE,LINK}_JOBS**:STRING; Building the llvm toolchain can use a lot of resources, particularly; linking. These options, when you use the Ninja generator, allow you; to restrict the parallelism. For example, to avoid OOMs or going; into swap, permit only one link job per 15GB of RAM available on a; 32GB machine, specify ``-G Ninja -DLLVM_PARALLEL_LINK_JOBS=2``. **LLVM_TARGETS_TO_BUILD**:STRING; Control which targets are enabled. For example you may only need to enable; your native target with, for example, ``-DLLVM_TARGETS_TO_BUILD=X86``. .. _llvm_use_linker:. **LLVM_USE_LINKER**:STRING; Override the system's default linker. For instance use ``lld`` with; ``-DLLVM_USE_LINKER=lld``. Rarely-used CMake variables; ---------------------------. Here are some of the CMake variables that are rarely used, along with a brief; explanation and LLVM-related notes. For full documentation, consult the CMake; manual, or execute ``cmake --help-variable VARIABLE_NAME``. **CMAKE_CXX_STANDARD**:STRING; Sets the C++ standard to conform to when building LLVM. Possible values are; 17 and 20. LLVM Requires C++ 17 or higher. This defaults to 17. **CMAKE_INSTALL_BINDIR**:PATH; The path to install executables, relative to the *CMAKE_INSTALL_PREFIX*.; Defaults to ""bin"". **CMAKE_INSTALL_INCLUDEDIR**:PATH; The path to install header files, relative to the *CMAKE_INSTALL_PREFIX*.; Defaults to ""include"". **CMAKE_INSTALL_DOCDIR**:PATH; The path to install documentation, relative to the *CMAKE_INSTALL_PREFIX*.; Defaults to ""share/doc"". **CMAKE_INSTALL_MANDIR**:PATH; The path to install manpage files, relative to the *CMAKE_INSTALL_PREFIX*.; Defaults to ""share/man"". .. _LLVM-related variables:. LLVM-related variables; -----------------------. These variables provide fine control over the build of LLVM and; ena",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:10391,variab,variables,10391,interpreter/llvm-project/llvm/docs/CMake.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst,1,['variab'],['variables']
Modifiability,"x was updated from 0.6.4 to 0.6.7 (support for OpenSSL 1.1, [ROOT-9353](https://sft.its.cern.ch/jira/browse/ROOT-9353)); - Vdt has been updated from 0.3.9 to 0.4.1 (includes new atan function); - XRootd has been updated from 4.6.1 to 4.8.2 (for GCC 8.x support); - Builtin TBB can now be used on Windows; - xxHash and LZ4 have been separated so that a system version of LZ4 can be used even if it does not include xxHash headers ([ROOT-9099](https://sft.its.cern.ch/jira/browse/ROOT-9099)); - In addition, several updates have been made to fix minor build system issues, such as not checking for external packages if their builtin is turned off, or checking for packages even when the respective option is disabled ([ROOT-8806](https://sft.its.cern.ch/jira/browse/ROOT-8806), [ROOT-9190](https://sft.its.cern.ch/jira/browse/ROOT-9190), [ROOT-9315](https://sft.its.cern.ch/jira/browse/ROOT-9315), [ROOT-9385](https://sft.its.cern.ch/jira/browse/ROOT-9385)).; - The `python3` option to CMake has been removed ([ROOT-9033](https://sft.its.cern.ch/jira/browse/ROOT-9033), [ROOT-9143](https://sft.its.cern.ch/jira/browse/ROOT-9143)). Python support is enabled by default. To configure ROOT to use specific Python versions, there is a new option called `python_version`. This is how to configure ROOT and Python for the common use cases:. * Use the default Python interpreter:; - `-Dpython=ON` (default); * Search only for Python 2.x or only 3.x:; - `-Dpython_version=2` or `-Dpython_version=3`; * Use a specific version of Python from `$PATH`:; - `-Dpython_version=2.7` or `-Dpython_version=3.5`; * Use a specific Python interpreter, whatever the version:; - `-DPYTHON_EXECUTABLE=/usr/local/bin/python`. Note: The use of `PYTHON_EXECUTABLE` requires the full path to the interpreter. ## Infrastructure and Testing. - Reduce time taken by tests which takes too long to run ({One,Two}SidedFrequentistUpperLimitWithBands.C); - Disable PyROOT SQL tutorials (the C++ counterparts are since several releases).; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v614/index.md:19589,config,configure,19589,README/ReleaseNotes/v614/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v614/index.md,2,['config'],['configure']
Modifiability,"x) {; for (unsigned I = 0; I < 10; ++I) { BAR(I); }; }; int main() {; foo<int>(0);; foo<float>(0);; return 0;; }; EOF. Compiling with coverage enabled; ===============================. To compile code with coverage enabled, pass ``-fprofile-instr-generate; -fcoverage-mapping`` to the compiler:. .. code-block:: console. # Step 1: Compile with coverage enabled.; % clang++ -fprofile-instr-generate -fcoverage-mapping foo.cc -o foo. Note that linking together code with and without coverage instrumentation is; supported. Uninstrumented code simply won't be accounted for in reports. To compile code with Modified Condition/Decision Coverage (MC/DC) enabled,; pass ``-fcoverage-mcdc`` in addition to the clang options specified above.; MC/DC is an advanced form of code coverage most applicable in the embedded; space. Running the instrumented program; ================================. The next step is to run the instrumented program. When the program exits it; will write a **raw profile** to the path specified by the ``LLVM_PROFILE_FILE``; environment variable. If that variable does not exist, the profile is written; to ``default.profraw`` in the current directory of the program. If; ``LLVM_PROFILE_FILE`` contains a path to a non-existent directory, the missing; directory structure will be created. Additionally, the following special; **pattern strings** are rewritten:. * ""%p"" expands out to the process ID. * ""%h"" expands out to the hostname of the machine running the program. * ""%t"" expands out to the value of the ``TMPDIR`` environment variable. On; Darwin, this is typically set to a temporary scratch directory. * ""%Nm"" expands out to the instrumented binary's signature. When this pattern; is specified, the runtime creates a pool of N raw profiles which are used for; on-line profile merging. The runtime takes care of selecting a raw profile; from the pool, locking it, and updating it before the program exits. If N is; not specified (i.e the pattern is ""%m""), it's assumed that",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/SourceBasedCodeCoverage.rst:2251,variab,variable,2251,interpreter/llvm-project/clang/docs/SourceBasedCodeCoverage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/SourceBasedCodeCoverage.rst,1,['variab'],['variable']
Modifiability,"x,y,z);; h3->Fill(x,y,z,w);; ```. The `Fill` method computes the bin number corresponding to the given; x, y or z argument and increments this bin by the given weight. The; `Fill()` method returns the bin number for 1-D histograms or global; bin number for 2-D and 3-D histograms. If **`TH1`**`::Sumw2()` has; been called before filling, the sum of squares is also stored. One can; increment a bin number directly by calling; **`TH1`**`::AddBinContent()`, replace the existing content via; **`TH1`**`::SetBinContent()` , and access the bin content of a given; bin via **`TH1`**`::GetBinContent()` . ``` {.cpp}; Double_t binContent = h->GetBinContent(bin);; ```. ### Automatic Re-binning Option. By default, the number of bins is computed using the range of the; axis. You can change this to re-bin automatically by setting the; automatic re-binning option:. ``` {.cpp}; h->SetBit(TH1::kCanRebin);; ```; \index{histogram!rebin}. Once this is set, the `Fill()` method will automatically extend the; axis range to accommodate the new value specified in the `Fill()`; argument. The used method is to double the bin size until the new; value fits in the range, merging bins two by two. The; **`TTree`**`::Draw()` method extensively uses this automatic binning; option when drawing histograms of variables in **`TTree`** with an; unknown range. The automatic binning option is supported for 1-D, 2-D; and 3-D histograms. During filling, some statistics parameters are; incremented to compute the mean value and root mean square with the; maximum precision. In case of histograms of type **`TH1C`**,; **`TH1S`**, **`TH2C`**, **`TH2S`**, **`TH3C`**, **`TH3S`** a check is; made that the bin contents do not exceed the maximum positive capacity; (127 or 65 535). Histograms of all types may have positive or/and; negative bin contents. ## Random Numbers and Histograms. **`TH1`**`::FillRandom()` can be used to randomly fill a histogram; using the contents of an existing **`TF1`** function or another; **`TH1",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Histograms.md:8404,extend,extend,8404,documentation/users-guide/Histograms.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Histograms.md,1,['extend'],['extend']
Modifiability,x/PostingList.h; clang-tools-extra/clangd/index/dex/Token.h; clang-tools-extra/clangd/index/dex/Trigram.cpp; clang-tools-extra/clangd/index/dex/Trigram.h; clang-tools-extra/clangd/index/dex/dexp/Dexp.cpp; clang-tools-extra/clangd/index/remote/Client.cpp; clang-tools-extra/clangd/index/remote/Client.h; clang-tools-extra/clangd/index/remote/marshalling/Marshalling.cpp; clang-tools-extra/clangd/index/remote/marshalling/Marshalling.h; clang-tools-extra/clangd/index/remote/monitor/Monitor.cpp; clang-tools-extra/clangd/index/remote/server/Server.cpp; clang-tools-extra/clangd/index/remote/unimplemented/UnimplementedClient.cpp; clang-tools-extra/clangd/indexer/IndexerMain.cpp; clang-tools-extra/clangd/refactor/InsertionPoint.cpp; clang-tools-extra/clangd/refactor/InsertionPoint.h; clang-tools-extra/clangd/refactor/Rename.h; clang-tools-extra/clangd/refactor/Tweak.cpp; clang-tools-extra/clangd/refactor/Tweak.h; clang-tools-extra/clangd/refactor/tweaks/AddUsing.cpp; clang-tools-extra/clangd/refactor/tweaks/AnnotateHighlightings.cpp; clang-tools-extra/clangd/refactor/tweaks/DefineInline.cpp; clang-tools-extra/clangd/refactor/tweaks/DefineOutline.cpp; clang-tools-extra/clangd/refactor/tweaks/DumpAST.cpp; clang-tools-extra/clangd/refactor/tweaks/ExpandMacro.cpp; clang-tools-extra/clangd/refactor/tweaks/ExtractFunction.cpp; clang-tools-extra/clangd/refactor/tweaks/ObjCLocalizeStringLiteral.cpp; clang-tools-extra/clangd/refactor/tweaks/RemoveUsingNamespace.cpp; clang-tools-extra/clangd/refactor/tweaks/SwapIfBranches.cpp; clang-tools-extra/clangd/support/Cancellation.cpp; clang-tools-extra/clangd/support/Cancellation.h; clang-tools-extra/clangd/support/Context.cpp; clang-tools-extra/clangd/support/Context.h; clang-tools-extra/clangd/support/FileCache.cpp; clang-tools-extra/clangd/support/FileCache.h; clang-tools-extra/clangd/support/Function.h; clang-tools-extra/clangd/support/Logger.cpp; clang-tools-extra/clangd/support/Markup.cpp; clang-tools-extra/clangd/support/Markup.h; clang-,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt:80318,refactor,refactor,80318,interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,1,['refactor'],['refactor']
Modifiability,"x170fa80 'N' 'const int'))); (UnaryOperator 0x173b0b0 'int' lvalue prefix '++'; (DeclRefExpr 0x173b088 'int' lvalue Var 0x173af50 'i' 'int')); (CompoundStatement ... We already know that the declaration and increments both match, or this; loop wouldn't have been dumped. The culprit lies in the implicit cast; applied to the first operand (i.e. the LHS) of the less-than operator,; an L-value to R-value conversion applied to the expression referencing; ``i``. Thankfully, the matcher library offers a solution to this problem; in the form of ``ignoringParenImpCasts``, which instructs the matcher to; ignore implicit casts and parentheses before continuing to match.; Adjusting the condition operator will restore the desired match. .. code-block:: c++. hasCondition(binaryOperator(; hasOperatorName(""<""),; hasLHS(ignoringParenImpCasts(declRefExpr(; to(varDecl(hasType(isInteger())))))),; hasRHS(expr(hasType(isInteger()))))). After adding binds to the expressions we wished to capture and; extracting the identifier strings into variables, we have array-step-2; completed. Step 4: Retrieving Matched Nodes; ================================. So far, the matcher callback isn't very interesting: it just dumps the; loop's AST. At some point, we will need to make changes to the input; source code. Next, we'll work on using the nodes we bound in the; previous step. The ``MatchFinder::run()`` callback takes a; ``MatchFinder::MatchResult&`` as its parameter. We're most interested in; its ``Context`` and ``Nodes`` members. Clang uses the ``ASTContext``; class to represent contextual information about the AST, as the name; implies, though the most functionally important detail is that several; operations require an ``ASTContext*`` parameter. More immediately useful; is the set of matched nodes, and how we retrieve them. Since we bind three variables (identified by ConditionVarName,; InitVarName, and IncrementVarName), we can obtain the matched nodes by; using the ``getNodeAs()`` member functi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LibASTMatchersTutorial.rst:15553,variab,variables,15553,interpreter/llvm-project/clang/docs/LibASTMatchersTutorial.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LibASTMatchersTutorial.rst,1,['variab'],['variables']
Modifiability,"x[] = { { 1.0f, 1.0f } }; // [0] = (1, 1); complex float x[] = { 1.0f, 1.0f }; // [0] = (1, 0), [1] = (1, 0). This extension also works in C++ mode, as far as that goes, but does not apply; to the C++ ``std::complex``. (In C++11, list initialization allows the same; syntax to be used with ``std::complex`` with the same meaning.). For GCC compatibility, ``__builtin_complex(re, im)`` can also be used to; construct a complex number from the given real and imaginary components. OpenCL Features; ===============. Clang supports internal OpenCL extensions documented below. ``__cl_clang_bitfields``; --------------------------------. With this extension it is possible to enable bitfields in structs; or unions using the OpenCL extension pragma mechanism detailed in; `the OpenCL Extension Specification, section 1.2; <https://www.khronos.org/registry/OpenCL/specs/3.0-unified/html/OpenCL_Ext.html#extensions-overview>`_. Use of bitfields in OpenCL kernels can result in reduced portability as struct; layout is not guaranteed to be consistent when compiled by different compilers.; If structs with bitfields are used as kernel function parameters, it can result; in incorrect functionality when the layout is different between the host and; device code. **Example of Use**:. .. code-block:: c++. #pragma OPENCL EXTENSION __cl_clang_bitfields : enable; struct with_bitfield {; unsigned int i : 5; // compiled - no diagnostic generated; };. #pragma OPENCL EXTENSION __cl_clang_bitfields : disable; struct without_bitfield {; unsigned int i : 5; // error - bitfields are not supported; };. ``__cl_clang_function_pointers``; --------------------------------. With this extension it is possible to enable various language features that; are relying on function pointers using regular OpenCL extension pragma; mechanism detailed in `the OpenCL Extension Specification,; section 1.2; <https://www.khronos.org/registry/OpenCL/specs/3.0-unified/html/OpenCL_Ext.html#extensions-overview>`_. In C++ for OpenCL t",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst:85946,portab,portability,85946,interpreter/llvm-project/clang/docs/LanguageExtensions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst,1,['portab'],['portability']
Modifiability,"x`. ``` {.cpp}; ""temp:mass:px""; ```. The symbols used for the type are:. - `C`: a character string terminated by the 0 character; - `B`: an 8 bit signed integer; - `b`: an 8 bit unsigned integer; - `S`: a 16 bit signed integer; - `s`: a 16 bit unsigned integer; - `I`: a 32 bit signed integer; - `i`: a 32 bit unsigned integer; - `L`: a 64 bit signed integer; - `l`: a 64 bit unsigned integer; - `G`: a long signed integer, stored as 64 bit; - `g`: a long unsigned integer, stored as 64 bit; - `F`: a 32 bit floating point; - `D`: a 64 bit floating point; - `O`: [the letter 'o', not a zero] a boolean (Bool\_t). The type is used for a byte count to decide how much space to allocate.; The variable written is simply the block of bytes starting at the; starting address given in the second parameter. It may or may not match; the leaf list depending on whether or not the programmer is being; careful when choosing the leaf address, name, and type. By default, a variable will be copied with the number of bytes specified; in the type descriptor symbol. However, if the type consists of two; characters, the number specifies the number of bytes to be used when; copying the variable to the output buffer. The line below describes; `ntrack` to be written as a 16-bit integer (rather than a 32-bit; integer). ``` {.cpp}; ""ntrack/I2""; ```. With this Branch method, you can also add a leaf that holds an entire; array of variables. To add an array of floats use the `f[n]` notation; when describing the leaf. ``` {.cpp}; Float_t f[10];; tree->Branch(""fBranch"",f,""f[10]/F"");; ```. You can also add an array of variable length:. ``` {.cpp}; {; TFile *f = new TFile(""peter.root"",""recreate"");; Int_t nPhot;; Float_t E[500];; TTree* nEmcPhotons = new TTree(""nEmcPhotons"",""EMC Photons"");; nEmcPhotons->Branch(""nPhot"",&nPhot,""nPhot/I"");; nEmcPhotons->Branch(""E"",E,""E[nPhot]/F"");; }; ```. See ""Example 2: A Tree with a C Structure"" below; (`$ROOTSYS/tutorials/tree/tree2.C`) and `staff.C` at the beginning of; thi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md:22035,variab,variable,22035,documentation/users-guide/Trees.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md,1,['variab'],['variable']
Modifiability,"xamples, it now should be; clear how easy it is to convert any ROOT Macro in C++ to a Python version. As another example, let us revisit macro3 from Chapter 4. A straight-forward; Python version relying on the ROOT class `TMath`:. ``` {.python}; @ROOT_INCLUDE_FILE macros/macro3.py; ```. ### More Python- less C++ ###. You may have noticed already that there are some Python modules providing; functionality similar to ROOT classes, which fit more seamlessly into your; Python code. A more “pythonic” version of the above macro3 would use a replacement of the; ROOT class TMath for the provisioning of data to TGraphPolar. With the math; package, the part of the code becomes. ``` {.cpp}; import math; from array import array; from ROOT import TCanvas , TGraphPolar; ...; ipt=range(0,npoints); r=array('d',map(lambda x: x*(rmax-rmin)/(npoints-1.)+rmin,ipt)); theta=array('d',map(math.sin,r)); e=array('d',npoints*[0.]); ... ```. #### Customised Binning ####; This example combines comfortable handling of arrays in Python to define; variable bin sizes of a ROOT histogram. All we need to know is the interface; of the relevant ROOT class and its methods (from the ROOT documentation):. ``` {.cpp}; TH1F(const char* name , const char* title , Int_t nbinsx , const Double_t* xbins); ```. Here is the Python code:. ``` {.python}; import ROOT; from array import array; arrBins = array('d' ,(1 ,4 ,9 ,16) ) # array of bin edges; histo = ROOT.TH1F(""hist"", ""hist"", len(arrBins)-1, arrBins); # fill it with equally spaced numbers; for i in range (1 ,16) :; histo.Fill(i); histo.Draw (); ```. ## Custom code: from C++ to Python ##; The ROOT interpreter and type sytem offer interesting possibilities when it comes; to JITting of C++ code.; Take for example this header file, containing a class and a function. ```{.cpp}; // file cpp2pythonExample.h; #include ""stdio.h"". class A{; public:; A(int i):m_i(i){}; int getI() const {return m_i;}; private:; int m_i=0;; };. void printA(const A& a ){; printf (""The val",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/primer/root_in_python.md:2865,variab,variable,2865,documentation/primer/root_in_python.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/primer/root_in_python.md,1,['variab'],['variable']
Modifiability,"xes that are allowed in the; file-to-main-include mapping. When guessing whether a #include is the ""main"" include (to assign; category 0, see above), use this regex of allowed suffixes to the header; stem. A partial match is done, so that:; - """" means ""arbitrary suffix""; - ""$"" means ""no suffix"". For example, if configured to ""(_test)?$"", then a header a.h would be seen; as the ""main"" include in both a.cc and a_test.cc. .. _IncludeIsMainSourceRegex:. **IncludeIsMainSourceRegex** (``String``) :versionbadge:`clang-format 10` :ref:`¶ <IncludeIsMainSourceRegex>`; Specify a regular expression for files being formatted; that are allowed to be considered ""main"" in the; file-to-main-include mapping. By default, clang-format considers files as ""main"" only when they end; with: ``.c``, ``.cc``, ``.cpp``, ``.c++``, ``.cxx``, ``.m`` or ``.mm``; extensions.; For these files a guessing of ""main"" include takes place; (to assign category 0, see above). This config option allows for; additional suffixes and extensions for files to be considered as ""main"". For example, if this option is configured to ``(Impl\.hpp)$``,; then a file ``ClassImpl.hpp`` is considered ""main"" (in addition to; ``Class.c``, ``Class.cc``, ``Class.cpp`` and so on) and ""main; include file"" logic will be executed (with *IncludeIsMainRegex* setting; also being respected in later phase). Without this option set,; ``ClassImpl.hpp`` would not have the main include file put on top; before any other include. .. _IndentAccessModifiers:. **IndentAccessModifiers** (``Boolean``) :versionbadge:`clang-format 13` :ref:`¶ <IndentAccessModifiers>`; Specify whether access modifiers should have their own indentation level. When ``false``, access modifiers are indented (or outdented) relative to; the record members, respecting the ``AccessModifierOffset``. Record; members are indented one level below the record.; When ``true``, access modifiers get their own indentation level. As a; consequence, record members are always indented 2 ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst:69157,config,config,69157,interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,1,['config'],['config']
Modifiability,"xity reaching the specialized topics at the end. The; experienced user looking for special topics may find these chapters; useful: see ""Networking"", ""Writing a Graphical User Interface"",; ""Threads"", and ""PROOF: Parallel Processing"". ## Conventions Used in This Book. We tried to follow a style convention for the sake of clarity. The; styles in used are described below. To show source code in scripts or source files:. ``` {.cpp}; {; cout << "" Hello"" << endl;; float x = 3.;; float y = 5.;; int i = 101;; cout <<"" x = ""<<x<<"" y = ""<<y<<"" i = ""<<i<< endl;; }; ```. To show the ROOT command line, we show the ROOT prompt without numbers.; In the interactive system, the ROOT prompt has a line number; (`root[12]`); for the sake of simplicity, the line numbers are left; off. ``` {.cpp}; root[] TLine l; root[] l.Print(); TLine X1=0.000000 Y1=0.000000 X2=0.000000 Y2=0.000000; ```. Italic bold monotype font indicates a global variable, for example; ***`gDirectory`***. When a variable term is used, it is shown between angled brackets. In; the example below the variable term \<library\> can be replaced with; any library in the `$ROOTSYS` directory: `$ROOTSYS/<library>/inc.`. ## The Framework. ROOT is an object-oriented framework aimed at solving the data; analysis challenges of high-energy physics. There are two key words in; this definition, object oriented and framework. First, we explain what; we mean by a framework and then why it is an object-oriented; framework. ### What Is a Framework?. Programming inside a framework is a little like living in a city.; Plumbing, electricity, telephone, and transportation are services; provided by the city. In your house, you have interfaces to the; services such as light switches, electrical outlets, and telephones.; The details, for example, the routing algorithm of the phone switching; system, are transparent to you as the user. You do not care; you are; only interested in using the phone to communicate with your; collaborators to solve your",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Introduction.md:4331,variab,variable,4331,documentation/users-guide/Introduction.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Introduction.md,1,['variab'],['variable']
Modifiability,"xpected 'in' keyword after 'var'"");; getNextToken(); // eat 'in'. auto Body = ParseExpression();; if (!Body); return nullptr;. return std::make_unique<VarExprAST>(std::move(VarNames),; std::move(Body));; }. Now that we can parse and represent the code, we need to support; emission of LLVM IR for it. This code starts out with:. .. code-block:: c++. Value *VarExprAST::codegen() {; std::vector<AllocaInst *> OldBindings;. Function *TheFunction = Builder->GetInsertBlock()->getParent();. // Register all variables and emit their initializer.; for (unsigned i = 0, e = VarNames.size(); i != e; ++i) {; const std::string &VarName = VarNames[i].first;; ExprAST *Init = VarNames[i].second.get();. Basically it loops over all the variables, installing them one at a; time. For each variable we put into the symbol table, we remember the; previous value that we replace in OldBindings. .. code-block:: c++. // Emit the initializer before adding the variable to scope, this prevents; // the initializer from referencing the variable itself, and permits stuff; // like this:; // var a = 1 in; // var a = a in ... # refers to outer 'a'.; Value *InitVal;; if (Init) {; InitVal = Init->codegen();; if (!InitVal); return nullptr;; } else { // If not specified, use 0.0.; InitVal = ConstantFP::get(*TheContext, APFloat(0.0));; }. AllocaInst *Alloca = CreateEntryBlockAlloca(TheFunction, VarName);; Builder->CreateStore(InitVal, Alloca);. // Remember the old variable binding so that we can restore the binding when; // we unrecurse.; OldBindings.push_back(NamedValues[VarName]);. // Remember this binding.; NamedValues[VarName] = Alloca;; }. There are more comments here than code. The basic idea is that we emit; the initializer, create the alloca, then update the symbol table to; point to it. Once all the variables are installed in the symbol table,; we evaluate the body of the var/in expression:. .. code-block:: c++. // Codegen the body, now that all vars are in scope.; Value *BodyVal = Body->codegen();; i",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl07.rst:27184,variab,variable,27184,interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl07.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl07.rst,2,['variab'],['variable']
Modifiability,"xsihx; . Similar to stxsiwx:; def STXSIWX : XX1Form<31, 140, (outs), (ins vsfrc:$XT, memrr:$dst),; ""stxsiwx $XT, $dst"", IIC_LdStSTFD,; [(PPCstfiwx f64:$XT, xoaddr:$dst)]>;. . (PPCstfiwx f64:$XT, xoaddr:$dst). - Load Vector Halfword*8/Byte*16 Indexed: lxvh8x lxvb16x; . Similar to lxvd2x/lxvw4x:; def LXVD2X : XX1Form<31, 844,; (outs vsrc:$XT), (ins memrr:$src),; ""lxvd2x $XT, $src"", IIC_LdStLFD,; [(set v2f64:$XT, (int_ppc_vsx_lxvd2x xoaddr:$src))]>;. . (set v8i16:$XT, (int_ppc_vsx_lxvh8x xoaddr:$src)); (set v16i8:$XT, (int_ppc_vsx_lxvb16x xoaddr:$src)). - Store Vector Halfword*8/Byte*16 Indexed: stxvh8x stxvb16x; . Similar to stxvd2x/stxvw4x:; def STXVD2X : XX1Form<31, 972,; (outs), (ins vsrc:$XT, memrr:$dst),; ""stxvd2x $XT, $dst"", IIC_LdStSTFD,; [(store v2f64:$XT, xoaddr:$dst)]>;. . (store v8i16:$XT, xoaddr:$dst); (store v16i8:$XT, xoaddr:$dst). - Load/Store Vector (Left-justified) with Length: lxvl lxvll stxvl stxvll; . Likely needs an intrinsic; . (set v?:$XT, (int_ppc_vsx_lxvl xoaddr:$src)); (set v?:$XT, (int_ppc_vsx_lxvll xoaddr:$src)). . (int_ppc_vsx_stxvl xoaddr:$dst)); (int_ppc_vsx_stxvll xoaddr:$dst)). - Load Vector Word & Splat Indexed: lxvwsx; . Likely needs an intrinsic; . (set v?:$XT, (int_ppc_vsx_lxvwsx xoaddr:$src)). Atomic operations (l[dw]at, st[dw]at):; - Provide custom lowering for common atomic operations to use these; instructions with the correct Function Code; - Ensure the operands are in the correct register (i.e. RT+1, RT+2); - Provide builtins since not all FC's necessarily have an existing LLVM; atomic operation. Move to CR from XER Extended (mcrxrx):; - Is there a use for this in LLVM?. Fixed Point Facility:. - Copy-Paste Facility: copy copy_first cp_abort paste paste. paste_last; . Use instrinstics:; (int_ppc_copy_first i32:$rA, i32:$rB); (int_ppc_copy i32:$rA, i32:$rB). (int_ppc_paste i32:$rA, i32:$rB); (int_ppc_paste_last i32:$rA, i32:$rB). (int_cp_abort). - Message Synchronize: msgsync; - SLB*: slbieg slbsync; - stop; . No instrinstics; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/README_P9.txt:20158,Extend,Extended,20158,interpreter/llvm-project/llvm/lib/Target/PowerPC/README_P9.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/README_P9.txt,1,['Extend'],['Extended']
Modifiability,"xt. ### Dynamic Path: `ROOT_LIBRARY_PATH`. A new way to set ROOT's ""Dynamic Path"" was added: the; environment variable `ROOT_LIBRARY_PATH`. On Unix it should contain a colon; separated list of paths, on Windows a semicolon separated list. It is; intended to be cross platform and to be specific to ROOT (and thus not; interfere with the system's shared linker).; The final ""Dynamic Path"" is now composed of these sources in order:; 1. `ROOT_LIBRARY_PATH` environment variable; 2. System specific shared linker environment variables like; `LD_LIBRARY_PATH`, `LIBPATH`, or `PATH`.; 3. Setting from rootrc; 4. ROOT's builtin library directory. ### Interpreter. - cling's LLVM is upgraded to version 9.0; - New interface to enable/disable optional cling features. Currently, it can be used to enable/disable support for redefinitions. See [this](https://github.com/root-project/cling/issues/360) issue for more information. ### Multithreading. - Fix an uninitialized variable in global read-write lock which could have caused deadlocks or crashes in some rare cases.; - Default global read-write lock transitioned to new implementation based on TBB thread local storage when TBB is available on supported platforms (all except Windows). This gives an O(10%) performance improvement for some typical RDataFrame scenarios with 256 threads due to reduced lock contention. ## I/O Libraries. - Exclusive use of the global lock is reduced or migrated to finer grained read and write locks in a few hotspots that occur during file opening/closing or task initialization in RDataFrame. This can lead to O(100x) improvements for some typical RDataFrame scenarios with 256 threads due to massively reduced lock contention. ## TTree Libraries. - `TTree` now supports the inclusion of leaves of types `long` and `unsigned long` (and therefore also `std::size_t` on most systems) also for branches in ""leaflist mode"". The corresponding leaflist letters are 'G' and 'g'.; - when looping over a `TTree` with a friend wit",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v624/index.md:3875,variab,variable,3875,README/ReleaseNotes/v624/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v624/index.md,1,['variab'],['variable']
Modifiability,"xtensions; ======================. Objective-C extends the definition of a Block reference type to be; that also of id. A variable or expression of Block type may be; messaged or used as a parameter wherever an id may be. The converse is; also true. Block references may thus appear as properties and are; subject to the assign, retain, and copy attribute logic that is; reserved for objects. All Blocks are constructed to be Objective-C objects regardless of; whether the Objective-C runtime is operational in the program or; not. Blocks using automatic (stack) memory are objects and may be; messaged, although they may not be assigned into ``__weak`` locations; if garbage collection is enabled. Within a Block literal expression within a method definition; references to instance variables are also imported into the lexical; scope of the compound statement. These variables are implicitly; qualified as references from self, and so self is imported as a const; copy. The net effect is that instance variables can be mutated. The :block-term:`Block_copy` operator retains all objects held in; variables of automatic storage referenced within the Block expression; (or form strong references if running under garbage collection).; Object variables of ``__block`` storage type are assumed to hold; normal pointers with no provision for retain and release messages. Foundation defines (and supplies) ``-copy`` and ``-release`` methods for; Blocks. In the Objective-C and Objective-C++ languages, we allow the; ``__weak`` specifier for ``__block`` variables of object type. If; garbage collection is not enabled, this qualifier causes these; variables to be kept without retain messages being sent. This; knowingly leads to dangling pointers if the Block (or a copy) outlives; the lifetime of this object. In garbage collected environments, the ``__weak`` variable is set to; nil when the object it references is collected, as long as the; ``__block`` variable resides in the heap (either by default ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/BlockLanguageSpec.rst:9627,variab,variables,9627,interpreter/llvm-project/clang/docs/BlockLanguageSpec.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/BlockLanguageSpec.rst,1,['variab'],['variables']
Modifiability,xx; src/ROCCurve.cxx; src/RootFinder.cxx; src/RuleCut.cxx; src/Rule.cxx; src/RuleEnsemble.cxx; src/RuleFitAPI.cxx; src/RuleFit.cxx; src/RuleFitParams.cxx; src/SdivSqrtSplusB.cxx; src/SeparationBase.cxx; src/SimulatedAnnealing.cxx; src/SimulatedAnnealingFitter.cxx; src/SVEvent.cxx; src/SVKernelFunction.cxx; src/SVKernelMatrix.cxx; src/SVWorkingSet.cxx; src/TActivationChooser.cxx; src/TActivation.cxx; src/TActivationIdentity.cxx; src/TActivationRadial.cxx; src/TActivationReLU.cxx; src/TActivationSigmoid.cxx; src/TActivationTanh.cxx; src/Timer.cxx; src/TNeuron.cxx; src/TNeuronInputAbs.cxx; src/TNeuronInputChooser.cxx; src/TNeuronInput.cxx; src/TNeuronInputSqSum.cxx; src/TNeuronInputSum.cxx; src/Tools.cxx; src/TrainingHistory.cxx; src/TransformationHandler.cxx; src/TSpline1.cxx; src/TSpline2.cxx; src/TSynapse.cxx; src/Types.cxx; src/VariableDecorrTransform.cxx; src/VariableGaussTransform.cxx; src/VariableIdentityTransform.cxx; src/VariableImportance.cxx; src/VariableInfo.cxx; src/VariableNormalizeTransform.cxx; src/VariablePCATransform.cxx; src/VariableRearrangeTransform.cxx; src/VariableTransformBase.cxx; src/VariableTransform.cxx; src/VarTransformHandler.cxx; src/Volume.cxx; src/DNN/Architectures/Reference.cxx; src/DNN/Architectures/Reference/DataLoader.cxx; src/DNN/Architectures/Reference/TensorDataLoader.cxx; src/DNN/Architectures/Cpu.cxx; src/DNN/Architectures/Cpu/CpuBuffer.cxx; src/DNN/Architectures/Cpu/CpuMatrix.cxx; ${TMVA_EXTRA_SOURCES}; DEPENDENCIES; TreePlayer; Tree; Hist; Matrix; Minuit; MLP; MathCore; Core; RIO; XMLIO; ${TMVA_EXTRA_DEPENDENCIES}; DICTIONARY_OPTIONS; -writeEmptyRootPCM; INSTALL_OPTIONS; ${installoptions}; ${EXTRA_DICT_OPTS}; ). if(MSVC); target_compile_definitions(TMVA PRIVATE _USE_MATH_DEFINES); endif(). if(vdt OR builtin_vdt); target_link_libraries(TMVA PRIVATE VDT::VDT); endif(); if(builtin_vdt); add_dependencies(TMVA VDT); endif(). if(tmva-cpu); target_include_directories(TMVA PRIVATE ${TBB_INCLUDE_DIRS}); target_link_libraries(TMVA PRIV,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/CMakeLists.txt:8675,Variab,VariableNormalizeTransform,8675,tmva/tmva/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/CMakeLists.txt,1,['Variab'],['VariableNormalizeTransform']
Modifiability,xx; src/ResultsClassification.cxx; src/Results.cxx; src/ResultsMulticlass.cxx; src/ResultsRegression.cxx; src/ROCCalc.cxx; src/ROCCurve.cxx; src/RootFinder.cxx; src/RuleCut.cxx; src/Rule.cxx; src/RuleEnsemble.cxx; src/RuleFitAPI.cxx; src/RuleFit.cxx; src/RuleFitParams.cxx; src/SdivSqrtSplusB.cxx; src/SeparationBase.cxx; src/SimulatedAnnealing.cxx; src/SimulatedAnnealingFitter.cxx; src/SVEvent.cxx; src/SVKernelFunction.cxx; src/SVKernelMatrix.cxx; src/SVWorkingSet.cxx; src/TActivationChooser.cxx; src/TActivation.cxx; src/TActivationIdentity.cxx; src/TActivationRadial.cxx; src/TActivationReLU.cxx; src/TActivationSigmoid.cxx; src/TActivationTanh.cxx; src/Timer.cxx; src/TNeuron.cxx; src/TNeuronInputAbs.cxx; src/TNeuronInputChooser.cxx; src/TNeuronInput.cxx; src/TNeuronInputSqSum.cxx; src/TNeuronInputSum.cxx; src/Tools.cxx; src/TrainingHistory.cxx; src/TransformationHandler.cxx; src/TSpline1.cxx; src/TSpline2.cxx; src/TSynapse.cxx; src/Types.cxx; src/VariableDecorrTransform.cxx; src/VariableGaussTransform.cxx; src/VariableIdentityTransform.cxx; src/VariableImportance.cxx; src/VariableInfo.cxx; src/VariableNormalizeTransform.cxx; src/VariablePCATransform.cxx; src/VariableRearrangeTransform.cxx; src/VariableTransformBase.cxx; src/VariableTransform.cxx; src/VarTransformHandler.cxx; src/Volume.cxx; src/DNN/Architectures/Reference.cxx; src/DNN/Architectures/Reference/DataLoader.cxx; src/DNN/Architectures/Reference/TensorDataLoader.cxx; src/DNN/Architectures/Cpu.cxx; src/DNN/Architectures/Cpu/CpuBuffer.cxx; src/DNN/Architectures/Cpu/CpuMatrix.cxx; ${TMVA_EXTRA_SOURCES}; DEPENDENCIES; TreePlayer; Tree; Hist; Matrix; Minuit; MLP; MathCore; Core; RIO; XMLIO; ${TMVA_EXTRA_DEPENDENCIES}; DICTIONARY_OPTIONS; -writeEmptyRootPCM; INSTALL_OPTIONS; ${installoptions}; ${EXTRA_DICT_OPTS}; ). if(MSVC); target_compile_definitions(TMVA PRIVATE _USE_MATH_DEFINES); endif(). if(vdt OR builtin_vdt); target_link_libraries(TMVA PRIVATE VDT::VDT); endif(); if(builtin_vdt); add_dependencies(TMVA VDT,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/CMakeLists.txt:8558,Variab,VariableGaussTransform,8558,tmva/tmva/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/CMakeLists.txt,1,['Variab'],['VariableGaussTransform']
Modifiability,"xx; src/RuleFitParams.cxx; src/SdivSqrtSplusB.cxx; src/SeparationBase.cxx; src/SimulatedAnnealing.cxx; src/SimulatedAnnealingFitter.cxx; src/SVEvent.cxx; src/SVKernelFunction.cxx; src/SVKernelMatrix.cxx; src/SVWorkingSet.cxx; src/TActivationChooser.cxx; src/TActivation.cxx; src/TActivationIdentity.cxx; src/TActivationRadial.cxx; src/TActivationReLU.cxx; src/TActivationSigmoid.cxx; src/TActivationTanh.cxx; src/Timer.cxx; src/TNeuron.cxx; src/TNeuronInputAbs.cxx; src/TNeuronInputChooser.cxx; src/TNeuronInput.cxx; src/TNeuronInputSqSum.cxx; src/TNeuronInputSum.cxx; src/Tools.cxx; src/TrainingHistory.cxx; src/TransformationHandler.cxx; src/TSpline1.cxx; src/TSpline2.cxx; src/TSynapse.cxx; src/Types.cxx; src/VariableDecorrTransform.cxx; src/VariableGaussTransform.cxx; src/VariableIdentityTransform.cxx; src/VariableImportance.cxx; src/VariableInfo.cxx; src/VariableNormalizeTransform.cxx; src/VariablePCATransform.cxx; src/VariableRearrangeTransform.cxx; src/VariableTransformBase.cxx; src/VariableTransform.cxx; src/VarTransformHandler.cxx; src/Volume.cxx; src/DNN/Architectures/Reference.cxx; src/DNN/Architectures/Reference/DataLoader.cxx; src/DNN/Architectures/Reference/TensorDataLoader.cxx; src/DNN/Architectures/Cpu.cxx; src/DNN/Architectures/Cpu/CpuBuffer.cxx; src/DNN/Architectures/Cpu/CpuMatrix.cxx; ${TMVA_EXTRA_SOURCES}; DEPENDENCIES; TreePlayer; Tree; Hist; Matrix; Minuit; MLP; MathCore; Core; RIO; XMLIO; ${TMVA_EXTRA_DEPENDENCIES}; DICTIONARY_OPTIONS; -writeEmptyRootPCM; INSTALL_OPTIONS; ${installoptions}; ${EXTRA_DICT_OPTS}; ). if(MSVC); target_compile_definitions(TMVA PRIVATE _USE_MATH_DEFINES); endif(). if(vdt OR builtin_vdt); target_link_libraries(TMVA PRIVATE VDT::VDT); endif(); if(builtin_vdt); add_dependencies(TMVA VDT); endif(). if(tmva-cpu); target_include_directories(TMVA PRIVATE ${TBB_INCLUDE_DIRS}); target_link_libraries(TMVA PRIVATE ${TBB_LIBRARIES}); set_target_properties(TMVA PROPERTIES COMPILE_FLAGS ""${TBB_CXXFLAGS}""). if(BLAS_FOUND); target_link_librar",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/CMakeLists.txt:8808,Variab,VariableTransform,8808,tmva/tmva/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/CMakeLists.txt,1,['Variab'],['VariableTransform']
Modifiability,"y (or make sure ``llvm-symbolizer`` is in your; ``$PATH``):. .. code-block:: console. % ASAN_SYMBOLIZER_PATH=/usr/local/bin/llvm-symbolizer ./a.out; ==9442== ERROR: AddressSanitizer heap-use-after-free on address 0x7f7ddab8c084 at pc 0x403c8c bp 0x7fff87fb82d0 sp 0x7fff87fb82c8; READ of size 4 at 0x7f7ddab8c084 thread T0; #0 0x403c8c in main example_UseAfterFree.cc:4; #1 0x7f7ddabcac4d in __libc_start_main ??:0; 0x7f7ddab8c084 is located 4 bytes inside of 400-byte region [0x7f7ddab8c080,0x7f7ddab8c210); freed by thread T0 here:; #0 0x404704 in operator delete[](void*) ??:0; #1 0x403c53 in main example_UseAfterFree.cc:4; #2 0x7f7ddabcac4d in __libc_start_main ??:0; previously allocated by thread T0 here:; #0 0x404544 in operator new[](unsigned long) ??:0; #1 0x403c43 in main example_UseAfterFree.cc:2; #2 0x7f7ddabcac4d in __libc_start_main ??:0; ==9442== ABORTING. If that does not work for you (e.g. your process is sandboxed), you can use a; separate script to symbolize the result offline (online symbolization can be; force disabled by setting ``ASAN_OPTIONS=symbolize=0``):. .. code-block:: console. % ASAN_OPTIONS=symbolize=0 ./a.out 2> log; % projects/compiler-rt/lib/asan/scripts/asan_symbolize.py / < log | c++filt; ==9442== ERROR: AddressSanitizer heap-use-after-free on address 0x7f7ddab8c084 at pc 0x403c8c bp 0x7fff87fb82d0 sp 0x7fff87fb82c8; READ of size 4 at 0x7f7ddab8c084 thread T0; #0 0x403c8c in main example_UseAfterFree.cc:4; #1 0x7f7ddabcac4d in __libc_start_main ??:0; ... Note that on macOS you may need to run ``dsymutil`` on your binary to have the; file\:line info in the AddressSanitizer reports. Additional Checks; =================. Initialization order checking; -----------------------------. AddressSanitizer can optionally detect dynamic initialization order problems,; when initialization of globals defined in one translation unit uses; globals defined in another translation unit. To enable this check at runtime,; you should set environment variable; `",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst:4526,sandbox,sandboxed,4526,interpreter/llvm-project/clang/docs/AddressSanitizer.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst,1,['sandbox'],['sandboxed']
Modifiability,"y be applied to one; parameter. .. _swiftasync:. ``swiftasync``; This indicates that the parameter is the asynchronous context parameter and; triggers the creation of a target-specific extended frame record to store; this pointer. This is not a valid attribute for return values and can only; be applied to one parameter. ``swifterror``; This attribute is motivated to model and optimize Swift error handling. It; can be applied to a parameter with pointer to pointer type or a; pointer-sized alloca. At the call site, the actual argument that corresponds; to a ``swifterror`` parameter has to come from a ``swifterror`` alloca or; the ``swifterror`` parameter of the caller. A ``swifterror`` value (either; the parameter or the alloca) can only be loaded and stored from, or used as; a ``swifterror`` argument. This is not a valid attribute for return values; and can only be applied to one parameter. These constraints allow the calling convention to optimize access to; ``swifterror`` variables by associating them with a specific register at; call boundaries rather than placing them in memory. Since this does change; the calling convention, a function which uses the ``swifterror`` attribute; on a parameter is not ABI-compatible with one which does not. These constraints also allow LLVM to assume that a ``swifterror`` argument; does not alias any other memory visible within a function and that a; ``swifterror`` alloca passed as an argument does not escape. ``immarg``; This indicates the parameter is required to be an immediate; value. This must be a trivial immediate integer or floating-point; constant. Undef or constant expressions are not valid. This is; only valid on intrinsic declarations and cannot be applied to a; call site or arbitrary function. ``noundef``; This attribute applies to parameters and return values. If the value; representation contains any undefined or poison bits, the behavior is; undefined. Note that this does not refer to padding introduced by the; type'",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:63806,variab,variables,63806,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['variab'],['variables']
Modifiability,"y centered. - Angle = 0 (degrees). - Color = 1 (black). - Size = calculate when number of entries is known. - Font = helvetica-medium-r-normal scalable font = 42, and bold = 62; for title. The title is a regular entry and supports **`TLatex`**. The default is; no title (`header = 0`). The options are the same as for **`TPave`**; by; default, they are ""`brand`"". Once the legend box is created, one has to; add the text with the `AddEntry()` method:. ``` {.cpp}; TLegendEntry* TLegend::AddEntry(TObject *obj,; const char *label,; Option_t *option); ```. The parameters are:. - `*obj `is a pointer to an object having marker, line, or fill; attributes (a histogram, or a graph). - `label` is the label to be associated to the object. - `option`:. - ""L"" draw line associated with line attributes of `obj`, if `obj`; inherits from **`TAttLine`**. - ""P"" draw poly-marker associated with marker attributes of `obj`, if; `obj` inherits **`TAttMarker`**. - ""F"" draw a box with fill associated with fill attributes of `obj`,; if `obj` inherits **`TAttFill`**. One may also use the other form of the method `AddEntry`:. ``` {.cpp}; TLegendEntry* TLegend::AddEntry(const char *name,; const char *label,; Option_t *option); ```. Here `name` is the name of the object in the pad. Other parameters are; as in the previous case. Next example shows how to create a legend:. ``` {.cpp}; leg = new TLegend(0.4,0.6,0.89,0.89);; leg->AddEntry(fun1,""One Theory"",""l"");; leg->AddEntry(fun3,""Another Theory"",""f"");; leg->AddEntry(gr,""The Data"",""p"");; leg->Draw();; // oops we forgot the blue line... add it after; leg->AddEntry(fun2,; ""#sqrt{2#pi} P_{T} (#gamma) latex formula"",""f"");; // and add a header (or ""title"") for the legend; leg->SetHeader(""The Legend Title"");; leg->Draw();; ```. Here `fun1`, `fun2`, `fun3` and `gr` are pre-existing functions and; graphs. You can edit the **`TLegend`** by right clicking on it. ![A legend example](pictures/030000D8.png). ## The PostScript Interface. To generate a PostScript (o",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Graphics.md:91075,inherit,inherits,91075,documentation/users-guide/Graphics.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Graphics.md,1,['inherit'],['inherits']
Modifiability,"y common collector designs and easy; extension points. If you don't already have a specific binary interface; you need to support, we recommend trying to use one of these built in collector; strategies. .. _gc_intrinsics:. LLVM IR Features; ================. This section describes the garbage collection facilities provided by the; :doc:`LLVM intermediate representation <LangRef>`. The exact behavior of these; IR features is specified by the selected :ref:`GC strategy description; <plugin>`. Specifying GC code generation: ``gc ""...""``; -------------------------------------------. .. code-block:: text. define <returntype> @name(...) gc ""name"" { ... }. The ``gc`` function attribute is used to specify the desired GC strategy to the; compiler. Its programmatic equivalent is the ``setGC`` method of ``Function``. Setting ``gc ""name""`` on a function triggers a search for a matching subclass; of GCStrategy. Some collector strategies are built in. You can add others; using either the loadable plugin mechanism, or by patching your copy of LLVM.; It is the selected GC strategy which defines the exact nature of the code; generated to support GC. If none is found, the compiler will raise an error. Specifying the GC style on a per-function basis allows LLVM to link together; programs that use different garbage collection algorithms (or none at all). .. _gcroot:. Identifying GC roots on the stack; ----------------------------------. LLVM currently supports two different mechanisms for describing references in; compiled code at safepoints. ``llvm.gcroot`` is the older mechanism;; ``gc.statepoint`` has been added more recently. At the moment, you can choose; either implementation (on a per :ref:`GC strategy <plugin>` basis). Longer; term, we will probably either migrate away from ``llvm.gcroot`` entirely, or; substantially merge their implementations. Note that most new development; work is focused on ``gc.statepoint``. Using ``gc.statepoint``; ^^^^^^^^^^^^^^^^^^^^^^^^; :doc:`This pa",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst:8951,plugin,plugin,8951,interpreter/llvm-project/llvm/docs/GarbageCollection.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst,1,['plugin'],['plugin']
Modifiability,"y context menus for improving interactivity; - Implement col0 and col0z draw option for TH2 histograms, similar to ROOT6; - Implement box and hbox draw options for TH1 class; - Significant (factor 4) I/O performance improvement; - New 'flex' layout:; - create frames like in Multi Document Interface; - one could move/resize/minimize/maximize such frames. For more details, like the complete change log, the documentation, and very detailed examples, see the [JSROOT home page](https://root.cern.ch/js) and the [JSROOT project github page](https://github.com/linev/jsroot) . ## Tutorials; * New tutorial `treegetval.C` illustrating how to retrieve `TTree` variables in arrays.; * Add script to automatically translate tutorials into notebooks; * Embed it into the documentation generation; * Make the notebooks available in the [tutorials section of the class documentation](https://root.cern/doc/master/group__Tutorials.html). ## Build, Configuration and Testing Infrastructure; - `root-config` does not suppress deprecation warnings (-Wno-deprecated-declarations) anymore. This means compilers will now diagnose the use of deprecated interfaces in user code.; - Added new 'builtin_vc' option to bundle a version of Vc within ROOT.; The default is OFF, however if the Vc package is not found in the system the option is switched to; ON if the option 'vc' option is ON.; - Many improvements (provided by Mattias Ellert):; - Build RFIO using dpm libraries if castor libraries are not available; - Add missing glib header path in GFAL module for version > 2; - Search also for globus libraries wouthout the flavour in the name; - Add missing io/hdfs/CMakeLists.txt; - net/globusauth has no installed headers - remove ROOT_INSTALL_HEADERS(); - Add missing pieces to the cmake config that are built by configure: bin/pq2, bin/rootd, bin/xpdtest, initd and xinitd start-up scripts; - Only link to libgfortranbegin.a when it is provided by the compiler; - Don't remove -Wall without also removing -Werror=*;",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:28227,config,config,28227,README/ReleaseNotes/v608/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md,1,['config'],['config']
Modifiability,"y dynamically allocated ref-countable object passed as a call argument spans past the end of the call. This applies to call to any function, method, lambda, function pointer or functor. Ref-countable types aren't supposed to be allocated on stack so we check arguments for parameters of raw pointers and references to uncounted types. Here are some examples of situations that we warn about as they *might* be potentially unsafe. The logic is that either we're able to guarantee that an argument is safe or it's considered if not a bug then bug-prone. .. code-block:: cpp. RefCountable* provide_uncounted();; void consume(RefCountable*);. // In these cases we can't make sure callee won't directly or indirectly call `deref()` on the argument which could make it unsafe from such point until the end of the call. void foo1() {; consume(provide_uncounted()); // warn; }. void foo2() {; RefCountable* uncounted = provide_uncounted();; consume(uncounted); // warn; }. Although we are enforcing member variables to be ref-counted by `webkit.NoUncountedMemberChecker` any method of the same class still has unrestricted access to these. Since from a caller's perspective we can't guarantee a particular member won't get modified by callee (directly or indirectly) we don't consider values obtained from members safe. Note: It's likely this heuristic could be made more precise with fewer false positives - for example calls to free functions that don't have any parameter other than the pointer should be safe as the callee won't be able to tamper with the member unless it's a global variable. .. code-block:: cpp. struct Foo {; RefPtr<RefCountable> member;; void consume(RefCountable*) { /* ... */ }; void bugprone() {; consume(member.get()); // warn; }; };. The implementation of this rule is a heuristic - we define a whitelist of kinds of values that are considered safe to be passed as arguments. If we can't prove an argument is safe it's considered an error. Allowed kinds of arguments:. - values o",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/checkers.rst:82007,variab,variables,82007,interpreter/llvm-project/clang/docs/analyzer/checkers.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/checkers.rst,1,['variab'],['variables']
Modifiability,"y following the `.. code-block:: c`, but; it looks like garbage; the line numbers don't even line up with the; lines. Is this a Sphinx bug, or is it a CSS problem?. .. code-block:: c. 1 int compute_factorial(int n); 2 {; 3 if (n <= 1); 4 return 1;; 5; 6 int f = n;; 7 while (--n > 1); 8 f *= n;; 9 return f;; 10 }; 11; 12; 13 int main(int argc, char** argv); 14 {; 15 if (argc < 2); 16 return -1;; 17 char firstletter = argv[1][0];; 18 int result = compute_factorial(firstletter - '0');; 19; 20 // Returned result is clipped at 255...; 21 return result;; 22 }. Here is a sample command line session that shows how to build and run this; code via ``lli`` inside LLDB:. .. code-block:: bash. > export BINPATH=/workspaces/llvm-project/build/bin; > $BINPATH/clang -g -S -emit-llvm --target=x86_64-unknown-unknown-elf showdebug.c; > lldb $BINPATH/lli; (lldb) target create ""/workspaces/llvm-project/build/bin/lli""; Current executable set to '/workspaces/llvm-project/build/bin/lli' (x86_64).; (lldb) settings set plugin.jit-loader.gdb.enable on; (lldb) b compute_factorial; Breakpoint 1: no locations (pending).; WARNING: Unable to resolve breakpoint to any actual locations.; (lldb) run --jit-kind=mcjit showdebug.ll 5; 1 location added to breakpoint 1; Process 21340 stopped; * thread #1, name = 'lli', stop reason = breakpoint 1.1; frame #0: 0x00007ffff7fd0007 JIT(0x45c2cb0)`compute_factorial(n=5) at showdebug.c:3:11; 1 int compute_factorial(int n); 2 {; -> 3 if (n <= 1); 4 return 1;; 5 int f = n;; 6 while (--n > 1); 7 f *= n;; (lldb) p n; (int) $0 = 5; (lldb) b showdebug.c:9; Breakpoint 2: where = JIT(0x45c2cb0)`compute_factorial + 60 at showdebug.c:9:1, address = 0x00007ffff7fd003c; (lldb) c; Process 21340 resuming; Process 21340 stopped; * thread #1, name = 'lli', stop reason = breakpoint 2.1; frame #0: 0x00007ffff7fd003c JIT(0x45c2cb0)`compute_factorial(n=1) at showdebug.c:9:1; 6 while (--n > 1); 7 f *= n;; 8 return f;; -> 9 }; 10; 11 int main(int argc, char** argv); 12 {; (lldb) p f; (",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DebuggingJITedCode.rst:3524,plugin,plugin,3524,interpreter/llvm-project/llvm/docs/DebuggingJITedCode.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DebuggingJITedCode.rst,1,['plugin'],['plugin']
Modifiability,"y from the second last entry and appends the result to the; expression stack.; - ``DW_OP_plus_uconst, 93`` adds ``93`` to the working expression.; - ``DW_OP_LLVM_fragment, 16, 8`` specifies the offset and size (``16`` and ``8``; here, respectively) of the variable fragment from the working expression. Note; that contrary to DW_OP_bit_piece, the offset is describing the location; within the described source variable.; - ``DW_OP_LLVM_convert, 16, DW_ATE_signed`` specifies a bit size and encoding; (``16`` and ``DW_ATE_signed`` here, respectively) to which the top of the; expression stack is to be converted. Maps into a ``DW_OP_convert`` operation; that references a base type constructed from the supplied values.; - ``DW_OP_LLVM_tag_offset, tag_offset`` specifies that a memory tag should be; optionally applied to the pointer. The memory tag is derived from the; given tag offset in an implementation-defined manner.; - ``DW_OP_swap`` swaps top two stack entries.; - ``DW_OP_xderef`` provides extended dereference mechanism. The entry at the top; of the stack is treated as an address. The second stack entry is treated as an; address space identifier.; - ``DW_OP_stack_value`` marks a constant value.; - ``DW_OP_LLVM_entry_value, N`` refers to the value a register had upon; function entry. When targeting DWARF, a ``DBG_VALUE(reg, ...,; DIExpression(DW_OP_LLVM_entry_value, 1, ...)`` is lowered to; ``DW_OP_entry_value [reg], ...``, which pushes the value ``reg`` had upon; function entry onto the DWARF expression stack. The next ``(N - 1)`` operations will be part of the ``DW_OP_entry_value``; block argument. For example, ``!DIExpression(DW_OP_LLVM_entry_value, 1,; DW_OP_plus_uconst, 123, DW_OP_stack_value)`` specifies an expression where; the entry value of ``reg`` is pushed onto the stack, and is added with 123.; Due to framework limitations ``N`` must be 1, in other words,; ``DW_OP_entry_value`` always refers to the value/address operand of the; instruction. Because ``DW_OP_LLVM",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:262792,extend,extended,262792,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['extend'],['extended']
Modifiability,"y instrumentation of 'safe' variables. SafeStack is going to be the; first user. 'safe' variables can be defined as variables that can not be used out-of-scope; (e.g. use-after-return) or accessed out of bounds. In the future it can be; extended to track other variable properties. E.g. we plan to extend; implementation with a check to make sure that variable is always initialized; before every read to optimize use-of-uninitialized-memory checks. How it works; ============. The analysis is implemented in two stages:. The intra-procedural, or 'local', stage performs a depth-first search inside; functions to collect all uses of each alloca, including loads/stores and uses as; arguments functions. After this stage we know which parts of the alloca are used; by functions itself but we don't know what happens after it is passed as; an argument to another function. The inter-procedural, or 'global', stage, resolves what happens to allocas after; they are passed as function arguments. This stage performs a depth-first search; on function calls inside a single module and propagates allocas usage through; functions calls. When used with ThinLTO, the global stage performs a whole program analysis over; the Module Summary Index. Testing; =======. The analysis is covered with lit tests. We expect that users can tolerate false classification of variables as; 'unsafe' when in-fact it's 'safe'. This may lead to inefficient code. However, we; can't accept false 'safe' classification which may cause sanitizers to miss actual; bugs in instrumented code. To avoid that we want additional validation tool. AddressSanitizer may help with this validation. We can instrument all variables; as usual but additionally store stack-safe information in the; ``ASanStackVariableDescription``. Then if AddressSanitizer detects a bug on; a 'safe' variable we can produce an additional report to let the user know that; probably Stack Safety Analysis failed and we should check for a bug in the; compiler.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst:1677,variab,variables,1677,interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst,3,['variab'],"['variable', 'variables']"
Modifiability,"y lines specified by ``--dump-input-filter``.; When there are multiple occurrences of this option, the largest specified; ``<N>`` has precedence. The default is 5. .. option:: --dump-input-filter <value>. In the dump requested by ``--dump-input``, print only input lines of kind; ``<value>`` plus any context specified by ``--dump-input-context``. When; there are multiple occurrences of this option, the ``<value>`` that appears; earliest in the list below has precedence. The default is ``error`` when; ``--dump-input=fail``, and it's ``all`` when ``--dump-input=always``. * ``all`` - All input lines; * ``annotation-full`` - Input lines with annotations; * ``annotation`` - Input lines with starting points of annotations; * ``error`` - Input lines with starting points of error annotations. .. option:: --enable-var-scope. Enables scope for regex variables. Variables with names that start with ``$`` are considered global and; remain set throughout the file. All other variables get undefined after each encountered ``CHECK-LABEL``. .. option:: -D<VAR=VALUE>. Sets a filecheck pattern variable ``VAR`` with value ``VALUE`` that can be; used in ``CHECK:`` lines. .. option:: -D#<FMT>,<NUMVAR>=<NUMERIC EXPRESSION>. Sets a filecheck numeric variable ``NUMVAR`` of matching format ``FMT`` to; the result of evaluating ``<NUMERIC EXPRESSION>`` that can be used in; ``CHECK:`` lines. See section; ``FileCheck Numeric Variables and Expressions`` for details on supported; numeric expressions. .. option:: -version. Show the version number of this program. .. option:: -v. Print good directive pattern matches. However, if ``-dump-input=fail`` or; ``-dump-input=always``, add those matches as input annotations instead. .. option:: -vv. Print information helpful in diagnosing internal FileCheck issues, such as; discarded overlapping ``CHECK-DAG:`` matches, implicit EOF pattern matches,; and ``CHECK-NOT:`` patterns that do not have matches. Implies ``-v``.; However, if ``-dump-input=fail`` or ``-du",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/FileCheck.rst:6041,variab,variables,6041,interpreter/llvm-project/llvm/docs/CommandGuide/FileCheck.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/FileCheck.rst,1,['variab'],['variables']
Modifiability,"y of; the back-end, which has more accurate information about register pressure and; also handles other optimizations than LICM that increase live-ranges. This pass uses alias analysis for two purposes:. #. Moving loop invariant loads and calls out of loops. If we can determine; that a load or call inside of a loop never aliases anything stored to, we; can hoist it or sink it like any other instruction. #. Scalar Promotion of Memory. If there is a store instruction inside of the; loop, we try to move the store to happen AFTER the loop instead of inside of; the loop. This can only happen if a few conditions are true:. #. The pointer stored through is loop invariant.; #. There are no stores or loads in the loop which *may* alias the pointer.; There are no calls in the loop which mod/ref the pointer. If these conditions are true, we can promote the loads and stores in the; loop of the pointer to use a temporary alloca'd variable. We then use the; :ref:`mem2reg <passes-mem2reg>` functionality to construct the appropriate; SSA form for the variable. ``loop-deletion``: Delete dead loops; ------------------------------------. This file implements the Dead Loop Deletion Pass. This pass is responsible for; eliminating loops with non-infinite computable trip counts that have no side; effects or volatile instructions, and do not contribute to the computation of; the function's return value. .. _passes-loop-extract:. ``loop-extract``: Extract loops into new functions; --------------------------------------------------. A pass wrapper around the ``ExtractLoop()`` scalar transformation to extract; each top-level loop into its own new function. If the loop is the *only* loop; in a given function, it is not touched. This is a pass most useful for; debugging via bugpoint. ``loop-reduce``: Loop Strength Reduction; ----------------------------------------. This pass performs a strength reduction on array references inside loops that; have as one or more of their components the loop in",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Passes.rst:25152,variab,variable,25152,interpreter/llvm-project/llvm/docs/Passes.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Passes.rst,1,['variab'],['variable']
Modifiability,"y reasoning about; the semantics of code. The goal of the Clang Static Analyzer is to provide a; industrial-quality static analysis framework for analyzing C, C++, and; Objective-C programs that is freely available, extensible, and has a high quality of implementation.; Part of Clang and LLVM; As its name implies, the Clang Static Analyzer is built on top of Clang and LLVM.; Strictly speaking, the analyzer is part of Clang, as Clang consists of a set of; reusable C++ libraries for building powerful source-level tools. The static; analysis engine used by the Clang Static Analyzer is a Clang library, and has; the capability to be reused in different contexts and by different clients.; Important Points to Consider; While we believe that the static analyzer is already very useful for finding; bugs, we ask you to bear in mind a few points when using it.; Work-in-Progress; The analyzer is a continuous work-in-progress. There are many planned; enhancements to improve both the precision and scope of its analysis algorithms; as well as the kinds of bugs it will find. While there are fundamental; limitations to what static analysis can do, we have a long way to go before; hitting that wall.; Slower than Compilation; Operationally, using static analysis to; automatically find deep program bugs is about trading CPU time for the hardening; of code. Because of the deep analysis performed by state-of-the-art static; analysis tools, static analysis can be much slower than compilation.; While the Clang Static Analyzer is being designed to be as fast and; light-weight as possible, please do not expect it to be as fast as compiling a; program (even with optimizations enabled). Some of the algorithms needed to find; bugs require in the worst case exponential time.; The Clang Static Analyzer runs in a reasonable amount of time by both; bounding the amount of checking work it will do as well as using clever; algorithms to reduce the amount of work it must do to find bugs.; False Positive",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/index.html:2433,enhance,enhancements,2433,interpreter/llvm-project/clang/www/analyzer/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/index.html,2,['enhance'],['enhancements']
Modifiability,"y reasons the term ""undef; dbg.value"" may be used in existing code. The ``DbgVariableIntrinsic`` methods; ``isKillLocation`` and ``setKillLocation`` should be used where possible rather; than inspecting location operands directly to check or set whether a dbg.value; is a kill location. In general, if any dbg.value has its operand optimized out and cannot be; recovered, then a kill dbg.value is necessary to terminate earlier variable; locations. Additional kill dbg.values may be necessary when the debugger can; observe re-ordering of assignments. How variable location metadata is transformed during CodeGen; ============================================================. LLVM preserves debug information throughout mid-level and backend passes,; ultimately producing a mapping between source-level information and; instruction ranges. This; is relatively straightforwards for line number information, as mapping; instructions to line numbers is a simple association. For variable locations; however the story is more complex. As each ``llvm.dbg.value`` intrinsic; represents a source-level assignment of a value to a source variable, the; variable location intrinsics effectively embed a small imperative program; within the LLVM IR. By the end of CodeGen, this becomes a mapping from each; variable to their machine locations over ranges of instructions.; From IR to object emission, the major transformations which affect variable; location fidelity are:. 1. Instruction Selection; 2. Register allocation; 3. Block layout. each of which are discussed below. In addition, instruction scheduling can; significantly change the ordering of the program, and occurs in a number of; different passes. Some variable locations are not transformed during CodeGen. Stack locations; specified by ``llvm.dbg.declare`` are valid and unchanging for the entire; duration of the function, and are recorded in a simple MachineFunction table.; Location changes in the prologue and epilogue of a function are also ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:24249,variab,variable,24249,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,1,['variab'],['variable']
Modifiability,"y the ``ROOT::Fit::DataOptions`` class, the range by the ``ROOT::Fit::DataRange`` class. Here is an example how to specify the input option to use the integral of the function value in the bin instead of using the function value; evaluated at the bin center, when doing the fit and to use a; range beween the 'xmin' and 'xmax' values. ``` {.cpp}; ROOT::Fit::DataOptions opt;; opt.fIntegral = true;; ROOT::Fit::DataRange range(xmin,xmax);; ROOT::Fit::BinData data(opt,range);; // fill the bin data using the histogram; // we can do this using the following helper function from the Hist library; TH1 * h1 = (TH1*) gDirectory->Get(""myHistogram"");; ROOT::Fit::FillData(data, h1);; ```. The list of possible fit options available is the following:; ``` {.cpp}; ROOT::Fit::DataOptions opt;; opt.fIntegral = true; // use integral of bin content instead of bin center (default is false).; opt.fBinVolume = true; // normalize data by the bin volume (default is false).; // This is for fitting density functions in histograms with variable bin sizes.; opt.fUseRange =true; // use the function range when creating the fit data (default is false).; opt.fExpErrors = true; // use the expected errors estimated from the function values; // assuming Poisson statistics and not the observed errors (default is false).; opt.fUseEmpty = true; // use empty bins when fitting (default is false). If fExpErrors; 							 // is not set an arbitrary error = 1 is assigned to those bins.; opt.fErrors1 = true; // Set all measured errors to 1 (default is false).; opt.fCoordErrors = false; // When available coordinate errors are not used in the fit; // (default is true: the errors are used when they are available,; // e.g. fitting a TGraphErrors).; opt.fAsymErrors = false; // When available asymmetric errors are considered in the fit; // (default is true, the asymmetric errors are used when they are available,; // e.g. fitting a TGraphAsymmErrors).; ```. The `ROOT::Fit::DataRange` class supports defining multiple rect",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/FittingHistograms.md:31949,variab,variable,31949,documentation/users-guide/FittingHistograms.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/FittingHistograms.md,1,['variab'],['variable']
Modifiability,"y the preprocessed content of; ""system"" headers to the output; instead, preserve the #include directive.; This can greatly reduce the volume of text produced by :option:`-E` which; can be helpful when trying to produce a ""small"" reproduceable test case. This option does not guarantee reproduceability, however. If the including; source defines preprocessor symbols that influence the behavior of system; headers (for example, ``_XOPEN_SOURCE``) the operation of :option:`-E` will; remove that definition and thus can change the semantics of the included; header. Also, using a different version of the system headers (especially a; different version of the STL) may result in different behavior. Always verify; the preprocessed file by compiling it separately. ENVIRONMENT; -----------. .. envvar:: TMPDIR, TEMP, TMP. These environment variables are checked, in order, for the location to write; temporary files used during the compilation process. .. envvar:: CPATH. If this environment variable is present, it is treated as a delimited list of; paths to be added to the default system include path list. The delimiter is; the platform dependent delimiter, as used in the PATH environment variable. Empty components in the environment variable are ignored. .. envvar:: C_INCLUDE_PATH, OBJC_INCLUDE_PATH, CPLUS_INCLUDE_PATH, OBJCPLUS_INCLUDE_PATH. These environment variables specify additional paths, as for :envvar:`CPATH`, which are; only used when processing the appropriate language. .. envvar:: MACOSX_DEPLOYMENT_TARGET. If :option:`-mmacosx-version-min` is unspecified, the default deployment; target is read from this environment variable. This option only affects; Darwin targets. BUGS; ----. To report bugs, please visit <https://github.com/llvm/llvm-project/issues/>. Most bug reports should; include preprocessed source files (use the :option:`-E` option) and the full; output of the compiler, along with information to reproduce. SEE ALSO; --------. :manpage:`as(1)`, :manpage:`ld(1)`; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/CommandGuide/clang.rst:20952,variab,variable,20952,interpreter/llvm-project/clang/docs/CommandGuide/clang.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/CommandGuide/clang.rst,5,['variab'],"['variable', 'variables']"
Modifiability,"y the supported attributes. That means that even though; ``variable(unless(is_parameter))`` is a valid match rule,; ``variable(unless(is_thread_local))`` is not. Supported Attributes; --------------------. Not all attributes can be used with the ``#pragma clang attribute`` directive.; Notably, statement attributes like ``[[fallthrough]]`` or type attributes; like ``address_space`` aren't supported by this directive. You can determine; whether or not an attribute is supported by the pragma by referring to the; :doc:`individual documentation for that attribute <AttributeReference>`. The attributes are applied to all matching declarations individually, even when; the attribute is semantically incorrect. The attributes that aren't applied to; any declaration are not verified semantically. Specifying section names for global objects (#pragma clang section); ===================================================================. The ``#pragma clang section`` directive provides a means to assign section-names; to global variables, functions and static variables. The section names can be specified as:. .. code-block:: c++. #pragma clang section bss=""myBSS"" data=""myData"" rodata=""myRodata"" relro=""myRelro"" text=""myText"". The section names can be reverted back to default name by supplying an empty; string to the section kind, for example:. .. code-block:: c++. #pragma clang section bss="""" data="""" text="""" rodata="""" relro="""". The ``#pragma clang section`` directive obeys the following rules:. * The pragma applies to all global variable, statics and function declarations; from the pragma to the end of the translation unit. * The pragma clang section is enabled automatically, without need of any flags. * This feature is only defined to work sensibly for ELF targets. * If section name is specified through _attribute_((section(""myname""))), then; the attribute name gains precedence. * Global variables that are initialized to zero will be placed in the named; bss section, if one is present",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst:186532,variab,variables,186532,interpreter/llvm-project/clang/docs/LanguageExtensions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst,2,['variab'],['variables']
Modifiability,"y those; of Clang itself. They are entirely within the Clang *project*,; regardless of the version control scheme. Core Clang Tools; ================. The core set of Clang tools that are within the main repository are; tools that very specifically complement, and allow use and testing of; *Clang* specific functionality. ``clang-check``; ---------------. :doc:`ClangCheck` combines the LibTooling framework for running a; Clang tool with the basic Clang diagnostics by syntax checking specific files; in a fast, command line interface. It can also accept flags to re-display the; diagnostics in different formats with different flags, suitable for use driving; an IDE or editor. Furthermore, it can be used in fixit-mode to directly apply; fixit-hints offered by clang. See :doc:`HowToSetupToolingForLLVM` for; instructions on how to setup and used `clang-check`. ``clang-format``; ----------------. Clang-format is both a :doc:`library <LibFormat>` and a :doc:`stand-alone tool; <ClangFormat>` with the goal of automatically reformatting C++ sources files; according to configurable style guides. To do so, clang-format uses Clang's; ``Lexer`` to transform an input file into a token stream and then changes all; the whitespace around those tokens. The goal is for clang-format to serve both; as a user tool (ideally with powerful IDE integrations) and as part of other; refactoring tools, e.g. to do a reformatting of all the lines changed during a; renaming. Extra Clang Tools; =================. As various categories of Clang Tools are added to the extra repository,; they'll be tracked here. The focus of this documentation is on the scope; and features of the tools for other tool developers; each tool should; provide its own user-focused documentation. ``clang-tidy``; --------------. `clang-tidy <https://clang.llvm.org/extra/clang-tidy/>`_ is a clang-based C++; linter tool. It provides an extensible framework for building compiler-based; static analyses detecting and fixing bug-prone ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangTools.rst:3421,config,configurable,3421,interpreter/llvm-project/clang/docs/ClangTools.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangTools.rst,1,['config'],['configurable']
Modifiability,"y to do much better than that, with its own; n-tuple classes. Among the many advantages provided by these classes one; could cite. - Optimised disk I/O. - Possibility to store many n-tuple rows. - Write the n-tuples in ROOT files. - Interactive inspection with `TBrowser`. - Store not only numbers, but also *objects* in the columns. In this section we will discuss briefly the `TNtuple` class, which is a; simplified version of the `TTree` class. A ROOT `TNtuple` object can; store rows of float entries. Let's tackle the problem according to the; usual strategy commenting a minimal example. ``` {.cpp}; @ROOT_INCLUDE_FILE macros/write_ntuple_to_file.C; ```. This data written to this example n-tuple represents, in the statistical; sense, three independent variables (Potential or Voltage, Pressure and; Temperature), and one variable (Current) which depends on the others; according to very simple laws, and an additional Gaussian smearing. This; set of variables mimics a measurement of an electrical resistance while; varying pressure and temperature. Imagine your task now consists in finding the relations among the; variables -- of course without knowing the code used to generate them.; You will see that the possibilities of the `NTuple` class enable you to; perform this analysis task. Open the ROOT file (`cond_data.root`); written by the macro above in an interactive session and use a; `TBrowser` to interactively inspect it:. ``` {.cpp}; root[0] TBrowser b; ```; You find the columns of your n-tuple written as *leafs*. Simply clicking; on them you can obtain histograms of the variables!. Next, try the following commands at the shell prompt and in the; interactive ROOT shell, respectively:. ``` {.cpp}; > root conductivity_experiment.root; Attaching file conductivity_experiment.root as _file0...; root [0] cond_data->Draw(""Current:Potential""); ```. You just produced a correlation plot with one single line of code!. Try to extend the syntax typing for example. ``` {.cpp}; root [1",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/primer/filio.md:2590,variab,variables,2590,documentation/primer/filio.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/primer/filio.md,1,['variab'],['variables']
Modifiability,"y to:. - have a system-wide, sysadmin-provided experiment configuration. - execute user actions either *before* or *after* the execution of the; system-wide script (for instance, choosing the preferred version of; the experiment's software). - transfer a custom user **payload** on each PROOF worker (for instance,; user's client-generated Grid credentials to make PROOF workers; capable of accessing a remote authenticated storage). Configuration files are searched for in two different locations:. - a system-wide directory: `<client_install_dir>/etc`. - user's home directory: `~/.vaf`. > A system-wide configuration file always has precedence over user's; > configuration. It is thus possible for the sysadmin to enforce a; > policy where some scripts cannot ever be overridden. Thanks to this separation, users can maintain an uncluttered directory; with very simple configuration files that contain only what really needs; or is allowed to be customized: for instance, user might specify a single line; containing the needed ROOT version, while all the technicalities to set; up the environment are taken care of inside system-installed scripts,; leaving the user's configuration directory clean and uncluttered. ### Local environment configuration. All the local environment files are loaded at the time of the; client's startup following a certain order. - `common.before`. - `local.before`. - `local.conf`. - `$VafConf_LocalPodLocation/PoD_env.sh`. - `common.after`. - `local.after`. The `common.*` files are sourced both for the local and the remote; environment. This might be convenient to avoid repeating the same; configuration in different places. Each file is looked for first in the system-wide directory and then in; the user's directory. If a configuration file does not exist, it is; silently skipped. The `$VafConf_LocalPodLocation/PoD_env.sh` environment script, provided; with each PROOF on Demand installation, *must exist*: without this file,; the VAF client won't start. ###",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md:2157,config,configuration,2157,proof/doc/confman/UsingVirtualAnalysisFacility.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md,2,['config'],['configuration']
Modifiability,"y value. Here are the possible suffixes for some primary *value*. *value*\ ``{17}``; The final value is bit 17 of the integer *value* (note the braces). *value*\ ``{8...15}``; The final value is bits 8--15 of the integer *value*. The order of the; bits can be reversed by specifying ``{15...8}``. *value*\ ``[i]``; The final value is element `i` of the list *value* (note the brackets).; In other words, the brackets act as a subscripting operator on the list.; This is the case only when a single element is specified. *value*\ ``[i,]``; The final value is a list that contains a single element `i` of the list.; In short, a list slice with a single element. *value*\ ``[4...7,17,2...3,4]``; The final value is a new list that is a slice of the list *value*.; The new list contains elements 4, 5, 6, 7, 17, 2, 3, and 4.; Elements may be included multiple times and in any order. This is the result; only when more than one element is specified. *value*\ ``[i,m...n,j,ls]``; Each element may be an expression (variables, bang operators).; The type of `m` and `n` should be `int`.; The type of `i`, `j`, and `ls` should be either `int` or `list<int>`. *value*\ ``.``\ *field*; The final value is the value of the specified *field* in the specified; record *value*. The paste operator; ------------------. The paste operator (``#``) is the only infix operator available in TableGen; expressions. It allows you to concatenate strings or lists, but has a few; unusual features. The paste operator can be used when specifying the record name in a; :token:`Def` or :token:`Defm` statement, in which case it must construct a; string. If an operand is an undefined name (:token:`TokIdentifier`) or the; name of a global :token:`Defvar` or :token:`Defset`, it is treated as a; verbatim string of characters. The value of a global name is not used. The paste operator can be used in all other value expressions, in which case; it can construct a string or a list. Rather oddly, but consistent with the; previous",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TableGen/ProgRef.rst:19844,variab,variables,19844,interpreter/llvm-project/llvm/docs/TableGen/ProgRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TableGen/ProgRef.rst,1,['variab'],['variables']
Modifiability,"y, it contains a few helpful member functions that try to make common; operations easy. .. _m_Module:. Important Public Members of the ``Module`` class; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. * ``Module::Module(std::string name = """")``. Constructing a Module_ is easy. You can optionally provide a name for it; (probably based on the name of the translation unit). * | ``Module::iterator`` - Typedef for function list iterator; | ``Module::const_iterator`` - Typedef for const_iterator.; | ``begin()``, ``end()``, ``size()``, ``empty()``. These are forwarding methods that make it easy to access the contents of a; ``Module`` object's :ref:`Function <c_Function>` list. * ``Module::FunctionListType &getFunctionList()``. Returns the list of :ref:`Function <c_Function>`\ s. This is necessary to use; when you need to update the list or perform a complex action that doesn't have; a forwarding method. ----------------. * | ``Module::global_iterator`` - Typedef for global variable list iterator; | ``Module::const_global_iterator`` - Typedef for const_iterator.; | ``Module::insertGlobalVariable()`` - Inserts a global variable to the list.; | ``Module::removeGlobalVariable()`` - Removes a global variable from the list.; | ``Module::eraseGlobalVariable()`` - Removes a global variable from the list and deletes it.; | ``global_begin()``, ``global_end()``, ``global_size()``, ``global_empty()``. These are forwarding methods that make it easy to access the contents of a; ``Module`` object's GlobalVariable_ list. ----------------. * ``SymbolTable *getSymbolTable()``. Return a reference to the SymbolTable_ for this ``Module``. ----------------. * ``Function *getFunction(StringRef Name) const``. Look up the specified function in the ``Module`` SymbolTable_. If it does not; exist, return ``null``. * ``FunctionCallee getOrInsertFunction(const std::string &Name,; const FunctionType *T)``. Look up the specified function in the ``Module`` SymbolTable_. If; it does not exist, add an exte",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:138977,variab,variable,138977,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,1,['variab'],['variable']
Modifiability,"y/italian-english/scudo>`_; (and Escudo in Spanish). Design; ======. Allocator; ---------; Scudo was designed with security in mind, but aims at striking a good balance; between security and performance. It was designed to be highly tunable and; configurable, and while we provide some default configurations, we encourage; consumers to come up with the parameters that will work best for their use; cases. The allocator combines several components that serve distinct purposes:. - the Primary allocator: fast and efficient, it services smaller allocation; sizes by carving reserved memory regions into blocks of identical size. There; are currently two Primary allocators implemented, specific to 32 and 64 bit; architectures. It is configurable via compile time options. - the Secondary allocator: slower, it services larger allocation sizes via the; memory mapping primitives of the underlying operating system. Secondary backed; allocations are surrounded by Guard Pages. It is also configurable via compile; time options. - the thread specific data Registry: defines how local caches operate for each; thread. There are currently two models implemented: the exclusive model where; each thread holds its own caches (using the ELF TLS); or the shared model; where threads share a fixed size pool of caches. - the Quarantine: offers a way to delay the deallocation operations, preventing; blocks to be immediately available for reuse. Blocks held will be recycled; once certain size criteria are reached. This is essentially a delayed freelist; which can help mitigate some use-after-free situations. This feature is fairly; costly in terms of performance and memory footprint, is mostly controlled by; runtime options and is disabled by default. Allocations Header; ------------------; Every chunk of heap memory returned to an application by the allocator will be; preceded by a header. This has two purposes:. - being to store various information about the chunk, that can be leveraged to; ensure",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ScudoHardenedAllocator.rst:1720,config,configurable,1720,interpreter/llvm-project/llvm/docs/ScudoHardenedAllocator.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ScudoHardenedAllocator.rst,1,['config'],['configurable']
Modifiability,"y; 4. Fix - problem with empty STL containers; 5. Fix - empty baskets at the end of branch store; 6. Fix - problem with zooming in THStack. ## Changes in 5.0.0; 1. Reading TTree data; - all kinds of branches, including split STL containers; - branches with several elementary leaves; - branches from different ROOT files; - JSROOT.TSelector class to access TTree data; - simple access to branch data with ""dump"" draw option; 2. TTree::Draw support; - simple 1D/2D/3D histograms; - simple cut conditions; - configurable histogram like ""px:py>>hist(50,-5,5,50,-5,5)""; - strings support; - iterate over arrays indexes, let use another branch as index values; - support ""Entry$"" and ""Entries$"" variables in expressions; - bits histogram like ""event.fTracks.fBits>>bits(16)""; - special handling of TBits; - arbitrary math function from JavaScript Math class, some TMath:: function from ROOT; - if branch is object, one could use methods ""TMath::Abs(lep1_p4.X()+lep1_p4.Y())""; - interactive player to configure and execute draw expression; 3. Full support of Float16_t and Double32_t types in I/O; 4. Drawing of RooPlot objects, I/O support for RooFit classes; 5. Many improvements in object inspector; - support of large lists; only first part is shown; - support of large arrays; values group in decades; - allow to call draw function for sub-elements in inspector; 6. Canvas or selected sub-pad can be enlarged when double-clicked outside frame (#116); Complete drawing will be expanded to the visible space.; Not available for flex, tabs and collapsible layouts.; 7. Support reading of local ROOT files with HTML5 FileReader.; Files can be selected only with interactive dialog.; 8. Combine ""Ctrl"" and ""Shift"" keys with mouse click on the items:; - with Shift key typically object inspector will be activated; - with Ctrl key alternative draw options will be used (like colz for TH2); 9. Update libraries; - d3.js - 4.4.4; - three.js - 84; - jquery - 3.3.1; - jquery-ui - 1.12.1. ## Changes in 4.8.2; 1",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/js/changes.md:47491,config,configure,47491,js/changes.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/js/changes.md,1,['config'],['configure']
Modifiability,"y; 9. Migrate to Node.js 8, do not support older versions. ## Changes in 5.5.2; 1. Fix - draw TH2Poly bins outline when no content specified; 2. Fix - always set axis interactive handlers (#170); 3. Fix - take into account zaxis properties when drawing color palette (#171). ## Changes in 5.5.1; 1. Fix - adjust v7 part to new class naming convention, started with R; 2. Fix - show RCanvas title; 3. New - implement 'nocache' option for JSROOT scripts loading. When specified in URL with; JSRootCore.js script, tries to avoid scripts caching problem by adding stamp parameter to all URLs; 4. New - provide simple drawing for TObjString (#164). ## Changes in 5.5.0; 1. Introduce JSROOT.StoreJSON() function. It creates JSON code for the; TCanvas with all drawn objects inside. Allows to store current canvas state; 2. Support ""item=img:file.png"" parameter to insert images in existing layout (#151); 3. Support TTree drawing into TGraph (#153), thanks @cozzyd; 4. Let configure ""&toolbar=right"" in URL to change position of tool buttons; 5. Let configure ""&divsize=500x400"" in URL of size of main div element (default - full browser); 6. Implement ""optstat1001"" and ""optfit101"" draw options for histograms; 7. Remove ""autocol"" options - standard ""plc"" should be used instead; 8. Provide drawing of artificial ""$legend"" item - it creates TLegend for all primitives in pad; Can be used when several histograms or several graphs superimposed; 9. Let configure ""&toolbar=vert"" in URL to change orientation of tool buttons; 10. Improve markers and error bars drawing for TH1/TProfile. ## Changes in 5.4.3; 1. Fix - draw functions also when histogram ""same"" option used (#159); 2. Fix - when draw histogram as markers improve optimization algorithm; 3. Fix - correct histogram Y-axis range selection in logarithmic scale; 4. Fix - for TH2 draw options allow combination ""colztext"" (#162); 5. Fix - PNG file generation with 3D drawings inside. ## Changes in 5.4.2; 1. Fix - take into account extra quotes in m",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/js/changes.md:33765,config,configure,33765,js/changes.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/js/changes.md,1,['config'],['configure']
Modifiability,"y; `LineDraw(Line l)` and call it with your object as argument:. ``` {.cpp}; LineDraw(firstline);; ```. In C++, we would not do that. We would instead define a class like this:. ``` {.cpp}; class TLine {; Double_t x1;; Double_t y1;; Double_t x2;; Double_t y2;; TLine(int x1, int y1, int x2, int y2);; void Draw();; }; ```. Here we added two functions, that we will call methods or member; functions, to the **`TLine`** class. The first method is used for; initializing the line objects we would build. It is called a; constructor. The second one is the `Draw` method itself. Therefore, to; build and draw a line, we have to do:. ``` {.cpp}; TLine l(0.2,0.2,0.8,0.9);; l.Draw();; ```. The first line builds the object `l` by calling its constructor. The; second line calls the **`TLine`**`::Draw()` method of this object. You; don't need to pass any parameters to this method since it applies to; the object `l`, which knows the coordinates of the line. These are; internal variables `x1`, `y1`, `x2`, `y2` that were initialized by the; constructor. ## Inheritance and Data Encapsulation. We have defined a **`TLine`** class that contains everything necessary; to draw a line. If we want to draw an arrow, is it so different from; drawing a line? We just have to draw a triangle at one end. It would; be very inefficient to define the class **`TArrow`** from scratch.; Fortunately, inheritance allows a class to be defined from an existing; class. We would write something like:. ``` {.cpp}; class TArrow : public TLine {; int ArrowHeadSize;; void Draw();; void SetArrowSize(int arrowsize);; }; ```. The keyword ""`public`"" will be explained later. The class **`TArrow`**; now contains everything that the class **`TLine`** does, and a couple; of more things, the size of the arrowhead and a function that can; change it. The Draw method of **`TArrow`** will draw the head and call; the draw method of **`TLine`**. We just have to write the code for; drawing the head!. ### Method Overriding. Giving th",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/ALittleC++.md:2148,variab,variables,2148,documentation/users-guide/ALittleC++.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/ALittleC++.md,1,['variab'],['variables']
Modifiability,"y; clang-format is turned off or back on. .. code-block:: c++. int formatted_code;; // clang-format off; void unformatted_code ;; // clang-format on; void formatted_code_again;. Configuring Style in Code; =========================. When using ``clang::format::reformat(...)`` functions, the format is specified; by supplying the `clang::format::FormatStyle; <https://clang.llvm.org/doxygen/structclang_1_1format_1_1FormatStyle.html>`_; structure. Configurable Format Style Options; =================================. This section lists the supported style options. Value type is specified for; each option. For enumeration types possible values are specified both as a C++; enumeration member (with a prefix, e.g. ``LS_Auto``), and as a value usable in; the configuration (without a prefix: ``Auto``). .. _BasedOnStyle:. **BasedOnStyle** (``String``) :ref:`¶ <BasedOnStyle>`; The style used for all options not specifically set in the configuration. This option is supported only in the :program:`clang-format` configuration; (both within ``-style='{...}'`` and the ``.clang-format`` file). Possible values:. * ``LLVM``; A style complying with the `LLVM coding standards; <https://llvm.org/docs/CodingStandards.html>`_; * ``Google``; A style complying with `Google's C++ style guide; <https://google.github.io/styleguide/cppguide.html>`_; * ``Chromium``; A style complying with `Chromium's style guide; <https://chromium.googlesource.com/chromium/src/+/refs/heads/main/styleguide/styleguide.md>`_; * ``Mozilla``; A style complying with `Mozilla's style guide; <https://firefox-source-docs.mozilla.org/code-quality/coding-style/index.html>`_; * ``WebKit``; A style complying with `WebKit's style guide; <https://www.webkit.org/coding/coding-style.html>`_; * ``Microsoft``; A style complying with `Microsoft's style guide; <https://docs.microsoft.com/en-us/visualstudio/ide/editorconfig-code-style-settings-reference>`_; * ``GNU``; A style complying with the `GNU coding standards; <https://www.gnu.org",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst:5266,config,configuration,5266,interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,1,['config'],['configuration']
Modifiability,"y; please take a look at; the `latest version of PrintFunctionNames.cpp; <https://github.com/llvm/llvm-project/blob/main/clang/examples/PrintFunctionNames/PrintFunctionNames.cpp>`_. Running the plugin; ==================. Using the compiler driver; --------------------------. The Clang driver accepts the `-fplugin` option to load a plugin.; Clang plugins can receive arguments from the compiler driver command; line via the `fplugin-arg-<plugin name>-<argument>` option. Using this; method, the plugin name cannot contain dashes itself, but the argument; passed to the plugin can. .. code-block:: console. $ export BD=/path/to/build/directory; $ make -C $BD CallSuperAttr; $ clang++ -fplugin=$BD/lib/CallSuperAttr.so \; -fplugin-arg-call_super_plugin-help \; test.cpp. If your plugin name contains dashes, either rename the plugin or used the; cc1 command line options listed below. Using the cc1 command line; --------------------------. To run a plugin, the dynamic library containing the plugin registry must be; loaded via the `-load` command line option. This will load all plugins; that are registered, and you can select the plugins to run by specifying the; `-plugin` option. Additional parameters for the plugins can be passed with; `-plugin-arg-<plugin-name>`. Note that those options must reach clang's cc1 process. There are two; ways to do so:. * Directly call the parsing process by using the `-cc1` option; this; has the downside of not configuring the default header search paths, so; you'll need to specify the full system path configuration on the command; line.; * Use clang as usual, but prefix all arguments to the cc1 process with; `-Xclang`. For example, to run the ``print-function-names`` plugin over a source file in; clang, first build the plugin, and then call clang with the plugin from the; source tree:. .. code-block:: console. $ export BD=/path/to/build/directory; $ (cd $BD && make PrintFunctionNames ); $ clang++ -D_GNU_SOURCE -D_DEBUG -D__STDC_CONSTANT_MACROS \; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangPlugins.rst:5175,plugin,plugin,5175,interpreter/llvm-project/clang/docs/ClangPlugins.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangPlugins.rst,2,['plugin'],['plugin']
Modifiability,"yLevel No Default Default, Debug, Verbose, Info, Warning, Error, Fatal Verbosity level. VarTransform No None − List of variable transformations performed before training, e.g., D_Background,P_Signal,G,N_AllClasses for: Decorrelation, PCA-transformation, Gaussianisation, Normalisation, each for the given class of events ('AllClasses' denotes all events of all classes, if no class indication is given, 'All' is assumed). H No False − Print method-specific help message. CreateMVAPdfs No False − Create PDFs for classifier outputs (signal and background). IgnoreNegWeightsInTraining No False − Events with negative weights are ignored in the training (but are included for testing and performance evaluation). FitMethod No GA GA, SA, MC, MCEvents, MINUIT, EventScan Minimisation Method (GA, SA, and MC are the primary methods to be used; the others have been introduced for testing purposes and are depreciated). EffMethod No EffSel EffSel, EffPDF Selection Method. CutRangeMin Yes -1 − Minimum of allowed cut range (set per variable). CutRangeMax Yes -1 − Maximum of allowed cut range (set per variable). VarProp Yes NotEnforced NotEnforced, FMax, FMin, FSmart Categorisation of cuts. Configuration options for MVA method :. Configuration options reference for MVA method: PDEFoam. Option Array Default value Predefined values Description. V No False − Verbose output (short form of VerbosityLevel below - overrides the latter one). VerbosityLevel No Default Default, Debug, Verbose, Info, Warning, Error, Fatal Verbosity level. VarTransform No None − List of variable transformations performed before training, e.g., D_Background,P_Signal,G,N_AllClasses for: Decorrelation, PCA-transformation, Gaussianisation, Normalisation, each for the given class of events ('AllClasses' denotes all events of all classes, if no class indication is given, 'All' is assumed). H No False − Print method-specific help message. CreateMVAPdfs No False − Create PDFs for classifier outputs (signal and background). Ig",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/tmva/UsersGuide/optionRef.html:25469,variab,variable,25469,documentation/tmva/UsersGuide/optionRef.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/tmva/UsersGuide/optionRef.html,2,['variab'],['variable']
Modifiability,"y_streambuf);; }; };. void test() {; my_stream1<char> *p1 = new my_stream1<char>;; my_stream2<char> *p2 = new my_stream2<char>;; p1->narrow('a', 'b'); // warn; p2->narrow('a', 'b'); // ok; }. undefbehavior.MinusOnePosType; (C++); Undefined behavior: passing -1 to any streambuf/; istream/ostream member that accepts a value of; type traits::pos_type result in undefined behavior.; Source: C++03 27.4.3.2p3; C++11 27.5.4.2p3. #include <fstream>. class my_streambuf : public std::streambuf {; void f() {; seekpos(-1); // warn; }; };. #include <fstream>. void test() {; std::filebuf fb;; std::istream in(&fb);; std::filebuf::off_type pos(-1);; in.seekg(pos); // warn; }. different. Name, DescriptionExampleProgress. different.SuccessiveAssign; (C); Successive assign to a variable. int test() {; int i;; i=1;; i=2; // warn; return i;; }. different.NullDerefStmtOrder; (C); Dereferencing of the null pointer might take place. Checking the pointer for; null should be performed first.; Note: possibly an enhancement to ; core.NullDereference. struct S {; int x;; };. struct S* f();. void test() {; struct S *p1 = f();; int x1 = p1->x; // warn; if (p1) {};. struct S *p2 = f();; int x2 = p2->x; // ok; }. different.NullDerefCondOrder; (C); Dereferencing of the null pointer might take place. Checking the pointer for; null should be performed first.; Note: possibly an enhancement to ; core.NullDereference. struct S {int i;};. struct S* f();. void test() {; struct S *p = f();; if (p->i && p) {}; // warn; }. different.MultipleAccessors; (C++); Identical accessor bodies. Possibly a misprint. class A {; int i;; int j;; public:; int getI() { return i; }; int getJ() { return i; } // warn; };. class A {; int i;; int j;; public:; void setI(int& ii) { i = ii; }; void setJ(int& jj) { i = jj; } // warn; };. different.AccessorsForPublic; (C++); Accessors exist for a public class field. Should this field really be; public?. class A {; public:; int i; // warn; int getI() { return i; }; void setI(int& ii) { ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/potential_checkers.html:19959,enhance,enhancement,19959,interpreter/llvm-project/clang/www/analyzer/potential_checkers.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/potential_checkers.html,2,['enhance'],['enhancement']
Modifiability,"y_string ""a b c d""). Lists of Lists; --------------. One of the more complicated patterns in CMake is lists of lists. Because a list; cannot contain an element with a semi-colon to construct a list of lists you; make a list of variable names that refer to other lists. For example:. .. code-block:: cmake. set(list_of_lists a b c); set(a 1 2 3); set(b 4 5 6); set(c 7 8 9). With this layout you can iterate through the list of lists printing each value; with the following code:. .. code-block:: cmake. foreach(list_name IN LISTS list_of_lists); foreach(value IN LISTS ${list_name}); message(${value}); endforeach(); endforeach(). You'll notice that the inner foreach loop's list is doubly dereferenced. This is; because the first dereference turns ``list_name`` into the name of the sub-list; (a, b, or c in the example), then the second dereference is to get the value of; the list. This pattern is used throughout CMake, the most common example is the compiler; flags options, which CMake refers to using the following variable expansions:; CMAKE_${LANGUAGE}_FLAGS and CMAKE_${LANGUAGE}_FLAGS_${CMAKE_BUILD_TYPE}. Other Types; -----------. Variables that are cached or specified on the command line can have types; associated with them. The variable's type is used by CMake's UI tool to display; the right input field. A variable's type generally doesn't impact evaluation,; however CMake does have special handling for some variables such as PATH.; You can read more about the special handling in `CMake's set documentation; <https://cmake.org/cmake/help/v3.5/command/set.html#set-cache-entry>`_. Scope; -----. CMake inherently has a directory-based scoping. Setting a variable in a; CMakeLists file, will set the variable for that file, and all subdirectories.; Variables set in a CMake module that is included in a CMakeLists file will be; set in the scope they are included from, and all subdirectories. When a variable that is already set is set again in a subdirectory it overrides; the valu",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst:5591,variab,variable,5591,interpreter/llvm-project/llvm/docs/CMakePrimer.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst,1,['variab'],['variable']
Modifiability,"yms are; valuable [ParzyszekAcronym]_ [LattnerAcronym]_. The most commonly cited acronym; is ``TLI`` however that is used to refer to both ``TargetLowering`` and; ``TargetLibraryInfo`` [GreeneDistinguish]_. The following is a list of acronyms considered sufficiently useful that the; benefit of using them outweighs the cost of learning them. Acronyms that are; either not on the list or are used to refer to a different type should be; expanded. ============================ =============; Class name Variable name; ============================ =============; DeterministicFiniteAutomaton dfa; DominatorTree dt; LoopInfo li; MachineFunction mf; MachineInstr mi; MachineRegisterInfo mri; ScalarEvolution se; TargetInstrInfo tii; TargetLibraryInfo tli; TargetRegisterInfo tri; ============================ =============. In some cases renaming acronyms to the full type name will result in overly; verbose code. Unlike most classes, a variable's scope is limited and therefore; some of its purpose can implied from that scope, meaning that fewer words are; necessary to give it a clear name. For example, in an optimization pass the reader; can assume that a variable's purpose relates to optimization and therefore an; ``OptimizationRemarkEmitter`` variable could be given the name ``remarkEmitter``; or even ``remarker``. The following is a list of longer class names and the associated shorter; variable name. ========================= =============; Class name Variable name; ========================= =============; BasicBlock block; ConstantExpr expr; ExecutionEngine engine; MachineOperand operand; OptimizationRemarkEmitter remarker; PreservedAnalyses analyses; PreservedAnalysesChecker checker; TargetLowering lowering; TargetMachine machine; ========================= =============. Transition Options; ==================. There are three main options for transitioning:. 1. Keep the current coding standard; 2. Laissez faire; 3. Big bang. Keep the current coding standard; -----------------",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/VariableNames.rst:6450,variab,variable,6450,interpreter/llvm-project/llvm/docs/Proposals/VariableNames.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/VariableNames.rst,1,['variab'],['variable']
Modifiability,"you must export ``MACOSX_DEPLOYMENT_TARGET=10.9`` before running; the script. This script builds three phases of Clang+LLVM twice each (Release and; Release+Asserts), so use screen or nohup to avoid headaches, since it'll take; a long time. Use the ``--help`` option to see all the options and chose it according to; your needs. findRegressions-nightly.py; --------------------------. TODO. .. _test-suite:. Test Suite; ==========. .. contents::; :local:. Follow the `LNT Quick Start Guide; <https://llvm.org/docs/lnt/quickstart.html>`__ link on how to set-up the; test-suite. The binary location you'll have to use for testing is inside the; ``rcN/Phase3/Release+Asserts/llvmCore-REL-RC.install``.; Link that directory to an easier location and run the test-suite. An example on the run command line, assuming you created a link from the correct; install directory to ``~/devel/llvm/install``::. ./sandbox/bin/python sandbox/bin/lnt runtest \; nt \; -j4 \; --sandbox sandbox \; --test-suite ~/devel/llvm/test/test-suite \; --cc ~/devel/llvm/install/bin/clang \; --cxx ~/devel/llvm/install/bin/clang++. It should have no new regressions, compared to the previous release or release; candidate. You don't need to fix all the bugs in the test-suite, since they're; not necessarily meant to pass on all architectures all the time. This is; due to the nature of the result checking, which relies on direct comparison,; and most of the time, the failures are related to bad output checking, rather; than bad code generation. If the errors are in LLVM itself, please report every single regression found; as blocker, and all the other bugs as important, but not necessarily blocking; the release to proceed. They can be set as ""known failures"" and to be; fix on a future date. .. _pre-release-process:. Pre-Release Process; ===================. .. contents::; :local:. When the release process is announced on the mailing list, you should prepare; for the testing, by applying the same testing you'll do on",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ReleaseProcess.rst:3873,sandbox,sandbox,3873,interpreter/llvm-project/llvm/docs/ReleaseProcess.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ReleaseProcess.rst,4,['sandbox'],['sandbox']
Modifiability,"yout you can iterate through the list of lists printing each value; with the following code:. .. code-block:: cmake. foreach(list_name IN LISTS list_of_lists); foreach(value IN LISTS ${list_name}); message(${value}); endforeach(); endforeach(). You'll notice that the inner foreach loop's list is doubly dereferenced. This is; because the first dereference turns ``list_name`` into the name of the sub-list; (a, b, or c in the example), then the second dereference is to get the value of; the list. This pattern is used throughout CMake, the most common example is the compiler; flags options, which CMake refers to using the following variable expansions:; CMAKE_${LANGUAGE}_FLAGS and CMAKE_${LANGUAGE}_FLAGS_${CMAKE_BUILD_TYPE}. Other Types; -----------. Variables that are cached or specified on the command line can have types; associated with them. The variable's type is used by CMake's UI tool to display; the right input field. A variable's type generally doesn't impact evaluation,; however CMake does have special handling for some variables such as PATH.; You can read more about the special handling in `CMake's set documentation; <https://cmake.org/cmake/help/v3.5/command/set.html#set-cache-entry>`_. Scope; -----. CMake inherently has a directory-based scoping. Setting a variable in a; CMakeLists file, will set the variable for that file, and all subdirectories.; Variables set in a CMake module that is included in a CMakeLists file will be; set in the scope they are included from, and all subdirectories. When a variable that is already set is set again in a subdirectory it overrides; the value in that scope and any deeper subdirectories. The CMake set command provides two scope-related options. PARENT_SCOPE sets a; variable into the parent scope, and not the current scope. The CACHE option sets; the variable in the CMakeCache, which results in it being set in all scopes. The; CACHE option will not set a variable that already exists in the CACHE unless the; FORCE option i",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst:5893,variab,variable,5893,interpreter/llvm-project/llvm/docs/CMakePrimer.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst,2,['variab'],"['variable', 'variables']"
Modifiability,"yout. - The scheduling the I/O customization rules within a StreamerInfo is now as soon as possible, i.e. after all sources have been read. One significant consequence is that now when an object is stored in a split branch; the rule is associtated with the branch of the last of the rule's sources rather; than the last of the object's data member. - Properly support TStreamerInfo written by ROOT v4.00. - Fix the ordering of the keys in a TFile being written; in particular fixing the result of GetKey and FindKey which were no longer returning the lastest cycle for a TFile being written since v5.34/11. ## Networking Libraries. ### HTTP Server. ##### Command Interface; One can now register an arbitrary command to the server, which become visible in the web browser. Then, when the item is clicked by the user, the command ends-up in a gROOT->ProcessLineSync() call. ##### Custom Properties ; Custom properties can be configured for any item in the server. For example, one could configure an icon for each item visible in the browser. Or one could 'hide' any item from the user (but keep access with normal http requests). With such properties one could specify which item is drawn when web page is loaded, or configure monitoring. See tutorials/http/httpcontrol.C macro for more details. ##### Method Calls; Implement exe.json requests to be able to execute any method of registered objects. This request is used to provide remote TTree::Draw() functionality. ##### Misc; Correctly set 'Cache-Control' headers when replying to http requests.; Better support of STL containers when converting objects into json with TBufferJSON class. ## JavaScript ROOT. - Several files can now be loaded simultaneously; - Use d3.time.scale to display time scales; - Implemented drag and drop to superimpose histograms or graphs; - Allow selection of drawing option via context menu; - Better support of touch devices; - Provide simple layout, making it default; - Allow to open ROOT files in online session (vi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md:9702,config,configure,9702,README/ReleaseNotes/v604/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md,1,['config'],['configure']
Modifiability,"ype hierarchy in C++ programs. The first is; a genuine type hierarchy where different types in the hierarchy model; a specific subset of the functionality and semantics, and these types nest; strictly within each other. Good examples of this can be seen in the ``Value``; or ``Type`` type hierarchies. A second is the desire to dispatch dynamically across a collection of; polymorphic interface implementations. This latter use case can be modeled with; virtual dispatch and inheritance by defining an abstract interface base class; which all implementations derive from and override. However, this; implementation strategy forces an **""is-a""** relationship to exist that is not; actually meaningful. There is often not some nested hierarchy of useful; generalizations which code might interact with and move up and down. Instead,; there is a singular interface which is dispatched across a range of; implementations. The preferred implementation strategy for the second use case is that of; generic programming (sometimes called ""compile-time duck typing"" or ""static; polymorphism""). For example, a template over some type parameter ``T`` can be; instantiated across any particular implementation that conforms to the; interface or *concept*. A good example here is the highly generic properties of; any type which models a node in a directed graph. LLVM models these primarily; through templates and generic programming. Such templates include the; ``LoopInfoBase`` and ``DominatorTreeBase``. When this type of polymorphism; truly needs **dynamic** dispatch you can generalize it using a technique; called *concept-based polymorphism*. This pattern emulates the interfaces and; behaviors of templates using a very limited form of virtual dispatch for type; erasure inside its implementation. You can find examples of this technique in; the ``PassManager.h`` system, and there is a more detailed introduction to it; by Sean Parent in several of his talks and papers:. #. `Inheritance Is The Base Clas",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:130165,polymorphi,polymorphism,130165,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,1,['polymorphi'],['polymorphism']
Modifiability,"ype is; determined at runtime and we are not 100% sure that our type info is; correct. For virtual calls, inline the most plausible definition. * ``analyzer-config ipa=dynamic-bifurcate`` - Same as -analyzer-config ipa=dynamic,; but the path is split. We inline on one branch and do not inline on the; other. This mode does not drop the coverage in cases when the parent class; has code that is only exercised when some of its methods are overridden. Currently, ``-analyzer-config ipa=dynamic-bifurcate`` is the default mode. While ``-analyzer-config ipa`` determines in general how aggressively the analyzer; will try to inline functions, several additional options control which types of; functions can inlined, in an all-or-nothing way. These options use the; analyzer's configuration table, so they are all specified as follows:. ``-analyzer-config OPTION=VALUE``. c++-inlining; ------------. This option controls which C++ member functions may be inlined. ``-analyzer-config c++-inlining=[none | methods | constructors | destructors]``. Each of these modes implies that all the previous member function kinds will be; inlined as well; it doesn't make sense to inline destructors without inlining; constructors, for example. The default c++-inlining mode is 'destructors', meaning that all member; functions with visible definitions will be considered for inlining. In some; cases the analyzer may still choose not to inline the function. Note that under 'constructors', constructors for types with non-trivial; destructors will not be inlined. Additionally, no C++ member functions will be; inlined under -analyzer-config ipa=none or -analyzer-config ipa=basic-inlining,; regardless of the setting of the c++-inlining mode. c++-template-inlining; ^^^^^^^^^^^^^^^^^^^^^. This option controls whether C++ templated functions may be inlined. ``-analyzer-config c++-template-inlining=[true | false]``. Currently, template functions are considered for inlining by default. The motivation behind this o",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/developer-docs/IPA.rst:1913,config,config,1913,interpreter/llvm-project/clang/docs/analyzer/developer-docs/IPA.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/developer-docs/IPA.rst,1,['config'],['config']
Modifiability,"ype of a thrown exception differs from those specified in; a throw(type) specifier. struct S{};. void test() throw(int) {; S s;; throw (s); // warn; }. smart pointers. Name, DescriptionExampleProgress. smartptr.SmartPtrInit; (C++); C++03: auto_ptr should store a pointer to an object obtained via; new as allocated memory will be cleaned using delete.; C++11: one should use unique_ptr<type[]> to keep a; pointer to memory allocated by new[].; C++11: to keep a pointer to memory allocated by new[] in; a shared_ptr one should use a custom deleter that calls ; delete[]..; Source: C++03 20.4.5p1; C++11 auto_ptr is deprecated (D.10). #include <stdlib.h>; #include <memory>. void test() {; std::auto_ptr<int> p1(new int); // Ok; std::auto_ptr<int> p2(new int[3]); // warn; }. #include <stdlib.h>; #include <memory>. void test() {; std::auto_ptr<int> p((int *)malloc(sizeof(int))); // warn; }. dead code. Name, DescriptionExampleProgress. deadcode.UnmodifiedVariable; (C, C++); A variable is never modified but was not declared const and is not a; reference.(opt-in checker). extern int computeDelta();. int test(bool cond) {; int i = 0;; if (cond) {; const int delta = computeDelta();; // warn: forgot to modify 'i'; }; return i;; }. PR16890. deadcode.IdempotentOperations; (C); Warn about idempotent operations. void test() {; int x = 7;; x = x; // warn: value is always the same; }. void test() {; int x = 7;; x /= x; // warn: value is always 1; }. void test() {; int x = 7, one = 1;; x *= one; // warn: right op is always 1; }. void test() {; int x = 7, zero = 0;; x = x - zero;; // warn: the right operand to '-' is always 0; }. removed from alpha.deadcode.* at; r198476. POSIX. Name, DescriptionExampleProgress. posix.Errno; (C); Record that errno is non-zero when certain functions; fail. #include <stdlib.h>. int readWrapper(int fd, int *count) {; int lcount = read(fd, globalBuf, sizeof(globalBuf));; if (lcount < 0); return errno;; *count = lcount;; return 0;; }. void use(int fd) {; int count",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/potential_checkers.html:4224,variab,variable,4224,interpreter/llvm-project/clang/www/analyzer/potential_checkers.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/potential_checkers.html,2,['variab'],['variable']
Modifiability,"ype_information>`_, for example,; ``dynamic_cast<>``). That said, LLVM does make extensive use of a hand-rolled form of RTTI that use; templates like :ref:`isa\<>, cast\<>, and dyn_cast\<> <isa>`.; This form of RTTI is opt-in and can be; :doc:`added to any class <HowToSetUpLLVMStyleRTTI>`. Prefer C++-style casts; ^^^^^^^^^^^^^^^^^^^^^^. When casting, use ``static_cast``, ``reinterpret_cast``, and ``const_cast``,; rather than C-style casts. There are two exceptions to this:. * When casting to ``void`` to suppress warnings about unused variables (as an; alternative to ``[[maybe_unused]]``). Prefer C-style casts in this instance. * When casting between integral types (including enums that are not strongly-; typed), functional-style casts are permitted as an alternative to; ``static_cast``. .. _static constructor:. Do not use Static Constructors; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Static constructors and destructors (e.g., global variables whose types have a; constructor or destructor) should not be added to the code base, and should be; removed wherever possible. Globals in different source files are initialized in `arbitrary order; <https://yosefk.com/c++fqa/ctors.html#fqa-10.12>`_, making the code more; difficult to reason about. Static constructors have negative impact on launch time of programs that use; LLVM as a library. We would really like for there to be zero cost for linking; in an additional LLVM target or other library into an application, but static; constructors undermine this goal. Use of ``class`` and ``struct`` Keywords; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. In C++, the ``class`` and ``struct`` keywords can be used almost; interchangeably. The only difference is when they are used to declare a class:; ``class`` makes all members private by default while ``struct`` makes all; members public by default. * All declarations and definitions of a given ``class`` or ``struct`` must use; the same keyword. For example:. .. code-block:: c++. // Avoid if `Example",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:23346,variab,variables,23346,interpreter/llvm-project/llvm/docs/CodingStandards.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst,1,['variab'],['variables']
Modifiability,"ype`` carries a reference to its owning context, most other entities can; determine what context they belong to by looking at their own ``Type``. If you; are adding new entities to LLVM IR, please try to maintain this interface; design. .. _jitthreading:. Threads and the JIT; -------------------. LLVM's ""eager"" JIT compiler is safe to use in threaded programs. Multiple; threads can call ``ExecutionEngine::getPointerToFunction()`` or; ``ExecutionEngine::runFunction()`` concurrently, and multiple threads can run; code output by the JIT concurrently. The user must still ensure that only one; thread accesses IR in a given ``LLVMContext`` while another thread might be; modifying it. One way to do that is to always hold the JIT lock while accessing; IR outside the JIT (the JIT *modifies* the IR by adding ``CallbackVH``\ s).; Another way is to only call ``getPointerToFunction()`` from the; ``LLVMContext``'s thread. When the JIT is configured to compile lazily (using; ``ExecutionEngine::DisableLazyCompilation(false)``), there is currently a `race; condition <https://bugs.llvm.org/show_bug.cgi?id=5184>`_ in updating call sites; after a function is lazily-jitted. It's still possible to use the lazy JIT in a; threaded program if you ensure that only one thread at a time can call any; particular lazy stub and that the JIT lock guards any IR access, but we suggest; using only the eager JIT in threaded programs. .. _advanced:. Advanced Topics; ===============. This section describes some of the advanced or obscure API's that most clients; do not need to be aware of. These API's tend manage the inner workings of the; LLVM system, and only need to be accessed in unusual circumstances. .. _SymbolTable:. The ``ValueSymbolTable`` class; ------------------------------. The ``ValueSymbolTable`` (`doxygen; <https://llvm.org/doxygen/classllvm_1_1ValueSymbolTable.html>`__) class provides; a symbol table that the :ref:`Function <c_Function>` and Module_ classes use for; naming value definiti",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:124749,config,configured,124749,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,1,['config'],['configured']
Modifiability,"ypes; supported by QL you will get a window showing the file content, for file types; not supported you will get a generic window showing some basic file info. The idea of QL is that file content can be shown without the heavy application; startup process. Generating a QL view of a ROOT file depends on the size of the; file, but generally it is a quick operation. Get the binary for the ROOTQL plugin from:. ftp://root.cern.ch/root/ROOTQL.tgz. To install the plugin, after untarring the above file, just drag the bundle; ROOTQL.qlgenerator to /Library/QuickLook (global, i.e. for all users on a; system) or to ~/Library/QuickLook (local, this user only) directory.; You may need to create that folder if it doesn't already exist. To build from source, get it from svn using:. svn co http://root.cern.ch/svn/root/trunk/misc/rootql rootql. Open the ROOTQL project in Xcode and click on ""Build"" (make sure the Active; Build Configuration is set the ""Release""). Copy the resulting; plugin from build/Release to the desired QuickLook directory. SpotLight plugin for MacOS X. This is a Spotlight plugin that allows ROOT files to be indexed by SL.; Once indexed SL can find ROOT files based on the names and titles of the; objects in the files. Spotlight is available on MacOS X since version 10.4 (Tiger). To use SL; select the SL icon on the top right of the menubar and type in a search text. Get the binary for the ROOTSL plugin from:. ftp://root.cern.ch/root/ROOTSL.tgz. To install the plugin, after untarring the above file, just drag the bundle; ROOTSL.mdimporter to /Library/Spotlight (global, i.e. for all users on a; system) or to ~/Library/Spotlight (local, this user only) directory.; You may need to create that folder if it doesn't already exist. To build from source, get it from svn using:. svn co http://root.cern.ch/svn/root/trunk/misc/rootsl rootsl. Open the ROOTSL project in Xcode and click on ""Build"" (make sure the Active; Build Configuration is set the ""Release""). Copy the resulti",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/misc/doc/v524/index.html:1249,plugin,plugin,1249,misc/doc/v524/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/misc/doc/v524/index.html,2,['plugin'],['plugin']
Modifiability,"ys whose size is a value-dependent expression. Given; template<typename T, int Size>; class array {; T data[Size];; };; dependentSizedArrayType(); matches ""T data[Size]"". Matcher<Type>dependentSizedExtVectorTypeMatcher<DependentSizedExtVectorType>...; Matches C++ extended vector type where either the type or size is; dependent. Given; template<typename T, int Size>; class vector {; typedef T __attribute__((ext_vector_type(Size))) type;; };; dependentSizedExtVectorType(); matches ""T __attribute__((ext_vector_type(Size)))"". Matcher<Type>elaboratedTypeMatcher<ElaboratedType>...; Matches types specified with an elaborated type keyword or with a; qualified name. Given; namespace N {; namespace M {; class D {};; }; }; class C {};. class C c;; N::M::D d;. elaboratedType() matches the type of the variable declarations of both; c and d. Matcher<Type>enumTypeMatcher<EnumType>...; Matches enum types. Given; enum C { Green };; enum class S { Red };. C c;; S s;. enumType() matches the type of the variable declarations of both c and; s. Matcher<Type>functionProtoTypeMatcher<FunctionProtoType>...; Matches FunctionProtoType nodes. Given; int (*f)(int);; void g();; functionProtoType(); matches ""int (*f)(int)"" and the type of ""g"" in C++ mode.; In C mode, ""g"" is not matched because it does not contain a prototype. Matcher<Type>functionTypeMatcher<FunctionType>...; Matches FunctionType nodes. Given; int (*f)(int);; void g();; functionType(); matches ""int (*f)(int)"" and the type of ""g"". Matcher<Type>incompleteArrayTypeMatcher<IncompleteArrayType>...; Matches C arrays with unspecified size. Given; int a[] = { 2, 3 };; int b[42];; void f(int c[]) { int d[a[0]]; };; incompleteArrayType(); matches ""int a[]"" and ""int c[]"". Matcher<Type>injectedClassNameTypeMatcher<InjectedClassNameType>...; Matches injected class name types. Example matches S s, but not S<T> s.; (matcher = parmVarDecl(hasType(injectedClassNameType()))); template <typename T> struct S {; void f(S s);; void g(S<T> s);; };. Matc",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LibASTMatchersReference.html:47988,variab,variable,47988,interpreter/llvm-project/clang/docs/LibASTMatchersReference.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LibASTMatchersReference.html,2,['variab'],['variable']
Modifiability,"ysis results from the outer analysis manager; should be immutable, so invalidation shouldn't be a concern. However, it is; possible for some inner analysis to depend on some outer analysis, and when; the outer analysis is invalidated, we need to make sure that dependent inner; analyses are also invalidated. This actually happens with alias analysis; results. Alias analysis is a function-level analysis, but there are; module-level implementations of specific types of alias analysis. Currently; ``GlobalsAA`` is the only module-level alias analysis and it generally is not; invalidated so this is not so much of a concern. See; ``OuterAnalysisManagerProxy::Result::registerOuterAnalysisInvalidation()``; for more details. Invoking ``opt``; ================. .. code-block:: shell. $ opt -passes='pass1,pass2' /tmp/a.ll -S; # -p is an alias for -passes; $ opt -p pass1,pass2 /tmp/a.ll -S. The new PM typically requires explicit pass nesting. For example, to run a; function pass, then a module pass, we need to wrap the function pass in a module; adaptor:. .. code-block:: shell. $ opt -passes='function(no-op-function),no-op-module' /tmp/a.ll -S. A more complete example, and ``-debug-pass-manager`` to show the execution; order:. .. code-block:: shell. $ opt -passes='no-op-module,cgscc(no-op-cgscc,function(no-op-function,loop(no-op-loop))),function(no-op-function,loop(no-op-loop))' /tmp/a.ll -S -debug-pass-manager. Improper nesting can lead to error messages such as. .. code-block:: shell. $ opt -passes='no-op-function,no-op-module' /tmp/a.ll -S; opt: unknown function pass 'no-op-module'. The nesting is: module (-> cgscc) -> function -> loop, where the CGSCC nesting is optional. There are a couple of special cases for easier typing:. * If the first pass is not a module pass, a pass manager of the first pass is; implicitly created. * For example, the following are equivalent. .. code-block:: shell. $ opt -passes='no-op-function,no-op-function' /tmp/a.ll -S; $ opt -passes='function(no",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/NewPassManager.rst:18641,adapt,adaptor,18641,interpreter/llvm-project/llvm/docs/NewPassManager.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/NewPassManager.rst,1,['adapt'],['adaptor']
Modifiability,"ysis, financial movements'; predictions and analysis, or sales forecast and product shipping; optimization. In particles physics neural networks are mainly used for; classification tasks (signal over background discrimination). A vast; majority of commonly used neural networks are multilayer perceptrons.; This implementation of multilayer perceptrons is inspired from the; `MLPfit` package, which remains one of the fastest tools for neural; networks studies. ### The MLP. The multilayer perceptron is a simple feed-forward network with the; following structure showed on the left. ![](pictures/0300008D.png). It is made of neurons characterized by a bias and weighted links in; between - let's call those links synapses. The input neurons receive; the inputs, normalize them and forward them to the first hidden layer.; Each neuron in any subsequent layer first computes a linear; combination of the outputs of the previous layer. The output of the; neuron is then function of that combination with f being linear for; output neurons or a sigmoid for hidden layers. Such a structure is very useful because of two theorems:. 1- A linear combination of `sigmoids` can approximate any continuous; function. 2- Trained with `output=1` for the signal and 0 for the background,; the approximated function of inputs `X` is the probability of signal,; knowing `X`. ### Learning Methods. The aim of all learning methods is to minimize the total error on a; set of weighted examples. The error is defined as the sum in quadrate,; divided by two, of the error on each individual output neuron. In all; methods implemented in this library, one needs to compute the first; derivative of that error with respect to the weights. Exploiting the; well-known properties of the derivative, one can express this; derivative as the product of the local partial derivative by the; weighted sum of the outputs derivatives (for a neuron) or as the; product of the input value with the local partial derivative of the; outp",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/FittingHistograms.md:71081,layers,layers,71081,documentation/users-guide/FittingHistograms.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/FittingHistograms.md,1,['layers'],['layers']
Modifiability,"yzer-config ipa``:. * ``analyzer-config ipa=none`` - All inlining is disabled. This is the only mode; available in LLVM 3.1 and earlier and in Xcode 4.3 and earlier. * ``analyzer-config ipa=basic-inlining`` - Turns on inlining for C functions, C++; static member functions, and blocks -- essentially, the calls that behave; like simple C function calls. This is essentially the mode used in; Xcode 4.4. * ``analyzer-config ipa=inlining`` - Turns on inlining when we can confidently find; the function/method body corresponding to the call. (C functions, static; functions, devirtualized C++ methods, Objective-C class methods, Objective-C; instance methods when ExprEngine is confident about the dynamic type of the; instance). * ``analyzer-config ipa=dynamic`` - Inline instance methods for which the type is; determined at runtime and we are not 100% sure that our type info is; correct. For virtual calls, inline the most plausible definition. * ``analyzer-config ipa=dynamic-bifurcate`` - Same as -analyzer-config ipa=dynamic,; but the path is split. We inline on one branch and do not inline on the; other. This mode does not drop the coverage in cases when the parent class; has code that is only exercised when some of its methods are overridden. Currently, ``-analyzer-config ipa=dynamic-bifurcate`` is the default mode. While ``-analyzer-config ipa`` determines in general how aggressively the analyzer; will try to inline functions, several additional options control which types of; functions can inlined, in an all-or-nothing way. These options use the; analyzer's configuration table, so they are all specified as follows:. ``-analyzer-config OPTION=VALUE``. c++-inlining; ------------. This option controls which C++ member functions may be inlined. ``-analyzer-config c++-inlining=[none | methods | constructors | destructors]``. Each of these modes implies that all the previous member function kinds will be; inlined as well; it doesn't make sense to inline destructors without inlin",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/developer-docs/IPA.rst:1097,config,config,1097,interpreter/llvm-project/clang/docs/analyzer/developer-docs/IPA.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/developer-docs/IPA.rst,2,['config'],['config']
Modifiability,"y| Libraries to link against. |; +----------------------+---------------------------------------------------------------------------------------------+; |H_DIRS directory | Base directories for H_FILES. |; +----------------------+---------------------------------------------------------------------------------------------+; |H_FILES h_file | Header files for which to generate bindings in pkg. |; | | Absolute filenames, or filenames relative to H_DIRS. All |; | | definitions found directly in these files will contribute |; | | to the bindings. (NOTE: This means that if ""forwarding |; | | headers"" are present, the real ""legacy"" headers must be |; | | specified as H_FILES). |; | | All header files which contribute to a given C++ namespace |; | | should be grouped into a single pkg to ensure a 1-to-1 |; | | mapping with the implementing Python class. |; +----------------------+---------------------------------------------------------------------------------------------+. Returns via PARENT_SCOPE variables::. target The CMake target used to build.; setup_py The setup.py script used to build or install pkg. Examples::. find_package(Qt5Core NO_MODULE); find_package(KF5KDcraw NO_MODULE); get_target_property(_H_DIRS KF5::KDcraw INTERFACE_INCLUDE_DIRECTORIES); get_target_property(_LINK_LIBRARIES KF5::KDcraw INTERFACE_LINK_LIBRARIES); set(_LINK_LIBRARIES KF5::KDcraw ${_LINK_LIBRARIES}); include(${KF5KDcraw_DIR}/KF5KDcrawConfigVersion.cmake). cppyy_add_bindings(; ""KDCRAW"" ""${PACKAGE_VERSION}"" ""Shaheed"" ""srhaque@theiet.org""; LANGUAGE_STANDARD ""14""; LINKDEFS ""../linkdef_overrides.h""; GENERATE_OPTIONS ""-D__PIC__;-Wno-macro-redefined""; INCLUDE_DIRS ${Qt5Core_INCLUDE_DIRS}; LINK_LIBRARIES ${_LINK_LIBRARIES}; H_DIRS ${_H_DIRS}; H_FILES ""dcrawinfocontainer.h;kdcraw.h;rawdecodingsettings.h;rawfiles.h""). cppyy_find_pips; ^^^^^^^^^^^^^^^. Return a list of available pip programs. .. _`support for exporting all`: https://cmake.org/cmake/help/latest/prop_tgt/WINDOWS_EXPORT_ALL_SYMBOLS.html;",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/cmake_interface.rst:10404,variab,variables,10404,bindings/pyroot/cppyy/cppyy/doc/source/cmake_interface.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/cmake_interface.rst,1,['variab'],['variables']
Modifiability,"zation of `TDirectory` in favor of item-getting syntax. The new recommended way to get objects from a `TFile` or any `TDirectory` in general is now via `__getitem__`:. ```python; tree = my_file[""my_tree""] # instead of my_file.my_tree; ```. This is more consistent with other Python collections (like dictionaries), makes sure that member functions can't be confused with branch names, and easily allows you to use string variables as keys. With the new dictionary-like syntax, you can also get objects with names that don't qualify as a Python variable. Here is a short demo:; ```python; import ROOT. with ROOT.TFile.Open(""my_file.root"", ""RECREATE"") as my_file:. # Populate the TFile with simple objects.; my_file.WriteObject(ROOT.std.string(""hello world""), ""my_string""); my_file.WriteObject(ROOT.vector[""int""]([1, 2, 3]), ""my vector""). print(my_file[""my_string""]) # new syntax; print(my_file.my_string) # old deprecated syntax. # With the dictionary syntax, you can also use names that don't qualify as; # a Python variable:; print(my_file[""my vector""]); # print(my_file.my vector) # the old syntax would not work here!; ```. The old pythonization with the `__getattr__` syntax still works, but emits a deprecation warning and will be removed from ROOT 6.34. ### Removal of Python 2 support. ROOT does no longer support Python 2. The minimum Python version necessary to use ROOT in a Python application is 3.8.; As a consequence, any reference to Python 2 in ROOT code was removed and certain configuration options are no longer; usable, e.g. * `root-config --python2-version`; * cmake -Dpyroot-python2. The cmake build system now looks for the standard `Python3` package and previously custom Python-related cmake variables; are now just the ones automatically produced by cmake (see https://cmake.org/cmake/help/latest/module/FindPython.html). ### More usage of the public cppyy API. Many implementation details of the ROOT pythonizations were moved from C++ functions to pure Python bindings usin",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v632/index.md:22167,variab,variable,22167,README/ReleaseNotes/v632/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v632/index.md,1,['variab'],['variable']
Modifiability,"zation`` method is an infrequently used method that is called; when the pass framework has finished calling :ref:`runOnSCC; <writing-an-llvm-pass-runOnSCC>` for every SCC in the program being compiled. .. _writing-an-llvm-pass-FunctionPass:. The ``FunctionPass`` class; --------------------------. In contrast to ``ModulePass`` subclasses, `FunctionPass; <https://llvm.org/doxygen/classllvm_1_1Pass.html>`_ subclasses do have a; predictable, local behavior that can be expected by the system. All; ``FunctionPass`` execute on each function in the program independent of all of; the other functions in the program. ``FunctionPass``\ es do not require that; they are executed in a particular order, and ``FunctionPass``\ es do not modify; external functions. To be explicit, ``FunctionPass`` subclasses are not allowed to:. #. Inspect or modify a ``Function`` other than the one currently being processed.; #. Add or remove ``Function``\ s from the current ``Module``.; #. Add or remove global variables from the current ``Module``.; #. Maintain state across invocations of :ref:`runOnFunction; <writing-an-llvm-pass-runOnFunction>` (including global data). Implementing a ``FunctionPass`` is usually straightforward (See the :ref:`Hello; World <writing-an-llvm-pass-basiccode>` pass for example).; ``FunctionPass``\ es may override three virtual methods to do their work. All; of these methods should return ``true`` if they modified the program, or; ``false`` if they didn't. .. _writing-an-llvm-pass-doInitialization-mod:. The ``doInitialization(Module &)`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual bool doInitialization(Module &M);. The ``doInitialization`` method is allowed to do most of the things that; ``FunctionPass``\ es are not allowed to do. They can add and remove functions,; get pointers to functions, etc. The ``doInitialization`` method is designed to; do simple initialization type of stuff that does not depend on the functions; being processe",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:17819,variab,variables,17819,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,1,['variab'],['variables']
Modifiability,"ze a ``T __strong *`` with a ``U __strong *``. For purposes of overload resolution, an implicit conversion sequence requiring; a pass-by-writeback is always worse than an implicit conversion sequence not; requiring a pass-by-writeback. The pass-by-writeback is ill-formed if the argument expression does not have a; legal form:. * ``&var``, where ``var`` is a scalar variable of automatic storage duration; with retainable object pointer type; * a conditional expression where the second and third operands are both legal; forms; * a cast whose operand is a legal form; * a null pointer constant. .. admonition:: Rationale. The restriction in the form of the argument serves two purposes. First, it; makes it impossible to pass the address of an array to the argument, which; serves to protect against an otherwise serious risk of mis-inferring an; ""array"" argument as an out-parameter. Second, it makes it much less likely; that the user will see confusing aliasing problems due to the implementation,; below, where their store to the writeback temporary is not immediately seen; in the original argument variable. A pass-by-writeback is evaluated as follows:. #. The argument is evaluated to yield a pointer ``p`` of type ``U oq *``.; #. If ``p`` is a null pointer, then a null pointer is passed as the argument,; and no further work is required for the pass-by-writeback.; #. Otherwise, a temporary of type ``T __autoreleasing`` is created and; initialized to a null pointer.; #. If the parameter is not an Objective-C method parameter marked ``out``,; then ``*p`` is read, and the result is written into the temporary with; primitive semantics.; #. The address of the temporary is passed as the argument to the actual call.; #. After the call completes, the temporary is loaded with primitive; semantics, and that value is assigned into ``*p``. .. admonition:: Rationale. This is all admittedly convoluted. In an ideal world, we would see that a; local variable is being passed to an out-parameter",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst:49904,variab,variable,49904,interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,1,['variab'],['variable']
Modifiability,"ze"" case, but; the stack size is too large to encode in the compact unwind encoding. Instead; it requires that the function contains ""``subl $nnnnnn, %esp``"" in its; prolog. The compact encoding contains the offset to the ``$nnnnnn`` value in; the function in bits 9-12 (mask: ``0x00001C00``). .. _Late Machine Code Optimizations:. Late Machine Code Optimizations; -------------------------------. .. note::. To Be Written. .. _Code Emission:. Code Emission; -------------. The code emission step of code generation is responsible for lowering from the; code generator abstractions (like `MachineFunction`_, `MachineInstr`_, etc) down; to the abstractions used by the MC layer (`MCInst`_, `MCStreamer`_, etc). This; is done with a combination of several different classes: the (misnamed); target-independent AsmPrinter class, target-specific subclasses of AsmPrinter; (such as SparcAsmPrinter), and the TargetLoweringObjectFile class. Since the MC layer works at the level of abstraction of object files, it doesn't; have a notion of functions, global variables etc. Instead, it thinks about; labels, directives, and instructions. A key class used at this time is the; MCStreamer class. This is an abstract API that is implemented in different ways; (e.g. to output a .s file, output an ELF .o file, etc) that is effectively an; ""assembler API"". MCStreamer has one method per directive, such as EmitLabel,; EmitSymbolAttribute, switchSection, etc, which directly correspond to assembly; level directives. If you are interested in implementing a code generator for a target, there are; three important things that you have to implement for your target:. #. First, you need a subclass of AsmPrinter for your target. This class; implements the general lowering process converting MachineFunction's into MC; label constructs. The AsmPrinter base class provides a number of useful; methods and routines, and also allows you to override the lowering process in; some important ways. You should get much of ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:75456,variab,variables,75456,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst,1,['variab'],['variables']
Modifiability,"ze`.; Higher values lead to more accurate measurements but lengthen the benchmark. .. option:: --loop-body-size=<Preferred loop body size>. Only effective for `-repetition-mode=[loop|min]`.; Instead of looping over the snippet directly, first duplicate it so that the; loop body contains at least this many instructions. This potentially results; in loop body being cached in the CPU Op Cache / Loop Cache, which allows to; which may have higher throughput than the CPU decoders. .. option:: --max-configs-per-opcode=<value>. Specify the maximum configurations that can be generated for each opcode.; By default this is `1`, meaning that we assume that a single measurement is; enough to characterize an opcode. This might not be true of all instructions:; for example, the performance characteristics of the LEA instruction on X86; depends on the value of assigned registers and immediates. Setting a value of; `-max-configs-per-opcode` larger than `1` allows `llvm-exegesis` to explore; more configurations to discover if some register or immediate assignments; lead to different performance characteristics. .. option:: --benchmarks-file=</path/to/file>. File to read (`analysis` mode) or write (`latency`/`uops`/`inverse_throughput`; modes) benchmark results. ""-"" uses stdin/stdout. .. option:: --analysis-clusters-output-file=</path/to/file>. If provided, write the analysis clusters as CSV to this file. ""-"" prints to; stdout. By default, this analysis is not run. .. option:: --analysis-inconsistencies-output-file=</path/to/file>. If non-empty, write inconsistencies found during analysis to this file. `-`; prints to stdout. By default, this analysis is not run. .. option:: --analysis-filter=[all|reg-only|mem-only]. By default, all benchmark results are analysed, but sometimes it may be useful; to only look at those that to not involve memory, or vice versa. This option; allows to either keep all benchmarks, or filter out (ignore) either all the; ones that do involve memory (involve in",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-exegesis.rst:14277,config,configs-per-opcode,14277,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-exegesis.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-exegesis.rst,2,['config'],"['configs-per-opcode', 'configurations']"
Modifiability,"zer, ``inttoptr`` and ``ptrtoint`` for; non-integral types are analogous to ones on integral types with one; key exception: the optimizer may not, in general, insert new dynamic; occurrences of such casts. If a new cast is inserted, the optimizer would; need to either ensure that a) all possible values are valid, or b); appropriate fencing is inserted. Since the appropriate fencing is; implementation defined, the optimizer can't do the latter. The former is; challenging as many commonly expected properties, such as; ``ptrtoint(v)-ptrtoint(v) == 0``, don't hold for non-integral types.; Similar restrictions apply to intrinsics that might examine the pointer bits,; such as :ref:`llvm.ptrmask<int_ptrmask>`. . The alignment information provided by the frontend for a non-integral pointer; (typically using attributes or metadata) must be valid for every possible ; representation of the pointer. .. _globalvars:. Global Variables; ----------------. Global variables define regions of memory allocated at compilation time; instead of run-time. Global variable definitions must be initialized. Global variables in other translation units can also be declared, in which; case they don't have an initializer. Global variables can optionally specify a :ref:`linkage type <linkage>`. Either global variable definitions or declarations may have an explicit section; to be placed in and may have an optional explicit alignment specified. If there; is a mismatch between the explicit or inferred section information for the; variable declaration and its definition the resulting behavior is undefined. A variable may be defined as a global ``constant``, which indicates that; the contents of the variable will **never** be modified (enabling better; optimization, allowing the global data to be placed in the read-only; section of an executable, etc). Note that variables that need runtime; initialization cannot be marked ``constant`` as there is a store to the; variable. LLVM explicitly allows *declar",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:30394,variab,variables,30394,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['variab'],['variables']
Modifiability,"zer-list; Clang 3.7. 1632; CD5; Lambda capture in member initializers; Unknown. 1633; CD4; Copy-initialization in member initialization; Unknown. 1634; drafting; Temporary storage duration; Not resolved. 1635; drafting; How similar are template default arguments to function default arguments?; Not resolved. 1636; CD5; Bits required for negative enumerator values; Unknown. 1637; NAD; Recursion in constexpr template default constructor; Unknown. 1638; CD4; Declaring an explicit specialization of a scoped enumeration; Clang 3.1. 1639; CD4; exception-specifications and pointer/pointer-to-member expressions; Unknown. 1640; CD5; Array of abstract instance of class template; Unknown. 1641; NAD; Assignment in member initializer; Unknown. 1642; DRWP; Missing requirements for prvalue operands; Unknown. 1643; NAD; Default arguments for template parameter packs; Unknown. 1644; NAD; Equivalent exception-specifications in function template declarations; Unknown. 1645; CD4; Identical inheriting constructors via default arguments; Clang 3.9. 1646; CD5; decltype-specifiers, abstract classes, and deduction failure; Unknown. 1647; drafting; Type agreement of non-type template arguments in partial specializations; Not resolved. 1648; C++14; thread_local vs block extern declarations; Unknown. 1649; C++14; Error in the syntax of mem-initializer-list; Unknown. 1650; NAD; Class prvalues in reference initialization; Unknown. 1651; NAD; Lifetime extension of temporary via reference to subobject; Unknown. 1652; CD4; Object addresses in constexpr expressions; Clang 3.6. 1653; CD4; Removing deprecated increment of bool; Clang 4 (C++17 onwards). 1654; dup; Literal types and constexpr defaulted constructors; Unknown. 1655; drafting; Line endings in raw string literals; Not resolved. 1656; CD6; Encoding of numerically-escaped characters; Unknown. 1657; CD4; Attributes for namespaces and enumerators; Unknown. 1658; C++14; Deleted default constructor for abstract class via destructor; Clang 5. 1659; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/cxx_dr_status.html:111136,inherit,inheriting,111136,interpreter/llvm-project/clang/www/cxx_dr_status.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/cxx_dr_status.html,2,['inherit'],['inheriting']
Modifiability,"zerOptions` class.; For example to select `Minuit2` instead of `Minuit` for fitting an histogram do:. ``` {.cpp}; ROOT::Math::MinimizerOptions::SetDefaultMinimizer(""Minuit2"");; // fit the histogram histo with the gaussian pre-defined function; histo->Fit(""gaus"");; ```. In the following we will give some brief description of the minimization packages.; The packages all implement the `ROOT::Math::Minimizer` interface which can be use for; finding the minimum of a multi-dimensional function.; The interface is documented in the Mathematical Library Chapter. In addition packages like Minuit or Minuit2 provide their own interfaces. ## MINUIT (Old TMInuit Version). This package was originally written in FORTRAN by Fred James and part; of `PACKLIB` (patch D506). It has been converted to a C++ class by; René Brun. The current implementation in C++ is a straightforward; conversion of the original FORTRAN version. The main changes are:. - The variables in the various `Minuit` labeled common blocks have; been changed to the **`TMinuit`** class data members. - The internal arrays with a maximum dimension depending on the; maximum number of parameters are now data members' arrays with a; dynamic dimension such that one can fit very large problems by; simply initializing the **`TMinuit`** constructor with the maximum; number of parameters. - The include file `Minuit.h` has been commented as much as possible; using existing comments in the code or the printed documentation. - The original `Minuit` subroutines are now member functions. - Constructors and destructor have been added. - Instead of passing the `FCN` function in the argument list, the; addresses of this function is stored as pointer in the data; members of the class. This is by far more elegant and flexible in; an interactive environment. The member function `SetFCN` can be; used to define this pointer. - The ROOT static function `Printf` is provided to replace all; format statements and to print on currently defined out",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/FittingHistograms.md:53268,variab,variables,53268,documentation/users-guide/FittingHistograms.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/FittingHistograms.md,1,['variab'],['variables']
Modifiability,"zonk(); br label %exit; falsebr:; %fval = add i32 %bar, 2; call @llvm.dbg.value(metadata i32 %fval, metadata !1, metadata !2); %g2 = call i32 @gazonk(); br label %exit; exit:; %merge = phi [ %tval, %truebr ], [ %fval, %falsebr ]; %g = phi [ %g1, %truebr ], [ %g2, %falsebr ]; call @llvm.dbg.value(metadata i32 %merge, metadata !1, metadata !2); call @llvm.dbg.value(metadata i32 %g, metadata !3, metadata !2); %plusten = add i32 %merge, 10; %toret = add i32 %plusten, %g; call @llvm.dbg.value(metadata i32 %toret, metadata !1, metadata !2); ret i32 %toret; }. Containing two source-level variables in ``!1`` and ``!3``. The function could,; perhaps, be optimized into the following code:. .. code-block:: llvm. define i32 @foo(i32 %bar, i1 %cond) {; entry:; %g = call i32 @gazonk(); %addoper = select i1 %cond, i32 11, i32 12; %plusten = add i32 %bar, %addoper; %toret = add i32 %plusten, %g; ret i32 %toret; }. What ``llvm.dbg.value`` intrinsics should be placed to represent the original variable; locations in this code? Unfortunately the second, third and fourth; dbg.values for ``!1`` in the source function have had their operands; (%tval, %fval, %merge) optimized out. Assuming we cannot recover them, we; might consider this placement of dbg.values:. .. code-block:: llvm. define i32 @foo(i32 %bar, i1 %cond) {; entry:; call @llvm.dbg.value(metadata i32 0, metadata !1, metadata !2); %g = call i32 @gazonk(); call @llvm.dbg.value(metadata i32 %g, metadata !3, metadata !2); %addoper = select i1 %cond, i32 11, i32 12; %plusten = add i32 %bar, %addoper; %toret = add i32 %plusten, %g; call @llvm.dbg.value(metadata i32 %toret, metadata !1, metadata !2); ret i32 %toret; }. However, this will cause ``!3`` to have the return value of ``@gazonk()`` at; the same time as ``!1`` has the constant value zero -- a pair of assignments; that never occurred in the unoptimized program. To avoid this, we must terminate; the range that ``!1`` has the constant value assignment by inserting a poison; dbg",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:21207,variab,variable,21207,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,1,['variab'],['variable']
Modifiability,"{#; sphinxdoc/layout.html; ~~~~~~~~~~~~~~~~~~~~~. Sphinx layout template for the sphinxdoc theme. :copyright: Copyright 2007-2010 by the Sphinx team, see AUTHORS.; :license: BSD, see LICENSE for details.; #}; {% extends ""basic/layout.html"" %}. {% block relbar1 %}. {{ super() }}; {% endblock %}. {# put the sidebar before the body #}; {% block sidebar1 %}{{ sidebar() }}{% endblock %}; {% block sidebar2 %}{% endblock %}; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/_themes/llvm-theme/layout.html:212,extend,extends,212,interpreter/llvm-project/llvm/docs/_themes/llvm-theme/layout.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/_themes/llvm-theme/layout.html,2,['extend'],['extends']
Modifiability,"{% extends ""!layout.html"" %}. {% block extrahead %}. {% endblock %}. {% block rootrellink %}; LLVM Home | ; Documentation»; {% endblock %}; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/_templates/layout.html:3,extend,extends,3,interpreter/llvm-project/llvm/docs/_templates/layout.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/_templates/layout.html,2,['extend'],['extends']
Modifiability,"{; ...; }; };. Refactoring Action Rules; ------------------------. An individual refactoring action is responsible for creating the set of; grouped refactoring action rules that represent one refactoring operation.; Although the rules in one action may have a number of different implementations,; they should strive to produce a similar result. It should be easy for users to; identify which refactoring action produced the result regardless of which; refactoring action rule was used. The distinction between actions and rules enables the creation of actions; that define a set of different rules that produce similar results. For example,; the ""add missing switch cases"" refactoring operation typically adds missing; cases to one switch at a time. However, it could be useful to have a; refactoring that works on all switches that operate on a particular enum, as; one could then automatically update all of them after adding a new enum; constant. To achieve that, we can create two different rules that will use one; ``clang-refactor`` subcommand. The first rule will describe a local operation; that's initiated when the user selects a single switch. The second rule will; describe a global operation that works across translation units and is initiated; when the user provides the name of the enum to clang-refactor (or the user could; select the enum declaration instead). The clang-refactor tool will then analyze; the selection and other options passed to the refactoring action, and will pick; the most appropriate rule for the given selection and other options. Rule Types; ^^^^^^^^^^. Clang's refactoring engine supports several different refactoring rules:. - ``SourceChangeRefactoringRule`` produces source replacements that are applied; to the source files. Subclasses that choose to implement this rule have to; implement the ``createSourceReplacements`` member function. This type of; rule is typically used to implement local refactorings that transform the; source in one translatio",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/RefactoringEngine.rst:3098,refactor,refactor,3098,interpreter/llvm-project/clang/docs/RefactoringEngine.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/RefactoringEngine.rst,1,['refactor'],['refactor']
Modifiability,"{; //_Block_byref_release(src->captured_i);; _Block_object_dispose(src->captured_i, BLOCK_FIELD_IS_BYREF | BLOCK_BYREF_CALLER);; }. static struct __block_descriptor_5 {; unsigned long int reserved;; unsigned long int Block_size;; void (*copy_helper)(struct __block_literal_5 *dst, struct __block_literal_5 *src);; void (*dispose_helper)(struct __block_literal_5 *);; } __block_descriptor_5 = { 0, sizeof(struct __block_literal_5) __block_copy_5, __block_dispose_5 };. and:. .. code-block:: c. struct _block_byref_i i = {( .isa=NULL, .forwarding=&i, .flags=0, .size=sizeof(struct _block_byref_i), .captured_i=2 )};; struct __block_literal_5 _block_literal = {; &_NSConcreteStackBlock,; (1<<25)|(1<<29), <uninitialized>,; __block_invoke_5,; &__block_descriptor_5,; &i,; };. Importing ``__attribute__((NSObject))`` ``__block`` variables; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. A ``__block`` variable that is also marked ``__attribute__((NSObject))`` should; have ``byref_keep`` and ``byref_dispose`` helper functions that use; ``_Block_object_assign`` and ``_Block_object_dispose``. ``__block`` escapes; ^^^^^^^^^^^^^^^^^^^. Because ``Blocks`` referencing ``__block`` variables may have ``Block_copy()``; performed upon them the underlying storage for the variables may move to the; heap. In Objective-C Garbage Collection Only compilation environments the heap; used is the garbage collected one and no further action is required. Otherwise; the compiler must issue a call to potentially release any heap storage for; ``__block`` variables at all escapes or terminations of their scope. The call; should be:. .. code-block:: c. _Block_object_dispose(&_block_byref_foo, BLOCK_FIELD_IS_BYREF);. Nesting; ^^^^^^^. ``Blocks`` may contain ``Block`` literal expressions. Any variables used within; inner blocks are imported into all enclosing ``Block`` scopes even if the; variables are not used. This includes ``const`` imports as well as ``__block``; variables. Objective C Extensio",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Block-ABI-Apple.rst:17506,variab,variable,17506,interpreter/llvm-project/clang/docs/Block-ABI-Apple.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Block-ABI-Apple.rst,1,['variab'],['variable']
Modifiability,"{target=thumbv6m-none-unknown-eabi}; # then this multilib variant will be considered a match.; Flags: [--target=thumbv6m-none-unknown-eabi]. # Similarly, a multilib variant targeting Arm v7-M with an FPU (floating; # point unit).; - Dir: thumb/v7-m; # Here, the flags generated by Clang must be a superset of; # {--target=thumbv7m-none-eabi, -mfpu=fpv4-sp-d16} for this multilib variant; # to be a match.; Flags: [--target=thumbv7m-none-eabi, -mfpu=fpv4-sp-d16]. # The second section of the file is a list of regular expressions that are; # used to map from flags generated from command line options to custom flags.; # This is optional.; # Each regular expression must match a whole flag string.; # Flags in the ""Flags"" list will be added if any flag generated from command; # line options matches the regular expression.; Mappings:. # Set a ""--target=thumbv7m-none-eabi"" flag if the regular expression matches; # any of the flags generated from the command line options.; # Match is a POSIX extended regular expression string.; - Match: --target=thumbv([7-9]|[1-9][0-9]+).*; # Flags is a list of one or more strings.; Flags: [--target=thumbv7m-none-eabi]. Design principles; =================. Stable interface; ----------------. ``multilib.yaml`` and ``-print-multi-flags-experimental`` are new; interfaces to Clang. In order for them to be usable over time and across LLVM; versions their interfaces should be stable.; The new multilib system will be considered experimental in LLVM 17, but in; LLVM 18 it will be stable. In particular this is important to which multilib; selection flags Clang generates from command line options. Once a flag is; generated by a released version of Clang it may be used in ``multilib.yaml``; files that exist independently of the LLVM release cycle, and therefore; ceasing to generate the flag would be a breaking change and should be; avoided. However, an exception is the normalization of ``-march``.; ``-march`` for Arm architectures contains a list of enable",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Multilib.rst:9066,extend,extended,9066,interpreter/llvm-project/clang/docs/Multilib.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Multilib.rst,1,['extend'],['extended']
Modifiability,"{};; void y(X &x) { x; X z; }; class Y { friend class X; };; class Z : public virtual X {};. Example matches class Derived; (matcher = cxxRecordDecl(hasAnyBase(hasType(cxxRecordDecl(hasName(""Base"")))))); class Base {};; class Derived : Base {};. Usable as: Matcher<Expr>, Matcher<FriendDecl>, Matcher<ValueDecl>,; Matcher<CXXBaseSpecifier>. Matcher<ValueDecl>hasTypeMatcher<QualType> InnerMatcher; Matches if the expression's or declaration's type matches a type; matcher. Example matches x (matcher = expr(hasType(cxxRecordDecl(hasName(""X""))))); and z (matcher = varDecl(hasType(cxxRecordDecl(hasName(""X""))))); and U (matcher = typedefDecl(hasType(asString(""int""))); and friend class X (matcher = friendDecl(hasType(""X"")); and public virtual X (matcher = cxxBaseSpecifier(hasType(; asString(""class X""))); class X {};; void y(X &x) { x; X z; }; typedef int U;; class Y { friend class X; };; class Z : public virtual X {};. Matcher<VarDecl>hasInitializerMatcher<Expr> InnerMatcher; Matches a variable declaration that has an initializer expression; that matches the given matcher. Example matches x (matcher = varDecl(hasInitializer(callExpr()))); bool y() { return true; }; bool x = y();. Matcher<VariableArrayType>hasSizeExprMatcher<Expr> InnerMatcher; Matches VariableArrayType nodes that have a specific size; expression. Given; void f(int b) {; int a[b];; }; variableArrayType(hasSizeExpr(ignoringImpCasts(declRefExpr(to(; varDecl(hasName(""b""))))))); matches ""int a[b]"". Matcher<WhileStmt>hasBodyMatcher<Stmt> InnerMatcher; Matches a 'for', 'while', 'while' statement or a function or coroutine; definition that has a given body. Note that in case of functions or; coroutines this matcher only matches the definition itself and not the; other declarations of the same function or coroutine. Given; for (;;) {}; forStmt(hasBody(compoundStmt())); matches 'for (;;) {}'; with compoundStmt(); matching '{}'. Given; void f();; void f() {}; functionDecl(hasBody(compoundStmt())); matches 'void f() {}'; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LibASTMatchersReference.html:253700,variab,variable,253700,interpreter/llvm-project/clang/docs/LibASTMatchersReference.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LibASTMatchersReference.html,2,['variab'],['variable']
Modifiability,"| 0x100 |; +--------------------------------------+-------+; | DW_APPLE_PROPERTY_weak | 0x200 |; +--------------------------------------+-------+; | DW_APPLE_PROPERTY_strong | 0x400 |; +--------------------------------------+-------+; | DW_APPLE_PROPERTY_unsafe_unretained | 0x800 |; +--------------------------------------+-------+; | DW_APPLE_PROPERTY_nullability | 0x1000|; +--------------------------------------+-------+; | DW_APPLE_PROPERTY_null_resettable | 0x2000|; +--------------------------------------+-------+; | DW_APPLE_PROPERTY_class | 0x4000|; +--------------------------------------+-------+. Name Accelerator Tables; -----------------------. Introduction; ^^^^^^^^^^^^. The ""``.debug_pubnames``"" and ""``.debug_pubtypes``"" formats are not what a; debugger needs. The ""``pub``"" in the section name indicates that the entries; in the table are publicly visible names only. This means no static or hidden; functions show up in the ""``.debug_pubnames``"". No static variables or private; class variables are in the ""``.debug_pubtypes``"". Many compilers add different; things to these tables, so we can't rely upon the contents between gcc, icc, or; clang. The typical query given by users tends not to match up with the contents of; these tables. For example, the DWARF spec states that ""In the case of the name; of a function member or static data member of a C++ structure, class or union,; the name presented in the ""``.debug_pubnames``"" section is not the simple name; given by the ``DW_AT_name attribute`` of the referenced debugging information; entry, but rather the fully qualified name of the data or function member.""; So the only names in these tables for complex C++ entries is a fully; qualified name. Debugger users tend not to enter their search strings as; ""``a::b::c(int,const Foo&) const``"", but rather as ""``c``"", ""``b::c``"" , or; ""``a::b::c``"". So the name entered in the name table must be demangled in; order to chop it up appropriately and additional names must be",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:56791,variab,variables,56791,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,2,['variab'],['variables']
Modifiability,"| U <number> -> linear with uval modifier; | ls <pos> -> runtime linear; | Rs <pos> -> runtime linear with ref modifier; | Ls <pos> -> runtime linear with val modifier; | Us <pos> -> runtime linear with uval modifier; | u -> uniform. <scalar_name>:= name of the scalar function. <vector_redirection>:= optional, custom name of the vector function. ``preallocated(<ty>)``; This attribute is required on calls to ``llvm.call.preallocated.arg``; and cannot be used on any other call. See; :ref:`llvm.call.preallocated.arg<int_call_preallocated_arg>` for more; details. .. _glattrs:. Global Attributes; -----------------. Attributes may be set to communicate additional information about a global variable.; Unlike :ref:`function attributes <fnattrs>`, attributes on a global variable; are grouped into a single :ref:`attribute group <attrgrp>`. ``no_sanitize_address``; This attribute indicates that the global variable should not have; AddressSanitizer instrumentation applied to it, because it was annotated; with `__attribute__((no_sanitize(""address"")))`,; `__attribute__((disable_sanitizer_instrumentation))`, or included in the; `-fsanitize-ignorelist` file.; ``no_sanitize_hwaddress``; This attribute indicates that the global variable should not have; HWAddressSanitizer instrumentation applied to it, because it was annotated; with `__attribute__((no_sanitize(""hwaddress"")))`,; `__attribute__((disable_sanitizer_instrumentation))`, or included in the; `-fsanitize-ignorelist` file.; ``sanitize_memtag``; This attribute indicates that the global variable should have AArch64 memory; tags (MTE) instrumentation applied to it. This attribute causes the; suppression of certain optimisations, like GlobalMerge, as well as ensuring; extra directives are emitted in the assembly and extra bits of metadata are; placed in the object file so that the linker can ensure the accesses are; protected by MTE. This attribute is added by clang when; `-fsanitize=memtag-globals` is provided, as long as the glob",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:115207,variab,variable,115207,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['variab'],['variable']
Modifiability,"}. static struct __block_descriptor_10 {; unsigned long int reserved;; unsigned long int Block_size;; void (*copy_helper)(struct __block_literal_10 *dst, struct __block_literal_10 *src);; void (*dispose_helper)(struct __block_literal_10 *);; } __block_descriptor_10 = { 0, sizeof(struct __block_literal_10), __block_copy_10, __block_dispose_10 };. and the code would be:. .. code-block:: c++. {; FOO foo;; comp_ctor(&foo); // default constructor; struct __block_literal_10 _block_literal = {; &_NSConcreteStackBlock,; (1<<25)|(1<<26)|(1<<29), <uninitialized>,; __block_invoke_10,; &__block_descriptor_10,; };; comp_ctor(&_block_literal->foo, &foo); // const copy into stack version; struct __block_literal_10 &block = &_block_literal; // assign literal to block variable; block->invoke(block); // invoke block; comp_dtor(&_block_literal->foo); // destroy stack version of const block copy; comp_dtor(&foo); // destroy original version; }. C++ objects stored in ``__block`` storage start out on the stack in a; ``block_byref`` data structure as do other variables. Such objects (if not; ``const`` objects) must support a regular copy constructor. The ``block_byref``; data structure will have copy and destroy helper routines synthesized by the; compiler. The copy helper will have code created to perform the copy; constructor based on the initial stack ``block_byref`` data structure, and will; also set the (1<<26) bit in addition to the (1<<25) bit. The destroy helper; will have code to do the destructor on the object stored within the supplied; ``block_byref`` heap data structure. For example,. .. code-block:: c++. __block FOO blockStorageFoo;. requires the normal constructor for the embedded ``blockStorageFoo`` object:. .. code-block:: c++. FOO_ctor(& _block_byref_blockStorageFoo->blockStorageFoo);. and at scope termination the destructor:. .. code-block:: c++. FOO_dtor(& _block_byref_blockStorageFoo->blockStorageFoo);. Note that the forwarding indirection is *NOT* used. The compiler w",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Block-ABI-Apple.rst:26048,variab,variables,26048,interpreter/llvm-project/clang/docs/Block-ABI-Apple.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Block-ABI-Apple.rst,1,['variab'],['variables']
Modifiability,"}. void foo(bool b); {; if (b); {; baz(2);; }; else; {; baz(5);; }; }. void bar() { foo(true); }; } // namespace N. * ``BS_WebKit`` (in configuration: ``WebKit``); Like ``Attach``, but break before functions. .. code-block:: c++. namespace N {; enum E {; E1,; E2,; };. class C {; public:; C();; };. bool baz(int i); {; try {; do {; switch (i) {; case 1: {; foobar();; break;; }; default: {; break;; }; }; } while (--i);; return true;; } catch (...) {; handleError();; return false;; }; }. void foo(bool b); {; if (b) {; baz(2);; } else {; baz(5);; }; }. void bar() { foo(true); }; } // namespace N. * ``BS_Custom`` (in configuration: ``Custom``); Configure each individual brace in ``BraceWrapping``. .. _BreakBeforeConceptDeclarations:. **BreakBeforeConceptDeclarations** (``BreakBeforeConceptDeclarationsStyle``) :versionbadge:`clang-format 12` :ref:`¶ <BreakBeforeConceptDeclarations>`; The concept declaration style to use. Possible values:. * ``BBCDS_Never`` (in configuration: ``Never``); Keep the template declaration line together with ``concept``. .. code-block:: c++. template <typename T> concept C = ...;. * ``BBCDS_Allowed`` (in configuration: ``Allowed``); Breaking between template declaration and ``concept`` is allowed. The; actual behavior depends on the content and line breaking rules and; penalties. * ``BBCDS_Always`` (in configuration: ``Always``); Always break before ``concept``, putting it in the line after the; template declaration. .. code-block:: c++. template <typename T>; concept C = ...;. .. _BreakBeforeInlineASMColon:. **BreakBeforeInlineASMColon** (``BreakBeforeInlineASMColonStyle``) :versionbadge:`clang-format 16` :ref:`¶ <BreakBeforeInlineASMColon>`; The inline ASM colon style to use. Possible values:. * ``BBIAS_Never`` (in configuration: ``Never``); No break before inline ASM colon. .. code-block:: c++. asm volatile(""string"", : : val);. * ``BBIAS_OnlyMultiline`` (in configuration: ``OnlyMultiline``); Break before inline ASM colon if the line length is l",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst:52240,config,configuration,52240,interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,1,['config'],['configuration']
Modifiability,"}; ${_CLAD_LIBRARY_PATH}/${CMAKE_STATIC_LIBRARY_PREFIX}cladDifferentiator${CMAKE_STATIC_LIBRARY_SUFFIX}; ); endif(). if(APPLE); set(_clad_extra_cmake_args -DCMAKE_OSX_SYSROOT=${CMAKE_OSX_SYSROOT}); endif(). if (CMAKE_CXX_STANDARD); list(APPEND _clad_extra_cmake_args -DCMAKE_CXX_STANDARD=${CMAKE_CXX_STANDARD}); endif(CMAKE_CXX_STANDARD). if (Clang_DIR); list(APPEND _clad_extra_cmake_args -DClang_DIR=${Clang_DIR} -DClang_CONFIG_EXTRA_PATH_HINTS=${Clang_Config_ExtraPathHints}); endif(Clang_DIR). if (LLVM_FORCE_USE_OLD_TOOLCHAIN); list(APPEND _clad_extra_cmake_args -DLLVM_FORCE_USE_OLD_TOOLCHAIN=${LLVM_FORCE_USE_OLD_TOOLCHAIN}); endif(LLVM_FORCE_USE_OLD_TOOLCHAIN). list(APPEND _clad_extra_cmake_args -DCLAD_BUILD_STATIC_ONLY=ON). # Wrap download, configure and build steps in a script to log output; set(_clad_extra_settings; LOG_DOWNLOAD ON; LOG_CONFIGURE ON; LOG_BUILD ON; LOG_INSTALL ON; LOG_OUTPUT_ON_FAILURE ON; ). # If the CLAD_SOURCE_DIR variable is defined in the CMake configuration, we're; # skipping the download of the repository and use the passed directory.; if (DEFINED CLAD_SOURCE_DIR); list(APPEND _clad_extra_settings DOWNLOAD_COMMAND """"); list(APPEND _clad_extra_settings SOURCE_DIR ${CLAD_SOURCE_DIR}); endif(). #list(APPEND _clad_patches_list ""patch1.patch"" ""patch2.patch""); #set(_clad_patch_command; # ${CMAKE_COMMAND} -E copy_directory; # ${CMAKE_SOURCE_DIR}/interpreter/cling/tools/plugins/clad/patches <SOURCE_DIR>; # && git checkout <SOURCE_DIR>; # && git apply --ignore-space-change --ignore-whitespace ${_clad_patches_list}; # ). ExternalProject_Add(; clad; GIT_REPOSITORY https://github.com/vgvassilev/clad.git; GIT_TAG v1.7; UPDATE_COMMAND """"; PATCH_COMMAND ${_clad_patch_command}; CMAKE_ARGS -G ${CMAKE_GENERATOR}; -DCMAKE_BUILD_TYPE=${CMAKE_BUILD_TYPE}; -DCMAKE_C_COMPILER=${CMAKE_C_COMPILER}; -DCMAKE_C_FLAGS=${CMAKE_C_FLAGS}; -DCMAKE_CXX_COMPILER=${CMAKE_CXX_COMPILER}; -DCMAKE_CXX_FLAGS=${CLAD_CXX_FLAGS}; -DCMAKE_INSTALL_PREFIX=${clad_install_dir}/plugins; -D",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/plugins/clad/CMakeLists.txt:2349,variab,variable,2349,interpreter/cling/tools/plugins/clad/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/plugins/clad/CMakeLists.txt,2,"['config', 'variab']","['configuration', 'variable']"
Modifiability,"}][f61]. ## Toy Monte Carlo Experiments ##. Let us look at a simple example of a toy experiment comparing two; methods to fit a function to a histogram, the $\chi^{2}$. method and a method called ""binned log-likelihood fit"", both available in ROOT. As a very simple yet powerful quantity to check the quality of the fit; results, we construct for each pseudo-data set the so-called ""pull"", the; difference of the estimated and the true value of a parameter,; normalised to the estimated error on the parameter,; $\frac{(p_{estim} - p_{true})}{\sigma_{p}}$. If everything is OK, the; distribution of the pull values is a standard normal distribution, i.e.; a Gaussian distribution centred around zero with a standard deviation of one. The macro performs a rather big number of toy experiments, where a; histogram is repeatedly filled with Gaussian distributed numbers,; representing the pseudo-data in this example. Each time, a fit is; performed according to the selected method, and the pull is calculated; and filled into a histogram. Here is the code:. ``` {.cpp .numberLines}; @ROOT_INCLUDE_FILE macros/macro9.C; ```. Your present knowledge of ROOT should be enough to understand all the; technicalities behind the macro. Note that the variable `pull` in line; *61* is different from the definition above: instead of the parameter; error on `mean`, the fitted standard deviation of the distribution; divided by the square root of the number of entries,; `sig/sqrt(n_tot_entries)`, is used. - What method exhibits the better performance with the default; parameters ?. - What happens if you increase the number of entries per histogram by; a factor of ten ? Why ?. The answers to these questions are well beyond the scope of this guide.; Basically all books about statistical methods provide a complete; treatment of the aforementioned topics. [^5]: ""Monte Carlo"" simulation means that random numbers play a role here; which is as crucial as in games of pure chance in the Casino of Monte Carlo.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/primer/functions_and_parameter_estimation.md:5244,variab,variable,5244,documentation/primer/functions_and_parameter_estimation.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/primer/functions_and_parameter_estimation.md,1,['variab'],['variable']
Modifiability,"~~~{.cpp}; void RemoveNode(TGeoNode* node); TGeoNode*ReplaceNode(TGeoNode* nodeorig, TGeoShape* newshape = 0,; TGeoMatrix* newpos = 0, TGeoMedium* newmed = 0); ~~~. The last method allows replacing an existing daughter of a volume with; another one. Providing only the node to be replaced will just create a; new volume for the node but having exactly the same parameters as the; old one. This helps in case of divisions for decoupling a node from the; logical hierarchy so getting new content/properties. For non-divided; volumes, one can change the shape and/or the position of the daughter. \anchor GP01bd; #### Virtual Containers and Assemblies of Volumes. Virtual containers are volumes that do not represent real objects, but; they are needed for grouping and positioning together other volumes.; Such grouping helps not only geometry creation, but also optimizes; tracking performance; therefore, it is highly recommended. Virtual; volumes need to inherit material/medium properties from the volume they; are placed into in order to be ""invisible"" at tracking time. Let us suppose that we need to group together two volumes `A` and `B`; into a structure and position this into several other volumes `D,E,` and; `F`. What we need to do is to create a virtual container volume `C`; holding `A` and `B`, then position `C` in the other volumes. Note that `C` is a volume having a determined medium. Since it is not a; real volume, we need to manually set its medium the same as that of; `D,E` or `F` in order to make it ""invisible"" (same physics properties).; In other words, the limitation in proceeding this way is that `D,E,` and; `F` must point to the same medium. If this was not the case, we would; have to define different virtual volumes for each placement: `C`, `C`'; and `C`\"", having the same shape but different media matching the; corresponding containers. This might not happen so often, but when it; does, it forces the creation of several extra virtual volumes. Other; limitation co",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:30381,inherit,inherit,30381,geom/geom/doc/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md,1,['inherit'],['inherit']
Modifiability,"~~~~~~~; A *link-declaration* specifies a library or framework against which a program should be linked if the enclosing module is imported in any translation unit in that program. .. parsed-literal::. *link-declaration*:; ``link`` ``framework``:sub:`opt` *string-literal*. The *string-literal* specifies the name of the library or framework against which the program should be linked. For example, specifying ""clangBasic"" would instruct the linker to link with ``-lclangBasic`` for a Unix-style linker. A *link-declaration* with the ``framework`` specifies that the linker should link against the named framework, e.g., with ``-framework MyFramework``. .. note::. Automatic linking with the ``link`` directive is not yet widely; implemented, because it requires support from both the object file; format and the linker. The notion is similar to Microsoft Visual; Studio's ``#pragma comment(lib...)``. Configuration macros declaration; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~; The *config-macros-declaration* specifies the set of configuration macros that have an effect on the API of the enclosing module. .. parsed-literal::. *config-macros-declaration*:; ``config_macros`` *attributes*:sub:`opt` *config-macro-list*:sub:`opt`. *config-macro-list*:; *identifier* (',' *identifier*)*. Each *identifier* in the *config-macro-list* specifies the name of a macro. The compiler is required to maintain different variants of the given module for differing definitions of any of the named macros. A *config-macros-declaration* shall only be present on a top-level module, i.e., a module that is not nested within an enclosing module. The ``exhaustive`` attribute specifies that the list of macros in the *config-macros-declaration* is exhaustive, meaning that no other macro definition is intended to have an effect on the API of that module. .. note::. The ``exhaustive`` attribute implies that any macro definitions; for macros not listed as configuration macros should be ignored; completely when building the",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Modules.rst:46264,config,config-macros-declaration,46264,interpreter/llvm-project/clang/docs/Modules.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Modules.rst,2,['config'],"['config-macros-declaration', 'configuration']"
Performance,"	%esi, %edi; 	testb	$-1, %dil; 	sete	%al; 	movzbl	%al, %eax; 	ret. A cmpb instead of the xorl+testb would be one instruction shorter. //===---------------------------------------------------------------------===//. Given the following C code:; int f(int a, int b) { return (signed char)a == (signed char)b; }. We generate the following IR with clang:; define i32 @f(i32 %a, i32 %b) nounwind readnone {; entry:; %sext = shl i32 %a, 24 ; <i32> [#uses=1]; %conv1 = ashr i32 %sext, 24 ; <i32> [#uses=1]; %sext6 = shl i32 %b, 24 ; <i32> [#uses=1]; %conv4 = ashr i32 %sext6, 24 ; <i32> [#uses=1]; %cmp = icmp eq i32 %conv1, %conv4 ; <i1> [#uses=1]; %conv5 = zext i1 %cmp to i32 ; <i32> [#uses=1]; ret i32 %conv5; }. And the following x86 code:; 	movsbl	%sil, %eax; 	movsbl	%dil, %ecx; 	cmpl	%eax, %ecx; 	sete	%al; 	movzbl	%al, %eax; 	ret. It should be possible to eliminate the sign extensions. //===---------------------------------------------------------------------===//. LLVM misses a load+store narrowing opportunity in this code:. %struct.bf = type { i64, i16, i16, i32 }. @bfi = external global %struct.bf* ; <%struct.bf**> [#uses=2]. define void @t1() nounwind ssp {; entry:; %0 = load %struct.bf** @bfi, align 8 ; <%struct.bf*> [#uses=1]; %1 = getelementptr %struct.bf* %0, i64 0, i32 1 ; <i16*> [#uses=1]; %2 = bitcast i16* %1 to i32* ; <i32*> [#uses=2]; %3 = load i32* %2, align 1 ; <i32> [#uses=1]; %4 = and i32 %3, -65537 ; <i32> [#uses=1]; store i32 %4, i32* %2, align 1; %5 = load %struct.bf** @bfi, align 8 ; <%struct.bf*> [#uses=1]; %6 = getelementptr %struct.bf* %5, i64 0, i32 1 ; <i16*> [#uses=1]; %7 = bitcast i16* %6 to i32* ; <i32*> [#uses=2]; %8 = load i32* %7, align 1 ; <i32> [#uses=1]; %9 = and i32 %8, -131073 ; <i32> [#uses=1]; store i32 %9, i32* %7, align 1; ret void; }. LLVM currently emits this:. movq bfi(%rip), %rax; andl $-65537, 8(%rax); movq bfi(%rip), %rax; andl $-131073, 8(%rax); ret. It could narrow the loads and stores to emit this:. movq bfi(%rip), %rax; andb ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README.txt:37276,load,load,37276,interpreter/llvm-project/llvm/lib/Target/X86/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README.txt,2,['load'],['load']
Performance,"	%xmm2, %xmm2, %xmm3; - - - 1.00 - 1.00 - - - - - - - - vhaddps	%xmm3, %xmm3, %xmm4. According to this report, the dot-product kernel has been executed 300 times,; for a total of 900 simulated instructions. The total number of simulated micro; opcodes (uOps) is also 900. The report is structured in three main sections. The first section collects a; few performance numbers; the goal of this section is to give a very quick; overview of the performance throughput. Important performance indicators are; **IPC**, **uOps Per Cycle**, and **Block RThroughput** (Block Reciprocal; Throughput). Field *DispatchWidth* is the maximum number of micro opcodes that are dispatched; to the out-of-order backend every simulated cycle. For processors with an; in-order backend, *DispatchWidth* is the maximum number of micro opcodes issued; to the backend every simulated cycle. IPC is computed dividing the total number of simulated instructions by the total; number of cycles. Field *Block RThroughput* is the reciprocal of the block throughput. Block; throughput is a theoretical quantity computed as the maximum number of blocks; (i.e. iterations) that can be executed per simulated clock cycle in the absence; of loop carried dependencies. Block throughput is superiorly limited by the; dispatch rate, and the availability of hardware resources. In the absence of loop-carried data dependencies, the observed IPC tends to a; theoretical maximum which can be computed by dividing the number of instructions; of a single iteration by the `Block RThroughput`. Field 'uOps Per Cycle' is computed dividing the total number of simulated micro; opcodes by the total number of cycles. A delta between Dispatch Width and this; field is an indicator of a performance issue. In the absence of loop-carried; data dependencies, the observed 'uOps Per Cycle' should tend to a theoretical; maximum throughput which can be computed by dividing the number of uOps of a; single iteration by the `Block RThroughput`. Field *uOp",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:16334,throughput,throughput,16334,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,1,['throughput'],['throughput']
Performance," 	fldl	8(%esp); 	fisttpll	(%esp); 	movl	4(%esp), %edx; 	movl	(%esp), %eax; 	addl	$20, %esp; 	#FP_REG_KILL; 	ret. This should just fldl directly from the input stack slot. //===---------------------------------------------------------------------===//. This code:; int foo (int x) { return (x & 65535) | 255; }. Should compile into:. _foo:; movzwl 4(%esp), %eax; orl $255, %eax; ret. instead of:; _foo:; 	movl	$65280, %eax; 	andl	4(%esp), %eax; 	orl	$255, %eax; 	ret. //===---------------------------------------------------------------------===//. We're codegen'ing multiply of long longs inefficiently:. unsigned long long LLM(unsigned long long arg1, unsigned long long arg2) {; return arg1 * arg2;; }. We compile to (fomit-frame-pointer):. _LLM:; 	pushl	%esi; 	movl	8(%esp), %ecx; 	movl	16(%esp), %esi; 	movl	%esi, %eax; 	mull	%ecx; 	imull	12(%esp), %esi; 	addl	%edx, %esi; 	imull	20(%esp), %ecx; 	movl	%esi, %edx; 	addl	%ecx, %edx; 	popl	%esi; 	ret. This looks like a scheduling deficiency and lack of remat of the load from; the argument area. ICC apparently produces:. movl 8(%esp), %ecx; imull 12(%esp), %ecx; movl 16(%esp), %eax; imull 4(%esp), %eax ; addl %eax, %ecx ; movl 4(%esp), %eax; mull 12(%esp) ; addl %ecx, %edx; ret. Note that it remat'd loads from 4(esp) and 12(esp). See this GCC PR:; http://gcc.gnu.org/bugzilla/show_bug.cgi?id=17236. //===---------------------------------------------------------------------===//. We can fold a store into ""zeroing a reg"". Instead of:. xorl %eax, %eax; movl %eax, 124(%esp). we should get:. movl $0, 124(%esp). if the flags of the xor are dead. Likewise, we isel ""x<<1"" into ""add reg,reg"". If reg is spilled, this should; be folded into: shl [mem], 1. //===---------------------------------------------------------------------===//. In SSE mode, we turn abs and neg into a load from the constant pool plus a xor; or and instruction, for example:. 	xorpd	LCPI1_0, %xmm2. However, if xmm2 gets spilled, we end up with really ugly code like this:.",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README.txt:21499,load,load,21499,interpreter/llvm-project/llvm/lib/Target/X86/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README.txt,2,['load'],['load']
Performance," ![Overlap checking](pictures/030001DF.png). This can be activated both at volume level (checking for illegal; overlaps only one level inside a given volume) and from the geometry; manager level (checking full geometry):. ``` {.cpp}; myVolume->CheckOverlaps(precision, option);; gGeoManager->CheckOverlaps(precision);; myNode->CheckOverlaps(precision);; ```. Here precision represents the desired maximum accepted overlap value in; centimeters (default value is 0.1). This tool checks all possible; significant pairs of candidates inside a given volume (not declared as; overlapping or division volumes). The check is performed by verifying; the mesh representation of one candidate against the shape of the other.; This sort of check cannot identify all possible overlapping topologies,; but it works for more than 95% and is much faster than the usual; shape-to-shape comparison. For a 100% reliability, one can perform the; check at the level of a single volume by using `option`=""`d`"" or; `option`=""`d<number>`"" to perform overlap checking by sampling the; volume with \<`number`\> random points (default 1 million). This; produces also a picture showing in red the overlapping region and; estimates the volume of the overlaps. An extrusion A) is declared in any of the following cases:. - At least one of the vertices of the daughter mesh representation is; outside the mother volume (in fact its shape) and having a safety; distance to the mother greater than the desired value;; - At least one of the mother vertices is contained also by one of its; daughters, in the same conditions. An overlap B) is declared if:. - At least one vertex of a positioned volume mesh is contained (having; a safety bigger than the accepted maximum value) by other positioned; volume inside the same container. The check is performed also by; inverting the candidates. The code is highly optimized to avoid checking candidates that are far; away in space by performing a fast check on their bounding boxes. Once; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md:133278,perform,perform,133278,documentation/users-guide/Geometry.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md,2,['perform'],['perform']
Performance," !ne; : !not !or !range !repr !setdagarg; : !setdagname !setdagop !shl !size !sra; : !srl !strconcat !sub !subst !substr; : !tail !tolower !toupper !xor. The ``!cond`` operator has a slightly different; syntax compared to other bang operators, so it is defined separately:. .. productionlist::; CondOperator: !cond. See `Appendix A: Bang Operators`_ for a description of each bang operator. Include files; -------------. TableGen has an include mechanism. The content of the included file; lexically replaces the ``include`` directive and is then parsed as if it was; originally in the main file. .. productionlist::; IncludeDirective: ""include"" `TokString`. Portions of the main file and included files can be conditionalized using; preprocessor directives. .. productionlist::; PreprocessorDirective: ""#define"" | ""#ifdef"" | ""#ifndef"". Types; =====. The TableGen language is statically typed, using a simple but complete type; system. Types are used to check for errors, to perform implicit conversions,; and to help interface designers constrain the allowed input. Every value is; required to have an associated type. TableGen supports a mixture of low-level types (e.g., ``bit``) and; high-level types (e.g., ``dag``). This flexibility allows you to describe a; wide range of records conveniently and compactly. .. productionlist::; Type: ""bit"" | ""int"" | ""string"" | ""dag""; :| ""bits"" ""<"" `TokInteger` "">""; :| ""list"" ""<"" `Type` "">""; :| `ClassID`; ClassID: `TokIdentifier`. ``bit``; A ``bit`` is a boolean value that can be 0 or 1. ``int``; The ``int`` type represents a simple 64-bit integer value, such as 5 or; -42. ``string``; The ``string`` type represents an ordered sequence of characters of arbitrary; length. ``bits<``\ *n*\ ``>``; The ``bits`` type is a fixed-sized integer of arbitrary length *n* that; is treated as separate bits. These bits can be accessed individually.; A field of this type is useful for representing an instruction operation; code, register number, or address mode/reg",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TableGen/ProgRef.rst:10301,perform,perform,10301,interpreter/llvm-project/llvm/docs/TableGen/ProgRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TableGen/ProgRef.rst,1,['perform'],['perform']
Performance," ""SetLineAttributes"", then left-click on ""Set Parameters"". This gives; access to a panel allowing you to interactively change the parameters of; the function, as shown in Figure [2.4](#f24). Change the slit width, or go from one to; two and then three or more slits, just as you like. When clicking on; ""Apply"", the function plot is updated to reflect the actual value of the; parameters you have set. [f25]: figures/ROOTPanel_FitPanel.png ""f25""; <a name=""f25""></a>. ![Fit Panel. \label{f25}][f25]. Another very useful interactive tool is the `FitPanel`, available for the; classes `TGraphErrors` and `TH1F`. Predefined fit functions can be selected; from a pull-down menu, including ""`gaus`"", ""`expo`"" and ""`pol0`"" - ""`pol9`""; for Gaussian and exponential functions or polynomials of degree 0 to 9,; respectively. In addition, user-defined functions using the same syntax as; for functions with parameters are possible. After setting the initial parameters, a fit of the selected function to the; data of a graph or histogram can be performed and the result displayed on the plot.; The fit panel is shown in Figure [2.5](#f25). The fit panel has a number of control options to; select the fit method, fix or release individual parameters in the fit, to steer; the level of output printed on the console, or to extract and display additional; information like contour lines showing parameter correlations. As function fitting; is of prime importance in any kind of data analysis, this topic will again show up; later. If you are satisfied with your plot, you probably want to save it. Just; close all selector boxes you opened previously and select the menu item; `Save as...` from the menu line of the window. It will pop up a file; selector box to allow you to choose the format, file name and target; directory to store the image. There is one very noticeable feature here:; you can store a plot as a root macro! In this macro, you find the C++; representation of all methods and classes involved i",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/primer/ROOT_as_calculator.md:15323,perform,performed,15323,documentation/primer/ROOT_as_calculator.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/primer/ROOT_as_calculator.md,1,['perform'],['performed']
Performance," ""Wingdings"" fonts; 25. Make ""col"" default draw option for TH2 in JSROOT gui. ## Changes in 6.3.4; 1. Fix bug in handling superimposing items via URL syntax; 2. Enable geometry clipping in node.js; 3. Upgrade node.js packages; 4. Let draw TGeo object inside TCanvas; 5. Let superimpose TPolyLine3D and TPolyMarker3D with TGeo drawing; 6. Fix plain #sum and #int parsing in TLatex; 7. Fix ticks position for axes with labels. ## Changes in 6.3.3; 1. Fix TEfficiency drawing; 2. Provide TPadPainter.divide method; 3. Fix browsing remote file via THttpServer; 4. Fix lego draw update while zooming. ## Changes in 6.3.2; 1. Fix bug in TH1 drawing when minimum or/and maximum was configured for histogram. ## Changes in 6.3.1; 1. Fix bug with col draw option in TH2/RH2. ## Changes in 6.3.0; 1. Fully rewrite TLatex parsing, use svg elements instead of plain text/tspan; 2. Make TLatex reliably working in node.js, does not depend from availability of canvas component; 3. Many optimizations to produce smaller (and faster) SVG output; 4. Provide x3dscNNN and y3dscNNN draw option for histogram to resize x/y axis in 3D plots; 5. Provide ""Find label"" command in TAxis context menu to zoom into bin region; 6. Allows to use JSROOT.define() in external scripts; 7. Provide JSROOT.Painter.setDefaultDrawOpt() to change class default draw option; 8. Provide example of custom entries in histogram context menu; 9. Provide alternative external location for zstd-codec, let use zstd even when not found locally; 10. Let skip HEAD requests when reading files, adding ""^"" symbol to file name (#223); 11. Show long histogram names in stats box when possible; 12. Fix logic how ""ndiv"" parameter of TAxis is handled, showing really the configured number of ticks; 13. Fix problem with curved TGraph drawings (#218); 14. Fix problems with TGraph drawing updates; 15. Base version for ROOT 6.26 release. ## Changes in 6.2.2; 1. Fix - proper fill TH1 which drawn with line option; 2. Fix - object drawing from inspector",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/js/changes.md:21188,optimiz,optimizations,21188,js/changes.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/js/changes.md,1,['optimiz'],['optimizations']
Performance," # Conditionally update predicate state.; testl %edx, %edx; je .LBB0_4; .LBB0_1:; cmoveq %r8, %rax # Conditionally update predicate state.; popq %rax; retq; .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; ...; ```. Here we create the ""empty"" or ""correct execution"" predicate state by zeroing; `%rax`, and we create a constant ""incorrect execution"" predicate value by; putting `-1` into `%r8`. Then, along each edge coming out of a conditional; branch we do a conditional move that in a correct execution will be a no-op,; but if misspeculated, will replace the `%rax` with the value of `%r8`.; Misspeculating any one of the three predicates will cause `%rax` to hold the; ""incorrect execution"" value from `%r8` as we preserve incoming values when; execution is correct rather than overwriting it. We now have a value in `%rax` in each basic block that indicates if at some; point previously a predicate was mispredicted. And we have arranged for that; value to be particularly effective when used below to harden loads. ##### Indirect Call, Branch, and Return Predicates. There is no analogous flag to use when tracing indirect calls, branches, and; returns. The predicate state must be accumulated through some other means.; Fundamentally, this is the reverse of the problem posed in CFI: we need to; check where we came from rather than where we are going. For function-local; jump tables, this is easily arranged by testing the input to the jump table; within each destination (not yet implemented, use retpolines):; ```; pushq %rax; xorl %eax, %eax # Zero out initial predicate state.; movq $-1, %r8 # Put all-ones mask into a register.; jmpq *.LJTI0_0(,%rdi,8) # Indirect jump through table.; .LBB0_2: # %sw.bb; testq $0, %rdi # Validate index used for jump table.; cmovneq %r8, %rax # Conditionally update predicate state.; ...; jmp _Z4leaki # TAILCALL. .LBB0_3: # %sw.bb1; testq $1, %rdi # Validate index used for jump table.; cmovneq %r8, %rax # Conditionally up",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:17804,load,loads,17804,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,1,['load'],['loads']
Performance," #+4]; add r0, r0, #2. //===---------------------------------------------------------------------===//. LLVM aggressively lift CSE out of loop. Sometimes this can be negative side-; effects:. R1 = X + 4; R2 = X + 7; R3 = X + 15. loop:; load [i + R1]; ...; load [i + R2]; ...; load [i + R3]. Suppose there is high register pressure, R1, R2, R3, can be spilled. We need; to implement proper re-materialization to handle this:. R1 = X + 4; R2 = X + 7; R3 = X + 15. loop:; R1 = X + 4 @ re-materialized; load [i + R1]; ...; R2 = X + 7 @ re-materialized; load [i + R2]; ...; R3 = X + 15 @ re-materialized; load [i + R3]. Furthermore, with re-association, we can enable sharing:. R1 = X + 4; R2 = X + 7; R3 = X + 15. loop:; T = i + X; load [T + 4]; ...; load [T + 7]; ...; load [T + 15]; //===---------------------------------------------------------------------===//. It's not always a good idea to choose rematerialization over spilling. If all; the load / store instructions would be folded then spilling is cheaper because; it won't require new live intervals / registers. See 2003-05-31-LongShifts for; an example. //===---------------------------------------------------------------------===//. With a copying garbage collector, derived pointers must not be retained across; collector safe points; the collector could move the objects and invalidate the; derived pointer. This is bad enough in the first place, but safe points can; crop up unpredictably. Consider:. %array = load { i32, [0 x %obj] }** %array_addr; %nth_el = getelementptr { i32, [0 x %obj] }* %array, i32 0, i32 %n; %old = load %obj** %nth_el; %z = div i64 %x, %y; store %obj* %new, %obj** %nth_el. If the i64 division is lowered to a libcall, then a safe point will (must); appear for the call site. If a collection occurs, %array and %nth_el no longer; point into the correct object. The fix for this is to copy address calculations so that dependent pointers; are never live across safe point boundaries. But the loads cannot be cop",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/README.txt:2457,load,load,2457,interpreter/llvm-project/llvm/lib/CodeGen/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/README.txt,1,['load'],['load']
Performance," #. Each read of the variable becomes a load from the stack.; #. Each update of the variable becomes a store to the stack.; #. Taking the address of a variable just uses the stack address; directly. While this solution has solved our immediate problem, it introduced; another one: we have now apparently introduced a lot of stack traffic; for very simple and common operations, a major performance problem.; Fortunately for us, the LLVM optimizer has a highly-tuned optimization; pass named ""mem2reg"" that handles this case, promoting allocas like this; into SSA registers, inserting Phi nodes as appropriate. If you run this; example through the pass, for example, you'll get:. .. code-block:: bash. $ llvm-as < example.ll | opt -passes=mem2reg | llvm-dis; @G = weak global i32 0; @H = weak global i32 0. define i32 @test(i1 %Condition) {; entry:; br i1 %Condition, label %cond_true, label %cond_false. cond_true:; %X.0 = load i32, i32* @G; br label %cond_next. cond_false:; %X.1 = load i32, i32* @H; br label %cond_next. cond_next:; %X.01 = phi i32 [ %X.1, %cond_false ], [ %X.0, %cond_true ]; ret i32 %X.01; }. The mem2reg pass implements the standard ""iterated dominance frontier""; algorithm for constructing SSA form and has a number of optimizations; that speed up (very common) degenerate cases. The mem2reg optimization; pass is the answer to dealing with mutable variables, and we highly; recommend that you depend on it. Note that mem2reg only works on; variables in certain circumstances:. #. mem2reg is alloca-driven: it looks for allocas and if it can handle; them, it promotes them. It does not apply to global variables or heap; allocations.; #. mem2reg only looks for alloca instructions in the entry block of the; function. Being in the entry block guarantees that the alloca is only; executed once, which makes analysis simpler.; #. mem2reg only promotes allocas whose uses are direct loads and stores.; If the address of the stack object is passed to a function, or if any; funny po",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl07.rst:7236,load,load,7236,interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl07.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl07.rst,1,['load'],['load']
Performance," #176, #179, #180, #182. 2019-11-07: 1.5.7; -----------------. * Allow implicit converions for move arguments; * Choose vector over initializer_list if part of the template argument list. 2019-11-03: 1.5.6; -----------------. * Added public C++ API for some CPyCppyy core functions (CPython only); * Support for char16_t/char16_t* and char32_t/char32_t*; * Respect ``std::hash`` in ``__hash__``; * Fix iteration over vector of shared_ptr; * Length checking on global variables of type 'signed char[N]'; * Properly support overloaded templated with non-templated ``__setitem__``; * Support for array of const char* as C-strings; * Enable type resolution of clang's builtin ``__type_pack_element``; * Fix for inner class type naming when it directly declares a variable. 2019-10-16: 1.5.5; -----------------. * Added signal -> exception support in cppyy.ll; * Support for lazily combining overloads of operator*/+-; * No longer call trivial destructors; * Support for free function unary operators; * Refactored and optimized operator==/!= usage; * Refactored converters/executors for lower memory usage; * Bug fixes in rootcling and _cppyy_generator.py. 2019-09-25: 1.5.4; -----------------. * operator+/* now respect C++-side associativity; * Fix potential crash if modules are reloaded; * Fix some portability issues on Mac/Windows of cppyy-cling. 2019-09-15: 1.5.3; -----------------. * Performance improvements; * Support for anonymous/unnamed/nested unions; * Extended documentation. 2019-09-06: 1.5.2; -----------------. * Added a ""low level"" interface (cppyy.ll) for hard-casting and ll types; * Extended support for passing ctypes arguments through ptr, ref, ptr-ptr; * Fixed crash when creating an array of instances of a scoped inner struct; * Extended documentation. 2019-08-26: 1.5.1; -----------------. * Upgrade cppyy-cling to 6.18.2; * Various patches to upstream's pre-compiled header generation and use; * Instantiate templates with larger integer types if argument values require; * I",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst:16344,optimiz,optimized,16344,bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst,1,['optimiz'],['optimized']
Performance," #2 sounded good to me. I'm not sure I understand your; > concern about an explicit 'icall' instruction?. I worry too much. :) The other alternative has been removed. 'icall' is; now up in the instruction list next to 'call'. > I believe tail calls are relatively easy to identify; do you know why; > .NET has a tailcall instruction?. Although I am just guessing, I believe it probably has to do with the fact; that they want languages like Haskell and lisp to be efficiently runnable; on their VM. Of course this means that the VM MUST implement tail calls; 'correctly', or else life will suck. :) I would put this into a future; feature bin, because it could be pretty handy... > A pair of important synchronization instr'ns to think about:; > load-linked; > store-conditional. What is 'load-linked'? I think that (at least for now) I should add these; to the 'possible extensions' section, because they are not immediately; needed... > Other classes of instructions that are valuable for pipeline; > performance:; > conditional-move ; > predicated instructions. Conditional move is effectly a special case of a predicated; instruction... and I think that all predicated instructions can possibly; be implemented later in LLVM. It would significantly change things, and; it doesn't seem to be very necessary right now. It would seem to; complicate flow control analysis a LOT in the virtual machine. I would; tend to prefer that a predicated architecture like IA64 convert from a; ""basic block"" representation to a predicated rep as part of it's dynamic; complication phase. Also, if a basic block contains ONLY a move, then; that can be trivally translated into a conditional move... > I agree that we need a static data space. Otherwise, emulating global; > data gets unnecessarily complex. Definitely. Also a later item though. :). > We once talked about adding a symbolic thread-id field to each; > ..; > Instead, it could a great topic for a separate study. Agreed. :). > What is the semantics",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-02-09-AdveCommentsResponse.txt:6166,perform,performance,6166,interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-02-09-AdveCommentsResponse.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-02-09-AdveCommentsResponse.txt,1,['perform'],['performance']
Performance," $ cmake -C <path to cache file> <path to sources>. CMake cache scripts are processed in an isolated scope, only cached variables; remain set when the main configuration runs. CMake cached variables do not reset; variables that are already set unless the FORCE option is specified. A few notes about CMake Caches:. - Order of command line arguments is important. - -D arguments specified before -C are set before the cache is processed and; can be read inside the cache file; - -D arguments specified after -C are set after the cache is processed and; are unset inside the cache file. - All -D arguments will override cache file settings; - CMAKE_TOOLCHAIN_FILE is evaluated after both the cache file and the command; line arguments; - It is recommended that all -D options should be specified *before* -C. For more information about some of the advanced build configurations supported; via Cache files see :doc:`AdvancedBuilds`. Executing the Tests; ===================. Testing is performed when the *check-all* target is built. For instance, if you are; using Makefiles, execute this command in the root of your build directory:. .. code-block:: console. $ make check-all. On Visual Studio, you may run tests by building the project ""check-all"".; For more information about testing, see the :doc:`TestingGuide`. Cross compiling; ===============. See `this wiki page <https://gitlab.kitware.com/cmake/community/wikis/doc/cmake/CrossCompiling>`_ for; generic instructions on how to cross-compile with CMake. It goes into detailed; explanations and may seem daunting, but it is not. On the wiki page there are; several examples including toolchain files. Go directly to the; ``Information how to set up various cross compiling toolchains`` section; for a quick solution. Also see the `LLVM-related variables`_ section for variables used when; cross-compiling. Embedding LLVM in your project; ==============================. From LLVM 3.5 onwards the CMake build system exports LLVM libraries as; impor",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:39912,perform,performed,39912,interpreter/llvm-project/llvm/docs/CMake.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst,1,['perform'],['performed']
Performance," $noreg, 4, $noreg, debug-location !5 :: (load 4 from %ir.addr1); DBG_VALUE %1, $noreg, !1, !2. Here, to avoid presenting a state in which the first assignment to ``!1``; disappears, the DBG_VALUE at the top of the block assigns the variable the; undefined location, until its value is available at the end of the block where; an additional DBG_VALUE is added. Were any other DBG_VALUE for ``!1`` to occur; in the instructions that the MOV32rm was sunk past, the DBG_VALUE for ``%1``; would be dropped and the debugger would never observe it in the variable. This; accurately reflects that the value is not available during the corresponding; portion of the original program. Variable locations during Register Allocation; ---------------------------------------------. To avoid debug instructions interfering with the register allocator, the; LiveDebugVariables pass extracts variable locations from a MIR function and; deletes the corresponding DBG_VALUE instructions. Some localized copy; propagation is performed within blocks. After register allocation, the; VirtRegRewriter pass re-inserts DBG_VALUE instructions in their original; positions, translating virtual register references into their physical; machine locations. To avoid encoding incorrect variable locations, in this; pass any DBG_VALUE of a virtual register that is not live, is replaced by; the undefined location. The LiveDebugVariables may insert redundant DBG_VALUEs; because of virtual register rewriting. These will be subsequently removed by; the RemoveRedundantDebugValues pass. LiveDebugValues expansion of variable locations; -----------------------------------------------. After all optimizations have run and shortly before emission, the; LiveDebugValues pass runs to achieve two aims:. * To propagate the location of variables through copies and register spills,; * For every block, to record every valid variable location in that block. After this pass the DBG_VALUE instruction changes meaning: rather than; correspo",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:35887,perform,performed,35887,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,1,['perform'],['performed']
Performance," %inFloat3.713, <4 x float>* %P2; ret void; }. Generates:. _test:; 	movl	8(%esp), %eax; 	movaps	(%eax), %xmm0; 	pxor	%xmm1, %xmm1; 	movaps	%xmm0, %xmm2; 	shufps	$50, %xmm1, %xmm2; 	shufps	$132, %xmm2, %xmm0; 	movaps	%xmm0, (%eax); 	ret. Would it be better to generate:. _test:; movl 8(%esp), %ecx; movaps (%ecx), %xmm0; 	xor %eax, %eax; pinsrw $6, %eax, %xmm0; pinsrw $7, %eax, %xmm0; movaps %xmm0, (%ecx); ret. ?. //===---------------------------------------------------------------------===//. Some useful information in the Apple Altivec / SSE Migration Guide:. http://developer.apple.com/documentation/Performance/Conceptual/; Accelerate_sse_migration/index.html. e.g. SSE select using and, andnot, or. Various SSE compare translations. //===---------------------------------------------------------------------===//. Add hooks to commute some CMPP operations. //===---------------------------------------------------------------------===//. Apply the same transformation that merged four float into a single 128-bit load; to loads from constant pool. //===---------------------------------------------------------------------===//. Floating point max / min are commutable when -enable-unsafe-fp-path is; specified. We should turn int_x86_sse_max_ss and X86ISD::FMIN etc. into other; nodes which are selected to max / min instructions that are marked commutable. //===---------------------------------------------------------------------===//. We should materialize vector constants like ""all ones"" and ""signbit"" with ; code like:. cmpeqps xmm1, xmm1 ; xmm1 = all-ones. and:; cmpeqps xmm1, xmm1 ; xmm1 = all-ones; psrlq xmm1, 31 ; xmm1 = all 100000000000... instead of using a load from the constant pool. The later is important for; ABS/NEG/copysign etc. //===---------------------------------------------------------------------===//. These functions:. #include <xmmintrin.h>; __m128i a;; void x(unsigned short n) {; a = _mm_slli_epi32 (a, n);; }; void y(unsigned n) {; a = _mm_slli_epi32 (a, n",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README-SSE.txt:9454,load,load,9454,interpreter/llvm-project/llvm/lib/Target/X86/README-SSE.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README-SSE.txt,4,['load'],"['load', 'loads']"
Performance," %mask, <4 x i32> %a, <4 x i32> <i32 -1, i32 -1, i32 -1, i32 -1>; %reduction = call i32 @llvm.vector.reduce.umin.v4i32(<4 x i32> %masked.a); %also.r = call i32 @llvm.umin.i32(i32 %reduction, i32 %start). .. _int_vp_reduce_fmax:. '``llvm.vp.reduce.fmax.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare float @llvm.vp.reduce.fmax.v4f32(float <start_value>, <4 x float> <val>, <4 x i1> <mask>, float <vector_length>); declare double @llvm.vp.reduce.fmax.nxv8f64(double <start_value>, <vscale x 8 x double> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated floating-point ``MAX`` reduction of a vector and a scalar starting; value, returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value of the reduction, which must be a scalar; floating-point type equal to the result type. The second operand is the vector; on which the reduction is performed and must be a vector of floating-point; values whose element type is the result/start type. The third operand is the; vector mask and is a vector of boolean values with the same number of elements; as the vector operand. The fourth operand is the explicit vector length of the; operation. Semantics:; """""""""""""""""""". The '``llvm.vp.reduce.fmax``' intrinsic performs the floating-point ``MAX``; reduction (:ref:`llvm.vector.reduce.fmax <int_vector_reduce_fmax>`) of the; vector operand ``val`` on each enabled lane, taking the maximum of that and the; scalar ``start_value``. Disabled lanes are treated as containing the neutral; value (i.e. having no effect on the reduction operation). If the vector length; is zero, the result is the start value. The neutral value is dependent on the :ref:`fast-math flags <fastmath>`. If no; flags are set, the neutral value is ``-QNAN``. If ``nnan`` and ``ninf`` are; both set, then the neutral value is the smallest floating-point value for the; result type. If only ``nnan``",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:771760,perform,performed,771760,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['performed']
Performance," %mask, i32 %evl); declare <vscale x 1 x i64> @llvm.vp.load.nxv1i64.p6(ptr addrspace(6) %ptr, <vscale x 1 x i1> %mask, i32 %evl). Overview:; """""""""""""""""". The '``llvm.vp.load.*``' intrinsic is the vector length predicated version of; the :ref:`llvm.masked.load <int_mload>` intrinsic. Arguments:; """""""""""""""""""". The first operand is the base pointer for the load. The second operand is a; vector of boolean values with the same number of elements as the return type.; The third is the explicit vector length of the operation. The return type and; underlying type of the base pointer are the same vector types. The :ref:`align <attr_align>` parameter attribute can be provided for the first; operand. Semantics:; """""""""""""""""""". The '``llvm.vp.load``' intrinsic reads a vector from memory in the same way as; the '``llvm.masked.load``' intrinsic, where the mask is taken from the; combination of the '``mask``' and '``evl``' operands in the usual VP way.; Certain '``llvm.masked.load``' operands do not have corresponding operands in; '``llvm.vp.load``': the '``passthru``' operand is implicitly ``poison``; the; '``alignment``' operand is taken as the ``align`` parameter attribute, if; provided. The default alignment is taken as the ABI alignment of the return; type as specified by the :ref:`datalayout string<langref_datalayout>`. Examples:; """""""""""""""""". .. code-block:: text. %r = call <8 x i8> @llvm.vp.load.v8i8.p0(ptr align 2 %ptr, <8 x i1> %mask, i32 %evl); ;; For all lanes below %evl, %r is lane-wise equivalent to %also.r. %also.r = call <8 x i8> @llvm.masked.load.v8i8.p0(ptr %ptr, i32 2, <8 x i1> %mask, <8 x i8> poison). .. _int_vp_store:. '``llvm.vp.store``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare void @llvm.vp.store.v4f32.p0(<4 x float> %val, ptr %ptr, <4 x i1> %mask, i32 %evl); declare void @llvm.vp.store.nxv2i16.p0(<vscale x 2 x i16> %val, ptr %ptr, <vscale x 2 x i1> %mask, i32 %evl); declare void @llv",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:784248,load,load,784248,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['load'],['load']
Performance," '``llvm.pcmarker``' intrinsic is a method to export a Program; Counter (PC) in a region of code to simulators and other tools. The; method is target specific, but it is expected that the marker will use; exported symbols to transmit the PC of the marker. The marker makes no; guarantees that it will remain with any specific instruction after; optimizations. It is possible that the presence of a marker will inhibit; optimizations. The intended use is to be inserted after optimizations to; allow correlations of simulation runs. Arguments:; """""""""""""""""""". ``id`` is a numerical id identifying the marker. Semantics:; """""""""""""""""""". This intrinsic does not modify the behavior of the program. Backends; that do not support this intrinsic may ignore it. '``llvm.readcyclecounter``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i64 @llvm.readcyclecounter(). Overview:; """""""""""""""""". The '``llvm.readcyclecounter``' intrinsic provides access to the cycle; counter register (or similar low latency, high accuracy clocks) on those; targets that support it. On X86, it should map to RDTSC. On Alpha, it; should map to RPCC. As the backing counters overflow quickly (on the; order of 9 seconds on alpha), this should only be used for small; timings. Semantics:; """""""""""""""""""". When directly supported, reading the cycle counter should not modify any; memory. Implementations are allowed to either return an application; specific value or a system wide value. On backends without support, this; is lowered to a constant 0. Note that runtime support may be conditional on the privilege-level code is; running at and the host platform. '``llvm.clear_cache``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare void @llvm.clear_cache(ptr, ptr). Overview:; """""""""""""""""". The '``llvm.clear_cache``' intrinsic ensures visibility of modifications; in the specified range to the execution unit of the processor. On; targets with non-unified instruction and data cache, t",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:525204,latency,latency,525204,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['latency'],['latency']
Performance," 'any' causes the merge command to; fail if any profiles are invalid, and 'all' causes the merge command to fail; only if all profiles are invalid. If 'all' is set, information from any; invalid profiles is excluded from the final merged product. The default; failure mode is 'any'. .. option:: --prof-sym-list=<path>. Specify a file which contains a list of symbols to generate profile symbol; list in the profile. This option can only be used with sample-based profile; in extbinary format. The entries in this file are newline-separated. .. option:: --compress-all-sections=[true|false]. Compress all sections when writing the profile. This option can only be used; with sample-based profile in extbinary format. .. option:: --use-md5=[true|false]. Use MD5 to represent string in name table when writing the profile.; This option can only be used with sample-based profile in extbinary format. .. option:: --gen-partial-profile=[true|false]. Mark the profile to be a partial profile which only provides partial profile; coverage for the optimized target. This option can only be used with; sample-based profile in extbinary format. .. option:: --convert-sample-profile-layout=[nest|flat]. Convert the merged profile into a profile with a new layout. Supported; layout are ``nest`` (Nested profile, the input should be CS flat profile) and; ``flat`` (Profile with nested inlinees flattened out). .. option:: --supplement-instr-with-sample=<file>. Supplement an instrumentation profile with sample profile. The sample profile; is the input of the flag. Output will be in instrumentation format (only works; with -instr). .. option:: --zero-counter-threshold=<float>. For the function which is cold in instr profile but hot in sample profile, if; the ratio of the number of zero counters divided by the total number of; counters is above the threshold, the profile of the function will be regarded; as being harmful for performance and will be dropped. .. option:: --instr-prof-cold-threshold=<int>. U",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-profdata.rst:5154,optimiz,optimized,5154,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-profdata.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-profdata.rst,1,['optimiz'],['optimized']
Performance," 'fn'. Remove 'protocol+server' from file tagging and matching, i.e. use; only filepath+anchor; in this way a list is valid even after re-staging; of the dataset files, which typically changes the end-point data servers.; Entry-lists created with the full path should still be matched correctly. Miscellaneous. Repaired the behavior of TTreeCache when the TTree has a dramatic dynamic range with a lots of very small entriesat the beginning and very large entries at the end, the size in bytes of the cluster for the later entries will be very large (because of the cluster size in entries is large!). TTreeCache::FillBuffer was always attempting to load complete clusters not matter the; size (even with the size was larger than 2GB!). This patch resolves the issue by limiting the amount of memory used to:. The requested size if more than one cluster fits in the cache.; Twice the requested size if at least one basket per branch fits in the cache.; Four time the requested size in the case where the cache can not even hold one basket per branch. The filling will restart at the next cluster boundary in the case a) and will; restart at the maximum of entry number read in the cache in the case b) and c).; Baskets that are below this boundary and did not fit in the cache will be read; individually.; Repaired the basket flushing frequency when the TTree has already more than one cluster size.; Repaired binning of string histogram generated by TTree::Draw.; Many bug fixes and fix for issues discovery by Coverity, see change log for more details.; In TTree::MakeProxy add proper support for top level stl collection of objects and for stl collection of objects that are 'empty' in the file (and thus we know nothing about its content).; Avoid deficiency in hadd when the resulting TTree is longer than the AutoSave length *and* the TFileMerger needs to handle the input files in more than one pass for example when there is more than 1000 input files or the -n option is passed to hadd.; Fix s",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v534/index.html:3393,cache,cache,3393,tree/doc/v534/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v534/index.html,2,['cache'],['cache']
Performance," 'malloc/calloc/realloc' call and the operand; of sizeof expressions contained within its argument(s).; checker-264; built: April 26, 2012; highlights:; This release contains misc. bug fixes and performance enhancements over checker-263, including; a reduction of some kinds of false positives related to the malloc() checker.; checker-263; built: March 22, 2012; highlights:. Fixes several serious bugs with inter-procedural analysis, including a case where retain/releases would be ""double-counted"". checker-262; built: March 15, 2012; highlights:. Enables experimental interprocedural analysis (within a file), which greatly amplifies the analyzer's ability to find issues.; Many bug fixes to the malloc/free checker.; Support for new Objective-C NSArray/NSDictionary/NSNumber literals syntax, and Objective-C container subscripting. NOTE: This build contains new interprocedural analysis that allows the analyzer to find more complicated bugs that span function boundaries. It may have problems, performance issues, etc. We'd like to hear about them. checker-261; built: February 22, 2012; highlights:. Contains a new experimental malloc/free checker.; Better support for projects using ARC.; Warns about null pointers passed as arguments to C string functions.; Warns about common anti-patterns in 'strncat' size argument, which can lead to buffer overflows.; set-xcode-analyzer now supports self-contained Xcode.app (Xcode 4.3 and later).; Contains a newer version of the analyzer than Xcode 4.3.; Misc. bug fixes and performance work. checker-260; built: January 25, 2012; highlights:; This is essentially the same as checker-259, but enables the following experimental checkers (please provide feedback):. Warns about unsafe uses of CFArrayCreate, CFSetCreate, and CFDictionaryCreate; Warns about unsafe uses of getpw, gets, which are sources of buffer overflows; Warns about unsafe uses of mktemp and mktemps, which can lead to insecure temporary files; Warns about unsafe uses of vfork, whic",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/release_notes.html:8721,perform,performance,8721,interpreter/llvm-project/clang/www/analyzer/release_notes.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/release_notes.html,2,['perform'],['performance']
Performance," (If you are writing a backend for an; architecture which cannot satisfy these restrictions and cares about; concurrency, please send an email to llvm-dev.). Unordered; ---------. Unordered is the lowest level of atomicity. It essentially guarantees that races; produce somewhat sane results instead of having undefined behavior. It also; guarantees the operation to be lock-free, so it does not depend on the data; being part of a special atomic structure or depend on a separate per-process; global lock. Note that code generation will fail for unsupported atomic; operations; if you need such an operation, use explicit locking. Relevant standard; This is intended to match the Java memory model for shared variables. Notes for frontends; This cannot be used for synchronization, but is useful for Java and other; ""safe"" languages which need to guarantee that the generated code never; exhibits undefined behavior. Note that this guarantee is cheap on common; platforms for loads of a native width, but can be expensive or unavailable for; wider loads, like a 64-bit store on ARM. (A frontend for Java or other ""safe""; languages would normally split a 64-bit store on ARM into two 32-bit unordered; stores.). Notes for optimizers; In terms of the optimizer, this prohibits any transformation that transforms a; single load into multiple loads, transforms a store into multiple stores,; narrows a store, or stores a value which would not be stored otherwise. Some; examples of unsafe optimizations are narrowing an assignment into a bitfield,; rematerializing a load, and turning loads and stores into a memcpy; call. Reordering unordered operations is safe, though, and optimizers should; take advantage of that because unordered operations are common in languages; that need them. Notes for code generation; These operations are required to be atomic in the sense that if you use; unordered loads and unordered stores, a load cannot see a value which was; never stored. A normal load or store ins",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Atomics.rst:8744,load,loads,8744,interpreter/llvm-project/llvm/docs/Atomics.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Atomics.rst,2,['load'],['loads']
Performance," (LDS) address space and is treated as work-group. The memory model does not support the region address space which is treated as; non-atomic. Acquire memory ordering is not meaningful on store atomic instructions and is; treated as non-atomic. Release memory ordering is not meaningful on load atomic instructions and is; treated a non-atomic. Acquire-release memory ordering is not meaningful on load or store atomic; instructions and is treated as acquire and release respectively. The memory order also adds the single thread optimization constraints defined in; table; :ref:`amdgpu-amdhsa-memory-model-single-thread-optimization-constraints-table`. .. table:: AMDHSA Memory Model Single Thread Optimization Constraints; :name: amdgpu-amdhsa-memory-model-single-thread-optimization-constraints-table. ============ ==============================================================; LLVM Memory Optimization Constraints; Ordering; ============ ==============================================================; unordered *none*; monotonic *none*; acquire - If a load atomic/atomicrmw then no following load/load; atomic/store/store atomic/atomicrmw/fence instruction can be; moved before the acquire.; - If a fence then same as load atomic, plus no preceding; associated fence-paired-atomic can be moved after the fence.; release - If a store atomic/atomicrmw then no preceding load/load; atomic/store/store atomic/atomicrmw/fence instruction can be; moved after the release.; - If a fence then same as store atomic, plus no following; associated fence-paired-atomic can be moved before the; fence.; acq_rel Same constraints as both acquire and release.; seq_cst - If a load atomic then same constraints as acquire, plus no; preceding sequentially consistent load atomic/store; atomic/atomicrmw/fence instruction can be moved after the; seq_cst.; - If a store atomic then the same constraints as release, plus; no following sequentially consistent load atomic/store; atomic/atomicrmw/fence instruction ca",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:204754,load,load,204754,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,3,['load'],['load']
Performance," (MEMrr $rs1, $rs2):$addr),; ""ld [$addr], $dst"",; [(set i32:$dst, (load ADDRrr:$addr))]>;. The fourth parameter is the input source, which uses the address operand; ``MEMrr`` that is defined earlier in ``SparcInstrInfo.td``:. .. code-block:: text. def MEMrr : Operand<i32> {; let PrintMethod = ""printMemOperand"";; let MIOperandInfo = (ops IntRegs, IntRegs);; }. The fifth parameter is a string that is used by the assembly printer and can be; left as an empty string until the assembly printer interface is implemented.; The sixth and final parameter is the pattern used to match the instruction; during the SelectionDAG Select Phase described in :doc:`CodeGenerator`.; This parameter is detailed in the next section, :ref:`instruction-selector`. Instruction class definitions are not overloaded for different operand types,; so separate versions of instructions are needed for register, memory, or; immediate value operands. For example, to perform a Load Integer instruction; for a Word from an immediate operand to a register, the following instruction; class is defined:. .. code-block:: text. def LDri : F3_2 <3, 0b000000, (outs IntRegs:$rd), (ins (MEMri $rs1, $simm13):$addr),; ""ld [$addr], $dst"",; [(set i32:$rd, (load ADDRri:$addr))]>;. Writing these definitions for so many similar instructions can involve a lot of; cut and paste. In ``.td`` files, the ``multiclass`` directive enables the; creation of templates to define several instruction classes at once (using the; ``defm`` directive). For example in ``SparcInstrInfo.td``, the ``multiclass``; pattern ``F3_12`` is defined to create 2 instruction classes each time; ``F3_12`` is invoked:. .. code-block:: text. multiclass F3_12 <string OpcStr, bits<6> Op3Val, SDNode OpNode> {; def rr : F3_1 <2, Op3Val,; (outs IntRegs:$rd), (ins IntRegs:$rs1, IntRegs:$rs1),; !strconcat(OpcStr, "" $rs1, $rs2, $rd""),; [(set i32:$rd, (OpNode i32:$rs1, i32:$rs2))]>;; def ri : F3_2 <2, Op3Val,; (outs IntRegs:$rd), (ins IntRegs:$rs1, i32imm:$simm13),; !",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:33959,perform,perform,33959,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,1,['perform'],['perform']
Performance," (all the registers that are; preserved on the fast path, composed of the entry and exit blocks). This calling convention behaves identical to the `C` calling convention on; how arguments and return values are passed, but it uses a different set of; caller/callee-saved registers. Given that each platform has its own lowering sequence, hence its own set; of preserved registers, we can't use the existing `PreserveMost`. - On X86-64 the callee preserves all general purpose registers, except for; RDI and RAX.; ""``tailcc``"" - Tail callable calling convention; This calling convention ensures that calls in tail position will always be; tail call optimized. This calling convention is equivalent to fastcc,; except for an additional guarantee that tail calls will be produced; whenever possible. `Tail calls can only be optimized when this, the fastcc,; the GHC or the HiPE convention is used. <CodeGenerator.html#tail-call-optimization>`_; This calling convention does not support varargs and requires the prototype of; all callees to exactly match the prototype of the function definition.; ""``swiftcc``"" - This calling convention is used for Swift language.; - On X86-64 RCX and R8 are available for additional integer returns, and; XMM2 and XMM3 are available for additional FP/vector returns.; - On iOS platforms, we use AAPCS-VFP calling convention.; ""``swifttailcc``""; This calling convention is like ``swiftcc`` in most respects, but also the; callee pops the argument area of the stack so that mandatory tail calls are; possible as in ``tailcc``.; ""``cfguard_checkcc``"" - Windows Control Flow Guard (Check mechanism); This calling convention is used for the Control Flow Guard check function,; calls to which can be inserted before indirect calls to check that the call; target is a valid function address. The check function has no return value,; but it will trigger an OS-level error if the address is not a valid target.; The set of registers preserved by the check function, and the regi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:21303,optimiz,optimization,21303,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['optimiz'],['optimization']
Performance," (and later ip) is the hidden parameter from caller to store the value in. The; first ldmia loads the constants into r0, r1, r2. The last stmia stores r0, r1,; r2 into the address passed in. However, there is one additional stmia that; stores r0, r1, and r2 to some stack location. The store is dead. The llvm-gcc generated code looks like this:. csretcc void %foo(%struct.s* %agg.result) {; entry:; 	%S = alloca %struct.s, align 4		; <%struct.s*> [#uses=1]; 	%memtmp = alloca %struct.s		; <%struct.s*> [#uses=1]; 	cast %struct.s* %S to sbyte*		; <sbyte*>:0 [#uses=2]; 	call void %llvm.memcpy.i32( sbyte* %0, sbyte* cast ({ double, int }* %C.0.904 to sbyte*), uint 12, uint 4 ); 	cast %struct.s* %agg.result to sbyte*		; <sbyte*>:1 [#uses=2]; 	call void %llvm.memcpy.i32( sbyte* %1, sbyte* %0, uint 12, uint 0 ); 	cast %struct.s* %memtmp to sbyte*		; <sbyte*>:2 [#uses=1]; 	call void %llvm.memcpy.i32( sbyte* %2, sbyte* %1, uint 12, uint 0 ); 	ret void; }. llc ends up issuing two memcpy's (the first memcpy becomes 3 loads from; constantpool). Perhaps we should 1) fix llvm-gcc so the memcpy is translated; into a number of load and stores, or 2) custom lower memcpy (of small size) to; be ldmia / stmia. I think option 2 is better but the current register; allocator cannot allocate a chunk of registers at a time. A feasible temporary solution is to use specific physical registers at the; lowering time for small (<= 4 words?) transfer size. * ARM CSRet calling convention requires the hidden argument to be returned by; the callee. //===---------------------------------------------------------------------===//. We can definitely do a better job on BB placements to eliminate some branches.; It's very common to see llvm generated assembly code that looks like this:. LBB3:; ...; LBB4:; ...; beq LBB3; b LBB2. If BB4 is the only predecessor of BB3, then we can emit BB3 after BB4. We can; then eliminate beq and turn the unconditional branch to LBB2 to a bne. See McCat/18-imp/ComputeBoundingBo",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/README.txt:7110,load,loads,7110,interpreter/llvm-project/llvm/lib/Target/ARM/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/README.txt,2,['load'],['loads']
Performance," (stateless AA impl); Function Alias Analysis Results; Memory Dependence Analysis; Global Value Numbering; Hello World Pass; Dominator Tree Construction; Natural Loop Information; Canonicalize natural loops; Loop-Closed SSA Form Pass; Basic Alias Analysis (stateless AA impl); Function Alias Analysis Results; Scalar Evolution Analysis; Loop Pass Manager; Loop Invariant Code Motion; Module Verifier; Bitcode Writer; Hello: __main; Hello: puts; Hello: main. Here we see that the :ref:`Hello World <writing-an-llvm-pass-basiccode>` pass; has killed the Dominator Tree pass, even though it doesn't modify the code at; all! To fix this, we need to add the following :ref:`getAnalysisUsage; <writing-an-llvm-pass-getAnalysisUsage>` method to our pass:. .. code-block:: c++. // We don't modify the program, so we preserve all analyses; void getAnalysisUsage(AnalysisUsage &AU) const override {; AU.setPreservesAll();; }. Now when we run our pass, we get this output:. .. code-block:: console. $ opt -load lib/LLVMHello.so -gvn -hello -licm --debug-pass=Structure < hello.bc > /dev/null; Pass Arguments: -gvn -hello -licm; ModulePass Manager; FunctionPass Manager; Dominator Tree Construction; Basic Alias Analysis (stateless AA impl); Function Alias Analysis Results; Memory Dependence Analysis; Global Value Numbering; Hello World Pass; Natural Loop Information; Canonicalize natural loops; Loop-Closed SSA Form Pass; Basic Alias Analysis (stateless AA impl); Function Alias Analysis Results; Scalar Evolution Analysis; Loop Pass Manager; Loop Invariant Code Motion; Module Verifier; Bitcode Writer; Hello: __main; Hello: puts; Hello: main. Which shows that we don't accidentally invalidate dominator information; anymore, and therefore do not have to compute it twice. .. _writing-an-llvm-pass-releaseMemory:. The ``releaseMemory`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual void releaseMemory();. The ``PassManager`` automatically determines when to compute analysis results,; an",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:46065,load,load,46065,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,1,['load'],['load']
Performance," **`TGeoVolumeAssembly`** object and position the components inside as; for any volume:. ``` {.cpp}; TGeoVolume *vol = new TGeoVolumeAssembly(name);; vol->AddNode(vdaughter1, cpy1, matrix1);; vol->AddNode(vdaughter2, cpy2, matrix2);; ```. Note that components cannot be declared as ""overlapping"" and that a; component can be an assembly volume. For existing flat volume; structures, one can define assemblies to force a hierarchical structure; therefore optimizing the performance. Usage of assemblies does NOT imply; penalties in performance, but in some cases, it can be observed that it; is not as performing as bounding the structure in a container volume; with a simple shape. Choosing a normal container is therefore; recommended whenever possible. ![Assemblies of volumes](pictures/080001CF.png). ### Geometrical Transformations. All geometrical transformations handled by the modeller are provided as; a built-in package. This was designed to minimize memory requirements; and optimize performance of point/vector master-to-local and; local-to-master computation. We need to have in mind that a; transformation in **`TGeo`** has two major use-cases. The first one is; for defining the placement of a volume with respect to its container; reference frame. This frame will be called 'master' and the frame of the; positioned volume - 'local'. If `T` is a transformation used for; positioning volume daughters, then: `MASTER = T * LOCAL`. Therefore `T `is used to perform a local to master conversion, while; `T-1` for a master to local conversion. The second use case is the; computation of the global transformation of a given object in the; geometry. Since the geometry is built as 'volumes-inside-volumes', the; global transformation represents the pile-up of all local; transformations in the corresponding branch. Once a given object in the; hierarchy becomes the current one, the conversion from master to local; coordinates or the other way around can be done from the manager class. A g",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md:91160,optimiz,optimize,91160,documentation/users-guide/Geometry.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md,2,"['optimiz', 'perform']","['optimize', 'performance']"
Performance," *name*; exists; 0 otherwise. *name* should be of type *string*. ``!filter(``\ *var*\ ``,`` *list*\ ``,`` *predicate*\ ``)``. This operator creates a new ``list`` by filtering the elements in; *list*. To perform the filtering, TableGen binds the variable *var* to each; element and then evaluates the *predicate* expression, which presumably; refers to *var*. The predicate must; produce a boolean value (``bit``, ``bits``, or ``int``). The value is; interpreted as with ``!if``:; if the value is 0, the element is not included in the new list. If the value; is anything else, the element is included. ``!find(``\ *string1*\ ``,`` *string2*\ [``,`` *start*]\ ``)``; This operator searches for *string2* in *string1* and produces its; position. The starting position of the search may be specified by *start*,; which can range between 0 and the length of *string1*; the default is 0.; If the string is not found, the result is -1. ``!foldl(``\ *init*\ ``,`` *list*\ ``,`` *acc*\ ``,`` *var*\ ``,`` *expr*\ ``)``; This operator performs a left-fold over the items in *list*. The; variable *acc* acts as the accumulator and is initialized to *init*.; The variable *var* is bound to each element in the *list*. The; expression is evaluated for each element and presumably uses *acc* and; *var* to calculate the accumulated value, which ``!foldl`` stores back in; *acc*. The type of *acc* is the same as *init*; the type of *var* is the; same as the elements of *list*; *expr* must have the same type as *init*. The following example computes the total of the ``Number`` field in the; list of records in ``RecList``::. int x = !foldl(0, RecList, total, rec, !add(total, rec.Number));. If your goal is to filter the list and produce a new list that includes only; some of the elements, see ``!filter``. ``!foreach(``\ *var*\ ``,`` *sequence*\ ``,`` *expr*\ ``)``; This operator creates a new ``list``/``dag`` in which each element is a; function of the corresponding element in the *sequence* ``list``/``dag",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TableGen/ProgRef.rst:63934,perform,performs,63934,interpreter/llvm-project/llvm/docs/TableGen/ProgRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TableGen/ProgRef.rst,1,['perform'],['performs']
Performance, *none* - global - !volatile & !nontemporal; - generic; - private 1. buffer/global/flat_load; - constant; - !volatile & nontemporal. 1. buffer/global/flat_load; glc=1 slc=1. - volatile. 1. buffer/global/flat_load; glc=1; 2. s_waitcnt vmcnt(0). - Must happen before; any following volatile; global/generic; load/store.; - Ensures that; volatile; operations to; different; addresses will not; be reordered by; hardware. load *none* *none* - local 1. ds_load; store *none* *none* - global - !volatile & !nontemporal; - generic; - private 1. buffer/global/flat_store; - constant; - !volatile & nontemporal. 1. buffer/global/flat_store; glc=1 slc=1. - volatile. 1. buffer/global/flat_store; 2. s_waitcnt vmcnt(0). - Must happen before; any following volatile; global/generic; load/store.; - Ensures that; volatile; operations to; different; addresses will not; be reordered by; hardware. store *none* *none* - local 1. ds_store; **Unordered Atomic**; ------------------------------------------------------------------------------------; load atomic unordered *any* *any* *Same as non-atomic*.; store atomic unordered *any* *any* *Same as non-atomic*.; atomicrmw unordered *any* *any* *Same as monotonic atomic*.; **Monotonic Atomic**; ------------------------------------------------------------------------------------; load atomic monotonic - singlethread - global 1. buffer/global/ds/flat_load; - wavefront - local; - workgroup - generic; load atomic monotonic - agent - global 1. buffer/global/flat_load; - system - generic glc=1; store atomic monotonic - singlethread - global 1. buffer/global/flat_store; - wavefront - generic; - workgroup; - agent; - system; store atomic monotonic - singlethread - local 1. ds_store; - wavefront; - workgroup; atomicrmw monotonic - singlethread - global 1. buffer/global/flat_atomic; - wavefront - generic; - workgroup; - agent; - system; atomicrmw monotonic - singlethread - local 1. ds_atomic; - wavefront; - workgroup; **Acquire Atomic**; ----------------------,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:213061,load,load,213061,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['load']
Performance," *none* - global - !volatile & !nontemporal; - generic; - private 1. buffer/global/flat_load; - constant; - !volatile & nontemporal. 1. buffer/global/flat_load; glc=1 slc=1. - volatile. 1. buffer/global/flat_load; glc=1; 2. s_waitcnt vmcnt(0). - Must happen before; any following volatile; global/generic; load/store.; - Ensures that; volatile; operations to; different; addresses will not; be reordered by; hardware. load *none* *none* - local 1. ds_load; store *none* *none* - global - !volatile & !nontemporal; - generic; - private 1. buffer/global/flat_store; - constant; - !volatile & nontemporal. 1. buffer/global/flat_store; glc=1 slc=1. - volatile. 1. buffer/global/flat_store; 2. s_waitcnt vmcnt(0). - Must happen before; any following volatile; global/generic; load/store.; - Ensures that; volatile; operations to; different; addresses will not; be reordered by; hardware. store *none* *none* - local 1. ds_store; **Unordered Atomic**; ------------------------------------------------------------------------------------; load atomic unordered *any* *any* *Same as non-atomic*.; store atomic unordered *any* *any* *Same as non-atomic*.; atomicrmw unordered *any* *any* *Same as monotonic atomic*.; **Monotonic Atomic**; ------------------------------------------------------------------------------------; load atomic monotonic - singlethread - global 1. buffer/global/flat_load; - wavefront - generic; load atomic monotonic - workgroup - global 1. buffer/global/flat_load; - generic glc=1. - If not TgSplit execution; mode, omit glc=1. load atomic monotonic - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; - workgroup be used.*. 1. ds_load; load atomic monotonic - agent - global 1. buffer/global/flat_load; - generic glc=1; load atomic monotonic - system - global 1. buffer/global/flat_load; - generic glc=1; store atomic monotonic - singlethread - global 1. buffer/global/flat_store; - wavefront - generic; - workgroup; - agent; store atomic m",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:243549,load,load,243549,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['load']
Performance," *none* 1. s_waitcnt lgkmcnt(0) &; vmcnt(0) & vscnt(0). - If CU wavefront execution; mode, omit vmcnt(0) and; vscnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - If OpenCL and; address space is; local, omit; vmcnt(0) and vscnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate. If; fence had an; address space then; set to address; space of OpenCL; fence flag, or to; generic if both; local and global; flags are; specified.; - Could be split into; separate s_waitcnt; vmcnt(0), s_waitcnt; vscnt(0) and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/load; atomic/; atomicrmw-with-return-value.; - s_waitcnt vscnt(0); must happen after; any preceding; global/generic; store/store atomic/; atomicrmw-no-return-value.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store atomic/; atomicrmw.; - Must happen before; any following store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Ensures that all; memory operations; have; completed before; performing the; following; fence-paired-atomic. fence release - agent *none* 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0) & vscnt(0). - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - If OpenCL and; address space is; local, omit; vmcnt(0) and vscnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate. If; fence had an; address space then; set to address; space of OpenCL; fence flag, or to; generic if both; local and global; flags are; specified.; - Could be split into; separate s_waitcnt; vmcnt(0), s_waitcnt; vscnt(0) and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according t",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:361136,load,load,361136,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],['load']
Performance," *start = A.GetMatrixArray();; Double_t *rp1 = start+i*ncols;; const Double_t *rp2 = start+j*ncols;; while (rp1 < start+ncols) *rp1++ = *rp2++;; ```. Check that the columns of a Haar -matrix of order `order` are indeed; orthogonal:. ``` {.cpp}; const TMatrixD haar = THaarMatrixD(order);; TVectorD colj(1<<order);; TVectorD coll(1<<order);; for (Int_t j = haar.GetColLwb(); j <= haar.GetColUpb(); j++) {; colj = TMatrixDColumn_const(haar,j);; Assert(TMath::Abs(colj*colj-1.0) <= 1.0e-15);. for (Int_t l = j+1; l <= haar.GetColUpb(); l++) {; coll = TMatrixDColumn_const(haar,l);; Assert(TMath::Abs(colj*coll) <= 1.0e-15);; }; }; ```. Multiplying part of a matrix with another part of that matrix (they can overlap). ``` {.cpp}; TMatrixDSub(m,1,3,1,3) *= m.GetSub(5,7,5,7);; ```. ## Matrix Decompositions. The linear algebra package offers several classes to assist in matrix; decompositions. Each of the decomposition methods performs a set of; matrix transformations to facilitate solving a system of linear; equations, the formation of inverses as well as the estimation of; determinants and condition numbers. More specifically the classes; **`TDecompLU`**, **`TDecompBK`**, **`TDecompChol`**, **`TDecompQRH`** and; **`TDecompSVD`** give a simple and consistent interface to the LU,; Bunch-Kaufman, Cholesky, QR and SVD decompositions. All of these classes; are derived from the base class **`TDecompBase`** of which the important; methods are listed in next table:. +-----------------------------------------------------+--------------------------------------+; | Method | Action |; +-----------------------------------------------------+--------------------------------------+; | `Bool_t Decompose()` | perform the matrix decomposition |; +-----------------------------------------------------+--------------------------------------+; | `Double_t Condition()` | calculate ||*A*||1 ||*A*-1||1, |; | | see ""Condition number"" |; +-----------------------------------------------------+----------------",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/LinearAlgebra.md:33489,perform,performs,33489,documentation/users-guide/LinearAlgebra.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/LinearAlgebra.md,1,['perform'],['performs']
Performance," *uOps Per Cycle* is bounded from above by the dispatch width. That is; because the dispatch width limits the maximum size of a dispatch group. Both IPC; and 'uOps Per Cycle' are limited by the amount of hardware parallelism. The; availability of hardware resources affects the resource pressure distribution,; and it limits the number of instructions that can be executed in parallel every; cycle. A delta between Dispatch Width and the theoretical maximum uOps per; Cycle (computed by dividing the number of uOps of a single iteration by the; `Block RThroughput`) is an indicator of a performance bottleneck caused by the; lack of hardware resources.; In general, the lower the Block RThroughput, the better. In this example, ``uOps per iteration/Block RThroughput`` is 1.50. Since there; are no loop-carried dependencies, the observed `uOps Per Cycle` is expected to; approach 1.50 when the number of iterations tends to infinity. The delta between; the Dispatch Width (2.00), and the theoretical maximum uOp throughput (1.50) is; an indicator of a performance bottleneck caused by the lack of hardware; resources, and the *Resource pressure view* can help to identify the problematic; resource usage. The second section of the report is the `instruction info view`. It shows the; latency and reciprocal throughput of every instruction in the sequence. It also; reports extra information related to the number of micro opcodes, and opcode; properties (i.e., 'MayLoad', 'MayStore', and 'HasSideEffects'). Field *RThroughput* is the reciprocal of the instruction throughput. Throughput; is computed as the maximum number of instructions of a same type that can be; executed per clock cycle in the absence of operand dependencies. In this; example, the reciprocal throughput of a vector float multiply is 1; cycles/instruction. That is because the FP multiplier JFPM is only available; from pipeline JFPU1. Instruction encodings are displayed within the instruction info view when flag; `-show-encodin",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:18318,throughput,throughput,18318,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,1,['throughput'],['throughput']
Performance," *‘No drawing'* sets On/Off the option ""`0`""- do not draw the fit; results. *‘Do not store/draw'* sets On/Off option ""`N`""- do not store the; function and do not draw it. ### Advances Options. The advance option button is enabled only after having performed the fit and provides; additional drawing options that can be used after having done the fit. These new drawing tools,; which can be selected by the ""Advanced Drawing Tool"" panel that pops up when clicking the ""Advanced"" button, are:. * *Contour*: to plot the confidence contour of two chosen parameters. One can select the number of points to draw the contour; (more points might require more time to compute it), the parameters and the desired confidence level . * *Scan* : to plot a scan of the minimization function (likelihood or chi-squared) around the minimum as function of the chosen parameter. * *Conf Interval* : to plot the confidence interval of the fitted function as a filled coloured band around its central value.; One can select the desired confidence level for the band to be plotted. ### Print Options. This set of options specifies the amount of feedback printed on the; root command line after performed fits. *‘Verbose'* - prints fit results after each iteration. *‘Quiet'* - no fit information is printed. *‘Default'* - between Verbose and Quiet. ### Command Buttons. *Fit button* - performs a fit taking different option settings via the; Fit Panel interface. *Reset* - sets the GUI elements and related fit settings to the; default ones. *Close* - closes the Fit panel window. ### Minimization Options. With this tab one can select specific options for minimization. These include. * The minimizer library ( *Minuit*, *Minuit2*, *Fumili*, *GSL*, *Genetics* ); * The method (algorithm) for minimization. For example for Minuit one can choose between (*Migrad*, *Simplex* or *Scan*); * Error definition; * Minimization tolerance; * Number of iterations/function calls; * Print Level: (*Default*, *Verbose* or *Quiet*). ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/gui/fitpanel/doc/index.md:5436,perform,performed,5436,gui/fitpanel/doc/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/gui/fitpanel/doc/index.md,2,['perform'],"['performed', 'performs']"
Performance," +-------------------------------+-------------------------------+---------------------+; | | ``LDR`` layout | ``LD1`` layout |; +===============================+===============================+=====================+; | Lane ordering | ``LDR + REV`` | ``LD1`` |; +-------------------------------+-------------------------------+---------------------+; | AAPCS | ``LDR`` | ``LD1 + REV`` |; +-------------------------------+-------------------------------+---------------------+; | Alignment for strict mode | ``LDR`` / ``LD1 + REV`` | ``LD1`` |; +-------------------------------+-------------------------------+---------------------+. Neither approach is perfect, and choosing one boils down to choosing the lesser of two evils. The issue with lane ordering, it was decided, would have to change target-agnostic compiler passes and would result in a strange IR in which lane indices were reversed. It was decided that this was worse than the changes that would have to be made to support ``LD1``, so ``LD1`` was chosen as the canonical vector load instruction (and by inference, ``ST1`` for vector stores). Implementation; ==============. There are 3 parts to the implementation:. 1. Predicate ``LDR`` and ``STR`` instructions so that they are never allowed to be selected to generate vector loads and stores. The exception is one-lane vectors [1]_ - these by definition cannot have lane ordering problems so are fine to use ``LDR``/``STR``. 2. Create code generation patterns for bitconverts that create ``REV`` instructions. 3. Make sure appropriate bitconverts are created so that vector values get passed over call boundaries as 1-element vectors (which is the same as if they were loaded with ``LDR``). Bitconverts; -----------. .. image:: ARM-BE-bitcastfail.png; :align: right. The main problem with the ``LD1`` solution is dealing with bitconverts (or bitcasts, or reinterpret casts). These are pseudo instructions that only change the compiler's interpretation of data, not the underlying data ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BigEndianNEON.rst:9090,load,load,9090,interpreter/llvm-project/llvm/docs/BigEndianNEON.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BigEndianNEON.rst,1,['load'],['load']
Performance," - If OpenCL omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the flat_load; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - singlethread - global 1. buffer/global/ds/flat_atomic; - wavefront - local; - generic; atomicrmw acquire - workgroup - global 1. buffer/global_atomic; atomicrmw acquire - workgroup - local 1. ds/flat_atomic; - generic 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local; atomicrmw value; being acquired. atomicrmw acquire - agent - global 1. buffer/global_atomic; - system 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - agent - generic 1. flat_atomic; - system 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. fence acquire - singlethread *none* *none*; - wavefront; fence acquire - workgroup *none* 1. s_waitcnt lgkmcnt(0). - If OpenCL and; address space is; not generic, omit.; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate. If; fence had an; address space then; set to address; space of OpenCL; fence fla",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:216110,cache,cache,216110,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['cache'],['cache']
Performance," - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global and L2 writeback; have completed before; performing the; atomicrmw that is; being released. 3. flat_atomic sc1=1; 4. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_inv.; - Ensures the; atomicrmw has; completed before; invalidating the; caches. 5. buffer_inv sc0=1 sc1=1. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; MTYPE NC global data.; MTYPE RW and CC memory will; never be stale due to the; memory probes. fence acq_rel - singlethread *none* *none*; - wavefront; fence acq_rel - workgroup *none* 1. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - If OpenCL and; address space is; local, omit; vmcnt(0).; - However,; since LLVM; currently has no; address space on; the fence need to; conservatively; always generate; (see comment for; previous fence).; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Must happen before; any following; global/generic; load/load; atomic/store/sto",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:324712,load,load,324712,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],['load']
Performance," - generic sc1=1; atomicrmw monotonic - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; - workgroup be used.*. 1. ds_atomic; **Acquire Atomic**; ------------------------------------------------------------------------------------; load atomic acquire - singlethread - global 1. buffer/global/ds/flat_load; - wavefront - local; - generic; load atomic acquire - workgroup - global 1. buffer/global_load sc0=1; 2. s_waitcnt vmcnt(0). - If not TgSplit execution; mode, omit.; - Must happen before the; following buffer_inv. 3. buffer_inv sc0=1. - If not TgSplit execution; mode, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale data. load atomic acquire - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_load; 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than the local load; atomic value being; acquired. load atomic acquire - workgroup - generic 1. flat_load sc0=1; 2. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit lgkmcnt(0).; - Must happen before; the following; buffer_inv and any; following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic value being; acquired. 3. buffer_inv sc0=1. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. load atomic acquire - agent - global 1. buffer/global_load; sc1=1; 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_inv.; - Ensures the load; has completed; before invalidating; the cache. 3. buffer_inv sc1=1. - Must happen before; any following; global/g",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:296280,load,load,296280,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],['load']
Performance," - local 1. ds/flat_atomic; - generic 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local; atomicrmw value; being acquired. atomicrmw acquire - agent - global 1. buffer/global_atomic; - system 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - agent - generic 1. flat_atomic; - system 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. fence acquire - singlethread *none* *none*; - wavefront; fence acquire - workgroup *none* 1. s_waitcnt lgkmcnt(0). - If OpenCL and; address space is; not generic, omit.; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate. If; fence had an; address space then; set to address; space of OpenCL; fence flag, or to; generic if both; local and global; flags are; specified.; - Must happen after; any preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than the; value read by the; fence-paired-atomic. fence acquire - agent *none* 1. s_waitcnt lgkmcnt(0)",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:216622,load,load,216622,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],['load']
Performance," - this gives you; dereferencability information. In MCJIT, use getSymbolAddress to provide; actual address. #. Be wary of ordered and atomic memory operations. They are hard to optimize; and may not be well optimized by the current optimizer. Depending on your; source language, you may consider using fences instead. #. If calling a function which is known to throw an exception (unwind), use; an invoke with a normal destination which contains an unreachable; instruction. This form conveys to the optimizer that the call returns; abnormally. For an invoke which neither returns normally or requires unwind; code in the current function, you can use a noreturn call instruction if; desired. This is generally not required because the optimizer will convert; an invoke with an unreachable unwind destination to a call instruction. #. Use profile metadata to indicate statically known cold paths, even if; dynamic profiling information is not available. This can make a large; difference in code placement and thus the performance of tight loops. #. When generating code for loops, try to avoid terminating the header block of; the loop earlier than necessary. If the terminator of the loop header; block is a loop exiting conditional branch, the effectiveness of LICM will; be limited for loads not in the header. (This is due to the fact that LLVM; may not know such a load is safe to speculatively execute and thus can't; lift an otherwise loop invariant load unless it can prove the exiting; condition is not taken.) It can be profitable, in some cases, to emit such; instructions into the header even if they are not used along a rarely; executed path that exits the loop. This guidance specifically does not; apply if the condition which terminates the loop header is itself invariant,; or can be easily discharged by inspecting the loop index variables. #. In hot loops, consider duplicating instructions from small basic blocks; which end in highly predictable terminators into their successo",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:7199,perform,performance,7199,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,1,['perform'],['performance']
Performance," ---------------------------------------. LLVM provides intrinsics for predicated vector load and store operations. The predicate is specified by a mask operand, which holds one bit per vector element, switching the associated vector lane on or off. The memory addresses corresponding to the ""off"" lanes are not accessed. When all bits of the mask are on, the intrinsic is identical to a regular vector load or store. When all bits are off, no memory is accessed. .. _int_mload:. '``llvm.masked.load.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. The loaded data is a vector of any integer, floating-point or pointer data type. ::. declare <16 x float> @llvm.masked.load.v16f32.p0(ptr <ptr>, i32 <alignment>, <16 x i1> <mask>, <16 x float> <passthru>); declare <2 x double> @llvm.masked.load.v2f64.p0(ptr <ptr>, i32 <alignment>, <2 x i1> <mask>, <2 x double> <passthru>); ;; The data is a vector of pointers; declare <8 x ptr> @llvm.masked.load.v8p0.p0(ptr <ptr>, i32 <alignment>, <8 x i1> <mask>, <8 x ptr> <passthru>). Overview:; """""""""""""""""". Reads a vector from memory according to the provided mask. The mask holds a bit for each vector lane, and is used to prevent memory accesses to the masked-off lanes. The masked-off lanes in the result vector are taken from the corresponding lanes of the '``passthru``' operand. Arguments:; """""""""""""""""""". The first operand is the base pointer for the load. The second operand is the alignment of the source location. It must be a power of two constant integer value. The third operand, mask, is a vector of boolean values with the same number of elements as the return type. The fourth is a pass-through value that is used to fill the masked-off lanes of the result. The return type, underlying type of the base pointer and the type of the '``passthru``' operand are the same vector types. Semantics:; """""""""""""""""""". The '``llvm.masked.load``' intrinsic is designed for conditional reading of selected vect",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:843648,load,load,843648,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['load'],['load']
Performance," ---------------. The following options exist in RNTuple for multithreaded data processing. ### Implicit Multi-Threading; When `ROOT::EnableImplicitMT()` is used, RNTuple uses ROOT's task arena to compress and decompress pages.; That requires writes to be buffered and reads uses the cluster pool resp.; The RNTuple data source for RDataFrame lets RDataFrame full control of the thread pool.; That means that RDataFrame uses a separate data source for every thread, each of the data sources runs in sequential mode. ### Concurrent Readers; Multiple readers can read the same RNTuple concurrently as long as access to every individual reader is sequential. ### Parallel REntry Preparation; Multiple `REntry` object can be concurrently prepared by multiple threads.; I.e., construction and binding of the objects can happen in parallel.; The actual reading and writing of entries (`RNTupleReader::LoadEntry()`, `RNTupleWriter::Fill()`) needs to be protected by a mutex.; This is considered ""mild scalability parallelization"" in RNTuple. ### RNTupleParallelWriter; The parallel writer offers the most scalable parallel writing interface.; Multiple _fill contexts_ can concurrently serialize and compress data.; Every fill context prepares a set of entire clusters in the final on-disk layout.; When a fill context flushes data,; a brief serialization point handles the RNTuple meta-data updates and the reservation of disk space to write into. Low precision float types; --------------------------; RNTuple supports encoding floating point types with a lower precision when writing them to disk. This encoding is specified by the; user per field and it is independent on the in-memory type used for that field (meaning both a `RField<double>` or `RField<float>` can; be mapped to e.g. a low-precision 16 bit float). RNTuple supports the following encodings (all mutually exclusive):. - **Real16**/**SplitReal16**: IEEE-754 half precision float. Set by calling `RField::SetHalfPrecision()`;; - **Real32Tru",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md:25380,scalab,scalability,25380,tree/ntuple/v7/doc/Architecture.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md,1,['scalab'],['scalability']
Performance," -> target-specific intrinsic by overriding; ``shouldExpandAtomicRMWInIR``, ``emitMaskedAtomicRMWIntrinsic``,; ``shouldExpandAtomicCmpXchgInIR``, and ``emitMaskedAtomicCmpXchgIntrinsic``. For an example of these look at the ARM (first five lowerings) or RISC-V (last; lowering) backend. AtomicExpandPass supports two strategies for lowering atomicrmw/cmpxchg to; load-linked/store-conditional (LL/SC) loops. The first expands the LL/SC loop; in IR, calling target lowering hooks to emit intrinsics for the LL and SC; operations. However, many architectures have strict requirements for LL/SC; loops to ensure forward progress, such as restrictions on the number and type; of instructions in the loop. It isn't possible to enforce these restrictions; when the loop is expanded in LLVM IR, and so affected targets may prefer to; expand to LL/SC loops at a very late stage (i.e. after register allocation).; AtomicExpandPass can help support lowering of part-word atomicrmw or cmpxchg; using this strategy by producing IR for any shifting and masking that can be; performed outside of the LL/SC loop. Libcalls: __atomic_*; ====================. There are two kinds of atomic library calls that are generated by LLVM. Please; note that both sets of library functions somewhat confusingly share the names of; builtin functions defined by clang. Despite this, the library functions are; not directly related to the builtins: it is *not* the case that ``__atomic_*``; builtins lower to ``__atomic_*`` library calls and ``__sync_*`` builtins lower; to ``__sync_*`` library calls. The first set of library functions are named ``__atomic_*``. This set has been; ""standardized"" by GCC, and is described below. (See also `GCC's documentation; <https://gcc.gnu.org/wiki/Atomic/GCCMM/LIbrary>`_). LLVM's AtomicExpandPass will translate atomic operations on data sizes above; ``MaxAtomicSizeInBitsSupported`` into calls to these functions. There are four generic functions, which can be called with data of any size",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Atomics.rst:22579,perform,performed,22579,interpreter/llvm-project/llvm/docs/Atomics.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Atomics.rst,1,['perform'],['performed']
Performance," -O3 - Enable expensive optimizations; -debug_level - Set the debugging level:; =none - disable debug information; =quick - enable quick debug information; =detailed - enable detailed debug information; -f - Enable binary output on terminals; -help - display available options (-help-hidden for more); -o <filename> - Specify output filename; -quiet - Don't print informational messages. Again, the only structural difference between the debug level declaration and; the optimization level declaration is that the debug level declaration includes; an option name (``""debug_level""``), which automatically changes how the library; processes the argument. The CommandLine library supports both forms so that you; can choose the form most appropriate for your application. .. _lists:. Parsing a list of options; -------------------------. Now that we have the standard run-of-the-mill argument types out of the way,; lets get a little wild and crazy. Lets say that we want our optimizer to accept; a **list** of optimizations to perform, allowing duplicates. For example, we; might want to run: ""``compiler -dce -instsimplify -inline -dce -strip``"". In this; case, the order of the arguments and the number of appearances is very; important. This is what the ""``cl::list``"" template is for. First, start by; defining an enum of the optimizations that you would like to perform:. .. code-block:: c++. enum Opts {; // 'inline' is a C++ keyword, so name it 'inlining'; dce, instsimplify, inlining, strip; };. Then define your ""``cl::list``"" variable:. .. code-block:: c++. cl::list<Opts> OptimizationList(cl::desc(""Available Optimizations:""),; cl::values(; clEnumVal(dce , ""Dead Code Elimination""),; clEnumVal(instsimplify , ""Instruction Simplification""),; clEnumValN(inlining, ""inline"", ""Procedure Integration""),; clEnumVal(strip , ""Strip Symbols"")));. This defines a variable that is conceptually of the type; ""``std::vector<enum Opts>``"". Thus, you can access it with standard vector; methods:. .. code-b",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:19259,optimiz,optimizer,19259,interpreter/llvm-project/llvm/docs/CommandLine.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst,3,"['optimiz', 'perform']","['optimizations', 'optimizer', 'perform']"
Performance," -arch i386 -arch x86_64 t0.c t1.c; 0: input, ""t0.c"", c; 1: preprocessor, {0}, cpp-output; 2: compiler, {1}, assembler; 3: assembler, {2}, object; 4: bind-arch, ""i386"", {3}, object; 5: bind-arch, ""x86_64"", {3}, object; 6: lipo, {4, 5}, object; 7: input, ""t1.c"", c; 8: preprocessor, {7}, cpp-output; 9: compiler, {8}, assembler; 10: assembler, {9}, object; 11: bind-arch, ""i386"", {10}, object; 12: bind-arch, ""x86_64"", {10}, object; 13: lipo, {11, 12}, object. After this stage is complete the compilation process is divided into; a simple set of actions which need to be performed to produce; intermediate or final outputs (in some cases, like ``-fsyntax-only``,; there is no ""real"" final output). Phases are well known compilation; steps, such as ""preprocess"", ""compile"", ""assemble"", ""link"", etc. #. **Bind: Tool & Filename Selection**. This stage (in conjunction with the Translate stage) turns the tree; of Actions into a list of actual subprocess to run. Conceptually, the; driver performs a top down matching to assign Action(s) to Tools. The; ToolChain is responsible for selecting the tool to perform a; particular action; once selected the driver interacts with the tool; to see if it can match additional actions (for example, by having an; integrated preprocessor). Once Tools have been selected for all actions, the driver determines; how the tools should be connected (for example, using an inprocess; module, pipes, temporary files, or user provided filenames). If an; output file is required, the driver also computes the appropriate; file name (the suffix and file location depend on the input types and; options such as ``-save-temps``). The driver interacts with a ToolChain to perform the Tool bindings.; Each ToolChain contains information about all the tools needed for; compilation for a particular architecture, platform, and operating; system. A single driver invocation may query multiple ToolChains; during one compilation in order to interact with tools for separate; archite",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DriverInternals.rst:8672,perform,performs,8672,interpreter/llvm-project/clang/docs/DriverInternals.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DriverInternals.rst,1,['perform'],['performs']
Performance," -debug-only=foo; 'foo' debug type; $ opt < a.bc > /dev/null -mypass -debug-only=bar; 'bar' debug type; $ opt < a.bc > /dev/null -mypass -debug-only=foo,bar; 'foo' debug type; 'bar' debug type. Of course, in practice, you should only set ``DEBUG_TYPE`` at the top of a file,; to specify the debug type for the entire module. Be careful that you only do; this after including Debug.h and not around any #include of headers. Also, you; should use names more meaningful than ""foo"" and ""bar"", because there is no; system in place to ensure that names do not conflict. If two different modules; use the same string, they will all be turned on when the name is specified.; This allows, for example, all debug information for instruction scheduling to be; enabled with ``-debug-only=InstrSched``, even if the source lives in multiple; files. The name must not include a comma (,) as that is used to separate the; arguments of the ``-debug-only`` option. For performance reasons, -debug-only is not available in optimized build; (``--enable-optimized``) of LLVM. The ``DEBUG_WITH_TYPE`` macro is also available for situations where you would; like to set ``DEBUG_TYPE``, but only for one specific ``DEBUG`` statement. It; takes an additional first parameter, which is the type to use. For example, the; preceding example could be written as:. .. code-block:: c++. DEBUG_WITH_TYPE(""foo"", dbgs() << ""'foo' debug type\n"");; DEBUG_WITH_TYPE(""bar"", dbgs() << ""'bar' debug type\n"");. .. _Statistic:. The ``Statistic`` class & ``-stats`` option; -------------------------------------------. The ``llvm/ADT/Statistic.h`` (`doxygen; <https://llvm.org/doxygen/Statistic_8h_source.html>`__) file provides a class; named ``Statistic`` that is used as a unified way to keep track of what the LLVM; compiler is doing and how effective various optimizations are. It is useful to; see what optimizations are contributing to making a particular program run; faster. Often you may run your pass on some big program, and you're",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:45690,perform,performance,45690,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,3,"['optimiz', 'perform']","['optimized', 'performance']"
Performance," -emit-obj use.c -fmodules -fimplicit-module-maps -fmodules-cache-path=prebuilt -fdisable-module-hash; ls prebuilt/*.pcm; # prebuilt/A.pcm prebuilt/B.pcm. Note that with explicit or prebuilt modules, we are responsible for, and should be particularly careful about the compatibility of our modules.; Using mismatching compilation options and modules may lead to issues. .. code-block:: sh. clang -cc1 -emit-obj use.c -fmodules -fimplicit-module-maps -fprebuilt-module-path=prebuilt -DENABLE_A; # use.c:4:10: warning: implicit declaration of function 'a' is invalid in C99 [-Wimplicit-function-declaration]; # return a(x);; # ^; # 1 warning generated. So we need to maintain multiple versions of prebuilt modules. We can do so using a manual module mapping, or pointing to a different prebuilt module cache path. For example:. .. code-block:: sh. rm -rf prebuilt ; mkdir prebuilt ; rm -rf prebuilt_a ; mkdir prebuilt_a; clang -cc1 -emit-obj use.c -fmodules -fimplicit-module-maps -fmodules-cache-path=prebuilt -fdisable-module-hash; clang -cc1 -emit-obj use.c -fmodules -fimplicit-module-maps -fmodules-cache-path=prebuilt_a -fdisable-module-hash -DENABLE_A; clang -cc1 -emit-obj use.c -fmodules -fimplicit-module-maps -fprebuilt-module-path=prebuilt; clang -cc1 -emit-obj use.c -fmodules -fimplicit-module-maps -fprebuilt-module-path=prebuilt_a -DENABLE_A. Instead of managing the different module versions manually, we can build implicit modules in a given cache path (using ``-fmodules-cache-path``), and reuse them as prebuilt implicit modules by passing ``-fprebuilt-module-path`` and ``-fprebuilt-implicit-modules``. .. code-block:: sh. rm -rf prebuilt; mkdir prebuilt; clang -cc1 -emit-obj -o use.o use.c -fmodules -fimplicit-module-maps -fmodules-cache-path=prebuilt; clang -cc1 -emit-obj -o use.o use.c -fmodules -fimplicit-module-maps -fmodules-cache-path=prebuilt -DENABLE_A; find prebuilt -name ""*.pcm""; # prebuilt/1AYBIGPM8R2GA/A-3L1K4LUA6O31.pcm; # prebuilt/1AYBIGPM8R2GA/B-3L1K4LUA6O31.p",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Modules.rst:21777,cache,cache-path,21777,interpreter/llvm-project/clang/docs/Modules.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Modules.rst,1,['cache'],['cache-path']
Performance," -fprofile-exclude-files=""^/usr/include/.*$"" \; -fprofile-filter-files=""^/usr/.*$"". In that case ``/usr/foo/oof.h`` is instrumented since it matches the filter regex and; doesn't match the exclude regex, but ``/usr/include/foo.h`` doesn't since it matches; the exclude regex. Controlling Debug Information; -----------------------------. Controlling Size of Debug Information; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Debug info kind generated by Clang can be set by one of the flags listed; below. If multiple flags are present, the last one is used. .. option:: -g0. Don't generate any debug info (default). .. option:: -gline-tables-only. Generate line number tables only. This kind of debug info allows to obtain stack traces with function names,; file names and line numbers (by such tools as ``gdb`` or ``addr2line``). It; doesn't contain any other data (e.g. description of local variables or; function parameters). .. option:: -fstandalone-debug. Clang supports a number of optimizations to reduce the size of debug; information in the binary. They work based on the assumption that; the debug type information can be spread out over multiple; compilation units. Specifically, the optimizations are:. - will not emit type definitions for types that are not needed by a; module and could be replaced with a forward declaration.; - will only emit type info for a dynamic C++ class in the module that; contains the vtable for the class.; - will only emit type info for a C++ class (non-trivial, non-aggregate); in the modules that contain a definition for one of its constructors.; - will only emit type definitions for types that are the subject of explicit; template instantiation declarations in the presence of an explicit; instantiation definition for the type. The **-fstandalone-debug** option turns off these optimizations.; This is useful when working with 3rd-party libraries that don't come; with debug information. Note that Clang will never emit type; information for types that are no",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:124977,optimiz,optimizations,124977,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,1,['optimiz'],['optimizations']
Performance," . TMVA. TMVA version 4.1.0 is included in this root release. The most; important new feature is the support for simulataneous classification ; of multiple output classes for several multi-variate methods. ; A lot of effort went into consolidation of the software,; i.e. method performance and robustness, and framework; stability. The changes with respect to ROOT 5.27 / TMVA 4.0.7 are; in detail:. Framework. Multi-class support. The support of multiple; output classes (i.e., more than a single background and signal; class) has been enabled for these methods: MLP (NN), BDTG,; FDA.; The multiclass; functionality can be enabled with the Factory option; ""AnalysisType=multiclass"". Training data is; specified with an additional classname, e.g. via; factory->AddTree(tree,""classname"");. After the; training a genetic algorithm is invoked to determine the best; cuts for selecting a specific class, based on the figure of; merit: purity*efficiency. TMVA comes with two examples in; $ROOTSYS/tmva/test: TMVAMulticlass.C; and TMVAMulticlassApplication.C. New TMVA event vector building. The code; for splitting the input data into training and test samples for; all classes and the mixing of those samples to one training and; one test sample has been rewritten completely. The new code is; more performant and has a clearer structure. This fixes several; bugs which have been reported by some users of TMVA.; Code and performance test framework: A unit; test framework for daily software and method performance; validation has been implemented.; . Methods. BDT Automatic parameter optimisation for building the; tree architecture: The optimisation procedure uses the; performance of the trained classifier on the ""test sample"" for; finding the set of optimal parameters. Two different methods to; traverse the parameter space are available (scanning, genetic; algorithm). Currently parameter optimization is implemented only; for these three parameters that influence the tree architectur:; the maximu",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v528/index.html:278,perform,performance,278,tmva/doc/v528/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v528/index.html,2,['perform'],['performance']
Performance," . TMVA; ; This version corresponds to TMVA version 3.9.5.; ; . New; reference page for configuration options The; page is automatically generated for each new release. Next to; the classifiers also exist information links for hints to; improve the classifier performance (click on the ""i""; button). Many thanks to Zhiyi Liu (Fraser U) for suggesting; this.; ; Methods:. BDT: New Decision Tree Pruning algorithm: Cost; Complexity Pruning a la CART. Written by Doug Schouten; (Fraser U.). It replaces the old CostComplexity and; CostComplexity2 algorithms.; . BDT: New no splitting option (choosable with; NCuts<0) that finds best split point by first sorting the; events for each variable and then looping through all; events, placing the cuts always in the middle between two; of the sorted events, and finding the true possible; maximum separation gain in the training sample by cutting; on this variable.; . BDT, AdaBoost The beta parameter is now an; option (default is 1).; . BDT: The node purity at which a node is; classified as signal (respective background node) for; determining the error fraction in the pruning became a; parameter that can be set via the option NodePurityLimit; (default is 0.5).; . Dataset preparation:. First implementation of a new preprocessing method: transformation of the; variables first into a Gaussian distribution, then performing a decorrelation of; the ""Gaussianised"" variables. The transformation is again done by default such that; (by default) the signal distributions become Gaussian and are decorrelated. Note ; that simultaneous Gaussianisation and decorrelation of signal and background is ; only possible (and done) for methods, such as Likelihood, which test both hypotheses.; . Bug fixes:. Fix in Expected error pruning: Rather than multiplying both sides, the error on ; the node and the sub-tree, with the prune strength, now only the expected error ; of the sub-tree is scaled.; . Fix in FDA parsing of the input formula. There were problems when",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v522/index.html:260,perform,performance,260,tmva/doc/v522/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v522/index.html,2,['perform'],['performance']
Performance," .. code::. <bundle-entry-id> ::== <offload-kind> ""-"" <target-triple> [ ""-"" <target-id> ]. Where:. **offload-kind**; The runtime responsible for managing the bundled entry code object. See; :ref:`clang-offload-kind-table`. .. table:: Bundled Code Object Offload Kind; :name: clang-offload-kind-table. ============= ==============================================================; Offload Kind Description; ============= ==============================================================; host Host code object. ``clang-offload-bundler`` always includes; this entry as the first bundled code object entry. For an; embedded bundled code object this entry is not used by the; runtime and so is generally an empty code object. hip Offload code object for the HIP language. Used for all; HIP language offload code objects when the; ``clang-offload-bundler`` is used to bundle code objects as; intermediate steps of the tool chain. Also used for AMD GPU; code objects before ABI version V4 when the; ``clang-offload-bundler`` is used to create a *fat binary*; to be loaded by the HIP runtime. The fat binary can be; loaded directly from a file, or be embedded in the host code; object as a data section with the name ``.hip_fatbin``. hipv4 Offload code object for the HIP language. Used for AMD GPU; code objects with at least ABI version V4 when the; ``clang-offload-bundler`` is used to create a *fat binary*; to be loaded by the HIP runtime. The fat binary can be; loaded directly from a file, or be embedded in the host code; object as a data section with the name ``.hip_fatbin``. openmp Offload code object for the OpenMP language extension.; ============= ==============================================================. **target-triple**; The target triple of the code object. See `Target Triple; <https://clang.llvm.org/docs/CrossCompilation.html#target-triple>`_. The bundler accepts target triples with or without the optional environment; field:. ``<arch><sub>-<vendor>-<sys>``, or; ``<arch><sub>-<ven",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangOffloadBundler.rst:8746,load,loaded,8746,interpreter/llvm-project/clang/docs/ClangOffloadBundler.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangOffloadBundler.rst,1,['load'],['loaded']
Performance," .. option:: --num-repetitions=<Number of repetitions>. Specify the target number of executed instructions. Note that the actual; repetition count of the snippet will be `num-repetitions`/`snippet size`.; Higher values lead to more accurate measurements but lengthen the benchmark. .. option:: --loop-body-size=<Preferred loop body size>. Only effective for `-repetition-mode=[loop|min]`.; Instead of looping over the snippet directly, first duplicate it so that the; loop body contains at least this many instructions. This potentially results; in loop body being cached in the CPU Op Cache / Loop Cache, which allows to; which may have higher throughput than the CPU decoders. .. option:: --max-configs-per-opcode=<value>. Specify the maximum configurations that can be generated for each opcode.; By default this is `1`, meaning that we assume that a single measurement is; enough to characterize an opcode. This might not be true of all instructions:; for example, the performance characteristics of the LEA instruction on X86; depends on the value of assigned registers and immediates. Setting a value of; `-max-configs-per-opcode` larger than `1` allows `llvm-exegesis` to explore; more configurations to discover if some register or immediate assignments; lead to different performance characteristics. .. option:: --benchmarks-file=</path/to/file>. File to read (`analysis` mode) or write (`latency`/`uops`/`inverse_throughput`; modes) benchmark results. ""-"" uses stdin/stdout. .. option:: --analysis-clusters-output-file=</path/to/file>. If provided, write the analysis clusters as CSV to this file. ""-"" prints to; stdout. By default, this analysis is not run. .. option:: --analysis-inconsistencies-output-file=</path/to/file>. If non-empty, write inconsistencies found during analysis to this file. `-`; prints to stdout. By default, this analysis is not run. .. option:: --analysis-filter=[all|reg-only|mem-only]. By default, all benchmark results are analysed, but sometimes it may be us",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-exegesis.rst:14133,perform,performance,14133,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-exegesis.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-exegesis.rst,1,['perform'],['performance']
Performance," .. option:: -foptimization-record-file. Control the file to which optimization reports are written. This implies; :ref:`-fsave-optimization-record <opt_fsave-optimization-record>`. On Darwin platforms, this is incompatible with passing multiple; ``-arch <arch>`` options. .. option:: -foptimization-record-passes. Only include passes which match a specified regular expression. When optimization reports are being output (see; :ref:`-fsave-optimization-record <opt_fsave-optimization-record>`), this; option controls the passes that will be included in the final report. If this option is not used, all the passes are included in the optimization; record. .. _opt_fdiagnostics-show-hotness:. .. option:: -f[no-]diagnostics-show-hotness. Enable profile hotness information in diagnostic line. This option controls whether Clang prints the profile hotness associated; with diagnostics in the presence of profile-guided optimization information.; This is currently supported with optimization remarks (see; :ref:`Options to Emit Optimization Reports <rpass>`). The hotness information; allows users to focus on the hot optimization remarks that are likely to be; more relevant for run-time performance. For example, in this output, the block containing the callsite of `foo` was; executed 3000 times according to the profile data:. ::. s.c:7:10: remark: foo inlined into bar (hotness: 3000) [-Rpass-analysis=inline]; sum += foo(x, x - 2);; ^. This option is implied when; :ref:`-fsave-optimization-record <opt_fsave-optimization-record>` is used.; Otherwise, it defaults to off. .. option:: -fdiagnostics-hotness-threshold. Prevent optimization remarks from being output if they do not have at least; this hotness value. This option, which defaults to zero, controls the minimum hotness an; optimization remark would need in order to be output by Clang. This is; currently supported with optimization remarks (see :ref:`Options to Emit; Optimization Reports <rpass>`) when profile hotness information in",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:14052,optimiz,optimization,14052,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,1,['optimiz'],['optimization']
Performance," .. option:: -mcpu=<cpuname>. Specify a specific chip in the current architecture to generate code for.; By default this is inferred from the target triple and autodetected to; the current architecture. For a list of available CPUs, use:. .. code-block:: none. llvm-as < /dev/null | llc -march=xyz -mcpu=help. .. option:: -filetype=<output file type>. Specify what kind of output ``llc`` should generated. Options are: ``asm``; for textual assembly ( ``'.s'``), ``obj`` for native object files (``'.o'``); and ``null`` for not emitting anything (for performance testing). Note that not all targets support all options. .. option:: -mattr=a1,+a2,-a3,... Override or control specific attributes of the target, such as whether SIMD; operations are enabled or not. The default set of attributes is set by the; current CPU. For a list of available attributes, use:. .. code-block:: none. llvm-as < /dev/null | llc -march=xyz -mattr=help. .. option:: --frame-pointer. Specify effect of frame pointer elimination optimization (all,non-leaf,none). .. option:: --disable-excess-fp-precision. Disable optimizations that may produce excess precision for floating point.; Note that this option can dramatically slow down code on some systems; (e.g. X86). .. option:: --enable-no-infs-fp-math. Enable optimizations that assume no Inf values. .. option:: --enable-no-nans-fp-math. Enable optimizations that assume no NAN values. .. option:: --enable-no-signed-zeros-fp-math. Enable FP math optimizations that assume the sign of 0 is insignificant. .. option:: --enable-no-trapping-fp-math. Enable setting the FP exceptions build attribute not to use exceptions. .. option:: --enable-unsafe-fp-math. Enable optimizations that make unsafe assumptions about IEEE math (e.g. that; addition is associative) or may not work for all input ranges. These; optimizations allow the code generator to make use of some instructions which; would otherwise not be usable (such as ``fsin`` on X86). .. option:: --stats. Print stat",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llc.rst:3154,optimiz,optimization,3154,interpreter/llvm-project/llvm/docs/CommandGuide/llc.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llc.rst,1,['optimiz'],['optimization']
Performance," // (if possible) and add again; if (reqSections != TBuffer3D::kNone); shape.GetBuffer3D(reqSections, localFrame);; ```. Together these allow clients to publish objects to any one of the 3D; viewers free of viewer specific drawing code. They allow our simple x3d; viewer, and considerably more sophisticated OpenGL one to both work with; both geometry libraries (`g3d` and `geom`) efficiently. In addition to external viewers, created in separate windows, this; architecture is also used by internal **`TPad`** drawing when it; requires 3D projections. Publishing to a viewer consists of the; following steps:. 1- Create / obtain viewer handle. 2- Begin scene on viewer. 3- Fill mandatory parts of TBuffer3D describing object. 4- Add to viewer. 5- Fill optional parts of TBuffer3D as requested by viewer. [ .... repeat 3/4/5 as required for other/child objects]. 6- End scene on viewer. You should attach the top-level node of your external geometry (or the; manager) to a **`TPad`** object using **`TObject::Draw()`, and perform; the publishing to the viewer in your object's `TObject::Paint()`; overloaded method. See ""Scene Rebuilds"", and example scripts, for more; details.**. #### Creating / Obtaining Viewer Handle. External viewers are bound to a **`TPad`** object (this may be removed; as a requirement in the future). You can create or obtain the current; viewer handle via the method:. ``` {.cpp}; TVirtualViewer3D * v = gPad->GetViewer3D(""type"");; ```. Here the ""type"" string defines the viewer type - currently one of:. - ""`ogl`"" : External GL viewer. - ""`x3d`"": External X3D viewer. - ""`pad`"": Pad viewer. If no type is passed (null string), and there is no current viewer, then; the type is defaulted to ""`pad`"". If no type is passed and there is a; current viewer, then this is returned - hence once a viewer is created; it can be obtained elsewhere by:. ``` {.cpp}; TVirtualViewer3D * v = gPad->GetViewer3D();; ```. #### Opening / Closing Scenes. Objects must be added to viewer betwee",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Graphics.md:124545,perform,perform,124545,documentation/users-guide/Graphics.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Graphics.md,1,['perform'],['perform']
Performance," // error - bitfields are not supported; };. ``__cl_clang_function_pointers``; --------------------------------. With this extension it is possible to enable various language features that; are relying on function pointers using regular OpenCL extension pragma; mechanism detailed in `the OpenCL Extension Specification,; section 1.2; <https://www.khronos.org/registry/OpenCL/specs/3.0-unified/html/OpenCL_Ext.html#extensions-overview>`_. In C++ for OpenCL this also enables:. - Use of member function pointers;. - Unrestricted use of references to functions;. - Virtual member functions. Such functionality is not conformant and does not guarantee to compile; correctly in any circumstances. It can be used if:. - the kernel source does not contain call expressions to (member-) function; pointers, or virtual functions. For example this extension can be used in; metaprogramming algorithms to be able to specify/detect types generically. - the generated kernel binary does not contain indirect calls because they; are eliminated using compiler optimizations e.g. devirtualization. - the selected target supports the function pointer like functionality e.g.; most CPU targets. **Example of Use**:. .. code-block:: c++. #pragma OPENCL EXTENSION __cl_clang_function_pointers : enable; void foo(); {; void (*fp)(); // compiled - no diagnostic generated; }. #pragma OPENCL EXTENSION __cl_clang_function_pointers : disable; void bar(); {; void (*fp)(); // error - pointers to function are not allowed; }. ``__cl_clang_variadic_functions``; ---------------------------------. With this extension it is possible to enable variadic arguments in functions; using regular OpenCL extension pragma mechanism detailed in `the OpenCL; Extension Specification, section 1.2; <https://www.khronos.org/registry/OpenCL/specs/3.0-unified/html/OpenCL_Ext.html#extensions-overview>`_. This is not conformant behavior and it can only be used portably when the; functions with variadic prototypes do not get generated in bin",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst:87556,optimiz,optimizations,87556,interpreter/llvm-project/clang/docs/LanguageExtensions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst,1,['optimiz'],['optimizations']
Performance," /// Sets a callback to be invoked on calls to `write`. The callback is invoked; /// before the write is done. The write is not guaranteed to succeed when the; /// callback executes. Pass in NULL to remove any callback.; typedef void (*dfsan_write_callback_t)(int fd, const void *buf, size_t count);; void dfsan_set_write_callback(dfsan_write_callback_t labeled_write_callback);. /// Callbacks to be invoked on calls to `memcmp` or `strncmp`.; void dfsan_weak_hook_memcmp(void *caller_pc, const void *s1, const void *s2,; size_t n, dfsan_label s1_label,; dfsan_label s2_label, dfsan_label n_label);; void dfsan_weak_hook_strncmp(void *caller_pc, const char *s1, const char *s2,; size_t n, dfsan_label s1_label,; dfsan_label s2_label, dfsan_label n_label);. Taint label representation; --------------------------. We use an 8-bit unsigned integer for the representation of a; label. The label identifier 0 is special, and means that the data item; is unlabelled. This is optimizing for low CPU and code size overhead; of the instrumentation. When a label union operation is requested at a; join point (any arithmetic or logical operation with two or more; operands, such as addition), we can simply OR the two labels in O(1). Users are responsible for managing the 8 integer labels (i.e., keeping; track of what labels they have used so far, picking one that is yet; unused, etc). Origin tracking trace representation; ------------------------------------. An origin tracking trace is a list of chains. Each chain has a stack trace; where the DFSan runtime records a label propagation, and a pointer to its; previous chain. The very first chain does not point to any chain. Every four 4-bytes aligned application bytes share a 4-byte origin trace ID. A; 4-byte origin trace ID contains a 4-bit depth and a 28-bit hash ID of a chain. A chain ID is calculated as a hash from a chain structure. A chain structure; contains a stack ID and the previous chain ID. The chain head has a zero; previous chain ID",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowSanitizerDesign.rst:5705,optimiz,optimizing,5705,interpreter/llvm-project/clang/docs/DataFlowSanitizerDesign.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowSanitizerDesign.rst,1,['optimiz'],['optimizing']
Performance," 0.0), 2.0). Since we know that x+2.0 doesn't care about the sign of any zeros in X, we can; transform the fmul to 0.0, and then the fadd to 2.0. //===---------------------------------------------------------------------===//. We should enhance memcpy/memcpy/memset to allow a metadata node on them; indicating that some bytes of the transfer are undefined. This is useful for; frontends like clang when lowering struct copies, when some elements of the; struct are undefined. Consider something like this:. struct x {; char a;; int b[4];; };; void foo(struct x*P);; struct x testfunc() {; struct x V1, V2;; foo(&V1);; V2 = V1;. return V2;; }. We currently compile this to:; $ clang t.c -S -o - -O0 -emit-llvm | opt -sroa -S. %struct.x = type { i8, [4 x i32] }. define void @testfunc(%struct.x* sret %agg.result) nounwind ssp {; entry:; %V1 = alloca %struct.x, align 4; call void @foo(%struct.x* %V1); %tmp1 = bitcast %struct.x* %V1 to i8*; %0 = bitcast %struct.x* %V1 to i160*; %srcval1 = load i160* %0, align 4; %tmp2 = bitcast %struct.x* %agg.result to i8*; %1 = bitcast %struct.x* %agg.result to i160*; store i160 %srcval1, i160* %1, align 4; ret void; }. This happens because SRoA sees that the temp alloca has is being memcpy'd into; and out of and it has holes and it has to be conservative. If we knew about the; holes, then this could be much much better. Having information about these holes would also improve memcpy (etc) lowering at; llc time when it gets inlined, because we can use smaller transfers. This also; avoids partial register stalls in some important cases. //===---------------------------------------------------------------------===//. We don't fold (icmp (add) (add)) unless the two adds only have a single use.; There are a lot of cases that we're refusing to fold in (e.g.) 256.bzip2, for; example:. %indvar.next90 = add i64 %indvar89, 1 ;; Has 2 uses; %tmp96 = add i64 %tmp95, 1 ;; Has 1 use; %exitcond97 = icmp eq i64 %indvar.next90, %tmp96. We don't fold this becaus",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/README.txt:62876,load,load,62876,interpreter/llvm-project/llvm/lib/Target/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/README.txt,2,['load'],['load']
Performance," 1. buffer/global/ds/flat_atomic; - wavefront - local; - generic; atomicrmw acq_rel - workgroup - global 1. s_waitcnt lgkmcnt(0) &; vmcnt(0) & vscnt(0). - If CU wavefront execution; mode, omit vmcnt(0) and; vscnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Could be split into; separate s_waitcnt; vmcnt(0), s_waitcnt; vscnt(0), and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/load; atomic/; atomicrmw-with-return-value.; - s_waitcnt vscnt(0); must happen after; any preceding; global/generic; store/store; atomic/; atomicrmw-no-return-value.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global_atomic; 3. s_waitcnt vm/vscnt(0). - If CU wavefront execution; mode, omit.; - Use vmcnt(0) if atomic with; return and vscnt(0) if; atomic with no-return.; - Must happen before; the following; buffer_gl0_inv.; - Ensures any; following global; data read is no; older than the; atomicrmw value; being acquired. 4. buffer_gl0_inv. - If CU wavefront execution; mode, omit.; - Ensures that; following; loads will not see; stale data. atomicrmw acq_rel - workgroup - local 1. s_waitcnt vmcnt(0) & vscnt(0). - If CU wavefront execution; mode, omit.; - If OpenCL, omit.; - Could be split into; separate s_waitcnt; vmcnt(0) and s_waitcnt; vscnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/load; atomic/; atomicrmw-with-return-value.; - s_waitcnt vscnt(0); must happen after; any preceding; global/generic; store/store ato",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:363975,perform,performing,363975,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['perform'],['performing']
Performance," 1. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit; lgkmcnt(0).; - Must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global_atomic; 3. s_waitcnt vmcnt(0). - If not TgSplit execution; mode, omit.; - Must happen before; the following; buffer_wbinvl1_vol.; - Ensures any; following global; data read is no; older than the; atomicrmw value; being acquired. 4. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. atomicrmw acq_rel - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_atomic; 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than the local load; atomic value being; acquired. atomicrmw acq_rel - workgroup - generic 1. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit; lgkmcnt(0).; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; have; completed before; performing the; atomicrmw that is; being rele",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:267515,load,loads,267515,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['loads']
Performance," 1.4.10; -------------------. * Imported several FindCppyy.cmake improvements from Camille's cppyy-bbhash; * Fixes to cppyy-generator for unresolved templates, void, etc.; * Fixes in typedef parsing for template arguments in unknown namespaces; * Fix in templated operator code generation; * Fixed ref-counting error for instantiated template methods. 2019-04-25 : 1.4.9; ------------------. * Fix import error on pypy-c. 2019-04-22 : 1.4.8; ------------------. * ``std::tuple`` is now iterable for return assignments w/o tie; * Support for opaque handles and typedefs of pointers to classes; * Keep unresolved enums desugared and provide generic converters; * Treat int8_t and uint8_t as integers (even when they are chars); * Fix lookup of enum values in global namespace; * Backported name mangling (esp. for static/global data lookup) for 32b Windows; * Fixed more linker problems with malloc on 64b Windows; * Consistency in buffer length calculations and c_int/c_uint handling on Windows; * Properly resolve overloaded functions with using of templates from bases; * Get templated constructor info from decl instead of name comparison; * Fixed a performance regression for free functions. 2019-04-04 : 1.4.7; ------------------. * Enable initializer_list conversion on Windows as well; * Improved mapping of operator() for indexing (e.g. for matrices); * Implicit conversion no longer uses global state to prevent recursion; * Improved overload reordering; * Fixes for templated constructors in namespaces. 2019-04-02 : 1.4.6; ------------------. * More transparent use of smart pointers such as shared_ptr; * Expose versioned std namespace through using on Mac; * Improved error handling and interface checking in cross-inheritance; * Argument of (const/non-const) ref types support in callbacks/cross-inheritance; * Do template argument resolution in order: reference, pointer, value; * Fix for return type deduction of resolved but uninstantiated templates; * Fix wrapper generation for defau",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst:20595,perform,performance,20595,bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst,1,['perform'],['performance']
Performance," 10.59s +/- 0.05 (700 entries) ; cms3.root Y 0.717 Gb 8.29s +/- 0.08 (700 entries) ; cms5.root N 1.55 Gb 10.20s +/- 0.17 (700 entries) ; cms5.root Y 1.40 Gb 8.09s +/- 0.08 (700 entries) . In the case of a data member which is a pointer to a STL container, eg:; std::container<Data> *fDataObjects;; and which is stored member-wise, add support for the schema evolution of the class 'Data'. This requires a change in the on file format used to store this type; of data members (i.e. by adding inline the version number of the class; 'Data'). To read file containing this construct and written with this revision; using an older version of ROOT you will need the following patches:; For v5.22/00, you will need the patch r33174; or v5.22/00k; For v5.26/00, you will need patch r33176; or v5.26/00c. Additionally, we no longer allow the member wise streaming of a class which; has a custom streamer nor of any data members marked with //||. Run time performance. We introduced an optimized infrastructure for reading objects using a StreamerInfo. Rather than driving the streaming using a switch statement inside TStreamerInfo::ReadBuffer,; the streaming is now driven using a simple loop over a sequence of configured StreamerInfo actions. This improves run-time performance by allowing a dramatic reduction in function calls and code; branches at the expense of some code duplication. There are 3 versions of this loop implemented in TBufferFile and overloaded in TBufferXML and TBufferSQL:. virtual Int_t ReadSequence(const TStreamerInfoActions::TActionSequence &sequence, void *object);; virtual Int_t ReadSequence(const TStreamerInfoActions::TActionSequence &sequence,; void *start_collection, void *end_collection);; virtual Int_t ReadSequence(const TStreamerInfoActions::TActionSequence &sequence,; void *start_collection, void *end_collection);. The 1st version is optimized to read a single object. The 2nd version is optimized to read the content of TClonesArrays and vectors of pointers to obj",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/io/doc/v528/index.html:2855,optimiz,optimized,2855,io/doc/v528/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/doc/v528/index.html,2,['optimiz'],['optimized']
Performance," 2 64-bit address of amd_queue_t; (enable_sgpr_queue_ptr) object for AQL queue on which; the dispatch packet was; queued.; then Kernarg Segment Ptr 2 64-bit address of Kernarg; (enable_sgpr_kernarg segment. This is directly; _segment_ptr) copied from the; kernarg_address in the kernel; dispatch packet. Having CP load it once avoids; loading it at the beginning of; every wavefront.; then Dispatch Id 2 64-bit Dispatch ID of the; (enable_sgpr_dispatch_id) dispatch packet being; executed.; then Flat Scratch Init 2 See; (enable_sgpr_flat_scratch :ref:`amdgpu-amdhsa-kernel-prolog-flat-scratch`.; _init); then Preloaded Kernargs N/A See; (kernarg_preload_spec :ref:`amdgpu-amdhsa-kernarg-preload`.; _length); then Private Segment Size 1 The 32-bit byte size of a; (enable_sgpr_private single work-item's memory; _segment_size) allocation. This is the; value from the kernel; dispatch packet Private; Segment Byte Size rounded up; by CP to a multiple of; DWORD. Having CP load it once avoids; loading it at the beginning of; every wavefront. This is not used for; GFX7-GFX8 since it is the same; value as the second SGPR of; Flat Scratch Init. However, it; may be needed for GFX9-GFX11 which; changes the meaning of the; Flat Scratch Init value.; then Work-Group Id X 1 32-bit work-group id in X; (enable_sgpr_workgroup_id dimension of grid for; _X) wavefront.; then Work-Group Id Y 1 32-bit work-group id in Y; (enable_sgpr_workgroup_id dimension of grid for; _Y) wavefront.; then Work-Group Id Z 1 32-bit work-group id in Z; (enable_sgpr_workgroup_id dimension of grid for; _Z) wavefront.; then Work-Group Info 1 {first_wavefront, 14'b0000,; (enable_sgpr_workgroup ordered_append_term[10:0],; _info) threadgroup_size_in_wavefronts[5:0]}; then Scratch Wavefront Offset 1 See; (enable_sgpr_private :ref:`amdgpu-amdhsa-kernel-prolog-flat-scratch`.; _segment_wavefront_offset) and; :ref:`amdgpu-amdhsa-kernel-prolog-private-segment-buffer`.; ========== ========================== ====== ================",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:185512,load,load,185512,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],"['load', 'loading']"
Performance," 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than the local; atomicrmw value; being acquired. atomicrmw acquire - workgroup - generic 1. flat_atomic; 2. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit lgkmcnt(0).; - Must happen before; the following; buffer_wbinvl1_vol and; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local; atomicrmw value; being acquired. 3. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. atomicrmw acquire - agent - global 1. buffer/global_atomic; 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - system - global 1. buffer/global_atomic; 2. s_waitcnt vmcnt(0). - Must happen before; following buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; caches. 3. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. atomicrmw acquire - agent - generic 1. flat_atomic; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has;",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:250636,cache,cache,250636,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['cache'],['cache']
Performance," 5. ``DW_OP_LLVM_call_frame_entry_reg`` *New*. ``DW_OP_LLVM_call_frame_entry_reg`` has a single unsigned LEB128 integer; operand that represents a target architecture register number R. It pushes a location description L that holds the value of register R on; entry to the current subprogram as defined by the call frame information; (see :ref:`amdgpu-dwarf-call-frame-information`). *If there is no call frame information defined, then the default rules for; the target architecture are used. If the register rule is* undefined\ *, then; the undefined location description is pushed. If the register rule is* same; value\ *, then a register location description for R is pushed.*. .. _amdgpu-dwarf-undefined-location-description-operations:. A.2.5.4.4.2 Undefined Location Description Operations; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. note::. This section replaces DWARF Version 5 section 2.6.1.1.1. *The undefined location storage represents a piece or all of an object that is; present in the source but not in the object code (perhaps due to optimization).; Neither reading nor writing to the undefined location storage is meaningful.*. An undefined location description specifies the undefined location storage.; There is no concept of the size of the undefined location storage, nor of a bit; offset for an undefined location description. The ``DW_OP_LLVM_*offset``; operations leave an undefined location description unchanged. The; ``DW_OP_*piece`` operations can explicitly or implicitly specify an undefined; location description, allowing any size and offset to be specified, and results; in a part with all undefined bits. 1. ``DW_OP_LLVM_undefined`` *New*. ``DW_OP_LLVM_undefined`` pushes a location description L that comprises one; undefined location description SL. .. _amdgpu-dwarf-memory-location-description-operations:. A.2.5.4.4.3 Memory Location Description Operations; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. note::. This section replaces par",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:103202,optimiz,optimization,103202,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,1,['optimiz'],['optimization']
Performance," 8.20s +/- 0.05 (1000 entries) ; cms3.root N 0.780 Gb 10.59s +/- 0.05 (700 entries) ; cms3.root Y 0.717 Gb 8.29s +/- 0.08 (700 entries) ; cms5.root N 1.55 Gb 10.20s +/- 0.17 (700 entries) ; cms5.root Y 1.40 Gb 8.09s +/- 0.08 (700 entries) . In the case of a data member which is a pointer to a STL container, eg:; std::container<Data> *fDataObjects;; and which is stored member-wise, add support for the schema evolution of the class 'Data'. This requires a change in the on file format used to store this type; of data members (i.e. by adding inline the version number of the class; 'Data'). To read file containing this construct and written with this revision; using an older version of ROOT you will need the following patches:; For v5.22/00, you will need the patch r33174; or v5.22/00k; For v5.26/00, you will need patch r33176; or v5.26/00c. Additionally, we no longer allow the member wise streaming of a class which; has a custom streamer nor of any data members marked with //||. Run time performance. We introduced an optimized infrastructure for reading objects using a StreamerInfo. Rather than driving the streaming using a switch statement inside TStreamerInfo::ReadBuffer,; the streaming is now driven using a simple loop over a sequence of configured StreamerInfo actions. This improves run-time performance by allowing a dramatic reduction in function calls and code; branches at the expense of some code duplication. There are 3 versions of this loop implemented in TBufferFile and overloaded in TBufferXML and TBufferSQL:. virtual Int_t ReadSequence(const TStreamerInfoActions::TActionSequence &sequence, void *object);; virtual Int_t ReadSequence(const TStreamerInfoActions::TActionSequence &sequence,; void *start_collection, void *end_collection);; virtual Int_t ReadSequence(const TStreamerInfoActions::TActionSequence &sequence,; void *start_collection, void *end_collection);. The 1st version is optimized to read a single object. The 2nd version is optimized to read the co",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/io/doc/v528/index.html:2825,perform,performance,2825,io/doc/v528/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/doc/v528/index.html,2,['perform'],['performance']
Performance," ; CHECK-LABEL: D_ctor_base:. The use of ``CHECK-LABEL:`` directives in this case ensures that the three; ``CHECK:`` directives only accept lines corresponding to the body of the; ``@C_ctor_base`` function, even if the patterns match lines found later in; the file. Furthermore, if one of these three ``CHECK:`` directives fail,; FileCheck will recover by continuing to the next block, allowing multiple test; failures to be detected in a single invocation. There is no requirement that ``CHECK-LABEL:`` directives contain strings that; correspond to actual syntactic labels in a source or output language: they must; simply uniquely match a single line in the file being verified. ``CHECK-LABEL:`` directives cannot contain variable definitions or uses. Directive modifiers; ~~~~~~~~~~~~~~~~~~~. A directive modifier can be append to a directive by following the directive; with ``{<modifier>}`` where the only supported value for ``<modifier>`` is; ``LITERAL``. The ``LITERAL`` directive modifier can be used to perform a literal match. The; modifier results in the directive not recognizing any syntax to perform regex; matching, variable capture or any substitutions. This is useful when the text; to match would require excessive escaping otherwise. For example, the; following will perform literal matches rather than considering these as; regular expressions:. .. code-block:: text. Input: [[[10, 20]], [[30, 40]]]; Output %r10: [[10, 20]]; Output %r10: [[30, 40]]. ; CHECK{LITERAL}: [[[10, 20]], [[30, 40]]]; ; CHECK-DAG{LITERAL}: [[30, 40]]; ; CHECK-DAG{LITERAL}: [[10, 20]]. FileCheck Regex Matching Syntax; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. All FileCheck directives take a pattern to match.; For most uses of FileCheck, fixed string matching is perfectly sufficient. For; some things, a more flexible form of matching is desired. To support this,; FileCheck allows you to specify regular expressions in matching strings,; surrounded by double braces: ``{{yourregex}}``. FileCheck implements ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/FileCheck.rst:23976,perform,perform,23976,interpreter/llvm-project/llvm/docs/CommandGuide/FileCheck.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/FileCheck.rst,1,['perform'],['perform']
Performance," ; variables in SSA form, as opposed to having a two dimensional namespace; of the original variable and the SSA instance subscript. ARGUMENT AGAINST:; * A two dimensional namespace would be valuable when doing alias ; analysis because the extra information can help limit the scope of; analysis. ARGUMENT FOR:; * Including this information would require that all users of the LLVM; bytecode would have to parse and handle it. This would slow down the; common case and inflate the instruction representation with another; infinite variable space. REASONING:; * It was decided that because original variable sources could be; reconstructed from SSA form in linear time, that it would be an; unjustified expense for the common case to include the extra; information for one optimization. Alias analysis itself is typically; greater than linear in asymptotic complexity, so this extra analaysis; would not affect the runtime of the optimization in a significant; way. Additionally, this would be an unlikely optimization to do at; runtime. IDEAS TO CONSIDER; -----------------. 1. Including dominator information in the LLVM bytecode; representation. This is one example of an analysis result that may be; packaged with the bytecodes themselves. As a conceptual implementation ; idea, we could include an immediate dominator number for each basic block; in the LLVM bytecode program. Basic blocks could be numbered according; to the order of occurrence in the bytecode representation. 2. Including loop header and body information. This would facilitate; detection of intervals and natural loops. UNRESOLVED ISSUES ; ----------------- . 1. Will oSUIF provide enough of an infrastructure to support the research; that we will be doing? We know that it has less than stellar; performance, but hope that this will be of little importance for our; static compiler. This could affect us if we decided to do some IP; research. Also we do not yet understand the level of exception support; currently implemente",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2000-12-06-MeetingSummary.txt:1198,optimiz,optimization,1198,interpreter/llvm-project/llvm/docs/HistoricalNotes/2000-12-06-MeetingSummary.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2000-12-06-MeetingSummary.txt,1,['optimiz'],['optimization']
Performance," ; yields i32:result = 2; <result> = lshr i32 4, 2 ; yields i32:result = 1; <result> = lshr i8 4, 3 ; yields i8:result = 0; <result> = lshr i8 -2, 1 ; yields i8:result = 0x7F; <result> = lshr i32 1, 32 ; undefined; <result> = lshr <2 x i32> < i32 -2, i32 4>, < i32 1, i32 2> ; yields: result=<2 x i32> < i32 0x7FFFFFFF, i32 1>. .. _i_ashr:. '``ashr``' Instruction; ^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. <result> = ashr <ty> <op1>, <op2> ; yields ty:result; <result> = ashr exact <ty> <op1>, <op2> ; yields ty:result. Overview:; """""""""""""""""". The '``ashr``' instruction (arithmetic shift right) returns the first; operand shifted to the right a specified number of bits with sign; extension. Arguments:; """""""""""""""""""". Both arguments to the '``ashr``' instruction must be the same; :ref:`integer <t_integer>` or :ref:`vector <t_vector>` of integer type.; '``op2``' is treated as an unsigned value. Semantics:; """""""""""""""""""". This instruction always performs an arithmetic shift right operation,; The most significant bits of the result will be filled with the sign bit; of ``op1``. If ``op2`` is (statically or dynamically) equal to or larger; than the number of bits in ``op1``, this instruction returns a :ref:`poison; value <poisonvalues>`. If the arguments are vectors, each vector element; of ``op1`` is shifted by the corresponding shift amount in ``op2``. If the ``exact`` keyword is present, the result value of the ``ashr`` is; a poison value if any of the bits shifted out are non-zero. Example:; """""""""""""""". .. code-block:: text. <result> = ashr i32 4, 1 ; yields i32:result = 2; <result> = ashr i32 4, 2 ; yields i32:result = 1; <result> = ashr i8 4, 3 ; yields i8:result = 0; <result> = ashr i8 -2, 1 ; yields i8:result = -1; <result> = ashr i32 1, 32 ; undefined; <result> = ashr <2 x i32> < i32 -2, i32 4>, < i32 1, i32 3> ; yields: result=<2 x i32> < i32 -1, i32 0>. .. _i_and:. '``and``' Instruction; ^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. <result> = and <ty> <op1>, <op2> ; yields ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:396139,perform,performs,396139,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['performs']
Performance," ;. splits parameter m in the product of states of c and d. Another possibility; is the 'constrained' split which clones the parameter for all but one state; and insert a formula specialization in a chosen state that evaluates; to 1 - sum_i(a_i) where a_i are all other specializations. For example,; given a category c with state ""A"",""B"",""C"",""D"" the specification. SplitParamConstrained(""m"",""c"",""D""). will result in parameters m_A,m_B,m_C and a formula expression m_D; that evaluates to (1-(m_A+m_B+m_C)). Constrained split can also be; specified in product of categories. In that case the name of the; remainder state follows the syntax {State1;State2} where State1; and State2 are the state names of the two spitting categories. Additional; functionality exists to work with multiple prototype p.d.f.s simultaneously. ; Improved infrastructure for caching p.d.f and functions. The infrastructure that exists for caching p.d.f.s, i.e. p.d.f that precalculate their value; for all observable values at one and cache those in a histogram that is returned as p.d.f shape; (with optional interpolation), has been expanded. This infrastructure comprises RooAbsCached; the base class for all caching p.d.fs, RooAbsSelfCachedPdf a base class for end-user; caching p.d.f implementations that simply cache the result of evaluate() and RooCachedPdf; that can wrap and cache any input p.d.f specified in its constructor. . By default a p.d.f is sampled and cached in all observables in any; given use context, with no need to specify what those are in advance.; The internal code has also been changed such that all cache; histograms now store pre-normalized p.d.f, which is more efficient; than 'raw' p.d.f histograms that are explicitly post-normalized; through integration. Multiple different use cases (e.g. definitions; of what are observables vs parameters) can be cached; simultaneously. Now it is also possible to specify that p.d.f.s; should be sampled and cached in one or more parameter dimensions; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html:13642,cache,cache,13642,roofit/doc/v520/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html,2,['cache'],['cache']
Performance," <4 x i32> %t, <4 x i32> poison. '``llvm.vp.is.fpclass.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare <vscale x 2 x i1> @llvm.vp.is.fpclass.nxv2f32(<vscale x 2 x float> <op>, i32 <test>, <vscale x 2 x i1> <mask>, i32 <vector_length>); declare <2 x i1> @llvm.vp.is.fpclass.v2f16(<2 x half> <op>, i32 <test>, <2 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated llvm.is.fpclass :ref:`llvm.is.fpclass <llvm.is.fpclass>`. Arguments:; """""""""""""""""""". The first operand is a floating-point vector, the result type is a vector of; boolean with the same number of elements as the first argument. The second; operand specifies, which tests to perform :ref:`llvm.is.fpclass <llvm.is.fpclass>`.; The third operand is the vector mask and has the same number of elements as the; result vector type. The fourth operand is the explicit vector length of the; operation. Semantics:; """""""""""""""""""". The '``llvm.vp.is.fpclass``' intrinsic performs llvm.is.fpclass (:ref:`llvm.is.fpclass <llvm.is.fpclass>`). Examples:; """""""""""""""""". .. code-block:: llvm. %r = call <2 x i1> @llvm.vp.is.fpclass.v2f16(<2 x half> %x, i32 3, <2 x i1> %m, i32 %evl); %t = call <vscale x 2 x i1> @llvm.vp.is.fpclass.nxv2f16(<vscale x 2 x half> %x, i32 3, <vscale x 2 x i1> %m, i32 %evl). .. _int_mload_mstore:. Masked Vector Load and Store Intrinsics; ---------------------------------------. LLVM provides intrinsics for predicated vector load and store operations. The predicate is specified by a mask operand, which holds one bit per vector element, switching the associated vector lane on or off. The memory addresses corresponding to the ""off"" lanes are not accessed. When all bits of the mask are on, the intrinsic is identical to a regular vector load or store. When all bits are off, no memory is accessed. .. _int_mload:. '``llvm.masked.load.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. The l",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:842263,perform,performs,842263,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['performs']
Performance," <4 x i32> @llvm.bswap.v4i32(<4 x i32> %a); %also.r = select <4 x i1> %mask, <4 x i32> %t, <4 x i32> poison. .. _int_vp_ctpop:. '``llvm.vp.ctpop.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare <16 x i32> @llvm.vp.ctpop.v16i32 (<16 x i32> <op>, <16 x i1> <mask>, i32 <vector_length>); declare <vscale x 4 x i32> @llvm.vp.ctpop.nxv4i32 (<vscale x 4 x i32> <op>, <vscale x 4 x i1> <mask>, i32 <vector_length>); declare <256 x i64> @llvm.vp.ctpop.v256i64 (<256 x i64> <op>, <256 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated ctpop of a vector of integers. Arguments:; """""""""""""""""""". The first operand and the result have the same vector of integer type. The; second operand is the vector mask and has the same number of elements as the; result vector type. The third operand is the explicit vector length of the; operation. Semantics:; """""""""""""""""""". The '``llvm.vp.ctpop``' intrinsic performs ctpop (:ref:`ctpop <int_ctpop>`) of the first operand on each; enabled lane. The result on disabled lanes is a :ref:`poison value <poisonvalues>`. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call <4 x i32> @llvm.vp.ctpop.v4i32(<4 x i32> %a, <4 x i1> %mask, i32 %evl); ;; For all lanes below %evl, %r is lane-wise equivalent to %also.r. %t = call <4 x i32> @llvm.ctpop.v4i32(<4 x i32> %a); %also.r = select <4 x i1> %mask, <4 x i32> %t, <4 x i32> poison. .. _int_vp_ctlz:. '``llvm.vp.ctlz.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare <16 x i32> @llvm.vp.ctlz.v16i32 (<16 x i32> <op>, <16 x i1> <mask>, i32 <vector_length>, i1 <is_zero_poison>); declare <vscale x 4 x i32> @llvm.vp.ctlz.nxv4i32 (<vscale x 4 x i32> <op>, <vscale x 4 x i1> <mask>, i32 <vector_length>, i1 <is_zero_poison>); declare <256 x i64> @llvm.vp.ctlz.v256i64 (<256 x i64> <op>, <256 x i1> <mask>, i32 <vector_length>, i1 <is_zero_poison>). Overview:; """""""""""""""""". Predicated ctl",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:834886,perform,performs,834886,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['performs']
Performance," <i32> [#uses=2]; 	%tmp9 = add i32 %x.0.0, 1		; <i32> [#uses=2]; 	%tmp = icmp sgt i32 %tmp9, 39		; <i1> [#uses=1]; 	br i1 %tmp, label %bb12, label %cond_true. bb12:		; preds = %cond_true; 	ret i32 %tmp7; }; is pessimized by -loop-reduce and -indvars. //===---------------------------------------------------------------------===//. u32 to float conversion improvement:. float uint32_2_float( unsigned u ) {; float fl = (int) (u & 0xffff);; float fh = (int) (u >> 16);; fh *= 0x1.0p16f;; return fh + fl;; }. 00000000 subl $0x04,%esp; 00000003 movl 0x08(%esp,1),%eax; 00000007 movl %eax,%ecx; 00000009 shrl $0x10,%ecx; 0000000c cvtsi2ss %ecx,%xmm0; 00000010 andl $0x0000ffff,%eax; 00000015 cvtsi2ss %eax,%xmm1; 00000019 mulss 0x00000078,%xmm0; 00000021 addss %xmm1,%xmm0; 00000025 movss %xmm0,(%esp,1); 0000002a flds (%esp,1); 0000002d addl $0x04,%esp; 00000030 ret. //===---------------------------------------------------------------------===//. When using fastcc abi, align stack slot of argument of type double on 8 byte; boundary to improve performance. //===---------------------------------------------------------------------===//. GCC's ix86_expand_int_movcc function (in i386.c) has a ton of interesting; simplifications for integer ""x cmp y ? a : b"". //===---------------------------------------------------------------------===//. Consider the expansion of:. define i32 @test3(i32 %X) {; %tmp1 = urem i32 %X, 255; ret i32 %tmp1; }. Currently it compiles to:. ...; movl $2155905153, %ecx; movl 8(%esp), %esi; movl %esi, %eax; mull %ecx; ... This could be ""reassociated"" into:. movl $2155905153, %eax; movl 8(%esp), %ecx; mull %ecx. to avoid the copy. In fact, the existing two-address stuff would do this; except that mul isn't a commutative 2-addr instruction. I guess this has; to be done at isel time based on the #uses to mul?. //===---------------------------------------------------------------------===//. Make sure the instruction which starts a loop does not cross a cacheline; bound",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README.txt:9581,perform,performance,9581,interpreter/llvm-project/llvm/lib/Target/X86/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README.txt,2,['perform'],['performance']
Performance," <val>, i64 <expected_val>, double <prob>). Overview:; """""""""""""""""". The ``llvm.expect.with.probability`` intrinsic provides information about; expected value of ``val`` with probability(or confidence) ``prob``, which can; be used by optimizers. Arguments:; """""""""""""""""""". The ``llvm.expect.with.probability`` intrinsic takes three arguments. The first; argument is a value. The second argument is an expected value. The third; argument is a probability. Semantics:; """""""""""""""""""". This intrinsic is lowered to the ``val``. .. _int_assume:. '``llvm.assume``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare void @llvm.assume(i1 %cond). Overview:; """""""""""""""""". The ``llvm.assume`` allows the optimizer to assume that the provided; condition is true. This information can then be used in simplifying other parts; of the code. More complex assumptions can be encoded as; :ref:`assume operand bundles <assume_opbundles>`. Arguments:; """""""""""""""""""". The argument of the call is the condition which the optimizer may assume is; always true. Semantics:; """""""""""""""""""". The intrinsic allows the optimizer to assume that the provided condition is; always true whenever the control flow reaches the intrinsic call. No code is; generated for this intrinsic, and instructions that contribute only to the; provided condition are not used for code generation. If the condition is; violated during execution, the behavior is undefined. Note that the optimizer might limit the transformations performed on values; used by the ``llvm.assume`` intrinsic in order to preserve the instructions; only used to form the intrinsic's input argument. This might prove undesirable; if the extra information provided by the ``llvm.assume`` intrinsic does not cause; sufficient overall improvement in code quality. For this reason,; ``llvm.assume`` should not be used to document basic mathematical invariants; that the optimizer can otherwise deduce or facts that are of little use to the; optimizer. .. _int_ssa_copy:. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:935512,optimiz,optimizer,935512,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['optimiz'],['optimizer']
Performance," <vscale x 4 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". The '``llvm.vp.zext``' intrinsic zero extends its first operand to the return; type. The operation has a mask and an explicit vector length parameter. Arguments:; """""""""""""""""""". The '``llvm.vp.zext``' intrinsic takes a value to cast as its first operand.; The return type is the type to cast the value to. Both types must be vectors of; :ref:`integer <t_integer>` type. The bit size of the value must be smaller than; the bit size of the return type. The second operand is the vector mask. The; return type, the value to cast, and the vector mask have the same number of; elements. The third operand is the explicit vector length of the operation. Semantics:; """""""""""""""""""". The '``llvm.vp.zext``' intrinsic fill the high order bits of the value with zero; bits until it reaches the size of the return type. When zero extending from i1,; the result will always be either 0 or 1. The conversion is performed on lane; positions below the explicit vector length and where the vector mask is true.; Masked-off lanes are ``poison``. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call <4 x i32> @llvm.vp.zext.v4i32.v4i16(<4 x i16> %a, <4 x i1> %mask, i32 %evl); ;; For all lanes below %evl, %r is lane-wise equivalent to %also.r. %t = zext <4 x i16> %a to <4 x i32>; %also.r = select <4 x i1> %mask, <4 x i32> %t, <4 x i32> poison. .. _int_vp_sext:. '``llvm.vp.sext.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare <16 x i32> @llvm.vp.sext.v16i32.v16i16 (<16 x i16> <op>, <16 x i1> <mask>, i32 <vector_length>); declare <vscale x 4 x i32> @llvm.vp.sext.nxv4i32.nxv4i16 (<vscale x 4 x i16> <op>, <vscale x 4 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". The '``llvm.vp.sext``' intrinsic sign extends its first operand to the return; type. The operation has a mask and an explicit vector length parameter. Arguments:; """""""""""""""""""". The '``llvm.vp.sext``' intrinsi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:798843,perform,performed,798843,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['performed']
Performance," = %bb1; ..; 	%9 = getelementptr %struct.f* %g, i32 0, i32 0		; 	store i32 %8, i32* %9, align bel %bb3. bb3:		; preds = %bb1, %bb2, %bb; 	%c_addr.0 = phi %struct.f* [ %g, %bb2 ], [ %c, %bb ], [ %c, %bb1 ]; 	%b_addr.0 = phi %struct.f* [ %b, %bb2 ], [ %g, %bb ], [ %b, %bb1 ]; 	%10 = getelementptr %struct.f* %c_addr.0, i32 0, i32 0; 	%11 = load i32* %10, align 4. %11 is partially redundant, an in BB2 it should have the value %8. GCC PR33344 and PR35287 are similar cases. //===---------------------------------------------------------------------===//. [LOAD PRE]. There are many load PRE testcases in testsuite/gcc.dg/tree-ssa/loadpre* in the; GCC testsuite, ones we don't get yet are (checked through loadpre25):. [CRIT EDGE BREAKING]; predcom-4.c. [PRE OF READONLY CALL]; loadpre5.c. [TURN SELECT INTO BRANCH]; loadpre14.c loadpre15.c . actually a conditional increment: loadpre18.c loadpre19.c. //===---------------------------------------------------------------------===//. [LOAD PRE / STORE SINKING / SPEC HACK]. This is a chunk of code from 456.hmmer:. int f(int M, int *mc, int *mpp, int *tpmm, int *ip, int *tpim, int *dpp,; int *tpdm, int xmb, int *bp, int *ms) {; int k, sc;; for (k = 1; k <= M; k++) {; mc[k] = mpp[k-1] + tpmm[k-1];; if ((sc = ip[k-1] + tpim[k-1]) > mc[k]) mc[k] = sc;; if ((sc = dpp[k-1] + tpdm[k-1]) > mc[k]) mc[k] = sc;; if ((sc = xmb + bp[k]) > mc[k]) mc[k] = sc;; mc[k] += ms[k];; }; }. It is very profitable for this benchmark to turn the conditional stores to mc[k]; into a conditional move (select instr in IR) and allow the final store to do the; store. See GCC PR27313 for more details. Note that this is valid to xform even; with the new C++ memory model, since mc[k] is previously loaded and later; stored. //===---------------------------------------------------------------------===//. [SCALAR PRE]; There are many PRE testcases in testsuite/gcc.dg/tree-ssa/ssa-pre-*.c in the; GCC testsuite. //===---------------------------------------------------------",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/README.txt:33832,LOAD,LOAD,33832,interpreter/llvm-project/llvm/lib/Target/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/README.txt,1,['LOAD'],['LOAD']
Performance," = Int_t(fChain->GetEntries());; TH1F *myHisto = new TH1F(""myHisto"",""fPx"", 100, -5,5);; TH1F *smallHisto = new TH1F(""small"",""fPx"", 100, -5,5);; ...; ```. In the for-loop, we need to add another for-loop to go over all the; tracks. In the outer for-loop, we get the entry and the number of; tracks. In the inner for-loop, we fill the large histogram (`myHisto`); with all tracks and the small histogram (`smallHisto`) with the track if; it is in the first 100. ``` {.cpp}; ...; for (Int_t jentry=0; jentry<nentries;jentry++) {; GetEntry(jentry);; for (Int_t j = 0; j < 100; j++) {; myHisto->Fill(fTracks_fPx[j]);; if (j < 100) {; smallHisto->Fill(fTracks_fPx[j]);; }; }; }; ...; ```. Outside of the for-loop, we draw both histograms on the same canvas. ``` {.cpp}; ...; myHisto->Draw();; smallHisto->Draw(""Same"");; ...; ```. Save these changes to `MyClass.C` and start a fresh root session. We; will now load `MyClass` and experiment with its methods. ### Loading MyClass. The first step is to load the library and the class file. Then we can; instantiate a `MyClass` object. ``` {.cpp}; root[] .L libEvent.so; root[] .L MyClass.C; root[] MyClass m; ```. Now we can get a specific entry and populate the event leaf. In the code; snipped below, we get entry 0, and print the number of tracks (594).; Then we get entry 1 and print the number of tracks (597). ``` {.cpp}; root[] m.GetEntry(0); (int)57503; root[] m.fNtrack(); (Int_t)594; root[] m.GetEntry(1); (int)48045; root[] m.fNtrack(); (Int_t)597; ```. Now we can call the `Loop` method, which will build and display the two; histograms. ``` {.cpp}; root[] m.Loop(); ```. You should now see a canvas that looks like this. ![](pictures/03000106.png). To conclude the discussion on `MakeClass` let us lists the steps that; got us here. - Call `TTree::MakeClass`, which automatically creates a class to loop; over the tree. - Modify the `MyClass::Loop()` method in `MyClass.C` to fit your task. - Load and instantiate `MyClass`, and run `MyClass::Loop",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md:130008,load,load,130008,documentation/users-guide/Trees.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md,1,['load'],['load']
Performance," = alloca i32 ; yields ptr; store i32 3, ptr %ptr ; yields void; %val = load i32, ptr %ptr ; yields i32:val = i32 3. .. _i_store:. '``store``' Instruction; ^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. store [volatile] <ty> <value>, ptr <pointer>[, align <alignment>][, !nontemporal !<nontemp_node>][, !invariant.group !<empty_node>] ; yields void; store atomic [volatile] <ty> <value>, ptr <pointer> [syncscope(""<target-scope>"")] <ordering>, align <alignment> [, !invariant.group !<empty_node>] ; yields void; !<nontemp_node> = !{ i32 1 }; !<empty_node> = !{}. Overview:; """""""""""""""""". The '``store``' instruction is used to write to memory. Arguments:; """""""""""""""""""". There are two arguments to the ``store`` instruction: a value to store and an; address at which to store it. The type of the ``<pointer>`` operand must be a; pointer to the :ref:`first class <t_firstclass>` type of the ``<value>``; operand. If the ``store`` is marked as ``volatile``, then the optimizer is not; allowed to modify the number or order of execution of this ``store`` with other; :ref:`volatile operations <volatile>`. Only values of :ref:`first class; <t_firstclass>` types of known size (i.e. not containing an :ref:`opaque; structural type <t_opaque>`) can be stored. If the ``store`` is marked as ``atomic``, it takes an extra :ref:`ordering; <ordering>` and optional ``syncscope(""<target-scope>"")`` argument. The; ``acquire`` and ``acq_rel`` orderings aren't valid on ``store`` instructions.; Atomic loads produce :ref:`defined <memmodel>` results when they may see; multiple atomic stores. The type of the pointee must be an integer, pointer, or; floating-point type whose bit width is a power of two greater than or equal to; eight and less than or equal to a target-specific size limit. ``align`` must be; explicitly specified on atomic stores. Note: if the alignment is not greater or; equal to the size of the `<value>` type, the atomic operation is likely to; require a lock and have poor performance. ``!nontemp",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:419852,optimiz,optimizer,419852,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['optimiz'],['optimizer']
Performance," = centered. - 3 = top. For example, align: 11 = left adjusted and bottom adjusted; 32 = right; adjusted and vertically centered. #### Setting Text Angle. Use `TAttText::SetTextAngle` to set the text angle. The `angle` is the; degrees of the horizontal. ``` {.cpp}; root[] la->SetTextAngle(angle); ```. #### Setting Text Color. Use `TAttText::SetTextColor` to set the text color. The `color` is the; color index. The colors are described in ""Color and Color Palettes"". ``` {.cpp}; root[] la->SetTextColor(color); ```. #### Setting Text Font. Use `TAttText::SetTextFont` to set the font. The parameter font is the; font code, combining the font and precision:; `font = 10 * fontID + precision`. ``` {.cpp}; root[] la->SetTextFont(font); ```. The table below lists the available fonts. The font IDs must be between; 1 and 14. The precision can be:. - Precision = 0 fast hardware fonts (steps in the size). - Precision = 1 scalable and rotate-able hardware fonts (see below). - Precision = 2 scalable and rotate-able hardware fonts. When precision 0 is used, only the original non-scaled system fonts are; used. The fonts have a minimum (4) and maximum (37) size in pixels.; These fonts are fast and are of good quality. Their size varies with; large steps and they cannot be rotated. Precision 1 and 2 fonts have a; different behavior depending if True Type Fonts (TTF) are used or not.; If TTF are used, you always get very good quality scalable and; rotate-able fonts. However, TTF are slow. Precision 1 and 2 fonts have a; different behavior for PostScript in case of **`TLatex`** objects:. - With precision 1, the PostScript text uses the old convention (see; **`TPostScript`**) for some special characters to draw sub and; superscripts or Greek text. - With precision 2, the ""PostScript"" special characters are drawn as; such. To draw sub and superscripts it is highly recommended to use; **`TLatex`** objects instead. For example: `font = 62` is the font with ID `6` and precision `2`. ![Font's ex",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Graphics.md:70743,scalab,scalable,70743,documentation/users-guide/Graphics.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Graphics.md,1,['scalab'],['scalable']
Performance," = extractvalue {i32, i1} %res, 0; %obit = extractvalue {i32, i1} %res, 1; br i1 %obit, label %overflow, label %normal. Saturation Arithmetic Intrinsics; ---------------------------------. Saturation arithmetic is a version of arithmetic in which operations are; limited to a fixed range between a minimum and maximum value. If the result of; an operation is greater than the maximum value, the result is set (or; ""clamped"") to this maximum. If it is below the minimum, it is clamped to this; minimum. '``llvm.sadd.sat.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax; """""""""""""". This is an overloaded intrinsic. You can use ``llvm.sadd.sat``; on any integer bit width or vectors of integers. ::. declare i16 @llvm.sadd.sat.i16(i16 %a, i16 %b); declare i32 @llvm.sadd.sat.i32(i32 %a, i32 %b); declare i64 @llvm.sadd.sat.i64(i64 %a, i64 %b); declare <4 x i32> @llvm.sadd.sat.v4i32(<4 x i32> %a, <4 x i32> %b). Overview; """""""""""""""""". The '``llvm.sadd.sat``' family of intrinsic functions perform signed; saturating addition on the 2 arguments. Arguments; """""""""""""""""""". The arguments (%a and %b) and the result may be of integer types of any bit; width, but they must have the same bit width. ``%a`` and ``%b`` are the two; values that will undergo signed addition. Semantics:; """""""""""""""""""". The maximum value this operation can clamp to is the largest signed value; representable by the bit width of the arguments. The minimum value is the; smallest signed value representable by this bit width. Examples; """""""""""""""""". .. code-block:: llvm. %res = call i4 @llvm.sadd.sat.i4(i4 1, i4 2) ; %res = 3; %res = call i4 @llvm.sadd.sat.i4(i4 5, i4 6) ; %res = 7; %res = call i4 @llvm.sadd.sat.i4(i4 -4, i4 2) ; %res = -2; %res = call i4 @llvm.sadd.sat.i4(i4 -4, i4 -5) ; %res = -8. '``llvm.uadd.sat.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax; """""""""""""". This is an overloaded intrinsic. You can use ``llvm.uadd.sat``; on any integer bit width or vectors of integers. ::. declare i16 @llvm.uadd.sat.",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:611437,perform,perform,611437,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['perform']
Performance," = getelementptr inbounds %struct.anon* %tmp3, i64 %indvar, i32 0; %tmp5 = load double* %tmp4, align 8, !tbaa !4; %idxprom7 = sext i32 %i.01718 to i64; %tmp10 = getelementptr inbounds %struct.anon* %tmp3, i64 %idxprom7, i32 0; %tmp11 = load double* %tmp10, align 8, !tbaa !4; %cmp12 = fcmp ogt double %tmp5, %tmp11; br i1 %cmp12, label %if.then, label %for.inc. if.then: ; preds = %for.body; %i.017 = trunc i64 %indvar to i32; br label %for.inc. for.inc: ; preds = %for.body, %if.then; %i.01719 = phi i32 [ %i.01718, %for.body ], [ %i.017, %if.then ]; %indvar.next = add i64 %indvar, 1; %exitcond = icmp eq i64 %indvar.next, %tmp22; br i1 %exitcond, label %for.cond.for.end_crit_edge, label %for.body. It is good that we hoisted the reloads of numf2's, and Y out of the loop and; sunk the store to winner out. However, this is awful on several levels: the conditional truncate in the loop; (-indvars at fault? why can't we completely promote the IV to i64?). Beyond that, we have a partially redundant load in the loop: if ""winner"" (aka ; %i.01718) isn't updated, we reload Y[winner].y the next time through the loop.; Similarly, the addressing that feeds it (including the sext) is redundant. In; the end we get this generated assembly:. LBB0_2: ## %for.body; ## =>This Inner Loop Header: Depth=1; 	movsd	(%rdi), %xmm0; 	movslq	%edx, %r8; 	shlq	$4, %r8; 	ucomisd	(%rcx,%r8), %xmm0; 	jbe	LBB0_4; 	movl	%esi, %edx; LBB0_4: ## %for.inc; 	addq	$16, %rdi; 	incq	%rsi; 	cmpq	%rsi, %rax; 	jne	LBB0_2. All things considered this isn't too bad, but we shouldn't need the movslq or; the shlq instruction, or the load folded into ucomisd every time through the; loop. On an x86-specific topic, if the loop can't be restructure, the movl should be a; cmov. //===---------------------------------------------------------------------===//. [STORE SINKING]. GCC PR37810 is an interesting case where we should sink load/store reload; into the if block and outside the loop, so we don't reload/store it on the; non-c",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/README.txt:31194,load,load,31194,interpreter/llvm-project/llvm/lib/Target/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/README.txt,2,['load'],['load']
Performance," = icmp eq i32 %decl_context_addr.0, 1 ; %decl_context_addr.1 = select i1 %tmp1, i32 0, i32 %decl_context_addr.0. tmp1 should be simplified to something like:; (!tmp || decl_context == 1). This allows recursive simplifications, tmp1 is used all over the place in; the function, e.g. by:. %tmp23 = icmp eq i32 %decl_context_addr.1, 0 ; <i1> [#uses=1]; %tmp24 = xor i1 %tmp1, true ; <i1> [#uses=1]; %or.cond8 = and i1 %tmp23, %tmp24 ; <i1> [#uses=1]. later. //===---------------------------------------------------------------------===//. [STORE SINKING]. Store sinking: This code:. void f (int n, int *cond, int *res) {; int i;; *res = 0;; for (i = 0; i < n; i++); if (*cond); *res ^= 234; /* (*) */; }. On this function GVN hoists the fully redundant value of *res, but nothing; moves the store out. This gives us this code:. bb:		; preds = %bb2, %entry; 	%.rle = phi i32 [ 0, %entry ], [ %.rle6, %bb2 ]	; 	%i.05 = phi i32 [ 0, %entry ], [ %indvar.next, %bb2 ]; 	%1 = load i32* %cond, align 4; 	%2 = icmp eq i32 %1, 0; 	br i1 %2, label %bb2, label %bb1. bb1:		; preds = %bb; 	%3 = xor i32 %.rle, 234	; 	store i32 %3, i32* %res, align 4; 	br label %bb2. bb2:		; preds = %bb, %bb1; 	%.rle6 = phi i32 [ %3, %bb1 ], [ %.rle, %bb ]	; 	%indvar.next = add i32 %i.05, 1	; 	%exitcond = icmp eq i32 %indvar.next, %n; 	br i1 %exitcond, label %return, label %bb. DSE should sink partially dead stores to get the store out of the loop. Here's another partial dead case:; http://gcc.gnu.org/bugzilla/show_bug.cgi?id=12395. //===---------------------------------------------------------------------===//. Scalar PRE hoists the mul in the common block up to the else:. int test (int a, int b, int c, int g) {; int d, e;; if (a); d = b * c;; else; d = b - c;; e = b * c + g;; return d + e;; }. It would be better to do the mul once to reduce codesize above the if.; This is GCC PR38204. //===---------------------------------------------------------------------===//; This simple function from 179.art:. int winner, nu",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/README.txt:28808,load,load,28808,interpreter/llvm-project/llvm/lib/Target/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/README.txt,2,['load'],['load']
Performance," = ptrs[i] + offset*sizeof(i8); %A = getelementptr i8, <4 x ptr> %ptrs, i64 %offset. ; Add distinct offsets to the same pointer:; ; A[i] = ptr + offsets[i]*sizeof(i8); %A = getelementptr i8, ptr %ptr, <4 x i64> %offsets. ; In all cases described above the type of the result is <4 x ptr>. The two following instructions are equivalent:. .. code-block:: llvm. getelementptr %struct.ST, <4 x ptr> %s, <4 x i64> %ind1,; <4 x i32> <i32 2, i32 2, i32 2, i32 2>,; <4 x i32> <i32 1, i32 1, i32 1, i32 1>,; <4 x i32> %ind4,; <4 x i64> <i64 13, i64 13, i64 13, i64 13>. getelementptr %struct.ST, <4 x ptr> %s, <4 x i64> %ind1,; i32 2, i32 1, <4 x i32> %ind4, i64 13. Let's look at the C code, where the vector version of ``getelementptr``; makes sense:. .. code-block:: c. // Let's assume that we vectorize the following loop:; double *A, *B; int *C;; for (int i = 0; i < size; ++i) {; A[i] = B[C[i]];; }. .. code-block:: llvm. ; get pointers for 8 elements from array B; %ptrs = getelementptr double, ptr %B, <8 x i32> %C; ; load 8 elements from array B into A; %A = call <8 x double> @llvm.masked.gather.v8f64.v8p0f64(<8 x ptr> %ptrs,; i32 8, <8 x i1> %mask, <8 x double> %passthru). Conversion Operations; ---------------------. The instructions in this category are the conversion instructions; (casting) which all take a single operand and a type. They perform; various bit conversions on the operand. .. _i_trunc:. '``trunc .. to``' Instruction; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. <result> = trunc <ty> <value> to <ty2> ; yields ty2. Overview:; """""""""""""""""". The '``trunc``' instruction truncates its operand to the type ``ty2``. Arguments:; """""""""""""""""""". The '``trunc``' instruction takes a value to trunc, and a type to trunc; it to. Both types must be of :ref:`integer <t_integer>` types, or vectors; of the same number of integers. The bit size of the ``value`` must be; larger than the bit size of the destination type, ``ty2``. Equal sized; types are not allowed. Semantics:; """"""""""""""""""",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:441667,load,load,441667,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['load'],['load']
Performance," = v*v`** ` = t*t-x*x-y*y-z*z `. If `mag2` is negative: **`mag = -Sqrt(-mag*mag)`**. The methods are:. ``` {.cpp}; Double_t s, s2;; s = v1.Dot(v2);// scalar product; s = v1*v2;// scalar product; s2 = v.Mag2();ors2 = v.M2();; s = v.Mag();s = v.M();; ```. Since in case of momentum and energy the magnitude has the meaning of; invariant mass **`TLorentzVector`** provides the more meaningful aliases; `M2()` and `M()`. The methods `Beta()` and `Gamma()` returns `beta` and; `gamma = 1/Sqrt(1-beta*beta)`. ### Lorentz Boost. A boost in a general direction can be parameterized with three; parameters which can be taken as the components of a three vector; `b=(bx,by,bz)`. With `x=(x,y,z)` and `gamma=1/Sqrt(1-beta*beta)` (beta; being the module of vector b)`,` an arbitrary active Lorentz boost; transformation (from the rod frame to the original frame) can be written; as:. `x = x' + (gamma-1)/(beta*beta)*(b*x')*b + gamma*t'*b `. `t = gamma(t'+ b*x') `. The `Boost()` method performs a boost transformation from the rod frame; to the original frame. `BoostVector()` returns a **`TVector3`** of the; spatial components divided by the time component:. ``` {.cpp}; TVector3 b;; v.Boost(bx,by,bz);; v.Boost(b);; b = v.BoostVector();// b=(x/t,y/t,z/t); ```. ### Rotations. There are four sets of functions to rotate the **`TVector3`** component; of a **`TLorentzVector`**:. Around Axes:. ``` {.cpp}; v.RotateX(TMath::Pi()/2.);; v.RotateY(.5);; v.RotateZ(.99);; ```. Around an arbitrary axis:. ``` {.cpp}; v.Rotate(TMath::Pi()/4., v1); // rotation around v1; ```. Transformation from rotated frame:. ``` {.cpp}; v.RotateUz(direction); // direction must be a unit TVector3; ```. Rotation by **`TRotation`**:. ``` {.cpp}; TRotation r;; v.Transform(r);//or v *= r; (v = r*v); ```. ### Miscellaneous. Angle between two vectors:. ``` {.cpp}; Double_t a = v1.Angle(v2);// get angle between v1 and v2; ```. Methods `Plus()` and `Minus()` return the positive and negative; light-cone components:. ``` {.cpp}; Double",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/PhysicsVectors.md:13632,perform,performs,13632,documentation/users-guide/PhysicsVectors.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/PhysicsVectors.md,1,['perform'],['performs']
Performance," =================== =============== =============== =======================================. .. .. table:: AMDGPU Trap Handler for AMDHSA OS Code Object V3; :name: amdgpu-trap-handler-for-amdhsa-os-v3-table. =================== =============== =============== =======================================; Usage Code Sequence Trap Handler Description; Inputs; =================== =============== =============== =======================================; reserved ``s_trap 0x00`` Reserved by hardware.; debugger breakpoint ``s_trap 0x01`` *none* Reserved for debugger to use for; breakpoints. Causes wave to be halted; with the PC at the trap instruction.; The debugger is responsible to resume; the wave, including the instruction; that the breakpoint overwrote.; ``llvm.trap`` ``s_trap 0x02`` ``SGPR0-1``: Causes wave to be halted with the PC at; ``queue_ptr`` the trap instruction. The associated; queue is signalled to put it into the; error state. When the queue is put in; the error state, the waves executing; dispatches on the queue will be; terminated.; ``llvm.debugtrap`` ``s_trap 0x03`` *none* - If debugger not enabled then behaves; as a no-operation. The trap handler; is entered and immediately returns to; continue execution of the wavefront.; - If the debugger is enabled, causes; the debug trap to be reported by the; debugger and the wavefront is put in; the halt state with the PC at the; instruction. The debugger must; increment the PC and resume the wave.; reserved ``s_trap 0x04`` Reserved.; reserved ``s_trap 0x05`` Reserved.; reserved ``s_trap 0x06`` Reserved.; reserved ``s_trap 0x07`` Reserved.; reserved ``s_trap 0x08`` Reserved.; reserved ``s_trap 0xfe`` Reserved.; reserved ``s_trap 0xff`` Reserved.; =================== =============== =============== =======================================. .. .. table:: AMDGPU Trap Handler for AMDHSA OS Code Object V4 and Above; :name: amdgpu-trap-handler-for-amdhsa-os-v4-onwards-table. =================== =============== ==============",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:383111,queue,queue,383111,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['queue'],['queue']
Performance," =============================== =========================================================. dlc; ~~~. See a description :ref:`here<amdgpu_synid_dlc>`. Miscellaneous Modifiers; -----------------------. .. _amdgpu_synid_dlc:. dlc; ~~~. Controls device level cache policy for memory operations. Used for synchronization.; When specified, forces operation to bypass device level cache, making the operation device; level coherent. By default, instructions use device level cache. ======================================== ================================================; Syntax Description; ======================================== ================================================; dlc Bypass device level cache.; ======================================== ================================================. .. _amdgpu_synid_glc:. glc; ~~~. For atomic opcodes, this modifier indicates that the instruction returns the value from memory; before the operation. For other opcodes, it is used together with :ref:`slc<amdgpu_synid_slc>`; to specify cache policy. The default value is off (0). ======================================== ================================================; Syntax Description; ======================================== ================================================; glc Set glc bit to 1.; ======================================== ================================================. .. _amdgpu_synid_lds:. lds; ~~~. Specifies where to store the result: VGPRs or LDS (VGPRs by default). ======================================== ===========================; Syntax Description; ======================================== ===========================; lds Store the result in LDS.; ======================================== ===========================. .. _amdgpu_synid_nv:. nv; ~~. Specifies if the instruction is operating on non-volatile memory.; By default, memory is volatile. ======================================== ================================================; Syntax Description; =",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst:17838,cache,cache,17838,interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst,1,['cache'],['cache']
Performance," ====================================================; .. contents::; :local:; :depth: 1. Introduction; ============. The -opt-bisect-limit option provides a way to disable all optimization passes; above a specified limit without modifying the way in which the Pass Managers; are populated. The intention of this option is to assist in tracking down; problems where incorrect transformations during optimization result in incorrect; run-time behavior. This feature is implemented on an opt-in basis. Passes which can be safely; skipped while still allowing correct code generation call a function to; check the opt-bisect limit before performing optimizations. Passes which; either must be run or do not modify the IR do not perform this check and are; therefore never skipped. Generally, this means analysis passes, passes; that are run at CodeGenOptLevel::None and passes which are required for register; allocation. The -opt-bisect-limit option can be used with any tool, including front ends; such as clang, that uses the core LLVM library for optimization and code; generation. The exact syntax for invoking the option is discussed below. This feature is not intended to replace other debugging tools such as bugpoint.; Rather it provides an alternate course of action when reproducing the problem; requires a complex build infrastructure that would make using bugpoint; impractical or when reproducing the failure requires a sequence of; transformations that is difficult to replicate with tools like opt and llc. Getting Started; ===============. The -opt-bisect-limit command line option can be passed directly to tools such; as opt, llc and lli. The syntax is as follows:. ::. <tool name> [other options] -opt-bisect-limit=<limit>. If a value of -1 is used the tool will perform all optimizations but a message; will be printed to stderr for each optimization that could be skipped; indicating the index value that is associated with that optimization. To skip; optimizations, pass the value",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/OptBisect.rst:1155,optimiz,optimization,1155,interpreter/llvm-project/llvm/docs/OptBisect.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/OptBisect.rst,1,['optimiz'],['optimization']
Performance," @llvm.masked.load.v8p0.p0(ptr <ptr>, i32 <alignment>, <8 x i1> <mask>, <8 x ptr> <passthru>). Overview:; """""""""""""""""". Reads a vector from memory according to the provided mask. The mask holds a bit for each vector lane, and is used to prevent memory accesses to the masked-off lanes. The masked-off lanes in the result vector are taken from the corresponding lanes of the '``passthru``' operand. Arguments:; """""""""""""""""""". The first operand is the base pointer for the load. The second operand is the alignment of the source location. It must be a power of two constant integer value. The third operand, mask, is a vector of boolean values with the same number of elements as the return type. The fourth is a pass-through value that is used to fill the masked-off lanes of the result. The return type, underlying type of the base pointer and the type of the '``passthru``' operand are the same vector types. Semantics:; """""""""""""""""""". The '``llvm.masked.load``' intrinsic is designed for conditional reading of selected vector elements in a single IR operation. It is useful for targets that support vector masked loads and allows vectorizing predicated basic blocks on these targets. Other targets may support this intrinsic differently, for example by lowering it into a sequence of branches that guard scalar load operations.; The result of this operation is equivalent to a regular vector load instruction followed by a 'select' between the loaded and the passthru values, predicated on the same mask. However, using this intrinsic prevents exceptions on memory access to masked-off lanes. ::. %res = call <16 x float> @llvm.masked.load.v16f32.p0(ptr %ptr, i32 4, <16 x i1>%mask, <16 x float> %passthru). ;; The result of the two following instructions is identical aside from potential memory access exception; %loadlal = load <16 x float>, ptr %ptr, align 4; %res = select <16 x i1> %mask, <16 x float> %loadlal, <16 x float> %passthru. .. _int_mstore:. '``llvm.masked.store.*``' Intrinsics; ^^^^^^^^^^",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:844581,load,load,844581,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['load'],['load']
Performance," A single transient buffer holding the compressed data is now managed by TTree (and could be made thread local); rather than having one per TBranch.; In TTree::Fill, call FlushBasket before calling OptimizeBaskets so that we have a correct; and accurate value of fTotBytes to use as the requested memory.; In TTree::OptimizeBasket enforces hard minimun for the basket size (no lower than the; estimate size of one entry in the branch and no lower than 8 bytes). TTree::Process. Add support for the flag TSelector::kAbortFile. TTree::Draw. The line width setting was missing in a few places.; Namely support the option 'a' for TGraphs in TTree::Draw (delegate the axis management to the TGraph object). TTreeSQL. Allow TTreeSQL to see temporary tables.; Avoid creating the unnecessary array fEntryOffset ... which when its content is always set to zero actually prevent reading text field with TTreeSQL.; Properly find the column even if they were not created by TTreeSQL itself. Fix the loading of data for the last column. Other. Update the branch split mechanism to no longer split a base class; that can not be split (i.e. respect the information returned; by TStreamerElement::CannotSplit (and thus TClass::CanSplit).; In TChain::ls, print the name of the chain and indent the list of files (this fixes #79909).; When setting fBranch in the loaded basket, make sure to set it also for the first/only basket ; this prevents a crash when calling SetBasketSize for a split top level branch in a file produced by v4.00/08.; In TTree::Streamer, if the object we are reading in was already attached to a directory, let's make sure to unregister the object before setting fDirectory to zero.; Prevent TChainIndex and TTreeIndex from finding the branches from the friend tree when looking up the value in the master/parent TTree. This fixes #79166.; Update GetEntryNumberFriend and related functions to retun a Long64_t as needed.; Fix the case of a split collection which contains a class with one; data ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v530/index.html:3154,load,loading,3154,tree/doc/v530/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v530/index.html,2,['load'],['loading']
Performance," AMD graphics targets. Functions with this calling convention; cannot be used as entry points.; ..TODO::; Describe. ``amdgpu_gs`` Used for Mesa/AMDPAL geometry shaders.; ..TODO::; Describe. ``amdgpu_hs`` Used for Mesa/AMDPAL hull shaders (= tessellation control shaders).; ..TODO::; Describe. ``amdgpu_kernel`` See :ref:`amdgpu-amdhsa-function-call-convention-kernel-functions`. ``amdgpu_ls`` Used for AMDPAL vertex shader if tessellation is in use.; ..TODO::; Describe. ``amdgpu_ps`` Used for Mesa/AMDPAL pixel shaders.; ..TODO::; Describe. ``amdgpu_vs`` Used for Mesa/AMDPAL last shader stage before rasterization (vertex; shader if tessellation and geometry are not in use, or otherwise; copy shader if one is needed).; ..TODO::; Describe. =============================== ==========================================================. .. _amdgpu-elf-code-object:. ELF Code Object; ===============. The AMDGPU backend generates a standard ELF [ELF]_ relocatable code object that; can be linked by ``lld`` to produce a standard ELF shared code object which can; be loaded and executed on an AMDGPU target. .. _amdgpu-elf-header:. Header; ------. The AMDGPU backend uses the following ELF header:. .. table:: AMDGPU ELF Header; :name: amdgpu-elf-header-table. ========================== ===============================; Field Value; ========================== ===============================; ``e_ident[EI_CLASS]`` ``ELFCLASS64``; ``e_ident[EI_DATA]`` ``ELFDATA2LSB``; ``e_ident[EI_OSABI]`` - ``ELFOSABI_NONE``; - ``ELFOSABI_AMDGPU_HSA``; - ``ELFOSABI_AMDGPU_PAL``; - ``ELFOSABI_AMDGPU_MESA3D``; ``e_ident[EI_ABIVERSION]`` - ``ELFABIVERSION_AMDGPU_HSA_V2``; - ``ELFABIVERSION_AMDGPU_HSA_V3``; - ``ELFABIVERSION_AMDGPU_HSA_V4``; - ``ELFABIVERSION_AMDGPU_HSA_V5``; - ``ELFABIVERSION_AMDGPU_PAL``; - ``ELFABIVERSION_AMDGPU_MESA3D``; ``e_type`` - ``ET_REL``; - ``ET_DYN``; ``e_machine`` ``EM_AMDGPU``; ``e_entry`` 0; ``e_flags`` See :ref:`amdgpu-elf-header-e_flags-v2-table`,; :ref:`amdgpu-elf-header-e_flag",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:55872,load,loaded,55872,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['loaded']
Performance," AddressSanitizer is **2x**. How to build; ============. Build LLVM/Clang with `CMake <https://llvm.org/docs/CMake.html>` and enable; the ``compiler-rt`` runtime. An example CMake configuration that will allow; for the use/testing of AddressSanitizer:. .. code-block:: console. $ cmake -DCMAKE_BUILD_TYPE=Release -DLLVM_ENABLE_PROJECTS=""clang"" -DLLVM_ENABLE_RUNTIMES=""compiler-rt"" <path to source>/llvm. Usage; =====. Simply compile and link your program with ``-fsanitize=address`` flag. The; AddressSanitizer run-time library should be linked to the final executable, so; make sure to use ``clang`` (not ``ld``) for the final link step. When linking; shared libraries, the AddressSanitizer run-time is not linked, so; ``-Wl,-z,defs`` may cause link errors (don't use it with AddressSanitizer). To; get a reasonable performance add ``-O1`` or higher. To get nicer stack traces; in error messages add ``-fno-omit-frame-pointer``. To get perfect stack traces; you may need to disable inlining (just use ``-O1``) and tail call elimination; (``-fno-optimize-sibling-calls``). .. code-block:: console. % cat example_UseAfterFree.cc; int main(int argc, char **argv) {; int *array = new int[100];; delete [] array;; return array[argc]; // BOOM; }. # Compile and link; % clang++ -O1 -g -fsanitize=address -fno-omit-frame-pointer example_UseAfterFree.cc. or:. .. code-block:: console. # Compile; % clang++ -O1 -g -fsanitize=address -fno-omit-frame-pointer -c example_UseAfterFree.cc; # Link; % clang++ -g -fsanitize=address example_UseAfterFree.o. If a bug is detected, the program will print an error message to stderr and; exit with a non-zero exit code. AddressSanitizer exits on the first detected error.; This is by design:. * This approach allows AddressSanitizer to produce faster and smaller generated code; (both by ~5%).; * Fixing bugs becomes unavoidable. AddressSanitizer does not produce; false alarms. Once a memory corruption occurs, the program is in an inconsistent; state, which could lead t",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst:1836,optimiz,optimize-sibling-calls,1836,interpreter/llvm-project/clang/docs/AddressSanitizer.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst,1,['optimiz'],['optimize-sibling-calls']
Performance," Allocation; ---------------------------------------------. To avoid debug instructions interfering with the register allocator, the; LiveDebugVariables pass extracts variable locations from a MIR function and; deletes the corresponding DBG_VALUE instructions. Some localized copy; propagation is performed within blocks. After register allocation, the; VirtRegRewriter pass re-inserts DBG_VALUE instructions in their original; positions, translating virtual register references into their physical; machine locations. To avoid encoding incorrect variable locations, in this; pass any DBG_VALUE of a virtual register that is not live, is replaced by; the undefined location. The LiveDebugVariables may insert redundant DBG_VALUEs; because of virtual register rewriting. These will be subsequently removed by; the RemoveRedundantDebugValues pass. LiveDebugValues expansion of variable locations; -----------------------------------------------. After all optimizations have run and shortly before emission, the; LiveDebugValues pass runs to achieve two aims:. * To propagate the location of variables through copies and register spills,; * For every block, to record every valid variable location in that block. After this pass the DBG_VALUE instruction changes meaning: rather than; corresponding to a source-level assignment where the variable may change value,; it asserts the location of a variable in a block, and loses effect outside the; block. Propagating variable locations through copies and spills is; straightforwards: determining the variable location in every basic block; requires the consideration of control flow. Consider the following IR, which; presents several difficulties:. .. code-block:: text. define dso_local i32 @foo(i1 %cond, i32 %input) !dbg !12 {; entry:; br i1 %cond, label %truebr, label %falsebr. bb1:; %value = phi i32 [ %value1, %truebr ], [ %value2, %falsebr ]; br label %exit, !dbg !26. truebr:; call void @llvm.dbg.value(metadata i32 %input, metadata !30, metadat",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:36544,optimiz,optimizations,36544,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,1,['optimiz'],['optimizations']
Performance," At global scope.; uselistorder ptr @global, { 1, 2, 0 }; uselistorder i32 7, { 1, 0 }; uselistorder i32 (i32) @bar, { 1, 0 }; uselistorder_bb @foo, %bb, { 5, 1, 3, 2, 0, 4 }. .. _source_filename:. Source Filename; ---------------. The *source filename* string is set to the original module identifier,; which will be the name of the compiled source file when compiling from; source through the clang front end, for example. It is then preserved through; the IR and bitcode. This is currently necessary to generate a consistent unique global; identifier for local functions used in profile data, which prepends the; source file name to the local function name. The syntax for the source file name is simply:. .. code-block:: text. source_filename = ""/path/to/source.c"". .. _typesystem:. Type System; ===========. The LLVM type system is one of the most important features of the; intermediate representation. Being typed enables a number of; optimizations to be performed on the intermediate representation; directly, without having to do extra analyses on the side before the; transformation. A strong type system makes it easier to read the; generated code and enables novel analyses and transformations that are; not feasible to perform on normal three address code representations. .. _t_void:. Void Type; ---------. :Overview:. The void type does not represent any value and has no size. :Syntax:. ::. void. .. _t_function:. Function Type; -------------. :Overview:. The function type can be thought of as a function signature. It consists of a; return type and a list of formal parameter types. The return type of a function; type is a void type or first class type --- except for :ref:`label <t_label>`; and :ref:`metadata <t_metadata>` types. :Syntax:. ::. <returntype> (<parameter list>). ...where '``<parameter list>``' is a comma-separated list of type; specifiers. Optionally, the parameter list may include a type ``...``, which; indicates that the function takes a variable number of arg",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:165348,optimiz,optimizations,165348,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,2,"['optimiz', 'perform']","['optimizations', 'performed']"
Performance," C Standard are; currently under investigation. Any defect report whose status in Clang is; currently unknown will be marked in purple.; The LLVM bug tracker uses; the ""c"", ""c99"", ""c11"", ""c17"", and ""c23"" labels to track known bugs with Clang's language; conformance. Number; Status; Issue title; Available in Clang?. 1; C89; Do functions return values by copying?; Yes. 2; NAD; Subclause 6.8.3.2: Semantics of #; Unknown. 3; NAD; Subclause 6.1.8: Preprocessing numbers; Unknown. 4; NAD; Are multiple definitions of unused identifiers with external linkage permitted?; Yes. 5; NAD; May a conforming implementation define and recognize a pragma which would change the semantics of the language?; Yes. 6; C89; It is unclear how the strtoul function behaves when presented with a subject sequence that begins with a minus sign; N/A. 7; NAD; Are declarations of the form struct-or-union identifier ; permitted after the identifier tag has already been declared?; Yes. 8; NAD; Can a conforming C compiler to perform dead-store elimination?; Yes. 9; C89; Use of typedef names in parameter declarations; No. 10; NAD; Is a typedef to an incomplete type legal?; Yes. 11; C89; Merging of declarations for linked identifier; Yes. 12; NAD; Is it valid to take the address of a dereferenced void pointer?; Yes. 13; C89; Compatible and composite function types; Yes. 14; C89; Issues with setjmp and fscanf descriptions; N/A. 15; NAD; What is the promoted type of a plain int bit-field?; Yes. 16; C89; What does static storage duration do when zero for the type is not all zero bits?; Unknown. 17; C89; 39 unrelated questions about C89; Unknown. 18; NAD; How does fscanf behave in the presence of multibyte characters?; N/A. 19; NAD; Definition of the term ""printing character"" and isgraph(); N/A. 20; NAD; Is a compiler which allows the Relaxed Ref/Def linkage model to be considered a conforming compiler?; Yes. 21; C89; What is the result of: printf(""%#.4o"", 345);?; N/A. 22; C89; What is the result of: strtod(""10",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/c_dr_status.html:1236,perform,perform,1236,interpreter/llvm-project/clang/www/c_dr_status.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/c_dr_status.html,2,['perform'],['perform']
Performance," CMake language-defined functions. .. code-block:: cmake. cmake_minimum_required(VERSION 3.20.0); project(HelloWorld); add_executable(HelloWorld HelloWorld.cpp). The CMake language provides control flow constructs in the form of foreach loops; and if blocks. To make the example above more complicated you could add an if; block to define ""APPLE"" when targeting Apple platforms:. .. code-block:: cmake. cmake_minimum_required(VERSION 3.20.0); project(HelloWorld); add_executable(HelloWorld HelloWorld.cpp); if(APPLE); target_compile_definitions(HelloWorld PUBLIC APPLE); endif(). Variables, Types, and Scope; ===========================. Dereferencing; -------------. In CMake variables are ""stringly"" typed. All variables are represented as; strings throughout evaluation. Wrapping a variable in ``${}`` dereferences it; and results in a literal substitution of the name for the value. CMake refers to; this as ""variable evaluation"" in their documentation. Dereferences are performed; *before* the command being called receives the arguments. This means; dereferencing a list results in multiple separate arguments being passed to the; command. Variable dereferences can be nested and be used to model complex data. For; example:. .. code-block:: cmake. set(var_name var1); set(${var_name} foo) # same as ""set(var1 foo)""; set(${${var_name}}_var bar) # same as ""set(foo_var bar)"". Dereferencing an unset variable results in an empty expansion. It is a common; pattern in CMake to conditionally set variables knowing that it will be used in; code paths that the variable isn't set. There are examples of this throughout; the LLVM CMake build system. An example of variable empty expansion is:. .. code-block:: cmake. if(APPLE); set(extra_sources Apple.cpp); endif(); add_executable(HelloWorld HelloWorld.cpp ${extra_sources}). In this example the ``extra_sources`` variable is only defined if you're; targeting an Apple platform. For all other targets the ``extra_sources`` will be; evaluated as empty",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst:3153,perform,performed,3153,interpreter/llvm-project/llvm/docs/CMakePrimer.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst,1,['perform'],['performed']
Performance, COMMAND testDerivativesCpu). # DNN - Backpropagation CPU; ROOT_EXECUTABLE(testBackpropagationCpu TestBackpropagationCpu.cxx LIBRARIES ${Libraries}); ROOT_ADD_TEST(TMVA-DNN-Backpropagation-Cpu COMMAND testBackpropagationCpu). # DNN - BackpropagationDL CPU; ROOT_EXECUTABLE(testBackpropagationDLCpu TestBackpropagationDLCpu.cxx LIBRARIES ${Libraries}); ROOT_ADD_TEST(TMVA-DNN-Backpropagation-DL-Cpu COMMAND testBackpropagationDLCpu). # DNN - Batch normalization; ROOT_EXECUTABLE(testBatchNormalizationCpu TestBatchNormalizationCpu.cxx LIBRARIES ${Libraries}); ROOT_ADD_TEST(TMVA-DNN-BatchNormalization-Cpu COMMAND testBatchNormalizationCpu). # DNN - Optimization CPU; ROOT_EXECUTABLE(testOptimizationCpu TestOptimizationCpu.cxx LIBRARIES ${Libraries}); ROOT_ADD_TEST(TMVA-DNN-Optimization-Cpu COMMAND testOptimizationCpu). # DNN - MethodDL SGD Optimization CPU; ROOT_EXECUTABLE(testMethodDLSGDOptimizationCpu TestMethodDLSGDOptimizationCpu.cxx LIBRARIES ${Libraries}); ROOT_ADD_TEST(TMVA-DNN-MethodDL-SGD-Optimization-Cpu COMMAND testMethodDLSGDOptimizationCpu). # DNN - MethodDL Adam Optimization CPU; ROOT_EXECUTABLE(testMethodDLAdamOptimizationCpu TestMethodDLAdamOptimizationCpu.cxx LIBRARIES ${Libraries}); ROOT_ADD_TEST(TMVA-DNN-MethodDL-Adam-Optimization-Cpu COMMAND testMethodDLAdamOptimizationCpu TIMEOUT 1800). # DNN - MethodDL Adagrad Optimization CPU; ROOT_EXECUTABLE(testMethodDLAdagradOptimizationCpu TestMethodDLAdagradOptimizationCpu.cxx LIBRARIES ${Libraries}); ROOT_ADD_TEST(TMVA-DNN-MethodDL-Adagrad-Optimization-Cpu COMMAND testMethodDLAdagradOptimizationCpu). # DNN - MethodDL RMSProp Optimization CPU; ROOT_EXECUTABLE(testMethodDLRMSPropOptimizationCpu TestMethodDLRMSPropOptimizationCpu.cxx LIBRARIES ${Libraries}); ROOT_ADD_TEST(TMVA-DNN-MethodDL-RMSProp-Optimization-Cpu COMMAND testMethodDLRMSPropOptimizationCpu). # DNN - MethodDL Adadelta Optimization CPU; ROOT_EXECUTABLE(testMethodDLAdadeltaOptimizationCpu TestMethodDLAdadeltaOptimizationCpu.cxx LIBRARIES ${Libraries});,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/test/DNN/CMakeLists.txt:5730,Optimiz,Optimization-Cpu,5730,tmva/tmva/test/DNN/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/test/DNN/CMakeLists.txt,1,['Optimiz'],['Optimization-Cpu']
Performance," CU. In WGP wavefront execution mode the; wavefronts may be executed by different SIMDs in different CUs in the same; WGP.; * Each WGP has a single LDS memory shared by the wavefronts of the work-groups; executing on it.; * All LDS operations of a WGP are performed as wavefront wide operations in a; global order and involve no caching. Completion is reported to a wavefront in; execution order.; * The LDS memory has multiple request queues shared by the SIMDs of a; WGP. Therefore, the LDS operations performed by different wavefronts of a; work-group can be reordered relative to each other, which can result in; reordering the visibility of vector memory operations with respect to LDS; operations of other wavefronts in the same work-group. A ``s_waitcnt; lgkmcnt(0)`` is required to ensure synchronization between LDS operations and; vector memory operations between wavefronts of a work-group, but not between; operations performed by the same wavefront.; * The vector memory operations are performed as wavefront wide operations.; Completion of load/store/sample operations are reported to a wavefront in; execution order of other load/store/sample operations performed by that; wavefront.; * The vector memory operations access a vector L0 cache. There is a single L0; cache per CU. Each SIMD of a CU accesses the same L0 cache. Therefore, no; special action is required for coherence between the lanes of a single; wavefront. However, a ``buffer_gl0_inv`` is required for coherence between; wavefronts executing in the same work-group as they may be executing on SIMDs; of different CUs that access different L0s. A ``buffer_gl0_inv`` is also; required for coherence between wavefronts executing in different work-groups; as they may be executing on different WGPs.; * The scalar memory operations access a scalar L0 cache shared by all wavefronts; on a WGP. The scalar and vector L0 caches are not coherent. However, scalar; operations are used in a restricted way so do not impact the me",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:336544,perform,performed,336544,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['perform'],['performed']
Performance," CUs associated with other L2 caches, or writes from the CPU, due to; the cache probe caused by coherent requests. Coherent requests are caused; by GPU accesses to pages with the PTE C-bit set, by CPU accesses over; XGMI, and by PCIe requests that are configured to be coherent requests.; * XGMI accesses from the CPU to local memory may be cached on the CPU.; Subsequent access from the GPU will automatically invalidate or writeback; the CPU cache due to the L2 probe filter and and the PTE C-bit being set.; * Since all work-groups on the same agent share the same L2, no L2; invalidation or writeback is required for coherence.; * To ensure coherence of local and remote memory writes of work-groups in; different agents a ``buffer_wbl2`` is required. It will writeback dirty L2; cache lines of MTYPE RW (used for local coarse grain memory) and MTYPE NC; ()used for remote coarse grain memory). Note that MTYPE CC (used for local; fine grain memory) causes write through to DRAM, and MTYPE UC (used for; remote fine grain memory) bypasses the L2, so both will never result in; dirty L2 cache lines.; * To ensure coherence of local and remote memory reads of work-groups in; different agents a ``buffer_invl2`` is required. It will invalidate L2; cache lines with MTYPE NC (used for remote coarse grain memory). Note that; MTYPE CC (used for local fine grain memory) and MTYPE RW (used for local; coarse memory) cause local reads to be invalidated by remote writes with; with the PTE C-bit so these cache lines are not invalidated. Note that; MTYPE UC (used for remote fine grain memory) bypasses the L2, so will; never result in L2 cache lines that need to be invalidated. * PCIe access from the GPU to the CPU memory is kept coherent by using the; MTYPE UC (uncached) which bypasses the L2. Scalar memory operations are only used to access memory that is proven to not; change during the execution of the kernel dispatch. This includes constant; address space and global address space for progra",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:239068,cache,cache,239068,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['cache'],['cache']
Performance," Chapter 2 of the ""Building an ORC-based JIT in LLVM"" tutorial. In; `Chapter 1 <BuildingAJIT1.html>`_ of this series we examined a basic JIT; class, KaleidoscopeJIT, that could take LLVM IR modules as input and produce; executable code in memory. KaleidoscopeJIT was able to do this with relatively; little code by composing two off-the-shelf *ORC layers*: IRCompileLayer and; ObjectLinkingLayer, to do much of the heavy lifting. In this layer we'll learn more about the ORC layer concept by using a new layer,; IRTransformLayer, to add IR optimization support to KaleidoscopeJIT. Optimizing Modules using the IRTransformLayer; =============================================. In `Chapter 4 <LangImpl04.html>`_ of the ""Implementing a language with LLVM""; tutorial series the llvm *FunctionPassManager* is introduced as a means for; optimizing LLVM IR. Interested readers may read that chapter for details, but; in short: to optimize a Module we create an llvm::FunctionPassManager; instance, configure it with a set of optimizations, then run the PassManager on; a Module to mutate it into a (hopefully) more optimized but semantically; equivalent form. In the original tutorial series the FunctionPassManager was; created outside the KaleidoscopeJIT and modules were optimized before being; added to it. In this Chapter we will make optimization a phase of our JIT; instead. For now this will provide us a motivation to learn more about ORC; layers, but in the long term making optimization part of our JIT will yield an; important benefit: When we begin lazily compiling code (i.e. deferring; compilation of each function until the first time it's run) having; optimization managed by our JIT will allow us to optimize lazily too, rather; than having to do all our optimization up-front. To add optimization support to our JIT we will take the KaleidoscopeJIT from; Chapter 1 and compose an ORC *IRTransformLayer* on top. We will look at how the; IRTransformLayer works in more detail below, but the ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/BuildingAJIT2.rst:1614,optimiz,optimize,1614,interpreter/llvm-project/llvm/docs/tutorial/BuildingAJIT2.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/BuildingAJIT2.rst,3,['optimiz'],"['optimizations', 'optimize', 'optimized']"
Performance," Clang implements. These; lists currently have a number of entries marked as Unknown.; Completing the investigation involves adding test coverage for; C; and; C++; defect reports and updating the documentation accordingly.; Bug triage: Clang's ; issue trackercurrently has over 20,000 open issues, many of which are not; appropriately tagged, are no longer reproducible, could use a reduced test case,; or otherwise needs some manual interaction. We can always use help with; bug triage and; issue tracker maintenance. Improve build times with Clang: the time it takes Clang to process a; translation unit is very important to our users; the lower the build time, the; better the overall user experience. It would be good to improve Clang's; performance as well as to find ways to proactively alert us when we've; introduced a change that has significant negative impact on build times.; Complete support for the experimental constant expression interpreter; : Clang's production constant expression interpreter computes a constant; expression result by walking over AST nodes, performing calculations as it; goes. This does not have good performance properties, and so we've begun work; on an ; experimental constant expression interpreter that works by converting the; AST into bytecode that is interpreted. This effort has a long tail of work left; to complete because it requires implementing byte code for every kind of; expression and type that can be used in a constant expression for C++ and C. Improve clang-doc: Clang's library-based design allows it to be used; by a variety of tools that reason about source code.; clang-doc is one; great application of this functionality, which generates code documentation; from source code. The tool is in early stages of development and could use more; dedicated effort to complete the implementation.; Self-testing using clang: There are several neat ways to; improve the quality of clang by self-testing. Some examples:. Improve the reliability of ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/OpenProjects.html:3476,perform,performing,3476,interpreter/llvm-project/clang/www/OpenProjects.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/OpenProjects.html,2,['perform'],['performing']
Performance," Code command. .. option:: --macho-dsymtab. Display the Dsymtab command. .. option:: --macho-indirect-symbols. Display indirect symbols. .. option:: --macho-linker-options. Display the Mach-O-specific linker options. .. option:: --macho-segment. Display the Segment command. .. option:: --macho-version-min. Display the version min command. PE/COFF SPECIFIC OPTIONS; ------------------------. The following options are implemented only for the PE/COFF file format. .. option:: --codeview. Display CodeView debug information. .. option:: --codeview-ghash. Enable global hashing for CodeView type stream de-duplication. .. option:: --codeview-merged-types. Display the merged CodeView type stream. .. option:: --codeview-subsection-bytes. Dump raw contents of CodeView debug sections and records. .. option:: --coff-basereloc. Display the .reloc section. .. option:: --coff-debug-directory. Display the debug directory. .. option:: --coff-tls-directory. Display the TLS directory. .. option:: --coff-directives. Display the .drectve section. .. option:: --coff-exports. Display the export table. .. option:: --coff-imports. Display the import table. .. option:: --coff-load-config. Display the load config. .. option:: --coff-resources. Display the .rsrc section. XCOFF SPECIFIC OPTIONS; ----------------------. The following options are implemented only for the XCOFF file format. .. option:: --auxiliary-header. Display XCOFF Auxiliary header. .. option:: --exception-section. Display XCOFF exception section entries. .. option:: --loader-section-header. Display XCOFF loader section header. .. option:: --loader-section-symbols. Display symbol table of loader section. .. option:: --loader-section-relocations. Display relocation entries of loader section. EXIT STATUS; -----------. :program:`llvm-readobj` returns 0 under normal operation. It returns a non-zero; exit code if there were any errors. SEE ALSO; --------. :manpage:`llvm-nm(1)`, :manpage:`llvm-objdump(1)`, :manpage:`llvm-readelf(1)`; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readobj.rst:8274,load,load-config,8274,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readobj.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readobj.rst,8,['load'],"['load', 'load-config', 'loader', 'loader-section-header', 'loader-section-relocations', 'loader-section-symbols']"
Performance," Complete support for big-endian architectures (PR [#10402](https://github.com/root-project/root/pull/10402)). - Support for `std::pair<T1, T2>` and `std::tuple<Ts...>` fields. - Support for C array fields whose type is of the form `T[N]`. Note that only single-dimension arrays are currently supported. - Improvements to the ROOT file embedding (PR [#10558](https://github.com/root-project/root/pull/10558)). In particular, a `RNTupleReader` or `RDataFrame` object can be created from a `TFile` instance as follows; ```; auto f = TFile::Open(""data.root"");; auto ntpl = f->Get<ROOT::Experimental::RNTuple>(""Events"");. auto reader = ROOT::Experimental::RNTupleReader::Open(ntpl);; // or for RDataFrame; auto rdf = ROOT::Experimental::MakeNTupleDataFrame(ntpl);; ```. - If buffered write is enabled, vector writes are used where possible. In particular, this yields important improvements in storage backends leveraging parallel writes, e.g. in object storages. - Large read/write throughput improvements in the experimental Intel DAOS backend. - `RNTupleWriter::Fill()` now returns the number of uncompressed bytes written, which is align with TTree behavior. - Support for user-defined classes that behave as a collection via the `TVirtualCollectionProxy` interface.; Fields created via `RFieldBase::Create()` automatically detect the presence of a collection proxy at run-time. However, if `RField<T>` (`T` being a class) is used instead, the trait `IsCollectionProxy<T>` must be set for the given type (see PR [#11525](https://github.com/root-project/root/pull/11525) for details).; Note that associative collections are not yet supported. - Some internal support for per field post-read callbacks. This functionality will be presented in upcoming releases through custom I/O rules. Please, report any issues regarding the abovementioned features should you encounter them.; RNTuple is still experimental and is scheduled to become production grade in 2024. Thus, we appreciate feedback and suggesti",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v628/index.md:9633,throughput,throughput,9633,README/ReleaseNotes/v628/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v628/index.md,1,['throughput'],['throughput']
Performance," DAG node with the same operator and arguments as; *dag*, but replacing the name of the argument specified by the *key* with; *name*. That *key* could be either an integer index or a string name. ``!setdagop(``\ *dag*\ ``,`` *op*\ ``)``; This operator produces a DAG node with the same arguments as *dag*, but with its; operator replaced with *op*. Example: ``!setdagop((foo 1, 2), bar)`` results in ``(bar 1, 2)``. ``!shl(``\ *a*\ ``,`` *count*\ ``)``; This operator shifts *a* left logically by *count* bits and produces the resulting; value. The operation is performed on a 64-bit integer; the result; is undefined for shift counts outside 0...63. ``!size(``\ *a*\ ``)``; This operator produces the size of the string, list, or dag *a*.; The size of a DAG is the number of arguments; the operator does not count. ``!sra(``\ *a*\ ``,`` *count*\ ``)``; This operator shifts *a* right arithmetically by *count* bits and produces the resulting; value. The operation is performed on a 64-bit integer; the result; is undefined for shift counts outside 0...63. ``!srl(``\ *a*\ ``,`` *count*\ ``)``; This operator shifts *a* right logically by *count* bits and produces the resulting; value. The operation is performed on a 64-bit integer; the result; is undefined for shift counts outside 0...63. ``!strconcat(``\ *str1*\ ``,`` *str2*\ ``, ...)``; This operator concatenates the string arguments *str1*, *str2*, etc., and; produces the resulting string. ``!sub(``\ *a*\ ``,`` *b*\ ``)``; This operator subtracts *b* from *a* and produces the arithmetic difference. ``!subst(``\ *target*\ ``,`` *repl*\ ``,`` *value*\ ``)``; This operator replaces all occurrences of the *target* in the *value* with; the *repl* and produces the resulting value. The *value* can; be a string, in which case substring substitution is performed. The *value* can be a record name, in which case the operator produces the *repl*; record if the *target* record name equals the *value* record name; otherwise it; produces the *va",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TableGen/ProgRef.rst:71849,perform,performed,71849,interpreter/llvm-project/llvm/docs/TableGen/ProgRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TableGen/ProgRef.rst,1,['perform'],['performed']
Performance," Enabling optimization remarks; =============================. There are two modes that are supported for enabling optimization remarks in; LLVM: through remark diagnostics, or through serialized remarks. Remark diagnostics; ------------------. Optimization remarks can be emitted as diagnostics. These diagnostics will be; propagated to front-ends if desired, or emitted by tools like :doc:`llc; <CommandGuide/llc>` or :doc:`opt <CommandGuide/opt>`. .. option:: -pass-remarks=<regex>. Enables optimization remarks from passes whose name match the given (POSIX); regular expression. .. option:: -pass-remarks-missed=<regex>. Enables missed optimization remarks from passes whose name match the given; (POSIX) regular expression. .. option:: -pass-remarks-analysis=<regex>. Enables optimization analysis remarks from passes whose name match the given; (POSIX) regular expression. Serialized remarks; ------------------. While diagnostics are useful during development, it is often more useful to; refer to optimization remarks post-compilation, typically during performance; analysis. For that, LLVM can serialize the remarks produced for each compilation unit to; a file that can be consumed later. By default, the format of the serialized remarks is :ref:`YAML; <yamlremarks>`, and it can be accompanied by a :ref:`section <remarkssection>`; in the object files to easily retrieve it. :doc:`llc <CommandGuide/llc>` and :doc:`opt <CommandGuide/opt>` support the; following options:. ``Basic options``. .. option:: -pass-remarks-output=<filename>. Enables the serialization of remarks to a file specified in <filename>. By default, the output is serialized to :ref:`YAML <yamlremarks>`. .. option:: -pass-remarks-format=<format>. Specifies the output format of the serialized remarks. Supported formats:. * :ref:`yaml <yamlremarks>` (default); * :ref:`yaml-strtab <yamlstrtabremarks>`; * :ref:`bitstream <bitstreamremarks>`. ``Content configuration``. .. option:: -pass-remarks-filter=<regex>. Only pas",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Remarks.rst:2029,optimiz,optimization,2029,interpreter/llvm-project/llvm/docs/Remarks.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Remarks.rst,2,"['optimiz', 'perform']","['optimization', 'performance']"
Performance," Files; --------------------------------. After symbol resolution, the linker tells the LTO shared object which symbols; are needed by native object files. In the example above, the linker reports; that only ``foo1()`` is used by native object files using; ``lto_codegen_add_must_preserve_symbol()``. Next the linker invokes the LLVM; optimizer and code generators using ``lto_codegen_compile()`` which returns a; native object file creating by merging the LLVM bitcode files and applying; various optimization passes. Phase 4 : Symbol Resolution after optimization; ----------------------------------------------. In this phase, the linker reads optimized a native object file and updates the; internal global symbol table to reflect any changes. The linker also collects; information about any changes in use of external symbols by LLVM bitcode; files. In the example above, the linker notes that ``foo4()`` is not used any; more. If dead code stripping is enabled then the linker refreshes the live; symbol information appropriately and performs dead code stripping. After this phase, the linker continues linking as if it never saw LLVM bitcode; files. .. _libLTO:. ``libLTO``; ==========. ``libLTO`` is a shared object that is part of the LLVM tools, and is intended; for use by a linker. ``libLTO`` provides an abstract C interface to use the LLVM; interprocedural optimizer without exposing details of LLVM's internals. The; intention is to keep the interface as stable as possible even when the LLVM; optimizer continues to evolve. It should even be possible for a completely; different compilation technology to provide a different libLTO that works with; their object files and the standard linker tool. ``lto_module_t``; ----------------. A non-native object file is handled via an ``lto_module_t``. The following; functions allow the linker to check if a file (on disk or in a memory buffer) is; a file which libLTO can process:. .. code-block:: c. lto_module_is_object_file(const char*); ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LinkTimeOptimization.rst:7877,perform,performs,7877,interpreter/llvm-project/llvm/docs/LinkTimeOptimization.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LinkTimeOptimization.rst,1,['perform'],['performs']
Performance," Fix - display of labels on X axis with TProfile; 3. Fix - support time display in TMultiGraph; 4. Fix - correctly parse ""optstat"" and ""optfit"" in URL; 5. Fix - correctly update TGraph drawing when X range is changing; 6. Fix - return only TF1/TF2 object when searching function (#158). ## Changes in 5.4.1; 1. Fix - monitoring mode in draw.htm page; 2. Fix - zooming in colz palette; 3. Fix - support both 9.x and 10.x jsdom version in Node.js (#149); 4. Fix - draw axis main line with appropriate attributes (#150); 5. Fix - use axis color when drawing grids lines (#150); 6. Fix - when set pad logx/logy, reset existing user ranges in pad; 7. Fix - avoid too deep calling stack when drawing many graphs or histos (#154); 8. Fix - correctly (re)draw tooltips on canvas with many subpads. ## Changes in 5.4.0; 1. New supported classes:; - TDiamond; - TArc; - TCurlyLine; - TCurlyArc; - TCrown; 2. New draw options:; - ""RX"" and ""RY"" for TGraph to reverse axis; - ""noopt"" for TGraph to disable drawing optimization; - ""CPN"" for TCanvas to create color palette from N last colors; - ""line"" for TGraph2D; 3. New features:; - support LZ4 compression; - tooltips and zooming in TGraphPolar drawings; - TPavesText with multiple underlying paves; - implement all fill styles; - draw borders for TWbox; - draw all objects from TList/TObjArray as they appear in list of primitives; - let enable/disable highlight of extra objects in geometry viewer; - draw axis labels on both sides when pad.fTick[x/y] > 1; - make drawing of TCanvas with many primitives smoother; - add fOptTitle, fOptLogx/y/z fields in JSROOT.gStyle; 4. Behavior changes:; - disable automatic frame adjustment, can be enabled with ""&adjframe"" parameter in URL; - when drawing TH2/TH3 scatter plots, always generate same ""random"" pattern; - use barwidth/baroffset parameters in lego plots; 5. Bug fixes:; - use same number of points to draw lines and markers on the TGraph; - correctly draw filled TArrow endings; - let combine ""L"" or ""C"" TGr",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/js/changes.md:35830,optimiz,optimization,35830,js/changes.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/js/changes.md,1,['optimiz'],['optimization']
Performance," For an example, look at the `X86InstrPostProcess::postProcessInstruction` method; within `llvm/lib/Target/X86/MCA/X86CustomBehaviour.cpp`. A load/store barrier consumes one entry of the load/store queue. A load/store; barrier enforces ordering of loads/stores. A younger load cannot pass a load; barrier. Also, a younger store cannot pass a store barrier. A younger load; has to wait for the memory/load barrier to execute. A load/store barrier is; ""executed"" when it becomes the oldest entry in the load/store queue(s). That; also means, by construction, all of the older loads/stores have been executed. In conclusion, the full set of load/store consistency rules are:. #. A store may not pass a previous store.; #. A store may not pass a previous load (regardless of ``-noalias``).; #. A store has to wait until an older store barrier is fully executed.; #. A load may pass a previous load.; #. A load may not pass a previous store unless ``-noalias`` is set.; #. A load has to wait until an older load barrier is fully executed. In-order Issue and Execute; """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; In-order processors are modelled as a single ``InOrderIssueStage`` stage. It; bypasses Dispatch, Scheduler and Load/Store unit. Instructions are issued as; soon as their operand registers are available and resource requirements are; met. Multiple instructions can be issued in one cycle according to the value of; the ``IssueWidth`` parameter in LLVM's scheduling model. Once issued, an instruction is moved to ``IssuedInst`` set until it is ready to; retire. :program:`llvm-mca` ensures that writes are committed in-order. However,; an instruction is allowed to commit writes and retire out-of-order if; ``RetireOOO`` property is true for at least one of its writes. Custom Behaviour; """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; Due to certain instructions not being expressed perfectly within their; scheduling model, :program:`llvm-mca` isn't always able to simulate them; perfectly. Modifying the sched",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:43060,load,load,43060,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,2,['load'],['load']
Performance," G_FSQRT, G_FFLOOR, G_FRINT, G_FNEARBYINT; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. These correspond to the standard C functions of the same name. G_INTRINSIC_TRUNC; ^^^^^^^^^^^^^^^^^. Returns the operand rounded to the nearest integer not larger in magnitude than the operand. G_INTRINSIC_ROUND; ^^^^^^^^^^^^^^^^^. Returns the operand rounded to the nearest integer. G_LROUND, G_LLROUND; ^^^^^^^^^^^^^^^^^^^. Returns the source operand rounded to the nearest integer with ties away from; zero. See the LLVM LangRef entry on '``llvm.lround.*'`` for details on behaviour. .. code-block:: none. %rounded_32:_(s32) = G_LROUND %round_me:_(s64); %rounded_64:_(s64) = G_LLROUND %round_me:_(s64). Vector Specific Operations; --------------------------. G_CONCAT_VECTORS; ^^^^^^^^^^^^^^^^. Concatenate two vectors to form a longer vector. G_BUILD_VECTOR, G_BUILD_VECTOR_TRUNC; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Create a vector from multiple scalar registers. No implicit; conversion is performed (i.e. the result element type must be the; same as all source operands). The _TRUNC version truncates the larger operand types to fit the; destination vector elt type. G_INSERT_VECTOR_ELT; ^^^^^^^^^^^^^^^^^^^. Insert an element into a vector. G_EXTRACT_VECTOR_ELT; ^^^^^^^^^^^^^^^^^^^^. Extract an element from a vector. G_SHUFFLE_VECTOR; ^^^^^^^^^^^^^^^^. Concatenate two vectors and shuffle the elements according to the mask operand.; The mask operand should be an IR Constant which exactly matches the; corresponding mask for the IR shufflevector instruction. Vector Reduction Operations; ---------------------------. These operations represent horizontal vector reduction, producing a scalar result. G_VECREDUCE_SEQ_FADD, G_VECREDUCE_SEQ_FMUL; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The SEQ variants perform reductions in sequential order. The first operand is; an initial scalar accumulator value, and the second operand is the vector to reduce. G_VECREDUCE_FADD, G_VECRED",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst:13620,perform,performed,13620,interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst,1,['perform'],['performed']
Performance," GetZaxis for THStack. - Fix Graph Errorbar Offsets for the new Marker Styles and thick markers. - When the palette width is bigger than the palette height, the palette; is automatically drawn horizontally. - THStack::GetXaxis->SetRange did not auto-zoom Yaxis range. - The Paint method of THStack always redrew the histograms in the sub-pads defined by the; THStack drawing option ""pads"". Like the ""pad dividing"" the ""histograms' drawing"" should be; done only the first time the THStack is painted otherwise any additional graphics objects; added in one of the pads (created by the ""pads"" option) will be removed. - Improve TRatioPlot axes drawing. ## Math Libraries. - `RVec` has been heavily re-engineered in order to add a small buffer optimization and to streamline its internals. The change should provide a small performance boost to; applications that make heavy use of `RVec`s and should otherwise be user-transparent. Please report any issues you should encounter.; - I/O support of `RVec` objects has been optimized. As a side-effect, `RVec`s can now be read back as `std::vector`s and vice-versa.; - Add `ROOT::VecOps::Drop`, an operation that removes `RVec` elements at the specified indices.; - handy aliases `ROOT::RVecI`, `ROOT::RVecD`, `ROOT::RVecF`, ..., have been introduced as short-hands for `RVec<int>`, `RVec<double>`, `RVec<float>`, ...; - Add `VecOps::StableArgsort` and `VecOps::StableSort` operations. ## RooFit Libraries. ### Experimental CUDA support for RooFit's `BatchMode`. RooFit's [`BatchMode`](https://root.cern/doc/master/classRooAbsPdf.html#a8f802a3a93467d5b7b089e3ccaec0fa8) has been around; [since ROOT 6.20](https://root.cern/doc/v620/release-notes.html#fast-function-evaluation-and-vectorisation).; It was further [improved in ROOT 6.24](https://root.cern/doc/v624/release-notes.html#massive-speed-up-of-roofits-batchmode-on-cpus-with-vector-extensions) to use vector extensions of modern CPUs without recompiling ROOT, introducing the new `RooBatchCompute` li",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v626/index.md:14336,optimiz,optimized,14336,README/ReleaseNotes/v626/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v626/index.md,1,['optimiz'],['optimized']
Performance," If OpenCL, omit lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0), s_waitcnt; vscnt(0) and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/load; atomic/; atomicrmw-with-return-value.; - s_waitcnt vscnt(0); must happen after; any preceding; global/generic; store/store; atomic/; atomicrmw-no-return-value.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; have; completed before; performing the; atomicrmw that is; being released. 2. flat_atomic; 3. s_waitcnt lgkmcnt(0) &; vmcnt(0) & vscnt(0). - If CU wavefront execution; mode, omit vmcnt(0) and; vscnt(0).; - If OpenCL, omit lgkmcnt(0).; - Must happen before; the following; buffer_gl0_inv.; - Ensures any; following global; data read is no; older than the load; atomic value being; acquired. 3. buffer_gl0_inv. - If CU wavefront execution; mode, omit.; - Ensures that; following; loads will not see; stale data. atomicrmw acq_rel - agent - global 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0) & vscnt(0). - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0), s_waitcnt; vscnt(0) and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/load atomic/; atomicrmw-with-return-value.; - s_waitcnt vscnt(0); must happen after; any preceding; global/generic; store/store atomic/; atomicrmw-no-return-value.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global have; completed before; performing the; atomicrmw that is; bein",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:366693,load,load,366693,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['load']
Performance," If OpenCL, omit.; - Could be split into; separate s_waitcnt; vmcnt(0) and s_waitcnt; vscnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/load; atomic/; atomicrmw-with-return-value.; - s_waitcnt vscnt(0); must happen after; any preceding; global/generic; store/store atomic/; atomicrmw-no-return-value.; - Must happen before; the following; store.; - Ensures that all; global memory; operations have; completed before; performing the; store that is being; released. 2. ds_store; store atomic release - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0) & vscnt(0). - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0), s_waitcnt vscnt(0); and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/load; atomic/; atomicrmw-with-return-value.; - s_waitcnt vscnt(0); must happen after; any preceding; global/generic; store/store atomic/; atomicrmw-no-return-value.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; have; completed before; performing the; store that is being; released. 2. buffer/global/flat_store; atomicrmw release - singlethread - global 1. buffer/global/ds/flat_atomic; - wavefront - local; - generic; atomicrmw release - workgroup - global 1. s_waitcnt lgkmcnt(0) &; - generic vmcnt(0) & vscnt(0). - If CU wavefront execution; mode, omit vmcnt(0) and; vscnt(0).; - If OpenCL, omit lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0), s_waitcnt; vscnt(0) and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:356929,load,load,356929,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],['load']
Performance," If the bit operand value is 1 vectorization is enabled. A value of; 0 disables vectorization:. .. code-block:: llvm. !0 = !{!""llvm.loop.vectorize.enable"", i1 0}; !1 = !{!""llvm.loop.vectorize.enable"", i1 1}. '``llvm.loop.vectorize.predicate.enable``' Metadata; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. This metadata selectively enables or disables creating predicated instructions; for the loop, which can enable folding of the scalar epilogue loop into the; main loop. The first operand is the string; ``llvm.loop.vectorize.predicate.enable`` and the second operand is a bit. If; the bit operand value is 1 vectorization is enabled. A value of 0 disables; vectorization:. .. code-block:: llvm. !0 = !{!""llvm.loop.vectorize.predicate.enable"", i1 0}; !1 = !{!""llvm.loop.vectorize.predicate.enable"", i1 1}. '``llvm.loop.vectorize.scalable.enable``' Metadata; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. This metadata selectively enables or disables scalable vectorization for the; loop, and only has any effect if vectorization for the loop is already enabled.; The first operand is the string ``llvm.loop.vectorize.scalable.enable``; and the second operand is a bit. If the bit operand value is 1 scalable; vectorization is enabled, whereas a value of 0 reverts to the default fixed; width vectorization:. .. code-block:: llvm. !0 = !{!""llvm.loop.vectorize.scalable.enable"", i1 0}; !1 = !{!""llvm.loop.vectorize.scalable.enable"", i1 1}. '``llvm.loop.vectorize.width``' Metadata; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. This metadata sets the target width of the vectorizer. The first; operand is the string ``llvm.loop.vectorize.width`` and the second; operand is an integer specifying the width. For example:. .. code-block:: llvm. !0 = !{!""llvm.loop.vectorize.width"", i32 4}. Note that setting ``llvm.loop.vectorize.width`` to 1 disables; vectorization of the loop. If ``llvm.loop.vectorize.width`` is set to; 0 or if the loop does not have this metadata the width will be; det",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:298595,scalab,scalable,298595,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['scalab'],['scalable']
Performance," In practice, however, dereferencing a ``null`` pointer is; extremely rare in well-behaved Java programs, and typically the null; check can be folded into a nearby memory operation that operates on; the same memory location. The Fault Map Section; =====================. Information about implicit checks generated by LLVM are put in a; special ""fault map"" section. On Darwin this section is named; ``__llvm_faultmaps``. The format of this section is. .. code-block:: none. Header {; uint8 : Fault Map Version (current version is 1); uint8 : Reserved (expected to be 0); uint16 : Reserved (expected to be 0); }; uint32 : NumFunctions; FunctionInfo[NumFunctions] {; uint64 : FunctionAddress; uint32 : NumFaultingPCs; uint32 : Reserved (expected to be 0); FunctionFaultInfo[NumFaultingPCs] {; uint32 : FaultKind; uint32 : FaultingPCOffset; uint32 : HandlerPCOffset; }; }. FailtKind describes the reason of expected fault. Currently three kind; of faults are supported:. 1. ``FaultMaps::FaultingLoad`` - fault due to load from memory.; 2. ``FaultMaps::FaultingLoadStore`` - fault due to instruction load and store.; 3. ``FaultMaps::FaultingStore`` - fault due to store to memory. The ``ImplicitNullChecks`` pass; ===============================. The ``ImplicitNullChecks`` pass transforms explicit control flow for; checking if a pointer is ``null``, like:. .. code-block:: llvm. %ptr = call i32* @get_ptr(); %ptr_is_null = icmp i32* %ptr, null; br i1 %ptr_is_null, label %is_null, label %not_null, !make.implicit !0. not_null:; %t = load i32, i32* %ptr; br label %do_something_with_t. is_null:; call void @HFC(); unreachable. !0 = !{}. to control flow implicit in the instruction loading or storing through; the pointer being null checked:. .. code-block:: llvm. %ptr = call i32* @get_ptr(); %t = load i32, i32* %ptr ;; handler-pc = label %is_null; br label %do_something_with_t. is_null:; call void @HFC(); unreachable. This transform happens at the ``MachineInstr`` level, not the LLVM IR; level (so t",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FaultMaps.rst:1833,load,load,1833,interpreter/llvm-project/llvm/docs/FaultMaps.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FaultMaps.rst,1,['load'],['load']
Performance," In this way it's not different; from someone who would check out all the projects with SVN today. If you want to avoid checking out all the sources, you can hide the other; directories using a Git sparse checkout::. git config core.sparseCheckout true; echo /compiler-rt > .git/info/sparse-checkout; git read-tree -mu HEAD. The data for all sub-projects is still in your `.git` directory, but in your; checkout, you only see `compiler-rt`.; Before you push, you'll need to fetch and rebase (`git pull --rebase`) as; usual. Note that when you fetch you'll likely pull in changes to sub-projects you don't; care about. If you are using sparse checkout, the files from other projects; won't appear on your disk. The only effect is that your commit hash changes. You can check whether the changes in the last fetch are relevant to your commit; by running::. git log origin/main@{1}..origin/main -- libcxx. This command can be hidden in a script so that `git llvmpush` would perform all; these steps, fail only if such a dependent change exists, and show immediately; the change that prevented the push. An immediate repeat of the command would; (almost) certainly result in a successful push.; Note that today with SVN or git-svn, this step is not possible since the; ""rebase"" implicitly happens while committing (unless a conflict occurs). Checkout/Clone Multiple Projects, with Commit Access; ----------------------------------------------------. Let's look how to assemble llvm+clang+libcxx at a given revision. Currently; ^^^^^^^^^. ::. svn co https://llvm.org/svn/llvm-project/llvm/trunk llvm -r $REVISION; cd llvm/tools; svn co https://llvm.org/svn/llvm-project/clang/trunk clang -r $REVISION; cd ../projects; svn co https://llvm.org/svn/llvm-project/libcxx/trunk libcxx -r $REVISION. Or using git-svn::. git clone https://llvm.org/git/llvm.git; cd llvm/; git svn init https://llvm.org/svn/llvm-project/llvm/trunk --username=<username>; git config svn-remote.svn.fetch :refs/remotes/origin/main; gi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:14827,perform,perform,14827,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,1,['perform'],['perform']
Performance," Instructions from the critical sequence are expected to significantly impact; performance. By construction, the accuracy of this analysis is strongly; dependent on the simulation and (as always) by the quality of the processor; model in llvm. Bottleneck analysis is currently not supported for processors with an in-order; backend. Extra Statistics to Further Diagnose Performance Issues; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; The ``-all-stats`` command line option enables extra statistics and performance; counters for the dispatch logic, the reorder buffer, the retire control unit,; and the register file. Below is an example of ``-all-stats`` output generated by :program:`llvm-mca`; for 300 iterations of the dot-product example discussed in the previous; sections. .. code-block:: none. Dynamic Dispatch Stall Cycles:; RAT - Register unavailable: 0; RCU - Retire tokens unavailable: 0; SCHEDQ - Scheduler full: 272 (44.6%); LQ - Load queue full: 0; SQ - Store queue full: 0; GROUP - Static restrictions on the dispatch group: 0. Dispatch Logic - number of cycles where we saw N micro opcodes dispatched:; [# dispatched], [# cycles]; 0, 24 (3.9%); 1, 272 (44.6%); 2, 314 (51.5%). Schedulers - number of cycles where we saw N micro opcodes issued:; [# issued], [# cycles]; 0, 7 (1.1%); 1, 306 (50.2%); 2, 297 (48.7%). Scheduler's queue usage:; [1] Resource name.; [2] Average number of used buffer entries.; [3] Maximum number of used buffer entries.; [4] Total number of buffer entries. [1] [2] [3] [4]; JALU01 0 0 20; JFPU01 17 18 18; JLSAGU 0 0 12. Retire Control Unit - number of cycles where we saw N instructions retired:; [# retired], [# cycles]; 0, 109 (17.9%); 1, 102 (16.7%); 2, 399 (65.4%). Total ROB Entries: 64; Max Used ROB Entries: 35 ( 54.7% ); Average Used ROB Entries per cy: 32 ( 50.0% ). Register File statistics:; Total number of mappings created: 900; Max number of mappings used: 35. * Register File #1 -- JFpuPRF:; Number of physical registers: 72; Tot",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:29169,queue,queue,29169,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,2,['queue'],['queue']
Performance," Interpreter on the Bela Platform <https://gist.github.com/jarmitage/6e411ae8746c04d6ecbee1cbc1ebdcd4>`_; - Jack Armitage 2019; - Cling has been installed on a BeagleBoard to bring live coding to the Bela interactive audio platform.; * - `Implementation of GlobalModuleIndex in ROOT and Cling <https://indico.cern.ch/event/840376/contributions/3525646/attachments/1895398/3127159/GSoC_Presentation__GMI.pdf>`_; - *Arpitha Raghunandan* 2012 Google Summer of Code GSoC; - GlobalModuleIndex can be used for improving ROOT’s and Cling’s performance ; * - `Example project using cling as library <https://github.com/root-project/cling/tree/master/tools/demo>`_; - *Axel Naumann* 2016 GitHub; - This video showcases how to use Cling as a library, and shows how to set up a simple CMake configuration that uses Cling.; * - `Cling C++ interpreter testdrive <https://www.youtube.com/watch?v=1IGTHusaJ18>`_; - *Mika* 2015 Youtube; - In this tutorial, a developer tries Cling for the first time by uploading a few simple C++ user-cases onto Cling, involving also the loading of external files; * - `Building an Order Book in C++ <https://www.youtube.com/watch?v=fxN4xEZvrxI>`_; - *Dimitri Nesteruk* 2015 Youtube; - This demo shows how to build a simple order book using C++, CLion, Google Test and, of course, Cling. ; * - `Cling C++ interpreter testdrive <https://www.youtube.com/watch?v=1IGTHusaJ18>`_; - Dimitri Nesteruk 2015 Youtube; - This tutorial describes Cling’s general features. You will learn how to start Cling on Ubuntu, how to write a simple expression (N=5, N++) and how to define a Class for calculating body mass index. ; * - `Cling Interactive OpenGL Demo <https://www.youtube.com/watch?v=eoIuqLNvzFs>`_; - *Alexander Penev* 2012 Youtube; - This demo shows how to use Cling for interactive OpenGL. A rotating triangle with changing color, a static figure, and a figure with light effects are created.; ; . .. list-table:: Language Interoperability with Cling:; :widths: 25 25 50; :header-rows:",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/references.rst:4870,load,loading,4870,interpreter/cling/docs/chapters/references.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/references.rst,1,['load'],['loading']
Performance," Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare <pointer type>; @llvm.experimental.gc.relocate(token %statepoint_token,; i32 %base_offset,; i32 %pointer_offset). Overview:; """""""""""""""""". A ``gc.relocate`` returns the potentially relocated value of a pointer; at the safepoint. Operands:; """""""""""""""""". The first argument is the ``gc.statepoint`` which starts the; safepoint sequence of which this ``gc.relocation`` is a part.; Despite the typing of this as a generic token, *only* the value defined; by a ``gc.statepoint`` is legal here. The second and third arguments are both indices into operands of the; corresponding statepoint's :ref:`gc-live <ob_gc_live>` operand bundle. The second argument is an index which specifies the allocation for the pointer; being relocated. The associated value must be within the object with which the; pointer being relocated is associated. The optimizer is free to change *which*; interior derived pointer is reported, provided that it does not replace an; actual base pointer with another interior derived pointer. Collectors are; allowed to rely on the base pointer operand remaining an actual base pointer if; so constructed. The third argument is an index which specify the (potentially) derived pointer; being relocated. It is legal for this index to be the same as the second; argument if-and-only-if a base pointer is being relocated. Semantics:; """""""""""""""""""". The return value of ``gc.relocate`` is the potentially relocated value; of the pointer specified by its arguments. It is unspecified how the; value of the returned pointer relates to the argument to the; ``gc.statepoint`` other than that a) it points to the same source; language object with the same offset, and b) the 'based-on'; relationship of the newly relocated pointers is a projection of the; unrelocated pointers. In particular, the integer value of the pointer; returned is unspecified. A ``gc.relocate`` is modeled as a ``readnone`` pure function. It",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:505842,optimiz,optimizer,505842,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['optimiz'],['optimizer']
Performance," It is higher performance than global memory. The data store; (DS) instructions can be used to access it. **Private**; The private address space uses the hardware scratch memory support which; automatically allocates memory when it creates a wavefront and frees it when; a wavefronts terminates. The memory accessed by a lane of a wavefront for any; given private address will be different to the memory accessed by another lane; of the same or different wavefront for the same private address. If a kernel dispatch uses scratch, then the hardware allocates memory from a; pool of backing memory allocated by the runtime for each wavefront. The lanes; of the wavefront access this using dword (4 byte) interleaving. The mapping; used from private address to backing memory address is:. ``wavefront-scratch-base +; ((private-address / 4) * wavefront-size * 4) +; (wavefront-lane-id * 4) + (private-address % 4)``. If each lane of a wavefront accesses the same private address, the; interleaving results in adjacent dwords being accessed and hence requires; fewer cache lines to be fetched. There are different ways that the wavefront scratch base address is; determined by a wavefront (see; :ref:`amdgpu-amdhsa-initial-kernel-execution-state`). Scratch memory can be accessed in an interleaved manner using buffer; instructions with the scratch buffer descriptor and per wavefront scratch; offset, by the scratch instructions, or by flat instructions. Multi-dword; access is not supported except by flat and scratch instructions in; GFX9-GFX11. Code that manipulates the stack values in other lanes of a wavefront,; such as by ``addrspacecast``-ing stack pointers to generic ones and taking offsets; that reach other lanes or by explicitly constructing the scratch buffer descriptor,; triggers undefined behavior when it modifies the scratch values of other lanes.; The compiler may assume that such modifications do not occur.; When using code object V5 ``LIBOMPTARGET_STACK_SIZE`` may be used to pro",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:27454,cache,cache,27454,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['cache'],['cache']
Performance," JSON format.; 2. Fix small error in dtree.js - one should always set; last sibling (_ls) property while tree can be dynamically changed.; 3. In JSRootCore.js provide central function, which handles different kinds; of XMLHttpRequest. Use only async requests, also when getting file header.; 4. Fully reorganize data management in file/tree/directory/collection hierarchical; display. Now complete description collected in HPainter class and decoupled from; visualization, performed with dTree.js.; 5. Remove all global variables from the code.; 6. Automatic scripts/style loading handled via JSROOT.loadScript() function.; One can specify arbitrary scripts list, which asynchronously loaded by browser.; 7. Method to build simple GUI changed and more simplified :). The example in index.htm.; While loadScript and AssertPrerequisites functions moved to JSROOT, one; can easily build many different kinds of GUIs, reusing provided JSRootCore.js functions.; 8. In example.htm also use AssertPrerequisites to load necessary scripts.; This helps to keep code up-to-date even by big changes in JavaScript code.; 9. Provide monitoring of online THttpServer with similar interface as for ROOT files.; 10. Fix several errors in TKey Streamer, use member names as in ROOT itself.; 11. Keep the only version identifier JSROOT.version for JS code; 12. One can specify in JSROOT.AssertPrerequisites functionality which is required.; One could specify '2d', 'io' (default) or '3d'.; 13. Use new AssertPrerequisites functionality to load only required functionality.; 14. When displaying single element, one could specify draw options and monitor property like:; <http://localhost:8080/Files/job1.root/hpxpy/draw.htm?opt=col&monitor=2000>; Such link is best possibility to integrate display into different HTML pages,; using `<iframe/>` tag like:; `<iframe src=""http://localhost:8080/Files/job1.root/hpx/draw.htm""`; `style=""width: 800px; height:600px""></iframe>`; 15. Remove 'JSROOTIO.' prefix from _typename. Now ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/js/changes.md:74832,load,load,74832,js/changes.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/js/changes.md,1,['load'],['load']
Performance," Java; functions for example... > c. How do we get more high-level information into the VM while keeping; > to a low-level VM design?; > o Explicit array references as operands? An alternative is; > to have just an array type, and let the index computations be; > separate 3-operand instructions. C. In the model I was thinking of (subject to change of course), we; would just have an array type (distinct from the pointer; types). This would allow us to have arbitrarily complex index; expressions, while still distinguishing ""load"" from ""Array load"",; for example. Perhaps also, switch jump tables would be first class; types as well? This would allow better reasoning about the program. 5. Support dynamic loading of code from various sources. Already; mentioned above was the example of loading java bytecodes, but we want; to support dynamic loading of VM code as well. This makes the job of; the runtime compiler much more interesting: it can do interprocedural; optimizations that the static compiler can't do, because it doesn't; have all of the required information (for example, inlining from; shared libraries, etc...). 6. Define a set of generally useful annotations to add to the VM; representation. For example, a function can be analysed to see if it; has any sideeffects when run... also, the MOD/REF sets could be; calculated, etc... we would have to determine what is reasonable. This; would generally be used to make IP optimizations cheaper for the; runtime compiler... > o Explicit instructions to handle aliasing, e.g.s:; > -- an instruction to say ""I speculate that these two values are not; > aliased, but check at runtime"", like speculative execution in; > EPIC?; > -- or an instruction to check whether two values are aliased and; > execute different code depending on the answer, somewhat like; > predicated code in EPIC. These are also very good points... if this can be determined at compile; time. I think that an epic style of representation (not the instruction; packi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2000-11-18-EarlyDesignIdeasResp.txt:5842,optimiz,optimizations,5842,interpreter/llvm-project/llvm/docs/HistoricalNotes/2000-11-18-EarlyDesignIdeasResp.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2000-11-18-EarlyDesignIdeasResp.txt,1,['optimiz'],['optimizations']
Performance," LDS operations of a WGP are performed as wavefront wide operations in a; global order and involve no caching. Completion is reported to a wavefront in; execution order.; * The LDS memory has multiple request queues shared by the SIMDs of a; WGP. Therefore, the LDS operations performed by different wavefronts of a; work-group can be reordered relative to each other, which can result in; reordering the visibility of vector memory operations with respect to LDS; operations of other wavefronts in the same work-group. A ``s_waitcnt; lgkmcnt(0)`` is required to ensure synchronization between LDS operations and; vector memory operations between wavefronts of a work-group, but not between; operations performed by the same wavefront.; * The vector memory operations are performed as wavefront wide operations.; Completion of load/store/sample operations are reported to a wavefront in; execution order of other load/store/sample operations performed by that; wavefront.; * The vector memory operations access a vector L0 cache. There is a single L0; cache per CU. Each SIMD of a CU accesses the same L0 cache. Therefore, no; special action is required for coherence between the lanes of a single; wavefront. However, a ``buffer_gl0_inv`` is required for coherence between; wavefronts executing in the same work-group as they may be executing on SIMDs; of different CUs that access different L0s. A ``buffer_gl0_inv`` is also; required for coherence between wavefronts executing in different work-groups; as they may be executing on different WGPs.; * The scalar memory operations access a scalar L0 cache shared by all wavefronts; on a WGP. The scalar and vector L0 caches are not coherent. However, scalar; operations are used in a restricted way so do not impact the memory model. See; :ref:`amdgpu-amdhsa-memory-spaces`.; * The vector and scalar memory L0 caches use an L1 cache shared by all WGPs on; the same SA. Therefore, no special action is required for coherence between; the wavefronts o",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:336795,cache,cache,336795,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['cache'],['cache']
Performance," LLVM with ``%1``). Again, ``MemoryPhi``\ s don't correspond to any LLVM; Instruction, so the line directly below a ``MemoryPhi`` isn't special. Going from the top down:. - ``6 = MemoryPhi({entry,1},{if.end,4})`` notes that, when entering; ``while.cond``, the reaching definition for it is either ``1`` or ``4``. This; ``MemoryPhi`` is referred to in the textual IR by the number ``6``.; - ``2 = MemoryDef(6)`` notes that ``store i8 0, ptr %p1`` is a definition,; and its reaching definition before it is ``6``, or the ``MemoryPhi`` after; ``while.cond``. (See the `Use and Def optimization`_ and `Precision`_; sections below for why this ``MemoryDef`` isn't linked to a separate,; disambiguated ``MemoryPhi``.); - ``3 = MemoryDef(6)`` notes that ``store i8 0, ptr %p2`` is a definition; its; reaching definition is also ``6``.; - ``5 = MemoryPhi({if.then,2},{if.else,3})`` notes that the clobber before; this block could either be ``2`` or ``3``.; - ``MemoryUse(5)`` notes that ``load i8, ptr %p1`` is a use of memory, and that; it's clobbered by ``5``.; - ``4 = MemoryDef(5)`` notes that ``store i8 2, ptr %p2`` is a definition; its; reaching definition is ``5``.; - ``MemoryUse(1)`` notes that ``load i8, ptr %p3`` is just a user of memory,; and the last thing that could clobber this use is above ``while.cond`` (e.g.; the store to ``%p3``). In memory versioning parlance, it really only depends on; the memory version 1, and is unaffected by the new memory versions generated since; then. As an aside, ``MemoryAccess`` is a ``Value`` mostly for convenience; it's not; meant to interact with LLVM IR. Design of MemorySSA; ===================. ``MemorySSA`` is an analysis that can be built for any arbitrary function. When; it's built, it does a pass over the function's IR in order to build up its; mapping of ``MemoryAccess``\ es. You can then query ``MemorySSA`` for things; like the dominance relation between ``MemoryAccess``\ es, and get the; ``MemoryAccess`` for any given ``Instruction`` .",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MemorySSA.rst:7609,load,load,7609,interpreter/llvm-project/llvm/docs/MemorySSA.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MemorySSA.rst,1,['load'],['load']
Performance," MachineMemOperand in addition to explicit; operands. If the result size is larger than the memory size, the; high bits are undefined, sign-extended, or zero-extended respectively. Only G_LOAD is valid if the result is a vector type. If the result is larger; than the memory size, the high elements are undefined (i.e. this is not a; per-element, vector anyextload). Unlike in SelectionDAG, atomic loads are expressed with the same; opcodes as regular loads. G_LOAD, G_SEXTLOAD and G_ZEXTLOAD may all; have atomic memory operands. G_INDEXED_LOAD; ^^^^^^^^^^^^^^. Generic indexed load. Combines a GEP with a load. $newaddr is set to $base + $offset.; If $am is 0 (post-indexed), then the value is loaded from $base; if $am is 1 (pre-indexed); then the value is loaded from $newaddr. G_INDEXED_SEXTLOAD; ^^^^^^^^^^^^^^^^^^. Same as G_INDEXED_LOAD except that the load performed is sign-extending, as with G_SEXTLOAD. G_INDEXED_ZEXTLOAD; ^^^^^^^^^^^^^^^^^^. Same as G_INDEXED_LOAD except that the load performed is zero-extending, as with G_ZEXTLOAD. G_STORE; ^^^^^^^. Generic store. Expects a MachineMemOperand in addition to explicit; operands. If the stored value size is greater than the memory size,; the high bits are implicitly truncated. If this is a vector store, the; high elements are discarded (i.e. this does not function as a per-lane; vector, truncating store). G_INDEXED_STORE; ^^^^^^^^^^^^^^^. Combines a store with a GEP. See description of G_INDEXED_LOAD for indexing behaviour. G_ATOMIC_CMPXCHG_WITH_SUCCESS; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Generic atomic cmpxchg with internal success check. Expects a; MachineMemOperand in addition to explicit operands. G_ATOMIC_CMPXCHG; ^^^^^^^^^^^^^^^^. Generic atomic cmpxchg. Expects a MachineMemOperand in addition to explicit; operands. G_ATOMICRMW_XCHG, G_ATOMICRMW_ADD, G_ATOMICRMW_SUB, G_ATOMICRMW_AND,; G_ATOMICRMW_NAND, G_ATOMICRMW_OR, G_ATOMICRMW_XOR, G_ATOMICRMW_MAX,; G_ATOMICRMW_MIN, G_ATOMICRMW_UMAX, G_ATOMICRMW_UMIN, G_ATOMICRMW_FA",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst:16517,load,load,16517,interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst,2,"['load', 'perform']","['load', 'performed']"
Performance," MakeStruct() { return DeviceS(); }. // Now host and device code can call MakeStruct(). Unfortunately, this idiom isn't compatible with nvcc, because it doesn't allow; you to overload based on the H/D attributes. Here's an idiom that works with; both clang and nvcc:. .. code-block:: c++. struct HostS { ... };; struct DeviceS { ... };. #ifdef __NVCC__; #ifndef __CUDA_ARCH__; __host__ HostS MakeStruct() { return HostS(); }; #else; __device__ DeviceS MakeStruct() { return DeviceS(); }; #endif; #else; __host__ HostS MakeStruct() { return HostS(); }; __device__ DeviceS MakeStruct() { return DeviceS(); }; #endif. // Now host and device code can call MakeStruct(). Hopefully you don't have to do this sort of thing often. Optimizations; =============. Modern CPUs and GPUs are architecturally quite different, so code that's fast; on a CPU isn't necessarily fast on a GPU. We've made a number of changes to; LLVM to make it generate good GPU code. Among these changes are:. * `Straight-line scalar optimizations <https://goo.gl/4Rb9As>`_ -- These; reduce redundancy within straight-line code. * `Aggressive speculative execution; <https://llvm.org/docs/doxygen/html/SpeculativeExecution_8cpp_source.html>`_; -- This is mainly for promoting straight-line scalar optimizations, which are; most effective on code along dominator paths. * `Memory space inference; <https://llvm.org/doxygen/NVPTXInferAddressSpaces_8cpp_source.html>`_ --; In PTX, we can operate on pointers that are in a particular ""address space""; (global, shared, constant, or local), or we can operate on pointers in the; ""generic"" address space, which can point to anything. Operations in a; non-generic address space are faster, but pointers in CUDA are not explicitly; annotated with their address space, so it's up to LLVM to infer it where; possible. * `Bypassing 64-bit divides; <https://llvm.org/docs/doxygen/html/BypassSlowDivision_8cpp_source.html>`_ --; This was an existing optimization that we enabled for the PTX backend.",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst:18437,optimiz,optimizations,18437,interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst,1,['optimiz'],['optimizations']
Performance," Making a volume with a given shape in one step; TGeoVolume *vol = gGeoManager->MakeBox(""VNAME"",ptrMed,dx,dy,dz);; TGeoVolume *vol = gGeoManager->MakeTubs(""VNAME"",ptrMed,rmin,rmax,; dz,phi1,phi2);. // See class TGeoManager for the rest of shapes.; // Making a volume with a given shape with a unique prototype; TGeoVolume *vol = gGeoManager->Volume(""VNAME"",""XXXX"",nmed,upar,; npar);. // Where XXXX stands for the first 4 letters of the specific shape; // classes, nmed is the medium number, upar is an Double_t * array; // of the shape parameters and npar is the number of parameters.; // This prototype allows (npar = 0) to define volumes with shape; // defined only at positioning time (volumes defined in this way; // need to be positioned using TGeoManager::Node() method); ```. #### Positioned Volumes (Nodes). Geometrical modeling is a difficult task when the number of different; geometrical objects is 106-108. This is more or less the case for; detector geometries of complex experiments, where a ‘flat' CSG model; description cannot scale with the current CPU performances. This is the; reason why models like GEANT [1] introduced an additional dimension; (depth) in order to reduce the complexity of the problem. This concept; is also preserved by the ROOT modeller and introduces a pure geometrical; constraint between objects (volumes in our case) - containment. This; means in fact that any positioned volume has to be contained by another.; Now what means contained and positioned?. - We will say that a volume `contains` a point if this is inside the; shape associated to the volume. For instance, a volume having a box; shape will contain all points `P=(X,Y,Z)` verifying the conditions:; `Abs(Pi)dXi`. The points on the shape boundaries are considered as; inside the volume. The volume contains a daughter if it contains all; the points contained by the daughter.; - The definition of containment works of course only with points; defined in the local coordinate system of the consid",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md:65854,perform,performances,65854,documentation/users-guide/Geometry.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md,1,['perform'],['performances']
Performance," Mask out bits from all three loads.; ```. ###### Preserving the flags while hardening loaded values on Haswell, Zen, and newer processors. Sadly, there are no useful instructions on x86 that apply a mask to all 64 bits; without touching the flag registers. However, we can harden loaded values that; are narrower than a word (fewer than 32-bits on 32-bit systems and fewer than; 64-bits on 64-bit systems) by zero-extending the value to the full word size; and then shifting right by at least the number of original bits using the BMI2; `shrx` instruction:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; addl (%rsi), %edi # Load and accumulate 32 bits of data.; shrxq %rax, %rdi, %rdi # Shift out all 32 bits loaded.; ```. Because on x86 the zero-extend is free, this can efficiently harden the loaded; value. ##### Hardening the address of the load. When hardening the loaded value is inapplicable, most often because the; instruction directly leaks information (like `cmp` or `jmpq`), we switch to; hardening the _address_ of the load instead of the loaded value. This avoids; increasing register pressure by unfolding the load or paying some other high; cost. To understand how this works in practice, we need to examine the exact; semantics of the x86 addressing modes which, in its fully general form, looks; like `(%base,%index,scale)offset`. Here `%base` and `%index` are 64-bit; registers that can potentially be any value, and may be attacker controlled,; and `scale` and `offset` are fixed immediate values. `scale` must be `1`, `2`,; `4`, or `8`, and `offset` can be any 32-bit sign extended value. The exact; computation performed to find the address is then: `%base + (scale * %index) +; offset` under 64-bit 2's complement modular arithmetic. One issue with this approach is that, after hardening, the `%base + (scale *; %index)` subexpression will compute a value near zero (`-1 + (scale * -1)`) and; then a large, positive `offset` will index",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:27551,load,loaded,27551,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,3,['load'],"['load', 'loaded']"
Performance," MemorySanitizer; -fsanitize-recover=<value>; Enable recovery for specified sanitizers; -fsanitize-stats Enable sanitizer statistics gathering.; -fsanitize-thread-atomics; Enable atomic operations instrumentation in ThreadSanitizer (default); -fsanitize-thread-func-entry-exit; Enable function entry/exit instrumentation in ThreadSanitizer (default); -fsanitize-thread-memory-access; Enable memory access instrumentation in ThreadSanitizer (default); -fsanitize-trap=<value> Enable trapping for specified sanitizers; -fsanitize-undefined-strip-path-components=<number>; Strip (or keep only, if negative) a given number of path components when emitting check metadata.; -fsanitize=<check> Turn on runtime checks for various forms of undefined or suspicious; behavior. See user manual for available checks; -fsplit-lto-unit Enables splitting of the LTO unit.; -fstandalone-debug Emit full debug info for all types used by the program; -fstrict-aliasing	 Enable optimizations based on strict aliasing rules; -fsyntax-only Run the preprocessor, parser and semantic analysis stages; -fwhole-program-vtables Enables whole-program vtable optimization. Requires -flto; -gcodeview-ghash Emit type record hashes in a .debug$H section; -gcodeview Generate CodeView debug information; -gline-directives-only Emit debug line info directives only; -gline-tables-only Emit debug line number tables only; -miamcu Use Intel MCU ABI; -mllvm <value> Additional arguments to forward to LLVM's option processing; -nobuiltininc Disable builtin #include directories; -Qunused-arguments Don't emit warning for unused driver arguments; -R<remark> Enable the specified remark; --target=<value> Generate code for the given target; --version Print version information; -v Show commands to run and use verbose output; -W<warning> Enable the specified warning; -Xclang <arg> Pass <arg> to the clang compiler. The /clang: Option; ^^^^^^^^^^^^^^^^^^. When clang-cl is run with a set of ``/clang:<arg>`` options, it will gather all; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:185311,optimiz,optimizations,185311,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,2,['optimiz'],"['optimization', 'optimizations']"
Performance," More Information on R interpolation; [here](http://stat.ethz.ch/R-manual/R-patched/library/stats/html/approxfun.html). ~~~{.cxx}; #include<TRInterface.h>; #include<TRandom.h>; #include<vector>. void Interpolation(); {; ROOT::R::TRInterface &r=ROOT::R::TRInterface::Instance();; //Creating points; TRandom rg;; std::vector<Double_t> x(10),y(10);; for(int i=0;i<10;i++); {; x[i]=i;; y[i]=rg.Gaus();; }. r[""x""]=x;; r[""y""]=y;. r<<""dev.new()"";//Required to activate new window for plotting; //Plot parameter. Plotting using two rows and one column; r<<""par(mfrow = c(2,1))"";. //plotting the points; r<<""plot(x, y, main = 'approx(.) and approxfun(.)')"";. //The function ""approx"" returns a list with components x and y,; //containing n coordinates which interpolate the given data points according to the method (and rule) desired.; r<<""points(approx(x, y), col = 2, pch = '*')"";; r<<""points(approx(x, y, method = 'constant'), col = 4, pch = '*')"";. //The function ""approxfun"" returns a function performing (linear or constant); //interpolation of the given data.; //For a given set of x values, this function will return the corresponding interpolated values.; r<<""f <- approxfun(x, y)"";. r<<""curve(f(x), 0, 11, col = 'green2')"";; r<<""points(x, y)"";. //using approxfun with const method; r<<""fc <- approxfun(x, y, method = 'const')"";; r<<""curve(fc(x), 0, 10, col = 'darkblue', add = TRUE)"";; // different interpolation on left and right side :; r<<""plot(approxfun(x, y, rule = 2:1), 0, 11,col = 'tomato', add = TRUE, lty = 3, lwd = 2)"";; }; ~~~; The image shows the interpolated function plotted within R:; \image html R_image3.png. ## Integration (Passing vectorized function to R); Numerical integration using R passing the function from ROOT. ~~~{.cxx}; #include<TMath.h>; #include<TRInterface.h>; #include<Math/Integrator.h>; #include<TF1.h>. //To integrate using R the function must be vectorized; //The idea is just to receive a vector like an argument,to evaluate; //every element saving the result",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/r/doc/users-guide/ROOTR_Users_Guide.md:21555,perform,performing,21555,bindings/r/doc/users-guide/ROOTR_Users_Guide.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/r/doc/users-guide/ROOTR_Users_Guide.md,1,['perform'],['performing']
Performance," Most layers that derived from IRLayer can rely on this default implementation; of the ``add`` method. These two operations, ``add`` and ``emit``, together constitute the layer; concept: A layer is a way to wrap a part of a compiler pipeline (in this case; the ""opt"" phase of an LLVM compiler) whose API is opaque to ORC with an; interface that ORC can call as needed. The add method takes an; module in some input program representation (in this case an LLVM IR module); and stores it in the target ``JITDylib``, arranging for it to be passed back; to the layer's emit method when any symbol defined by that module is requested.; Each layer can complete its own work by calling the ``emit`` method of its base; layer. For example, in this tutorial our IRTransformLayer calls through to; our IRCompileLayer to compile the transformed IR, and our IRCompileLayer in; turn calls our ObjectLayer to link the object file produced by our compiler. So far we have learned how to optimize and compile our LLVM IR, but we have; not focused on when compilation happens. Our current REPL optimizes and; compiles each function as soon as it is referenced by any other code,; regardless of whether it is ever called at runtime. In the next chapter we; will introduce a fully lazy compilation, in which functions are not compiled; until they are first called at run-time. At this point the trade-offs get much; more interesting: the lazier we are, the quicker we can start executing the; first function, but the more often we will have to pause to compile newly; encountered functions. If we only code-gen lazily, but optimize eagerly, we; will have a longer startup time (as everything is optimized at that time) but; relatively short pauses as each function just passes through code-gen. If we; both optimize and code-gen lazily we can start executing the first function; more quickly, but we will have longer pauses as each function has to be both; optimized and code-gen'd when it is first executed. Things bec",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/BuildingAJIT2.rst:10386,optimiz,optimize,10386,interpreter/llvm-project/llvm/docs/tutorial/BuildingAJIT2.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/BuildingAJIT2.rst,1,['optimiz'],['optimize']
Performance," Name Description; ======= ======= ================ =========================================; 0:9 10 bits Work-Item Id X Work-item id in X; dimension of work-group for; wavefront lane. Always initialized. 10:19 10 bits Work-Item Id Y Work-item id in Y; dimension of work-group for; wavefront lane. Initialized if enable_vgpr_workitem_id >; 0, otherwise set to 0.; 20:29 10 bits Work-Item Id Z Work-item id in Z; dimension of work-group for; wavefront lane. Initialized if enable_vgpr_workitem_id >; 1, otherwise set to 0.; 30:31 2 bits Reserved, set to 0.; ======= ======= ================ =========================================. The setting of registers is done by GPU CP/ADC/SPI hardware as follows:. 1. SGPRs before the Work-Group Ids are set by CP using the 16 User Data; registers.; 2. Work-group Id registers X, Y, Z are set by ADC which supports any; combination including none.; 3. Scratch Wavefront Offset is set by SPI in a per wavefront basis which is why; its value cannot be included with the flat scratch init value which is per; queue (see :ref:`amdgpu-amdhsa-kernel-prolog-flat-scratch`).; 4. The VGPRs are set by SPI which only supports specifying either (X), (X, Y); or (X, Y, Z).; 5. Flat Scratch register pair initialization is described in; :ref:`amdgpu-amdhsa-kernel-prolog-flat-scratch`. The global segment can be accessed either using buffer instructions (GFX6 which; has V# 64-bit address support), flat instructions (GFX7-GFX11), or global; instructions (GFX9-GFX11). If buffer operations are used, then the compiler can generate a V# with the; following properties:. * base address of 0; * no swizzle; * ATC: 1 if IOMMU present (such as APU); * ptr64: 1; * MTYPE set to support memory coherence that matches the runtime (such as CC for; APU and NC for dGPU). .. _amdgpu-amdhsa-kernarg-preload:. Preloaded Kernel Arguments; ++++++++++++++++++++++++++. On hardware that supports this feature, kernel arguments can be preloaded into; User SGPRs, up to the maximum number of",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:189741,queue,queue,189741,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['queue'],['queue']
Performance," No 1 − Cost parameter. Tol No 0.01 − Tolerance parameter. MaxIter No 1000 − Maximum number of training loops. Configuration options for MVA method :. Configuration options reference for MVA method: CFMlpANN. Option Array Default value Predefined values Description. V No False − Verbose output (short form of VerbosityLevel below - overrides the latter one). VerbosityLevel No Default Default, Debug, Verbose, Info, Warning, Error, Fatal Verbosity level. VarTransform No None − List of variable transformations performed before training, e.g., D_Background,P_Signal,G,N_AllClasses for: Decorrelation, PCA-transformation, Gaussianisation, Normalisation, each for the given class of events ('AllClasses' denotes all events of all classes, if no class indication is given, 'All' is assumed). H No False − Print method-specific help message. CreateMVAPdfs No False − Create PDFs for classifier outputs (signal and background). IgnoreNegWeightsInTraining No False − Events with negative weights are ignored in the training (but are included for testing and performance evaluation). NCycles No 3000 − Number of training cycles. HiddenLayers No N,N-1 − Specification of hidden layer architecture. Configuration options for MVA method :. Configuration options reference for MVA method: KNN. Option Array Default value Predefined values Description. V No False − Verbose output (short form of VerbosityLevel below - overrides the latter one). VerbosityLevel No Default Default, Debug, Verbose, Info, Warning, Error, Fatal Verbosity level. VarTransform No None − List of variable transformations performed before training, e.g., D_Background,P_Signal,G,N_AllClasses for: Decorrelation, PCA-transformation, Gaussianisation, Normalisation, each for the given class of events ('AllClasses' denotes all events of all classes, if no class indication is given, 'All' is assumed). H No False − Print method-specific help message. CreateMVAPdfs No False − Create PDFs for classifier outputs (signal and background). I",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/tmva/UsersGuide/optionRef.html:9277,perform,performance,9277,documentation/tmva/UsersGuide/optionRef.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/tmva/UsersGuide/optionRef.html,2,['perform'],['performance']
Performance," No None None, Gauss, LinNeighbors Kernel type used. TargetSelection No Mean Mean, Mpv Target selection method. Configuration options for MVA method :. Configuration options reference for MVA method: TMlpANN. Option Array Default value Predefined values Description. V No False − Verbose output (short form of VerbosityLevel below - overrides the latter one). VerbosityLevel No Default Default, Debug, Verbose, Info, Warning, Error, Fatal Verbosity level. VarTransform No None − List of variable transformations performed before training, e.g., D_Background,P_Signal,G,N_AllClasses for: Decorrelation, PCA-transformation, Gaussianisation, Normalisation, each for the given class of events ('AllClasses' denotes all events of all classes, if no class indication is given, 'All' is assumed). H No False − Print method-specific help message. CreateMVAPdfs No False − Create PDFs for classifier outputs (signal and background). IgnoreNegWeightsInTraining No False − Events with negative weights are ignored in the training (but are included for testing and performance evaluation). NCycles No 200 − Number of training cycles. HiddenLayers No N,N-1 − Specification of hidden layer architecture (N stands for number of variables; any integers may also be used). ValidationFraction No 0.5 − Fraction of events in training tree used for cross validation. LearningMethod No Stochastic Stochastic, Batch, SteepestDescent, RibierePolak, FletcherReeves, BFGS Learning method. Configuration options for setup and tuning of specific fitter :. Configuration options reference for fitting method: Simulated Annealing (SA). Option Array Default value Predefined values Description. MaxCalls No 100000 − Maximum number of minimisation calls. InitialTemp No 1e+06 − Initial temperature. MinTemp No 1e-06 − Mimimum temperature. Eps No 1e-10 − Epsilon. TempScale No 1 − Temperature scale. AdaptiveSpeed No 1 − Adaptive speed. TempAdaptiveStep No 0.009875 − Step made in each generation temperature adaptive. UseDefaultSca",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/tmva/UsersGuide/optionRef.html:28695,perform,performance,28695,documentation/tmva/UsersGuide/optionRef.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/tmva/UsersGuide/optionRef.html,2,['perform'],['performance']
Performance," Note that NotAtomic volatile loads and stores are not properly; atomic; do not try to use them as a substitute. (Per the C/C++ standards,; volatile does provide some limited guarantees around asynchronous signals, but; atomics are generally a better solution.). Notes for optimizers; Introducing loads to shared variables along a codepath where they would not; otherwise exist is allowed; introducing stores to shared variables is not. See; `Optimization outside atomic`_. Notes for code generation; The one interesting restriction here is that it is not allowed to write to; bytes outside of the bytes relevant to a store. This is mostly relevant to; unaligned stores: it is not allowed in general to convert an unaligned store; into two aligned stores of the same width as the unaligned store. Backends are; also expected to generate an i8 store as an i8 store, and not an instruction; which writes to surrounding bytes. (If you are writing a backend for an; architecture which cannot satisfy these restrictions and cares about; concurrency, please send an email to llvm-dev.). Unordered; ---------. Unordered is the lowest level of atomicity. It essentially guarantees that races; produce somewhat sane results instead of having undefined behavior. It also; guarantees the operation to be lock-free, so it does not depend on the data; being part of a special atomic structure or depend on a separate per-process; global lock. Note that code generation will fail for unsupported atomic; operations; if you need such an operation, use explicit locking. Relevant standard; This is intended to match the Java memory model for shared variables. Notes for frontends; This cannot be used for synchronization, but is useful for Java and other; ""safe"" languages which need to guarantee that the generated code never; exhibits undefined behavior. Note that this guarantee is cheap on common; platforms for loads of a native width, but can be expensive or unavailable for; wider loads, like a 64-bit store on",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Atomics.rst:7876,concurren,concurrency,7876,interpreter/llvm-project/llvm/docs/Atomics.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Atomics.rst,1,['concurren'],['concurrency']
Performance," Note: Method Thread0 cannot be a virtual member function, since the cast; of `Thread0` to `void(*)` in the **`TThread`** constructor may raise; problems with C++ virtual function table. However, Thread0 may call; another virtual member function virtual void `Myclass::Func0()` which; then can be overridden in a derived class of `Myclass`. (See example; `TMhs3`). Class `Myclass` may also provide a method to stop the running thread:. ``` {.cpp}; Int_t Myclass::Threadstop() {; if (mTh) {; TThread::Delete(mTh);; delete mTh;; mTh=0;; return 0;; }; return 1;; }; ```. Example `TMhs3:` Class **`TThreadframe`**; (`TThreadframe.h, TThreadframe.cxx`) is a simple example of a framework; class managing up to four threaded methods. Class `TMhs3`; (`TMhs3.h, TMhs3.cxx)` inherits from this base class, showing the `mhs3`; example 8.1 `(mhs3.h, mhs3.cxx) `within a class. The `Makefile` of this; example builds the shared libraries `libTThreadframe.so` and; `libTMhs3.so`. These are either loaded or executed by the ROOT script; `TMhs3demo.C,` or are linked against an executable: `TMhs3run.cxx`. ### Known Problems. Parts of the ROOT framework, like the interpreter, are not yet; thread-safe. Therefore, you should use this package with caution. If you; restrict your threads to distinct and \`simple' duties, you will able to; benefit from their use. The **`TThread`** class is available on all; platforms, which provide a POSIX compliant thread implementation. On; Linux, Xavier Leroy's Linux Threads implementation is widely used, but; the **`TThread`** implementation should be usable on all platforms that; provide `pthread`. **Linux Xlib on SMP machines** is not yet thread-safe. This may cause; crashes during threaded graphics operations; this problem is independent; of ROOT. **Object instantiation:** there is no implicit locking mechanism for; memory allocation and global ROOT lists. The user has to explicitly; protect their code when using them. ## The Signals of ROOT. The list of default s",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Threads.md:16829,load,loaded,16829,documentation/users-guide/Threads.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Threads.md,1,['load'],['loaded']
Performance," OUTPUT_NAME LLVM ${INSTALL_WITH_TOOLCHAIN} ${SOURCES}); # Add symlink for backwards compatibility with old library name; llvm_install_library_symlink(LLVM-${LLVM_VERSION_MAJOR}${LLVM_VERSION_SUFFIX} $<TARGET_FILE_NAME:LLVM> SHARED FULL_DEST COMPONENT LLVM); endif(). list(REMOVE_DUPLICATES LIB_NAMES); if(""${CMAKE_SYSTEM_NAME}"" STREQUAL ""Darwin""); set(LIB_NAMES -Wl,-all_load ${LIB_NAMES}); else(); configure_file(; ${CMAKE_CURRENT_SOURCE_DIR}/simple_version_script.map.in; ${LLVM_LIBRARY_DIR}/tools/llvm-shlib/simple_version_script.map). # GNU ld doesn't resolve symbols in the version script.; set(LIB_NAMES -Wl,--whole-archive ${LIB_NAMES} -Wl,--no-whole-archive); if (NOT LLVM_LINKER_IS_SOLARISLD AND NOT MINGW); # Solaris ld does not accept global: *; so there is no way to version *all* global symbols; set(LIB_NAMES -Wl,--version-script,${LLVM_LIBRARY_DIR}/tools/llvm-shlib/simple_version_script.map ${LIB_NAMES}); endif(); if (NOT MINGW AND NOT LLVM_LINKER_IS_SOLARISLD_ILLUMOS); # Optimize function calls for default visibility definitions to avoid PLT and; # reduce dynamic relocations.; # Note: for -fno-pic default, the address of a function may be different from; # inside and outside libLLVM.so.; target_link_options(LLVM PRIVATE LINKER:-Bsymbolic-functions); endif(); endif(). target_link_libraries(LLVM PRIVATE ${LIB_NAMES}). if(LLVM_ENABLE_THREADS AND NOT HAVE_CXX_ATOMICS64_WITHOUT_LIB); target_link_libraries(LLVM PUBLIC atomic); endif(). if (APPLE); set_property(TARGET LLVM APPEND_STRING PROPERTY; LINK_FLAGS; "" -compatibility_version 1 -current_version ${LLVM_VERSION_MAJOR}.${LLVM_VERSION_MINOR}.${LLVM_VERSION_PATCH}""); endif(). if(TARGET libLLVMExports); add_dependencies(LLVM libLLVMExports); endif(); endif(). if(LLVM_BUILD_LLVM_C_DYLIB AND NOT MSVC); if(NOT APPLE); message(FATAL_ERROR ""Generating libLLVM-c is only supported on Darwin""); endif(). if(NOT LLVM_BUILD_LLVM_DYLIB); message(FATAL_ERROR ""Generating libLLVM-c requires LLVM_BUILD_LLVM_C_DYLIB on Darwin""); endif",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-shlib/CMakeLists.txt:2353,Optimiz,Optimize,2353,interpreter/llvm-project/llvm/tools/llvm-shlib/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-shlib/CMakeLists.txt,1,['Optimiz'],['Optimize']
Performance," Optimizations`_ --- This optional stage consists of a; series of machine-code optimizations that operate on the SSA-form produced by; the instruction selector. Optimizations like modulo-scheduling or peephole; optimization work here. 4. `Register Allocation`_ --- The target code is transformed from an infinite; virtual register file in SSA form to the concrete register file used by the; target. This phase introduces spill code and eliminates all virtual register; references from the program. 5. `Prolog/Epilog Code Insertion`_ --- Once the machine code has been generated; for the function and the amount of stack space required is known (used for; LLVM alloca's and spill slots), the prolog and epilog code for the function; can be inserted and ""abstract stack location references"" can be eliminated.; This stage is responsible for implementing optimizations like frame-pointer; elimination and stack packing. 6. `Late Machine Code Optimizations`_ --- Optimizations that operate on ""final""; machine code can go here, such as spill code scheduling and peephole; optimizations. 7. `Code Emission`_ --- The final stage actually puts out the code for the; current function, either in the target assembler format or in machine; code. The code generator is based on the assumption that the instruction selector will; use an optimal pattern matching selector to create high-quality sequences of; native instructions. Alternative code generator designs based on pattern; expansion and aggressive iterative peephole optimization are much slower. This; design permits efficient compilation (important for JIT environments) and; aggressive optimization (used when generating code offline) by allowing; components of varying levels of sophistication to be used for any step of; compilation. In addition to these stages, target implementations can insert arbitrary; target-specific passes into the flow. For example, the X86 target uses a; special pass to handle the 80x87 floating point stack architecture.",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:7110,optimiz,optimizations,7110,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst,1,['optimiz'],['optimizations']
Performance," PassManager is set up, we need to make use of it. We do this by; running it after our newly created function is constructed (in; ``FunctionAST::codegen()``), but before it is returned to the client:. .. code-block:: c++. if (Value *RetVal = Body->codegen()) {; // Finish off the function.; Builder.CreateRet(RetVal);. // Validate the generated code, checking for consistency.; verifyFunction(*TheFunction);. // Optimize the function.; TheFPM->run(*TheFunction, *TheFAM);. return TheFunction;; }. As you can see, this is pretty straightforward. The; ``FunctionPassManager`` optimizes and updates the LLVM Function\* in; place, improving (hopefully) its body. With this in place, we can try; our test above again:. ::. ready> def test(x) (1+2+x)*(x+(1+2));; ready> Read function definition:; define double @test(double %x) {; entry:; %addtmp = fadd double %x, 3.000000e+00; %multmp = fmul double %addtmp, %addtmp; ret double %multmp; }. As expected, we now get our nicely optimized code, saving a floating; point add instruction from every execution of this function. LLVM provides a wide variety of optimizations that can be used in; certain circumstances. Some `documentation about the various; passes <../../Passes.html>`_ is available, but it isn't very complete.; Another good source of ideas can come from looking at the passes that; ``Clang`` runs to get started. The ""``opt``"" tool allows you to; experiment with passes from the command line, so you can see if they do; anything. Now that we have reasonable code coming out of our front-end, let's talk; about executing it!. Adding a JIT Compiler; =====================. Code that is available in LLVM IR can have a wide variety of tools; applied to it. For example, you can run optimizations on it (as we did; above), you can dump it out in textual or binary forms, you can compile; the code to an assembly file (.s) for some target, or you can JIT; compile it. The nice thing about the LLVM IR representation is that it; is the ""common curren",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl04.rst:8946,optimiz,optimized,8946,interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl04.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl04.rst,1,['optimiz'],['optimized']
Performance," PyPy with pyproject.toml; * ``std::string`` not converterd to ``str`` on function returns; * Cover more use cases where C string memory can be managed; * Automatic memory management of converted python functions; * Added pyinstaller hooks (https://stackoverflow.com/questions/64406727); * Support for enums in pseudo-constructors of aggregates; * Fixes for overloaded/split-access protected members in cross-inheritance; * Support for deep, mixed, hierarchies for multi-cross-inheritance; * Added tp_iter method to low level views. 2020-11-06: 1.8.6; -----------------. * Fix preprocessor macro of CPyCppyy header for Windows/MSVC. 2020-10-31: 1.8.5; -----------------. * Fix leaks when using vector iterators on Py3/Linux. 2020-10-10: 1.8.4; -----------------. * ``std::string`` globals/data members no longer automatically converted to ``str``; * New methods for std::string to allow ``str`` interchangability; * Added a ``decode`` method to ``std::string``; * Add pythonized ``__contains__`` to ``std::set``; * Fix constructor generation for aggregates with static data; * Fix performance bug when using implicit conversions; * Fix memory overwrite when parsing during sorting of methods; * PyPy pip install again falls back to setup.py install. 2020-09-21: 1.8.3; -----------------. * Add initializer constructors for PODs and aggregates; * Use actual underlying type for enums, where possible; * Enum values remain instances of their type; * Expose enum underlying type name as ``__underlying`` and ``__ctype__``; * Strictly follow C++ enum scoping rules; * Same enum in transparent scope refers to same type; * More detailed enum ``repr()`` printing, where possible; * Fix for (extern) explicit template instantiations in namespaces; * Throw objects from an std::tuple a life line; * Global pythonizors now always run on all classes; * Simplified iteraton over STL-like containers defining ``begin()``/``end()``. 2020-09-08: 1.8.2; -----------------. * Add ``cppyy.set_debug()`` to enable debu",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst:10004,perform,performance,10004,bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst,1,['perform'],['performance']
Performance," Python interpreter Application Programming Interfaces (APIs;; the exact same that Python uses itself internally).; If you use a compile-time binder such as `SWIG`_ or `pybind11`_ to bind a C++; class, then what gets compiled is the series of API calls necessary to; construct a Python-side equivalent at `run-time` (when the module gets; loaded), not the Python class object.; In short, whether a binding is created at ""compile-time"" or at run-time has; no measurable bearing on performance. What does affect performance is the overhead to cross the language barrier.; This consists of unboxing Python objects to extract or convert the underlying; objects or data to something that matches what C++ expects; overload; resolution based on the unboxed arguments; offset calculations; and finally; the actual dispatch.; As a practical matter, overload resolution is the most costly part, followed; by the unboxing and conversion.; Best performance is achieved by specialization of the paths through the; run-time: recognize early the case at hand and select an optimized path.; For that reason, `PyPy`_ is so fast: JIT-ed traces operate on unboxed objects; and resolved overloads are baked into the trace, incurring no further cost.; Similarly, this is why pybind11 is so slow: its code generation is the C++; compiler's template engine, so complex path selection and specialization is; very hard to do in a performance-portable way. In cppyy, a great deal of attention has gone into built-in specialization; paths, which drives its performance.; For example, basic inheritance sequentially lines up classes, whereas; multiple (virtual) inheritance usually requires thunks.; Thus, when calling base class methods on a derived instance, the latter; requires offset calculations that depend on that instance, whereas the former; has fixed offsets fully determined by the class definitions themselves.; By labeling classes appropriately, single inheritance classes (by far the; most common case) do not inc",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst:2178,perform,performance,2178,bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst,2,"['optimiz', 'perform']","['optimized', 'performance']"
Performance," ROOT are typically faster from `PyROOT`, whereas loops are typically; slower. When programming in Python, the modus operandi is to consider; performance generally ""good enough"" on the outset, and when it turns out; that, it is not good enough; the performance critical part is converted; into C/C++ in an extension module. The school of thought where; pre-mature optimization is the root of all evil should find this way of; working very satisfying. In addition, if you look at their history, you; will see that many of the standard Python modules have followed this; path. Your code should always make maximum use of ROOT facilities; such that; most of the time is spending in compiled code. This goes even for very; simple things: e.g. do not compute invariant masses in Python, use; **`TLorentzVector`** instead. Moreover, before you start optimizing,; make sure that you have run a profiler to find out where the bottlenecks; are. Some performance, without cost in terms of programmer effort, may; be gained by using `psyco`, see the next link:; <http://psyco.sourceforge.net>, a Python just in time compiler (JIT).; Note, however, that `psyco` is limited to Intel i386 CPUs. Since `psyco`; optimizes Python, not `PyROOT` calls; it generally does not improve; performance that much if most of your code consists of ROOT API calls.; Mathematical computations in Python, on the other hand, benefit a lot. Every call to a Python member function results in a lookup of that; member function and an association of this method with `'self'`.; Furthermore, a temporary object is created during this process that is; discarded after the method call. In inner loops, it may be worth your; while (up to 30%), to short-cut this process by looking up and binding; the method before the loop, and discarding it afterwards. Here is an; example:. ``` {.cpp}; hpx = TH1F('hpx','px',100,-4,4); hpxFill = hpx.Fill # cache bound method; for i in xrange(25000):; px = gRandom.Gaus(); hpxFill(px) # use bound method:",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/PythonRuby.md:23553,perform,performance,23553,documentation/users-guide/PythonRuby.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/PythonRuby.md,1,['perform'],['performance']
Performance, ROOT_EXECUTABLE(testReshape TestReshape.cxx LIBRARIES ${Libraries}); ROOT_ADD_TEST(TMVA-DNN-CNN-Reshape COMMAND testReshape). ROOT_EXECUTABLE(testRotWeights TestRotateWeights.cxx LIBRARIES ${Libraries}); ROOT_ADD_TEST(TMVA-DNN-CNN-RotWeights COMMAND testRotWeights). #-- features not implemeted in ref architectures; #ROOT_EXECUTABLE(testForwardPass TestForwardPass.cxx LIBRARIES ${Libraries}); #ROOT_ADD_TEST(TMVA-DNN-CNN-Forward COMMAND testForwardPass). #ROOT_EXECUTABLE(testConvNetLoss TestConvNetLoss.cxx LIBRARIES ${Libraries}); #ROOT_ADD_TEST(TMVA-DNN-CNN-Loss COMMAND testConvNetLoss). #ROOT_EXECUTABLE(testConvNetPred TestConvNetPrediction.cxx LIBRARIES ${Libraries}); #ROOT_ADD_TEST(TMVA-DNN-CNN-Pred COMMAND testConvNetPred). #ROOT_EXECUTABLE(testDLMinimization TestMinimization.cxx LIBRARIES ${Libraries}); #ROOT_ADD_TEST(TMVA-DNN-CNN-Minimization COMMAND testDLMinimization). #ROOT_EXECUTABLE(testTensorDataLoader TestTensorDataLoader.cxx LIBRARIES ${Libraries}); #ROOT_ADD_TEST(TMVA-DNN-Tensor-Data-Loader COMMAND testTensorDataLoader). endif(). #--- CPU tests. ----------------------------; if ((BLAS_FOUND OR mathmore) AND imt AND tmva-cpu). ROOT_EXECUTABLE(testIm2ColCpu TestIm2ColCpu.cxx LIBRARIES ${Libraries}); ROOT_ADD_TEST(TMVA-DNN-CNN-Im2Col-CPU COMMAND testIm2ColCpu). ROOT_EXECUTABLE(testPoolingLayerCpu TestPoolingLayerCpu.cxx LIBRARIES ${Libraries}); ROOT_ADD_TEST(TMVA-DNN-CNN-PoolingLayer-CPU COMMAND testPoolingLayerCpu). ROOT_EXECUTABLE(testConvLayerCpu TestConvLayerCpu.cxx LIBRARIES ${Libraries}); ROOT_ADD_TEST(TMVA-DNN-CNN-ConvLayer-CPU COMMAND testConvLayerCpu). ROOT_EXECUTABLE(testRotWeightsCpu TestRotateWeightsCpu.cxx LIBRARIES ${Libraries}); ROOT_ADD_TEST(TMVA-DNN-CNN-RotWeights-CPU COMMAND testRotWeightsCpu). ROOT_EXECUTABLE(testForwardPassCpu TestForwardPassCpu.cxx LIBRARIES ${Libraries}); ROOT_ADD_TEST(TMVA-DNN-CNN-Forward-CPU COMMAND testForwardPassCpu). ROOT_EXECUTABLE(testConvNetLossCpu TestConvNetLossCpu.cxx LIBRARIES ${Libraries}); ROOT_ADD_TES,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/test/DNN/CNN/CMakeLists.txt:4696,Load,Loader,4696,tmva/tmva/test/DNN/CNN/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/test/DNN/CNN/CMakeLists.txt,1,['Load'],['Loader']
Performance," Recipe. A Recipe; may specify how its ingredients are to be transformed to produce the output IR; instructions; e.g., cloned once, replicated multiple times or widened; according to selected VF. :VPValue:; The base of VPlan's def-use relations class hierarchy. When instantiated, it; models a constant or a live-in Value in VPlan. It has users, which are of type; VPUser, but no operands. :VPUser:; A VPUser represents an entity that uses a number of VPValues as operands.; VPUser is similar in some aspects to LLVM's User class. :VPDef:; A VPDef represents an entity that defines zero, one or multiple VPValues.; It is used to model the fact that recipes in VPlan can define multiple; VPValues. :VPInstruction:; A VPInstruction is both a VPRecipe and a VPUser. It models a single; VPlan-level instruction to be generated if the VPlan is executed, including; its opcode and possibly additional characteristics. It is the basis for; writing instruction-level analyses and optimizations in VPlan as creating,; replacing or moving VPInstructions record both def-use and scheduling; decisions. VPInstructions also extend LLVM IR's opcodes with idiomatic; operations that enrich the Vectorizer's semantics. :VPTransformState:; Stores information used for generating output IR, passed from; LoopVectorizationPlanner to its selected VPlan for execution, and used to pass; additional information down to VPBlocks and VPRecipes. The Planning Process and VPlan Roadmap; ======================================. Transforming the Loop Vectorizer to use VPlan follows a staged approach. First,; VPlan is used to record the final vectorization decisions, and to execute them:; the Hierarchical CFG models the planned control-flow, and Recipes capture; decisions taken inside basic-blocks. Next, VPlan will be used also as the basis; for taking these decisions, effectively turning them into a series of; VPlan-to-VPlan algorithms. Finally, VPlan will support the planning process; itself including cost-based analys",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/VectorizationPlan.rst:7629,optimiz,optimizations,7629,interpreter/llvm-project/llvm/docs/VectorizationPlan.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/VectorizationPlan.rst,1,['optimiz'],['optimizations']
Performance," RooCategory category observable encoding distribution and accept/reject state respectively. See rf701_efficiencyfit.C for details ; RooAbsPdf - Included extended ML term by default in fit if p.d.f is extendable. You can still use Extended() to override default behavior. Do not run MINOS by default anymore if no fit options are provided.; RooProfileLL - Add option to always start minimization from global minimimum (takes more time, but improves reproducibility). Can now profile multi-core paralellized likelihoods as well.; RooRealSumPdf - Enable plotting of component p.d.f.s using same scheme as RooAddPdf, i.e. just use the Components() specified in plotOn().; RooExpensiveObjectCache - New cache manager for sharing and storing of expensive components cached by operator p.d.f.s ; RooMCStudy - Add Silence() argument to constructor to request minimal verbosity during running; RooMinuit - Improve contour() method to return RooPlots rather than drawing TGraphs straight on a canvas; RooWorkspace - Add private expensive object cache to workspace; RooBinningCategory - New real-to-category function that maps values of input RooRealVar to categories with labels that correspond to bins of input RooRealVar. See rf405_realtocatfuncs.C for details . RooStats; This is a new package introduced in this version for statistical tools built on top of RooFit. It is a joint effort between the LHC experiments and the ROOT team (see the RooStats Wiki page).; ; This version contains the interfaces for performing the statistical calculations and dealing with the obtained results and concrete classes implementing the statistical methods.; ; All the classes and functions in RooStats are provided in the namespace RooStats.; ; RooStats interfaces. ConfInterval: interface for describing a confidence interval. ; IntervalCalculator: interface for a statistical tool producing confidence intervals (class ConfInterval).; HypoTestResult: interface for representing results of a hypothesis test; HypoTest",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html:9115,cache,cache,9115,roofit/doc/v522/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html,2,['cache'],['cache']
Performance," SS = 0, IL = 0, <...>. This is only available when ``lldb`` is built with XML support.; Where possible the CPU's capabilities are used to decide which; fields are present, however this is not always possible or entirely; accurate. If in doubt, refer to the numerical value. * On Windows, LLDB can now read the thread names. Changes to Sanitizers; ---------------------; * HWASan now defaults to detecting use-after-scope bugs. * `SpecialCaseList <https://clang.llvm.org/docs/SanitizerSpecialCaseList.html#format>`_; used by sanitizer ignore lists (e.g. ``*_ignorelist.txt`` in the Clang; resource directory) now uses glob patterns instead of a variant of POSIX; Extended Regular Expression (where ``*`` is translated to ``.*``) by default.; Search for ``|`` to find patterns that may have different meanings now, and; replace ``a|b`` with ``{a,b}``. Changes to the Profile Runtime; ------------------------------. * Public header ``profile/instr_prof_interface.h`` is added to declare four; API functions to fine tune profile collection. Other Changes; -------------. * The ``Flags`` field of ``llvm::opt::Option`` has been split into ``Flags``; and ``Visibility`` to simplify option sharing between various drivers (such; as ``clang``, ``clang-cl``, or ``flang``) that rely on Clang's Options.td.; Overloads of ``llvm::opt::OptTable`` that use ``FlagsToInclude`` have been; deprecated. There is a script and instructions on how to resolve conflicts -; see https://reviews.llvm.org/D157150 and https://reviews.llvm.org/D157151 for; details. * On Linux, FreeBSD, and NetBSD, setting the environment variable; ``LLVM_ENABLE_SYMBOLIZER_MARKUP`` causes tools to print stacktraces using; :doc:`Symbolizer Markup <SymbolizerMarkupFormat>`.; This works even if the tools have no embedded symbol information (i.e. are; fully stripped); :doc:`llvm-symbolizer <CommandGuide/llvm-symbolizer>` can; symbolize the markup afterwards using ``debuginfod``. External Open Source Projects Using LLVM 15; =============",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ReleaseNotes.rst:18173,tune,tune,18173,interpreter/llvm-project/llvm/docs/ReleaseNotes.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ReleaseNotes.rst,1,['tune'],['tune']
Performance," See McCat/18-imp/ComputeBoundingBoxes for an example. //===---------------------------------------------------------------------===//. Pre-/post- indexed load / stores:. 1) We should not make the pre/post- indexed load/store transform if the base ptr; is guaranteed to be live beyond the load/store. This can happen if the base; ptr is live out of the block we are performing the optimization. e.g. mov r1, r2; ldr r3, [r1], #4; ... vs. ldr r3, [r2]; add r1, r2, #4; ... In most cases, this is just a wasted optimization. However, sometimes it can; negatively impact the performance because two-address code is more restrictive; when it comes to scheduling. Unfortunately, liveout information is currently unavailable during DAG combine; time. 2) Consider spliting a indexed load / store into a pair of add/sub + load/store; to solve #1 (in TwoAddressInstructionPass.cpp). 3) Enhance LSR to generate more opportunities for indexed ops. 4) Once we added support for multiple result patterns, write indexed loads; patterns instead of C++ instruction selection code. 5) Use VLDM / VSTM to emulate indexed FP load / store. //===---------------------------------------------------------------------===//. Implement support for some more tricky ways to materialize immediates. For; example, to get 0xffff8000, we can use:. mov r9, #&3f8000; sub r9, r9, #&400000. //===---------------------------------------------------------------------===//. We sometimes generate multiple add / sub instructions to update sp in prologue; and epilogue if the inc / dec value is too large to fit in a single immediate; operand. In some cases, perhaps it might be better to load the value from a; constantpool instead. //===---------------------------------------------------------------------===//. GCC generates significantly better code for this function. int foo(int StackPtr, unsigned char *Line, unsigned char *Stack, int LineLen) {; int i = 0;. if (StackPtr != 0) {; while (StackPtr != 0 && i < (((LineLen) < (32768",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/README.txt:9063,load,loads,9063,interpreter/llvm-project/llvm/lib/Target/ARM/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/README.txt,2,['load'],['loads']
Performance," SimplifyLibcalls into; libanalysis' constantfolding logic. This would allow IPSCCP to be able to; handle simple things like this:. static int foo(const char *X) { return strlen(X); }; int bar() { return foo(""abcd""); }. //===---------------------------------------------------------------------===//. function-attrs doesn't know much about memcpy/memset. This function should be; marked readnone rather than readonly, since it only twiddles local memory, but; function-attrs doesn't handle memset/memcpy/memmove aggressively:. struct X { int *p; int *q; };; int foo() {; int i = 0, j = 1;; struct X x, y;; int **p;; y.p = &i;; x.q = &j;; p = __builtin_memcpy (&x, &y, sizeof (int *));; return **p;; }. This can be seen at:; $ clang t.c -S -o - -mkernel -O0 -emit-llvm | opt -function-attrs -S. //===---------------------------------------------------------------------===//. Missed instcombine transformation:; define i1 @a(i32 %x) nounwind readnone {; entry:; %cmp = icmp eq i32 %x, 30; %sub = add i32 %x, -30; %cmp2 = icmp ugt i32 %sub, 9; %or = or i1 %cmp, %cmp2; ret i1 %or; }; This should be optimized to a single compare. Testcase derived from gcc. //===---------------------------------------------------------------------===//. Missed instcombine or reassociate transformation:; int a(int a, int b) { return (a==12)&(b>47)&(b<58); }. The sgt and slt should be combined into a single comparison. Testcase derived; from gcc. //===---------------------------------------------------------------------===//. Missed instcombine transformation:. %382 = srem i32 %tmp14.i, 64 ; [#uses=1]; %383 = zext i32 %382 to i64 ; [#uses=1]; %384 = shl i64 %381, %383 ; [#uses=1]; %385 = icmp slt i32 %tmp14.i, 64 ; [#uses=1]. The srem can be transformed to an and because if %tmp14.i is negative, the; shift is undefined. Testcase derived from 403.gcc. //===---------------------------------------------------------------------===//. This is a range comparison on a divided result (from 403.gcc):. %1337 = sdiv ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/README.txt:47678,optimiz,optimized,47678,interpreter/llvm-project/llvm/lib/Target/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/README.txt,2,['optimiz'],['optimized']
Performance," TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit lgkmcnt(0).; - Must happen before; the following; buffer_inv and; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local; atomicrmw value; being acquired. 3. buffer_inv sc0=1. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. atomicrmw acquire - agent - global 1. buffer/global_atomic; 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_inv.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 3. buffer_inv sc1=1. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - system - global 1. buffer/global_atomic; sc1=1; 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_inv.; - Ensures the; atomicrmw has; completed before; invalidating the; caches. 3. buffer_inv sc0=1 sc1=1. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale MTYPE NC global data.; MTYPE RW and CC memory will; never be stale due to the; memory probes. atomicrmw acquire - agent - generic 1. flat_atomic; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_inv.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 3. buffer_inv sc1=1. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - system - generic 1. flat_atomic sc1=1; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_inv.; - Ensures the; atomicrmw ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:301078,cache,caches,301078,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['cache'],['caches']
Performance," The :doc:`AdvancedBuilds` documentation describes the built-in tooling for; generating LLVM profiling information to drive Profile-Guided-Optimization. The; in-tree profiling tests are very limited, and generating the profile takes a; significant amount of time, but it can result in a significant improvement in; the performance of the generated binaries. In addition to PGO profiling we also have limited support in-tree for generating; linker order files. These files provide the linker with a suggested ordering for; functions in the final binary layout. This can measurably speed up clang by; physically grouping functions that are called temporally close to each other.; The current tooling is only available on Darwin systems with ``dtrace(1)``. It; is worth noting that dtrace is non-deterministic, and so the order file; generation using dtrace is also non-deterministic. Options for Reducing Size; =========================. .. warning::; Any steps taken to reduce the binary size will come at a cost of runtime; performance in the generated binaries. The simplest and least significant way to reduce binary size is to set the; *CMAKE_BUILD_TYPE* variable to ``MinSizeRel``, which will set the compiler; optimization level to ``-Os`` which optimizes for binary size. This will have; both the least benefit to size and the least impact on performance. The most impactful way to reduce binary size is to dynamically link LLVM into; all the tools. This reduces code size by decreasing duplication of common code; between the LLVM-based tools. This can be done by setting the following two; CMake options to ``On``: *LLVM_BUILD_LLVM_DYLIB* and *LLVM_LINK_LLVM_DYLIB*. .. warning::; Distributions should never be built using the *BUILD_SHARED_LIBS* CMake; option. (:ref:`See the warning above for more explanation <shared_libs>`.). Relevant CMake Options; ======================. This section provides documentation of the CMake options that are intended to; help construct distributions. This ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst:9988,perform,performance,9988,interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,1,['perform'],['performance']
Performance," The CoreCLR GC; -------------------------. .. code-block:: c++. F.setGC(""coreclr"");. This GC leverages the ``gc.statepoint`` mechanism to support the; `CoreCLR <https://github.com/dotnet/coreclr>`__ runtime. Support for this GC strategy is a work in progress. This strategy will; differ from; :ref:`statepoint-example GC<statepoint_example_gc>` strategy in; certain aspects like:. * Base-pointers of interior pointers are not explicitly; tracked and reported. * A different format is used for encoding stack maps. * Safe-point polls are only needed before loop-back edges; and before tail-calls (not needed at function-entry). Custom GC Strategies; ====================. If none of the built in GC strategy descriptions met your needs above, you will; need to define a custom GCStrategy and possibly, a custom LLVM pass to perform; lowering. Your best example of where to start defining a custom GCStrategy; would be to look at one of the built in strategies. You may be able to structure this additional code as a loadable plugin library.; Loadable plugins are sufficient if all you need is to enable a different; combination of built in functionality, but if you need to provide a custom; lowering pass, you will need to build a patched version of LLVM. If you think; you need a patched build, please ask for advice on llvm-dev. There may be an; easy way we can extend the support to make it work for your use case without; requiring a custom build. Collector Requirements; ----------------------. You should be able to leverage any existing collector library that includes the following elements:. #. A memory allocator which exposes an allocation function your compiled; code can call. #. A binary format for the stack map. A stack map describes the location; of references at a safepoint and is used by precise collectors to identify; references within a stack frame on the machine stack. Note that collectors; which conservatively scan the stack don't require such a structure. #. A stack craw",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst:21899,load,loadable,21899,interpreter/llvm-project/llvm/docs/GarbageCollection.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst,1,['load'],['loadable']
Performance," The caller and callee's return types must match. The caller cannot; be void unless the callee is, too. AArch64 constraints:. * No variable argument lists are used. Example:. Call as ``llc -tailcallopt test.ll``. .. code-block:: llvm. declare fastcc i32 @tailcallee(i32 inreg %a1, i32 inreg %a2, i32 %a3, i32 %a4). define fastcc i32 @tailcaller(i32 %in1, i32 %in2) {; %l1 = add i32 %in1, %in2; %tmp = tail call fastcc i32 @tailcallee(i32 inreg %in1, i32 inreg %in2, i32 %in1, i32 %l1); ret i32 %tmp; }. Implications of ``-tailcallopt``:. To support tail call optimization in situations where the callee has more; arguments than the caller a 'callee pops arguments' convention is used. This; currently causes each ``fastcc`` call that is not tail call optimized (because; one or more of above constraints are not met) to be followed by a readjustment; of the stack. So performance might be worse in such cases. Sibling call optimization; -------------------------. Sibling call optimization is a restricted form of tail call optimization.; Unlike tail call optimization described in the previous section, it can be; performed automatically on any tail calls when ``-tailcallopt`` option is not; specified. Sibling call optimization is currently performed on x86/x86-64 when the; following constraints are met:. * Caller and callee have the same calling convention. It can be either ``c`` or; ``fastcc``. * The call is a tail call - in tail position (ret immediately follows call and; ret uses value of call or is void). * Caller and callee have matching return type or the callee result is not used. * If any of the callee arguments are being passed in stack, they must be; available in caller's own incoming argument stack and the frame offsets must; be the same. Example:. .. code-block:: llvm. declare i32 @bar(i32, i32). define i32 @foo(i32 %a, i32 %b, i32 %c) {; entry:; %0 = tail call i32 @bar(i32 %a, i32 %b); ret i32 %0; }. The X86 backend; ---------------. The X86 code generator lives in the",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:88299,optimiz,optimization,88299,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst,2,['optimiz'],['optimization']
Performance," The following is a list of acronyms considered sufficiently useful that the; benefit of using them outweighs the cost of learning them. Acronyms that are; either not on the list or are used to refer to a different type should be; expanded. ============================ =============; Class name Variable name; ============================ =============; DeterministicFiniteAutomaton dfa; DominatorTree dt; LoopInfo li; MachineFunction mf; MachineInstr mi; MachineRegisterInfo mri; ScalarEvolution se; TargetInstrInfo tii; TargetLibraryInfo tli; TargetRegisterInfo tri; ============================ =============. In some cases renaming acronyms to the full type name will result in overly; verbose code. Unlike most classes, a variable's scope is limited and therefore; some of its purpose can implied from that scope, meaning that fewer words are; necessary to give it a clear name. For example, in an optimization pass the reader; can assume that a variable's purpose relates to optimization and therefore an; ``OptimizationRemarkEmitter`` variable could be given the name ``remarkEmitter``; or even ``remarker``. The following is a list of longer class names and the associated shorter; variable name. ========================= =============; Class name Variable name; ========================= =============; BasicBlock block; ConstantExpr expr; ExecutionEngine engine; MachineOperand operand; OptimizationRemarkEmitter remarker; PreservedAnalyses analyses; PreservedAnalysesChecker checker; TargetLowering lowering; TargetMachine machine; ========================= =============. Transition Options; ==================. There are three main options for transitioning:. 1. Keep the current coding standard; 2. Laissez faire; 3. Big bang. Keep the current coding standard; --------------------------------. Proponents of keeping the current coding standard (i.e. not transitioning at; all) question whether the cost of transition outweighs the benefit; [EmersonConcern]_ [ReamesConcern]_ [Bradbur",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/VariableNames.rst:6626,optimiz,optimization,6626,interpreter/llvm-project/llvm/docs/Proposals/VariableNames.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/VariableNames.rst,2,['optimiz'],['optimization']
Performance," The memory model has been; subsequently adjusted to correct errors in the initial; specification, so LLVM currently intends to implement the version; specified by C++20. (See the `C++20 draft standard; <https://isocpp.org/files/papers/N4860.pdf>`_ or the unofficial; `latest C++ draft <https://eel.is/c++draft/>`_. A `C2x draft; <https://www.open-std.org/jtc1/sc22/wg14/www/docs/n3047.pdf>`_ is; also available, though the text has not yet been updated with the; errata corrected by C++20.). * Proper semantics for Java-style memory, for both ``volatile`` and regular; shared variables. (`Java Specification; <http://docs.oracle.com/javase/specs/jls/se8/html/jls-17.html>`_). * gcc-compatible ``__sync_*`` builtins. (`Description; <https://gcc.gnu.org/onlinedocs/gcc/_005f_005fsync-Builtins.html>`_). * Other scenarios with atomic semantics, including ``static`` variables with; non-trivial constructors in C++. Atomic and volatile in the IR are orthogonal; ""volatile"" is the C/C++ volatile,; which ensures that every volatile load and store happens and is performed in the; stated order. A couple examples: if a SequentiallyConsistent store is; immediately followed by another SequentiallyConsistent store to the same; address, the first store can be erased. This transformation is not allowed for a; pair of volatile stores. On the other hand, a non-volatile non-atomic load can; be moved across a volatile load freely, but not an Acquire load. This document is intended to provide a guide to anyone either writing a frontend; for LLVM or working on optimization passes for LLVM with a guide for how to deal; with instructions with special semantics in the presence of concurrency. This; is not intended to be a precise guide to the semantics; the details can get; extremely complicated and unreadable, and are not usually necessary. .. _Optimization outside atomic:. Optimization outside atomic; ===========================. The basic ``'load'`` and ``'store'`` allow a variety of optimizations, b",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Atomics.rst:1561,load,load,1561,interpreter/llvm-project/llvm/docs/Atomics.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Atomics.rst,2,"['load', 'perform']","['load', 'performed']"
Performance," The only supported key; value type is a uint32. The only requirement is that the producer and consumer; agree on the hash function. As such, the hash function can is not discussed; further in this document, it is assumed that for a particular instance of a PDB; file hash table, the appropriate hash function is being used. On-Disk Format; ==============. .. code-block:: none. .--------------------.-- +0; | Size |; .--------------------.-- +4; | Capacity |; .--------------------.-- +8; | Present Bit Vector |; .--------------------.-- +N; | Deleted Bit Vector |; .--------------------.-- +M ─╮; | Key | │; .--------------------.-- +M+4 │; | Value | │; .--------------------.-- +M+4+sizeof(Value) │; ... ├─ |Capacity| Bucket entries; .--------------------. │; | Key | │; .--------------------. │; | Value | │; .--------------------. ─╯. - **Size** - The number of values contained in the hash table. - **Capacity** - The number of buckets in the hash table. Producers should; maintain a load factor of no greater than ``2/3*Capacity+1``. - **Present Bit Vector** - A serialized bit vector which contains information; about which buckets have valid values. If the bucket has a value, the; corresponding bit will be set, and if the bucket doesn't have a value (either; because the bucket is empty or because the value is a tombstone value) the bit; will be unset. - **Deleted Bit Vector** - A serialized bit vector which contains information; about which buckets have tombstone values. If the entry in this bucket is; deleted, the bit will be set, otherwise it will be unset. - **Keys and Values** - A list of ``Capacity`` hash buckets, where the first; entry is the key (always a uint32), and the second entry is the value. The; state of each bucket (valid, empty, deleted) can be determined by examining; the present and deleted bit vectors. .. _hash_bit_vectors:. Present and Deleted Bit Vectors; ===============================. The bit vectors indicating the status of each bucket are serialize",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/HashTable.rst:1581,load,load,1581,interpreter/llvm-project/llvm/docs/PDB/HashTable.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/HashTable.rst,1,['load'],['load']
Performance," The type specified must be a :ref:`first class <t_firstclass>` type of; known size (i.e. not containing an :ref:`opaque structural type <t_opaque>`). If; the ``load`` is marked as ``volatile``, then the optimizer is not allowed to; modify the number or order of execution of this ``load`` with other; :ref:`volatile operations <volatile>`. If the ``load`` is marked as ``atomic``, it takes an extra :ref:`ordering; <ordering>` and optional ``syncscope(""<target-scope>"")`` argument. The; ``release`` and ``acq_rel`` orderings are not valid on ``load`` instructions.; Atomic loads produce :ref:`defined <memmodel>` results when they may see; multiple atomic stores. The type of the pointee must be an integer, pointer, or; floating-point type whose bit width is a power of two greater than or equal to; eight and less than or equal to a target-specific size limit. ``align`` must be; explicitly specified on atomic loads. Note: if the alignment is not greater or; equal to the size of the `<value>` type, the atomic operation is likely to; require a lock and have poor performance. ``!nontemporal`` does not have any; defined semantics for atomic loads. The optional constant ``align`` argument specifies the alignment of the; operation (that is, the alignment of the memory address). It is the; responsibility of the code emitter to ensure that the alignment information is; correct. Overestimating the alignment results in undefined behavior.; Underestimating the alignment may produce less efficient code. An alignment of; 1 is always safe. The maximum possible alignment is ``1 << 32``. An alignment; value higher than the size of the loaded type implies memory up to the; alignment value bytes can be safely loaded without trapping in the default; address space. Access of the high bytes can interfere with debugging tools, so; should not be accessed if the function has the ``sanitize_thread`` or; ``sanitize_address`` attributes. The alignment is only optional when parsing textual IR; for in-m",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:413786,perform,performance,413786,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['performance']
Performance," The user code does not need to check if the API names are defined, because; these names are automatically replaced by ``(0)`` or the equivalence of noop; if the ``clang`` is not compiling for profile generation. Such replacement can happen because ``clang`` adds one of two macros depending; on the ``-fprofile-generate`` and the ``-fprofile-use`` flags. * ``__LLVM_INSTR_PROFILE_GENERATE``: defined when one of; ``-fprofile[-instr]-generate``/``-fcs-profile-generate`` is in effect.; * ``__LLVM_INSTR_PROFILE_USE``: defined when one of; ``-fprofile-use``/``-fprofile-instr-use`` is in effect. The two macros can be used to provide more flexibiilty so a user program; can execute code specifically intended for profile generate or profile use.; For example, a user program can have special logging during profile generate:. .. code-block:: c. #if __LLVM_INSTR_PROFILE_GENERATE; expensive_logging_of_full_program_state();; #endif. The logging is automatically excluded during a normal build of the program,; hence it does not impact performance during a normal execution. It is advised to use such fine tuning only in a program's cold regions. The weak; symbols can introduce extra control flow (the ``if`` checks), while the macros; (hence declarations they guard in ``profile/instr_prof_interface.h``); can change the control flow of the functions that use them between profile; generation and profile use (which can lead to discarded counters in such; functions). Using these APIs in the program's cold regions introduces less; overhead and leads to more optimized code. Disabling Instrumentation; ^^^^^^^^^^^^^^^^^^^^^^^^^. In certain situations, it may be useful to disable profile generation or use; for specific files in a build, without affecting the main compilation flags; used for the other files in the project. In these cases, you can use the flag ``-fno-profile-instr-generate`` (or; ``-fno-profile-generate``) to disable profile generation, and; ``-fno-profile-instr-use`` (or ``-fno-pr",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:114388,perform,performance,114388,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,1,['perform'],['performance']
Performance," ThinLTO and PGO. All were built with `-march=haswell` to give access to BMI2; instructions, and benchmarks were run on large Haswell servers. We collected; data both with an `lfence`-based mitigation and load hardening as presented; here. The summary is that mitigating with load hardening is 1.77x faster than; mitigating with `lfence`, and the overhead of load hardening compared to a; normal program is likely between a 10% overhead and a 50% overhead with most; large applications seeing a 30% overhead or less. | Benchmark | `lfence` | Load Hardening | Mitigated Speedup |; | -------------------------------------- | -------: | -------------: | ----------------: |; | Google microbenchmark suite | -74.8% | -36.4% | **2.5x** |; | Large server QPS (using ThinLTO & PGO) | -62% | -29% | **1.8x** |. Below is a visualization of the microbenchmark suite results which helps show; the distribution of results that is somewhat lost in the summary. The y-axis is; a log-scale speedup ratio of load hardening relative to `lfence` (up -> faster; -> better). Each box-and-whiskers represents one microbenchmark which may have; many different metrics measured. The red line marks the median, the box marks; the first and third quartiles, and the whiskers mark the min and max. ![Microbenchmark result visualization](speculative_load_hardening_microbenchmarks.png). We don't yet have benchmark data on SPEC or the LLVM test suite, but we can; work on getting that. Still, the above should give a pretty clear; characterization of the performance, and specific benchmarks are unlikely to; reveal especially interesting properties. ### Future Work: Fine Grained Control and API-Integration. The performance overhead of this technique is likely to be very significant and; something users wish to control or reduce. There are interesting options here; that impact the implementation strategy used. One particularly appealing option is to allow both opt-in and opt-out of this; mitigation at reasonably fine gra",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:48184,load,load,48184,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,1,['load'],['load']
Performance," This is mainly for promoting straight-line scalar optimizations, which are; most effective on code along dominator paths. * `Memory space inference; <https://llvm.org/doxygen/NVPTXInferAddressSpaces_8cpp_source.html>`_ --; In PTX, we can operate on pointers that are in a particular ""address space""; (global, shared, constant, or local), or we can operate on pointers in the; ""generic"" address space, which can point to anything. Operations in a; non-generic address space are faster, but pointers in CUDA are not explicitly; annotated with their address space, so it's up to LLVM to infer it where; possible. * `Bypassing 64-bit divides; <https://llvm.org/docs/doxygen/html/BypassSlowDivision_8cpp_source.html>`_ --; This was an existing optimization that we enabled for the PTX backend. 64-bit integer divides are much slower than 32-bit ones on NVIDIA GPUs.; Many of the 64-bit divides in our benchmarks have a divisor and dividend; which fit in 32-bits at runtime. This optimization provides a fast path for; this common case. * Aggressive loop unrolling and function inlining -- Loop unrolling and; function inlining need to be more aggressive for GPUs than for CPUs because; control flow transfer in GPU is more expensive. More aggressive unrolling and; inlining also promote other optimizations, such as constant propagation and; SROA, which sometimes speed up code by over 10x. (Programmers can force unrolling and inline using clang's `loop unrolling pragmas; <https://clang.llvm.org/docs/AttributeReference.html#pragma-unroll-pragma-nounroll>`_; and ``__attribute__((always_inline))``.). Publication; ===========. The team at Google published a paper in CGO 2016 detailing the optimizations; they'd made to clang/LLVM. Note that ""gpucc"" is no longer a meaningful name:; The relevant tools are now just vanilla clang/LLVM. | `gpucc: An Open-Source GPGPU Compiler <http://dl.acm.org/citation.cfm?id=2854041>`_; | Jingyue Wu, Artem Belevich, Eli Bendersky, Mark Heffernan, Chris Leary, Jacque",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst:19624,optimiz,optimization,19624,interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst,1,['optimiz'],['optimization']
Performance," This is particularly useful on indirect; calls; without this we may treat such calls as though the target; is non-convergent. See :doc:`ConvergentOperations` for further details. It is an error to call :ref:`llvm.experimental.convergence.entry; <llvm.experimental.convergence.entry>` from a function that; does not have this attribute.; ``disable_sanitizer_instrumentation``; When instrumenting code with sanitizers, it can be important to skip certain; functions to ensure no instrumentation is applied to them. This attribute is not always similar to absent ``sanitize_<name>``; attributes: depending on the specific sanitizer, code can be inserted into; functions regardless of the ``sanitize_<name>`` attribute to prevent false; positive reports. ``disable_sanitizer_instrumentation`` disables all kinds of instrumentation,; taking precedence over the ``sanitize_<name>`` attributes and other compiler; flags.; ``""dontcall-error""``; This attribute denotes that an error diagnostic should be emitted when a; call of a function with this attribute is not eliminated via optimization.; Front ends can provide optional ``srcloc`` metadata nodes on call sites of; such callees to attach information about where in the source language such a; call came from. A string value can be provided as a note.; ``""dontcall-warn""``; This attribute denotes that a warning diagnostic should be emitted when a; call of a function with this attribute is not eliminated via optimization.; Front ends can provide optional ``srcloc`` metadata nodes on call sites of; such callees to attach information about where in the source language such a; call came from. A string value can be provided as a note.; ``fn_ret_thunk_extern``; This attribute tells the code generator that returns from functions should; be replaced with jumps to externally-defined architecture-specific symbols.; For X86, this symbol's identifier is ``__x86_return_thunk``.; ``""frame-pointer""``; This attribute tells the code generator whether the f",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:82148,optimiz,optimization,82148,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['optimiz'],['optimization']
Performance," This problem was; previously discussed; on the mailing list, but no solution was implemented.; (Difficulty: Medium) . Floating-point support.; Currently, the analyzer treats all floating-point values as unknown.; This project would involve adding a new SVal kind; for constant floats, generalizing the constraint manager to handle floats,; and auditing existing code to make sure it doesn't; make incorrect assumptions (most notably, that X == X; is always true, since it does not hold for NaN).; (Difficulty: Medium). Improved loop execution modeling.; The analyzer simply unrolls each loop N times before; dropping the path, for a fixed constant N.; However, that results in lost coverage in cases where the loop always; executes more than N times.; A Google Summer Of Code; project; was completed to make the loop bound parameterizable,; but the widening; problem still remains open. (Difficulty: Hard). Basic function summarization support; The analyzer performs inter-procedural analysis using; either inlining or ""conservative evaluation"" (invalidating all data; passed to the function).; Often, a very simple summary; (e.g. ""this function is pure"") would be; enough to be a large improvement over conservative evaluation.; Such summaries could be obtained either syntactically,; or using a dataflow framework.; (Difficulty: Hard). Implement a dataflow flamework.; The analyzer core; implements a symbolic execution; engine, which performs checks; (use-after-free, uninitialized value read, etc.); over a single program path.; However, many useful properties; (dead code, check-after-use, etc.) require; reasoning over all possible in a program.; Such reasoning requires a; dataflow analysis framework.; Clang already implements; a few dataflow analyses (most notably, liveness),; but they implemented in an ad-hoc fashion.; A proper framework would enable us writing many more useful checkers.; (Difficulty: Hard) . Track type information through casts more precisely.; The DynamicTypePropagat",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/open_projects.html:7355,perform,performs,7355,interpreter/llvm-project/clang/www/analyzer/open_projects.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/open_projects.html,2,['perform'],['performs']
Performance," This specification describes ARC as performing specific ``retain`` and; ``release`` operations on retainable object pointers at specific; points during the execution of a program. These operations make up a; non-contiguous subsequence of the computation history of the program.; The portion of this sequence for a particular retainable object; pointer for which a specific function execution is directly; responsible is the :arc-term:`formal local retain history` of the; object pointer. The corresponding actual sequence executed is the; `dynamic local retain history`. However, under certain circumstances, ARC is permitted to re-order and; eliminate operations in a manner which may alter the overall; computation history beyond what is permitted by the general ""as if""; rule of C/C++ and the :ref:`restrictions <arc.objects.retains>` on; the implementation of ``retain`` and ``release``. .. admonition:: Rationale. Specifically, ARC is sometimes permitted to optimize ``release``; operations in ways which might cause an object to be deallocated; before it would otherwise be. Without this, it would be almost; impossible to eliminate any ``retain``/``release`` pairs. For; example, consider the following code:. .. code-block:: objc. id x = _ivar;; [x foo];. If we were not permitted in any event to shorten the lifetime of the; object in ``x``, then we would not be able to eliminate this retain; and release unless we could prove that the message send could not; modify ``_ivar`` (or deallocate ``self``). Since message sends are; opaque to the optimizer, this is not possible, and so ARC's hands; would be almost completely tied. ARC makes no guarantees about the execution of a computation history; which contains undefined behavior. In particular, ARC makes no; guarantees in the presence of race conditions. ARC may assume that any retainable object pointers it receives or; generates are instantaneously valid from that point until a point; which, by the concurrency model of the host la",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst:76642,optimiz,optimize,76642,interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,1,['optimiz'],['optimize']
Performance," U : Def->uses()) {; MemoryAccess *MA = cast<MemoryAccess>(Use.getUser());; if (auto *MU = cast_of_null<MemoryUse>MA) {; // Process MemoryUse as needed.; }; else {; // Process MemoryDef or MemoryPhi as needed. // As a user can come up twice, as an optimized access and defining; // access, keep a visited list. // Check transitive uses as needed; checkUses (MA); // use a worklist for an iterative algorithm; }; }; }. An example of similar traversals can be found in the DeadStoreElimination pass. Invalidation and updating; -------------------------. Because ``MemorySSA`` keeps track of LLVM IR, it needs to be updated whenever; the IR is updated. ""Update"", in this case, includes the addition, deletion, and; motion of ``Instructions``. The update API is being made on an as-needed basis.; If you'd like examples, ``GVNHoist`` and ``LICM`` are users of ``MemorySSA``\ s; update API.; Note that adding new ``MemoryDef``\ s (by calling ``insertDef``) can be a; time-consuming update, if the new access triggers many ``MemoryPhi`` insertions and; renaming (optimization invalidation) of many ``MemoryAccesses``\ es. Phi placement; ^^^^^^^^^^^^^. ``MemorySSA`` only places ``MemoryPhi``\ s where they're actually; needed. That is, it is a pruned SSA form, like LLVM's SSA form. For; example, consider:. .. code-block:: llvm. define void @foo() {; entry:; %p1 = alloca i8; %p2 = alloca i8; %p3 = alloca i8; ; 1 = MemoryDef(liveOnEntry); store i8 0, ptr %p3; br label %while.cond. while.cond:; ; 3 = MemoryPhi({%0,1},{if.end,2}); br i1 undef, label %if.then, label %if.else. if.then:; br label %if.end. if.else:; br label %if.end. if.end:; ; MemoryUse(1); %1 = load i8, ptr %p1; ; 2 = MemoryDef(3); store i8 2, ptr %p2; ; MemoryUse(1); %2 = load i8, ptr %p3; br label %while.cond; }. Because we removed the stores from ``if.then`` and ``if.else``, a ``MemoryPhi``; for ``if.end`` would be pointless, so we don't place one. So, if you need to; place a ``MemoryDef`` in ``if.then`` or ``if.else``, you'll ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MemorySSA.rst:14613,optimiz,optimization,14613,interpreter/llvm-project/llvm/docs/MemorySSA.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MemorySSA.rst,1,['optimiz'],['optimization']
Performance," Unix-like platforms, LLVM requires the presence of GCC's atomic; intrinsics in order to support threaded operation. If you need a; multithreading-capable LLVM on a platform without a suitably modern system; compiler, consider compiling LLVM and LLVM-GCC in single-threaded mode, and; using the resultant compiler to build a copy of LLVM with multithreading; support. .. _shutdown:. Ending Execution with ``llvm_shutdown()``; -----------------------------------------. When you are done using the LLVM APIs, you should call ``llvm_shutdown()`` to; deallocate memory used for internal structures. .. _managedstatic:. Lazy Initialization with ``ManagedStatic``; ------------------------------------------. ``ManagedStatic`` is a utility class in LLVM used to implement static; initialization of static resources, such as the global type tables. In a; single-threaded environment, it implements a simple lazy initialization scheme.; When LLVM is compiled with support for multi-threading, however, it uses; double-checked locking to implement thread-safe lazy initialization. .. _llvmcontext:. Achieving Isolation with ``LLVMContext``; ----------------------------------------. ``LLVMContext`` is an opaque class in the LLVM API which clients can use to; operate multiple, isolated instances of LLVM concurrently within the same; address space. For instance, in a hypothetical compile-server, the compilation; of an individual translation unit is conceptually independent from all the; others, and it would be desirable to be able to compile incoming translation; units concurrently on independent server threads. Fortunately, ``LLVMContext``; exists to enable just this kind of scenario!. Conceptually, ``LLVMContext`` provides isolation. Every LLVM entity; (``Module``\ s, ``Value``\ s, ``Type``\ s, ``Constant``\ s, etc.) in LLVM's; in-memory IR belongs to an ``LLVMContext``. Entities in different contexts; *cannot* interact with each other: ``Module``\ s in different contexts cannot be; linked to",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:122380,multi-thread,multi-threading,122380,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,1,['multi-thread'],['multi-threading']
Performance," Unlike XML, the bitstream format is a binary encoding, and unlike XML it; provides a mechanism for the file to self-describe ""abbreviations"", which are; effectively size optimizations for the content. LLVM IR files may be optionally embedded into a `wrapper`_ structure, or in a; `native object file`_. Both of these mechanisms make it easy to embed extra; data along with LLVM IR files. This document first describes the LLVM bitstream format, describes the wrapper; format, then describes the record structure used by LLVM IR files. .. _bitstream container format:. Bitstream Format; ================. The bitstream format is literally a stream of bits, with a very simple; structure. This structure consists of the following concepts:. * A ""`magic number`_"" that identifies the contents of the stream. * Encoding `primitives`_ like variable bit-rate integers. * `Blocks`_, which define nested content. * `Data Records`_, which describe entities within the file. * Abbreviations, which specify compression optimizations for the file. Note that the :doc:`llvm-bcanalyzer <CommandGuide/llvm-bcanalyzer>` tool can be; used to dump and inspect arbitrary bitstreams, which is very useful for; understanding the encoding. .. _magic number:. Magic Numbers; -------------. The first four bytes of a bitstream are used as an application-specific magic; number. Generic bitcode tools may look at the first four bytes to determine; whether the stream is a known stream type. However, these tools should *not*; determine whether a bitstream is valid based on its magic number alone. New; application-specific bitstream formats are being developed all the time; tools; should not reject them just because they have a hitherto unseen magic number. .. _primitives:. Primitives; ----------. A bitstream literally consists of a stream of bits, which are read in order; starting with the least significant bit of each byte. The stream is made up of; a number of primitive values that encode a stream of unsigned inte",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BitCodeFormat.rst:1742,optimiz,optimizations,1742,interpreter/llvm-project/llvm/docs/BitCodeFormat.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BitCodeFormat.rst,1,['optimiz'],['optimizations']
Performance," Wavefront Offset for use as the; flat scratch base in flat memory instructions. .. _amdgpu-amdhsa-kernel-prolog-private-segment-buffer:. Private Segment Buffer; ++++++++++++++++++++++. If the *Target Properties* column of :ref:`amdgpu-processor-table` specifies; *Architected flat scratch* then a Private Segment Buffer is not supported.; Instead the flat SCRATCH instructions are used. Otherwise, Private Segment Buffer SGPR register is used to initialize 4 SGPRs; that are used as a V# to access scratch. CP uses the value provided by the; runtime. It is used, together with Scratch Wavefront Offset as an offset, to; access the private memory space using a segment address. See; :ref:`amdgpu-amdhsa-initial-kernel-execution-state`. The scratch V# is a four-aligned SGPR and always selected for the kernel as; follows:. - If it is known during instruction selection that there is stack usage,; SGPR0-3 is reserved for use as the scratch V#. Stack usage is assumed if; optimizations are disabled (``-O0``), if stack objects already exist (for; locals, etc.), or if there are any function calls. - Otherwise, four high numbered SGPRs beginning at a four-aligned SGPR index; are reserved for the tentative scratch V#. These will be used if it is; determined that spilling is needed. - If no use is made of the tentative scratch V#, then it is unreserved,; and the register count is determined ignoring it.; - If use is made of the tentative scratch V#, then its register numbers; are shifted to the first four-aligned SGPR index after the highest one; allocated by the register allocator, and all uses are updated. The; register count includes them in the shifted location.; - In either case, if the processor has the SGPR allocation bug, the; tentative allocation is not shifted or unreserved in order to ensure; the register count is higher to workaround the bug. .. note::. This approach of using a tentative scratch V# and shifting the register; numbers if used avoids having to perform register a",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:198906,optimiz,optimizations,198906,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['optimiz'],['optimizations']
Performance," Wavefronts are executed in native mode with in-order reporting of loads and; sample instructions. In this mode vmcnt reports completion of load, atomic with; return and sample instructions in order, and the vscnt reports the completion of; store and atomic without return in order. See ``MEM_ORDERED`` field in; :ref:`amdgpu-amdhsa-compute_pgm_rsrc1-gfx6-gfx12-table`. Wavefronts can be executed in WGP or CU wavefront execution mode:. * In WGP wavefront execution mode the wavefronts of a work-group are executed; on the SIMDs of both CUs of the WGP. Therefore, explicit management of the per; CU L0 caches is required for work-group synchronization. Also accesses to L1; at work-group scope need to be explicitly ordered as the accesses from; different CUs are not ordered.; * In CU wavefront execution mode the wavefronts of a work-group are executed on; the SIMDs of a single CU of the WGP. Therefore, all global memory access by; the work-group access the same L0 which in turn ensures L1 accesses are; ordered and so do not require explicit management of the caches for; work-group synchronization. See ``WGP_MODE`` field in; :ref:`amdgpu-amdhsa-compute_pgm_rsrc1-gfx6-gfx12-table` and; :ref:`amdgpu-target-features`. The code sequences used to implement the memory model for GFX10-GFX11 are defined in; table :ref:`amdgpu-amdhsa-memory-model-code-sequences-gfx10-gfx11-table`. .. table:: AMDHSA Memory Model Code Sequences GFX10-GFX11; :name: amdgpu-amdhsa-memory-model-code-sequences-gfx10-gfx11-table. ============ ============ ============== ========== ================================; LLVM Instr LLVM Memory LLVM Memory AMDGPU AMDGPU Machine Code; Ordering Sync Scope Address GFX10-GFX11; Space; ============ ============ ============== ========== ================================; **Non-Atomic**; ------------------------------------------------------------------------------------; load *none* *none* - global - !volatile & !nontemporal; - generic; - private 1. buffer/global/flat_load",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:342883,cache,caches,342883,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['cache'],['caches']
Performance," WebAssembly constraints:. * No variable argument lists are used. * The 'tail-call' target attribute is enabled. * The caller and callee's return types must match. The caller cannot; be void unless the callee is, too. AArch64 constraints:. * No variable argument lists are used. Example:. Call as ``llc -tailcallopt test.ll``. .. code-block:: llvm. declare fastcc i32 @tailcallee(i32 inreg %a1, i32 inreg %a2, i32 %a3, i32 %a4). define fastcc i32 @tailcaller(i32 %in1, i32 %in2) {; %l1 = add i32 %in1, %in2; %tmp = tail call fastcc i32 @tailcallee(i32 inreg %in1, i32 inreg %in2, i32 %in1, i32 %l1); ret i32 %tmp; }. Implications of ``-tailcallopt``:. To support tail call optimization in situations where the callee has more; arguments than the caller a 'callee pops arguments' convention is used. This; currently causes each ``fastcc`` call that is not tail call optimized (because; one or more of above constraints are not met) to be followed by a readjustment; of the stack. So performance might be worse in such cases. Sibling call optimization; -------------------------. Sibling call optimization is a restricted form of tail call optimization.; Unlike tail call optimization described in the previous section, it can be; performed automatically on any tail calls when ``-tailcallopt`` option is not; specified. Sibling call optimization is currently performed on x86/x86-64 when the; following constraints are met:. * Caller and callee have the same calling convention. It can be either ``c`` or; ``fastcc``. * The call is a tail call - in tail position (ret immediately follows call and; ret uses value of call or is void). * Caller and callee have matching return type or the callee result is not used. * If any of the callee arguments are being passed in stack, they must be; available in caller's own incoming argument stack and the frame offsets must; be the same. Example:. .. code-block:: llvm. declare i32 @bar(i32, i32). define i32 @foo(i32 %a, i32 %b, i32 %c) {; entry:; %0 = tail ca",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:88190,perform,performance,88190,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst,1,['perform'],['performance']
Performance," [2,0] . DeeE-----R . vmulps	%xmm0, %xmm1, %xmm2; [2,1] . D====eeeER . vhaddps	%xmm2, %xmm2, %xmm3; [2,2] . D======eeeER vhaddps	%xmm3, %xmm3, %xmm4. Average Wait times (based on the timeline view):; [0]: Executions; [1]: Average time spent waiting in a scheduler's queue; [2]: Average time spent waiting in a scheduler's queue while ready; [3]: Average time elapsed from WB until retire stage. [0] [1] [2] [3]; 0. 3 1.0 1.0 3.3 vmulps	%xmm0, %xmm1, %xmm2; 1. 3 3.3 0.7 1.0 vhaddps	%xmm2, %xmm2, %xmm3; 2. 3 5.7 0.0 0.0 vhaddps	%xmm3, %xmm3, %xmm4; 3 3.3 0.5 1.4 <total>. The timeline view is interesting because it shows instruction state changes; during execution. It also gives an idea of how the tool processes instructions; executed on the target, and how their timing information might be calculated. The timeline view is structured in two tables. The first table shows; instructions changing state over time (measured in cycles); the second table; (named *Average Wait times*) reports useful timing statistics, which should; help diagnose performance bottlenecks caused by long data dependencies and; sub-optimal usage of hardware resources. An instruction in the timeline view is identified by a pair of indices, where; the first index identifies an iteration, and the second index is the; instruction index (i.e., where it appears in the code sequence). Since this; example was generated using 3 iterations: ``-iterations=3``, the iteration; indices range from 0-2 inclusively. Excluding the first and last column, the remaining columns are in cycles.; Cycles are numbered sequentially starting from 0. From the example output above, we know the following:. * Instruction [1,0] was dispatched at cycle 1.; * Instruction [1,0] started executing at cycle 2.; * Instruction [1,0] reached the write back stage at cycle 4.; * Instruction [1,0] was retired at cycle 10. Instruction [1,0] (i.e., vmulps from iteration #1) does not have to wait in the; scheduler's queue for the operands to become av",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:23360,perform,performance,23360,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,2,"['bottleneck', 'perform']","['bottlenecks', 'performance']"
Performance," `Merge(...)` interface for the `TFileMerger`. ### RPageSource / Sink; The page source and sink can read and write pages and clusters from and to a storage backend.; There are concrete class implementations for an RNTuple stored in a ROOT file (local or remote), and for an RNTuple stored in a DAOS object store.; There is a virtual page sink for buffered writes, which also groups pages of the same column before flushing them to disk.; There is a virtual page source for aligned friend datasets (horizontal data combination). Page sources and sinks do not operate entry-based but based on pages/indices of columns.; For instance, there is no API in the page sink to write an entry, but only to write pages of columns.; The higher-level APIs, e.g. `RField`, `REntry`, `RNTupleWriter`, take care of presenting the available data as entries where necessary. The page source also gives access to an `RNTupleDescriptor` through a read/write lock guard.; The `RNTupleDescriptor` owned by the page source changes only when new cluster meta-data are loaded.; The header and the cluster group summary information is stable throughout its lifetime (cf. format specification). ### R{NTuple,Field,Column,Cluster,...}Descriptor; The descriptor classes provide read-only access to the on-disk meta-data of an RNTuple.; The meta-data include the schema (fields and columns), information about clusters and the page locations.; The descriptor classes are closely related to the format specification. For normal read and write tasks, access to the descriptor is not necessary.; One notable exception is bulk reading, where the descriptor can be used to determine entry boundaries of clusters.; The descriptors are used internally, e.g. to build an RNTupleModel from the on-disk information.; The descriptors are also useful for inspection purposes. The descriptor classes contain a copy of the meta-data; they are not linked to an open page source.; A descriptor can be used after its originating page source has be",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md:6709,load,loaded,6709,tree/ntuple/v7/doc/Architecture.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md,1,['load'],['loaded']
Performance," `PyROOT` isn't; currently aware of, and it is up to the developer to keep at lease one; Python reference alive. See `$ROOTSYS/tutorials/pyroot/zdemo.py`; (available in the latest release) for an example. Alternatively, one can; tell python to give up ownership for individual instances:. ``` {.cpp}; o = ROOT.TObject(); ROOT.SetOwnership( o, False ) # True to own, False to release; ```. #### Memory Management by Hand. If needed, you can explicitly destroy a ROOT object that you own through; its associated **`TClass`**:. ``` {.cpp}; myobject.IsA().Destructor(myobject); ```. which will send out the deletion notification to the system (thus you do; not need to care anymore at this point about Python reference counting,; the object will go, even if it's reference count it non-zero), and free; the memory. ### Performance. The performance of `PyROOT` when programming with ROOT in Python is; similar to that of Cling. Differences occur mainly because of differences; in the respective languages: C++ is much harder to parse, but once; parsed, it is much easier to optimize. Consequently, individual calls to; ROOT are typically faster from `PyROOT`, whereas loops are typically; slower. When programming in Python, the modus operandi is to consider; performance generally ""good enough"" on the outset, and when it turns out; that, it is not good enough; the performance critical part is converted; into C/C++ in an extension module. The school of thought where; pre-mature optimization is the root of all evil should find this way of; working very satisfying. In addition, if you look at their history, you; will see that many of the standard Python modules have followed this; path. Your code should always make maximum use of ROOT facilities; such that; most of the time is spending in compiled code. This goes even for very; simple things: e.g. do not compute invariant masses in Python, use; **`TLorentzVector`** instead. Moreover, before you start optimizing,; make sure that you have run a ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/PythonRuby.md:22568,optimiz,optimize,22568,documentation/users-guide/PythonRuby.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/PythonRuby.md,1,['optimiz'],['optimize']
Performance," `RooFit::TestStatistics` classes. # RooFit::TestStatistics usage notes. The `RooFit::TestStatistics` namespace contains a major refactoring of the `RooAbsTestStatistic`-`RooAbsOptTestStatistic`-`RooNLLVar` inheritance tree into:. 1. statistics-based classes on the one hand;; 2. calculation/evaluation/optimization based classes on the other hand. The motivation for this refactoring was also twofold:. 1. These test statistics classes make a cleaner separation of concerns than the existing `RooAbsTestStatistic` based tree and are hence more maintainable and future proof.; 2. They provided a place for us to try out new parallelized gradient calculation methods using the `RooFit::MultiProcess` module. See the usage example below on how to use this. ## Statistics; The likelihood is the central unit on the statistics side.; The `RooAbsL` class is implemented for four kinds of likelihoods: binned, unbinned, ""subsidiary"" (an optimization for numerical stability that gathers components like global observables) and ""sum"" (over multiple components of the other types), in the correspondingly named classes `RooBinnedL`, `RooUnbinnedL`, `RooSubsidiaryL` and `RooSumL`.; These classes provide a `evaluatePartition` function that allows for computing them in parallelizable chunks that can be used by the calculator classes as they see fit. On top of the likelihood classes, we also provide for convenience a likelihood builder `buildLikelihood`, as a free function in the namespace.; This function analyzes the `pdf` and automatically constructs the proper likelihood, built; up from the available `RooAbsL` subclasses. The new classes are not per se meant to be used outside of `RooMinimizer`, although they can be.; The main reason is that they do not behave as regular `RooAbsReal` objects, but have their own interface which was kept to the minimum necessary for interacting with `RooMinimizer` as an object that encodes purely the statistics concepts.; However, we do provide the `RooRealL` c",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/developers/test_statistics.md:1103,optimiz,optimization,1103,roofit/doc/developers/test_statistics.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/developers/test_statistics.md,1,['optimiz'],['optimization']
Performance," ``2`` provide; intermediate behavior between these two extremes. Query for this feature with ``__has_builtin(__builtin_prefetch)``. ``__sync_swap``; ---------------. ``__sync_swap`` is used to atomically swap integers or pointers in memory. **Syntax**:. .. code-block:: c++. type __sync_swap(type *ptr, type value, ...). **Example of Use**:. .. code-block:: c++. int old_value = __sync_swap(&value, new_value);. **Description**:. The ``__sync_swap()`` builtin extends the existing ``__sync_*()`` family of; atomic intrinsics to allow code to atomically swap the current value with the; new value. More importantly, it helps developers write more efficient and; correct code by avoiding expensive loops around; ``__sync_bool_compare_and_swap()`` or relying on the platform specific; implementation details of ``__sync_lock_test_and_set()``. The; ``__sync_swap()`` builtin is a full barrier. ``__builtin_addressof``; -----------------------. ``__builtin_addressof`` performs the functionality of the built-in ``&``; operator, ignoring any ``operator&`` overload. This is useful in constant; expressions in C++11, where there is no other way to take the address of an; object that overloads ``operator&``. Clang automatically adds; ``[[clang::lifetimebound]]`` to the parameter of ``__builtin_addressof``. **Example of use**:. .. code-block:: c++. template<typename T> constexpr T *addressof(T &value) {; return __builtin_addressof(value);; }. ``__builtin_function_start``; -----------------------------. ``__builtin_function_start`` returns the address of a function body. **Syntax**:. .. code-block:: c++. void *__builtin_function_start(function). **Example of use**:. .. code-block:: c++. void a() {}; void *p = __builtin_function_start(a);. class A {; public:; void a(int n);; void a();; };. void A::a(int n) {}; void A::a() {}. void *pa1 = __builtin_function_start((void(A::*)(int)) &A::a);; void *pa2 = __builtin_function_start((void(A::*)()) &A::a);. **Description**:. The ``__builtin_function_st",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst:117406,perform,performs,117406,interpreter/llvm-project/clang/docs/LanguageExtensions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst,1,['perform'],['performs']
Performance," ``MyVar+40``, and the value of; ``%idx2`` is also ``MyVar+40``. Can GEP index into vector elements?; -----------------------------------. This hasn't always been forcefully disallowed, though it's not recommended. It; leads to awkward special cases in the optimizers, and fundamental inconsistency; in the IR. In the future, it will probably be outright disallowed. What effect do address spaces have on GEPs?; -------------------------------------------. None, except that the address space qualifier on the second operand pointer type; always matches the address space qualifier on the result type. How is GEP different from ``ptrtoint``, arithmetic, and ``inttoptr``?; ---------------------------------------------------------------------. It's very similar; there are only subtle differences. With ptrtoint, you have to pick an integer type. One approach is to pick i64;; this is safe on everything LLVM supports (LLVM internally assumes pointers are; never wider than 64 bits in many places), and the optimizer will actually narrow; the i64 arithmetic down to the actual pointer size on targets which don't; support 64-bit arithmetic in most cases. However, there are some cases where it; doesn't do this. With GEP you can avoid this problem. Also, GEP carries additional pointer aliasing rules. It's invalid to take a GEP; from one object, address into a different separately allocated object, and; dereference it. IR producers (front-ends) must follow this rule, and consumers; (optimizers, specifically alias analysis) benefit from being able to rely on; it. See the `Rules`_ section for more information. And, GEP is more concise in common cases. However, for the underlying integer computation implied, there is no; difference. I'm writing a backend for a target which needs custom lowering for GEP. How do I do this?; -----------------------------------------------------------------------------------------. You don't. The integer computation implied by a GEP is target-independent.; Typ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GetElementPtr.rst:10042,optimiz,optimizer,10042,interpreter/llvm-project/llvm/docs/GetElementPtr.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GetElementPtr.rst,1,['optimiz'],['optimizer']
Performance," ``__weak`` objects, the current pointee is retained and then released at; the end of the current full-expression. In particular, messaging a ``__weak``; object keeps the object retained until the end of the full expression. .. code-block:: objc. __weak MyObject *weakObj;. void foo() {; // weakObj is retained before the message send and released at the end of; // the full expression.; [weakObj m];; }. This must execute atomically with respect to assignments and to the final; release of the pointee.; * For all other objects, the lvalue is loaded with primitive semantics. :arc-term:`Assignment` occurs when evaluating an assignment operator. The; semantics vary based on the qualification:. * For ``__strong`` objects, the new pointee is first retained; second, the; lvalue is loaded with primitive semantics; third, the new pointee is stored; into the lvalue with primitive semantics; and finally, the old pointee is; released. This is not performed atomically; external synchronization must be; used to make this safe in the face of concurrent loads and stores.; * For ``__weak`` objects, the lvalue is updated to point to the new pointee,; unless the new pointee is an object currently undergoing deallocation, in; which case the lvalue is updated to a null pointer. This must execute; atomically with respect to other assignments to the object, to reads from the; object, and to the final release of the new pointee.; * For ``__unsafe_unretained`` objects, the new pointee is stored into the; lvalue using primitive semantics.; * For ``__autoreleasing`` objects, the new pointee is retained, autoreleased,; and stored into the lvalue using primitive semantics. :arc-term:`Initialization` occurs when an object's lifetime begins, which; depends on its storage duration. Initialization proceeds in two stages:. #. First, a null pointer is stored into the lvalue using primitive semantics.; This step is skipped if the object is ``__unsafe_unretained``.; #. Second, if the object has an initiali",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst:38901,perform,performed,38901,interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,3,"['concurren', 'load', 'perform']","['concurrent', 'loads', 'performed']"
Performance," ``cmpxchg``), but no other; memory operation can happen on any thread between the load and store. A ``fence`` provides Acquire and/or Release ordering which is not part; of another operation; it is normally used along with Monotonic memory; operations. A Monotonic load followed by an Acquire fence is roughly; equivalent to an Acquire load, and a Monotonic store following a; Release fence is roughly equivalent to a Release; store. SequentiallyConsistent fences behave as both an Acquire and a; Release fence, and additionally provide a total ordering with some; complicated guarantees, see the C++ standard for details. Frontends generating atomic instructions generally need to be aware of the; target to some degree; atomic instructions are guaranteed to be lock-free, and; therefore an instruction which is wider than the target natively supports can be; impossible to generate. .. _Atomic orderings:. Atomic orderings; ================. In order to achieve a balance between performance and necessary guarantees,; there are six levels of atomicity. They are listed in order of strength; each; level includes all the guarantees of the previous level except for; Acquire/Release. (See also `LangRef Ordering <LangRef.html#ordering>`_.). .. _NotAtomic:. NotAtomic; ---------. NotAtomic is the obvious, a load or store which is not atomic. (This isn't; really a level of atomicity, but is listed here for comparison.) This is; essentially a regular load or store. If there is a race on a given memory; location, loads from that location return undef. Relevant standard; This is intended to match shared variables in C/C++, and to be used in any; other context where memory access is necessary, and a race is impossible. (The; precise definition is in `LangRef Memory Model <LangRef.html#memmodel>`_.). Notes for frontends; The rule is essentially that all memory accessed with basic loads and stores; by multiple threads should be protected by a lock or other synchronization;; otherwise, you are",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Atomics.rst:5680,perform,performance,5680,interpreter/llvm-project/llvm/docs/Atomics.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Atomics.rst,1,['perform'],['performance']
Performance," ``dest`` is a valid pointer; which has not been registered as a ``__weak`` object. ``dest`` is initialized to be equivalent to ``src``, potentially registering it; with the runtime. ``src`` may then be left in its original state, in which; case this call is equivalent to :ref:`objc_copyWeak; <arc.runtime.objc_copyWeak>`, or it may be left as null. Must be atomic with respect to calls to ``objc_storeWeak`` on ``src``. .. _arc.runtime.objc_release:. ``void objc_release(id value);``; --------------------------------. *Precondition:* ``value`` is null or a pointer to a valid object. If ``value`` is null, this call has no effect. Otherwise, it performs a; release operation exactly as if the object had been sent the ``release``; message. .. _arc.runtime.objc_retain:. ``id objc_retain(id value);``; -----------------------------. *Precondition:* ``value`` is null or a pointer to a valid object. If ``value`` is null, this call has no effect. Otherwise, it performs a retain; operation exactly as if the object had been sent the ``retain`` message. Always returns ``value``. .. _arc.runtime.objc_retainAutorelease:. ``id objc_retainAutorelease(id value);``; ----------------------------------------. *Precondition:* ``value`` is null or a pointer to a valid object. If ``value`` is null, this call has no effect. Otherwise, it performs a retain; operation followed by an autorelease operation. Equivalent to the following; code:. .. code-block:: objc. id objc_retainAutorelease(id value) {; return objc_autorelease(objc_retain(value));; }. Always returns ``value``. .. _arc.runtime.objc_retainAutoreleaseReturnValue:. ``id objc_retainAutoreleaseReturnValue(id value);``; ---------------------------------------------------. *Precondition:* ``value`` is null or a pointer to a valid object. If ``value`` is null, this call has no effect. Otherwise, it performs a retain; operation followed by the operation described in; :ref:`objc_autoreleaseReturnValue <arc.runtime.objc_autoreleaseReturnValue>",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst:113614,perform,performs,113614,interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,1,['perform'],['performs']
Performance," ``emit``, together constitute the layer; concept: A layer is a way to wrap a part of a compiler pipeline (in this case; the ""opt"" phase of an LLVM compiler) whose API is opaque to ORC with an; interface that ORC can call as needed. The add method takes an; module in some input program representation (in this case an LLVM IR module); and stores it in the target ``JITDylib``, arranging for it to be passed back; to the layer's emit method when any symbol defined by that module is requested.; Each layer can complete its own work by calling the ``emit`` method of its base; layer. For example, in this tutorial our IRTransformLayer calls through to; our IRCompileLayer to compile the transformed IR, and our IRCompileLayer in; turn calls our ObjectLayer to link the object file produced by our compiler. So far we have learned how to optimize and compile our LLVM IR, but we have; not focused on when compilation happens. Our current REPL optimizes and; compiles each function as soon as it is referenced by any other code,; regardless of whether it is ever called at runtime. In the next chapter we; will introduce a fully lazy compilation, in which functions are not compiled; until they are first called at run-time. At this point the trade-offs get much; more interesting: the lazier we are, the quicker we can start executing the; first function, but the more often we will have to pause to compile newly; encountered functions. If we only code-gen lazily, but optimize eagerly, we; will have a longer startup time (as everything is optimized at that time) but; relatively short pauses as each function just passes through code-gen. If we; both optimize and code-gen lazily we can start executing the first function; more quickly, but we will have longer pauses as each function has to be both; optimized and code-gen'd when it is first executed. Things become even more; interesting if we consider interprocedural optimizations like inlining, which; must be performed eagerly. These are comple",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/BuildingAJIT2.rst:10491,optimiz,optimizes,10491,interpreter/llvm-project/llvm/docs/tutorial/BuildingAJIT2.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/BuildingAJIT2.rst,1,['optimiz'],['optimizes']
Performance," ``id``, or a type equal to the declaring class or a superclass, then it is said; to have a related result type. In this case, when invoked in an explicit; message send, it is assumed to return a type related to the type of the; receiver:. * if it is a class method, and the receiver is a class name ``T``, the message; send expression has type ``T*``; otherwise; * if it is an instance method, and the receiver has type ``T``, the message; send expression has type ``T``; otherwise; * the message send expression has the normal result type of the method. This is a new rule of the Objective-C language and applies outside of ARC. .. admonition:: Rationale. ARC's automatic code emission is more prone than most code to signature; errors, i.e. errors where a call was emitted against one method signature,; but the implementing method has an incompatible signature. Having more; precise type information helps drastically lower this risk, as well as; catching a number of latent bugs. .. _arc.optimization:. Optimization; ============. Within this section, the word :arc-term:`function` will be used to; refer to any structured unit of code, be it a C function, an; Objective-C method, or a block. This specification describes ARC as performing specific ``retain`` and; ``release`` operations on retainable object pointers at specific; points during the execution of a program. These operations make up a; non-contiguous subsequence of the computation history of the program.; The portion of this sequence for a particular retainable object; pointer for which a specific function execution is directly; responsible is the :arc-term:`formal local retain history` of the; object pointer. The corresponding actual sequence executed is the; `dynamic local retain history`. However, under certain circumstances, ARC is permitted to re-order and; eliminate operations in a manner which may alter the overall; computation history beyond what is permitted by the general ""as if""; rule of C/C++ and the :ref:`",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst:75474,optimiz,optimization,75474,interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,1,['optimiz'],['optimization']
Performance," ``llvm.coro.end`` without having first; reached a ``llvm.coro.suspend.retcon`` has undefined behavior. The remainder of this section describes the behavior under switched-resume; lowering. This intrinsic is lowered when a coroutine is split into; the start, resume and destroy parts. In the start part, it is a no-op,; in resume and destroy parts, it is replaced with `ret void` instruction and; the rest of the block containing `coro.end` instruction is discarded.; In landing pads it is replaced with an appropriate instruction to unwind to; caller. The handling of coro.end differs depending on whether the target is; using landingpad or WinEH exception model. For landingpad based exception model, it is expected that frontend uses the; `coro.end`_ intrinsic as follows:. .. code-block:: llvm. ehcleanup:; %InResumePart = call i1 @llvm.coro.end(ptr null, i1 true, token none); br i1 %InResumePart, label %eh.resume, label %cleanup.cont. cleanup.cont:; ; rest of the cleanup. eh.resume:; %exn = load ptr, ptr %exn.slot, align 8; %sel = load i32, ptr %ehselector.slot, align 4; %lpad.val = insertvalue { ptr, i32 } undef, ptr %exn, 0; %lpad.val29 = insertvalue { ptr, i32 } %lpad.val, i32 %sel, 1; resume { ptr, i32 } %lpad.val29. The `CoroSpit` pass replaces `coro.end` with ``True`` in the resume functions,; thus leading to immediate unwind to the caller, whereas in start function it; is replaced with ``False``, thus allowing to proceed to the rest of the cleanup; code that is only needed during initial invocation of the coroutine. For Windows Exception handling model, a frontend should attach a funclet bundle; referring to an enclosing cleanuppad as follows:. .. code-block:: llvm. ehcleanup:; %tok = cleanuppad within none []; %unused = call i1 @llvm.coro.end(ptr null, i1 true, token none) [ ""funclet""(token %tok) ]; cleanupret from %tok unwind label %RestOfTheCleanup. The `CoroSplit` pass, if the funclet bundle is present, will insert; ``cleanupret from %tok unwind to caller`` befor",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:44973,load,load,44973,interpreter/llvm-project/llvm/docs/Coroutines.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst,1,['load'],['load']
Performance," ``llvm/lib/ExecutionEngine/``. Libraries for directly executing bitcode at runtime in interpreted and; JIT-compiled scenarios. ``llvm/lib/Support/``. Source code that corresponding to the header files in ``llvm/include/ADT/``; and ``llvm/include/Support/``. ``llvm/bindings``; ----------------------. Contains bindings for the LLVM compiler infrastructure to allow; programs written in languages other than C or C++ to take advantage of the LLVM; infrastructure.; LLVM project provides language bindings for OCaml and Python. ``llvm/projects``; -----------------. Projects not strictly part of LLVM but shipped with LLVM. This is also the; directory for creating your own LLVM-based projects which leverage the LLVM; build system. ``llvm/test``; -------------. Feature and regression tests and other sanity checks on LLVM infrastructure. These; are intended to run quickly and cover a lot of territory without being exhaustive. ``test-suite``; --------------. A comprehensive correctness, performance, and benchmarking test suite; for LLVM. This comes in a ``separate git repository; <https://github.com/llvm/llvm-test-suite>``, because it contains a; large amount of third-party code under a variety of licenses. For; details see the :doc:`Testing Guide <TestingGuide>` document. .. _tools:. ``llvm/tools``; --------------. Executables built out of the libraries; above, which form the main part of the user interface. You can always get help; for a tool by typing ``tool_name -help``. The following is a brief introduction; to the most important tools. More detailed information is in; the `Command Guide <CommandGuide/index.html>`_. ``bugpoint``. ``bugpoint`` is used to debug optimization passes or code generation backends; by narrowing down the given test case to the minimum number of passes and/or; instructions that still cause a problem, whether it is a crash or; miscompilation. See `<HowToSubmitABug.html>`_ for more information on using; ``bugpoint``. ``llvm-ar``. The archiver produces ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GettingStarted.rst:38215,perform,performance,38215,interpreter/llvm-project/llvm/docs/GettingStarted.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GettingStarted.rst,1,['perform'],['performance']
Performance," ``no-`` prefix, and; ``off`` is specified by including the ``no-`` prefix. The default; if not specified is ``off``. For example:. ``-mcpu=gfx908:xnack+``; Enable the ``xnack`` feature.; ``-mcpu=gfx908:xnack-``; Disable the ``xnack`` feature.; ``-mcumode``; Enable the ``cumode`` feature.; ``-mno-cumode``; Disable the ``cumode`` feature. .. table:: AMDGPU Target Features; :name: amdgpu-target-features-table. =============== ============================ ==================================================; Target Feature Clang Option to Control Description; Name; =============== ============================ ==================================================; cumode - ``-m[no-]cumode`` Control the wavefront execution mode used; when generating code for kernels. When disabled; native WGP wavefront execution mode is used,; when enabled CU wavefront execution mode is used; (see :ref:`amdgpu-amdhsa-memory-model`). sramecc - ``-mcpu`` If specified, generate code that can only be; - ``--offload-arch`` loaded and executed in a process that has a; matching setting for SRAMECC. If not specified for code object V2 to V3, generate; code that can be loaded and executed in a process; with SRAMECC enabled. If not specified for code object V4 or above, generate; code that can be loaded and executed in a process; with either setting of SRAMECC. tgsplit ``-m[no-]tgsplit`` Enable/disable generating code that assumes; work-groups are launched in threadgroup split mode.; When enabled the waves of a work-group may be; launched in different CUs. wavefrontsize64 - ``-m[no-]wavefrontsize64`` Control the wavefront size used when; generating code for kernels. When disabled; native wavefront size 32 is used, when enabled; wavefront size 64 is used. xnack - ``-mcpu`` If specified, generate code that can only be; - ``--offload-arch`` loaded and executed in a process that has a; matching setting for XNACK replay. If not specified for code object V2 to V3, generate; code that can be loaded and execut",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:17260,load,loaded,17260,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['loaded']
Performance, ``r600`` AMD GPUs HD2XXX-HD6XXX for graphics and compute shaders.; ``amdgcn`` AMD GPUs GCN GFX6 onwards for graphics and compute shaders.; ============ ==============================================================. .. table:: AMDGPU Vendors; :name: amdgpu-vendor-table. ============ ==============================================================; Vendor Description; ============ ==============================================================; ``amd`` Can be used for all AMD GPU usage.; ``mesa3d`` Can be used if the OS is ``mesa3d``.; ============ ==============================================================. .. table:: AMDGPU Operating Systems; :name: amdgpu-os. ============== ============================================================; OS Description; ============== ============================================================; *<empty>* Defaults to the *unknown* OS.; ``amdhsa`` Compute kernels executed on HSA [HSA]_ compatible runtimes; such as:. - AMD's ROCm™ runtime [AMD-ROCm]_ using the *rocm-amdhsa*; loader on Linux. See *AMD ROCm Platform Release Notes*; [AMD-ROCm-Release-Notes]_ for supported hardware and; software.; - AMD's PAL runtime using the *pal-amdhsa* loader on; Windows. ``amdpal`` Graphic shaders and compute kernels executed on AMD's PAL; runtime using the *pal-amdpal* loader on Windows and Linux; Pro.; ``mesa3d`` Graphic shaders and compute kernels executed on AMD's Mesa; 3D runtime using the *mesa-mesa3d* loader on Linux.; ============== ============================================================. .. table:: AMDGPU Environments; :name: amdgpu-environment-table. ============ ==============================================================; Environment Description; ============ ==============================================================; *<empty>* Default.; ============ ==============================================================. .. _amdgpu-processors:. Processors; ----------. Use the Clang options ``-mcpu=<target-id>`` or ``--offload-arch=<tar,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:2415,load,loader,2415,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['loader']
Performance," ``replaceWithNewValue`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. This method is a simple helper method that is provided to make clients easier to; use. It is implemented by copying the old analysis information to the new; value, then deleting the old value. This method cannot be overridden by alias; analysis implementations. The ``addEscapingUse`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The ``addEscapingUse`` method is used when the uses of a pointer value have; changed in ways that may invalidate precomputed analysis information.; Implementations may either use this callback to provide conservative responses; for points whose uses have change since analysis time, or may recompute some or; all of their internal state to continue providing accurate responses. In general, any new use of a pointer value is considered an escaping use, and; must be reported through this callback, *except* for the uses below:. * A ``bitcast`` or ``getelementptr`` of the pointer; * A ``store`` through the pointer (but not a ``store`` *of* the pointer); * A ``load`` through the pointer. Efficiency Issues; -----------------. From the LLVM perspective, the only thing you need to do to provide an efficient; alias analysis is to make sure that alias analysis **queries** are serviced; quickly. The actual calculation of the alias analysis results (the ""run""; method) is only performed once, but many (perhaps duplicate) queries may be; performed. Because of this, try to move as much computation to the run method; as possible (within reason). Limitations; -----------. The AliasAnalysis infrastructure has several limitations which make writing a; new ``AliasAnalysis`` implementation difficult. There is no way to override the default alias analysis. It would be very useful; to be able to do something like ""``opt -my-aa -O2``"" and have it use ``-my-aa``; for all passes which need AliasAnalysis, but there is currently no support for; that, short of changing the source code and recompiling. Similarly, ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AliasAnalysis.rst:16408,load,load,16408,interpreter/llvm-project/llvm/docs/AliasAnalysis.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AliasAnalysis.rst,1,['load'],['load']
Performance," ``urem`` or ``srem``; instruction.; - The condition operand of a :ref:`br <i_br>` instruction.; - The callee operand of a :ref:`call <i_call>` or :ref:`invoke <i_invoke>`; instruction.; - The parameter operand of a :ref:`call <i_call>` or :ref:`invoke <i_invoke>`; instruction, when the function or invoking call site has a ``noundef``; attribute in the corresponding position.; - The operand of a :ref:`ret <i_ret>` instruction if the function or invoking; call site has a `noundef` attribute in the return value position. Here are some examples:. .. code-block:: llvm. entry:; %poison = sub nuw i32 0, 1 ; Results in a poison value.; %poison2 = sub i32 poison, 1 ; Also results in a poison value.; %still_poison = and i32 %poison, 0 ; 0, but also poison.; %poison_yet_again = getelementptr i32, ptr @h, i32 %still_poison; store i32 0, ptr %poison_yet_again ; Undefined behavior due to; ; store to poison. store i32 %poison, ptr @g ; Poison value stored to memory.; %poison3 = load i32, ptr @g ; Poison value loaded back from memory. %poison4 = load i16, ptr @g ; Returns a poison value.; %poison5 = load i64, ptr @g ; Returns a poison value. %cmp = icmp slt i32 %poison, 0 ; Returns a poison value.; br i1 %cmp, label %end, label %end ; undefined behavior. end:. .. _welldefinedvalues:. Well-Defined Values; -------------------. Given a program execution, a value is *well defined* if the value does not; have an undef bit and is not poison in the execution.; An aggregate value or vector is well defined if its elements are well defined.; The padding of an aggregate isn't considered, since it isn't visible; without storing it into memory and loading it with a different type. A constant of a :ref:`single value <t_single_value>`, non-vector type is well; defined if it is neither '``undef``' constant nor '``poison``' constant.; The result of :ref:`freeze instruction <i_freeze>` is well defined regardless; of its operand. .. _blockaddress:. Addresses of Basic Blocks; -------------------------",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:198867,load,load,198867,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,2,['load'],"['load', 'loaded']"
Performance," `opcode-index`, `opcode-name` or `snippets-file` must be set. .. option:: --snippets-file=<filename>. Specify the custom code snippet to measure. See example 2 for details.; Either `opcode-index`, `opcode-name` or `snippets-file` must be set. .. option:: --mode=[latency|uops|inverse_throughput|analysis]. Specify the run mode. Note that some modes have additional requirements and options. `latency` mode can be make use of either RDTSC or LBR.; `latency[LBR]` is only available on X86 (at least `Skylake`).; To run in `latency` mode, a positive value must be specified; for `x86-lbr-sample-period` and `--repetition-mode=loop`. In `analysis` mode, you also need to specify at least one of the; `-analysis-clusters-output-file=` and `-analysis-inconsistencies-output-file=`. .. option:: --benchmark-phase=[prepare-snippet|prepare-and-assemble-snippet|assemble-measured-code|measure]. By default, when `-mode=` is specified, the generated snippet will be executed; and measured, and that requires that we are running on the hardware for which; the snippet was generated, and that supports performance measurements.; However, it is possible to stop at some stage before measuring. Choices are:; * ``prepare-snippet``: Only generate the minimal instruction sequence.; * ``prepare-and-assemble-snippet``: Same as ``prepare-snippet``, but also dumps an excerpt of the sequence (hex encoded).; * ``assemble-measured-code``: Same as ``prepare-and-assemble-snippet``. but also creates the full sequence that can be dumped to a file using ``--dump-object-to-disk``.; * ``measure``: Same as ``assemble-measured-code``, but also runs the measurement. .. option:: --x86-lbr-sample-period=<nBranches/sample>. Specify the LBR sampling period - how many branches before we take a sample.; When a positive value is specified for this option and when the mode is `latency`,; we will use LBRs for measuring.; On choosing the ""right"" sampling period, a small value is preferred, but throttling; could occur if the sam",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-exegesis.rst:10784,perform,performance,10784,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-exegesis.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-exegesis.rst,1,['perform'],['performance']
Performance," `pn1->Align()` will invalidate the pointer to the node `B_1`; in `pn2` object.. The way out is to either call `pn1->Align()` before; the creation of `pn2`, either to use a global method that will correct; all existing physical nodes:. ~~~{.cpp}; void RefreshPhysicalNodes(Bool_t lock = kTRUE); ~~~. The method above will optionally lock the possibility of doing any; further misalignment. \anchor GP06; ## Geometry I/O. Once geometry is successfully built, it can be saved in a root file, as; C++ macro or as GDML file by calling:. ~~~{.cpp}; TGeoManager::Export(const char *filename,const char*keyname="""",; Option_t *opt=""vg""); ~~~. - `Filename` is the name of the file to be written (mandatory).; Depending on the extension of the file, the geometry is exported; either as ,root file or .C(.cxx) macro or GDML file in case; extension is .gdml.; - `keyname`is the name of the key in the file (default """"); - `opt` = `""v""` is an export voxelization (default), otherwise; voxelization is recomputed after loading the geometry, `""g""` this; option (default) is taken into account only for exporting to gdml; file and it ensures compatibility with Geant4 (e.g. it adds extra; plane to incorrectly set polycone, it checks whether offset of Phi; division is in (-360;0\> range, ...), for this gdml export there are; two more option, that are not set by default: `""f""` and `""n""`. If; none of this two options are set, then names of solids and volumes; in resulting gdml file will have incremental suffix (e.g.; TGeoBBox\_0x1, TGeoBBox\_0x2, ...). If `""f""` option is set then then; suffix will contain pointer of object (e.g. TGeoBBox\_0xAAAAA01,; ...). Finally if option `""n""` is set then no suffix will be added,; though in this case uniqueness of the names is not ensured and it can; cause that file will be invalid. Loading geometry from a root file can be done in the same way as for any; other ROOT object, but a static method is also provided:. ~~~{.cpp}; TGeoManager::Import(const char *filename,cons",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:111205,load,loading,111205,geom/geom/doc/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md,1,['load'],['loading']
Performance," a CU. Therefore:. * No special action is required for coherence between the lanes of a single; wavefront. * No special action is required for coherence between wavefronts in the same; work-group since they execute on the same CU. The exception is when in; tgsplit execution mode as wavefronts of the same work-group can be in; different CUs and so a ``buffer_inv sc0`` is required which will invalidate; the L1 cache. * A ``buffer_inv sc0`` is required to invalidate the L1 cache for coherence; between wavefronts executing in different work-groups as they may be; executing on different CUs. * Atomic read-modify-write instructions implicitly bypass the L1 cache.; Therefore, they do not use the sc0 bit for coherence and instead use it to; indicate if the instruction returns the original value being updated. They; do use sc1 to indicate system or agent scope coherence. * The scalar memory operations access a scalar L1 cache shared by all wavefronts; on a group of CUs. The scalar and vector L1 caches are not coherent. However,; scalar operations are used in a restricted way so do not impact the memory; model. See :ref:`amdgpu-amdhsa-memory-spaces`.; * The vector and scalar memory operations use an L2 cache. * The gfx942 can be configured as a number of smaller agents with each having; a single L2 shared by all CUs on the same agent, or as fewer (possibly one); larger agents with groups of CUs on each agent each sharing separate L2; caches.; * The L2 cache has independent channels to service disjoint ranges of virtual; addresses.; * Each CU has a separate request queue per channel for its associated L2.; Therefore, the vector and scalar memory operations performed by wavefronts; executing with different L1 caches and the same L2 cache can be reordered; relative to each other.; * A ``s_waitcnt vmcnt(0)`` is required to ensure synchronization between; vector memory operations of different CUs. It ensures a previous vector; memory operation has completed before executing a subs",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:287079,cache,caches,287079,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['cache'],['caches']
Performance," a CU. Therefore:. * No special action is required for coherence between the lanes of a single; wavefront. * No special action is required for coherence between wavefronts in the same; work-group since they execute on the same CU. The exception is when in; tgsplit execution mode as wavefronts of the same work-group can be in; different CUs and so a ``buffer_wbinvl1_vol`` is required as described in; the following item. * A ``buffer_wbinvl1_vol`` is required for coherence between wavefronts; executing in different work-groups as they may be executing on different; CUs. * The scalar memory operations access a scalar L1 cache shared by all wavefronts; on a group of CUs. The scalar and vector L1 caches are not coherent. However,; scalar operations are used in a restricted way so do not impact the memory; model. See :ref:`amdgpu-amdhsa-memory-spaces`.; * The vector and scalar memory operations use an L2 cache shared by all CUs on; the same agent. * The L2 cache has independent channels to service disjoint ranges of virtual; addresses.; * Each CU has a separate request queue per channel. Therefore, the vector and; scalar memory operations performed by wavefronts executing in different; work-groups (which may be executing on different CUs), or the same; work-group if executing in tgsplit mode, of an agent can be reordered; relative to each other. A ``s_waitcnt vmcnt(0)`` is required to ensure; synchronization between vector memory operations of different CUs. It; ensures a previous vector memory operation has completed before executing a; subsequent vector memory or LDS operation and so can be used to meet the; requirements of acquire and release.; * The L2 cache of one agent can be kept coherent with other agents by:; using the MTYPE RW (read-write) or MTYPE CC (cache-coherent) with the PTE; C-bit for memory local to the L2; and using the MTYPE NC (non-coherent) with; the PTE C-bit set or MTYPE UC (uncached) for memory not local to the L2. * Any local memory cache lines w",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:236895,cache,cache,236895,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['cache'],['cache']
Performance," a binary with SSL; support. #### Ubuntu/Debian; On Debian, Ubuntu, Linux Mint, CrunchBang, or any other distro based on Debian; which supports APT package manager, you can install all the required packages by:; ```sh; sudo apt-get update; sudo apt-get install git g++ debhelper devscripts gnupg python; ```; You are not required to do this manually since CPT can do this for you automatically. ###### Setting up:; Make sure GnuPG is properly set up with your correct fingerprint. These; credentials are needed to sign the Debian package and create Debian changelogs.; On a build machine (Electric Commander), make sure the fingerprint is of the; user who is supposed to sign the official uploads. You might also want to; configure GnuPG to not ask for the passphrase while signing the Debian package. The [Ubuntu Packaging Guide] contains a quick guide on creating a GPG key on an; Ubuntu system. To test if you have successfully set up your GnuPG key, use the following command:; ```sh; gpg --fingerprint; ```; Again, all these checks are performed by default when you launch CPT with ```-c``` option.; [Ubuntu Packaging Guide]:http://packaging.ubuntu.com/html/getting-set-up.html#create-your-gpg-key. #### Windows; CPT is meant to be executed on cmd.exe prompt. Make sure you have set the; environment properly before continuing.; Below is a list of required packages for Windows (Win32-x86):. [MSYS Git] for Windows. [Python] for Windows. Microsoft Visual Studio 11 (2012), with Microsoft Visual C++ 2012. [MSYS Git]:http://msysgit.github.io/; [Python]:https://www.python.org/. ###### Setting Up:; Unlike other UNIX-like platforms, Windows requires you to follow some rules.; Do not ignore this section unless you want CPT to fail mid-way with wierd; errors. You should require these instructions only once. * While installing the packages make sure the executable is in a path that; doesn't contain spaces. For example, you should install Python in a path like. ```sh; C:\Python27; ```; rather t",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md:3390,perform,performed,3390,interpreter/cling/tools/packaging/README.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md,1,['perform'],['performed']
Performance," a conversion on; values returned from a function for some calling conventions. See `issue; #66803 <https://github.com/llvm/llvm-project/issues/66803>`_.; - Older MIPS versions use the opposite polarity for the quiet/signaling bit, and; LLVM does not correctly represent this. See `issue #60796; <https://github.com/llvm/llvm-project/issues/60796>`_. .. _fastmath:. Fast-Math Flags; ---------------. LLVM IR floating-point operations (:ref:`fneg <i_fneg>`, :ref:`fadd <i_fadd>`,; :ref:`fsub <i_fsub>`, :ref:`fmul <i_fmul>`, :ref:`fdiv <i_fdiv>`,; :ref:`frem <i_frem>`, :ref:`fcmp <i_fcmp>`), :ref:`phi <i_phi>`,; :ref:`select <i_select>` and :ref:`call <i_call>`; may use the following flags to enable otherwise unsafe; floating-point transformations. ``nnan``; No NaNs - Allow optimizations to assume the arguments and result are not; NaN. If an argument is a nan, or the result would be a nan, it produces; a :ref:`poison value <poisonvalues>` instead. ``ninf``; No Infs - Allow optimizations to assume the arguments and result are not; +/-Inf. If an argument is +/-Inf, or the result would be +/-Inf, it; produces a :ref:`poison value <poisonvalues>` instead. ``nsz``; No Signed Zeros - Allow optimizations to treat the sign of a zero; argument or zero result as insignificant. This does not imply that -0.0; is poison and/or guaranteed to not exist in the operation. ``arcp``; Allow Reciprocal - Allow optimizations to use the reciprocal of an; argument rather than perform division. ``contract``; Allow floating-point contraction (e.g. fusing a multiply followed by an; addition into a fused multiply-and-add). This does not enable reassociating; to form arbitrary contractions. For example, ``(a*b) + (c*d) + e`` can not; be transformed into ``(a*b) + ((c*d) + e)`` to create two fma operations. .. _fastmath_afn:. ``afn``; Approximate functions - Allow substitution of approximate calculations for; functions (sin, log, sqrt, etc). See floating-point intrinsic definitions; for places where th",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:162051,optimiz,optimizations,162051,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['optimiz'],['optimizations']
Performance," a custom streamer nor of any data members marked with //||. Run time performance. We introduced an optimized infrastructure for reading objects using a StreamerInfo. Rather than driving the streaming using a switch statement inside TStreamerInfo::ReadBuffer,; the streaming is now driven using a simple loop over a sequence of configured StreamerInfo actions. This improves run-time performance by allowing a dramatic reduction in function calls and code; branches at the expense of some code duplication. There are 3 versions of this loop implemented in TBufferFile and overloaded in TBufferXML and TBufferSQL:. virtual Int_t ReadSequence(const TStreamerInfoActions::TActionSequence &sequence, void *object);; virtual Int_t ReadSequence(const TStreamerInfoActions::TActionSequence &sequence,; void *start_collection, void *end_collection);; virtual Int_t ReadSequence(const TStreamerInfoActions::TActionSequence &sequence,; void *start_collection, void *end_collection);. The 1st version is optimized to read a single object. The 2nd version is optimized to read the content of TClonesArrays and vectors of pointers to objects. The 3rd version is used to streamed any collections. TBufferXML and TBufferSQL overload the loops to introduce extra code to help the buffer keep track of which streamer element is being streamed (this functionality is not used by TBufferFile.). A TStreamerInfoActions::TActionSequence is an ordered sequence of configured actions. A configured action has both an action which is a free standing function and a configuration object deriving; from TStreamerInfoActions::TConfiguration. The configuration contains information that is specific to the action; but varies from use to use, including the offset from the beginning of the object that needs to be updated.; Other examples of configuration include the number of bits requested for storing a Double32_t or its factor and minimum. When the sequence is intended for a collection, the sequence has a configuration obj",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/io/doc/v528/index.html:3748,optimiz,optimized,3748,io/doc/v528/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/doc/v528/index.html,2,['optimiz'],['optimized']
Performance," a frame at the same address, respectively. There is no need for a; ``s_dcache_inv`` as all scalar writes are write-before-read in the same thread. For kernarg backing memory:. * CP invalidates the L0 and L1 caches at the start of each kernel dispatch.; * On dGPU the kernarg backing memory is accessed as MTYPE UC (uncached) to avoid; needing to invalidate the L2 cache.; * On APU the kernarg backing memory is accessed as MTYPE CC (cache coherent) and; so the L2 cache will be coherent with the CPU and other agents. Scratch backing memory (which is used for the private address space) is accessed; with MTYPE NC (non-coherent). Since the private address space is only accessed; by a single thread, and is always write-before-read, there is never a need to; invalidate these entries from the L0 or L1 caches. Wavefronts are executed in native mode with in-order reporting of loads and; sample instructions. In this mode vmcnt reports completion of load, atomic with; return and sample instructions in order, and the vscnt reports the completion of; store and atomic without return in order. See ``MEM_ORDERED`` field in; :ref:`amdgpu-amdhsa-compute_pgm_rsrc1-gfx6-gfx12-table`. Wavefronts can be executed in WGP or CU wavefront execution mode:. * In WGP wavefront execution mode the wavefronts of a work-group are executed; on the SIMDs of both CUs of the WGP. Therefore, explicit management of the per; CU L0 caches is required for work-group synchronization. Also accesses to L1; at work-group scope need to be explicitly ordered as the accesses from; different CUs are not ordered.; * In CU wavefront execution mode the wavefronts of a work-group are executed on; the SIMDs of a single CU of the WGP. Therefore, all global memory access by; the work-group access the same L0 which in turn ensures L1 accesses are; ordered and so do not require explicit management of the caches for; work-group synchronization. See ``WGP_MODE`` field in; :ref:`amdgpu-amdhsa-compute_pgm_rsrc1-gfx6-gfx12-table` a",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:341957,load,load,341957,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['load']
Performance," a hardware-loop instruction.; The result is the conditional value of whether the given count is not zero. '``llvm.test.start.loop.iterations.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". This is an overloaded intrinsic. ::. declare {i32, i1} @llvm.test.start.loop.iterations.i32(i32); declare {i64, i1} @llvm.test.start.loop.iterations.i64(i64). Overview:; """""""""""""""""". The '``llvm.test.start.loop.iterations.*``' intrinsics are similar to the; '``llvm.test.set.loop.iterations.*``' and '``llvm.start.loop.iterations.*``'; intrinsics, used to specify the hardware-loop trip count, but also produce a; value identical to the input that can be used as the input to the loop. The; second i1 output controls entry to a while-loop. Arguments:; """""""""""""""""""". The integer operand is the loop trip count of the hardware-loop, and thus; not e.g. the loop back-edge taken count. Semantics:; """""""""""""""""""". The '``llvm.test.start.loop.iterations.*``' intrinsics do not perform any; arithmetic on their operand. It's a hint to the backend that can use this to; set up the hardware-loop count with a target specific instruction, usually a; move of this value to a special register or a hardware-loop instruction.; The result is a pair of the input and a conditional value of whether the; given count is not zero. '``llvm.loop.decrement.reg.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". This is an overloaded intrinsic. ::. declare i32 @llvm.loop.decrement.reg.i32(i32, i32); declare i64 @llvm.loop.decrement.reg.i64(i64, i64). Overview:; """""""""""""""""". The '``llvm.loop.decrement.reg.*``' intrinsics are used to lower the loop; iteration counter and return an updated value that will be used in the next; loop test check. Arguments:; """""""""""""""""""". Both arguments must have identical integer types. The first operand is the; loop iteration counter. The second operand is the maximum number of elements; processed in an iteration. Semantics:; """""""""""""""""""". Th",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:647293,perform,perform,647293,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['perform']
Performance," a list of lists you; make a list of variable names that refer to other lists. For example:. .. code-block:: cmake. set(list_of_lists a b c); set(a 1 2 3); set(b 4 5 6); set(c 7 8 9). With this layout you can iterate through the list of lists printing each value; with the following code:. .. code-block:: cmake. foreach(list_name IN LISTS list_of_lists); foreach(value IN LISTS ${list_name}); message(${value}); endforeach(); endforeach(). You'll notice that the inner foreach loop's list is doubly dereferenced. This is; because the first dereference turns ``list_name`` into the name of the sub-list; (a, b, or c in the example), then the second dereference is to get the value of; the list. This pattern is used throughout CMake, the most common example is the compiler; flags options, which CMake refers to using the following variable expansions:; CMAKE_${LANGUAGE}_FLAGS and CMAKE_${LANGUAGE}_FLAGS_${CMAKE_BUILD_TYPE}. Other Types; -----------. Variables that are cached or specified on the command line can have types; associated with them. The variable's type is used by CMake's UI tool to display; the right input field. A variable's type generally doesn't impact evaluation,; however CMake does have special handling for some variables such as PATH.; You can read more about the special handling in `CMake's set documentation; <https://cmake.org/cmake/help/v3.5/command/set.html#set-cache-entry>`_. Scope; -----. CMake inherently has a directory-based scoping. Setting a variable in a; CMakeLists file, will set the variable for that file, and all subdirectories.; Variables set in a CMake module that is included in a CMakeLists file will be; set in the scope they are included from, and all subdirectories. When a variable that is already set is set again in a subdirectory it overrides; the value in that scope and any deeper subdirectories. The CMake set command provides two scope-related options. PARENT_SCOPE sets a; variable into the parent scope, and not the current scope. The CA",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst:5731,cache,cached,5731,interpreter/llvm-project/llvm/docs/CMakePrimer.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst,1,['cache'],['cached']
Performance," a positive, constant integer with; ``%Stride >= <Rows>``. ``%Stride`` is used to compute the column memory; addresses. I.e., for a column ``C``, its start memory addresses is calculated; with ``%Ptr + C * %Stride``. The fourth argument ``<IsVolatile>`` is a boolean; value. The arguments ``<Rows>`` and ``<Cols>`` correspond to the number of rows; and columns, respectively, and must be positive, constant integers. The :ref:`align <attr_align>` parameter attribute can be provided; for the ``%Ptr`` arguments. Half Precision Floating-Point Intrinsics; ----------------------------------------. For most target platforms, half precision floating-point is a; storage-only format. This means that it is a dense encoding (in memory); but does not support computation in the format. This means that code must first load the half-precision floating-point; value as an i16, then convert it to float with; :ref:`llvm.convert.from.fp16 <int_convert_from_fp16>`. Computation can; then be performed on the float value (including extending to double; etc). To store the value back to memory, it is first converted to float; if needed, then converted to i16 with; :ref:`llvm.convert.to.fp16 <int_convert_to_fp16>`, then storing as an; i16 value. .. _int_convert_to_fp16:. '``llvm.convert.to.fp16``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i16 @llvm.convert.to.fp16.f32(float %a); declare i16 @llvm.convert.to.fp16.f64(double %a). Overview:; """""""""""""""""". The '``llvm.convert.to.fp16``' intrinsic function performs a conversion from a; conventional floating-point type to half precision floating-point format. Arguments:; """""""""""""""""""". The intrinsic function contains single argument - the value to be; converted. Semantics:; """""""""""""""""""". The '``llvm.convert.to.fp16``' intrinsic function performs a conversion from a; conventional floating-point format to half precision floating-point format. The; return value is an ``i16`` which contains the converted number. Examples:; """"""""",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:681194,perform,performed,681194,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['performed']
Performance," a value against a constant, emit the check using a consistent; comparison type. The GVN pass *will* optimize redundant equalities even if; the type of comparison is inverted, but GVN only runs late in the pipeline.; As a result, you may miss the opportunity to run other important; optimizations. #. Avoid using arithmetic intrinsics unless you are *required* by your source; language specification to emit a particular code sequence. The optimizer; is quite good at reasoning about general control flow and arithmetic, it is; not anywhere near as strong at reasoning about the various intrinsics. If; profitable for code generation purposes, the optimizer will likely form the; intrinsics itself late in the optimization pipeline. It is *very* rarely; profitable to emit these directly in the language frontend. This item; explicitly includes the use of the :ref:`overflow intrinsics <int_overflow>`. #. Avoid using the :ref:`assume intrinsic <int_assume>` until you've; established that a) there's no other way to express the given fact and b); that fact is critical for optimization purposes. Assumes are a great; prototyping mechanism, but they can have negative effects on both compile; time and optimization effectiveness. The former is fixable with enough; effort, but the later is fairly fundamental to their designed purpose. Describing Language Specific Properties; =======================================. When translating a source language to LLVM, finding ways to express concepts; and guarantees available in your source language which are not natively; provided by LLVM IR will greatly improve LLVM's ability to optimize your code.; As an example, C/C++'s ability to mark every add as ""no signed wrap (nsw)"" goes; a long way to assisting the optimizer in reasoning about loop induction; variables and thus generating more optimal code for loops. The LLVM LangRef includes a number of mechanisms for annotating the IR with; additional semantic information. It is *strongly* recommended ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:9535,optimiz,optimization,9535,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,1,['optimiz'],['optimization']
Performance," a; multiple of ``element_size`` bytes wide and aligned at an ``element_size`` boundary. The order of the assignment is unspecified. Only one write is issued to the; destination buffer per element. It is well defined to have concurrent reads and; writes to the destination provided those reads and writes are unordered atomic; when specified. This intrinsic does not provide any additional ordering guarantees over those; provided by a set of unordered stores to the destination. Lowering:; """""""""""""""""". In the most general case call to the '``llvm.memset.element.unordered.atomic.*``' is; lowered to a call to the symbol ``__llvm_memset_element_unordered_atomic_*``. Where '*'; is replaced with an actual element size. The optimizer is allowed to inline the memory assignment when it's profitable to do so. Objective-C ARC Runtime Intrinsics; ----------------------------------. LLVM provides intrinsics that lower to Objective-C ARC runtime entry points.; LLVM is aware of the semantics of these functions, and optimizes based on that; knowledge. You can read more about the details of Objective-C ARC `here; <https://clang.llvm.org/docs/AutomaticReferenceCounting.html>`_. '``llvm.objc.autorelease``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; ::. declare ptr @llvm.objc.autorelease(ptr). Lowering:; """""""""""""""""". Lowers to a call to `objc_autorelease <https://clang.llvm.org/docs/AutomaticReferenceCounting.html#arc-runtime-objc-autorelease>`_. '``llvm.objc.autoreleasePoolPop``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; ::. declare void @llvm.objc.autoreleasePoolPop(ptr). Lowering:; """""""""""""""""". Lowers to a call to `objc_autoreleasePoolPop <https://clang.llvm.org/docs/AutomaticReferenceCounting.html#void-objc-autoreleasepoolpop-void-pool>`_. '``llvm.objc.autoreleasePoolPush``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; ::. declare ptr @llvm.objc.autoreleasePoolPush(). Lowering:; """""""""""""""""". Lowers to a c",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:966252,optimiz,optimizes,966252,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['optimiz'],['optimizes']
Performance," abi, align stack slot of argument of type double on 8 byte; boundary to improve performance. //===---------------------------------------------------------------------===//. GCC's ix86_expand_int_movcc function (in i386.c) has a ton of interesting; simplifications for integer ""x cmp y ? a : b"". //===---------------------------------------------------------------------===//. Consider the expansion of:. define i32 @test3(i32 %X) {; %tmp1 = urem i32 %X, 255; ret i32 %tmp1; }. Currently it compiles to:. ...; movl $2155905153, %ecx; movl 8(%esp), %esi; movl %esi, %eax; mull %ecx; ... This could be ""reassociated"" into:. movl $2155905153, %eax; movl 8(%esp), %ecx; mull %ecx. to avoid the copy. In fact, the existing two-address stuff would do this; except that mul isn't a commutative 2-addr instruction. I guess this has; to be done at isel time based on the #uses to mul?. //===---------------------------------------------------------------------===//. Make sure the instruction which starts a loop does not cross a cacheline; boundary. This requires knowning the exact length of each machine instruction.; That is somewhat complicated, but doable. Example 256.bzip2:. In the new trace, the hot loop has an instruction which crosses a cacheline; boundary. In addition to potential cache misses, this can't help decoding as I; imagine there has to be some kind of complicated decoder reset and realignment; to grab the bytes from the next cacheline. 532 532 0x3cfc movb (1809(%esp, %esi), %bl <<<--- spans 2 64 byte lines; 942 942 0x3d03 movl %dh, (1809(%esp, %esi); 937 937 0x3d0a incl %esi; 3 3 0x3d0b cmpb %bl, %dl; 27 27 0x3d0d jnz 0x000062db <main+11707>. //===---------------------------------------------------------------------===//. In c99 mode, the preprocessor doesn't like assembly comments like #TRUNCATE. //===---------------------------------------------------------------------===//. This could be a single 16-bit load. int f(char *p) {; if ((p[0] == 1) & (p[1] == 2)) return 1;;",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README.txt:10522,cache,cacheline,10522,interpreter/llvm-project/llvm/lib/Target/X86/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README.txt,2,['cache'],['cacheline']
Performance," able to query the AST file to find entities stored there. For each Clang data structure that requires direct interaction with the AST; reader logic, there is an abstract class that provides the interface between; the two modules. The ``ASTReader`` class, which handles the loading of an AST; file, inherits from all of these abstract classes to provide lazy; deserialization of Clang's data structures. ``ASTReader`` implements the; following abstract classes:. ``ExternalSLocEntrySource``; This abstract interface is associated with the ``SourceManager`` class, and; is used whenever the :ref:`source manager <pchinternals-sourcemgr>` needs to; load the details of a file, buffer, or macro instantiation. ``IdentifierInfoLookup``; This abstract interface is associated with the ``IdentifierTable`` class, and; is used whenever the program source refers to an identifier that has not yet; been seen. In this case, the AST reader searches for this identifier within; its :ref:`identifier table <pchinternals-ident-table>` to load any top-level; declarations or macros associated with that identifier. ``ExternalASTSource``; This abstract interface is associated with the ``ASTContext`` class, and is; used whenever the abstract syntax tree nodes need to loaded from the AST; file. It provides the ability to de-serialize declarations and types; identified by their numeric values, read the bodies of functions when; required, and read the declarations stored within a declaration context; (either for iteration or for name lookup). ``ExternalSemaSource``; This abstract interface is associated with the ``Sema`` class, and is used; whenever semantic analysis needs to read information from the :ref:`global; method pool <pchinternals-method-pool>`. .. _pchinternals-chained:. Chained precompiled headers; ---------------------------. Chained precompiled headers were initially intended to improve the performance; of IDE-centric operations such as syntax highlighting and code completion while; a par",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/PCHInternals.rst:22772,load,load,22772,interpreter/llvm-project/clang/docs/PCHInternals.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/PCHInternals.rst,1,['load'],['load']
Performance," accesses a different L2 channel. Each L1; quadrant has a separate request queue per L2 channel. Therefore, the vector; and scalar memory operations performed by wavefronts executing in different; work-groups (which may be executing on different SAs) of an agent can be; reordered relative to each other. A ``s_waitcnt vmcnt(0) & vscnt(0)`` is; required to ensure synchronization between vector memory operations of; different SAs. It ensures a previous vector memory operation has completed; before executing a subsequent vector memory and so can be used to meet the; requirements of acquire, release and sequential consistency.; * The L2 cache can be kept coherent with other agents on some targets, or ranges; of virtual addresses can be set up to bypass it to ensure system coherence.; * On GFX10.3 and GFX11 a memory attached last level (MALL) cache exists for GPU memory.; The MALL cache is fully coherent with GPU memory and has no impact on system; coherence. All agents (GPU and CPU) access GPU memory through the MALL cache. Scalar memory operations are only used to access memory that is proven to not; change during the execution of the kernel dispatch. This includes constant; address space and global address space for program scope ``const`` variables.; Therefore, the kernel machine code does not have to maintain the scalar cache to; ensure it is coherent with the vector caches. The scalar and vector caches are; invalidated between kernel dispatches by CP since constant address space data; may change between kernel dispatch executions. See; :ref:`amdgpu-amdhsa-memory-spaces`. The one exception is if scalar writes are used to spill SGPR registers. In this; case the AMDGPU backend ensures the memory location used to spill is never; accessed by vector memory operations at the same time. If scalar writes are used; then a ``s_dcache_wb`` is inserted before the ``s_endpgm`` and before a function; return since the locations may be used for vector memory instructions by a; future",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:339958,cache,cache,339958,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['cache'],['cache']
Performance," actually see any benefits from modules, one first has to introduce module maps for the underlying C standard library and the libraries and headers on which it depends. The section `Modularizing a Platform`_ describes the steps one must take to write these module maps. One can use module maps without modules to check the integrity of the use of header files. To do this, use the ``-fimplicit-module-maps`` option instead of the ``-fmodules`` option, or use ``-fmodule-map-file=`` option to explicitly specify the module map files to load. Compilation model; -----------------; The binary representation of modules is automatically generated by the compiler on an as-needed basis. When a module is imported (e.g., by an ``#include`` of one of the module's headers), the compiler will spawn a second instance of itself [#]_, with a fresh preprocessing context [#]_, to parse just the headers in that module. The resulting Abstract Syntax Tree (AST) is then persisted into the binary representation of the module that is then loaded into translation unit where the module import was encountered. The binary representation of modules is persisted in the *module cache*. Imports of a module will first query the module cache and, if a binary representation of the required module is already available, will load that representation directly. Thus, a module's headers will only be parsed once per language configuration, rather than once per translation unit that uses the module. Modules maintain references to each of the headers that were part of the module build. If any of those headers changes, or if any of the modules on which a module depends change, then the module will be (automatically) recompiled. The process should never require any user intervention. Command-line parameters; -----------------------; ``-fmodules``; Enable the modules feature. ``-fbuiltin-module-map``; Load the Clang builtins module map file. (Equivalent to ``-fmodule-map-file=<resource dir>/include/module.modulemap``)",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Modules.rst:13587,load,loaded,13587,interpreter/llvm-project/clang/docs/Modules.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Modules.rst,1,['load'],['loaded']
Performance," added as follows:. ``` {.json}; ""<json-key>"": {; ""class"": ""<C++ class name>"",; ""arguments"": [; ""<json-key of constructor argument #1>"",; ""<json-key of constructor argument #2>"",; ...; ]; }; ```. Similarly, for the exporter, an entry in the; [export keys](https://github.com/root-project/root/blob/master/etc/RooFitHS3_wsexportkeys.json); needs to be added as follows:. ``` {.json}; ""<C++ class name>"": {; ""type"": ""<json-key>"",; ""proxies"": {; ""<name of proxy>"": ""<json-key of this element>"",; ""<name of proxy>"": ""<json-key of this element>"",; ...; }; }; ```. If you don't want to edit the central `json` files containing the; factory expressions or export keys, you can also put your custom; export keys or factory expressions into a different json file and load; that using `RooFit::JSONIO::loadExportKeys(const std::string; &fname)` and `RooFit::JSONIO::loadFactoryExpressions(const; std::string &fname)`. If either the importer or the exporter cannot be created with factory; expressions and export keys, you can instead write a custom `C++`; class to perform the import and export for you. ### Writing your own importers and exporters: Custom `C++` code. In order to implement your own importer or exporter, you can inherit; from the corresponding base classes `RooFit::JSONIO::Importer`; or `RooFit::JSONIO::Exporter`, respectively. You can find; [simple examples](https://github.com/root-project/root/blob/master/roofit/hs3/src/JSONFactories_RooFitCore.cxx); as well as; [more complicated ones](https://github.com/root-project/root/blob/master/roofit/hs3/src/JSONFactories_HistFactory.cxx); in `ROOT`. Any importer should take the following form:. ``` {.cpp}; class MyClassFactory : public RooFit::JSONIO::Importer {; public:; bool importFunction(RooJSONFactoryWSTool *tool, const JSONNode &p) const override; {; std::string name(RooJSONFactoryWSTool::name(p));. // check if the required keys are available in the JSON; if (!p.has_child(""<class member key #1>"")) {; RooJSONFactoryWSTool::error(",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/developers/roofit_hs3.md:4721,perform,perform,4721,roofit/doc/developers/roofit_hs3.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/developers/roofit_hs3.md,1,['perform'],['perform']
Performance," added or subtracted. ``` {.cpp}; TGeoTranslation t1;; t1->SetTranslation(-5,10,4);; TGeoTranslation *t2 = new TGeoTranslation(4,3,10);; t2->Subtract(&t1);; ```. - Rotations (**`TGeoRotation`** class) represent a pure rotation. Data; members are `Double_t fRotationMatrix[3*3]`. Rotations can be; defined either by Euler angles, either, by GEANT3 angles:. ``` {.cpp}; TGeoRotation *r1 = new TGeoRotation();; r1->SetAngles(phi,theta,psi); // all angles in degrees; ```. This represents the composition of: first a rotation about Z axis with; angle phi, then a rotation with theta about the rotated X axis, and; finally a rotation with `psi `about the new Z axis. ``` {.cpp}; r1->SetAngles(th1,phi1,th2,phi2,th3,phi3); ```. This is a rotation defined in GEANT3 style. Theta and phi are the; spherical angles of each axis of the rotated coordinate system with; respect to the initial one. This construction allows definition of; malformed rotations, e.g. not orthogonal. A check is performed and an; error message is issued in this case. Specific utilities: determinant, inverse. - Scale transformations (**`TGeoScale`** class) - represent a scaled; shrinking/enlargement, possibly different on all axes. Data members:; `Double_t fScale[3]`. Not implemented yet.; - Combined transformations - represent a rotation followed by a; translation. Data members:; `Double_t fTranslation[3], `**`TGeoRotation *fRotation`.**. ``` {.cpp}; TGeoRotation *rot = new TGeoRotation(""rot"",10,20,30);; TGeoTranslation trans;; ...; TGeoCombiTrans *c1 = new TGeoCombiTrans(trans,rot);; TGeoCombiTrans *c2 = new TGeoCombiTrans(""somename"",10,20,30,rot); ```. - General transformations: (**`TGeoHMatrix`** class) represent; combined transformations in any order.; - Identity transformation: (**`TGeoIdentity`** class) is a generic; identity transformation represented by a singleton class object; **`gGeoIdentity`**. ### Ownership of Geometry Objects. The class **`TGeoManager`** class contains the entire API needed for; build",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md:98386,perform,performed,98386,documentation/users-guide/Geometry.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md,1,['perform'],['performed']
Performance," address space cannot; - workgroup be used.*. 1. ds_store; atomicrmw monotonic - singlethread - global 1. buffer/global/flat_atomic; - wavefront - generic; - workgroup; - agent; atomicrmw monotonic - system - global 1. buffer/global/flat_atomic; - generic sc1=1; atomicrmw monotonic - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; - workgroup be used.*. 1. ds_atomic; **Acquire Atomic**; ------------------------------------------------------------------------------------; load atomic acquire - singlethread - global 1. buffer/global/ds/flat_load; - wavefront - local; - generic; load atomic acquire - workgroup - global 1. buffer/global_load sc0=1; 2. s_waitcnt vmcnt(0). - If not TgSplit execution; mode, omit.; - Must happen before the; following buffer_inv. 3. buffer_inv sc0=1. - If not TgSplit execution; mode, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale data. load atomic acquire - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_load; 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than the local load; atomic value being; acquired. load atomic acquire - workgroup - generic 1. flat_load sc0=1; 2. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit lgkmcnt(0).; - Must happen before; the following; buffer_inv and any; following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic value being; acquired. 3. buffer_inv sc0=1. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. load atomic acquire - a",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:296030,load,loads,296030,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['loads']
Performance," after; any preceding; global/generic load; atomic/; atomicrmw-with-return-value; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - s_waitcnt vscnt(0); must happen after; any preceding; global/generic; atomicrmw-no-return-value; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Must happen before; the following; buffer_gl0_inv.; - Ensures that the; fence-paired atomic; has completed; before invalidating; the; cache. Therefore; any following; locations read must; be no older than; the value read by; the; fence-paired-atomic. 3. buffer_gl0_inv. - If CU wavefront execution; mode, omit.; - Ensures that; following; loads will not see; stale data. fence acquire - agent *none* 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0) & vscnt(0). - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - If OpenCL and; address space is; local, omit; vmcnt(0) and vscnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate; (see comment for; previous fence).; - Could be split into; separate s_waitcnt; vmcnt(0), s_waitcnt; vscnt(0) and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load; atomic/; atomicrmw-with-return-value; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - s_waitcnt vscnt(0); must happen after; any preceding; global/generic; atomicrmw-no-return-value; with an equal or; wider sync scope; and memory ordering; stronger than; unorde",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:352927,load,loads,352927,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['loads']
Performance," alias analysis to predict when loads and stores do not alias with; each other. Note that, in the case of write-combining memory, rule 3 could be relaxed to; allow reordering of non-aliasing store operations. That being said, at the; moment, there is no way to further relax the memory model (``-noalias`` is the; only option). Essentially, there is no option to specify a different memory; type (e.g., write-back, write-combining, write-through; etc.) and consequently; to weaken, or strengthen, the memory model. Other limitations are:. * The LSUnit does not know when store-to-load forwarding may occur.; * The LSUnit does not know anything about cache hierarchy and memory types.; * The LSUnit does not know how to identify serializing operations and memory; fences. The LSUnit does not attempt to predict if a load or store hits or misses the L1; cache. It only knows if an instruction ""MayLoad"" and/or ""MayStore."" For; loads, the scheduling model provides an ""optimistic"" load-to-use latency (which; usually matches the load-to-use latency for when there is a hit in the L1D). :program:`llvm-mca` does not (on its own) know about serializing operations or; memory-barrier like instructions. The LSUnit used to conservatively use an; instruction's ""MayLoad"", ""MayStore"", and unmodeled side effects flags to; determine whether an instruction should be treated as a memory-barrier. This was; inaccurate in general and was changed so that now each instruction has an; IsAStoreBarrier and IsALoadBarrier flag. These flags are mca specific and; default to false for every instruction. If any instruction should have either of; these flags set, it should be done within the target's InstrPostProcess class.; For an example, look at the `X86InstrPostProcess::postProcessInstruction` method; within `llvm/lib/Target/X86/MCA/X86CustomBehaviour.cpp`. A load/store barrier consumes one entry of the load/store queue. A load/store; barrier enforces ordering of loads/stores. A younger load cannot pass a loa",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:41309,load,loads,41309,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,5,"['latency', 'load']","['latency', 'load-to-use', 'loads']"
Performance," all formats except YAML. For example:. ``clang -fsave-optimization-record=bitstream in.c -o out`` will generate. * ``/var/folders/43/9y164hh52tv_2nrdxrj31nyw0000gn/T/a-9be59b.o``. * ``/var/folders/43/9y164hh52tv_2nrdxrj31nyw0000gn/T/a-9be59b.opt.bitstream``. * ``out``. * ``out.dSYM/Contents/Resources/Remarks/out``. Darwin-only: compiling for multiple architectures will use the following; scheme:. ``<base>-<arch>.opt.<format>``. Note that this is incompatible with passing the; :option:`-foptimization-record-file` option. .. option:: -foptimization-record-file. Control the file to which optimization reports are written. This implies; :ref:`-fsave-optimization-record <opt_fsave-optimization-record>`. On Darwin platforms, this is incompatible with passing multiple; ``-arch <arch>`` options. .. option:: -foptimization-record-passes. Only include passes which match a specified regular expression. When optimization reports are being output (see; :ref:`-fsave-optimization-record <opt_fsave-optimization-record>`), this; option controls the passes that will be included in the final report. If this option is not used, all the passes are included in the optimization; record. .. _opt_fdiagnostics-show-hotness:. .. option:: -f[no-]diagnostics-show-hotness. Enable profile hotness information in diagnostic line. This option controls whether Clang prints the profile hotness associated; with diagnostics in the presence of profile-guided optimization information.; This is currently supported with optimization remarks (see; :ref:`Options to Emit Optimization Reports <rpass>`). The hotness information; allows users to focus on the hot optimization remarks that are likely to be; more relevant for run-time performance. For example, in this output, the block containing the callsite of `foo` was; executed 3000 times according to the profile data:. ::. s.c:7:10: remark: foo inlined into bar (hotness: 3000) [-Rpass-analysis=inline]; sum += foo(x, x - 2);; ^. This option is implied when; :ref:",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:13458,optimiz,optimization,13458,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,3,['optimiz'],"['optimization', 'optimization-record']"
Performance," all:. #. Each mutable variable becomes a stack allocation.; #. Each read of the variable becomes a load from the stack.; #. Each update of the variable becomes a store to the stack.; #. Taking the address of a variable just uses the stack address; directly. While this solution has solved our immediate problem, it introduced; another one: we have now apparently introduced a lot of stack traffic; for very simple and common operations, a major performance problem.; Fortunately for us, the LLVM optimizer has a highly-tuned optimization; pass named ""mem2reg"" that handles this case, promoting allocas like this; into SSA registers, inserting Phi nodes as appropriate. If you run this; example through the pass, for example, you'll get:. .. code-block:: bash. $ llvm-as < example.ll | opt -passes=mem2reg | llvm-dis; @G = weak global i32 0; @H = weak global i32 0. define i32 @test(i1 %Condition) {; entry:; br i1 %Condition, label %cond_true, label %cond_false. cond_true:; %X.0 = load i32, i32* @G; br label %cond_next. cond_false:; %X.1 = load i32, i32* @H; br label %cond_next. cond_next:; %X.01 = phi i32 [ %X.1, %cond_false ], [ %X.0, %cond_true ]; ret i32 %X.01; }. The mem2reg pass implements the standard ""iterated dominance frontier""; algorithm for constructing SSA form and has a number of optimizations; that speed up (very common) degenerate cases. The mem2reg optimization; pass is the answer to dealing with mutable variables, and we highly; recommend that you depend on it. Note that mem2reg only works on; variables in certain circumstances:. #. mem2reg is alloca-driven: it looks for allocas and if it can handle; them, it promotes them. It does not apply to global variables or heap; allocations.; #. mem2reg only looks for alloca instructions in the entry block of the; function. Being in the entry block guarantees that the alloca is only; executed once, which makes analysis simpler.; #. mem2reg only promotes allocas whose uses are direct loads and stores.; If the address of t",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl07.rst:7176,load,load,7176,interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl07.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl07.rst,1,['load'],['load']
Performance," allow checking; of cross-DSO virtual and indirect calls. .. option:: -fsanitize-cfi-icall-generalize-pointers. Generalize pointers in return and argument types in function type signatures; checked by Control Flow Integrity indirect call checking. See; :doc:`ControlFlowIntegrity` for more details. .. option:: -fsanitize-cfi-icall-experimental-normalize-integers. Normalize integers in return and argument types in function type signatures; checked by Control Flow Integrity indirect call checking. See; :doc:`ControlFlowIntegrity` for more details. This option is currently experimental. .. option:: -fstrict-vtable-pointers. Enable optimizations based on the strict rules for overwriting polymorphic; C++ objects, i.e. the vptr is invariant during an object's lifetime.; This enables better devirtualization. Turned off by default, because it is; still experimental. .. option:: -fwhole-program-vtables. Enable whole-program vtable optimizations, such as single-implementation; devirtualization and virtual constant propagation, for classes with; :doc:`hidden LTO visibility <LTOVisibility>`. Requires ``-flto``. .. option:: -f[no]split-lto-unit. Controls splitting the :doc:`LTO unit <LTOVisibility>` into regular LTO and; :doc:`ThinLTO` portions, when compiling with -flto=thin. Defaults to false; unless ``-fsanitize=cfi`` or ``-fwhole-program-vtables`` are specified, in; which case it defaults to true. Splitting is required with ``fsanitize=cfi``,; and it is an error to disable via ``-fno-split-lto-unit``. Splitting is; optional with ``-fwhole-program-vtables``, however, it enables more; aggressive whole program vtable optimizations (specifically virtual constant; propagation). When enabled, vtable definitions and select virtual functions are placed; in the split regular LTO module, enabling more aggressive whole program; vtable optimizations required for CFI and virtual constant propagation.; However, this can increase the LTO link time and memory requirements over; pure ThinLTO, ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:80549,optimiz,optimizations,80549,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,1,['optimiz'],['optimizations']
Performance," allow us to have arbitrarily complex index; expressions, while still distinguishing ""load"" from ""Array load"",; for example. Perhaps also, switch jump tables would be first class; types as well? This would allow better reasoning about the program. 5. Support dynamic loading of code from various sources. Already; mentioned above was the example of loading java bytecodes, but we want; to support dynamic loading of VM code as well. This makes the job of; the runtime compiler much more interesting: it can do interprocedural; optimizations that the static compiler can't do, because it doesn't; have all of the required information (for example, inlining from; shared libraries, etc...). 6. Define a set of generally useful annotations to add to the VM; representation. For example, a function can be analysed to see if it; has any sideeffects when run... also, the MOD/REF sets could be; calculated, etc... we would have to determine what is reasonable. This; would generally be used to make IP optimizations cheaper for the; runtime compiler... > o Explicit instructions to handle aliasing, e.g.s:; > -- an instruction to say ""I speculate that these two values are not; > aliased, but check at runtime"", like speculative execution in; > EPIC?; > -- or an instruction to check whether two values are aliased and; > execute different code depending on the answer, somewhat like; > predicated code in EPIC. These are also very good points... if this can be determined at compile; time. I think that an epic style of representation (not the instruction; packing, just the information presented) could be a very interesting model; to use... more later... > o (This one is a difficult but powerful idea.); > A ""thread-id"" field on every instruction that allows the static; > compiler to generate a set of parallel threads, and then have; > the runtime compiler and hardware do what they please with it.; > This has very powerful uses, but thread-id on every instruction; > is expensive in terms of instr",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2000-11-18-EarlyDesignIdeasResp.txt:6312,optimiz,optimizations,6312,interpreter/llvm-project/llvm/docs/HistoricalNotes/2000-11-18-EarlyDesignIdeasResp.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2000-11-18-EarlyDesignIdeasResp.txt,1,['optimiz'],['optimizations']
Performance," an OpenCL pipe is passed in; the kernarg. ""Queue""; A global address space pointer; to an OpenCL device enqueue; queue is passed in the; kernarg. ""HiddenGlobalOffsetX""; The OpenCL grid dispatch; global offset for the X; dimension is passed in the; kernarg. ""HiddenGlobalOffsetY""; The OpenCL grid dispatch; global offset for the Y; dimension is passed in the; kernarg. ""HiddenGlobalOffsetZ""; The OpenCL grid dispatch; global offset for the Z; dimension is passed in the; kernarg. ""HiddenNone""; An argument that is not used; by the kernel. Space needs to; be left for it, but it does; not need to be set up. ""HiddenPrintfBuffer""; A global address space pointer; to the runtime printf buffer; is passed in kernarg. Mutually; exclusive with; ""HiddenHostcallBuffer"". ""HiddenHostcallBuffer""; A global address space pointer; to the runtime hostcall buffer; is passed in kernarg. Mutually; exclusive with; ""HiddenPrintfBuffer"". ""HiddenDefaultQueue""; A global address space pointer; to the OpenCL device enqueue; queue that should be used by; the kernel by default is; passed in the kernarg. ""HiddenCompletionAction""; A global address space pointer; to help link enqueued kernels into; the ancestor tree for determining; when the parent kernel has finished. ""HiddenMultiGridSyncArg""; A global address space pointer for; multi-grid synchronization is; passed in the kernarg. ""ValueType"" string Unused and deprecated. This should no longer; be emitted, but is accepted for compatibility. ""PointeeAlign"" integer Alignment in bytes of pointee; type for pointer type kernel; argument. Must be a power; of 2. Only present if; ""ValueKind"" is; ""DynamicSharedPointer"".; ""AddrSpaceQual"" string Kernel argument address space; qualifier. Only present if; ""ValueKind"" is ""GlobalBuffer"" or; ""DynamicSharedPointer"". Values; are:. - ""Private""; - ""Global""; - ""Constant""; - ""Local""; - ""Generic""; - ""Region"". .. TODO::. Is GlobalBuffer only Global; or Constant? Is; DynamicSharedPointer always; Local? Can HCC allow Generic?; How",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:125074,queue,queue,125074,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['queue'],['queue']
Performance," an accelerator library and use ctypes to invoke functions.; * When the ROOT kernel is used, the output is consumed progressively; * Capture unlimited output also when using an IPython Kernel (fixes [ROOT-7960]). ## JavaScript ROOT. - New geometry (TGeo) classes support:; - browsing through volumes hieararchy; - changing visibility flags; - drawing of selected volumes; - support of large (~10M volumes) models, only most significant volumes are shown; - one could activate several clip planes (only with WebGL); - interaction with object browser to change visibility flags or focus on selected volume; - support of floating browser for TGeo objects; - intensive use of HTML Worker to offload computation tasks and keep interactivity; - enable more details when changing camera position/zoom; - Improvements in histograms 3D drawing; - all lego options: lego1..lego4, combined with 'fb', 'bb', '0' or 'z'; - support axis labels on lego plots; - support lego plots for TH1; - Significant (up to factor 10) performance improvement in 3D-graphics; - Implement ROOT6-like color palettes; - Support non-equidistant bins for TH1/TH2 objects.; - Improve TF1 drawing - support exp function in TFormula, fix errors with logx scale, enable zoom-in, (re)calculate function points when zooming; - Introduce many context menus for improving interactivity; - Implement col0 and col0z draw option for TH2 histograms, similar to ROOT6; - Implement box and hbox draw options for TH1 class; - Significant (factor 4) I/O performance improvement; - New 'flex' layout:; - create frames like in Multi Document Interface; - one could move/resize/minimize/maximize such frames. For more details, like the complete change log, the documentation, and very detailed examples, see the [JSROOT home page](https://root.cern.ch/js) and the [JSROOT project github page](https://github.com/linev/jsroot) . ## Tutorials; * New tutorial `treegetval.C` illustrating how to retrieve `TTree` variables in arrays.; * Add script to automa",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:26946,perform,performance,26946,README/ReleaseNotes/v608/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md,1,['perform'],['performance']
Performance," an intrinsic function is the; method of choice for LLVM extension. Before you invest a significant amount of effort into a non-trivial extension,; **ask on the list** if what you are looking to do can be done with; already-existing infrastructure, or if maybe someone else is already working on; it. You will save yourself a lot of time and effort by doing so. .. _intrinsic function:. Adding a new intrinsic function; ===============================. Adding a new intrinsic function to LLVM is much easier than adding a new; instruction. Almost all extensions to LLVM should start as an intrinsic; function and then be turned into an instruction if warranted. #. ``llvm/docs/LangRef.html``:. Document the intrinsic. Decide whether it is code generator specific and; what the restrictions are. Talk to other people about it so that you are; sure it's a good idea. #. ``llvm/include/llvm/IR/Intrinsics*.td``:. Add an entry for your intrinsic. Describe its memory access; characteristics for optimization (this controls whether it will be; DCE'd, CSE'd, etc). If any arguments need to be immediates, these; must be indicated with the ImmArg property. Note that any intrinsic; using one of the ``llvm_any*_ty`` types for an argument or return; type will be deemed by ``tblgen`` as overloaded and the; corresponding suffix will be required on the intrinsic's name. #. ``llvm/lib/Analysis/ConstantFolding.cpp``:. If it is possible to constant fold your intrinsic, add support to it in the; ``canConstantFoldCallTo`` and ``ConstantFoldCall`` functions. #. ``llvm/test/*``:. Add test cases for your test cases to the test suite. Once the intrinsic has been added to the system, you must add code generator; support for it. Generally you must do the following steps:. Add support to the .td file for the target(s) of your choice in; ``lib/Target/*/*.td``. This is usually a matter of adding a pattern to the .td file that matches the; intrinsic, though it may obviously require adding the instructions you w",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExtendingLLVM.rst:2250,optimiz,optimization,2250,interpreter/llvm-project/llvm/docs/ExtendingLLVM.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExtendingLLVM.rst,1,['optimiz'],['optimization']
Performance," an optional successor, ``continue``,; which must be the label of another basic block beginning with either a; ``cleanuppad`` or ``catchswitch`` instruction. This unwind destination must; be a legal target with respect to the ``parent`` links, as described in the; `exception handling documentation\ <ExceptionHandling.html#wineh-constraints>`_. Semantics:; """""""""""""""""""". The '``cleanupret``' instruction indicates to the; :ref:`personality function <personalityfn>` that one; :ref:`cleanuppad <i_cleanuppad>` it transferred control to has ended.; It transfers control to ``continue`` or unwinds out of the function. Example:; """""""""""""""". .. code-block:: text. cleanupret from %cleanup unwind to caller; cleanupret from %cleanup unwind label %continue. .. _i_unreachable:. '``unreachable``' Instruction; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. unreachable. Overview:; """""""""""""""""". The '``unreachable``' instruction has no defined semantics. This; instruction is used to inform the optimizer that a particular portion of; the code is not reachable. This can be used to indicate that the code; after a no-return function cannot be reached, and other facts. Semantics:; """""""""""""""""""". The '``unreachable``' instruction has no defined semantics. .. _unaryops:. Unary Operations; -----------------. Unary operators require a single operand, execute an operation on; it, and produce a single value. The operand might represent multiple; data, as is the case with the :ref:`vector <t_vector>` data type. The; result value has the same type as its operand. .. _i_fneg:. '``fneg``' Instruction; ^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. <result> = fneg [fast-math flags]* <ty> <op1> ; yields ty:result. Overview:; """""""""""""""""". The '``fneg``' instruction returns the negation of its operand. Arguments:; """""""""""""""""""". The argument to the '``fneg``' instruction must be a; :ref:`floating-point <t_floating>` or :ref:`vector <t_vector>` of; floating-point values. Semantics:; """""""""""""""""""". The value produced is",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:375194,optimiz,optimizer,375194,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['optimiz'],['optimizer']
Performance," an overloaded intrinsic. ::. declare i32 @llvm.vp.reduce.umax.v4i32(i32 <start_value>, <4 x i32> <val>, <4 x i1> <mask>, i32 <vector_length>); declare i16 @llvm.vp.reduce.umax.nxv8i16(i16 <start_value>, <vscale x 8 x i16> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated unsigned-integer ``MAX`` reduction of a vector and a scalar starting; value, returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value of the reduction, which must be a scalar; integer type equal to the result type. The second operand is the vector on; which the reduction is performed and must be a vector of integer values whose; element type is the result/start type. The third operand is the vector mask and; is a vector of boolean values with the same number of elements as the vector; operand. The fourth operand is the explicit vector length of the operation. Semantics:; """""""""""""""""""". The '``llvm.vp.reduce.umax``' intrinsic performs the unsigned-integer ``MAX``; reduction (:ref:`llvm.vector.reduce.umax <int_vector_reduce_umax>`) of the; vector operand ``val`` on each enabled lane, and taking the maximum of that and; the scalar ``start_value``. Disabled lanes are treated as containing the; neutral value ``0`` (i.e. having no effect on the reduction operation). If the; vector length is zero, the result is the start value. To ignore the start value, the neutral value can be used. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call i32 @llvm.vp.reduce.umax.v4i32(i32 %start, <4 x i32> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equal to %evl; ; are treated as though %mask were false for those lanes. %masked.a = select <4 x i1> %mask, <4 x i32> %a, <4 x i32> <i32 0, i32 0, i32 0, i32 0>; %reduction = call i32 @llvm.vector.reduce.umax.v4i32(<4 x i32> %masked.a); %also.r = call i32 @llvm.umax.i32(i32 %reduction, i32 %start). .. _int_vp_reduce_umin:. '``llvm.vp.reduce.umin.*``' Intrinsics",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:767939,perform,performs,767939,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['performs']
Performance," an overloaded intrinsic. ::. declare i32 @llvm.vp.reduce.umin.v4i32(i32 <start_value>, <4 x i32> <val>, <4 x i1> <mask>, i32 <vector_length>); declare i16 @llvm.vp.reduce.umin.nxv8i16(i16 <start_value>, <vscale x 8 x i16> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated unsigned-integer ``MIN`` reduction of a vector and a scalar starting; value, returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value of the reduction, which must be a scalar; integer type equal to the result type. The second operand is the vector on; which the reduction is performed and must be a vector of integer values whose; element type is the result/start type. The third operand is the vector mask and; is a vector of boolean values with the same number of elements as the vector; operand. The fourth operand is the explicit vector length of the operation. Semantics:; """""""""""""""""""". The '``llvm.vp.reduce.umin``' intrinsic performs the unsigned-integer ``MIN``; reduction (:ref:`llvm.vector.reduce.umin <int_vector_reduce_umin>`) of the; vector operand ``val`` on each enabled lane, taking the minimum of that and the; scalar ``start_value``. Disabled lanes are treated as containing the neutral; value ``UINT_MAX``, or ``-1`` (i.e. having no effect on the reduction; operation). If the vector length is zero, the result is the start value. To ignore the start value, the neutral value can be used. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call i32 @llvm.vp.reduce.umin.v4i32(i32 %start, <4 x i32> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equal to %evl; ; are treated as though %mask were false for those lanes. %masked.a = select <4 x i1> %mask, <4 x i32> %a, <4 x i32> <i32 -1, i32 -1, i32 -1, i32 -1>; %reduction = call i32 @llvm.vector.reduce.umin.v4i32(<4 x i32> %masked.a); %also.r = call i32 @llvm.umin.i32(i32 %reduction, i32 %start). .. _int_vp_reduce_fmax:. '``llvm.vp.reduce.fm",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:770007,perform,performs,770007,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['performs']
Performance," analyses get invalidated, and; which analyses are needed to be run for a pass. An important part of work; is that the ``PassManager`` tracks the exact lifetime of all analysis; results, allowing it to :ref:`free memory; <writing-an-llvm-pass-releaseMemory>` allocated to holding analysis results; as soon as they are no longer needed. #. **Pipeline the execution of passes on the program.** The ``PassManager``; attempts to get better cache and memory usage behavior out of a series of; passes by pipelining the passes together. This means that, given a series; of consecutive :ref:`FunctionPass <writing-an-llvm-pass-FunctionPass>`, it; will execute all of the :ref:`FunctionPass; <writing-an-llvm-pass-FunctionPass>` on the first function, then all of the; :ref:`FunctionPasses <writing-an-llvm-pass-FunctionPass>` on the second; function, etc... until the entire program has been run through the passes. This improves the cache behavior of the compiler, because it is only; touching the LLVM program representation for a single function at a time,; instead of traversing the entire program. It reduces the memory consumption; of compiler, because, for example, only one `DominatorSet; <https://llvm.org/doxygen/classllvm_1_1DominatorSet.html>`_ needs to be; calculated at a time. The effectiveness of the ``PassManager`` is influenced directly by how much; information it has about the behaviors of the passes it is scheduling. For; example, the ""preserved"" set is intentionally conservative in the face of an; unimplemented :ref:`getAnalysisUsage <writing-an-llvm-pass-getAnalysisUsage>`; method. Not implementing when it should be implemented will have the effect of; not allowing any analysis results to live across the execution of your pass. The ``PassManager`` class exposes a ``--debug-pass`` command line options that; is useful for debugging pass execution, seeing how things work, and diagnosing; when you should be preserving more analyses than you currently are. (To get; information a",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:42313,cache,cache,42313,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,1,['cache'],['cache']
Performance," and earlier, HLSL supported logical operators (and the ternary; operator) on vector types. This behavior required that operators not short; circuit. The non-short circuiting behavior applies to all data types until HLSL; 2021. In HLSL 2021, logical and ternary operators do not support vector types; instead builtin functions ``and``, ``or`` and ``select`` are available, and; operators short circuit matching C behavior. Precise Qualifier; -----------------. HLSL has a ``precise`` qualifier that behaves unlike anything else in the C; language. The support for this qualifier in DXC is buggy, so our bar for; compatibility is low. The ``precise`` qualifier applies in the inverse direction from normal; qualifiers. Rather than signifying that the declaration containing ``precise``; qualifier be precise, it signifies that the operations contributing to the; declaration's value be ``precise``. Additionally, ``precise`` is a misnomer:; values attributed as ``precise`` comply with IEEE-754 floating point semantics,; and are prevented from optimizations which could decrease *or increase*; precision. Differences in Templates; ------------------------. HLSL uses templates to define builtin types and methods, but disallowed; user-defined templates until HLSL 2021. HLSL also allows omitting empty template; parameter lists when all template parameters are defaulted. This is an ambiguous; syntax in C++, but Clang detects the case and issues a diagnostic. This makes; supporting the case in Clang minimally invasive. Vector Extensions; -----------------. HLSL uses the OpenCL vector extensions, and also provides C++-style constructors; for vectors that are not supported by Clang. Standard Library; ----------------. HLSL does not support the C or C++ standard libraries. Like OpenCL, HLSL; describes its own library of built in types, complex data types, and functions. Unsupported C & C++ Features; ----------------------------. HLSL does not support all features of C and C++. In implementing",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/HLSL/HLSLSupport.rst:8619,optimiz,optimizations,8619,interpreter/llvm-project/clang/docs/HLSL/HLSLSupport.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/HLSL/HLSLSupport.rst,1,['optimiz'],['optimizations']
Performance," and estimate.; ; Macros plot various deviation and correlation quantities.; A new GUI (macros/TMVARegGui.C) collects these macros.; . Improvements of / new features for MVA methods . Linear Discriminant:; Re-implementation of ""Fisher"" method as general linear discriminant (""LD""),; which is also regression capable (so far: single-target only). PDEFoam:; PDE-Foam is a variation of the PDE-RS method using a self-adapting binning; method to divide the multi-dimensional variable space into a finite number; of hyper-rectangles (cells). The binning algorithm adjusts the size and; position of a predefined number of cells such that the variance of the; signal and background densities inside the cells reaches a minimum. BDT:; Introduced gradient boosting and stochastic gradient boosting for ; classification with BDT (as desribed by Friedman 1999). See ""BDTG"" ; example in TMVAClassification.C/cxx. A new option allows to restrict the maximum tree depth. This may be used to; avoid overtraining and often gives better performance than pruning. (The; pruning mechanism needs to be revisited). MLP:; Introduced recognition of convergence via general ConvergenceTest-class for; interrupting computations when convergence is reached. This feature has is; used now in MethodMLP. Improved treatment of event-weights in BFGS training. Implemented random and importance sampling of events in DataSet. Implemented; the usage of this feature for MLP.; ; TMlpANN (interface to TMultiLayerPerceptron) now also uses event weights; and writes standalone C++ class. k-NN:; A new global knn search function has been added to NodekNN that searches for; k-nearest neighbor using event weights instead of raw event counts. ModulekNN; has been modified to allow searches using ""weight"" or ""count"" option, where; ""count"" is default. Added UseWeight option to MethodKNN to allow using of; ""weight"" or ""count"". ; (Work by Rustem Ospanov, CERN). . Likelihood (and general PDF treatment):; Adaptive smoothing the PDF class, ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v524/index.html:3041,perform,performance,3041,tmva/doc/v524/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v524/index.html,2,['perform'],['performance']
Performance," and heap allocations can never alias.; * Globals, stack allocations, and heap allocations never alias the null pointer.; * Different fields of a structure do not alias.; * Indexes into arrays with statically differing subscripts cannot alias.; * Many common standard C library functions `never access memory or only read; memory`_.; * Pointers that obviously point to constant globals ""``pointToConstantMemory``"".; * Function calls can not modify or references stack allocations if they never; escape from the function that allocates them (a common case for automatic; arrays). The ``-globalsmodref-aa`` pass; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. This pass implements a simple context-sensitive mod/ref and alias analysis for; internal global variables that don't ""have their address taken"". If a global; does not have its address taken, the pass knows that no pointers alias the; global. This pass also keeps track of functions that it knows never access; memory or never read memory. This allows certain optimizations (e.g. GVN) to; eliminate call instructions entirely. The real power of this pass is that it provides context-sensitive mod/ref; information for call instructions. This allows the optimizer to know that calls; to a function do not clobber or read the value of the global, allowing loads and; stores to be eliminated. .. note::. This pass is somewhat limited in its scope (only support non-address taken; globals), but is very quick analysis. The ``-steens-aa`` pass; ^^^^^^^^^^^^^^^^^^^^^^^. The ``-steens-aa`` pass implements a variation on the well-known ""Steensgaard's; algorithm"" for interprocedural alias analysis. Steensgaard's algorithm is a; unification-based, flow-insensitive, context-insensitive, and field-insensitive; alias analysis that is also very scalable (effectively linear time). The LLVM ``-steens-aa`` pass implements a ""speculatively field-**sensitive**""; version of Steensgaard's algorithm using the Data Structure Analysis framework.; This gives it substantial",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AliasAnalysis.rst:24923,optimiz,optimizations,24923,interpreter/llvm-project/llvm/docs/AliasAnalysis.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AliasAnalysis.rst,1,['optimiz'],['optimizations']
Performance," and instructions have lists of types.; That had two flaws: the type and size are redundant, and there was no generic; way of getting a given operand's type (as there was no 1:1 mapping between; instruction types and operands).; We considered putting the type in some variant of MCInstrDesc instead:; See `PR26576 <https://llvm.org/PR26576>`_: [GlobalISel] Generic MachineInstrs; need a type but this increases the memory footprint of the related objects. .. _gmir-regbank:. Register Bank; -------------. A Register Bank is a set of register classes defined by the target. This; definition is rather loose so let's talk about what they can achieve. Suppose we have a processor that has two register files, A and B. These are; equal in every way and support the same instructions for the same cost. They're; just physically stored apart and each instruction can only access registers from; A or B but never a mix of the two. If we want to perform an operation on data; that's in split between the two register files, we must first copy all the data; into a single register file. Given a processor like this, we would benefit from clustering related data; together into one register file so that we minimize the cost of copying data; back and forth to satisfy the (possibly conflicting) requirements of all the; instructions. Register Banks are a means to constrain the register allocator to; use a particular register file for a virtual register. In practice, register files A and B are rarely equal. They can typically store; the same data but there's usually some restrictions on what operations you can; do on each register file. A fairly common pattern is for one of them to be; accessible to integer operations and the other accessible to floating point; operations. To accommodate this, let's rename A and B to GPR (general purpose; registers) and FPR (floating point registers). We now have some additional constraints that limit us. An operation like G_FMUL; has to happen in FPR and G_ADD has",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GMIR.rst:3821,perform,perform,3821,interpreter/llvm-project/llvm/docs/GlobalISel/GMIR.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GMIR.rst,1,['perform'],['perform']
Performance," and it will take longer to generate, but it provides the most; opportunity for the compiler to optimize. The guidance for minimizing distribution size is to dynamically link LLVM and; Clang libraries into the tools to reduce code duplication. This will come at a; substantial performance penalty to the generated binary both because it reduces; optimization opportunity, and because dynamic linking requires resolving symbols; at process launch time, which can be very slow for C++ code. .. _shared_libs:. .. warning::; One very important note: Distributions should never be built using the; *BUILD_SHARED_LIBS* CMake option. That option exists for optimizing developer; workflow only. Due to design and implementation decisions, LLVM relies on; global data which can end up being duplicated across shared libraries; resulting in bugs. As such this is not a safe way to distribute LLVM or; LLVM-based tools. The simplest example of building a distribution with reasonable performance is; captured in the DistributionExample CMake cache file located at; clang/cmake/caches/DistributionExample.cmake. The following command will perform; and install the distribution build:. .. code-block:: console. $ cmake -G Ninja -C <path to clang>/cmake/caches/DistributionExample.cmake <path to LLVM source>; $ ninja stage2-distribution; $ ninja stage2-install-distribution. Difference between ``install`` and ``install-distribution``; -----------------------------------------------------------. One subtle but important thing to note is the difference between the ``install``; and ``install-distribution`` targets. The ``install`` target is expected to; install every part of LLVM that your build is configured to generate except the; LLVM testing tools. Alternatively the ``install-distribution`` target, which is; recommended for building distributions, only installs specific parts of LLVM as; specified at configuration time by *LLVM_DISTRIBUTION_COMPONENTS*. Additionally by default the ``install`` target w",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst:2554,perform,performance,2554,interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,3,"['cache', 'perform']","['cache', 'caches', 'performance']"
Performance," and return value are floating-point numbers of the same type. Semantics:; """""""""""""""""""". Return the same value as a corresponding libm '``exp10``' function but without; trapping or setting ``errno``. When specified with the fast-math-flag 'afn', the result may be approximated; using a less accurate calculation. '``llvm.ldexp.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". This is an overloaded intrinsic. You can use ``llvm.ldexp`` on any; floating point or vector of floating point type. Not all targets support; all types however. ::. declare float @llvm.ldexp.f32.i32(float %Val, i32 %Exp); declare double @llvm.ldexp.f64.i32(double %Val, i32 %Exp); declare x86_fp80 @llvm.ldexp.f80.i32(x86_fp80 %Val, i32 %Exp); declare fp128 @llvm.ldexp.f128.i32(fp128 %Val, i32 %Exp); declare ppc_fp128 @llvm.ldexp.ppcf128.i32(ppc_fp128 %Val, i32 %Exp); declare <2 x float> @llvm.ldexp.v2f32.v2i32(<2 x float> %Val, <2 x i32> %Exp). Overview:; """""""""""""""""". The '``llvm.ldexp.*``' intrinsics perform the ldexp function. Arguments:; """""""""""""""""""". The first argument and the return value are :ref:`floating-point; <t_floating>` or :ref:`vector <t_vector>` of floating-point values of; the same type. The second argument is an integer with the same number; of elements. Semantics:; """""""""""""""""""". This function multiplies the first argument by 2 raised to the second; argument's power. If the first argument is NaN or infinite, the same; value is returned. If the result underflows a zero with the same sign; is returned. If the result overflows, the result is an infinity with; the same sign. .. _int_frexp:. '``llvm.frexp.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". This is an overloaded intrinsic. You can use ``llvm.frexp`` on any; floating point or vector of floating point type. Not all targets support; all types however. ::. declare { float, i32 } @llvm.frexp.f32.i32(float %Val); declare { double, i32 } @llvm.frexp.f64.i32(double %Val); declare { x86_fp80, i32 } @llvm.frexp.f",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:565143,perform,perform,565143,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['perform']
Performance," and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/load atomic; atomicrmw-with-return-value.; - s_waitcnt vscnt(0); must happen after; any preceding; global/generic; store/store atomic/; atomicrmw-no-return-value.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; have; completed before; performing the; atomicrmw that is; being released. 2. flat_atomic; 3. s_waitcnt vm/vscnt(0) &; lgkmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Use vmcnt(0) if atomic with; return and vscnt(0) if; atomic with no-return.; - Must happen before; following; buffer_gl*_inv.; - Ensures the; atomicrmw has; completed before; invalidating the; caches. 4. buffer_gl0_inv;; buffer_gl1_inv. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. fence acq_rel - singlethread *none* *none*; - wavefront; fence acq_rel - workgroup *none* 1. s_waitcnt lgkmcnt(0) &; vmcnt(0) & vscnt(0). - If CU wavefront execution; mode, omit vmcnt(0) and; vscnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - If OpenCL and; address space is; local, omit; vmcnt(0) and vscnt(0).; - However,; since LLVM; currently has no; address space on; the fence need to; conservatively; always generate; (see comment for; previous fence).; - Could be split into; separate s_waitcnt; vmcnt(0), s_waitcnt; vscnt(0) and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/load; atomic/; atomicrmw-with-return-value.; - s_waitcnt vscnt(0); must happen after; any preceding; global/generic; store/store atomic/; atomicrm",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:369339,load,load,369339,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],['load']
Performance," and the ``zext`` argument is negative, the result; is a poison value. Example:; """""""""""""""". .. code-block:: llvm. %X = zext i32 257 to i64 ; yields i64:257; %Y = zext i1 true to i32 ; yields i32:1; %Z = zext <2 x i16> <i16 8, i16 7> to <2 x i32> ; yields <i32 8, i32 7>. %a = zext nneg i8 127 to i16 ; yields i16 127; %b = zext nneg i8 -1 to i16 ; yields i16 poison. .. _i_sext:. '``sext .. to``' Instruction; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. <result> = sext <ty> <value> to <ty2> ; yields ty2. Overview:; """""""""""""""""". The '``sext``' sign extends ``value`` to the type ``ty2``. Arguments:; """""""""""""""""""". The '``sext``' instruction takes a value to cast, and a type to cast it; to. Both types must be of :ref:`integer <t_integer>` types, or vectors of; the same number of integers. The bit size of the ``value`` must be; smaller than the bit size of the destination type, ``ty2``. Semantics:; """""""""""""""""""". The '``sext``' instruction performs a sign extension by copying the sign; bit (highest order bit) of the ``value`` until it reaches the bit size; of the type ``ty2``. When sign extending from i1, the extension always results in -1 or 0. Example:; """""""""""""""". .. code-block:: llvm. %X = sext i8 -1 to i16 ; yields i16 :65535; %Y = sext i1 true to i32 ; yields i32:-1; %Z = sext <2 x i16> <i16 8, i16 7> to <2 x i32> ; yields <i32 8, i32 7>. '``fptrunc .. to``' Instruction; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. <result> = fptrunc <ty> <value> to <ty2> ; yields ty2. Overview:; """""""""""""""""". The '``fptrunc``' instruction truncates ``value`` to type ``ty2``. Arguments:; """""""""""""""""""". The '``fptrunc``' instruction takes a :ref:`floating-point <t_floating>`; value to cast and a :ref:`floating-point <t_floating>` type to cast it to.; The size of ``value`` must be larger than the size of ``ty2``. This; implies that ``fptrunc`` cannot be used to make a *no-op cast*. Semantics:; """""""""""""""""""". The '``fptrunc``' instruction casts a ``value`` from a larger; :ref:`floating-poin",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:445067,perform,performs,445067,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['performs']
Performance," and to; support compiler-rt as the reference implementation. Allocator Support; -----------------. GWP-ASan is not a replacement for a traditional allocator. Instead, it works by; inserting stubs into a supporting allocator to redirect allocations to GWP-ASan; when they're chosen to be sampled. These stubs are generally implemented in the; implementation of ``malloc()``, ``free()`` and ``realloc()``. The stubs are; extremely small, which makes using GWP-ASan in most allocators fairly trivial.; The stubs follow the same general pattern (example ``malloc()`` pseudocode; below):. .. code:: cpp. #ifdef INSTALL_GWP_ASAN_STUBS; gwp_asan::GuardedPoolAllocator GWPASanAllocator;; #endif. void* YourAllocator::malloc(..) {; #ifdef INSTALL_GWP_ASAN_STUBS; if (GWPASanAllocator.shouldSample(..)); return GWPASanAllocator.allocate(..);; #endif. // ... the rest of your allocator code here.; }. Then, all the supporting allocator needs to do is compile with; ``-DINSTALL_GWP_ASAN_STUBS`` and link against the GWP-ASan library! For; performance reasons, we strongly recommend static linkage of the GWP-ASan; library. Guarded Allocation Pool; -----------------------. The core of GWP-ASan is the guarded allocation pool. Each sampled allocation is; backed using its own *guarded* slot, which may consist of one or more accessible; pages. Each guarded slot is surrounded by two *guard* pages, which are mapped as; inaccessible. The collection of all guarded slots makes up the *guarded; allocation pool*. Buffer Underflow/Overflow Detection; -----------------------------------. We gain buffer-overflow and buffer-underflow detection through these guard; pages. When a memory access overruns the allocated buffer, it will touch the; inaccessible guard page, causing memory exception. This exception is caught and; handled by the internal crash handler. Because each allocation is recorded with; metadata about where (and by what thread) it was allocated and deallocated, we; can provide information that will",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GwpAsan.rst:3053,perform,performance,3053,interpreter/llvm-project/llvm/docs/GwpAsan.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GwpAsan.rst,1,['perform'],['performance']
Performance," and; completion is reported to a wavefront in execution order. The exception is; that for GFX7-GFX9 ``flat_load/store/atomic`` instructions can report out of; vector memory order if they access LDS memory, and out of LDS operation order; if they access global memory.; * The vector memory operations access a single vector L1 cache shared by all; SIMDs a CU. Therefore, no special action is required for coherence between the; lanes of a single wavefront, or for coherence between wavefronts in the same; work-group. A ``buffer_wbinvl1_vol`` is required for coherence between; wavefronts executing in different work-groups as they may be executing on; different CUs.; * The scalar memory operations access a scalar L1 cache shared by all wavefronts; on a group of CUs. The scalar and vector L1 caches are not coherent. However,; scalar operations are used in a restricted way so do not impact the memory; model. See :ref:`amdgpu-amdhsa-memory-spaces`.; * The vector and scalar memory operations use an L2 cache shared by all CUs on; the same agent.; * The L2 cache has independent channels to service disjoint ranges of virtual; addresses.; * Each CU has a separate request queue per channel. Therefore, the vector and; scalar memory operations performed by wavefronts executing in different; work-groups (which may be executing on different CUs) of an agent can be; reordered relative to each other. A ``s_waitcnt vmcnt(0)`` is required to; ensure synchronization between vector memory operations of different CUs. It; ensures a previous vector memory operation has completed before executing a; subsequent vector memory or LDS operation and so can be used to meet the; requirements of acquire and release.; * The L2 cache can be kept coherent with other agents on some targets, or ranges; of virtual addresses can be set up to bypass it to ensure system coherence. Scalar memory operations are only used to access memory that is proven to not; change during the execution of the kernel dispatch. Th",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:208424,cache,cache,208424,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['cache'],['cache']
Performance," and; size of the memory access. Currently, the following sequence is used:. .. code-block:: none. // int foo(int *a) { return *a; }; // clang -O2 --target=aarch64-linux-android30 -fsanitize=hwaddress -S -o - load.c; [...]; foo:; stp x30, x20, [sp, #-16]!; adrp x20, :got:__hwasan_shadow // load shadow address from GOT into x20; ldr x20, [x20, :got_lo12:__hwasan_shadow]; bl __hwasan_check_x0_2_short_v2 // call outlined tag check; // (arguments: x0 = address, x20 = shadow base;; // ""2"" encodes the access type and size); ldr w0, [x0] // inline load; ldp x30, x20, [sp], #16; ret. [...]; __hwasan_check_x0_2_short_v2:; sbfx x16, x0, #4, #52 // shadow offset; ldrb w16, [x20, x16] // load shadow tag; cmp x16, x0, lsr #56 // extract address tag, compare with shadow tag; b.ne .Ltmp0 // jump to short tag handler on mismatch; .Ltmp1:; ret; .Ltmp0:; cmp w16, #15 // is this a short tag?; b.hi .Ltmp2 // if not, error; and x17, x0, #0xf // find the address's position in the short granule; add x17, x17, #3 // adjust to the position of the last byte loaded; cmp w16, w17 // check that position is in bounds; b.ls .Ltmp2 // if not, error; orr x16, x0, #0xf // compute address of last byte of granule; ldrb w16, [x16] // load tag from it; cmp x16, x0, lsr #56 // compare with pointer tag; b.eq .Ltmp1 // if matches, continue; .Ltmp2:; stp x0, x1, [sp, #-256]! // save original x0, x1 on stack (they will be overwritten); stp x29, x30, [sp, #232] // create frame record; mov x1, #2 // set x1 to a constant indicating the type of failure; adrp x16, :got:__hwasan_tag_mismatch_v2 // call runtime function to save remaining registers and report error; ldr x16, [x16, :got_lo12:__hwasan_tag_mismatch_v2] // (load address from GOT to avoid potential register clobbers in delay load handler); br x16. Heap; ----. Tagging the heap memory/pointers is done by `malloc`.; This can be based on any malloc that forces all objects to be TG-aligned.; `free` tags the memory with a different tag. Stack; -----. Stack fram",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/HardwareAssistedAddressSanitizerDesign.rst:4610,load,loaded,4610,interpreter/llvm-project/clang/docs/HardwareAssistedAddressSanitizerDesign.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/HardwareAssistedAddressSanitizerDesign.rst,1,['load'],['loaded']
Performance," any new; inputs found by one fuzzer process will be available to the other fuzzer; processes (unless you disable this with the ``-reload=0`` option). This is primarily controlled by the ``-jobs=N`` option, which indicates that; that `N` fuzzing jobs should be run to completion (i.e. until a bug is found or; time/iteration limits are reached). These jobs will be run across a set of; worker processes, by default using half of the available CPU cores; the count of; worker processes can be overridden by the ``-workers=N`` option. For example,; running with ``-jobs=30`` on a 12-core machine would run 6 workers by default,; with each worker averaging 5 bugs by completion of the entire process. Fork mode; ---------. **Experimental** mode ``-fork=N`` (where ``N`` is the number of parallel jobs); enables oom-, timeout-, and crash-resistant; fuzzing with separate processes (using ``fork-exec``, not just ``fork``). The top libFuzzer process will not do any fuzzing itself, but will; spawn up to ``N`` concurrent child processes providing them; small random subsets of the corpus. After a child exits, the top process; merges the corpus generated by the child back to the main corpus. Related flags:. ``-ignore_ooms``; True by default. If an OOM happens during fuzzing in one of the child processes,; the reproducer is saved on disk, and fuzzing continues.; ``-ignore_timeouts``; True by default, same as ``-ignore_ooms``, but for timeouts.; ``-ignore_crashes``; False by default, same as ``-ignore_ooms``, but for all other crashes. The plan is to eventually replace ``-jobs=N`` and ``-workers=N`` with ``-fork=N``. Resuming merge; --------------. Merging large corpora may be time consuming, and it is often desirable to do it; on preemptable VMs, where the process may be killed at any time.; In order to seamlessly resume the merge, use the ``-merge_control_file`` flag; and use ``killall -SIGUSR1 /path/to/fuzzer/binary`` to stop the merge gracefully. Example:. .. code-block:: console. % rm -",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LibFuzzer.rst:7679,concurren,concurrent,7679,interpreter/llvm-project/llvm/docs/LibFuzzer.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LibFuzzer.rst,1,['concurren'],['concurrent']
Performance," application. .. option:: -miphoneos-version-min. When building for iPhone OS, specify the minimum version supported by your; application. .. option:: --print-supported-cpus. Print out a list of supported processors for the given target (specified; through ``--target=<architecture>`` or :option:`-arch` ``<architecture>``). If no; target is specified, the system default target will be used. .. option:: -mcpu=?, -mtune=?. Acts as an alias for :option:`--print-supported-cpus`. .. option:: -mcpu=help, -mtune=help. Acts as an alias for :option:`--print-supported-cpus`. .. option:: -march=<cpu>. Specify that Clang should generate code for a specific processor family; member and later. For example, if you specify -march=i486, the compiler is; allowed to generate instructions that are valid on i486 and later processors,; but which may not exist on earlier ones. Code Generation Options; ~~~~~~~~~~~~~~~~~~~~~~~. .. option:: -O0, -O1, -O2, -O3, -Ofast, -Os, -Oz, -Og, -O, -O4. Specify which optimization level to use:. :option:`-O0` Means ""no optimization"": this level compiles the fastest and; generates the most debuggable code. :option:`-O1` Somewhere between :option:`-O0` and :option:`-O2`. :option:`-O2` Moderate level of optimization which enables most; optimizations. :option:`-O3` Like :option:`-O2`, except that it enables optimizations that; take longer to perform or that may generate larger code (in an attempt to; make the program run faster). :option:`-Ofast` Enables all the optimizations from :option:`-O3` along; with other aggressive optimizations that may violate strict compliance with; language standards. :option:`-Os` Like :option:`-O2` with extra optimizations to reduce code; size. :option:`-Oz` Like :option:`-Os` (and thus :option:`-O2`), but reduces code; size further. :option:`-Og` Like :option:`-O1`. In future versions, this option might; disable different optimizations in order to improve debuggability. :option:`-O` Equivalent to :option:`-O1`. :option:`-O4` an",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/CommandGuide/clang.rst:10482,optimiz,optimization,10482,interpreter/llvm-project/clang/docs/CommandGuide/clang.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/CommandGuide/clang.rst,1,['optimiz'],['optimization']
Performance," apply button is; pressed, the changes are applied to the edited shape and drawn. The; ""*Undo*"" button becomes active after the first modification has been; applied. It allows restoring the initial parameters of the shape. NOTE: In this version the ""*Undo*"" does not allow restoring an; intermediate state of the parameters that was applied - it will always; restore the parameters at the moment the shape was edited. All material properties changes are undoable. The mixture editor; currently allows adding elements one by one in the mixture composition.; This can be done either by element weight fraction or by number of; atoms. Once an element was added using one method the other method is not; selectable anymore. Summing component fractions up to 1 in the final; mixture is the user responsibility. Adding materials as components of a; mixture is not supported in this version. The elements that were added to the mixture appear in the bottom of the; mixture editor. The operations performed on mixture are not undoable. ### Creation of New Objects. As described above, all geometry object creators are accessible within; the geometry manager editor frame. Generally, if the new object that; needs to be created does not depend on other objects, it will be built; with a set of default parameters. This is the case for all shapes; (except composite shapes) and matrices. For all the other objects the; interface forces the selection of components before creating the object. ### Editing Volumes. Volumes are hierarchical components in the geometry, therefore their; editor is more complex. It provides the following functionalities:. - *General*. This category allows changing the name of the volume and; selecting other shape or medium among existing ones. - *Daughters*. The category allows removing existing daughter nodes or; adding new ones. The button ""*Position*"" allows editing the; positioning matrix of a given node. ![Setting volume properties and modifying volume hierarchy](pictur",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md:171722,perform,performed,171722,documentation/users-guide/Geometry.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md,1,['perform'],['performed']
Performance," are currently reserved for user-defined code. The GS-segment is; represented by address space 256, the FS-segment is represented by address space; 257, and the SS-segment is represented by address space 258. Other x86 segments; have yet to be allocated address space numbers. While these address spaces may seem similar to TLS via the ``thread_local``; keyword, and often use the same underlying hardware, there are some fundamental; differences. The ``thread_local`` keyword applies to global variables and specifies that they; are to be allocated in thread-local memory. There are no type qualifiers; involved, and these variables can be pointed to with normal pointers and; accessed with normal loads and stores. The ``thread_local`` keyword is; target-independent at the LLVM IR level (though LLVM doesn't yet have; implementations of it for some configurations). Special address spaces, in contrast, apply to static types. Every load and store; has a particular address space in its address operand type, and this is what; determines which address space is accessed. LLVM ignores these special address; space qualifiers on global variables, and does not provide a way to directly; allocate storage in them. At the LLVM IR level, the behavior of these special; address spaces depends in part on the underlying OS or runtime environment, and; they are specific to x86 (and LLVM doesn't yet handle them correctly in some; cases). Some operating systems and runtime environments use (or may in the future use); the FS/GS-segment registers for various low-level purposes, so care should be; taken when considering them. Instruction naming; ^^^^^^^^^^^^^^^^^^. An instruction name consists of the base name, a default operand size, and a; character per operand with an optional special size. For example:. ::. ADD8rr -> add, 8-bit register, 8-bit register; IMUL16rmi -> imul, 16-bit register, 16-bit memory, 16-bit immediate; IMUL16rmi8 -> imul, 16-bit register, 16-bit memory, 8-bit immediate; MOVSX",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:93068,load,load,93068,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst,1,['load'],['load']
Performance," are ignored in the training (but are included for testing and performance evaluation). nkNN No 20 − Number of k-nearest neighbors. BalanceDepth No 6 − Binary tree balance depth. ScaleFrac No 0.8 − Fraction of events used to compute variable width. SigmaFact No 1 − Scale factor for sigma in Gaussian kernel. Kernel No Gaus − Use polynomial (=Poln) or Gaussian (=Gaus) kernel. Trim No False − Use equal number of signal and background events. UseKernel No False − Use polynomial kernel weight. UseWeight No True − Use weight to count kNN events. UseLDA No False − Use local linear discriminant - experimental feature. Configuration options for MVA method :. Configuration options reference for MVA method: BDT. Option Array Default value Predefined values Description. V No False − Verbose output (short form of VerbosityLevel below - overrides the latter one). VerbosityLevel No Default Default, Debug, Verbose, Info, Warning, Error, Fatal Verbosity level. VarTransform No None − List of variable transformations performed before training, e.g., D_Background,P_Signal,G,N_AllClasses for: Decorrelation, PCA-transformation, Gaussianisation, Normalisation, each for the given class of events ('AllClasses' denotes all events of all classes, if no class indication is given, 'All' is assumed). H No False − Print method-specific help message. CreateMVAPdfs No False − Create PDFs for classifier outputs (signal and background). IgnoreNegWeightsInTraining No False − Events with negative weights are ignored in the training (but are included for testing and performance evaluation). NTrees No 800 − Number of trees in the forest. MaxDepth No 3 − Max depth of the decision tree allowed. MinNodeSize No 5% − Minimum percentage of training events required in a leaf node (default: Classification: 5%, Regression: 0.2%). nCuts No 20 − Number of grid points in variable range used in finding optimal cut in node splitting. BoostType No AdaBoost AdaBoost, RealAdaBoost, Bagging, AdaBoostR2, Grad Boosting type",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/tmva/UsersGuide/optionRef.html:11303,perform,performed,11303,documentation/tmva/UsersGuide/optionRef.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/tmva/UsersGuide/optionRef.html,2,['perform'],['performed']
Performance," are invisible since the current track has not yet reached; its mother. This is not the case when going the other way since the; track has first to exit the extruding node before checking the mother.; In other words, an extrusion behavior is dependent on the track; parameters, which is a highly undesirable effect. B) We will call ***`overlaps`*** only the regions in space contained by; more than one node inside the same container. The owner of such regions; cannot be determined based on hierarchical considerations; therefore; they will be considered as belonging to the node from which the current; track is coming from. When coming from their container, the ownership is totally; unpredictable. Again, the ownership of overlapping regions highly; depends on the current track parameters. We must say that even the overlaps of type A) and B) are allowed in case; the corresponding nodes are created using; **`TGeoVolume`**`::AddNodeOverlap()` method. Navigation is performed in such; cases by giving priority to the non-overlapping nodes. The modeller has; to perform an additional search through the overlapping candidates.; These are detected automatically during the geometry closing procedure; in order to optimize the algorithm, but we will stress that extensive; usage of this feature leads to a drastic deterioration of performance.; In the following we will focus on the non-declared overlaps of type A); and B) since this is the main source of errors during tracking. These; are generally non-intended overlaps due to coding mistakes or bad; geometry design. The checking package is loaded together with the; painter classes and contains an automated overlap checker.**. ![Overlap checking](pictures/030001DF.png). This can be activated both at volume level (checking for illegal; overlaps only one level inside a given volume) and from the geometry; manager level (checking full geometry):. ``` {.cpp}; myVolume->CheckOverlaps(precision, option);; gGeoManager->CheckOverlaps(precision",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md:131650,perform,performed,131650,documentation/users-guide/Geometry.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md,1,['perform'],['performed']
Performance," are loaded also. The dependent; libraries are shown in the ROOT reference guide's library dependency; graph. The difference between reference guide `libHist` and; `libHistPainter` is that the former needs to be explicitly linked and; the latter will be loaded automatically at runtime when ROOT needs it,; by means of the Plugin Manager. plugin manager. In the Figure 1-2, the libraries represented by green boxes outside of; the core are loaded via the plugin manager plugin manager or; equivalent techniques, while the white ones are not. Of course, if one; wants to access a plugin library directly, it has to be explicitly; linked. An example of a plugin library is `libMinuit`. To create and; fill histograms you need to link `libHist.so`. If the code has a call; to fit the histogram, the ""fitter"" will dynamically load libMinuit if; it is not yet loaded. #### Plugins: Runtime Library Dependencies for Linking. plugin manager The Plugin Manager **`TPluginManager`** allows; postponing library dependencies to runtime: a plugin library will only; be loaded when it is needed. Non-plugins will need to be linked, and; are thus loaded at start-up. Plugins are defined by a base class (e.g.; **`TFile`**) that will be implemented in a plugin, a tag used to; identify the plugin (e.g. `^rfio:` as part of the protocol string),; the plugin class of which an object will be created; (e.g. **`TRFIOFile`**), the library to be loaded (in short; `libRFIO.so` to RFIO), and the constructor to be called (e.g.; ""`TRFIOFile()`""). This can be specified in the `.rootrc` which already; contains many plugin definitions, or by calls to; `gROOT->GetPluginManager()->AddHandler()`. #### Library AutoLoading. When using a class in Cling, e.g. in an interpreted source file, ROOT; will automatically load the library that defines this class. On; start-up, ROOT parses all files ending on `.rootmap` rootmap that are; in one of the `$LD_LIBRARY_PATH` (or `$DYLD_LIBRARY_PATH` for `MacOS`,; or `$PATH` for `Windows",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Introduction.md:19112,load,loaded,19112,documentation/users-guide/Introduction.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Introduction.md,1,['load'],['loaded']
Performance," are not the same enable the schema evolution support (in case ROOT; objects; are transferred). . XROOTD. New version 20080621-0000 containing several improvements and fixes; Server:. New daemon 'cmsd' supposed to replace 'olbd' with improved performances; Improved polling strategy; Fix problem with handling writev creating unjustified disconnections ; Fix problem with setrlimit on MacOsX Leopard. Client:; ; Fix a nasty memory leak in XrdClientCacheRead affecting; processing via TChain; Optimized file closing recipe; Fix; potential cache thrashing problem with big blocks requests. Fixes / improvements in the GSI plug-in:; ; support for large (> 32 bits) certificate serial; numbers in CRL handling; support for an external function for DN-to-username; mapping function; provide example for an LDAP based search; fixed a few problem with return code checking. netx. TXNetFile:; . Enable dynamic cache size synchronization; ; Enable per-instance control of the cache parameters; also for RAW files; by; default cache is OFF for these files, but there maybe cases in which the cache can; improve performances.; Remove call to XrdClient::Sync in SysStat. Correctly honor the create/recreate options coming from TFile::Open(); Allow the size of the (written) file to be retrieved after the Close (solves several reported file size mismatches).; . TXNetSystem:; ; Fix problem with GetDirEntry: the entry object was; going out-of-scope so; that the returned string was meaningless.; Reset; the list if dir entries in FreeDirectory.; Fix problem affecting repeated calls. The implementation of TFile throughput and info sending was; just sending 'regular' samples about the activity of the single TFile; instance that happened to trigger an activity in the right moment.; Now TMonaLisaWriter keeps internally track of every; activity; and regularly sends summaries valid for all the files which had; activity in the last time interval.; Additionally, it's now finalized the infrastructure able to; me",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/net/doc/v520/index.html:1467,cache,cache,1467,net/doc/v520/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/net/doc/v520/index.html,10,"['cache', 'perform']","['cache', 'performances']"
Performance," are represented in memory and in registers. First, a recap. The ""endianness"" of an item affects its representation in memory only. In a register, a number is just a sequence of bits - 64 bits in the case of AArch64 general purpose registers. Memory, however, is a sequence of addressable units of 8 bits in size. Any number greater than 8 bits must therefore be split up into 8-bit chunks, and endianness describes the order in which these chunks are laid out in memory. A ""little endian"" layout has the least significant byte first (lowest in memory address). A ""big endian"" layout has the *most* significant byte first. This means that when loading an item from big endian memory, the lowest 8-bits in memory must go in the most significant 8-bits, and so forth. ``LDR`` and ``LD1``; ===================. .. figure:: ARM-BE-ldr.png; :align: right. Big endian vector load using ``LDR``. A vector is a consecutive sequence of items that are operated on simultaneously. To load a 64-bit vector, 64 bits need to be read from memory. In little endian mode, we can do this by just performing a 64-bit load - ``LDR q0, [foo]``. However if we try this in big endian mode, because of the byte swapping the lane indices end up being swapped! The zero'th item as laid out in memory becomes the n'th lane in the vector. .. figure:: ARM-BE-ld1.png; :align: right. Big endian vector load using ``LD1``. Note that the lanes retain the correct ordering. Because of this, the instruction ``LD1`` performs a vector load but performs byte swapping not on the entire 64 bits, but on the individual items within the vector. This means that the register content is the same as it would have been on a little endian system. It may seem that ``LD1`` should suffice to perform vector loads on a big endian machine. However there are pros and cons to the two approaches that make it less than simple which register format to pick. There are two options:. 1. The content of a vector register is the same *as if* it had been ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BigEndianNEON.rst:2787,load,load,2787,interpreter/llvm-project/llvm/docs/BigEndianNEON.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BigEndianNEON.rst,1,['load'],['load']
Performance," are subregisters of this class; list<RegisterClass> SubRegClassList = [];. code MethodProtos = [{}]; // to insert arbitrary code; code MethodBodies = [{}];; }. To define a ``RegisterClass``, use the following 4 arguments:. * The first argument of the definition is the name of the namespace. * The second argument is a list of ``ValueType`` register type values that are; defined in ``include/llvm/CodeGen/ValueTypes.td``. Defined values include; integer types (such as ``i16``, ``i32``, and ``i1`` for Boolean),; floating-point types (``f32``, ``f64``), and vector types (for example,; ``v8i16`` for an ``8 x i16`` vector). All registers in a ``RegisterClass``; must have the same ``ValueType``, but some registers may store vector data in; different configurations. For example a register that can process a 128-bit; vector may be able to handle 16 8-bit integer elements, 8 16-bit integers, 4; 32-bit integers, and so on. * The third argument of the ``RegisterClass`` definition specifies the; alignment required of the registers when they are stored or loaded to; memory. * The final argument, ``regList``, specifies which registers are in this class.; If an alternative allocation order method is not specified, then ``regList``; also defines the order of allocation used by the register allocator. Besides; simply listing registers with ``(add R0, R1, ...)``, more advanced set; operators are available. See ``include/llvm/Target/Target.td`` for more; information. In ``SparcRegisterInfo.td``, three ``RegisterClass`` objects are defined:; ``FPRegs``, ``DFPRegs``, and ``IntRegs``. For all three register classes, the; first argument defines the namespace with the string ""``SP``"". ``FPRegs``; defines a group of 32 single-precision floating-point registers (``F0`` to; ``F31``); ``DFPRegs`` defines a group of 16 double-precision registers; (``D0-D15``). .. code-block:: text. // F0, F1, F2, ..., F31; def FPRegs : RegisterClass<""SP"", [f32], 32, (sequence ""F%u"", 0, 31)>;. def DFPRegs : Regist",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:22343,load,loaded,22343,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,1,['load'],['loaded']
Performance," are two variant types. ``BinaryIdsSize``; The byte size of `binary id`_ section. ``NumData``; The number of profile metadata. The byte size of `profile metadata`_ section; could be computed with this field. ``NumCounter``; The number of entries in the profile counter section. The byte size of `counter`_; section could be computed with this field. ``NumBitmapBytes``; The number of bytes in the profile `bitmap`_ section. ``NamesSize``; The number of bytes in the name section. .. _`CountersDelta`:. ``CountersDelta``; This field records the in-memory address difference between the `profile metadata`_; and counter section in the instrumented binary, i.e., ``start(__llvm_prf_cnts) - start(__llvm_prf_data)``. It's used jointly with the `CounterPtr`_ field to compute the counter offset; relative to ``start(__llvm_prf_cnts)``. Check out calculation-of-counter-offset_; for a visualized explanation. .. note::; The ``__llvm_prf_data`` object file section might not be loaded into memory; when instrumented binary runs or might not get generated in the instrumented; binary in the first place. In those cases, ``CountersDelta`` is not used and; other mechanisms are used to match counters with instrumented code. See; `lightweight instrumentation`_ and `binary profile correlation`_ for examples. ``BitmapDelta``; This field records the in-memory address difference between the `profile metadata`_; and bitmap section in the instrumented binary, i.e., ``start(__llvm_prf_bits) - start(__llvm_prf_data)``. It's used jointly with the `BitmapPtr`_ to find the bitmap of a profile data; record, in a similar way to how counters are referenced as explained by; calculation-of-counter-offset_ . Similar to `CountersDelta`_ field, this field may not be used in non-PGO variants; of profiles. ``NamesDelta``; Records the in-memory address of name section. Not used except for raw profile; reader error checking. ``ValueKindLast``; Records the number of value kinds. Macro `VALUE_PROF_KIND`_ defines the val",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/InstrProfileFormat.rst:4661,load,loaded,4661,interpreter/llvm-project/llvm/docs/InstrProfileFormat.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/InstrProfileFormat.rst,1,['load'],['loaded']
Performance," are:. - `tree1.C`: a tree with several simple (integers and floating point); variables. - `tree2.C`: a tree built from a C structure (`struct`). This example; uses the `Geant3` C wrapper as an example of a FORTRAN common block; ported to C with a C structure. - `tree3.C:` in this example, we will show how to extend a tree with a; branch from another tree with the Friends feature. These trees have; branches with variable length arrays. Each entry has a variable; number of tracks, and each track has several variables. - `tree4.C:` a tree with a class (`Event`). The class Event is defined; in `$ROOTSYS/test`. In this example we first encounter the impact of; splitting a branch. Each script contains the main function, with the same name as the file; (i.e. `tree1`), the function to write - `tree1w`, and the function to; read - `tree1r`. If the script is not run in batch mode, it displays the; tree in the browser and tree viewer. To study the example scripts, you; can either execute the main script, or load the script and execute a; specific function. For example:. ``` {.cpp}; // execute the function that writes, reads, shows the tree; root[] x tree1.C; // use ACLiC to build shared library, check syntax, execute; root[] x tree1.C++; // Load the script and select a function to execute; root[] L tree1.C; root[] tree1w(); root[] tree1r(); ```. ## Example 1: A Tree with Simple Variables. This example shows how to write, view, and read a tree with several; simple (integers and floating-point) variables. ### Writing the Tree. Below is the function that writes the tree (`tree1w`). First, the; variables are defined (`px, py, pz,` `random` and `ev`). Then we add a; branch for each of the variables to the tree, by calling the; `TTree::Branch` method for each variable. ``` {.cpp}; void tree1w(){. // create a tree file tree1.root - create the file, the Tree and; // a few branches; TFile f(""tree1.root"",""recreate"");; TTree t1(""t1"",""a simple Tree with simple variables"");; Float_t px, p",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md:34472,load,load,34472,documentation/users-guide/Trees.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md,1,['load'],['load']
Performance," as `llvm_blake3_hasher_finalize`, but with an additional `seek`; parameter for the starting byte position in the output stream. To; efficiently stream a large output without allocating memory, call this; function in a loop, incrementing `seek` by the output length each time. ---. ```c; void llvm_blake3_hasher_reset(; llvm_blake3_hasher *self);; ```. Reset the hasher to its initial state, prior to any calls to; `llvm_blake3_hasher_update`. Currently this is no different from calling; `llvm_blake3_hasher_init` or similar again. However, if this implementation gains; multithreading support in the future, and if `llvm_blake3_hasher` holds (optional); threading resources, this function will reuse those resources. # Building. This implementation is just C and assembly files. ## x86. Dynamic dispatch is enabled by default on x86. The implementation will; query the CPU at runtime to detect SIMD support, and it will use the; widest instruction set available. By default, `blake3_dispatch.c`; expects to be linked with code for five different instruction sets:; portable C, SSE2, SSE4.1, AVX2, and AVX-512. For each of the x86 SIMD instruction sets, four versions are available:; three flavors of assembly (Unix, Windows MSVC, and Windows GNU) and one; version using C intrinsics. The assembly versions are generally; preferred. They perform better, they perform more consistently across; different compilers, and they build more quickly. On the other hand, the; assembly versions are x86\_64-only, and you need to select the right; flavor for your target platform. ## ARM NEON. The NEON implementation is enabled by default on AArch64, but not on; other ARM targets, since not all of them support it. To enable it, set; `BLAKE3_USE_NEON=1`. To explicitiy disable using NEON instructions on AArch64, set; `BLAKE3_USE_NEON=0`. ## Other Platforms. The portable implementation should work on most other architectures. # Multithreading. The implementation doesn't currently support multithreading.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md:7544,perform,perform,7544,interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md,2,['perform'],['perform']
Performance," as a ``<Inner> x <OuterColumns>`` matrix, and; multiplies them. The result matrix is returned in the result vector. Arguments:; """""""""""""""""""". The first vector argument ``%A`` corresponds to a matrix with ``<OuterRows> *; <Inner>`` elements, and the second argument ``%B`` to a matrix with; ``<Inner> * <OuterColumns>`` elements. Arguments ``<OuterRows>``,; ``<Inner>`` and ``<OuterColumns>`` must be positive, constant integers. The; returned vector must have ``<OuterRows> * <OuterColumns>`` elements.; Vectors ``%A``, ``%B``, and the returned vector all have the same float or; integer element type. '``llvm.matrix.column.major.load.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare vectorty @llvm.matrix.column.major.load.*(; ptrty %Ptr, i64 %Stride, i1 <IsVolatile>, i32 <Rows>, i32 <Cols>). Overview:; """""""""""""""""". The '``llvm.matrix.column.major.load.*``' intrinsics load a ``<Rows> x <Cols>``; matrix using a stride of ``%Stride`` to compute the start address of the; different columns. The offset is computed using ``%Stride``'s bitwidth. This; allows for convenient loading of sub matrixes. If ``<IsVolatile>`` is true, the; intrinsic is considered a :ref:`volatile memory access <volatile>`. The result; matrix is returned in the result vector. If the ``%Ptr`` argument is known to; be aligned to some boundary, this can be specified as an attribute on the; argument. Arguments:; """""""""""""""""""". The first argument ``%Ptr`` is a pointer type to the returned vector type, and; corresponds to the start address to load from. The second argument ``%Stride``; is a positive, constant integer with ``%Stride >= <Rows>``. ``%Stride`` is used; to compute the column memory addresses. I.e., for a column ``C``, its start; memory addresses is calculated with ``%Ptr + C * %Stride``. The third Argument; ``<IsVolatile>`` is a boolean value. The fourth and fifth arguments,; ``<Rows>`` and ``<Cols>``, correspond to the number of ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:677924,load,load,677924,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['load'],['load']
Performance," as hardware resource pressure. The analysis and; reporting style were inspired by the IACA tool from Intel. For example, you can compile code with clang, output assembly, and pipe it; directly into :program:`llvm-mca` for analysis:. .. code-block:: bash. $ clang foo.c -O2 --target=x86_64 -S -o - | llvm-mca -mcpu=btver2. Or for Intel syntax:. .. code-block:: bash. $ clang foo.c -O2 --target=x86_64 -masm=intel -S -o - | llvm-mca -mcpu=btver2. (:program:`llvm-mca` detects Intel syntax by the presence of an `.intel_syntax`; directive at the beginning of the input. By default its output syntax matches; that of its input.). Scheduling models are not just used to compute instruction latencies and; throughput, but also to understand what processor resources are available; and how to simulate them. By design, the quality of the analysis conducted by :program:`llvm-mca` is; inevitably affected by the quality of the scheduling models in LLVM. If you see that the performance report is not accurate for a processor,; please `file a bug <https://github.com/llvm/llvm-project/issues>`_; against the appropriate backend. OPTIONS; -------. If ``input`` is ""``-``"" or omitted, :program:`llvm-mca` reads from standard; input. Otherwise, it will read from the specified filename. If the :option:`-o` option is omitted, then :program:`llvm-mca` will send its output; to standard output if the input is from standard input. If the :option:`-o`; option specifies ""``-``"", then the output will also be sent to standard output. .. option:: -help. Print a summary of command line options. .. option:: -o <filename>. Use ``<filename>`` as the output filename. See the summary above for more; details. .. option:: -mtriple=<target triple>. Specify a target triple string. .. option:: -march=<arch>. Specify the architecture for which to analyze the code. It defaults to the; host default target. .. option:: -mcpu=<cpuname>. Specify the processor for which to analyze the code. By default, the cpu name; is autode",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:1819,perform,performance,1819,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,1,['perform'],['performance']
Performance," as if it were an if-block opened by the preceding; part of the statement:. .. code-block:: c++. std::sort(foo.begin(), foo.end(), [&](Foo a, Foo b) -> bool {; if (a.blah < b.blah); return true;; if (a.baz < b.baz); return true;; return a.bam < b.bam;; });. To take best advantage of this formatting, if you are designing an API which; accepts a continuation or single callable argument (be it a function object, or; a ``std::function``), it should be the last argument if at all possible. If there are multiple multi-line lambdas in a statement, or additional; parameters after the lambda, indent the block two spaces from the indent of the; ``[]``:. .. code-block:: c++. dyn_switch(V->stripPointerCasts(),; [] (PHINode *PN) {; // process phis...; },; [] (SelectInst *SI) {; // process selects...; },; [] (LoadInst *LI) {; // process loads...; },; [] (AllocaInst *AI) {; // process allocas...; });. Braced Initializer Lists; """""""""""""""""""""""""""""""""""""""""""""""". Starting from C++11, there are significantly more uses of braced lists to; perform initialization. For example, they can be used to construct aggregate; temporaries in expressions. They now have a natural way of ending up nested; within each other and within function calls in order to build up aggregates; (such as option structs) from local variables. The historically common formatting of braced initialization of aggregate; variables does not mix cleanly with deep nesting, general expression contexts,; function arguments, and lambdas. We suggest new code use a simple rule for; formatting braced initialization lists: act as-if the braces were parentheses; in a function call. The formatting rules exactly match those already well; understood for formatting nested function calls. Examples:. .. code-block:: c++. foo({a, b, c}, {1, 2, 3});. llvm::Constant *Mask[] = {; llvm::ConstantInt::get(llvm::Type::getInt32Ty(getLLVMContext()), 0),; llvm::ConstantInt::get(llvm::Type::getInt32Ty(getLLVMContext()), 1),; llvm::ConstantInt::get(llvm::Type:",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:20196,perform,perform,20196,interpreter/llvm-project/llvm/docs/CodingStandards.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst,1,['perform'],['perform']
Performance," as it skips intermediate; `CMakeLists.txt` files which may be required. - `TEST_SUITE_COLLECT_STATS`. Collect internal LLVM statistics. Appends `-save-stats=obj` when invoking the; compiler and makes the lit runner collect and merge the statistic files. - `TEST_SUITE_RUN_BENCHMARKS`. If this is set to `OFF` then lit will not actually run the tests but just; collect build statistics like compile time and code size. - `TEST_SUITE_USE_PERF`. Use the `perf` tool for time measurement instead of the `timeit` tool that; comes with the test-suite. The `perf` is usually available on linux systems. - `TEST_SUITE_SPEC2000_ROOT`, `TEST_SUITE_SPEC2006_ROOT`, `TEST_SUITE_SPEC2017_ROOT`, ... Specify installation directories of external benchmark suites. You can find; more information about expected versions or usage in the README files in the; `External` directory (such as `External/SPEC/README`). ### Common CMake Flags. - `-GNinja`. Generate build files for the ninja build tool. - `-Ctest-suite/cmake/caches/<cachefile.cmake>`. Use a CMake cache. The test-suite comes with several CMake caches which; predefine common or tricky build configurations. Displaying and Analyzing Results; --------------------------------. The `compare.py` script displays and compares result files. A result file is; produced when invoking lit with the `-o filename.json` flag. Example usage:. - Basic Usage:. ```text; % test-suite/utils/compare.py baseline.json; Warning: 'test-suite :: External/SPEC/CINT2006/403.gcc/403.gcc.test' has No metrics!; Tests: 508; Metric: exec_time. Program baseline. INT2006/456.hmmer/456.hmmer 1222.90; INT2006/464.h264ref/464.h264ref 928.70; ...; baseline; count 506.000000; mean 20.563098; std 111.423325; min 0.003400; 25% 0.011200; 50% 0.339450; 75% 4.067200; max 1222.896800; ```. - Show compile_time or text segment size metrics:. ```bash; % test-suite/utils/compare.py -m compile_time baseline.json; % test-suite/utils/compare.py -m size.__text baseline.json; ```. - Compare two r",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:7041,cache,caches,7041,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,2,['cache'],"['cachefile', 'caches']"
Performance," as the first line of the; method. If that still doesn't remove enough, then change the caller of; ``InstCombiner::DoOneIteration``, ``InstCombiner::runOnFunction`` to limit the; number of iterations. You may also find it useful to use ""``-stats``"" now to see what parts of; instcombine are firing. This can guide where to put additional reporting code. At this point, if the amount of transformations is still too large, then; inserting code to limit whether or not to execute the body of the code in the; visit function can be helpful. Add a static counter which is incremented on; every invocation of the function. Then add code which simply returns false on; desired ranges. For example:. .. code-block:: c++. static int calledCount = 0;; calledCount++;; LLVM_DEBUG(if (calledCount < 212) return false);; LLVM_DEBUG(if (calledCount > 217) return false);; LLVM_DEBUG(if (calledCount == 213) return false);; LLVM_DEBUG(if (calledCount == 214) return false);; LLVM_DEBUG(if (calledCount == 215) return false);; LLVM_DEBUG(if (calledCount == 216) return false);; LLVM_DEBUG(dbgs() << ""visitXOR calledCount: "" << calledCount << ""\n"");; LLVM_DEBUG(dbgs() << ""I: ""; I->dump());. could be added to ``visitXOR`` to limit ``visitXor`` to being applied only to; calls 212 and 217. This is from an actual test case and raises an important; point---a simple binary search may not be sufficient, as transformations that; interact may require isolating more than one call. In TargetLowering, use; ``return SDNode();`` instead of ``return false;``. Now that the number of transformations is down to a manageable number, try; examining the output to see if you can figure out which transformations are; being done. If that can be figured out, then do the usual debugging. If which; code corresponds to the transformation being performed isn't obvious, set a; breakpoint after the call count based disabling and step through the code.; Alternatively, you can use ""``printf``"" style debugging to report waypoints.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst:11190,perform,performed,11190,interpreter/llvm-project/llvm/docs/Bugpoint.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst,1,['perform'],['performed']
Performance," as though %mask were false for those lanes. %masked.a = select <4 x i1> %mask, <4 x float> %a, <4 x float> <float 1.0, float 1.0, float 1.0, float 1.0>; %also.r = call float @llvm.vector.reduce.fmul.v4f32(float %start, <4 x float> %masked.a). .. _int_vp_reduce_and:. '``llvm.vp.reduce.and.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare i32 @llvm.vp.reduce.and.v4i32(i32 <start_value>, <4 x i32> <val>, <4 x i1> <mask>, i32 <vector_length>); declare i16 @llvm.vp.reduce.and.nxv8i16(i16 <start_value>, <vscale x 8 x i16> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated integer ``AND`` reduction of a vector and a scalar starting value,; returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value of the reduction, which must be a scalar; integer type equal to the result type. The second operand is the vector on; which the reduction is performed and must be a vector of integer values whose; element type is the result/start type. The third operand is the vector mask and; is a vector of boolean values with the same number of elements as the vector; operand. The fourth operand is the explicit vector length of the operation. Semantics:; """""""""""""""""""". The '``llvm.vp.reduce.and``' intrinsic performs the integer ``AND`` reduction; (:ref:`llvm.vector.reduce.and <int_vector_reduce_and>`) of the vector operand; ``val`` on each enabled lane, performing an '``and``' of that with with the; scalar ``start_value``. Disabled lanes are treated as containing the neutral; value ``UINT_MAX``, or ``-1`` (i.e. having no effect on the reduction; operation). If the vector length is zero, the result is the start value. To ignore the start value, the neutral value can be used. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call i32 @llvm.vp.reduce.and.v4i32(i32 %start, <4 x i32> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:757379,perform,performed,757379,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['performed']
Performance," as though %mask were false for those lanes. %masked.a = select <4 x i1> %mask, <4 x i32> %a, <4 x i32> <i32 0, i32 0, i32 0, i32 0>; %reduction = call i32 @llvm.vector.reduce.or.v4i32(<4 x i32> %masked.a); %also.r = or i32 %reduction, %start. .. _int_vp_reduce_xor:. '``llvm.vp.reduce.xor.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare i32 @llvm.vp.reduce.xor.v4i32(i32 <start_value>, <4 x i32> <val>, <4 x i1> <mask>, i32 <vector_length>); declare i16 @llvm.vp.reduce.xor.nxv8i16(i16 <start_value>, <vscale x 8 x i16> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated integer ``XOR`` reduction of a vector and a scalar starting value,; returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value of the reduction, which must be a scalar; integer type equal to the result type. The second operand is the vector on; which the reduction is performed and must be a vector of integer values whose; element type is the result/start type. The third operand is the vector mask and; is a vector of boolean values with the same number of elements as the vector; operand. The fourth operand is the explicit vector length of the operation. Semantics:; """""""""""""""""""". The '``llvm.vp.reduce.xor``' intrinsic performs the integer ``XOR`` reduction; (:ref:`llvm.vector.reduce.xor <int_vector_reduce_xor>`) of the vector operand; ``val`` on each enabled lane, performing an '``xor``' of that with the scalar; ``start_value``. Disabled lanes are treated as containing the neutral value; ``0`` (i.e. having no effect on the reduction operation). If the vector length; is zero, the result is the start value. To ignore the start value, the neutral value can be used. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call i32 @llvm.vp.reduce.xor.v4i32(i32 %start, <4 x i32> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equal to %evl;",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:761427,perform,performed,761427,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['performed']
Performance," at the beginning of; the entry block should be preferred. In particular, place them before any; call instructions. Call instructions might get inlined and replaced with; multiple basic blocks. The end result is that a following alloca instruction; would no longer be in the entry basic block afterward. The SROA (Scalar Replacement Of Aggregates) and Mem2Reg passes only attempt; to eliminate alloca instructions that are in the entry basic block. Given; SSA is the canonical form expected by much of the optimizer; if allocas can; not be eliminated by Mem2Reg or SROA, the optimizer is likely to be less; effective than it could be. Avoid loads and stores of large aggregate type; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. LLVM currently does not optimize well loads and stores of large :ref:`aggregate; types <t_aggregate>` (i.e. structs and arrays). As an alternative, consider; loading individual fields from memory. Aggregates that are smaller than the largest (performant) load or store; instruction supported by the targeted hardware are well supported. These can; be an effective way to represent collections of small packed fields. Prefer zext over sext when legal; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. On some architectures (X86_64 is one), sign extension can involve an extra; instruction whereas zero extension can be folded into a load. LLVM will try to; replace a sext with a zext when it can be proven safe, but if you have; information in your source language about the range of an integer value, it can; be profitable to use a zext rather than a sext. Alternatively, you can :ref:`specify the range of the value using metadata; <range-metadata>` and LLVM can do the sext to zext conversion for you. Zext GEP indices to machine register width; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Internally, LLVM often promotes the width of GEP indices to machine register; width. When it does so, it will default to using sign extension (sext); operations for safety. If your source",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:3333,perform,performant,3333,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,2,"['load', 'perform']","['load', 'performant']"
Performance," atomic/atomicrmw.; - Ensures that; following; loads will not see; stale MTYPE NC global data.; MTYPE RW and CC memory will; never be stale due to the; memory probes. load atomic acquire - agent - generic 1. flat_load sc1=1; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL omit; lgkmcnt(0).; - Must happen before; following; buffer_inv.; - Ensures the flat_load; has completed; before invalidating; the cache. 3. buffer_inv sc1=1. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. load atomic acquire - system - generic 1. flat_load sc0=1 sc1=1; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL omit; lgkmcnt(0).; - Must happen before; the following; buffer_inv.; - Ensures the flat_load; has completed; before invalidating; the caches. 3. buffer_inv sc0=1 sc1=1. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale MTYPE NC global data.; MTYPE RW and CC memory will; never be stale due to the; memory probes. atomicrmw acquire - singlethread - global 1. buffer/global/flat_atomic; - wavefront - generic; atomicrmw acquire - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; be used.*. 1. ds_atomic; atomicrmw acquire - workgroup - global 1. buffer/global_atomic; 2. s_waitcnt vmcnt(0). - If not TgSplit execution; mode, omit.; - Must happen before the; following buffer_inv.; - Ensures the atomicrmw; has completed; before invalidating; the cache. 3. buffer_inv sc0=1. - If not TgSplit execution; mode, omit.; - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_atomic; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:298699,load,load,298699,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],['load']
Performance," atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Ensures that all; memory operations; have; completed before; performing the; following; fence-paired-atomic. **Acquire-Release Atomic**; ------------------------------------------------------------------------------------; atomicrmw acq_rel - singlethread - global 1. buffer/global/ds/flat_atomic; - wavefront - local; - generic; atomicrmw acq_rel - workgroup - global 1. s_waitcnt lgkmcnt(0) &; vmcnt(0) & vscnt(0). - If CU wavefront execution; mode, omit vmcnt(0) and; vscnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Could be split into; separate s_waitcnt; vmcnt(0), s_waitcnt; vscnt(0), and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/load; atomic/; atomicrmw-with-return-value.; - s_waitcnt vscnt(0); must happen after; any preceding; global/generic; store/store; atomic/; atomicrmw-no-return-value.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global_atomic; 3. s_waitcnt vm/vscnt(0). - If CU wavefront execution; mode, omit.; - Use vmcnt(0) if atomic with; return and vscnt(0) if; atomic with no-return.; - Must happen before; the following; buffer_gl0_inv.; - Ensures any; following global; data read is no; older than the; atomicrmw value; being acquired. 4. buffer_gl0_inv. - If CU wavefront execution; mode, omit.; - Ensures that; following; loads will not see; stale data. atomicrmw acq_rel - workgroup - local 1. s_waitcnt vmcnt(0) & vscnt(0). - If CU wavef",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:363568,load,load,363568,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],['load']
Performance," atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global_atomic; 3. s_waitcnt vmcnt(0). - If not TgSplit execution; mode, omit.; - Must happen before; the following; buffer_inv.; - Ensures any; following global; data read is no; older than the; atomicrmw value; being acquired. 4. buffer_inv sc0=1. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. atomicrmw acq_rel - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_atomic; 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than the local load; atomic value being; acquired. atomicrmw acq_rel - workgroup - generic 1. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit; lgkmcnt(0).; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; have; completed before; performing the; atomicrmw that is; being released. 2. flat_atomic; 3. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If not TgSplit execution; mode, omit vmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Must happen before; the following; buffer_inv and; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; a",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:318399,load,load,318399,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['load']
Performance," atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic value being; acquired. 3. buffer_inv sc0=1. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. load atomic acquire - agent - global 1. buffer/global_load; sc1=1; 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_inv.; - Ensures the load; has completed; before invalidating; the cache. 3. buffer_inv sc1=1. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale global data. load atomic acquire - system - global 1. buffer/global/flat_load; sc0=1 sc1=1; 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_inv.; - Ensures the load; has completed; before invalidating; the cache. 3. buffer_inv sc0=1 sc1=1. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale MTYPE NC global data.; MTYPE RW and CC memory will; never be stale due to the; memory probes. load atomic acquire - agent - generic 1. flat_load sc1=1; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL omit; lgkmcnt(0).; - Must happen before; following; buffer_inv.; - Ensures the flat_load; has completed; before invalidating; the cache. 3. buffer_inv sc1=1. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. load atomic acquire - system - generic 1. flat_load sc0=1 sc1=1; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL omit; lgkmcnt(0).; - Must happen before; the following; buffer_inv.; - Ensures the flat_load; has completed; before invalidating; the caches. 3. buffer_inv sc0=1 sc1=1. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures tha",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:297733,load,loads,297733,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['loads']
Performance," atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; have; completed before; performing the; store that is being; released. 2. GFX940, GFX941; buffer/global/flat_store; sc0=1 sc1=1; GFX942; buffer/global/flat_store; sc0=1; store atomic release - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_store; store atomic release - agent - global 1. buffer_wbl2 sc1=1; - generic; - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at agent scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; to memory have; completed before; performing the; store that is being; released. 3. GFX940, GFX941; buffer/global/flat_store; sc0=1 sc1=1; GFX942; buffer/global/flat_store; sc1=1; store atomic release - system - global 1. buffer_wbl2 sc0=1 sc1=1; - generic; - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at system scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:308331,load,load,308331,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],['load']
Performance," atomicity of every load and; store operation would be prohibitive and preclude a vast amount of; optimization. ARC may assume that non-ARC code engages in sensible balancing; behavior and does not rely on exact or minimum retain count values; except as guaranteed by ``__strong`` object invariants or +1 transfer; conventions. For example, if an object is provably double-retained; and double-released, ARC may eliminate the inner retain and release;; it does not need to guard against code which performs an unbalanced; release followed by a ""balancing"" retain. .. _arc.optimization.liveness:. Object liveness; ---------------. ARC may not allow a retainable object ``X`` to be deallocated at a; time ``T`` in a computation history if:. * ``X`` is the value stored in a ``__strong`` object ``S`` with; :ref:`precise lifetime semantics <arc.optimization.precise>`, or. * ``X`` is the value stored in a ``__strong`` object ``S`` with; imprecise lifetime semantics and, at some point after ``T`` but; before the next store to ``S``, the computation history features a; load from ``S`` and in some way depends on the value loaded, or. * ``X`` is a value described as being released at the end of the; current full-expression and, at some point after ``T`` but before; the end of the full-expression, the computation history depends; on that value. .. admonition:: Rationale. The intent of the second rule is to say that objects held in normal; ``__strong`` local variables may be released as soon as the value in; the variable is no longer being used: either the variable stops; being used completely or a new value is stored in the variable. The intent of the third rule is to say that return values may be; released after they've been used. A computation history depends on a pointer value ``P`` if it:. * performs a pointer comparison with ``P``,; * loads from ``P``,; * stores to ``P``,; * depends on a pointer value ``Q`` derived via pointer arithmetic; from ``P`` (including an instance-variable o",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst:79137,load,load,79137,interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,2,['load'],"['load', 'loaded']"
Performance," attacker-controlled inputs.; * It does not completely block speculative execution, and merely prevents; *mis*-speculated paths from leaking secrets from memory (and stalls; speculation until this can be determined).; * It is completely general and makes no fundamental assumptions about the; underlying architecture other than the ability to do branchless conditional; data updates and a lack of value prediction.; * It does not require programmers to identify all possible secret data using; static source code annotations or code vulnerable to a variant #1 style; attack. Limitations of this approach:; * It requires re-compiling source code to insert hardening instruction; sequences. Only software compiled in this mode is protected.; * The performance is heavily dependent on a particular architecture's; implementation strategy. We outline a potential x86 implementation below and; characterize its performance.; * It does not defend against secret data already loaded from memory and; residing in registers or leaked through other side-channels in; non-speculative execution. Code dealing with this, e.g cryptographic; routines, already uses constant-time algorithms and code to prevent; side-channels. Such code should also scrub registers of secret data following; [these; guidelines](https://github.com/HACS-workshop/spectre-mitigations/blob/master/crypto_guidelines.md).; * To achieve reasonable performance, many loads may not be checked, such as; those with compile-time fixed addresses. This primarily consists of accesses; at compile-time constant offsets of global and local variables. Code which; needs this protection and intentionally stores secret data must ensure the; memory regions used for secret data are necessarily dynamic mappings or heap; allocations. This is an area which can be tuned to provide more comprehensive; protection at the cost of performance.; * [Hardened loads](#hardening-the-address-of-the-load) may still load data from; _valid_ addresses if not _attack",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:6760,load,loaded,6760,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,1,['load'],['loaded']
Performance," attributes.; + ``-Wthread-safety-analysis``: The core analysis.; + ``-Wthread-safety-precise``: Requires that mutex expressions match precisely.; This warning can be disabled for code which has a lot of aliases.; + ``-Wthread-safety-reference``: Checks when guarded members are passed by reference. :ref:`negative` are an experimental feature, which are enabled with:. * ``-Wthread-safety-negative``: Negative capabilities. Off by default. When new features and checks are added to the analysis, they can often introduce; additional warnings. Those warnings are initially released as *beta* warnings; for a period of time, after which they are migrated into the standard analysis. * ``-Wthread-safety-beta``: New features. Off by default. .. _negative:. Negative Capabilities; =====================. Thread Safety Analysis is designed to prevent both race conditions and; deadlock. The GUARDED_BY and REQUIRES attributes prevent race conditions, by; ensuring that a capability is held before reading or writing to guarded data,; and the EXCLUDES attribute prevents deadlock, by making sure that a mutex is; *not* held. However, EXCLUDES is an optional attribute, and does not provide the same; safety guarantee as REQUIRES. In particular:. * A function which acquires a capability does not have to exclude it.; * A function which calls a function that excludes a capability does not; have transitively exclude that capability. As a result, EXCLUDES can easily produce false negatives:. .. code-block:: c++. class Foo {; Mutex mu;. void foo() {; mu.Lock();; bar(); // No warning.; baz(); // No warning.; mu.Unlock();; }. void bar() { // No warning. (Should have EXCLUDES(mu)).; mu.Lock();; // ...; mu.Unlock();; }. void baz() {; bif(); // No warning. (Should have EXCLUDES(mu)).; }. void bif() EXCLUDES(mu);; };. Negative requirements are an alternative EXCLUDES that provide; a stronger safety guarantee. A negative requirement uses the REQUIRES; attribute, in conjunction with the ``!`` operator, to",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ThreadSafetyAnalysis.rst:16836,race condition,race conditions,16836,interpreter/llvm-project/clang/docs/ThreadSafetyAnalysis.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ThreadSafetyAnalysis.rst,1,['race condition'],['race conditions']
Performance," aware that executing stress with 1000; events*will create several files consuming about 100 MB of disk space;*; running stress with 30 events will consume about 20 MB. The disk space; is released once stress is done. There are two ways to run `stress`:. From the system prompt or from the ROOT prompt using the interpreter. ``` {.cpp}; > cd $ROOTSYS/test; > stress // default 1000 events; > stress 30 // test with 30 events; ```. Start ROOT with the batch mode option (-b) to suppress the graphic; output. ``` {.cpp}; > root -b; root[] .L stress.cxx; root[] stress(1000)// test with 1000 events; root[] stress(30)// test with 30 events; ```. The output of stress includes a pass/fail conclusion for each test, the; total number of bytes read and written, and the elapsed real and CPU; time. It also calculates a performance index for your machine relative; to a reference machine a DELL Inspiron 7500 (Pentium III 600 MHz) with; 256 MB of memory and 18GB IDE disk in ROOTMARKS. Higher ROOTMARKS means; better performance. The reference machine has 200 ROOTMARKS, so the; sample run below with 53.7 ROOTMARKS is about four times slower than the; reference machine. Here is a sample run:. ``` {.cpp}; % root -b; root[] .x stress.cxx(30). Test 1 : Functions, Random Numbers, Histogram Fits............. OK; Test 2 : Check size & compression factor of a Root file........ OK; Test 3 : Purge, Reuse of gaps in TFile......................... OK; Test 4 : Test of 2-d histograms, functions, 2-d fits........... OK; Test 5 : Test graphics & PostScript ............................OK; Test 6 : Test subdirectories in a Root file.................... OK; Test 7 : TNtuple, selections, TCutG, TEventList.......... OK; Test 8 : Trees split and compression modes..................... OK; Test 9 : Analyze Event.root file of stress 8................... OK; Test 10 : Create 10 files starting from Event.root.............. OK; Test 11 : Test chains of Trees using the 10 files............... OK; Test 12 : Compare h",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/TutorialsandTests.md:14538,perform,performance,14538,documentation/users-guide/TutorialsandTests.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/TutorialsandTests.md,1,['perform'],['performance']
Performance," be cached on the CPU.; Subsequent access from the GPU will automatically invalidate or writeback; the CPU cache due to the L2 probe filter.; * To ensure coherence of local memory writes of CUs with different L1 caches; in the same agent a ``buffer_wbl2`` is required. It does nothing if the; agent is configured to have a single L2, or will writeback dirty L2 cache; lines if configured to have multiple L2 caches.; * To ensure coherence of local memory writes of CUs in different agents a; ``buffer_wbl2 sc1`` is required. It will writeback dirty L2 cache lines.; * To ensure coherence of local memory reads of CUs with different L1 caches; in the same agent a ``buffer_inv sc1`` is required. It does nothing if the; agent is configured to have a single L2, or will invalidate non-local L2; cache lines if configured to have multiple L2 caches.; * To ensure coherence of local memory reads of CUs in different agents a; ``buffer_inv sc0 sc1`` is required. It will invalidate non-local L2 cache; lines if configured to have multiple L2 caches. * PCIe access from the GPU to the CPU can be kept coherent by using the MTYPE; UC (uncached) which bypasses the L2. Scalar memory operations are only used to access memory that is proven to not; change during the execution of the kernel dispatch. This includes constant; address space and global address space for program scope ``const`` variables.; Therefore, the kernel machine code does not have to maintain the scalar cache to; ensure it is coherent with the vector caches. The scalar and vector caches are; invalidated between kernel dispatches by CP since constant address space data; may change between kernel dispatch executions. See; :ref:`amdgpu-amdhsa-memory-spaces`. The one exception is if scalar writes are used to spill SGPR registers. In this; case the AMDGPU backend ensures the memory location used to spill is never; accessed by vector memory operations at the same time. If scalar writes are used; then a ``s_dcache_wb`` is inserted bef",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:289621,cache,cache,289621,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['cache'],"['cache', 'caches']"
Performance," be either zero or one without affecting control or; data flow of a program. The BDCE pass removes instructions that only; compute these dead bits. **BURS**; Bottom Up Rewriting System --- A method of instruction selection for code; generation. An example is the `BURG; <http://www.program-transformation.org/Transform/BURG>`_ tool. C; -. **CFI**; This abbreviation has two meanings.; Either:; Call Frame Information. Used in DWARF debug info and in C++ unwind info; to show how the function prolog lays out the stack frame. Or:; Control Flow Integrity. A general term for computer security techniques; that prevent a wide variety of malware attacks from redirecting the flow; of execution (the control flow) of a program. **CIE**; Common Information Entry. A kind of CFI used to reduce the size of FDEs.; The compiler creates a CIE which contains the information common across all; the FDEs. Each FDE then points to its CIE. **CSE**; Common Subexpression Elimination. An optimization that removes common; subexpression computation. For example ``(a+b)*(a+b)`` has two; subexpressions that are the same: ``(a+b)``. This optimization would; perform the addition only once and then perform the multiply (but only if; it's computationally correct/safe). D; -. **DAG**; Directed Acyclic Graph. .. _derived pointer:; .. _derived pointers:. **Derived Pointer**; A pointer to the interior of an object, such that a garbage collector is; unable to use the pointer for reachability analysis. While a derived pointer; is live, the corresponding object pointer must be kept in a root, otherwise; the collector might free the referenced object. With copying collectors,; derived pointers pose an additional hazard that they may be invalidated at; any `safe point`_. This term is used in opposition to `object pointer`_. **DSA**; Data Structure Analysis. **DSE**; Dead Store Elimination. E; -. **ento**; This namespace houses the; `Clang Static Analyzer <https://clang.llvm.org/docs/ClangStaticAnalyzer.html>`_.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Lexicon.rst:2074,optimiz,optimization,2074,interpreter/llvm-project/llvm/docs/Lexicon.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Lexicon.rst,1,['optimiz'],['optimization']
Performance," before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acq_rel - agent - generic 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global have; completed before; performing the; atomicrmw that is; being released. 2. flat_atomic; 3. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 4. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. fence acq_rel - singlethread *none* *none*; - wavefront; fence acq_rel - workgroup *none* 1. s_waitcnt lgkmcnt(0). - If OpenCL and; address space is; not generic, omit.; - However,; since LLVM; currently has no; address space on; the fence need to; conservatively; always generate; (see comment for; previous fence).; - Must happen after; any preceding; local/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that all; memory operations; to local have; completed before; performing any; following global; memory operations.; - Ensures that the; preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; u",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:227080,cache,cache,227080,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['cache'],['cache']
Performance," before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than the local load; atomic value being; acquired. load atomic acquire - workgroup - generic 1. flat_load glc=1. - If not TgSplit execution; mode, omit glc=1. 2. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit lgkmcnt(0).; - Must happen before; the following; buffer_wbinvl1_vol and any; following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic value being; acquired. 3. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. load atomic acquire - agent - global 1. buffer/global_load; glc=1; 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the load; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale global data. load atomic acquire - system - global 1. buffer/global/flat_load; glc=1; 2. s_waitcnt vmcnt(0). - Must happen before; following buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures the load; has completed; before invalidating; the cache. 3. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. load atomic acquire - agent - generic 1. flat_load glc=1; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the flat_loa",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:246917,load,load,246917,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,"['cache', 'load']","['cache', 'load']"
Performance," behavior is dependent on the track; parameters, which is a highly undesirable effect. *B)* We will call ""overlaps"" only the regions in space contained by; more than one node inside the same container. The owner of such regions; cannot be determined based on hierarchical considerations; therefore; they will be considered as belonging to the node from which the current; track is coming from. When coming from their container, the ownership is totally; unpredictable. Again, the ownership of overlapping regions highly; depends on the current track parameters. We must say that even the overlaps of type *A)* and *B)* are allowed in case; the corresponding nodes are created using; TGeoVolume::AddNodeOverlap() method. Navigation is performed in such; cases by giving priority to the non-overlapping nodes. The modeller has; to perform an additional search through the overlapping candidates.; These are detected automatically during the geometry closing procedure; in order to optimize the algorithm, but we will stress that extensive; usage of this feature leads to a drastic deterioration of performance.; In the following we will focus on the non-declared overlaps of type *A)*; and *B)* since this is the main source of errors during tracking. These; are generally non-intended overlaps due to coding mistakes or bad; geometry design. The checking package is loaded together with the; painter classes and contains an automated overlap checker. \image html geometry008.png ""Overlap checking"". This can be activated both at volume level (checking for illegal; overlaps only one level inside a given volume) and from the geometry; manager level (checking full geometry):. ~~~{.cpp}; myVolume->CheckOverlaps(precision, option);; gGeoManager->CheckOverlaps(precision);; myNode->CheckOverlaps(precision);; ~~~. Here precision represents the desired maximum accepted overlap value in; centimeters (default value is 0.1). This tool checks all possible; significant pairs of candidates inside a given vol",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:92373,optimiz,optimize,92373,geom/geom/doc/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md,2,"['optimiz', 'perform']","['optimize', 'performance']"
Performance," bind to the local symbol. That is, the symbol; cannot be overridden by another module. A symbol with ``internal`` or ``private`` linkage must have ``default``; visibility. .. _dllstorageclass:. DLL Storage Classes; -------------------. All Global Variables, Functions and Aliases can have one of the following; DLL storage class:. ``dllimport``; ""``dllimport``"" causes the compiler to reference a function or variable via; a global pointer to a pointer that is set up by the DLL exporting the; symbol. On Microsoft Windows targets, the pointer name is formed by; combining ``__imp_`` and the function or variable name.; ``dllexport``; On Microsoft Windows targets, ""``dllexport``"" causes the compiler to provide; a global pointer to a pointer in a DLL, so that it can be referenced with the; ``dllimport`` attribute. the pointer name is formed by combining ``__imp_``; and the function or variable name. On XCOFF targets, ``dllexport`` indicates; that the symbol will be made visible to other modules using ""exported""; visibility and thus placed by the linker in the loader section symbol table.; Since this storage class exists for defining a dll interface, the compiler,; assembler and linker know it is externally referenced and must refrain from; deleting the symbol. A symbol with ``internal`` or ``private`` linkage cannot have a DLL storage; class. .. _tls_model:. Thread Local Storage Models; ---------------------------. A variable may be defined as ``thread_local``, which means that it will; not be shared by threads (each thread will have a separated copy of the; variable). Not all targets support thread-local variables. Optionally, a; TLS model may be specified:. ``localdynamic``; For variables that are only used within the current shared library.; ``initialexec``; For variables in modules that will not be loaded dynamically.; ``localexec``; For variables defined in the executable and only used within it. If no explicit model is given, the ""general dynamic"" model is used. The m",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:25260,load,loader,25260,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['load'],['loader']
Performance," block, and the; child functions can use '``llvm.localrecover``' to access the escaped allocas.; The '``llvm.localescape``' intrinsic blocks inlining, as inlining changes where; the escaped allocas are allocated, which would break attempts to use; '``llvm.localrecover``'. '``llvm.seh.try.begin``' and '``llvm.seh.try.end``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare void @llvm.seh.try.begin(); declare void @llvm.seh.try.end(). Overview:; """""""""""""""""". The '``llvm.seh.try.begin``' and '``llvm.seh.try.end``' intrinsics mark; the boundary of a _try region for Windows SEH Asynchrous Exception Handling. Semantics:; """""""""""""""""""". When a C-function is compiled with Windows SEH Asynchrous Exception option,; -feh_asynch (aka MSVC -EHa), these two intrinsics are injected to mark _try; boundary and to prevent potential exceptions from being moved across boundary.; Any set of operations can then be confined to the region by reading their leaf; inputs via volatile loads and writing their root outputs via volatile stores. '``llvm.seh.scope.begin``' and '``llvm.seh.scope.end``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare void @llvm.seh.scope.begin(); declare void @llvm.seh.scope.end(). Overview:; """""""""""""""""". The '``llvm.seh.scope.begin``' and '``llvm.seh.scope.end``' intrinsics mark; the boundary of a CPP object lifetime for Windows SEH Asynchrous Exception; Handling (MSVC option -EHa). Semantics:; """""""""""""""""""". LLVM's ordinary exception-handling representation associates EH cleanups and; handlers only with ``invoke``s, which normally correspond only to call sites. To; support arbitrary faulting instructions, it must be possible to recover the current; EH scope for any instruction. Turning every operation in LLVM that could fault; into an ``invoke`` of a new, potentially-throwing intrinsic would require adding a; large number of intrinsics, impede optimization of ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:515906,load,loads,515906,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['load'],['loads']
Performance," buffer/global/flat_load; nt=1. - volatile. 1. buffer/global/flat_load; sc0=1 sc1=1; 2. s_waitcnt vmcnt(0). - Must happen before; any following volatile; global/generic; load/store.; - Ensures that; volatile; operations to; different; addresses will not; be reordered by; hardware. load *none* *none* - local 1. ds_load; store *none* *none* - global - !volatile & !nontemporal; - generic; - private 1. GFX940, GFX941; - constant buffer/global/flat_store; sc0=1 sc1=1; GFX942; buffer/global/flat_store. - !volatile & nontemporal. 1. GFX940, GFX941; buffer/global/flat_store; nt=1 sc0=1 sc1=1; GFX942; buffer/global/flat_store; nt=1. - volatile. 1. buffer/global/flat_store; sc0=1 sc1=1; 2. s_waitcnt vmcnt(0). - Must happen before; any following volatile; global/generic; load/store.; - Ensures that; volatile; operations to; different; addresses will not; be reordered by; hardware. store *none* *none* - local 1. ds_store; **Unordered Atomic**; ------------------------------------------------------------------------------------; load atomic unordered *any* *any* *Same as non-atomic*.; store atomic unordered *any* *any* *Same as non-atomic*.; atomicrmw unordered *any* *any* *Same as monotonic atomic*.; **Monotonic Atomic**; ------------------------------------------------------------------------------------; load atomic monotonic - singlethread - global 1. buffer/global/flat_load; - wavefront - generic; load atomic monotonic - workgroup - global 1. buffer/global/flat_load; - generic sc0=1; load atomic monotonic - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; - workgroup be used.*. 1. ds_load; load atomic monotonic - agent - global 1. buffer/global/flat_load; - generic sc1=1; load atomic monotonic - system - global 1. buffer/global/flat_load; - generic sc0=1 sc1=1; store atomic monotonic - singlethread - global 1. buffer/global/flat_store; - wavefront - generic; store atomic monotonic - workgroup - global 1. buffer/global/flat_store; - g",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:293778,load,load,293778,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['load']
Performance," build this file and tree follow the instructions on how to; build the examples in `$ROOTSYS/test`. Execute `Event` and instruct it; to split the object with this command (from the UNIX command line). ``` {.cpp}; > $ROOTSYS/test/Event 400 1 2 1; ```. This creates an `Event.root` file with 400 events, compressed, split,; and filled. See `$ROOTSYS/test/MainEvent.cxx` for more info. The person who designed the tree makes a shared library available to; you, which defines the classes needed. In this case, the classes are; Event, `EventHeader`, and Track and they are defined in the shared; library `libEvent.so`. The designer also gives you the `Event.h` file to; see the definition of the classes. You can locate `Event.h` in; `$ROOTSYS/test`, and if you have not yet built `libEvent.so`, please see; the instructions of how to build it (typing make in \$ROOTSYS/test is; enough). If you have already built it, you can now use it again. ### Creating a Class with MakeClass. First, we load the shared library and open `Event.root`. ``` {.cpp}; root[] .L libEvent.so; root[] TFile *f = new TFile(""Event.root"");; root[] f->ls();; TFile** Event.root TTree benchmark ROOT file; TFile* Event.root TTree benchmark ROOT file; KEY: TH1F htime;1 Real-Time to write versus time; KEY: TTree T;1 An example of a ROOT tree; ```. We can see there is a tree ""`T`"", and just to verify that we are working; with the correct one, we print the tree, which will show us the header; and branches. ``` {.cpp}; root[] T->Print();; ```. From the output of print we can see that the tree has one branch for; each data member of `Event`, `Track`, and `EventHeader`. Now we can use; `TTree::MakeClass` on our tree ""`T`"". `MakeClass` takes one parameter, a; string containing the name of the class to be made. In the command; below, the name of our class will be ""`MyClass`"". ``` {.cpp}; root[] T->MakeClass(""MyClass""); Files: MyClass.h and MyClass.C generated from Tree: T; ```. Cling informs us that it has created two files. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md:123125,load,load,123125,documentation/users-guide/Trees.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md,1,['load'],['load']
Performance," but is very quick analysis. The ``-steens-aa`` pass; ^^^^^^^^^^^^^^^^^^^^^^^. The ``-steens-aa`` pass implements a variation on the well-known ""Steensgaard's; algorithm"" for interprocedural alias analysis. Steensgaard's algorithm is a; unification-based, flow-insensitive, context-insensitive, and field-insensitive; alias analysis that is also very scalable (effectively linear time). The LLVM ``-steens-aa`` pass implements a ""speculatively field-**sensitive**""; version of Steensgaard's algorithm using the Data Structure Analysis framework.; This gives it substantially more precision than the standard algorithm while; maintaining excellent analysis scalability. .. note::. ``-steens-aa`` is available in the optional ""poolalloc"" module. It is not part; of the LLVM core. The ``-ds-aa`` pass; ^^^^^^^^^^^^^^^^^^^. The ``-ds-aa`` pass implements the full Data Structure Analysis algorithm. Data; Structure Analysis is a modular unification-based, flow-insensitive,; context-**sensitive**, and speculatively field-**sensitive** alias; analysis that is also quite scalable, usually at ``O(n * log(n))``. This algorithm is capable of responding to a full variety of alias analysis; queries, and can provide context-sensitive mod/ref information as well. The; only major facility not implemented so far is support for must-alias; information. .. note::. ``-ds-aa`` is available in the optional ""poolalloc"" module. It is not part of; the LLVM core. The ``-scev-aa`` pass; ^^^^^^^^^^^^^^^^^^^^^. The ``-scev-aa`` pass implements AliasAnalysis queries by translating them into; ScalarEvolution queries. This gives it a more complete understanding of; ``getelementptr`` instructions and loop induction variables than other alias; analyses have. Alias analysis driven transformations; -------------------------------------. LLVM includes several alias-analysis driven transformations which can be used; with any of the implementations above. The ``-adce`` pass; ^^^^^^^^^^^^^^^^^^. The ``-adce`` pass, wh",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AliasAnalysis.rst:26416,scalab,scalable,26416,interpreter/llvm-project/llvm/docs/AliasAnalysis.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AliasAnalysis.rst,1,['scalab'],['scalable']
Performance," by the `Block RThroughput`. Field 'uOps Per Cycle' is computed dividing the total number of simulated micro; opcodes by the total number of cycles. A delta between Dispatch Width and this; field is an indicator of a performance issue. In the absence of loop-carried; data dependencies, the observed 'uOps Per Cycle' should tend to a theoretical; maximum throughput which can be computed by dividing the number of uOps of a; single iteration by the `Block RThroughput`. Field *uOps Per Cycle* is bounded from above by the dispatch width. That is; because the dispatch width limits the maximum size of a dispatch group. Both IPC; and 'uOps Per Cycle' are limited by the amount of hardware parallelism. The; availability of hardware resources affects the resource pressure distribution,; and it limits the number of instructions that can be executed in parallel every; cycle. A delta between Dispatch Width and the theoretical maximum uOps per; Cycle (computed by dividing the number of uOps of a single iteration by the; `Block RThroughput`) is an indicator of a performance bottleneck caused by the; lack of hardware resources.; In general, the lower the Block RThroughput, the better. In this example, ``uOps per iteration/Block RThroughput`` is 1.50. Since there; are no loop-carried dependencies, the observed `uOps Per Cycle` is expected to; approach 1.50 when the number of iterations tends to infinity. The delta between; the Dispatch Width (2.00), and the theoretical maximum uOp throughput (1.50) is; an indicator of a performance bottleneck caused by the lack of hardware; resources, and the *Resource pressure view* can help to identify the problematic; resource usage. The second section of the report is the `instruction info view`. It shows the; latency and reciprocal throughput of every instruction in the sequence. It also; reports extra information related to the number of micro opcodes, and opcode; properties (i.e., 'MayLoad', 'MayStore', and 'HasSideEffects'). Field *RThroughput",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:17893,perform,performance,17893,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,2,"['bottleneck', 'perform']","['bottleneck', 'performance']"
Performance," by the wavefronts of the work-groups; executing on it. The exception is when in tgsplit execution mode when no LDS; is allocated as wavefronts of the same work-group can be in different CUs.; * All LDS operations of a CU are performed as wavefront wide operations in a; global order and involve no caching. Completion is reported to a wavefront in; execution order.; * The LDS memory has multiple request queues shared by the SIMDs of a; CU. Therefore, the LDS operations performed by different wavefronts of a; work-group can be reordered relative to each other, which can result in; reordering the visibility of vector memory operations with respect to LDS; operations of other wavefronts in the same work-group. A ``s_waitcnt; lgkmcnt(0)`` is required to ensure synchronization between LDS operations and; vector memory operations between wavefronts of a work-group, but not between; operations performed by the same wavefront.; * The vector memory operations are performed as wavefront wide operations and; completion is reported to a wavefront in execution order. The exception is; that ``flat_load/store/atomic`` instructions can report out of vector memory; order if they access LDS memory, and out of LDS operation order if they access; global memory.; * The vector memory operations access a single vector L1 cache shared by all; SIMDs a CU. Therefore:. * No special action is required for coherence between the lanes of a single; wavefront. * No special action is required for coherence between wavefronts in the same; work-group since they execute on the same CU. The exception is when in; tgsplit execution mode as wavefronts of the same work-group can be in; different CUs and so a ``buffer_inv sc0`` is required which will invalidate; the L1 cache. * A ``buffer_inv sc0`` is required to invalidate the L1 cache for coherence; between wavefronts executing in different work-groups as they may be; executing on different CUs. * Atomic read-modify-write instructions implicitly bypass the",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:285701,perform,performed,285701,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['perform'],['performed']
Performance," by the wavefronts of the work-groups; executing on it. The exception is when in tgsplit execution mode when no LDS; is allocated as wavefronts of the same work-group can be in different CUs.; * All LDS operations of a CU are performed as wavefront wide operations in a; global order and involve no caching. Completion is reported to a wavefront in; execution order.; * The LDS memory has multiple request queues shared by the SIMDs of a; CU. Therefore, the LDS operations performed by different wavefronts of a; work-group can be reordered relative to each other, which can result in; reordering the visibility of vector memory operations with respect to LDS; operations of other wavefronts in the same work-group. A ``s_waitcnt; lgkmcnt(0)`` is required to ensure synchronization between LDS operations and; vector memory operations between wavefronts of a work-group, but not between; operations performed by the same wavefront.; * The vector memory operations are performed as wavefront wide operations and; completion is reported to a wavefront in execution order. The exception is; that ``flat_load/store/atomic`` instructions can report out of vector memory; order if they access LDS memory, and out of LDS operation order if they access; global memory.; * The vector memory operations access a single vector L1 cache shared by all; SIMDs a CU. Therefore:. * No special action is required for coherence between the lanes of a single; wavefront. * No special action is required for coherence between wavefronts in the same; work-group since they execute on the same CU. The exception is when in; tgsplit execution mode as wavefronts of the same work-group can be in; different CUs and so a ``buffer_wbinvl1_vol`` is required as described in; the following item. * A ``buffer_wbinvl1_vol`` is required for coherence between wavefronts; executing in different work-groups as they may be executing on different; CUs. * The scalar memory operations access a scalar L1 cache shared by all wavefronts",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:235553,perform,performed,235553,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['perform'],['performed']
Performance," byte first (lowest in memory address). A ""big endian"" layout has the *most* significant byte first. This means that when loading an item from big endian memory, the lowest 8-bits in memory must go in the most significant 8-bits, and so forth. ``LDR`` and ``LD1``; ===================. .. figure:: ARM-BE-ldr.png; :align: right. Big endian vector load using ``LDR``. A vector is a consecutive sequence of items that are operated on simultaneously. To load a 64-bit vector, 64 bits need to be read from memory. In little endian mode, we can do this by just performing a 64-bit load - ``LDR q0, [foo]``. However if we try this in big endian mode, because of the byte swapping the lane indices end up being swapped! The zero'th item as laid out in memory becomes the n'th lane in the vector. .. figure:: ARM-BE-ld1.png; :align: right. Big endian vector load using ``LD1``. Note that the lanes retain the correct ordering. Because of this, the instruction ``LD1`` performs a vector load but performs byte swapping not on the entire 64 bits, but on the individual items within the vector. This means that the register content is the same as it would have been on a little endian system. It may seem that ``LD1`` should suffice to perform vector loads on a big endian machine. However there are pros and cons to the two approaches that make it less than simple which register format to pick. There are two options:. 1. The content of a vector register is the same *as if* it had been loaded with an ``LDR`` instruction.; 2. The content of a vector register is the same *as if* it had been loaded with an ``LD1`` instruction. Because ``LD1 == LDR + REV`` and similarly ``LDR == LD1 + REV`` (on a big endian system), we can simulate either type of load with the other type of load plus a ``REV`` instruction. So we're not deciding which instructions to use, but which format to use (which will then influence which instruction is best to use). .. The 'clearer' container is required to make the following sect",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BigEndianNEON.rst:3296,perform,performs,3296,interpreter/llvm-project/llvm/docs/BigEndianNEON.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BigEndianNEON.rst,3,"['load', 'perform']","['load', 'performs']"
Performance," bytecode representation:. ISSUES RESOLVED; ---------------. 1. We decided that we shall use a flat namespace to represent our ; variables in SSA form, as opposed to having a two dimensional namespace; of the original variable and the SSA instance subscript. ARGUMENT AGAINST:; * A two dimensional namespace would be valuable when doing alias ; analysis because the extra information can help limit the scope of; analysis. ARGUMENT FOR:; * Including this information would require that all users of the LLVM; bytecode would have to parse and handle it. This would slow down the; common case and inflate the instruction representation with another; infinite variable space. REASONING:; * It was decided that because original variable sources could be; reconstructed from SSA form in linear time, that it would be an; unjustified expense for the common case to include the extra; information for one optimization. Alias analysis itself is typically; greater than linear in asymptotic complexity, so this extra analaysis; would not affect the runtime of the optimization in a significant; way. Additionally, this would be an unlikely optimization to do at; runtime. IDEAS TO CONSIDER; -----------------. 1. Including dominator information in the LLVM bytecode; representation. This is one example of an analysis result that may be; packaged with the bytecodes themselves. As a conceptual implementation ; idea, we could include an immediate dominator number for each basic block; in the LLVM bytecode program. Basic blocks could be numbered according; to the order of occurrence in the bytecode representation. 2. Including loop header and body information. This would facilitate; detection of intervals and natural loops. UNRESOLVED ISSUES ; ----------------- . 1. Will oSUIF provide enough of an infrastructure to support the research; that we will be doing? We know that it has less than stellar; performance, but hope that this will be of little importance for our; static compiler. This could affect",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2000-12-06-MeetingSummary.txt:1122,optimiz,optimization,1122,interpreter/llvm-project/llvm/docs/HistoricalNotes/2000-12-06-MeetingSummary.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2000-12-06-MeetingSummary.txt,1,['optimiz'],['optimization']
Performance," bytes read from TFiles during the readspeed test (possibly including meta-data).; Uncompressed bytes is the number of bytes processed by reading the branch values in the TTree.; Throughput is calculated as the total number of bytes over the total runtime (including; decompression time) in the uncompressed and compressed cases. ## Interpreting results:. ### There are three possible scenarios when using rootreadspeed, namely:. - The 'Real Time' is significantly lower than your own analysis runtime.; This would imply your actual application code is dominating the runtime of your analysis,; ie. your analysis logic or framework is taking up the time.; The best way to decrease the runtime would be to optimize your code (or the framework's),; parallelize it onto multiple threads if possible (for example with; [RDataFrame](https://root.cern/doc/master/classROOT_1_1RDataFrame.html); and [EnableImplicitMT](https://root.cern/doc/master/namespaceROOT.html#a06f2b8b216b615e5abbc872c9feff40f)); or switch to a machine with a more performant CPU.; - The 'Real Time' is significantly higher than 'CPU Time / number of threads'*.; If the real time is higher than the CPU time per core it implies the reading of data is the; bottleneck, as the CPU cores are wasting time waiting for data to arrive from your disk/drive; or network connection in order to decompress it.; The best way to decrease your runtime would be transferring the data you need onto a faster; storage medium (ie. a faster disk/drive such as an SSD, or connecting to a faster network; for remote file access), or to use a compression algorithm with a higher compression ratio,; possibly at the cost of the decompression rate.; Changing the number of threads is unlikely to help, and in fact using too many threads may; degrade performance if they make requests to different regions of your local storage. ; * If no '--threads' argument was provided this is 1, otherwise it is the minimum of the value; provided and the number of threa",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/readspeed/README.md:1646,perform,performant,1646,tree/readspeed/README.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/readspeed/README.md,1,['perform'],['performant']
Performance," caches. The scalar and vector caches are; invalidated between kernel dispatches by CP since constant address space data; may change between kernel dispatch executions. See; :ref:`amdgpu-amdhsa-memory-spaces`. The one exception is if scalar writes are used to spill SGPR registers. In this; case the AMDGPU backend ensures the memory location used to spill is never; accessed by vector memory operations at the same time. If scalar writes are used; then a ``s_dcache_wb`` is inserted before the ``s_endpgm`` and before a function; return since the locations may be used for vector memory instructions by a; future wavefront that uses the same scratch area, or a function call that; creates a frame at the same address, respectively. There is no need for a; ``s_dcache_inv`` as all scalar writes are write-before-read in the same thread. For kernarg backing memory:. * CP invalidates the L0 and L1 caches at the start of each kernel dispatch.; * On dGPU the kernarg backing memory is accessed as MTYPE UC (uncached) to avoid; needing to invalidate the L2 cache.; * On APU the kernarg backing memory is accessed as MTYPE CC (cache coherent) and; so the L2 cache will be coherent with the CPU and other agents. Scratch backing memory (which is used for the private address space) is accessed; with MTYPE NC (non-coherent). Since the private address space is only accessed; by a single thread, and is always write-before-read, there is never a need to; invalidate these entries from the L0 or L1 caches. Wavefronts are executed in native mode with in-order reporting of loads and; sample instructions. In this mode vmcnt reports completion of load, atomic with; return and sample instructions in order, and the vscnt reports the completion of; store and atomic without return in order. See ``MEM_ORDERED`` field in; :ref:`amdgpu-amdhsa-compute_pgm_rsrc1-gfx6-gfx12-table`. Wavefronts can be executed in WGP or CU wavefront execution mode:. * In WGP wavefront execution mode the wavefronts of a work-group ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:341372,cache,cache,341372,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['cache'],['cache']
Performance," can avoid re-reading the same entry too many; times when executing TRef::GetObject.; Reduce by 40% the time taken GetEntry for a branch created using a leaflist (exclusive of the decompression time).; Introduce TVirtualPerfStats::FileUnzipEvent to be able to keep track of the cost of unzipping and use this in TTreePerfStats and TBasket ... This give a good picture of where the time in unzip or in unstreaming; Add more clusters to the TTreeCache buffer until fBufferMinSize is hit to avoid severely underfilled buffer when; a low number of branches is selected/used.; When reading backwards, make sure to load a full (new) cluster and several other fixes to TTreeCache.; Reduce the memory used by a TTree in half. Refactor the code reading and writing the TBasket data.; A single transient buffer holding the compressed data is now managed by TTree (and could be made thread local); rather than having one per TBranch.; In TTree::Fill, call FlushBasket before calling OptimizeBaskets so that we have a correct; and accurate value of fTotBytes to use as the requested memory.; In TTree::OptimizeBasket enforces hard minimun for the basket size (no lower than the; estimate size of one entry in the branch and no lower than 8 bytes). TTree::Process. Add support for the flag TSelector::kAbortFile. TTree::Draw. The line width setting was missing in a few places.; Namely support the option 'a' for TGraphs in TTree::Draw (delegate the axis management to the TGraph object). TTreeSQL. Allow TTreeSQL to see temporary tables.; Avoid creating the unnecessary array fEntryOffset ... which when its content is always set to zero actually prevent reading text field with TTreeSQL.; Properly find the column even if they were not created by TTreeSQL itself. Fix the loading of data for the last column. Other. Update the branch split mechanism to no longer split a base class; that can not be split (i.e. respect the information returned; by TStreamerElement::CannotSplit (and thus TClass::CanSplit).; In ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v530/index.html:2365,Optimiz,OptimizeBaskets,2365,tree/doc/v530/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v530/index.html,1,['Optimiz'],['OptimizeBaskets']
Performance," can be accessed via normal web server. From the browser side, JSROOT could regularly read the specified objects and update their drawings. But such solution has three major caveats. First of all, one need to store the data of all objects, which only potentially could be displayed in the browser. In case of 10 objects it does not matter, but for 1000 or 100000 objects this will be a major performance penalty. With such big amount of data one will never achieve higher update rate. The second problem is I/O. To read the first object from the ROOT file, one need to perform several (about 5) file-reading operations via http protocol.; There is no http file locking mechanism (at least not for standard web servers),; therefore there is no guarantee that the file content is not changed/replaced between consequent read operations. Therefore, one should expect frequent I/O failures while trying to monitor data from ROOT binary files. There is a workaround for the problem - one could load the file completely and exclude many partial I/O operations by this. To achieve this with JSROOT, one should add ""+"" sign at the end of the file name. Of course, it only could work for small files. If somebody still wants to use monitoring of data from ROOT files, could try link like:. - <https://root.cern/js/latest/?nobrowser&file=../files/hsimple.root+&item=hpx;1&monitoring=2000>. In this particular case, the histogram is not changing. ## JSROOT API. JSROOT can be used in arbitrary HTML pages to display data, produced with or without ROOT-based applications. Many different examples of JSROOT API usage can be found on [JSROOT API examples](https://root.cern/js/latest/api.htm) page. ### Import JSROOT functionality. Major JSROOT functions are located in `main.mjs` module and can be imported like:. ```javascript; <script type='module'>; import { openFile, draw } from 'https://root.cern/js/latest/modules/main.mjs';; let filename = ""https://root.cern/js/files/hsimple.root"";; let file = await ope",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/JSROOT/JSROOT.md:33363,load,load,33363,documentation/JSROOT/JSROOT.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/JSROOT/JSROOT.md,1,['load'],['load']
Performance," can be asked for at a given moment, but; rather represented by the combination: current node/current global; matrix. However, physical nodes have unique ID's that can be retrieved; for a given modeller state. These can be fed back to the modeller in; order to force a physical node to become current. The advantage of this; comes from the fact that all navigation queries check first the current; node; therefore the location of a point in the geometry can be saved as; a starting state for later use. Nodes can be declared as `overlapping` in case they do overlap with; other nodes inside the same container or extrude this container (see; also ‘Checking the Geometry'). Non-overlapping nodes can be created; with:. ~~~{.cpp}; TGeoVolume::AddNode(TGeoVolume *daughter,Int_t copy_No,; TGeoMatrix *matr);; ~~~. The creation of overlapping nodes can be done with a similar prototype:. ~~~{.cpp}; TGeoVolume::AddNodeOverlap(/*same arguments*/);; ~~~. When closing the geometry, overlapping nodes perform a check of possible; overlaps with their neighbors. These are stored and checked all the time; during navigation; therefore, navigation is slower when embedding such; nodes into geometry. Nodes have visualization attributes as the volume; has. When undefined by users, painting a node on a pad will take the; corresponding volume attributes. \anchor GP01b; ### Creating and Positioning Volumes. \anchor GP01ba; #### Making Volumes. As mentioned before, volumes are the basic objects used in building the; geometrical hierarchy. They represent objects that are not positioned,; but store all information about the placement of the other volumes they; may contain. Therefore a volume can be replicated several times in the; geometry. As it was explained, in order to create a volume, one has to; put together a shape and a medium, which are already defined. Volumes have to be named by users at creation time. Every different name; may represent a unique volume object, but may also represent more; ge",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:23282,perform,perform,23282,geom/geom/doc/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md,1,['perform'],['perform']
Performance," can be retrieved; using ``getParamElementType()``. This attribute is required in cases where; the intrinsic does not naturally encode a needed element type. This is also; used for inline assembly. Note that some of the methods mentioned above only exist to support both typed; and opaque pointers at the same time, and will be dropped once the migration; has completed. For example, ``isOpaqueOrPointeeTypeEquals()`` becomes; meaningless once all pointers are opaque. While direct usage of pointer element types is immediately apparent in code,; there is a more subtle issue that opaque pointers need to contend with: A lot; of code assumes that pointer equality also implies that the used load/store; type or GEP source element type is the same. Consider the following examples; with typed and opaque pointers:. .. code-block:: llvm. define i32 @test(i32* %p) {; store i32 0, i32* %p; %bc = bitcast i32* %p to i64*; %v = load i64, i64* %bc; ret i64 %v; }. define i32 @test(ptr %p) {; store i32 0, ptr %p; %v = load i64, ptr %p; ret i64 %v; }. Without opaque pointers, a check that the pointer operand of the load and; store are the same also ensures that the accessed type is the same. Using a; different type requires a bitcast, which will result in distinct pointer; operands. With opaque pointers, the bitcast is not present, and this check is no longer; sufficient. In the above example, it could result in store to load forwarding; of an incorrect type. Code making such assumptions needs to be adjusted to; check the accessed type explicitly:; ``LI->getType() == SI->getValueOperand()->getType()``. Frontends; ---------. Frontends need to be adjusted to track pointee types independently of LLVM,; insofar as they are necessary for lowering. For example, clang now tracks the; pointee type in the ``Address`` structure. Frontends using the C API through an FFI interface should be aware that a; number of C API functions are deprecated and will be removed as part of the; opaque pointer transi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/OpaquePointers.rst:9097,load,load,9097,interpreter/llvm-project/llvm/docs/OpaquePointers.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/OpaquePointers.rst,1,['load'],['load']
Performance," can be very impactful. #. Use fast-math flags on floating point operations if legal. If you don't; need strict IEEE floating point semantics, there are a number of additional; optimizations that can be performed. This can be highly impactful for; floating point intensive computations. Describing Aliasing Properties; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. #. Add noalias/align/dereferenceable/nonnull to function arguments and return; values as appropriate. #. Use pointer aliasing metadata, especially tbaa metadata, to communicate; otherwise-non-deducible pointer aliasing facts. #. Use inbounds on geps. This can help to disambiguate some aliasing queries. Undefined Values; ^^^^^^^^^^^^^^^^. #. Use poison values instead of undef values whenever possible. #. Tag function parameters with the noundef attribute whenever possible. Modeling Memory Effects; ^^^^^^^^^^^^^^^^^^^^^^^^. #. Mark functions as readnone/readonly/argmemonly or noreturn/nounwind when; known. The optimizer will try to infer these flags, but may not always be; able to. Manual annotations are particularly important for external; functions that the optimizer can not analyze. #. Use the lifetime.start/lifetime.end and invariant.start/invariant.end; intrinsics where possible. Common profitable uses are for stack like data; structures (thus allowing dead store elimination) and for describing; life times of allocas (thus allowing smaller stack sizes). #. Mark invariant locations using !invariant.load and TBAA's constant flags. Pass Ordering; ^^^^^^^^^^^^^. One of the most common mistakes made by new language frontend projects is to; use the existing -O2 or -O3 pass pipelines as is. These pass pipelines make a; good starting point for an optimizing compiler for any language, but they have; been carefully tuned for C and C++, not your target language. You will almost; certainly need to use a custom pass order to achieve optimal performance. A; couple specific suggestions:. #. For languages with numerous rarely executed ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:11801,optimiz,optimizer,11801,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,1,['optimiz'],['optimizer']
Performance," can cause the; state to change, resulting in a new node in the ExplodedGraph with an; updated program point and an updated state. A bug is found by hitting; a node that satisfies some ""bug condition"" (basically a violation of a; checking invariant). The analyzer traces out multiple paths by reasoning about branches and; then bifurcating the state: on the true branch the conditions of the; branch are assumed to be true and on the false branch the conditions; of the branch are assumed to be false. Such ""assumptions"" create; constraints on the values of the program, and those constraints are; recorded in the ProgramState object (and are manipulated by the; ConstraintManager). If assuming the conditions of a branch would; cause the constraints to be unsatisfiable, the branch is considered; infeasible and that path is not taken. This is how we get; path-sensitivity. We reduce exponential blow-up by caching nodes. If; a new node with the same state and program point as an existing node; would get generated, the path ""caches out"" and we simply reuse the; existing node. Thus the ExplodedGraph is not a DAG; it can contain; cycles as paths loop back onto each other and cache out. ProgramState and ExplodedNodes are basically immutable once created. Once; one creates a ProgramState, you need to create a new one to get a new; ProgramState. This immutability is key since the ExplodedGraph represents; the behavior of the analyzed program from the entry point. To; represent these efficiently, we use functional data structures (e.g.,; ImmutableMaps) which share data between instances. Finally, individual Checkers work by also manipulating the analysis; state. The analyzer engine talks to them via a visitor interface.; For example, the PreVisitCallExpr() method is called by ExprEngine; to tell the Checker that we are about to analyze a CallExpr, and the; checker is asked to check for any preconditions that might not be; satisfied. The checker can do nothing, or it can generate a new;",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/StaticAnalyzer/README.txt:2554,cache,caches,2554,interpreter/llvm-project/clang/lib/StaticAnalyzer/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/StaticAnalyzer/README.txt,1,['cache'],['caches']
Performance," can use ``llvm.ssub.with.overflow``; on any integer bit width or vectors of integers. ::. declare {i16, i1} @llvm.ssub.with.overflow.i16(i16 %a, i16 %b); declare {i32, i1} @llvm.ssub.with.overflow.i32(i32 %a, i32 %b); declare {i64, i1} @llvm.ssub.with.overflow.i64(i64 %a, i64 %b); declare {<4 x i32>, <4 x i1>} @llvm.ssub.with.overflow.v4i32(<4 x i32> %a, <4 x i32> %b). Overview:; """""""""""""""""". The '``llvm.ssub.with.overflow``' family of intrinsic functions perform; a signed subtraction of the two arguments, and indicate whether an; overflow occurred during the signed subtraction. Arguments:; """""""""""""""""""". The arguments (%a and %b) and the first element of the result structure; may be of integer types of any bit width, but they must have the same; bit width. The second element of the result structure must be of type; ``i1``. ``%a`` and ``%b`` are the two values that will undergo signed; subtraction. Semantics:; """""""""""""""""""". The '``llvm.ssub.with.overflow``' family of intrinsic functions perform; a signed subtraction of the two arguments. They return a structure --- the; first element of which is the subtraction, and the second element of; which is a bit specifying if the signed subtraction resulted in an; overflow. Examples:; """""""""""""""""". .. code-block:: llvm. %res = call {i32, i1} @llvm.ssub.with.overflow.i32(i32 %a, i32 %b); %sum = extractvalue {i32, i1} %res, 0; %obit = extractvalue {i32, i1} %res, 1; br i1 %obit, label %overflow, label %normal. '``llvm.usub.with.overflow.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". This is an overloaded intrinsic. You can use ``llvm.usub.with.overflow``; on any integer bit width or vectors of integers. ::. declare {i16, i1} @llvm.usub.with.overflow.i16(i16 %a, i16 %b); declare {i32, i1} @llvm.usub.with.overflow.i32(i32 %a, i32 %b); declare {i64, i1} @llvm.usub.with.overflow.i64(i64 %a, i64 %b); declare {<4 x i32>, <4 x i1>} @llvm.usub.with.overflow.v4i32(<4 x i32> %a, <4 x i32> %b). Overview:; """""""""""""""""".",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:605217,perform,perform,605217,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['perform']
Performance," can use llvm.is.constant with any argument type. ::. declare i1 @llvm.is.constant.i32(i32 %operand) nounwind memory(none); declare i1 @llvm.is.constant.f32(float %operand) nounwind memory(none); declare i1 @llvm.is.constant.TYPENAME(TYPE %operand) nounwind memory(none). Overview:; """""""""""""""""". The '``llvm.is.constant``' intrinsic will return true if the argument; is known to be a manifest compile-time constant. It is guaranteed to; fold to either true or false before generating machine code. Semantics:; """""""""""""""""""". This intrinsic generates no code. If its argument is known to be a; manifest compile-time constant value, then the intrinsic will be; converted to a constant true value. Otherwise, it will be converted to; a constant false value. In particular, note that if the argument is a constant expression; which refers to a global (the address of which _is_ a constant, but; not manifest during the compile), then the intrinsic evaluates to; false. The result also intentionally depends on the result of optimization; passes -- e.g., the result can change depending on whether a; function gets inlined or not. A function's parameters are; obviously not constant. However, a call like; ``llvm.is.constant.i32(i32 %param)`` *can* return true after the; function is inlined, if the value passed to the function parameter was; a constant. .. _int_ptrmask:. '``llvm.ptrmask``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare ptrty llvm.ptrmask(ptrty %ptr, intty %mask) speculatable memory(none). Arguments:; """""""""""""""""""". The first argument is a pointer or vector of pointers. The second argument is; an integer or vector of integers with the same bit width as the index type; size of the first argument. Overview:; """""""""""""""""""". The ``llvm.ptrmask`` intrinsic masks out bits of the pointer according to a mask.; This allows stripping data from tagged pointers without converting them to an; integer (ptrtoint/inttoptr). As a consequence, we can preserve more informat",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:953506,optimiz,optimization,953506,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['optimiz'],['optimization']
Performance," can; cause code to be executed with data inputs that never occur in correct; executions, making checks against malicious inputs ineffective and allowing; attackers to use malicious data inputs to leak secret data. Here is an example,; extracted and simplified from the Project Zero paper:; ```; struct array {; unsigned long length;; unsigned char data[];; };; struct array *arr1 = ...; // small array; struct array *arr2 = ...; // array of size 0x400; unsigned long untrusted_offset_from_caller = ...;; if (untrusted_offset_from_caller < arr1->length) {; unsigned char value = arr1->data[untrusted_offset_from_caller];; unsigned long index2 = ((value&1)*0x100)+0x200;; unsigned char value2 = arr2->data[index2];; }; ```. The key of the attack is to call this with `untrusted_offset_from_caller` that; is far outside of the bounds when the branch predictor will predict that it; will be in-bounds. In that case, the body of the `if` will be executed; speculatively, and may read secret data into `value` and leak it via a; cache-timing side channel when a dependent access is made to populate `value2`. ## High Level Mitigation Approach. While several approaches are being actively pursued to mitigate specific; branches and/or loads inside especially risky software (most notably various OS; kernels), these approaches require manual and/or static analysis aided auditing; of code and explicit source changes to apply the mitigation. They are unlikely; to scale well to large applications. We are proposing a comprehensive; mitigation approach that would apply automatically across an entire program; rather than through manual changes to the code. While this is likely to have a; high performance cost, some applications may be in a good position to take this; performance / security tradeoff. The specific technique we propose is to cause loads to be checked using; branchless code to ensure that they are executing along a valid control flow; path. Consider the following C-pseudo-code representi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:2245,cache,cache-timing,2245,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,1,['cache'],['cache-timing']
Performance," canvas as PNG; 4. TGraph drawing optimization - limit number of drawn points; 5. Implement painter for TPolyMarker3D; 6. Improve drawing and update of TMultiGraph; 7. Reorganize 3D drawing of TH2/TH3 histograms, allow to mix 2D and 3D display together; 8. Support overlay of 3D graphic over SVG canvas (used for IE); 9. Fix problems and improve flex(ible) layout. ## Changes in 4.0; 1. New TGeo classes support:; - browsing through volumes hierarchy; - changing visibility flags; - drawing of selected volumes; 2. New 'flex' layout:; - create frames like in Multi Document Interface; - one could move/resize/minimize/maximize such frames; 3. Significant (factor 4) I/O performance improvement:; - use ArrayBuffer class in HTTP requests instead of String; - use native arrays (like Int32Array) for array data members; - highly optimize streamer infos handling; 4. TH2 drawing optimization:; - if there are too many non-empty bins, combine them together; - when zoom-in, all original bins will be displayed separately; - let draw big TH2 histogram faster than in 1 sec; - optimization can be disabled by providing '&optimize=0' in URL; 5. TF1 drawing optimization:; - function 'compiled' only once; 6. Reorganize scripts structure:; - move all math functions to JSRootMath.js; - TH2, TF1, THStack and TMultiGraph painters moved into JSRootPainter.more.js script; - reduce size of scripts required for default functionality; 7. Update all basic libraries:; - d3.js - v3.5.9,; - jquery.js - v2.1.4,; - jquery-ui.js - v1.11.4,; - three.js - r73; 8. Implement ROOT6-like color palettes:; - all palettes in range 51...112 are implemented; - by default palette 57 is used; - one could change default palette with '&palette=111' in URL; - or palette can be specified in draw option like '&opt=colz,pal77'. ## Changes in 3.9; 1. Support non-equidistant bins for TH1/TH2 objects.; 2. Display entries count from histo.fEntries member, only when not set use computed value; 3. Support italic and bold text when u",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/js/changes.md:59946,optimiz,optimization,59946,js/changes.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/js/changes.md,3,['optimiz'],"['optimization', 'optimize']"
Performance," capability to 2.1</td>`; :raw-html:`</tr>`; :raw-html:`<tr>`; :raw-html:`<td>sm_30</td>`; :raw-html:`<td align=""left"">Set shader model/compute capability to 3.0</td>`; :raw-html:`</tr>`; :raw-html:`<tr>`; :raw-html:`<td>sm_35</td>`; :raw-html:`<td align=""left"">Set shader model/compute capability to 3.5</td>`; :raw-html:`</tr>`; :raw-html:`<tr>`; :raw-html:`<td>ptx30</td>`; :raw-html:`<td align=""left"">Target PTX 3.0</td>`; :raw-html:`</tr>`; :raw-html:`<tr>`; :raw-html:`<td>ptx31</td>`; :raw-html:`<td align=""left"">Target PTX 3.1</td>`; :raw-html:`</tr>`; :raw-html:`</table>`. The extended Berkeley Packet Filter (eBPF) backend; --------------------------------------------------. Extended BPF (or eBPF) is similar to the original (""classic"") BPF (cBPF) used; to filter network packets. The; `bpf() system call <http://man7.org/linux/man-pages/man2/bpf.2.html>`_; performs a range of operations related to eBPF. For both cBPF and eBPF; programs, the Linux kernel statically analyzes the programs before loading; them, in order to ensure that they cannot harm the running system. eBPF is; a 64-bit RISC instruction set designed for one to one mapping to 64-bit CPUs.; Opcodes are 8-bit encoded, and 87 instructions are defined. There are 10; registers, grouped by function as outlined below. ::. R0 return value from in-kernel functions; exit value for eBPF program; R1 - R5 function call arguments to in-kernel functions; R6 - R9 callee-saved registers preserved by in-kernel functions; R10 stack frame pointer (read only). Instruction encoding (arithmetic and jump); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; eBPF is reusing most of the opcode encoding from classic to simplify conversion; of classic BPF to eBPF. For arithmetic and jump instructions the 8-bit 'code'; field is divided into three parts:. ::. +----------------+--------+--------------------+; | 4 bits | 1 bit | 3 bits |; | operation code | source | instruction class |; +----------------+--------+--------------------+; (MSB)",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:102891,load,loading,102891,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst,1,['load'],['loading']
Performance," case when going the other way since the; track has first to exit the extruding node before checking the mother.; In other words, an extrusion behavior is dependent on the track; parameters, which is a highly undesirable effect. B) We will call ***`overlaps`*** only the regions in space contained by; more than one node inside the same container. The owner of such regions; cannot be determined based on hierarchical considerations; therefore; they will be considered as belonging to the node from which the current; track is coming from. When coming from their container, the ownership is totally; unpredictable. Again, the ownership of overlapping regions highly; depends on the current track parameters. We must say that even the overlaps of type A) and B) are allowed in case; the corresponding nodes are created using; **`TGeoVolume`**`::AddNodeOverlap()` method. Navigation is performed in such; cases by giving priority to the non-overlapping nodes. The modeller has; to perform an additional search through the overlapping candidates.; These are detected automatically during the geometry closing procedure; in order to optimize the algorithm, but we will stress that extensive; usage of this feature leads to a drastic deterioration of performance.; In the following we will focus on the non-declared overlaps of type A); and B) since this is the main source of errors during tracking. These; are generally non-intended overlaps due to coding mistakes or bad; geometry design. The checking package is loaded together with the; painter classes and contains an automated overlap checker.**. ![Overlap checking](pictures/030001DF.png). This can be activated both at volume level (checking for illegal; overlaps only one level inside a given volume) and from the geometry; manager level (checking full geometry):. ``` {.cpp}; myVolume->CheckOverlaps(precision, option);; gGeoManager->CheckOverlaps(precision);; myNode->CheckOverlaps(precision);; ```. Here precision represents the desired maxim",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md:131745,perform,perform,131745,documentation/users-guide/Geometry.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md,1,['perform'],['perform']
Performance," cause control flow to transfer to; a specified function, with its incoming arguments bound to the specified; values. Upon a '``ret``' instruction in the called function, control; flow continues with the instruction after the function call, and the; return value of the function is bound to the result argument. Example:; """""""""""""""". .. code-block:: llvm. %retval = call i32 @test(i32 %argc); call i32 (ptr, ...) @printf(ptr %msg, i32 12, i8 42) ; yields i32; %X = tail call i32 @foo() ; yields i32; %Y = tail call fastcc i32 @foo() ; yields i32; call void %foo(i8 signext 97). %struct.A = type { i32, i8 }; %r = call %struct.A @foo() ; yields { i32, i8 }; %gr = extractvalue %struct.A %r, 0 ; yields i32; %gr1 = extractvalue %struct.A %r, 1 ; yields i8; %Z = call void @foo() noreturn ; indicates that %foo never returns normally; %ZZ = call zeroext i32 @bar() ; Return value is %zero extended. llvm treats calls to some functions with names and arguments that match; the standard C99 library as being the C99 library functions, and may; perform optimizations or generate code for them under that assumption.; This is something we'd like to change in the future to provide better; support for freestanding environments and non-C-based languages. .. _i_va_arg:. '``va_arg``' Instruction; ^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. <resultval> = va_arg <va_list*> <arglist>, <argty>. Overview:; """""""""""""""""". The '``va_arg``' instruction is used to access arguments passed through; the ""variable argument"" area of a function call. It is used to implement; the ``va_arg`` macro in C. Arguments:; """""""""""""""""""". This instruction takes a ``va_list*`` value and the type of the; argument. It returns a value of the specified argument type and; increments the ``va_list`` to point to the next argument. The actual; type of ``va_list`` is target specific. Semantics:; """""""""""""""""""". The '``va_arg``' instruction loads an argument of the specified type; from the specified ``va_list`` and causes the ``va_list`` to",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:478818,perform,perform,478818,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,2,"['optimiz', 'perform']","['optimizations', 'perform']"
Performance," chapter (see; ""Linear Algebra in ROOT""). `SMatrix` is a C++ package, for high; performance vector and matrix computations. It has been introduced in; ROOT v5.08. It is optimized for describing small matrices and vectors; and It can be used only in problems when the size of the matrices is; known at compile time, like in the tracking reconstruction of physics; experiments. It is based on a C++ technique, called expression; templates, to achieve an high level optimization. The C++ templates can; be used to implement vector and matrix expressions such that these; expressions can be transformed at compile time to code which is; equivalent to hand optimized code in a low-level language like FORTRAN; or C (see for example T. Veldhuizen, Expression Templates, C++ Report,; 1995). The `SMatrix` has been developed initially by T. Glebe in; Max-Planck-Institut, Heidelberg, as part of the `HeraB` analysis; framework. A subset of the original package has been now incorporated in; the ROOT distribution, with the aim to provide a stand-alone and high; performance matrix package. The API of the current package differs from; the original one, in order to be compliant to the ROOT coding; conventions. `SMatrix` contains the generic **`ROOT::Math::SMatrix`** and; **`ROOT::Math::SVector`** classes for describing matrices and vectors of; arbitrary dimensions and of arbitrary type. The classes are templated on; the scalar type and on the size, like number of rows and columns for a; matrix . Therefore, the matrix/vector dimension has to be known at; compile time. An advantage of using the dimension as template parameters; is that the correctness of dimension in the matrix/vector operations can; be checked at compile time. `SMatrix` supports, since ROOT v5.10, symmetric matrices using a storage; class (**`ROOT::Math::MatRepSym`**) which contains only the `N*(N+1)/2`; independent element of a `NxN` symmetric matrix. It is not in the; mandate of this package to provide complete linear algebr",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/MathLibraries.md:100039,perform,performance,100039,documentation/users-guide/MathLibraries.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/MathLibraries.md,1,['perform'],['performance']
Performance, clang-tools-extra/clang-tidy/objc/SuperSelfCheck.cpp; clang-tools-extra/clang-tidy/objc/SuperSelfCheck.h; clang-tools-extra/clang-tidy/openmp/ExceptionEscapeCheck.cpp; clang-tools-extra/clang-tidy/openmp/ExceptionEscapeCheck.h; clang-tools-extra/clang-tidy/openmp/OpenMPTidyModule.cpp; clang-tools-extra/clang-tidy/openmp/UseDefaultNoneCheck.cpp; clang-tools-extra/clang-tidy/openmp/UseDefaultNoneCheck.h; clang-tools-extra/clang-tidy/performance/FasterStringFindCheck.cpp; clang-tools-extra/clang-tidy/performance/ForRangeCopyCheck.cpp; clang-tools-extra/clang-tidy/performance/InefficientAlgorithmCheck.cpp; clang-tools-extra/clang-tidy/performance/InefficientAlgorithmCheck.h; clang-tools-extra/clang-tidy/performance/InefficientStringConcatenationCheck.cpp; clang-tools-extra/clang-tidy/performance/InefficientStringConcatenationCheck.h; clang-tools-extra/clang-tidy/performance/MoveConstArgCheck.cpp; clang-tools-extra/clang-tidy/performance/MoveConstArgCheck.h; clang-tools-extra/clang-tidy/performance/MoveConstructorInitCheck.cpp; clang-tools-extra/clang-tidy/performance/MoveConstructorInitCheck.h; clang-tools-extra/clang-tidy/performance/NoAutomaticMoveCheck.cpp; clang-tools-extra/clang-tidy/performance/NoAutomaticMoveCheck.h; clang-tools-extra/clang-tidy/performance/NoexceptMoveConstructorCheck.cpp; clang-tools-extra/clang-tidy/performance/NoexceptMoveConstructorCheck.h; clang-tools-extra/clang-tidy/performance/NoIntToPtrCheck.cpp; clang-tools-extra/clang-tidy/performance/NoIntToPtrCheck.h; clang-tools-extra/clang-tidy/performance/PerformanceTidyModule.cpp; clang-tools-extra/clang-tidy/performance/TriviallyDestructibleCheck.cpp; clang-tools-extra/clang-tidy/performance/TriviallyDestructibleCheck.h; clang-tools-extra/clang-tidy/performance/TypePromotionInMathFnCheck.cpp; clang-tools-extra/clang-tidy/performance/TypePromotionInMathFnCheck.h; clang-tools-extra/clang-tidy/performance/UnnecessaryCopyInitialization.cpp; clang-tools-extra/clang-tidy/performance/UnnecessaryValueP,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt:65267,perform,performance,65267,interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,1,['perform'],['performance']
Performance, clang-tools-extra/clang-tidy/performance/InefficientAlgorithmCheck.h; clang-tools-extra/clang-tidy/performance/InefficientStringConcatenationCheck.cpp; clang-tools-extra/clang-tidy/performance/InefficientStringConcatenationCheck.h; clang-tools-extra/clang-tidy/performance/MoveConstArgCheck.cpp; clang-tools-extra/clang-tidy/performance/MoveConstArgCheck.h; clang-tools-extra/clang-tidy/performance/MoveConstructorInitCheck.cpp; clang-tools-extra/clang-tidy/performance/MoveConstructorInitCheck.h; clang-tools-extra/clang-tidy/performance/NoAutomaticMoveCheck.cpp; clang-tools-extra/clang-tidy/performance/NoAutomaticMoveCheck.h; clang-tools-extra/clang-tidy/performance/NoexceptMoveConstructorCheck.cpp; clang-tools-extra/clang-tidy/performance/NoexceptMoveConstructorCheck.h; clang-tools-extra/clang-tidy/performance/NoIntToPtrCheck.cpp; clang-tools-extra/clang-tidy/performance/NoIntToPtrCheck.h; clang-tools-extra/clang-tidy/performance/PerformanceTidyModule.cpp; clang-tools-extra/clang-tidy/performance/TriviallyDestructibleCheck.cpp; clang-tools-extra/clang-tidy/performance/TriviallyDestructibleCheck.h; clang-tools-extra/clang-tidy/performance/TypePromotionInMathFnCheck.cpp; clang-tools-extra/clang-tidy/performance/TypePromotionInMathFnCheck.h; clang-tools-extra/clang-tidy/performance/UnnecessaryCopyInitialization.cpp; clang-tools-extra/clang-tidy/performance/UnnecessaryValueParamCheck.cpp; clang-tools-extra/clang-tidy/performance/UnnecessaryValueParamCheck.h; clang-tools-extra/clang-tidy/plugin/ClangTidyPlugin.cpp; clang-tools-extra/clang-tidy/portability/PortabilityTidyModule.cpp; clang-tools-extra/clang-tidy/portability/RestrictSystemIncludesCheck.cpp; clang-tools-extra/clang-tidy/portability/SIMDIntrinsicsCheck.cpp; clang-tools-extra/clang-tidy/readability/AvoidConstParamsInDecls.h; clang-tools-extra/clang-tidy/readability/BracesAroundStatementsCheck.cpp; clang-tools-extra/clang-tidy/readability/BracesAroundStatementsCheck.h; clang-tools-extra/clang-tidy/readability/Cons,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt:65877,perform,performance,65877,interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,1,['perform'],['performance']
Performance," clearer structure. This fixes several; bugs which have been reported by some users of TMVA.; Code and performance test framework: A unit; test framework for daily software and method performance; validation has been implemented.; . Methods. BDT Automatic parameter optimisation for building the; tree architecture: The optimisation procedure uses the; performance of the trained classifier on the ""test sample"" for; finding the set of optimal parameters. Two different methods to; traverse the parameter space are available (scanning, genetic; algorithm). Currently parameter optimization is implemented only; for these three parameters that influence the tree architectur:; the maximum depth of a tree, MaxDepth, the minimum; number of events in each node, NodeMinEvents, and; the number of tress, NTrees. Optimization can; is invoked by calling; factory->OptimizeAllMethods(); prior to the call; factory->TrainAllMethods();. Automated and configurable parameter optimization is soon to; be enabled for all methods (for those parameters where; optimization is applicable).; . BDT node splitting: While Decision Trees; typically have only univariate splits, in TMVA one can now; also opt for multivariate splits that use a ""Fisher; Discriminant"" (option: UseFisherCuts), built from all; observables that show correlations larger than some threshold; (MinLinCorrForFisher). The training will then test at each; split a cut on this fisher discriminant in addition to all; univariate cuts on the variables (or only on those variables; that have not been used in the Fisher discriminant, option; UseExcusiveVars). No obvious improvement betwen very simple; decision trees after boosting has been observed so far, but; only a limited number of studies has been performed concerning; potiential benenfit of these simple multivariate splits.; . Bug fixes. A problem in the BDTG has been fixed, leading to a much; improved regression performance.; A problem in the TMVA::Reader has been fixed.; With the new ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v528/index.html:2280,optimiz,optimization,2280,tmva/doc/v528/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v528/index.html,4,['optimiz'],['optimization']
Performance," code for this function at -O2 or -Os:. void foo(signed char* p) {; if (*p == 3); bar();; else if (*p == 4); baz();; else if (*p == 5); quux();; }. llvm decides it's a good idea to turn the repeated if...else into a; binary tree, as if it were a switch; the resulting code requires -1; compare-and-branches when *p<=2 or *p==5, the same number if *p==4; or *p>6, and +1 if *p==3. So it should be a speed win; (on balance). However, the revised code is larger, with 4 conditional; branches instead of 3. More seriously, there is a byte->word extend before; each comparison, where there should be only one, and the condition codes; are not remembered when the same two values are compared twice. //===---------------------------------------------------------------------===//. More LSR enhancements possible:. 1. Teach LSR about pre- and post- indexed ops to allow iv increment be merged; in a load / store.; 2. Allow iv reuse even when a type conversion is required. For example, i8; and i32 load / store addressing modes are identical. //===---------------------------------------------------------------------===//. This:. int foo(int a, int b, int c, int d) {; long long acc = (long long)a * (long long)b;; acc += (long long)c * (long long)d;; return (int)(acc >> 32);; }. Should compile to use SMLAL (Signed Multiply Accumulate Long) which multiplies; two signed 32-bit values to produce a 64-bit value, and accumulates this with; a 64-bit value. We currently get this with both v4 and v6:. _foo:; smull r1, r0, r1, r0; smull r3, r2, r3, r2; adds r3, r3, r1; adc r0, r2, r0; bx lr. //===---------------------------------------------------------------------===//. This:; #include <algorithm>; std::pair<unsigned, bool> full_add(unsigned a, unsigned b); { return std::make_pair(a + b, a + b < a); }; bool no_overflow(unsigned a, unsigned b); { return !full_add(a, b).second; }. Should compile to:. _Z8full_addjj:; 	adds	r2, r1, r2; 	movcc	r1, #0; 	movcs	r1, #1; 	str	r2, [r0, #0]; 	strb	r1, [r0, #4]",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/README.txt:12623,load,load,12623,interpreter/llvm-project/llvm/lib/Target/ARM/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/README.txt,2,['load'],['load']
Performance," code from the original to the instrumentation version; by tracing the LLVM-to-Machine code basic block map and then copying; each machine code basic block we think is in the hot region into the; trace cache. Then we instrument that code. The process is similar for; generating the final optimized trace; we copy the same basic blocks; because we might need to put in fixup code for exit BBs. LLVM basic blocks are not typically used in the Reoptimizer except; for the mapping information. We are restricted to using single instructions to branch between the; original code, trace, and instrumented code. So we have to keep the; code copies in memory near the original code (they can't be far enough; away that a single pc-relative branch would not work.) Malloc() or; data region space is too far away. this impacts the design of the ; trace cache. We use a dummy function that is full of a bunch of for loops which we; overwrite with trace-cache code. The trace manager keeps track of; whether or not we have enough space in the trace cache, etc. The trace insertion routine takes an original start address, a vector; of machine instructions representing the trace, index of branches and; their corresponding absolute targets, and index of calls and their; corresponding absolute targets. The trace insertion routine is responsible for inserting branches from; the beginning of the original code to the beginning of the optimized; trace. This is because at some point the trace cache may run out of; space and it may have to evict a trace, at which point the branch to; the trace would also have to be removed. It uses a round-robin; replacement policy; we have found that this is almost as good as LRU; and better than random (especially because of problems fitting the new; trace in.). We cannot deal with discontiguous trace cache areas. The trace cache; is supposed to be cache-line-aligned, but it is not page-aligned. We generate instrumentation traces and optimized traces into separate; trac",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2003-06-25-Reoptimizer1.txt:4909,cache,cache,4909,interpreter/llvm-project/llvm/docs/HistoricalNotes/2003-06-25-Reoptimizer1.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2003-06-25-Reoptimizer1.txt,1,['cache'],['cache']
Performance," code with ""clang; -emit-llvm-bc | opt -O3"". //===---------------------------------------------------------------------===//. unsigned a(unsigned long long x) {return 40 * (x >> 1);}; Should combine to ""20 * (((unsigned)x) & -2)"". Currently not; optimized with ""clang -emit-llvm-bc | opt -O3"". //===---------------------------------------------------------------------===//. int g(int x) { return (x - 10) < 0; }; Should combine to ""x <= 9"" (the sub has nsw). Currently not; optimized with ""clang -emit-llvm-bc | opt -O3"". //===---------------------------------------------------------------------===//. int g(int x) { return (x + 10) < 0; }; Should combine to ""x < -10"" (the add has nsw). Currently not; optimized with ""clang -emit-llvm-bc | opt -O3"". //===---------------------------------------------------------------------===//. int f(int i, int j) { return i < j + 1; }; int g(int i, int j) { return j > i - 1; }; Should combine to ""i <= j"" (the add/sub has nsw). Currently not; optimized with ""clang -emit-llvm-bc | opt -O3"". //===---------------------------------------------------------------------===//. unsigned f(unsigned x) { return ((x & 7) + 1) & 15; }; The & 15 part should be optimized away, it doesn't change the result. Currently; not optimized with ""clang -emit-llvm-bc | opt -O3"". //===---------------------------------------------------------------------===//. This was noticed in the entryblock for grokdeclarator in 403.gcc:. %tmp = icmp eq i32 %decl_context, 4 ; %decl_context_addr.0 = select i1 %tmp, i32 3, i32 %decl_context ; %tmp1 = icmp eq i32 %decl_context_addr.0, 1 ; %decl_context_addr.1 = select i1 %tmp1, i32 0, i32 %decl_context_addr.0. tmp1 should be simplified to something like:; (!tmp || decl_context == 1). This allows recursive simplifications, tmp1 is used all over the place in; the function, e.g. by:. %tmp23 = icmp eq i32 %decl_context_addr.1, 0 ; <i1> [#uses=1]; %tmp24 = xor i1 %tmp1, true ; <i1> [#uses=1]; %or.cond8 = and i1 %tmp23, %tmp24 ; <i1> [#us",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/README.txt:27266,optimiz,optimized,27266,interpreter/llvm-project/llvm/lib/Target/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/README.txt,2,['optimiz'],['optimized']
Performance," code-block:: c++. template<typename T> T twice(T t) {; return 2 * t;; }. #pragma clang optimize off; template<typename T> T thrice(T t) {; return 3 * t;; }. int container(int a, int b) {; return twice(a) + thrice(b);; }; #pragma clang optimize on. In this example, the definition of the template function ``twice`` is outside; the pragma region, whereas the definition of ``thrice`` is inside the region.; The ``container`` function is also in the region and will not be optimized, but; it causes the instantiation of ``twice`` and ``thrice`` with an ``int`` type; of; these two instantiations, ``twice`` will be optimized (because its definition; was outside the region) and ``thrice`` will not be optimized. Clang also implements MSVC's range-based pragma,; ``#pragma optimize(""[optimization-list]"", on | off)``. At the moment, Clang only; supports an empty optimization list, whereas MSVC supports the arguments, ``s``,; ``g``, ``t``, and ``y``. Currently, the implementation of ``pragma optimize`` behaves; the same as ``#pragma clang optimize``. All functions; between ``off`` and ``on`` will be decorated with the ``optnone`` attribute. .. code-block:: c++. #pragma optimize("""", off); // This function will be decorated with optnone.; void f1() {}. #pragma optimize("""", on); // This function will be optimized with whatever was specified on; // the commandline.; void f2() {}. // This will warn with Clang's current implementation.; #pragma optimize(""g"", on); void f3() {}. For MSVC, an empty optimization list and ``off`` parameter will turn off; all optimizations, ``s``, ``g``, ``t``, and ``y``. An empty optimization and; ``on`` parameter will reset the optimizations to the ones specified on the; commandline. .. list-table:: Parameters (unsupported by Clang). * - Parameter; - Type of optimization; * - g; - Deprecated; * - s or t; - Short or fast sequences of machine code; * - y; - Enable frame pointers. Extensions for loop hint optimizations; ======================================. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst:161286,optimiz,optimize,161286,interpreter/llvm-project/clang/docs/LanguageExtensions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst,2,['optimiz'],['optimize']
Performance," code-block:: llvm. entry:; ..; br i1 true, label %foo, label %bar; foo:; ..; bar:; ; Dead code; .. Therefore, it is recommended that ``NVVMReflect`` is executed early in the; optimization pipeline before dead-code elimination. The NVPTX TargetMachine knows how to schedule ``NVVMReflect`` at the beginning; of your pass manager; just use the following code when setting up your pass; manager and the PassBuilder will use ``registerPassBuilderCallbacks`` to let; NVPTXTargetMachine::registerPassBuilderCallbacks add the pass to the; pass manager:. .. code-block:: c++. std::unique_ptr<TargetMachine> TM = ...;; PassBuilder PB(TM);; ModulePassManager MPM;; PB.parsePassPipeline(MPM, ...);. Reflection Parameters; ---------------------. The libdevice library currently uses the following reflection parameters to; control code generation:. ==================== ======================================================; Flag Description; ==================== ======================================================; ``__CUDA_FTZ=[0,1]`` Use optimized code paths that flush subnormals to zero; ==================== ======================================================. The value of this flag is determined by the ""nvvm-reflect-ftz"" module flag.; The following sets the ftz flag to 1. .. code-block:: llvm. !llvm.module.flag = !{!0}; !0 = !{i32 4, !""nvvm-reflect-ftz"", i32 1}. (``i32 4`` indicates that the value set here overrides the value in another; module we link with. See the `LangRef <LangRef.html#module-flags-metadata>`; for details.). Executing PTX; =============. The most common way to execute PTX assembly on a GPU device is to use the CUDA; Driver API. This API is a low-level interface to the GPU driver and allows for; JIT compilation of PTX code to native GPU machine code. Initializing the Driver API:. .. code-block:: c++. CUdevice device;; CUcontext context;. // Initialize the driver API; cuInit(0);; // Get a handle to the first compute device; cuDeviceGet(&device, 0);; // Create a ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/NVPTXUsage.rst:10697,optimiz,optimized,10697,interpreter/llvm-project/llvm/docs/NVPTXUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/NVPTXUsage.rst,1,['optimiz'],['optimized']
Performance," code. .. code-block:: text. a: store undef -> %X; b: store %X -> undef; Safe:; a: <deleted> (if the stored value in %X is provably not poison); b: unreachable. A store *of* an undefined value can be assumed to not have any effect;; we can assume that the value is overwritten with bits that happen to; match what was already there. This argument is only valid if the stored value; is provably not ``poison``. However, a store *to* an undefined; location could clobber arbitrary memory, therefore, it has undefined; behavior. Branching on an undefined value is undefined behavior.; This explains optimizations that depend on branch conditions to construct; predicates, such as Correlated Value Propagation and Global Value Numbering.; In case of switch instruction, the branch condition should be frozen, otherwise; it is undefined behavior. .. code-block:: llvm. Unsafe:; br undef, BB1, BB2 ; UB. %X = and i32 undef, 255; switch %X, label %ret [ .. ] ; UB. store undef, ptr %ptr; %X = load ptr %ptr ; %X is undef; switch i8 %X, label %ret [ .. ] ; UB. Safe:; %X = or i8 undef, 255 ; always 255; switch i8 %X, label %ret [ .. ] ; Well-defined. %X = freeze i1 undef; br %X, BB1, BB2 ; Well-defined (non-deterministic jump). .. _poisonvalues:. Poison Values; -------------. A poison value is a result of an erroneous operation.; In order to facilitate speculative execution, many instructions do not; invoke immediate undefined behavior when provided with illegal operands,; and return a poison value instead.; The string '``poison``' can be used anywhere a constant is expected, and; operations such as :ref:`add <i_add>` with the ``nsw`` flag can produce; a poison value. Most instructions return '``poison``' when one of their arguments is; '``poison``'. A notable exception is the :ref:`select instruction <i_select>`.; Propagation of poison can be stopped with the; :ref:`freeze instruction <i_freeze>`. It is correct to replace a poison value with an; :ref:`undef value <undefvalues>` or any valu",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:196452,load,load,196452,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['load'],['load']
Performance," coherence and instead use it to; indicate if the instruction returns the original value being updated. They; do use sc1 to indicate system or agent scope coherence. * The scalar memory operations access a scalar L1 cache shared by all wavefronts; on a group of CUs. The scalar and vector L1 caches are not coherent. However,; scalar operations are used in a restricted way so do not impact the memory; model. See :ref:`amdgpu-amdhsa-memory-spaces`.; * The vector and scalar memory operations use an L2 cache. * The gfx942 can be configured as a number of smaller agents with each having; a single L2 shared by all CUs on the same agent, or as fewer (possibly one); larger agents with groups of CUs on each agent each sharing separate L2; caches.; * The L2 cache has independent channels to service disjoint ranges of virtual; addresses.; * Each CU has a separate request queue per channel for its associated L2.; Therefore, the vector and scalar memory operations performed by wavefronts; executing with different L1 caches and the same L2 cache can be reordered; relative to each other.; * A ``s_waitcnt vmcnt(0)`` is required to ensure synchronization between; vector memory operations of different CUs. It ensures a previous vector; memory operation has completed before executing a subsequent vector memory; or LDS operation and so can be used to meet the requirements of acquire and; release.; * An L2 cache can be kept coherent with other L2 caches by using the MTYPE RW; (read-write) for memory local to the L2, and MTYPE NC (non-coherent) with; the PTE C-bit set for memory not local to the L2. * Any local memory cache lines will be automatically invalidated by writes; from CUs associated with other L2 caches, or writes from the CPU, due to; the cache probe caused by the PTE C-bit.; * XGMI accesses from the CPU to local memory may be cached on the CPU.; Subsequent access from the GPU will automatically invalidate or writeback; the CPU cache due to the L2 probe filter.; * To ensure co",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:287752,perform,performed,287752,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,3,"['cache', 'perform']","['cache', 'caches', 'performed']"
Performance," command option; ``-all-stats`` or ``-dispatch-stats``. The next table, *Schedulers*, presents a histogram displaying a count,; representing the number of micro opcodes issued on some number of cycles. In; this case, of the 610 simulated cycles, single opcodes were issued 306 times; (50.2%) and there were 7 cycles where no opcodes were issued. The *Scheduler's queue usage* table shows that the average and maximum number of; buffer entries (i.e., scheduler queue entries) used at runtime. Resource JFPU01; reached its maximum (18 of 18 queue entries). Note that AMD Jaguar implements; three schedulers:. * JALU01 - A scheduler for ALU instructions.; * JFPU01 - A scheduler floating point operations.; * JLSAGU - A scheduler for address generation. The dot-product is a kernel of three floating point instructions (a vector; multiply followed by two horizontal adds). That explains why only the floating; point scheduler appears to be used. A full scheduler queue is either caused by data dependency chains or by a; sub-optimal usage of hardware resources. Sometimes, resource pressure can be; mitigated by rewriting the kernel using different instructions that consume; different scheduler resources. Schedulers with a small queue are less resilient; to bottlenecks caused by the presence of long data dependencies. The scheduler; statistics are displayed by using the command option ``-all-stats`` or; ``-scheduler-stats``. The next table, *Retire Control Unit*, presents a histogram displaying a count,; representing the number of instructions retired on some number of cycles. In; this case, of the 610 simulated cycles, two instructions were retired during the; same cycle 399 times (65.4%) and there were 109 cycles where no instructions; were retired. The retire statistics are displayed by using the command option; ``-all-stats`` or ``-retire-stats``. The last table presented is *Register File statistics*. Each physical register; file (PRF) used by the pipeline is presented in this tabl",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:31910,queue,queue,31910,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,1,['queue'],['queue']
Performance," commands at the shell prompt and in the; interactive ROOT shell, respectively:. ``` {.cpp}; > root conductivity_experiment.root; Attaching file conductivity_experiment.root as _file0...; root [0] cond_data->Draw(""Current:Potential""); ```. You just produced a correlation plot with one single line of code!. Try to extend the syntax typing for example. ``` {.cpp}; root [1] cond_data->Draw(""Current:Potential"",""Temperature<270""); ```. What do you obtain ?. Now try. ``` {.cpp}; root [2] cond_data->Draw(""Current/Potential:Temperature""); ```. It should have become clear from these examples how to navigate in such; a multi-dimensional space of variables and unveil relations between; variables using n-tuples. ### Reading N-tuples. For completeness, you find here a small macro to read the data back from; a ROOT n-tuple. ``` {.cpp}; @ROOT_INCLUDE_FILE macros/read_ntuple_from_file.C; ```. The macro shows the easiest way of accessing the content of a n-tuple:; after loading the n-tuple, its branches are assigned to variables and; `GetEntry(long)` automatically fills them with the content for a; specific row. By doing so, the logic for reading the n-tuple and the; code to process it can be split and the source code remains clear. ### Storing Arbitrary N-tuples ###. It is also possible to write n-tuples of arbitrary type by using ROOT's; `TBranch` class. This is especially important as `TNtuple::Fill()`; accepts only floats. The following macro creates the same n-tuple as; before but the branches are booked directly. The `Fill()` function then; fills the current values of the connected variables to the tree. ``` {.cpp}; @ROOT_INCLUDE_FILE macros/write_ntuple_to_file_advanced.C; ```. The `Branch()` function requires a pointer to a variable and a; definition of the variable type. The following table lists some of the possible; values.; Please note that ROOT is not checking the input and mistakes are likely; to result in serious problems. This holds especially if values are read; as a",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/primer/filio.md:4229,load,loading,4229,documentation/primer/filio.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/primer/filio.md,1,['load'],['loading']
Performance," compiler when the a definition of; a symbol is needed. ORC is actually fully language agnostic: LLVM IR is not; treated specially, and is supported via the same wrapper mechanism (the; ``MaterializationUnit`` class) that is used for custom compilers. **Concurrent JIT'd code** and **Concurrent Compilation**; JIT'd code may be executed in multiple threads, may spawn new threads, and may; re-enter the ORC (e.g. to request lazy compilation) concurrently from multiple; threads. Compilers launched my ORC can run concurrently (provided the client; sets up an appropriate dispatcher). Built-in dependency tracking ensures that; ORC does not release pointers to JIT'd code or data until all dependencies; have also been JIT'd and they are safe to call or use. **Removable Code**; Resources for JIT'd program representations. **Orthogonality** and **Composability**; Each of the features above can be used independently. It is possible to put; ORC components together to make a non-lazy, in-process, single threaded JIT; or a lazy, out-of-process, concurrent JIT, or anything in between. LLJIT and LLLazyJIT; ===================. ORC provides two basic JIT classes off-the-shelf. These are useful both as; examples of how to assemble ORC components to make a JIT, and as replacements; for earlier LLVM JIT APIs (e.g. MCJIT). The LLJIT class uses an IRCompileLayer and RTDyldObjectLinkingLayer to support; compilation of LLVM IR and linking of relocatable object files. All operations; are performed eagerly on symbol lookup (i.e. a symbol's definition is compiled; as soon as you attempt to look up its address). LLJIT is a suitable replacement; for MCJIT in most cases (note: some more advanced features, e.g.; JITEventListeners are not supported yet). The LLLazyJIT extends LLJIT and adds a CompileOnDemandLayer to enable lazy; compilation of LLVM IR. When an LLVM IR module is added via the addLazyIRModule; method, function bodies in that module will not be compiled until they are first; called. LLL",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ORCv2.rst:3516,concurren,concurrent,3516,interpreter/llvm-project/llvm/docs/ORCv2.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ORCv2.rst,1,['concurren'],['concurrent']
Performance," completed before; performing the; following; fence-paired-atomic. fence release - system *none* 1. buffer_wbl2. - If OpenCL and; address space is; local, omit.; - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at system scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - If OpenCL and; address space is; local, omit; vmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate. If; fence had an; address space then; set to address; space of OpenCL; fence flag, or to; generic if both; local and global; flags are; specified.; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; any following store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Ensures that all; memory operations; have; completed before; performing the; following; fence-paired-atomic. **Acquire-Release Atomic**; ------------------------------------------------------------------------------------; atomicrmw acq_rel - singlethread - global 1. buffer/global/flat_atomic; - wavefront - generic; atomicrmw acq_rel - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; be used.*. 1. ds_atomic; atomicrmw acq_rel - workgroup - global 1. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:265662,load,load,265662,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],['load']
Performance," computed dividing the total number of simulated instructions by the total; number of cycles. Field *Block RThroughput* is the reciprocal of the block throughput. Block; throughput is a theoretical quantity computed as the maximum number of blocks; (i.e. iterations) that can be executed per simulated clock cycle in the absence; of loop carried dependencies. Block throughput is superiorly limited by the; dispatch rate, and the availability of hardware resources. In the absence of loop-carried data dependencies, the observed IPC tends to a; theoretical maximum which can be computed by dividing the number of instructions; of a single iteration by the `Block RThroughput`. Field 'uOps Per Cycle' is computed dividing the total number of simulated micro; opcodes by the total number of cycles. A delta between Dispatch Width and this; field is an indicator of a performance issue. In the absence of loop-carried; data dependencies, the observed 'uOps Per Cycle' should tend to a theoretical; maximum throughput which can be computed by dividing the number of uOps of a; single iteration by the `Block RThroughput`. Field *uOps Per Cycle* is bounded from above by the dispatch width. That is; because the dispatch width limits the maximum size of a dispatch group. Both IPC; and 'uOps Per Cycle' are limited by the amount of hardware parallelism. The; availability of hardware resources affects the resource pressure distribution,; and it limits the number of instructions that can be executed in parallel every; cycle. A delta between Dispatch Width and the theoretical maximum uOps per; Cycle (computed by dividing the number of uOps of a single iteration by the; `Block RThroughput`) is an indicator of a performance bottleneck caused by the; lack of hardware resources.; In general, the lower the Block RThroughput, the better. In this example, ``uOps per iteration/Block RThroughput`` is 1.50. Since there; are no loop-carried dependencies, the observed `uOps Per Cycle` is expected to; approa",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:17186,throughput,throughput,17186,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,1,['throughput'],['throughput']
Performance," consecutive; floating-point numbers ``a`` and ``b``, without being equal to one; of them, then ``ulp(x) = |b - a|``, otherwise ``ulp(x)`` is the; distance between the two non-equal finite floating-point numbers; nearest ``x``. Moreover, ``ulp(NaN)`` is ``NaN``. The metadata node shall consist of a single positive float type number; representing the maximum relative error, for example:. .. code-block:: llvm. !0 = !{ float 2.5 } ; maximum acceptable inaccuracy is 2.5 ULPs. .. _range-metadata:. '``range``' Metadata; ^^^^^^^^^^^^^^^^^^^^. ``range`` metadata may be attached only to ``load``, ``call`` and ``invoke`` of; integer or vector of integer types. It expresses the possible ranges the loaded; value or the value returned by the called function at this call site is in. If; the loaded or returned value is not in the specified range, a poison value is; returned instead. The ranges are represented with a flattened list of integers.; The loaded value or the value returned is known to be in the union of the ranges; defined by each consecutive pair. Each pair has the following properties:. - The type must match the scalar type of the instruction.; - The pair ``a,b`` represents the range ``[a,b)``.; - Both ``a`` and ``b`` are constants.; - The range is allowed to wrap.; - The range should not represent the full or empty set. That is,; ``a!=b``. In addition, the pairs must be in signed order of the lower bound and; they must be non-contiguous. For vector-typed instructions, the range is applied element-wise. Examples:. .. code-block:: llvm. %a = load i8, ptr %x, align 1, !range !0 ; Can only be 0 or 1; %b = load i8, ptr %y, align 1, !range !1 ; Can only be 255 (-1), 0 or 1; %c = call i8 @foo(), !range !2 ; Can only be 0, 1, 3, 4 or 5; %d = invoke i8 @bar() to label %cont; unwind label %lpad, !range !3 ; Can only be -2, -1, 3, 4 or 5; %e = load <2 x i8>, ptr %x, !range 0 ; Can only be <0 or 1, 0 or 1>; ...; !0 = !{ i8 0, i8 2 }; !1 = !{ i8 255, i8 2 }; !2 = !{ i8 0, i8 2, i8 ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:285184,load,loaded,285184,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['load'],['loaded']
Performance," constant folding for nodes that take the same number; of arguments as your new node. #. ``lib/CodeGen/SelectionDAG/LegalizeDAG.cpp``:. Add code to `legalize, promote, and expand; <CodeGenerator.html#selectiondag_legalize>`_ the node as necessary. At a; minimum, you will need to add a case statement for your node in; ``LegalizeOp`` which calls LegalizeOp on the node's operands, and returns a; new node if any of the operands changed as a result of being legalized. It; is likely that not all targets supported by the SelectionDAG framework will; natively support the new node. In this case, you must also add code in your; node's case statement in ``LegalizeOp`` to Expand your node into simpler,; legal operations. The case for ``ISD::UREM`` for expanding a remainder into; a divide, multiply, and a subtract is a good example. #. ``lib/CodeGen/SelectionDAG/LegalizeDAG.cpp``:. If targets may support the new node being added only at certain sizes, you; will also need to add code to your node's case statement in ``LegalizeOp``; to Promote your node's operands to a larger size, and perform the correct; operation. You will also need to add code to ``PromoteOp`` to do this as; well. For a good example, see ``ISD::BSWAP``, which promotes its operand to; a wider size, performs the byteswap, and then shifts the correct bytes right; to emulate the narrower byteswap in the wider type. #. ``lib/CodeGen/SelectionDAG/LegalizeDAG.cpp``:. Add a case for your node in ``ExpandOp`` to teach the legalizer how to; perform the action represented by the new node on a value that has been split; into high and low halves. This case will be used to support your node with a; 64 bit operand on a 32 bit target. #. ``lib/CodeGen/SelectionDAG/DAGCombiner.cpp``:. If your node can be combined with itself, or other existing nodes in a; peephole-like fashion, add a visit function for it, and call that function; from. There are several good examples for simple combines you can do;; ``visitFABS`` and ``visitSR",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExtendingLLVM.rst:5489,perform,perform,5489,interpreter/llvm-project/llvm/docs/ExtendingLLVM.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExtendingLLVM.rst,1,['perform'],['perform']
Performance," construct-expression.; Apart from the technical difficulties of juggling program points around; correctly to avoid accidentally merging paths together, we'll have to; be a judge on when to exit the loop and how to widen it.; Given that the constructor is going to be a default constructor,; a nice 95% solution might be to execute exactly one constructor and; then default-bind the resulting LazyCompoundVal to the whole array;; it'll work whenever the default constructor doesn't touch global state; but only initializes the object to various default values.; But if, say, we're making an array of strings,; depending on the implementation you might have to allocate a new buffer; for each string, and in this case default-binding won't cut it.; We might want to come up with an auxiliary analysis in order to perform; widening of these simple loops more precisely.; . Handle constructors that can be elided due to Named Return Value Optimization (NRVO); Local variables which are returned by values on all return statements; may be stored directly at the address for the return value,; eliding the copy or move constructor call.; Such variables can be identified using the AST call VarDecl::isNRVOVariable.; . Handle constructors of lambda captures; Variables which are captured by value into a lambda require a call to; a copy constructor.; This call is not currently modeled.; . Handle constructors for default arguments; Default arguments in C++ are recomputed at every call,; and are therefore local, and not static, variables.; See tests cases in handle_constructors_for_default_arguments.cpp.; . Default arguments are annoying because the initializer expression is; evaluated at the call site but doesn't syntactically belong to the; caller's AST; instead it belongs to the ParmVarDecl for the default; parameter. This can lead to situations when the same expression has to; carry different values simultaneously -; when multiple instances of the same function are evaluated as part of the; s",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/open_projects.html:3975,Optimiz,Optimization,3975,interpreter/llvm-project/clang/www/analyzer/open_projects.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/open_projects.html,1,['Optimiz'],['Optimization']
Performance," contain all; class definitions from the `atlfast.root` file. The necessary `makefile`; to build a shared library are also created, and since the '++' is; appended, the shared library is also loaded. ``` {.cpp}; root[] f.MakeProject(""MyProject"",""*"", ""recreate++""); MakeProject has generated 0 classes in MyProject; MyProject/MAKE file has been generated; Shared lib MyProject/MyProject.so has been generated; Shared lib MyProject/MyProject.so has been dynamically linked; ```. The contents of `MyProject`:. ``` {.cpp}; root[] .! ls MyProject; ATLFCluster.h ATLFJet.h ATLFMiscMaker.h ATLFTrack.h; TMCParticle.h ATLFClusterMaker.h ATLFJetMaker.h ATLFMuon.h; ATLFElectron.h ATLFMCMaker.h ATLFMuonMaker.h ATLFElectronMaker.h; ATLFMaker.h ATLFPhoton.h ATLFHistBrowser.h ATLFMisc.h; ATLFPhotonMaker.h ATLFTrackMaker.h ATLFTrigger.h ATLFTriggerMaker.h; LinkDef.h MAKE MyProject.so MyProjectProjectDict.h; MyProjectProjectDict.cxx MyProjectProjectDict.o; ```. Now you can load the shared library in any consecutive root session to; use the `atlfast` classes. ``` {.cpp}; root[]gSystem->Load(""MyProject/MyProject""); root[]ATLFMuon muon; ```. This is an example of a generated header file:. ``` {.cpp}; //////////////////////////////////////////////////////////; // This class has been generated by TFile::MakeProject; // (Thu Apr 5 10:18:37 2001 by ROOT version 3.00/06); // from the TStreamerInfo in file atlfast.root; //////////////////////////////////////////////////////////; #ifndef ATLFMuon_h; #define ATLFMuon_h; #include ""TObject.h""; #include ""TAtt3D.h""; class ATLFMuon : public TObject , public TAtt3D {; public:; Int_t m_KFcode; //Muon KF-code; Int_t m_MCParticle; //Muon position in MCParticles list; Int_t m_KFmother; //Muon mother KF-code; Int_t m_UseFlag; //Muon energy usage flag; Int_t m_Isolated; //Muon isolation (1 for isolated); Float_t m_Eta; //Eta coordinate; Float_t m_Phi; //Phi coordinate; Float_t m_PT; //Transverse energy; Int_t m_Trigger; //Result of trigger; ATLFMuon() {;}; virtua",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/InputOutput.md:90321,load,load,90321,documentation/users-guide/InputOutput.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/InputOutput.md,1,['load'],['load']
Performance," correct. Overestimating the alignment results in undefined behavior.; Underestimating the alignment may produce less efficient code. An alignment of; 1 is always safe. The maximum possible alignment is ``1 << 32``. An alignment; value higher than the size of the loaded type implies memory up to the; alignment value bytes can be safely loaded without trapping in the default; address space. Access of the high bytes can interfere with debugging tools, so; should not be accessed if the function has the ``sanitize_thread`` or; ``sanitize_address`` attributes. The alignment is only optional when parsing textual IR; for in-memory IR, it is; always present. An omitted ``align`` argument means that the operation has the; ABI alignment for the target. The optional ``!nontemporal`` metadata must reference a single metadata; name ``<nontemp_node>`` corresponding to a metadata node with one ``i32`` entry; of value 1. The existence of the ``!nontemporal`` metadata on the instruction; tells the optimizer and code generator that this load is not expected to; be reused in the cache. The code generator may select special; instructions to save cache bandwidth, such as the ``MOVNT`` instruction on; x86. The optional ``!invariant.group`` metadata must reference a; single metadata name ``<empty_node>``. See ``invariant.group`` metadata. Semantics:; """""""""""""""""""". The contents of memory are updated to contain ``<value>`` at the; location specified by the ``<pointer>`` operand. If ``<value>`` is; of scalar type then the number of bytes written does not exceed the; minimum number of bytes needed to hold all bits of the type. For; example, storing an ``i24`` writes at most three bytes. When writing a; value of a type like ``i20`` with a size that is not an integral number; of bytes, it is unspecified what happens to the extra bits that do not; belong to the type, but they will typically be overwritten.; If ``<value>`` is of aggregate type, padding is filled with; :ref:`undef <undefvalues>`.; If",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:422174,optimiz,optimizer,422174,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,3,"['cache', 'load', 'optimiz']","['cache', 'load', 'optimizer']"
Performance," correct. Overestimating the alignment results in undefined behavior.; Underestimating the alignment may produce less efficient code. An alignment of; 1 is always safe. The maximum possible alignment is ``1 << 32``. An alignment; value higher than the size of the loaded type implies memory up to the; alignment value bytes can be safely loaded without trapping in the default; address space. Access of the high bytes can interfere with debugging tools, so; should not be accessed if the function has the ``sanitize_thread`` or; ``sanitize_address`` attributes. The alignment is only optional when parsing textual IR; for in-memory IR, it is; always present. An omitted ``align`` argument means that the operation has the; ABI alignment for the target. The optional ``!nontemporal`` metadata must reference a single; metadata name ``<nontemp_node>`` corresponding to a metadata node with one; ``i32`` entry of value 1. The existence of the ``!nontemporal``; metadata on the instruction tells the optimizer and code generator; that this load is not expected to be reused in the cache. The code; generator may select special instructions to save cache bandwidth, such; as the ``MOVNT`` instruction on x86. The optional ``!invariant.load`` metadata must reference a single; metadata name ``<empty_node>`` corresponding to a metadata node with no; entries. If a load instruction tagged with the ``!invariant.load``; metadata is executed, the memory location referenced by the load has; to contain the same value at all points in the program where the; memory location is dereferenceable; otherwise, the behavior is; undefined. The optional ``!invariant.group`` metadata must reference a single metadata name; ``<empty_node>`` corresponding to a metadata node with no entries.; See ``invariant.group`` metadata :ref:`invariant.group <md_invariant.group>`. The optional ``!nonnull`` metadata must reference a single; metadata name ``<empty_node>`` corresponding to a metadata node with no; entries. The exis",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:415088,optimiz,optimizer,415088,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,3,"['cache', 'load', 'optimiz']","['cache', 'load', 'optimizer']"
Performance," corresponding static methods.; Fitting Classes: improve in general all classes in view of using them in the histogram and graph fitting routines. Few bugs have been as well fixed (see the cvs log for details). The fitter class, ROOT::Fit::Fitter is used now to implement the fit functionality of the Hist library (i.e. TH1::Fit, TGraph::Fit/; ; The Fitter class has been changed to retain a pointer to the Minimizer and Objective function of the last fit. The objective function depends on a reference to the data and the model function, therefore the objective function pointer is valid as far the data and the model function are maintained alive.; ; The library provides the implementation of standard objective function like the Chi2 function, the Poisson likelihood function (for binned likelihood fits) and the loh likelihood function (for unbinned fits). These standard objective functions can be created with or without gradient functionality. In the first case the minimization will be performed using the gradient provided by the function. These functions can also be used in specialized fitting methods like Fumili or the GSL non-linear least square.; . MathCore. Fixed a bug in setting the VEGAS integration mode in the GSLMCIntegrator class.; . Fumili. Add implementation of Minimizer interface using TFumili.; ; Minuit. In TMinuitMinimizer: do not delete the contained TMinuit reference, but maintain it alive, and accessible outside as gMinuit. It can then be used after fitting, for example for drawing contour plots. Add also support for Scan and Contour plots.; ; TLinearMinimizer: add support for robust fitting; . Minuit2. Add support to perform parallel minimization using a thread for each gradient calculation with openMP. In the ROOT environment the Minuit2 library can be built using openMP ( -fopenmp compilation flag for gcc) if the environment variables USE_PARALLEL_MINUIT2 and USE_OPENMP are set.; In the Minuit2 standalone built libraries (using autoconf) support for o",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/doc/v522/index.html:2447,perform,performed,2447,math/doc/v522/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/doc/v522/index.html,2,['perform'],['performed']
Performance," count:. .. code-block:: c++. #pragma clang loop vectorize_width(2) interleave_count(2); for(...) {; ...; }. See the Clang; `language extensions; <https://clang.llvm.org/docs/LanguageExtensions.html#extensions-for-loop-hint-optimizations>`_; for details. Diagnostics; -----------. Many loops cannot be vectorized including loops with complicated control flow,; unvectorizable types, and unvectorizable calls. The loop vectorizer generates; optimization remarks which can be queried using command line options to identify; and diagnose loops that are skipped by the loop-vectorizer. Optimization remarks are enabled using:. ``-Rpass=loop-vectorize`` identifies loops that were successfully vectorized. ``-Rpass-missed=loop-vectorize`` identifies loops that failed vectorization and; indicates if vectorization was specified. ``-Rpass-analysis=loop-vectorize`` identifies the statements that caused; vectorization to fail. If in addition ``-fsave-optimization-record`` is; provided, multiple causes of vectorization failure may be listed (this behavior; might change in the future). Consider the following loop:. .. code-block:: c++. #pragma clang loop vectorize(enable); for (int i = 0; i < Length; i++) {; switch(A[i]) {; case 0: A[i] = i*2; break;; case 1: A[i] = i; break;; default: A[i] = 0;; }; }. The command line ``-Rpass-missed=loop-vectorize`` prints the remark:. .. code-block:: console. no_switch.cpp:4:5: remark: loop not vectorized: vectorization is explicitly enabled [-Rpass-missed=loop-vectorize]. And the command line ``-Rpass-analysis=loop-vectorize`` indicates that the; switch statement cannot be vectorized. .. code-block:: console. no_switch.cpp:4:5: remark: loop not vectorized: loop contains a switch statement [-Rpass-analysis=loop-vectorize]; switch(A[i]) {; ^. To ensure line and column numbers are produced include the command line options; ``-gline-tables-only`` and ``-gcolumn-info``. See the Clang `user manual; <https://clang.llvm.org/docs/UsersManual.html#options-to-e",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Vectorizers.rst:3173,optimiz,optimization-record,3173,interpreter/llvm-project/llvm/docs/Vectorizers.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Vectorizers.rst,1,['optimiz'],['optimization-record']
Performance," created for each assignment, recording the; variable's new location. Compared with the ``llvm.dbg.declare`` intrinsic:. * A dbg.value terminates the effect of any preceding dbg.values for (any; overlapping fragments of) the specified variable.; * The dbg.value's position in the IR defines where in the instruction stream; the variable's value changes.; * Operands can be constants, indicating the variable is assigned a; constant value. Care must be taken to update ``llvm.dbg.value`` intrinsics when optimization; passes alter or move instructions and blocks -- the developer could observe such; changes reflected in the value of variables when debugging the program. For any; execution of the optimized program, the set of variable values presented to the; developer by the debugger should not show a state that would never have existed; in the execution of the unoptimized program, given the same input. Doing so; risks misleading the developer by reporting a state that does not exist,; damaging their understanding of the optimized program and undermining their; trust in the debugger. Sometimes perfectly preserving variable locations is not possible, often when a; redundant calculation is optimized out. In such cases, a ``llvm.dbg.value``; with operand ``poison`` should be used, to terminate earlier variable locations; and let the debugger present ``optimized out`` to the developer. Withholding; these potentially stale variable values from the developer diminishes the; amount of available debug information, but increases the reliability of the; remaining information. To illustrate some potential issues, consider the following example:. .. code-block:: llvm. define i32 @foo(i32 %bar, i1 %cond) {; entry:; call @llvm.dbg.value(metadata i32 0, metadata !1, metadata !2); br i1 %cond, label %truebr, label %falsebr; truebr:; %tval = add i32 %bar, 1; call @llvm.dbg.value(metadata i32 %tval, metadata !1, metadata !2); %g1 = call i32 @gazonk(); br label %exit; falsebr:; %fval = add i3",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:19294,optimiz,optimized,19294,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,1,['optimiz'],['optimized']
Performance," creates JSON code for the; TCanvas with all drawn objects inside. Allows to store current canvas state; 2. Support ""item=img:file.png"" parameter to insert images in existing layout (#151); 3. Support TTree drawing into TGraph (#153), thanks @cozzyd; 4. Let configure ""&toolbar=right"" in URL to change position of tool buttons; 5. Let configure ""&divsize=500x400"" in URL of size of main div element (default - full browser); 6. Implement ""optstat1001"" and ""optfit101"" draw options for histograms; 7. Remove ""autocol"" options - standard ""plc"" should be used instead; 8. Provide drawing of artificial ""$legend"" item - it creates TLegend for all primitives in pad; Can be used when several histograms or several graphs superimposed; 9. Let configure ""&toolbar=vert"" in URL to change orientation of tool buttons; 10. Improve markers and error bars drawing for TH1/TProfile. ## Changes in 5.4.3; 1. Fix - draw functions also when histogram ""same"" option used (#159); 2. Fix - when draw histogram as markers improve optimization algorithm; 3. Fix - correct histogram Y-axis range selection in logarithmic scale; 4. Fix - for TH2 draw options allow combination ""colztext"" (#162); 5. Fix - PNG file generation with 3D drawings inside. ## Changes in 5.4.2; 1. Fix - take into account extra quotes in multipart http reply (#157); 2. Fix - display of labels on X axis with TProfile; 3. Fix - support time display in TMultiGraph; 4. Fix - correctly parse ""optstat"" and ""optfit"" in URL; 5. Fix - correctly update TGraph drawing when X range is changing; 6. Fix - return only TF1/TF2 object when searching function (#158). ## Changes in 5.4.1; 1. Fix - monitoring mode in draw.htm page; 2. Fix - zooming in colz palette; 3. Fix - support both 9.x and 10.x jsdom version in Node.js (#149); 4. Fix - draw axis main line with appropriate attributes (#150); 5. Fix - use axis color when drawing grids lines (#150); 6. Fix - when set pad logx/logy, reset existing user ranges in pad; 7. Fix - avoid too deep calling sta",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/js/changes.md:34517,optimiz,optimization,34517,js/changes.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/js/changes.md,1,['optimiz'],['optimization']
Performance," creates as in; ""new"", in addition if the directory does exist, all existing files; are deleted before creating the new files. - ""`update`"" The new classes are added to the existing directory and; the existing classes are replaced with the new definition. If the; directory does not exist, it creates it as in ""new"". - ""+"": This option can be used in combination with the other three. It; will create the necessary files to easily build a shared library; containing the class definitions.Specifically it will:. - Generate a script called `MAKE` that builds the shared library; containing the definition of all classes in the directory. - Generate a `LinkDef.h `files to use with `rootcling` in `MAKE`. - Run `rootcling` to generate a `<dirname>ProjectDict.cxx` file. - Compile the \<`dirname>ProjectDict.cxx `with the current options in; `compiledata.h`. - Build a shared library` <dirname>.so`. - ""++"":This option can be used instead of the single ""+"". It does; everything the single ""+"" does, and dynamically loads the shared; library `<dirname>.so`. This example makes a directory called `MyProject` that will contain all; class definitions from the `atlfast.root` file. The necessary `makefile`; to build a shared library are also created, and since the '++' is; appended, the shared library is also loaded. ``` {.cpp}; root[] f.MakeProject(""MyProject"",""*"", ""recreate++""); MakeProject has generated 0 classes in MyProject; MyProject/MAKE file has been generated; Shared lib MyProject/MyProject.so has been generated; Shared lib MyProject/MyProject.so has been dynamically linked; ```. The contents of `MyProject`:. ``` {.cpp}; root[] .! ls MyProject; ATLFCluster.h ATLFJet.h ATLFMiscMaker.h ATLFTrack.h; TMCParticle.h ATLFClusterMaker.h ATLFJetMaker.h ATLFMuon.h; ATLFElectron.h ATLFMCMaker.h ATLFMuonMaker.h ATLFElectronMaker.h; ATLFMaker.h ATLFPhoton.h ATLFHistBrowser.h ATLFMisc.h; ATLFPhotonMaker.h ATLFTrackMaker.h ATLFTrigger.h ATLFTriggerMaker.h; LinkDef.h MAKE MyProject.so MyProjectProjec",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/InputOutput.md:89256,load,loads,89256,documentation/users-guide/InputOutput.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/InputOutput.md,1,['load'],['loads']
Performance," currently filled.; By default, this limit is set to twice the compressed target cluster size when compression is used,; and to the cluster target size for uncompressed data.; Initially, and after flushing, all columns use small pages,; just big enough to hold the configurable minimum number of elements (64 by default).; Page sizes are doubled as more data is filled into them.; When a page reaches the maximum page size (see above), it is flushed.; When the overall page budget is reached,; pages larger than the page at hand are flushed before the page at hand is flushed.; For the parallel writer, every fill context maintains the page memory budget independently. Note that the total amount of memory consumed for writing is usually larger than the write page budget.; For instance, if buffered writing is used (the default), additional memory is required.; Use RNTupleModel::EstimateWriteMemoryUsage() for the total estimated memory use for writing. The default values are tuned for a total write memory of around 300 MB per writer resp. fill context.; In order to decrease the memory consumption,; users should decrease the target cluster size before tuning more intricate memory settings. Notes; =====. Approximation of the compressed cluster size; --------------------------------------------. The estimator for the compressed cluster size uses the average compression factor; of the so far written clusters.; This has been choosen as a simple, yet expectedly accurate enough estimator (to be validated).; The following alternative strategies were discussed:. - The average compression factor of all so-far written pages.; Easy to implement.; It would better prevent outlier clusters from skewing the estimate of the successor clusters.; It would be slower though in adjusting to systematic changes in the data set,; e.g. ones that are caused by changing experimental conditions during data taking. - The average over a window of the last $k$ clusters, possibly with exponential smoothing.;",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/tuning.md:2878,tune,tuned,2878,tree/ntuple/v7/doc/tuning.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/tuning.md,1,['tune'],['tuned']
Performance," data flow analysis to identify an output; parameter. The refactoring can be safely done when the data flow algorithm; computes a normal state with all of the fields proven to be overwritten in the; exit basic block of the function. ```c++; struct Customer {; int account_id;; std::string name;; };. void GetCustomer(Customer* c) {; // Overwritten: {}; c->account_id = ...; // Overwritten: {c->account_id}; if (...) {; c->name = ...; // Overwritten: {c->account_id, c->name}; } else {; c->name = ...; // Overwritten: {c->account_id, c->name}; }; // Overwritten: {c->account_id, c->name}; }; ```. When the data flow algorithm computes a normal state, but not all fields are; proven to be overwritten we can't perform the refactoring. ```c++; void target(bool b, Customer* c) {; // Overwritten: {}; if (b) {; c->account_id = 42; // Overwritten: {c->account_id}; } else {; c->name = ""Konrad""; // Overwritten: {c->name}; }; // Overwritten: {}; }; ```. Similarly, when the data flow algorithm computes a failure state, we also can't; perform the refactoring. ```c++; Customer* kGlobalCustomer;. void GetCustomer(Customer* c) {; // Overwritten: {}; c->account_id = ...; // Overwritten: {c->account_id}; if (...) {; print(c->name); // Unsafe read; } else {; kGlobalCustomer = c; // Pointer escape; }; // Unsafe read, Pointer escape; }; ```. ## Example: finding dead stores. Let's say we want to find redundant stores, because they indicate potential; bugs. ```c++; x = GetX();; x = GetY();; ```. The first store to `x` is never read, probably there is a bug. The implementation of dead store analysis is very similar to output parameter; analysis: we need to track stores and loads, and find stores that were never; read. [Liveness analysis](https://en.wikipedia.org/wiki/Live_variable_analysis) is a; generalization of this idea, which is often used to answer many related; questions, for example:. * finding dead stores,; * finding uninitialized variables,; * finding a good point to deallocate memory,; *",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md:19320,perform,perform,19320,interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md,1,['perform'],['perform']
Performance," data read is no; older than a local load; atomic value being; acquired. atomicrmw acq_rel - agent - global 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global_atomic; 3. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 4. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acq_rel - agent - generic 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global have; completed before; performing the; atomicrmw that is; being released. 2. flat_atomic; 3. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating t",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:226089,load,load,226089,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],['load']
Performance," data symbol, the associated section is loaded into memory; and the symbol is stored in a symbol table map data structure. When the; iteration is complete, a section is emitted for the common symbols. Next, RuntimeDyldImpl::loadObject iterates through the sections in the; object image and for each section iterates through the relocations for; that sections. For each relocation, it calls the format-specific; processRelocationRef method, which will examine the relocation and store; it in one of two data structures, a section-based relocation list map and; an external symbol relocation map. .. image:: MCJIT-load-object.png. When RuntimeDyldImpl::loadObject returns, all of the code and data; sections for the object will have been loaded into memory allocated by the; memory manager and relocation information will have been prepared, but the; relocations have not yet been applied and the generated code is still not; ready to be executed. [Currently (as of August 2013) the MCJIT engine will immediately apply; relocations when loadObject completes. However, this shouldn't be; happening. Because the code may have been generated for a remote target,; the client should be given a chance to re-map the section addresses before; relocations are applied. It is possible to apply relocations multiple; times, but in the case where addresses are to be re-mapped, this first; application is wasted effort.]. Address Remapping; =================. At any time after initial code has been generated and before; finalizeObject is called, the client can remap the address of sections in; the object. Typically this is done because the code was generated for an; external process and is being mapped into that process' address space.; The client remaps the section address by calling MCJIT::mapSectionAddress.; This should happen before the section memory is copied to its new; location. When MCJIT::mapSectionAddress is called, MCJIT passes the call on to; RuntimeDyldImpl (via its Dyld member). RuntimeD",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MCJITDesignAndImplementation.rst:5545,load,loadObject,5545,interpreter/llvm-project/llvm/docs/MCJITDesignAndImplementation.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MCJITDesignAndImplementation.rst,1,['load'],['loadObject']
Performance," debug information for the data types defined in the AST. Tools built on top of; libclang that do not need debug information may also produce raw AST files that; only contain the serialized AST. The ``clangast`` section is organized into several different blocks, each of; which contains the serialized representation of a part of Clang's internal; representation. Each of the blocks corresponds to either a block or a record; within `LLVM's bitstream format <https://llvm.org/docs/BitCodeFormat.html>`_.; The contents of each of these logical blocks are described below. .. image:: PCHLayout.png. The ``llvm-objdump`` utility provides a ``-raw-clang-ast`` option to extract the; binary contents of the AST section from an object file container. The `llvm-bcanalyzer <https://llvm.org/docs/CommandGuide/llvm-bcanalyzer.html>`_; utility can be used to examine the actual structure of the bitstream for the AST; section. This information can be used both to help understand the structure of; the AST section and to isolate areas where the AST representation can still be; optimized, e.g., through the introduction of abbreviations. Metadata Block; ^^^^^^^^^^^^^^. The metadata block contains several records that provide information about how; the AST file was built. This metadata is primarily used to validate the use of; an AST file. For example, a precompiled header built for a 32-bit x86 target; cannot be used when compiling for a 64-bit x86 target. The metadata block; contains information about:. Language options; Describes the particular language dialect used to compile the AST file,; including major options (e.g., Objective-C support) and more minor options; (e.g., support for ""``//``"" comments). The contents of this record correspond to; the ``LangOptions`` class. Target architecture; The target triple that describes the architecture, platform, and ABI for; which the AST file was generated, e.g., ``i386-apple-darwin9``. AST version; The major and minor version numbers of the AST fi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/PCHInternals.rst:7376,optimiz,optimized,7376,interpreter/llvm-project/clang/docs/PCHInternals.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/PCHInternals.rst,1,['optimiz'],['optimized']
Performance," debug information"")));. This definition defines an enumerated command line variable of type ""``enum; DebugLev``"", which works exactly the same way as before. The difference here is; just the interface exposed to the user of your program and the help output by; the ""``-help``"" option:. ::. USAGE: compiler [options] <input file>. OPTIONS:; Choose optimization level:; -g - No optimizations, enable debugging; -O1 - Enable trivial optimizations; -O2 - Enable default optimizations; -O3 - Enable expensive optimizations; -debug_level - Set the debugging level:; =none - disable debug information; =quick - enable quick debug information; =detailed - enable detailed debug information; -f - Enable binary output on terminals; -help - display available options (-help-hidden for more); -o <filename> - Specify output filename; -quiet - Don't print informational messages. Again, the only structural difference between the debug level declaration and; the optimization level declaration is that the debug level declaration includes; an option name (``""debug_level""``), which automatically changes how the library; processes the argument. The CommandLine library supports both forms so that you; can choose the form most appropriate for your application. .. _lists:. Parsing a list of options; -------------------------. Now that we have the standard run-of-the-mill argument types out of the way,; lets get a little wild and crazy. Lets say that we want our optimizer to accept; a **list** of optimizations to perform, allowing duplicates. For example, we; might want to run: ""``compiler -dce -instsimplify -inline -dce -strip``"". In this; case, the order of the arguments and the number of appearances is very; important. This is what the ""``cl::list``"" template is for. First, start by; defining an enum of the optimizations that you would like to perform:. .. code-block:: c++. enum Opts {; // 'inline' is a C++ keyword, so name it 'inlining'; dce, instsimplify, inlining, strip; };. Then define your """,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:18757,optimiz,optimization,18757,interpreter/llvm-project/llvm/docs/CommandLine.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst,1,['optimiz'],['optimization']
Performance," declare float @llvm.vp.reduce.fmax.v4f32(float <start_value>, <4 x float> <val>, <4 x i1> <mask>, float <vector_length>); declare double @llvm.vp.reduce.fmax.nxv8f64(double <start_value>, <vscale x 8 x double> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated floating-point ``MAX`` reduction of a vector and a scalar starting; value, returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value of the reduction, which must be a scalar; floating-point type equal to the result type. The second operand is the vector; on which the reduction is performed and must be a vector of floating-point; values whose element type is the result/start type. The third operand is the; vector mask and is a vector of boolean values with the same number of elements; as the vector operand. The fourth operand is the explicit vector length of the; operation. Semantics:; """""""""""""""""""". The '``llvm.vp.reduce.fmax``' intrinsic performs the floating-point ``MAX``; reduction (:ref:`llvm.vector.reduce.fmax <int_vector_reduce_fmax>`) of the; vector operand ``val`` on each enabled lane, taking the maximum of that and the; scalar ``start_value``. Disabled lanes are treated as containing the neutral; value (i.e. having no effect on the reduction operation). If the vector length; is zero, the result is the start value. The neutral value is dependent on the :ref:`fast-math flags <fastmath>`. If no; flags are set, the neutral value is ``-QNAN``. If ``nnan`` and ``ninf`` are; both set, then the neutral value is the smallest floating-point value for the; result type. If only ``nnan`` is set then the neutral value is ``-Infinity``. This instruction has the same comparison semantics as the; :ref:`llvm.vector.reduce.fmax <int_vector_reduce_fmax>` intrinsic (and thus the; '``llvm.maxnum.*``' intrinsic). That is, the result will always be a number; unless all elements of the vector and the starting value are ``NaN``. For a; vector with maximum e",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:772123,perform,performs,772123,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['performs']
Performance," declare float @llvm.vp.reduce.fmin.v4f32(float <start_value>, <4 x float> <val>, <4 x i1> <mask>, float <vector_length>); declare double @llvm.vp.reduce.fmin.nxv8f64(double <start_value>, <vscale x 8 x double> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated floating-point ``MIN`` reduction of a vector and a scalar starting; value, returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value of the reduction, which must be a scalar; floating-point type equal to the result type. The second operand is the vector; on which the reduction is performed and must be a vector of floating-point; values whose element type is the result/start type. The third operand is the; vector mask and is a vector of boolean values with the same number of elements; as the vector operand. The fourth operand is the explicit vector length of the; operation. Semantics:; """""""""""""""""""". The '``llvm.vp.reduce.fmin``' intrinsic performs the floating-point ``MIN``; reduction (:ref:`llvm.vector.reduce.fmin <int_vector_reduce_fmin>`) of the; vector operand ``val`` on each enabled lane, taking the minimum of that and the; scalar ``start_value``. Disabled lanes are treated as containing the neutral; value (i.e. having no effect on the reduction operation). If the vector length; is zero, the result is the start value. The neutral value is dependent on the :ref:`fast-math flags <fastmath>`. If no; flags are set, the neutral value is ``+QNAN``. If ``nnan`` and ``ninf`` are; both set, then the neutral value is the largest floating-point value for the; result type. If only ``nnan`` is set then the neutral value is ``+Infinity``. This instruction has the same comparison semantics as the; :ref:`llvm.vector.reduce.fmin <int_vector_reduce_fmin>` intrinsic (and thus the; '``llvm.minnum.*``' intrinsic). That is, the result will always be a number; unless all elements of the vector and the starting value are ``NaN``. For a; vector with maximum el",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:774997,perform,performs,774997,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['performs']
Performance," declare i32 @llvm.nvvm.read.ptx.sreg.tid.x() readnone nounwind; ; libdevice function; declare float @__nv_powf(float, float). define void @kernel(float addrspace(1)* %A,; float addrspace(1)* %B,; float addrspace(1)* %C) {; entry:; ; What is my ID?; %id = tail call i32 @llvm.nvvm.read.ptx.sreg.tid.x() readnone nounwind. ; Compute pointers into A, B, and C; %ptrA = getelementptr float, float addrspace(1)* %A, i32 %id; %ptrB = getelementptr float, float addrspace(1)* %B, i32 %id; %ptrC = getelementptr float, float addrspace(1)* %C, i32 %id. ; Read A, B; %valA = load float, float addrspace(1)* %ptrA, align 4; %valB = load float, float addrspace(1)* %ptrB, align 4. ; Compute C = pow(A, B); %valC = call float @__nv_powf(float %valA, float %valB). ; Store back to C; store float %valC, float addrspace(1)* %ptrC, align 4. ret void; }. !nvvm.annotations = !{!0}; !0 = !{void (float addrspace(1)*,; float addrspace(1)*,; float addrspace(1)*)* @kernel, !""kernel"", i32 1}. To compile this kernel, we perform the following steps:. 1. Link with libdevice; 2. Internalize all but the public kernel function; 3. Run ``NVVMReflect`` and set ``__CUDA_FTZ`` to 0; 4. Optimize the linked module; 5. Codegen the module. These steps can be performed by the LLVM ``llvm-link``, ``opt``, and ``llc``; tools. In a complete compiler, these steps can also be performed entirely; programmatically by setting up an appropriate pass configuration (see; :ref:`libdevice`). .. code-block:: text. # llvm-link t2.bc libdevice.compute_20.10.bc -o t2.linked.bc; # opt -internalize -internalize-public-api-list=kernel -nvvm-reflect-list=__CUDA_FTZ=0 -nvvm-reflect -O3 t2.linked.bc -o t2.opt.bc; # llc -mcpu=sm_20 t2.opt.bc -o t2.ptx. .. note::. The ``-nvvm-reflect-list=_CUDA_FTZ=0`` is not strictly required, as any; undefined variables will default to zero. It is shown here for evaluation; purposes. This gives us the following PTX (excerpt):. .. code-block:: text. //; // Generated by LLVM NVPTX Back-End; //. .version 3.1",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/NVPTXUsage.rst:25006,perform,perform,25006,interpreter/llvm-project/llvm/docs/NVPTXUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/NVPTXUsage.rst,1,['perform'],['perform']
Performance," derived pointer. By default RewriteStatepointsForGC passes in ``0xABCDEF00`` as the statepoint; ID and ``0`` as the number of patchable bytes to the newly constructed; ``gc.statepoint``. These values can be configured on a per-callsite; basis using the attributes ``""statepoint-id""`` and; ``""statepoint-num-patch-bytes""``. If a call site is marked with a; ``""statepoint-id""`` function attribute and its value is a positive; integer (represented as a string), then that value is used as the ID; of the newly constructed ``gc.statepoint``. If a call site is marked; with a ``""statepoint-num-patch-bytes""`` function attribute and its; value is a positive integer, then that value is used as the 'num patch; bytes' parameter of the newly constructed ``gc.statepoint``. The; ``""statepoint-id""`` and ``""statepoint-num-patch-bytes""`` attributes; are not propagated to the ``gc.statepoint`` call or invoke if they; could be successfully parsed. In practice, RewriteStatepointsForGC should be run much later in the pass; pipeline, after most optimization is already done. This helps to improve; the quality of the generated code when compiled with garbage collection support. .. _RewriteStatepointsForGC_intrinsic_lowering:. RewriteStatepointsForGC intrinsic lowering; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. As a part of lowering to the explicit model of relocations; RewriteStatepointsForGC performs GC specific lowering for the following; intrinsics:. * ``gc.get.pointer.base``; * ``gc.get.pointer.offset``; * ``llvm.memcpy.element.unordered.atomic.*``; * ``llvm.memmove.element.unordered.atomic.*``. There are two possible lowerings for the memcpy and memmove operations:; GC leaf lowering and GC parseable lowering. If a call is explicitly marked with; ""gc-leaf-function"" attribute the call is lowered to a GC leaf call to; '``__llvm_memcpy_element_unordered_atomic_*``' or; '``__llvm_memmove_element_unordered_atomic_*``' symbol. Such a call can not; take a safepoint. Otherwise, the call is made G",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:29082,optimiz,optimization,29082,interpreter/llvm-project/llvm/docs/Statepoints.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst,1,['optimiz'],['optimization']
Performance," description of the `ROOT::Fit` classes and how to use them.; Using these classes instead of the interface provided directly in the ROOT data objects, like `TH1::Fit` allow are more fine control; to configure and customise the fits. For example, using these classes a combined fit of several histograms can be performed. To understand how these class work, let's go through a simple example, such as fitting an histogram. When fitting an histogram, instead of using `TH1::Fit` we will show in the following hot wo use the `ROOT::Fit` classes.; We will show how to perform the following different type of fits with the histogram data:; * a least square fit using the observed errors (Neyman chi-squared);; * a least square fit using the expected errors from the function (Pearson chi-squared);; * a binned likelihood fit;; * an extended unbinned likelihood fits, if the histogram has been set to store in the buffer the original data used to fill it. Let's go through all the steps required for performing these fits using the `ROOT::Fit::Fitter` class.; These steps are:; 1. Create the input fit data object.; 2. Create the input model function.; 3. Configure the fit.; 4. Perform the data fitting.; 5. Examine the result. ### Creating the input fit data. We have two types of input data, binned data (class `ROOT::Fit::BinData`) used for least square (chi-square) fits of histograms or `TGraph` objects; or un-binned data (class `ROOT::Fit::UnBinData`) used for; fitting vectors of data points (e.g. from a `TTree`). #### Using Binned data. Let's suppose we have an histogram, represented as a **`TH1`** type object (it can be one or multi-dimensional). The following shows how to create and; fill a `ROOT:Fit::BinData` object. ``` {.cpp}; ROOT::Fit::DataOptions opt;; opt.fIntegral = true;; ROOT::Fit::BinData data(opt);; // fill the bin data using the histogram; // we can do this using the following helper function from the Hist library; TH1 * h1 = (TH1*) gDirectory->Get(""myHistogram"");; ROOT::F",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/FittingHistograms.md:29346,perform,performing,29346,documentation/users-guide/FittingHistograms.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/FittingHistograms.md,1,['perform'],['performing']
Performance," determine volume size. KernelEstimator No Box Box, Sphere, Teepee, Gauss, Sinc3, Sinc5, Sinc7, Sinc9, Sinc11, Lanczos2, Lanczos3, Lanczos5, Lanczos8, Trim Kernel estimation function. DeltaFrac No 3 − nEventsMin/Max for minmax and rms volume range. NEventsMin No 100 − nEventsMin for adaptive volume range. NEventsMax No 200 − nEventsMax for adaptive volume range. MaxVIterations No 150 − MaxVIterations for adaptive volume range. InitialScale No 0.99 − InitialScale for adaptive volume range. GaussSigma No 0.1 − Width (wrt volume size) of Gaussian kernel estimator. NormTree No False − Normalize binary search tree. Configuration options for MVA method :. Configuration options reference for MVA method: FDA. Option Array Default value Predefined values Description. V No False − Verbose output (short form of VerbosityLevel below - overrides the latter one). VerbosityLevel No Default Default, Debug, Verbose, Info, Warning, Error, Fatal Verbosity level. VarTransform No None − List of variable transformations performed before training, e.g., D_Background,P_Signal,G,N_AllClasses for: Decorrelation, PCA-transformation, Gaussianisation, Normalisation, each for the given class of events ('AllClasses' denotes all events of all classes, if no class indication is given, 'All' is assumed). H No False − Print method-specific help message. CreateMVAPdfs No False − Create PDFs for classifier outputs (signal and background). IgnoreNegWeightsInTraining No False − Events with negative weights are ignored in the training (but are included for testing and performance evaluation). Formula No (0) − The discrimination formula. ParRanges No () − Parameter ranges. FitMethod No MINUIT MC, GA, SA, MINUIT Optimisation Method. Converger No None None, MINUIT FitMethod uses Converger to improve result. Configuration options for MVA method :. Configuration options reference for MVA method: LD. Option Array Default value Predefined values Description. V No False − Verbose output (short form of VerbosityLe",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/tmva/UsersGuide/optionRef.html:5455,perform,performed,5455,documentation/tmva/UsersGuide/optionRef.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/tmva/UsersGuide/optionRef.html,2,['perform'],['performed']
Performance," dev; 1. Let use custom time zone for time display, support '&utc' and '&cet' in URL parameters; 2. Support gStyle.fLegendFillStyle; 3. Let change histogram min/max values via context menu; 4. Support Z-scale zooming with TScatter; 5. Implement ""haxis"" draw option for histogram to draw only axes for hbar; 6. Implement ""axisg"" and ""haxisg"" to draw axes with grids; 7. Support TH1 marker, text and line drawing superimposed with ""haxis""; 8. Support `TBox`, `TLatex`, `TLine`, `TMarker` drawing on ""frame"", support drawing on swapped axes; 9. `TProfile` and `TProfile2D` projections https://github.com/root-project/root/issues/15851; 10. Draw total histogram from TEfficiency when draw option starts with 'b'; 11. Let redraw TEfficiency, THStack and TMultiGraph with different draw options via hist context menu; 12. Support 'pads' draw options for TMultiGraph, support context menu for it; 13. Let drop object on sub-pads; 14. Properly loads ES6 modules for web canvas; 15. Improve performance of TH3/RH3 drawing by using THREE.InstancedMesh; 16. Implement batch mode with '&batch' URL parameter to create SVG/PNG images with default GUI; 17. Adjust node.js implementation to produce identical output with normal browser; 18. Create necessary infrastructure for testing with 'puppeteer'; 19. Support inject of ES6 modules via '&inject=path.mjs'; 20. Using importmap for 'jsroot' in all major HTML files and in demos; 21. Implement `settings.CutAxisLabels` flag to remove labels which may exceed graphical range; 22. Let disable usage of TAxis custom labels via context menu; 23. Let configure default draw options via context menu, they can be preserved in the local storage; 24. Let save canvas as JSON file from context menu, object as JSON from inspector; 25. Upgrade three.js r162 -> r168, use r162 only in node.js because of ""gl"" module; 26. Create unified svg2pdf/jspdf ES6 modules, integrate in jsroot builds; 27. Let create multipage PDF document - in TWebCanvas batch mode; 28. Let add extern",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/js/changes.md:1015,perform,performance,1015,js/changes.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/js/changes.md,1,['perform'],['performance']
Performance," devices; - Provide simple layout, making it default; - Allow to open ROOT files in online session (via url parameter); - One could monitor simultaneously objects from server and root files; - Implement 'autocol' draw option - when superimposing histograms,; their line colors will be automatically assigned; - Implement 'nostat' draw option - disabled stat drawing; - Using '_same_' identifier in item name, one can easily draw or superimpose; similar items from different files. Could be used in URL like:; `...&files=[file1.root,file2.root]&items=[file1.root/hpx, file2.root/_same_]`; `...&files=[file1.root,file2.root]&item=file1.root/hpx+file2.root/_same_`; Main limitation - file names should have similar length.; - When 'autozoom' specified in draw options, histogram zoomed into; non-empty content. Same command available via context menu.; - Item of 'Text' kind can be created. It is displayed as; lain text in the browser. If property 'mathjax' specified,; MathJax.js library will be loaded and used for rendering.; See tutorials/http/httpcontrol.C macro for example.; - When using foreignObject, provide workaround for absolute positioning; problem in Chrome/Safari, see <http://bit.ly/1wjqCQ9>; - Support usage of minimized versions of .js and .css files.; Minimized scripts used by default on web servers.; - Implement JSROOT.extend instead of jQuery.extend, reduce; usage of jquery.js in core JSROOT classes; - Implement main graphics without jquery at all,; such mode used in `nobrowser` mode.; - Provide optional latex drawing with MathJax SVG.; TMathText always drawn with MathJax,; other classes require `mathjax` option in URL; - Improve drawing of different text classes, correctly handle; their alignment and scaling, special handling for IE. ## TTree Libraries. ### TTree Behavior change. #### Merging. Added fast cloning support to TTree::MergeTrees and TTree::Merge(TCollection*,Option_t*). #### TTreeCache. The TTreeCache is now enabled by default. The default size of the TT",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md:11611,load,loaded,11611,README/ReleaseNotes/v604/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md,1,['load'],['loaded']
Performance," diagnostic may or many not have an associated category, if it; has one, it is listed in the diagnostic categorization field of the; diagnostic line (in the []'s). For example, a format string warning will produce these three; renditions based on the setting of this option:. ::. t.c:3:11: warning: conversion specifies type 'char *' but the argument has type 'int' [-Wformat]; t.c:3:11: warning: conversion specifies type 'char *' but the argument has type 'int' [-Wformat,1]; t.c:3:11: warning: conversion specifies type 'char *' but the argument has type 'int' [-Wformat,Format String]. This category can be used by clients that want to group diagnostics; by category, so it should be a high level category. We want dozens; of these, not hundreds or thousands of them. .. _opt_fsave-optimization-record:. .. option:: -f[no-]save-optimization-record[=<format>]. Enable optimization remarks during compilation and write them to a separate; file. This option, which defaults to off, controls whether Clang writes; optimization reports to a separate file. By recording diagnostics in a file,; users can parse or sort the remarks in a convenient way. By default, the serialization format is YAML. The supported serialization formats are:. - .. _opt_fsave_optimization_record_yaml:. ``-fsave-optimization-record=yaml``: A structured YAML format. - .. _opt_fsave_optimization_record_bitstream:. ``-fsave-optimization-record=bitstream``: A binary format based on LLVM; Bitstream. The output file is controlled by :option:`-foptimization-record-file`. In the absence of an explicit output file, the file is chosen using the; following scheme:. ``<base>.opt.<format>``. where ``<base>`` is based on the output file of the compilation (whether; it's explicitly specified through `-o` or not) when used with `-c` or `-S`.; For example:. * ``clang -fsave-optimization-record -c in.c -o out.o`` will generate; ``out.opt.yaml``. * ``clang -fsave-optimization-record -c in.c`` will generate; ``in.opt.yaml``. When",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:11013,optimiz,optimization,11013,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,1,['optimiz'],['optimization']
Performance," diagnostics from Clang's; `static analyzer <https://clang-analyzer.llvm.org>`_ can also be; influenced by the user via changes to the source code. See the available; `annotations <https://clang-analyzer.llvm.org/annotations.html>`_ and the; analyzer's `FAQ; page <https://clang-analyzer.llvm.org/faq.html#exclude_code>`_ for more; information. .. _usersmanual-precompiled-headers:. Precompiled Headers; -------------------. `Precompiled headers <https://en.wikipedia.org/wiki/Precompiled_header>`_; are a general approach employed by many compilers to reduce compilation; time. The underlying motivation of the approach is that it is common for; the same (and often large) header files to be included by multiple; source files. Consequently, compile times can often be greatly improved; by caching some of the (redundant) work done by a compiler to process; headers. Precompiled header files, which represent one of many ways to; implement this optimization, are literally files that represent an; on-disk cache that contains the vital information necessary to reduce; some of the work needed to process a corresponding header file. While; details of precompiled headers vary between compilers, precompiled; headers have been shown to be highly effective at speeding up program; compilation on systems with very large system headers (e.g., macOS). Generating a PCH File; ^^^^^^^^^^^^^^^^^^^^^. To generate a PCH file using Clang, one invokes Clang with the; `-x <language>-header` option. This mirrors the interface in GCC; for generating PCH files:. .. code-block:: console. $ gcc -x c-header test.h -o test.h.gch; $ clang -x c-header test.h -o test.h.pch. Using a PCH File; ^^^^^^^^^^^^^^^^. A PCH file can then be used as a prefix header when a ``-include-pch``; option is passed to ``clang``:. .. code-block:: console. $ clang -include-pch test.h.pch test.c -o test. The ``clang`` driver will check if the PCH file ``test.h.pch`` is; available; if so, the contents of ``test.h`` (and the files i",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:46186,optimiz,optimization,46186,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,2,"['cache', 'optimiz']","['cache', 'optimization']"
Performance," directory. The appropriate sub-directory should be selected (see the; :doc:`Testing Guide <TestingGuide>` for details). * Test cases should be written in :doc:`LLVM assembly language <LangRef>`. * Test cases, especially for regressions, should be reduced as much as possible,; by :doc:`bugpoint <Bugpoint>` or manually. It is unacceptable to place an; entire failing program into ``llvm/test`` as this creates a *time-to-test*; burden on all developers. Please keep them short. * Avoid adding links to resources that are not available to the entire; community, such as links to private bug trackers, internal corporate; documentation, etc. Instead, add sufficient comments to the test to provide; the context behind such links. Note that llvm/test and clang/test are designed for regression and small feature; tests only. More extensive test cases (e.g., entire applications, benchmarks,; etc) should be added to the ``llvm-test`` test suite. The llvm-test suite is; for coverage (correctness, performance, etc) testing, not feature or regression; testing. Release Notes; -------------. Many projects in LLVM communicate important changes to users through release; notes, typically found in ``docs/ReleaseNotes.rst`` for the project. Changes to; a project that are user-facing, or that users may wish to know about, should be; added to the project's release notes at the author's or code reviewer's; discretion, preferably as part of the commit landing the changes. Examples of; changes that would typically warrant adding a release note (this list is not; exhaustive):. * Adding, removing, or modifying command-line options.; * Adding, removing, or regrouping a diagnostic.; * Fixing a bug that potentially has significant user-facing impact (please link; to the issue fixed in the bug database).; * Adding or removing optimizations that have widespread impact or enables new; programming paradigms.; * Modifying a C stable API.; * Notifying users about a potentially disruptive change expected to ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:10718,perform,performance,10718,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,1,['perform'],['performance']
Performance," dispatch width for the processor. The dispatch width; defaults to field 'IssueWidth' in the processor scheduling model. If width is; zero, then the default dispatch width is used. .. option:: -register-file-size=<size>. Specify the size of the register file. When specified, this flag limits how; many physical registers are available for register renaming purposes. A value; of zero for this flag means ""unlimited number of physical registers"". .. option:: -iterations=<number of iterations>. Specify the number of iterations to run. If this flag is set to 0, then the; tool sets the number of iterations to a default value (i.e. 100). .. option:: -noalias=<bool>. If set, the tool assumes that loads and stores don't alias. This is the; default behavior. .. option:: -lqueue=<load queue size>. Specify the size of the load queue in the load/store unit emulated by the tool.; By default, the tool assumes an unbound number of entries in the load queue.; A value of zero for this flag is ignored, and the default load queue size is; used instead. .. option:: -squeue=<store queue size>. Specify the size of the store queue in the load/store unit emulated by the; tool. By default, the tool assumes an unbound number of entries in the store; queue. A value of zero for this flag is ignored, and the default store queue; size is used instead. .. option:: -timeline. Enable the timeline view. .. option:: -timeline-max-iterations=<iterations>. Limit the number of iterations to print in the timeline view. By default, the; timeline view prints information for up to 10 iterations. .. option:: -timeline-max-cycles=<cycles>. Limit the number of cycles in the timeline view, or use 0 for no limit. By; default, the number of cycles is set to 80. .. option:: -resource-pressure. Enable the resource pressure view. This is enabled by default. .. option:: -register-file-stats. Enable register file usage statistics. .. option:: -dispatch-stats. Enable extra dispatch statistics. This view collects and analy",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:4363,load,load,4363,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,2,"['load', 'queue']","['load', 'queue']"
Performance," document covers; useful features of the LLVM build system as well as best practices and general; information about packaging LLVM. If you are new to CMake you may find the :doc:`CMake` or :doc:`CMakePrimer`; documentation useful. Some of the things covered in this document are the inner; workings of the builds described in the :doc:`AdvancedBuilds` document. General Distribution Guidance; =============================. When building a distribution of a compiler it is generally advised to perform a; bootstrap build of the compiler. That means building a ""stage 1"" compiler with; your host toolchain, then building the ""stage 2"" compiler using the ""stage 1""; compiler. This is done so that the compiler you distribute benefits from all the; bug fixes, performance optimizations and general improvements provided by the; new compiler. In deciding how to build your distribution there are a few trade-offs that you; will need to evaluate. The big two are:. #. Compile time of the distribution against performance of the built compiler. #. Binary size of the distribution against performance of the built compiler. The guidance for maximizing performance of the generated compiler is to use LTO,; PGO, and statically link everything. This will result in an overall larger; distribution, and it will take longer to generate, but it provides the most; opportunity for the compiler to optimize. The guidance for minimizing distribution size is to dynamically link LLVM and; Clang libraries into the tools to reduce code duplication. This will come at a; substantial performance penalty to the generated binary both because it reduces; optimization opportunity, and because dynamic linking requires resolving symbols; at process launch time, which can be very slow for C++ code. .. _shared_libs:. .. warning::; One very important note: Distributions should never be built using the; *BUILD_SHARED_LIBS* CMake option. That option exists for optimizing developer; workflow only. Due to design and impleme",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst:1297,perform,performance,1297,interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,1,['perform'],['performance']
Performance," does not offer v_dot4_i32_i8, and rather offers; v_dot4_i32_iu8 which has operands to hold the signedness of the; vector operands. Thus, this intrinsic lowers to the signed version; of this instruction for gfx11 targets. llvm.amdgcn.sdot8 Provides direct access to v_dot8_u32_u4 across targets which; support such instructions. This performs signed dot product; with two i32 operands (holding a vector of 8 4bit values), summed; with the third i32 operand. The i1 fourth operand is used to clamp; the output.; When applicable (i.e. no clamping / operand modifiers), this is lowered; into v_dot8c_i32_i4 for targets which support it.; RDNA3 does not offer v_dot8_i32_i4, and rather offers; v_dot4_i32_iu4 which has operands to hold the signedness of the; vector operands. Thus, this intrinsic lowers to the signed version; of this instruction for gfx11 targets. llvm.amdgcn.sudot4 Provides direct access to v_dot4_i32_iu8 on gfx11 targets. This performs; dot product with two i32 operands (holding a vector of 4 8bit values), summed; with the fifth i32 operand. The i1 sixth operand is used to clamp; the output. The i1s preceding the vector operands decide the signedness. llvm.amdgcn.sudot8 Provides direct access to v_dot8_i32_iu4 on gfx11 targets. This performs; dot product with two i32 operands (holding a vector of 8 4bit values), summed; with the fifth i32 operand. The i1 sixth operand is used to clamp; the output. The i1s preceding the vector operands decide the signedness. llvm.amdgcn.sched_barrier Controls the types of instructions that may be allowed to cross the intrinsic; during instruction scheduling. The parameter is a mask for the instruction types; that can cross the intrinsic. - 0x0000: No instructions may be scheduled across sched_barrier.; - 0x0001: All, non-memory, non-side-effect producing instructions may be; scheduled across sched_barrier, *i.e.* allow ALU instructions to pass.; - 0x0002: VALU instructions may be scheduled across sched_barrier.; - 0x0004: SALU in",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:41694,perform,performs,41694,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['perform'],['performs']
Performance," does not; itself cause dependence, but since generally the optimizer will not; be able to prove that the function doesn't depend on that parameter,; it will be forced to conservatively assume it does. Dependency propagates to values loaded from a pointer because those; values might be invalidated by deallocating the object. For; example, given the code ``__strong id x = p->ivar;``, ARC must not; move the release of ``p`` to between the load of ``p->ivar`` and the; retain of that value for storing into ``x``. Dependency does not propagate through stores of dependent pointer; values because doing so would allow dependency to outlive the; full-expression which produced the original value. For example, the; address of an instance variable could be written to some global; location and then freely accessed during the lifetime of the local,; or a function could return an inner pointer of an object and store; it to a local. These cases would be potentially impossible to; reason about and so would basically prevent any optimizations based; on imprecise lifetime. There are also uncommon enough to make it; reasonable to require the precise-lifetime annotation if someone; really wants to rely on them. Dependency does propagate through return values of pointer type.; The compelling source of need for this rule is a property accessor; which returns an un-autoreleased result; the calling function must; have the chance to operate on the value, e.g. to retain it, before; ARC releases the original pointer. Note again, however, that; dependence does not survive a store, so ARC does not guarantee the; continued validity of the return value past the end of the; full-expression. .. _arc.optimization.object_lifetime:. No object lifetime extension; ----------------------------. If, in the formal computation history of the program, an object ``X``; has been deallocated by the time of an observable side-effect, then; ARC must cause ``X`` to be deallocated by no later than the occurrence; of",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst:81729,optimiz,optimizations,81729,interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,1,['optimiz'],['optimizations']
Performance," dominate specific; uses. It is not meant for general use, only for building temporary; renaming forms that require value splits at certain points. .. _type.test:. '``llvm.type.test``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i1 @llvm.type.test(ptr %ptr, metadata %type) nounwind memory(none). Arguments:; """""""""""""""""""". The first argument is a pointer to be tested. The second argument is a; metadata object representing a :doc:`type identifier <TypeMetadata>`. Overview:; """""""""""""""""". The ``llvm.type.test`` intrinsic tests whether the given pointer is associated; with the given type identifier. .. _type.checked.load:. '``llvm.type.checked.load``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare {ptr, i1} @llvm.type.checked.load(ptr %ptr, i32 %offset, metadata %type) nounwind memory(argmem: read). Arguments:; """""""""""""""""""". The first argument is a pointer from which to load a function pointer. The; second argument is the byte offset from which to load the function pointer. The; third argument is a metadata object representing a :doc:`type identifier; <TypeMetadata>`. Overview:; """""""""""""""""". The ``llvm.type.checked.load`` intrinsic safely loads a function pointer from a; virtual table pointer using type metadata. This intrinsic is used to implement; control flow integrity in conjunction with virtual call optimization. The; virtual call optimization pass will optimize away ``llvm.type.checked.load``; intrinsics associated with devirtualized calls, thereby removing the type; check in cases where it is not needed to enforce the control flow integrity; constraint. If the given pointer is associated with a type metadata identifier, this; function returns true as the second element of its return value. (Note that; the function may also return true if the given pointer is not associated; with a type metadata identifier.) If the function's return value's second; element is true, the following rules apply to the first element",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:938049,load,load,938049,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['load'],['load']
Performance," don't; need strict IEEE floating point semantics, there are a number of additional; optimizations that can be performed. This can be highly impactful for; floating point intensive computations. Describing Aliasing Properties; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. #. Add noalias/align/dereferenceable/nonnull to function arguments and return; values as appropriate. #. Use pointer aliasing metadata, especially tbaa metadata, to communicate; otherwise-non-deducible pointer aliasing facts. #. Use inbounds on geps. This can help to disambiguate some aliasing queries. Undefined Values; ^^^^^^^^^^^^^^^^. #. Use poison values instead of undef values whenever possible. #. Tag function parameters with the noundef attribute whenever possible. Modeling Memory Effects; ^^^^^^^^^^^^^^^^^^^^^^^^. #. Mark functions as readnone/readonly/argmemonly or noreturn/nounwind when; known. The optimizer will try to infer these flags, but may not always be; able to. Manual annotations are particularly important for external; functions that the optimizer can not analyze. #. Use the lifetime.start/lifetime.end and invariant.start/invariant.end; intrinsics where possible. Common profitable uses are for stack like data; structures (thus allowing dead store elimination) and for describing; life times of allocas (thus allowing smaller stack sizes). #. Mark invariant locations using !invariant.load and TBAA's constant flags. Pass Ordering; ^^^^^^^^^^^^^. One of the most common mistakes made by new language frontend projects is to; use the existing -O2 or -O3 pass pipelines as is. These pass pipelines make a; good starting point for an optimizing compiler for any language, but they have; been carefully tuned for C and C++, not your target language. You will almost; certainly need to use a custom pass order to achieve optimal performance. A; couple specific suggestions:. #. For languages with numerous rarely executed guard conditions (e.g. null; checks, type checks, range checks) consider adding an extra ex",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:11953,optimiz,optimizer,11953,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,1,['optimiz'],['optimizer']
Performance," drawing.; 15. In main index.htm page browser can be disabled (nobrowser parameter) and; page can be used to display only specified items from the file; 16. Add support of TPolyMarker3D in binary I/O. ### September 2014; 1. First try to handle resize of the browser,; for the moment works only with collapsible layout; 2. Also first try to interactively move separation line between; browser and drawing field.; 3. Small fix of minor ticks drawing on the axis; 4. Introduce display class for MDI drawing. Provide two implementations -; 'collapsible' for old kind and 'tabs' for new kinds.; 5. Adjust size of color palette drawing when labels would take more place as provided.; 6. Add correct filling of statistic for TProfile,; fix small problem with underflow/overflow bins.; 7. Provide way to select display kind ('collapsible', 'tabs') in the simple GUI.; 8. Implement 'grid' display, one could specify any number of division like; 'grid 3x3' or 'grid 4x2'.; 9. MDI display object created at the moment when first draw is performed.; 10. Introduce painter class for TCanvas, support resize and update of canvas drawing; 11. Resize almost works for all layouts and all objects kinds.; 12. Implement JSROOT.GetUrlOption to extract options from document URL.; 13. Provide example fileitem.htm how read and display item from ROOT file.; 14. In default index.htm page one could specify 'file', 'layout',; 'item' and 'items' parameters like:; <http://root.cern.ch/js/3.0/index.htm?file=../files/hsimple.root&layout=grid3x2&item=hpx;1>; 15. Support direct reading of objects from sub-sub-directories.; 16. Introduce demo.htm, which demonstrates online usage of JSROOT.; 17. One could use demo.htm directly with THttpServer providing address like:; <http://localhost:8080/jsrootsys/demo/demo.htm?addr=../../Files/job1.root/hpx/root.json.gz&layout=3x3>; 18. Also for online server process url options like 'item', 'items', 'layout'; 19. Possibility to generate URL, which reproduces opened page with layout",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/js/changes.md:72758,perform,performed,72758,js/changes.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/js/changes.md,1,['perform'],['performed']
Performance," due to failure to; uphold the security model. One in particular is worth discussing as many others; will reduce to it. We wondered whether only the *first* load in a basic block could be checked. If; the check works as intended, it forms an invalid pointer that doesn't even; virtual-address translate in the hardware. It should fault very early on in its; processing. Maybe that would stop things in time for the misspeculated path to; fail to leak any secrets. This doesn't end up working because the processor is; fundamentally out-of-order, even in its speculative domain. As a consequence,; the attacker could cause the initial address computation itself to stall and; allow an arbitrary number of unrelated loads (including attacked loads of; secret data) to pass through. #### Interprocedural Checking. Modern x86 processors may speculate into called functions and out of functions; to their return address. As a consequence, we need a way to check loads that; occur after a misspeculated predicate but where the load and the misspeculated; predicate are in different functions. In essence, we need some interprocedural; generalization of the predicate state tracking. A primary challenge to passing; the predicate state between functions is that we would like to not require a; change to the ABI or calling convention in order to make this mitigation more; deployable, and further would like code mitigated in this way to be easily; mixed with code not mitigated in this way and without completely losing the; value of the mitigation. ##### Embed the predicate state into the high bit(s) of the stack pointer. We can use the same technique that allows hardening pointers to pass the; predicate state into and out of functions. The stack pointer is trivially; passed between functions and we can test for it having the high bits set to; detect when it has been marked due to misspeculation. The callsite instruction; sequence looks like (assuming a misspeculated state value of `-1`):; ```; ..",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:37949,load,loads,37949,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,2,['load'],"['load', 'loads']"
Performance," due to importing all C++ Modules at startup; we see overhead which depends on the number of preloaded modules. For; ROOT it is between 40-60 MB depending on the concrete configuration.; When the workload increases we notice that the overall memory performance; decreases in number of cases.; * Execution times -- likewise we have an execution overhead. For ; workflows which take ms the slowdown can be 2x. Increasing of the work; to seconds shows 50-60% slowdowns. The performance is dependent on many factors such as configuration of ROOT and; workflow. You can read more at our Intel IPCC-ROOT Showcase presentation; here (pp 25-33)[[8]]. #### Loading C++ Modules on Demand. In long term, we should optimize the preloading of modules to be a no-op and; avoid recursive behavior based on identifier lookup callbacks. Unfortunately,; at the moment the loading of C++ modules on demand shows significantly better; performance results. You can visit our continuous performance monitoring tool where we compare; the performance of ROOT against ROOT with a PCH [[9]].; *Note: if you get error 400, clean your cache or open a private browser session.*. ## How to use; C++ Modules in ROOT are default since v6.20 (Unix) and v6.22 (OSX). Enjoy. To disable C++ Modules in ROOT use `-Druntime_cxxmodules=Off`. ## Citing ROOT's C++ Modules; ```latex; % Peer-Reviewed Publication; %; % 22nd International Conference on Computing in High Energy and Nuclear Physics (CHEP); % 8-14 October, 2016, San Francisco, USA; %; @inproceedings{Vassilev_ROOTModules,; author = {Vassilev,V.},; title = {{Optimizing ROOT's Performance Using C++ Modules}},; journal = {Journal of Physics: Conference Series},; year = 2017,; month = {oct},; volume = {898},; number = {7},; pages = {072023},; doi = {10.1088/1742-6596/898/7/072023},; url = {https://iopscience.iop.org/article/10.1088/1742-6596/898/7/072023/pdf},; publisher = {{IOP} Publishing}; }; ```; ; # Acknowledgement. We would like to thank the ROOT team. We would like ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/README.CXXMODULES.md:19169,perform,performance,19169,README/README.CXXMODULES.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/README.CXXMODULES.md,2,['perform'],['performance']
Performance," elided. .. code-block:: llvm. entry:; %id = call token @llvm.coro.id(i32 0, ptr null, ptr null, ptr null); %need.dyn.alloc = call i1 @llvm.coro.alloc(token %id); br i1 %need.dyn.alloc, label %dyn.alloc, label %coro.begin; dyn.alloc:; %size = call i32 @llvm.coro.size.i32(); %alloc = call ptr @CustomAlloc(i32 %size); br label %coro.begin; coro.begin:; %phi = phi ptr [ null, %entry ], [ %alloc, %dyn.alloc ]; %hdl = call noalias ptr @llvm.coro.begin(token %id, ptr %phi). In the cleanup block, we will make freeing the coroutine frame conditional on; `coro.free`_ intrinsic. If allocation is elided, `coro.free`_ returns `null`; thus skipping the deallocation code:. .. code-block:: llvm. cleanup:; %mem = call ptr @llvm.coro.free(token %id, ptr %hdl); %need.dyn.free = icmp ne ptr %mem, null; br i1 %need.dyn.free, label %dyn.free, label %if.end; dyn.free:; call void @CustomFree(ptr %mem); br label %if.end; if.end:; ... With allocations and deallocations represented as described as above, after; coroutine heap allocation elision optimization, the resulting main will be:. .. code-block:: llvm. define i32 @main() {; entry:; call void @print(i32 4); call void @print(i32 5); call void @print(i32 6); ret i32 0; }. Multiple Suspend Points; -----------------------. Let's consider the coroutine that has more than one suspend point:. .. code-block:: c++. void *f(int n) {; for(;;) {; print(n++);; <suspend>; print(-n);; <suspend>; }; }. Matching LLVM code would look like (with the rest of the code remaining the same; as the code in the previous section):. .. code-block:: llvm. loop:; %n.addr = phi i32 [ %n, %entry ], [ %inc, %loop.resume ]; call void @print(i32 %n.addr) #4; %2 = call i8 @llvm.coro.suspend(token none, i1 false); switch i8 %2, label %suspend [i8 0, label %loop.resume; i8 1, label %cleanup]; loop.resume:; %inc = add nsw i32 %n.addr, 1; %sub = xor i32 %n.addr, -1; call void @print(i32 %sub); %3 = call i8 @llvm.coro.suspend(token none, i1 false); switch i8 %3, label %suspend",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:17783,optimiz,optimization,17783,interpreter/llvm-project/llvm/docs/Coroutines.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst,1,['optimiz'],['optimization']
Performance," ensure previous; global/generic; store/atomicrmw are; visible at agent scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global have; completed before; performing the; atomicrmw that is; being released. 3. buffer/global_atomic; 4. s_waitcnt vmcnt(0). - Must happen before; following; buffer_inv.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 5. buffer_inv sc1=1. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acq_rel - system - global 1. buffer_wbl2 sc0=1 sc1=1. - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at system scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global and L2 writeback; have completed before; performing the; a",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:320671,load,load,320671,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],['load']
Performance," equivalent to an Acquire load, and a Monotonic store following a; Release fence is roughly equivalent to a Release; store. SequentiallyConsistent fences behave as both an Acquire and a; Release fence, and additionally provide a total ordering with some; complicated guarantees, see the C++ standard for details. Frontends generating atomic instructions generally need to be aware of the; target to some degree; atomic instructions are guaranteed to be lock-free, and; therefore an instruction which is wider than the target natively supports can be; impossible to generate. .. _Atomic orderings:. Atomic orderings; ================. In order to achieve a balance between performance and necessary guarantees,; there are six levels of atomicity. They are listed in order of strength; each; level includes all the guarantees of the previous level except for; Acquire/Release. (See also `LangRef Ordering <LangRef.html#ordering>`_.). .. _NotAtomic:. NotAtomic; ---------. NotAtomic is the obvious, a load or store which is not atomic. (This isn't; really a level of atomicity, but is listed here for comparison.) This is; essentially a regular load or store. If there is a race on a given memory; location, loads from that location return undef. Relevant standard; This is intended to match shared variables in C/C++, and to be used in any; other context where memory access is necessary, and a race is impossible. (The; precise definition is in `LangRef Memory Model <LangRef.html#memmodel>`_.). Notes for frontends; The rule is essentially that all memory accessed with basic loads and stores; by multiple threads should be protected by a lock or other synchronization;; otherwise, you are likely to run into undefined behavior. If your frontend is; for a ""safe"" language like Java, use Unordered to load and store any shared; variable. Note that NotAtomic volatile loads and stores are not properly; atomic; do not try to use them as a substitute. (Per the C/C++ standards,; volatile does provide som",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Atomics.rst:6006,load,load,6006,interpreter/llvm-project/llvm/docs/Atomics.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Atomics.rst,1,['load'],['load']
Performance," exactly the way you; want them. Write extensive tests to check that you're getting good; diagnostics for mistakes and that you can use various forms of; subexpressions with your expression.; * When type-checking a type or subexpression, make sure to first check; whether the type is ""dependent"" (``Type::isDependentType()``) or whether a; subexpression is type-dependent (``Expr::isTypeDependent()``). If any of; these return ``true``, then you're inside a template and you can't do much; type-checking now. That's normal, and your AST node (when you get there); will have to deal with this case. At this point, you can write tests that; use your expression within templates, but don't try to instantiate the; templates.; * For each subexpression, be sure to call ``Sema::CheckPlaceholderExpr()``; to deal with ""weird"" expressions that don't behave well as subexpressions.; Then, determine whether you need to perform lvalue-to-rvalue conversions; (``Sema::DefaultLvalueConversions``) or the usual unary conversions; (``Sema::UsualUnaryConversions``), for places where the subexpression is; producing a value you intend to use.; * Your ``BuildXXX`` function will probably just return ``ExprError()`` at; this point, since you don't have an AST. That's perfectly fine, and; shouldn't impact your testing. #. Introduce an AST node for your new expression. This starts with declaring; the node in ``include/Basic/StmtNodes.td`` and creating a new class for your; expression in the appropriate ``include/AST/Expr*.h`` header. It's best to; look at the class for a similar expression to get ideas, and there are some; specific things to watch for:. * If you need to allocate memory, use the ``ASTContext`` allocator to; allocate memory. Never use raw ``malloc`` or ``new``, and never hold any; resources in an AST node, because the destructor of an AST node is never; called.; * Make sure that ``getSourceRange()`` covers the exact source range of your; expression. This is needed for diagnostics and for ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/InternalsManual.rst:147524,perform,perform,147524,interpreter/llvm-project/clang/docs/InternalsManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/InternalsManual.rst,1,['perform'],['perform']
Performance," execution mode.; - If OpenCL, omit lgkmcnt(0).; - Must happen before; the following; buffer_wbinvl1_vol and any; following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic value being; acquired. 3. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. load atomic acquire - agent - global 1. buffer/global_load; glc=1; 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the load; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale global data. load atomic acquire - system - global 1. buffer/global/flat_load; glc=1; 2. s_waitcnt vmcnt(0). - Must happen before; following buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures the load; has completed; before invalidating; the cache. 3. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. load atomic acquire - agent - generic 1. flat_load glc=1; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the flat_load; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. load atomic acquire - system - generic 1. flat_load glc=1; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL omit; lgkmcnt(0).; - Must ha",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:247323,load,load,247323,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,"['cache', 'load']","['cache', 'load']"
Performance," execution; mode, omit.; - Ensures that; following; loads will not see; stale data. atomicrmw acq_rel - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_atomic; 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than the local load; atomic value being; acquired. atomicrmw acq_rel - workgroup - generic 1. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit; lgkmcnt(0).; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; have; completed before; performing the; atomicrmw that is; being released. 2. flat_atomic; 3. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If not TgSplit execution; mode, omit vmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Must happen before; the following; buffer_inv and; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic value being; acquired. 3. buffer_inv sc0=1. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. atomicrmw acq_rel - agent - global 1. buffer_wbl2 sc1=1. - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at agent scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; a",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:318984,perform,performing,318984,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['perform'],['performing']
Performance," execution; mode, omit.; - Ensures that; following; loads will not see; stale data. atomicrmw acq_rel - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_atomic; 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than the local load; atomic value being; acquired. atomicrmw acq_rel - workgroup - generic 1. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit; lgkmcnt(0).; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; have; completed before; performing the; atomicrmw that is; being released. 2. flat_atomic; 3. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If not TgSplit execution; mode, omit vmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Must happen before; the following; buffer_wbinvl1_vol and; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic value being; acquired. 3. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. atomicrmw acq_rel - agent - global 1. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_w",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:268471,perform,performing,268471,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['perform'],['performing']
Performance," execution; mode, omit.; - Ensures that; following; loads will not see; stale data. fence acq_rel - agent *none* 1. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate; (see comment for; previous fence).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; buffer_wbinvl1_vol.; - Ensures that the; preceding; global/local/generic; load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; acquire-fence-paired-atomic); has completed; before invalidating; the cache. This; satisfies the; requirements of; acquire.; - Ensures that all; previous memory; operations have; completed before a; following; global/local/generic; store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; release-fence-paired-atomic).; This satisfies the; requirements of; release. 2. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. This; satisfies the; requirements of; acquire. fence acq_rel - system *none* 1. buffer_wbl2. - If OpenCL and; address space is; local, omit.; - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at system scope. 2. s_waitcnt lgkmcnt(0) ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:276984,load,load,276984,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,"['cache', 'load']","['cache', 'load']"
Performance," expected value of ``val`` with probability(or confidence) ``prob``, which can; be used by optimizers. Arguments:; """""""""""""""""""". The ``llvm.expect.with.probability`` intrinsic takes three arguments. The first; argument is a value. The second argument is an expected value. The third; argument is a probability. Semantics:; """""""""""""""""""". This intrinsic is lowered to the ``val``. .. _int_assume:. '``llvm.assume``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare void @llvm.assume(i1 %cond). Overview:; """""""""""""""""". The ``llvm.assume`` allows the optimizer to assume that the provided; condition is true. This information can then be used in simplifying other parts; of the code. More complex assumptions can be encoded as; :ref:`assume operand bundles <assume_opbundles>`. Arguments:; """""""""""""""""""". The argument of the call is the condition which the optimizer may assume is; always true. Semantics:; """""""""""""""""""". The intrinsic allows the optimizer to assume that the provided condition is; always true whenever the control flow reaches the intrinsic call. No code is; generated for this intrinsic, and instructions that contribute only to the; provided condition are not used for code generation. If the condition is; violated during execution, the behavior is undefined. Note that the optimizer might limit the transformations performed on values; used by the ``llvm.assume`` intrinsic in order to preserve the instructions; only used to form the intrinsic's input argument. This might prove undesirable; if the extra information provided by the ``llvm.assume`` intrinsic does not cause; sufficient overall improvement in code quality. For this reason,; ``llvm.assume`` should not be used to document basic mathematical invariants; that the optimizer can otherwise deduce or facts that are of little use to the; optimizer. .. _int_ssa_copy:. '``llvm.ssa.copy``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare type @llvm.ssa.copy(type returned %operand)",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:935599,optimiz,optimizer,935599,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['optimiz'],['optimizer']
Performance," explanation about what we mean.; These features are:. End-User Features:. Fast compiles and low memory use; Expressive diagnostics; GCC compatibility. Utility and Applications:. Library based architecture; Support diverse clients; Integration with IDEs; Use the LLVM 'BSD' License. Internal Design and Implementation:. A real-world, production quality compiler; A simple and hackable code base; A single unified parser for C, Objective C, C++,; and Objective C++; Conformance with C/C++/ObjC and their; variants. End-User Features. Fast compiles and Low Memory Use. A major focus of our work on clang is to make it fast, light and scalable.; The library-based architecture of clang makes it straight-forward to time and; profile the cost of each layer of the stack, and the driver has a number of; options for performance analysis. Many detailed benchmarks can be found online.; Compile time performance is important, but when using clang as an API, often; memory use is even more so: the less memory the code takes the more code you can; fit into memory at a time (useful for whole program analysis tools, for; example).; In addition to being efficient when pitted head-to-head against GCC in batch; mode, clang is built with a library based; architecture that makes it relatively easy to adapt it and build new tools; with it. This means that it is often possible to apply out-of-the-box thinking; and novel techniques to improve compilation in various ways. Expressive Diagnostics. In addition to being fast and functional, we aim to make Clang extremely user; friendly. As far as a command-line compiler goes, this basically boils down to; making the diagnostics (error and warning messages) generated by the compiler; be as useful as possible. There are several ways that we do this, but the; most important are pinpointing exactly what is wrong in the program,; highlighting related information so that it is easy to understand at a glance,; and making the wording as clear as possible.; Here ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/features.html:1041,perform,performance,1041,interpreter/llvm-project/clang/www/features.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/features.html,2,['perform'],['performance']
Performance," express the unpredictability of control; flow. Similar to the llvm.expect intrinsic, it may be used to alter; optimizations related to compare and branch instructions. The metadata; is treated as a boolean value; if it exists, it signals that the branch; or switch that it is attached to is completely unpredictable. .. _md_dereferenceable:. '``dereferenceable``' Metadata; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The existence of the ``!dereferenceable`` metadata on the instruction; tells the optimizer that the value loaded is known to be dereferenceable,; otherwise the behavior is undefined.; The number of bytes known to be dereferenceable is specified by the integer; value in the metadata node. This is analogous to the ''dereferenceable''; attribute on parameters and return values. .. _md_dereferenceable_or_null:. '``dereferenceable_or_null``' Metadata; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The existence of the ``!dereferenceable_or_null`` metadata on the; instruction tells the optimizer that the value loaded is known to be either; dereferenceable or null, otherwise the behavior is undefined.; The number of bytes known to be dereferenceable is specified by the integer; value in the metadata node. This is analogous to the ''dereferenceable_or_null''; attribute on parameters and return values. .. _llvm.loop:. '``llvm.loop``'; ^^^^^^^^^^^^^^^. It is sometimes useful to attach information to loop constructs. Currently,; loop metadata is implemented as metadata attached to the branch instruction; in the loop latch block. The loop metadata node is a list of; other metadata nodes, each representing a property of the loop. Usually,; the first item of the property node is a string. For example, the; ``llvm.loop.unroll.count`` suggests an unroll factor to the loop; unroller:. .. code-block:: llvm. br i1 %exitcond, label %._crit_edge, label %.lr.ph, !llvm.loop !0; ...; !0 = !{!0, !1, !2}; !1 = !{!""llvm.loop.unroll.enable""}; !2 = !{!""llvm.loop.unroll.count"", i32 4}. For legacy reason",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:293245,optimiz,optimizer,293245,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,2,"['load', 'optimiz']","['loaded', 'optimizer']"
Performance," expression or statement needs to be introduced, along; with patterns to follow to ensure that the new expression or statement works; well across all of the C languages. We focus on expressions, but statements; are similar. #. Introduce parsing actions into the parser. Recursive-descent parsing is; mostly self-explanatory, but there are a few things that are worth keeping; in mind:. * Keep as much source location information as possible! You'll want it later; to produce great diagnostics and support Clang's various features that map; between source code and the AST.; * Write tests for all of the ""bad"" parsing cases, to make sure your recovery; is good. If you have matched delimiters (e.g., parentheses, square; brackets, etc.), use ``Parser::BalancedDelimiterTracker`` to give nice; diagnostics when things go wrong. #. Introduce semantic analysis actions into ``Sema``. Semantic analysis should; always involve two functions: an ``ActOnXXX`` function that will be called; directly from the parser, and a ``BuildXXX`` function that performs the; actual semantic analysis and will (eventually!) build the AST node. It's; fairly common for the ``ActOnCXX`` function to do very little (often just; some minor translation from the parser's representation to ``Sema``'s; representation of the same thing), but the separation is still important:; C++ template instantiation, for example, should always call the ``BuildXXX``; variant. Several notes on semantic analysis before we get into construction; of the AST:. * Your expression probably involves some types and some subexpressions.; Make sure to fully check that those types, and the types of those; subexpressions, meet your expectations. Add implicit conversions where; necessary to make sure that all of the types line up exactly the way you; want them. Write extensive tests to check that you're getting good; diagnostics for mistakes and that you can use various forms of; subexpressions with your expression.; * When type-checking a type",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/InternalsManual.rst:145872,perform,performs,145872,interpreter/llvm-project/clang/docs/InternalsManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/InternalsManual.rst,1,['perform'],['performs']
Performance," fMyInt3; Char_t fMyCode[4]; };"" );. from ROOT import MyStruct; mystruct = MyStruct(); f = TFile('mytree.root','RECREATE'); tree = TTree('T','Just A Tree'); tree.Branch('myints',mystruct,'MyInt1/I:MyInt2:MyInt3'); tree.Branch('mycode',AddressOf(mystruct,'fMyCode'),'MyCode/C'); for i in range(0,10):; mystruct.fMyInt1 = i; mystruct.fMyInt2 = i*i; mystruct.fMyInt3 = i*i*i; mystruct.fMyCode = ""%03d"" % i # note string assignment. tree.Fill(). f.Write(); f.Close(); ```. The C++ class is defined through the `gROOT.ProcessLine()` call, and; note how the `AddressOf()` function is used for data members of built-in; type. Most of the above is for ROOT version 5.02 and later only. For; older releases, and without further support, here is an example as to; how you can get hold of a pointer-to-pointer to a ROOT object:. ``` {.cpp}; h = TH1F(); addressofobject = array('i',[h.IsA().DynamicCast(h.IsA(),h)]); ```. ### Using Your Own Classes. A user's own classes can be accessed after loading, either directly or; indirectly, the library that contains the dictionary. One easy way of; obtaining such a library, is by using ACLiC:. ``` {.cpp}; $ cat MyClass.C; class MyClass {; public:. MyClass(int value = 0) {; m_value = value;; }. void SetValue(int value) {; m_value = value;; }. int GetValue() {; return m_value;; }. private:; int m_value;; };. $ echo .L MyClass.C+ | root.exe -b; [...]; Info in <TUnixSystem::ACLiC>: creating shared library [..]/./MyClass_C.so; $; ```. Then you can use it, for example, like so:. ``` {.cpp}; from ROOT import gSystem. # load library with MyClass dictionary; gSystem.Load('MyClass_C'). # get MyClass from ROOT; from ROOT import MyClass; # use MyClass; m = MyClass(42); print(m.GetValue()); ```. You can also load a macro directly, but if you do not use ACLiC, you; will be restricted to use the default constructor of your class, which; is otherwise fully functional. For example:. ``` {.cpp}; from ROOT import gROOT. # load MyClass definition macro (append '+' to us",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/PythonRuby.md:32569,load,loading,32569,documentation/users-guide/PythonRuby.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/PythonRuby.md,1,['load'],['loading']
Performance," fast selectors share the :ref:`pipeline`, and targets can; configure that pipeline to better suit their needs. Design and Implementation Reference; ===================================. More information on the design and implementation of GlobalISel can be found in; the following sections. .. toctree::; :maxdepth: 1. GMIR; GenericOpcode; MIRPatterns; Pipeline; Porting; Resources. More information on specific passes can be found in the following sections:. .. toctree::; :maxdepth: 1. IRTranslator; Legalizer; RegBankSelect; InstructionSelect; KnownBits. .. _progress:. Progress and Future Work; ========================. The initial goal is to replace FastISel on AArch64. The next step will be to; replace SelectionDAG as the optimized ISel. ``NOTE``:; While we iterate on GlobalISel, we strive to avoid affecting the performance of; SelectionDAG, FastISel, or the other MIR passes. For instance, the types of; :ref:`gmir-gvregs` are stored in a separate table in ``MachineRegisterInfo``,; that is destroyed after :ref:`instructionselect`. .. _progress-fastisel:. FastISel Replacement; --------------------. For the initial FastISel replacement, we intend to fallback to SelectionDAG on; selection failures. Currently, compile-time of the fast pipeline is within 1.5x of FastISel.; We're optimistic we can get to within 1.1/1.2x, but beating FastISel will be; challenging given the multi-pass approach.; Still, supporting all IR (via a complete legalizer) and avoiding the fallback; to SelectionDAG in the worst case should enable better amortized performance; than SelectionDAG+FastISel. ``NOTE``:; We considered never having a fallback to SelectionDAG, instead deciding early; whether a given function is supported by GlobalISel or not. The decision would; be based on :ref:`milegalizer` queries.; We abandoned that for two reasons:; a) on IR inputs, we'd need to basically simulate the :ref:`irtranslator`;; b) to be robust against unforeseen failures and to enable iterative; improvements.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/index.rst:2832,perform,performance,2832,interpreter/llvm-project/llvm/docs/GlobalISel/index.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/index.rst,1,['perform'],['performance']
Performance," faster than the usual; shape-to-shape comparison. For a 100% reliability, one can perform the; check at the level of a single volume by using `option`=""`d`"" or; `option`=""`d<number>`"" to perform overlap checking by sampling the; volume with \<`number`\> random points (default 1 million). This; produces also a picture showing in red the overlapping region and; estimates the volume of the overlaps. An extrusion *A)* is declared in any of the following cases:. - At least one of the vertices of the daughter mesh representation is; outside the mother volume (in fact its shape) and having a safety; distance to the mother greater than the desired value;; - At least one of the mother vertices is contained also by one of its; daughters, in the same conditions. An overlap *B)* is declared if:. - At least one vertex of a positioned volume mesh is contained (having; a safety bigger than the accepted maximum value) by other positioned; volume inside the same container. The check is performed also by; inverting the candidates. The code is highly optimized to avoid checking candidates that are far; away in space by performing a fast check on their bounding boxes. Once; the checking tool is fired-up inside a volume or at top level, the list; of overlaps (visible as Illegal overlaps inside a TBrowser) held; by the manager class will be filled with TGeoOverlap objects; containing a full description of the detected overlaps. The list is; sorted in the decreasing order of the overlapping distance, extrusions; coming first. An overlap object name represents the full description of; the overlap, containing both candidate node names and a letter; (x-extrusion, o-overlap) representing the type. Double-clicking an; overlap item in a TBrowser produces a picture of the overlap; containing only the two overlapping nodes (one in blue and one in green); and having the critical vertices represented by red points. The picture; can be rotated/zoomed or drawn in X3d as any other view. Calling; gGeo",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:94662,perform,performed,94662,geom/geom/doc/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md,1,['perform'],['performed']
Performance," faster, because we are using a ""smarter"" IR (SSA based). > BTW, about SGI, ""borrowing"" SSA-based optimizations from one compiler and; > putting it into another is not necessarily easier than re-doing it.; > Optimization code is usually heavily tied in to the specific IR they use. Understood. The only reason that I brought this up is because SGI's IR is; more similar to LLVM than it is different in many respects (SSA based,; relatively low level, etc), and could be easily adapted. Also their; optimizations are written in C++ and are actually somewhat; structured... of course it would be no walk in the park, but it would be; much less time consuming to adapt, say, SSA-PRE than to rewrite it. > But your larger point is valid that adding SSA based optimizations is; > feasible and should be fun. (Again, link time cost is the issue.). Assuming linktime cost wasn't an issue, the question is: ; Does using GCC's backend buy us anything?. > It also occurs to me that GCC is probably doing quite a bit of back-end; > optimization (step 16 in your list). Do you have a breakdown of that?. Not really. The irritating part of GCC is that it mixes it all up and; doesn't have a clean separation of concerns. A lot of the ""back end; optimization"" happens right along with other data optimizations (ie, CSE; of machine specific things). As far as REAL back end optimizations go, it looks something like this:. 1. Instruction combination: try to make CISCy instructions, if available; 2. Register movement: try to get registers in the right places for the; architecture to avoid register to register moves. For example, try to get; the first argument of a function to naturally land in %o0 for sparc.; 3. Instruction scheduling: 'nuff said :); 4. Register class preferencing: ??; 5. Local register allocation; 6. global register allocation; 7. Spilling; 8. Local regalloc; 9. Jump optimization; 10. Delay slot scheduling; 11. Branch shorting for CISC machines; 12. Instruction selection & peephole optim",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-06-01-GCCOptimizations2.txt:1877,optimiz,optimization,1877,interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-06-01-GCCOptimizations2.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-06-01-GCCOptimizations2.txt,1,['optimiz'],['optimization']
Performance," faster, to push eax on entry and to; pop into a dummy register instead of using addl/subl of esp. Just don't pop ; into any return registers :). //===---------------------------------------------------------------------===//. The X86 backend should fold (branch (or (setcc, setcc))) into multiple ; branches. We generate really poor code for:. double testf(double a) {; return a == 0.0 ? 0.0 : (a > 0.0 ? 1.0 : -1.0);; }. For example, the entry BB is:. _testf:; subl $20, %esp; pxor %xmm0, %xmm0; movsd 24(%esp), %xmm1; ucomisd %xmm0, %xmm1; setnp %al; sete %cl; testb %cl, %al; jne LBB1_5 # UnifiedReturnBlock; LBB1_1: # cond_true. it would be better to replace the last four instructions with:. 	jp LBB1_1; 	je LBB1_5; LBB1_1:. We also codegen the inner ?: into a diamond:. cvtss2sd LCPI1_0(%rip), %xmm2; cvtss2sd LCPI1_1(%rip), %xmm3; ucomisd %xmm1, %xmm0; ja LBB1_3 # cond_true; LBB1_2: # cond_true; movapd %xmm3, %xmm2; LBB1_3: # cond_true; movapd %xmm2, %xmm0; ret. We should sink the load into xmm3 into the LBB1_2 block. This should; be pretty easy, and will nuke all the copies. //===---------------------------------------------------------------------===//. This:; #include <algorithm>; inline std::pair<unsigned, bool> full_add(unsigned a, unsigned b); { return std::make_pair(a + b, a + b < a); }; bool no_overflow(unsigned a, unsigned b); { return !full_add(a, b).second; }. Should compile to:; 	addl	%esi, %edi; 	setae	%al; 	movzbl	%al, %eax; 	ret. on x86-64, instead of the rather stupid-looking:; 	addl	%esi, %edi; 	setb	%al; 	xorb	$1, %al; 	movzbl	%al, %eax; 	ret. //===---------------------------------------------------------------------===//. The following code:. bb114.preheader:		; preds = %cond_next94; 	%tmp231232 = sext i16 %tmp62 to i32		; <i32> [#uses=1]; 	%tmp233 = sub i32 32, %tmp231232		; <i32> [#uses=1]; 	%tmp245246 = sext i16 %tmp65 to i32		; <i32> [#uses=1]; 	%tmp252253 = sext i16 %tmp68 to i32		; <i32> [#uses=1]; 	%tmp254 = sub i32 32, %tmp252253		; <i32> [#use",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README.txt:14444,load,load,14444,interpreter/llvm-project/llvm/lib/Target/X86/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README.txt,2,['load'],['load']
Performance," fields. * ``string FilterClass``. The table will have one entry for each record; that derives from this class. * ``string FilterClassField``. This is an optional field of ``FilterClass``; which should be `bit` type. If specified, only those records with this field; being true will have corresponding entries in the table. This field won't be; included in generated C++ fields if it isn't included in ``Fields`` list. * ``string CppTypeName``. The name of the C++ struct/class type of the; table that holds the entries. If unspecified, the ``FilterClass`` name is; used. * ``list<string> Fields``. A list of the names of the fields *in the; collected records* that contain the data for the table entries. The order of; this list determines the order of the values in the C++ initializers. See; below for information about the types of these fields. * ``list<string> PrimaryKey``. The list of fields that make up the; primary key. * ``string PrimaryKeyName``. The name of the generated C++ function; that performs a lookup on the primary key. * ``bit PrimaryKeyEarlyOut``. See the third example below. TableGen attempts to deduce the type of each of the table fields so that it; can format the C++ initializers in the emitted table. It can deduce ``bit``,; ``bits<n>``, ``string``, ``Intrinsic``, and ``Instruction``. These can be; used in the primary key. Any other field types must be specified; explicitly; this is done as shown in the second example below. Such fields; cannot be used in the primary key. One special case of the field type has to do with code. Arbitrary code is; represented by a string, but has to be emitted as a C++ initializer without; quotes. If the code field was defined using a code literal (``[{...}]``),; then TableGen will know to emit it without quotes. However, if it was; defined using a string literal or complex string expression, then TableGen; will not know. In this case, you can force TableGen to treat the field as; code by including the following line in the",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TableGen/BackEnds.rst:24211,perform,performs,24211,interpreter/llvm-project/llvm/docs/TableGen/BackEnds.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TableGen/BackEnds.rst,1,['perform'],['performs']
Performance," file of source code). So the first thing we need to do is; construct one for our fib.ks file. DWARF Emission Setup; ====================. Similar to the ``IRBuilder`` class we have a; `DIBuilder <https://llvm.org/doxygen/classllvm_1_1DIBuilder.html>`_ class; that helps in constructing debug metadata for an LLVM IR file. It; corresponds 1:1 similarly to ``IRBuilder`` and LLVM IR, but with nicer names.; Using it does require that you be more familiar with DWARF terminology than; you needed to be with ``IRBuilder`` and ``Instruction`` names, but if you; read through the general documentation on the; `Metadata Format <https://llvm.org/docs/SourceLevelDebugging.html>`_ it; should be a little more clear. We'll be using this class to construct all; of our IR level descriptions. Construction for it takes a module so we; need to construct it shortly after we construct our module. We've left it; as a global static variable to make it a bit easier to use. Next we're going to create a small container to cache some of our frequent; data. The first will be our compile unit, but we'll also write a bit of; code for our one type since we won't have to worry about multiple typed; expressions:. .. code-block:: c++. static std::unique_ptr<DIBuilder> DBuilder;. struct DebugInfo {; DICompileUnit *TheCU;; DIType *DblTy;. DIType *getDoubleTy();; } KSDbgInfo;. DIType *DebugInfo::getDoubleTy() {; if (DblTy); return DblTy;. DblTy = DBuilder->createBasicType(""double"", 64, dwarf::DW_ATE_float);; return DblTy;; }. And then later on in ``main`` when we're constructing our module:. .. code-block:: c++. DBuilder = std::make_unique<DIBuilder>(*TheModule);. KSDbgInfo.TheCU = DBuilder->createCompileUnit(; dwarf::DW_LANG_C, DBuilder->createFile(""fib.ks"", "".""),; ""Kaleidoscope Compiler"", false, """", 0);. There are a couple of things to note here. First, while we're producing a; compile unit for a language called Kaleidoscope we used the language; constant for C. This is because a debugger wouldn't necess",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl09.rst:6740,cache,cache,6740,interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl09.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl09.rst,1,['cache'],['cache']
Performance," file. CASE 3 : autof = 0; The AutoFlush mechanism is disabled. Flushing the buffers at regular intervals optimize the location of; consecutive entries on the disk. Changed the default value of AutoSave from 10 to 30 MBytes. New class TTreePerfStats; This new class is an important tool to measure the I/O performance of a Tree.; It shows the locations in the file when reading a Tree. In particular it is easy; to see the performance of the Tree Cache. The results can be:. drawn in a canvas.; printed on standard output.; saved to a file for processing later. Example of use; {; TFile *f = TFile::Open(""RelValMinBias-GEN-SIM-RECO.root"");; T = (TTree*)f->Get(""Events"");; Long64_t nentries = T->GetEntries();; T->SetCacheSize(10000000);; T->AddBranchToCache(""*"");. TTreePerfStats *ps= new TTreePerfStats(""ioperf"",T);. for (Int_t i=0;i<nentries;i++) {; T->GetEntry(i);; }; ps->SaveAs(""atlas_perf.root"");; }. then, in a root interactive session, one can do:. root > TFile f(""atlas_perf.root"");; root > ioperf->Draw();; root > ioperf->Print();. The Draw or Print functions print the following information:. TreeCache = TTree cache size in MBytes; N leaves = Number of leaves in the TTree; ReadTotal = Total number of zipped bytes read; ReadUnZip = Total number of unzipped bytes read; ReadCalls = Total number of disk reads; ReadSize = Average read size in KBytes; Readahead = Readahead size in KBytes; Readextra = Readahead overhead in percent; Real Time = Real Time in seconds; CPU Time = CPU Time in seconds; Disk Time = Real Time spent in pure raw disk IO; Disk IO = Raw disk IO speed in MBytes/second; ReadUZRT = Unzipped MBytes per RT second; ReadUZCP = Unipped MBytes per CP second; ReadRT = Zipped MBytes per RT second; ReadCP = Zipped MBytes per CP second. The Figure below shows the result for an original non optimized file when; the Tree Cache is not used. The Figure below shows the result for the above data file written with the; new version of ROOT and when the Tree cache is activated. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v526/index.html:8067,cache,cache,8067,tree/doc/v526/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v526/index.html,7,"['Cache', 'cache', 'optimiz']","['Cache', 'cache', 'optimized']"
Performance," file. You should also write; additional code for a subclass of the ``TargetRegisterInfo`` class that; represents the class register file data used for register allocation and also; describes the interactions between registers. * Describe the instruction set of the target. Use TableGen to generate code; for target-specific instructions from target-specific versions of; ``TargetInstrFormats.td`` and ``TargetInstrInfo.td``. You should write; additional code for a subclass of the ``TargetInstrInfo`` class to represent; machine instructions supported by the target machine. * Describe the selection and conversion of the LLVM IR from a Directed Acyclic; Graph (DAG) representation of instructions to native target-specific; instructions. Use TableGen to generate code that matches patterns and; selects instructions based on additional information in a target-specific; version of ``TargetInstrInfo.td``. Write code for ``XXXISelDAGToDAG.cpp``,; where ``XXX`` identifies the specific target, to perform pattern matching and; DAG-to-DAG instruction selection. Also write code in ``XXXISelLowering.cpp``; to replace or remove operations and data types that are not supported; natively in a SelectionDAG. * Write code for an assembly printer that converts LLVM IR to a GAS format for; your target machine. You should add assembly strings to the instructions; defined in your target-specific version of ``TargetInstrInfo.td``. You; should also write code for a subclass of ``AsmPrinter`` that performs the; LLVM-to-assembly conversion and a trivial subclass of ``TargetAsmInfo``. * Optionally, add support for subtargets (i.e., variants with different; capabilities). You should also write code for a subclass of the; ``TargetSubtarget`` class, which allows you to use the ``-mcpu=`` and; ``-mattr=`` command-line options. * Optionally, add JIT support and create a machine code emitter (subclass of; ``TargetJITInfo``) that is used to emit binary code directly into memory. In the ``.cpp`` and ``.h``.",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:4662,perform,perform,4662,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,1,['perform'],['perform']
Performance," files opened even further. Update hadd and TFileMerger so that they prefix all their information message; with their names (when running hadd, the TFileMerger message are prefixed by hadd):. $ hadd -v 0 -f output.root input1.root input2.root; $ hadd -v 1 -f output.root input1.root input2.root; hadd merged 2 input files in output.root.; $ hadd -v 2 -f output.root input1.root input2.root; hadd target file: output.root; hadd Source file 1: input1.root; hadd Source file 2: input2.root; hadd Target path: output.root:/. Introduce non-static version of TFile::Cp allows the copy of; an existing TFile object. Introduce new explicit interface for providing reseting; capability after a merge. If a class has a method with; the name and signature:. void ResetAfterMerge(TFileMergeInfo*);. it will be used by a TMemFile to reset its objects after; a merge operation has been done. If this method does not exist, the TClass will use; a method with the name and signature:. void Reset(Optiont_t *);. TClass now provides a quick access to these merging; function via TClass::GetResetAfterMerge. The wrapper function; is automatically created by rootcint and can be installed; via TClass::SetResetAfterMerge. The wrapper function should have; the signature/type ROOT::ResetAfterMergeFunc_t:. void (*)(void *thisobj, TFileMergeInfo*);. ResetAfterMerge functions were added to the following classes:; TDirectoryFile, TMemFile, TTree, TChain, TBranch, TBranchElement,; TBranchClones, TBranchObject and TBranchRef. Avoid leaking the inner object in a container like vector<vector<MyClass*> > ; and vector<vector<MyClass*> *> . Put in place the infrastructure to optimize the I/O writes in the same way we optimized the I/O reads. Add the function TBuffer::AutoExpand to centralize the automatic; buffer extension policy. This enable the ability to tweak it later; (for example instead of always doubling the size, increasing by; only at most 2Mb or take hints from the number of entries already; in a TBasket). ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/io/doc/v532/index.html:9408,optimiz,optimize,9408,io/doc/v532/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/doc/v532/index.html,4,['optimiz'],"['optimize', 'optimized']"
Performance," first-level; instrumentation, by making sure that the number of times we took an; exit edge from the hot trace is less than 10% of the number of; iterations. LLC has been taught to recognize llvm_first_trigger() calls and NOT; generate saves and restores of caller-saved registers around these; calls. Phase behavior; --------------. We turn off llvm_first_trigger() calls with NOPs, but this would hide; phase behavior from us (when some funcs/traces stop being hot and; others become hot.). We have a SIGALRM timer that counts time for us. Every time we get a; SIGALRM we look at our priority queue of locations where we have; removed llvm_first_trigger() calls. Each location is inserted along; with a time when we will next turn instrumentation back on for that; call site. If the time has arrived for a particular call site, we pop; that off the prio. queue and turn instrumentation back on for that; call site. Generating traces; -----------------. When we finally generate an optimized trace we first copy the code; into the trace cache. This leaves us with 3 copies of the code: the; original code, the instrumented code, and the optimized trace. The; optimized trace does not have instrumentation. The original code and; the instrumented code are modified to have a branch to the trace; cache, where the optimized traces are kept. We copy the code from the original to the instrumentation version; by tracing the LLVM-to-Machine code basic block map and then copying; each machine code basic block we think is in the hot region into the; trace cache. Then we instrument that code. The process is similar for; generating the final optimized trace; we copy the same basic blocks; because we might need to put in fixup code for exit BBs. LLVM basic blocks are not typically used in the Reoptimizer except; for the mapping information. We are restricted to using single instructions to branch between the; original code, trace, and instrumented code. So we have to keep the; code copies in memo",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2003-06-25-Reoptimizer1.txt:3504,optimiz,optimized,3504,interpreter/llvm-project/llvm/docs/HistoricalNotes/2003-06-25-Reoptimizer1.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2003-06-25-Reoptimizer1.txt,2,"['cache', 'optimiz']","['cache', 'optimized']"
Performance," fixed-width vectors is still to use a shufflevector, as that may allow for more; optimization opportunities. For example:. .. code-block:: text. llvm.experimental.vector.splice(<A,B,C,D>, <E,F,G,H>, 1); ==> <B, C, D, E> index; llvm.experimental.vector.splice(<A,B,C,D>, <E,F,G,H>, -3); ==> <B, C, D, E> trailing elements. Arguments:; """""""""""""""""""". The first two operands are vectors with the same type. The start index is imm; modulo the runtime number of elements in the source vector. For a fixed-width; vector <N x eltty>, imm is a signed integer constant in the range; -N <= imm < N. For a scalable vector <vscale x N x eltty>, imm is a signed; integer constant in the range -X <= imm < X where X=vscale_range_min * N. '``llvm.experimental.stepvector``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. This is an overloaded intrinsic. You can use ``llvm.experimental.stepvector``; to generate a vector whose lane values comprise the linear sequence; <0, 1, 2, ...>. It is primarily intended for scalable vectors. ::. declare <vscale x 4 x i32> @llvm.experimental.stepvector.nxv4i32(); declare <vscale x 8 x i16> @llvm.experimental.stepvector.nxv8i16(). The '``llvm.experimental.stepvector``' intrinsics are used to create vectors; of integers whose elements contain a linear sequence of values starting from 0; with a step of 1. This experimental intrinsic can only be used for vectors; with integer elements that are at least 8 bits in size. If the sequence value; exceeds the allowed limit for the element type then the result for that lane is; undefined. These intrinsics work for both fixed and scalable vectors. While this intrinsic; is marked as experimental, the recommended way to express this operation for; fixed-width vectors is still to generate a constant vector instead. Arguments:; """""""""""""""""""". None. '``llvm.experimental.get.vector.length``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare i32 @",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:672621,scalab,scalable,672621,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['scalab'],['scalable']
Performance," fixes and improvements in the PROOF system occured since the release of 5.34/00 are available both in the latest 5.34 tags and in 6.00/00.; The following is a summary of the major modifications since 5.34 . ### New developments/functionality. - Several improvements in the merging phase; in particular:; - Modification of output sending protocol to control memory usage, significantly reducing the memory footprint on the master, in particular when merging; large numbers of histograms.; - Use an hash table for the output list to significantly speed up names lookups during merging.; - Add support for dynamic addition of workers to a currently running process (currently supported by the unit packetizer).; - Automatization of the usage of file-based technology to handle outputs.; - [Improved dataset management model](https://root.cern/doc/v628/classTDataSetManagerAliEn.html); where the PROOF (ROOT) dataset manager is a light frontend to the experiment file catalogs; TDataSetManagerFile is still; used as local cache of the experiment information or to store the work-in-progress status of the dataset manager daemon. This model addresses the scalability issues observed at ALICE AFs.; - Improvements in [TProofBench](https://root.cern.ch/doc/master/classTProofBench.html):; - Recording and display of the maximum rate during query, CPU efficiency calculation for PROOF-Lite runs, better measurement of wall time.; - Support for dynamic startup mode. - Test program xpdtest to test the status of xproofd (see also man page under $ROOTSYS/man/man1):. ``` {.sh}; $ xpdtest [options]; --help, -h; Gives a short list of options avaliable, and exit; -t <test>; type of test to be run:; 0 ping the daemon (includes process existence check if pid specified; see below); 1 ping the daemon and check connection for default user; 2 ping the daemon and check connection for the default user and all recent users; ...; ```; - Interface with **igprof** for fast statistic profiling. Like valgrind, it can b",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v600/index.md:1043,cache,cache,1043,proof/doc/v600/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v600/index.md,1,['cache'],['cache']
Performance," float> poison. .. _int_vp_roundeven:. '``llvm.vp.roundeven.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare <16 x float> @llvm.vp.roundeven.v16f32 (<16 x float> <op>, <16 x i1> <mask>, i32 <vector_length>); declare <vscale x 4 x float> @llvm.vp.roundeven.nxv4f32 (<vscale x 4 x float> <op>, <vscale x 4 x i1> <mask>, i32 <vector_length>); declare <256 x double> @llvm.vp.roundeven.v256f64 (<256 x double> <op>, <256 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated floating-point roundeven of a vector of floating-point values. Arguments:; """""""""""""""""""". The first operand and the result have the same vector of floating-point type.; The second operand is the vector mask and has the same number of elements as the; result vector type. The third operand is the explicit vector length of the; operation. Semantics:; """""""""""""""""""". The '``llvm.vp.roundeven``' intrinsic performs floating-point roundeven; (:ref:`roundeven <int_roundeven>`) of the first vector operand on each enabled; lane. The result on disabled lanes is a :ref:`poison value <poisonvalues>`. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call <4 x float> @llvm.vp.roundeven.v4f32(<4 x float> %a, <4 x i1> %mask, i32 %evl); ;; For all lanes below %evl, %r is lane-wise equivalent to %also.r. %t = call <4 x float> @llvm.roundeven.v4f32(<4 x float> %a); %also.r = select <4 x i1> %mask, <4 x float> %t, <4 x float> poison. .. _int_vp_roundtozero:. '``llvm.vp.roundtozero.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare <16 x float> @llvm.vp.roundtozero.v16f32 (<16 x float> <op>, <16 x i1> <mask>, i32 <vector_length>); declare <vscale x 4 x float> @llvm.vp.roundtozero.nxv4f32 (<vscale x 4 x float> <op>, <vscale x 4 x i1> <mask>, i32 <vector_length>); declare <256 x double> @llvm.vp.roundtozero.v256f64 (<256 x double> <op>, <256 x i1> <mask>, i32 <vector_length>). Overview",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:829308,perform,performs,829308,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['performs']
Performance," following C-pseudo-code representing the core idea of a; predicate guarding potentially invalid loads:; ```; void leak(int data);; void example(int* pointer1, int* pointer2) {; if (condition) {; // ... lots of code ...; leak(*pointer1);; } else {; // ... more code ...; leak(*pointer2);; }; }; ```. This would get transformed into something resembling the following:; ```; uintptr_t all_ones_mask = std::numerical_limits<uintptr_t>::max();; uintptr_t all_zeros_mask = 0;; void leak(int data);; void example(int* pointer1, int* pointer2) {; uintptr_t predicate_state = all_ones_mask;; if (condition) {; // Assuming ?: is implemented using branchless logic...; predicate_state = !condition ? all_zeros_mask : predicate_state;; // ... lots of code ...; //; // Harden the pointer so it can't be loaded; pointer1 &= predicate_state;; leak(*pointer1);; } else {; predicate_state = condition ? all_zeros_mask : predicate_state;; // ... more code ...; //; // Alternative: Harden the loaded value; int value2 = *pointer2 & predicate_state;; leak(value2);; }; }; ```. The result should be that if the `if (condition) {` branch is mis-predicted,; there is a *data* dependency on the condition used to zero out any pointers; prior to loading through them or to zero out all of the loaded bits. Even; though this code pattern may still execute speculatively, *invalid* speculative; executions are prevented from leaking secret data from memory (but note that; this data might still be loaded in safe ways, and some regions of memory are; required to not hold secrets, see below for detailed limitations). This; approach only requires the underlying hardware have a way to implement a; branchless and unpredicted conditional update of a register's value. All modern; architectures have support for this, and in fact such support is necessary to; correctly implement constant time cryptographic primitives. Crucial properties of this approach:; * It is not preventing any particular side-channel from working. This ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:4163,load,loaded,4163,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,1,['load'],['loaded']
Performance," following MIR:. .. code-block:: text. %7:gr32 = SUB32rr %6, %5, implicit-def dead $eflags; %1:gr32 = MOV32rm %0, 1, $noreg, 4, $noreg, debug-location !5 :: (load 4 from %ir.addr1); DBG_VALUE %1, $noreg, !1, !2; %4:gr32 = ADD32rr %3, %2, implicit-def dead $eflags; DBG_VALUE %4, $noreg, !3, !4; DBG_VALUE %7, $noreg, !5, !6. In this circumstance LLVM would leave the MIR as shown above. Were we to move; the DBG_VALUE of virtual register %7 upwards with the SUB32rr, we would re-order; assignments and introduce a new state of the program. Whereas with the solution; above, the debugger will see one fewer combination of variable values, because; ``!3`` and ``!5`` will change value at the same time. This is preferred over; misrepresenting the original program. In comparison, if one sunk the MOV32rm, LLVM would produce the following:. .. code-block:: text. DBG_VALUE $noreg, $noreg, !1, !2; %4:gr32 = ADD32rr %3, %2, implicit-def dead $eflags; DBG_VALUE %4, $noreg, !3, !4; %7:gr32 = SUB32rr %6, %5, implicit-def dead $eflags; DBG_VALUE %7, $noreg, !5, !6; %1:gr32 = MOV32rm %0, 1, $noreg, 4, $noreg, debug-location !5 :: (load 4 from %ir.addr1); DBG_VALUE %1, $noreg, !1, !2. Here, to avoid presenting a state in which the first assignment to ``!1``; disappears, the DBG_VALUE at the top of the block assigns the variable the; undefined location, until its value is available at the end of the block where; an additional DBG_VALUE is added. Were any other DBG_VALUE for ``!1`` to occur; in the instructions that the MOV32rm was sunk past, the DBG_VALUE for ``%1``; would be dropped and the debugger would never observe it in the variable. This; accurately reflects that the value is not available during the corresponding; portion of the original program. Variable locations during Register Allocation; ---------------------------------------------. To avoid debug instructions interfering with the register allocator, the; LiveDebugVariables pass extracts variable locations from a MIR function a",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:34922,load,load,34922,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,1,['load'],['load']
Performance," following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic value being; acquired. 3. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. load atomic acquire - agent - global 1. buffer/global_load; glc=1; 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the load; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale global data. load atomic acquire - system - global 1. buffer/global/flat_load; glc=1; 2. s_waitcnt vmcnt(0). - Must happen before; following buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures the load; has completed; before invalidating; the cache. 3. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. load atomic acquire - agent - generic 1. flat_load glc=1; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the flat_load; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. load atomic acquire - system - generic 1. flat_load glc=1; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL omit; lgkmcnt(0).; - Must happen before; following; buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures the flat_load; has completed; before inv",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:247467,load,load,247467,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],['load']
Performance," following loads; will not see stale; global data. **Release Atomic**; ------------------------------------------------------------------------------------; store atomic release - singlethread - global 1. GFX940, GFX941; - wavefront - generic buffer/global/flat_store; sc0=1 sc1=1; GFX942; buffer/global/flat_store. store atomic release - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; be used.*. 1. ds_store; store atomic release - workgroup - global 1. s_waitcnt lgkm/vmcnt(0); - generic; - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit lgkmcnt(0).; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; have; completed before; performing the; store that is being; released. 2. GFX940, GFX941; buffer/global/flat_store; sc0=1 sc1=1; GFX942; buffer/global/flat_store; sc0=1; store atomic release - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_store; store atomic release - agent - global 1. buffer_wbl2 sc1=1; - generic; - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at agent scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:307460,perform,performing,307460,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['perform'],['performing']
Performance," following; atomicrmw.; - Ensures that all; memory operations; to global have; completed before; performing the; atomicrmw that is; being released. 2. flat_atomic; 3. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 4. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. fence acq_rel - singlethread *none* *none*; - wavefront; fence acq_rel - workgroup *none* 1. s_waitcnt lgkmcnt(0). - If OpenCL and; address space is; not generic, omit.; - However,; since LLVM; currently has no; address space on; the fence need to; conservatively; always generate; (see comment for; previous fence).; - Must happen after; any preceding; local/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that all; memory operations; to local have; completed before; performing any; following global; memory operations.; - Ensures that the; preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; acquire-fence-paired-atomic); has completed; before following; global memory; operations. This; satisfies the; requirements of; acquire.; - Ensures that all; previous memory; operations have; completed before a; following; local/generic store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; release-fence-paired-atomic).; This satisfies the; requirements of; release. fence acq_rel - agent *none* 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0). - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - However, since LLVM; currently has no; address space on; the ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:227731,load,load,227731,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],['load']
Performance," following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. load atomic acquire - agent - generic 1. flat_load glc=1; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the flat_load; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. load atomic acquire - system - generic 1. flat_load glc=1; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL omit; lgkmcnt(0).; - Must happen before; following; buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures the flat_load; has completed; before invalidating; the caches. 3. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. atomicrmw acquire - singlethread - global 1. buffer/global/flat_atomic; - wavefront - generic; atomicrmw acquire - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; be used.*. 1. ds_atomic; atomicrmw acquire - workgroup - global 1. buffer/global_atomic; 2. s_waitcnt vmcnt(0). - If not TgSplit execution; mode, omit.; - Must happen before the; following buffer_wbinvl1_vol.; - Ensures the atomicrmw; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; fol",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:248469,cache,caches,248469,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['cache'],['caches']
Performance," foo2(void);; extern void foo4(void);. --- a.c ---; #include ""a.h"". static signed int i = 0;. void foo2(void) {; i = -1;; }. static int foo3() {; foo4();; return 10;; }. int foo1(void) {; int data = 0;. if (i < 0); data = foo3();. data = data + 42;; return data;; }. --- main.c ---; #include <stdio.h>; #include ""a.h"". void foo4(void) {; printf(""Hi\n"");; }. int main() {; return foo1();; }. To compile, run:. .. code-block:: console. % clang -flto -c a.c -o a.o # <-- a.o is LLVM bitcode file; % clang -c main.c -o main.o # <-- main.o is native object file; % clang -flto a.o main.o -o main # <-- standard link command with -flto. * In this example, the linker recognizes that ``foo2()`` is an externally; visible symbol defined in LLVM bitcode file. The linker completes its usual; symbol resolution pass and finds that ``foo2()`` is not used; anywhere. This information is used by the LLVM optimizer and it; removes ``foo2()``. * As soon as ``foo2()`` is removed, the optimizer recognizes that condition ``i; < 0`` is always false, which means ``foo3()`` is never used. Hence, the; optimizer also removes ``foo3()``. * And this in turn, enables linker to remove ``foo4()``. This example illustrates the advantage of tight integration with the; linker. Here, the optimizer can not remove ``foo3()`` without the linker's; input. Alternative Approaches; ----------------------. **Compiler driver invokes link time optimizer separately.**; In this model the link time optimizer is not able to take advantage of; information collected during the linker's normal symbol resolution phase.; In the above example, the optimizer can not remove ``foo2()`` without the; linker's input because it is externally visible. This in turn prohibits the; optimizer from removing ``foo3()``. **Use separate tool to collect symbol information from all object files.**; In this model, a new, separate, tool or library replicates the linker's; capability to collect information for link time optimization. Not only is; thi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LinkTimeOptimization.rst:2839,optimiz,optimizer,2839,interpreter/llvm-project/llvm/docs/LinkTimeOptimization.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LinkTimeOptimization.rst,1,['optimiz'],['optimizer']
Performance," for comments. > The configuration file is automatically checked at each loop: this; > means you can change configuration without restarting the daemon or; > stopping your current transfers. A detailed description of each directive follows. set *VARIABLE=value*; : This statement will substitute every occurrence of `$VARIABLE` with; its *value* in the rest of the configuration file. You can have; multiple `set` statements. xpd.stagereqrepo [dir:]*directory*; : This directive is shared with PROOF: *directory* is the full path to; the dataset repository. **Defaults to empty:** without this; directive the daemon is not operative. The `dir:` prefix is optional. dsmgrd.purgenoopds *true|false*; : Set it to *true* **(default is false)** to remove a dataset when no file to stage; is found. If no file to stage is found, but corrupted files exist, the; dataset is kept to signal failures. Used in combination with `xpd.stagereqrepo`; makes it ""disposable"": only the datasets effectively needed for signaling; the staging status will be kept, improving scalability and stability. dsmgrd.urlregex *regex* *subst*; : Each source URL present in the datasets will be matched to *regex*; and substituted to *subst*. *regex* supports grouping using; parentheses, and groups can be referenced in order using the dollar; sign with a number (`$1` for instance) in *subst*. Matching and substitution for multiple URL schemas are supported by; using in addition directives `dsmgrd.urlregex2` up to; `dsmgrd.urlregex4` which have the same syntax of this one. Example of URL translation via regexp:. > - Configuration line:; >; > dsmgrd.urlregex alien://(.*)$ root://xrd.cern.ch/$1; >; > - Source URL:; >; > alien:///alice/data/2012/LHC12b/000178209/ESDs/pass1/12000178209061.17/AliESDs.root; >; > - Resulting URL:; >; > root://xrd.cern.ch//alice/data/2012/LHC12b/000178209/ESDs/pass1/12000178209061.17/AliESDs.root; >; dsmgrd.sleepsecs *secs*; : Seconds to sleep between each loop. The dataset stager checks at; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md:2384,scalab,scalability,2384,proof/doc/confman/DatasetStager.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md,1,['scalab'],['scalability']
Performance," for example, by LICM before hoisting an; operation. * ``mayReadFromMemory()``/``mayWriteToMemory()``: Existing predicate, but note; that they return true for any operation which is volatile or at least; Monotonic. * ``isStrongerThan`` / ``isAtLeastOrStrongerThan``: These are predicates on; orderings. They can be useful for passes that are aware of atomics, for; example to do DSE across a single atomic access, but not across a; release-acquire pair (see MemoryDependencyAnalysis for an example of this). * Alias analysis: Note that AA will return ModRef for anything Acquire or; Release, and for the address accessed by any Monotonic operation. To support optimizing around atomic operations, make sure you are using the; right predicates; everything should work if that is done. If your pass should; optimize some atomic operations (Unordered operations in particular), make sure; it doesn't replace an atomic load or store with a non-atomic operation. Some examples of how optimizations interact with various kinds of atomic; operations:. * ``memcpyopt``: An atomic operation cannot be optimized into part of a; memcpy/memset, including unordered loads/stores. It can pull operations; across some atomic operations. * LICM: Unordered loads/stores can be moved out of a loop. It just treats; monotonic operations like a read+write to a memory location, and anything; stricter than that like a nothrow call. * DSE: Unordered stores can be DSE'ed like normal stores. Monotonic stores can; be DSE'ed in some cases, but it's tricky to reason about, and not especially; important. It is possible in some case for DSE to operate across a stronger; atomic operation, but it is fairly tricky. DSE delegates this reasoning to; MemoryDependencyAnalysis (which is also used by other passes like GVN). * Folding a load: Any atomic load from a constant global can be constant-folded,; because it cannot be observed. Similar reasoning allows sroa with; atomic loads and stores. Atomics and Codegen; ===========",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Atomics.rst:17108,optimiz,optimizations,17108,interpreter/llvm-project/llvm/docs/Atomics.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Atomics.rst,1,['optimiz'],['optimizations']
Performance," for i32. llvm.amdgcn.udot2 Provides direct access to v_dot2_u32_u16 across targets which; support such instructions. This performs unsigned dot product; with two v2i16 operands, summed with the third i32 operand. The; i1 fourth operand is used to clamp the output. llvm.amdgcn.udot4 Provides direct access to v_dot4_u32_u8 across targets which; support such instructions. This performs unsigned dot product; with two i32 operands (holding a vector of 4 8bit values), summed; with the third i32 operand. The i1 fourth operand is used to clamp; the output. llvm.amdgcn.udot8 Provides direct access to v_dot8_u32_u4 across targets which; support such instructions. This performs unsigned dot product; with two i32 operands (holding a vector of 8 4bit values), summed; with the third i32 operand. The i1 fourth operand is used to clamp; the output. llvm.amdgcn.sdot2 Provides direct access to v_dot2_i32_i16 across targets which; support such instructions. This performs signed dot product; with two v2i16 operands, summed with the third i32 operand. The; i1 fourth operand is used to clamp the output.; When applicable (e.g. no clamping), this is lowered into; v_dot2c_i32_i16 for targets which support it. llvm.amdgcn.sdot4 Provides direct access to v_dot4_i32_i8 across targets which; support such instructions. This performs signed dot product; with two i32 operands (holding a vector of 4 8bit values), summed; with the third i32 operand. The i1 fourth operand is used to clamp; the output.; When applicable (i.e. no clamping / operand modifiers), this is lowered; into v_dot4c_i32_i8 for targets which support it.; RDNA3 does not offer v_dot4_i32_i8, and rather offers; v_dot4_i32_iu8 which has operands to hold the signedness of the; vector operands. Thus, this intrinsic lowers to the signed version; of this instruction for gfx11 targets. llvm.amdgcn.sdot8 Provides direct access to v_dot8_u32_u4 across targets which; support such instructions. This performs signed dot product; with two i32 o",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:40085,perform,performs,40085,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['perform'],['performs']
Performance," for those lanes. %masked.a = select <4 x i1> %mask, <4 x i32> %a, <4 x i32> zeroinitializer; %reduction = call i32 @llvm.vector.reduce.add.v4i32(<4 x i32> %masked.a); %also.r = add i32 %reduction, %start. .. _int_vp_reduce_fadd:. '``llvm.vp.reduce.fadd.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare float @llvm.vp.reduce.fadd.v4f32(float <start_value>, <4 x float> <val>, <4 x i1> <mask>, i32 <vector_length>); declare double @llvm.vp.reduce.fadd.nxv8f64(double <start_value>, <vscale x 8 x double> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated floating-point ``ADD`` reduction of a vector and a scalar starting; value, returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value of the reduction, which must be a scalar; floating-point type equal to the result type. The second operand is the vector; on which the reduction is performed and must be a vector of floating-point; values whose element type is the result/start type. The third operand is the; vector mask and is a vector of boolean values with the same number of elements; as the vector operand. The fourth operand is the explicit vector length of the; operation. Semantics:; """""""""""""""""""". The '``llvm.vp.reduce.fadd``' intrinsic performs the floating-point ``ADD``; reduction (:ref:`llvm.vector.reduce.fadd <int_vector_reduce_fadd>`) of the; vector operand ``val`` on each enabled lane, adding it to the scalar; ``start_value``. Disabled lanes are treated as containing the neutral value; ``-0.0`` (i.e. having no effect on the reduction operation). If no lanes are; enabled, the resulting value will be equal to ``start_value``. To ignore the start value, the neutral value can be used. See the unpredicated version (:ref:`llvm.vector.reduce.fadd; <int_vector_reduce_fadd>`) for more detail on the semantics of the reduction. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call float",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:751002,perform,performed,751002,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['performed']
Performance," for. The query either returns the element; matching the ID or it returns an opaque ID that indicates where insertion should; take place. Construction of the ID usually does not require heap traffic. Because FoldingSet uses intrusive links, it can support polymorphic objects in; the set (for example, you can have SDNode instances mixed with LoadSDNodes).; Because the elements are individually allocated, pointers to the elements are; stable: inserting or removing elements does not invalidate any pointers to other; elements. .. _dss_set:. <set>; ^^^^^. ``std::set`` is a reasonable all-around set class, which is decent at many; things but great at nothing. std::set allocates memory for each element; inserted (thus it is very malloc intensive) and typically stores three pointers; per element in the set (thus adding a large amount of per-element space; overhead). It offers guaranteed log(n) performance, which is not particularly; fast from a complexity standpoint (particularly if the elements of the set are; expensive to compare, like strings), and has extremely high constant factors for; lookup, insertion and removal. The advantages of std::set are that its iterators are stable (deleting or; inserting an element from the set does not affect iterators or pointers to other; elements) and that iteration over the set is guaranteed to be in sorted order.; If the elements in the set are large, then the relative overhead of the pointers; and malloc traffic is not a big deal, but if the elements of the set are small,; std::set is almost never a good choice. .. _dss_setvector:. llvm/ADT/SetVector.h; ^^^^^^^^^^^^^^^^^^^^. LLVM's ``SetVector<Type>`` is an adapter class that combines your choice of a; set-like container along with a :ref:`Sequential Container <ds_sequential>` The; important property that this provides is efficient insertion with uniquing; (duplicate elements are ignored) with iteration support. It implements this by; inserting elements into both a set-like container",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:83559,perform,performance,83559,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,1,['perform'],['performance']
Performance," frame and resume program execution using the information; provided by the stack map. For example, execution may resume in an; interpreter or a recompiled version of the same function. This usage restricts LLVM optimization. Clearly, LLVM must not move; stores across a stack map. However, loads must also be handled; conservatively. If the load may trigger an exception, hoisting it; above a stack map could be invalid. For example, the runtime may; determine that a load is safe to execute without a type check given; the current state of the type system. If the type system changes while; some activation of the load's function exists on the stack, the load; becomes unsafe. The runtime can prevent subsequent execution of that; load by immediately patching any stack map location that lies between; the current call site and the load (typically, the runtime would; simply patch all stack map locations to invalidate the function). If; the compiler had hoisted the load above the stack map, then the; program could crash before the runtime could take back control. To enforce these semantics, stackmap and patchpoint intrinsics are; considered to potentially read and write all memory. This may limit; optimization more than some clients desire. This limitation may be; avoided by marking the call site as ""readonly"". In the future we may; also allow meta-data to be added to the intrinsic call to express; aliasing, thereby allowing optimizations to hoist certain loads above; stack maps. Direct Stack Map Entries; ^^^^^^^^^^^^^^^^^^^^^^^^. As shown in :ref:`stackmap-section`, a Direct stack map location; records the address of frame index. This address is itself the value; that the runtime requested. This differs from Indirect locations,; which refer to a stack locations from which the requested values must; be loaded. Direct locations can communicate the address if an alloca,; while Indirect locations handle register spills. For example:. .. code-block:: none. entry:; %a = alloca i64...",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:18650,load,load,18650,interpreter/llvm-project/llvm/docs/StackMaps.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst,1,['load'],['load']
Performance," frame expansion. When representing function; scoped variables or locations, placing alloca instructions at the beginning of; the entry block should be preferred. In particular, place them before any; call instructions. Call instructions might get inlined and replaced with; multiple basic blocks. The end result is that a following alloca instruction; would no longer be in the entry basic block afterward. The SROA (Scalar Replacement Of Aggregates) and Mem2Reg passes only attempt; to eliminate alloca instructions that are in the entry basic block. Given; SSA is the canonical form expected by much of the optimizer; if allocas can; not be eliminated by Mem2Reg or SROA, the optimizer is likely to be less; effective than it could be. Avoid loads and stores of large aggregate type; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. LLVM currently does not optimize well loads and stores of large :ref:`aggregate; types <t_aggregate>` (i.e. structs and arrays). As an alternative, consider; loading individual fields from memory. Aggregates that are smaller than the largest (performant) load or store; instruction supported by the targeted hardware are well supported. These can; be an effective way to represent collections of small packed fields. Prefer zext over sext when legal; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. On some architectures (X86_64 is one), sign extension can involve an extra; instruction whereas zero extension can be folded into a load. LLVM will try to; replace a sext with a zext when it can be proven safe, but if you have; information in your source language about the range of an integer value, it can; be profitable to use a zext rather than a sext. Alternatively, you can :ref:`specify the range of the value using metadata; <range-metadata>` and LLVM can do the sext to zext conversion for you. Zext GEP indices to machine register width; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Internally, LLVM often promotes the width of GEP indices to machine register; width",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:3248,load,loading,3248,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,1,['load'],['loading']
Performance," frame of the current volume and to; compute the distance to exit its shape from inside. The returned value; is again compared to the maximum allowed step (the proposed one) and in; case the distance is safe no other action is performed and the proposed; step is approved. In case the boundary is closer, the computed distance; is taken as maximum allowed step. For optimization purposed, for; particles starting very close to the current volume boundary (less than; 0.01 microns) and exiting the algorithm stops here. After computing the distance to exit the current node, the distance to; the daughter of the current volume which is crossed next is computed by; **`TGeoManager`**`::FindNextDaughterBoundary().` This computes the; distance to all daughter candidates that can be possibly crossed by; using volume voxelization. The algorithm is efficient in average only in; case the number of daughters is greater than 4. For fewer nodes, a; simple loop is performed and the minimum distance (from a point outside; each shape) is taken and compared to the maximum allowed step. The step; value is again updated if `step<stepmax` . A special case is when the current node is declared as possibly; overlapping with something else. If this is the case, the distance is; computed for all possibly overlapping candidates, taking into account; the overlapping priorities (see also: "" Overlapping volumes ""). The global matrix describing the next crossed physical node is; systematically computed in case the value of the proposed step is; negative. In this case, one can subsequently call; `TGeoManager::ComputeNormalFast()` to get the normal vector to the; crossed surface, after propagating the current point with the; `TGeoManager::GetStep()` value. This propagation can be done like:. ``` {.cpp}; Double_t *current_point = gGeoManager->GetCurrentPoint();; Double_t *current_dir = gGeoManager->GetCurrentDirection();; for (Int_t i=0; i<3; i++); current_point[i] += step * current_dir[I];; ```. Note: Th",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md:163532,perform,performed,163532,documentation/users-guide/Geometry.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md,1,['perform'],['performed']
Performance," from a function:. 1. VGPR0-31 and SGPR4-29 are used to pass function result arguments as; described below. Any registers used are considered clobbered registers.; 2. The following registers are preserved and have the same value as on entry:. * FLAT_SCRATCH; * EXEC; * GFX6-GFX8: M0; * All SGPR registers except the clobbered registers of SGPR4-31.; * VGPR40-47; * VGPR56-63; * VGPR72-79; * VGPR88-95; * VGPR104-111; * VGPR120-127; * VGPR136-143; * VGPR152-159; * VGPR168-175; * VGPR184-191; * VGPR200-207; * VGPR216-223; * VGPR232-239; * VGPR248-255. .. note::. Except the argument registers, the VGPRs clobbered and the preserved; registers are intermixed at regular intervals in order to keep a; similar ratio independent of the number of allocated VGPRs. * GFX90A: All AGPR registers except the clobbered registers AGPR0-31.; * Lanes of all VGPRs that are inactive at the call site. For the AMDGPU backend, an inter-procedural register allocation (IPRA); optimization may mark some of clobbered SGPR and VGPR registers as; preserved if it can be determined that the called function does not change; their value. 2. The PC is set to the RA provided on entry.; 3. MODE register: *TBD*.; 4. All other registers are clobbered.; 5. Any necessary ``s_waitcnt`` has been performed to ensure memory accessed by; function is available to the caller. .. TODO::. - How are function results returned? The address of structured types is passed; by reference, but what about other types?. The function input arguments are made up of the formal arguments explicitly; declared by the source language function plus the implicit input arguments used; by the implementation. The source language input arguments are:. 1. Any source language implicit ``this`` or ``self`` argument comes first as a; pointer type.; 2. Followed by the function formal arguments in left to right source order. The source language result arguments are:. 1. The function result argument. The source language input or result struct type argu",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:391172,optimiz,optimization,391172,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['optimiz'],['optimization']
Performance," from the program. 5. `Prolog/Epilog Code Insertion`_ --- Once the machine code has been generated; for the function and the amount of stack space required is known (used for; LLVM alloca's and spill slots), the prolog and epilog code for the function; can be inserted and ""abstract stack location references"" can be eliminated.; This stage is responsible for implementing optimizations like frame-pointer; elimination and stack packing. 6. `Late Machine Code Optimizations`_ --- Optimizations that operate on ""final""; machine code can go here, such as spill code scheduling and peephole; optimizations. 7. `Code Emission`_ --- The final stage actually puts out the code for the; current function, either in the target assembler format or in machine; code. The code generator is based on the assumption that the instruction selector will; use an optimal pattern matching selector to create high-quality sequences of; native instructions. Alternative code generator designs based on pattern; expansion and aggressive iterative peephole optimization are much slower. This; design permits efficient compilation (important for JIT environments) and; aggressive optimization (used when generating code offline) by allowing; components of varying levels of sophistication to be used for any step of; compilation. In addition to these stages, target implementations can insert arbitrary; target-specific passes into the flow. For example, the X86 target uses a; special pass to handle the 80x87 floating point stack architecture. Other; targets with unusual requirements can be supported with custom passes as needed. Using TableGen for target description; -------------------------------------. The target description classes require a detailed description of the target; architecture. These target descriptions often have a large amount of common; information (e.g., an ``add`` instruction is almost identical to a ``sub``; instruction). In order to allow the maximum amount of commonality to be; factored ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:7556,optimiz,optimization,7556,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst,1,['optimiz'],['optimization']
Performance," function, Security Remarks. #include <windows.h>. void test() {; STARTUPINFO si;; PROCESS_INFORMATION pi;; CreateProcess(NULL, TEXT(""C:\\Program Files\\App -L -S""),; NULL, NULL, TRUE, 0, NULL, NULL, &si, π);; // warn; }. WinAPI.LoadLibrary; (C); The SearchPath() function is used to retrieve a path to a DLL for; a subsequent LoadLibrary() call.; Source: ; MSDN: LoadLibrary function, Security Remarks. #include <windows.h>. HINSTANCE test() {; char filePath[100];; SearchPath(NULL, ""file.dll"", NULL, 100, filePath, NULL);; return LoadLibrary(filePath); // warn; }. WinAPI.WideCharToMultiByte; (C); Buffer overrun while calling WideCharToMultiByte(). The size of; the input buffer equals the number of characters in the Unicode string, while; the size of the output buffer equals the number of bytes.; Source: ; MSDN: WideCharToMultiByte function. #include <windows.h>. void test() {; wchar_t ws[] = L""abc"";; char s[3];; WideCharToMultiByte(CP_UTF8, 0, ws, -1, s,; 3, NULL, NULL); // warn; }. optimization. Name, DescriptionExampleProgress. optimization.PassConstObjByValue; (C, C++); Optimization: It is more effective to pass constant parameter by reference to; avoid unnecessary object copying. struct A {};. void f(const struct A a); // warn. optimization.PostfixIncIter; (C++); Optimization: It is more effective to use prefix increment operator with; iterator.; Source: Scott Meyers ""More Effective C++"", item 6:; Distinguish between prefix and postfix forms of increment and decrement; operators. #include <vector>. void test() {; std::vector<int> v;; std::vector<int>::const_iterator it;; for(it = v.begin();; it != v.end(); it++) {}; // warn; }. optimization.MultipleCallsStrlen; (C); Optimization: multiple calls to strlen() for a string in an; expression. It is more effective to hold a value returned; from strlen() in a temporary variable. #include <string.h>. void test(const char* s) {; if (strlen(s) > 0 &&; strlen(s) < 7) {}; // warn; }. optimization.StrLengthCalculation; (C++); Op",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/potential_checkers.html:27216,optimiz,optimization,27216,interpreter/llvm-project/clang/www/analyzer/potential_checkers.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/potential_checkers.html,2,['optimiz'],['optimization']
Performance," function; ``__jit_debug_register_code`` that the debugger knows about. When the debugger; attaches to a process, it puts a breakpoint in this function and associates a; special handler with it. Once MCJIT calls the registration function, the; debugger catches the breakpoint signal, loads the new object file from the; inferior's memory and resumes execution. This way it can obtain debug; information for pure in-memory object files. GDB Version; ===========. In order to debug code JIT-ed by LLVM, you need GDB 7.0 or newer, which is; available on most modern distributions of Linux. The version of GDB that; Apple ships with Xcode has been frozen at 6.3 for a while. LLDB Version; ============. Due to a regression in release 6.0, LLDB didn't support JITed code debugging for; a while. The bug was fixed in mainline recently, so that debugging JITed ELF; objects should be possible again from the upcoming release 12.0 on. On macOS the; feature must be enabled explicitly using the ``plugin.jit-loader.gdb.enable``; setting. Debugging MCJIT-ed code; =======================. The emerging MCJIT component of LLVM allows full debugging of JIT-ed code with; GDB. This is due to MCJIT's ability to use the MC emitter to provide full; DWARF debugging information to GDB. Note that lli has to be passed the ``--jit-kind=mcjit`` flag to JIT the code; with MCJIT instead of the newer ORC JIT. Example; -------. Consider the following C code (with line numbers added to make the example; easier to follow):. ..; FIXME:; Sphinx has the ability to automatically number these lines by adding; :linenos: on the line immediately following the `.. code-block:: c`, but; it looks like garbage; the line numbers don't even line up with the; lines. Is this a Sphinx bug, or is it a CSS problem?. .. code-block:: c. 1 int compute_factorial(int n); 2 {; 3 if (n <= 1); 4 return 1;; 5; 6 int f = n;; 7 while (--n > 1); 8 f *= n;; 9 return f;; 10 }; 11; 12; 13 int main(int argc, char** argv); 14 {; 15 if (argc < 2); 1",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DebuggingJITedCode.rst:1898,load,loader,1898,interpreter/llvm-project/llvm/docs/DebuggingJITedCode.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DebuggingJITedCode.rst,1,['load'],['loader']
Performance," generate flamegraphs for; visualizing your instrumented invocations. The tool does not generate the graphs; themselves, but instead generates a format that can be used with Brendan Gregg's; FlameGraph tool, currently available on `github; <https://github.com/brendangregg/FlameGraph>`_. To generate output for a flamegraph, a few more options are necessary. - ``--all-stacks`` - Emits all of the stacks.; - ``--stack-format`` - Choose the flamegraph output format 'flame'.; - ``--aggregation-type`` - Choose the metric to graph. You may pipe the command output directly to the flamegraph tool to obtain an; svg file. ::. $ llvm-xray stack xray-log.llc.5rqxkU --instr_map=./bin/llc --stack-format=flame --aggregation-type=time --all-stacks | \; /path/to/FlameGraph/flamegraph.pl > flamegraph.svg. If you open the svg in a browser, mouse events allow exploring the call stacks. Chrome Trace Viewer Visualization; ---------------------------------. We can also generate a trace which can be loaded by the Chrome Trace Viewer; from the same generated trace:. ::. $ llvm-xray convert --symbolize --instr_map=./bin/llc \; --output-format=trace_event xray-log.llc.5rqxkU \; | gzip > llc-trace.txt.gz. From a Chrome browser, navigating to ``chrome:///tracing`` allows us to load; the ``sample-trace.txt.gz`` file to visualize the execution trace. Further Exploration; -------------------. The ``llvm-xray`` tool has a few other subcommands that are in various stages; of being developed. One interesting subcommand that can highlight a few; interesting things is the ``graph`` subcommand. Given for example the following; toy program that we build with XRay instrumentation, we can see how the; generated graph may be a helpful indicator of where time is being spent for the; application. .. code-block:: c++. // sample.cc; #include <iostream>; #include <thread>. [[clang::xray_always_instrument]] void f() {; std::cerr << '.';; }. [[clang::xray_always_instrument]] void g() {; for (int i = 0; i < 1 << 10; +",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRayExample.rst:13460,load,loaded,13460,interpreter/llvm-project/llvm/docs/XRayExample.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRayExample.rst,1,['load'],['loaded']
Performance," generators; -----------------------------------------------------------------------. This transformation is designed for use by code generators which do not yet; support stack unwinding. This pass converts ``invoke`` instructions to; ``call`` instructions, so that any exception-handling ``landingpad`` blocks; become dead code (which can be removed by running the ``-simplifycfg`` pass; afterwards). ``lowerswitch``: Lower ``SwitchInst``\ s to branches; ----------------------------------------------------. Rewrites switch instructions with a sequence of branches, which allows targets; to get away with not implementing the switch instruction until it is; convenient. .. _passes-mem2reg:. ``mem2reg``: Promote Memory to Register; ---------------------------------------. This file promotes memory references to be register references. It promotes; alloca instructions which only have loads and stores as uses. An ``alloca`` is; transformed by using dominator frontiers to place phi nodes, then traversing; the function in depth-first order to rewrite loads and stores as appropriate.; This is just the standard SSA construction algorithm to construct ""pruned"" SSA; form. ``memcpyopt``: MemCpy Optimization; ----------------------------------. This pass performs various transformations related to eliminating ``memcpy``; calls, or transforming sets of stores into ``memset``\ s. ``mergefunc``: Merge Functions; ------------------------------. This pass looks for equivalent functions that are mergeable and folds them. Total-ordering is introduced among the functions set: we define comparison; that answers for every two functions which of them is greater. It allows to; arrange functions into the binary tree. For every new function we check for equivalent in tree. If equivalent exists we fold such functions. If both functions are overridable,; we move the functionality into a new internal function and leave two; overridable thunks to it. If there is no equivalent, then we add this functio",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Passes.rst:30751,load,loads,30751,interpreter/llvm-project/llvm/docs/Passes.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Passes.rst,1,['load'],['loads']
Performance," get a big win for the compilation time in O0. But with optimizations, things are different:. (we omit ``code generation`` part for each end due to the limited space). .. code-block:: none. ├-------- frontend ---------┼--------------- middle end --------------------┼------ backend ----┤; │ │ │ │; └--- parsing ---- sema -----┴--- optimizations --- IPO ---- optimizations---┴--- optimizations -┘. ┌-----------------------------------------------------------------------------------------------┐; │ │; │ source file │; │ │; └-----------------------------------------------------------------------------------------------┘; ┌---------------------------------------┐; │ │; │ │; │ imported code │; │ │; │ │; └---------------------------------------┘. It would be very unfortunate if we end up with worse performance after using modules.; The main concern is that when we compile a source file, the compiler needs to see the function body; of imported module units so that it can perform IPO (InterProcedural Optimization, primarily inlining; in practice) to optimize functions in current source file with the help of the information provided by; the imported module units.; In other words, the imported code would be processed again and again in importee units; by optimizations (including IPO itself).; The optimizations before IPO and the IPO itself are the most time-consuming part in whole compilation process.; So from this perspective, we might not be able to get the improvements described in the theory.; But we could still save the time for optimizations after IPO and the whole backend. Overall, at ``O0`` the implementations of functions defined in a module will not impact module users,; but at higher optimization levels the definitions of such functions are provided to user compilations for the; purposes of optimization (but definitions of these functions are still not included in the use's object file)-; this means the build speedup at higher optimization levels may be lower than expe",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/StandardCPlusPlusModules.rst:42315,perform,perform,42315,interpreter/llvm-project/clang/docs/StandardCPlusPlusModules.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/StandardCPlusPlusModules.rst,2,"['optimiz', 'perform']","['optimize', 'perform']"
Performance," given); >>> c.callit(c); called Concrete::abstract_method; >>>. `Static methods`; ----------------. Class static functions are treated the same way as free functions, except; that they are accessible either through the class or through an instance,; just like Python's ``staticmethod``. `Instance methods`; ------------------. For class methods, see the :ref:`methods section <sec-methods-label>` under; the :doc:`classes heading<classes>`. `Lambda's`; ----------. C++ lambda functions are supported by first binding to a ``std::function``,; then providing a proxy to that on the Python side.; Example::. >>> cppyy.cppdef(""""""\; ... auto create_lambda(int a) {; ... return [a](int b) { return a+b; };; ... }""""""); True; >>> l = cppyy.gbl.create_lambda(4); >>> type(l); <class cppyy.gbl.std.function<int(int)> at 0x11505b830>; >>> l(2); 6; >>> . `Operators`; -----------. Globally defined operators are found lazily (ie. can resolve after the class; definition by loading the global definition or by defining them interactively); and are mapped onto a Python equivalent when possible.; See the :ref:`operators section <sec-operators-label>` under the; :doc:`classes heading<classes>` for more details. `Templates`; -----------. Templated functions (and class methods) can either be called using square; brackets (``[]``) to provide the template arguments explicitly, or called; directly, through automatic lookup.; The template arguments may either be a string of type names (this results; in faster code, as it needs no further lookup/verification) or a list of; the actual types to use (which tends to be more convenient). **Note**: the Python type ``float`` maps to the C++ type ``float``, even; as Python uses a C ``double`` as its internal representation.; The motivation is that doing so makes the Python code more readable (and; Python may anyway change its internal representation in the future).; The same has been true for Python ``int``, which used to be a C ``long``; internally. Examples, ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/functions.rst:3238,load,loading,3238,bindings/pyroot/cppyy/cppyy/doc/source/functions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/functions.rst,1,['load'],['loading']
Performance," global 1. buffer/global/flat_atomic; - wavefront - generic; - workgroup; - agent; - system; atomicrmw monotonic - singlethread - local 1. ds_atomic; - wavefront; - workgroup; **Acquire Atomic**; ------------------------------------------------------------------------------------; load atomic acquire - singlethread - global 1. buffer/global/ds/flat_load; - wavefront - local; - generic; load atomic acquire - workgroup - global 1. buffer/global_load glc=1. - If CU wavefront execution; mode, omit glc=1. 2. s_waitcnt vmcnt(0). - If CU wavefront execution; mode, omit.; - Must happen before; the following buffer_gl0_inv; and before any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw. 3. buffer_gl0_inv. - If CU wavefront execution; mode, omit.; - Ensures that; following; loads will not see; stale data. load atomic acquire - workgroup - local 1. ds_load; 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; the following buffer_gl0_inv; and before any following; global/generic load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than the local load; atomic value being; acquired. 3. buffer_gl0_inv. - If CU wavefront execution; mode, omit.; - If OpenCL, omit.; - Ensures that; following; loads will not see; stale data. load atomic acquire - workgroup - generic 1. flat_load glc=1. - If CU wavefront execution; mode, omit glc=1. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If CU wavefront execution; mode, omit vmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Must happen before; the following; buffer_gl0_inv and any; following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic value being; acquired. 3. buffer_gl0_inv. - If CU wavefront execution; mode, omit.; - Ensures that; following; loads will not see; stale data. load atomic acquire - agent - global 1. buffer/global_load; - system glc=1 dlc=1. - If GF",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:346846,load,load,346846,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],['load']
Performance," global <identifiers>` is used and always have; :ref:`pointer <t_pointer>` type. For example, the following is a legal LLVM; file:. .. code-block:: llvm. @X = global i32 17; @Y = global i32 42; @Z = global [2 x ptr] [ ptr @X, ptr @Y ]. .. _undefvalues:. Undefined Values; ----------------. The string '``undef``' can be used anywhere a constant is expected, and; indicates that the user of the value may receive an unspecified; bit-pattern. Undefined values may be of any type (other than '``label``'; or '``void``') and be used anywhere a constant is permitted. .. note::. A '``poison``' value (described in the next section) should be used instead of; '``undef``' whenever possible. Poison values are stronger than undef, and; enable more optimizations. Just the existence of '``undef``' blocks certain; optimizations (see the examples below). Undefined values are useful because they indicate to the compiler that; the program is well defined no matter what value is used. This gives the; compiler more freedom to optimize. Here are some examples of; (potentially surprising) transformations that are valid (in pseudo IR):. .. code-block:: llvm. %A = add %X, undef; %B = sub %X, undef; %C = xor %X, undef; Safe:; %A = undef; %B = undef; %C = undef. This is safe because all of the output bits are affected by the undef; bits. Any output bit can have a zero or one depending on the input bits. .. code-block:: llvm. %A = or %X, undef; %B = and %X, undef; Safe:; %A = -1; %B = 0; Safe:; %A = %X ;; By choosing undef as 0; %B = %X ;; By choosing undef as -1; Unsafe:; %A = undef; %B = undef. These logical operations have bits that are not always affected by the; input. For example, if ``%X`` has a zero bit, then the output of the; '``and``' operation will always be a zero for that bit, no matter what; the corresponding bit from the '``undef``' is. As such, it is unsafe to; optimize or assume that the result of the '``and``' is '``undef``'.; However, it is safe to assume that all bits of the '`",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:191476,optimiz,optimize,191476,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['optimiz'],['optimize']
Performance," global/generic store; atomic/; atomicrmw-no-return-value; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; vscnt(0) and so do; not need to be; considered.); - Ensures any; preceding; sequential; consistent global; memory instructions; have completed; before executing; this sequentially; consistent; instruction. This; prevents reordering; a seq_cst store; followed by a; seq_cst load. (Note; that seq_cst is; stronger than; acquire/release as; the reordering of; load acquire; followed by a store; release is; prevented by the; s_waitcnt of; the release, but; there is nothing; preventing a store; release followed by; load acquire from; completing out of; order. The s_waitcnt; could be placed after; seq_store or before; the seq_load. We; choose the load to; make the s_waitcnt be; as late as possible; so that the store; may have already; completed.). 2. *Following; instructions same as; corresponding load; atomic acquire,; except must generate; all instructions even; for OpenCL.*. load atomic seq_cst - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0) & vscnt(0). - Could be split into; separate s_waitcnt; vmcnt(0), s_waitcnt; vscnt(0) and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt lgkmcnt(0); must happen after; preceding; local load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; lgkmcnt(0) and so do; not need to be; considered.); - s_waitcnt vmcnt(0); must happen after; preceding; global/generic load; atomic/; atomicrmw-with-return-value; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; vmcnt(0) and so do; not need to be; considered.); - s_waitcnt vscnt(0); Must happen after; preceding; global/generic store; atomic/; atomi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:377470,load,load,377470,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['load']
Performance," global/generic store; atomic/; atomicrmw-no-return-value; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; vscnt(0) and so do; not need to be; considered.); - Ensures any; preceding; sequential; consistent global; memory instructions; have completed; before executing; this sequentially; consistent; instruction. This; prevents reordering; a seq_cst store; followed by a; seq_cst load. (Note; that seq_cst is; stronger than; acquire/release as; the reordering of; load acquire; followed by a store; release is; prevented by the; s_waitcnt of; the release, but; there is nothing; preventing a store; release followed by; load acquire from; completing out of; order. The s_waitcnt; could be placed after; seq_store or before; the seq_load. We; choose the load to; make the s_waitcnt be; as late as possible; so that the store; may have already; completed.). 2. *Following; instructions same as; corresponding load; atomic acquire,; except must generate; all instructions even; for OpenCL.*; store atomic seq_cst - singlethread - global *Same as corresponding; - wavefront - local store atomic release,; - workgroup - generic except must generate; - agent all instructions even; - system for OpenCL.*; atomicrmw seq_cst - singlethread - global *Same as corresponding; - wavefront - local atomicrmw acq_rel,; - workgroup - generic except must generate; - agent all instructions even; - system for OpenCL.*; fence seq_cst - singlethread *none* *Same as corresponding; - wavefront fence acq_rel,; - workgroup except must generate; - agent all instructions even; - system for OpenCL.*; ============ ============ ============== ========== ================================. .. _amdgpu-amdhsa-trap-handler-abi:. Trap Handler ABI; ~~~~~~~~~~~~~~~~. For code objects generated by the AMDGPU backend for HSA [HSA]_ compatible; runtimes (see :ref:`amdgpu-os`), the runtime installs a trap handler that; supports the ``s_trap`` instructi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:379433,load,load,379433,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['load']
Performance," green and blue values for the component; adjusted via the sliders. You can apply this adjustment to the shape; itself, or to all shapes sharing a common ‘family'. Shapes of the same; family have external objects with the same **`TObject`** name string.; You can also adjust the ‘Opacity' and ‘Shine' for the shapes materials; via the sliders. #### Geometry. Viewer Controls Pane ‘Geometry' tab. Review and modify the shapes X/Y/Z center and scaling factors via the; edit boxes. Selection and editing of shapes is not available via the API; at present. #### Outputting Viewer Contents. The current viewer rendering can be output to an external `EPS` or; `PDF`, using the options under the ‘File' menu on the top menu bar. The; file is named ‘`viewer.eps`' or ‘`viewer.pdf`' and written to the; current ROOT directory. ### The X3D Viewer. The X3D viewer is a fairly simple and limited viewer, capable of showing; basic lines and polygons. It lacks the quality, performance and more; advanced features of the GL Viewer, and additionally is not supported on; Windows. It is not actively developed and you are encouraged to use the; GL Viewer out of preference. The below table presents the main; interactions - these are repeated in the Help dialog of the viewer. Action KeyActionKey. Wireframe Mode wRotate about xx a. Hidden Line Mode eRotate about yy b. Hidden Surface Mode rRotate about zz c. Move object down uAuto-rotate about x1 2 3. Move object up iAuto-rotate about y4 5 6. Move object left lAuto-rotate about z7 8 9. Move object right hToggle controls styleo. Move object forward jToggle stereo displays. Move object backward kToggle blue stereo viewd. Adjust focus (stereo mode) [ ] { }Toggle double bufferf. Rotate object Left mouse button down + move. ### Common 3D Viewer Architecture. The 3D Viewer Architecture provides a common mechanism for viewer; clients to publish 3D objects to it. It enables:. - Decoupling of producers (geometry packages etc) who model collection; of 3D objects f",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Graphics.md:121198,perform,performance,121198,documentation/users-guide/Graphics.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Graphics.md,1,['perform'],['performance']
Performance," group does not exist in the Z dimension. ""hidden_grid_dims""; The grid dispatch dimensionality. This is the same value; as the AQL dispatch packet dimensionality. Must be a value; between 1 and 3. ""hidden_heap_v1""; A global address space pointer to an initialized memory; buffer that conforms to the requirements of the malloc/free; device library V1 version implementation. ""hidden_dynamic_lds_size""; Size of the dynamically allocated LDS memory is passed in the kernarg. ""hidden_private_base""; The high 32 bits of the flat addressing private aperture base.; Only used by GFX8 to allow conversion between private segment; and flat addresses. See :ref:`amdgpu-amdhsa-kernel-prolog-flat-scratch`. ""hidden_shared_base""; The high 32 bits of the flat addressing shared aperture base.; Only used by GFX8 to allow conversion between shared segment; and flat addresses. See :ref:`amdgpu-amdhsa-kernel-prolog-flat-scratch`. ""hidden_queue_ptr""; A global memory address space pointer to the ROCm runtime; ``struct amd_queue_t`` structure for the HSA queue of the; associated dispatch AQL packet. It is only required for pre-GFX9; devices for the trap handler ABI (see :ref:`amdgpu-amdhsa-trap-handler-abi`). ====================== ============== ========= ================================. .. Kernel Dispatch; ~~~~~~~~~~~~~~~. The HSA architected queuing language (AQL) defines a user space memory interface; that can be used to control the dispatch of kernels, in an agent independent; way. An agent can have zero or more AQL queues created for it using an HSA; compatible runtime (see :ref:`amdgpu-os`), in which AQL packets (all of which; are 64 bytes) can be placed. See the *HSA Platform System Architecture; Specification* [HSA]_ for the AQL queue mechanics and packet layouts. The packet processor of a kernel agent is responsible for detecting and; dispatching HSA kernels from the AQL queues associated with it. For AMD GPUs the; packet processor is implemented by the hardware command processor (CP),",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:148576,queue,queue,148576,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['queue'],['queue']
Performance," handled together, for different possible reasons. One; of these is that the structure has to be replicated in several parts of; the geometry, or it may simply happen that they really represent a; single object, too complex to be described by a primitive shape. Usually handling structures like these can be easily done by positioning; all components in the same container volume, then positioning the; container itself. However, there are many practical cases when defining; such a container is not straightforward or even possible without; generating overlaps with the rest of the geometry. There are few ways; out of this:. - Defining the container for the structure as ""overlapping"" (see also; ""Overlapping Volumes""); - Representing the container as a composite shape - the Boolean union; of all components (see also ""Composite Shapes""); - Using an assembly volume - this will be described in the following. The first two approaches have the disadvantage of penalizing the; navigation performance with a factor increasing more than linear of the; number of components in the structure. The best solution is the third; one because it uses all volume-related navigation optimizations. The; class TGeoVolumeAssembly represents an assembly volume. Its shape; is represented by TGeoShapeAssembly class that is the union of all; components. It uses volume voxelization to perform navigation tasks. An assembly volume creates a hierarchical level and it geometrically; insulates the structure from the rest (as a normal volume). Physically,; a point that is INSIDE a TGeoShapeAssembly is always inside one of; the components, so a TGeoVolumeAssembly does not need to have a; medium. Due to the self-containment of assemblies, they are very; practical to use when a container is hard to define due to possible; overlaps during positioning. For instance, it is very easy creating; honeycomb structures. A very useful example for creating and using; assemblies can be found at: assembly.C. Creation of an a",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:49420,perform,performance,49420,geom/geom/doc/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md,1,['perform'],['performance']
Performance," has shown us there is no point in partitioning to more than; one variable. It simply generates more IR, and optimizations still; have to query something to disambiguate further anyway. As a result, LLVM partitions to one variable. Precision in practice; ^^^^^^^^^^^^^^^^^^^^^. In practice, there are implementation details in LLVM that also affect the; results' precision provided by ``MemorySSA``. For example, AliasAnalysis has various; caps, or restrictions on looking through phis which can affect what ``MemorySSA``; can infer. Changes made by different passes may make MemorySSA either ""overly; optimized"" (it can provide a more accurate result than if it were recomputed; from scratch), or ""under optimized"" (it could infer more if it were recomputed).; This can lead to challenges to reproduced results in isolation with a single pass; when the result relies on the state acquired by ``MemorySSA`` due to being updated by; multiple subsequent passes.; Passes that use and update ``MemorySSA`` should do so through the APIs provided by the; ``MemorySSAUpdater``, or through calls on the Walker.; Direct optimizations to ``MemorySSA`` are not permitted.; There is currently a single, narrowly scoped exception where DSE (DeadStoreElimination); updates an optimized access of a store, after a traversal that guarantees the; optimization is correct. This is solely allowed due to the traversals and inferences; being beyond what ``MemorySSA`` does and them being ""free"" (i.e. DSE does them anyway).; This exception is set under a flag (""-dse-optimize-memoryssa"") and can be disabled to; help reproduce optimizations in isolation. LLVM Developers Meeting presentations; -------------------------------------. - `2016 LLVM Developers' Meeting: G. Burgess - MemorySSA in Five Minutes <https://www.youtube.com/watch?v=bdxWmryoHak>`_.; - `2020 LLVM Developers' Meeting: S. Baziotis & S. Moll - Finding Your Way Around the LLVM Dependence Analysis Zoo <https://www.youtube.com/watch?v=1e5y6WDbXCQ>`_; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MemorySSA.rst:19334,optimiz,optimizations,19334,interpreter/llvm-project/llvm/docs/MemorySSA.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MemorySSA.rst,5,['optimiz'],"['optimization', 'optimizations', 'optimize-memoryssa', 'optimized']"
Performance," has the same number of; elements as the result. The third argument is the explicit vector length of; the operation. Semantics:; """""""""""""""""""". This intrinsic reverses the order of the first ``evl`` elements in a vector.; The lanes in the result vector disabled by ``mask`` are ``poison``. The; elements past ``evl`` are poison. .. _int_vp_load:. '``llvm.vp.load``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare <4 x float> @llvm.vp.load.v4f32.p0(ptr %ptr, <4 x i1> %mask, i32 %evl); declare <vscale x 2 x i16> @llvm.vp.load.nxv2i16.p0(ptr %ptr, <vscale x 2 x i1> %mask, i32 %evl); declare <8 x float> @llvm.vp.load.v8f32.p1(ptr addrspace(1) %ptr, <8 x i1> %mask, i32 %evl); declare <vscale x 1 x i64> @llvm.vp.load.nxv1i64.p6(ptr addrspace(6) %ptr, <vscale x 1 x i1> %mask, i32 %evl). Overview:; """""""""""""""""". The '``llvm.vp.load.*``' intrinsic is the vector length predicated version of; the :ref:`llvm.masked.load <int_mload>` intrinsic. Arguments:; """""""""""""""""""". The first operand is the base pointer for the load. The second operand is a; vector of boolean values with the same number of elements as the return type.; The third is the explicit vector length of the operation. The return type and; underlying type of the base pointer are the same vector types. The :ref:`align <attr_align>` parameter attribute can be provided for the first; operand. Semantics:; """""""""""""""""""". The '``llvm.vp.load``' intrinsic reads a vector from memory in the same way as; the '``llvm.masked.load``' intrinsic, where the mask is taken from the; combination of the '``mask``' and '``evl``' operands in the usual VP way.; Certain '``llvm.masked.load``' operands do not have corresponding operands in; '``llvm.vp.load``': the '``passthru``' operand is implicitly ``poison``; the; '``alignment``' operand is taken as the ``align`` parameter attribute, if; provided. The default alignment is taken as the ABI alignment of the return; type as speci",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:783533,load,load,783533,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['load'],['load']
Performance," have exited the loop.; abort();; }; if (c3) {; // The unreachable allows the compiler to assume that this will not rejoin the loop.; do_something();; __builtin_unreachable();; }; if (c4) {; // This statically infinite loop is not nested because control-flow will not continue with the for-loop.; while(true) {; do_something();; }; }; }. * There is no requirement for the control flow to eventually leave the; loop, i.e. a loop can be infinite. A **statically infinite loop** is a; loop that has no exiting edges. A **dynamically infinite loop** has; exiting edges, but it is possible to be never taken. This may happen; only under some circumstances, such as when n == UINT_MAX in the code; below. .. code-block:: C. for (unsigned i = 0; i <= n; ++i); body(i);. It is possible for the optimizer to turn a dynamically infinite loop; into a statically infinite loop, for instance when it can prove that the; exiting condition is always false. Because the exiting edge is never; taken, the optimizer can change the conditional branch into an; unconditional one. If a is loop is annotated with; :ref:`llvm.loop.mustprogress <langref_llvm_loop_mustprogress>` metadata,; the compiler is allowed to assume that it will eventually terminate, even; if it cannot prove it. For instance, it may remove a mustprogress-loop; that does not have any side-effect in its body even though the program; could be stuck in that loop forever. Languages such as C and; `C++ <https://eel.is/c++draft/intro.progress#1>`_ have such; forward-progress guarantees for some loops. Also see the; :ref:`mustprogress <langref_mustprogress>` and; :ref:`willreturn <langref_willreturn>` function attributes, as well as; the older :ref:`llvm.sideeffect <llvm_sideeffect>` intrinsic. * The number of executions of the loop header before leaving the loop is; the **loop trip count** (or **iteration count**). If the loop should; not be executed at all, a **loop guard** must skip the entire loop:. .. image:: ./loop-guard.svg; :width: 50",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LoopTerminology.rst:7362,optimiz,optimizer,7362,interpreter/llvm-project/llvm/docs/LoopTerminology.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LoopTerminology.rst,1,['optimiz'],['optimizer']
Performance," header0:; ...; br i1 %cmp, label %t1, label %t2, !irr_loop !0. ...; !0 = !{""loop_header_weight"", i64 100}. Irreducible loop header weights are typically based on profile data. .. _md_invariant.group:. '``invariant.group``' Metadata; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The experimental ``invariant.group`` metadata may be attached to; ``load``/``store`` instructions referencing a single metadata with no entries.; The existence of the ``invariant.group`` metadata on the instruction tells; the optimizer that every ``load`` and ``store`` to the same pointer operand; can be assumed to load or store the same; value (but see the ``llvm.launder.invariant.group`` intrinsic which affects; when two pointers are considered the same). Pointers returned by bitcast or; getelementptr with only zero indices are considered the same. Examples:. .. code-block:: llvm. @unknownPtr = external global i8; ...; %ptr = alloca i8; store i8 42, ptr %ptr, !invariant.group !0; call void @foo(ptr %ptr). %a = load i8, ptr %ptr, !invariant.group !0 ; Can assume that value under %ptr didn't change; call void @foo(ptr %ptr). %newPtr = call ptr @getPointer(ptr %ptr); %c = load i8, ptr %newPtr, !invariant.group !0 ; Can't assume anything, because we only have information about %ptr. %unknownValue = load i8, ptr @unknownPtr; store i8 %unknownValue, ptr %ptr, !invariant.group !0 ; Can assume that %unknownValue == 42. call void @foo(ptr %ptr); %newPtr2 = call ptr @llvm.launder.invariant.group.p0(ptr %ptr); %d = load i8, ptr %newPtr2, !invariant.group !0 ; Can't step through launder.invariant.group to get value of %ptr. ...; declare void @foo(ptr); declare ptr @getPointer(ptr); declare ptr @llvm.launder.invariant.group.p0(ptr). !0 = !{}. The invariant.group metadata must be dropped when replacing one pointer by; another based on aliasing information. This is because invariant.group is tied; to the SSA value of the pointer operand. .. code-block:: llvm. %v = load i8, ptr %x, !invariant.group !0; ; if %x mustalia",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:316631,load,load,316631,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['load'],['load']
Performance," higher; pointer bits for other purposes.; * May require changes in the OS kernels (e.g. Linux seems to dislike; tagged pointers passed from address space:; https://www.kernel.org/doc/Documentation/arm64/tagged-pointers.txt).; * **Does not require redzones to detect buffer overflows**,; but the buffer overflow detection is probabilistic, with roughly; `1/(2**TS)` chance of missing a bug (6.25% or 0.39% with 4 and 8-bit TS; respectively).; * **Does not require quarantine to detect heap-use-after-free,; or stack-use-after-return**.; The detection is similarly probabilistic. The memory overhead of HWASAN is expected to be much smaller; than that of AddressSanitizer:; `1/TG` extra memory for the shadow; and some overhead due to `TG`-aligning all objects. Supported architectures; =======================; HWASAN relies on `Address Tagging`_ which is only available on AArch64.; For other 64-bit architectures it is possible to remove the address tags; before every load and store by compiler instrumentation, but this variant; will have limited deployability since not all of the code is; typically instrumented. On x86_64, HWASAN utilizes page aliasing to place tags in userspace address; bits. Currently only heap tagging is supported. The page aliases rely on; shared memory, which will cause heap memory to be shared between processes if; the application calls ``fork()``. Therefore x86_64 is really only safe for; applications that do not fork. HWASAN does not currently support 32-bit architectures since they do not; support `Address Tagging`_ and the address space is too constrained to easily; implement page aliasing. Related Work; ============; * `SPARC ADI`_ implements a similar tool mostly in hardware.; * `Effective and Efficient Memory Protection Using Dynamic Tainting`_ discusses; similar approaches (""lock & key"").; * `Watchdog`_ discussed a heavier, but still somewhat similar; ""lock & key"" approach.; * *TODO: add more ""related work"" links. Suggestions are welcome.*. .. _W",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/HardwareAssistedAddressSanitizerDesign.rst:10604,load,load,10604,interpreter/llvm-project/clang/docs/HardwareAssistedAddressSanitizerDesign.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/HardwareAssistedAddressSanitizerDesign.rst,1,['load'],['load']
Performance," highly tuned and; well tested support for this, though the way it works is a bit; unexpected for some. Why is this a hard problem?; ===========================. To understand why mutable variables cause complexities in SSA; construction, consider this extremely simple C example:. .. code-block:: c. int G, H;; int test(_Bool Condition) {; int X;; if (Condition); X = G;; else; X = H;; return X;; }. In this case, we have the variable ""X"", whose value depends on the path; executed in the program. Because there are two different possible values; for X before the return instruction, a PHI node is inserted to merge the; two values. The LLVM IR that we want for this example looks like this:. .. code-block:: llvm. @G = weak global i32 0 ; type of @G is i32*; @H = weak global i32 0 ; type of @H is i32*. define i32 @test(i1 %Condition) {; entry:; br i1 %Condition, label %cond_true, label %cond_false. cond_true:; %X.0 = load i32, i32* @G; br label %cond_next. cond_false:; %X.1 = load i32, i32* @H; br label %cond_next. cond_next:; %X.2 = phi i32 [ %X.1, %cond_false ], [ %X.0, %cond_true ]; ret i32 %X.2; }. In this example, the loads from the G and H global variables are; explicit in the LLVM IR, and they live in the then/else branches of the; if statement (cond\_true/cond\_false). In order to merge the incoming; values, the X.2 phi node in the cond\_next block selects the right value; to use based on where control flow is coming from: if control flow comes; from the cond\_false block, X.2 gets the value of X.1. Alternatively, if; control flow comes from cond\_true, it gets the value of X.0. The intent; of this chapter is not to explain the details of SSA form. For more; information, see one of the many `online; references <http://en.wikipedia.org/wiki/Static_single_assignment_form>`_. The question for this article is ""who places the phi nodes when lowering; assignments to mutable variables?"". The issue here is that LLVM; *requires* that its IR be in SSA form: there is no ""non-ss",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl07.rst:2281,load,load,2281,interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl07.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl07.rst,1,['load'],['load']
Performance," histogram, the ""fitter"" will dynamically load libMinuit if; it is not yet loaded. #### Plugins: Runtime Library Dependencies for Linking. plugin manager The Plugin Manager **`TPluginManager`** allows; postponing library dependencies to runtime: a plugin library will only; be loaded when it is needed. Non-plugins will need to be linked, and; are thus loaded at start-up. Plugins are defined by a base class (e.g.; **`TFile`**) that will be implemented in a plugin, a tag used to; identify the plugin (e.g. `^rfio:` as part of the protocol string),; the plugin class of which an object will be created; (e.g. **`TRFIOFile`**), the library to be loaded (in short; `libRFIO.so` to RFIO), and the constructor to be called (e.g.; ""`TRFIOFile()`""). This can be specified in the `.rootrc` which already; contains many plugin definitions, or by calls to; `gROOT->GetPluginManager()->AddHandler()`. #### Library AutoLoading. When using a class in Cling, e.g. in an interpreted source file, ROOT; will automatically load the library that defines this class. On; start-up, ROOT parses all files ending on `.rootmap` rootmap that are; in one of the `$LD_LIBRARY_PATH` (or `$DYLD_LIBRARY_PATH` for `MacOS`,; or `$PATH` for `Windows`). They contain class names and the library; names that the class depends on. After reading them, ROOT knows which; classes are available, and which libraries to load for them. When `TSystem::Load(""ALib"")` is called, ROOT uses this information to; determine which libraries `libALib.so` depends on. It will load these; libraries first. Otherwise, loading the requested library could cause; a system (dynamic loader) error due to unresolved symbols. ### \$ROOTSYS/tutorials. tutorials The tutorials directory contains many example example; scripts. They assume some basic knowledge of ROOT, and for the new; user we recommend reading the chapters: ""Histograms"" and; ""Input/Output"" before trying the examples. The more experienced user; can jump to chapter ""The Tutorials and Tests",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Introduction.md:19843,load,load,19843,documentation/users-guide/Introduction.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Introduction.md,1,['load'],['load']
Performance," i32 %X, 8; ret i32 %Y; }. _test1:; movl 4(%esp), %eax; movl %eax, %ecx; sarl $31, %ecx; shrl $29, %ecx; addl %ecx, %eax; sarl $3, %eax; ret. GCC knows several different ways to codegen it, one of which is this:. _test1:; movl 4(%esp), %eax; cmpl $-1, %eax; leal 7(%eax), %ecx; cmovle %ecx, %eax; sarl $3, %eax; ret. which is probably slower, but it's interesting at least :). //===---------------------------------------------------------------------===//. We are currently lowering large (1MB+) memmove/memcpy to rep/stosl and rep/movsl; We should leave these as libcalls for everything over a much lower threshold,; since libc is hand tuned for medium and large mem ops (avoiding RFO for large; stores, TLB preheating, etc). //===---------------------------------------------------------------------===//. Optimize this into something reasonable:; x * copysign(1.0, y) * copysign(1.0, z). //===---------------------------------------------------------------------===//. Optimize copysign(x, *y) to use an integer load from y. //===---------------------------------------------------------------------===//. The following tests perform worse with LSR:. lambda, siod, optimizer-eval, ackermann, hash2, nestedloop, strcat, and Treesor. //===---------------------------------------------------------------------===//. Adding to the list of cmp / test poor codegen issues:. int test(__m128 *A, __m128 *B) {; if (_mm_comige_ss(*A, *B)); return 3;; else; return 4;; }. _test:; 	movl 8(%esp), %eax; 	movaps (%eax), %xmm0; 	movl 4(%esp), %eax; 	movaps (%eax), %xmm1; 	comiss %xmm0, %xmm1; 	setae %al; 	movzbl %al, %ecx; 	movl $3, %eax; 	movl $4, %edx; 	cmpl $0, %ecx; 	cmove %edx, %eax; 	ret. Note the setae, movzbl, cmpl, cmove can be replaced with a single cmovae. There; are a number of issues. 1) We are introducing a setcc between the result of the; intrisic call and select. 2) The intrinsic is expected to produce a i32 value; so a any extend (which becomes a zero extend) is added. We probably need",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README.txt:5346,load,load,5346,interpreter/llvm-project/llvm/lib/Target/X86/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README.txt,3,"['Optimiz', 'load']","['Optimize', 'load']"
Performance," i32> @llvm.bitreverse.v4i32(<4 x i32> %a); %also.r = select <4 x i1> %mask, <4 x i32> %t, <4 x i32> poison. .. _int_vp_bswap:. '``llvm.vp.bswap.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare <16 x i32> @llvm.vp.bswap.v16i32 (<16 x i32> <op>, <16 x i1> <mask>, i32 <vector_length>); declare <vscale x 4 x i32> @llvm.vp.bswap.nxv4i32 (<vscale x 4 x i32> <op>, <vscale x 4 x i1> <mask>, i32 <vector_length>); declare <256 x i64> @llvm.vp.bswap.v256i64 (<256 x i64> <op>, <256 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated bswap of a vector of integers. Arguments:; """""""""""""""""""". The first operand and the result have the same vector of integer type. The; second operand is the vector mask and has the same number of elements as the; result vector type. The third operand is the explicit vector length of the; operation. Semantics:; """""""""""""""""""". The '``llvm.vp.bswap``' intrinsic performs bswap (:ref:`bswap <int_bswap>`) of the first operand on each; enabled lane. The result on disabled lanes is a :ref:`poison value <poisonvalues>`. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call <4 x i32> @llvm.vp.bswap.v4i32(<4 x i32> %a, <4 x i1> %mask, i32 %evl); ;; For all lanes below %evl, %r is lane-wise equivalent to %also.r. %t = call <4 x i32> @llvm.bswap.v4i32(<4 x i32> %a); %also.r = select <4 x i1> %mask, <4 x i32> %t, <4 x i32> poison. .. _int_vp_ctpop:. '``llvm.vp.ctpop.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare <16 x i32> @llvm.vp.ctpop.v16i32 (<16 x i32> <op>, <16 x i1> <mask>, i32 <vector_length>); declare <vscale x 4 x i32> @llvm.vp.ctpop.nxv4i32 (<vscale x 4 x i32> <op>, <vscale x 4 x i1> <mask>, i32 <vector_length>); declare <256 x i64> @llvm.vp.ctpop.v256i64 (<256 x i64> <op>, <256 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated ctpop of a vector of integers. Arguments:; """""""""""""""""""". The fi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:833560,perform,performs,833560,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['performs']
Performance," if TgSplit; execution mode.; - If OpenCL, omit; lgkmcnt(0).; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global/flat_atomic; atomicrmw release - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_atomic; atomicrmw release - agent - global 1. s_waitcnt lgkmcnt(0) &; - generic vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global and local; have completed; before performing; the atomicrmw that; is being released. 2. buffer/global/flat_atomic; atomicrmw release - system - global 1. buffer_wbl2; - generic; - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at system scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/at",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:261034,load,load,261034,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],['load']
Performance," if the; called function requires the struct to be in memory, for example because its; address is taken, then the function body is responsible for allocating a stack; location and copying the field arguments into it. Clang terms this *direct; struct*. The source language input struct type arguments that are greater than 16 bytes,; are passed by reference. The caller is responsible for allocating a stack; location to make a copy of the struct value and pass the address as the input; argument. The called function is responsible to perform the dereference when; accessing the input argument. Clang terms this *by-value struct*. A source language result struct type argument that is greater than 16 bytes, is; returned by reference. The caller is responsible for allocating a stack location; to hold the result value and passes the address as the last input argument; (before the implicit input arguments). In this case there are no result; arguments. The called function is responsible to perform the dereference when; storing the result value. Clang terms this *structured return (sret)*. *TODO: correct the ``sret`` definition.*. .. TODO::. Is this definition correct? Or is ``sret`` only used if passing in registers, and; pass as non-decomposed struct as stack argument? Or something else? Is the; memory location in the caller stack frame, or a stack memory argument and so; no address is passed as the caller can directly write to the argument stack; location? But then the stack location is still live after return. If an; argument stack location is it the first stack argument or the last one?. Lambda argument types are treated as struct types with an implementation defined; set of fields. .. TODO::. Need to specify the ABI for lambda types for AMDGPU. For AMDGPU backend all source language arguments (including the decomposed; struct type arguments) are passed in VGPRs unless marked ``inreg`` in which case; they are passed in SGPRs. The AMDGPU backend walks the function call graph ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:393383,perform,perform,393383,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['perform'],['perform']
Performance," in L2 due to; the memory probes. load atomic acquire - agent - generic 1. flat_load glc=1; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the flat_load; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. load atomic acquire - system - generic 1. flat_load glc=1; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL omit; lgkmcnt(0).; - Must happen before; following; buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures the flat_load; has completed; before invalidating; the caches. 3. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. atomicrmw acquire - singlethread - global 1. buffer/global/flat_atomic; - wavefront - generic; atomicrmw acquire - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; be used.*. 1. ds_atomic; atomicrmw acquire - workgroup - global 1. buffer/global_atomic; 2. s_waitcnt vmcnt(0). - If not TgSplit execution; mode, omit.; - Must happen before the; following buffer_wbinvl1_vol.; - Ensures the atomicrmw; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_atomic; 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; -",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:248625,load,loads,248625,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['loads']
Performance," in ``XXXInstrInfo.td`` files; according to the target-specific instruction set. Relation models are defined; using ``InstrMapping`` class as a base. TableGen parses all the models; and generates instruction relation maps using the specified information.; Relation maps are emitted as tables in the ``XXXGenInstrInfo.inc`` file; along with the functions to query them. For the detailed information on how to; use this feature, please refer to :doc:`HowToUseInstrMappings`. Implement a subclass of ``TargetInstrInfo``; -------------------------------------------. The final step is to hand code portions of ``XXXInstrInfo``, which implements; the interface described in ``TargetInstrInfo.h`` (see :ref:`TargetInstrInfo`).; These functions return ``0`` or a Boolean or they assert, unless overridden.; Here's a list of functions that are overridden for the SPARC implementation in; ``SparcInstrInfo.cpp``:. * ``isLoadFromStackSlot`` --- If the specified machine instruction is a direct; load from a stack slot, return the register number of the destination and the; ``FrameIndex`` of the stack slot. * ``isStoreToStackSlot`` --- If the specified machine instruction is a direct; store to a stack slot, return the register number of the destination and the; ``FrameIndex`` of the stack slot. * ``copyPhysReg`` --- Copy values between a pair of physical registers. * ``storeRegToStackSlot`` --- Store a register value to a stack slot. * ``loadRegFromStackSlot`` --- Load a register value from a stack slot. * ``storeRegToAddr`` --- Store a register value to memory. * ``loadRegFromAddr`` --- Load a register value from memory. * ``foldMemoryOperand`` --- Attempt to combine instructions of any load or; store instruction for the specified operand(s). Branch Folding and If Conversion; --------------------------------. Performance can be improved by combining instructions or by eliminating; instructions that are never reached. The ``analyzeBranch`` method in; ``XXXInstrInfo`` may be implemented to exam",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:46103,load,load,46103,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,1,['load'],['load']
Performance," in an anonymous namespace --- this reflects the fact that passes; are self contained units that do not need external interfaces (although they; can have them) to be useful. Running a pass with ``opt``; ---------------------------. Now that you have a brand new shiny shared object file, we can use the; :program:`opt` command to run an LLVM program through your pass. Because you; registered your pass with ``RegisterPass``, you will be able to use the; :program:`opt` tool to access it, once loaded. To test it, follow the example at the end of the :doc:`GettingStarted` to; compile ""Hello World"" to LLVM. We can now run the bitcode file (hello.bc) for; the program through our transformation like this (or course, any bitcode file; will work):. .. code-block:: console. $ opt -load lib/LLVMHello.so -hello < hello.bc > /dev/null; Hello: __main; Hello: puts; Hello: main. The :option:`-load` option specifies that :program:`opt` should load your pass; as a shared object, which makes ""``-hello``"" a valid command line argument; (which is one reason you need to :ref:`register your pass; <writing-an-llvm-pass-registration>`). Because the Hello pass does not modify; the program in any interesting way, we just throw away the result of; :program:`opt` (sending it to ``/dev/null``). To see what happened to the other string you registered, try running; :program:`opt` with the :option:`-help` option:. .. code-block:: console. $ opt -load lib/LLVMHello.so -help; OVERVIEW: llvm .bc -> .bc modular optimizer and analysis printer. USAGE: opt [subcommand] [options] <input bitcode file>. OPTIONS:; Optimizations available:; ...; -guard-widening - Widen guards; -gvn - Global Value Numbering; -gvn-hoist - Early GVN Hoisting of Expressions; -hello - Hello World Pass; -indvars - Induction Variable Simplification; -inferattrs - Infer set function attributes; ... The pass name gets added as the information string for your pass, giving some; documentation to users of :program:`opt`. Now that you have a",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:8357,load,load,8357,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,2,['load'],['load']
Performance," in highly predictable terminators into their successor blocks.; If a hot successor block contains instructions which can be vectorized; with the duplicated ones, this can provide a noticeable throughput; improvement. Note that this is not always profitable and does involve a; potentially large increase in code size. #. When checking a value against a constant, emit the check using a consistent; comparison type. The GVN pass *will* optimize redundant equalities even if; the type of comparison is inverted, but GVN only runs late in the pipeline.; As a result, you may miss the opportunity to run other important; optimizations. #. Avoid using arithmetic intrinsics unless you are *required* by your source; language specification to emit a particular code sequence. The optimizer; is quite good at reasoning about general control flow and arithmetic, it is; not anywhere near as strong at reasoning about the various intrinsics. If; profitable for code generation purposes, the optimizer will likely form the; intrinsics itself late in the optimization pipeline. It is *very* rarely; profitable to emit these directly in the language frontend. This item; explicitly includes the use of the :ref:`overflow intrinsics <int_overflow>`. #. Avoid using the :ref:`assume intrinsic <int_assume>` until you've; established that a) there's no other way to express the given fact and b); that fact is critical for optimization purposes. Assumes are a great; prototyping mechanism, but they can have negative effects on both compile; time and optimization effectiveness. The former is fixable with enough; effort, but the later is fairly fundamental to their designed purpose. Describing Language Specific Properties; =======================================. When translating a source language to LLVM, finding ways to express concepts; and guarantees available in your source language which are not natively; provided by LLVM IR will greatly improve LLVM's ability to optimize your code.; As an example, C",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:9109,optimiz,optimizer,9109,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,2,['optimiz'],"['optimization', 'optimizer']"
Performance," in order to fix the bug described here:; https://savannah.cern.ch/bugs/?41423 .; The simple following macro was enough to show the problem:. {; TH1D h(""h"", ""h"", 10., 0., 1.); h.Fill(.5);; THStack s(""s"", ""s""); s.Add(&h);; TCanvas canvas(""canvas"");; frame = canvas.DrawFrame(-1., 0., 2., 2.);; frame.SetLabelSize(0.05, ""XY"");; frame.Draw(); s.Draw(""same"");; }. Make the data member fHistogram persistent in order to save the; axis attributes which may have been changed during a root session (like,; for instance, the axis titles).; When a THStack is drawn with the option ""pads"", the number of lines is; now optimized to make sure there is no empty line. . TUnfold. Introduces this new class for solving inverse problems:. data histograms with Gaussian errors are decomposed into; several template distributions (""generator level"" bins). The result are new normalisation constants for the template; distributions (the unfolded ""generator level"" distribution). The solution can be tuned by properly adjusting the; regularisation parameter tau. A standard method, the L-curve scan is; implemented to help finding a good choice of this parameter. Two example tutorials are included to show the usage of this class: tutorials/math/testUnfiold1.C and tutorials/math/testUnfiold2.C. FitPanel; Add a new revised version of the Fit Panel with the following functionality:. Add support now for fitting, in addition to the TH1 and TGraph; also for TH2, TH3, TMultiGraph and TGraph2D and TTree (with un-binned; fits); Add possibility to select the data object directly from the Fit; panel. The Fit Panel can also be open directly from the TCanvas menu; (under Tools); Improve the function selection by having the possibility to; support user defined function, predefined functions and functions; used before for fitting. ; Allow the opening of the parameter dialog in case of linear; fitter. This is needed for example for fixing some of the; parameters; Improve minimization panel by adding some extra methods, ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/hist/doc/v522/index.html:7672,tune,tuned,7672,hist/doc/v522/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/hist/doc/v522/index.html,2,['tune'],['tuned']
Performance," in the ``@llvm.used`` list, then the compiler, assembler,; and linker are required to treat the symbol as if there is a reference to the; symbol that it cannot see (which is why they have to be named). For example, if; a variable has internal linkage and no references other than that from the; ``@llvm.used`` list, it cannot be deleted. This is commonly used to represent; references from inline asms and other things the compiler cannot ""see"", and; corresponds to ""``attribute((used))``"" in GNU C. On some targets, the code generator must emit a directive to the; assembler or object file to prevent the assembler and linker from; removing the symbol. .. _gv_llvmcompilerused:. The '``llvm.compiler.used``' Global Variable; --------------------------------------------. The ``@llvm.compiler.used`` directive is the same as the ``@llvm.used``; directive, except that it only prevents the compiler from touching the; symbol. On targets that support it, this allows an intelligent linker to; optimize references to the symbol without being impeded as it would be; by ``@llvm.used``. This is a rare construct that should only be used in rare circumstances,; and should not be exposed to source languages. .. _gv_llvmglobalctors:. The '``llvm.global_ctors``' Global Variable; -------------------------------------------. .. code-block:: llvm. %0 = type { i32, ptr, ptr }; @llvm.global_ctors = appending global [1 x %0] [%0 { i32 65535, ptr @ctor, ptr @data }]. The ``@llvm.global_ctors`` array contains a list of constructor; functions, priorities, and an associated global or function.; The functions referenced by this array will be called in ascending order; of priority (i.e. lowest first) when the module is loaded. The order of; functions with the same priority is not defined. If the third field is non-null, and points to a global variable; or function, the initializer function will only run if the associated; data from the current module is not discarded.; On ELF the referenced global varia",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:352321,optimiz,optimize,352321,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['optimiz'],['optimize']
Performance," in the logging stream. It should; always be possible for the symbolizing filter to be implemented as a single pass; over the raw logging stream, accumulating context and massaging text as it goes. ``{{{reset}}}``. This should be output before any other contextual element. The need for this; contextual element is to support implementations that handle logs coming from; multiple processes. Such implementations might not know when a new process; starts or ends. Because some identifying information (like process IDs) might; be the same between old and new processes, a way is needed to distinguish two; processes with such identical identifying information. This element informs; such implementations to reset the state of a filter so that information from a; previous process's contextual elements is not assumed for new process that; just happens have the same identifying information. ``{{{module:%i:%s:%s:...}}}``. This element represents a so-called ""module"". A ""module"" is a single linked; binary, such as a loaded ELF file. Usually each module occupies a contiguous; range of memory. Here ``%i`` is the module ID which is used by other contextual elements to; refer to this module. The first ``%s`` is a human-readable identifier for the; module, such as an ELF ``DT_SONAME`` string or a file name; but it might be; empty. It's only for casual information. Only the module ID is used to refer; to this module in other contextual elements, never the ``%s`` string. The; ``module`` element defining a module ID must always be emitted before any; other elements that refer to that module ID, so that a filter never needs to; keep track of dangling references. The second ``%s`` is the module type and it; determines what the remaining fields are. The following module types are; supported:. * ``elf:%x``. Here ``%x`` encodes an ELF Build ID. The Build ID should refer to a single; linked binary. The Build ID string is the sole way to identify the binary from; which this module was loaded. Ex",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst:19055,load,loaded,19055,interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst,1,['load'],['loaded']
Performance," in total and per thread. ## Compressed vs Uncompressed Throughput:. Throughput speeds are provided as compressed and uncompressed - ROOT files are usually; saved in compressed format, so these will often differ. Compressed bytes is the total; number of bytes read from TFiles during the readspeed test (possibly including meta-data).; Uncompressed bytes is the number of bytes processed by reading the branch values in the TTree.; Throughput is calculated as the total number of bytes over the total runtime (including; decompression time) in the uncompressed and compressed cases. ## Interpreting results:. ### There are three possible scenarios when using rootreadspeed, namely:. - The 'Real Time' is significantly lower than your own analysis runtime.; This would imply your actual application code is dominating the runtime of your analysis,; ie. your analysis logic or framework is taking up the time.; The best way to decrease the runtime would be to optimize your code (or the framework's),; parallelize it onto multiple threads if possible (for example with; [RDataFrame](https://root.cern/doc/master/classROOT_1_1RDataFrame.html); and [EnableImplicitMT](https://root.cern/doc/master/namespaceROOT.html#a06f2b8b216b615e5abbc872c9feff40f)); or switch to a machine with a more performant CPU.; - The 'Real Time' is significantly higher than 'CPU Time / number of threads'*.; If the real time is higher than the CPU time per core it implies the reading of data is the; bottleneck, as the CPU cores are wasting time waiting for data to arrive from your disk/drive; or network connection in order to decompress it.; The best way to decrease your runtime would be transferring the data you need onto a faster; storage medium (ie. a faster disk/drive such as an SSD, or connecting to a faster network; for remote file access), or to use a compression algorithm with a higher compression ratio,; possibly at the cost of the decompression rate.; Changing the number of threads is unlikely to help, and",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/readspeed/README.md:1320,optimiz,optimize,1320,tree/readspeed/README.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/readspeed/README.md,1,['optimiz'],['optimize']
Performance," including section, symbol and relocation information. RuntimeDyldImpl::loadObject then iterates through the symbols in the; image. Information about common symbols is collected for later use. For; each function or data symbol, the associated section is loaded into memory; and the symbol is stored in a symbol table map data structure. When the; iteration is complete, a section is emitted for the common symbols. Next, RuntimeDyldImpl::loadObject iterates through the sections in the; object image and for each section iterates through the relocations for; that sections. For each relocation, it calls the format-specific; processRelocationRef method, which will examine the relocation and store; it in one of two data structures, a section-based relocation list map and; an external symbol relocation map. .. image:: MCJIT-load-object.png. When RuntimeDyldImpl::loadObject returns, all of the code and data; sections for the object will have been loaded into memory allocated by the; memory manager and relocation information will have been prepared, but the; relocations have not yet been applied and the generated code is still not; ready to be executed. [Currently (as of August 2013) the MCJIT engine will immediately apply; relocations when loadObject completes. However, this shouldn't be; happening. Because the code may have been generated for a remote target,; the client should be given a chance to re-map the section addresses before; relocations are applied. It is possible to apply relocations multiple; times, but in the case where addresses are to be re-mapped, this first; application is wasted effort.]. Address Remapping; =================. At any time after initial code has been generated and before; finalizeObject is called, the client can remap the address of sections in; the object. Typically this is done because the code was generated for an; external process and is being mapped into that process' address space.; The client remaps the section address by calling MCJIT::",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MCJITDesignAndImplementation.rst:5161,load,loadObject,5161,interpreter/llvm-project/llvm/docs/MCJITDesignAndImplementation.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MCJITDesignAndImplementation.rst,2,['load'],"['loadObject', 'loaded']"
Performance," independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/load atomic/; atomicrmw-with-return-value.; - s_waitcnt vscnt(0); must happen after; any preceding; global/generic; store/store atomic/; atomicrmw-no-return-value.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global_atomic; 3. s_waitcnt vm/vscnt(0). - Use vmcnt(0) if atomic with; return and vscnt(0) if; atomic with no-return.; - Must happen before; following; buffer_gl*_inv.; - Ensures the; atomicrmw has; completed before; invalidating the; caches. 4. buffer_gl0_inv;; buffer_gl1_inv. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acq_rel - agent - generic 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0) & vscnt(0). - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0), s_waitcnt; vscnt(0), and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/load atomic; atomicrmw-with-return-value.; - s_waitcnt vscnt(0); must happen after; any preceding; global/generic; store/store atomic/; atomicrmw-no-return-value.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; have; completed before; performing the; atomicrmw that is; being released. 2. flat_atomic; 3. s_waitcnt vm/vscnt(0) &; lgkmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Use vmcnt(0) if atomic with; return and vscnt",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:368088,load,loads,368088,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['loads']
Performance," indicated by the register *id*.; hwreg(<*name*>) All bits of a register indicated by the register *name*.; hwreg({0..63}, {0..31}, {1..32}) Register bits indicated by the register *id*, first bit *offset* and *size*.; hwreg(<*name*>, {0..31}, {1..32}) Register bits indicated by the register *name*, first bit *offset* and *size*.; ==================================== ===============================================================================. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Predefined register *names* include:. ============================== ==========================================; Name Description; ============================== ==========================================; HW_REG_MODE Shader writable mode bits.; HW_REG_STATUS Shader read-only status.; HW_REG_TRAPSTS Trap status.; HW_REG_HW_ID1 Id of wave, simd, compute unit, etc.; HW_REG_HW_ID2 Id of queue, pipeline, etc.; HW_REG_GPR_ALLOC Per-wave SGPR and VGPR allocation.; HW_REG_LDS_ALLOC Per-wave LDS allocation.; HW_REG_IB_STS Counters of outstanding instructions.; HW_REG_SH_MEM_BASES Memory aperture.; HW_REG_TBA_LO tba_lo register.; HW_REG_TBA_HI tba_hi register.; HW_REG_TMA_LO tma_lo register.; HW_REG_TMA_HI tma_hi register.; HW_REG_FLAT_SCR_LO flat_scratch_lo register.; HW_REG_FLAT_SCR_HI flat_scratch_hi register.; HW_REG_POPS_PACKER pops_packer register.; HW_REG_SHADER_CYCLES Current graphics clock counter value.; ============================== ==========================================. Examples:. .. parsed-literal::. reg = 1; offset = 2; size = 4; hwreg_enc = reg | (offset << 6) | ((size - 1) << 11). s_getreg_b32 s2, 0x1881; s_getreg_b32 s2, hwreg_enc // the same as above; s_getreg_b32 s2, hwreg(1, 2, 4) // the same as above; s_getreg_b32 s2, hwreg(reg, offset, size) // the same as above. s_getreg_b32 s2, hwreg(15); s_getreg_b32 s2, hwreg(51, 1, 31); s_getreg_b32 s2, hwre",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_hwreg.rst:2141,queue,queue,2141,interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_hwreg.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_hwreg.rst,1,['queue'],['queue']
Performance," indicated by the register *id*.; hwreg(<*name*>) All bits of a register indicated by the register *name*.; hwreg({0..63}, {0..31}, {1..32}) Register bits indicated by the register *id*, first bit *offset* and *size*.; hwreg(<*name*>, {0..31}, {1..32}) Register bits indicated by the register *name*, first bit *offset* and *size*.; ==================================== ===============================================================================. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Predefined register *names* include:. ============================== ==========================================; Name Description; ============================== ==========================================; HW_REG_MODE Shader writable mode bits.; HW_REG_STATUS Shader read-only status.; HW_REG_TRAPSTS Trap status.; HW_REG_HW_ID1 Id of wave, simd, compute unit, etc.; HW_REG_HW_ID2 Id of queue, pipeline, etc.; HW_REG_GPR_ALLOC Per-wave SGPR and VGPR allocation.; HW_REG_LDS_ALLOC Per-wave LDS allocation.; HW_REG_IB_STS Counters of outstanding instructions.; HW_REG_SH_MEM_BASES Memory aperture.; HW_REG_TBA_LO tba_lo register.; HW_REG_TBA_HI tba_hi register.; HW_REG_TMA_LO tma_lo register.; HW_REG_TMA_HI tma_hi register.; HW_REG_FLAT_SCR_LO flat_scratch_lo register.; HW_REG_FLAT_SCR_HI flat_scratch_hi register.; HW_REG_XNACK_MASK xnack_mask register.; HW_REG_POPS_PACKER pops_packer register.; ============================== ==========================================. Examples:. .. parsed-literal::. reg = 1; offset = 2; size = 4; hwreg_enc = reg | (offset << 6) | ((size - 1) << 11). s_getreg_b32 s2, 0x1881; s_getreg_b32 s2, hwreg_enc // the same as above; s_getreg_b32 s2, hwreg(1, 2, 4) // the same as above; s_getreg_b32 s2, hwreg(reg, offset, size) // the same as above. s_getreg_b32 s2, hwreg(15); s_getreg_b32 s2, hwreg(51, 1, 31); s_getreg_b32 s2, hwreg(HW_REG_LDS_ALLOC, ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx10_hwreg.rst:2139,queue,queue,2139,interpreter/llvm-project/llvm/docs/AMDGPU/gfx10_hwreg.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx10_hwreg.rst,1,['queue'],['queue']
Performance," information as they; perform aggressive optimizations. This means that, with effort, the LLVM; optimizers could optimize debug code just as well as non-debug code. * LLVM debug information does not prevent optimizations from; happening (for example inlining, basic block reordering/merging/cleanup,; tail duplication, etc). * LLVM debug information is automatically optimized along with the rest of; the program, using existing facilities. For example, duplicate; information is automatically merged by the linker, and unused information; is automatically removed. Basically, the debug information allows you to compile a program with; ""``-O0 -g``"" and get full debug information, allowing you to arbitrarily modify; the program as it executes from a debugger. Compiling a program with; ""``-O3 -g``"" gives you full debug information that is always available and; accurate for reading (e.g., you get accurate stack traces despite tail call; elimination and inlining), but you might lose the ability to modify the program; and call functions which were optimized out of the program, or inlined away; completely. The :doc:`LLVM test-suite <TestSuiteMakefileGuide>` provides a framework to; test the optimizer's handling of debugging information. It can be run like; this:. .. code-block:: bash. % cd llvm/projects/test-suite/MultiSource/Benchmarks # or some other level; % make TEST=dbgopt. This will test impact of debugging information on optimization passes. If; debugging information influences optimization passes then it will be reported; as a failure. See :doc:`TestingGuide` for more information on LLVM test; infrastructure and how to run various tests. .. _format:. Debugging information format; ============================. LLVM debugging information has been carefully designed to make it possible for; the optimizer to optimize the program and debugging information without; necessarily having to know anything about debugging information. In; particular, the use of metadata avoids dupli",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:5619,optimiz,optimized,5619,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,1,['optimiz'],['optimized']
Performance," information on what and how to install is provided below,; but the recommended (and much easier) way is to use the following command which; performs the required checks automatically and displays useful suggestions too; specific to your platform.; ```sh; cd tools/packaging/; ./cpt.py --check-requirements; ```; or; ```sh; cd tools/packaging/; ./cpt.py -c; ```; Regardless of the platform and operating system, make sure to call the cpt script; with Python 3.; CPT uses some features and modules which are not a part of older versions of Python.; The same holds true for the versions of GCC/Clang you have on your machine. Older; compilers do not support c++11 features and thus you can expect a build error if you; choose not to update them. All pre-compiled binaries of Python ship with built-in support for SSL. However if; the Python on your system was compiled by you manually, chances are that it doesn't; have SSL support. This is very likely if you had performed a minimal installation; of Scientific Linux CERN which doesn't include OpenSSL development package. In such; a case, you should install ```openssl-devel```, re-compile Python and ```configure```; will automatically link against the required libraries and produce a binary with SSL; support. #### Ubuntu/Debian; On Debian, Ubuntu, Linux Mint, CrunchBang, or any other distro based on Debian; which supports APT package manager, you can install all the required packages by:; ```sh; sudo apt-get update; sudo apt-get install git g++ debhelper devscripts gnupg python; ```; You are not required to do this manually since CPT can do this for you automatically. ###### Setting up:; Make sure GnuPG is properly set up with your correct fingerprint. These; credentials are needed to sign the Debian package and create Debian changelogs.; On a build machine (Electric Commander), make sure the fingerprint is of the; user who is supposed to sign the official uploads. You might also want to; configure GnuPG to not ask for the passphrase",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md:2077,perform,performed,2077,interpreter/cling/tools/packaging/README.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md,1,['perform'],['performed']
Performance," instantiate any_cast<int>:; int boost::any_cast(boost::any&& operand) =>; wrapexcept<boost::bad_any_cast>: boost::bad_any_cast: failed conversion using boost::any_cast; >>> extract = boost.any_cast[std.vector[int]](val) # correct cast; >>> type(extract) is std.vector[int]; True; >>> extract += xrange(100); >>> len(extract); 100; >>> val.__assign__(std.move(extract)) # move forced; <cppyy.gbl.boost.any object at 0xf6a8a0>; >>> len(extract) # now empty (or invalid); 0; >>> extract = boost.any_cast[std.vector[int]](val); >>> list(extract); [0, 1, 2, 3, 4, 5, 6, ..., 97, 98, 99]; >>>. Of course, there is no reason to use Boost from Python (in fact, this example; calls out for :doc:`pythonizations <pythonizations>`), but it shows that; cppyy seamlessly supports many advanced C++ features. cppyy is available for both `CPython`_ (v2 and v3) and `PyPy`_, reaching; C++-like performance with the latter.; It makes judicious use of precompiled headers, dynamic loading, and lazy; instantiation, to support C++ programs consisting of millions of lines of; code and many thousands of classes.; cppyy minimizes dependencies to allow its use in distributed, heterogeneous,; development environments. .. _Cling: https://github.com/vgvassilev/cling; .. _tutorial: https://github.com/wlav/cppyy/blob/master/doc/tutorial/CppyyTutorial.ipynb; .. _`PyHPC'16 paper`: http://wlav.web.cern.ch/wlav/Cppyy_LavrijsenDutta_PyHPC16.pdf; .. _`CAAS presentation`: https://www.youtube.com/watch?v=stMD7VDWlVU; .. _`Jason Turner's`: https://www.youtube.com/watch?v=TL83P77vZ1k; .. _`Boost`: http://www.boost.org/; .. _`CPython`: http://python.org; .. _`PyPy`: http://pypy.org. .. only: not latex. Contents:. .. toctree::; :maxdepth: 1. changelog; license. .. toctree::; :caption: Getting Started; :maxdepth: 1. installation; starting; examples; bugs. .. toctree::; :caption: Features; :maxdepth: 1. toplevel; basic_types; strings; classes; functions; type_conversions; stl; exceptions; python; numba; cuda; lowlevel; mi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/index.rst:4416,load,loading,4416,bindings/pyroot/cppyy/cppyy/doc/source/index.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/index.rst,1,['load'],['loading']
Performance," instruction; requiring REX prefix. However, divb and mulb both produce results in AH. If isel; emits a CopyFromReg which gets turned into a movb and that can be allocated a; r8b - r15b. To get around this, isel emits a CopyFromReg from AX and then right shift it; down by 8 and truncate it. It's not pretty but it works. We need some register; allocation magic to make the hack go away (e.g. putting additional constraints; on the result of the movb). //===---------------------------------------------------------------------===//. The x86-64 ABI for hidden-argument struct returns requires that the; incoming value of %rdi be copied into %rax by the callee upon return. The idea is that it saves callers from having to remember this value,; which would often require a callee-saved register. Callees usually; need to keep this value live for most of their body anyway, so it; doesn't add a significant burden on them. We currently implement this in codegen, however this is suboptimal; because it means that it would be quite awkward to implement the; optimization for callers. A better implementation would be to relax the LLVM IR rules for sret; arguments to allow a function with an sret argument to have a non-void; return type, and to have the front-end to set up the sret argument value; as the return value of the function. The front-end could more easily; emit uses of the returned struct value to be in terms of the function's; lowered return value, and it would free non-C frontends from a; complication only required by a C-based ABI. //===---------------------------------------------------------------------===//. We get a redundant zero extension for code like this:. int mask[1000];; int foo(unsigned x) {; if (x < 10); x = x * 45;; else; x = x * 78;; return mask[x];; }. _foo:; LBB1_0:	## entry; 	cmpl	$9, %edi; 	jbe	LBB1_3	## bb; LBB1_1:	## bb1; 	imull	$78, %edi, %eax; LBB1_2:	## bb2; 	movl	%eax, %eax <----; 	movq	_mask@GOTPCREL(%rip), %rcx; 	movl	(%rcx,%rax,4), %eax; 	ret; LBB",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README-X86-64.txt:2259,optimiz,optimization,2259,interpreter/llvm-project/llvm/lib/Target/X86/README-X86-64.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README-X86-64.txt,2,['optimiz'],['optimization']
Performance," instructions in the; linked section to narrow down the bug so that the person who fixes it will be; able to find the problem more easily. Once you have a reduced test-case, go to `the LLVM Bug Tracking System; <https://github.com/llvm/llvm-project/issues>`_ and fill out the form with the; necessary details (note that you don't need to pick a label, just use if you're; not sure). The bug description should contain the following information:. * All information necessary to reproduce the problem.; * The reduced test-case that triggers the bug.; * The location where you obtained LLVM (if not from our Git; repository). Thanks for helping us make LLVM better!. .. _crashes the compiler:. Crashing Bugs; =============. More often than not, bugs in the compiler cause it to crash---often due to; an assertion failure of some sort. The most important piece of the puzzle; is to figure out if it is crashing in the Clang front-end or if it is one of; the LLVM libraries (e.g. the optimizer or code generator) that has; problems. To figure out which component is crashing (the front-end, middle-end; optimizer, or backend code generator), run the ``clang`` command line as you; were when the crash occurred, but with the following extra command line; options:. * ``-emit-llvm -Xclang -disable-llvm-passes``: If ``clang`` still crashes when; passed these options (which disable the optimizer and code generator), then; the crash is in the front-end. Jump ahead to :ref:`front-end bugs; <frontend-crash>`. * ``-emit-llvm``: If ``clang`` crashes with this option (which disables; the code generator), you found a middle-end optimizer bug. Jump ahead to; :ref:`middle-end bugs <middleend-crash>`. * Otherwise, you have a backend code generator crash. Jump ahead to :ref:`code; generator bugs <backend-crash>`. .. _frontend-crash:. Front-end bugs; --------------. On a ``clang`` crash, the compiler will dump a preprocessed file and a script; to replay the ``clang`` command. For example, you should see some",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToSubmitABug.rst:1692,optimiz,optimizer,1692,interpreter/llvm-project/llvm/docs/HowToSubmitABug.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToSubmitABug.rst,1,['optimiz'],['optimizer']
Performance," interpretations: the full; tag interpretation (where the pointer tag is between 1 and `TG-1` and the; last byte of the granule is ordinary data) and the short tag interpretation; (where the pointer tag is stored in the granule). When HWASAN detects an error near a memory tag between 1 and `TG-1`, it; will show both the memory tag and the last byte of the granule. Currently,; it is up to the user to disambiguate the two possibilities. Instrumentation; ===============. Memory Accesses; ---------------; In the majority of cases, memory accesses are prefixed with a call to; an outlined instruction sequence that verifies the tags. The code size; and performance overhead of the call is reduced by using a custom calling; convention that. * preserves most registers, and; * is specialized to the register containing the address, and the type and; size of the memory access. Currently, the following sequence is used:. .. code-block:: none. // int foo(int *a) { return *a; }; // clang -O2 --target=aarch64-linux-android30 -fsanitize=hwaddress -S -o - load.c; [...]; foo:; stp x30, x20, [sp, #-16]!; adrp x20, :got:__hwasan_shadow // load shadow address from GOT into x20; ldr x20, [x20, :got_lo12:__hwasan_shadow]; bl __hwasan_check_x0_2_short_v2 // call outlined tag check; // (arguments: x0 = address, x20 = shadow base;; // ""2"" encodes the access type and size); ldr w0, [x0] // inline load; ldp x30, x20, [sp], #16; ret. [...]; __hwasan_check_x0_2_short_v2:; sbfx x16, x0, #4, #52 // shadow offset; ldrb w16, [x20, x16] // load shadow tag; cmp x16, x0, lsr #56 // extract address tag, compare with shadow tag; b.ne .Ltmp0 // jump to short tag handler on mismatch; .Ltmp1:; ret; .Ltmp0:; cmp w16, #15 // is this a short tag?; b.hi .Ltmp2 // if not, error; and x17, x0, #0xf // find the address's position in the short granule; add x17, x17, #3 // adjust to the position of the last byte loaded; cmp w16, w17 // check that position is in bounds; b.ls .Ltmp2 // if not, error; orr x16, x0, #0xf //",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/HardwareAssistedAddressSanitizerDesign.rst:3771,load,load,3771,interpreter/llvm-project/clang/docs/HardwareAssistedAddressSanitizerDesign.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/HardwareAssistedAddressSanitizerDesign.rst,1,['load'],['load']
Performance," into a single executable (which is fairly common in large apps).; Having a single malloc would just not suffice, and instead would simply; complicate the picture further because it adds an extra variant in; addition to the one each language provides. Instead, providing a default library version of malloc and free; (and perhaps a malloc_gc with garbage collection instead of free); would make a good implementation available to anyone who wants it. I don't recall all your arguments in favor so let's discuss this again,; and soon. o 'alloca' on the other hand sounds like a good idea, and the; implementation seems fairly language-independent so it doesn't have the; problems with malloc listed above. o About indirect call:; Your option #2 sounded good to me. I'm not sure I understand your; concern about an explicit 'icall' instruction?. o A pair of important synchronization instr'ns to think about:; load-linked; store-conditional. o Other classes of instructions that are valuable for pipeline performance:; conditional-move		 ; predicated instructions. o I believe tail calls are relatively easy to identify; do you know why; .NET has a tailcall instruction?. o I agree that we need a static data space. Otherwise, emulating global; data gets unnecessarily complex. o About explicit parallelism:. We once talked about adding a symbolic thread-id field to each; instruction. (It could be optional so single-threaded codes are; not penalized.) This could map well to multi-threaded architectures; while providing easy ILP for single-threaded onces. But it is probably; too radical an idea to include in a base version of LLVM. Instead, it; could a great topic for a separate study. What is the semantics of the IA64 stop bit?. o And finally, another thought about the syntax for arrays :-). Although this syntax:; 	 array <dimension-list> of <type>; is verbose, it will be used only in the human-readable assembly code so; size should not matter. I think we should consider it because I find i",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-02-09-AdveComments.txt:3442,perform,performance,3442,interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-02-09-AdveComments.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-02-09-AdveComments.txt,1,['perform'],['performance']
Performance," into memory at arbitrary locations,; and set bias to the offset between the original and the new counter location,; at which point every subsequent counter access will be to the new location,; which allows updating profile directly akin to the continuous mode. The advantage of this approach is that doesn't require any special OS support.; The disadvantage is the extra overhead due to additional instructions required; for each counter access (overhead both in terms of binary size and performance); plus duplication of counters (i.e. one copy in the binary itself and another; copy that's mapped into memory). This implementation can be also enabled for; other platforms by passing the ``-runtime-counter-relocation`` option to the; backend during compilation. For a program such as the `Lit <https://llvm.org/docs/CommandGuide/lit.html>`_; testing tool which invokes other programs, it may be necessary to set; ``LLVM_PROFILE_FILE`` for each invocation. The pattern strings ""%p"" or ""%Nm""; may help to avoid corruption due to concurrency. Note that ""%p"" is also a Lit; token and needs to be escaped as ""%%p"". .. code-block:: console. % clang++ -fprofile-instr-generate -fcoverage-mapping -mllvm -runtime-counter-relocation foo.cc -o foo. Creating coverage reports; =========================. Raw profiles have to be **indexed** before they can be used to generate; coverage reports. This is done using the ""merge"" tool in ``llvm-profdata``; (which can combine multiple raw profiles and index them at the same time):. .. code-block:: console. # Step 3(a): Index the raw profile.; % llvm-profdata merge -sparse foo.profraw -o foo.profdata. For an example of merging multiple profiles created by testing,; see the LLVM `coverage build script <https://github.com/llvm/llvm-zorg/blob/main/zorg/jenkins/jobs/jobs/llvm-coverage>`_. There are multiple different ways to render coverage reports. The simplest; option is to generate a line-oriented report:. .. code-block:: console. # Step 3(b): Create a l",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/SourceBasedCodeCoverage.rst:5635,concurren,concurrency,5635,interpreter/llvm-project/clang/docs/SourceBasedCodeCoverage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/SourceBasedCodeCoverage.rst,1,['concurren'],['concurrency']
Performance," into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Must happen before; the following; buffer_wbinvl1_vol.; - Ensures that the; fence-paired atomic; has completed; before invalidating; the; cache. Therefore; any following; locations read must; be no older than; the value read by; the; fence-paired-atomic. 2. buffer_wbinvl1_vol. - Must happen before any; following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. **Release Atomic**; ------------------------------------------------------------------------------------; store atomic release - singlethread - global 1. buffer/global/ds/flat_store; - wavefront - local; - generic; store atomic release - workgroup - global 1. s_waitcnt lgkmcnt(0); - generic; - If OpenCL, omit.; - Must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; to local have; completed before; performing the; store that is being; released. 2. buffer/global/flat_store; store atomic release - workgroup - local 1. ds_store; store atomic release - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0). - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; foll",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:218857,load,loads,218857,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['loads']
Performance," into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Must happen before; the following; buffer_wbinvl1_vol.; - Ensures that the; fence-paired atomic; has completed; before invalidating; the; cache. Therefore; any following; locations read must; be no older than; the value read by; the; fence-paired-atomic. 2. buffer_wbinvl1_vol. - Must happen before any; following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. fence acquire - system *none* 1. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate; (see comment for; previous fence).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Must happen before; the followin",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:255197,load,loads,255197,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['loads']
Performance," intrinsic. ::. declare <16 x float> @llvm.vp.fma.v16f32 (<16 x float> <left_op>, <16 x float> <middle_op>, <16 x float> <right_op>, <16 x i1> <mask>, i32 <vector_length>); declare <vscale x 4 x float> @llvm.vp.fma.nxv4f32 (<vscale x 4 x float> <left_op>, <vscale x 4 x float> <middle_op>, <vscale x 4 x float> <right_op>, <vscale x 4 x i1> <mask>, i32 <vector_length>); declare <256 x double> @llvm.vp.fma.v256f64 (<256 x double> <left_op>, <256 x double> <middle_op>, <256 x double> <right_op>, <256 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated floating-point fused multiply-add of two vectors of floating-point values. Arguments:; """""""""""""""""""". The first three operands and the result have the same vector of floating-point type. The; fourth operand is the vector mask and has the same number of elements as the; result vector type. The fifth operand is the explicit vector length of the; operation. Semantics:; """""""""""""""""""". The '``llvm.vp.fma``' intrinsic performs floating-point fused multiply-add (:ref:`llvm.fma <int_fma>`); of the first, second, and third vector operand on each enabled lane. The result on; disabled lanes is a :ref:`poison value <poisonvalues>`. The operation is; performed in the default floating-point environment. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call <4 x float> @llvm.vp.fma.v4f32(<4 x float> %a, <4 x float> %b, <4 x float> %c, <4 x i1> %mask, i32 %evl); ;; For all lanes below %evl, %r is lane-wise equivalent to %also.r. %t = call <4 x float> @llvm.fma(<4 x float> %a, <4 x float> %b, <4 x float> %c); %also.r = select <4 x i1> %mask, <4 x float> %t, <4 x float> poison. .. _int_vp_fmuladd:. '``llvm.vp.fmuladd.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare <16 x float> @llvm.vp.fmuladd.v16f32 (<16 x float> <left_op>, <16 x float> <middle_op>, <16 x float> <right_op>, <16 x i1> <mask>, i32 <vector_length>); declare <vscale x 4 x float> @llvm.vp.fmuladd.nx",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:745549,perform,performs,745549,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['performs']
Performance," intrinsics treat ``%A`` as a ``<OuterRows> x; <Inner>`` matrix, ``%B`` as a ``<Inner> x <OuterColumns>`` matrix, and; multiplies them. The result matrix is returned in the result vector. Arguments:; """""""""""""""""""". The first vector argument ``%A`` corresponds to a matrix with ``<OuterRows> *; <Inner>`` elements, and the second argument ``%B`` to a matrix with; ``<Inner> * <OuterColumns>`` elements. Arguments ``<OuterRows>``,; ``<Inner>`` and ``<OuterColumns>`` must be positive, constant integers. The; returned vector must have ``<OuterRows> * <OuterColumns>`` elements.; Vectors ``%A``, ``%B``, and the returned vector all have the same float or; integer element type. '``llvm.matrix.column.major.load.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare vectorty @llvm.matrix.column.major.load.*(; ptrty %Ptr, i64 %Stride, i1 <IsVolatile>, i32 <Rows>, i32 <Cols>). Overview:; """""""""""""""""". The '``llvm.matrix.column.major.load.*``' intrinsics load a ``<Rows> x <Cols>``; matrix using a stride of ``%Stride`` to compute the start address of the; different columns. The offset is computed using ``%Stride``'s bitwidth. This; allows for convenient loading of sub matrixes. If ``<IsVolatile>`` is true, the; intrinsic is considered a :ref:`volatile memory access <volatile>`. The result; matrix is returned in the result vector. If the ``%Ptr`` argument is known to; be aligned to some boundary, this can be specified as an attribute on the; argument. Arguments:; """""""""""""""""""". The first argument ``%Ptr`` is a pointer type to the returned vector type, and; corresponds to the start address to load from. The second argument ``%Stride``; is a positive, constant integer with ``%Stride >= <Rows>``. ``%Stride`` is used; to compute the column memory addresses. I.e., for a column ``C``, its start; memory addresses is calculated with ``%Ptr + C * %Stride``. The third Argument; ``<IsVolatile>`` is a boolean value. The fourth and fif",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:677903,load,load,677903,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['load'],['load']
Performance," is already zero ; extended in the 32-bit stack slot IIRC. For signed short, it should also be; save, as a really-signed value would be undefined for pslld. //===---------------------------------------------------------------------===//. #include <math.h>; int t1(double d) { return signbit(d); }. This currently compiles to:; 	subl	$12, %esp; 	movsd	16(%esp), %xmm0; 	movsd	%xmm0, (%esp); 	movl	4(%esp), %eax; 	shrl	$31, %eax; 	addl	$12, %esp; 	ret. We should use movmskp{s|d} instead. //===---------------------------------------------------------------------===//. CodeGen/X86/vec_align.ll tests whether we can turn 4 scalar loads into a single; (aligned) vector load. This functionality has a couple of problems. 1. The code to infer alignment from loads of globals is in the X86 backend,; not the dag combiner. This is because dagcombine2 needs to be able to see; through the X86ISD::Wrapper node, which DAGCombine can't really do.; 2. The code for turning 4 x load into a single vector load is target ; independent and should be moved to the dag combiner.; 3. The code for turning 4 x load into a vector load can only handle a direct ; load from a global or a direct load from the stack. It should be generalized; to handle any load from P, P+4, P+8, P+12, where P can be anything.; 4. The alignment inference code cannot handle loads from globals in non-static; mode because it doesn't look through the extra dyld stub load. If you try; vec_align.ll without -relocation-model=static, you'll see what I mean. //===---------------------------------------------------------------------===//. We should lower store(fneg(load p), q) into an integer load+xor+store, which; eliminates a constant pool load. For example, consider:. define i64 @ccosf(float %z.0, float %z.1) nounwind readonly {; entry:; %tmp6 = fsub float -0.000000e+00, %z.1		; <float> [#uses=1]; %tmp20 = tail call i64 @ccoshf( float %tmp6, float %z.0 ) nounwind readonly; ret i64 %tmp20; }; declare i64 @ccoshf(float %z.0, float %z.1",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README-SSE.txt:11781,load,load,11781,interpreter/llvm-project/llvm/lib/Target/X86/README-SSE.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README-SSE.txt,4,['load'],['load']
Performance," is an overloaded intrinsic. ::. declare i32 @llvm.vp.reduce.smax.v4i32(i32 <start_value>, <4 x i32> <val>, <4 x i1> <mask>, i32 <vector_length>); declare i16 @llvm.vp.reduce.smax.nxv8i16(i16 <start_value>, <vscale x 8 x i16> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated signed-integer ``MAX`` reduction of a vector and a scalar starting; value, returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value of the reduction, which must be a scalar; integer type equal to the result type. The second operand is the vector on; which the reduction is performed and must be a vector of integer values whose; element type is the result/start type. The third operand is the vector mask and; is a vector of boolean values with the same number of elements as the vector; operand. The fourth operand is the explicit vector length of the operation. Semantics:; """""""""""""""""""". The '``llvm.vp.reduce.smax``' intrinsic performs the signed-integer ``MAX``; reduction (:ref:`llvm.vector.reduce.smax <int_vector_reduce_smax>`) of the; vector operand ``val`` on each enabled lane, and taking the maximum of that and; the scalar ``start_value``. Disabled lanes are treated as containing the; neutral value ``INT_MIN`` (i.e. having no effect on the reduction operation).; If the vector length is zero, the result is the start value. To ignore the start value, the neutral value can be used. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call i8 @llvm.vp.reduce.smax.v4i8(i8 %start, <4 x i8> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equal to %evl; ; are treated as though %mask were false for those lanes. %masked.a = select <4 x i1> %mask, <4 x i8> %a, <4 x i8> <i8 -128, i8 -128, i8 -128, i8 -128>; %reduction = call i8 @llvm.vector.reduce.smax.v4i8(<4 x i8> %masked.a); %also.r = call i8 @llvm.smax.i8(i8 %reduction, i8 %start). .. _int_vp_reduce_smin:. '``llvm.vp.reduce.smin.*``' Intrinsics",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:763811,perform,performs,763811,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['performs']
Performance," is an overloaded intrinsic. ::. declare i32 @llvm.vp.reduce.smin.v4i32(i32 <start_value>, <4 x i32> <val>, <4 x i1> <mask>, i32 <vector_length>); declare i16 @llvm.vp.reduce.smin.nxv8i16(i16 <start_value>, <vscale x 8 x i16> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated signed-integer ``MIN`` reduction of a vector and a scalar starting; value, returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value of the reduction, which must be a scalar; integer type equal to the result type. The second operand is the vector on; which the reduction is performed and must be a vector of integer values whose; element type is the result/start type. The third operand is the vector mask and; is a vector of boolean values with the same number of elements as the vector; operand. The fourth operand is the explicit vector length of the operation. Semantics:; """""""""""""""""""". The '``llvm.vp.reduce.smin``' intrinsic performs the signed-integer ``MIN``; reduction (:ref:`llvm.vector.reduce.smin <int_vector_reduce_smin>`) of the; vector operand ``val`` on each enabled lane, and taking the minimum of that and; the scalar ``start_value``. Disabled lanes are treated as containing the; neutral value ``INT_MAX`` (i.e. having no effect on the reduction operation).; If the vector length is zero, the result is the start value. To ignore the start value, the neutral value can be used. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call i8 @llvm.vp.reduce.smin.v4i8(i8 %start, <4 x i8> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equal to %evl; ; are treated as though %mask were false for those lanes. %masked.a = select <4 x i1> %mask, <4 x i8> %a, <4 x i8> <i8 127, i8 127, i8 127, i8 127>; %reduction = call i8 @llvm.vector.reduce.smin.v4i8(<4 x i8> %masked.a); %also.r = call i8 @llvm.smin.i8(i8 %reduction, i8 %start). .. _int_vp_reduce_umax:. '``llvm.vp.reduce.umax.*``' Intrinsics; ^^",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:765876,perform,performs,765876,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['performs']
Performance," is checked to validate of debugging information. See README.txt in the; test suite for more information. This test suite is located in the; ``cross-project-tests/debuginfo-tests`` directory. Quick start; ===========. The tests are located in two separate repositories. The unit and; regression tests are in the main ""llvm""/ directory under the directories; ``llvm/unittests`` and ``llvm/test`` (so you get these tests for free with the; main LLVM tree). Use ``make check-all`` to run the unit and regression tests; after building LLVM. The ``test-suite`` module contains more comprehensive tests including whole C; and C++ programs. See the :doc:`TestSuiteGuide` for details. Unit and Regression tests; -------------------------. To run all of the LLVM unit tests use the check-llvm-unit target:. .. code-block:: bash. % make check-llvm-unit. To run all of the LLVM regression tests use the check-llvm target:. .. code-block:: bash. % make check-llvm. In order to get reasonable testing performance, build LLVM and subprojects; in release mode, i.e. .. code-block:: bash. % cmake -DCMAKE_BUILD_TYPE=""Release"" -DLLVM_ENABLE_ASSERTIONS=On. If you have `Clang <https://clang.llvm.org/>`_ checked out and built, you; can run the LLVM and Clang tests simultaneously using:. .. code-block:: bash. % make check-all. To run the tests with Valgrind (Memcheck by default), use the ``LIT_ARGS`` make; variable to pass the required options to lit. For example, you can use:. .. code-block:: bash. % make check LIT_ARGS=""-v --vg --vg-leak"". to enable testing with valgrind and with leak checking enabled. To run individual tests or subsets of tests, you can use the ``llvm-lit``; script which is built as part of LLVM. For example, to run the; ``Integer/BitPacked.ll`` test by itself you can run:. .. code-block:: bash. % llvm-lit ~/llvm/test/Integer/BitPacked.ll. or to run all of the ARM CodeGen tests:. .. code-block:: bash. % llvm-lit ~/llvm/test/CodeGen/ARM. The regression tests will use the Python psutil ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:5325,perform,performance,5325,interpreter/llvm-project/llvm/docs/TestingGuide.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst,1,['perform'],['performance']
Performance," is combined with poison-generating metadata like ``!nonnull``,; violation of that metadata constraint will also result in undefined behavior. Semantics:; """""""""""""""""""". The location of memory pointed to is loaded. If the value being loaded; is of scalar type then the number of bytes read does not exceed the; minimum number of bytes needed to hold all bits of the type. For; example, loading an ``i24`` reads at most three bytes. When loading a; value of a type like ``i20`` with a size that is not an integral number; of bytes, the result is undefined if the value was not originally; written using a store of the same type.; If the value being loaded is of aggregate type, the bytes that correspond to; padding may be accessed but are ignored, because it is impossible to observe; padding from the loaded aggregate value.; If ``<pointer>`` is not a well-defined value, the behavior is undefined. Examples:; """""""""""""""""". .. code-block:: llvm. %ptr = alloca i32 ; yields ptr; store i32 3, ptr %ptr ; yields void; %val = load i32, ptr %ptr ; yields i32:val = i32 3. .. _i_store:. '``store``' Instruction; ^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. store [volatile] <ty> <value>, ptr <pointer>[, align <alignment>][, !nontemporal !<nontemp_node>][, !invariant.group !<empty_node>] ; yields void; store atomic [volatile] <ty> <value>, ptr <pointer> [syncscope(""<target-scope>"")] <ordering>, align <alignment> [, !invariant.group !<empty_node>] ; yields void; !<nontemp_node> = !{ i32 1 }; !<empty_node> = !{}. Overview:; """""""""""""""""". The '``store``' instruction is used to write to memory. Arguments:; """""""""""""""""""". There are two arguments to the ``store`` instruction: a value to store and an; address at which to store it. The type of the ``<pointer>`` operand must be a; pointer to the :ref:`first class <t_firstclass>` type of the ``<value>``; operand. If the ``store`` is marked as ``volatile``, then the optimizer is not; allowed to modify the number or order of execution of this ``store`` with other",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:418965,load,load,418965,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['load'],['load']
Performance," is equivalent to calling ``func`` with the same argument list,; but with ``nval`` used for the missing ``nest`` argument. If, after; calling ``llvm.init.trampoline``, the memory pointed to by ``tramp`` is; modified, then the effect of any later call to the returned function; pointer is undefined. .. _int_at:. '``llvm.adjust.trampoline``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare ptr @llvm.adjust.trampoline(ptr <tramp>). Overview:; """""""""""""""""". This performs any required machine-specific adjustment to the address of; a trampoline (passed as ``tramp``). Arguments:; """""""""""""""""""". ``tramp`` must point to a block of memory which already has trampoline; code filled in by a previous call to; :ref:`llvm.init.trampoline <int_it>`. Semantics:; """""""""""""""""""". On some architectures the address of the code to be executed needs to be; different than the address where the trampoline is actually stored. This; intrinsic returns the executable address corresponding to ``tramp``; after performing the required machine specific adjustments. The pointer; returned can then be :ref:`bitcast and executed <int_trampoline>`. .. _int_vp:. Vector Predication Intrinsics; -----------------------------; VP intrinsics are intended for predicated SIMD/vector code. A typical VP; operation takes a vector mask and an explicit vector length parameter as in:. ::. <W x T> llvm.vp.<opcode>.*(<W x T> %x, <W x T> %y, <W x i1> %mask, i32 %evl). The vector mask parameter (%mask) always has a vector of `i1` type, for example; `<32 x i1>`. The explicit vector length parameter always has the type `i32` and; is an unsigned integer value. The explicit vector length parameter (%evl) is in; the range:. ::. 0 <= %evl <= W, where W is the number of vector elements. Note that for :ref:`scalable vector types <t_vector>` ``W`` is the runtime; length of the vector. The VP intrinsic has undefined behavior if ``%evl > W``. The explicit vector; length (%evl) creates a mask, %EVLmask, with all e",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:691467,perform,performing,691467,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['performing']
Performance," is evaluated in; the context of the calling frame. *It may be used to determine the value of arguments on entry to the current; call frame provided they are not clobbered.*. It has two operands. The first is an unsigned LEB128 integer S. The second; is a block of bytes, with a length equal S, interpreted as a DWARF; operation expression E. E is evaluated with the current context, except the result kind is; unspecified, the call frame is the one that called the current frame, the; program location is the call site in the calling frame, the object is; unspecified, and the initial stack is empty. The calling frame information; is obtained by virtually unwinding the current call frame using the call; frame information (see :ref:`amdgpu-dwarf-call-frame-information`). If the result of E is a location description L (see; :ref:`amdgpu-dwarf-register-location-description-operations`), and the last; operation executed by E is a ``DW_OP_reg*`` for register R with a target; architecture specific base type of T, then the contents of the register are; retrieved as if a ``DW_OP_deref_type DR`` operation was performed where DR; is the offset of a hypothetical debug information entry in the current; compilation unit for T. The resulting value V s pushed on the stack. *Using* ``DW_OP_reg*`` *provides a more compact form for the case where the; value was in a register on entry to the subprogram.*. .. note::. It is unclear how this provides a more compact expression, as; ``DW_OP_regval_type`` could be used which is marginally larger. If the result of E is a value V, then V is pushed on the stack. Otherwise, the DWARF expression is ill-formed. *The* ``DW_OP_entry_value`` *operation is deprecated as its main usage is; provided by other means. DWARF Version 5 added the*; ``DW_TAG_call_site_parameter`` *debugger information entry for call sites; that has* ``DW_AT_call_value``\ *,* ``DW_AT_call_data_location``\ *, and*; ``DW_AT_call_data_value`` *attributes that provide DWARF expressions t",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:96544,perform,performed,96544,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,1,['perform'],['performed']
Performance," is inconvenient and wasteful for every front-end to; have to reproduce this logic. Memory in LLVM; ==============. The 'trick' here is that while LLVM does require all register values to; be in SSA form, it does not require (or permit) memory objects to be in; SSA form. In the example above, note that the loads from G and H are; direct accesses to G and H: they are not renamed or versioned. This; differs from some other compiler systems, which do try to version memory; objects. In LLVM, instead of encoding dataflow analysis of memory into; the LLVM IR, it is handled with `Analysis; Passes <../../WritingAnLLVMPass.html>`_ which are computed on demand. With this in mind, the high-level idea is that we want to make a stack; variable (which lives in memory, because it is on the stack) for each; mutable object in a function. To take advantage of this trick, we need; to talk about how LLVM represents stack variables. In LLVM, all memory accesses are explicit with load/store instructions,; and it is carefully designed not to have (or need) an ""address-of""; operator. Notice how the type of the @G/@H global variables is actually; ""i32\*"" even though the variable is defined as ""i32"". What this means is; that @G defines *space* for an i32 in the global data area, but its; *name* actually refers to the address for that space. Stack variables; work the same way, except that instead of being declared with global; variable definitions, they are declared with the `LLVM alloca; instruction <../../LangRef.html#alloca-instruction>`_:. .. code-block:: llvm. define i32 @example() {; entry:; %X = alloca i32 ; type of %X is i32*.; ...; %tmp = load i32, i32* %X ; load the stack value %X from the stack.; %tmp2 = add i32 %tmp, 1 ; increment it; store i32 %tmp2, i32* %X ; store it back; ... This code shows an example of how you can declare and manipulate a stack; variable in the LLVM IR. Stack memory allocated with the alloca; instruction is fully general: you can pass the address of the stac",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl07.rst:4374,load,load,4374,interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl07.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl07.rst,1,['load'],['load']
Performance," is inferred from the target triple and autodetected to; the current architecture. For a list of available CPUs, use:. .. code-block:: none. llvm-as < /dev/null | llc -march=xyz -mcpu=help. .. option:: -filetype=<output file type>. Specify what kind of output ``llc`` should generated. Options are: ``asm``; for textual assembly ( ``'.s'``), ``obj`` for native object files (``'.o'``); and ``null`` for not emitting anything (for performance testing). Note that not all targets support all options. .. option:: -mattr=a1,+a2,-a3,... Override or control specific attributes of the target, such as whether SIMD; operations are enabled or not. The default set of attributes is set by the; current CPU. For a list of available attributes, use:. .. code-block:: none. llvm-as < /dev/null | llc -march=xyz -mattr=help. .. option:: --frame-pointer. Specify effect of frame pointer elimination optimization (all,non-leaf,none). .. option:: --disable-excess-fp-precision. Disable optimizations that may produce excess precision for floating point.; Note that this option can dramatically slow down code on some systems; (e.g. X86). .. option:: --enable-no-infs-fp-math. Enable optimizations that assume no Inf values. .. option:: --enable-no-nans-fp-math. Enable optimizations that assume no NAN values. .. option:: --enable-no-signed-zeros-fp-math. Enable FP math optimizations that assume the sign of 0 is insignificant. .. option:: --enable-no-trapping-fp-math. Enable setting the FP exceptions build attribute not to use exceptions. .. option:: --enable-unsafe-fp-math. Enable optimizations that make unsafe assumptions about IEEE math (e.g. that; addition is associative) or may not work for all input ranges. These; optimizations allow the code generator to make use of some instructions which; would otherwise not be usable (such as ``fsin`` on X86). .. option:: --stats. Print statistics recorded by code-generation passes. .. option:: --time-passes. Record the amount of time needed for each pass and",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llc.rst:3239,optimiz,optimizations,3239,interpreter/llvm-project/llvm/docs/CommandGuide/llc.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llc.rst,1,['optimiz'],['optimizations']
Performance," is inverted, but GVN only runs late in the pipeline.; As a result, you may miss the opportunity to run other important; optimizations. #. Avoid using arithmetic intrinsics unless you are *required* by your source; language specification to emit a particular code sequence. The optimizer; is quite good at reasoning about general control flow and arithmetic, it is; not anywhere near as strong at reasoning about the various intrinsics. If; profitable for code generation purposes, the optimizer will likely form the; intrinsics itself late in the optimization pipeline. It is *very* rarely; profitable to emit these directly in the language frontend. This item; explicitly includes the use of the :ref:`overflow intrinsics <int_overflow>`. #. Avoid using the :ref:`assume intrinsic <int_assume>` until you've; established that a) there's no other way to express the given fact and b); that fact is critical for optimization purposes. Assumes are a great; prototyping mechanism, but they can have negative effects on both compile; time and optimization effectiveness. The former is fixable with enough; effort, but the later is fairly fundamental to their designed purpose. Describing Language Specific Properties; =======================================. When translating a source language to LLVM, finding ways to express concepts; and guarantees available in your source language which are not natively; provided by LLVM IR will greatly improve LLVM's ability to optimize your code.; As an example, C/C++'s ability to mark every add as ""no signed wrap (nsw)"" goes; a long way to assisting the optimizer in reasoning about loop induction; variables and thus generating more optimal code for loops. The LLVM LangRef includes a number of mechanisms for annotating the IR with; additional semantic information. It is *strongly* recommended that you become; highly familiar with this document. The list below is intended to highlight a; couple of items of particular interest, but is by no means exhaust",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:9663,optimiz,optimization,9663,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,1,['optimiz'],['optimization']
Performance," is irrelevant; it's perfectly; valid to compute arbitrary element indices, as the computation only depends on; the size of the array element, not the number of elements. Note that zero-sized; arrays are not a special case here. This sense is unconnected with ``inbounds`` keyword. The ``inbounds`` keyword is; designed to describe low-level pointer arithmetic overflow conditions, rather; than high-level array indexing rules. Analysis passes which wish to understand array indexing should not assume that; the static array type bounds are respected. The second sense of being out of bounds is computing an address that's beyond; the actual underlying allocated object. With the ``inbounds`` keyword, the result value of the GEP is ``poison`` if the; address is outside the actual underlying allocated object and not the address; one-past-the-end. Without the ``inbounds`` keyword, there are no restrictions on computing; out-of-bounds addresses. Obviously, performing a load or a store requires an; address of allocated and sufficiently aligned memory. But the GEP itself is only; concerned with computing addresses. Can array indices be negative?; ------------------------------. Yes. This is basically a special case of array indices being out of bounds. Can I compare two values computed with GEPs?; --------------------------------------------. Yes. If both addresses are within the same allocated object, or; one-past-the-end, you'll get the comparison result you expect. If either is; outside of it, integer arithmetic wrapping may occur, so the comparison may not; be meaningful. Can I do GEP with a different pointer type than the type of the underlying object?; ----------------------------------------------------------------------------------. Yes. There are no restrictions on bitcasting a pointer value to an arbitrary; pointer type. The types in a GEP serve only to define the parameters for the; underlying integer computation. They need not correspond with the actual type of; the un",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GetElementPtr.rst:14033,perform,performing,14033,interpreter/llvm-project/llvm/docs/GetElementPtr.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GetElementPtr.rst,2,"['load', 'perform']","['load', 'performing']"
Performance," is painted the same way in GL and non-GL mode.; The mismatch was reported in [this post](https://root-forum.cern.ch/t/how-to-specify-the-level-value-in-isosurface-drawing-with-tf3-and-gl/32179). ## Geometry Libraries. ## Database Libraries. The CMake module `FindOracle.cmake` was updated to support version 18.x; of the Oracle client libraries. ## Networking Libraries. ## GUI Libraries. ## Montecarlo Libraries. ## PROOF Libraries. ## Language Bindings. ## JavaScript ROOT. ### New functionality from 5.7.0 release. - Add support of `TProfile2Poly` class; - Add support of `TGeoOverlap` class; - Add support of `TGeoHalfSpace` for composites; - Implement update of `TF2` drawings, see `tutorials/graphics/anim.C`; - Improve windows handling in flex(ible) layout; - Provide special widget for object inspector; - Use `requestAnimationFrame` when do monitoring, improves performance; - Better position for text in `TH2Poly` drawings; - Support eve7 geometry viewer - render data generated in ROOT itself; - Provide initial WebVR support, thanks to Diego Marcos; - Use `gStyle` attributes to draw histogram title; - Enable projections drawing also with `TH2` lego plots; - Many adjustment with new `TWebCanvas` - interactivity, attributes/position updates, context menus; - Upgrade three.js 86 -> 102, use `SoftwareRenderer` instead of `CanvasRenderer`; - Upgrade d3.js 4.4.4 -> 5.7.0; - Fix - support clipping for tracks and points in geo painter; - Fix - drawing of TGeoNode with finder; - Fix - key press events processed only in active pad (ROOT-9128); - Fix - use X0/Y0 in xtru shape, thanks to @altavir. ### New files location. JSROOT sources were moved from `etc/http/` into `js/` subfolder in ROOT sources tree.; OpenUI5 files were moved to `ui5/` subfolder. After ROOT compilation they can be found in; `$ROOTSYS/js/` and `$ROOTSYS/ui5/` subfolders respectively. ## Tutorials; - Add `RSqliteDS` examples.; - Make RCsvDS and RLazyDS tutorials standalone, i.e. downloading input csv directly us",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v618/index.md:20715,perform,performance,20715,README/ReleaseNotes/v618/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v618/index.md,1,['perform'],['performance']
Performance," is the minimum remaining bit storage size of L which is defined as; follows. LS is the location storage and LO is the location bit offset; specified by a single location description SL of L. The remaining bit; storage size RBSS of SL is the bit size of LS minus LO. *rbss(L)* is the; minimum RBSS of each single location description SL of L. The DWARF expression is ill-formed if *rbss(BL)* is less than BO plus BS. If BS is 0, then the operation pushes BL. If BO is 0 and BS equals *rbss(BL)*, then the operation pushes OL. Otherwise, the operation is equivalent to performing the following steps to; push a composite location description. *The composite location description is conceptually the base location; description BL with the overlay location description OL positioned as an; overlay starting at the overlay offset BO and covering overlay bit size BS.*. 1. If BO is not 0 then push BL followed by performing the ``DW_OP_bit_piece; BO, 0`` operation.; 2. Push OL followed by performing the ``DW_OP_bit_piece BS, 0`` operation.; 3. If *rbss(BL)* is greater than BO plus BS, push BL followed by performing; the ``DW_OP_bit_piece (rbss(BL) - BO - BS), (BO + BS)`` operation.; 4. Perform the ``DW_OP_LLVM_piece_end`` operation. .. _amdgpu-dwarf-location-list-expressions:. A.2.5.5 DWARF Location List Expressions; +++++++++++++++++++++++++++++++++++++++. .. note::. This section replaces DWARF Version 5 section 2.6.2. *To meet the needs of recent computer architectures and optimization techniques,; debugging information must be able to describe the location of an object whose; location changes over the object’s lifetime, and may reside at multiple; locations during parts of an object's lifetime. Location list expressions are; used in place of operation expressions whenever the object whose location is; being described has these requirements.*. A location list expression consists of a series of location list entries. Each; location list entry is one of the following kinds:. *Bounded ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:142056,perform,performing,142056,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,1,['perform'],['performing']
Performance," is their defining or optimized; access.; Traditionally ``MemorySSA`` optimized ``MemoryUse``\ s at build-time, up to a; given threshold.; Specifically, the operand of every ``MemoryUse`` was optimized to point to the; actual clobber of said ``MemoryUse``. This can be seen in the above example; the; second ``MemoryUse`` in ``if.end`` has an operand of ``1``, which is a; ``MemoryDef`` from the entry block. This is done to make walking,; value numbering, etc, faster and easier.; As of `this revision <https://reviews.llvm.org/D121381>`_, the default was; changed to not optimize uses at build time, in order to provide the option to; reduce compile-time if the walking is not necessary in a pass. Most users call; the new API ``ensureOptimizedUses()`` to keep the previous behavior and do a; one-time optimization of ``MemoryUse``\ s, if this was not done before.; New pass users are recommended to call ``ensureOptimizedUses()``. Initially it was not possible to optimize ``MemoryDef``\ s in the same way, as we; restricted ``MemorySSA`` to one operand per access.; This was changed and ``MemoryDef``\ s now keep two operands.; The first one, the defining access, is; always the previous ``MemoryDef`` or ``MemoryPhi`` in the same basic block, or; the last one in a dominating predecessor if the current block doesn't have any; other accesses writing to memory. This is needed for walking Def chains.; The second operand is the optimized access, if there was a previous call on the; walker's ``getClobberingMemoryAccess(MA)``. This API will cache information; as part of ``MA``.; Optimizing all ``MemoryDef``\ s has quadratic time complexity and is not done; by default. A walk of the uses for any MemoryDef can find the accesses that were optimized; to it.; A code snippet for such a walk looks like this:. .. code-block:: c++. MemoryDef *Def; // find who's optimized or defining for this MemoryDef; for (auto& U : Def->uses()) {; MemoryAccess *MA = cast<MemoryAccess>(Use.getUser());; if (auto *",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MemorySSA.rst:12016,optimiz,optimize,12016,interpreter/llvm-project/llvm/docs/MemorySSA.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MemorySSA.rst,1,['optimiz'],['optimize']
Performance," is unresponsive with `SIGKILL`).; Defaults to **0 (no timeout)**. dsmgrd.corruptafterfails *n*; : Set this to a number above zero to tell the daemon to mark files as; corrupted after a certain number of either download or verification; failures. A value of **0 (default)** tells the daemon to retry; forever. Configuring the MonALISA monitoring plugin; ------------------------------------------. The Dataset Stager supports generic monitoring plugins. The only plugin; distributed with the stager is the MonALISA monitoring plugin. dsmgrd.notifyplugin */path/to/libafdsmgrd\_notify\_apmon.so*; : Set it to the path of the MonALISA plugin shared object. By default,; notification plugin is disabled. dsmgrd.apmonurl *apmon://apmon.cern.ch*; : This variable tells the ApMon notification plugin how to contact one; or more MonALISA server(s) to activate monitoring via ApMon. It; supports two kinds of URLs:. - `http[s]://host/path/configuration_file.conf` (a remote file; where to fetch the list of servers from). - `apmon://[:password@]monalisahost[:8884]` (a single server to; contact directly). If the variable is not set, yet the plugin is loaded, MonALISA; monitoring is inhibited until a valid configuration variable is; provided. dsmgrd.apmonprefix *MY::CLUSTER::PREFIX*; : Since MonALISA organizes information in ""clusters"" and ""hosts"", here; you can specify what to use as cluster prefix for monitoring; datasets information and daemon status. If this variable is not set,; MonALISA monitoring is inhibited. Please note that the suffix; `_datasets` or `_status` is appended for each of the two types of; monitoring. A sample configuration file; ---------------------------. xpd.stagereqrepo /opt/aaf/var/proof/datasets; dsmgrd.purgenoopds true; dsmgrd.urlregex alien://(.*)$ /storage$1; dsmgrd.sleepsecs 20; dsmgrd.scandseveryloops 30; dsmgrd.parallelxfrs 10; dsmgrd.stagecmd /opt/aaf/bin/af-xrddm-verify.sh ""$URLTOSTAGE"" ""$TREENAME""; dsmgrd.cmdtimeoutsecs 3600; dsmgrd.corruptafterfails 0; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md:5551,load,loaded,5551,proof/doc/confman/DatasetStager.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md,1,['load'],['loaded']
Performance," is unsafe to; optimize or assume that the result of the '``and``' is '``undef``'.; However, it is safe to assume that all bits of the '``undef``' could be; 0, and optimize the '``and``' to 0. Likewise, it is safe to assume that; all the bits of the '``undef``' operand to the '``or``' could be set,; allowing the '``or``' to be folded to -1. .. code-block:: llvm. %A = select undef, %X, %Y; %B = select undef, 42, %Y; %C = select %X, %Y, undef; Safe:; %A = %X (or %Y); %B = 42 (or %Y); %C = %Y (if %Y is provably not poison; unsafe otherwise); Unsafe:; %A = undef; %B = undef; %C = undef. This set of examples shows that undefined '``select``' (and conditional; branch) conditions can go *either way*, but they have to come from one; of the two operands. In the ``%A`` example, if ``%X`` and ``%Y`` were; both known to have a clear low bit, then ``%A`` would have to have a; cleared low bit. However, in the ``%C`` example, the optimizer is; allowed to assume that the '``undef``' operand could be the same as; ``%Y`` if ``%Y`` is provably not '``poison``', allowing the whole '``select``'; to be eliminated. This is because '``poison``' is stronger than '``undef``'. .. code-block:: llvm. %A = xor undef, undef. %B = undef; %C = xor %B, %B. %D = undef; %E = icmp slt %D, 4; %F = icmp gte %D, 4. Safe:; %A = undef; %B = undef; %C = undef; %D = undef; %E = undef; %F = undef. This example points out that two '``undef``' operands are not; necessarily the same. This can be surprising to people (and also matches; C semantics) where they assume that ""``X^X``"" is always zero, even if; ``X`` is undefined. This isn't true for a number of reasons, but the; short answer is that an '``undef``' ""variable"" can arbitrarily change; its value over its ""live range"". This is true because the variable; doesn't actually *have a live range*. Instead, the value is logically; read from arbitrary registers that happen to be around when needed, so; the value is not necessarily consistent over time. In fact, ``%A`",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:193252,optimiz,optimizer,193252,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['optimiz'],['optimizer']
Performance," is; not generic, omit; lgkmcnt(0).; - If OpenCL and; address space is; local, omit; vmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate. If; fence had an; address space then; set to address; space of OpenCL; fence flag, or to; generic if both; local and global; flags are; specified.; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; any following store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Ensures that all; memory operations; have; completed before; performing the; following; fence-paired-atomic. **Acquire-Release Atomic**; ------------------------------------------------------------------------------------; atomicrmw acq_rel - singlethread - global 1. buffer/global/ds/flat_atomic; - wavefront - local; - generic; atomicrmw acq_rel - workgroup - global 1. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to local have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global_atomic. atomicrmw acq_rel - workgroup - local 1. ds_atomic; 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than the local load; atomic value being; acquired. atomicrmw acq_rel - workgroup - g",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:223564,perform,performing,223564,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['perform'],['performing']
Performance," is; not generic, omit; lgkmcnt(0).; - If OpenCL and; address space is; local, omit; vmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate. If; fence had an; address space then; set to address; space of OpenCL; fence flag, or to; generic if both; local and global; flags are; specified.; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; any following store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Ensures that all; memory operations; have; completed before; performing the; following; fence-paired-atomic. **Acquire-Release Atomic**; ------------------------------------------------------------------------------------; atomicrmw acq_rel - singlethread - global 1. buffer/global/flat_atomic; - wavefront - generic; atomicrmw acq_rel - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; be used.*. 1. ds_atomic; atomicrmw acq_rel - workgroup - global 1. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit; lgkmcnt(0).; - Must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures tha",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:266086,perform,performing,266086,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['perform'],['performing']
Performance," is; not generic, omit; lgkmcnt(0).; - If OpenCL and; address space is; local, omit; vmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate. If; fence had an; address space then; set to address; space of OpenCL; fence flag, or to; generic if both; local and global; flags are; specified.; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; any following store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Ensures that all; memory operations; have; completed before; performing the; following; fence-paired-atomic. fence release - system *none* 1. buffer_wbl2 sc0=1 sc1=1. - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at system scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - If OpenCL and; address space is; local, omit; vmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate. If; fence had an; address space then; set to address; space of OpenCL; fence flag, or to; generic if both; local and global; flags are; specified.; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; ato",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:315228,perform,performing,315228,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['perform'],['performing']
Performance," is; not generic, omit; lgkmcnt(0).; - If OpenCL and; address space is; local, omit; vmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate. If; fence had an; address space then; set to address; space of OpenCL; fence flag, or to; generic if both; local and global; flags are; specified.; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; any following store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Ensures that all; memory operations; have; completed before; performing the; following; fence-paired-atomic. fence release - system *none* 1. buffer_wbl2. - If OpenCL and; address space is; local, omit.; - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at system scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - If OpenCL and; address space is; local, omit; vmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate. If; fence had an; address space then; set to address; space of OpenCL; fence flag, or to; generic if both; local and global; flags are; specified.; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:264668,perform,performing,264668,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['perform'],['performing']
Performance," it has loaded the shared; object. The most foolproof way of doing this is to set a breakpoint in; ``PassManager::run`` and then run the process with the arguments you want:. .. code-block:: console. $ (gdb) break llvm::PassManager::run; Breakpoint 1 at 0x2413bc: file Pass.cpp, line 70.; (gdb) run test.bc -load $(LLVMTOP)/llvm/Debug+Asserts/lib/[libname].so -[passoption]; Starting program: opt test.bc -load $(LLVMTOP)/llvm/Debug+Asserts/lib/[libname].so -[passoption]; Breakpoint 1, PassManager::run (this=0xffbef174, M=@0x70b298) at Pass.cpp:70; 70 bool PassManager::run(Module &M) { return PM->run(M); }; (gdb). Once the :program:`opt` stops in the ``PassManager::run`` method you are now; free to set breakpoints in your pass so that you can trace through execution or; do other standard debugging stuff. Miscellaneous Problems; ^^^^^^^^^^^^^^^^^^^^^^. Once you have the basics down, there are a couple of problems that GDB has,; some with solutions, some without. * Inline functions have bogus stack information. In general, GDB does a pretty; good job getting stack traces and stepping through inline functions. When a; pass is dynamically loaded however, it somehow completely loses this; capability. The only solution I know of is to de-inline a function (move it; from the body of a class to a ``.cpp`` file). * Restarting the program breaks breakpoints. After following the information; above, you have succeeded in getting some breakpoints planted in your pass.; Next thing you know, you restart the program (i.e., you type ""``run``"" again),; and you start getting errors about breakpoints being unsettable. The only; way I have found to ""fix"" this problem is to delete the breakpoints that are; already set in your pass, run the program, and re-set the breakpoints once; execution stops in ``PassManager::run``. Hopefully these tips will help with common case debugging situations. If you'd; like to contribute some tips of your own, just contact `Chris; <mailto:sabre@nondot.org>`_.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:54548,load,loaded,54548,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,1,['load'],['loaded']
Performance," it may simply happen that they really represent a; single object, too complex to be described by a primitive shape. Usually handling structures like these can be easily done by positioning; all components in the same container volume, then positioning the; container itself. However, there are many practical cases when defining; such a container is not straightforward or even possible without; generating overlaps with the rest of the geometry. There are few ways; out of this:. - Defining the container for the structure as ""overlapping"" (see also; "" Overlapping Volumes **""**); - Representing the container as a composite shape - the Boolean union; of all components (see also "" Composite Shapes ""); - Using an assembly volume - this will be described in the following. The first two approaches have the disadvantage of penalizing the; navigation performance with a factor increasing more than linear of the; number of components in the structure. The best solution is the third; one because it uses all volume-related navigation optimizations. The; class **`TGeoVolumeAssembly`** represents an assembly volume. Its shape; is represented by **`TGeoShapeAssembly`** class that is the union of all; components. It uses volume voxelization to perform navigation tasks. An assembly volume creates a hierarchical level and it geometrically; insulates the structure from the rest (as a normal volume). Physically,; a point that is INSIDE a **`TGeoShapeAssembly`** is always inside one of; the components, so a **`TGeoVolumeAssembly`** does not need to have a; medium. Due to the self-containment of assemblies, they are very; practical to use when a container is hard to define due to possible; overlaps during positioning. For instance, it is very easy creating; honeycomb structures. A very useful example for creating and using; assemblies can be found at:; <http://root.cern.ch/root/html/examples/assembly.C.html>`.`. Creation of an assembly is very easy: one has just to create a; **`TGeoVolumeAss",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md:89226,optimiz,optimizations,89226,documentation/users-guide/Geometry.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md,1,['optimiz'],['optimizations']
Performance," it must retain the power to decrease the lifetime of an object.; Unfortunately, while it's generally poor style for the destruction; of objects to have arbitrary side-effects, it's certainly possible.; Hence the caveat. .. _arc.optimization.precise:. Precise lifetime semantics; --------------------------. In general, ARC maintains an invariant that a retainable object pointer held in; a ``__strong`` object will be retained for the full formal lifetime of the; object. Objects subject to this invariant have :arc-term:`precise lifetime; semantics`. By default, local variables of automatic storage duration do not have precise; lifetime semantics. Such objects are simply strong references which hold; values of retainable object pointer type, and these values are still fully; subject to the optimizations on values under local control. .. admonition:: Rationale. Applying these precise-lifetime semantics strictly would be prohibitive.; Many useful optimizations that might theoretically decrease the lifetime of; an object would be rendered impossible. Essentially, it promises too much. A local variable of retainable object owner type and automatic storage duration; may be annotated with the ``objc_precise_lifetime`` attribute to indicate that; it should be considered to be an object with precise lifetime semantics. .. admonition:: Rationale. Nonetheless, it is sometimes useful to be able to force an object to be; released at a precise time, even if that object does not appear to be used.; This is likely to be uncommon enough that the syntactic weight of explicitly; requesting these semantics will not be burdensome, and may even make the code; clearer. .. _arc.misc:. Miscellaneous; =============. .. _arc.misc.special_methods:. Special methods; ---------------. .. _arc.misc.special_methods.retain:. Memory management methods; ^^^^^^^^^^^^^^^^^^^^^^^^^. A program is ill-formed if it contains a method definition, message send, or; ``@selector`` expression for any of the followin",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst:84196,optimiz,optimizations,84196,interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,1,['optimiz'],['optimizations']
Performance," iterate over the category states.; - The `HybridCalculatorOriginal` and `HypoTestInverterOriginal` classes in RooStats that were deprecated for a very long time aleady are removed. Please use `HybridCalculator` and `HypoTestInverter`.; - The `RooSimPdfBuilder` that was deprecated in ROOT 5.20 and replaced by the `RooSimWSTool` is removed.; - The RDataFrame factory functions `MakeNumpyDataFrame`, `MakeCsvDataFrame`, `MakeArrowDataFrame`, `MakeNTupleDataFrame` and `MakeSqliteDataFrame` are now deprecated in favor of `FromNumpy`, `FromCSV`, `FromArrow`, `FromRNTuple` and `FromSqlite` respectively. - The build option `alien` has been removed.; - The build options `gfal`, `gsl_shared`, `jemalloc`, `monalisa`, `pyroot_legacy`, `tcmalloc`, and `xproofd` have been deprecated. Please complain with root-dev@cern.ch should you still need one!. ## rootreadspeed. This version adds the new `rootreadspeed` CLI tool. This tool can be used to help identify bottlenecks in analysis runtimes, by providing time and throughput measurements when reading ROOT files via file systems or XRootD. More detailed information can be found in the tool's help information. To see help information, install and source a recent enough version of ROOT, and run the command `rootreadspeed --help` in your terminal. ### Example usage of the tool:. ```console; $ rootreadspeed --files <local-folder>/File1.root xrootd://<url-folder>/File2.root --trees Events --all-branches --threads 8; ```. ## Core Libraries. ### Interpreter. #### Support for profiling/debugging interpreted/JITted code. This version of ROOT adds an LLVM JIT event listener to create perf map files; during runtime. This allows profiling of interpreted/JITted code generated by; cling. Instead of function addresses, the perf data will contain full function; names. In addition, stack frame pointers are enabled in JITted code, so full; stack traces can be generated. Debugging is aided by switching off optimisations; and adding frame pointers for bett",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v628/index.md:4991,bottleneck,bottlenecks,4991,README/ReleaseNotes/v628/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v628/index.md,2,"['bottleneck', 'throughput']","['bottlenecks', 'throughput']"
Performance," its operand %reg1039 is the result of the; PHI node. We should treat it as a two-address code and make sure the ADDri is; scheduled after any node that reads %reg1039. //===---------------------------------------------------------------------===//. Use local info (i.e. register scavenger) to assign it a free register to allow; reuse:; ldr r3, [sp, #+4]; add r3, r3, #3; ldr r2, [sp, #+8]; add r2, r2, #2; ldr r1, [sp, #+4] <==; add r1, r1, #1; ldr r0, [sp, #+4]; add r0, r0, #2. //===---------------------------------------------------------------------===//. LLVM aggressively lift CSE out of loop. Sometimes this can be negative side-; effects:. R1 = X + 4; R2 = X + 7; R3 = X + 15. loop:; load [i + R1]; ...; load [i + R2]; ...; load [i + R3]. Suppose there is high register pressure, R1, R2, R3, can be spilled. We need; to implement proper re-materialization to handle this:. R1 = X + 4; R2 = X + 7; R3 = X + 15. loop:; R1 = X + 4 @ re-materialized; load [i + R1]; ...; R2 = X + 7 @ re-materialized; load [i + R2]; ...; R3 = X + 15 @ re-materialized; load [i + R3]. Furthermore, with re-association, we can enable sharing:. R1 = X + 4; R2 = X + 7; R3 = X + 15. loop:; T = i + X; load [T + 4]; ...; load [T + 7]; ...; load [T + 15]; //===---------------------------------------------------------------------===//. It's not always a good idea to choose rematerialization over spilling. If all; the load / store instructions would be folded then spilling is cheaper because; it won't require new live intervals / registers. See 2003-05-31-LongShifts for; an example. //===---------------------------------------------------------------------===//. With a copying garbage collector, derived pointers must not be retained across; collector safe points; the collector could move the objects and invalidate the; derived pointer. This is bad enough in the first place, but safe points can; crop up unpredictably. Consider:. %array = load { i32, [0 x %obj] }** %array_addr; %nth_el = getelementptr { i",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/README.txt:2061,load,load,2061,interpreter/llvm-project/llvm/lib/CodeGen/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/README.txt,1,['load'],['load']
Performance," keep the state as small as possible.; When file pointers ""escape"" (are used in a way that the analyzer can no longer; track them), mark them as such. This prevents false positives in the cases where; the analyzer cannot be sure whether the file was closed or not. These events that will be used for each of these actions are, respectively, PreCall,; PostCall,; DeadSymbols,; and PointerEscape.; The high-level structure of the checker's class is thus:. class SimpleStreamChecker : public Checker<check::PreCall,; check::PostCall,; check::DeadSymbols,; check::PointerEscape> {; public:. void checkPreCall(const CallEvent &Call, CheckerContext &C) const;. void checkPostCall(const CallEvent &Call, CheckerContext &C) const;. void checkDeadSymbols(SymbolReaper &SR, CheckerContext &C) const;. ProgramStateRef checkPointerEscape(ProgramStateRef State,; const InvalidatedSymbols &Escaped,; const CallEvent *Call,; PointerEscapeKind Kind) const;; };. Custom Program States; Checkers often need to keep track of information specific to the checks they; perform. However, since checkers have no guarantee about the order in which the; program will be explored, or even that all possible paths will be explored, this; state information cannot be kept within individual checkers. Therefore, if; checkers need to store custom information, they need to add new categories of; data to the ProgramState. The preferred way to do so is to use one of; several macros designed for this purpose. They are:. REGISTER_TRAIT_WITH_PROGRAMSTATE:; Used when the state information is a single value. The methods available for; state types declared with this macro are get, set, and; remove.; REGISTER_LIST_WITH_PROGRAMSTATE:; Used when the state information is a list of values. The methods available for; state types declared with this macro are add, get,; remove, and contains.; REGISTER_SET_WITH_PROGRAMSTATE:; Used when the state information is a set of values. The methods available for; state types declared with this m",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/checker_dev_manual.html:12122,perform,perform,12122,interpreter/llvm-project/clang/www/analyzer/checker_dev_manual.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/checker_dev_manual.html,2,['perform'],['perform']
Performance," known retain-agnostic. An expression is :arc-term:`known retain-agnostic` if it is:. * an Objective-C string literal,; * a load from a ``const`` system global variable of :ref:`C retainable pointer; type <arc.misc.c-retainable>`, or; * a null pointer constant. An expression is :arc-term:`known unretained` if it is an rvalue of :ref:`C; retainable pointer type <arc.misc.c-retainable>` and it is:. * a direct call to a function, and either that function has the; ``cf_returns_not_retained`` attribute or it is an :ref:`audited; <arc.misc.c-retainable.audit>` function that does not have the; ``cf_returns_retained`` attribute and does not follow the create/copy naming; convention,; * a message send, and the declared method either has the; ``cf_returns_not_retained`` attribute or it has neither the; ``cf_returns_retained`` attribute nor a :ref:`selector family; <arc.method-families>` that implies a retained result, or; * :when-revised:`[beginning LLVM 3.6]` :revision:`a load from a` ``const``; :revision:`non-system global variable.`. An expression is :arc-term:`known retained` if it is an rvalue of :ref:`C; retainable pointer type <arc.misc.c-retainable>` and it is:. * a message send, and the declared method either has the; ``cf_returns_retained`` attribute, or it does not have the; ``cf_returns_not_retained`` attribute but it does have a :ref:`selector; family <arc.method-families>` that implies a retained result. Furthermore:. * a comma expression is classified according to its right-hand side,; * a statement expression is classified according to its result expression, if; it has one,; * an lvalue-to-rvalue conversion applied to an Objective-C property lvalue is; classified according to the underlying message send, and; * a conditional operator is classified according to its second and third; operands, if they agree in classification, or else the other if one is known; retain-agnostic. If the cast operand is known retained, the conversion is treated as a; ``__bridge_trans",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst:26987,load,load,26987,interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,1,['load'],['load']
Performance," lanes. %masked.a = select <4 x i1> %mask, <4 x i8> %a, <4 x i8> <i8 127, i8 127, i8 127, i8 127>; %reduction = call i8 @llvm.vector.reduce.smin.v4i8(<4 x i8> %masked.a); %also.r = call i8 @llvm.smin.i8(i8 %reduction, i8 %start). .. _int_vp_reduce_umax:. '``llvm.vp.reduce.umax.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare i32 @llvm.vp.reduce.umax.v4i32(i32 <start_value>, <4 x i32> <val>, <4 x i1> <mask>, i32 <vector_length>); declare i16 @llvm.vp.reduce.umax.nxv8i16(i16 <start_value>, <vscale x 8 x i16> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated unsigned-integer ``MAX`` reduction of a vector and a scalar starting; value, returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value of the reduction, which must be a scalar; integer type equal to the result type. The second operand is the vector on; which the reduction is performed and must be a vector of integer values whose; element type is the result/start type. The third operand is the vector mask and; is a vector of boolean values with the same number of elements as the vector; operand. The fourth operand is the explicit vector length of the operation. Semantics:; """""""""""""""""""". The '``llvm.vp.reduce.umax``' intrinsic performs the unsigned-integer ``MAX``; reduction (:ref:`llvm.vector.reduce.umax <int_vector_reduce_umax>`) of the; vector operand ``val`` on each enabled lane, and taking the maximum of that and; the scalar ``start_value``. Disabled lanes are treated as containing the; neutral value ``0`` (i.e. having no effect on the reduction operation). If the; vector length is zero, the result is the start value. To ignore the start value, the neutral value can be used. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call i32 @llvm.vp.reduce.umax.v4i32(i32 %start, <4 x i32> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:767584,perform,performed,767584,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['performed']
Performance," language which; supports garbage collection. **Note that LLVM itself does not provide a; garbage collector.** You must provide your own. Quick Start; ============. First, you should pick a collector strategy. LLVM includes a number of built; in ones, but you can also implement a loadable plugin with a custom definition.; Note that the collector strategy is a description of how LLVM should generate; code such that it interacts with your collector and runtime, not a description; of the collector itself. Next, mark your generated functions as using your chosen collector strategy.; From c++, you can call:. .. code-block:: c++. F.setGC(<collector description name>);. This will produce IR like the following fragment:. .. code-block:: llvm. define void @foo() gc ""<collector description name>"" { ... }. When generating LLVM IR for your functions, you will need to:. * Use ``@llvm.gcread`` and/or ``@llvm.gcwrite`` in place of standard load and; store instructions. These intrinsics are used to represent load and store; barriers. If you collector does not require such barriers, you can skip; this step. * Use the memory allocation routines provided by your garbage collector's; runtime library. * If your collector requires them, generate type maps according to your; runtime's binary interface. LLVM is not involved in the process. In; particular, the LLVM type system is not suitable for conveying such; information though the compiler. * Insert any coordination code required for interacting with your collector.; Many collectors require running application code to periodically check a; flag and conditionally call a runtime function. This is often referred to; as a safepoint poll. You will need to identify roots (i.e. references to heap objects your collector; needs to know about) in your generated IR, so that LLVM can encode them into; your final stack maps. Depending on the collector strategy chosen, this is; accomplished by using either the ``@llvm.gcroot`` intrinsics or an; ``gc.s",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst:1224,load,load,1224,interpreter/llvm-project/llvm/docs/GarbageCollection.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst,1,['load'],['load']
Performance," language with; LLVM <index.html>`_"" tutorial. In chapters 1 through 6, we've built a; very respectable, albeit simple, `functional programming; language <http://en.wikipedia.org/wiki/Functional_programming>`_. In our; journey, we learned some parsing techniques, how to build and represent; an AST, how to build LLVM IR, and how to optimize the resultant code as; well as JIT compile it. While Kaleidoscope is interesting as a functional language, the fact; that it is functional makes it ""too easy"" to generate LLVM IR for it. In; particular, a functional language makes it very easy to build LLVM IR; directly in `SSA; form <http://en.wikipedia.org/wiki/Static_single_assignment_form>`_.; Since LLVM requires that the input code be in SSA form, this is a very; nice property and it is often unclear to newcomers how to generate code; for an imperative language with mutable variables. The short (and happy) summary of this chapter is that there is no need; for your front-end to build SSA form: LLVM provides highly tuned and; well tested support for this, though the way it works is a bit; unexpected for some. Why is this a hard problem?; ===========================. To understand why mutable variables cause complexities in SSA; construction, consider this extremely simple C example:. .. code-block:: c. int G, H;; int test(_Bool Condition) {; int X;; if (Condition); X = G;; else; X = H;; return X;; }. In this case, we have the variable ""X"", whose value depends on the path; executed in the program. Because there are two different possible values; for X before the return instruction, a PHI node is inserted to merge the; two values. The LLVM IR that we want for this example looks like this:. .. code-block:: llvm. @G = weak global i32 0 ; type of @G is i32*; @H = weak global i32 0 ; type of @H is i32*. define i32 @test(i1 %Condition) {; entry:; br i1 %Condition, label %cond_true, label %cond_false. cond_true:; %X.0 = load i32, i32* @G; br label %cond_next. cond_false:; %X.1 = load i3",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl07.rst:1306,tune,tuned,1306,interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl07.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl07.rst,1,['tune'],['tuned']
Performance," last Python; reference to the proxy disappears.; You can check/change the ownership with the __python_owns__ flag that every; bound instance carries.; Example:. .. code-block:: python. >>> from cppyy.gbl import Concrete; >>> c = Concrete(); >>> c.__python_owns__ # True: object created in Python; True; >>>. * ``__creates__``: a flag that every C++ overload carries and determines; whether the return value is owned by C++ or Python: if ``True``, Python owns; the return value, otherwise C++. * ``__set_lifeline__``: a flag that every C++ overload carries and determines; whether the return value should place a back-reference on ``self``, to; prevent the latter from going out of scope before the return value does.; The default is ``False``, but will be automatically set at run-time if a; return value's address is a C++ object pointing into the memory of ``this``,; or if ``self`` is a by-value return. * ``__release_gil__``: a flag that every C++ overload carries and determines; whether the Global Interpreter Lock (GIL) should be released during the C++; call to allow multi-threading.; The default is ``False``. * ``__useffi__``: a flag that every C++ overload carries and determines; whether generated wrappers or direct foreign functions should be used.; This is for PyPy only; the flag has no effect on CPython. * ``__sig2exc__``: a flag that every C++ overload carries and determines; whether C++ signals (such as SIGABRT) should be converted into Python; exceptions. * ``__cpp_name__``: a string that every C++ bound class carries and contains; the actual C++ name (as opposed to ``__name__`` which has the Python name).; This can be useful for template instantiations, documentation, etc. * ``__cpp_template__``: a back-reference to the template used to instantiate; a templated class.; This variable only exists if the class was dynamically instantiated from; Python at least once. `STL algorithms`; ----------------. It is usually easier to use a Python equivalent or code up the eff",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/misc.rst:2095,multi-thread,multi-threading,2095,bindings/pyroot/cppyy/cppyy/doc/source/misc.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/misc.rst,1,['multi-thread'],['multi-threading']
Performance," latency (which; usually matches the load-to-use latency for when there is a hit in the L1D). :program:`llvm-mca` does not (on its own) know about serializing operations or; memory-barrier like instructions. The LSUnit used to conservatively use an; instruction's ""MayLoad"", ""MayStore"", and unmodeled side effects flags to; determine whether an instruction should be treated as a memory-barrier. This was; inaccurate in general and was changed so that now each instruction has an; IsAStoreBarrier and IsALoadBarrier flag. These flags are mca specific and; default to false for every instruction. If any instruction should have either of; these flags set, it should be done within the target's InstrPostProcess class.; For an example, look at the `X86InstrPostProcess::postProcessInstruction` method; within `llvm/lib/Target/X86/MCA/X86CustomBehaviour.cpp`. A load/store barrier consumes one entry of the load/store queue. A load/store; barrier enforces ordering of loads/stores. A younger load cannot pass a load; barrier. Also, a younger store cannot pass a store barrier. A younger load; has to wait for the memory/load barrier to execute. A load/store barrier is; ""executed"" when it becomes the oldest entry in the load/store queue(s). That; also means, by construction, all of the older loads/stores have been executed. In conclusion, the full set of load/store consistency rules are:. #. A store may not pass a previous store.; #. A store may not pass a previous load (regardless of ``-noalias``).; #. A store has to wait until an older store barrier is fully executed.; #. A load may pass a previous load.; #. A load may not pass a previous store unless ``-noalias`` is set.; #. A load has to wait until an older load barrier is fully executed. In-order Issue and Execute; """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; In-order processors are modelled as a single ``InOrderIssueStage`` stage. It; bypasses Dispatch, Scheduler and Load/Store unit. Instructions are issued as; soon as their operand regis",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:42362,load,load,42362,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,2,['load'],['load']
Performance," level:""),; cl::values(; clEnumVal(g , ""No optimizations, enable debugging""),; clEnumVal(O1, ""Enable trivial optimizations""),; clEnumVal(O2, ""Enable default optimizations""),; clEnumVal(O3, ""Enable expensive optimizations"")));. ...; if (OptimizationLevel >= O2) doPartialRedundancyElimination(...);; ... This declaration defines a variable ""``OptimizationLevel``"" of the; ""``OptLevel``"" enum type. This variable can be assigned any of the values that; are listed in the declaration. The CommandLine library enforces that; the user can only specify one of the options, and it ensure that only valid enum; values can be specified. The ""``clEnumVal``"" macros ensure that the command; line arguments matched the enum values. With this option added, our help output; now is:. ::. USAGE: compiler [options] <input file>. OPTIONS:; Choose optimization level:; -g - No optimizations, enable debugging; -O1 - Enable trivial optimizations; -O2 - Enable default optimizations; -O3 - Enable expensive optimizations; -f - Enable binary output on terminals; -help - display available options (-help-hidden for more); -o <filename> - Specify output filename; -quiet - Don't print informational messages. In this case, it is sort of awkward that flag names correspond directly to enum; names, because we probably don't want an enum definition named ""``g``"" in our; program. Because of this, we can alternatively write this example like this:. .. code-block:: c++. enum OptLevel {; Debug, O1, O2, O3; };. cl::opt<OptLevel> OptimizationLevel(cl::desc(""Choose optimization level:""),; cl::values(; clEnumValN(Debug, ""g"", ""No optimizations, enable debugging""),; clEnumVal(O1 , ""Enable trivial optimizations""),; clEnumVal(O2 , ""Enable default optimizations""),; clEnumVal(O3 , ""Enable expensive optimizations"")));. ...; if (OptimizationLevel == Debug) outputDebugInfo(...);; ... By using the ""``clEnumValN``"" macro instead of ""``clEnumVal``"", we can directly; specify the name that the flag should get. In general a direct m",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:15571,optimiz,optimization,15571,interpreter/llvm-project/llvm/docs/CommandLine.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst,5,['optimiz'],"['optimization', 'optimizations']"
Performance," lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures that the; preceding; global/local/generic; load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; acquire-fence-paired-atomic); has completed; before invalidating; the cache. This; satisfies the; requirements of; acquire.; - Ensures that all; previous memory; operations have; completed before a; following; global/local/generic; store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; release-fence-paired-atomic).; This satisfies the; requirements of; release. 3. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. **Sequential Consistent Atomic**; ------------------------------------------------------------------------------------; load atomic seq_cst - singlethread - global *Same as corresponding; - wavefront - local load atomic acquire,; - generic except must generate; all instructions even; for OpenCL.*; load atomic seq_cst - workgroup - global 1. s_waitcnt lgkm/vmcnt(0); - generic; - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - s_waitcnt lgkmcnt(0) must; happen after; preceding; local/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; lgkmcnt(0) and so do; not need to be; considered.); - s_waitcnt vmcnt(0); must happen after; preceding; global/generic load; atomic/store; atomic/atomicrmw; with me",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:279599,load,loads,279599,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['loads']
Performance," lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to memory and the L2; writeback have; completed before; performing the; store that is being; released. 3. buffer/global/flat_atomic; sc0=1 sc1=1; fence release - singlethread *none* *none*; - wavefront; fence release - workgroup *none* 1. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - If OpenCL and; address space is; local, omit; vmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate. If; fence had an; address space then; set to address; space of OpenCL; fence flag, or to; generic if both; local and global; flags are; specified.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Must happen before; any following store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Ensures that all; memory operations; have; completed before; performing the; following; fence-paired-atomic. fence release - agent *none* 1. buffer_wbl2 sc1=1. - If OpenCL and; address space is; local, omit.; - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at agent scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - If OpenCL and; address space is; local, omit; vmcnt(0).; - However, since LLVM; currently has no; address spac",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:313380,load,load,313380,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],['load']
Performance, libc/include/llvm-libc-types/imaxdiv_t.h; libc/include/llvm-libc-types/jmp_buf.h; libc/include/llvm-libc-types/ldiv_t.h; libc/include/llvm-libc-types/lldiv_t.h; libc/include/llvm-libc-types/mode_t.h; libc/include/llvm-libc-types/mtx_t.h; libc/include/llvm-libc-types/off_t.h; libc/include/llvm-libc-types/once_flag.h; libc/include/llvm-libc-types/size_t.h; libc/include/llvm-libc-types/ssize_t.h; libc/include/llvm-libc-types/struct_sigaction.h; libc/include/llvm-libc-types/struct_tm.h; libc/include/llvm-libc-types/thrd_start_t.h; libc/include/llvm-libc-types/thrd_t.h; libc/include/llvm-libc-types/time_t.h; libc/include/llvm-libc-types/__atexithandler_t.h; libc/include/llvm-libc-types/__bsearchcompare_t.h; libc/include/llvm-libc-types/__call_once_func_t.h; libc/include/llvm-libc-types/__futex_word.h; libc/include/llvm-libc-types/__mutex_type.h; libc/include/llvm-libc-types/__qsortcompare_t.h; libc/include/llvm-libc-types/__sighandler_t.h; libc/loader/linux/aarch64/start.cpp; libc/loader/linux/x86_64/start.cpp; libc/src/assert/__assert_fail.h; libc/src/ctype/isalnum.cpp; libc/src/ctype/isalnum.h; libc/src/ctype/isalpha.cpp; libc/src/ctype/isalpha.h; libc/src/ctype/isascii.cpp; libc/src/ctype/isascii.h; libc/src/ctype/isblank.cpp; libc/src/ctype/isblank.h; libc/src/ctype/iscntrl.cpp; libc/src/ctype/iscntrl.h; libc/src/ctype/isdigit.cpp; libc/src/ctype/isdigit.h; libc/src/ctype/isgraph.cpp; libc/src/ctype/isgraph.h; libc/src/ctype/islower.cpp; libc/src/ctype/islower.h; libc/src/ctype/isprint.cpp; libc/src/ctype/isprint.h; libc/src/ctype/ispunct.cpp; libc/src/ctype/ispunct.h; libc/src/ctype/isspace.cpp; libc/src/ctype/isspace.h; libc/src/ctype/isupper.cpp; libc/src/ctype/isupper.h; libc/src/ctype/isxdigit.cpp; libc/src/ctype/isxdigit.h; libc/src/ctype/toascii.cpp; libc/src/ctype/toascii.h; libc/src/ctype/tolower.cpp; libc/src/ctype/tolower.h; libc/src/ctype/toupper.cpp; libc/src/ctype/toupper.h; libc/src/errno/dummy_errno.cpp; libc/src/errno/dummy_errno.h; libc/src/errno/e,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt:132281,load,loader,132281,interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,1,['load'],['loader']
Performance," limiting the transformation of; releases, this rule requires ARC to eliminate retains and release; only in pairs. ARC's power to reorder the destruction of objects is critical to its; ability to do any optimization, for essentially the same reason that; it must retain the power to decrease the lifetime of an object.; Unfortunately, while it's generally poor style for the destruction; of objects to have arbitrary side-effects, it's certainly possible.; Hence the caveat. .. _arc.optimization.precise:. Precise lifetime semantics; --------------------------. In general, ARC maintains an invariant that a retainable object pointer held in; a ``__strong`` object will be retained for the full formal lifetime of the; object. Objects subject to this invariant have :arc-term:`precise lifetime; semantics`. By default, local variables of automatic storage duration do not have precise; lifetime semantics. Such objects are simply strong references which hold; values of retainable object pointer type, and these values are still fully; subject to the optimizations on values under local control. .. admonition:: Rationale. Applying these precise-lifetime semantics strictly would be prohibitive.; Many useful optimizations that might theoretically decrease the lifetime of; an object would be rendered impossible. Essentially, it promises too much. A local variable of retainable object owner type and automatic storage duration; may be annotated with the ``objc_precise_lifetime`` attribute to indicate that; it should be considered to be an object with precise lifetime semantics. .. admonition:: Rationale. Nonetheless, it is sometimes useful to be able to force an object to be; released at a precise time, even if that object does not appear to be used.; This is likely to be uncommon enough that the syntactic weight of explicitly; requesting these semantics will not be burdensome, and may even make the code; clearer. .. _arc.misc:. Miscellaneous; =============. .. _arc.misc.special_methods:",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst:84038,optimiz,optimizations,84038,interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,1,['optimiz'],['optimizations']
Performance," linker, and unused information; is automatically removed. Basically, the debug information allows you to compile a program with; ""``-O0 -g``"" and get full debug information, allowing you to arbitrarily modify; the program as it executes from a debugger. Compiling a program with; ""``-O3 -g``"" gives you full debug information that is always available and; accurate for reading (e.g., you get accurate stack traces despite tail call; elimination and inlining), but you might lose the ability to modify the program; and call functions which were optimized out of the program, or inlined away; completely. The :doc:`LLVM test-suite <TestSuiteMakefileGuide>` provides a framework to; test the optimizer's handling of debugging information. It can be run like; this:. .. code-block:: bash. % cd llvm/projects/test-suite/MultiSource/Benchmarks # or some other level; % make TEST=dbgopt. This will test impact of debugging information on optimization passes. If; debugging information influences optimization passes then it will be reported; as a failure. See :doc:`TestingGuide` for more information on LLVM test; infrastructure and how to run various tests. .. _format:. Debugging information format; ============================. LLVM debugging information has been carefully designed to make it possible for; the optimizer to optimize the program and debugging information without; necessarily having to know anything about debugging information. In; particular, the use of metadata avoids duplicated debugging information from; the beginning, and the global dead code elimination pass automatically deletes; debugging information for a function if it decides to delete the function. To do this, most of the debugging information (descriptors for types,; variables, functions, source files, etc) is inserted by the language front-end; in the form of LLVM metadata. Debug information is designed to be agnostic about the target debugger and; debugging information representation (e.g. DWARF/Stabs/etc). I",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:6064,optimiz,optimization,6064,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,1,['optimiz'],['optimization']
Performance," load atomic acquire - workgroup - global 1. buffer/global_load; load atomic acquire - workgroup - local 1. ds/flat_load; - generic 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic value being; acquired. load atomic acquire - agent - global 1. buffer/global_load; - system glc=1; 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the load; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale global data. load atomic acquire - agent - generic 1. flat_load glc=1; - system 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If OpenCL omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the flat_load; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - singlethread - global 1. buffer/global/ds/flat_atomic; - wavefront - local; - generic; atomicrmw acquire - workgroup - global 1. buffer/global_atomic; atomicrmw acquire - workgroup - local 1. ds/flat_atomic; - generic 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local; atomicrmw value; being acquired. atomicrmw acquire - agent - global 1. buffer/global_atomic; - system 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/lo",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:215230,cache,cache,215230,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['cache'],['cache']
Performance," load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - singlethread - global 1. buffer/global/ds/flat_atomic; - wavefront - local; - generic; atomicrmw acquire - workgroup - global 1. buffer/global_atomic; 2. s_waitcnt vm/vscnt(0). - If CU wavefront execution; mode, omit.; - Use vmcnt(0) if atomic with; return and vscnt(0) if; atomic with no-return.; - Must happen before; the following buffer_gl0_inv; and before any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw. 3. buffer_gl0_inv. - If CU wavefront execution; mode, omit.; - Ensures that; following; loads will not see; stale data. atomicrmw acquire - workgroup - local 1. ds_atomic; 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; the following; buffer_gl0_inv.; - Ensures any; following global; data read is no; older than the local; atomicrmw value; being acquired. 3. buffer_gl0_inv. - If OpenCL omit.; - Ensures that; following; loads will not see; stale data. atomicrmw acquire - workgroup - generic 1. flat_atomic; 2. s_waitcnt lgkmcnt(0) &; vm/vscnt(0). - If CU wavefront execution; mode, omit vm/vscnt(0).; - If OpenCL, omit lgkmcnt(0).; - Use vmcnt(0) if atomic with; return and vscnt(0) if; atomic with no-return.; - Must happen before; the following; buffer_gl0_inv.; - Ensures any; following global; data read is no; older than a local; atomicrmw value; being acquired. 3. buffer_gl0_inv. - If CU wavefront execution; mode, omit.; - Ensures that; following; loads will not see; stale data. atomicrmw acquire - agent - global 1. buffer/global_atomic; - system 2. s_waitcnt vm/vscnt(0). - Use vmcnt(0) if atomic with; return and vscnt(0) if; atomic with no-return.; - Must happen before; following; buffer_gl*_inv.; - Ensures the; atomicrmw has; completed before; invalidating the; caches. 3. buffer_gl0_inv;; buffer_gl1_inv. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that;",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:349543,load,loads,349543,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['loads']
Performance," load/store has this alignment, or; it is undefined behavior’. This means that the back end is free to emit; instructions that rely on that alignment (and mid-level optimizers are free to; perform transforms that require that alignment). For x86, it doesn’t make; much difference, as almost all instructions are alignment-independent. For; MIPS, it can make a big difference. Note that if your loads and stores are atomic, the backend will be unable to; lower an under aligned access into a sequence of natively aligned accesses.; As a result, alignment is mandatory for atomic loads and stores. Other Things to Consider; ^^^^^^^^^^^^^^^^^^^^^^^^. #. Use ptrtoint/inttoptr sparingly (they interfere with pointer aliasing; analysis), prefer GEPs. #. Prefer globals over inttoptr of a constant address - this gives you; dereferencability information. In MCJIT, use getSymbolAddress to provide; actual address. #. Be wary of ordered and atomic memory operations. They are hard to optimize; and may not be well optimized by the current optimizer. Depending on your; source language, you may consider using fences instead. #. If calling a function which is known to throw an exception (unwind), use; an invoke with a normal destination which contains an unreachable; instruction. This form conveys to the optimizer that the call returns; abnormally. For an invoke which neither returns normally or requires unwind; code in the current function, you can use a noreturn call instruction if; desired. This is generally not required because the optimizer will convert; an invoke with an unreachable unwind destination to a call instruction. #. Use profile metadata to indicate statically known cold paths, even if; dynamic profiling information is not available. This can make a large; difference in code placement and thus the performance of tight loops. #. When generating code for loops, try to avoid terminating the header block of; the loop earlier than necessary. If the terminator of the loop header; bl",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:6357,optimiz,optimize,6357,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,3,['optimiz'],"['optimize', 'optimized', 'optimizer']"
Performance," load; atomic value being; acquired. load atomic acquire - workgroup - generic 1. flat_load sc0=1; 2. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit lgkmcnt(0).; - Must happen before; the following; buffer_inv and any; following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic value being; acquired. 3. buffer_inv sc0=1. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. load atomic acquire - agent - global 1. buffer/global_load; sc1=1; 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_inv.; - Ensures the load; has completed; before invalidating; the cache. 3. buffer_inv sc1=1. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale global data. load atomic acquire - system - global 1. buffer/global/flat_load; sc0=1 sc1=1; 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_inv.; - Ensures the load; has completed; before invalidating; the cache. 3. buffer_inv sc0=1 sc1=1. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale MTYPE NC global data.; MTYPE RW and CC memory will; never be stale due to the; memory probes. load atomic acquire - agent - generic 1. flat_load sc1=1; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL omit; lgkmcnt(0).; - Must happen before; following; buffer_inv.; - Ensures the flat_load; has completed; before invalidating; the cache. 3. buffer_inv sc1=1. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. load atomic acquire - system - generic 1. flat_load sc0=1 sc1=1; 2. s_waitcnt vmcnt(0)",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:297381,load,load,297381,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['load']
Performance," loads from before an Acquire; operation to after it. Notes for code generation; Architectures with weak memory ordering (essentially everything relevant today; except x86 and SPARC) require some sort of fence to maintain the Acquire; semantics. The precise fences required varies widely by architecture, but for; a simple implementation, most architectures provide a barrier which is strong; enough for everything (``dmb`` on ARM, ``sync`` on PowerPC, etc.). Putting; such a fence after the equivalent Monotonic operation is sufficient to; maintain Acquire semantics for a memory operation. Release; -------. Release is similar to Acquire, but with a barrier of the sort necessary to; release a lock. Relevant standard; This corresponds to the C++/C ``memory_order_release``. Notes for frontends; If you are writing a frontend which uses this directly, use with caution.; Release only provides a semantic guarantee when paired with an Acquire; operation. Notes for optimizers; Optimizers not aware of atomics can treat this like a nothrow call. It is; also possible to move loads from after a Release store or read-modify-write; operation to before it, and move non-Release stores from after a Release; operation to before it. Notes for code generation; See the section on Acquire; a fence before the relevant operation is usually; sufficient for Release. Note that a store-store fence is not sufficient to; implement Release semantics; store-store fences are generally not exposed to; IR because they are extremely difficult to use correctly. AcquireRelease; --------------. AcquireRelease (``acq_rel`` in IR) provides both an Acquire and a Release; barrier (for fences and operations which both read and write memory). Relevant standard; This corresponds to the C++/C ``memory_order_acq_rel``. Notes for frontends; If you are writing a frontend which uses this directly, use with caution.; Acquire only provides a semantic guarantee when paired with a Release; operation, and vice versa. Notes for",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Atomics.rst:13089,optimiz,optimizers,13089,interpreter/llvm-project/llvm/docs/Atomics.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Atomics.rst,1,['optimiz'],['optimizers']
Performance," local load; atomic value being; acquired. 3. buffer_inv sc0=1. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. atomicrmw acq_rel - agent - global 1. buffer_wbl2 sc1=1. - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at agent scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global have; completed before; performing the; atomicrmw that is; being released. 3. buffer/global_atomic; 4. s_waitcnt vmcnt(0). - Must happen before; following; buffer_inv.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 5. buffer_inv sc1=1. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acq_rel - system - global 1. buffer_wbl2 sc0=1 sc1=1. - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at system scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:320379,perform,performing,320379,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['perform'],['performing']
Performance," local load; atomic value being; acquired. atomicrmw acq_rel - workgroup - generic 1. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to local have; completed before; performing the; atomicrmw that is; being released. 2. flat_atomic; 3. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic value being; acquired. atomicrmw acq_rel - agent - global 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global_atomic; 3. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 4. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acq_rel - agent - generic 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:225492,load,load,225492,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],['load']
Performance," local/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that all; memory operations; have; completed before; performing any; following global; memory operations.; - Ensures that the; preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; acquire-fence-paired-atomic); has completed; before following; global memory; operations. This; satisfies the; requirements of; acquire.; - Ensures that all; previous memory; operations have; completed before a; following; local/generic store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; release-fence-paired-atomic).; This satisfies the; requirements of; release.; - Must happen before; the following; buffer_inv.; - Ensures that the; acquire-fence-paired; atomic has completed; before invalidating; the; cache. Therefore; any following; locations read must; be no older than; the value read by; the; acquire-fence-paired-atomic. 3. buffer_inv sc0=1. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. fence acq_rel - agent *none* 1. buffer_wbl2 sc1=1. - If OpenCL and; address space is; local, omit.; - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at agent scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate; (see comment for; previous fence).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:326596,cache,cache,326596,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['cache'],['cache']
Performance," lowering function, using; templated functions. For example:. // lib/Target/Mips/MipsISelLowering.cpp; SDValue MipsTargetLowering::; lowerJumpTable(SDValue Op, SelectionDAG &DAG) const. calls. template <class NodeTy> // lib/Target/Mips/MipsISelLowering.h; SDValue getAddrLocal(NodeTy *N, const SDLoc &DL, EVT Ty,; SelectionDAG &DAG, bool IsN32OrN64) const. which calls the overloaded function:. // lib/Target/Mips/MipsISelLowering.h; SDValue getTargetNode(JumpTableSDNode *N, EVT Ty, SelectionDAG &DAG,; unsigned Flag) const;. 2. Generic address nodes are lowered to some combination of target; independent and machine specific SDNodes (for example:; MipsISD::{Highest, Higher, Hi, Lo}) depending upon relocation model,; ABI, and compilation options. The choice of specific instructions that are to be used is delegated; to ISel which in turn relies on TableGen patterns to choose subtarget; specific instructions. For example, in getAddrLocal, the pseudo-code; generated is:. (add (load (wrapper $gp, %got(sym)), %lo(sym)). where ""%lo"" represents an instance of an SDNode with opcode; ""MipsISD::Lo"", ""wrapper"" indicates one with opcode ""MipsISD::Wrapper"",; and ""%got"" the global table pointer ""getGlobalReg(...)"". The ""add"" is; ""ISD::ADD"", not a target dependent one. 3. A TableGen multiclass pattern ""MipsHiLoRelocs"" is used to define a; template pattern parameterized over the load upper immediate; instruction, add operation, the zero register, and register class.; Here the instantiation of MipsHiLoRelocs in MipsInstrInfo.td is used; to MIPS32 to compute addresses for the static relocation model. // lib/Target/Mips/MipsInstrInfo.td; multiclass MipsHiLoRelocs<Instruction Lui, Instruction Addiu,; Register ZeroReg, RegisterOperand GPROpnd> {; def : MipsPat<(MipsHi tglobaladdr:$in), (Lui tglobaladdr:$in)>;; ...; def : MipsPat<(MipsLo tglobaladdr:$in), (Addiu ZeroReg, tglobaladdr:$in)>;; ...; def : MipsPat<(add GPROpnd:$hi, (MipsLo tglobaladdr:$lo)),; (Addiu GPROpnd:$hi, tglobaladdr:$lo)>;;",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Mips/Relocation.txt:1530,load,load,1530,interpreter/llvm-project/llvm/lib/Target/Mips/Relocation.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Mips/Relocation.txt,2,['load'],['load']
Performance," mask; 4. lvsl slot + x; vperm to rotate result into correct slot; 5. vsel result together. //===----------------------------------------------------------------------===//. Should codegen branches on vec_any/vec_all to avoid mfcr. Two examples:. #include <altivec.h>; int f(vector float a, vector float b); {; int aa = 0;; if (vec_all_ge(a, b)); aa |= 0x1;; if (vec_any_ge(a,b)); aa |= 0x2;; return aa;; }. vector float f(vector float a, vector float b) { ; if (vec_any_eq(a, b)) ; return a; ; else ; return b; ; }. //===----------------------------------------------------------------------===//. We should do a little better with eliminating dead stores.; The stores to the stack are dead since %a and %b are not needed. ; Function Attrs: nounwind; define <16 x i8> @test_vpmsumb() #0 {; entry:; %a = alloca <16 x i8>, align 16; %b = alloca <16 x i8>, align 16; store <16 x i8> <i8 1, i8 2, i8 3, i8 4, i8 5, i8 6, i8 7, i8 8, i8 9, i8 10, i8 11, i8 12, i8 13, i8 14, i8 15, i8 16>, <16 x i8>* %a, align 16; store <16 x i8> <i8 113, i8 114, i8 115, i8 116, i8 117, i8 118, i8 119, i8 120, i8 121, i8 122, i8 123, i8 124, i8 125, i8 126, i8 127, i8 112>, <16 x i8>* %b, align 16; %0 = load <16 x i8>* %a, align 16; %1 = load <16 x i8>* %b, align 16; %2 = call <16 x i8> @llvm.ppc.altivec.crypto.vpmsumb(<16 x i8> %0, <16 x i8> %1); ret <16 x i8> %2; }. ; Function Attrs: nounwind readnone; declare <16 x i8> @llvm.ppc.altivec.crypto.vpmsumb(<16 x i8>, <16 x i8>) #1. Produces the following code with -mtriple=powerpc64-unknown-linux-gnu:; # %bb.0: # %entry; addis 3, 2, .LCPI0_0@toc@ha; addis 4, 2, .LCPI0_1@toc@ha; addi 3, 3, .LCPI0_0@toc@l; addi 4, 4, .LCPI0_1@toc@l; lxvw4x 0, 0, 3; addi 3, 1, -16; lxvw4x 35, 0, 4; stxvw4x 0, 0, 3; ori 2, 2, 0; lxvw4x 34, 0, 3; addi 3, 1, -32; stxvw4x 35, 0, 3; vpmsumb 2, 2, 3; blr; .long 0; .quad 0. The two stxvw4x instructions are not needed.; With -mtriple=powerpc64le-unknown-linux-gnu, the associated permutes; are present too. //===---------------------",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/README_ALTIVEC.txt:6509,load,load,6509,interpreter/llvm-project/llvm/lib/Target/PowerPC/README_ALTIVEC.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/README_ALTIVEC.txt,4,['load'],['load']
Performance," matcher would be as follows:. .. code-block:: text. CHECK: Name: foo; CHECK: Value:; CHECK-SAME: {{ 1$}}. This verifies that the *next* time ""``Value:``"" appears in the output, it has; the value ``1``. Note: a ""``CHECK-SAME:``"" cannot be the first directive in a file. The ""CHECK-EMPTY:"" directive; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~. If you need to check that the next line has nothing on it, not even whitespace,; you can use the ""``CHECK-EMPTY:``"" directive. .. code-block:: llvm. declare void @foo(). declare void @bar(); ; CHECK: foo; ; CHECK-EMPTY:; ; CHECK-NEXT: bar. Just like ""``CHECK-NEXT:``"" the directive will fail if there is more than one; newline before it finds the next blank line, and it cannot be the first; directive in a file. The ""CHECK-NOT:"" directive; ~~~~~~~~~~~~~~~~~~~~~~~~~~. The ""``CHECK-NOT:``"" directive is used to verify that a string doesn't occur; between two matches (or before the first match, or after the last match). For; example, to verify that a load is removed by a transformation, a test like this; can be used:. .. code-block:: llvm. define i8 @coerce_offset0(i32 %V, i32* %P) {; store i32 %V, i32* %P. %P2 = bitcast i32* %P to i8*; %P3 = getelementptr i8* %P2, i32 2. %A = load i8* %P3; ret i8 %A; ; CHECK: @coerce_offset0; ; CHECK-NOT: load; ; CHECK: ret i8; }. The ""CHECK-COUNT:"" directive; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~. If you need to match multiple lines with the same pattern over and over again; you can repeat a plain ``CHECK:`` as many times as needed. If that looks too; boring you can instead use a counted check ""``CHECK-COUNT-<num>:``"", where; ``<num>`` is a positive decimal number. It will match the pattern exactly; ``<num>`` times, no more and no less. If you specified a custom check prefix,; just use ""``<PREFIX>-COUNT-<num>:``"" for the same effect.; Here is a simple example:. .. code-block:: text. Loop at depth 1; Loop at depth 1; Loop at depth 1; Loop at depth 1; Loop at depth 2; Loop at depth 3. ; CHECK-COUNT-6: Loop at depth {{[0-9]+}",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/FileCheck.rst:16806,load,load,16806,interpreter/llvm-project/llvm/docs/CommandGuide/FileCheck.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/FileCheck.rst,1,['load'],['load']
Performance," may compute intermediate; results (""derived pointers"") which point outside of the allocation or; even into the middle of another allocation. The eventual use of this; intermediate value must yield an address within the bounds of the; allocation, but such ""exterior derived pointers"" may be visible to the; collector. Given this, a garbage collector can not safely rely on the; runtime value of an address to indicate the object it is associated; with. If the garbage collector wishes to move any object, the; compiler must provide a mapping, for each pointer, to an indication of; its allocation. To simplify the interaction between a collector and the compiled code,; most garbage collectors are organized in terms of three abstractions:; load barriers, store barriers, and safepoints. #. A load barrier is a bit of code executed immediately after the; machine load instruction, but before any use of the value loaded.; Depending on the collector, such a barrier may be needed for all; loads, merely loads of a particular type (in the original source; language), or none at all. #. Analogously, a store barrier is a code fragment that runs; immediately before the machine store instruction, but after the; computation of the value stored. The most common use of a store; barrier is to update a 'card table' in a generational garbage; collector. #. A safepoint is a location at which pointers visible to the compiled; code (i.e. currently in registers or on the stack) are allowed to; change. After the safepoint completes, the actual pointer value; may differ, but the 'object' (as seen by the source language); pointed to will not. Note that the term 'safepoint' is somewhat overloaded. It refers to; both the location at which the machine state is parsable and the; coordination protocol involved in bring application threads to a; point at which the collector can safely use that information. The; term ""statepoint"" as used in this document refers exclusively to the; former. This document focus",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:2774,load,loads,2774,interpreter/llvm-project/llvm/docs/Statepoints.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst,2,['load'],['loads']
Performance," mem is automatically freed at this point */; }. **Description**:. ``__builtin_alloca_with_align`` is meant to be used to allocate a dynamic amount of memory; on the stack. It is similar to ``__builtin_alloca`` but accepts a second; argument whose value is the alignment constraint, as a power of 2 in *bits*. Query for this feature with ``__has_builtin(__builtin_alloca_with_align)``. .. _langext-__builtin_assume:. ``__builtin_assume``; --------------------. ``__builtin_assume`` is used to provide the optimizer with a boolean; invariant that is defined to be true. **Syntax**:. .. code-block:: c++. __builtin_assume(bool). **Example of Use**:. .. code-block:: c++. int foo(int x) {; __builtin_assume(x != 0);; // The optimizer may short-circuit this check using the invariant.; if (x == 0); return do_something();; return do_something_else();; }. **Description**:. The boolean argument to this function is defined to be true. The optimizer may; analyze the form of the expression provided as the argument and deduce from; that information used to optimize the program. If the condition is violated; during execution, the behavior is undefined. The argument itself is never; evaluated, so any side effects of the expression will be discarded. Query for this feature with ``__has_builtin(__builtin_assume)``. .. _langext-__builtin_assume_separate_storage:. ``__builtin_assume_separate_storage``; -------------------------------------. ``__builtin_assume_separate_storage`` is used to provide the optimizer with the; knowledge that its two arguments point to separately allocated objects. **Syntax**:. .. code-block:: c++. __builtin_assume_separate_storage(const volatile void *, const volatile void *). **Example of Use**:. .. code-block:: c++. int foo(int *x, int *y) {; __builtin_assume_separate_storage(x, y);; *x = 0;; *y = 1;; // The optimizer may optimize this to return 0 without reloading from *x.; return *x;; }. **Description**:. The arguments to this function are assumed to point into se",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst:99142,optimiz,optimizer,99142,interpreter/llvm-project/clang/docs/LanguageExtensions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst,2,['optimiz'],"['optimize', 'optimizer']"
Performance," memory can be accomplished with the `LLVM-EXEGESIS-MEM-DEF`; and `LLVM-EXEGESIS-MEM-MAP` annotations. To execute the following snippet:. .. code-block:: none. movq $8192, %rax; movq (%rax), %rdi. We need to have at least eight bytes of memory allocated starting `0x2000`.; We can create the necessary execution environment with the following; annotations added to the snippet:. .. code-block:: none. # LLVM-EXEGESIS-MEM-DEF test1 4096 7fffffff; # LLVM-EXEGESIS-MEM-MAP test1 8192. movq $8192, %rax; movq (%rax), %rdi. EXAMPLE 4: analysis; -------------------. Assuming you have a set of benchmarked instructions (either latency or uops) as; YAML in file `/tmp/benchmarks.yaml`, you can analyze the results using the; following command:. .. code-block:: bash. $ llvm-exegesis --mode=analysis \; --benchmarks-file=/tmp/benchmarks.yaml \; --analysis-clusters-output-file=/tmp/clusters.csv \; --analysis-inconsistencies-output-file=/tmp/inconsistencies.html. This will group the instructions into clusters with the same performance; characteristics. The clusters will be written out to `/tmp/clusters.csv` in the; following format:. .. code-block:: none. cluster_id,opcode_name,config,sched_class; ...; 2,ADD32ri8_DB,,WriteALU,1.00; 2,ADD32ri_DB,,WriteALU,1.01; 2,ADD32rr,,WriteALU,1.01; 2,ADD32rr_DB,,WriteALU,1.00; 2,ADD32rr_REV,,WriteALU,1.00; 2,ADD64i32,,WriteALU,1.01; 2,ADD64ri32,,WriteALU,1.01; 2,MOVSX64rr32,,BSWAP32r_BSWAP64r_MOVSX64rr32,1.00; 2,VPADDQYrr,,VPADDBYrr_VPADDDYrr_VPADDQYrr_VPADDWYrr_VPSUBBYrr_VPSUBDYrr_VPSUBQYrr_VPSUBWYrr,1.02; 2,VPSUBQYrr,,VPADDBYrr_VPADDDYrr_VPADDQYrr_VPADDWYrr_VPSUBBYrr_VPSUBDYrr_VPSUBQYrr_VPSUBWYrr,1.01; 2,ADD64ri8,,WriteALU,1.00; 2,SETBr,,WriteSETCC,1.01; ... :program:`llvm-exegesis` will also analyze the clusters to point out; inconsistencies in the scheduling information. The output is an html file. For; example, `/tmp/inconsistencies.html` will contain messages like the following :. .. image:: llvm-exegesis-analysis.png; :align: center. Note that ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-exegesis.rst:7976,perform,performance,7976,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-exegesis.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-exegesis.rst,1,['perform'],['performance']
Performance," memory order if they access LDS memory, and out of LDS operation order; if they access global memory.; * The vector memory operations access a single vector L1 cache shared by all; SIMDs a CU. Therefore, no special action is required for coherence between the; lanes of a single wavefront, or for coherence between wavefronts in the same; work-group. A ``buffer_wbinvl1_vol`` is required for coherence between; wavefronts executing in different work-groups as they may be executing on; different CUs.; * The scalar memory operations access a scalar L1 cache shared by all wavefronts; on a group of CUs. The scalar and vector L1 caches are not coherent. However,; scalar operations are used in a restricted way so do not impact the memory; model. See :ref:`amdgpu-amdhsa-memory-spaces`.; * The vector and scalar memory operations use an L2 cache shared by all CUs on; the same agent.; * The L2 cache has independent channels to service disjoint ranges of virtual; addresses.; * Each CU has a separate request queue per channel. Therefore, the vector and; scalar memory operations performed by wavefronts executing in different; work-groups (which may be executing on different CUs) of an agent can be; reordered relative to each other. A ``s_waitcnt vmcnt(0)`` is required to; ensure synchronization between vector memory operations of different CUs. It; ensures a previous vector memory operation has completed before executing a; subsequent vector memory or LDS operation and so can be used to meet the; requirements of acquire and release.; * The L2 cache can be kept coherent with other agents on some targets, or ranges; of virtual addresses can be set up to bypass it to ensure system coherence. Scalar memory operations are only used to access memory that is proven to not; change during the execution of the kernel dispatch. This includes constant; address space and global address space for program scope ``const`` variables.; Therefore, the kernel machine code does not have to maintain the ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:208593,queue,queue,208593,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['queue'],['queue']
Performance," mismatches).; . TXNetSystem:; ; Fix problem with GetDirEntry: the entry object was; going out-of-scope so; that the returned string was meaningless.; Reset; the list if dir entries in FreeDirectory.; Fix problem affecting repeated calls. The implementation of TFile throughput and info sending was; just sending 'regular' samples about the activity of the single TFile; instance that happened to trigger an activity in the right moment.; Now TMonaLisaWriter keeps internally track of every; activity; and regularly sends summaries valid for all the files which had; activity in the last time interval.; Additionally, it's now finalized the infrastructure able to; measure; and keep track of the file Open latency. A packet is sent for each; successful Open, sending the measures of the latencies for the; various phases of the open. Currently exploited fully by TAlienFile; and TXNetFile. Easy to report from other TFiles too.; Now, the hook for the Close() func triggers sending of a; packet containing various information about the performance related to; that file only.; Added support also for performance monitoring when writing. RGLITE: A ROOT GRID interface. RGLite plug-in - a ROOT plug-in module, which implements the ROOT Grid; interface and offers to ROOT users possibilities to perform a number of; operations using gLite middleware from within ROOT. Supported features:. Workload Management System operations:; ; job submission – normal, DAG and parametric; jobs (gLite; WMProxy API), ; smart look-up algorithm for WMP-Endpoints, ; job status querying (gLite LB API), ; job output retrieving (Globus GridFTP). . File Catalog operations (gLite/LCG LFC API):; ; smart session manager, ; set/query the current working catalog directory, ; list files, directories and their stats, ; add/remove files in a catalog namespace, ; add/remove directories, ; add/remove replicas from a given file. . An executive logging. ; Support of an external XML configuration file with; according XML; schema.",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/net/doc/v520/index.html:2933,perform,performance,2933,net/doc/v520/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/net/doc/v520/index.html,2,['perform'],['performance']
Performance," mitigation strategy works is that it establishes a; data-flow check on the loaded address. However, this means that if the address; itself was already loaded using a checked load, there is no need to check a; dependent load provided it is within the same basic block as the checked load,; and therefore has no additional predicates guarding it. Consider code like the; following:; ```; ... .LBB0_4: # %danger; movq (%rcx), %rdi; movl (%rdi), %edx; ```. This will get transformed into:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; orq %rax, %rcx # Mask the pointer if misspeculating.; movq (%rcx), %rdi # Hardened load.; movl (%rdi), %edx # Unhardened load due to dependent addr.; ```. This doesn't check the load through `%rdi` as that pointer is dependent on a; checked load already. ###### Protect large, load-heavy blocks with a single lfence. It may be worth using a single `lfence` instruction at the start of a block; which begins with a (very) large number of loads that require independent; protection *and* which require hardening the address of the load. However, this; is unlikely to be profitable in practice. The latency hit of the hardening; would need to exceed that of an `lfence` when *correctly* speculatively; executed. But in that case, the `lfence` cost is a complete loss of speculative; execution (at a minimum). So far, the evidence we have of the performance cost; of using `lfence` indicates few if any hot code patterns where this trade off; would make sense. ###### Tempting optimizations that break the security model. Several optimizations were considered which didn't pan out due to failure to; uphold the security model. One in particular is worth discussing as many others; will reduce to it. We wondered whether only the *first* load in a basic block could be checked. If; the check works as intended, it forms an invalid pointer that doesn't even; virtual-address translate in the hardware. It should fault very early on",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:36353,load,loads,36353,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,2,['load'],"['load', 'loads']"
Performance," modeling a sequence of output instructions using; a ""Recipe"", which is responsible for computing its cost and generating its; code. 6. Encapsulate Single-Entry Single-Exit regions (SESE). During vectorization; such regions may need to be, for example, predicated and linearized, or; replicated VF*UF times to handle scalarized and predicated instructions.; Innerloops are also modelled as SESE regions. 7. Support instruction-level analysis and transformation, as part of Planning; Step 2.b: During vectorization instructions may need to be traversed, moved,; replaced by other instructions or be created. For example, vector idiom; detection and formation involves searching for and optimizing instruction; patterns. Definitions; ===========; The low-level design of VPlan comprises of the following classes. :LoopVectorizationPlanner:; A LoopVectorizationPlanner is designed to handle the vectorization of a loop; or a loop nest. It can construct, optimize and discard one or more VPlans,; each VPlan modelling a distinct way to vectorize the loop or the loop nest.; Once the best VPlan is determined, including the best VF and UF, this VPlan; drives the generation of output IR. :VPlan:; A model of a vectorized candidate for a given input IR loop or loop nest. This; candidate is represented using a Hierarchical CFG. VPlan supports estimating; the cost and driving the generation of the output IR code it represents. :Hierarchical CFG:; A control-flow graph whose nodes are basic-blocks or Hierarchical CFG's. The; Hierarchical CFG data structure is similar to the Tile Tree [5]_, where; cross-Tile edges are lifted to connect Tiles instead of the original; basic-blocks as in Sharir [6]_, promoting the Tile encapsulation. The terms; Region and Block are used rather than Tile [5]_ to avoid confusion with loop; tiling. :VPBlockBase:; The building block of the Hierarchical CFG. A pure-virtual base-class of; VPBasicBlock and VPRegionBlock, see below. VPBlockBase models the hierarchical; cont",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/VectorizationPlan.rst:4185,optimiz,optimize,4185,interpreter/llvm-project/llvm/docs/VectorizationPlan.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/VectorizationPlan.rst,1,['optimiz'],['optimize']
Performance," module allows the compiler to build the ``std`` module as a standalone entity, and having the mapping from header names to (sub)modules allows the automatic translation of ``#include`` directives to module imports. Module maps are specified as separate files (each named ``module.modulemap``) alongside the headers they describe, which allows them to be added to existing software libraries without having to change the library headers themselves (in most cases [#]_). The actual `Module map language`_ is described in a later section. .. note::. To actually see any benefits from modules, one first has to introduce module maps for the underlying C standard library and the libraries and headers on which it depends. The section `Modularizing a Platform`_ describes the steps one must take to write these module maps. One can use module maps without modules to check the integrity of the use of header files. To do this, use the ``-fimplicit-module-maps`` option instead of the ``-fmodules`` option, or use ``-fmodule-map-file=`` option to explicitly specify the module map files to load. Compilation model; -----------------; The binary representation of modules is automatically generated by the compiler on an as-needed basis. When a module is imported (e.g., by an ``#include`` of one of the module's headers), the compiler will spawn a second instance of itself [#]_, with a fresh preprocessing context [#]_, to parse just the headers in that module. The resulting Abstract Syntax Tree (AST) is then persisted into the binary representation of the module that is then loaded into translation unit where the module import was encountered. The binary representation of modules is persisted in the *module cache*. Imports of a module will first query the module cache and, if a binary representation of the required module is already available, will load that representation directly. Thus, a module's headers will only be parsed once per language configuration, rather than once per translation ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Modules.rst:13097,load,load,13097,interpreter/llvm-project/clang/docs/Modules.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Modules.rst,1,['load'],['load']
Performance," months of change to Clang itself.; New checker for C++ leaks is turned on by default.; Added various small checks and bug fixes.; Added experimental checkers for Objective-C:. New localizability checks:; ; Checker warning about uses of non-localized NSStrings passed to UI methods expecting localized strings.; Checker warning when the comment argument is missing from NSLocalizedString macros.; These can be enabled by passing the following command to scan-build:.   -enable-checker alpha.osx.cocoa.NonLocalizedStringChecker,alpha.osx.cocoa.EmptyLocalizationContextChecker. New checks for _Nonnull type qualifiers. These can be enabled with:.   -enable-checker nullability.NullPassedToNonnull,nullability.NullReturnedFromNonnull; New checks for misuse of Objective-C generics. These can be enabled with -enable-checker alpha.osx.cocoa.ObjCGenerics. Support for cf_returns_retained and cf_returns_not_retained attributes in out-parameters.; The analyzer now creates one state for a range switch case instead of multiple, resulting in performance improvements.; Now requires OS X 10.7 or later.; 	; checker-276; built: February 19, 2014; download: checker-276.tar.bz2; highlights:. Includes about 9 months of change to Clang itself (improved C++11/14 support, etc.); More precise modeling of Objective-C properties, which enables the analyzer to find more bugs.; Includes a new ""missing call to super"" warning, which looks for common pattern in iOS/OSX APIs that require chaining a call to a super class's implementation of a method.; Accepts -arch arm64 (which may be passed by Xcode 5.0), but for the time being analyzes code in such cases as -arch armv7s.; Many sundry fixes, improvements to C++ support, etc. checker-275; built: May 23, 2013; download: checker-275.tar.bz2; highlights:. Xcode: Includes a new arrow layout algorithm for issue presentation within Xcode. The goal is for interprocedural bug reports to look cleaner and less busy (and easier to read). Feedback appreciated.; Xcode: B",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/release_notes.html:2836,perform,performance,2836,interpreter/llvm-project/clang/www/analyzer/release_notes.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/release_notes.html,2,['perform'],['performance']
Performance," must agree). If a new patch; does not address all outstanding feedback, the author should explicitly state; that when providing the updated patch. When using the web-based code-review; tool, such notes can be provided in the ""Diff"" description (which is different; from the description of the ""Differential Revision"" as a whole used for the; commit message). If you suggest changes in a code review, but don't wish the suggestion to be; interpreted this strongly, please state so explicitly. Aim to Make Efficient Use of Everyone's Time; --------------------------------------------. Aim to limit the number of iterations in the review process. For example, when; suggesting a change, if you want the author to make a similar set of changes at; other places in the code, please explain the requested set of changes so that; the author can make all of the changes at once. If a patch will require; multiple steps prior to approval (e.g., splitting, refactoring, posting data; from specific performance tests), please explain as many of these up front as; possible. This allows the patch author and reviewers to make the most efficient; use of their time. LGTM - How a Patch Is Accepted; ------------------------------. A patch is approved to be committed when a reviewer accepts it, and this is; almost always associated with a message containing the text ""LGTM"" (which; stands for Looks Good To Me). Only approval from a single reviewer is required. When providing an unqualified LGTM (approval to commit), it is the; responsibility of the reviewer to have reviewed all of the discussion and; feedback from all reviewers ensuring that all feedback has been addressed and; that all other reviewers will almost surely be satisfied with the patch being; approved. If unsure, the reviewer should provide a qualified approval, (e.g.,; ""LGTM, but please wait for @someone, @someone_else""). You may also do this if; you are fairly certain that a particular community member will wish to review,; even if th",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst:6237,perform,performance,6237,interpreter/llvm-project/llvm/docs/CodeReview.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst,1,['perform'],['performance']
Performance," must have alignment greater than or; equal to the size in memory of the operand. Semantics:; """""""""""""""""""". The contents of memory at the location specified by the '``<pointer>``' operand; is read and compared to '``<cmp>``'; if the values are equal, '``<new>``' is; written to the location. The original value at the location is returned,; together with a flag indicating success (true) or failure (false). If the cmpxchg operation is marked as ``weak`` then a spurious failure is; permitted: the operation may not write ``<new>`` even if the comparison; matched. If the cmpxchg operation is strong (the default), the i1 value is 1 if and only; if the value loaded equals ``cmp``. A successful ``cmpxchg`` is a read-modify-write instruction for the purpose of; identifying release sequences. A failed ``cmpxchg`` is equivalent to an atomic; load with an ordering parameter determined the second ordering parameter. Example:; """""""""""""""". .. code-block:: llvm. entry:; %orig = load atomic i32, ptr %ptr unordered, align 4 ; yields i32; br label %loop. loop:; %cmp = phi i32 [ %orig, %entry ], [%value_loaded, %loop]; %squared = mul i32 %cmp, %cmp; %val_success = cmpxchg ptr %ptr, i32 %cmp, i32 %squared acq_rel monotonic ; yields { i32, i1 }; %value_loaded = extractvalue { i32, i1 } %val_success, 0; %success = extractvalue { i32, i1 } %val_success, 1; br i1 %success, label %done, label %loop. done:; ... .. _i_atomicrmw:. '``atomicrmw``' Instruction; ^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. atomicrmw [volatile] <operation> ptr <pointer>, <ty> <value> [syncscope(""<target-scope>"")] <ordering>[, align <alignment>] ; yields ty. Overview:; """""""""""""""""". The '``atomicrmw``' instruction is used to atomically modify memory. Arguments:; """""""""""""""""""". There are three arguments to the '``atomicrmw``' instruction: an; operation to apply, an address whose value to modify, an argument to the; operation. The operation must be one of the following keywords:. - xchg; - add; - sub; - and; - nand; - or; -",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:428574,load,load,428574,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['load'],['load']
Performance," must pass the ``llvm/test`` test suite. #. The code must not cause regressions on a reasonable subset of llvm-test,; where ""reasonable"" depends on the contributor's judgement and the scope of; the change (more invasive changes require more testing). A reasonable subset; might be something like ""``llvm-test/MultiSource/Benchmarks``"". #. Ensure that links in source code and test files point to publicly available; resources and are used primarily to add additional information rather than; to supply critical context. The surrounding comments should be sufficient; to provide the context behind such links. Additionally, the committer is responsible for addressing any problems found in; the future that the change is responsible for. For example:. * The code should compile cleanly on all supported platforms. * The changes should not cause any correctness regressions in the ``llvm-test``; suite and must not cause any major performance regressions. * The change set should not cause performance or correctness regressions for the; LLVM tools. * The changes should not cause performance or correctness regressions in code; compiled by LLVM on all applicable targets. * You are expected to address any `GitHub Issues <https://github.com/llvm/llvm-project/issues>`_ that; result from your change. We prefer for this to be handled before submission but understand that it isn't; possible to test all of this for every submission. Our build bots and nightly; testing infrastructure normally finds these problems. A good rule of thumb is; to check the nightly testers for regressions the day after your change. Build; bots will directly email you if a group of commits that included yours caused a; failure. You are expected to check the build bot messages to see if they are; your fault and, if so, fix the breakage. Commits that violate these quality standards (e.g. are very broken) may be; reverted. This is necessary when the change blocks other developers from making; progress. The developer is",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:13706,perform,performance,13706,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,1,['perform'],['performance']
Performance," mutually exclusive to the existing local storage; qualifiers auto, register, and static. [testme] Variables qualified by; ``__block`` act as if they were in allocated storage and this storage; is automatically recovered after last use of said variable. An; implementation may choose an optimization where the storage is; initially automatic and only ""moved"" to allocated (heap) storage upon; a Block_copy of a referencing Block. Such variables may be mutated as; normal variables are. In the case where a ``__block`` variable is a Block one must assume; that the ``__block`` variable resides in allocated storage and as such; is assumed to reference a Block that is also in allocated storage; (that it is the result of a ``Block_copy`` operation). Despite this; there is no provision to do a ``Block_copy`` or a ``Block_release`` if; an implementation provides initial automatic storage for Blocks. This; is due to the inherent race condition of potentially several threads; trying to update the shared variable and the need for synchronization; around disposing of older values and copying new ones. Such; synchronization is beyond the scope of this language specification. Control Flow; ============. The compound statement of a Block is treated much like a function body; with respect to control flow in that goto, break, and continue do not; escape the Block. Exceptions are treated *normally* in that when; thrown they pop stack frames until a catch clause is found. Objective-C Extensions; ======================. Objective-C extends the definition of a Block reference type to be; that also of id. A variable or expression of Block type may be; messaged or used as a parameter wherever an id may be. The converse is; also true. Block references may thus appear as properties and are; subject to the assign, retain, and copy attribute logic that is; reserved for objects. All Blocks are constructed to be Objective-C objects regardless of; whether the Objective-C runtime is operational in the",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/BlockLanguageSpec.rst:8066,race condition,race condition,8066,interpreter/llvm-project/clang/docs/BlockLanguageSpec.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/BlockLanguageSpec.rst,1,['race condition'],['race condition']
Performance," name. GradBaggingFraction --> BaggedSampleFraction. in an attempt to consolidate and avoid idential duplicate code; ; The option UseWeightedTrees has been removed and set to ""true"", as was default; anyway, as a measure of further consolidation. Removed the option NNodesMax --> This should be replaced by specifying MaxDepth; instead (limiting the maximum tree depth also limits the number of possible nodes!). b) Added a trial version of a new ""cost sensitive"" boosting algorithem according to; Wei Fan and Salvatore J. Stolfo, {\em AdaCost: misclassification cost-sensitive boosting}, Proceedings of the 16th International conference on machine learning (ICML 1999)}. With the currently; chosen DEFAULT settings (all costs equal and set to ""one""), it is equivalent to the ""real-AdaBoost"" (i.e. using the option !UseYesNoLeaf (which uses the leave node purity rather than a signal or background attribute in the leaf node of each individual tree). Unfortunatly, no reasonable performance has been achieved yet when choosing different cost parameters. c) BDT's with little tree depth (as favoured for good performance) do not *like* it if; there are very clean signal and background separation cuts available, which however ; have NOT been applied yet as preselection. Now there is a possibility to choose the option; ""DoPreselection"" that looks for suitable preselection cuts and applies them prior to ; the Decision Tree training. While that works fine, this clearly gives ""sharp"" peaks at +1 (-1); for the MVA output distribution and therefore the ""smoothing"" of this distribution used to; produce the ROC curve and efficiency estimates are somewhat thwarted.; ; --> It's better if you do these preselection cuts YOURSELF when defining training and test; sample!. d) Removed completely the (hopefully never used) option of treating negative events weights; via: PairNegWeightsInNode. e) Renamed option: IgnoreNegEvents --> IgnoreNegEventsInTraining; and removed the IDENTICAL option NoNegeventsInT",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/tmva/UsersGuide/ReleaseNotes4.2.0.txt:2482,perform,performance,2482,documentation/tmva/UsersGuide/ReleaseNotes4.2.0.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/tmva/UsersGuide/ReleaseNotes4.2.0.txt,1,['perform'],['performance']
Performance," need a runtime library for JIT'd code. This would include things like; TLS registration, reentry functions, registration code for language runtimes; (e.g. Objective C and Swift) and other JIT specific runtime code. This should; be built in a similar manner to compiler-rt (possibly even as part of it). 2. **Remote jit_dlopen / jit_dlclose**. To more fully mimic the environment that static programs operate in we would; like JIT'd code to be able to ""dlopen"" and ""dlclose"" JITDylibs, running all of; their initializers/deinitializers on the current thread. This would require; support from the runtime library described above. 3. **Debugging support**. ORC currently supports the GDBRegistrationListener API when using RuntimeDyld; as the underlying JIT linker. We will need a new solution for JITLink based; platforms. Further Future Work; -------------------. 1. **Speculative Compilation**. ORC's support for concurrent compilation allows us to easily enable; *speculative* JIT compilation: compilation of code that is not needed yet,; but which we have reason to believe will be needed in the future. This can be; used to hide compile latency and improve JIT throughput. A proof-of-concept; example of speculative compilation with ORC has already been developed (see; ``llvm/examples/SpeculativeJIT``). Future work on this is likely to focus on; re-using and improving existing profiling support (currently used by PGO) to; feed speculation decisions, as well as built-in tools to simplify use of; speculative compilation. .. [1] Formats/architectures vary in terms of supported features. MachO and; ELF tend to have better support than COFF. Patches very welcome!. .. [2] The ``LazyEmittingLayer``, ``RemoteObjectClientLayer`` and; ``RemoteObjectServerLayer`` do not have counterparts in the new; system. In the case of ``LazyEmittingLayer`` it was simply no longer; needed: in ORCv2, deferring compilation until symbols are looked up is; the default. The removal of ``RemoteObjectClientLayer``",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ORCv2.rst:37043,concurren,concurrent,37043,interpreter/llvm-project/llvm/docs/ORCv2.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ORCv2.rst,1,['concurren'],['concurrent']
Performance," needed for Cling; to be able to parse templates' instantiations and for some autoloading; functionalities.; - One (or more) libraries sections. These sections describe the ensamble of; the autoload keys related to one or more shared libraries. An autoload key; can be a class name, a namespace name, a typedef or alias or a header file name.; - Single line comments, which start with a ""#"" character. At ROOT startup, a check is performed on autoload keys. If the same key (which is not a template instantiation) refers to two different libraries (or sets of libraries) a warning is issued.; A typical Rootmap file look like:; ``` {.cpp}; { decls }; fwd declaration 1;; fwd declaration 2;; [...]; fwd declaration N;. [ libraryName1 libraryName2 ... ]; class className1; class className2; ...; typedef typedefName1; typedef typedefName2; ...; header headerName1; header headerName2; ... ```. ### TROOT. The list returned by `GetListOfTypes` is no longer filled when the dictionary; are loaded but instead are filled on demand, when the user explicitly (directly; or indirectly) request each typedef. In particular this means that. ``` {.cpp}; gROOT->GetListOfTypes()->ls(); // or Print(); ```. no longer prints the list of all available typedef but instead list only the; typedefs that have been previously accessed throught the list (plus the builtins; types). ### ACliC. ACLiC has the following backward incompatibilities:. - Since rootcling no longer re-\#defines the private and protected; keyword to public, the code compiled by ACLIC no longer has access; to protected and private members of a class (except where allowed by; the C++ standard). ### Collection. New collection `TListOfTypes` that implements on demand creation; of the `TDataType` describing a typedef. ### TUnixSystem. - Simplify `Setenv` coding.; - Implement `Unsetenv` using the system function `unsetenv`. ### TMacOSXSystem. - The file descriptors' management improved/fixed. ### TColor. - 5 new predefined palettes with 255 c",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/doc/v600/index.md:10731,load,loaded,10731,core/doc/v600/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/doc/v600/index.md,1,['load'],['loaded']
Performance," needs to follow certain conventions that; make it possible for a runtime function to patch over it later.; The exact effect of this attribute depends on its string value,; for which there currently is one legal possibility:. * ``""prologue-short-redirect""`` - This style of patchable; function is intended to support patching a function prologue to; redirect control away from the function in a thread safe; manner. It guarantees that the first instruction of the; function will be large enough to accommodate a short jump; instruction, and will be sufficiently aligned to allow being; fully changed via an atomic compare-and-swap instruction.; While the first requirement can be satisfied by inserting large; enough NOP, LLVM can and will try to re-purpose an existing; instruction (i.e. one that would have to be emitted anyway) as; the patchable instruction larger than a short jump. ``""prologue-short-redirect""`` is currently only supported on; x86-64. This attribute by itself does not imply restrictions on; inter-procedural optimizations. All of the semantic effects the; patching may have to be separately conveyed via the linkage type.; ``""probe-stack""``; This attribute indicates that the function will trigger a guard region; in the end of the stack. It ensures that accesses to the stack must be; no further apart than the size of the guard region to a previous; access of the stack. It takes one required string value, the name of; the stack probing function that will be called. If a function that has a ``""probe-stack""`` attribute is inlined into; a function with another ``""probe-stack""`` attribute, the resulting; function has the ``""probe-stack""`` attribute of the caller. If a; function that has a ``""probe-stack""`` attribute is inlined into a; function that has no ``""probe-stack""`` attribute at all, the resulting; function has the ``""probe-stack""`` attribute of the callee.; ``""stack-probe-size""``; This attribute controls the behavior of stack probes: either; the ``""probe-stack",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:97906,optimiz,optimizations,97906,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['optimiz'],['optimizations']
Performance," never auto generated and thus requires explicit request of the dictionary for each std::tuple class template instantiation used, like most other class templates.; * Custom streamers need to #include TBuffer.h explicitly (see [section Core Libraries](#core-libs)); * Check and flag short reads as errors in the xroot plugins. This fixes [ROOT-3341].; * Added support for AWS temporary security credentials to TS3WebFile by allowing the security token to be given.; * Resolve an issue when space is freed in a large `ROOT` file and a TDirectory is updated and stored the lower (less than 2GB) freed portion of the file [ROOT-8055]. - ##### TBufferJSON:; + support data members with `//[fN]` comment; + preliminary support of STL containers; + JSON data can be produced with `TObject::SaveAs()` method. ## TTree Libraries. * TChains can now be histogrammed without any C++ code, using the command line tool `rootdrawtree`. It is based on the new class `TSimpleAnalysis`.; * Do not automatically setup read cache during `TTree::Fill()`. This fixes [ROOT-8031].; * Make sure the option ""PARA"" in `TTree::Draw` is used with at least tow variables [ROOT-8196].; * The with `goff` option one can use as many variables as needed. There no more; limitation, like with the options `para`and `candle`.; * Fix detection of errors that appears in nested TTreeFormula [ROOT-8218]; * Better basket size optimization by taking into account meta data and rounding up to next 512 bytes, ensuring a complete cluster fits into a single basket. ### Fast Cloning. We added a cache specifically for the fast option of the TTreeCloner to significantly reduce the run-time when fast-cloning remote files to address [ROOT-5078]. It can be controlled from the `TTreeCloner`, `TTree::CopyEntries` or `hadd` interfaces. The new cache is enabled by default, to update the size of the cache or disable it from `TTreeCloner` use: `TTreeCloner::SetCacheSize`. To do the same from `TTree::CopyEntries` add to the option string ""cachesi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:8944,cache,cache,8944,README/ReleaseNotes/v608/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md,1,['cache'],['cache']
Performance," never be stale in L2 due to; the memory probes. atomicrmw acq_rel - agent - generic 1. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global have; completed before; performing the; atomicrmw that is; being released. 2. flat_atomic; 3. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 4. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acq_rel - system - generic 1. buffer_wbl2. - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at system scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that al",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:272499,cache,cache,272499,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['cache'],['cache']
Performance," new :program:`lit` testing implementation, or extending an existing one. :program:`lit` proper is primarily an infrastructure for discovering and running; arbitrary tests, and to expose a single convenient interface to these; tests. :program:`lit` itself doesn't know how to run tests, rather this logic is; defined by *test suites*. TEST SUITES; ~~~~~~~~~~~. As described in :ref:`test-discovery`, tests are always located inside a *test; suite*. Test suites serve to define the format of the tests they contain, the; logic for finding those tests, and any additional information to run the tests. :program:`lit` identifies test suites as directories containing ``lit.cfg`` or; ``lit.site.cfg`` files (see also :option:`--config-prefix`). Test suites are; initially discovered by recursively searching up the directory hierarchy for; all the input files passed on the command line. You can use; :option:`--show-suites` to display the discovered test suites at startup. Once a test suite is discovered, its config file is loaded. Config files; themselves are Python modules which will be executed. When the config file is; executed, two important global variables are predefined:. **lit_config**. The global **lit** configuration object (a *LitConfig* instance), which defines; the builtin test formats, global configuration parameters, and other helper; routines for implementing test configurations. **config**. This is the config object (a *TestingConfig* instance) for the test suite,; which the config file is expected to populate. The following variables are also; available on the *config* object, some of which must be set by the config and; others are optional or predefined:. **name** *[required]* The name of the test suite, for use in reports and; diagnostics. **test_format** *[required]* The test format object which will be used to; discover and run tests in the test suite. Generally this will be a builtin test; format available from the *lit.formats* module. **test_source_root** T",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/lit.rst:14834,load,loaded,14834,interpreter/llvm-project/llvm/docs/CommandGuide/lit.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/lit.rst,1,['load'],['loaded']
Performance," new; `DIAssignID` attachments each. In other words, treat the split stores as; separate assignments. For partial DSE (e.g. shortening a memset), we do the; same except that `llvm.dbg.assign` for the dead fragment gets an `Undef`; `Address`. **Promoting** allocas and store/loads: `llvm.dbg.assign` intrinsics implicitly; describe joined values in memory locations at CFG joins, but this is not; necessarily the case after promoting (or partially promoting) the; variable. Passes that promote variables are responsible for inserting; `llvm.dbg.assign` intrinsics after the resultant PHIs generated during; promotion. `mem2reg` already has to do this (with `llvm.dbg.value`) for; `llvm.dbg.declare`s. Where a store has no linked intrinsic, the store is; assumed to represent an assignment for variables stored at the destination; address. #### Debug intrinsic updates. **Moving** a debug intrinsic: avoid moving `llvm.dbg.assign` intrinsics where; possible, as they represent a source-level assignment, whose position in the; program should not be affected by optimization passes. **Deleting** a debug intrinsic: Nothing new to do. Just like for conventional; debug intrinsics, unless it is unreachable, it’s almost always incorrect to; delete a `llvm.dbg.assign` intrinsic. ### Lowering `llvm.dbg.assign` to MIR. To begin with only SelectionDAG ISel will be supported. `llvm.dbg.assign`; intrinsics are lowered to MIR `DBG_INSTR_REF` instructions. Before this happens; we need to decide where it is appropriate to use memory locations and where we; must use a non-memory location (or no location) for each variable. In order to; make those decisions we run a standard fixed-point dataflow analysis that makes; the choice at each instruction, iteratively joining the results for each block. ### TODO list. As this is an experimental work in progress so there are some items we still need; to tackle:. * As mentioned in test llvm/test/DebugInfo/assignment-tracking/X86/diamond-3.ll,; the analysis shoul",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AssignmentTracking.md:8640,optimiz,optimization,8640,interpreter/llvm-project/llvm/docs/AssignmentTracking.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AssignmentTracking.md,1,['optimiz'],['optimization']
Performance," no useful instructions on x86 that apply a mask to all 64 bits; without touching the flag registers. However, we can harden loaded values that; are narrower than a word (fewer than 32-bits on 32-bit systems and fewer than; 64-bits on 64-bit systems) by zero-extending the value to the full word size; and then shifting right by at least the number of original bits using the BMI2; `shrx` instruction:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; addl (%rsi), %edi # Load and accumulate 32 bits of data.; shrxq %rax, %rdi, %rdi # Shift out all 32 bits loaded.; ```. Because on x86 the zero-extend is free, this can efficiently harden the loaded; value. ##### Hardening the address of the load. When hardening the loaded value is inapplicable, most often because the; instruction directly leaks information (like `cmp` or `jmpq`), we switch to; hardening the _address_ of the load instead of the loaded value. This avoids; increasing register pressure by unfolding the load or paying some other high; cost. To understand how this works in practice, we need to examine the exact; semantics of the x86 addressing modes which, in its fully general form, looks; like `(%base,%index,scale)offset`. Here `%base` and `%index` are 64-bit; registers that can potentially be any value, and may be attacker controlled,; and `scale` and `offset` are fixed immediate values. `scale` must be `1`, `2`,; `4`, or `8`, and `offset` can be any 32-bit sign extended value. The exact; computation performed to find the address is then: `%base + (scale * %index) +; offset` under 64-bit 2's complement modular arithmetic. One issue with this approach is that, after hardening, the `%base + (scale *; %index)` subexpression will compute a value near zero (`-1 + (scale * -1)`) and; then a large, positive `offset` will index into memory within the first two; gigabytes of address space. While these offsets are not attacker controlled,; the attacker could chose to attack a load w",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:27806,load,load,27806,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,1,['load'],['load']
Performance," no; address space on; the fence need to; conservatively; always generate. If; fence had an; address space then; set to address; space of OpenCL; fence flag, or to; generic if both; local and global; flags are; specified.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load; atomic/; atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Must happen before; the following; buffer_inv and; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than the; value read by the; fence-paired-atomic. 3. buffer_inv sc0=1. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. fence acquire - agent *none* 1. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate; (see comment for; previous fence).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Must happen before; the following; b",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:303724,load,loads,303724,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['loads']
Performance," node is also used as LoopID (``Loop::getLoopID()``), i.e.; the loop effectively gets a new identifier. For instance,; ``llvm.mem.parallel_loop_access`` references the LoopID. Therefore, if; the parallel access property is to be preserved after adding/removing; loop attributes, any ``llvm.mem.parallel_loop_access`` reference must be; updated to the new LoopID. Transformation Metadata Structure; =================================. Some attributes describe code transformations (unrolling, vectorizing,; loop distribution, etc.). They can either be a hint to the optimizer; that a transformation might be beneficial, instruction to use a specific; option, , or convey a specific request from the user (such as; ``#pragma clang loop`` or ``#pragma omp simd``). If a transformation is forced but cannot be carried-out for any reason,; an optimization-missed warning must be emitted. Semantic information; such as a transformation being safe (e.g.; ``llvm.mem.parallel_loop_access``) can be unused by the optimizer; without generating a warning. Unless explicitly disabled, any optimization pass may heuristically; determine whether a transformation is beneficial and apply it. If; metadata for another transformation was specified, applying a different; transformation before it might be inadvertent due to being applied on a; different loop or the loop not existing anymore. To avoid having to; explicitly disable an unknown number of passes, the attribute; ``llvm.loop.disable_nonforced`` disables all optional, high-level,; restructuring transformations. The following example avoids the loop being altered before being; vectorized, for instance being unrolled. .. code-block:: llvm. br i1 %exitcond, label %for.exit, label %for.header, !llvm.loop !0; ...; !0 = distinct !{!0, !1, !2}; !1 = !{!""llvm.loop.vectorize.enable"", i1 true}; !2 = !{!""llvm.loop.disable_nonforced""}. After a transformation is applied, follow-up attributes are set on the; transformed and/or new loop(s). This allows additiona",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TransformMetadata.rst:2729,optimiz,optimizer,2729,interpreter/llvm-project/llvm/docs/TransformMetadata.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TransformMetadata.rst,1,['optimiz'],['optimizer']
Performance," nodes defined in this graph.; External symbols will still have null addresses. #. Phase 2. #. Run post-allocation passes. These passes are run on the graph after working and target memory have; been allocated, but before the ``JITLinkContext`` is notified of the; final addresses of the symbols in the graph. This gives these passes a; chance to set up data structures associated with target addresses before; any JITLink clients (especially ORC queries for symbol resolution) can; attempt to access them. Notable use cases: Setting up mappings between target addresses and; JIT data structures, such as a mapping between ``__dso_handle`` and; ``JITDylib*``. #. Notify the ``JITLinkContext`` of the assigned symbol addresses. Calls ``JITLinkContext::notifyResolved`` on the link graph, allowing; clients to react to the symbol address assignments made for this graph.; In ORC this is used to notify any pending queries for *resolved* symbols,; including pending queries from concurrently running JITLink instances that; have reached the next step and are waiting on the address of a symbol in; this graph to proceed with their link. #. Identify external symbols and resolve their addresses asynchronously. Calls the ``JITLinkContext`` to resolve the target address of any external; symbols in the graph. #. Phase 3. #. Apply external symbol resolution results. This updates the addresses of all external symbols. At this point all; nodes in the graph have their final target addresses, however node; content still points back to the original data in the object file. #. Run pre-fixup passes. These passes are called on the graph after all nodes have been assigned; their final target addresses, but before node content is copied into; working memory and fixed up. Passes run at this stage can make late; optimizations to the graph and content based on address layout. Notable use cases: GOT and PLT relaxation, where GOT and PLT accesses are; bypassed for fixup targets that are directly accessible u",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/JITLink.rst:20533,concurren,concurrently,20533,interpreter/llvm-project/llvm/docs/JITLink.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/JITLink.rst,1,['concurren'],['concurrently']
Performance," nodes tie a :ref:`DIGlobalVariable` together; with a :ref:`DIExpression`. .. code-block:: text. @lower = global i32, !dbg !0; @upper = global i32, !dbg !1; !0 = !DIGlobalVariableExpression(; var: !2,; expr: !DIExpression(DW_OP_LLVM_fragment, 0, 32); ); !1 = !DIGlobalVariableExpression(; var: !2,; expr: !DIExpression(DW_OP_LLVM_fragment, 32, 32); ); !2 = !DIGlobalVariable(name: ""split64"", linkageName: ""split64"", scope: !3,; file: !4, line: 8, type: !5, declaration: !6). All global variable expressions should be referenced by the `globals:` field of; a :ref:`compile unit <DICompileUnit>`. .. _DISubprogram:. DISubprogram; """""""""""""""""""""""". ``DISubprogram`` nodes represent functions from the source language. A distinct; ``DISubprogram`` may be attached to a function definition using ``!dbg``; metadata. A unique ``DISubprogram`` may be attached to a function declaration; used for call site debug info. The ``retainedNodes:`` field is a list of; :ref:`variables <DILocalVariable>` and :ref:`labels <DILabel>` that must be; retained, even if their IR counterparts are optimized out of the IR. The; ``type:`` field must point at an :ref:`DISubroutineType`. .. _DISubprogramDeclaration:. When ``spFlags: DISPFlagDefinition`` is not present, subprograms describe a; declaration in the type tree as opposed to a definition of a function. In this; case, the ``declaration`` field must be empty. If the scope is a composite type; with an ODR ``identifier:`` and that does not set ``flags: DIFwdDecl``, then; the subprogram declaration is uniqued based only on its ``linkageName:`` and; ``scope:``. .. code-block:: text. define void @_Z3foov() !dbg !0 {; ...; }. !0 = distinct !DISubprogram(name: ""foo"", linkageName: ""_Zfoov"", scope: !1,; file: !2, line: 7, type: !3,; spFlags: DISPFlagDefinition | DISPFlagLocalToUnit,; scopeLine: 8, containingType: !4,; virtuality: DW_VIRTUALITY_pure_virtual,; virtualIndex: 10, flags: DIFlagPrototyped,; isOptimized: true, unit: !5, templateParams: !6,; declaration: !",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:257912,optimiz,optimized,257912,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['optimiz'],['optimized']
Performance," not returned from the function or; stored in a global. This pass is implemented as a bottom-up traversal of the; call-graph. ``globaldce``: Dead Global Elimination; --------------------------------------. This transform is designed to eliminate unreachable internal globals from the; program. It uses an aggressive algorithm, searching out globals that are known; to be alive. After it finds all of the globals which are needed, it deletes; whatever is left over. This allows it to delete recursive chunks of the; program which are unreachable. ``globalopt``: Global Variable Optimizer; ----------------------------------------. This pass transforms simple global variables that never have their address; taken. If obviously true, it marks read/write globals as constant, deletes; variables only stored to, etc. ``gvn``: Global Value Numbering; -------------------------------. This pass performs global value numbering to eliminate fully and partially; redundant instructions. It also performs redundant load elimination. .. _passes-indvars:. ``indvars``: Canonicalize Induction Variables; ---------------------------------------------. This transformation analyzes and transforms the induction variables (and; computations derived from them) into simpler forms suitable for subsequent; analysis and transformation. This transformation makes the following changes to each loop with an; identifiable induction variable:. * All loops are transformed to have a *single* canonical induction variable; which starts at zero and steps by one.; * The canonical induction variable is guaranteed to be the first PHI node in; the loop header block.; * Any pointer arithmetic recurrences are raised to use array subscripts. If the trip count of a loop is computable, this pass also makes the following; changes:. * The exit condition for the loop is canonicalized to compare the induction; value against the exit value. This turns loops like:. .. code-block:: c++. for (i = 7; i*i < 1000; ++i). into. .. code-bl",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Passes.rst:17479,perform,performs,17479,interpreter/llvm-project/llvm/docs/Passes.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Passes.rst,2,"['load', 'perform']","['load', 'performs']"
Performance," not see stale; global data. atomicrmw acquire - system - global 1. buffer/global_atomic; 2. s_waitcnt vmcnt(0). - Must happen before; following buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; caches. 3. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. atomicrmw acquire - agent - generic 1. flat_atomic; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - system - generic 1. flat_atomic; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; caches. 3. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. fence acquire - singlethread *none* *none*; - wavefront; fence acquire - workgroup *none* 1. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - If OpenCL and; address space is; local, omit; vmcnt(0).; - Howe",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:251781,load,loads,251781,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['loads']
Performance," not see stale; global data. fence acq_rel - singlethread *none* *none*; - wavefront; fence acq_rel - workgroup *none* 1. s_waitcnt lgkmcnt(0) &; vmcnt(0) & vscnt(0). - If CU wavefront execution; mode, omit vmcnt(0) and; vscnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - If OpenCL and; address space is; local, omit; vmcnt(0) and vscnt(0).; - However,; since LLVM; currently has no; address space on; the fence need to; conservatively; always generate; (see comment for; previous fence).; - Could be split into; separate s_waitcnt; vmcnt(0), s_waitcnt; vscnt(0) and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/load; atomic/; atomicrmw-with-return-value.; - s_waitcnt vscnt(0); must happen after; any preceding; global/generic; store/store atomic/; atomicrmw-no-return-value.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store atomic/; atomicrmw.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that all; memory operations; have; completed before; performing any; following global; memory operations.; - Ensures that the; preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; acquire-fence-paired-atomic); has completed; before following; global memory; operations. This; satisfies the; requirements of; acquire.; - Ensures that all; previous memory; operations have; completed before a; following; local/generic store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; release-fence-paired-atomic).; This satisfies the; requirements of; release.; - Must happen before; the following; buffer_gl0_inv.; - Ensures that the; acquire-fence-paired; ato",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:370419,load,load,370419,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],['load']
Performance," not the case when going the other way since the; track has first to exit the extruding node before checking the mother.; In other words, an extrusion behavior is dependent on the track; parameters, which is a highly undesirable effect. *B)* We will call ""overlaps"" only the regions in space contained by; more than one node inside the same container. The owner of such regions; cannot be determined based on hierarchical considerations; therefore; they will be considered as belonging to the node from which the current; track is coming from. When coming from their container, the ownership is totally; unpredictable. Again, the ownership of overlapping regions highly; depends on the current track parameters. We must say that even the overlaps of type *A)* and *B)* are allowed in case; the corresponding nodes are created using; TGeoVolume::AddNodeOverlap() method. Navigation is performed in such; cases by giving priority to the non-overlapping nodes. The modeller has; to perform an additional search through the overlapping candidates.; These are detected automatically during the geometry closing procedure; in order to optimize the algorithm, but we will stress that extensive; usage of this feature leads to a drastic deterioration of performance.; In the following we will focus on the non-declared overlaps of type *A)*; and *B)* since this is the main source of errors during tracking. These; are generally non-intended overlaps due to coding mistakes or bad; geometry design. The checking package is loaded together with the; painter classes and contains an automated overlap checker. \image html geometry008.png ""Overlap checking"". This can be activated both at volume level (checking for illegal; overlaps only one level inside a given volume) and from the geometry; manager level (checking full geometry):. ~~~{.cpp}; myVolume->CheckOverlaps(precision, option);; gGeoManager->CheckOverlaps(precision);; myNode->CheckOverlaps(precision);; ~~~. Here precision represents the desired m",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:92223,perform,perform,92223,geom/geom/doc/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md,1,['perform'],['perform']
Performance," notify the context of failure. In ORC,; reported failures are propagated to queries pending on definitions provided by; the failing link, and also through edges of the dependence graph to any queries; waiting on dependent symbols. .. _connection_to_orc_runtime:. Connection to the ORC Runtime; =============================. The ORC Runtime (currently under development) aims to provide runtime support; for advanced JIT features, including object format features that require; non-trivial action in the executor (e.g. running initializers, managing thread; local storage, registering with language runtimes, etc.). ORC Runtime support for object format features typically requires cooperation; between the runtime (which executes in the executor process) and JITLink (which; runs in the JIT process and can inspect LinkGraphs to determine what actions; must be taken in the executor). For example: Execution of MachO static; initializers in the ORC runtime is performed by the ``jit_dlopen`` function,; which calls back to the JIT process to ask for the list of address ranges of; ``__mod_init`` sections to walk. This list is collated by the; ``MachOPlatformPlugin``, which installs a pass to record this information for; each object as it is linked into the target. .. _constructing_linkgraphs:. Constructing LinkGraphs; =======================. Clients usually access and manipulate ``LinkGraph`` instances that were created; for them by an ``ObjectLinkingLayer`` instance, but they can be created manually:. #. By directly constructing and populating a ``LinkGraph`` instance. #. By using the ``createLinkGraph`` family of functions to create a; ``LinkGraph`` from an in-memory buffer containing an object file. This is how; ``ObjectLinkingLayer`` usually creates ``LinkGraphs``. #. ``createLinkGraph_<Object-Format>_<Architecture>`` can be used when; both the object format and architecture are known ahead of time. #. ``createLinkGraph_<Object-Format>`` can be used when the object format is; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/JITLink.rst:33343,perform,performed,33343,interpreter/llvm-project/llvm/docs/JITLink.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/JITLink.rst,1,['perform'],['performed']
Performance," objCMessageExpr(hasSelector(""methodA:"", ""methodB:""));; matches both of the expressions below:; [myObj methodA:argA];; [myObj methodB:argB];. Matcher<ObjCMessageExpr>hasKeywordSelector; Matches when the selector is a keyword selector. objCMessageExpr(hasKeywordSelector()) matches the generated setFrame; message expression in. UIWebView *webView = ...;; CGRect bodyFrame = webView.frame;; bodyFrame.size.height = self.bodyContentHeight;; webView.frame = bodyFrame;; // ^---- matches here. Matcher<ObjCMessageExpr>hasNullSelector; Matches when the selector is the empty selector. Matches only when the selector of the objCMessageExpr is NULL. This may; represent an error condition in the tree!. Matcher<ObjCMessageExpr>hasSelectorstd::string BaseName; Matches when BaseName == Selector.getAsString(). matcher = objCMessageExpr(hasSelector(""loadHTMLString:baseURL:""));; matches the outer message expr in the code below, but NOT the message; invocation for self.bodyView.; [self.bodyView loadHTMLString:html baseURL:NULL];. Matcher<ObjCMessageExpr>hasUnarySelector; Matches when the selector is a Unary Selector. matcher = objCMessageExpr(matchesSelector(hasUnarySelector());; matches self.bodyView in the code below, but NOT the outer message; invocation of ""loadHTMLString:baseURL:"".; [self.bodyView loadHTMLString:html baseURL:NULL];. Matcher<ObjCMessageExpr>isClassMessage; Returns true when the Objective-C message is sent to a class. Example; matcher = objcMessageExpr(isClassMessage()); matches; [NSString stringWithFormat:@""format""];; but not; NSString *x = @""hello"";; [x containsString:@""h""];. Matcher<ObjCMessageExpr>isInstanceMessage; Returns true when the Objective-C message is sent to an instance. Example; matcher = objcMessageExpr(isInstanceMessage()); matches; NSString *x = @""hello"";; [x containsString:@""h""];; but not; [NSString stringWithFormat:@""format""];. Matcher<ObjCMessageExpr>matchesSelectorStringRef RegExp, Regex::RegexFlags Flags = NoFlags; Matches ObjC selectors whose na",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LibASTMatchersReference.html:106881,load,loadHTMLString,106881,interpreter/llvm-project/clang/docs/LibASTMatchersReference.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LibASTMatchersReference.html,2,['load'],['loadHTMLString']
Performance," object being returned.; This is important to preserve object identity as well as to make casting,; a pure C++ feature after all, superfluous.; Example:. .. code-block:: python. >>> from cppyy.gbl import Abstract, Concrete; >>> c = Concrete(); >>> Concrete.show_autocast.__doc__; 'Abstract* Concrete::show_autocast()'; >>> d = c.show_autocast(); >>> type(d); <class '__main__.Concrete'>; >>>. As a consequence, if your C++ classes should only be used through their; interfaces, then no bindings should be provided to the concrete classes; (e.g. by excluding them using a :ref:`selection file <selection-files>`).; Otherwise, more functionality will be available in Python than in C++. Sometimes, however, full control over a cast is needed.; For example, if the instance is bound by another tool or even a 3rd party,; hand-written, extension library.; Assuming the object supports the ``PyCapsule`` or ``CObject`` abstraction,; then a C++-style reinterpret_cast (i.e. without implicitly taking offsets; into account), can be done by taking and rebinding the address of an; object:. .. code-block:: python. >>> from cppyy import addressof, bind_object; >>> e = bind_object(addressof(d), Abstract); >>> type(e); <class '__main__.Abstract'>; >>>. `Operators`; -----------. If conversion operators are defined in the C++ class and a Python equivalent; exists (i.e. all builtin integer and floating point types, as well as; ``bool``), then these will map onto those Python conversions.; Note that ``char*`` is mapped onto ``__str__``.; Example:. .. code-block:: python. >>> from cppyy.gbl import Concrete; >>> print(Concrete()); Hello operator const char*!; >>>. C++ code can overload conversion operators by providing methods in a class or; global functions.; Special care needs to be taken for the latter: first, make sure that they are; actually available in some header file.; Second, make sure that headers are loaded in the desired order.; I.e. that these global overloads are available before use. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/type_conversions.rst:2652,load,loaded,2652,bindings/pyroot/cppyy/cppyy/doc/source/type_conversions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/type_conversions.rst,1,['load'],['loaded']
Performance," object. ``clang-offload-bundler`` always includes; this entry as the first bundled code object entry. For an; embedded bundled code object this entry is not used by the; runtime and so is generally an empty code object. hip Offload code object for the HIP language. Used for all; HIP language offload code objects when the; ``clang-offload-bundler`` is used to bundle code objects as; intermediate steps of the tool chain. Also used for AMD GPU; code objects before ABI version V4 when the; ``clang-offload-bundler`` is used to create a *fat binary*; to be loaded by the HIP runtime. The fat binary can be; loaded directly from a file, or be embedded in the host code; object as a data section with the name ``.hip_fatbin``. hipv4 Offload code object for the HIP language. Used for AMD GPU; code objects with at least ABI version V4 when the; ``clang-offload-bundler`` is used to create a *fat binary*; to be loaded by the HIP runtime. The fat binary can be; loaded directly from a file, or be embedded in the host code; object as a data section with the name ``.hip_fatbin``. openmp Offload code object for the OpenMP language extension.; ============= ==============================================================. **target-triple**; The target triple of the code object. See `Target Triple; <https://clang.llvm.org/docs/CrossCompilation.html#target-triple>`_. The bundler accepts target triples with or without the optional environment; field:. ``<arch><sub>-<vendor>-<sys>``, or; ``<arch><sub>-<vendor>-<sys>-<env>``. However, in order to standardize outputs for tools that consume bitcode; bundles, bundles written by the bundler internally use only the 4-field; target triple:. ``<arch><sub>-<vendor>-<sys>-<env>``. **target-id**; The canonical target ID of the code object. Present only if the target; supports a target ID. See :ref:`clang-target-id`. .. _code-object-composition:. Bundled Code Object Composition; -------------------------------. * Each entry of a bundled code object must ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangOffloadBundler.rst:9148,load,loaded,9148,interpreter/llvm-project/clang/docs/ClangOffloadBundler.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangOffloadBundler.rst,1,['load'],['loaded']
Performance," of EH,; before cleanups run, making it very difficult to build a faithful control flow; graph. For now, the new EH instructions cannot represent SEH filter; expressions, and frontends must outline them ahead of time. Local variables of; the parent function can be escaped and accessed using the ``llvm.localescape``; and ``llvm.localrecover`` intrinsics. New exception handling instructions; ------------------------------------. The primary design goal of the new EH instructions is to support funclet; generation while preserving information about the CFG so that SSA formation; still works. As a secondary goal, they are designed to be generic across MSVC; and Itanium C++ exceptions. They make very few assumptions about the data; required by the personality, so long as it uses the familiar core EH actions:; catch, cleanup, and terminate. However, the new instructions are hard to modify; without knowing details of the EH personality. While they can be used to; represent Itanium EH, the landingpad model is strictly better for optimization; purposes. The following new instructions are considered ""exception handling pads"", in that; they must be the first non-phi instruction of a basic block that may be the; unwind destination of an EH flow edge:; ``catchswitch``, ``catchpad``, and ``cleanuppad``.; As with landingpads, when entering a try scope, if the; frontend encounters a call site that may throw an exception, it should emit an; invoke that unwinds to a ``catchswitch`` block. Similarly, inside the scope of a; C++ object with a destructor, invokes should unwind to a ``cleanuppad``. New instructions are also used to mark the points where control is transferred; out of a catch/cleanup handler (which will correspond to exits from the; generated funclet). A catch handler which reaches its end by normal execution; executes a ``catchret`` instruction, which is a terminator indicating where in; the function control is returned to. A cleanup handler which reaches its end; by normal",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExceptionHandling.rst:25555,optimiz,optimization,25555,interpreter/llvm-project/llvm/docs/ExceptionHandling.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExceptionHandling.rst,1,['optimiz'],['optimization']
Performance," of an item affects its representation in memory only. In a register, a number is just a sequence of bits - 64 bits in the case of AArch64 general purpose registers. Memory, however, is a sequence of addressable units of 8 bits in size. Any number greater than 8 bits must therefore be split up into 8-bit chunks, and endianness describes the order in which these chunks are laid out in memory. A ""little endian"" layout has the least significant byte first (lowest in memory address). A ""big endian"" layout has the *most* significant byte first. This means that when loading an item from big endian memory, the lowest 8-bits in memory must go in the most significant 8-bits, and so forth. ``LDR`` and ``LD1``; ===================. .. figure:: ARM-BE-ldr.png; :align: right. Big endian vector load using ``LDR``. A vector is a consecutive sequence of items that are operated on simultaneously. To load a 64-bit vector, 64 bits need to be read from memory. In little endian mode, we can do this by just performing a 64-bit load - ``LDR q0, [foo]``. However if we try this in big endian mode, because of the byte swapping the lane indices end up being swapped! The zero'th item as laid out in memory becomes the n'th lane in the vector. .. figure:: ARM-BE-ld1.png; :align: right. Big endian vector load using ``LD1``. Note that the lanes retain the correct ordering. Because of this, the instruction ``LD1`` performs a vector load but performs byte swapping not on the entire 64 bits, but on the individual items within the vector. This means that the register content is the same as it would have been on a little endian system. It may seem that ``LD1`` should suffice to perform vector loads on a big endian machine. However there are pros and cons to the two approaches that make it less than simple which register format to pick. There are two options:. 1. The content of a vector register is the same *as if* it had been loaded with an ``LDR`` instruction.; 2. The content of a vector register is t",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BigEndianNEON.rst:2892,perform,performing,2892,interpreter/llvm-project/llvm/docs/BigEndianNEON.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BigEndianNEON.rst,2,"['load', 'perform']","['load', 'performing']"
Performance," of parallelism can; be reduced to ``N`` via:. - gold:; ``-Wl,-plugin-opt,jobs=N``; - ld64:; ``-Wl,-mllvm,-threads=N``; - ld.lld, ld64.lld:; ``-Wl,--thinlto-jobs=N``; - lld-link:; ``/opt:lldltojobs=N``. Other possible values for ``N`` are:. - 0:; Use one thread per physical core (default); - 1:; Use a single thread only (disable multi-threading); - all:; Use one thread per logical core (uses all hyper-threads). Incremental; -----------; .. _incremental:. ThinLTO supports fast incremental builds through the use of a cache,; which currently must be enabled through a linker option. - gold (as of LLVM 4.0):; ``-Wl,-plugin-opt,cache-dir=/path/to/cache``; - ld64 (supported since clang 3.9 and Xcode 8) and Mach-O ld64.lld (as of LLVM; 15.0):; ``-Wl,-cache_path_lto,/path/to/cache``; - ELF ld.lld (as of LLVM 5.0):; ``-Wl,--thinlto-cache-dir=/path/to/cache``; - COFF lld-link (as of LLVM 6.0):; ``/lldltocache:/path/to/cache``. Cache Pruning; -------------. To help keep the size of the cache under control, ThinLTO supports cache; pruning. Cache pruning is supported with gold, ld64, and lld, but currently only; gold and lld allow you to control the policy with a policy string. The cache; policy must be specified with a linker option. - gold (as of LLVM 6.0):; ``-Wl,-plugin-opt,cache-policy=POLICY``; - ELF ld.lld (as of LLVM 5.0), Mach-O ld64.lld (as of LLVM 15.0):; ``-Wl,--thinlto-cache-policy=POLICY``; - COFF lld-link (as of LLVM 6.0):; ``/lldltocachepolicy:POLICY``. A policy string is a series of key-value pairs separated by ``:`` characters.; Possible key-value pairs are:. - ``cache_size=X%``: The maximum size for the cache directory is ``X`` percent; of the available space on the disk. Set to 100 to indicate no limit,; 50 to indicate that the cache size will not be left over half the available; disk space. A value over 100 is invalid. A value of 0 disables the percentage; size-based pruning. The default is 75%. - ``cache_size_bytes=X``, ``cache_size_bytes=Xk``, ``cache_size_b",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ThinLTO.rst:5102,cache,cache,5102,interpreter/llvm-project/clang/docs/ThinLTO.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ThinLTO.rst,2,['cache'],['cache']
Performance," of restrictions placed on precompiled; headers. In particular, there can only be one precompiled header and it must; be included at the beginning of the translation unit. The extensions to the; AST file format required for modules are discussed in the section on; :ref:`modules <pchinternals-modules>`. Clang's AST files are designed with a compact on-disk representation, which; minimizes both creation time and the time required to initially load the AST; file. The AST file itself contains a serialized representation of Clang's; abstract syntax trees and supporting data structures, stored using the same; compressed bitstream as `LLVM's bitcode file format; <https://llvm.org/docs/BitCodeFormat.html>`_. Clang's AST files are loaded ""lazily"" from disk. When an AST file is initially; loaded, Clang reads only a small amount of data from the AST file to establish; where certain important data structures are stored. The amount of data read in; this initial load is independent of the size of the AST file, such that a; larger AST file does not lead to longer AST load times. The actual header data; in the AST file --- macros, functions, variables, types, etc. --- is loaded; only when it is referenced from the user's code, at which point only that; entity (and those entities it depends on) are deserialized from the AST file.; With this approach, the cost of using an AST file for a translation unit is; proportional to the amount of code actually used from the AST file, rather than; being proportional to the size of the AST file itself. When given the `-print-stats` option, Clang produces statistics; describing how much of the AST file was actually loaded from disk. For a; simple ""Hello, World!"" program that includes the Apple ``Cocoa.h`` header; (which is built as a precompiled header), this option illustrates how little of; the actual precompiled header is required:. .. code-block:: none. *** AST File Statistics:; 895/39981 source location entries read (2.238563%); 19/15315 type",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/PCHInternals.rst:3642,load,load,3642,interpreter/llvm-project/clang/docs/PCHInternals.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/PCHInternals.rst,2,['load'],['load']
Performance," of target features, that affect ISA generation. It is target; specific if a target ID is supported, or if the target triple alone is; sufficient to specify the ISA generation. It is used with the ``-mcpu=<target-id>`` and ``--offload-arch=<target-id>``; Clang compilation options to specify the kind of code to generate. It is also used as part of the bundle entry ID to identify the code object. See; :ref:`clang-bundle-entry-id`. Target ID syntax is defined by the following BNF syntax:. .. code::. <target-id> ::== <processor> ( "":"" <target-feature> ( ""+"" | ""-"" ) )*. Where:. **processor**; Is a the target specific processor or any alternative processor name. **target-feature**; Is a target feature name that is supported by the processor. Each target; feature must appear at most once in a target ID and can have one of three; values:. *Any*; Specified by omitting the target feature from the target ID.; A code object compiled with a target ID specifying the default; value of a target feature can be loaded and executed on a processor; configured with the target feature on or off. *On*; Specified by ``+``, indicating the target feature is enabled. A code; object compiled with a target ID specifying a target feature on; can only be loaded on a processor configured with the target feature on. *Off*; specified by ``-``, indicating the target feature is disabled. A code; object compiled with a target ID specifying a target feature off; can only be loaded on a processor configured with the target feature off. .. _compatibility-target-id:. Compatibility Rules for Target ID; ---------------------------------. A code object compiled for a Target ID is considered compatible for a; target, if:. * Their processor is same.; * Their feature set is compatible as defined above. There are two forms of target ID:. *Non-Canonical Form*; The non-canonical form is used as the input to user commands to allow the user; greater convenience. It allows both the primary and alternative processor na",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangOffloadBundler.rst:12067,load,loaded,12067,interpreter/llvm-project/clang/docs/ClangOffloadBundler.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangOffloadBundler.rst,1,['load'],['loaded']
Performance," of the available space on the disk. Set to 100 to indicate no limit,; 50 to indicate that the cache size will not be left over half the available; disk space. A value over 100 is invalid. A value of 0 disables the percentage; size-based pruning. The default is 75%. - ``cache_size_bytes=X``, ``cache_size_bytes=Xk``, ``cache_size_bytes=Xm``,; ``cache_size_bytes=Xg``:; Sets the maximum size for the cache directory to ``X`` bytes (or KB, MB,; GB respectively). A value over the amount of available space on the disk; will be reduced to the amount of available space. A value of 0 disables; the byte size-based pruning. The default is no byte size-based pruning. Note that ThinLTO will apply both size-based pruning policies simultaneously,; and changing one does not affect the other. For example, a policy of; ``cache_size_bytes=1g`` on its own will cause both the 1GB and default 75%; policies to be applied unless the default ``cache_size`` is overridden. - ``cache_size_files=X``:; Set the maximum number of files in the cache directory. Set to 0 to indicate; no limit. The default is 1000000 files. - ``prune_after=Xs``, ``prune_after=Xm``, ``prune_after=Xh``: Sets the; expiration time for cache files to ``X`` seconds (or minutes, hours; respectively). When a file hasn't been accessed for ``prune_after`` seconds,; it is removed from the cache. A value of 0 disables the expiration-based; pruning. The default is 1 week. - ``prune_interval=Xs``, ``prune_interval=Xm``, ``prune_interval=Xh``:; Sets the pruning interval to ``X`` seconds (or minutes, hours; respectively). This is intended to be used to avoid scanning the directory; too often. It does not impact the decision of which files to prune. A; value of 0 forces the scan to occur. The default is every 20 minutes. Clang Bootstrap; ---------------. To `bootstrap clang/LLVM <https://llvm.org/docs/AdvancedBuilds.html#bootstrap-builds>`_; with ThinLTO, follow these steps:. 1. The host compiler_ must be a version of clang that support",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ThinLTO.rst:6808,cache,cache,6808,interpreter/llvm-project/clang/docs/ThinLTO.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ThinLTO.rst,1,['cache'],['cache']
Performance," of the local variable `a`.; The only information remained is the value of a 32 bit integer. In this simple; case, it seems to be pretty clear that `__int_32_0` represents `a`. However, it; is not true. An important note with optimization is that the value of a variable may not; properly express the intended value in the source code. For example:. .. code-block:: c++. static task coro_task(int v) {; int a = v;; co_await await_counter{};; a++; // __int_32_0 is 43 here; std::cout << a << ""\n"";; a++; // __int_32_0 is still 43 here; std::cout << a << ""\n"";; a++; // __int_32_0 is still 43 here!; std::cout << a << ""\n"";; co_await await_counter{};; a++; // __int_32_0 is still 43 here!!; std::cout << a << ""\n"";; a++; // Why is __int_32_0 still 43 here?; std::cout << a << ""\n"";; }. When debugging step-by-step, the value of `__int_32_0` seemingly does not; change, despite being frequently incremented, and instead is always `43`.; While this might be surprising, this is a result of the optimizer recognizing; that it can eliminate most of the load/store operations. The above code gets; optimized to the equivalent of:. .. code-block:: c++. static task coro_task(int v) {; store v to __int_32_0 in the frame; co_await await_counter{};; a = load __int_32_0; std::cout << a+1 << ""\n"";; std::cout << a+2 << ""\n"";; std::cout << a+3 << ""\n"";; co_await await_counter{};; a = load __int_32_0; std::cout << a+4 << ""\n"";; std::cout << a+5 << ""\n"";; }. It should now be obvious why the value of `__int_32_0` remains unchanged; throughout the function. It is important to recognize that `__int_32_0`; does not directly correspond to `a`, but is instead a variable generated; to assist the compiler in code generation. The variables in an optimized; coroutine frame should not be thought of as directly representing the; variables in the C++ source. Get the suspended points; ========================. An important requirement for debugging coroutines is to understand suspended; points, which are where the c",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DebuggingCoroutines.rst:9599,optimiz,optimizer,9599,interpreter/llvm-project/clang/docs/DebuggingCoroutines.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DebuggingCoroutines.rst,2,"['load', 'optimiz']","['load', 'optimizer']"
Performance," of the memory after the operation. .. code-block:: llvm. define void @foo() {; entry:; %p1 = alloca i8; %p2 = alloca i8; %p3 = alloca i8; ; 1 = MemoryDef(liveOnEntry); store i8 0, ptr %p3; br label %while.cond. while.cond:; ; 6 = MemoryPhi({entry,1},{if.end,4}); br i1 undef, label %if.then, label %if.else. if.then:; ; 2 = MemoryDef(6); store i8 0, ptr %p1; br label %if.end. if.else:; ; 3 = MemoryDef(6); store i8 1, ptr %p2; br label %if.end. if.end:; ; 5 = MemoryPhi({if.then,2},{if.else,3}); ; MemoryUse(5); %1 = load i8, ptr %p1; ; 4 = MemoryDef(5); store i8 2, ptr %p2; ; MemoryUse(1); %2 = load i8, ptr %p3; br label %while.cond; }. The ``MemorySSA`` IR is shown in comments that precede the instructions they map; to (if such an instruction exists). For example, ``1 = MemoryDef(liveOnEntry)``; is a ``MemoryAccess`` (specifically, a ``MemoryDef``), and it describes the LLVM; instruction ``store i8 0, ptr %p3``. Other places in ``MemorySSA`` refer to this; particular ``MemoryDef`` as ``1`` (much like how one can refer to ``load i8, ptr; %p1`` in LLVM with ``%1``). Again, ``MemoryPhi``\ s don't correspond to any LLVM; Instruction, so the line directly below a ``MemoryPhi`` isn't special. Going from the top down:. - ``6 = MemoryPhi({entry,1},{if.end,4})`` notes that, when entering; ``while.cond``, the reaching definition for it is either ``1`` or ``4``. This; ``MemoryPhi`` is referred to in the textual IR by the number ``6``.; - ``2 = MemoryDef(6)`` notes that ``store i8 0, ptr %p1`` is a definition,; and its reaching definition before it is ``6``, or the ``MemoryPhi`` after; ``while.cond``. (See the `Use and Def optimization`_ and `Precision`_; sections below for why this ``MemoryDef`` isn't linked to a separate,; disambiguated ``MemoryPhi``.); - ``3 = MemoryDef(6)`` notes that ``store i8 0, ptr %p2`` is a definition; its; reaching definition is also ``6``.; - ``5 = MemoryPhi({if.then,2},{if.else,3})`` notes that the clobber before; this block could either be ``2`` or `",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MemorySSA.rst:6606,load,load,6606,interpreter/llvm-project/llvm/docs/MemorySSA.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MemorySSA.rst,1,['load'],['load']
Performance," of type `SHT_NOTE`, if the name; starts with "".note"". Otherwise, it will have type `SHT_PROGBITS`. Can be; specified multiple times to add multiple sections. For MachO objects, ``<section>`` must be formatted as; ``<segment name>,<section name>``. .. option:: --binary-architecture <arch>, -B. Ignored for compatibility. .. option:: --disable-deterministic-archives, -U. Use real values for UIDs, GIDs and timestamps when updating archive member; headers. .. option:: --discard-all, -x. Remove most local symbols from the output. Different file formats may limit; this to a subset of the local symbols. For example, file and section symbols in; ELF objects will not be discarded. Additionally, remove all debug sections. .. option:: --dump-section <section>=<file>. Dump the contents of section ``<section>`` into the file ``<file>``. Can be; specified multiple times to dump multiple sections to different files.; ``<file>`` is unrelated to the input and output files provided to; :program:`llvm-objcopy` and as such the normal copying and editing; operations will still be performed. No operations are performed on the sections; prior to dumping them. For MachO objects, ``<section>`` must be formatted as; ``<segment name>,<section name>``. .. option:: --enable-deterministic-archives, -D. Enable deterministic mode when copying archives, i.e. use 0 for archive member; header UIDs, GIDs and timestamp fields. On by default. .. option:: --help, -h. Print a summary of command line options. .. option:: --only-keep-debug. Produce a debug file as the output that only preserves contents of sections; useful for debugging purposes. For ELF objects, this removes the contents of `SHF_ALLOC` sections that are not; `SHT_NOTE` by making them `SHT_NOBITS` and shrinking the program headers where; possible. .. option:: --only-section <section>, -j. Remove all sections from the output, except for sections named ``<section>``.; Can be specified multiple times to keep multiple sections. For MachO object",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objcopy.rst:2493,perform,performed,2493,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objcopy.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objcopy.rst,1,['perform'],['performed']
Performance," of zero. This has been implemented by Jeromy Tompkins <Tompkins@nscl.msu.edu>. ## Geometry Libraries; A new module geom/vecgeom was introduced to give transparent access to VecGeom ; solid primitives. VecGeom is a high performance geometry package (link) providing ; SIMD vectorization for the CPU-intensive geometry algorithms used for geometry; navigation. The module creates a new library libConverterVG.so depending on the; VecGeom main library and loaded using the ROOT plug-in mechanism. The main functionality provided by the new vecgeom module is to make a conversion ; in memory of all the shapes in a loaded TGeo geometry into a special adapter; shape TGeoVGShape, redirecting all navigation calls to the corresponding VecGeom ; solid. The library loading and geometry conversion can be done with a single call ; `TVirtualGeoConverter::Instance()->ConvertGeometry()`; . After the conversion is done, all existing TGeo functionality is available as for; a native geometry, only that most of the converted solids provide better navigation ; performance, despite the overhead introduced by the new adapter shape. Prerequisites: installation of VecGeom. ; The installation instructions are available at <http://geant.web.cern.ch/content/installation>; Due to the fact that VecGeom provides for the moment static libraries ; and depends on ROOT, is is advised to compile first ROOT without VecGeom support, ; then compile VecGeom against this ROOT version, then re-configure ROOT to enable ; VecGeom and Vc support, using the flags -Dvc=ON -Dvecgeom=on; ; This has been implemented by Mihaela Gheata <Mihaela.Gheata@cern.ch>. ## Database Libraries. * Fix `TPgSQLStatement::SetBinary` to actually handle binary data (previous limited to ascii). ## Networking Libraries. * When seeing too many requested ranges, Apache 2.4 now simply sends the whole file; (MaxRanges configuration parameter). TWebFile can handle this case now, but this can; trigger multiple transmissions of the full file. TWebF",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:23994,perform,performance,23994,README/ReleaseNotes/v608/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md,1,['perform'],['performance']
Performance," older than the local load; atomic value being; acquired. 3. buffer_gl0_inv. - If CU wavefront execution; mode, omit.; - If OpenCL, omit.; - Ensures that; following; loads will not see; stale data. load atomic acquire - workgroup - generic 1. flat_load glc=1. - If CU wavefront execution; mode, omit glc=1. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If CU wavefront execution; mode, omit vmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Must happen before; the following; buffer_gl0_inv and any; following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic value being; acquired. 3. buffer_gl0_inv. - If CU wavefront execution; mode, omit.; - Ensures that; following; loads will not see; stale data. load atomic acquire - agent - global 1. buffer/global_load; - system glc=1 dlc=1. - If GFX11, omit dlc=1. 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_gl*_inv.; - Ensures the load; has completed; before invalidating; the caches. 3. buffer_gl0_inv;; buffer_gl1_inv. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale global data. load atomic acquire - agent - generic 1. flat_load glc=1 dlc=1; - system; - If GFX11, omit dlc=1. 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If OpenCL omit; lgkmcnt(0).; - Must happen before; following; buffer_gl*_invl.; - Ensures the flat_load; has completed; before invalidating; the caches. 3. buffer_gl0_inv;; buffer_gl1_inv. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - singlethread - global 1. buffer/global/ds/flat_atomic; - wavefront - local; - generic; atomicrmw acquire - workgroup - global 1. buffer/global_atomic; 2. s_waitcnt vm/vscnt(0). - If CU wavefront execution; mode, omit.; - Use vmcnt(0) if atomic with; return and vscnt(0) if; atomic with",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:347927,load,load,347927,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,"['cache', 'load']","['caches', 'load']"
Performance," omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global and L2 writeback; have completed before; performing the; atomicrmw that is; being released. 3. flat_atomic; 4. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; caches. 5. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. fence acq_rel - singlethread *none* *none*; - wavefront; fence acq_rel - workgroup *none* 1. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - If OpenCL and; address space is; local, omit; vmcnt(0).; - However,; since LLVM; currently has no; address space on; the fence need to; conservatively; always generate; (see comment for; previous fence).; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Must happen before; any following; gl",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:273961,load,load,273961,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],['load']
Performance," on LLVM build using CMake.; This document aims to provide a brief overview of CMake for developers modifying; LLVM projects or building their own projects on top of LLVM. The official CMake language references is available in the cmake-language; manpage and `cmake-language online documentation; <https://cmake.org/cmake/help/v3.4/manual/cmake-language.7.html>`_. 10,000 ft View; ==============. CMake is a tool that reads script files in its own language that describe how a; software project builds. As CMake evaluates the scripts it constructs an; internal representation of the software project. Once the scripts have been; fully processed, if there are no errors, CMake will generate build files to; actually build the project. CMake supports generating build files for a variety; of command line build tools as well as for popular IDEs. When a user runs CMake it performs a variety of checks similar to how autoconf; worked historically. During the checks and the evaluation of the build; description scripts CMake caches values into the CMakeCache. This is useful; because it allows the build system to skip long-running checks during; incremental development. CMake caching also has some drawbacks, but that will be; discussed later. Scripting Overview; ==================. CMake's scripting language has a very simple grammar. Every language construct; is a command that matches the pattern _name_(_args_). Commands come in three; primary types: language-defined (commands implemented in C++ in CMake), defined; functions, and defined macros. The CMake distribution also contains a suite of; CMake modules that contain definitions for useful functionality. The example below is the full CMake build for building a C++ ""Hello World""; program. The example uses only CMake language-defined functions. .. code-block:: cmake. cmake_minimum_required(VERSION 3.20.0); project(HelloWorld); add_executable(HelloWorld HelloWorld.cpp). The CMake language provides control flow constructs in the form o",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst:1427,cache,caches,1427,interpreter/llvm-project/llvm/docs/CMakePrimer.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst,1,['cache'],['caches']
Performance," on each agent each sharing separate L2; caches.; * The L2 cache has independent channels to service disjoint ranges of virtual; addresses.; * Each CU has a separate request queue per channel for its associated L2.; Therefore, the vector and scalar memory operations performed by wavefronts; executing with different L1 caches and the same L2 cache can be reordered; relative to each other.; * A ``s_waitcnt vmcnt(0)`` is required to ensure synchronization between; vector memory operations of different CUs. It ensures a previous vector; memory operation has completed before executing a subsequent vector memory; or LDS operation and so can be used to meet the requirements of acquire and; release.; * An L2 cache can be kept coherent with other L2 caches by using the MTYPE RW; (read-write) for memory local to the L2, and MTYPE NC (non-coherent) with; the PTE C-bit set for memory not local to the L2. * Any local memory cache lines will be automatically invalidated by writes; from CUs associated with other L2 caches, or writes from the CPU, due to; the cache probe caused by the PTE C-bit.; * XGMI accesses from the CPU to local memory may be cached on the CPU.; Subsequent access from the GPU will automatically invalidate or writeback; the CPU cache due to the L2 probe filter.; * To ensure coherence of local memory writes of CUs with different L1 caches; in the same agent a ``buffer_wbl2`` is required. It does nothing if the; agent is configured to have a single L2, or will writeback dirty L2 cache; lines if configured to have multiple L2 caches.; * To ensure coherence of local memory writes of CUs in different agents a; ``buffer_wbl2 sc1`` is required. It will writeback dirty L2 cache lines.; * To ensure coherence of local memory reads of CUs with different L1 caches; in the same agent a ``buffer_inv sc1`` is required. It does nothing if the; agent is configured to have a single L2, or will invalidate non-local L2; cache lines if configured to have multiple L2 caches.; * To en",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:288410,cache,cache,288410,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,3,['cache'],"['cache', 'caches']"
Performance," on local; values. These casts are required in order to transfer objects in and out of ARC; control; see the rationale in the section on :ref:`conversion of retainable; object pointers <arc.objects.restrictions.conversion>`. Using a ``__bridge_retained`` or ``__bridge_transfer`` cast purely to convince; ARC to emit an unbalanced retain or release, respectively, is poor form. .. _arc.objects.restrictions:. Restrictions; ------------. .. _arc.objects.restrictions.conversion:. Conversion of retainable object pointers; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. In general, a program which attempts to implicitly or explicitly convert a; value of retainable object pointer type to any non-retainable type, or; vice-versa, is ill-formed. For example, an Objective-C object pointer shall; not be converted to ``void*``. As an exception, cast to ``intptr_t`` is; allowed because such casts are not transferring ownership. The :ref:`bridged; casts <arc.objects.operands.casts>` may be used to perform these conversions; where necessary. .. admonition:: Rationale. We cannot ensure the correct management of the lifetime of objects if they; may be freely passed around as unmanaged types. The bridged casts are; provided so that the programmer may explicitly describe whether the cast; transfers control into or out of ARC. However, the following exceptions apply. .. _arc.objects.restrictions.conversion.with.known.semantics:. Conversion to retainable object pointer type of expressions with known semantics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. :when-revised:`[beginning Apple 4.0, LLVM 3.1]`; :revision:`These exceptions have been greatly expanded; they previously applied; only to a much-reduced subset which is difficult to categorize but which; included null pointers, message sends (under the given rules), and the various; global constants.`. An unbridged conversion to a retainable object pointer type from a type other; than a retainable object poin",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst:24856,perform,perform,24856,interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,1,['perform'],['perform']
Performance," on the pipeline (similar to -verify-each).; $ opt -debugify-each -O2 sample.ll. In order for ``check-debugify`` to work, the DI must be coming from; ``debugify``. Thus, modules with existing DI will be skipped. ``debugify`` can be used to test a backend, e.g:. .. code-block:: bash. $ opt -debugify < sample.ll | llc -o -. There is also a MIR-level debugify pass that can be run before each backend; pass, see:; :ref:`Mutation testing for MIR-level transformations<MIRDebugify>`. ``debugify`` in regression tests; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The output of the ``debugify`` pass must be stable enough to use in regression; tests. Changes to this pass are not allowed to break existing tests. .. note::. Regression tests must be robust. Avoid hardcoding line/variable numbers in; check lines. In cases where this can't be avoided (say, if a test wouldn't; be precise enough), moving the test to its own file is preferred. .. _MIRDebugify:. Test original debug info preservation in optimizations; ------------------------------------------------------. In addition to automatically generating debug info, the checks provided by; the ``debugify`` utility pass can also be used to test the preservation of; pre-existing debug info metadata. It could be run as follows:. .. code-block:: bash. # Run the pass by checking original Debug Info preservation.; $ opt -verify-debuginfo-preserve -pass-to-test sample.ll. # Check the preservation of original Debug Info after each pass.; $ opt -verify-each-debuginfo-preserve -O2 sample.ll. Limit number of observed functions to speed up the analysis:. .. code-block:: bash. # Test up to 100 functions (per compile unit) per pass.; $ opt -verify-each-debuginfo-preserve -O2 -debugify-func-limit=100 sample.ll. Please do note that running ``-verify-each-debuginfo-preserve`` on big projects; could be heavily time consuming. Therefore, we suggest using; ``-debugify-func-limit`` with a suitable limit number to prevent extremely long; builds. Furthermore, the",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToUpdateDebugInfo.rst:13658,optimiz,optimizations,13658,interpreter/llvm-project/llvm/docs/HowToUpdateDebugInfo.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToUpdateDebugInfo.rst,1,['optimiz'],['optimizations']
Performance," on; some versions of library, and absent in others. One cannot easily; express this with a single module map file in the library:. .. parsed-literal::. module Foo {; header ""Foo.h""; ...; }. module Foo_Private {; header ""Foo_Private.h""; ...; }. because the header ``Foo_Private.h`` won't always be available. The; module map file could be customized based on whether; ``Foo_Private.h`` is available or not, but doing so requires custom; build machinery. Private module map files, which are named ``module.private.modulemap``; (or, for backward compatibility, ``module_private.map``), allow one to; augment the primary module map file with an additional modules. For; example, we would split the module map file above into two module map; files:. .. code-block:: c. /* module.modulemap */; module Foo {; header ""Foo.h""; }. /* module.private.modulemap */; module Foo_Private {; header ""Foo_Private.h""; }. When a ``module.private.modulemap`` file is found alongside a; ``module.modulemap`` file, it is loaded after the ``module.modulemap``; file. In our example library, the ``module.private.modulemap`` file; would be available when ``Foo_Private.h`` is available, making it; easier to split a library's public and private APIs along header; boundaries. When writing a private module as part of a *framework*, it's recommended that:. * Headers for this module are present in the ``PrivateHeaders`` framework; subdirectory.; * The private module is defined as a *top level module* with the name of the; public framework prefixed, like ``Foo_Private`` above. Clang has extra logic; to work with this naming, using ``FooPrivate`` or ``Foo.Private`` (submodule); trigger warnings and might not work as expected. Modularizing a Platform; =======================; To get any benefit out of modules, one needs to introduce module maps for software libraries starting at the bottom of the stack. This typically means introducing a module map covering the operating system's headers and the C standard library h",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Modules.rst:51231,load,loaded,51231,interpreter/llvm-project/clang/docs/Modules.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Modules.rst,1,['load'],['loaded']
Performance," one large repository; (""the monorepo""). It may take a while to download!. .. code:: console. $ git clone https://github.com/llvm/llvm-project.git. This will create a directory ""llvm-project"" with all of the source; code. (Checking out anonymously is OK - pushing commits uses a different; mechanism, as we'll see later.). Configure your workspace; ------------------------. Before we can build the code, we must configure exactly how to build it; by running CMake. CMake combines information from three sources:. - explicit choices you make (is this a debug build?). - settings detected from your system (where are libraries installed?). - project structure (which files are part of 'clang'?). First, create a directory to build in. Usually, this is; llvm-project/build. .. code:: console. $ mkdir llvm-project/build; $ cd llvm-project/build. Now, run CMake:. .. code:: console. $ cmake -G Ninja ../llvm -DCMAKE_BUILD_TYPE=Release -DLLVM_ENABLE_PROJECTS=clang. If all goes well, you'll see a lot of ""performing test"" lines, and; finally:. .. code:: console. Configuring done; Generating done; Build files have been written to: /path/llvm-project/build. And you should see a build.ninja file. Let's break down that last command a little:. - **-G Ninja**: we're going to use ninja to build; please create; build.ninja. - **../llvm**: this is the path to the source of the ""main"" LLVM; project. - The two **-D** flags set CMake variables, which override; CMake/project defaults:. - **CMAKE_BUILD_TYPE=Release**: build in optimized mode, which is; (surprisingly) the fastest option. If you want to run under a debugger, you should use the default Debug; (which is totally unoptimized, and will lead to >10x slower test; runs) or RelWithDebInfo which is a halfway point.; **CMAKE_BUILD_TYPE** affects code generation only, assertions are; on by default regardless! **LLVM_ENABLE_ASSERTIONS=Off** disables; them. - **LLVM_ENABLE_PROJECTS=clang**: this lists the LLVM subprojects; you are interested in bui",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MyFirstTypoFix.rst:2951,perform,performing,2951,interpreter/llvm-project/llvm/docs/MyFirstTypoFix.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MyFirstTypoFix.rst,1,['perform'],['performing']
Performance," one. So, if you need to; place a ``MemoryDef`` in ``if.then`` or ``if.else``, you'll need to also create; a ``MemoryPhi`` for ``if.end``. If it turns out that this is a large burden, we can just place ``MemoryPhi``\ s; everywhere. Because we have Walkers that are capable of optimizing above said; phis, doing so shouldn't prohibit optimizations. Non-Goals; ---------. ``MemorySSA`` is meant to reason about the relation between memory; operations, and enable quicker querying.; It isn't meant to be the single source of truth for all potential memory-related; optimizations. Specifically, care must be taken when trying to use ``MemorySSA``; to reason about atomic or volatile operations, as in:. .. code-block:: llvm. define i8 @foo(ptr %a) {; entry:; br i1 undef, label %if.then, label %if.end. if.then:; ; 1 = MemoryDef(liveOnEntry); %0 = load volatile i8, ptr %a; br label %if.end. if.end:; %av = phi i8 [0, %entry], [%0, %if.then]; ret i8 %av; }. Going solely by ``MemorySSA``'s analysis, hoisting the ``load`` to ``entry`` may; seem legal. Because it's a volatile load, though, it's not. Design tradeoffs; ----------------. Precision; ^^^^^^^^^. ``MemorySSA`` in LLVM deliberately trades off precision for speed.; Let us think about memory variables as if they were disjoint partitions of the; memory (that is, if you have one variable, as above, it represents the entire; memory, and if you have multiple variables, each one represents some; disjoint portion of the memory). First, because alias analysis results conflict with each other, and; each result may be what an analysis wants (IE; TBAA may say no-alias, and something else may say must-alias), it is; not possible to partition the memory the way every optimization wants.; Second, some alias analysis results are not transitive (IE A noalias B,; and B noalias C, does not mean A noalias C), so it is not possible to; come up with a precise partitioning in all cases without variables to; represent every pair of possible aliases. T",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MemorySSA.rst:16481,load,load,16481,interpreter/llvm-project/llvm/docs/MemorySSA.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MemorySSA.rst,1,['load'],['load']
Performance," only one multi-line lambda in a statement, and there are no expressions; lexically after it in the statement, drop the indent to the standard two space; indent for a block of code, as if it were an if-block opened by the preceding; part of the statement:. .. code-block:: c++. std::sort(foo.begin(), foo.end(), [&](Foo a, Foo b) -> bool {; if (a.blah < b.blah); return true;; if (a.baz < b.baz); return true;; return a.bam < b.bam;; });. To take best advantage of this formatting, if you are designing an API which; accepts a continuation or single callable argument (be it a function object, or; a ``std::function``), it should be the last argument if at all possible. If there are multiple multi-line lambdas in a statement, or additional; parameters after the lambda, indent the block two spaces from the indent of the; ``[]``:. .. code-block:: c++. dyn_switch(V->stripPointerCasts(),; [] (PHINode *PN) {; // process phis...; },; [] (SelectInst *SI) {; // process selects...; },; [] (LoadInst *LI) {; // process loads...; },; [] (AllocaInst *AI) {; // process allocas...; });. Braced Initializer Lists; """""""""""""""""""""""""""""""""""""""""""""""". Starting from C++11, there are significantly more uses of braced lists to; perform initialization. For example, they can be used to construct aggregate; temporaries in expressions. They now have a natural way of ending up nested; within each other and within function calls in order to build up aggregates; (such as option structs) from local variables. The historically common formatting of braced initialization of aggregate; variables does not mix cleanly with deep nesting, general expression contexts,; function arguments, and lambdas. We suggest new code use a simple rule for; formatting braced initialization lists: act as-if the braces were parentheses; in a function call. The formatting rules exactly match those already well; understood for formatting nested function calls. Examples:. .. code-block:: c++. foo({a, b, c}, {1, 2, 3});. llvm::Constant *Mask",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:20004,load,loads,20004,interpreter/llvm-project/llvm/docs/CodingStandards.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst,1,['load'],['loads']
Performance," optimal number) do.                     ; proof->SetParameter(""PROOF_UseMergers"", S). The new functionality can be tested in tutorials by adding the argument; 'submergers' to runProof, e.g. .        ;        ;      root [0] .L; tutorials/proof/runProof.C+ ;        ;        ;      root [1]; runProof(""simple(nhist=10000,submergers)"") . (see the top of tutorials/proof/runProof.C for additional options). A test for the submerger functionality has also been added to; test/stressProof.cxx .; In PROOF-Lite, add the possibility for the administrator; to control the number of workers. This is done using; the rootrc variable ProofLite.MaxWorkers, which is read out of; /etc/system.rootrc and cannot be overwritten by users. Setting the; value to 0 disables PROOF-Lite. Improvements. TFileMerger. A few improvements on the way to make TFileMerger and; hadd totally equivalent:. import from hadd an optimization of key hashing; import from hadd a better way to invoke Merge for; generic objects; add option to merge histograms in one go, instead of; one-by-one as for generic objects (this option is not yet supported by; hadd). TProofOutputFile. Add support for the placeholder <file>; the definition of the outputfile. This allows to have complete URL and; to pass options to TFile::Open. XrdProofd plugin. Add automatically the line 'Path.ForceRemote 1' to the; session rootrc file if the ROOT version is < 5.24/00 ; this acts; as a workaround for the wrong TTreeCache initialization at the; transition between local and remote files fixed in 5.24/00 . Enable mass storage domain settings when working with; TChain's; in multi-master mode. The Mass Storage Domain must be specified as; option in the URL.              ; chain.AddFile(""root:// .....?msd=CERN"").  and the string must match the value specified in defining the; submaster node.; Improved performance monitoring: the 'Rate plot' button; in the dialog box has been renamed 'Performance Plot' and now shows up; to 4 plots as a function of t",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html:3659,optimiz,optimization,3659,proof/doc/v526/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html,2,['optimiz'],['optimization']
Performance," optimistic assumptions made during compilation. The semantics of; ``@llvm.experimental.guard`` is defined in terms of; ``@llvm.experimental.deoptimize`` -- its body is defined to be; equivalent to:. .. code-block:: text. define void @llvm.experimental.guard(i1 %pred, <args...>) {; %realPred = and i1 %pred, undef; br i1 %realPred, label %continue, label %leave [, !make.implicit !{}]. leave:; call void @llvm.experimental.deoptimize(<args...>) [ ""deopt""() ]; ret void. continue:; ret void; }. with the optional ``[, !make.implicit !{}]`` present if and only if it; is present on the call site. For more details on ``!make.implicit``,; see :doc:`FaultMaps`. In words, ``@llvm.experimental.guard`` executes the attached; ``""deopt""`` continuation if (but **not** only if) its first argument; is ``false``. Since the optimizer is allowed to replace the ``undef``; with an arbitrary value, it can optimize guard to fail ""spuriously"",; i.e. without the original condition being false (hence the ""not only; if""); and this allows for ""check widening"" type optimizations. ``@llvm.experimental.guard`` cannot be invoked. After ``@llvm.experimental.guard`` was first added, a more general; formulation was found in ``@llvm.experimental.widenable.condition``.; Support for ``@llvm.experimental.guard`` is slowly being rephrased in; terms of this alternate. '``llvm.experimental.widenable.condition``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i1 @llvm.experimental.widenable.condition(). Overview:; """""""""""""""""". This intrinsic represents a ""widenable condition"" which is; boolean expressions with the following property: whether this; expression is `true` or `false`, the program is correct and; well-defined. Together with :ref:`deoptimization operand bundles <deopt_opbundles>`,; ``@llvm.experimental.widenable.condition`` allows frontends to; express guards or checks on optimistic assumptions made during; compilation and represent them as branch instruc",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:946202,optimiz,optimizations,946202,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['optimiz'],['optimizations']
Performance," option with internal functions to directly adjust their API to; accept the predicate as an argument and return it. This is likely to be; marginally cheaper than embedding into `%rsp` for entering functions. ##### Use `lfence` to guard function transitions. An `lfence` instruction can be used to prevent subsequent loads from; speculatively executing until all prior mispredicted predicates have resolved.; We can use this broader barrier to speculative loads executing between; functions. We emit it in the entry block to handle calls, and prior to each; return. This approach also has the advantage of providing the strongest degree; of mitigation when mixed with unmitigated code by halting all misspeculation; entering a function which is mitigated, regardless of what occurred in the; caller. However, such a mixture is inherently more risky. Whether this kind of; mixture is a sufficient mitigation requires careful analysis. Unfortunately, experimental results indicate that the performance overhead of; this approach is very high for certain patterns of code. A classic example is; any form of recursive evaluation engine. The hot, rapid call and return; sequences exhibit dramatic performance loss when mitigated with `lfence`. This; component alone can regress performance by 2x or more, making it an unpleasant; tradeoff even when only used in a mixture of code. ##### Use an internal TLS location to pass predicate state. We can define a special thread-local value to hold the predicate state between; functions. This avoids direct ABI implications by using a side channel between; callers and callees to communicate the predicate state. It also allows implicit; zero-initialization of the state, which allows non-checked code to be the first; code executed. However, this requires a load from TLS in the entry block, a store to TLS; before every call and every ret, and a load from TLS after every call. As a; consequence it is expected to be substantially more expensive even than usin",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:42004,perform,performance,42004,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,1,['perform'],['performance']
Performance," option:: -fcx-limited-range:. This option enables the naive mathematical formulas for complex division and; multiplication with no NaN checking of results. The default is; ``-fno-cx-limited-range``, but this option is enabled by the ``-ffast-math``; option. .. option:: -fcx-fortran-rules:. This option enables the naive mathematical formulas for complex; multiplication and enables application of Smith's algorithm for complex; division. See SMITH, R. L. Algorithm 116: Complex division. Commun.; ACM 5, 8 (1962). The default is ``-fno-cx-fortran-rules``. .. _floating-point-environment:. Accessing the floating point environment; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; Many targets allow floating point operations to be configured to control things; such as how inexact results should be rounded and how exceptional conditions; should be handled. This configuration is called the floating point environment.; C and C++ restrict access to the floating point environment by default, and the; compiler is allowed to assume that all operations are performed in the default; environment. When code is compiled in this default mode, operations that depend; on the environment (such as floating-point arithmetic and `FLT_ROUNDS`) may have; undefined behavior if the dynamic environment is not the default environment; for; example, `FLT_ROUNDS` may or may not simply return its default value for the target; instead of reading the dynamic environment, and floating-point operations may be; optimized as if the dynamic environment were the default. Similarly, it is undefined; behavior to change the floating point environment in this default mode, for example; by calling the `fesetround` function.; C provides two pragmas to allow code to dynamically modify the floating point environment:. - ``#pragma STDC FENV_ACCESS ON`` allows dynamic changes to the entire floating; point environment. - ``#pragma STDC FENV_ROUND FE_DYNAMIC`` allows dynamic changes to just the floating; point rounding mode. Thi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:69418,perform,performed,69418,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,1,['perform'],['performed']
Performance," optional ``!dereferenceable`` metadata must reference a single metadata; name ``<deref_bytes_node>`` corresponding to a metadata node with one ``i64``; entry.; See ``dereferenceable`` metadata :ref:`dereferenceable <md_dereferenceable>`. The optional ``!dereferenceable_or_null`` metadata must reference a single; metadata name ``<deref_bytes_node>`` corresponding to a metadata node with one; ``i64`` entry.; See ``dereferenceable_or_null`` metadata :ref:`dereferenceable_or_null; <md_dereferenceable_or_null>`. The optional ``!align`` metadata must reference a single metadata name; ``<align_node>`` corresponding to a metadata node with one ``i64`` entry.; The existence of the ``!align`` metadata on the instruction tells the; optimizer that the value loaded is known to be aligned to a boundary specified; by the integer value in the metadata node. The alignment must be a power of 2.; This is analogous to the ''align'' attribute on parameters and return values.; This metadata can only be applied to loads of a pointer type. If the returned; value is not appropriately aligned at runtime, a poison value is returned; instead. The optional ``!noundef`` metadata must reference a single metadata name; ``<empty_node>`` corresponding to a node with no entries. The existence of; ``!noundef`` metadata on the instruction tells the optimizer that the value; loaded is known to be :ref:`well defined <welldefinedvalues>`.; If the value isn't well defined, the behavior is undefined. If the ``!noundef``; metadata is combined with poison-generating metadata like ``!nonnull``,; violation of that metadata constraint will also result in undefined behavior. Semantics:; """""""""""""""""""". The location of memory pointed to is loaded. If the value being loaded; is of scalar type then the number of bytes read does not exceed the; minimum number of bytes needed to hold all bits of the type. For; example, loading an ``i24`` reads at most three bytes. When loading a; value of a type like ``i20`` with a size t",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:417442,load,loads,417442,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['load'],['loads']
Performance," optionally specify a :ref:`linkage type <linkage>`. Either global variable definitions or declarations may have an explicit section; to be placed in and may have an optional explicit alignment specified. If there; is a mismatch between the explicit or inferred section information for the; variable declaration and its definition the resulting behavior is undefined. A variable may be defined as a global ``constant``, which indicates that; the contents of the variable will **never** be modified (enabling better; optimization, allowing the global data to be placed in the read-only; section of an executable, etc). Note that variables that need runtime; initialization cannot be marked ``constant`` as there is a store to the; variable. LLVM explicitly allows *declarations* of global variables to be marked; constant, even if the final definition of the global is not. This; capability can be used to enable slightly better optimization of the; program, but requires the language definition to guarantee that; optimizations based on the 'constantness' are valid for the translation; units that do not include the definition. As SSA values, global variables define pointer values that are in scope; (i.e. they dominate) all basic blocks in the program. Global variables; always define a pointer to their ""content"" type because they describe a; region of memory, and all memory objects in LLVM are accessed through; pointers. Global variables can be marked with ``unnamed_addr`` which indicates; that the address is not significant, only the content. Constants marked; like this can be merged with other constants if they have the same; initializer. Note that a constant with significant address *can* be; merged with a ``unnamed_addr`` constant, the result being a constant; whose address is significant. If the ``local_unnamed_addr`` attribute is given, the address is known to; not be significant within the module. A global variable may be declared to reside in a target-specific; numbered addr",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:31591,optimiz,optimization,31591,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,2,['optimiz'],"['optimization', 'optimizations']"
Performance," or Legal Entity authorized to submit on behalf of; the copyright owner. For the purposes of this definition, ""submitted""; means any form of electronic, verbal, or written communication sent; to the Licensor or its representatives, including but not limited to; communication on electronic mailing lists, source code control systems,; and issue tracking systems that are managed by, or on behalf of, the; Licensor for the purpose of discussing and improving the Work, but; excluding communication that is conspicuously marked or otherwise; designated in writing by the copyright owner as ""Not a Contribution."". ""Contributor"" shall mean Licensor and any individual or Legal Entity; on behalf of whom a Contribution has been received by Licensor and; subsequently incorporated within the Work. 2. Grant of Copyright License. Subject to the terms and conditions of; this License, each Contributor hereby grants to You a perpetual,; worldwide, non-exclusive, no-charge, royalty-free, irrevocable; copyright license to reproduce, prepare Derivative Works of,; publicly display, publicly perform, sublicense, and distribute the; Work and such Derivative Works in Source or Object form. 3. Grant of Patent License. Subject to the terms and conditions of; this License, each Contributor hereby grants to You a perpetual,; worldwide, non-exclusive, no-charge, royalty-free, irrevocable; (except as stated in this section) patent license to make, have made,; use, offer to sell, sell, import, and otherwise transfer the Work,; where such license applies only to those patent claims licensable; by such Contributor that are necessarily infringed by their; Contribution(s) alone or by combination of their Contribution(s); with the Work to which such Contribution(s) was submitted. If You; institute patent litigation against any entity (including a; cross-claim or counterclaim in a lawsuit) alleging that the Work; or a Contribution incorporated within the Work constitutes direct; or contributory patent infrin",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/LICENSE.TXT:3682,perform,perform,3682,interpreter/llvm-project/clang/LICENSE.TXT,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/LICENSE.TXT,5,['perform'],['perform']
Performance," or Twine as a scratch buffer, but then use std::string to persist; the result. .. _ds_set:. Set-Like Containers (std::set, SmallSet, SetVector, etc); --------------------------------------------------------. Set-like containers are useful when you need to canonicalize multiple values; into a single representation. There are several different choices for how to do; this, providing various trade-offs. .. _dss_sortedvectorset:. A sorted 'vector'; ^^^^^^^^^^^^^^^^^. If you intend to insert a lot of elements, then do a lot of queries, a great; approach is to use an std::vector (or other sequential container) with; std::sort+std::unique to remove duplicates. This approach works really well if; your usage pattern has these two distinct phases (insert then query), and can be; coupled with a good choice of :ref:`sequential container <ds_sequential>`. This combination provides the several nice properties: the result data is; contiguous in memory (good for cache locality), has few allocations, is easy to; address (iterators in the final vector are just indices or pointers), and can be; efficiently queried with a standard binary search (e.g.; ``std::lower_bound``; if you want the whole range of elements comparing; equal, use ``std::equal_range``). .. _dss_smallset:. llvm/ADT/SmallSet.h; ^^^^^^^^^^^^^^^^^^^. If you have a set-like data structure that is usually small and whose elements; are reasonably small, a ``SmallSet<Type, N>`` is a good choice. This set has; space for N elements in place (thus, if the set is dynamically smaller than N,; no malloc traffic is required) and accesses them with a simple linear search.; When the set grows beyond N elements, it allocates a more expensive; representation that guarantees efficient access (for most types, it falls back; to :ref:`std::set <dss_set>`, but for pointers it uses something far better,; :ref:`SmallPtrSet <dss_smallptrset>`. The magic of this class is that it handles small sets extremely efficiently, but; gracefully handles",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:77579,cache,cache,77579,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,1,['cache'],['cache']
Performance," or a; :ref:`function attribute <fnattrs>` holds for a certain value at a certain; location. Operand bundles enable assumptions that are either hard or impossible; to represent as a boolean argument of an :ref:`llvm.assume <int_assume>`. An assume operand bundle has the form:. ::. ""<tag>""([ <arguments>] ]). In the case of function or parameter attributes, the operand bundle has the; restricted form:. ::. ""<tag>""([ <holds for value> [, <attribute argument>] ]). * The tag of the operand bundle is usually the name of attribute that can be; assumed to hold. It can also be `ignore`, this tag doesn't contain any; information and should be ignored.; * The first argument if present is the value for which the attribute hold.; * The second argument if present is an argument of the attribute. If there are no arguments the attribute is a property of the call location. For example:. .. code-block:: llvm. call void @llvm.assume(i1 true) [""align""(ptr %val, i32 8)]. allows the optimizer to assume that at location of call to; :ref:`llvm.assume <int_assume>` ``%val`` has an alignment of at least 8. .. code-block:: llvm. call void @llvm.assume(i1 %cond) [""cold""(), ""nonnull""(ptr %val)]. allows the optimizer to assume that the :ref:`llvm.assume <int_assume>`; call location is cold and that ``%val`` may not be null. Just like for the argument of :ref:`llvm.assume <int_assume>`, if any of the; provided guarantees are violated at runtime the behavior is undefined. While attributes expect constant arguments, assume operand bundles may be; provided a dynamic value, for example:. .. code-block:: llvm. call void @llvm.assume(i1 true) [""align""(ptr %val, i32 %align)]. If the operand bundle value violates any requirements on the attribute value,; the behavior is undefined, unless one of the following exceptions applies:. * ``""align""`` operand bundles may specify a non-power-of-two alignment; (including a zero alignment). If this is the case, then the pointer value; must be a null pointer, otherwi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:124256,optimiz,optimizer,124256,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['optimiz'],['optimizer']
Performance," or pointing to a different prebuilt module cache path. For example:. .. code-block:: sh. rm -rf prebuilt ; mkdir prebuilt ; rm -rf prebuilt_a ; mkdir prebuilt_a; clang -cc1 -emit-obj use.c -fmodules -fimplicit-module-maps -fmodules-cache-path=prebuilt -fdisable-module-hash; clang -cc1 -emit-obj use.c -fmodules -fimplicit-module-maps -fmodules-cache-path=prebuilt_a -fdisable-module-hash -DENABLE_A; clang -cc1 -emit-obj use.c -fmodules -fimplicit-module-maps -fprebuilt-module-path=prebuilt; clang -cc1 -emit-obj use.c -fmodules -fimplicit-module-maps -fprebuilt-module-path=prebuilt_a -DENABLE_A. Instead of managing the different module versions manually, we can build implicit modules in a given cache path (using ``-fmodules-cache-path``), and reuse them as prebuilt implicit modules by passing ``-fprebuilt-module-path`` and ``-fprebuilt-implicit-modules``. .. code-block:: sh. rm -rf prebuilt; mkdir prebuilt; clang -cc1 -emit-obj -o use.o use.c -fmodules -fimplicit-module-maps -fmodules-cache-path=prebuilt; clang -cc1 -emit-obj -o use.o use.c -fmodules -fimplicit-module-maps -fmodules-cache-path=prebuilt -DENABLE_A; find prebuilt -name ""*.pcm""; # prebuilt/1AYBIGPM8R2GA/A-3L1K4LUA6O31.pcm; # prebuilt/1AYBIGPM8R2GA/B-3L1K4LUA6O31.pcm; # prebuilt/VH0YZMF1OIRK/A-3L1K4LUA6O31.pcm; # prebuilt/VH0YZMF1OIRK/B-3L1K4LUA6O31.pcm; clang -cc1 -emit-obj -o use.o use.c -fmodules -fimplicit-module-maps -fprebuilt-module-path=prebuilt -fprebuilt-implicit-modules; clang -cc1 -emit-obj -o use.o use.c -fmodules -fimplicit-module-maps -fprebuilt-module-path=prebuilt -fprebuilt-implicit-modules -DENABLE_A. Finally we want to allow implicit modules for configurations that were not prebuilt. When using the clang driver a module cache path is implicitly selected. Using ``-cc1``, we simply add use the ``-fmodules-cache-path`` option. .. code-block:: sh. clang -cc1 -emit-obj -o use.o use.c -fmodules -fimplicit-module-maps -fprebuilt-module-path=prebuilt -fprebuilt-implicit-modules -fmodules-cache",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Modules.rst:22542,cache,cache-path,22542,interpreter/llvm-project/clang/docs/Modules.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Modules.rst,1,['cache'],['cache-path']
Performance," ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Ensures that all; memory operations; to local have; completed before; performing the; following; fence-paired-atomic. fence release - agent *none* 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0). - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - If OpenCL and; address space is; local, omit; vmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate. If; fence had an; address space then; set to address; space of OpenCL; fence flag, or to; generic if both; local and global; flags are; specified.; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; any following store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Ensures that all; memory operations; have; completed before; performing the; following; fence-paired-atomic. **Acquire-Release Atomic**; ------------------------------------------------------------------------------------; atomicrmw acq_rel - singlethread - global 1. buffer/global/ds/flat_atomic; - wavefront - local; - generic; atomicrmw acq_rel - workgroup - global 1. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to local have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global_atomic. atomicrmw acq_rel - workgroup - loc",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:223263,load,load,223263,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],['load']
Performance," other hand, benefit a lot. Every call to a Python member function results in a lookup of that; member function and an association of this method with `'self'`.; Furthermore, a temporary object is created during this process that is; discarded after the method call. In inner loops, it may be worth your; while (up to 30%), to short-cut this process by looking up and binding; the method before the loop, and discarding it afterwards. Here is an; example:. ``` {.cpp}; hpx = TH1F('hpx','px',100,-4,4); hpxFill = hpx.Fill # cache bound method; for i in xrange(25000):; px = gRandom.Gaus(); hpxFill(px) # use bound method: no lookup needed; del hpxFill # done with cached method; ```. Note that if you do not discard the bound method, a reference to the; histogram will remain outstanding, and it will not be deleted when it; should be. It is therefore important to delete the method when you're; done with it. ### Use of Python Functions. It is possible to mix Python functions with ROOT and perform such; operations as plotting and fitting of histograms with them. In all; cases, the procedure consists of instantiating a ROOT **`TF1`**,; **`TF2`**, or **`TF3`** with the Python function and working with that; ROOT object. There are some memory issues, so it is for example not yet; possible to delete a **`TF1`** instance and then create another one with; the same name. In addition, the Python function, once used for; instantiating the **`TF1`**, is never deleted. Instead of a Python function, you can also use callable instances (e.g.,; an instance of a class that has implemented the `__call__` member; function). The signature of the Python callable should provide for one; or two arrays. The first array, which must always be present, shall; contain the `x`, `y`, `z`, and t values for the call. The second array,; which is optional and its size depends on the number given to the; **`TF1`** constructor, contains the values that parameterize the; function. For more details, see the **`TF1`*",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/PythonRuby.md:24983,perform,perform,24983,documentation/users-guide/PythonRuby.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/PythonRuby.md,1,['perform'],['perform']
Performance," other hand, changing the types of; local variables won't have such ABI implications. Hence, ``-fbounds-safety``; considers the outermost pointer types of local variables as non-ABI visible. The; rest of the pointers such as nested pointer types, pointer types of global; variables, struct fields, and function prototypes are considered ABI-visible. All ABI-visible pointers are treated as ``__single`` by default unless annotated; otherwise. This default both preserves ABI and makes these pointers safe by; default. This behavior can be controlled with macros, i.e.,; ``__ptrcheck_abi_assume_*ATTR*()``, to set the default annotation for; ABI-visible pointers to be either ``__single``, ``__bidi_indexable``,; ``__indexable``, or ``__unsafe_indexable``. For instance,; ``__ptrcheck_abi_assume_unsafe_indexable()`` will make all ABI-visible pointers; be ``__unsafe_indexable``. Non-ABI visible pointers — the outermost pointer; types of local variables — are ``__bidi_indexable`` by default, so that these; pointers have the bounds information necessary to perform bounds checks without; the need for a manual annotation. All ``const char`` pointers or any typedefs; equivalent to ``const char`` pointers are ``__null_terminated`` by default. This; means that ``char8_t`` is ``unsigned char`` so ``const char8_t *`` won't be; ``__null_terminated`` by default. Similarly, ``const wchar_t *`` won't be; ``__null_terminated`` by default unless the platform defines it as ``typedef; char wchar_t``. Please note, however, that the programmers can still explicitly; use ``__null_terminated`` in any other pointers, e.g., ``char8_t; *__null_terminated``, ``wchar_t *__null_terminated``, ``int; *__null_terminated``, etc. if they should be treated as ``__null_terminated``.; The same applies to other annotations.; In system headers, the default pointer attribute for ABI-visible pointers is set; to ``__unsafe_indexable`` by default. The ``__ptrcheck_abi_assume_*ATTR*()`` macros are defined as pragmas in ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/BoundsSafety.rst:21881,perform,perform,21881,interpreter/llvm-project/clang/docs/BoundsSafety.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/BoundsSafety.rst,1,['perform'],['perform']
Performance," other words,; convergence regions must be reasonably nested.). .. note::. For brevity, this document uses the term ""convergence region of a token; definition ``D``"" to actually refer to the convergence region of the token; ``T`` defined by ``D``. .. _inferring_noconvergent:. Inferring non-convergence; =========================. When the target or the environment guarantees that threads do not; communicate using convergent operations or that threads never diverge,; the dynamic instances in the program are irrelevant and an optimizer; may remove any occurrence of the ``convergent`` attribute on a; call-site or a function and any explicit ``convergencectrl`` operand; bundle at a call-site. An optimizer may remove the ``convergent`` attribute and any explicit; ``convergencectrl`` operand bundle from a call-site if it can prove; that the execution of this call-site always results in a call to a; non-convergent function. An optimizer may remove the ``convergent`` attribute on a function if it can; prove that the function does not contain a call to; :ref:`llvm.experimental.convergence.entry; <llvm.experimental.convergence.entry>`, or any uncontrolled convergent; operations. Memory Model Non-Interaction; ============================. The fact that an operation is convergent has no effect on how it is treated for; memory model purposes. In particular, an operation that is ``convergent`` and; ``readnone`` does not introduce additional ordering constraints as far as the; memory model is concerned. There is no implied barrier, neither in the memory; barrier sense nor in the control barrier sense of synchronizing the execution; of threads. Informational note: Threads that execute converged dynamic instances do not; necessarily do so at the same time. Other Interactions; ==================. A function can be both ``convergent`` and; ``speculatable``, indicating that the function does not have undefined; behavior and has no effects besides calculating its result, but is still; af",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst:33876,optimiz,optimizer,33876,interpreter/llvm-project/llvm/docs/ConvergentOperations.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst,1,['optimiz'],['optimizer']
Performance," otherwise. Notes for frontends; If a frontend is exposing atomic operations, these are much easier to reason; about for the programmer than other kinds of operations, and using them is; generally a practical performance tradeoff. Notes for optimizers; Optimizers not aware of atomics can treat this like a nothrow call. For; SequentiallyConsistent loads and stores, the same reorderings are allowed as; for Acquire loads and Release stores, except that SequentiallyConsistent; operations may not be reordered. Notes for code generation; SequentiallyConsistent loads minimally require the same barriers as Acquire; operations and SequentiallyConsistent stores require Release; barriers. Additionally, the code generator must enforce ordering between; SequentiallyConsistent stores followed by SequentiallyConsistent loads. This; is usually done by emitting either a full fence before the loads or a full; fence after the stores; which is preferred varies by architecture. Atomics and IR optimization; ===========================. Predicates for optimizer writers to query:. * ``isSimple()``: A load or store which is not volatile or atomic. This is; what, for example, memcpyopt would check for operations it might transform. * ``isUnordered()``: A load or store which is not volatile and at most; Unordered. This would be checked, for example, by LICM before hoisting an; operation. * ``mayReadFromMemory()``/``mayWriteToMemory()``: Existing predicate, but note; that they return true for any operation which is volatile or at least; Monotonic. * ``isStrongerThan`` / ``isAtLeastOrStrongerThan``: These are predicates on; orderings. They can be useful for passes that are aware of atomics, for; example to do DSE across a single atomic access, but not across a; release-acquire pair (see MemoryDependencyAnalysis for an example of this). * Alias analysis: Note that AA will return ModRef for anything Acquire or; Release, and for the address accessed by any Monotonic operation. To support optimizin",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Atomics.rst:15785,optimiz,optimization,15785,interpreter/llvm-project/llvm/docs/Atomics.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Atomics.rst,1,['optimiz'],['optimization']
Performance," out-of-order execution of memory operations, :program:`llvm-mca`; utilizes a simulated load/store unit (LSUnit) to simulate the speculative; execution of loads and stores. Each load (or store) consumes an entry in the load (or store) queue. Users can; specify flags ``-lqueue`` and ``-squeue`` to limit the number of entries in the; load and store queues respectively. The queues are unbounded by default. The LSUnit implements a relaxed consistency model for memory loads and stores.; The rules are:. 1. A younger load is allowed to pass an older load only if there are no; intervening stores or barriers between the two loads.; 2. A younger load is allowed to pass an older store provided that the load does; not alias with the store.; 3. A younger store is not allowed to pass an older store.; 4. A younger store is not allowed to pass an older load. By default, the LSUnit optimistically assumes that loads do not alias; (`-noalias=true`) store operations. Under this assumption, younger loads are; always allowed to pass older stores. Essentially, the LSUnit does not attempt; to run any alias analysis to predict when loads and stores do not alias with; each other. Note that, in the case of write-combining memory, rule 3 could be relaxed to; allow reordering of non-aliasing store operations. That being said, at the; moment, there is no way to further relax the memory model (``-noalias`` is the; only option). Essentially, there is no option to specify a different memory; type (e.g., write-back, write-combining, write-through; etc.) and consequently; to weaken, or strengthen, the memory model. Other limitations are:. * The LSUnit does not know when store-to-load forwarding may occur.; * The LSUnit does not know anything about cache hierarchy and memory types.; * The LSUnit does not know how to identify serializing operations and memory; fences. The LSUnit does not attempt to predict if a load or store hits or misses the L1; cache. It only knows if an instruction ""MayLoad"" and/or ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:40284,load,loads,40284,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,1,['load'],['loads']
Performance," over different functions in a CGSCC or; module. Since passes can ask for a cached analysis result, allowing passes to; trigger outer level analysis computation could result in non-determinism if; concurrency was supported. A related limitation is that outer level IR analyses; that are used must be immutable, or else they could be invalidated by changes to; inner level IR. Outer analyses unused by inner passes can and often will be; invalidated by changes to inner level IR. These invalidations happen after the; inner pass manager finishes, so accessing mutable analyses would give invalid; results. The exception to not being able to access outer level analyses is accessing; function analyses in loop passes. Loop passes often use function analyses such; as the dominator tree. Loop passes inherently require modifying the function the; loop is in, and that includes some function analyses the loop analyses depend; on. This discounts future concurrency over separate loops in a function, but; that's a tradeoff due to how tightly a loop and its function are coupled. To; make sure the function analyses that loop passes use are valid, they are; manually updated in the loop passes to ensure that invalidation is not; necessary. There is a set of common function analyses that loop passes and; analyses have access to which is passed into loop passes as a; ``LoopStandardAnalysisResults`` parameter. Other mutable function analyses are; not accessible from loop passes. As with any caching mechanism, we need some way to tell analysis managers; when results are no longer valid. Much of the analysis manager complexity; comes from trying to invalidate as few analysis results as possible to keep; compile times as low as possible. There are two ways to deal with potentially invalid analysis results. One is; to simply force clear the results. This should generally only be used when; the IR that the result is keyed on becomes invalid. For example, a function; is deleted, or a CGSCC has beco",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/NewPassManager.rst:10875,concurren,concurrency,10875,interpreter/llvm-project/llvm/docs/NewPassManager.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/NewPassManager.rst,1,['concurren'],['concurrency']
Performance," own vendor clones of LLVM and Clang (part of ROOT's trunk); on which it is based. This tool is the easiest way to build Cling for your favorite; platorm and bundle it into an installer. If you want to manually compile Cling; from source, go through the [README] of Cling or the build instructions [here]. [README]:https://github.com/root-project/cling/blob/master/README.md; [here]:https://root.cern/cling/cling_build_instructions/. Below is a list of platforms currently supported by CPT:; * Ubuntu and distros based on Debian - *DEB packages*; * Windows - *NSIS installers*; * Distros based on Red Hat Linux (Fedora/Scientific Linux CERN) - *RPM packages*; * Mac OS X - *Apple Disk Images*; * Virtually any UNIX-like platform which supports Bash - *Tarballs*. ### Requirements; Before using this tool, make sure you have the required packages installed on; your system. Detailed information on what and how to install is provided below,; but the recommended (and much easier) way is to use the following command which; performs the required checks automatically and displays useful suggestions too; specific to your platform.; ```sh; cd tools/packaging/; ./cpt.py --check-requirements; ```; or; ```sh; cd tools/packaging/; ./cpt.py -c; ```; Regardless of the platform and operating system, make sure to call the cpt script; with Python 3.; CPT uses some features and modules which are not a part of older versions of Python.; The same holds true for the versions of GCC/Clang you have on your machine. Older; compilers do not support c++11 features and thus you can expect a build error if you; choose not to update them. All pre-compiled binaries of Python ship with built-in support for SSL. However if; the Python on your system was compiled by you manually, chances are that it doesn't; have SSL support. This is very likely if you had performed a minimal installation; of Scientific Linux CERN which doesn't include OpenSSL development package. In such; a case, you should install ```openssl-",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md:1256,perform,performs,1256,interpreter/cling/tools/packaging/README.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md,1,['perform'],['performs']
Performance," package](Common Vector package). In contrast to CLHEP or; the ROOT physics libraries, `GenVector` provides class templates for; modeling the vectors. The user can control how the vector is internally; represented. This is expressed by a choice of coordinate system, which; is supplied as a template parameter when the vector is constructed.; Furthermore, each coordinate system is itself a template, so that the; user can specify the underlying scalar type. The `GenVector` classes do not inherit from **`TObject`**, therefore; cannot be used as in the case of the physics vector classes in ROOT; collections. In addition, to optimize performances, no virtual destructors are; provided. In the following paragraphs, the main characteristics of; `GenVector` are described. A more detailed description of all the; `GenVector` classes is available also at; <http://seal.cern.ch/documents/mathlib/GenVector.pdf>. ### Main Characteristics. #### Optimal Runtime Performances. We try to minimize any overhead in the run-time performance. We have; deliberately avoided the use of any virtual function and even virtual; destructors in the classes. In addition, as much as possible functions; are defined as inline. For this reason, we have chosen to use template; classes to implement the `GenVector` concepts instead of abstract or; base classes and virtual functions. It is then recommended to avoid; using the `GenVector` classes polymorphically and developing classes; inheriting from them. #### Points and Vector Concept. Mathematically vectors and points are two distinct concepts. They have; different transformations, as vectors only rotate while points rotate; and translate. You can add two vectors but not two points and the; difference between two points is a vector. We then distinguish for the 3; dimensional case, between points and vectors, modeling them with; different classes:. - `ROOT::Math::`**`DisplacementVector2D`** and; `ROOT::Math::`**`DisplacementVector3D`** template classes descri",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/MathLibraries.md:68968,perform,performance,68968,documentation/users-guide/MathLibraries.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/MathLibraries.md,1,['perform'],['performance']
Performance," page is geared towards users of the LLVM CMake build. If you're looking for; information about modifying the LLVM CMake build system you may want to see the; :doc:`CMakePrimer` page. It has a basic overview of the CMake language. .. _Quick start:. Quick start; ===========. We use here the command-line, non-interactive CMake interface. #. `Download <http://www.cmake.org/cmake/resources/software.html>`_ and install; CMake. Version 3.20.0 is the minimum required. #. Open a shell. Your development tools must be reachable from this shell; through the PATH environment variable. #. Create a build directory. Building LLVM in the source; directory is not supported. cd to this directory:. .. code-block:: console. $ mkdir mybuilddir; $ cd mybuilddir. #. Execute this command in the shell replacing `path/to/llvm/source/root` with; the path to the root of your LLVM source tree:. .. code-block:: console. $ cmake path/to/llvm/source/root. CMake will detect your development environment, perform a series of tests, and; generate the files required for building LLVM. CMake will use default values; for all build parameters. See the `Options and variables`_ section for; a list of build parameters that you can modify. This can fail if CMake can't detect your toolset, or if it thinks that the; environment is not sane enough. In this case, make sure that the toolset that; you intend to use is the only one reachable from the shell, and that the shell; itself is the correct one for your development environment. CMake will refuse; to build MinGW makefiles if you have a POSIX shell reachable through the PATH; environment variable, for instance. You can force CMake to use a given build; tool; for instructions, see the `Usage`_ section, below. You may; also wish to control which targets LLVM enables, or which LLVM; components are built; see the `Frequently Used LLVM-related; variables`_ below. #. After CMake has finished running, proceed to use IDE project files, or start; the build from the buil",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:1915,perform,perform,1915,interpreter/llvm-project/llvm/docs/CMake.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst,1,['perform'],['perform']
Performance," painful. Debuggers generally read debug information from object files on; disk, but for JITed code there is no such file to look for. In order to hand over the necessary debug info, `GDB established an; interface <https://sourceware.org/gdb/onlinedocs/gdb/JIT-Interface.html>`_; for registering JITed code with debuggers. LLDB implements it in the; JITLoaderGDB plugin. On the JIT side, LLVM MCJIT does implement the interface; for ELF object files. At a high level, whenever MCJIT generates new machine code, it does so in an; in-memory object file that contains the debug information in DWARF format.; MCJIT then adds this in-memory object file to a global list of dynamically; generated object files and calls a special function; ``__jit_debug_register_code`` that the debugger knows about. When the debugger; attaches to a process, it puts a breakpoint in this function and associates a; special handler with it. Once MCJIT calls the registration function, the; debugger catches the breakpoint signal, loads the new object file from the; inferior's memory and resumes execution. This way it can obtain debug; information for pure in-memory object files. GDB Version; ===========. In order to debug code JIT-ed by LLVM, you need GDB 7.0 or newer, which is; available on most modern distributions of Linux. The version of GDB that; Apple ships with Xcode has been frozen at 6.3 for a while. LLDB Version; ============. Due to a regression in release 6.0, LLDB didn't support JITed code debugging for; a while. The bug was fixed in mainline recently, so that debugging JITed ELF; objects should be possible again from the upcoming release 12.0 on. On macOS the; feature must be enabled explicitly using the ``plugin.jit-loader.gdb.enable``; setting. Debugging MCJIT-ed code; =======================. The emerging MCJIT component of LLVM allows full debugging of JIT-ed code with; GDB. This is due to MCJIT's ability to use the MC emitter to provide full; DWARF debugging information to GDB. Note th",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DebuggingJITedCode.rst:1183,load,loads,1183,interpreter/llvm-project/llvm/docs/DebuggingJITedCode.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DebuggingJITedCode.rst,1,['load'],['loads']
Performance," parameter; 7. Provide new code loader via JSROOT.require(); - introduces clean dependencies in JSROOT code; - by default uses plain script loading emulating require.js behavior; - can use require.js when available; - uses require() method when running inside node.js; - supports openui5 sap.ui.require loader if available before JSRoot.core.js; - deprecates old JSROOT.AssertPrerequisites() function; 8. Upgrade d3.js to v6.1.1, skip support of older versions; 9. Upgrade three.js to r121:; - SoftwareRenderer deprecated and removed; - let use WebGL for browser, batch and node.js (via headless-gl); - support r3d_gl, r3d_img, r3d_svg rendering options for TGeo and histograms; - keep support of SVGRendered as backup solution; 10. Upgrade MathJax.js to version 3.1.1; - reliably works in browser and node.js!; - all latex/mathjax related methods moved to special JSRoot.latex.js script, loaded on demand; 11. Update jquery to 3.5.1, openui5 to 1.82.2; 12. Use JS classes only in few places - performance is not good enough compared to Object.prototype; 13. Deprecate IE support; 14. Deprecate bower package manager; 15. Add support of ZSTD compression - works only on https://root.cern/js/ website; 16. Add support of log2 scale for axes drawing, v7 can have arbitrary log base; 17. Improve TH2 col drawings for large number of bins - up to factor 5 faster; 18. Allow to move axis title to opposite position; 19. Fix zooming in color palette; 20. Implement monitoring of object inspector. ## Changes in 5.9.1; 1. Fix zooming in color palette; 2. Fix interactive update of TGraph painting on time scale; 3. Fix I/O error in reading std::map (#204); 4. Fix functionality of ""open all"" / ""close all"" GUI buttons. ## Changes in 5.9.0; 1. Support RX and RY drawing option together with COL of TH2; 2. Add support of #overline, #underline, #strike into TLatex parsing (#196); 3. Add support of TGeoTessellated shape; 4. Major changes in v7 drawing: RFrame, RPalette, RColor, RStatBox, ...; 5. Fix in readi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/js/changes.md:26385,perform,performance,26385,js/changes.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/js/changes.md,1,['perform'],['performance']
Performance," parameters (if any). M will try to find; $\mbox{npoints}$ points on the contour (default 20). To calculate; more than one contour, the user needs to set the error definition; [howto:errordef] in its $\mbox{FCN}$ to the appropriate value for; the desired confidence level and call the method MnContours::operator(); for each contour. ### contour(...) ###. MnContours::contour(unsigned int parx, unsigned int pary, unsigned int; npoints = 20) causes a $\mbox{CONTOURS}$ error analysis and returns; the result in form of ContoursError. As a by-product ContoursError keeps; the MinosError information of parameters $\mbox{parx}$ and; $\mbox{pary}$. The result ContoursError can be easily printed using; std::cout. ## MnEigen ##. [api:eigen] MnEigen calculates and the eigenvalues of the user; covariance matrix MnUserCovariance. ### MnEigen() ###. MnEigen is instantiated via default constructor. ### operator() ###. operator()(const MnUserCovariance&) const will perform the calculation; of the eigenvalues of the covariance matrix and return the result in; form of a std::vector\<double\>. The eigenvalues are ordered from the; smallest first to the largest eigenvalue. ## MnHesse ##. [api:hesse]. With MnHesse the user can instructs M to calculate, by finite; differences, the Hessian or error matrix. That is, it calculates the; full matrix of second derivatives of the function with respect to the; currently variable parameters, and inverts it. ### MnHesse() ###. The default constructor of MnHesse() will use default settings of; MnStrategy. Other constructors with user specific MnStrategy settings; are provided as well. ### operator() ###. The MnHesse::operator() is overloaded both for internal (M ) and; external (user) parameters. External parameters can be specified as; std::vector$<$double$>$ or as MnUserParameters. The return value is; always a MnUserParameterState. The optional argument $\mbox{maxcalls}$ specifies the (approximate); maximum number of function calls after which the c",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/minuit2/Minuit2.md:40171,perform,perform,40171,documentation/minuit2/Minuit2.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/minuit2/Minuit2.md,1,['perform'],['perform']
Performance," part is how to then incorporate ``DeclContext``: all that is needed; is in ``bool DeclContext::classof(const Decl *)``, which asks the question; ""Given a ``Decl``, how can I determine if it is-a ``DeclContext``?"".; It answers this with a simple switch over the set of ``Decl`` ""kinds"", and; returning true for ones that are known to be ``DeclContext``'s. .. TODO::. Touch on some of the more advanced features, like ``isa_impl`` and; ``simplify_type``. However, those two need reference documentation in; the form of doxygen comments as well. We need the doxygen so that we can; say ""for full details, see https://llvm.org/doxygen/..."". Rules of Thumb; ==============. #. The ``Kind`` enum should have one entry per concrete class, ordered; according to a preorder traversal of the inheritance tree.; #. The argument to ``classof`` should be a ``const Base *``, where ``Base``; is some ancestor in the inheritance hierarchy. The argument should; *never* be a derived class or the class itself: the template machinery; for ``isa<>`` already handles this case and optimizes it.; #. For each class in the hierarchy that has no children, implement a; ``classof`` that checks only against its ``Kind``.; #. For each class in the hierarchy that has children, implement a; ``classof`` that checks a range of the first child's ``Kind`` and the; last child's ``Kind``. RTTI for Open Class Hierarchies; ===============================. Sometimes it is not possible to know all types in a hierarchy ahead of time.; For example, in the shapes hierarchy described above the authors may have; wanted their code to work for user defined shapes too. To support use cases; that require open hierarchies LLVM provides the ``RTTIRoot`` and; ``RTTIExtends`` utilities. The ``RTTIRoot`` class describes an interface for performing RTTI checks. The; ``RTTIExtends`` class template provides an implementation of this interface; for classes derived from ``RTTIRoot``. ``RTTIExtends`` uses the ""`Curiously; Recurring Template",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToSetUpLLVMStyleRTTI.rst:12542,optimiz,optimizes,12542,interpreter/llvm-project/llvm/docs/HowToSetUpLLVMStyleRTTI.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToSetUpLLVMStyleRTTI.rst,1,['optimiz'],['optimizes']
Performance," passing the appropriate option; to `Draw() `when attaching the drawn object(s) to a pad. For a fuller; explanation of pads, attaching objects with `Draw()` etc. refer to; ""Graphical Containers: Canvas and Pad"". ``` {.cpp}; root[] myShapes->Draw(""ogl"");; ```. Valid option strings are:. - ""`ogl`"" : external GL viewer. - ""`x3d`"": external X3D viewer. - ""`pad`"": pad viewer. If no option is passed to `Draw()` then the ""`pad`"" is used by default.; If you already have content in a pad, which you would like to display in; one of the external viewers you can select from the canvas View menu /; View With, and pick the viewer type. ![Invoking external 3D viewers from canvas menus](pictures/030000D9.png). Note: A current limitation means that when an external viewer is created; the pad is no longer redrawn. When the external viewer is closed,; clicking in the pad will refresh. ### The GL Viewer. The GL Viewer uses <OpenGL®> (or compliant libraries such as <Mesa3D>); to generate high quality, high-performance 3D renderings, with; sophisticated lighting, materials and rendering styles for 3D scenes.; Many users will be able to take advantage of hardware acceleration of; the underlying OpenGL commands by their computer's video card, resulting; is considerable performance gains - up to interactive manipulation of; 1000's of complex shapes in real-time. The GL Viewer is supported on all official ROOT platforms (assuming you; have suitable <OpenGL®> libraries), and is the main 3D viewer, which; development effort is concentrated upon. As OpenGL® is a trademark we; refer to our viewer built on this technology as the ‘GL Viewer'. The; code for it can be found under `$ROOTSYS/gl`. ![The GL 3D Viewer](pictures/020000DA.jpg). You can manipulate the viewer via the GUI or via the base; **`TGLViewer`** object behind the interface. These are detailed below -; see also `$ROOTSYS/tutorials/gl/glViewerExercise.C`. #### Projections Modes (Cameras). The GL Viewer supports two basic types of camer",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Graphics.md:107265,perform,performance,107265,documentation/users-guide/Graphics.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Graphics.md,1,['perform'],['performance']
Performance," pcon/pgon shape with rmin==rmax on top or bottom side. ## Changes in 4.4; 1. Fix faces orientation for all TGeo shapes.; 2. Improve TGeoTorus creation - handle all parameters combinations; 3. Implement TGeoCompositeShape, using ThreeCSG.js; 4. Fix problem with color palette when switch to 3D mode (#28); 5. Use nested CSS classes to avoid conflicts with other libraries (#29); 6. Let move and resize TFrame; 7. Improve TH1/TH2 drawings; - draw all histograms points in the range (no any skipped bins); - minimize SVG code for drawing (up to factor 100); - gives significant speedup in drawings; 8. SVG code improvement for TGraph, TF1, TAxis drawings; 9. Provide new tooltip kind; - created only when needed (minimizing SVG code); - tooltip can be drawn for every object in the frame; - touch devices are supported; 10. Fix - let draw same object on the canvas with different options; 11. Create cached list of known class methods. It can be extended by users.; 12. Use of cached methods improves binary I/O performance by 20%; 13. Support TGaxis; 14. Project now can be obtained via 'bower install jsroot'; 15. Support 'scat' and 'text' draw options for TH2; 16. Support in binary I/O zipped buffer bigger than 16M; 17. Correctly handle in binary I/O pointer on TArray object (like in THnSparseArrayChunk). ## Changes in 4.3; 1. Implement TGeoCtub, TGeoParaboloid and TGeoHype shapes; 2. Support TGeoTube with Rmin==0; 3. Exclude empty faces in TGeoArb8; 4. Improve TGeoSphere creation - handle all parameters combinations; 5. Introduce JSROOT.cleanup() function to safely clear all drawn objects; 6. Fix wrong resize method in 'tabs' and 'collapsible' layouts; 7. Fix canvas resize problem (issue #27); 8. Fix zero-height canvas when draw TGeo in collapsible layout; 9. Fix problem of simultaneous move TGeo drawings and canvas in flexible layout. ## Changes in 4.2; 1. Significant performance improvements in 3D drawings - TGeo/TH2/TH3; 2. Implement TGeoPara, TGeoGtra, TGeoXtru and TGeoEltu sha",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/js/changes.md:57325,cache,cached,57325,js/changes.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/js/changes.md,2,"['cache', 'perform']","['cached', 'performance']"
Performance," point and direction coordinates to the local frame of this; object and computes the distance to its shape. The node returned is the; one pointed by the input path in case the shape is crossed; otherwise; the returned value is NULL. In case the distance to next crossed; boundary is required, the current point has to be physically INSIDE the; shape pointed by the current volume. This is only insured in case a call; to TGeoManager::FindNode() was performed for the current point.; Therefore, the first step is to convert the global current point and; direction in the local reference frame of the current volume and to; compute the distance to exit its shape from inside. The returned value; is again compared to the maximum allowed step (the proposed one) and in; case the distance is safe no other action is performed and the proposed; step is approved. In case the boundary is closer, the computed distance; is taken as maximum allowed step. For optimization purposed, for; particles starting very close to the current volume boundary (less than; 0.01 microns) and exiting the algorithm stops here. After computing the distance to exit the current node, the distance to; the daughter of the current volume which is crossed next is computed by; TGeoManager::FindNextDaughterBoundary(). This computes the; distance to all daughter candidates that can be possibly crossed by; using volume voxelization. The algorithm is efficient in average only in; case the number of daughters is greater than 4. For fewer nodes, a; simple loop is performed and the minimum distance (from a point outside; each shape) is taken and compared to the maximum allowed step. The step; value is again updated if `step<stepmax` . A special case is when the current node is declared as possibly; overlapping with something else. If this is the case, the distance is; computed for all possibly overlapping candidates, taking into account; the overlapping priorities (see also: "" Overlapping volumes ""). The global matrix de",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:123474,optimiz,optimization,123474,geom/geom/doc/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md,1,['optimiz'],['optimization']
Performance," poor; performance. The alignment is only optional when parsing textual IR; for in-memory IR, it is; always present. If unspecified, the alignment is assumed to be equal to the; size of the '<value>' type. Note that this default alignment assumption is; different from the alignment used for the load/store instructions when align; isn't specified. The pointer passed into cmpxchg must have alignment greater than or; equal to the size in memory of the operand. Semantics:; """""""""""""""""""". The contents of memory at the location specified by the '``<pointer>``' operand; is read and compared to '``<cmp>``'; if the values are equal, '``<new>``' is; written to the location. The original value at the location is returned,; together with a flag indicating success (true) or failure (false). If the cmpxchg operation is marked as ``weak`` then a spurious failure is; permitted: the operation may not write ``<new>`` even if the comparison; matched. If the cmpxchg operation is strong (the default), the i1 value is 1 if and only; if the value loaded equals ``cmp``. A successful ``cmpxchg`` is a read-modify-write instruction for the purpose of; identifying release sequences. A failed ``cmpxchg`` is equivalent to an atomic; load with an ordering parameter determined the second ordering parameter. Example:; """""""""""""""". .. code-block:: llvm. entry:; %orig = load atomic i32, ptr %ptr unordered, align 4 ; yields i32; br label %loop. loop:; %cmp = phi i32 [ %orig, %entry ], [%value_loaded, %loop]; %squared = mul i32 %cmp, %cmp; %val_success = cmpxchg ptr %ptr, i32 %cmp, i32 %squared acq_rel monotonic ; yields { i32, i1 }; %value_loaded = extractvalue { i32, i1 } %val_success, 0; %success = extractvalue { i32, i1 } %val_success, 1; br i1 %success, label %done, label %loop. done:; ... .. _i_atomicrmw:. '``atomicrmw``' Instruction; ^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. atomicrmw [volatile] <operation> ptr <pointer>, <ty> <value> [syncscope(""<target-scope>"")] <ordering>[, align <alignment",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:428259,load,loaded,428259,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['load'],['loaded']
Performance," powerful as; necessary while providing a layer of simple ready-made solutions on top of it.; Probably a few reusable components for assembling checkers. And this layer; should ideally be pleasant enough to work with, so that people would prefer to; extend it when something is lacking, instead of falling back to the complex; omnipotent API. I'm thinking of AST matchers vs. AST visitors as a roughly; similar situation: matchers are not omnipotent, but they're so nice. * Separation between core and checkers is usually quite strange. Once we have; shared state traits, i generally wouldn't mind having region store or range; constraint manager as checkers (though it's probably not worth it to transform; them - just a mood). The main thing to avoid here would be the situation when; the checker overwrites stuff written by the core because it thinks it has a; better idea what's going on, so the core should provide a good default behavior. * Yeah, i totally care about performance as well, and if i try to implement; approach, i'd make sure it's good. **Artem:**. > Approach (2): We could teach the Store to scan itself for bindings to; > metadata-symbolic-based regions during scanReachableSymbols() whenever; > a region turns out to be reachable. This requires no work on checker side,; > but it sounds performance-heavy. Nope, this approach is wrong. Metadata symbols may become out-of-date: when the; object changes, metadata symbols attached to it aren't changing (because symbols; simply don't change). The same metadata may have different symbols to denote its; value in different moments of time, but at most one of them represents the; actual metadata value. So we'd be escaping more stuff than necessary. If only we had ""ghost fields""; (https://lists.llvm.org/pipermail/cfe-dev/2016-May/049000.html), it would have; been much easier, because the ghost field would only contain the actual; metadata, and the Store would always know about it. This example adds to my; belief that ghost f",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/developer-docs/InitializerLists.rst:7261,perform,performance,7261,interpreter/llvm-project/clang/docs/analyzer/developer-docs/InitializerLists.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/developer-docs/InitializerLists.rst,1,['perform'],['performance']
Performance," precede all of the integer parameters. Specific target extension types are registered with LLVM as having specific; properties. These properties can be used to restrict the type from appearing in; certain contexts, such as being the type of a global variable or having a; ``zeroinitializer`` constant be valid. A complete list of type properties may be; found in the documentation for ``llvm::TargetExtType::Property`` (`doxygen; <https://llvm.org/doxygen/classllvm_1_1TargetExtType.html>`_). :Syntax:. .. code-block:: llvm. target(""label""); target(""label"", void); target(""label"", void, i32); target(""label"", 0, 1, 2); target(""label"", void, i32, 0, 1, 2). .. _t_vector:. Vector Type; """""""""""""""""""""". :Overview:. A vector type is a simple derived type that represents a vector of; elements. Vector types are used when multiple primitive data are; operated in parallel using a single instruction (SIMD). A vector type; requires a size (number of elements), an underlying primitive data type,; and a scalable property to represent vectors where the exact hardware; vector length is unknown at compile time. Vector types are considered; :ref:`first class <t_firstclass>`. :Memory Layout:. In general vector elements are laid out in memory in the same way as; :ref:`array types <t_array>`. Such an analogy works fine as long as the vector; elements are byte sized. However, when the elements of the vector aren't byte; sized it gets a bit more complicated. One way to describe the layout is by; describing what happens when a vector such as <N x iM> is bitcasted to an; integer type with N*M bits, and then following the rules for storing such an; integer to memory. A bitcast from a vector type to a scalar integer type will see the elements; being packed together (without padding). The order in which elements are; inserted in the integer depends on endianness. For little endian element zero; is put in the least significant bits of the integer, and for big endian; element zero is put in the most signi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:174598,scalab,scalable,174598,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['scalab'],['scalable']
Performance," preceding; global/local/generic; load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; acquire-fence-paired-atomic); has completed; before invalidating; the caches. This; satisfies the; requirements of; acquire.; - Ensures that all; previous memory; operations have; completed before a; following; global/local/generic; store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; release-fence-paired-atomic).; This satisfies the; requirements of; release. 2. buffer_gl0_inv;; buffer_gl1_inv. - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. This; satisfies the; requirements of; acquire. **Sequential Consistent Atomic**; ------------------------------------------------------------------------------------; load atomic seq_cst - singlethread - global *Same as corresponding; - wavefront - local load atomic acquire,; - generic except must generate; all instructions even; for OpenCL.*; load atomic seq_cst - workgroup - global 1. s_waitcnt lgkmcnt(0) &; - generic vmcnt(0) & vscnt(0). - If CU wavefront execution; mode, omit vmcnt(0) and; vscnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0), s_waitcnt; vscnt(0), and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt lgkmcnt(0) must; happen after; preceding; local/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; lgkmcnt(0) and so do; not need to be; considered.); - s_waitcnt vmcnt(0); must happen after; preceding; global/generic load; atomic/; atomicrmw-with-return-value; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:373658,load,load,373658,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],['load']
Performance," preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global have; completed before; performing the; atomicrmw that is; being released. 2. flat_atomic; 3. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 4. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. fence acq_rel - singlethread *none* *none*; - wavefront; fence acq_rel - workgroup *none* 1. s_waitcnt lgkmcnt(0). - If OpenCL and; address space is; not generic, omit.; - However,; since LLVM; currently has no; address space on; the fence need to; conservatively; always generate; (see comment for; previous fence).; - Must happen after; any preceding; local/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that all; memory operations; to local have; completed before; performing any; following global; memory operations.; - Ensures that the; preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; acquire-fence-paired-atomic); has completed; before following; global memory; operations. This; satisfies the; requirements of; acquire.; - Ensures that all; previous memory; operations have; completed before a; following; local/generic store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; release-fence-paired-atomic).; This satisfies the; requirements of; release. fence acq_rel - agent *none* 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0). - If OpenCL and; address spa",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:227628,load,load,227628,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],['load']
Performance," preferred. Floating-point math operations are allowed to treat all NaNs as if they were; quiet NaNs. For example, ""pow(1.0, SNaN)"" may be simplified to 1.0. Code that requires different behavior than this should use the; :ref:`Constrained Floating-Point Intrinsics <constrainedfp>`.; In particular, constrained intrinsics rule out the ""Unchanged NaN propagation""; case; they are guaranteed to return a QNaN. Unfortunately, due to hard-or-impossible-to-fix issues, LLVM violates its own; specification on some architectures:. - x86-32 without SSE2 enabled may convert floating-point values to x86_fp80 and; back when performing floating-point math operations; this can lead to results; with different precision than expected and it can alter NaN values. Since; optimizations can make contradicting assumptions, this can lead to arbitrary; miscompilations. See `issue #44218; <https://github.com/llvm/llvm-project/issues/44218>`_.; - x86-32 (even with SSE2 enabled) may implicitly perform such a conversion on; values returned from a function for some calling conventions. See `issue; #66803 <https://github.com/llvm/llvm-project/issues/66803>`_.; - Older MIPS versions use the opposite polarity for the quiet/signaling bit, and; LLVM does not correctly represent this. See `issue #60796; <https://github.com/llvm/llvm-project/issues/60796>`_. .. _fastmath:. Fast-Math Flags; ---------------. LLVM IR floating-point operations (:ref:`fneg <i_fneg>`, :ref:`fadd <i_fadd>`,; :ref:`fsub <i_fsub>`, :ref:`fmul <i_fmul>`, :ref:`fdiv <i_fdiv>`,; :ref:`frem <i_frem>`, :ref:`fcmp <i_fcmp>`), :ref:`phi <i_phi>`,; :ref:`select <i_select>` and :ref:`call <i_call>`; may use the following flags to enable otherwise unsafe; floating-point transformations. ``nnan``; No NaNs - Allow optimizations to assume the arguments and result are not; NaN. If an argument is a nan, or the result would be a nan, it produces; a :ref:`poison value <poisonvalues>` instead. ``ninf``; No Infs - Allow optimizations to assume the",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:161058,perform,perform,161058,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['perform']
Performance," printed out by the tool in; the analysis report. .. option:: -print-imm-hex. Prefer hex format for numeric literals in the output assembly printed as part; of the report. .. option:: -dispatch=<width>. Specify a different dispatch width for the processor. The dispatch width; defaults to field 'IssueWidth' in the processor scheduling model. If width is; zero, then the default dispatch width is used. .. option:: -register-file-size=<size>. Specify the size of the register file. When specified, this flag limits how; many physical registers are available for register renaming purposes. A value; of zero for this flag means ""unlimited number of physical registers"". .. option:: -iterations=<number of iterations>. Specify the number of iterations to run. If this flag is set to 0, then the; tool sets the number of iterations to a default value (i.e. 100). .. option:: -noalias=<bool>. If set, the tool assumes that loads and stores don't alias. This is the; default behavior. .. option:: -lqueue=<load queue size>. Specify the size of the load queue in the load/store unit emulated by the tool.; By default, the tool assumes an unbound number of entries in the load queue.; A value of zero for this flag is ignored, and the default load queue size is; used instead. .. option:: -squeue=<store queue size>. Specify the size of the store queue in the load/store unit emulated by the; tool. By default, the tool assumes an unbound number of entries in the store; queue. A value of zero for this flag is ignored, and the default store queue; size is used instead. .. option:: -timeline. Enable the timeline view. .. option:: -timeline-max-iterations=<iterations>. Limit the number of iterations to print in the timeline view. By default, the; timeline view prints information for up to 10 iterations. .. option:: -timeline-max-cycles=<cycles>. Limit the number of cycles in the timeline view, or use 0 for no limit. By; default, the number of cycles is set to 80. .. option:: -resource-pressure. Enab",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:4128,load,load,4128,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,2,"['load', 'queue']","['load', 'queue']"
Performance," probabilities); .uleb128 2 # BB_1 successor 1 BB ID (only enabled with branch probabilities); .uleb128 0x11111111 # BB_1 successor 1 branch probability (only enabled with branch probabilities); .uleb128 3 # BB_1 successor 2 BB ID (only enabled with branch probabilities); .uleb128 0x11111111 # BB_1 successor 2 branch probability (only enabled with branch probabilities); # PGO data record for BB_2; .uleb128 18 # BB_2 basic block frequency (only when enabled); .uleb128 1 # BB_2 successors count (only enabled with branch probabilities); .uleb128 3 # BB_2 successor 1 BB ID (only enabled with branch probabilities); .uleb128 0xffffffff # BB_2 successor 1 branch probability (only enabled with branch probabilities); # PGO data record for BB_3; .uleb128 1000 # BB_3 basic block frequency (only when enabled); .uleb128 0 # BB_3 successors count (only enabled with branch probabilities). ``SHT_LLVM_OFFLOADING`` Section (offloading data); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; This section stores the binary data used to perform offloading device linking; and execution, creating a fat binary. This section is emitted during compilation; of offloading languages such as OpenMP or CUDA. If the data is intended to be; used by the device linker only, it should use the ``SHF_EXCLUDE`` flag so it is; automatically stripped from the final executable or shared library. The binary data stored in this section conforms to a custom binary format used; for storing offloading metadata. This format is effectively a string table; containing metadata accompanied by a device image. ``SHT_LLVM_LTO`` Section (LLVM bitcode for fat LTO); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; This section stores LLVM bitcode used to perform regular LTO or ThinLTO at link; time. This section is generated when the compiler enables fat LTO. This section; has the ``SHF_EXCLUDE`` flag so that it is stripped from the final executable; or shared library. CodeView-Dependent; ------------------. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Extensions.rst:17899,perform,perform,17899,interpreter/llvm-project/llvm/docs/Extensions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Extensions.rst,1,['perform'],['perform']
Performance," problem with [Cross-Origin Request](https://developer.mozilla.org/en/http_access_control) can appear. If the web server configuration cannot be changed, just copy JSROOT to the web server itself. ### Binary file-based monitoring (not recommended). Theoretically, one could use binary ROOT files to implement monitoring.; With such approach, a ROOT-based application creates and regularly updates content of a ROOT file, which can be accessed via normal web server. From the browser side, JSROOT could regularly read the specified objects and update their drawings. But such solution has three major caveats. First of all, one need to store the data of all objects, which only potentially could be displayed in the browser. In case of 10 objects it does not matter, but for 1000 or 100000 objects this will be a major performance penalty. With such big amount of data one will never achieve higher update rate. The second problem is I/O. To read the first object from the ROOT file, one need to perform several (about 5) file-reading operations via http protocol.; There is no http file locking mechanism (at least not for standard web servers),; therefore there is no guarantee that the file content is not changed/replaced between consequent read operations. Therefore, one should expect frequent I/O failures while trying to monitor data from ROOT binary files. There is a workaround for the problem - one could load the file completely and exclude many partial I/O operations by this. To achieve this with JSROOT, one should add ""+"" sign at the end of the file name. Of course, it only could work for small files. If somebody still wants to use monitoring of data from ROOT files, could try link like:. - <https://root.cern/js/latest/?nobrowser&file=../files/hsimple.root+&item=hpx;1&monitoring=2000>. In this particular case, the histogram is not changing. ## JSROOT API. JSROOT can be used in arbitrary HTML pages to display data, produced with or without ROOT-based applications. Many differen",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/JSROOT/JSROOT.md:32943,perform,perform,32943,documentation/JSROOT/JSROOT.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/JSROOT/JSROOT.md,1,['perform'],['perform']
Performance," process. The default pipeline implements the following sequence of stages used to; process instructions. * Dispatch (Instruction is dispatched to the schedulers).; * Issue (Instruction is issued to the processor pipelines).; * Write Back (Instruction is executed, and results are written back).; * Retire (Instruction is retired; writes are architecturally committed). The in-order pipeline implements the following sequence of stages:; * InOrderIssue (Instruction is issued to the processor pipelines).; * Retire (Instruction is retired; writes are architecturally committed). :program:`llvm-mca` assumes that instructions have all been decoded and placed; into a queue before the simulation start. Therefore, the instruction fetch and; decode stages are not modeled. Performance bottlenecks in the frontend are not; diagnosed. Also, :program:`llvm-mca` does not model branch prediction. Instruction Dispatch; """"""""""""""""""""""""""""""""""""""""; During the dispatch stage, instructions are picked in program order from a; queue of already decoded instructions, and dispatched in groups to the; simulated hardware schedulers. The size of a dispatch group depends on the availability of the simulated; hardware resources. The processor dispatch width defaults to the value; of the ``IssueWidth`` in LLVM's scheduling model. An instruction can be dispatched if:. * The size of the dispatch group is smaller than processor's dispatch width.; * There are enough entries in the reorder buffer.; * There are enough physical registers to do register renaming.; * The schedulers are not full. Scheduling models can optionally specify which register files are available on; the processor. :program:`llvm-mca` uses that information to initialize register; file descriptors. Users can limit the number of physical registers that are; globally available for register renaming by using the command option; ``-register-file-size``. A value of zero for this option means *unbounded*. By; knowing how many registers are available ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:34997,queue,queue,34997,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,1,['queue'],['queue']
Performance," processed twice or more times).; Fix problem with the transmission of non-default file; attributes (e.g. the number of entries) from TChainElement to; TDSetElement during TChain processing in PROOF; Fix problem in the default packetizer with validating the; exact number of needed files when the information about the entries is; already available.; Fix problem with 'xpd.putenv' and 'xpd.putrc' occuring when the variables themselves contain commas.; Avoid resolving the workers FQDN when running in PROOF-Lite,; creating unnecessary delays when running PROOF-Lite within virtual; machines.; Fix problem with the permissions of the user data directory.; Add files to the list of files to process only when finally validated.; Fix; problem with canvases when the feedback canvas and the final canvas are; the same (do not delete the feedback canvas at the end of processing); Make sure that TProof::Load, TProofPlayer::SendSelector and; TSelector::GetSelector treat consistently the extensions of the; implementation files.; Unlock the cache after failure to load a selector; prevents session freezing; Correctly update the number of submergers when workers die; Add missing protection causing a crash in submergers when the output list contained TProofOutputFile objects.; Move the creation and start of the idle timeout from the end; of SetupCommon to the end of CreateServer, so that the timeout is not; active during worker setup.; Make sure that the TProof instance on the client is invalidated after an idle timeout.; Fix an old issue with DeactivateWorker(""*"") (the session is; was terminated because no worker was active; this call coudl not be; used as intermediate step to select a small number of workers).; Consistently check both Proof.Sandbox and ProofLite.Sandbox for sandbox non-default location as done in TProofLite; Fix a problem with the registration of missing files in the; 'MissingFiles' list (files which could not be open on the workers were; not always added to the list). ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html:12491,cache,cache,12491,proof/doc/v528/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html,4,"['cache', 'load']","['cache', 'load']"
Performance," provided it is within the same basic block as the checked load,; and therefore has no additional predicates guarding it. Consider code like the; following:; ```; ... .LBB0_4: # %danger; movq (%rcx), %rdi; movl (%rdi), %edx; ```. This will get transformed into:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; orq %rax, %rcx # Mask the pointer if misspeculating.; movq (%rcx), %rdi # Hardened load.; movl (%rdi), %edx # Unhardened load due to dependent addr.; ```. This doesn't check the load through `%rdi` as that pointer is dependent on a; checked load already. ###### Protect large, load-heavy blocks with a single lfence. It may be worth using a single `lfence` instruction at the start of a block; which begins with a (very) large number of loads that require independent; protection *and* which require hardening the address of the load. However, this; is unlikely to be profitable in practice. The latency hit of the hardening; would need to exceed that of an `lfence` when *correctly* speculatively; executed. But in that case, the `lfence` cost is a complete loss of speculative; execution (at a minimum). So far, the evidence we have of the performance cost; of using `lfence` indicates few if any hot code patterns where this trade off; would make sense. ###### Tempting optimizations that break the security model. Several optimizations were considered which didn't pan out due to failure to; uphold the security model. One in particular is worth discussing as many others; will reduce to it. We wondered whether only the *first* load in a basic block could be checked. If; the check works as intended, it forms an invalid pointer that doesn't even; virtual-address translate in the hardware. It should fault very early on in its; processing. Maybe that would stop things in time for the misspeculated path to; fail to leak any secrets. This doesn't end up working because the processor is; fundamentally out-of-order, even in its speculative doma",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:36512,latency,latency,36512,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,1,['latency'],['latency']
Performance," provides overloaded builtins giving direct access to the three key ARM; instructions for implementing atomic operations. .. code-block:: c. T __builtin_arm_ldrex(const volatile T *addr);; T __builtin_arm_ldaex(const volatile T *addr);; int __builtin_arm_strex(T val, volatile T *addr);; int __builtin_arm_stlex(T val, volatile T *addr);; void __builtin_arm_clrex(void);. The types ``T`` currently supported are:. * Integer types with width at most 64 bits (or 128 bits on AArch64).; * Floating-point types; * Pointer types. Note that the compiler does not guarantee it will not insert stores which clear; the exclusive monitor in between an ``ldrex`` type operation and its paired; ``strex``. In practice this is only usually a risk when the extra store is on; the same cache line as the variable being modified and Clang will only insert; stack stores on its own, so it is best not to use these operations on variables; with automatic storage duration. Also, loads and stores may be implicit in code written between the ``ldrex`` and; ``strex``. Clang will not necessarily mitigate the effects of these either, so; care should be exercised. For these reasons the higher level atomic primitives should be preferred where; possible. Non-temporal load/store builtins; --------------------------------. Clang provides overloaded builtins allowing generation of non-temporal memory; accesses. .. code-block:: c. T __builtin_nontemporal_load(T *addr);; void __builtin_nontemporal_store(T value, T *addr);. The types ``T`` currently supported are:. * Integer types.; * Floating-point types.; * Vector types. Note that the compiler does not guarantee that non-temporal loads or stores; will be used. C++ Coroutines support builtins; --------------------------------. .. warning::; This is a work in progress. Compatibility across Clang/LLVM releases is not; guaranteed. Clang provides experimental builtins to support C++ Coroutines as defined by; https://wg21.link/P0057. The following four are intended to",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst:144459,load,loads,144459,interpreter/llvm-project/clang/docs/LanguageExtensions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst,1,['load'],['loads']
Performance," put a bunch of stuff into; a container that automatically eliminates duplicates. Some set-like; containers support efficient iteration through the elements in sorted order.; Set-like containers are more expensive than sequential containers. * a :ref:`sequential <ds_sequential>` container provides the most efficient way; to add elements and keeps track of the order they are added to the collection.; They permit duplicates and support efficient iteration, but do not support; efficient look-up based on a key. * a :ref:`string <ds_string>` container is a specialized sequential container or; reference structure that is used for character or byte arrays. * a :ref:`bit <ds_bit>` container provides an efficient way to store and; perform set operations on sets of numeric id's, while automatically; eliminating duplicates. Bit containers require a maximum of 1 bit for each; identifier you want to store. Once the proper category of container is determined, you can fine tune the; memory use, constant factors, and cache behaviors of access by intelligently; picking a member of the category. Note that constant factors and cache behavior; can be a big deal. If you have a vector that usually only contains a few; elements (but could contain many), for example, it's much better to use; :ref:`SmallVector <dss_smallvector>` than :ref:`vector <dss_vector>`. Doing so; avoids (relatively) expensive malloc/free calls, which dwarf the cost of adding; the elements to the container. .. _ds_sequential:. Sequential Containers (std::vector, std::list, etc); ---------------------------------------------------. There are a variety of sequential containers available for you, based on your; needs. Pick the first in this section that will do what you want. .. _dss_arrayref:. llvm/ADT/ArrayRef.h; ^^^^^^^^^^^^^^^^^^^. The ``llvm::ArrayRef`` class is the preferred class to use in an interface that; accepts a sequential list of elements in memory and just reads from them. By; taking an ``ArrayRef``, the ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:56891,tune,tune,56891,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,2,"['cache', 'tune']","['cache', 'tune']"
Performance," r0, lsr #24; 	orr	r0, r2, r0, lsl #24; 	orr	r0, r0, r1; 	bx	lr. Something like the following would be better (fewer instructions/registers):; 	eor r1, r0, r0, ror #16; 	bic r1, r1, #0xff0000; 	mov r1, r1, lsr #8; 	eor r0, r1, r0, ror #8; 	bx	lr. A custom Thumb version would also be a slight improvement over the generic; version. //===---------------------------------------------------------------------===//. Consider the following simple C code:. void foo(unsigned char *a, unsigned char *b, int *c) {; if ((*a | *b) == 0) *c = 0;; }. currently llvm-gcc generates something like this (nice branchless code I'd say):. ldrb r0, [r0]; ldrb r1, [r1]; orr r0, r1, r0; tst r0, #255; moveq r0, #0; streq r0, [r2]; bx lr. Note that both ""tst"" and ""moveq"" are redundant. //===---------------------------------------------------------------------===//. When loading immediate constants with movt/movw, if there are multiple; constants needed with the same low 16 bits, and those values are not live at; the same time, it would be possible to use a single movw instruction, followed; by multiple movt instructions to rewrite the high bits to different values.; For example:. volatile store i32 -1, i32* inttoptr (i32 1342210076 to i32*), align 4,; !tbaa; !0; volatile store i32 -1, i32* inttoptr (i32 1342341148 to i32*), align 4,; !tbaa; !0. is compiled and optimized to:. movw r0, #32796; mov.w r1, #-1; movt r0, #20480; str r1, [r0]; movw r0, #32796 @ <= this MOVW is not needed, value is there already; movt r0, #20482; str r1, [r0]. //===---------------------------------------------------------------------===//. Improve codegen for select's:; if (x != 0) x = 1; if (x == 1) x = 1. ARM codegen used to look like this:; mov r1, r0; cmp r1, #1; mov r0, #0; moveq r0, #1. The naive lowering select between two different values. It should recognize the; test is equality test so it's more a conditional move rather than a select:; cmp r0, #1; movne r0, #0. Currently this is a ARM specific dag combine. W",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/README.txt:19410,load,loading,19410,interpreter/llvm-project/llvm/lib/Target/ARM/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/README.txt,2,['load'],['loading']
Performance," r2. The last stmia stores r0, r1,; r2 into the address passed in. However, there is one additional stmia that; stores r0, r1, and r2 to some stack location. The store is dead. The llvm-gcc generated code looks like this:. csretcc void %foo(%struct.s* %agg.result) {; entry:; 	%S = alloca %struct.s, align 4		; <%struct.s*> [#uses=1]; 	%memtmp = alloca %struct.s		; <%struct.s*> [#uses=1]; 	cast %struct.s* %S to sbyte*		; <sbyte*>:0 [#uses=2]; 	call void %llvm.memcpy.i32( sbyte* %0, sbyte* cast ({ double, int }* %C.0.904 to sbyte*), uint 12, uint 4 ); 	cast %struct.s* %agg.result to sbyte*		; <sbyte*>:1 [#uses=2]; 	call void %llvm.memcpy.i32( sbyte* %1, sbyte* %0, uint 12, uint 0 ); 	cast %struct.s* %memtmp to sbyte*		; <sbyte*>:2 [#uses=1]; 	call void %llvm.memcpy.i32( sbyte* %2, sbyte* %1, uint 12, uint 0 ); 	ret void; }. llc ends up issuing two memcpy's (the first memcpy becomes 3 loads from; constantpool). Perhaps we should 1) fix llvm-gcc so the memcpy is translated; into a number of load and stores, or 2) custom lower memcpy (of small size) to; be ldmia / stmia. I think option 2 is better but the current register; allocator cannot allocate a chunk of registers at a time. A feasible temporary solution is to use specific physical registers at the; lowering time for small (<= 4 words?) transfer size. * ARM CSRet calling convention requires the hidden argument to be returned by; the callee. //===---------------------------------------------------------------------===//. We can definitely do a better job on BB placements to eliminate some branches.; It's very common to see llvm generated assembly code that looks like this:. LBB3:; ...; LBB4:; ...; beq LBB3; b LBB2. If BB4 is the only predecessor of BB3, then we can emit BB3 after BB4. We can; then eliminate beq and turn the unconditional branch to LBB2 to a bne. See McCat/18-imp/ComputeBoundingBoxes for an example. //===---------------------------------------------------------------------===//. Pre-/post- indexed load ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/README.txt:7217,load,load,7217,interpreter/llvm-project/llvm/lib/Target/ARM/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/README.txt,2,['load'],['load']
Performance," ratio comparing to ZLIB); - If two or more files have an identical streamer info record, this is only treated once therewith avoiding to take the global lock.; - Allow writing temporary objects (with same address) in the same TBuffer(s). A new flag to TBuffer*::WriteObject allows to skip the mechanism that prevent the 2nd streaming of an object. This allows the (re)use of temporary objects to store different data in the same buffer.; - Reuse branch proxies internally used by TTreeReader{Value,Array} therewith increasing performance when having multiple readers pointing to the same branch.; - Implement reading of objects data from JSON; - Provide TBufferJSON::ToJSON() and TBufferJSON::FromJSON() methods; - Provide TBufferXML::ToXML() and TBufferXML::FromXML() methods; - Converts NaN and Infinity values into null in JSON, there are no other direct equivalent. ## TTree Libraries; - Enable the TTreeCache by default of `TTree::Draw`, `TTreeReader` and `RDataFrame`; - Significant enhancement in the `TTreeCache` filling algorithm to increase robustness in case of oddly clustered `TTree` and under provisioned cache size. See the [merge request](https://github.com/root-project/root/pull/1960) for more details.; - Proxies are now properly re-used when multiple TTreeReader{Value,Array}s are associated to a single branch. Deserialisation is therefore performed once. This is an advantage for complex TDataFrame graphs.; - Add TBranch::BackFill to allow the addition of new branches to an existing tree and keep the new basket clustered in the same way as the rest of the TTree. Use with the following pattern,; make sure to to call BackFill for the same entry for all the branches consecutively:; ```; for(auto e = 0; e < tree->GetEntries(); ++e) { // loop over entries.; for(auto branch : branchCollection) {; ... Make change to the data associated with the branch ...; branch->BackFill();; }; }; ```; Since we loop over all the branches for each new entry all the baskets for a cluster ar",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v614/index.md:4700,cache,cache,4700,README/ReleaseNotes/v614/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v614/index.md,1,['cache'],['cache']
Performance," reasonably possible, easing; migration from GCC to Clang. In most cases, code ""just works"".; Clang also provides an alternative driver, :ref:`clang-cl`, that is designed; to be compatible with the Visual C++ compiler, cl.exe. In addition to language specific features, Clang has a variety of; features that depend on what CPU architecture or operating system is; being compiled for. Please see the :ref:`Target-Specific Features and; Limitations <target_features>` section for more details. The rest of the introduction introduces some basic :ref:`compiler; terminology <terminology>` that is used throughout this manual and; contains a basic :ref:`introduction to using Clang <basicusage>` as a; command line compiler. .. _terminology:. Terminology; -----------. Front end, parser, backend, preprocessor, undefined behavior,; diagnostic, optimizer. .. _basicusage:. Basic Usage; -----------. Intro to how to use a C compiler for newbies. compile + link compile then link debug info enabling optimizations; picking a language to use, defaults to C17 by default. Autosenses based; on extension. using a makefile. Command Line Options; ====================. This section is generally an index into other sections. It does not go; into depth on the ones that are covered by other sections. However, the; first part introduces the language selection and other high level; options like :option:`-c`, :option:`-g`, etc. Options to Control Error and Warning Messages; ---------------------------------------------. .. option:: -Werror. Turn warnings into errors. .. This is in plain monospaced font because it generates the same label as; .. -Werror, and Sphinx complains. ``-Werror=foo``. Turn warning ""foo"" into an error. .. option:: -Wno-error=foo. Turn warning ""foo"" into a warning even if :option:`-Werror` is specified. .. option:: -Wfoo. Enable warning ""foo"".; See the :doc:`diagnostics reference <DiagnosticsReference>` for a complete; list of the warning flags that can be specified in this way. ..",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:3323,optimiz,optimizations,3323,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,1,['optimiz'],['optimizations']
Performance," recognize llvm_first_trigger() calls and NOT; generate saves and restores of caller-saved registers around these; calls. Phase behavior; --------------. We turn off llvm_first_trigger() calls with NOPs, but this would hide; phase behavior from us (when some funcs/traces stop being hot and; others become hot.). We have a SIGALRM timer that counts time for us. Every time we get a; SIGALRM we look at our priority queue of locations where we have; removed llvm_first_trigger() calls. Each location is inserted along; with a time when we will next turn instrumentation back on for that; call site. If the time has arrived for a particular call site, we pop; that off the prio. queue and turn instrumentation back on for that; call site. Generating traces; -----------------. When we finally generate an optimized trace we first copy the code; into the trace cache. This leaves us with 3 copies of the code: the; original code, the instrumented code, and the optimized trace. The; optimized trace does not have instrumentation. The original code and; the instrumented code are modified to have a branch to the trace; cache, where the optimized traces are kept. We copy the code from the original to the instrumentation version; by tracing the LLVM-to-Machine code basic block map and then copying; each machine code basic block we think is in the hot region into the; trace cache. Then we instrument that code. The process is similar for; generating the final optimized trace; we copy the same basic blocks; because we might need to put in fixup code for exit BBs. LLVM basic blocks are not typically used in the Reoptimizer except; for the mapping information. We are restricted to using single instructions to branch between the; original code, trace, and instrumented code. So we have to keep the; code copies in memory near the original code (they can't be far enough; away that a single pc-relative branch would not work.) Malloc() or; data region space is too far away. this impacts the design o",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2003-06-25-Reoptimizer1.txt:3681,optimiz,optimized,3681,interpreter/llvm-project/llvm/docs/HistoricalNotes/2003-06-25-Reoptimizer1.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2003-06-25-Reoptimizer1.txt,1,['optimiz'],['optimized']
Performance," reference in the object graph. **Ignoring** them would badly violate user expectations about their code.; While it *would* make it easier to develop code simultaneously for ARC and; non-ARC, there is very little reason to do so except for certain library; developers. ARC and non-ARC translation units share an execution model and; can seamlessly interoperate. Within a translation unit, a developer who; faithfully maintains their code in non-ARC mode is suffering all the; restrictions of ARC for zero benefit, while a developer who isn't testing the; non-ARC mode is likely to be unpleasantly surprised if they try to go back to; it. **Banning** them has the disadvantage of making it very awkward to migrate; existing code to ARC. The best answer to that, given a number of other; changes and restrictions in ARC, is to provide a specialized tool to assist; users in that migration. Implementing these methods was banned because they are too integral to the; semantics of ARC; many tricks which worked tolerably under manual reference; counting will misbehave if ARC performs an ephemeral extra retain or two. If; absolutely required, it is still possible to implement them in non-ARC code,; for example in a category; the implementations must obey the :ref:`semantics; <arc.objects.retains>` laid out elsewhere in this document. .. _arc.misc.special_methods.dealloc:. ``dealloc``; ^^^^^^^^^^^. A program is ill-formed if it contains a message send or ``@selector``; expression for the selector ``dealloc``. .. admonition:: Rationale. There are no legitimate reasons to call ``dealloc`` directly. A class may provide a method definition for an instance method named; ``dealloc``. This method will be called after the final ``release`` of the; object but before it is deallocated or any of its instance variables are; destroyed. The superclass's implementation of ``dealloc`` will be called; automatically when the method returns. .. admonition:: Rationale. Even though ARC destroys instance varia",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst:87051,perform,performs,87051,interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,1,['perform'],['performs']
Performance," regions are invisible since the current track has not yet reached; its mother. This is not the case when going the other way since the; track has first to exit the extruding node before checking the mother.; In other words, an extrusion behavior is dependent on the track; parameters, which is a highly undesirable effect. *B)* We will call ""overlaps"" only the regions in space contained by; more than one node inside the same container. The owner of such regions; cannot be determined based on hierarchical considerations; therefore; they will be considered as belonging to the node from which the current; track is coming from. When coming from their container, the ownership is totally; unpredictable. Again, the ownership of overlapping regions highly; depends on the current track parameters. We must say that even the overlaps of type *A)* and *B)* are allowed in case; the corresponding nodes are created using; TGeoVolume::AddNodeOverlap() method. Navigation is performed in such; cases by giving priority to the non-overlapping nodes. The modeller has; to perform an additional search through the overlapping candidates.; These are detected automatically during the geometry closing procedure; in order to optimize the algorithm, but we will stress that extensive; usage of this feature leads to a drastic deterioration of performance.; In the following we will focus on the non-declared overlaps of type *A)*; and *B)* since this is the main source of errors during tracking. These; are generally non-intended overlaps due to coding mistakes or bad; geometry design. The checking package is loaded together with the; painter classes and contains an automated overlap checker. \image html geometry008.png ""Overlap checking"". This can be activated both at volume level (checking for illegal; overlaps only one level inside a given volume) and from the geometry; manager level (checking full geometry):. ~~~{.cpp}; myVolume->CheckOverlaps(precision, option);; gGeoManager->CheckOverlaps(preci",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:92128,perform,performed,92128,geom/geom/doc/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md,1,['perform'],['performed']
Performance," relevant new methods are:. TEntryList::Scan(const char *fn); Shows the root common paths for the files of the TEntryLists in 'fn'; TEntryList::Relocate(const char *fn, const char *newroot,; const char *oldroot = 0, const char *enlnm = 0); Relocates all paths starting with 'oldroot' to 'newroot' for the; entry-list 'enlnm' in file 'fn'. Remove 'protocol+server' from file tagging and matching, i.e. use; only filepath+anchor; in this way a list is valid even after re-staging; of the dataset files, which typically changes the end-point data servers.; Entry-lists created with the full path should still be matched correctly. Miscellaneous. Repaired the behavior of TTreeCache when the TTree has a dramatic dynamic range with a lots of very small entriesat the beginning and very large entries at the end, the size in bytes of the cluster for the later entries will be very large (because of the cluster size in entries is large!). TTreeCache::FillBuffer was always attempting to load complete clusters not matter the; size (even with the size was larger than 2GB!). This patch resolves the issue by limiting the amount of memory used to:. The requested size if more than one cluster fits in the cache.; Twice the requested size if at least one basket per branch fits in the cache.; Four time the requested size in the case where the cache can not even hold one basket per branch. The filling will restart at the next cluster boundary in the case a) and will; restart at the maximum of entry number read in the cache in the case b) and c).; Baskets that are below this boundary and did not fit in the cache will be read; individually.; Repaired the basket flushing frequency when the TTree has already more than one cluster size.; Repaired binning of string histogram generated by TTree::Draw.; Many bug fixes and fix for issues discovery by Coverity, see change log for more details.; In TTree::MakeProxy add proper support for top level stl collection of objects and for stl collection of objects ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v534/index.html:3039,load,load,3039,tree/doc/v534/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v534/index.html,2,['load'],['load']
Performance," repaint on the attached **`TPad`** object - hence you should attach you; master geometry object to the pad (via `TObject::Draw()`), and perform; the publishing to the viewer in response to **`TObject::Paint()`**. #### Physical IDs. TVirtualViewer3D provides for two methods of object addition:. ``` {.cpp}; virtual Int_t AddObject(const TBuffer3D &buffer,; Bool_t * addChildren = 0); virtual Int_t AddObject(UInt_t physicalID,; const TBuffer3D & buffer,; Bool_t *addChildren = 0); ```. If you use the first (simple) case a viewer using logical/physical pairs; will generate sequential IDs for each physical object internally. Scene; rebuilds will require destruction and recreation of all physical; objects. For the second you can specify an identifier from the client; side, which must be unique and stable - i.e. the IDs of a published; object is consistent, regardless of changes in termination of contained; child geometry branches. In this case the viewer can safely cache the; physical objects across scene rebuilds, discarding those no longer of; interest. #### Child Objects. In many geometries there is a rigid containment hierarchy, and so if the; viewer is not interested in a certain object due to limits/size then it; will also not be interest in any of the contained branch of siblings.; Both `TBuffer3D::AddObject()` methods have an `addChildren` return; parameter. The viewer will complete this (if passed) indicating if; children of the object just sent are worth sending. #### Recycling TBuffer3D. Once add `TBuffer3D::AddObject()` has been called, the contents are; copied to the viewer's internal data structures. You are free to destroy; this **`TBuffer3D`**, or recycle it for the next object if suitable. #### Examples. For an example of a simple geometry, working in master reference frame; examine the code under `$ROOTSYS/g3d`. For a more complex example, which; works in both master and local frames, and uses logical`/`physical; division of shape geometry and placement, e",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Graphics.md:138295,cache,cache,138295,documentation/users-guide/Graphics.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Graphics.md,1,['cache'],['cache']
Performance," resource pressure. Instruction Flow; ^^^^^^^^^^^^^^^^; This section describes the instruction flow through the default pipeline of; :program:`llvm-mca`, as well as the functional units involved in the process. The default pipeline implements the following sequence of stages used to; process instructions. * Dispatch (Instruction is dispatched to the schedulers).; * Issue (Instruction is issued to the processor pipelines).; * Write Back (Instruction is executed, and results are written back).; * Retire (Instruction is retired; writes are architecturally committed). The in-order pipeline implements the following sequence of stages:; * InOrderIssue (Instruction is issued to the processor pipelines).; * Retire (Instruction is retired; writes are architecturally committed). :program:`llvm-mca` assumes that instructions have all been decoded and placed; into a queue before the simulation start. Therefore, the instruction fetch and; decode stages are not modeled. Performance bottlenecks in the frontend are not; diagnosed. Also, :program:`llvm-mca` does not model branch prediction. Instruction Dispatch; """"""""""""""""""""""""""""""""""""""""; During the dispatch stage, instructions are picked in program order from a; queue of already decoded instructions, and dispatched in groups to the; simulated hardware schedulers. The size of a dispatch group depends on the availability of the simulated; hardware resources. The processor dispatch width defaults to the value; of the ``IssueWidth`` in LLVM's scheduling model. An instruction can be dispatched if:. * The size of the dispatch group is smaller than processor's dispatch width.; * There are enough entries in the reorder buffer.; * There are enough physical registers to do register renaming.; * The schedulers are not full. Scheduling models can optionally specify which register files are available on; the processor. :program:`llvm-mca` uses that information to initialize register; file descriptors. Users can limit the number of physical registers",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:34769,bottleneck,bottlenecks,34769,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,1,['bottleneck'],['bottlenecks']
Performance," result generated by the function object. E.g. .. code-block:: c++. ThreadSafeModule TSM = getModule(...);. // Dump the module:; size_t NumFunctionsInModule =; TSM.withModuleDo(; [](Module &M) { // <- Context locked before entering lambda.; return M.size();; } // <- Context unlocked after leaving.; );. Clients wishing to maximize possibilities for concurrent compilation will want; to create every new ThreadSafeModule on a new ThreadSafeContext. For this; reason a convenience constructor for ThreadSafeModule is provided that implicitly; constructs a new ThreadSafeContext value from a std::unique_ptr<LLVMContext>:. .. code-block:: c++. // Maximize concurrency opportunities by loading every module on a; // separate context.; for (const auto &IRPath : IRPaths) {; auto Ctx = std::make_unique<LLVMContext>();; auto M = std::make_unique<LLVMContext>(""M"", *Ctx);; CompileLayer.add(MainJD, ThreadSafeModule(std::move(M), std::move(Ctx)));; }. Clients who plan to run single-threaded may choose to save memory by loading; all modules on the same context:. .. code-block:: c++. // Save memory by using one context for all Modules:; ThreadSafeContext TSCtx(std::make_unique<LLVMContext>());; for (const auto &IRPath : IRPaths) {; ThreadSafeModule TSM(parsePath(IRPath, *TSCtx.getContext()), TSCtx);; CompileLayer.add(MainJD, ThreadSafeModule(std::move(TSM));; }. .. _ProcessAndLibrarySymbols:. How to Add Process and Library Symbols to JITDylibs; ===================================================. JIT'd code may need to access symbols in the host program or in supporting; libraries. The best way to enable this is to reflect these symbols into your; JITDylibs so that they appear the same as any other symbol defined within the; execution session (i.e. they are findable via `ExecutionSession::lookup`, and; so visible to the JIT linker during linking). One way to reflect external symbols is to add them manually using the; absoluteSymbols function:. .. code-block:: c++. const DataLayout &DL = g",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ORCv2.rst:31178,load,loading,31178,interpreter/llvm-project/llvm/docs/ORCv2.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ORCv2.rst,1,['load'],['loading']
Performance," results than a; sampling profiler. It also provides reproducible results, at least to the; extent that the code behaves consistently across runs. Clang supports two types of instrumentation: frontend-based and IR-based.; Frontend-based instrumentation can be enabled with the option ``-fprofile-instr-generate``,; and IR-based instrumentation can be enabled with the option ``-fprofile-generate``.; For best performance with PGO, IR-based instrumentation should be used. It has; the benefits of lower instrumentation overhead, smaller raw profile size, and; better runtime performance. Frontend-based instrumentation, on the other hand,; has better source correlation, so it should be used with source line-based; coverage testing. The flag ``-fcs-profile-generate`` also instruments programs using the same; instrumentation method as ``-fprofile-generate``. However, it performs a; post-inline late instrumentation and can produce context-sensitive profiles. Here are the steps for using profile guided optimization with; instrumentation:. 1. Build an instrumented version of the code by compiling and linking with the; ``-fprofile-generate`` or ``-fprofile-instr-generate`` option. .. code-block:: console. $ clang++ -O2 -fprofile-instr-generate code.cc -o code. 2. Run the instrumented executable with inputs that reflect the typical usage.; By default, the profile data will be written to a ``default.profraw`` file; in the current directory. You can override that default by using option; ``-fprofile-instr-generate=`` or by setting the ``LLVM_PROFILE_FILE``; environment variable to specify an alternate file. If non-default file name; is specified by both the environment variable and the command line option,; the environment variable takes precedence. The file name pattern specified; can include different modifiers: ``%p``, ``%h``, ``%m``, ``%t``, and ``%c``. Any instance of ``%p`` in that file name will be replaced by the process; ID, so that you can easily distinguish the profile outp",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:103369,optimiz,optimization,103369,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,1,['optimiz'],['optimization']
Performance," ret i8 %B ; }. define i8 @addshr(i8 %x) readnone nounwind {; %A = zext i8 %x to i9; %B = add i9 %A, 6 ;; 256 - 250 == 6; %C = lshr i9 %B, 8; %D = trunc i9 %C to i8; ret i8 %D; }. //===---------------------------------------------------------------------===//. From gcc bug 24696:; int; f (unsigned long a, unsigned long b, unsigned long c); {; return ((a & (c - 1)) != 0) || ((b & (c - 1)) != 0);; }; int; f (unsigned long a, unsigned long b, unsigned long c); {; return ((a & (c - 1)) != 0) | ((b & (c - 1)) != 0);; }; Both should combine to ((a|b) & (c-1)) != 0. Currently not optimized with; ""clang -emit-llvm-bc | opt -O3"". //===---------------------------------------------------------------------===//. From GCC Bug 20192:; #define PMD_MASK (~((1UL << 23) - 1)); void clear_pmd_range(unsigned long start, unsigned long end); {; if (!(start & ~PMD_MASK) && !(end & ~PMD_MASK)); f();; }; The expression should optimize to something like; ""!((start|end)&~PMD_MASK). Currently not optimized with ""clang; -emit-llvm-bc | opt -O3"". //===---------------------------------------------------------------------===//. unsigned int f(unsigned int i, unsigned int n) {++i; if (i == n) ++i; return; i;}; unsigned int f2(unsigned int i, unsigned int n) {++i; i += i == n; return i;}; These should combine to the same thing. Currently, the first function; produces better code on X86. //===---------------------------------------------------------------------===//. From GCC Bug 15784:; #define abs(x) x>0?x:-x; int f(int x, int y); {; return (abs(x)) >= 0;; }; This should optimize to x == INT_MIN. (With -fwrapv.) Currently not; optimized with ""clang -emit-llvm-bc | opt -O3"". //===---------------------------------------------------------------------===//. From GCC Bug 14753:; void; rotate_cst (unsigned int a); {; a = (a << 10) | (a >> 22);; if (a == 123); bar ();; }; void; minus_cst (unsigned int a); {; unsigned int tem;. tem = 20 - a;; if (tem == 5); bar ();; }; void; mask_gt (unsigned int a); {; /* ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/README.txt:21985,optimiz,optimized,21985,interpreter/llvm-project/llvm/lib/Target/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/README.txt,2,['optimiz'],['optimized']
Performance," return type. The operation has a mask and an explicit vector length parameter. Arguments:; """""""""""""""""""". The '``llvm.vp.inttoptr``' intrinsic takes a value to cast as its first operand; , which must be a vector of :ref:`integer <t_integer>` type, and a type to cast; it to return type, which must be a vector of pointers type.; The second operand is the vector mask. The return type, the value to cast, and; the vector mask have the same number of elements.; The third operand is the explicit vector length of the operation. Semantics:; """""""""""""""""""". The '``llvm.vp.inttoptr``' intrinsic converts ``value`` to return type by; applying either a zero extension or a truncation depending on the size of the; integer ``value``. If ``value`` is larger than the size of a pointer, then a; truncation is done. If ``value`` is smaller than the size of a pointer, then a; zero extension is done. If they are the same size, nothing is done (*no-op cast*).; The conversion is performed on lane positions below the explicit vector length; and where the vector mask is true. Masked-off lanes are ``poison``. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call <4 x ptr> @llvm.vp.inttoptr.v4p0i32.v4i32(<4 x i32> %a, <4 x i1> %mask, i32 %evl); ;; For all lanes below %evl, %r is lane-wise equivalent to %also.r. %t = inttoptr <4 x i32> %a to <4 x ptr>; %also.r = select <4 x i1> %mask, <4 x ptr> %t, <4 x ptr> poison. .. _int_vp_fcmp:. '``llvm.vp.fcmp.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare <16 x i1> @llvm.vp.fcmp.v16f32(<16 x float> <left_op>, <16 x float> <right_op>, metadata <condition code>, <16 x i1> <mask>, i32 <vector_length>); declare <vscale x 4 x i1> @llvm.vp.fcmp.nxv4f32(<vscale x 4 x float> <left_op>, <vscale x 4 x float> <right_op>, metadata <condition code>, <vscale x 4 x i1> <mask>, i32 <vector_length>); declare <256 x i1> @llvm.vp.fcmp.v256f64(<256 x double> <left_op>, <256 x double> <right_op>, metadata <conditi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:816400,perform,performed,816400,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['performed']
Performance," return values.; This attribute applies only to the particular copy of the pointer passed in; this argument. A caller could pass two copies of the same pointer with one; being annotated nocapture and the other not, and the callee could validly; capture through the non annotated parameter. .. code-block:: llvm. define void @f(ptr nocapture %a, ptr %b) {; ; (capture %b); }. call void @f(ptr @glb, ptr @glb) ; well-defined. ``nofree``; This indicates that callee does not free the pointer argument. This is not; a valid attribute for return values. .. _nest:. ``nest``; This indicates that the pointer parameter can be excised using the; :ref:`trampoline intrinsics <int_trampoline>`. This is not a valid; attribute for return values and can only be applied to one parameter. ``returned``; This indicates that the function always returns the argument as its return; value. This is a hint to the optimizer and code generator used when; generating the caller, allowing value propagation, tail call optimization,; and omission of register saves and restores in some cases; it is not; checked or enforced when generating the callee. The parameter and the; function return type must be valid operands for the; :ref:`bitcast instruction <i_bitcast>`. This is not a valid attribute for; return values and can only be applied to one parameter. ``nonnull``; This indicates that the parameter or return pointer is not null. This; attribute may only be applied to pointer typed parameters. This is not; checked or enforced by LLVM; if the parameter or return pointer is null,; :ref:`poison value <poisonvalues>` is returned or passed instead.; The ``nonnull`` attribute should be combined with the ``noundef`` attribute; to ensure a pointer is not null or otherwise the behavior is undefined. ``dereferenceable(<n>)``; This indicates that the parameter or return pointer is dereferenceable. This; attribute may only be applied to pointer typed parameters. A pointer that; is dereferenceable can be loaded from s",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:60216,optimiz,optimizer,60216,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,2,['optimiz'],"['optimization', 'optimizer']"
Performance," root session (like,; for instance, the axis titles).; When a THStack is drawn with the option ""pads"", the number of lines is; now optimized to make sure there is no empty line. . TUnfold. Introduces this new class for solving inverse problems:. data histograms with Gaussian errors are decomposed into; several template distributions (""generator level"" bins). The result are new normalisation constants for the template; distributions (the unfolded ""generator level"" distribution). The solution can be tuned by properly adjusting the; regularisation parameter tau. A standard method, the L-curve scan is; implemented to help finding a good choice of this parameter. Two example tutorials are included to show the usage of this class: tutorials/math/testUnfiold1.C and tutorials/math/testUnfiold2.C. FitPanel; Add a new revised version of the Fit Panel with the following functionality:. Add support now for fitting, in addition to the TH1 and TGraph; also for TH2, TH3, TMultiGraph and TGraph2D and TTree (with un-binned; fits); Add possibility to select the data object directly from the Fit; panel. The Fit Panel can also be open directly from the TCanvas menu; (under Tools); Improve the function selection by having the possibility to; support user defined function, predefined functions and functions; used before for fitting. ; Allow the opening of the parameter dialog in case of linear; fitter. This is needed for example for fixing some of the; parameters; Improve minimization panel by adding some extra methods, like; combined for a combined migrad-simplex minimization (option; ""MINIMIZE"" in Minuit).; Improve the slider by adding a numeric entry. ; Add the Advanced Graphics dialog, that allows the user to perform; Contour and Scan operation on the last fit.; Fix various bugs in setting the fit model function and in; setting the parameters (values, limits, etc..). Here is how the fit panel is now:; ; These are the currently support methods for the new Advance Graphics dialog:;  ; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/hist/doc/v522/index.html:8890,perform,perform,8890,hist/doc/v522/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/hist/doc/v522/index.html,2,['perform'],['perform']
Performance," rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; buffer_inv.; - Ensures that the; preceding; global/local/generic; load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; acquire-fence-paired-atomic); has completed; before invalidating; the cache. This; satisfies the; requirements of; acquire.; - Ensures that all; previous memory; operations have; completed before a; following; global/local/generic; store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; release-fence-paired-atomic).; This satisfies the; requirements of; release. 2. buffer_inv sc0=1 sc1=1. - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; MTYPE NC global data.; MTYPE RW and CC memory will; never be stale due to the; memory probes. **Sequential Consistent Atomic**; ------------------------------------------------------------------------------------; load atomic seq_cst - singlethread - global *Same as corresponding; - wavefront - local load atomic acquire,; - generic except must generate; all instructions even; for OpenCL.*; load atomic seq_cst - workgroup - global 1. s_waitcnt lgkm/vmcnt(0); - generic; - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - s_waitcnt lgkmcnt(0) must; happen after; preceding; local/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; lgkmcnt(0) and so do; not need to be; considered.); - s_waitcnt vmcnt(0); must happen after; prece",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:330409,load,load,330409,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],['load']
Performance," rules; used by the ``DW_OP_call*`` operations. .. note::. Delete the description of how the ``DW_OP_call*`` operations evaluate a; ``DW_AT_location`` attribute as that is now described in the operations. .. note::. See the discussion about the ``DW_AT_location`` attribute in the; ``DW_OP_call*`` operation. Having each attribute only have a single; purpose and single execution semantics seems desirable. It makes it easier; for the consumer that no longer have to track the context. It makes it; easier for the producer as it can rely on a single semantics for each; attribute. For that reason, limiting the ``DW_AT_location`` attribute to only; supporting evaluating the location description of an object, and using a; different attribute and encoding class for the evaluation of DWARF; expression *procedures* on the same operation expression stack seems; desirable. 2. ``DW_AT_const_value``. .. note::. Could deprecate using the ``DW_AT_const_value`` attribute for; ``DW_TAG_variable`` or ``DW_TAG_formal_parameter`` debugger information; entries that have been optimized to a constant. Instead,; ``DW_AT_location`` could be used with a DWARF expression that produces an; implicit location description now that any location description can be; used within a DWARF expression. This allows the ``DW_OP_call*`` operations; to be used to push the location description of any variable regardless of; how it is optimized. 3. ``DW_AT_LLVM_memory_space``. A ``DW_AT_memory_space`` attribute with a constant value representing a source; language specific DWARF memory space (see 2.14 ""Memory Spaces""). If omitted,; defaults to ``DW_MSPACE_none``. A.4.2 Common Block Entries; ~~~~~~~~~~~~~~~~~~~~~~~~~~. A common block entry also has a ``DW_AT_location`` attribute whose value is a; DWARF expression E that describes the location of the common block at run-time.; The result of the attribute is obtained by evaluating E with a context that has; a result kind of a location description, an unspecified obj",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:174464,optimiz,optimized,174464,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,1,['optimiz'],['optimized']
Performance," run against each modules after the build finished.; Use `--intercept-first` and `--override-compiler` flags together to get; this model. The 1. and 3. are using compiler wrappers, which works only if the build; process respects the `CC` and `CXX` environment variables. (Some build; process can override these variable as command line parameter only. This case; you need to pass the compiler wrappers manually. eg.: `intercept-build; --override-compiler make CC=intercept-cc CXX=intercept-c++ all` where the; original build command would have been `make all` only.). The 1. runs the analyzer right after the real compilation. So, if the build; process removes removes intermediate modules (generated sources) the analyzer; output still kept. The 2. and 3. generate the compilation database first, and filters out those; modules which are not exists. So, it's suitable for incremental analysis during; the development. The 2. mode is available only on FreeBSD and Linux. Where library preload; is available from the dynamic loader. Not supported on OS X (unless System; Integrity Protection feature is turned off). `intercept-build` command uses only the 2. and 3. mode to generate the; compilation database. `analyze-build` does only run the analyzer against the; captured compiler calls. Known problems; --------------. Because it uses `LD_PRELOAD` or `DYLD_INSERT_LIBRARIES` environment variables,; it does not append to it, but overrides it. So builds which are using these; variables might not work. (I don't know any build tool which does that, but; please let me know if you do.). Problem reports; ---------------. If you find a bug in this documentation or elsewhere in the program or would; like to propose an improvement, please use the project's [issue tracker][3].; Please describing the bug and where you found it. If you have a suggestion; how to fix it, include that as well. Patches are also welcome. License; -------. The project is licensed under Apache-2.0 with LLVM exceptions.; Se",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/tools/scan-build-py/README.md:3786,load,loader,3786,interpreter/llvm-project/clang/tools/scan-build-py/README.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/tools/scan-build-py/README.md,1,['load'],['loader']
Performance," run; optimizations or code generator components against every program in the; tree, collecting statistics or running custom checks for correctness. At; base, this is how the nightly tester works, it's just one example of a; general framework. Lets say that you have an LLVM optimization pass, and you want to see; how many times it triggers. First thing you should do is add an LLVM; `statistic <ProgrammersManual.html#Statistic>`_ to your pass, which will; tally counts of things you care about. Following this, you can set up a test and a report that collects these; and formats them for easy viewing. This consists of two files, a; ""``test-suite/TEST.XXX.Makefile``"" fragment (where XXX is the name of; your test) and a ""``test-suite/TEST.XXX.report``"" file that indicates; how to format the output into a table. There are many example reports of; various levels of sophistication included with the test suite, and the; framework is very general. If you are interested in testing an optimization pass, check out the; ""libcalls"" test as an example. It can be run like this:. .. code-block:: bash. % cd llvm/projects/test-suite/MultiSource/Benchmarks # or some other level; % make TEST=libcalls report. This will do a bunch of stuff, then eventually print a table like this:. ::. Name | total | #exit |; ...; FreeBench/analyzer/analyzer | 51 | 6 |; FreeBench/fourinarow/fourinarow | 1 | 1 |; FreeBench/neural/neural | 19 | 9 |; FreeBench/pifft/pifft | 5 | 3 |; MallocBench/cfrac/cfrac | 1 | * |; MallocBench/espresso/espresso | 52 | 12 |; MallocBench/gs/gs | 4 | * |; Prolangs-C/TimberWolfMC/timberwolfmc | 302 | * |; Prolangs-C/agrep/agrep | 33 | 12 |; Prolangs-C/allroots/allroots | * | * |; Prolangs-C/assembler/assembler | 47 | * |; Prolangs-C/bison/mybison | 74 | * |; ... This basically is grepping the -stats output and displaying it in a; table. You can also use the ""TEST=libcalls report.html"" target to get; the table in HTML form, similarly for report.csv and report.tex. The source for t",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst:6154,optimiz,optimization,6154,interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst,1,['optimiz'],['optimization']
Performance," rundown is that after RTL generation, the following happens:. 1 . [t] jump optimization (jumps to jumps, etc); 2 . [t] Delete unreachable code; 3 . Compute live ranges for CSE; 4 . [t] Jump threading (jumps to jumps with identical or inverse conditions); 5 . [t] CSE; 6 . *** Conversion to SSA ; 7 . [t] SSA Based DCE; 8 . *** Conversion to LLVM; 9 . UnSSA; 10. GCSE; 11. LICM; 12. Strength Reduction; 13. Loop unrolling; 14. [t] CSE; 15. [t] DCE; 16. Instruction combination, register movement, scheduling... etc. I've marked optimizations with a [t] to indicate things that I believe to; be relatively trivial to implement in LLVM itself. The time consuming; things to reimplement would be SSA based PRE, Strength reduction & loop; unrolling... these would be the major things we would miss out on if we; did LLVM creation from tree code [inlining and other high level; optimizations are done on the tree representation]. Given the lack of ""strong"" optimizations that would take a long time to; reimplement, I am leaning a bit more towards creating LLVM from the tree; code. Especially given that SGI has GPL'd their compiler, including many; SSA based optimizations that could be adapted (besides the fact that their; code looks MUCH nicer than GCC :). Even if we choose to do LLVM code emission from RTL, we will almost; certainly want to move LLVM emission from step 8 down until at least CSE; has been rerun... which causes me to wonder if the SSA generation code; will still work (due to global variable dependencies and stuff). I assume; that it can be made to work, but might be a little more involved than we; would like. I'm continuing to look at the Tree -> RTL code. It is pretty gross; because they do some of the translation a statement at a time, and some; of it a function at a time... I'm not quite clear why and how the; distinction is drawn, but it does not appear that there is a wonderful; place to attach extra info. Anyways, I'm proceeding with the RTL -> LLVM conversion phas",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-06-01-GCCOptimizations.txt:1251,optimiz,optimizations,1251,interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-06-01-GCCOptimizations.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-06-01-GCCOptimizations.txt,1,['optimiz'],['optimizations']
Performance," running other heavy applications - the number of your own threads; running at any time may be lower than the limit due to demand on the CPU.; - The 'Real Time' is similar to 'CPU Time / number of threads' AND 'Compressed Throughput' is lower than expected; for your storage medium: this would imply that your CPU threads aren't decompressing data as fast as your storage; medium can provide it, and so decompression is the bottleneck.; The best way to decrease your runtime would be to utilise a system with a faster CPU, or make use; use of more threads when running, or use a compression algorithm with a higher decompression rate such as LZ4,; possibly at the cost of some extra file size. ### A note on caching. If your data is stored on a local disk, the system may cache some/all of the file in memory after it is; first read. If this is realistic of how your analysis will run - then there is no concern. However, if; you expect to only read files once in a while - and as such the files are unlikely to be in the cache -; consider clearing the cache before running rootreadspeed.; On Linux this can be done by running 'echo 3 > /proc/sys/vm/drop_caches' as a superuser,; or a specific file can be dropped from the cache with; `dd of=<FILENAME> oflag=nocache conv=notrunc,fdatasync count=0 > /dev/null 2>&1`. ### Known overhead of TTreeReader, RDataFrame. `rootreadspeed` is designed to read all data present in the specified branches, trees and files at the highest; possible speed. When the application bottleneck is not in the computations performed by analysis logic,; higher-level interfaces built on top of TTree such as TTreeReader and RDataFrame are known to add a significant; runtime overhead with respect to the runtimes reported by `rootreadspeed` (up to a factor 2). In realistic analysis; applications it has been observed that a large part of that overhead is compensated by the ability of TTreeReader and; RDataFrame to read branch values selectively, based on event cuts, and",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/readspeed/README.md:3720,cache,cache,3720,tree/readspeed/README.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/readspeed/README.md,2,['cache'],['cache']
Performance," safe. The next stage is to check if computation of the distance to a give; physical object specified by a path was required. If this is the case,; the modeller changes the state to point to the required object, converts; the current point and direction coordinates to the local frame of this; object and computes the distance to its shape. The node returned is the; one pointed by the input path in case the shape is crossed; otherwise; the returned value is NULL. In case the distance to next crossed; boundary is required, the current point has to be physically INSIDE the; shape pointed by the current volume. This is only insured in case a call; to `TGeoManager::FindNode()` was performed for the current point.; Therefore, the first step is to convert the global current point and; direction in the local reference frame of the current volume and to; compute the distance to exit its shape from inside. The returned value; is again compared to the maximum allowed step (the proposed one) and in; case the distance is safe no other action is performed and the proposed; step is approved. In case the boundary is closer, the computed distance; is taken as maximum allowed step. For optimization purposed, for; particles starting very close to the current volume boundary (less than; 0.01 microns) and exiting the algorithm stops here. After computing the distance to exit the current node, the distance to; the daughter of the current volume which is crossed next is computed by; **`TGeoManager`**`::FindNextDaughterBoundary().` This computes the; distance to all daughter candidates that can be possibly crossed by; using volume voxelization. The algorithm is efficient in average only in; case the number of daughters is greater than 4. For fewer nodes, a; simple loop is performed and the minimum distance (from a point outside; each shape) is taken and compared to the maximum allowed step. The step; value is again updated if `step<stepmax` . A special case is when the current node is decla",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md:162801,perform,performed,162801,documentation/users-guide/Geometry.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md,1,['perform'],['performed']
Performance," scheduling a LoopPass.; After the loop optimizations are done, these extra phi nodes; will be deleted by :ref:`-instcombine <passes-instcombine>`. Note that an exit block is outside of a loop, so how can such a phi ""close""; the value inside the loop since it uses it outside of it ? First of all,; for phi nodes, as; `mentioned in the LangRef <https://llvm.org/docs/LangRef.html#id311>`_:; ""the use of each incoming value is deemed to occur on the edge from the; corresponding predecessor block to the current block"". Now, an; edge to an exit block is considered outside of the loop because; if we take that edge, it leads us clearly out of the loop. However, an edge doesn't actually contain any IR, so in source code,; we have to choose a convention of whether the use happens in; the current block or in the respective predecessor. For LCSSA's purpose,; we consider the use happens in the latter (so as to consider the; use inside) [#point-of-use-phis]_. The major benefit of LCSSA is that it makes many other loop optimizations; simpler. First of all, a simple observation is that if one needs to see all; the outside users, they can just iterate over all the (loop closing); PHI nodes in the exit blocks (the alternative would be to; scan the def-use chain [#def-use-chain]_ of all instructions in the loop). Then, consider for example; :ref:`simple-loop-unswitch <passes-simple-loop-unswitch>` ing the loop above.; Because it is in LCSSA form, we know that any value defined inside of; the loop will be used either only inside the loop or in a loop closing; PHI node. In this case, the only loop closing PHI node is X4.; This means that we can just copy the loop and change the X4; accordingly, like so:. .. code-block:: C. c = ...;; if (c) {; for (...) {; if (true); X1 = ...; else; X2 = ...; X3 = phi(X1, X2);; }; } else {; for (...) {; if (false); X1' = ...; else; X2' = ...; X3' = phi(X1', X2');; }; }; X4 = phi(X3, X3'). Now, all uses of X4 will get the updated value (in general,; if a l",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LoopTerminology.rst:12922,optimiz,optimizations,12922,interpreter/llvm-project/llvm/docs/LoopTerminology.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LoopTerminology.rst,1,['optimiz'],['optimizations']
Performance," scoping rules; * Same enum in transparent scope refers to same type; * More detailed enum ``repr()`` printing, where possible; * Fix for (extern) explicit template instantiations in namespaces; * Throw objects from an std::tuple a life line; * Global pythonizors now always run on all classes; * Simplified iteraton over STL-like containers defining ``begin()``/``end()``. 2020-09-08: 1.8.2; -----------------. * Add ``cppyy.set_debug()`` to enable debug output for fixing template errors; * Cover more partial template instantiation use cases; * Force template instantiation if necessary for type deduction (i.e. ``auto``). 2020-09-01: 1.8.1; -----------------. * Setup build dependencies with pyproject.toml; * Simplified flow of pointer types for callbacks and cross-derivation; * Pointer-comparing objects performs auto-cast as needed; * Add main dimension for ptr-ptr to builtin returns; * Transparant handling of ptr-ptr to instance returns; * Stricter handling of bool type in overload with int types; * Fix uint64_t template instantiation regression; * Do not filter out enum data for ``__dir__``; * Fix lookup of interpreter-only explicit instantiations; * Fix inconsistent naming of std types with char_traits; * Further hiding of upstream code/dependencies; * Extended documentation. 2020-07-12: 1.8.0; -----------------. * Support mixing of Python and C++ types in global operators; * Capture Cling error messages from cppdef and include in the Python exception; * Add a cppexec method to evalutate statements in Cling's global scope; * Support initialization of ``std::array<>`` from sequences; * Support C++17 style initialization of common STL containers; * Allow base classes with no virtual destructor (with warning); * Support const by-value returns in Python-side method overrides; * Support for cross-language multiple inheritance of C++ bases; * Allow for pass-by-value of ``std::unique_ptr`` through move; * Reduced dependencies on upstream code; * Put remaining upstream code i",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst:11280,perform,performs,11280,bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst,1,['perform'],['performs']
Performance," second argument ``%Ptr`` is a; pointer to the vector type of ``%In``, and is the start address of the matrix; in memory. The third argument ``%Stride`` is a positive, constant integer with; ``%Stride >= <Rows>``. ``%Stride`` is used to compute the column memory; addresses. I.e., for a column ``C``, its start memory addresses is calculated; with ``%Ptr + C * %Stride``. The fourth argument ``<IsVolatile>`` is a boolean; value. The arguments ``<Rows>`` and ``<Cols>`` correspond to the number of rows; and columns, respectively, and must be positive, constant integers. The :ref:`align <attr_align>` parameter attribute can be provided; for the ``%Ptr`` arguments. Half Precision Floating-Point Intrinsics; ----------------------------------------. For most target platforms, half precision floating-point is a; storage-only format. This means that it is a dense encoding (in memory); but does not support computation in the format. This means that code must first load the half-precision floating-point; value as an i16, then convert it to float with; :ref:`llvm.convert.from.fp16 <int_convert_from_fp16>`. Computation can; then be performed on the float value (including extending to double; etc). To store the value back to memory, it is first converted to float; if needed, then converted to i16 with; :ref:`llvm.convert.to.fp16 <int_convert_to_fp16>`, then storing as an; i16 value. .. _int_convert_to_fp16:. '``llvm.convert.to.fp16``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i16 @llvm.convert.to.fp16.f32(float %a); declare i16 @llvm.convert.to.fp16.f64(double %a). Overview:; """""""""""""""""". The '``llvm.convert.to.fp16``' intrinsic function performs a conversion from a; conventional floating-point type to half precision floating-point format. Arguments:; """""""""""""""""""". The intrinsic function contains single argument - the value to be; converted. Semantics:; """""""""""""""""""". The '``llvm.convert.to.fp16``' intrinsic function performs a conversion from a; conve",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:681026,load,load,681026,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['load'],['load']
Performance," second list entry. The metadata identifying each scope is also itself a list containing two or; three entries. The first entry is the name of the scope. Note that if the name; is a string then it can be combined across functions and translation units. A; self-reference can be used to create globally unique scope names. A metadata; reference to the scope's domain is the second entry. A descriptive string may; optionally be provided as a third list entry. For example,. .. code-block:: llvm. ; Two scope domains:; !0 = !{!0}; !1 = !{!1}. ; Some scopes in these domains:; !2 = !{!2, !0}; !3 = !{!3, !0}; !4 = !{!4, !1}. ; Some scope lists:; !5 = !{!4} ; A list containing only scope !4; !6 = !{!4, !3, !2}; !7 = !{!3}. ; These two instructions don't alias:; %0 = load float, ptr %c, align 4, !alias.scope !5; store float %0, ptr %arrayidx.i, align 4, !noalias !5. ; These two instructions also don't alias (for domain !1, the set of scopes; ; in the !alias.scope equals that in the !noalias list):; %2 = load float, ptr %c, align 4, !alias.scope !5; store float %2, ptr %arrayidx.i2, align 4, !noalias !6. ; These two instructions may alias (for domain !0, the set of scopes in; ; the !noalias list is not a superset of, or equal to, the scopes in the; ; !alias.scope list):; %2 = load float, ptr %c, align 4, !alias.scope !6; store float %0, ptr %arrayidx.i, align 4, !noalias !7. '``fpmath``' Metadata; ^^^^^^^^^^^^^^^^^^^^^. ``fpmath`` metadata may be attached to any instruction of floating-point; type. It can be used to express the maximum acceptable error in the; result of that instruction, in ULPs, thus potentially allowing the; compiler to use a more efficient but less accurate method of computing; it. ULP is defined as follows:. If ``x`` is a real number that lies between two finite consecutive; floating-point numbers ``a`` and ``b``, without being equal to one; of them, then ``ulp(x) = |b - a|``, otherwise ``ulp(x)`` is the; distance between the two non-equal finite floating-poin",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:283443,load,load,283443,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['load'],['load']
Performance," sections. Further, section clusters can also be specified using the ``list=<arg>``; option. For example, ``list=spec.txt`` where ``spec.txt`` contains:. ::. !foo; !!1 !!3 !!5; !!2 !!4 !!6. will create two unique sections for function ``foo`` with the first; containing the odd numbered basic blocks and the second containing the; even numbered basic blocks. Basic block sections allow the linker to reorder basic blocks and enables; link-time optimizations like whole program inter-procedural basic block; reordering. Profile Guided Optimization; ---------------------------. Profile information enables better optimization. For example, knowing that a; branch is taken very frequently helps the compiler make better decisions when; ordering basic blocks. Knowing that a function ``foo`` is called more; frequently than another function ``bar`` helps the inliner. Optimization; levels ``-O2`` and above are recommended for use of profile guided optimization. Clang supports profile guided optimization with two different kinds of; profiling. A sampling profiler can generate a profile with very low runtime; overhead, or you can build an instrumented version of the code that collects; more detailed profile information. Both kinds of profiles can provide execution; counts for instructions in the code and information on branches taken and; function invocation. Regardless of which kind of profiling you use, be careful to collect profiles; by running your code with inputs that are representative of the typical; behavior. Code that is not exercised in the profile will be optimized as if it; is unimportant, and the compiler may make poor optimization choices for code; that is disproportionately used while profiling. Differences Between Sampling and Instrumentation; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Although both techniques are used for similar purposes, there are important; differences between the two:. 1. Profile data generated with one cannot be used by the other, and the",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:90029,optimiz,optimization,90029,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,1,['optimiz'],['optimization']
Performance," serial calculation of a `RooNLLVar`.; 2. `LikelihoodGradientJob` calculates the partial derivatives or the gradient in parallel on multiple CPUs/cores, based on `RooFit::MultiProcess`, which is a fork-based multi-processing task execution framework with dynamic load balancing. Other possible implementations could use the GPU or external tools like TensorFlow. The coupling of all these classes to `RooMinimizer` is made via the `MinuitFcnGrad` class, which owns the `Wrappers` that calculate the likelihood components. Note: a second `LikelihoodWrapper` class called `LikelihoodJob` is also available.; This class emulates the existing `NumCPU(>1)` functionality of the `RooAbsTestStatistic` tree, which is implemented based on `RooRealMPFE`.; This class is not yet thoroughly tested and should not be considered production ready. ### Usage example: `MultiProcess` enabled parallel gradient calculator. The main selling point of using `RooFit::TestStatistics` from a performance point of view is the implementation of the `RooFit::MultiProcess` based `LikelihoodGradientJob` calculator class.; To use it, one should create a `RooMinimizer` using the new constructor that takes a `RooAbsL`-based likelihood instead of a `RooAbsReal`. Taking any of the above created `likelihood` objects (as long as they are in a `std::shared_ptr`), we can create a `RooMinimizer` with parallel gradient calculation using:; ``` {.cpp}; std::shared_ptr<RooAbsL> likelihood = /* see examples above */;; RooMinimizer m(likelihood);; ```. By default, `RooFit::MultiProcess` spins up as many workers as there are cores in the system (as detected by `std::thread::hardware_concurrency()`).; To change the number of workers, call `RooFit::MultiProcess::Config::setDefaultNWorkers(desired_N_workers)` **before** creating the `RooMinimizer`. As noted above, offsetting is purely a function of the `RooMinimizer` when using `TestStatistics` classes.; Whereas with `fitTo` we can pass in a `RooFit::Offset(true)` optional `Roo",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/developers/test_statistics.md:8125,perform,performance,8125,roofit/doc/developers/test_statistics.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/developers/test_statistics.md,1,['perform'],['performance']
Performance," set of condition flags we need to capture; prior to entering each basic block and reuse a common `cmovCC` sequence for; those.; * We could further reuse suffixes when there are multiple `cmovCC`; instructions required to capture the set of flags. Currently this is; believed to not be worth the cost as paired flags are relatively rare and; suffixes of them are exceedingly rare.; * A common pattern in x86 is to have multiple conditional jump instructions; that use the same flags but handle different conditions. Naively, we could; consider each fallthrough between them an ""edge"" but this causes a much more; complex control flow graph. Instead, we accumulate the set of conditions; necessary for fallthrough and use a sequence of `cmovCC` instructions in a; single fallthrough edge to track it. Second, we trade register pressure for simpler `cmovCC` instructions by; allocating a register for the ""bad"" state. We could read that value from memory; as part of the conditional move instruction, however, this creates more; micro-ops and requires the load-store unit to be involved. Currently, we place; the value into a virtual register and allow the register allocator to decide; when the register pressure is sufficient to make it worth spilling to memory; and reloading. #### Hardening Loads. Once we have the predicate accumulated into a special value for correct vs.; misspeculated, we need to apply this to loads in a way that ensures they do not; leak secret data. There are two primary techniques for this: we can either; harden the loaded value to prevent observation, or we can harden the address; itself to prevent the load from occurring. These have significantly different; performance tradeoffs. ##### Hardening loaded values. The most appealing way to harden loads is to mask out all of the bits loaded.; The key requirement is that for each bit loaded, along the misspeculated path; that bit is always fixed at either 0 or 1 regardless of the value of the bit; loaded. The most ob",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:22050,load,load-store,22050,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,1,['load'],['load-store']
Performance," setting called `ROOT.ZipMode` is now unused and ignored.; Instead, use `Root.CompressionAlgorithm` which sets the compression algorithm according to the values of [ECompression](https://root.cern/doc/master/Compression_8h.html#a0a7df9754a3b7be2b437f357254a771c):. * 0: use the default value of `R__ZipMode` (currently selecting ZLIB); * 1: use ZLIB (the default until 6.12 and from 6.16); * 2: use LZMA; * 3: legacy, please don't use; * 4: LZ4. ### TRef. * Improve thread scalability of `TRef`. Creating and looking up a lot of `TRef` from the same `processID` now has practically perfect weak scaling. ### Parallelism; * Upgrade the built-in TBB version to 2019_U1. ### Type System; * Upgrade the `TClass::GetMissingDictionaries` method to support `std::unique_ptr`, `std::array` and `std::tuple` without getting trapped in the internal STL implementation details. ## I/O Libraries. * To allow for increase run-time performance and increase thread scalability the override ability of `TFile::GetStreamerInfoList` is replaced by an override of `TFile::GetStreamerInfoListImp` with updated return type and arguments. If a class override `TFile::GetStreamerInfoList` you will now see a compilation error like:. ```; /opt/build/root_builds/rootcling.cmake/include/TSQLFile.h:225:19: error: declaration of 'GetStreamerInfoList' overrides a 'final' function; virtual TList *GetStreamerInfoList();; ^; /opt/build/root_builds/rootcling.cmake/include/TFile.h:231:24: note: overridden virtual function is here; virtual TList *GetStreamerInfoList() final; // Note: to override behavior, please override GetStreamerInfoListImpl; ^; ```. Instead you need to override the protected method:. ```; InfoListRet GetStreamerInfoListImpl(bool lookupSICache);; ```. which can be implemented as. ```; InfoListRet DerivedClass::GetStreamerInfoListImpl(bool /*lookupSICache*/) {; ROOT::Internal::RConcurrentHashColl::HashValue hash;; TList *infolist = nullptr;; //; // Body of the former Derived::GetStreamerInfoList with ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v616/index.md:3969,perform,performance,3969,README/ReleaseNotes/v616/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v616/index.md,2,"['perform', 'scalab']","['performance', 'scalability']"
Performance," should be treated as a memory-barrier. This was; inaccurate in general and was changed so that now each instruction has an; IsAStoreBarrier and IsALoadBarrier flag. These flags are mca specific and; default to false for every instruction. If any instruction should have either of; these flags set, it should be done within the target's InstrPostProcess class.; For an example, look at the `X86InstrPostProcess::postProcessInstruction` method; within `llvm/lib/Target/X86/MCA/X86CustomBehaviour.cpp`. A load/store barrier consumes one entry of the load/store queue. A load/store; barrier enforces ordering of loads/stores. A younger load cannot pass a load; barrier. Also, a younger store cannot pass a store barrier. A younger load; has to wait for the memory/load barrier to execute. A load/store barrier is; ""executed"" when it becomes the oldest entry in the load/store queue(s). That; also means, by construction, all of the older loads/stores have been executed. In conclusion, the full set of load/store consistency rules are:. #. A store may not pass a previous store.; #. A store may not pass a previous load (regardless of ``-noalias``).; #. A store has to wait until an older store barrier is fully executed.; #. A load may pass a previous load.; #. A load may not pass a previous store unless ``-noalias`` is set.; #. A load has to wait until an older load barrier is fully executed. In-order Issue and Execute; """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; In-order processors are modelled as a single ``InOrderIssueStage`` stage. It; bypasses Dispatch, Scheduler and Load/Store unit. Instructions are issued as; soon as their operand registers are available and resource requirements are; met. Multiple instructions can be issued in one cycle according to the value of; the ``IssueWidth`` parameter in LLVM's scheduling model. Once issued, an instruction is moved to ``IssuedInst`` set until it is ready to; retire. :program:`llvm-mca` ensures that writes are committed in-order. However,; an in",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:42728,load,load,42728,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,1,['load'],['load']
Performance," show that; the target can lower correctly with extensive LIT tests (IR to MIR, MIR to; ASM, etc).; 5. Some patches may be approved before others, but only after *all* patches are; approved that the whole set can be merged in one go. This is to guarantee; that all changes are good as a single block.; 6. After the initial merge, the target community can stop numbering patches and; start working asynchronously on the target to complete support. They should; still seek review from those who helped them in the initial phase, to make; sure the progress is still consistent.; 7. Once all official requirements have been fulfilled (as above), the code owner; should request the target to be enabled by default by sending another RFC to; the `LLVM Discourse forums`_. Adding an Established Project To the LLVM Monorepo; --------------------------------------------------. The `LLVM monorepo <https://github.com/llvm/llvm-project>`_ is the centerpoint; of development in the LLVM world, and has all of the primary LLVM components,; including the LLVM optimizer and code generators, Clang, LLDB, etc. `Monorepos; in general <https://en.wikipedia.org/wiki/Monorepo>`_ are great because they; allow atomic commits to the project, simplify CI, and make it easier for; subcommunities to collaborate. Like new targets, most projects already in the monorepo are considered to be in; the *core tier* of our :doc:`support policy<SupportPolicy>`. The burden to add; things to the LLVM monorepo needs to be very high - code that is added to this; repository is checked out by everyone in the community. As such, we hold; components to a high bar similar to ""official targets"", they:. * Must be generally aligned with the mission of the LLVM project to advance; compilers, languages, tools, runtimes, etc.; * Must conform to all of the policies laid out in this developer policy; document, including license, patent, coding standards, and code of conduct.; * Must have an active community that maintains the code, in",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:45175,optimiz,optimizer,45175,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,1,['optimiz'],['optimizer']
Performance," single leading ``/`` removed.; ======================= ==============. Other substitutions are provided that are variations on this base set and; further substitution patterns can be defined by each test module. See the; modules :ref:`local-configuration-files`. More detailed information on substitutions can be found in the; :doc:`../TestingGuide`. TEST RUN OUTPUT FORMAT; ~~~~~~~~~~~~~~~~~~~~~~. The :program:`lit` output for a test run conforms to the following schema, in; both short and verbose modes (although in short mode no PASS lines will be; shown). This schema has been chosen to be relatively easy to reliably parse by; a machine (for example in buildbot log scraping), and for other tools to; generate. Each test result is expected to appear on a line that matches:. .. code-block:: none. <result code>: <test name> (<progress info>). where ``<result-code>`` is a standard test result such as PASS, FAIL, XFAIL,; XPASS, UNRESOLVED, or UNSUPPORTED. The performance result codes of IMPROVED and; REGRESSED are also allowed. The ``<test name>`` field can consist of an arbitrary string containing no; newline. The ``<progress info>`` field can be used to report progress information such; as (1/300) or can be empty, but even when empty the parentheses are required. Each test result may include additional (multiline) log information in the; following format:. .. code-block:: none. <log delineator> TEST '(<test name>)' <trailing delineator>; ... log message ...; <log delineator>. where ``<test name>`` should be the name of a preceding reported test, ``<log; delineator>`` is a string of ""*"" characters *at least* four characters long; (the recommended length is 20), and ``<trailing delineator>`` is an arbitrary; (unparsed) string. The following is an example of a test run output which consists of four tests A,; B, C, and D, and a log message for the failing test C:. .. code-block:: none. PASS: A (1 of 4); PASS: B (2 of 4); FAIL: C (3 of 4); ******************** TEST 'C' FAILE",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/lit.rst:22773,perform,performance,22773,interpreter/llvm-project/llvm/docs/CommandGuide/lit.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/lit.rst,1,['perform'],['performance']
Performance," single-threaded mode, and; using the resultant compiler to build a copy of LLVM with multithreading; support. .. _shutdown:. Ending Execution with ``llvm_shutdown()``; -----------------------------------------. When you are done using the LLVM APIs, you should call ``llvm_shutdown()`` to; deallocate memory used for internal structures. .. _managedstatic:. Lazy Initialization with ``ManagedStatic``; ------------------------------------------. ``ManagedStatic`` is a utility class in LLVM used to implement static; initialization of static resources, such as the global type tables. In a; single-threaded environment, it implements a simple lazy initialization scheme.; When LLVM is compiled with support for multi-threading, however, it uses; double-checked locking to implement thread-safe lazy initialization. .. _llvmcontext:. Achieving Isolation with ``LLVMContext``; ----------------------------------------. ``LLVMContext`` is an opaque class in the LLVM API which clients can use to; operate multiple, isolated instances of LLVM concurrently within the same; address space. For instance, in a hypothetical compile-server, the compilation; of an individual translation unit is conceptually independent from all the; others, and it would be desirable to be able to compile incoming translation; units concurrently on independent server threads. Fortunately, ``LLVMContext``; exists to enable just this kind of scenario!. Conceptually, ``LLVMContext`` provides isolation. Every LLVM entity; (``Module``\ s, ``Value``\ s, ``Type``\ s, ``Constant``\ s, etc.) in LLVM's; in-memory IR belongs to an ``LLVMContext``. Entities in different contexts; *cannot* interact with each other: ``Module``\ s in different contexts cannot be; linked together, ``Function``\ s cannot be added to ``Module``\ s in different; contexts, etc. What this means is that is safe to compile on multiple; threads simultaneously, as long as no two threads operate on entities within the; same context. In practice, very fe",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:122708,concurren,concurrently,122708,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,1,['concurren'],['concurrently']
Performance," singlethread - global 1. buffer/global/ds/flat_atomic; - wavefront - local; - generic; atomicrmw release - workgroup - global 1. s_waitcnt lgkmcnt(0); - generic; - If OpenCL, omit.; - Must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to local have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global/flat_atomic; atomicrmw release - workgroup - local 1. ds_atomic; atomicrmw release - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global and local; have completed; before performing; the atomicrmw that; is being released. 2. buffer/global/flat_atomic; fence release - singlethread *none* *none*; - wavefront; fence release - workgroup *none* 1. s_waitcnt lgkmcnt(0). - If OpenCL and; address space is; not generic, omit.; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate. If; fence had an; address space then; set to address; space of OpenCL; fence flag, or to; generic if both; local and global; flags are; specified.; - Must happen after; any preceding; local/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Must happen before; any following store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Ensu",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:221349,load,load,221349,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],['load']
Performance," situations. LLVM allows a compiler implementor; to make complete decisions about what optimizations to use, in which; order, and in what situation. As a concrete example, LLVM supports both ""whole module"" passes, which; look across as large of body of code as they can (often a whole file,; but if run at link time, this can be a substantial portion of the whole; program). It also supports and includes ""per-function"" passes which just; operate on a single function at a time, without looking at other; functions. For more information on passes and how they are run, see the; `How to Write a Pass <../../WritingAnLLVMPass.html>`_ document and the; `List of LLVM Passes <../../Passes.html>`_. For Kaleidoscope, we are currently generating functions on the fly, one; at a time, as the user types them in. We aren't shooting for the; ultimate optimization experience in this setting, but we also want to; catch the easy and quick stuff where possible. As such, we will choose; to run a few per-function optimizations as the user types the function; in. If we wanted to make a ""static Kaleidoscope compiler"", we would use; exactly the code we have now, except that we would defer running the; optimizer until the entire file has been parsed. In addition to the distinction between function and module passes, passes can be; divided into transform and analysis passes. Transform passes mutate the IR, and; analysis passes compute information that other passes can use. In order to add; a transform pass, all analysis passes it depends upon must be registered in; advance. In order to get per-function optimizations going, we need to set up a; `FunctionPassManager <../../WritingAnLLVMPass.html#what-passmanager-doesr>`_ to hold; and organize the LLVM optimizations that we want to run. Once we have; that, we can add a set of optimizations to run. We'll need a new; FunctionPassManager for each module that we want to optimize, so we'll; add to a function created in the previous chapter (``InitializeMod",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl04.rst:4582,optimiz,optimizations,4582,interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl04.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl04.rst,1,['optimiz'],['optimizations']
Performance," so users are likely to want, for example,; both LLVM-2.6 and LLVM-2.7 installed at the same time to support apps developed; against each. Compile Flags; =============. LLVM runs much more quickly when it's optimized and assertions are removed.; However, such a build is currently incompatible with users who build without; defining ``NDEBUG``, and the lack of assertions makes it hard to debug problems; in user code. We recommend allowing users to install both optimized and debug; versions of LLVM in parallel. The following configure flags are relevant:. ``--disable-assertions``; Builds LLVM with ``NDEBUG`` defined. Changes the LLVM ABI. Also available; by setting ``DISABLE_ASSERTIONS=0|1`` in ``make``'s environment. This; defaults to enabled regardless of the optimization setting, but it slows; things down. ``--enable-debug-symbols``; Builds LLVM with ``-g``. Also available by setting ``DEBUG_SYMBOLS=0|1`` in; ``make``'s environment. This defaults to disabled when optimizing, so you; should turn it back on to let users debug their programs. ``--enable-optimized``; (For git checkouts) Builds LLVM with ``-O2`` and, by default, turns off; debug symbols. Also available by setting ``ENABLE_OPTIMIZED=0|1`` in; ``make``'s environment. This defaults to enabled when not in a; checkout. C++ Features; ============. RTTI; LLVM disables RTTI by default. Add ``REQUIRES_RTTI=1`` to your environment; while running ``make`` to re-enable it. This will allow users to build with; RTTI enabled and still inherit from LLVM classes. Shared Library; ==============. Configure with ``--enable-shared`` to build; ``libLLVM-<major>.<minor>.(so|dylib)`` and link the tools against it. This; saves lots of binary size at the cost of some startup time. Dependencies; ============. ``--enable-libffi``; Depend on `libffi <http://sources.redhat.com/libffi/>`_ to allow the LLVM; interpreter to call external functions. ``--with-oprofile``. Depend on `libopagent; <http://oprofile.sourceforge.net/doc/devel/ind",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Packaging.rst:1449,optimiz,optimizing,1449,interpreter/llvm-project/llvm/docs/Packaging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Packaging.rst,1,['optimiz'],['optimizing']
Performance," software), please do read the section below on; 'benchmark' selection. Please note that this script is only tested on a few Linux distros. Patches to; add support for other platforms, as always, are highly appreciated. :). This script also supports a ``--dry-run`` option, which causes it to print; important commands instead of running them. Selecting 'benchmarks'; ======================. PGO does best when the profiles gathered represent how the user plans to use the; compiler. Notably, highly accurate profiles of llc building x86_64 code aren't; incredibly helpful if you're going to be targeting ARM. By default, the script above does two things to get solid coverage. It:. - runs all of Clang and LLVM's lit tests, and; - uses the instrumented Clang to build Clang, LLVM, and all of the other; LLVM subprojects available to it. Together, these should give you:. - solid coverage of building C++,; - good coverage of building C,; - great coverage of running optimizations,; - great coverage of the backend for your host's architecture, and; - some coverage of other architectures (if other arches are supported backends). Altogether, this should cover a diverse set of uses for Clang and LLVM. If you; have very specific needs (e.g. your compiler is meant to compile a large browser; for four different platforms, or similar), you may want to do something else.; This is configurable in the script itself. Building Clang with PGO; =======================. If you prefer to not use the script or the cmake cache, this briefly goes over; how to build Clang/LLVM with PGO. First, you should have at least LLVM, Clang, and compiler-rt checked out; locally. Next, at a high level, you're going to need to do the following:. 1. Build a standard Release Clang and the relevant libclang_rt.profile library; 2. Build Clang using the Clang you built above, but with instrumentation; 3. Use the instrumented Clang to generate profiles, which consists of two steps:. - Running the instrumented Clang/LLVM",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToBuildWithPGO.rst:2329,optimiz,optimizations,2329,interpreter/llvm-project/llvm/docs/HowToBuildWithPGO.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToBuildWithPGO.rst,1,['optimiz'],['optimizations']
Performance," specific address space identifier AS. The operation is equivalent to performing ``DW_OP_swap;; DW_OP_LLVM_form_aspace_address; DW_OP_deref_size S``. The zero-extended; value V retrieved is left on the stack with the generic type. *This operation is deprecated as the* ``DW_OP_LLVM_form_aspace_address``; *operation can be used and provides greater expressiveness.*. 7. ``DW_OP_xderef_type`` *Deprecated*. ``DW_OP_xderef_type`` has two operands. The first is a 1-byte unsigned; integral constant S. The second operand is an unsigned LEB128 integer DR; that represents the byte offset of a debugging information entry D relative; to the beginning of the current compilation unit, that provides the type T; of the result value. It pops two stack entries. The first must be an integral type value that; represents an address A. The second must be an integral type value that; represents a target architecture specific address space identifier AS. The operation is equivalent to performing ``DW_OP_swap;; DW_OP_LLVM_form_aspace_address; DW_OP_deref_type S DR``. The value V; retrieved is left on the stack with the type T. *This operation is deprecated as the* ``DW_OP_LLVM_form_aspace_address``; *operation can be used and provides greater expressiveness.*. 8. ``DW_OP_entry_value`` *Deprecated*. ``DW_OP_entry_value`` pushes the value of an expression that is evaluated in; the context of the calling frame. *It may be used to determine the value of arguments on entry to the current; call frame provided they are not clobbered.*. It has two operands. The first is an unsigned LEB128 integer S. The second; is a block of bytes, with a length equal S, interpreted as a DWARF; operation expression E. E is evaluated with the current context, except the result kind is; unspecified, the call frame is the one that called the current frame, the; program location is the call site in the calling frame, the object is; unspecified, and the initial stack is empty. The calling frame information; is obtained b",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:95053,perform,performing,95053,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,1,['perform'],['performing']
Performance," specific; non-dynamic rounding mode which does not match the actual rounding mode at; runtime results in undefined behavior. The exception behavior argument is a metadata string describing the floating; point exception semantics that required for the intrinsic. This argument; must be one of the following strings:. ::. ""fpexcept.ignore""; ""fpexcept.maytrap""; ""fpexcept.strict"". If this argument is ""fpexcept.ignore"" optimization passes may assume that the; exception status flags will not be read and that floating-point exceptions will; be masked. This allows transformations to be performed that may change the; exception semantics of the original code. For example, FP operations may be; speculatively executed in this case whereas they must not be for either of the; other possible values of this argument. If the exception behavior argument is ""fpexcept.maytrap"" optimization passes; must avoid transformations that may raise exceptions that would not have been; raised by the original code (such as speculatively executing FP operations), but; passes are not required to preserve all exceptions that are implied by the; original code. For example, exceptions may be potentially hidden by constant; folding. If the exception behavior argument is ""fpexcept.strict"" all transformations must; strictly preserve the floating-point exception semantics of the original code.; Any FP exception that would have been raised by the original code must be raised; by the transformed code, and the transformed code must not raise any FP; exceptions that would not have been raised by the original code. This is the; exception behavior argument that will be used if the code being compiled reads; the FP exception status flags, but this mode can also be used with code that; unmasks FP exceptions. The number and order of floating-point exceptions is NOT guaranteed. For; example, a series of FP operations that each may raise exceptions may be; vectorized into a single instruction that raises each unique ex",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:870526,optimiz,optimization,870526,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['optimiz'],['optimization']
Performance," stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. fence acq_rel - singlethread *none* *none*; - wavefront; fence acq_rel - workgroup *none* 1. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - If OpenCL and; address space is; local, omit; vmcnt(0).; - However,; since LLVM; currently has no; address space on; the fence need to; conservatively; always generate; (see comment for; previous fence).; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that all; memory operations; have; completed before; performing any; following global; memory operations.; - Ensures that the; preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; acquire-fence-paired-atomic); has completed; before following; global memory; operations. This; satisfies the; requirements of; acquire.; - Ensures that all; previous memory; operations have; completed before a; following; local/generic store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; release-fence-paired-atomic).; This satisfies the; requirements of; release.; - Must happen before; the following; buffer_wbinvl1_vol.; - Ensures that the; acquire-fence-paired; atomic has completed; before invalidating; the; cache. Therefore; any following; locations read must; be no older than; the value read by; the; acquire-fence-paired-atomic. 2. buffer_wbinvl1_vol. - If not TgSplit execution;",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:275075,perform,performing,275075,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['perform'],['performing']
Performance," stale global data. load atomic acquire - system - global 1. buffer/global/flat_load; glc=1; 2. s_waitcnt vmcnt(0). - Must happen before; following buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures the load; has completed; before invalidating; the cache. 3. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. load atomic acquire - agent - generic 1. flat_load glc=1; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the flat_load; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. load atomic acquire - system - generic 1. flat_load glc=1; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL omit; lgkmcnt(0).; - Must happen before; following; buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures the flat_load; has completed; before invalidating; the caches. 3. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. atomicrmw acquire - singlethread - global 1. buffer/global/flat_atomic; - wavefront - generic; atomicrmw acquire - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; be used.*. 1. ds_atomic; atomicrmw acquire - workgroup - global 1. buffer/global_atomic; 2. s_waitcnt vmcnt(0). - If not TgSplit exe",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:248117,load,loads,248117,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['loads']
Performance," store/store; atomic/; atomicrmw-no-return-value.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global/flat_atomic; atomicrmw release - workgroup - local 1. s_waitcnt vmcnt(0) & vscnt(0). - If CU wavefront execution; mode, omit.; - If OpenCL, omit.; - Could be split into; separate s_waitcnt; vmcnt(0) and s_waitcnt; vscnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/load; atomic/; atomicrmw-with-return-value.; - s_waitcnt vscnt(0); must happen after; any preceding; global/generic; store/store atomic/; atomicrmw-no-return-value.; - Must happen before; the following; store.; - Ensures that all; global memory; operations have; completed before; performing the; store that is being; released. 2. ds_atomic; atomicrmw release - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0) & vscnt(0). - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0), s_waitcnt; vscnt(0) and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/load atomic/; atomicrmw-with-return-value.; - s_waitcnt vscnt(0); must happen after; any preceding; global/generic; store/store atomic/; atomicrmw-no-return-value.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global and local; have completed; before performing; the atomicrmw that; is being released. 2. buffer/global/flat_atomic; fence release - singlethread *none* ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:359090,perform,performing,359090,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['perform'],['performing']
Performance," stray ``#pragma clang optimize on`` does not selectively enable; additional optimizations when compiling at low optimization levels. This feature; can only be used to selectively disable optimizations. The pragma has an effect on functions only at the point of their definition; for; function templates, this means that the state of the pragma at the point of an; instantiation is not necessarily relevant. Consider the following example:. .. code-block:: c++. template<typename T> T twice(T t) {; return 2 * t;; }. #pragma clang optimize off; template<typename T> T thrice(T t) {; return 3 * t;; }. int container(int a, int b) {; return twice(a) + thrice(b);; }; #pragma clang optimize on. In this example, the definition of the template function ``twice`` is outside; the pragma region, whereas the definition of ``thrice`` is inside the region.; The ``container`` function is also in the region and will not be optimized, but; it causes the instantiation of ``twice`` and ``thrice`` with an ``int`` type; of; these two instantiations, ``twice`` will be optimized (because its definition; was outside the region) and ``thrice`` will not be optimized. Clang also implements MSVC's range-based pragma,; ``#pragma optimize(""[optimization-list]"", on | off)``. At the moment, Clang only; supports an empty optimization list, whereas MSVC supports the arguments, ``s``,; ``g``, ``t``, and ``y``. Currently, the implementation of ``pragma optimize`` behaves; the same as ``#pragma clang optimize``. All functions; between ``off`` and ``on`` will be decorated with the ``optnone`` attribute. .. code-block:: c++. #pragma optimize("""", off); // This function will be decorated with optnone.; void f1() {}. #pragma optimize("""", on); // This function will be optimized with whatever was specified on; // the commandline.; void f2() {}. // This will warn with Clang's current implementation.; #pragma optimize(""g"", on); void f3() {}. For MSVC, an empty optimization list and ``off`` parameter will turn off; all",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst:160766,optimiz,optimized,160766,interpreter/llvm-project/clang/docs/LanguageExtensions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst,3,['optimiz'],['optimized']
Performance," structured in three main sections. The first section collects a; few performance numbers; the goal of this section is to give a very quick; overview of the performance throughput. Important performance indicators are; **IPC**, **uOps Per Cycle**, and **Block RThroughput** (Block Reciprocal; Throughput). Field *DispatchWidth* is the maximum number of micro opcodes that are dispatched; to the out-of-order backend every simulated cycle. For processors with an; in-order backend, *DispatchWidth* is the maximum number of micro opcodes issued; to the backend every simulated cycle. IPC is computed dividing the total number of simulated instructions by the total; number of cycles. Field *Block RThroughput* is the reciprocal of the block throughput. Block; throughput is a theoretical quantity computed as the maximum number of blocks; (i.e. iterations) that can be executed per simulated clock cycle in the absence; of loop carried dependencies. Block throughput is superiorly limited by the; dispatch rate, and the availability of hardware resources. In the absence of loop-carried data dependencies, the observed IPC tends to a; theoretical maximum which can be computed by dividing the number of instructions; of a single iteration by the `Block RThroughput`. Field 'uOps Per Cycle' is computed dividing the total number of simulated micro; opcodes by the total number of cycles. A delta between Dispatch Width and this; field is an indicator of a performance issue. In the absence of loop-carried; data dependencies, the observed 'uOps Per Cycle' should tend to a theoretical; maximum throughput which can be computed by dividing the number of uOps of a; single iteration by the `Block RThroughput`. Field *uOps Per Cycle* is bounded from above by the dispatch width. That is; because the dispatch width limits the maximum size of a dispatch group. Both IPC; and 'uOps Per Cycle' are limited by the amount of hardware parallelism. The; availability of hardware resources affects the resource pr",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:16549,throughput,throughput,16549,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,1,['throughput'],['throughput']
Performance," sub %eax, %edx; # LLVM-MCA-END foo; add %eax, %edx; # LLVM-MCA-END bar. Note that multiple anonymous regions cannot overlap. Also, overlapping regions; cannot have the same name. There is no support for marking regions from high-level source code, like C or; C++. As a workaround, inline assembly directives may be used:. .. code-block:: c++. int foo(int a, int b) {; __asm volatile(""# LLVM-MCA-BEGIN foo"":::""memory"");; a += 42;; __asm volatile(""# LLVM-MCA-END"":::""memory"");; a *= b;; return a;; }. However, this interferes with optimizations like loop vectorization and may have; an impact on the code generated. This is because the ``__asm`` statements are; seen as real code having important side effects, which limits how the code; around them can be transformed. If users want to make use of inline assembly; to emit markers, then the recommendation is to always verify that the output; assembly is equivalent to the assembly generated in the absence of markers.; The `Clang options to emit optimization reports <https://clang.llvm.org/docs/UsersManual.html#options-to-emit-optimization-reports>`_; can also help in detecting missed optimizations. INSTRUMENT REGIONS; ------------------. An InstrumentRegion describes a region of assembly code guarded by; special LLVM-MCA comment directives. .. code-block:: none. # LLVM-MCA-<INSTRUMENT_TYPE> <data>; ... ## asm. where `INSTRUMENT_TYPE` is a type defined by the target and expects; to use `data`. A comment starting with substring `LLVM-MCA-<INSTRUMENT_TYPE>`; brings data into scope for llvm-mca to use in its analysis for; all following instructions. If a comment with the same `INSTRUMENT_TYPE` is found later in the; instruction list, then the original InstrumentRegion will be; automatically ended, and a new InstrumentRegion will begin. If there are comments containing the different `INSTRUMENT_TYPE`,; then both data sets remain available. In contrast with an AnalysisRegion,; an InstrumentRegion does not need a comment to end the regi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:10590,optimiz,optimization,10590,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,1,['optimiz'],['optimization']
Performance," subtraction, and the second element of; which is a bit specifying if the signed subtraction resulted in an; overflow. Examples:; """""""""""""""""". .. code-block:: llvm. %res = call {i32, i1} @llvm.ssub.with.overflow.i32(i32 %a, i32 %b); %sum = extractvalue {i32, i1} %res, 0; %obit = extractvalue {i32, i1} %res, 1; br i1 %obit, label %overflow, label %normal. '``llvm.usub.with.overflow.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". This is an overloaded intrinsic. You can use ``llvm.usub.with.overflow``; on any integer bit width or vectors of integers. ::. declare {i16, i1} @llvm.usub.with.overflow.i16(i16 %a, i16 %b); declare {i32, i1} @llvm.usub.with.overflow.i32(i32 %a, i32 %b); declare {i64, i1} @llvm.usub.with.overflow.i64(i64 %a, i64 %b); declare {<4 x i32>, <4 x i1>} @llvm.usub.with.overflow.v4i32(<4 x i32> %a, <4 x i32> %b). Overview:; """""""""""""""""". The '``llvm.usub.with.overflow``' family of intrinsic functions perform; an unsigned subtraction of the two arguments, and indicate whether an; overflow occurred during the unsigned subtraction. Arguments:; """""""""""""""""""". The arguments (%a and %b) and the first element of the result structure; may be of integer types of any bit width, but they must have the same; bit width. The second element of the result structure must be of type; ``i1``. ``%a`` and ``%b`` are the two values that will undergo unsigned; subtraction. Semantics:; """""""""""""""""""". The '``llvm.usub.with.overflow``' family of intrinsic functions perform; an unsigned subtraction of the two arguments. They return a structure ---; the first element of which is the subtraction, and the second element of; which is a bit specifying if the unsigned subtraction resulted in an; overflow. Examples:; """""""""""""""""". .. code-block:: llvm. %res = call {i32, i1} @llvm.usub.with.overflow.i32(i32 %a, i32 %b); %sum = extractvalue {i32, i1} %res, 0; %obit = extractvalue {i32, i1} %res, 1; br i1 %obit, label %overflow, label %normal. '``llvm.smul.with.overflow",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:606287,perform,perform,606287,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['perform']
Performance," temporary destination to temp; followed by a TFile::Cp to the final destination); this allows to avoid; reported problems with small temp partitions (see Forum).; In XrdProofConn, enable cycling through the; authentication protocol presented by the server. This only holds for; the choice of the protocol, because the server currently supports only; one full handshake.; In test/stressProof.cxx, avoid interferences between the; settings used for the PROOF tutorial and possible local settings; (daemon, dataset manager).; Add possibility to control the automatic re-loading of; the <proof.conf> file via the keyword; 'reload:1'/'reload:0'; in the xpd.resource directive.; Move the validation of <proof.conf> at the; moment of use; this allows to specify a file path and to dynamically; create/modify/destroy the file; used by PoD.; Improve displaying speed of large log files. Fixes. Fix two severe; bugs in the way TTreeCache; was used in PROOF: one bug was de facto disactivating the cache; the; other was causing a std::bad_alloc exception to be thrown on workers; when opening a remote file after a local one.    ; Fix several problems in TChain::Draw including. drawing into an existing histogram, i.e.; chain->Draw(""var>>myhist"");. treatment of histogram merging in case of small; statistics, i.e. when; the autobinning is not or only partially active;. usage of existing canvases when different histogram; names are specified;. Fix a problem causing a duplication of the final feedback; object. Fix problem with determining the subdir name in; TFileMerger::MergeRecursive on Windows; Make sure that the default sandbox is under $HOME/.proof; Fix a problem with dataset validation in multi-level; master setups; Fix a problem with ordinal numbers in multi-master setups; Fix a problem with defining the internal paths for; executables when configuring with '--prefix'; Fix backward-incompatibility issue giving the error; message  ""unknown action code: 5112""; Fix a few problems with file ret",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html:8749,cache,cache,8749,proof/doc/v524/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html,2,['cache'],['cache']
Performance, test programs that are only a single source file in size. A; subdirectory may contain several programs. - `MultiSource/`. Contains subdirectories which entire programs with multiple source files.; Large benchmarks and whole applications go here. - `MicroBenchmarks/`. Programs using the [google-benchmark](https://github.com/google/benchmark); library. The programs define functions that are run multiple times until the; measurement results are statistically significant. - `External/`. Contains descriptions and test data for code that cannot be directly; distributed with the test-suite. The most prominent members of this; directory are the SPEC CPU benchmark suites.; See [External Suites](#external-suites). - `Bitcode/`. These tests are mostly written in LLVM bitcode. - `CTMark/`. Contains symbolic links to other benchmarks forming a representative sample; for compilation performance measurements. ### Benchmarks. Every program can work as a correctness test. Some programs are unsuitable for; performance measurements. Setting the `TEST_SUITE_BENCHMARKING_ONLY` CMake; option to `ON` will disable them. Configuration; -------------. The test-suite has configuration options to customize building and running the; benchmarks. CMake can print a list of them:. ```bash; % cd test-suite-build; # Print basic options:; % cmake -LH; # Print all options:; % cmake -LAH; ```. ### Common Configuration Options. - `CMAKE_C_FLAGS`. Specify extra flags to be passed to C compiler invocations. The flags are; also passed to the C++ compiler and linker invocations. See; [https://cmake.org/cmake/help/latest/variable/CMAKE_LANG_FLAGS.html](https://cmake.org/cmake/help/latest/variable/CMAKE_LANG_FLAGS.html). - `CMAKE_C_COMPILER`. Select the C compiler executable to be used. Note that the C++ compiler is; inferred automatically i.e. when specifying `path/to/clang` CMake will; automatically use `path/to/clang++` as the C++ compiler. See; [https://cmake.org/cmake/help/latest/variable/CMAKE_LANG_COMP,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:3606,perform,performance,3606,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,1,['perform'],['performance']
Performance," textures. The default value is off (0). ======================================== ================================================; Syntax Description; ======================================== ================================================; tfe Set tfe bit to 1.; ======================================== ================================================. .. _amdgpu_synid_sc0:. sc0; ~~~. For atomic opcodes, this modifier indicates that the instruction returns the value from memory; before the operation. For other opcodes, it is used together with :ref:`sc1<amdgpu_synid_sc1>`; to specify cache policy. ======================================== ================================================; Syntax Description; ======================================== ================================================; sc0 Set sc0 bit to 1.; ======================================== ================================================. .. _amdgpu_synid_sc1:. sc1; ~~~. This modifier is used together with :ref:`sc0<amdgpu_synid_sc0>` to specify cache; policy. ======================================== ================================================; Syntax Description; ======================================== ================================================; sc1 Set sc1 bit to 1.; ======================================== ================================================. .. _amdgpu_synid_nt:. nt; ~~. Indicates an operation with non-temporal data. ======================================== ================================================; Syntax Description; ======================================== ================================================; nt Set nt bit to 1.; ======================================== ================================================. MUBUF/MTBUF Modifiers; ---------------------. .. _amdgpu_synid_idxen:. idxen; ~~~~~. Specifies whether address components include an index. By default, the index is not used. May be used together with :ref:`offen<amdgpu_synid_offen>`. Cannot be us",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst:20564,cache,cache,20564,interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst,1,['cache'],['cache']
Performance," than; reading each requested branch individually, the TTreeCache will read all the; branches thus trading off the latencies inherent to multiple small reads for; the potential of requesting more data than needed by read from the disk or; server the baskets for too many branches. The default behavior can be changed by either updating one of the rootrc files; or by setting environment variables. The rootrc files, both the global and the; local ones, now support the following the resource variable TTreeCache.Size; which set the default size factor for auto sizing TTreeCache for TTrees. The; estimated cluster size for the TTree and this factor is used to give the cache; size. If option is set to zero auto cache creation is disabled and the default; cache size is the historical one (equivalent to factor 1.0). If set to; non zero auto cache creation is enabled and both auto created and; default sized caches will use the configured factor: 0.0 no automatic cache; and greater than 0.0 to enable cache. This value can be overridden by the; environment variable ROOT_TTREECACHE_SIZE. The resource variable TTreeCache.Prefill sets the default TTreeCache prefilling; type. The prefill type may be: 0 for no prefilling and 1 to prefill all; the branches. It can be overridden by the environment variable ROOT_TTREECACHE_PREFILL. In particular the default can be set back to the same as in version 5 by; setting TTreeCache.Size (or ROOT_TTREECACHE_SIZE) and TTreeCache.Prefill; (or ROOT_TTREECACHE_PREFILL) both to zero. TTree methods which are expected to modify a cache, like AddBranchToCache, will; attempt to setup a cache of default size if one does not exist, irrespective of; whether the auto cache creation is enabled. Additionally several methods giving; control of the cache have changed return type from void to Int_t, to be able to; return a code to indicate if there was an error. Usually TTree::SetCacheSize will no longer reset the list of branches to be; cached (either set or previ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md:13769,cache,cache,13769,README/ReleaseNotes/v604/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md,1,['cache'],['cache']
Performance," that a newer compiler cannot read an older; precompiled header (and vice-versa). Original file name; The full path of the header that was used to generate the AST file. Predefines buffer; Although not explicitly stored as part of the metadata, the predefines buffer; is used in the validation of the AST file. The predefines buffer itself; contains code generated by the compiler to initialize the preprocessor state; according to the current target, platform, and command-line options. For; example, the predefines buffer will contain ""``#define __STDC__ 1``"" when we; are compiling C without Microsoft extensions. The predefines buffer itself; is stored within the :ref:`pchinternals-sourcemgr`, but its contents are; verified along with the rest of the metadata. A chained PCH file (that is, one that references another PCH) and a module; (which may import other modules) have additional metadata containing the list; of all AST files that this AST file depends on. Each of those files will be; loaded along with this AST file. For chained precompiled headers, the language options, target architecture and; predefines buffer data is taken from the end of the chain, since they have to; match anyway. .. _pchinternals-sourcemgr:. Source Manager Block; ^^^^^^^^^^^^^^^^^^^^. The source manager block contains the serialized representation of Clang's; :ref:`SourceManager <SourceManager>` class, which handles the mapping from; source locations (as represented in Clang's abstract syntax tree) into actual; column/line positions within a source file or macro instantiation. The AST; file's representation of the source manager also includes information about all; of the headers that were (transitively) included when building the AST file. The bulk of the source manager block is dedicated to information about the; various files, buffers, and macro instantiations into which a source location; can refer. Each of these is referenced by a numeric ""file ID"", which is a; unique number (allocated st",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/PCHInternals.rst:9444,load,loaded,9444,interpreter/llvm-project/clang/docs/PCHInternals.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/PCHInternals.rst,1,['load'],['loaded']
Performance," that is; being released. 3. buffer/global_atomic; sc1=1; 4. s_waitcnt vmcnt(0). - Must happen before; following; buffer_inv.; - Ensures the; atomicrmw has; completed before; invalidating the; caches. 5. buffer_inv sc0=1 sc1=1. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; MTYPE NC global data.; MTYPE RW and CC memory will; never be stale due to the; memory probes. atomicrmw acq_rel - agent - generic 1. buffer_wbl2 sc1=1. - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at agent scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global have; completed before; performing the; atomicrmw that is; being released. 3. flat_atomic; 4. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_inv.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 5. buffer_inv sc1=1. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acq_rel - system - generic 1. buffer_wbl2 sc0=1 sc1=1. - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at system scope. 2. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:322679,load,load,322679,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],['load']
Performance," that might have; an exception thrown through them). For most targets, this is enabled by; default for C++. .. option:: -ftrapv. Generate code to catch integer overflow errors. Signed integer overflow is; undefined in C. With this flag, extra code is generated to detect this and; abort when it happens. .. option:: -fvisibility. This flag sets the default visibility level. .. option:: -fcommon, -fno-common. This flag specifies that variables without initializers get common linkage.; It can be disabled with :option:`-fno-common`. .. option:: -ftls-model=<model>. Set the default thread-local storage (TLS) model to use for thread-local; variables. Valid values are: ""global-dynamic"", ""local-dynamic"",; ""initial-exec"" and ""local-exec"". The default is ""global-dynamic"". The default; model can be overridden with the tls_model attribute. The compiler will try; to choose a more efficient model if possible. .. option:: -flto, -flto=full, -flto=thin, -emit-llvm. Generate output files in LLVM formats, suitable for link time optimization.; When used with :option:`-S` this generates LLVM intermediate language; assembly files, otherwise this generates LLVM bitcode format object files; (which may be passed to the linker depending on the stage selection options). The default for :option:`-flto` is ""full"", in which the; LLVM bitcode is suitable for monolithic Link Time Optimization (LTO), where; the linker merges all such modules into a single combined module for; optimization. With ""thin"", :doc:`ThinLTO <../ThinLTO>`; compilation is invoked instead. .. note::. On Darwin, when using :option:`-flto` along with :option:`-g` and; compiling and linking in separate steps, you also need to pass; ``-Wl,-object_path_lto,<lto-filename>.o`` at the linking step to instruct the; ld64 linker not to delete the temporary object file generated during Link; Time Optimization (this flag is automatically passed to the linker by Clang; if compilation and linking are done in a single step). This allows debu",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/CommandGuide/clang.rst:15089,optimiz,optimization,15089,interpreter/llvm-project/clang/docs/CommandGuide/clang.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/CommandGuide/clang.rst,1,['optimiz'],['optimization']
Performance," that there were a total of 35,504 samples; collected in main. All of those were at line 1 (the call to ``foo``).; Of those, 31,977 were spent inside the body of ``bar``. The last line; of the profile (``2: 0``) corresponds to line 2 inside ``main``. No; samples were collected there. .. _prof_instr:. Profiling with Instrumentation; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Clang also supports profiling via instrumentation. This requires building a; special instrumented version of the code and has some runtime; overhead during the profiling, but it provides more detailed results than a; sampling profiler. It also provides reproducible results, at least to the; extent that the code behaves consistently across runs. Clang supports two types of instrumentation: frontend-based and IR-based.; Frontend-based instrumentation can be enabled with the option ``-fprofile-instr-generate``,; and IR-based instrumentation can be enabled with the option ``-fprofile-generate``.; For best performance with PGO, IR-based instrumentation should be used. It has; the benefits of lower instrumentation overhead, smaller raw profile size, and; better runtime performance. Frontend-based instrumentation, on the other hand,; has better source correlation, so it should be used with source line-based; coverage testing. The flag ``-fcs-profile-generate`` also instruments programs using the same; instrumentation method as ``-fprofile-generate``. However, it performs a; post-inline late instrumentation and can produce context-sensitive profiles. Here are the steps for using profile guided optimization with; instrumentation:. 1. Build an instrumented version of the code by compiling and linking with the; ``-fprofile-generate`` or ``-fprofile-instr-generate`` option. .. code-block:: console. $ clang++ -O2 -fprofile-instr-generate code.cc -o code. 2. Run the instrumented executable with inputs that reflect the typical usage.; By default, the profile data will be written to a ``default.profraw`` file; in the curren",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:102773,perform,performance,102773,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,1,['perform'],['performance']
Performance," that; exactly matches the operation-by-operation behavior of native support,; but that can require many extra truncations and extensions. By default,; when emulating ``_Float16`` and ``__bf16`` arithmetic using ``float``, Clang; does not truncate intermediate operands back to their true type unless the; operand is the result of an explicit cast or assignment. This is generally; much faster but can generate different results from strict operation-by-operation; emulation. Usually the results are more precise. This is permitted by the; C and C++ standards under the rules for excess precision in intermediate operands;; see the discussion of evaluation formats in the C standard and [expr.pre] in; the C++ standard. The use of excess precision can be independently controlled for these two; types with the ``-ffloat16-excess-precision=`` and; ``-fbfloat16-excess-precision=`` options. Valid values include:. * ``none``: meaning to perform strict operation-by-operation emulation; * ``standard``: meaning that excess precision is permitted under the rules; described in the standard, i.e. never across explicit casts or statements; * ``fast``: meaning that excess precision is permitted whenever the; optimizer sees an opportunity to avoid truncations; currently this has no; effect beyond ``standard``. The ``_Float16`` type is an interchange floating type specified in; ISO/IEC TS 18661-3:2015 (""Floating-point extensions for C""). It will; be supported on more targets as they define ABIs for it. The ``__bf16`` type is a non-standard extension, but it generally follows; the rules for arithmetic interchange floating types from ISO/IEC TS; 18661-3:2015. In previous versions of Clang, it was a storage-only type; that forbade arithmetic operations. It will be supported on more targets; as they define ABIs for it. The ``__fp16`` type was originally an ARM extension and is specified; by the `ARM C Language Extensions <https://github.com/ARM-software/acle/releases>`_.; Clang uses the ``binary",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst:33366,perform,perform,33366,interpreter/llvm-project/clang/docs/LanguageExtensions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst,1,['perform'],['perform']
Performance," that; following loads; will not see stale; global data. This; satisfies the; requirements of; acquire. fence acq_rel - system *none* 1. buffer_wbl2 sc0=1 sc1=1. - If OpenCL and; address space is; local, omit.; - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at system scope. 1. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate; (see comment for; previous fence).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; buffer_inv.; - Ensures that the; preceding; global/local/generic; load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; acquire-fence-paired-atomic); has completed; before invalidating; the cache. This; satisfies the; requirements of; acquire.; - Ensures that all; previous memory; operations have; completed before a; following; global/local/generic; store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; release-fence-paired-atomic).; This satisfies the; requirements of; release. 2. buffer_inv sc0=1 sc1=1. - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; MTYPE NC global data.; MTYPE RW and CC memory will; never be stale due to the; memory",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:329610,load,load,329610,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],['load']
Performance," the ""``=``"" in case of an output). This indicates that the asm; will write to or read from the contents of an *address* provided as an input; argument. (Note that in this way, indirect outputs act more like an *input* than; an output: just like an input, they consume an argument of the call expression,; rather than producing a return value. An indirect output constraint is an; ""output"" only in that the asm is expected to write to the contents of the input; memory location, instead of just read from it). This is most typically used for memory constraint, e.g. ""``=*m``"", to pass the; address of a variable as a value. It is also possible to use an indirect *register* constraint, but only on output; (e.g. ""``=*r``""). This will cause LLVM to allocate a register for an output; value normally, and then, separately emit a store to the address provided as; input, after the provided inline asm. (It's not clear what value this; functionality provides, compared to writing the store explicitly after the asm; statement, and it can only produce worse code, since it bypasses many; optimization passes. I would recommend not using it.). Call arguments for indirect constraints must have pointer type and must specify; the :ref:`elementtype <attr_elementtype>` attribute to indicate the pointer; element type. Clobber constraints; """""""""""""""""""""""""""""""""""""". A clobber constraint is indicated by a ""``~``"" prefix. A clobber does not; consume an input operand, nor generate an output. Clobbers cannot use any of the; general constraint code letters -- they may use only explicit register; constraints, e.g. ""``~{eax}``"". The one exception is that a clobber string of; ""``~{memory}``"" indicates that the assembly writes to arbitrary undeclared; memory locations -- not only the memory pointed to by a declared indirect; output. Note that clobbering named registers that are also present in output; constraints is not legal. Label constraints; """""""""""""""""""""""""""""""""". A label constraint is indicated by a ""``!``"" pre",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:216774,optimiz,optimization,216774,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['optimiz'],['optimization']
Performance," the ''align'' attribute on parameters and return values.; This metadata can only be applied to loads of a pointer type. If the returned; value is not appropriately aligned at runtime, a poison value is returned; instead. The optional ``!noundef`` metadata must reference a single metadata name; ``<empty_node>`` corresponding to a node with no entries. The existence of; ``!noundef`` metadata on the instruction tells the optimizer that the value; loaded is known to be :ref:`well defined <welldefinedvalues>`.; If the value isn't well defined, the behavior is undefined. If the ``!noundef``; metadata is combined with poison-generating metadata like ``!nonnull``,; violation of that metadata constraint will also result in undefined behavior. Semantics:; """""""""""""""""""". The location of memory pointed to is loaded. If the value being loaded; is of scalar type then the number of bytes read does not exceed the; minimum number of bytes needed to hold all bits of the type. For; example, loading an ``i24`` reads at most three bytes. When loading a; value of a type like ``i20`` with a size that is not an integral number; of bytes, the result is undefined if the value was not originally; written using a store of the same type.; If the value being loaded is of aggregate type, the bytes that correspond to; padding may be accessed but are ignored, because it is impossible to observe; padding from the loaded aggregate value.; If ``<pointer>`` is not a well-defined value, the behavior is undefined. Examples:; """""""""""""""""". .. code-block:: llvm. %ptr = alloca i32 ; yields ptr; store i32 3, ptr %ptr ; yields void; %val = load i32, ptr %ptr ; yields i32:val = i32 3. .. _i_store:. '``store``' Instruction; ^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. store [volatile] <ty> <value>, ptr <pointer>[, align <alignment>][, !nontemporal !<nontemp_node>][, !invariant.group !<empty_node>] ; yields void; store atomic [volatile] <ty> <value>, ptr <pointer> [syncscope(""<target-scope>"")] <ordering>, align <al",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:418331,load,loading,418331,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['load'],['loading']
Performance," the *repl*; record if the *target* record name equals the *value* record name; otherwise it; produces the *value*. ``!substr(``\ *string*\ ``,`` *start*\ [``,`` *length*]\ ``)``; This operator extracts a substring of the given *string*. The starting; position of the substring is specified by *start*, which can range; between 0 and the length of the string. The length of the substring; is specified by *length*; if not specified, the rest of the string is; extracted. The *start* and *length* arguments must be integers. ``!tail(``\ *a*\ ``)``; This operator produces a new list with all the elements; of the list *a* except for the zeroth one. (See also ``!head``.). ``!tolower(``\ *a*\ ``)``; This operator converts a string input *a* to lower case. ``!toupper(``\ *a*\ ``)``; This operator converts a string input *a* to upper case. ``!xor(``\ *a*\ ``,`` *b*\ ``, ...)``; This operator does a bitwise EXCLUSIVE OR on *a*, *b*, etc., and produces; the result. A logical XOR can be performed if all the arguments are either; 0 or 1. Appendix B: Paste Operator Examples; ===================================. Here is an example illustrating the use of the paste operator in record names. .. code-block:: text. defvar suffix = ""_suffstring"";; defvar some_ints = [0, 1, 2, 3];. def name # suffix {; }. foreach i = [1, 2] in {; def rec # i {; }; }. The first ``def`` does not use the value of the ``suffix`` variable. The; second def does use the value of the ``i`` iterator variable, because it is not a; global name. The following records are produced. .. code-block:: text. def namesuffix {; }; def rec1 {; }; def rec2 {; }. Here is a second example illustrating the paste operator in field value expressions. .. code-block:: text. def test {; string strings = suffix # suffix;; list<int> integers = some_ints # [4, 5, 6];; }. The ``strings`` field expression uses ``suffix`` on both sides of the paste; operator. It is evaluated normally on the left hand side, but taken verbatim; on the right han",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TableGen/ProgRef.rst:73758,perform,performed,73758,interpreter/llvm-project/llvm/docs/TableGen/ProgRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TableGen/ProgRef.rst,1,['perform'],['performed']
Performance," the 0'th; constraint). It is permitted to tie an input to an ""early-clobber"" output. In that case, no; *other* input may share the same register as the input tied to the early-clobber; (even when the other input has the same value). You may only tie an input to an output which has a register constraint, not a; memory constraint. Only a single input may be tied to an output. There is also an ""interesting"" feature which deserves a bit of explanation: if a; register class constraint allocates a register which is too small for the value; type operand provided as input, the input value will be split into multiple; registers, and all of them passed to the inline asm. However, this feature is often not as useful as you might think. Firstly, the registers are *not* guaranteed to be consecutive. So, on those; architectures that have instructions which operate on multiple consecutive; instructions, this is not an appropriate way to support them. (e.g. the 32-bit; SparcV8 has a 64-bit load, which instruction takes a single 32-bit register. The; hardware then loads into both the named register, and the next register. This; feature of inline asm would not be useful to support that.). A few of the targets provide a template string modifier allowing explicit access; to the second register of a two-register operand (e.g. MIPS ``L``, ``M``, and; ``D``). On such an architecture, you can actually access the second allocated; register (yet, still, not any subsequent ones). But, in that case, you're still; probably better off simply splitting the value into two separate operands, for; clarity. (e.g. see the description of the ``A`` constraint on X86, which,; despite existing only for use with this feature, is not really a good idea to; use). Indirect inputs and outputs; """""""""""""""""""""""""""""""""""""""""""""""""""""". Indirect output or input constraints can be specified by the ""``*``"" modifier; (which goes after the ""``=``"" in case of an output). This indicates that the asm; will write to or read from the",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:214775,load,load,214775,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['load'],['load']
Performance," the addressing mode to be less than or equal to 9. This means the full; address can only be guaranteed to be less than `(1 << 31) + 9`. The OS may wish; to protect an extra page of the low address space to account for this. ##### Optimizations. A very large portion of the cost for this approach comes from checking loads in; this way, so it is important to work to optimize this. However, beyond making; the instruction sequences to *apply* the checks efficient (for example by; avoiding `pushfq` and `popfq` sequences), the only significant optimization is; to check fewer loads without introducing a vulnerability. We apply several; techniques to accomplish that. ###### Don't check loads from compile-time constant stack offsets. We implement this optimization on x86 by skipping the checking of loads which; use a fixed frame pointer offset. The result of this optimization is that patterns like reloading a spilled; register or accessing a global field don't get checked. This is a very; significant performance win. ###### Don't check dependent loads. A core part of why this mitigation strategy works is that it establishes a; data-flow check on the loaded address. However, this means that if the address; itself was already loaded using a checked load, there is no need to check a; dependent load provided it is within the same basic block as the checked load,; and therefore has no additional predicates guarding it. Consider code like the; following:; ```; ... .LBB0_4: # %danger; movq (%rcx), %rdi; movl (%rdi), %edx; ```. This will get transformed into:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; orq %rax, %rcx # Mask the pointer if misspeculating.; movq (%rcx), %rdi # Hardened load.; movl (%rdi), %edx # Unhardened load due to dependent addr.; ```. This doesn't check the load through `%rdi` as that pointer is dependent on a; checked load already. ###### Protect large, load-heavy blocks with a single lfence. It may be worth using a si",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:35265,perform,performance,35265,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,1,['perform'],['performance']
Performance," the apply button is; pressed, the changes are applied to the edited shape and drawn. The; ""Undo"" button becomes active after the first modification has been; applied. It allows restoring the initial parameters of the shape. NOTE: In this version the ""Undo"" does not allow restoring an; intermediate state of the parameters that was applied - it will always; restore the parameters at the moment the shape was edited. All material properties changes are undoable. The mixture editor; currently allows adding elements one by one in the mixture composition.; This can be done either by element weight fraction or by number of; atoms. Once an element was added using one method the other method is not; selectable anymore. Summing component fractions up to 1 in the final; mixture is the user responsibility. Adding materials as components of a; mixture is not supported in this version. The elements that were added to the mixture appear in the bottom of the; mixture editor. The operations performed on mixture are not undoable. \anchor GP08d; ### Creation of New Objects. As described above, all geometry object creators are accessible within; the geometry manager editor frame. Generally, if the new object that; needs to be created does not depend on other objects, it will be built; with a set of default parameters. This is the case for all shapes; (except composite shapes) and matrices. For all the other objects the; interface forces the selection of components before creating the object. \anchor GP08e; ### Editing Volumes. Volumes are hierarchical components in the geometry, therefore their; editor is more complex. It provides the following functionalities:. - *General*. This category allows changing the name of the volume and; selecting other shape or medium among existing ones. - *Daughters*. The category allows removing existing daughter nodes or; adding new ones. The button ""Position"" allows editing the; positioning matrix of a given node. \image html geometry022.jpg width=600p",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:131660,perform,performed,131660,geom/geom/doc/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md,1,['perform'],['performed']
Performance," the common block up to the else:. int test (int a, int b, int c, int g) {; int d, e;; if (a); d = b * c;; else; d = b - c;; e = b * c + g;; return d + e;; }. It would be better to do the mul once to reduce codesize above the if.; This is GCC PR38204. //===---------------------------------------------------------------------===//; This simple function from 179.art:. int winner, numf2s;; struct { double y; int reset; } *Y;. void find_match() {; int i;; winner = 0;; for (i=0;i<numf2s;i++); if (Y[i].y > Y[winner].y); winner =i;; }. Compiles into (with clang TBAA):. for.body: ; preds = %for.inc, %bb.nph; %indvar = phi i64 [ 0, %bb.nph ], [ %indvar.next, %for.inc ]; %i.01718 = phi i32 [ 0, %bb.nph ], [ %i.01719, %for.inc ]; %tmp4 = getelementptr inbounds %struct.anon* %tmp3, i64 %indvar, i32 0; %tmp5 = load double* %tmp4, align 8, !tbaa !4; %idxprom7 = sext i32 %i.01718 to i64; %tmp10 = getelementptr inbounds %struct.anon* %tmp3, i64 %idxprom7, i32 0; %tmp11 = load double* %tmp10, align 8, !tbaa !4; %cmp12 = fcmp ogt double %tmp5, %tmp11; br i1 %cmp12, label %if.then, label %for.inc. if.then: ; preds = %for.body; %i.017 = trunc i64 %indvar to i32; br label %for.inc. for.inc: ; preds = %for.body, %if.then; %i.01719 = phi i32 [ %i.01718, %for.body ], [ %i.017, %if.then ]; %indvar.next = add i64 %indvar, 1; %exitcond = icmp eq i64 %indvar.next, %tmp22; br i1 %exitcond, label %for.cond.for.end_crit_edge, label %for.body. It is good that we hoisted the reloads of numf2's, and Y out of the loop and; sunk the store to winner out. However, this is awful on several levels: the conditional truncate in the loop; (-indvars at fault? why can't we completely promote the IV to i64?). Beyond that, we have a partially redundant load in the loop: if ""winner"" (aka ; %i.01718) isn't updated, we reload Y[winner].y the next time through the loop.; Similarly, the addressing that feeds it (including the sext) is redundant. In; the end we get this generated assembly:. LBB0_2: ## %for.body; ## =>",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/README.txt:30428,load,load,30428,interpreter/llvm-project/llvm/lib/Target/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/README.txt,2,['load'],['load']
Performance," the computation; (see ``-fsanitize=implicit-conversion``). Both of these two issues are; handled by ``-fsanitize=implicit-conversion`` group of checks.; - ``-fsanitize=unreachable``: If control flow reaches an unreachable; program point.; - ``-fsanitize=unsigned-integer-overflow``: Unsigned integer overflow, where; the result of an unsigned integer computation cannot be represented in its; type. Unlike signed integer overflow, this is not undefined behavior, but; it is often unintentional. This sanitizer does not check for lossy implicit; conversions performed before such a computation; (see ``-fsanitize=implicit-conversion``).; - ``-fsanitize=vla-bound``: A variable-length array whose bound; does not evaluate to a positive value.; - ``-fsanitize=vptr``: Use of an object whose vptr indicates that it is of; the wrong dynamic type, or that its lifetime has not begun or has ended.; Incompatible with ``-fno-rtti``. Link must be performed by ``clang++``, not; ``clang``, to make sure C++-specific parts of the runtime library and C++; standard libraries are present. You can also use the following check groups:; - ``-fsanitize=undefined``: All of the checks listed above other than; ``float-divide-by-zero``, ``unsigned-integer-overflow``,; ``implicit-conversion``, ``local-bounds`` and the ``nullability-*`` group; of checks.; - ``-fsanitize=undefined-trap``: Deprecated alias of; ``-fsanitize=undefined``.; - ``-fsanitize=implicit-integer-truncation``: Catches lossy integral; conversions. Enables ``implicit-signed-integer-truncation`` and; ``implicit-unsigned-integer-truncation``.; - ``-fsanitize=implicit-integer-arithmetic-value-change``: Catches implicit; conversions that change the arithmetic value of the integer. Enables; ``implicit-signed-integer-truncation`` and ``implicit-integer-sign-change``.; - ``-fsanitize=implicit-conversion``: Checks for suspicious; behavior of implicit conversions. Enables; ``implicit-unsigned-integer-truncation``,; ``implicit-signed-integer-trunc",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UndefinedBehaviorSanitizer.rst:9909,perform,performed,9909,interpreter/llvm-project/clang/docs/UndefinedBehaviorSanitizer.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UndefinedBehaviorSanitizer.rst,1,['perform'],['performed']
Performance," the corresponding coroutine. In other words, if two coroutines have the; same `promise_type`, they should behave in the same way.; To print a `promise_type` in a debugger when stopped at a breakpoint inside a; coroutine, printing the `promise_type` can be done by:. .. parsed-literal::. print __promise. It is also possible to print the `promise_type` of a coroutine from the address; of the coroutine frame. For example, if the address of a coroutine frame is; 0x416eb0, and the type of the `promise_type` is `task::promise_type`, printing; the `promise_type` can be done by:. .. parsed-literal::. print (task::promise_type)*(0x416eb0+0x10). This is possible because the `promise_type` is guaranteed by the ABI to be at a; 16 bit offset from the coroutine frame. Note that there is also an ABI independent method:. .. parsed-literal::. print std::coroutine_handle<task::promise_type>::from_address((void*)0x416eb0).promise(). The functions `from_address(void*)` and `promise()` are often small enough to; be removed during optimization, so this method may not be possible. Print coroutine frames; ======================. LLVM generates the debug information for the coroutine frame in the LLVM middle; end, which permits printing of the coroutine frame in the debugger. Much like; the `promise_type`, when stopped at a breakpoint inside a coroutine we can; print the coroutine frame by:. .. parsed-literal::. print __coro_frame. Just as printing the `promise_type` is possible from the coroutine address,; printing the details of the coroutine frame from an address is also possible:. ::. (gdb) # Get the address of coroutine frame; (gdb) print/x *0x418eb0; $1 = 0x4019e0; (gdb) # Get the linkage name for the coroutine; (gdb) x 0x4019e0; 0x4019e0 <_ZL9coro_taski>: 0xe5894855; (gdb) # Turn off the demangler temporarily to avoid the debugger misunderstanding the name.; (gdb) set demangle-style none; (gdb) # The coroutine frame type is 'linkage_name.coro_frame_ty'; (gdb) print ('_ZL9coro_taski.co",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DebuggingCoroutines.rst:4431,optimiz,optimization,4431,interpreter/llvm-project/clang/docs/DebuggingCoroutines.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DebuggingCoroutines.rst,1,['optimiz'],['optimization']
Performance," the current compilation unit for a base type of the; generic type. The operation is equivalent to performing ``DW_OP_deref_type S, DR``. 3. ``DW_OP_deref_size``. ``DW_OP_deref_size`` has a single 1-byte unsigned integral constant that; represents a byte result size S. TS is the smaller of the generic type bit size and S scaled by 8 (the byte; size). If TS is smaller than the generic type bit size then T is an unsigned; integral type of bit size TS, otherwise T is the generic type. DR is the; offset of a hypothetical debug information entry D in the current; compilation unit for a base type T. .. note::. Truncating the value when S is larger than the generic type matches what; GDB does. This allows the generic type size to not be an integral byte; size. It does allow S to be arbitrarily large. Should S be restricted to; the size of the generic type rounded up to a multiple of 8?. The operation is equivalent to performing ``DW_OP_deref_type S, DR``, except; if T is not the generic type, the value V pushed is zero-extended to the; generic type bit size and its type changed to the generic type. 4. ``DW_OP_deref_type``. ``DW_OP_deref_type`` has two operands. The first is a 1-byte unsigned; integral constant S. The second is an unsigned LEB128 integer DR that; represents the byte offset of a debugging information entry D relative to; the beginning of the current compilation unit, that provides the type T of; the result value. TS is the bit size of the type T. *While the size of the pushed value V can be inferred from the type T, it is; encoded explicitly as the operand S so that the operation can be parsed; easily without reference to the* ``.debug_info`` *section.*. .. note::. It is unclear why the operand S is needed. Unlike ``DW_OP_const_type``,; the size is not needed for parsing. Any evaluation needs to get the base; type T to push with the value to know its encoding and bit size. It pops one stack entry that must be a location description L. A value V of TS bits is",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:89777,perform,performing,89777,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,1,['perform'],['performing']
Performance," the file; ``yyy/zzz/default_xxxx.profraw``. To generate the profile data file with the compiler readable format, the; ``llvm-profdata`` tool can be used with the profile directory as the input:. .. code-block:: console. $ llvm-profdata merge -output=code.profdata yyy/zzz/. If the user wants to turn off the auto-merging feature, or simply override the; the profile dumping path specified at command line, the environment variable; ``LLVM_PROFILE_FILE`` can still be used to override; the directory and filename for the profile file at runtime.; To override the path and filename at compile time, use; ``-Xclang -fprofile-instrument-path=/path/to/file_pattern.profraw``. .. option:: -fcs-profile-generate[=<dirname>]. The ``-fcs-profile-generate`` and ``-fcs-profile-generate=`` flags will use; the same instrumentation method, and generate the same profile as in the; ``-fprofile-generate`` and ``-fprofile-generate=`` flags. The difference is; that the instrumentation is performed after inlining so that the resulted; profile has a better context sensitive information. They cannot be used; together with ``-fprofile-generate`` and ``-fprofile-generate=`` flags.; They are typically used in conjunction with ``-fprofile-use`` flag.; The profile generated by ``-fcs-profile-generate`` and ``-fprofile-generate``; can be merged by llvm-profdata. A use example:. .. code-block:: console. $ clang++ -O2 -fprofile-generate=yyy/zzz code.cc -o code; $ ./code; $ llvm-profdata merge -output=code.profdata yyy/zzz/. The first few steps are the same as that in ``-fprofile-generate``; compilation. Then perform a second round of instrumentation. .. code-block:: console. $ clang++ -O2 -fprofile-use=code.profdata -fcs-profile-generate=sss/ttt \; -o cs_code; $ ./cs_code; $ llvm-profdata merge -output=cs_code.profdata sss/ttt code.profdata. The resulted ``cs_code.prodata`` combines ``code.profdata`` and the profile; generated from binary ``cs_code``. Profile ``cs_code.profata`` can be used by; ``-fprofi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:109076,perform,performed,109076,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,1,['perform'],['performed']
Performance," the final vectorization decisions, and to execute them:; the Hierarchical CFG models the planned control-flow, and Recipes capture; decisions taken inside basic-blocks. Next, VPlan will be used also as the basis; for taking these decisions, effectively turning them into a series of; VPlan-to-VPlan algorithms. Finally, VPlan will support the planning process; itself including cost-based analyses for making these decisions, to fully; support compositional and iterative decision making. Some decisions are local to an instruction in the loop, such as whether to widen; it into a vector instruction or replicate it, keeping the generated instructions; in place. Other decisions, however, involve moving instructions, replacing them; with other instructions, and/or introducing new instructions. For example, a; cast may sink past a later instruction and be widened to handle first-order; recurrence; an interleave group of strided gathers or scatters may effectively; move to one place where they are replaced with shuffles and a common wide vector; load or store; new instructions may be introduced to compute masks, shuffle the; elements of vectors, and pack scalar values into vectors or vice-versa. In order for VPlan to support making instruction-level decisions and analyses,; it needs to model the relevant instructions along with their def/use relations.; This too follows a staged approach: first, the new instructions that compute; masks are modeled as VPInstructions, along with their induced def/use subgraph.; This effectively models masks in VPlan, facilitating VPlan-based predication.; Next, the logic embedded within each Recipe for generating its instructions at; VPlan execution time, will instead take part in the planning process by modeling; them as VPInstructions. Finally, only logic that applies to instructions as a; group will remain in Recipes, such as interleave groups and potentially other; idiom groups having synergistic cost. Related LLVM components; -------------",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/VectorizationPlan.rst:9314,load,load,9314,interpreter/llvm-project/llvm/docs/VectorizationPlan.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/VectorizationPlan.rst,1,['load'],['load']
Performance," the function. `tracksRegLiveness` on the other hand is often; necessary for some passes that care about block livein lists. - The (global) `liveins:` list is typically only interesting for early; instruction selection passes and can be removed when testing later passes.; The per-block `liveins:` on the other hand are necessary if; `tracksRegLiveness` is true. - Branch probability data in block `successors:` lists can be dropped if the; test doesn't depend on it. Example:; `successors: %bb.1(0x40000000), %bb.2(0x40000000)` can be replaced with; `successors: %bb.1, %bb.2`. - MIR code contains a whole IR module. This is necessary because there are; no equivalents in MIR for global variables, references to external functions,; function attributes, metadata, debug info. Instead some MIR data references; the IR constructs. You can often remove them if the test doesn't depend on; them. - Alias Analysis is performed on IR values. These are referenced by memory; operands in MIR. Example: `:: (load 8 from %ir.foobar, !alias.scope !9)`.; If the test doesn't depend on (good) alias analysis the references can be; dropped: `:: (load 8)`. - MIR blocks can reference IR blocks for debug printing, profile information; or debug locations. Example: `bb.42.myblock` in MIR references the IR block; `myblock`. It is usually possible to drop the `.myblock` reference and simply; use `bb.42`. - If there are no memory operands or blocks referencing the IR then the; IR function can be replaced by a parameterless dummy function like; `define @func() { ret void }`. - It is possible to drop the whole IR section of the MIR file if it only; contains dummy functions (see above). The .mir loader will create the; IR functions automatically in this case. .. _limitations:. Limitations; -----------. Currently the MIR format has several limitations in terms of which state it; can serialize:. - The target-specific state in the target-specific ``MachineFunctionInfo``; subclasses isn't serialized at the momen",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MIRLangRef.rst:4508,load,load,4508,interpreter/llvm-project/llvm/docs/MIRLangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MIRLangRef.rst,1,['load'],['load']
Performance," the interface between; the two modules. The ``ASTReader`` class, which handles the loading of an AST; file, inherits from all of these abstract classes to provide lazy; deserialization of Clang's data structures. ``ASTReader`` implements the; following abstract classes:. ``ExternalSLocEntrySource``; This abstract interface is associated with the ``SourceManager`` class, and; is used whenever the :ref:`source manager <pchinternals-sourcemgr>` needs to; load the details of a file, buffer, or macro instantiation. ``IdentifierInfoLookup``; This abstract interface is associated with the ``IdentifierTable`` class, and; is used whenever the program source refers to an identifier that has not yet; been seen. In this case, the AST reader searches for this identifier within; its :ref:`identifier table <pchinternals-ident-table>` to load any top-level; declarations or macros associated with that identifier. ``ExternalASTSource``; This abstract interface is associated with the ``ASTContext`` class, and is; used whenever the abstract syntax tree nodes need to loaded from the AST; file. It provides the ability to de-serialize declarations and types; identified by their numeric values, read the bodies of functions when; required, and read the declarations stored within a declaration context; (either for iteration or for name lookup). ``ExternalSemaSource``; This abstract interface is associated with the ``Sema`` class, and is used; whenever semantic analysis needs to read information from the :ref:`global; method pool <pchinternals-method-pool>`. .. _pchinternals-chained:. Chained precompiled headers; ---------------------------. Chained precompiled headers were initially intended to improve the performance; of IDE-centric operations such as syntax highlighting and code completion while; a particular source file is being edited by the user. To minimize the amount; of reparsing required after a change to the file, a form of precompiled header; --- called a precompiled *preamble* -",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/PCHInternals.rst:23001,load,loaded,23001,interpreter/llvm-project/clang/docs/PCHInternals.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/PCHInternals.rst,1,['load'],['loaded']
Performance," the kernel. It must be at least 16-byte aligned.; 4. Kernel argument values are assigned to the kernel argument memory; allocation. The layout is defined in the *HSA Programmer's Language; Reference* [HSA]_. For AMDGPU the kernel execution directly accesses the; kernel argument memory in the same way constant memory is accessed. (Note; that the HSA specification allows an implementation to copy the kernel; argument contents to another location that is accessed by the kernel.); 5. An AQL kernel dispatch packet is created on the AQL queue. The HSA compatible; runtime api uses 64-bit atomic operations to reserve space in the AQL queue; for the packet. The packet must be set up, and the final write must use an; atomic store release to set the packet kind to ensure the packet contents are; visible to the kernel agent. AQL defines a doorbell signal mechanism to; notify the kernel agent that the AQL queue has been updated. These rules, and; the layout of the AQL queue and kernel dispatch packet is defined in the *HSA; System Architecture Specification* [HSA]_.; 6. A kernel dispatch packet includes information about the actual dispatch,; such as grid and work-group size, together with information from the code; object about the kernel, such as segment sizes. The HSA compatible runtime; queries on the kernel symbol can be used to obtain the code object values; which are recorded in the :ref:`amdgpu-amdhsa-code-object-metadata`.; 7. CP executes micro-code and is responsible for detecting and setting up the; GPU to execute the wavefronts of a kernel dispatch.; 8. CP ensures that when the a wavefront starts executing the kernel machine; code, the scalar general purpose registers (SGPR) and vector general purpose; registers (VGPR) are set up as required by the machine code. The required; setup is defined in the :ref:`amdgpu-amdhsa-kernel-descriptor`. The initial; register state is defined in; :ref:`amdgpu-amdhsa-initial-kernel-execution-state`.; 9. The prolog of the kernel mach",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:151457,queue,queue,151457,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['queue'],['queue']
Performance," the latter are defined statically for each; instruction, whereas the former may vary depending on the program being; compiled. For example, an instruction that represents a function call will; always implicitly define or use the same set of physical registers. To read the; registers implicitly used by an instruction, use; ``TargetInstrInfo::get(opcode)::ImplicitUses``. Pre-colored registers impose; constraints on any register allocation algorithm. The register allocator must; make sure that none of them are overwritten by the values of virtual registers; while still alive. Mapping virtual registers to physical registers; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. There are two ways to map virtual registers to physical registers (or to memory; slots). The first way, that we will call *direct mapping*, is based on the use; of methods of the classes ``TargetRegisterInfo``, and ``MachineOperand``. The; second way, that we will call *indirect mapping*, relies on the ``VirtRegMap``; class in order to insert loads and stores sending and getting values to and from; memory. The direct mapping provides more flexibility to the developer of the register; allocator; however, it is more error prone, and demands more implementation; work. Basically, the programmer will have to specify where load and store; instructions should be inserted in the target function being compiled in order; to get and store values in memory. To assign a physical register to a virtual; register present in a given operand, use ``MachineOperand::setReg(p_reg)``. To; insert a store instruction, use ``TargetInstrInfo::storeRegToStackSlot(...)``,; and to insert a load instruction, use ``TargetInstrInfo::loadRegFromStackSlot``. The indirect mapping shields the application developer from the complexities of; inserting load and store instructions. In order to map a virtual register to a; physical one, use ``VirtRegMap::assignVirt2Phys(vreg, preg)``. In order to map; a certain virtual register to memory, us",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:64236,load,loads,64236,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst,1,['load'],['loads']
Performance," the left. You can change it; to be centered or right aligned if you use **`TGGroupFrame::kCenter`** or; `TGGroupFrame::kRight` as a parameter. ![](pictures/02000208.jpg). Be conservative in the use of borders because of the potential for; clutter. Do not place them around single entry fields, single combo; boxes, list boxes and groups of command buttons. The design of these; widgets provides them with a border. The picture above provides kind of; borders to avoid. ## Layout Management. The layout process is an integral part of any GUI. When you create a; simple message window, laying out its few buttons and text widgets is; quite simple. However, this process becomes increasingly difficult if; you have to implement large GUI's with many widgets that should behave; properly when the GUI is resized or uses a different font type or size.; Layout management is the process of determining the size and position of; every widget in a container. A layout manager is an object that performs layout management for the; widgets within a container. You already know that when adding a; component (child widget) to a container (parent widget) you can provide; alignment hints (or rely on the default ones). These hints are used by; the layout manager to correctly position the widgets in the container.; The **`TGLayoutManager`** is an abstract class providing the basic; layout functionality. ![The layout classes hierarchy](pictures/02000209.jpg). The base ""container"" class is **`TGCmpositeFrame`**. You can easily; change the layout manager using the; `SetLayoutManager(TGLayoutManager *l)` method. Setting the proper layout; manager for each container is the first step you have to do. The; container uses that layout manager to position and size the components; before they are painted. ROOT currently provides the layout managers; shown on the picture above. The next important step is to provide hints about every widget in the; container, i.e. to provide positions and right amount of space ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/WritingGUI.md:34099,perform,performs,34099,documentation/users-guide/WritingGUI.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/WritingGUI.md,1,['perform'],['performs']
Performance," the mode is consistent. User or platform code is expected to set; the floating point mode appropriately before function entry. If the input mode is ``""preserve-sign""``, or ``""positive-zero""``,; a floating-point operation must treat any input denormal value as; zero. In some situations, if an instruction does not respect this; mode, the input may need to be converted to 0 as if by; ``@llvm.canonicalize`` during lowering for correctness. ``""denormal-fp-math-f32""``; Same as ``""denormal-fp-math""``, but only controls the behavior of; the 32-bit float type (or vectors of 32-bit floats). If both are; are present, this overrides ``""denormal-fp-math""``. Not all targets; support separately setting the denormal mode per type, and no; attempt is made to diagnose unsupported uses. Currently this; attribute is respected by the AMDGPU and NVPTX backends. ``""thunk""``; This attribute indicates that the function will delegate to some other; function with a tail call. The prototype of a thunk should not be used for; optimization purposes. The caller is expected to cast the thunk prototype to; match the thunk target prototype. ``""tls-load-hoist""``; This attribute indicates that the function will try to reduce redundant; tls address calculation by hoisting tls variable. ``uwtable[(sync|async)]``; This attribute indicates that the ABI being targeted requires that; an unwind table entry be produced for this function even if we can; show that no exceptions passes by it. This is normally the case for; the ELF x86-64 abi, but it can be disabled for some compilation; units. The optional parameter describes what kind of unwind tables; to generate: ``sync`` for normal unwind tables, ``async`` for asynchronous; (instruction precise) unwind tables. Without the parameter, the attribute; ``uwtable`` is equivalent to ``uwtable(async)``.; ``nocf_check``; This attribute indicates that no control-flow check will be performed on; the attributed entity. It disables -fcf-protection=<> for a specific; ent",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:108360,optimiz,optimization,108360,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['optimiz'],['optimization']
Performance," the native functions.; For example, given the ABI list example provided in the user manual, the; following wrappers will be generated under the args ABI:. .. code-block:: llvm. define linkonce_odr { i8*, i16 } @""dfsw$malloc""(i64 %0, i16 %1) {; entry:; %2 = call i8* @malloc(i64 %0); %3 = insertvalue { i8*, i16 } undef, i8* %2, 0; %4 = insertvalue { i8*, i16 } %3, i16 0, 1; ret { i8*, i16 } %4; }. define linkonce_odr { i32, i16 } @""dfsw$tolower""(i32 %0, i16 %1) {; entry:; %2 = call i32 @tolower(i32 %0); %3 = insertvalue { i32, i16 } undef, i32 %2, 0; %4 = insertvalue { i32, i16 } %3, i16 %1, 1; ret { i32, i16 } %4; }. define linkonce_odr { i8*, i16 } @""dfsw$memcpy""(i8* %0, i8* %1, i64 %2, i16 %3, i16 %4, i16 %5) {; entry:; %labelreturn = alloca i16; %6 = call i8* @__dfsw_memcpy(i8* %0, i8* %1, i64 %2, i16 %3, i16 %4, i16 %5, i16* %labelreturn); %7 = load i16* %labelreturn; %8 = insertvalue { i8*, i16 } undef, i8* %6, 0; %9 = insertvalue { i8*, i16 } %8, i16 %7, 1; ret { i8*, i16 } %9; }. As an optimization, direct calls to native ABI functions will call the; native ABI function directly and the pass will compute the appropriate label; internally. This has the advantage of reducing the number of union operations; required when the return value label is known to be zero (i.e. ``discard``; functions, or ``functional`` functions with known unlabelled arguments). Checking ABI Consistency; ------------------------. DFSan changes the ABI of each function in the module. This makes it possible; for a function with the native ABI to be called with the instrumented ABI,; or vice versa, thus possibly invoking undefined behavior. A simple way; of statically detecting instances of this problem is to append the suffix; "".dfsan"" to the name of each instrumented-ABI function. This will not catch every such problem; in particular function pointers passed; across the instrumented-native barrier cannot be used on the other side.; These problems could potentially be caught dynamically.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowSanitizerDesign.rst:12248,optimiz,optimization,12248,interpreter/llvm-project/clang/docs/DataFlowSanitizerDesign.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowSanitizerDesign.rst,1,['optimiz'],['optimization']
Performance," the node for ``A`` (the constructor; needs a reference to ``B``). And the same could be true for the import of ``B``; (``A`` is requested to be imported before we could create the node for ``B``).; In case of the :ref:`templated-described swing <templated>` we take; extra attention to break the cyclical dependency: we import and set the; described template only after the ``CXXRecordDecl`` is created. As a best; practice, before creating the node in the ""to"" context, avoid importing of; other nodes which are not needed for the constructor of node ``A``. Error Handling; ^^^^^^^^^^^^^^. Every import function returns with either an ``llvm::Error`` or an; ``llvm::Expected<T>`` object. This enforces to check the return value of the; import functions. If there was an error during one import then we return with; that error. (Exception: when we import the members of a class, we collect the; individual errors with each member and we concatenate them in one Error; object.) We cache these errors in cases of declarations. During the next import; call if there is an existing error we just return with that. So, clients of the; library receive an Error object, which they must check. During import of a specific declaration, it may happen that some AST nodes had; already been created before we recognize an error. In this case, we signal back; the error to the caller, but the ""to"" context remains polluted with those nodes; which had been created. Ideally, those nodes should not had been created, but; that time we did not know about the error, the error happened later. Since the; AST is immutable (most of the cases we can't remove existing nodes) we choose; to mark these nodes as erroneous. We cache the errors associated with declarations in the ""from"" context in; ``ASTImporter::ImportDeclErrors`` and the ones which are associated with the; ""to"" context in ``ASTImporterSharedState::ImportErrors``. Note that, there may; be several ASTImporter objects which import into the same ""to"" cont",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/InternalsManual.rst:100657,cache,cache,100657,interpreter/llvm-project/clang/docs/InternalsManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/InternalsManual.rst,1,['cache'],['cache']
Performance," the object; editor. Then, it scans all object base classes searching the; corresponding object editors. When it finds one, it makes an instance of; the base class editor too. Once the object editor is in place, it sets the user interface elements; according to the object's status. After that, it is ready to interact; with the object following the user actions. The graphics editor gives an intuitive way to edit objects in a canvas; with immediate feedback. Complexity of some object editors is reduced by; hiding GUI elements and revealing them only on users' requests. An object in the canvas is selected by clicking on it with the left; mouse button. Its name is displayed on the top of the editor frame in; red color. If the editor frame needs more space than the canvas window,; a vertical scroll bar appears for easy navigation. ![Histogram, pad and axis editors](pictures/03000222.png). ### Editor Design Elements. The next rules describe the path to follow when creating your own object; editor that will be recognized and loaded by the graphics editor in; ROOT, i.e. it will be included as a part of it. (a) Derive the code of your object editor from the base editor class; **`TGedFrame`**. (b) Keep the correct naming convention: the name of the object editor; should be the object class name concatenated with the word `‘Editor'`. (c) Provide a default constructor. (d) Use the signals/slots communication mechanism for event processing. (e) Implement the virtual method `SetModel(TObject *obj)` where all; widgets are set with the current object's attributes. This method is; called when the editor receives a signal from the canvas saying that an; object is the selected. (f) Implement all necessary slots and connect them to appropriate; signals that GUI widgets send out. The GUI classes in ROOT are developed; to emit signals whenever they change a state that others might be; interested. As we noted already, the signals/slots communication; mechanism allows total independence of",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/WritingGUI.md:104431,load,loaded,104431,documentation/users-guide/WritingGUI.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/WritingGUI.md,1,['load'],['loaded']
Performance," the one found in the executable name. The following canonical driver names are used:. - ``clang`` for the ``gcc`` driver (used to compile C programs); - ``clang++`` for the ``gxx`` driver (used to compile C++ programs); - ``clang-cpp`` for the ``cpp`` driver (pure preprocessor); - ``clang-cl`` for the ``cl`` driver; - ``flang`` for the ``flang`` driver; - ``clang-dxc`` for the ``dxc`` driver. For example, when calling ``x86_64-pc-linux-gnu-clang-g++``,; the driver will first attempt to use the configuration file named::. x86_64-pc-linux-gnu-clang++.cfg. If this file is not found, it will attempt to use the name found; in the executable instead::. x86_64-pc-linux-gnu-clang-g++.cfg. Note that options such as ``--driver-mode=``, ``--target=``, ``-m32`` affect; the search algorithm. For example, the aforementioned executable called with; ``-m32`` argument will instead search for::. i386-pc-linux-gnu-clang++.cfg. If none of the aforementioned files are found, the driver will instead search; for separate driver and target configuration files and attempt to load both.; The former is named ``<driver>.cfg`` while the latter is named; ``<triple>.cfg``. Similarly to the previous variants, the canonical driver name; will be preferred, and the compiler will fall back to the actual name. For example, ``x86_64-pc-linux-gnu-clang-g++`` will attempt to load two; configuration files named respectively::. clang++.cfg; x86_64-pc-linux-gnu.cfg. with fallback to trying::. clang-g++.cfg; x86_64-pc-linux-gnu.cfg. It is not an error if either of these files is not found. The configuration file consists of command-line options specified on one or; more lines. Lines composed of whitespace characters only are ignored as well as; lines in which the first non-blank character is ``#``. Long options may be split; between several lines by a trailing backslash. Here is example of a; configuration file:. ::. # Several options on line; -c --target=x86_64-unknown-linux-gnu. # Long option split between",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:33549,load,load,33549,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,1,['load'],['load']
Performance," the output NaN is definitely quiet. Signaling NaN outputs can only occur if they; are provided as an input value. For example, ""fmul SNaN, 1.0"" may be simplified; to SNaN rather than QNaN. Similarly, if all input NaNs are preferred (or if; there are no input NaNs) and the target does not have any ""extra"" NaN payloads,; then the output NaN is guaranteed to be preferred. Floating-point math operations are allowed to treat all NaNs as if they were; quiet NaNs. For example, ""pow(1.0, SNaN)"" may be simplified to 1.0. Code that requires different behavior than this should use the; :ref:`Constrained Floating-Point Intrinsics <constrainedfp>`.; In particular, constrained intrinsics rule out the ""Unchanged NaN propagation""; case; they are guaranteed to return a QNaN. Unfortunately, due to hard-or-impossible-to-fix issues, LLVM violates its own; specification on some architectures:. - x86-32 without SSE2 enabled may convert floating-point values to x86_fp80 and; back when performing floating-point math operations; this can lead to results; with different precision than expected and it can alter NaN values. Since; optimizations can make contradicting assumptions, this can lead to arbitrary; miscompilations. See `issue #44218; <https://github.com/llvm/llvm-project/issues/44218>`_.; - x86-32 (even with SSE2 enabled) may implicitly perform such a conversion on; values returned from a function for some calling conventions. See `issue; #66803 <https://github.com/llvm/llvm-project/issues/66803>`_.; - Older MIPS versions use the opposite polarity for the quiet/signaling bit, and; LLVM does not correctly represent this. See `issue #60796; <https://github.com/llvm/llvm-project/issues/60796>`_. .. _fastmath:. Fast-Math Flags; ---------------. LLVM IR floating-point operations (:ref:`fneg <i_fneg>`, :ref:`fadd <i_fadd>`,; :ref:`fsub <i_fsub>`, :ref:`fmul <i_fmul>`, :ref:`fdiv <i_fdiv>`,; :ref:`frem <i_frem>`, :ref:`fcmp <i_fcmp>`), :ref:`phi <i_phi>`,; :ref:`select <i_select>` and :ref:",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:160695,perform,performing,160695,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['performing']
Performance," the program; state (if any). This should be minimized as much as possible. More detail about; implementing custom program state is given in section Custom Program States.; ; Checker Registration; All checker implementation files are located in; clang/lib/StaticAnalyzer/Checkers folder. The steps below describe; how the checker SimpleStreamChecker, which checks for misuses of; stream APIs, was registered with the analyzer.; Similar steps should be followed for a new checker. A new checker implementation file, SimpleStreamChecker.cpp, was; created in the directory lib/StaticAnalyzer/Checkers.; The following registration code was added to the implementation file:. void ento::registerSimpleStreamChecker(CheckerManager &mgr) {; mgr.registerChecker<SimpleStreamChecker>();; }. A package was selected for the checker and the checker was defined in the; table of checkers at include/clang/StaticAnalyzer/Checkers/Checkers.td.; Since all checkers should first be developed as ""alpha"", and the SimpleStreamChecker; performs UNIX API checks, the correct package is ""alpha.unix"", and the following; was added to the corresponding UnixAlpha section of Checkers.td:. let ParentPackage = UnixAlpha in {; ...; def SimpleStreamChecker : Checker<""SimpleStream"">,; HelpText<""Check for misuses of stream APIs"">,; DescFile<""SimpleStreamChecker.cpp"">;; ...; } // end ""alpha.unix"". The source code file was made visible to CMake by adding it to; lib/StaticAnalyzer/Checkers/CMakeLists.txt. After adding a new checker to the analyzer, one can verify that the new checker; was successfully added by seeing if it appears in the list of available checkers:; $clang -cc1 -analyzer-checker-help; Events, Callbacks, and Checker Class Structure; All checkers inherit from the ; Checker template class; the template parameter(s) describe the type of; events that the checker is interested in processing. The various types of events; that are available are described in the file ; CheckerDocumentation.cpp; For each event ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/checker_dev_manual.html:9404,perform,performs,9404,interpreter/llvm-project/clang/www/analyzer/checker_dev_manual.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/checker_dev_manual.html,2,['perform'],['performs']
Performance," the proposed step is; negative. In this case, one can subsequently call; TGeoManager::ComputeNormalFast() to get the normal vector to the; crossed surface, after propagating the current point with the; TGeoManager::GetStep() value. This propagation can be done like:. ~~~{.cpp}; Double_t *current_point = gGeoManager->GetCurrentPoint();; Double_t *current_dir = gGeoManager->GetCurrentDirection();; for (Int_t i=0; i<3; i++); current_point[i] += step * current_dir[I];; ~~~. Note: The method TGeoManager::FindNextBoundary() does not modify the; current point/direction nor the current volume/state. The returned node; is the next crossed one, but the physical path (state) AFTER crossing; the boundary is not determined. In order to find out this new state, one; has to propagate the point with a distance slightly bigger that the; computed step value (which is accurate within numerical precision). A; method that performs this task finding the next location is; TGeoManager::Step(), described in ""Making a Step"", but users may; implement more precise methods to insure post-step boundary crossing. \anchor GP08; ## Geometry Graphical User Interface. The geombuilder package allows you to create and edit geometries. The; package provides a library of all GUI classes related to geometry. Each; editable geometry class `TGeoXXX` have a correspondent editor; `TGeoXXXEditor` that provides a graphics user interface allowing to; edit some (or all) parameters of a geometry object. The editable objects; are geometry manager, volumes, nodes, shapes, media, materials and; matrices. The interfaces provide also access to specific functionality; of geometry objects. The editing mechanism is based on ROOT GED; (Graphics Editors) functionality and the library is loaded using the; plug-in mechanism. \anchor GP08a; ### Editing a Geometry. There are two different use cases having different ways of invoking the; geometry editors. The first one applies when starting with geometry from; scratch and using",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:125527,perform,performs,125527,geom/geom/doc/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md,1,['perform'],['performs']
Performance," the same underlying type as the element of the returned vector. The second operand, mask, is a vector of boolean values with the same number of elements as the return type. The third is a pass-through value that is used to fill the masked-off lanes of the result. The return type and the type of the '``passthru``' operand have the same vector type. Semantics:; """""""""""""""""""". The '``llvm.masked.expandload``' intrinsic is designed for reading multiple scalar values from adjacent memory addresses into possibly non-adjacent vector lanes. It is useful for targets that support vector expanding loads and allows vectorizing loop with cross-iteration dependency like in the following example:. .. code-block:: c. // In this loop we load from B and spread the elements into array A.; double *A, B; int *C;; for (int i = 0; i < size; ++i) {; if (C[i] != 0); A[i] = B[j++];; }. .. code-block:: llvm. ; Load several elements from array B and expand them in a vector.; ; The number of loaded elements is equal to the number of '1' elements in the Mask.; %Tmp = call <8 x double> @llvm.masked.expandload.v8f64(ptr %Bptr, <8 x i1> %Mask, <8 x double> poison); ; Store the result in A; call void @llvm.masked.store.v8f64.p0(<8 x double> %Tmp, ptr %Aptr, i32 8, <8 x i1> %Mask). ; %Bptr should be increased on each iteration according to the number of '1' elements in the Mask.; %MaskI = bitcast <8 x i1> %Mask to i8; %MaskIPopcnt = call i8 @llvm.ctpop.i8(i8 %MaskI); %MaskI64 = zext i8 %MaskIPopcnt to i64; %BNextInd = add i64 %BInd, %MaskI64. Other targets may support this intrinsic differently, for example, by lowering it into a sequence of conditional scalar load operations and shuffles.; If all mask elements are '1', the intrinsic behavior is equivalent to the regular unmasked vector load. .. _int_compressstore:. '``llvm.masked.compressstore.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. A number of scalar values of integer, floating ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:857346,load,loaded,857346,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['load'],['loaded']
Performance," the scalar epilogue loop into the; main loop. The first operand is the string; ``llvm.loop.vectorize.predicate.enable`` and the second operand is a bit. If; the bit operand value is 1 vectorization is enabled. A value of 0 disables; vectorization:. .. code-block:: llvm. !0 = !{!""llvm.loop.vectorize.predicate.enable"", i1 0}; !1 = !{!""llvm.loop.vectorize.predicate.enable"", i1 1}. '``llvm.loop.vectorize.scalable.enable``' Metadata; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. This metadata selectively enables or disables scalable vectorization for the; loop, and only has any effect if vectorization for the loop is already enabled.; The first operand is the string ``llvm.loop.vectorize.scalable.enable``; and the second operand is a bit. If the bit operand value is 1 scalable; vectorization is enabled, whereas a value of 0 reverts to the default fixed; width vectorization:. .. code-block:: llvm. !0 = !{!""llvm.loop.vectorize.scalable.enable"", i1 0}; !1 = !{!""llvm.loop.vectorize.scalable.enable"", i1 1}. '``llvm.loop.vectorize.width``' Metadata; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. This metadata sets the target width of the vectorizer. The first; operand is the string ``llvm.loop.vectorize.width`` and the second; operand is an integer specifying the width. For example:. .. code-block:: llvm. !0 = !{!""llvm.loop.vectorize.width"", i32 4}. Note that setting ``llvm.loop.vectorize.width`` to 1 disables; vectorization of the loop. If ``llvm.loop.vectorize.width`` is set to; 0 or if the loop does not have this metadata the width will be; determined automatically. '``llvm.loop.vectorize.followup_vectorized``' Metadata; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. This metadata defines which loop attributes the vectorized loop will; have. See :ref:`transformation-metadata` for details. '``llvm.loop.vectorize.followup_epilogue``' Metadata; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. This metadata defines which loop attributes the epilogue will have. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:299058,scalab,scalable,299058,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['scalab'],['scalable']
Performance," the second element of its return value. (Note that; the function may also return true if the given pointer is not associated; with a type metadata identifier.) If the function's return value's second; element is true, the following rules apply to the first element:. - If the given pointer is associated with the given type metadata identifier,; it is the function pointer loaded from the given byte offset from the given; pointer. - If the given pointer is not associated with the given type metadata; identifier, it is one of the following (the choice of which is unspecified):. 1. The function pointer that would have been loaded from an arbitrarily chosen; (through an unspecified mechanism) pointer associated with the type; metadata. 2. If the function has a non-void return type, a pointer to a function that; returns an unspecified value without causing side effects. If the function's return value's second element is false, the value of the; first element is undefined. .. _type.checked.load.relative:. '``llvm.type.checked.load.relative``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare {ptr, i1} @llvm.type.checked.load.relative(ptr %ptr, i32 %offset, metadata %type) argmemonly nounwind readonly. Overview:; """""""""""""""""". The ``llvm.type.checked.load.relative`` intrinsic loads a relative pointer to a; function from a virtual table pointer using metadata. Otherwise, its semantic is; identical to the ``llvm.type.checked.load`` intrinsic. A relative pointer is a pointer to an offset to the pointed to value. The; address of the underlying pointer of the relative pointer is obtained by adding; the offset to the address of the offset value. '``llvm.arithmetic.fence``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare <type>; @llvm.arithmetic.fence(<type> <op>). Overview:; """""""""""""""""". The purpose of the ``llvm.arithmetic.fence`` intrinsic; is to prevent the optimizer from performing fast-math optimizations,; par",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:939768,load,load,939768,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['load'],['load']
Performance," the simulation:. Instruction Dependency Information; +----< 2. vhaddps %xmm3, %xmm3, %xmm4; |; | < loop carried >; |; | 0. vmulps %xmm0, %xmm1, %xmm2; +----> 1. vhaddps %xmm2, %xmm2, %xmm3 ## RESOURCE interference: JFPA [ probability: 74% ]; +----> 2. vhaddps %xmm3, %xmm3, %xmm4 ## REGISTER dependency: %xmm3; |; | < loop carried >; |; +----> 1. vhaddps %xmm2, %xmm2, %xmm3 ## RESOURCE interference: JFPA [ probability: 74% ]. According to the analysis, throughput is limited by resource pressure and not by; data dependencies. The analysis observed increases in backend pressure during; 48.07% of the simulated run. Almost all those pressure increase events were; caused by contention on processor resources JFPA/JFPU0. The `critical sequence` is the most expensive sequence of instructions according; to the simulation. It is annotated to provide extra information about critical; register dependencies and resource interferences between instructions. Instructions from the critical sequence are expected to significantly impact; performance. By construction, the accuracy of this analysis is strongly; dependent on the simulation and (as always) by the quality of the processor; model in llvm. Bottleneck analysis is currently not supported for processors with an in-order; backend. Extra Statistics to Further Diagnose Performance Issues; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; The ``-all-stats`` command line option enables extra statistics and performance; counters for the dispatch logic, the reorder buffer, the retire control unit,; and the register file. Below is an example of ``-all-stats`` output generated by :program:`llvm-mca`; for 300 iterations of the dot-product example discussed in the previous; sections. .. code-block:: none. Dynamic Dispatch Stall Cycles:; RAT - Register unavailable: 0; RCU - Retire tokens unavailable: 0; SCHEDQ - Scheduler full: 272 (44.6%); LQ - Load queue full: 0; SQ - Store queue full: 0; GROUP - Static restrictions on the dispatch ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:28287,perform,performance,28287,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,1,['perform'],['performance']
Performance," the sort order to use the 'entry number' when the seek position are equal.; Consequently the default sort order for an older in-memory TTree is now; essentially kSortBasketsByEntry rather than kSortBasketsByBranch (old 'correct' sort; order) or 'random' (the 'broken' sort order prior to this release). IMPORTANT enhancement in TTree::Fill:; Slides from a recent seminar describing the main features of ROOT IO and Trees and the recent; improvements described below are available at; http://root.cern/files/brun_lcgapp09.pptx ; or; http://root.cern/files/brun_lcgapp09.pdf .; The baskets are flushed and the Tree header saved at regular intervals (See AutoFlush and OptimizeBaskets); When the amount of data written so far (fTotBytes) is greater than fAutoFlush (see SetAutoFlush) all the baskets are flushed to disk.; This makes future reading faster as it guarantees that baskets belonging to nearby entries will be on the same disk region.; When the first call to flush the baskets happens, we also take this opportunity to optimize the baskets buffers.; We also check if the number of bytes written is greater than fAutoSave (see SetAutoSave).; In this case we also write the Tree header. This makes the Tree recoverable up to this point in case the program writing the Tree crashes.; Note that the user can also decide to call FlushBaskets and AutoSave in her event loop on the base of the number of events written instead of the number of bytes written.; New function TTree::OptimizeBaskets. void TTree::OptimizeBaskets(Int_t maxMemory, Float_t minComp, Option_t *option). This function may be called after having filled some entries in a Tree; using the information in the existing branch buffers, it will reassign; new branch buffer sizes to optimize time and memory.; The function computes the best values for branch buffer sizes such that; the total buffer sizes is less than maxMemory and nearby entries written; at the same time.; In case the branch compression factor for the data writt",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v526/index.html:3865,optimiz,optimize,3865,tree/doc/v526/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v526/index.html,2,['optimiz'],['optimize']
Performance," the symbol address assignments made for this graph.; In ORC this is used to notify any pending queries for *resolved* symbols,; including pending queries from concurrently running JITLink instances that; have reached the next step and are waiting on the address of a symbol in; this graph to proceed with their link. #. Identify external symbols and resolve their addresses asynchronously. Calls the ``JITLinkContext`` to resolve the target address of any external; symbols in the graph. #. Phase 3. #. Apply external symbol resolution results. This updates the addresses of all external symbols. At this point all; nodes in the graph have their final target addresses, however node; content still points back to the original data in the object file. #. Run pre-fixup passes. These passes are called on the graph after all nodes have been assigned; their final target addresses, but before node content is copied into; working memory and fixed up. Passes run at this stage can make late; optimizations to the graph and content based on address layout. Notable use cases: GOT and PLT relaxation, where GOT and PLT accesses are; bypassed for fixup targets that are directly accessible under the assigned; memory layout. #. Copy block content to working memory and apply fixups. Copies all block content into allocated working memory (following the; target layout) and applies fixups. Graph blocks are updated to point at; the fixed up content. #. Run post-fixup passes. These passes are called on the graph after fixups have been applied and; blocks updated to point to the fixed up content. Post-fixup passes can inspect blocks contents to see the exact bytes that; will be copied to the assigned target addresses. #. Finalize memory asynchronously. Calls the ``JITLinkMemoryManager`` to copy working memory to the executor; process and apply the requested permissions. #. Phase 3. #. Notify the context that the graph has been emitted. Calls ``JITLinkContext::notifyFinalized`` and hands off the; ``",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/JITLink.rst:21362,optimiz,optimizations,21362,interpreter/llvm-project/llvm/docs/JITLink.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/JITLink.rst,1,['optimiz'],['optimizations']
Performance," the workers, which are available via the input list, but; which are not saved in the TQueryResult object. These are meant for big; objects whic can create a big overload when distributed via the; standard input list (which should mostly be used for job control; parameters).  To add an input-data object just use; TProof::AddInputData(TObject *); if the input-data objects are in a; file you can use TProof::SetInputDataFile(const char *file); the final; set of input-data objects is assembled from the objects added via; AddInputData and those found in the file defined bySetInputDataFile.  . Improvements:. More; complete set of tests in test/stressProof . To run with PROOF-Lite pass; the argument 'lite' as master URL, e.g. './stressProof lite'.Possibility; to control on the client via rc variable the location of the sandbox,; package directory, cache and dataset directory (the latters two only; for PROOF-Lite); the variable names are 'Proof.Sandbox', ; 'Proof.PackageDir', 'Proof.CacheDir' and 'Proof.DataSetDir'. The default location of the sandbox has been changed from ""~/proof"" to ""~/.proof"" to avoid interferences with possible users' working areas.XrdProofd plug-in. Overall refactorization for easier; maintainance and improved solidity; Improved format of printout messages: all information; messages contain now the tag 'xpd-I' and all error messages the; tag 'xpd-E', so that they can easily be grepped out from the; log file.; . Log sending. Implement selective sending of logs from workers to master to avoid duplicating; too many text lines on the master log. Logs are now sent only after Exec, Print; requests and in case an error (level >= kError) occured. Of course, the full; logs can always be retrieved via TProofMgr::GetSessionLogs; . Log retrieval:. for 'grep' operations, use the system 'grep' command; via 'popen'; instead of a handmade filtering; this implies that the full grep; functionality is now available; set the default number of displayed lines to 100; inste",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v522/index.html:4288,Cache,CacheDir,4288,proof/doc/v522/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v522/index.html,1,['Cache'],['CacheDir']
Performance," the; cache. 3. buffer_inv sc1=1. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - system - global 1. buffer/global_atomic; sc1=1; 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_inv.; - Ensures the; atomicrmw has; completed before; invalidating the; caches. 3. buffer_inv sc0=1 sc1=1. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale MTYPE NC global data.; MTYPE RW and CC memory will; never be stale due to the; memory probes. atomicrmw acquire - agent - generic 1. flat_atomic; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_inv.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 3. buffer_inv sc1=1. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - system - generic 1. flat_atomic sc1=1; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_inv.; - Ensures the; atomicrmw has; completed before; invalidating the; caches. 3. buffer_inv sc0=1 sc1=1. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale MTYPE NC global data.; MTYPE RW and CC memory will; never be stale due to the; memory probes. fence acquire - singlethread *none* *none*; - wavefront; fence acquire - workgroup *none* 1. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - If OpenCL and; address space is; local, omit; vmcnt(0).; - H",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:301705,load,load,301705,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],['load']
Performance," the; clobbering memory access for ``MA``, caching all intermediate results; computed along the way as part of each access queried. - ``MemoryAccess *getClobberingMemoryAccess(MemoryAccess *MA, const MemoryLocation &Loc);``; returns the access clobbering memory location ``Loc``, starting at ``MA``.; Because this API does not request the clobbering access of a specific memory; access, there are no results that can be cached. Locating clobbers yourself; ^^^^^^^^^^^^^^^^^^^^^^^^^^. If you choose to make your own walker, you can find the clobber for a; ``MemoryAccess`` by walking every ``MemoryDef`` that dominates said; ``MemoryAccess``. The structure of ``MemoryDef``\ s makes this relatively simple;; they ultimately form a linked list of every clobber that dominates the; ``MemoryAccess`` that you're trying to optimize. In other words, the; ``definingAccess`` of a ``MemoryDef`` is always the nearest dominating; ``MemoryDef`` or ``MemoryPhi`` of said ``MemoryDef``. Use and Def optimization; ------------------------. ``MemoryUse``\ s keep a single operand, which is their defining or optimized; access.; Traditionally ``MemorySSA`` optimized ``MemoryUse``\ s at build-time, up to a; given threshold.; Specifically, the operand of every ``MemoryUse`` was optimized to point to the; actual clobber of said ``MemoryUse``. This can be seen in the above example; the; second ``MemoryUse`` in ``if.end`` has an operand of ``1``, which is a; ``MemoryDef`` from the entry block. This is done to make walking,; value numbering, etc, faster and easier.; As of `this revision <https://reviews.llvm.org/D121381>`_, the default was; changed to not optimize uses at build time, in order to provide the option to; reduce compile-time if the walking is not necessary in a pass. Most users call; the new API ``ensureOptimizedUses()`` to keep the previous behavior and do a; one-time optimization of ``MemoryUse``\ s, if this was not done before.; New pass users are recommended to call ``ensureOptimizedUses",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MemorySSA.rst:10964,optimiz,optimization,10964,interpreter/llvm-project/llvm/docs/MemorySSA.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MemorySSA.rst,1,['optimiz'],['optimization']
Performance," the; execution known as 'safepoints' For most collectors, it is sufficient; to track at least one copy of each unique pointer value. However, for; a collector which wishes to relocate objects directly reachable from; running code, a higher standard is required. One additional challenge is that the compiler may compute intermediate; results (""derived pointers"") which point outside of the allocation or; even into the middle of another allocation. The eventual use of this; intermediate value must yield an address within the bounds of the; allocation, but such ""exterior derived pointers"" may be visible to the; collector. Given this, a garbage collector can not safely rely on the; runtime value of an address to indicate the object it is associated; with. If the garbage collector wishes to move any object, the; compiler must provide a mapping, for each pointer, to an indication of; its allocation. To simplify the interaction between a collector and the compiled code,; most garbage collectors are organized in terms of three abstractions:; load barriers, store barriers, and safepoints. #. A load barrier is a bit of code executed immediately after the; machine load instruction, but before any use of the value loaded.; Depending on the collector, such a barrier may be needed for all; loads, merely loads of a particular type (in the original source; language), or none at all. #. Analogously, a store barrier is a code fragment that runs; immediately before the machine store instruction, but after the; computation of the value stored. The most common use of a store; barrier is to update a 'card table' in a generational garbage; collector. #. A safepoint is a location at which pointers visible to the compiled; code (i.e. currently in registers or on the stack) are allowed to; change. After the safepoint completes, the actual pointer value; may differ, but the 'object' (as seen by the source language); pointed to will not. Note that the term 'safepoint' is somewhat overloaded. It",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:2527,load,load,2527,interpreter/llvm-project/llvm/docs/Statepoints.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst,1,['load'],['load']
Performance," the; linker via object files. The list is encoded in the IR using named metadata with the name; ``!llvm.dependent-libraries``. Each operand is expected to be a metadata node; which should contain a single string operand. For example, the following metadata section contains two library specifiers::. !0 = !{!""a library specifier""}; !1 = !{!""another library specifier""}; !llvm.dependent-libraries = !{ !0, !1 }. Each library specifier will be handled independently by the consuming linker.; The effect of the library specifiers are defined by the consuming linker. .. _summary:. ThinLTO Summary; ===============. Compiling with `ThinLTO <https://clang.llvm.org/docs/ThinLTO.html>`_; causes the building of a compact summary of the module that is emitted into; the bitcode. The summary is emitted into the LLVM assembly and identified; in syntax by a caret ('``^``'). The summary is parsed into a bitcode output, along with the Module; IR, via the ""``llvm-as``"" tool. Tools that parse the Module IR for the purposes; of optimization (e.g. ""``clang -x ir``"" and ""``opt``""), will ignore the; summary entries (just as they currently ignore summary entries in a bitcode; input file). Eventually, the summary will be parsed into a ModuleSummaryIndex object under; the same conditions where summary index is currently built from bitcode.; Specifically, tools that test the Thin Link portion of a ThinLTO compile; (i.e. llvm-lto and llvm-lto2), or when parsing a combined index; for a distributed ThinLTO backend via clang's ""``-fthinlto-index=<>``"" flag; (this part is not yet implemented, use llvm-as to create a bitcode object; before feeding into thin link tools for now). There are currently 3 types of summary entries in the LLVM assembly:; :ref:`module paths<module_path_summary>`,; :ref:`global values<gv_summary>`, and; :ref:`type identifiers<typeid_summary>`. .. _module_path_summary:. Module Path Summary Entry; -------------------------. Each module path summary entry lists a module containing gl",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:339066,optimiz,optimization,339066,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['optimiz'],['optimization']
Performance," the; transition between local and remote files fixed in 5.24/00 . Enable mass storage domain settings when working with; TChain's; in multi-master mode. The Mass Storage Domain must be specified as; option in the URL.              ; chain.AddFile(""root:// .....?msd=CERN"").  and the string must match the value specified in defining the; submaster node.; Improved performance monitoring: the 'Rate plot' button; in the dialog box has been renamed 'Performance Plot' and now shows up; to 4 plots as a function of the processing time:. Instantaneous processing rate, which is now better; estimated by a better estimation of the normalizing times; Average read chunck size, defined as; TFile::GetFileBytesRead() / TFile::GetFileReadCalls() during the last; unit of time; this allows to monitor the usage of the cache; this plot; is present only if some I/O is done, i.e. not for pure CPU tasks.; The number of active workers; The number of total and effecive sessions running; concurrently on the cluster (started by the same daemon); this plot is; present only is the number is at least onec different from 1. If enabled, send monitoring information from the master; at each GetNextPacket (at each call of TPerfStat::PacketEvent) to allow; extrnal real-time progress monitoring.; Save the status of a 'proofserv' session into a new file; in the 'activesessions' area. The full path of the new file is;          ; <admin_path>/.xproofd.<port>/activesessions/<user>.<group>.<pid>.status. The status indicates whether the session is idle, running or queued.; The status is updated every 'checkfq' secs (see xpd.proofservmgr;; default 30 s). The status is dumped by the reader thread of TXProofServ; and therefore its r/w access is protected. Enable the use of the tree cache also for local files,; adapting the default settings for the cache to the recent changes; In the XrdProofd plug-in. Improve synchronization between parent and child during; fork; Optimize loops over directory entries; Improve err",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html:5224,concurren,concurrently,5224,proof/doc/v526/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html,2,['concurren'],['concurrently']
Performance," their; own s_waitcnt; lgkmcnt(0) and so do; not need to be; considered.); - s_waitcnt vmcnt(0); must happen after; preceding; global/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; vmcnt(0) and so do; not need to be; considered.); - Ensures any; preceding; sequential; consistent global/local; memory instructions; have completed; before executing; this sequentially; consistent; instruction. This; prevents reordering; a seq_cst store; followed by a; seq_cst load. (Note; that seq_cst is; stronger than; acquire/release as; the reordering of; load acquire; followed by a store; release is; prevented by the; s_waitcnt of; the release, but; there is nothing; preventing a store; release followed by; load acquire from; completing out of; order. The s_waitcnt; could be placed after; seq_store or before; the seq_load. We; choose the load to; make the s_waitcnt be; as late as possible; so that the store; may have already; completed.). 2. *Following; instructions same as; corresponding load; atomic acquire,; except must generate; all instructions even; for OpenCL.*; load atomic seq_cst - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. *Same as corresponding; load atomic acquire,; except must generate; all instructions even; for OpenCL.*. load atomic seq_cst - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0); and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt lgkmcnt(0); must happen after; preceding; global/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; lgkmcnt(0) and so do; not need to be; considered.); - s_waitc",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:281397,load,load,281397,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],['load']
Performance," then use the; :ref:`mem2reg <passes-mem2reg>` functionality to construct the appropriate; SSA form for the variable. ``loop-deletion``: Delete dead loops; ------------------------------------. This file implements the Dead Loop Deletion Pass. This pass is responsible for; eliminating loops with non-infinite computable trip counts that have no side; effects or volatile instructions, and do not contribute to the computation of; the function's return value. .. _passes-loop-extract:. ``loop-extract``: Extract loops into new functions; --------------------------------------------------. A pass wrapper around the ``ExtractLoop()`` scalar transformation to extract; each top-level loop into its own new function. If the loop is the *only* loop; in a given function, it is not touched. This is a pass most useful for; debugging via bugpoint. ``loop-reduce``: Loop Strength Reduction; ----------------------------------------. This pass performs a strength reduction on array references inside loops that; have as one or more of their components the loop induction variable. This is; accomplished by creating a new value to hold the initial value of the array; access for the first iteration, and then creating a new GEP instruction in the; loop to increment the value by the appropriate amount. .. _passes-loop-rotate:. ``loop-rotate``: Rotate Loops; -----------------------------. A simple loop rotation transformation. A summary of it can be found in; :ref:`Loop Terminology for Rotated Loops <loop-terminology-loop-rotate>`. .. _passes-loop-simplify:. ``loop-simplify``: Canonicalize natural loops; ---------------------------------------------. This pass performs several transformations to transform natural loops into a; simpler form, which makes subsequent analyses and transformations simpler and; more effective. A summary of it can be found in; :ref:`Loop Terminology, Loop Simplify Form <loop-terminology-loop-simplify>`. Loop pre-header insertion guarantees that there is a single, non-c",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Passes.rst:25981,perform,performs,25981,interpreter/llvm-project/llvm/docs/Passes.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Passes.rst,1,['perform'],['performs']
Performance," these compilers requires a lot of options. To simplify the; configuration the Apple Clang build settings are contained in CMake Cache files.; You can build an Apple Clang compiler using the following commands:. .. code-block:: console. $ cmake -G Ninja -C <path to source>/clang/cmake/caches/Apple-stage1.cmake <path to source>/llvm; $ ninja stage2-distribution. This CMake invocation configures the stage1 host compiler, and sets; CLANG_BOOTSTRAP_CMAKE_ARGS to pass the Apple-stage2.cmake cache script to the; stage2 configuration step. When you build the stage2-distribution target it builds the minimal stage1; compiler and required tools, then configures and builds the stage2 compiler; based on the settings in Apple-stage2.cmake. This pattern of using cache scripts to set complex settings, and specifically to; make later stage builds include cache scripts is common in our more advanced; build configurations. Multi-stage PGO; ===============. Profile-Guided Optimizations (PGO) is a really great way to optimize the code; clang generates. Our multi-stage PGO builds are a workflow for generating PGO; profiles that can be used to optimize clang. At a high level, the way PGO works is that you build an instrumented compiler,; then you run the instrumented compiler against sample source files. While the; instrumented compiler runs it will output a bunch of files containing; performance counters (.profraw files). After generating all the profraw files; you use llvm-profdata to merge the files into a single profdata file that you; can feed into the LLVM_PROFDATA_FILE option. Our PGO.cmake cache automates that whole process. You can use it for; configuration with CMake with the following command:. .. code-block:: console. $ cmake -G Ninja -C <path to source>/clang/cmake/caches/PGO.cmake \; <path to source>/llvm. There are several additional options that the cache file also accepts to modify; the build, particularly the PGO_INSTRUMENT_LTO option. Setting this option to; Thin or Fu",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AdvancedBuilds.rst:4798,optimiz,optimize,4798,interpreter/llvm-project/llvm/docs/AdvancedBuilds.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AdvancedBuilds.rst,1,['optimiz'],['optimize']
Performance," this ID through directly to the stack map; record without checking uniqueness. LLVM guarantees a shadow of instructions following the stack map's; instruction offset during which neither the end of the basic block nor; another call to ``llvm.experimental.stackmap`` or; ``llvm.experimental.patchpoint`` may occur. This allows the runtime to; patch the code at this point in response to an event triggered from; outside the code. The code for instructions following the stack map; may be emitted in the stack map's shadow, and these instructions may; be overwritten by destructive patching. Without shadow bytes, this; destructive patching could overwrite program text or data outside the; current function. We disallow overlapping stack map shadows so that; the runtime does not need to consider this corner case. For example, a stack map with 8 byte shadow:. .. code-block:: llvm. call void @runtime(); call void (i64, i32, ...) @llvm.experimental.stackmap(i64 77, i32 8,; ptr %ptr); %val = load i64, ptr %ptr; %add = add i64 %val, 3; ret i64 %add. May require one byte of nop-padding:. .. code-block:: none. 0x00 callq _runtime; 0x05 nop <--- stack map address; 0x06 movq (%rdi), %rax; 0x07 addq $3, %rax; 0x0a popq %rdx; 0x0b ret <---- end of 8-byte shadow. Now, if the runtime needs to invalidate the compiled code, it may; patch 8 bytes of code at the stack map's address at follows:. .. code-block:: none. 0x00 callq _runtime; 0x05 movl $0xffff, %rax <--- patched code at stack map address; 0x0a callq *%rax <---- end of 8-byte shadow. This way, after the normal call to the runtime returns, the code will; execute a patched call to a special entry point that can rebuild a; stack frame from the values located by the stack map. '``llvm.experimental.patchpoint.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare void; @llvm.experimental.patchpoint.void(i64 <id>, i32 <numBytes>,; ptr <target>, i32 <numArgs>, ...); declare i64; @llvm.experimental.pat",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:6581,load,load,6581,interpreter/llvm-project/llvm/docs/StackMaps.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst,1,['load'],['load']
Performance," this even goes further:; as sin and cos are names of standard math functions, the constant folder; will directly evaluate the function calls to the correct result when called; with constants like in the ""``sin(1.0)``"" above. In the future we'll see how tweaking this symbol resolution rule can be used to; enable all sorts of useful features, from security (restricting the set of; symbols available to JIT'd code), to dynamic code generation based on symbol; names, and even lazy compilation. One immediate benefit of the symbol resolution rule is that we can now extend; the language by writing arbitrary C++ code to implement operations. For example,; if we add:. .. code-block:: c++. #ifdef _WIN32; #define DLLEXPORT __declspec(dllexport); #else; #define DLLEXPORT; #endif. /// putchard - putchar that takes a double and returns 0.; extern ""C"" DLLEXPORT double putchard(double X) {; fputc((char)X, stderr);; return 0;; }. Note, that for Windows we need to actually export the functions because; the dynamic symbol loader will use ``GetProcAddress`` to find the symbols. Now we can produce simple output to the console by using things like:; ""``extern putchard(x); putchard(120);``"", which prints a lowercase 'x'; on the console (120 is the ASCII code for 'x'). Similar code could be; used to implement file I/O, console input, and many other capabilities; in Kaleidoscope. This completes the JIT and optimizer chapter of the Kaleidoscope; tutorial. At this point, we can compile a non-Turing-complete; programming language, optimize and JIT compile it in a user-driven way.; Next up we'll look into `extending the language with control flow; constructs <LangImpl05.html>`_, tackling some interesting LLVM IR issues; along the way. Full Code Listing; =================. Here is the complete code listing for our running example, enhanced with; the LLVM JIT and optimizer. To build this example, use:. .. code-block:: bash. # Compile; clang++ -g toy.cpp `llvm-config --cxxflags --ldflags --system-",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl04.rst:24240,load,loader,24240,interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl04.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl04.rst,1,['load'],['loader']
Performance," this is a very straight forward and literal translation: exactly; what we want for zero cost (when unused) exception handling. Especially on; platforms with many registers (ie, the IA64) setjmp/longjmp style exception; handling is *very* impractical. Also, the ""with"" clauses describe the ; control flow paths explicitly so that analysis is not adversly effected. The foo/barCleanup labels are implemented as:. TryCleanup: // Executed if an exception escapes the try block ; c->~C(); barCleanup: // Executed if an exception escapes from bar(); // fall through; fooCleanup: // Executed if an exception escapes from foo(); b->~B(); a->~A(); Exception *E = getThreadLocalException(); call throw(E) // Implemented by the C++ runtime, described below. Which does the work one would expect. getThreadLocalException is a function; implemented by the C++ support library. It returns the current exception ; object for the current thread. Note that we do not attempt to recycle the ; shutdown code from before, because performance of the mainline code is ; critically important. Also, obviously fooCleanup and barCleanup may be ; merged and one of them eliminated. This just shows how the code generator ; would most likely emit code. The bazCleanup label is more interesting. Because the exception may be caught; by the try block, we must dispatch to its handler... but it does not exist; on the call stack (it does not have a VM Call->Label mapping installed), so ; we must dispatch statically with a goto. The bazHandler thus appears as:. bazHandler:; d->~D(); // destruct D as it goes out of scope when entering catch clauses; goto TryHandler. In general, TryHandler is not the same as bazHandler, because multiple ; function calls could be made from the try block. In this case, trivial ; optimization could merge the two basic blocks. TryHandler is the code ; that actually determines the type of exception, based on the Exception object; itself. For this discussion, assume that the exception object c",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-05-18-ExceptionHandling.txt:4407,perform,performance,4407,interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-05-18-ExceptionHandling.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-05-18-ExceptionHandling.txt,1,['perform'],['performance']
Performance," three arguments are the same as they are in the :ref:`@llvm.memcpy <int_memcpy>`; intrinsic, with the added constraint that ``len`` is required to be a positive integer; multiple of the ``element_size``. If ``len`` is not a positive integer multiple of; ``element_size``, then the behaviour of the intrinsic is undefined. ``element_size`` must be a compile-time constant positive power of two no greater than; target-specific atomic access size limit. For each of the input pointers ``align`` parameter attribute must be specified. It; must be a power of two no less than the ``element_size``. Caller guarantees that; both the source and destination pointers are aligned to that boundary. Semantics:; """""""""""""""""""". The '``llvm.memcpy.element.unordered.atomic.*``' intrinsic copies ``len`` bytes of; memory from the source location to the destination location. These locations are not; allowed to overlap. The memory copy is performed as a sequence of load/store operations; where each access is guaranteed to be a multiple of ``element_size`` bytes wide and; aligned at an ``element_size`` boundary. The order of the copy is unspecified. The same value may be read from the source; buffer many times, but only one write is issued to the destination buffer per; element. It is well defined to have concurrent reads and writes to both source and; destination provided those reads and writes are unordered atomic when specified. This intrinsic does not provide any additional ordering guarantees over those; provided by a set of unordered loads from the source location and stores to the; destination. Lowering:; """""""""""""""""". In the most general case call to the '``llvm.memcpy.element.unordered.atomic.*``' is; lowered to a call to the symbol ``__llvm_memcpy_element_unordered_atomic_*``. Where '*'; is replaced with an actual element size. See :ref:`RewriteStatepointsForGC intrinsic; lowering <RewriteStatepointsForGC_intrinsic_lowering>` for details on GC specific; lowering. Optimizer is allowed to inl",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:958996,perform,performed,958996,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,2,"['load', 'perform']","['load', 'performed']"
Performance," thus loaded at start-up. Plugins are defined by a base class (e.g.; **`TFile`**) that will be implemented in a plugin, a tag used to; identify the plugin (e.g. `^rfio:` as part of the protocol string),; the plugin class of which an object will be created; (e.g. **`TRFIOFile`**), the library to be loaded (in short; `libRFIO.so` to RFIO), and the constructor to be called (e.g.; ""`TRFIOFile()`""). This can be specified in the `.rootrc` which already; contains many plugin definitions, or by calls to; `gROOT->GetPluginManager()->AddHandler()`. #### Library AutoLoading. When using a class in Cling, e.g. in an interpreted source file, ROOT; will automatically load the library that defines this class. On; start-up, ROOT parses all files ending on `.rootmap` rootmap that are; in one of the `$LD_LIBRARY_PATH` (or `$DYLD_LIBRARY_PATH` for `MacOS`,; or `$PATH` for `Windows`). They contain class names and the library; names that the class depends on. After reading them, ROOT knows which; classes are available, and which libraries to load for them. When `TSystem::Load(""ALib"")` is called, ROOT uses this information to; determine which libraries `libALib.so` depends on. It will load these; libraries first. Otherwise, loading the requested library could cause; a system (dynamic loader) error due to unresolved symbols. ### \$ROOTSYS/tutorials. tutorials The tutorials directory contains many example example; scripts. They assume some basic knowledge of ROOT, and for the new; user we recommend reading the chapters: ""Histograms"" and; ""Input/Output"" before trying the examples. The more experienced user; can jump to chapter ""The Tutorials and Tests"" to find more explicit; and specific information about how to build and run the examples. The `$ROOTSYS/tutorials/` directory include the following; sub-directories:. `fft`: Fast Fourier Transform with the fftw package `fit`: Several; examples illustrating minimization/fitting `foam`: Random generator in; multidimensional space `geom`: Examples ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Introduction.md:20218,load,load,20218,documentation/users-guide/Introduction.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Introduction.md,1,['load'],['load']
Performance," to 1.; ======================================== ================================================. .. _amdgpu_synid_lds:. lds; ~~~. Specifies where to store the result: VGPRs or LDS (VGPRs by default). ======================================== ===========================; Syntax Description; ======================================== ===========================; lds Store the result in LDS.; ======================================== ===========================. .. _amdgpu_synid_nv:. nv; ~~. Specifies if the instruction is operating on non-volatile memory.; By default, memory is volatile. ======================================== ================================================; Syntax Description; ======================================== ================================================; nv Indicates that the instruction operates on; non-volatile memory.; ======================================== ================================================. .. _amdgpu_synid_slc:. slc; ~~~. Controls behavior of L2 cache. The default value is off (0). ======================================== ================================================; Syntax Description; ======================================== ================================================; slc Set slc bit to 1.; ======================================== ================================================. .. _amdgpu_synid_tfe:. tfe; ~~~. Controls access to partially resident textures. The default value is off (0). ======================================== ================================================; Syntax Description; ======================================== ================================================; tfe Set tfe bit to 1.; ======================================== ================================================. .. _amdgpu_synid_sc0:. sc0; ~~~. For atomic opcodes, this modifier indicates that the instruction returns the value from memory; before the operation. For other opcodes, it is used together with :ref:`sc1<amdgpu",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst:19109,cache,cache,19109,interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst,1,['cache'],['cache']
Performance," to a `RooFit` class are passed as; constructor arguments, it can be imported using a `factory; expression`. For the importer, an entry in the; [factory expressions](https://github.com/root-project/root/blob/master/etc/RooFitHS3_wsfactoryexpressions.json); needs to be added as follows:. ``` {.json}; ""<json-key>"": {; ""class"": ""<C++ class name>"",; ""arguments"": [; ""<json-key of constructor argument #1>"",; ""<json-key of constructor argument #2>"",; ...; ]; }; ```. Similarly, for the exporter, an entry in the; [export keys](https://github.com/root-project/root/blob/master/etc/RooFitHS3_wsexportkeys.json); needs to be added as follows:. ``` {.json}; ""<C++ class name>"": {; ""type"": ""<json-key>"",; ""proxies"": {; ""<name of proxy>"": ""<json-key of this element>"",; ""<name of proxy>"": ""<json-key of this element>"",; ...; }; }; ```. If you don't want to edit the central `json` files containing the; factory expressions or export keys, you can also put your custom; export keys or factory expressions into a different json file and load; that using `RooFit::JSONIO::loadExportKeys(const std::string; &fname)` and `RooFit::JSONIO::loadFactoryExpressions(const; std::string &fname)`. If either the importer or the exporter cannot be created with factory; expressions and export keys, you can instead write a custom `C++`; class to perform the import and export for you. ### Writing your own importers and exporters: Custom `C++` code. In order to implement your own importer or exporter, you can inherit; from the corresponding base classes `RooFit::JSONIO::Importer`; or `RooFit::JSONIO::Exporter`, respectively. You can find; [simple examples](https://github.com/root-project/root/blob/master/roofit/hs3/src/JSONFactories_RooFitCore.cxx); as well as; [more complicated ones](https://github.com/root-project/root/blob/master/roofit/hs3/src/JSONFactories_HistFactory.cxx); in `ROOT`. Any importer should take the following form:. ``` {.cpp}; class MyClassFactory : public RooFit::JSONIO::Importer {; public:; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/developers/roofit_hs3.md:4424,load,load,4424,roofit/doc/developers/roofit_hs3.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/developers/roofit_hs3.md,3,['load'],"['load', 'loadExportKeys', 'loadFactoryExpressions']"
Performance," to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global and local; have completed; before performing; the atomicrmw that; is being released. 2. buffer/global/flat_atomic; fence release - singlethread *none* *none*; - wavefront; fence release - workgroup *none* 1. s_waitcnt lgkmcnt(0). - If OpenCL and; address space is; not generic, omit.; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate. If; fence had an; address space then; set to address; space of OpenCL; fence flag, or to; generic if both; local and global; flags are; specified.; - Must happen after; any preceding; local/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Must happen before; any following store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Ensures that all; memory operations; to local have; completed before; performing the; following; fence-paired-atomic. fence release - agent *none* 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0). - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - If OpenCL and; address space is; local, omit; vmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate. If; fence had an; address space then; set to address; space of OpenCL; fence flag, or to; generic if both; local and global; flags are; specified.; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:222092,load,load,222092,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],['load']
Performance," to connect signals to slots methods. Therefore, all necessary elements for an object-oriented editor design; are in place. The editor complexity can be reduced by splitting it into; discrete units of so-called *`object`* *`editors`*. Any object editor; provides an object specific GUI. The main purpose of the ROOT graphics; editor is the organization of the object editors' appearance and the; task sequence between them. ### Object Editors. Every object editor follows a simple naming convention: to have as a; name the object class name concatenated with ‘*`Editor`*' (e.g. for; **`TGraph`** objects the object editor is **`TGraphEditor`**). Thanks to; the signals/slots communication mechanism and to the method; `DistancetoPrimitive()` that computes a ‘‘distance'' to an object from; the mouse position, it was possible to implement a signal method of the; canvas that says which is the selected object and to which pad it; belongs. Having this information the graphics editor loads the; corresponding object editor and the user interface is ready for use.; This way after a click on ‘axis'—the axis editor is active; a click on a; ‘pad' activates the pad editor, etc. The algorithm in use is simple and is based on the object-oriented; relationship and communication. When the user activates the editor,; according to the selected object **`<obj>`** in the canvas it looks for; a class name **`<obj>Editor`**. For that reason, the correct naming is; very important. If a class with this name is found, the editor verifies; that this class derives from the base editor class **`TGedFrame`**. If; all checks are satisfied, the editor makes an instance of the object; editor. Then, it scans all object base classes searching the; corresponding object editors. When it finds one, it makes an instance of; the base class editor too. Once the object editor is in place, it sets the user interface elements; according to the object's status. After that, it is ready to interact; with the object follo",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/WritingGUI.md:102721,load,loads,102721,documentation/users-guide/WritingGUI.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/WritingGUI.md,2,['load'],['loads']
Performance," to execute multiple iterations using; vector registers. Note that although this is similar to SIMT execution, the way a client debugger; uses the information is fundamentally different. In SIMT execution the debugger; needs to present the concurrent execution as distinct source language threads; that the user can list and switch focus between. With iteration concurrency; optimizations, such as software pipelining and vectorized SIMD, the debugger; must not present the concurrency as distinct source language threads. Instead,; it must inform the user that multiple loop iterations are executing in parallel; and allow the user to select between them. In general, SIMT execution fixes the number of concurrent executions per target; architecture thread. However, both software pipelining and SIMD vectorization; may vary the number of concurrent iterations for different loops executed by a; single source language thread. It is possible for the compiler to use both SIMT concurrency and iteration; concurrency techniques in the code of a single source language thread. Therefore, a DWARF operation is required to denote the current concurrent; iteration instance, much like ``DW_OP_push_object_address`` denotes the current; object. See ``DW_OP_LLVM_push_iteration`` in; :ref:`amdgpu-dwarf-literal-operations`. In addition, a way is needed for the compiler to communicate how many source; language loop iterations are executing concurrently. See; ``DW_AT_LLVM_iterations`` in :ref:`amdgpu-dwarf-low-level-information`. 2.20 DWARF Operation to Create Runtime Overlay Composite Location Description; -----------------------------------------------------------------------------. It is common in SIMD vectorization for the compiler to generate code that; promotes portions of an array into vector registers. For example, if the; hardware has vector registers with 8 elements, and 8 wide SIMD instructions, the; compiler may vectorize a loop so that is executes 8 iterations concurrently for; each v",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:34233,concurren,concurrency,34233,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,2,['concurren'],['concurrency']
Performance," to leak information. While in some cases static; analysis is effective at doing this at scale, in many cases it still relies on; human judgement to evaluate whether code might be vulnerable. Especially for; software systems which receive less detailed scrutiny but remain sensitive to; these attacks, this seems like an impractical security model. We need an; automatic and systematic mitigation strategy. ### Automatic `lfence` on Conditional Edges. A natural way to scale up the existing hand-coded mitigations is simply to; inject an `lfence` instruction into both the target and fallthrough; destinations of every conditional branch. This ensures that no predicate or; bounds check can be bypassed speculatively. However, the performance overhead; of this approach is, simply put, catastrophic. Yet it remains the only truly; ""secure by default"" approach known prior to this effort and serves as the; baseline for performance. One attempt to address the performance overhead of this and make it more; realistic to deploy is [MSVC's /Qspectre; switch](https://blogs.msdn.microsoft.com/vcblog/2018/01/15/spectre-mitigations-in-msvc/).; Their technique is to use static analysis within the compiler to only insert; `lfence` instructions into conditional edges at risk of attack. However,; [initial](https://arstechnica.com/gadgets/2018/02/microsofts-compiler-level-spectre-fix-shows-how-hard-this-problem-will-be-to-solve/); [analysis](https://www.paulkocher.com/doc/MicrosoftCompilerSpectreMitigation.html); has shown that this approach is incomplete and only catches a small and limited; subset of attackable patterns which happen to resemble very closely the initial; proofs of concept. As such, while its performance is acceptable, it does not; appear to be an adequate systematic mitigation. ## Performance Overhead. The performance overhead of this style of comprehensive mitigation is very; high. However, it compares very favorably with previously recommended; approaches such as the `lfence",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:45612,perform,performance,45612,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,1,['perform'],['performance']
Performance," to merge functions? The obvious answer is: Yes, that is quite a; possible case. We usually *do* have duplicates and it would be good to get rid; of them. But how do we detect duplicates? This is the idea: we split functions; into smaller bricks or parts and compare the ""bricks"" amount. If equal,; we compare the ""bricks"" themselves, and then do our conclusions about functions; themselves. What could the difference be? For example, on a machine with 64-bit pointers; (let's assume we have only one address space), one function stores a 64-bit; integer, while another one stores a pointer. If the target is the machine; mentioned above, and if functions are identical, except the parameter type (we; could consider it as a part of function type), then we can treat a ``uint64_t``; and a ``void*`` as equal. This is just an example; more possible details are described a bit below. As another example, the reader may imagine two more functions. The first; function performs a multiplication by 2, while the second one performs an; logical left shift by 1. Possible solutions; ^^^^^^^^^^^^^^^^^^; Let's briefly consider possible options about how and what we have to implement; in order to create full-featured functions merging, and also what it would; mean for us. Equal function detection obviously supposes that a ""detector"" method to be; implemented and latter should answer the question ""whether functions are equal"".; This ""detector"" method consists of tiny ""sub-detectors"", which each answers; exactly the same question, but for function parts. As the second step, we should merge equal functions. So it should be a ""merger""; method. ""Merger"" accepts two functions *F1* and *F2*, and produces *F1F2*; function, the result of merging. Having such routines in our hands, we can process a whole module, and merge all; equal functions. In this case, we have to compare every function with every another function. As; the reader may notice, this way seems to be quite expensive. Of course we could;",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MergeFunctions.rst:4365,perform,performs,4365,interpreter/llvm-project/llvm/docs/MergeFunctions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MergeFunctions.rst,2,['perform'],['performs']
Performance," to perform the check; according to the kind. Paired assignment check; =======================. ``-fbounds-safety`` enforces that variables or fields related with the same; external bounds annotation (e.g., ``buf`` and ``count`` related with; ``__counted_by`` in the example below) must be updated side by side within the; same basic block and without side effect in between. .. code-block:: c. typedef struct {; int *__counted_by(count) buf; size_t count;; } sized_buf_t;. void alloc_buf(sized_buf_t *sbuf, sized_t nelems) {; sbuf->buf = (int *)malloc(sizeof(int) * nelems);; sbuf->count = nelems;; }. To implement this rule, the compiler requires a linear representation of; statements to understand the ordering and the adjacency between the two or more; assignments. The Clang CFG is used to implement this analysis as Clang CFG; provides a linear view of statements within each ``CFGBlock`` (Clang; ``CFGBlock`` represents a single basic block in a source-level CFG). Bounds check optimizations; ==========================. In ``-fbounds-safety``, the Clang frontend emits run-time checks for every; memory dereference if the type system or analyses in the frontend couldn’t; verify its bounds safety. The implementation relies on LLVM optimizations to; remove redundant run-time checks. Using this optimization strategy, if the; original source code already has bounds checks, the fewer additional checks; ``-fbounds-safety`` will introduce. The LLVM ``ConstraintElimination`` pass is; design to remove provable redundant checks (please check Florian Hahn’s; presentation in 2021 LLVM Dev Meeting and the implementation to learn more). In; the following example, ``-fbounds-safety`` implicitly adds the redundant bounds; checks that the optimizer can remove:. .. code-block:: c. void fill_array_with_indices(int *__counted_by(count) p, size_t count) {; for (size_t i = 0; i < count; ++i) {; // implicit bounds checks:; // if (p + i < p || p + i + 1 > p + count) trap();; p[i] = i;; }; }. ``Cons",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/BoundsSafetyImplPlans.rst:5970,optimiz,optimizations,5970,interpreter/llvm-project/clang/docs/BoundsSafetyImplPlans.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/BoundsSafetyImplPlans.rst,1,['optimiz'],['optimizations']
Performance," to save a canvas into `file.xml` file; format instead of `file.root`. XML files do not have any advantages; compared to the normal ROOT files, except that the information in these; files can be edited via a normal editor. The main motivation for this; new format is to facilitate the communication with other non ROOT; applications. Currently writing and reading XML files is limited to ROOT; applications. It is our intention to develop a simple reader independent; of the ROOT libraries that could be used as an example for real; applications. The XML format should be used only for small data volumes, typically; histogram files, pictures, geometries, calibrations. The XML file is; built in memory before being dumped to disk. Like for normal ROOT files,; XML files use the same I/O mechanism exploiting the ROOT/Cling; dictionary. Any class having a dictionary can be saved in XML format.; This first implementation does not support subdirectories or trees. The shared library `libRXML.so` may be loaded dynamically via; `gSystem->Load(""libRXML"")`. This library is also automatically loaded by; the plug-in manager as soon a XML file is created. To create an XTM; file, simply specify a filename with an .xml extension when calling; **`TFile`**`::Open`. **`TFile`**`::Open` will recognize that you are trying to; open an XML file and return a **`TXMLFile`** object. When a XML file is; open in write mode, one can use the normal `TObject::Write` to write an; object in the file. ``` {.cpp}; // example of a session saving a histogram to a XML file; TFile *f = TFile::Open(""Example.xml"",""recreate"");; TH1F *h = new TH1F(""h"",""test"",1000,-2,2); h->FillRandom(""gaus"");; h->Write();; delete f;; // example of a session saving a histogram to a XML file; TFile *f = TFile::Open(""Example.xml"");; TH1F *h = (TH1F*)f->Get(""h"");; h->Draw();; ```. The canvas can be saved as a XML file format via File menu / Save or; Save As menu entries. One can do also:. ``` {.cpp}; canvas->Print(""Example.xml"");; ```; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/InputOutput.md:98094,load,loaded,98094,documentation/users-guide/InputOutput.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/InputOutput.md,2,['load'],['loaded']
Performance," to simple alias analysis; information, this class exposes Mod/Ref information from those implementations; which can provide it, allowing for powerful analyses and transformations to work; well together. This document contains information necessary to successfully implement this; interface, use it, and to test both sides. It also explains some of the finer; points about what exactly results mean. ``AliasAnalysis`` Class Overview; ================================. The `AliasAnalysis <https://llvm.org/doxygen/classllvm_1_1AliasAnalysis.html>`__; class defines the interface that the various alias analysis implementations; should support. This class exports two important enums: ``AliasResult`` and; ``ModRefResult`` which represent the result of an alias query or a mod/ref; query, respectively. The ``AliasAnalysis`` interface exposes information about memory, represented in; several different ways. In particular, memory objects are represented as a; starting address and size, and function calls are represented as the actual; ``call`` or ``invoke`` instructions that performs the call. The; ``AliasAnalysis`` interface also exposes some helper methods which allow you to; get mod/ref information for arbitrary instructions. All ``AliasAnalysis`` interfaces require that in queries involving multiple; values, values which are not :ref:`constants <constants>` are all; defined within the same function. Representation of Pointers; --------------------------. Most importantly, the ``AliasAnalysis`` class provides several methods which are; used to query whether or not two memory objects alias, whether function calls; can modify or read a memory object, etc. For all of these queries, memory; objects are represented as a pair of their starting address (a symbolic LLVM; ``Value*``) and a static size. Representing memory objects as a starting address and a size is critically; important for correct Alias Analyses. For example, consider this (silly, but; possible) C code:. .. code-block::",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AliasAnalysis.rst:2364,perform,performs,2364,interpreter/llvm-project/llvm/docs/AliasAnalysis.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AliasAnalysis.rst,1,['perform'],['performs']
Performance," to:. ```cpp; // ROOT prompt; root [] import Foo.*; // Preload Foo if it is not in the GMI.; root [] S *s; // #1: does not require a definition.; root [] foo::bar *baz1; // #2: does not require a definition.; root [] foo::bar baz2; // #3: requires a definition.; root [] TCanvas* c = new TCanvas(); // #4 requires a definition; ```. Line #4 forces cling to send ROOT a callback that TCanvas in unknown but; the GMI resolves it to module Gpad, loads it and returns the control to cling. ### Performance; This section compares ROOT PCH technology with C++ Modules which is important but; unfair comparison. As we noted earlier, PCH is very efficient, it cannot be; extended to the experiments’ software stacks because of its design constraints.; On the contrary, the C++ Modules can be used in third-party code where the PCH; is not available. The comparisons are to give a good metric when we are ready to switch ROOT to use; C++ Modules by default. However, since it is essentially the same technology,; optimizations of C++ Modules also affect the PCH. We have a few tricks up in; the sleeves to but they come with given trade-offs. #### Preloading of C++ Modules. The main focus for the technology preview was not in performance until recently.; We have invested some resources in optimizations and we would like to show you; (probably outdated) performance results:. * Memory footprint -- mostly due to importing all C++ Modules at startup; we see overhead which depends on the number of preloaded modules. For; ROOT it is between 40-60 MB depending on the concrete configuration.; When the workload increases we notice that the overall memory performance; decreases in number of cases.; * Execution times -- likewise we have an execution overhead. For ; workflows which take ms the slowdown can be 2x. Increasing of the work; to seconds shows 50-60% slowdowns. The performance is dependent on many factors such as configuration of ROOT and; workflow. You can read more at our Intel IPCC-ROOT Showc",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/README.CXXMODULES.md:17810,optimiz,optimizations,17810,README/README.CXXMODULES.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/README.CXXMODULES.md,1,['optimiz'],['optimizations']
Performance," to; metadata-symbolic-based regions during scanReachableSymbols() whenever a region; turns out to be reachable. This requires no work on checker side, but it sounds; performance-heavy. Approach (3): We could let checkers maintain the set of active metadata symbols; in the program state (ideally somewhere in the Store, which sounds weird but; causes the smallest amount of layering violations), so that the core knew what; to escape. This puts a stress on the checkers, but with a smart data map it; wouldn't be a problem. Approach (4): We could allow checkers to trigger pointer escapes in arbitrary; moments. If we allow doing this within ``checkPointerEscape`` callback itself, we; would be able to express facts like ""when this region escapes, that metadata; symbol attached to it should also escape"". This sounds like an ultimate freedom,; with maximum stress on the checkers - still not too much stress when we have; smart data maps. I'm personally liking the approach (2) - it should be possible to avoid; performance overhead, and clarity seems nice. **Gabor:**. At this point, I am a bit wondering about two questions. * When should something belong to a checker and when should something belong to the engine?; Sometimes we model library aspects in the engine and model language constructs in checkers. * What is the checker programming model that we are aiming for? Maximum freedom or more easy checker development?. I think if we aim for maximum freedom, we do not need to worry about the; potential stress on checkers, and we can introduce abstractions to mitigate that; later on.; If we want to simplify the API, then maybe it makes more sense to move language; construct modeling to the engine when the checker API is not sufficient instead; of complicating the API. Right now I have no preference or objections between the alternatives but there; are some random thoughts:. * Maybe it would be great to have a guideline how to evolve the analyzer and; follow it, so it can help us to",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/developer-docs/InitializerLists.rst:4586,perform,performance,4586,interpreter/llvm-project/clang/docs/analyzer/developer-docs/InitializerLists.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/developer-docs/InitializerLists.rst,1,['perform'],['performance']
Performance," together, for different possible reasons. One; of these is that the structure has to be replicated in several parts of; the geometry, or it may simply happen that they really represent a; single object, too complex to be described by a primitive shape. Usually handling structures like these can be easily done by positioning; all components in the same container volume, then positioning the; container itself. However, there are many practical cases when defining; such a container is not straightforward or even possible without; generating overlaps with the rest of the geometry. There are few ways; out of this:. - Defining the container for the structure as ""overlapping"" (see also; "" Overlapping Volumes **""**); - Representing the container as a composite shape - the Boolean union; of all components (see also "" Composite Shapes ""); - Using an assembly volume - this will be described in the following. The first two approaches have the disadvantage of penalizing the; navigation performance with a factor increasing more than linear of the; number of components in the structure. The best solution is the third; one because it uses all volume-related navigation optimizations. The; class **`TGeoVolumeAssembly`** represents an assembly volume. Its shape; is represented by **`TGeoShapeAssembly`** class that is the union of all; components. It uses volume voxelization to perform navigation tasks. An assembly volume creates a hierarchical level and it geometrically; insulates the structure from the rest (as a normal volume). Physically,; a point that is INSIDE a **`TGeoShapeAssembly`** is always inside one of; the components, so a **`TGeoVolumeAssembly`** does not need to have a; medium. Due to the self-containment of assemblies, they are very; practical to use when a container is hard to define due to possible; overlaps during positioning. For instance, it is very easy creating; honeycomb structures. A very useful example for creating and using; assemblies can be found at:; <ht",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md:89043,perform,performance,89043,documentation/users-guide/Geometry.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md,1,['perform'],['performance']
Performance," tool; <ClangFormat>` with the goal of automatically reformatting C++ sources files; according to configurable style guides. To do so, clang-format uses Clang's; ``Lexer`` to transform an input file into a token stream and then changes all; the whitespace around those tokens. The goal is for clang-format to serve both; as a user tool (ideally with powerful IDE integrations) and as part of other; refactoring tools, e.g. to do a reformatting of all the lines changed during a; renaming. Extra Clang Tools; =================. As various categories of Clang Tools are added to the extra repository,; they'll be tracked here. The focus of this documentation is on the scope; and features of the tools for other tool developers; each tool should; provide its own user-focused documentation. ``clang-tidy``; --------------. `clang-tidy <https://clang.llvm.org/extra/clang-tidy/>`_ is a clang-based C++; linter tool. It provides an extensible framework for building compiler-based; static analyses detecting and fixing bug-prone patterns, performance,; portability and maintainability issues. Ideas for new Tools; ===================. * C++ cast conversion tool. Will convert C-style casts (``(type) value``) to; appropriate C++ cast (``static_cast``, ``const_cast`` or; ``reinterpret_cast``).; * Non-member ``begin()`` and ``end()`` conversion tool. Will convert; ``foo.begin()`` into ``begin(foo)`` and similarly for ``end()``, where; ``foo`` is a standard container. We could also detect similar patterns for; arrays.; * ``tr1`` removal tool. Will migrate source code from using TR1 library; features to C++11 library. For example:. .. code-block:: c++. #include <tr1/unordered_map>; int main(); {; std::tr1::unordered_map <int, int> ma;; std::cout << ma.size () << std::endl;; return 0;; }. should be rewritten to:. .. code-block:: c++. #include <unordered_map>; int main(); {; std::unordered_map <int, int> ma;; std::cout << ma.size () << std::endl;; return 0;; }. * A tool to remove ``auto``. Will ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangTools.rst:4358,perform,performance,4358,interpreter/llvm-project/clang/docs/ClangTools.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangTools.rst,1,['perform'],['performance']
Performance," trees converted; 75 raise - Number of other getelementptr's formed; 138 raise - Number of load/store peepholes; 42 deadtypeelim - Number of unused typenames removed from symtab; 392 funcresolve - Number of varargs functions resolved; 27 globaldce - Number of global variables removed; 2 adce - Number of basic blocks removed; 134 cee - Number of branches revectored; 49 cee - Number of setcc instruction eliminated; 532 gcse - Number of loads removed; 2919 gcse - Number of instructions removed; 86 indvars - Number of canonical indvars added; 87 indvars - Number of aux indvars removed; 25 instcombine - Number of dead inst eliminate; 434 instcombine - Number of insts combined; 248 licm - Number of load insts hoisted; 1298 licm - Number of insts hoisted to a loop pre-header; 3 licm - Number of insts hoisted to multiple loop preds (bad, no loop pre-header); 75 mem2reg - Number of alloca's promoted; 1444 cfgsimplify - Number of blocks simplified. Obviously, with so many optimizations, having a unified framework for this stuff; is very nice. Making your pass fit well into the framework makes it more; maintainable and useful. .. _DebugCounters:. Adding debug counters to aid in debugging your code; ---------------------------------------------------. Sometimes, when writing new passes, or trying to track down bugs, it; is useful to be able to control whether certain things in your pass; happen or not. For example, there are times the minimization tooling; can only easily give you large testcases. You would like to narrow; your bug down to a specific transformation happening or not happening,; automatically, using bisection. This is where debug counters help.; They provide a framework for making parts of your code only execute a; certain number of times. The ``llvm/Support/DebugCounter.h`` (`doxygen; <https://llvm.org/doxygen/DebugCounter_8h_source.html>`__) file; provides a class named ``DebugCounter`` that can be used to create; command line counter options that control execu",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:49501,optimiz,optimizations,49501,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,1,['optimiz'],['optimizations']
Performance," trees with and without compression for the following cases:; `vector<THit>`, `vector<THit*>`, `TClonesArray(`**`TObjHit`**`)`; not split `TClonesArray(`**`TObjHit`**`)` split. The next graphs show the two columns on the right which represent the split and; non-split **`TClonesArray`**, are significantly lower than the vectors. The most; significant difference is in reading a file without compression. The file size with compression, write times with and without compression; and the read times with and without compression all favor the; **`TClonesArray`**. ## Impact of Compression on I/O. This benchmark illustrates the pros and cons of the compression option.; We recommend using compression when the time spent in I/O is small; compared to the total processing time. In this case, if the I/O; operation is increased by a factor of 5 it is still a small percentage; of the total time and it may very well save a factor of 10 on disk; space. On the other hand if the time spend on I/O is large, compression; may slow down the program's performance. The standard test program; `$ROOTSYS/test/Event` was used in various configurations with 400; events. The data file contains a **`TTree`**. The program was invoked; with:. ``` {.cpp}; Event 400 comp split; ```. - comp = 0 means: no compression at all.; - comp = 1 means: compress everything if split = 0.; - comp = 1 means: compress only the tree branches with integers if; split = 1.; - comp = 2 means: compress everything if split=1.; - split = 0 : the full event is serialized into one single buffer.; - split = 1 : the event is split into branches. One branch for each; data member of the Event class. The list of tracks (a; **`TClonesArray`**) has the data members of the Track class also; split into individual buffers. These tests were run on Pentium III CPU with 650 MHz. +------------+--------+---------------+---------------+----------------+----------------+; | Event | File | Total Time to | Effective | Total Time to | Total Time to ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md:136342,perform,performance,136342,documentation/users-guide/Trees.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md,1,['perform'],['performance']
Performance," trivial copy and move constructors. Better diagnostics for loops that execute 0 times; Fixes a linking issue that prevented the checker from running on OS X v10.6 and earlier; Fixes for misc. crashes and false positives. checker-271; built: February 8, 2013; highlights:. Faster analysis for scan-build xcodebuild when using Xcode 4.6 and higher:; ; scan-build now uses Xcode's built-in interposition mechanism for the static analyzer to provide faster builds while doing static analysis (PCH files are now built).; This change also allows scan-build to have better support for iOS project analysis without having to specifying weird SDK settings to scan-build. Better diagnostics for implicitly-defined member functions in C++.; New warning for malloc/free checker when passing malloc'ed pointer with non-zero offset to free().; Fixes for misc. parser crashes.; Newer than the static analyzer version in Xcode 4.6. checker-270; built: January 4, 2013; highlights:. Major performance enhancements to speed up interprocedural analysis.; Misc. bug fixes. checker-269; built: September 25, 2012; highlights:. Significantly improves interprocedural analysis for Objective-C.; Numerous bug fixes and heuristics to reduce false positives reported; 			over checker-268. checker-268; built: September 11, 2012; highlights:. Adds initial interprocedural analysis support for C++ and Objective-C. This will greatly improve analysis coverage and find deeper bugs in Objective-C and C++ code.; Contains a static analyzer newer than Xcode 4.4. NOTE: this checker build includes a huge number of changes. It has the potential to find many more bugs, but may report new kinds of false positives. We'd like to know about; these, and any other problems you encounter. When you encounter an issue, please file a bug report.; checker-267; built: June 1, 2012; highlights:; Adds basic interprocedural analysis support for blocks.; checker-266; built: May 23, 2012; highlights:; Contains numerous stability fixes over che",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/release_notes.html:6295,perform,performance,6295,interpreter/llvm-project/clang/www/analyzer/release_notes.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/release_notes.html,2,['perform'],['performance']
Performance," two maps. Some map-like containers also support efficient; iteration through the keys in sorted order. Map-like containers are the most; expensive sort, only use them if you need one of these capabilities. * a :ref:`set-like <ds_set>` container if you need to put a bunch of stuff into; a container that automatically eliminates duplicates. Some set-like; containers support efficient iteration through the elements in sorted order.; Set-like containers are more expensive than sequential containers. * a :ref:`sequential <ds_sequential>` container provides the most efficient way; to add elements and keeps track of the order they are added to the collection.; They permit duplicates and support efficient iteration, but do not support; efficient look-up based on a key. * a :ref:`string <ds_string>` container is a specialized sequential container or; reference structure that is used for character or byte arrays. * a :ref:`bit <ds_bit>` container provides an efficient way to store and; perform set operations on sets of numeric id's, while automatically; eliminating duplicates. Bit containers require a maximum of 1 bit for each; identifier you want to store. Once the proper category of container is determined, you can fine tune the; memory use, constant factors, and cache behaviors of access by intelligently; picking a member of the category. Note that constant factors and cache behavior; can be a big deal. If you have a vector that usually only contains a few; elements (but could contain many), for example, it's much better to use; :ref:`SmallVector <dss_smallvector>` than :ref:`vector <dss_vector>`. Doing so; avoids (relatively) expensive malloc/free calls, which dwarf the cost of adding; the elements to the container. .. _ds_sequential:. Sequential Containers (std::vector, std::list, etc); ---------------------------------------------------. There are a variety of sequential containers available for you, based on your; needs. Pick the first in this section that will do what",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:56650,perform,perform,56650,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,1,['perform'],['perform']
Performance," two; pads on it. Both pads keep histograms updated and filled by three; different threads. With the `CalcPi` example, you should be able to see; two threads calculating Pi with the given number of intervals as; precision. ### TThread in More Details. Cling is not thread safe yet, and it will block the execution of the; threads until it has finished executing. #### Asynchronous Actions. Different threads can work simultaneously with the same object. Some; actions can be dangerous. For example, when two threads create a; histogram object, ROOT allocates memory and puts them to the same; collection. If it happens at the same time, the results are; undetermined. To avoid this problem, the user has to synchronize these; actions with:. ``` {.cpp}; TThread::Lock() // Locking the following part of code; ... // Create an object, etc...; TThread::UnLock() // Unlocking; ```. The code between `Lock()` and `UnLock()` will be performed; uninterrupted. No other threads can perform actions or access; objects/collections while it is being executed. The methods; `TThread::Lock() `and **`TThread::UnLock()`** internally use a global; `TMutex` instance for locking. The user may also define their own **`TMutex`** `MyMutex` instance and may; locally protect their asynchronous actions by calling `MyMutex.Lock()` and; `MyMutex.UnLock().`. #### Synchronous Actions: TCondition. To synchronize the actions of different threads you can use the; **`TCondition`** class, which provides a signaling mechanism. The; **`TCondition`** instance must be accessible by all threads that need to; use it, i.e. it should be a global object (or a member of the class; which owns the threaded methods, see below). To create a; **`TCondition`** object, a **`TMutex`** instance is required for the; Wait and `TimedWait` locking methods. One can pass the address of an; external mutex to the **`TCondition`** constructor:. ``` {.cpp}; TMutex MyMutex;; TCondition MyCondition(&MyMutex);; ```. If zero is passed, **`TConditi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Threads.md:7117,perform,perform,7117,documentation/users-guide/Threads.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Threads.md,1,['perform'],['perform']
Performance," two; values that will undergo unsigned addition. Semantics:; """""""""""""""""""". The maximum value this operation can clamp to is the largest unsigned value; representable by the bit width of the arguments. Because this is an unsigned; operation, the result will never saturate towards zero. Examples; """""""""""""""""". .. code-block:: llvm. %res = call i4 @llvm.uadd.sat.i4(i4 1, i4 2) ; %res = 3; %res = call i4 @llvm.uadd.sat.i4(i4 5, i4 6) ; %res = 11; %res = call i4 @llvm.uadd.sat.i4(i4 8, i4 8) ; %res = 15. '``llvm.ssub.sat.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax; """""""""""""". This is an overloaded intrinsic. You can use ``llvm.ssub.sat``; on any integer bit width or vectors of integers. ::. declare i16 @llvm.ssub.sat.i16(i16 %a, i16 %b); declare i32 @llvm.ssub.sat.i32(i32 %a, i32 %b); declare i64 @llvm.ssub.sat.i64(i64 %a, i64 %b); declare <4 x i32> @llvm.ssub.sat.v4i32(<4 x i32> %a, <4 x i32> %b). Overview; """""""""""""""""". The '``llvm.ssub.sat``' family of intrinsic functions perform signed; saturating subtraction on the 2 arguments. Arguments; """""""""""""""""""". The arguments (%a and %b) and the result may be of integer types of any bit; width, but they must have the same bit width. ``%a`` and ``%b`` are the two; values that will undergo signed subtraction. Semantics:; """""""""""""""""""". The maximum value this operation can clamp to is the largest signed value; representable by the bit width of the arguments. The minimum value is the; smallest signed value representable by this bit width. Examples; """""""""""""""""". .. code-block:: llvm. %res = call i4 @llvm.ssub.sat.i4(i4 2, i4 1) ; %res = 1; %res = call i4 @llvm.ssub.sat.i4(i4 2, i4 6) ; %res = -4; %res = call i4 @llvm.ssub.sat.i4(i4 -4, i4 5) ; %res = -8; %res = call i4 @llvm.ssub.sat.i4(i4 4, i4 -5) ; %res = 7. '``llvm.usub.sat.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax; """""""""""""". This is an overloaded intrinsic. You can use ``llvm.usub.sat``; on any integer bit width or vectors of integers. ::. declare i16 @llvm.usub.s",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:613925,perform,perform,613925,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['perform']
Performance," type value that represents the overlay bit size value BS. The; second must be an integral type value that represents the overlay bit offset; value BO. The third must be a location description that represents the; overlay location description OL. The fourth must be a location description; that represents the base location description BL. The DWARF expression is ill-formed if BS or BO are negative values. *rbss(L)* is the minimum remaining bit storage size of L which is defined as; follows. LS is the location storage and LO is the location bit offset; specified by a single location description SL of L. The remaining bit; storage size RBSS of SL is the bit size of LS minus LO. *rbss(L)* is the; minimum RBSS of each single location description SL of L. The DWARF expression is ill-formed if *rbss(BL)* is less than BO plus BS. If BS is 0, then the operation pushes BL. If BO is 0 and BS equals *rbss(BL)*, then the operation pushes OL. Otherwise, the operation is equivalent to performing the following steps to; push a composite location description. *The composite location description is conceptually the base location; description BL with the overlay location description OL positioned as an; overlay starting at the overlay offset BO and covering overlay bit size BS.*. 1. If BO is not 0 then push BL followed by performing the ``DW_OP_bit_piece; BO, 0`` operation.; 2. Push OL followed by performing the ``DW_OP_bit_piece BS, 0`` operation.; 3. If *rbss(BL)* is greater than BO plus BS, push BL followed by performing; the ``DW_OP_bit_piece (rbss(BL) - BO - BS), (BO + BS)`` operation.; 4. Perform the ``DW_OP_LLVM_piece_end`` operation. .. _amdgpu-dwarf-location-list-expressions:. A.2.5.5 DWARF Location List Expressions; +++++++++++++++++++++++++++++++++++++++. .. note::. This section replaces DWARF Version 5 section 2.6.2. *To meet the needs of recent computer architectures and optimization techniques,; debugging information must be able to describe the location of an object who",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:141639,perform,performing,141639,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,1,['perform'],['performing']
Performance," type. The function will be placed such that the; beginning of the prefix data is aligned. This means that if the size; of the prefix data is not a multiple of the alignment size, the; function's entrypoint will not be aligned. If alignment of the; function's entrypoint is desired, padding must be added to the prefix; data. A function may have prefix data but no body. This has similar semantics; to the ``available_externally`` linkage in that the data may be used by the; optimizers but will not be emitted in the object file. .. _prologuedata:. Prologue Data; -------------. The ``prologue`` attribute allows arbitrary code (encoded as bytes) to; be inserted prior to the function body. This can be used for enabling; function hot-patching and instrumentation. To maintain the semantics of ordinary function calls, the prologue data must; have a particular format. Specifically, it must begin with a sequence of; bytes which decode to a sequence of machine instructions, valid for the; module's target, which transfer control to the point immediately succeeding; the prologue data, without performing any other visible action. This allows; the inliner and other passes to reason about the semantics of the function; definition without needing to reason about the prologue data. Obviously this; makes the format of the prologue data highly target dependent. A trivial example of valid prologue data for the x86 architecture is ``i8 144``,; which encodes the ``nop`` instruction:. .. code-block:: text. define void @f() prologue i8 144 { ... }. Generally prologue data can be formed by encoding a relative branch instruction; which skips the metadata, as in this example of valid prologue data for the; x86_64 architecture, where the first two bytes encode ``jmp .+10``:. .. code-block:: text. %0 = type <{ i8, i8, ptr }>. define void @f() prologue %0 <{ i8 235, i8 8, ptr @md}> { ... }. A function may have prologue data but no body. This has similar semantics; to the ``available_externally`` li",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:74499,perform,performing,74499,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['performing']
Performance," undefined behavior (e.g.; reading a variable before it is defined). In particular, check to see if the; program is clean under various `sanitizers; <https://github.com/google/sanitizers>`_ (e.g. ``clang; -fsanitize=undefined,address``) and `valgrind <http://valgrind.org/>`_. Many; ""LLVM bugs"" that we have chased down ended up being bugs in the program being; compiled, not LLVM. Once you determine that the program itself is not buggy, you should choose; which code generator you wish to compile the program with (e.g. LLC or the JIT); and optionally a series of LLVM passes to run. For example:. .. code-block:: bash. bugpoint -run-llc [... optzn passes ...] file-to-test.bc --args -- [program arguments]. bugpoint will try to narrow down your list of passes to the one pass that; causes an error, and simplify the bitcode file as much as it can to assist; you. It will print a message letting you know how to reproduce the; resulting error. The :doc:`OptBisect <OptBisect>` page shows an alternative method for finding; incorrect optimization passes. Incorrect code generation; =========================. Similarly to debugging incorrect compilation by mis-behaving passes, you; can debug incorrect code generation by either LLC or the JIT, using; ``bugpoint``. The process ``bugpoint`` follows in this case is to try to; narrow the code down to a function that is miscompiled by one or the other; method, but since for correctness, the entire program must be run,; ``bugpoint`` will compile the code it deems to not be affected with the C; Backend, and then link in the shared object it generates. To debug the JIT:. .. code-block:: bash. bugpoint -run-jit -output=[correct output file] [bitcode file] \; --tool-args -- [arguments to pass to lli] \; --args -- [program arguments]. Similarly, to debug the LLC, one would run:. .. code-block:: bash. bugpoint -run-llc -output=[correct output file] [bitcode file] \; --tool-args -- [arguments to pass to llc] \; --args -- [program arguments]. **Sp",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToSubmitABug.rst:9214,optimiz,optimization,9214,interpreter/llvm-project/llvm/docs/HowToSubmitABug.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToSubmitABug.rst,1,['optimiz'],['optimization']
Performance," underlying pipelines. The algorithm prioritizes older instructions over younger; instructions. Write-Back and Retire Stage; """"""""""""""""""""""""""""""""""""""""""""""""""""""; Issued instructions are moved from the ReadySet to the IssuedSet. There,; instructions wait until they reach the write-back stage. At that point, they; get removed from the queue and the retire control unit is notified. When instructions are executed, the retire control unit flags the instruction as; ""ready to retire."". Instructions are retired in program order. The register file is notified of the; retirement so that it can free the physical registers that were allocated for; the instruction during the register renaming stage. Load/Store Unit and Memory Consistency Model; """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; To simulate an out-of-order execution of memory operations, :program:`llvm-mca`; utilizes a simulated load/store unit (LSUnit) to simulate the speculative; execution of loads and stores. Each load (or store) consumes an entry in the load (or store) queue. Users can; specify flags ``-lqueue`` and ``-squeue`` to limit the number of entries in the; load and store queues respectively. The queues are unbounded by default. The LSUnit implements a relaxed consistency model for memory loads and stores.; The rules are:. 1. A younger load is allowed to pass an older load only if there are no; intervening stores or barriers between the two loads.; 2. A younger load is allowed to pass an older store provided that the load does; not alias with the store.; 3. A younger store is not allowed to pass an older store.; 4. A younger store is not allowed to pass an older load. By default, the LSUnit optimistically assumes that loads do not alias; (`-noalias=true`) store operations. Under this assumption, younger loads are; always allowed to pass older stores. Essentially, the LSUnit does not attempt; to run any alias analysis to predict when loads and stores do not alias with; each other. Note that, in the case of write-co",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:39469,load,load,39469,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,3,"['load', 'queue']","['load', 'queue']"
Performance," use of the target hook does not cause any test failures in common; architectures. If the compiler for a target architecture did want some; form of conversion, including a larger result type, it could always; explicitly use the ``DW_OP_convert`` operation. If T is a larger type than the register size, then the default GDB; register hook reads bytes from the next register (or reads out of bounds; for the last register!). Removing use of the target hook does not cause; any test failures in common architectures (except an illegal hand written; assembly test). If a target architecture requires this behavior, these; extensions allow a composite location description to be used to combine; multiple registers. 2. ``DW_OP_deref``. S is the bit size of the generic type divided by 8 (the byte size) and; rounded up to a whole number. DR is the offset of a hypothetical debug; information entry D in the current compilation unit for a base type of the; generic type. The operation is equivalent to performing ``DW_OP_deref_type S, DR``. 3. ``DW_OP_deref_size``. ``DW_OP_deref_size`` has a single 1-byte unsigned integral constant that; represents a byte result size S. TS is the smaller of the generic type bit size and S scaled by 8 (the byte; size). If TS is smaller than the generic type bit size then T is an unsigned; integral type of bit size TS, otherwise T is the generic type. DR is the; offset of a hypothetical debug information entry D in the current; compilation unit for a base type T. .. note::. Truncating the value when S is larger than the generic type matches what; GDB does. This allows the generic type size to not be an integral byte; size. It does allow S to be arbitrarily large. Should S be restricted to; the size of the generic type rounded up to a multiple of 8?. The operation is equivalent to performing ``DW_OP_deref_type S, DR``, except; if T is not the generic type, the value V pushed is zero-extended to the; generic type bit size and its type changed to the generic",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:88952,perform,performing,88952,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,1,['perform'],['performing']
Performance," use the command line option `-cachesize SIZE`. `SIZE` shouyld be given in number bytes and can be expressed in 'human readable form' (number followed by size unit like MB, MiB, GB or GiB, etc. or SIZE can be set zero to disable the cache. ### Other Changes. * Update `TChain::LoadTree` so that the user call back routine is actually called for each input file even those containing `TTree` objects with no entries.; * Repair setting the branch address of a leaflist style branch taking directly the address of the struct. (Note that leaflist is nonetheless still deprecated and declaring the struct to the interpreter and passing the object directly to create the branch is much better).; * Provide an implicitly parallel implementation of `TTree::GetEntry`. The approach is based on creating a task per top-level branch in order to do the reading, unzipping and deserialisation in parallel. In addition, a getter and a setter methods are provided to check the status and enable/disable implicit multi-threading for that tree (see Parallelisation section for more information about implicit multi-threading).; * Properly support `std::cin` (and other stream that can not be rewound) in `TTree::ReadStream`. This fixes [ROOT-7588].; * Prevent `TTreeCloner::CopyStreamerInfos()` from causing an autoparse on an abstract base class. ## Histogram Libraries. * TH2Poly has a functional Merge method.; * Implemented the `TGraphAsymmErrors` constructor directly from an ASCII file. ## Math Libraries. * New template class `TRandomGen<Engine>` which derives from `TRandom` and integrate new random generator engines as TRandom classes.; * New TRandom specific types have been defined for these following generators:; * `TRandomMixMax` - recommended MIXMAX generator with N=240; * `TRandomMixMax17` - MIXMAX generator with smaller state (N=17) and faster seeding time; * `TRandomMixMax256` - old version of MIXMAX generator (N=256); * `TRandomMT64` - 64 bit Mersenenne Twister generator from the standard libr",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:11006,multi-thread,multi-threading,11006,README/ReleaseNotes/v608/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md,2,['multi-thread'],['multi-threading']
Performance," used in randomised (and bagged) trees. NNodesMax No 0 − deprecated: Use MaxDepth instead to limit the tree size. Configuration options for MVA method :. Configuration options reference for MVA method: Boost. Option Array Default value Predefined values Description. V No False − Verbose output (short form of VerbosityLevel below - overrides the latter one). VerbosityLevel No Default Default, Debug, Verbose, Info, Warning, Error, Fatal Verbosity level. VarTransform No None − List of variable transformations performed before training, e.g., D_Background,P_Signal,G,N_AllClasses for: Decorrelation, PCA-transformation, Gaussianisation, Normalisation, each for the given class of events ('AllClasses' denotes all events of all classes, if no class indication is given, 'All' is assumed). H No False − Print method-specific help message. CreateMVAPdfs No False − Create PDFs for classifier outputs (signal and background). IgnoreNegWeightsInTraining No False − Events with negative weights are ignored in the training (but are included for testing and performance evaluation). Boost_Num No 100 − Number of times the classifier is boosted. Boost_MonitorMethod No True − Write monitoring histograms for each boosted classifier. Boost_DetailedMonitoring No False − Produce histograms for detailed boost-wise monitoring. Boost_Type No AdaBoost AdaBoost, Bagging, HighEdgeGauss, HighEdgeCoPara Boosting type for the classifiers. Boost_BaggedSampleFraction No 0.6 − Relative size of bagged event sample to original size of the data sample (used whenever bagging is used). Boost_MethodWeightType No ByError ByError, Average, ByROC, ByOverlap, LastMethod How to set the final weight of the boosted classifiers. Boost_RecalculateMVACut No True − Recalculate the classifier MVA Signallike cut at every boost iteration. Boost_AdaBoostBeta No 1 − The ADA boost parameter that sets the effect of every boost step on the events' weights. Boost_Transform No step step, linear, log, gauss Type of transform applied ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/tmva/UsersGuide/optionRef.html:16535,perform,performance,16535,documentation/tmva/UsersGuide/optionRef.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/tmva/UsersGuide/optionRef.html,2,['perform'],['performance']
Performance," user must only provide; an implementation of the FCNBase class to M and parameters and; uncertainties in form of std::vector containers. ### Memory allocation and thread safety ###. Differently to the version of M , the version has its own memory manager; (StackAllocator. The user can select between the standard dynamic memory; allocation and deallocation (default) and performance-optimized; stack–like allocation (optional). However, the library is not thread; save using stack–allocation. ### M parameters ###. Differently to the version of M there is no limit on the number of; parameters, variable or non-variable. Memory allocation is done; dynamically according to the actual needs and ""on demand"". There is no; protection against an upper limit on the number of parameters, however; the ""technological"" limitations of M can be seen around a maximum of 15; free parameters at a time. ## Interference with other packages ##. The new M has been designed to interfere as little as possible with; other programs or packages which may be loaded at the same time. M is; thread safe by default. Optionally the user can select a different way; of dynamically allocating memory in the class StackAllacator for M , in; which case (and after an entire recompilation of the whole library) the; thread safety is lost. ## Floating-point precision ##. [install:epsmac]. M is entirely based on double precision. The actual floating point; precision of double precision (32–bit or 64–bit) is platform dependent; and can even vary on the same platform, depending on whether a floating; point number is read from memory a CPU register. The argument of the user's implementation of FCNBase::operator() is; therefore a std:vector$<$double$>$. M expects that the calculations; inside $\mbox{FCN}$ will be performed approximately to the same; accuracy. The accuracy M expects is called *machine precision*; (MnMachinePrecision, see [api:epsmac]) and can be printed on demand; using std::cout. If the user fools M ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/minuit2/Minuit2.md:26175,load,loaded,26175,documentation/minuit2/Minuit2.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/minuit2/Minuit2.md,1,['load'],['loaded']
Performance," user sets this variable and the; directory contains executables with the expected names, no separate; native versions of those executables will be built. **LLVM_NO_INSTALL_NAME_DIR_FOR_BUILD_TREE**:BOOL; Defaults to ``OFF``. If set to ``ON``, CMake's default logic for library IDs; on Darwin in the build tree will be used. Otherwise the install-time library; IDs will be used in the build tree as well. Mainly useful when other CMake; library ID control variables (e.g., ``CMAKE_INSTALL_NAME_DIR``) are being; set to non-standard values. **LLVM_OPTIMIZED_TABLEGEN**:BOOL; If enabled and building a debug or asserts build the CMake build system will; generate a Release build tree to build a fully optimized tablegen for use; during the build. Enabling this option can significantly speed up build times; especially when building LLVM in Debug configurations. **LLVM_PARALLEL_COMPILE_JOBS**:STRING; Define the maximum number of concurrent compilation jobs. **LLVM_PARALLEL_LINK_JOBS**:STRING; Define the maximum number of concurrent link jobs. **LLVM_RAM_PER_COMPILE_JOB**:STRING; Calculates the amount of Ninja compile jobs according to available resources.; Value has to be in MB, overwrites LLVM_PARALLEL_COMPILE_JOBS. Compile jobs ; will be between one and amount of logical cores. **LLVM_RAM_PER_LINK_JOB**:STRING; Calculates the amount of Ninja link jobs according to available resources.; Value has to be in MB, overwrites LLVM_PARALLEL_LINK_JOBS. Link jobs will ; be between one and amount of logical cores. Link jobs will not run ; exclusively therefore you should add an offset of one or two compile jobs ; to be sure its not terminated in your memory restricted environment. On ELF; platforms also consider ``LLVM_USE_SPLIT_DWARF`` in Debug build. **LLVM_PROFDATA_FILE**:PATH; Path to a profdata file to pass into clang's -fprofile-instr-use flag. This; can only be specified if you're building with clang. **LLVM_REVERSE_ITERATION**:BOOL; If enabled, all supported unordered llvm containe",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:32557,concurren,concurrent,32557,interpreter/llvm-project/llvm/docs/CMake.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst,1,['concurren'],['concurrent']
Performance," uses ROOT's task arena to compress and decompress pages.; That requires writes to be buffered and reads uses the cluster pool resp.; The RNTuple data source for RDataFrame lets RDataFrame full control of the thread pool.; That means that RDataFrame uses a separate data source for every thread, each of the data sources runs in sequential mode. ### Concurrent Readers; Multiple readers can read the same RNTuple concurrently as long as access to every individual reader is sequential. ### Parallel REntry Preparation; Multiple `REntry` object can be concurrently prepared by multiple threads.; I.e., construction and binding of the objects can happen in parallel.; The actual reading and writing of entries (`RNTupleReader::LoadEntry()`, `RNTupleWriter::Fill()`) needs to be protected by a mutex.; This is considered ""mild scalability parallelization"" in RNTuple. ### RNTupleParallelWriter; The parallel writer offers the most scalable parallel writing interface.; Multiple _fill contexts_ can concurrently serialize and compress data.; Every fill context prepares a set of entire clusters in the final on-disk layout.; When a fill context flushes data,; a brief serialization point handles the RNTuple meta-data updates and the reservation of disk space to write into. Low precision float types; --------------------------; RNTuple supports encoding floating point types with a lower precision when writing them to disk. This encoding is specified by the; user per field and it is independent on the in-memory type used for that field (meaning both a `RField<double>` or `RField<float>` can; be mapped to e.g. a low-precision 16 bit float). RNTuple supports the following encodings (all mutually exclusive):. - **Real16**/**SplitReal16**: IEEE-754 half precision float. Set by calling `RField::SetHalfPrecision()`;; - **Real32Trunc**: floating point with less than 32 bits of precision (truncated mantissa).; Set by calling `RField::SetTruncated(n)`, with $10 <= n <= 31$ equal to the total number ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md:25551,concurren,concurrently,25551,tree/ntuple/v7/doc/Architecture.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md,1,['concurren'],['concurrently']
Performance," using a PHI node:. .. code-block:: llvm. @G = weak global i32 0 ; type of @G is i32*; @H = weak global i32 0 ; type of @H is i32*. define i32 @test(i1 %Condition) {; entry:; %X = alloca i32 ; type of %X is i32*.; br i1 %Condition, label %cond_true, label %cond_false. cond_true:; %X.0 = load i32, i32* @G; store i32 %X.0, i32* %X ; Update X; br label %cond_next. cond_false:; %X.1 = load i32, i32* @H; store i32 %X.1, i32* %X ; Update X; br label %cond_next. cond_next:; %X.2 = load i32, i32* %X ; Read X; ret i32 %X.2; }. With this, we have discovered a way to handle arbitrary mutable; variables without the need to create Phi nodes at all:. #. Each mutable variable becomes a stack allocation.; #. Each read of the variable becomes a load from the stack.; #. Each update of the variable becomes a store to the stack.; #. Taking the address of a variable just uses the stack address; directly. While this solution has solved our immediate problem, it introduced; another one: we have now apparently introduced a lot of stack traffic; for very simple and common operations, a major performance problem.; Fortunately for us, the LLVM optimizer has a highly-tuned optimization; pass named ""mem2reg"" that handles this case, promoting allocas like this; into SSA registers, inserting Phi nodes as appropriate. If you run this; example through the pass, for example, you'll get:. .. code-block:: bash. $ llvm-as < example.ll | opt -passes=mem2reg | llvm-dis; @G = weak global i32 0; @H = weak global i32 0. define i32 @test(i1 %Condition) {; entry:; br i1 %Condition, label %cond_true, label %cond_false. cond_true:; %X.0 = load i32, i32* @G; br label %cond_next. cond_false:; %X.1 = load i32, i32* @H; br label %cond_next. cond_next:; %X.01 = phi i32 [ %X.1, %cond_false ], [ %X.0, %cond_true ]; ret i32 %X.01; }. The mem2reg pass implements the standard ""iterated dominance frontier""; algorithm for constructing SSA form and has a number of optimizations; that speed up (very common) degenerate cases.",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl07.rst:6639,perform,performance,6639,interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl07.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl07.rst,1,['perform'],['performance']
Performance," using a retpoline, these edges will need independent protection from; variant #1 style attacks. The analogous approach to that used for conditional; control flow should work:; ```; uintptr_t all_ones_mask = std::numerical_limits<uintptr_t>::max();; uintptr_t all_zeros_mask = 0;; void leak(int data);; void example(int* pointer1, int* pointer2) {; uintptr_t predicate_state = all_ones_mask;; switch (condition) {; case 0:; // Assuming ?: is implemented using branchless logic...; predicate_state = (condition != 0) ? all_zeros_mask : predicate_state;; // ... lots of code ...; //; // Harden the pointer so it can't be loaded; pointer1 &= predicate_state;; leak(*pointer1);; break;. case 1:; predicate_state = (condition != 1) ? all_zeros_mask : predicate_state;; // ... more code ...; //; // Alternative: Harden the loaded value; int value2 = *pointer2 & predicate_state;; leak(value2);; break;. // ...; }; }; ```. The core idea remains the same: validate the control flow using data-flow and; use that validation to check that loads cannot leak information along; misspeculated paths. Typically this involves passing the desired target of such; control flow across the edge and checking that it is correct afterwards. Note; that while it is tempting to think that this mitigates variant #2 attacks, it; does not. Those attacks go to arbitrary gadgets that don't include the checks. ### Variant #1.1 and #1.2 attacks: ""Bounds Check Bypass Store"". Beyond the core variant #1 attack, there are techniques to extend this attack.; The primary technique is known as ""Bounds Check Bypass Store"" and is discussed; in this research paper: https://people.csail.mit.edu/vlk/spectre11.pdf. We will analyze these two variants independently. First, variant #1.1 works by; speculatively storing over the return address after a bounds check bypass. This; speculative store then ends up being used by the CPU during speculative; execution of the return, potentially directing speculative execution to; arbitrary gadg",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:10591,load,loads,10591,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,1,['load'],['loads']
Performance," usually autodetected, but it can be; configured manually to explicitly control the generation of those targets. **LLVM_ENABLE_LIBCXX**:BOOL; If the host compiler and linker supports the stdlib flag, -stdlib=libc++ is; passed to invocations of both so that the project is built using libc++; instead of stdlibc++. Defaults to OFF. **LLVM_ENABLE_LLVM_LIBC**: BOOL; If the LLVM libc overlay is installed in a location where the host linker; can access it, all built executables will be linked against the LLVM libc; overlay before linking against the system libc. Defaults to OFF. **LLVM_ENABLE_LIBPFM**:BOOL; Enable building with libpfm to support hardware counter measurements in LLVM; tools.; Defaults to ON. **LLVM_ENABLE_LLD**:BOOL; This option is equivalent to `-DLLVM_USE_LINKER=lld`, except during a 2-stage; build where a dependency is added from the first stage to the second ensuring; that lld is built before stage2 begins. **LLVM_ENABLE_LTO**:STRING; Add ``-flto`` or ``-flto=`` flags to the compile and link command; lines, enabling link-time optimization. Possible values are ``Off``,; ``On``, ``Thin`` and ``Full``. Defaults to OFF. **LLVM_ENABLE_MODULES**:BOOL; Compile with `Clang Header Modules; <https://clang.llvm.org/docs/Modules.html>`_. **LLVM_ENABLE_PEDANTIC**:BOOL; Enable pedantic mode. This disables compiler-specific extensions, if; possible. Defaults to ON. **LLVM_ENABLE_PIC**:BOOL; Add the ``-fPIC`` flag to the compiler command-line, if the compiler supports; this flag. Some systems, like Windows, do not need this flag. Defaults to ON. **LLVM_ENABLE_PROJECTS**:STRING; Semicolon-separated list of projects to build, or *all* for building all; (clang, lldb, lld, polly, etc) projects. This flag assumes that projects; are checked out side-by-side and not nested, i.e. clang needs to be in; parallel of llvm instead of nested in `llvm/tools`. This feature allows; to have one build for only LLVM and another for clang+llvm using the same; source checkout.; The full list",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:23434,optimiz,optimization,23434,interpreter/llvm-project/llvm/docs/CMake.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst,1,['optimiz'],['optimization']
Performance," value.; #. If it can prove that callees do not access their caller stack frame, they; are marked as eligible for tail call elimination (by the code generator). Utility Passes; ==============. This section describes the LLVM Utility Passes. ``deadarghaX0r``: Dead Argument Hacking (BUGPOINT USE ONLY; DO NOT USE); -----------------------------------------------------------------------. Same as dead argument elimination, but deletes arguments to functions which are; external. This is only for use by :doc:`bugpoint <Bugpoint>`. ``extract-blocks``: Extract Basic Blocks From Module (for bugpoint use); -----------------------------------------------------------------------. This pass is used by bugpoint to extract all blocks from the module into their; own functions. ``instnamer``: Assign names to anonymous instructions; -----------------------------------------------------. This is a little utility pass that gives instructions names, this is mostly; useful when diffing the effect of an optimization because deleting an unnamed; instruction can change all other instruction numbering, making the diff very; noisy. .. _passes-verify:. ``verify``: Module Verifier; ---------------------------. Verifies an LLVM IR code. This is useful to run after an optimization which is; undergoing testing. Note that llvm-as verifies its input before emitting; bitcode, and also that malformed bitcode is likely to make LLVM crash. All; language front-ends are therefore encouraged to verify their output before; performing optimizing transformations. #. Both of a binary operator's parameters are of the same type.; #. Verify that the indices of mem access instructions match other operands.; #. Verify that arithmetic and other things are only performed on first-class; types. Verify that shifts and logicals only happen on integrals f.e.; #. All of the constants in a switch statement are of the correct type.; #. The code is in valid SSA form.; #. It is illegal to put a label into any other type (like a",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Passes.rst:40763,optimiz,optimization,40763,interpreter/llvm-project/llvm/docs/Passes.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Passes.rst,1,['optimiz'],['optimization']
Performance," values.; It is possible to print the list of default control parameters using the `ROOT::Math::IntegratorMultiDimOptions::Print` function.; Example:; ```{.cpp}; ROOT::Math::IntegratorMultiDimOptions opt;; opt.Print();; Integrator Type : ADAPTIVE; Absolute tolerance : 1e-09; Relative tolerance : 1e-09; Workspace size : 100000; (max) function calls : 100000; ```; Depending on the algorithm, some of the control parameters might have no effect. #### `ROOT::Math::AdaptiveIntegratorMultiDim`. This class implements an adaptive quadrature integration method for multi dimensional functions. It is described in this paper; *Genz, A.A. Malik, An adaptive algorithm for numerical integration over an N-dimensional rectangular region, J. Comput. Appl. Math. 6 (1980) 295-302*.; It is part of the *MathCore* library.; The user can control the relative and absolute tolerance and the maximum allowed number of function evaluation. #### `ROOT::Math::GSLMCIntegrator`. It is a class for performing numerical integration of a multidimensional function. It uses the numerical integration algorithms of GSL, which reimplements the algorithms used; in the QUADPACK, a numerical integration package written in Fortran. Plain MC, MISER and VEGAS integration algorithms are supported for integration over finite (hypercubic) ranges.; For a detail description of the GSL methods visit the GSL users guide.; Specific configuration options (documented in the GSL user guide) for the `ROOT::Math::GSLMCIntegration` can be set directly in the class, or when using it via the `ROOT::Math::IntegratorMultiDim`; interface, can be defined using the `ROOT::Math::IntegratorMultiDimOptions`. ## Function Derivation. There are in ROOT only two classes to perform numerical derivation. One of them is in the MathCore library while the other is in the MathMore wrapping an integration function from the GSL library.; * RichardsonDerivator: Implements the Richardson method for numerical integration. It can calculate up to the thir",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/MathLibraries.md:61668,perform,performing,61668,documentation/users-guide/MathLibraries.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/MathLibraries.md,1,['perform'],['performing']
Performance," var); -fprofile-instr-generate=<file_name_pattern>; Generate instrumented code to collect execution counts into the file whose name pattern is specified as the argument; (overridden by LLVM_PROFILE_FILE env var); -fprofile-instr-generate; Generate instrumented code to collect execution counts into default.profraw file; (overridden by '=' form of option or LLVM_PROFILE_FILE env var); -fprofile-instr-use=<value>; Use instrumentation data for coverage testing or profile-guided optimization; -fprofile-use=<value>; Use instrumentation data for profile-guided optimization; -fprofile-remapping-file=<file>; Use the remappings described in <file> to match the profile data against names in the program; -fprofile-list=<file>; Filename defining the list of functions/files to instrument; -fsanitize-address-field-padding=<value>; Level of field padding for AddressSanitizer; -fsanitize-address-globals-dead-stripping; Enable linker dead stripping of globals in AddressSanitizer; -fsanitize-address-poison-custom-array-cookie; Enable poisoning array cookies when using custom operator new[] in AddressSanitizer; -fsanitize-address-use-after-return=<mode>; Select the mode of detecting stack use-after-return in AddressSanitizer: never | runtime (default) | always; -fsanitize-address-use-after-scope; Enable use-after-scope detection in AddressSanitizer; -fsanitize-address-use-odr-indicator; Enable ODR indicator globals to avoid false ODR violation reports in partially sanitized programs at the cost of an increase in binary size; -fsanitize-ignorelist=<value>; Path to ignorelist file for sanitizers; -fsanitize-cfi-cross-dso; Enable control flow integrity (CFI) checks for cross-DSO calls.; -fsanitize-cfi-icall-generalize-pointers; Generalize pointers in CFI indirect call type signature checks; -fsanitize-coverage=<value>; Specify the type of coverage instrumentation for Sanitizers; -fsanitize-hwaddress-abi=<value>; Select the HWAddressSanitizer ABI to target (interceptor or platform, defaul",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:182583,optimiz,optimization,182583,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,2,['optimiz'],['optimization']
Performance," variable; definitions:; - CMAKE_C_COMPILER=clang; - CMAKE_CXX_COMPILER=clang++; - LLVM_USE_SANITIZE_COVERAGE=YES; - LLVM_USE_SANITIZER=Address; - CLANG_ENABLE_PROTO_FUZZER=ON. Then build the clang-proto-fuzzer and clang-proto-to-cxx targets. Optionally,; you may also build clang-fuzzer with this setup. Example:; cd $LLVM_SOURCE_DIR; mkdir build && cd build; cmake .. -GNinja -DCMAKE_C_COMPILER=clang -DCMAKE_CXX_COMPILER=clang++ \; -DLLVM_USE_SANITIZE_COVERAGE=YES -DLLVM_USE_SANITIZER=Address \; -DCLANG_ENABLE_PROTO_FUZZER=ON; ninja clang-proto-fuzzer clang-proto-to-cxx. This directory also contains a Dockerfile which sets up all required; dependencies and builds the fuzzers. ============================; Running clang-proto-fuzzer; ============================; bin/clang-proto-fuzzer CORPUS_DIR. Arguments can be specified after -ignore_remaining_args=1 to modify the compiler; invocation. For example, the following command line will fuzz LLVM with a; custom optimization level and target triple:; bin/clang-proto-fuzzer CORPUS_DIR -ignore_remaining_args=1 -O3 -triple \; arm64apple-ios9. To translate a clang-proto-fuzzer corpus output to C++:; bin/clang-proto-to-cxx CORPUS_OUTPUT_FILE. ===================; llvm-proto-fuzzer; ===================; Like, clang-proto-fuzzer, llvm-proto-fuzzer is also a protobuf-mutator based; fuzzer. It receives as input a cxx_loop_proto which it then converts into a; string of valid LLVM IR: a function with either a single loop or two nested; loops. It then creates a new string of IR by running optimization passes over; the original IR. Currently, it only runs a loop-vectorize pass but more passes; can easily be added to the fuzzer. Once there are two versions of the input; function (optimized and not), llvm-proto-fuzzer uses LLVM's JIT Engine to; compile both functions. Lastly, it runs both functions on a suite of inputs and; checks that both functions behave the same on all inputs. In this way,; llvm-proto-fuzzer can find not only compil",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/tools/clang-fuzzer/README.txt:3866,optimiz,optimization,3866,interpreter/llvm-project/clang/tools/clang-fuzzer/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/tools/clang-fuzzer/README.txt,1,['optimiz'],['optimization']
Performance," variant contains undefined; behavior and will probably crash:. .. code-block:: c++. void foo(const Twine &T);; ...; StringRef X = ...; unsigned i = ...; const Twine &Tmp = X + ""."" + Twine(i);; foo(Tmp);. ... because the temporaries are destroyed before the call. That said, Twine's; are much more efficient than intermediate std::string temporaries, and they work; really well with StringRef. Just be aware of their limitations. .. _dss_smallstring:. llvm/ADT/SmallString.h; ^^^^^^^^^^^^^^^^^^^^^^. SmallString is a subclass of :ref:`SmallVector <dss_smallvector>` that adds some; convenience APIs like += that takes StringRef's. SmallString avoids allocating; memory in the case when the preallocated space is enough to hold its data, and; it calls back to general heap allocation when required. Since it owns its data,; it is very safe to use and supports full mutation of the string. Like SmallVector's, the big downside to SmallString is their sizeof. While they; are optimized for small strings, they themselves are not particularly small.; This means that they work great for temporary scratch buffers on the stack, but; should not generally be put into the heap: it is very rare to see a SmallString; as the member of a frequently-allocated heap data structure or returned; by-value. .. _dss_stdstring:. std::string; ^^^^^^^^^^^. The standard C++ std::string class is a very general class that (like; SmallString) owns its underlying data. sizeof(std::string) is very reasonable; so it can be embedded into heap data structures and returned by-value. On the; other hand, std::string is highly inefficient for inline editing (e.g.; concatenating a bunch of stuff together) and because it is provided by the; standard library, its performance characteristics depend a lot of the host; standard library (e.g. libc++ and MSVC provide a highly optimized string class,; GCC contains a really slow implementation). The major disadvantage of std::string is that almost every operation that makes; them",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:75505,optimiz,optimized,75505,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,1,['optimiz'],['optimized']
Performance," vector C from the input vectors A and B. To make this; easier, we also assume that only a single CTA (thread block) will be launched,; and that it will be one dimensional. The Kernel; ----------. .. code-block:: llvm. target datalayout = ""e-p:64:64:64-i1:8:8-i8:8:8-i16:16:16-i32:32:32-i64:64:64-f32:32:32-f64:64:64-v16:16:16-v32:32:32-v64:64:64-v128:128:128-n16:32:64""; target triple = ""nvptx64-nvidia-cuda"". ; Intrinsic to read X component of thread ID; declare i32 @llvm.nvvm.read.ptx.sreg.tid.x() readnone nounwind. define void @kernel(float addrspace(1)* %A,; float addrspace(1)* %B,; float addrspace(1)* %C) {; entry:; ; What is my ID?; %id = tail call i32 @llvm.nvvm.read.ptx.sreg.tid.x() readnone nounwind. ; Compute pointers into A, B, and C; %ptrA = getelementptr float, float addrspace(1)* %A, i32 %id; %ptrB = getelementptr float, float addrspace(1)* %B, i32 %id; %ptrC = getelementptr float, float addrspace(1)* %C, i32 %id. ; Read A, B; %valA = load float, float addrspace(1)* %ptrA, align 4; %valB = load float, float addrspace(1)* %ptrB, align 4. ; Compute C = A + B; %valC = fadd float %valA, %valB. ; Store back to C; store float %valC, float addrspace(1)* %ptrC, align 4. ret void; }. !nvvm.annotations = !{!0}; !0 = !{void (float addrspace(1)*,; float addrspace(1)*,; float addrspace(1)*)* @kernel, !""kernel"", i32 1}. We can use the LLVM ``llc`` tool to directly run the NVPTX code generator:. .. code-block:: text. # llc -mcpu=sm_20 kernel.ll -o kernel.ptx. .. note::. If you want to generate 32-bit code, change ``p:64:64:64`` to ``p:32:32:32``; in the module data layout string and use ``nvptx-nvidia-cuda`` as the; target triple. The output we get from ``llc`` (as of LLVM 3.4):. .. code-block:: text. //; // Generated by LLVM NVPTX Back-End; //. .version 3.1; .target sm_20; .address_size 64. // .globl kernel; // @kernel; .visible .entry kernel(; .param .u64 kernel_param_0,; .param .u64 kernel_param_1,; .param .u64 kernel_param_2; ); {; .reg .f32 %f<4>;; .reg .s32 %r<2>;;",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/NVPTXUsage.rst:13626,load,load,13626,interpreter/llvm-project/llvm/docs/NVPTXUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/NVPTXUsage.rst,2,['load'],['load']
Performance," vectorization passes; /Qvec Enable the loop vectorization passes; /showFilenames- Don't print the name of each compiled file (default); /showFilenames Print the name of each compiled file; /showIncludes Print info about included files to stderr; /source-charset:<value> Source encoding, supports only UTF-8; /std:<value> Language standard to compile for; /TC Treat all source files as C; /Tc <filename> Specify a C source file; /TP Treat all source files as C++; /Tp <filename> Specify a C++ source file; /utf-8 Set source and runtime encoding to UTF-8 (default); /U <macro> Undefine macro; /vd<value> Control vtordisp placement; /vmb Use a best-case representation method for member pointers; /vmg Use a most-general representation for member pointers; /vmm Set the default most-general representation to multiple inheritance; /vms Set the default most-general representation to single inheritance; /vmv Set the default most-general representation to virtual inheritance; /volatile:iso Volatile loads and stores have standard semantics; /volatile:ms Volatile loads and stores have acquire and release semantics; /W0 Disable all warnings; /W1 Enable -Wall; /W2 Enable -Wall; /W3 Enable -Wall; /W4 Enable -Wall and -Wextra; /Wall Enable -Weverything; /WX- Do not treat warnings as errors; /WX Treat warnings as errors; /w Disable all warnings; /X Don't add %INCLUDE% to the include search path; /Y- Disable precompiled headers, overrides /Yc and /Yu; /Yc<filename> Generate a pch file for all code up to and including <filename>; /Yu<filename> Load a pch file and use it instead of all code up to and including <filename>; /Z7 Enable CodeView debug information in object files; /Zc:char8_t Enable C++20 char8_t type; /Zc:char8_t- Disable C++20 char8_t type; /Zc:dllexportInlines- Don't dllexport/dllimport inline member functions of dllexport/import classes; /Zc:dllexportInlines dllexport/dllimport inline member functions of dllexport/import classes (default); /Zc:sizedDealloc- Disable C++14 sized",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:175839,load,loads,175839,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,1,['load'],['loads']
Performance," volumes) models, only most significant volumes are shown; - one could activate several clip planes (only with WebGL); - interaction with object browser to change visibility flags or focus on selected volume; - support of floating browser for TGeo objects; - intensive use of HTML Worker to offload computation tasks and keep interactivity; - enable more details when changing camera position/zoom; - Improvements in histograms 3D drawing; - all lego options: lego1..lego4, combined with 'fb', 'bb', '0' or 'z'; - support axis labels on lego plots; - support lego plots for TH1; - Significant (up to factor 10) performance improvement in 3D-graphics; - Implement ROOT6-like color palettes; - Support non-equidistant bins for TH1/TH2 objects.; - Improve TF1 drawing - support exp function in TFormula, fix errors with logx scale, enable zoom-in, (re)calculate function points when zooming; - Introduce many context menus for improving interactivity; - Implement col0 and col0z draw option for TH2 histograms, similar to ROOT6; - Implement box and hbox draw options for TH1 class; - Significant (factor 4) I/O performance improvement; - New 'flex' layout:; - create frames like in Multi Document Interface; - one could move/resize/minimize/maximize such frames. For more details, like the complete change log, the documentation, and very detailed examples, see the [JSROOT home page](https://root.cern.ch/js) and the [JSROOT project github page](https://github.com/linev/jsroot) . ## Tutorials; * New tutorial `treegetval.C` illustrating how to retrieve `TTree` variables in arrays.; * Add script to automatically translate tutorials into notebooks; * Embed it into the documentation generation; * Make the notebooks available in the [tutorials section of the class documentation](https://root.cern/doc/master/group__Tutorials.html). ## Build, Configuration and Testing Infrastructure; - `root-config` does not suppress deprecation warnings (-Wno-deprecated-declarations) anymore. This means compilers ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:27443,perform,performance,27443,README/ReleaseNotes/v608/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md,1,['perform'],['performance']
Performance," we can normally apply the `Alignment`_ and `Eliminating Bit Vector Checks; for All-Ones Bit Vectors`_ optimizations thus simplifying the check at each; call site to a range and alignment check. Shared library support; ======================. **EXPERIMENTAL**. The basic CFI mode described above assumes that the application is a; monolithic binary; at least that all possible virtual/indirect call; targets and the entire class hierarchy are known at link time. The; cross-DSO mode, enabled with **-f[no-]sanitize-cfi-cross-dso** relaxes; this requirement by allowing virtual and indirect calls to cross the; DSO boundary. Assuming the following setup: the binary consists of several; instrumented and several uninstrumented DSOs. Some of them may be; dlopen-ed/dlclose-d periodically, even frequently. - Calls made from uninstrumented DSOs are not checked and just work.; - Calls inside any instrumented DSO are fully protected.; - Calls between different instrumented DSOs are also protected, with; a performance penalty (in addition to the monolithic CFI; overhead).; - Calls from an instrumented DSO to an uninstrumented one are; unchecked and just work, with performance penalty.; - Calls from an instrumented DSO outside of any known DSO are; detected as CFI violations. In the monolithic scheme a call site is instrumented as. .. code-block:: none. if (!InlinedFastCheck(f)); abort();; call *f. In the cross-DSO scheme it becomes. .. code-block:: none. if (!InlinedFastCheck(f)); __cfi_slowpath(CallSiteTypeId, f);; call *f. CallSiteTypeId; --------------. ``CallSiteTypeId`` is a stable process-wide identifier of the; call-site type. For a virtual call site, the type in question is the class; type; for an indirect function call it is the function signature. The; mapping from a type to an identifier is an ABI detail. In the current,; experimental, implementation the identifier of type T is calculated as; follows:. - Obtain the mangled name for ""typeinfo name for T"".; - Calculate MD5 h",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ControlFlowIntegrityDesign.rst:19420,perform,performance,19420,interpreter/llvm-project/clang/docs/ControlFlowIntegrityDesign.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ControlFlowIntegrityDesign.rst,1,['perform'],['performance']
Performance," we look at the *Dynamic Dispatch Stall Cycles* table, we see the counter for; SCHEDQ reports 272 cycles. This counter is incremented every time the dispatch; logic is unable to dispatch a full group because the scheduler's queue is full. Looking at the *Dispatch Logic* table, we see that the pipeline was only able to; dispatch two micro opcodes 51.5% of the time. The dispatch group was limited to; one micro opcode 44.6% of the cycles, which corresponds to 272 cycles. The; dispatch statistics are displayed by either using the command option; ``-all-stats`` or ``-dispatch-stats``. The next table, *Schedulers*, presents a histogram displaying a count,; representing the number of micro opcodes issued on some number of cycles. In; this case, of the 610 simulated cycles, single opcodes were issued 306 times; (50.2%) and there were 7 cycles where no opcodes were issued. The *Scheduler's queue usage* table shows that the average and maximum number of; buffer entries (i.e., scheduler queue entries) used at runtime. Resource JFPU01; reached its maximum (18 of 18 queue entries). Note that AMD Jaguar implements; three schedulers:. * JALU01 - A scheduler for ALU instructions.; * JFPU01 - A scheduler floating point operations.; * JLSAGU - A scheduler for address generation. The dot-product is a kernel of three floating point instructions (a vector; multiply followed by two horizontal adds). That explains why only the floating; point scheduler appears to be used. A full scheduler queue is either caused by data dependency chains or by a; sub-optimal usage of hardware resources. Sometimes, resource pressure can be; mitigated by rewriting the kernel using different instructions that consume; different scheduler resources. Schedulers with a small queue are less resilient; to bottlenecks caused by the presence of long data dependencies. The scheduler; statistics are displayed by using the command option ``-all-stats`` or; ``-scheduler-stats``. The next table, *Retire Control Unit*, pre",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:31410,queue,queue,31410,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,1,['queue'],['queue']
Performance," we would like to add four optimization levels to our optimizer,; using the standard flags ""``-g``"", ""``-O0``"", ""``-O1``"", and ""``-O2``"". We; could easily implement this with boolean options like above, but there are; several problems with this strategy:. #. A user could specify more than one of the options at a time, for example,; ""``compiler -O3 -O2``"". The CommandLine library would not be able to catch; this erroneous input for us. #. We would have to test 4 different variables to see which ones are set. #. This doesn't map to the numeric levels that we want... so we cannot easily; see if some level >= ""``-O1``"" is enabled. To cope with these problems, we can use an enum value, and have the CommandLine; library fill it in with the appropriate level directly, which is used like this:. .. code-block:: c++. enum OptLevel {; g, O1, O2, O3; };. cl::opt<OptLevel> OptimizationLevel(cl::desc(""Choose optimization level:""),; cl::values(; clEnumVal(g , ""No optimizations, enable debugging""),; clEnumVal(O1, ""Enable trivial optimizations""),; clEnumVal(O2, ""Enable default optimizations""),; clEnumVal(O3, ""Enable expensive optimizations"")));. ...; if (OptimizationLevel >= O2) doPartialRedundancyElimination(...);; ... This declaration defines a variable ""``OptimizationLevel``"" of the; ""``OptLevel``"" enum type. This variable can be assigned any of the values that; are listed in the declaration. The CommandLine library enforces that; the user can only specify one of the options, and it ensure that only valid enum; values can be specified. The ""``clEnumVal``"" macros ensure that the command; line arguments matched the enum values. With this option added, our help output; now is:. ::. USAGE: compiler [options] <input file>. OPTIONS:; Choose optimization level:; -g - No optimizations, enable debugging; -O1 - Enable trivial optimizations; -O2 - Enable default optimizations; -O3 - Enable expensive optimizations; -f - Enable binary output on terminals; -help - display available options (-h",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:14728,optimiz,optimization,14728,interpreter/llvm-project/llvm/docs/CommandLine.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst,5,['optimiz'],"['optimization', 'optimizations']"
Performance," were issued 306 times; (50.2%) and there were 7 cycles where no opcodes were issued. The *Scheduler's queue usage* table shows that the average and maximum number of; buffer entries (i.e., scheduler queue entries) used at runtime. Resource JFPU01; reached its maximum (18 of 18 queue entries). Note that AMD Jaguar implements; three schedulers:. * JALU01 - A scheduler for ALU instructions.; * JFPU01 - A scheduler floating point operations.; * JLSAGU - A scheduler for address generation. The dot-product is a kernel of three floating point instructions (a vector; multiply followed by two horizontal adds). That explains why only the floating; point scheduler appears to be used. A full scheduler queue is either caused by data dependency chains or by a; sub-optimal usage of hardware resources. Sometimes, resource pressure can be; mitigated by rewriting the kernel using different instructions that consume; different scheduler resources. Schedulers with a small queue are less resilient; to bottlenecks caused by the presence of long data dependencies. The scheduler; statistics are displayed by using the command option ``-all-stats`` or; ``-scheduler-stats``. The next table, *Retire Control Unit*, presents a histogram displaying a count,; representing the number of instructions retired on some number of cycles. In; this case, of the 610 simulated cycles, two instructions were retired during the; same cycle 399 times (65.4%) and there were 109 cycles where no instructions; were retired. The retire statistics are displayed by using the command option; ``-all-stats`` or ``-retire-stats``. The last table presented is *Register File statistics*. Each physical register; file (PRF) used by the pipeline is presented in this table. In the case of AMD; Jaguar, there are two register files, one for floating-point registers (JFpuPRF); and one for integer registers (JIntegerPRF). The table shows that of the 900; instructions processed, there were 900 mappings created. Since this dot-produc",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:32178,queue,queue,32178,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,2,"['bottleneck', 'queue']","['bottlenecks', 'queue']"
Performance," when in learning phase rather than; reading each requested branch individually, the TTreeCache will read all the; branches thus trading off the latencies inherent to multiple small reads for; the potential of requesting more data than needed by read from the disk or; server the baskets for too many branches. The default behavior can be changed by either updating one of the rootrc files; or by setting environment variables. The rootrc files, both the global and the; local ones, now support the following the resource variable TTreeCache.Size; which set the default size factor for auto sizing TTreeCache for TTrees. The; estimated cluster size for the TTree and this factor is used to give the cache; size. If option is set to zero auto cache creation is disabled and the default; cache size is the historical one (equivalent to factor 1.0). If set to; non zero auto cache creation is enabled and both auto created and; default sized caches will use the configured factor: 0.0 no automatic cache; and greater than 0.0 to enable cache. This value can be overridden by the; environment variable ROOT_TTREECACHE_SIZE. The resource variable TTreeCache.Prefill sets the default TTreeCache prefilling; type. The prefill type may be: 0 for no prefilling and 1 to prefill all; the branches. It can be overridden by the environment variable ROOT_TTREECACHE_PREFILL. In particular the default can be set back to the same as in version 5 by; setting TTreeCache.Size (or ROOT_TTREECACHE_SIZE) and TTreeCache.Prefill; (or ROOT_TTREECACHE_PREFILL) both to zero. TTree methods which are expected to modify a cache, like AddBranchToCache, will; attempt to setup a cache of default size if one does not exist, irrespective of; whether the auto cache creation is enabled. Additionally several methods giving; control of the cache have changed return type from void to Int_t, to be able to; return a code to indicate if there was an error. Usually TTree::SetCacheSize will no longer reset the list of branches to be",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md:13731,cache,cache,13731,README/ReleaseNotes/v604/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md,1,['cache'],['cache']
Performance," when used for generating a linked binary from a source file; (through an intermediate object file), the driver will invoke `cc1` to; generate a temporary object file. The temporary remark file will be emitted; next to the object file, which will then be picked up by `dsymutil` and; emitted in the .dSYM bundle. This is available for all formats except YAML. For example:. ``clang -fsave-optimization-record=bitstream in.c -o out`` will generate. * ``/var/folders/43/9y164hh52tv_2nrdxrj31nyw0000gn/T/a-9be59b.o``. * ``/var/folders/43/9y164hh52tv_2nrdxrj31nyw0000gn/T/a-9be59b.opt.bitstream``. * ``out``. * ``out.dSYM/Contents/Resources/Remarks/out``. Darwin-only: compiling for multiple architectures will use the following; scheme:. ``<base>-<arch>.opt.<format>``. Note that this is incompatible with passing the; :option:`-foptimization-record-file` option. .. option:: -foptimization-record-file. Control the file to which optimization reports are written. This implies; :ref:`-fsave-optimization-record <opt_fsave-optimization-record>`. On Darwin platforms, this is incompatible with passing multiple; ``-arch <arch>`` options. .. option:: -foptimization-record-passes. Only include passes which match a specified regular expression. When optimization reports are being output (see; :ref:`-fsave-optimization-record <opt_fsave-optimization-record>`), this; option controls the passes that will be included in the final report. If this option is not used, all the passes are included in the optimization; record. .. _opt_fdiagnostics-show-hotness:. .. option:: -f[no-]diagnostics-show-hotness. Enable profile hotness information in diagnostic line. This option controls whether Clang prints the profile hotness associated; with diagnostics in the presence of profile-guided optimization information.; This is currently supported with optimization remarks (see; :ref:`Options to Emit Optimization Reports <rpass>`). The hotness information; allows users to focus on the hot optimization remarks tha",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:13202,optimiz,optimization-record,13202,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,2,['optimiz'],['optimization-record']
Performance," where this hasn't been practical to apply. In; situations where you absolutely must emit a non-programmatic error and; the ``Error`` model isn't workable you can call ``report_fatal_error``,; which will call installed error handlers, print a message, and abort the; program. The use of `report_fatal_error` in this case is discouraged. Recoverable errors are modeled using LLVM's ``Error`` scheme. This scheme; represents errors using function return values, similar to classic C integer; error codes, or C++'s ``std::error_code``. However, the ``Error`` class is; actually a lightweight wrapper for user-defined error types, allowing arbitrary; information to be attached to describe the error. This is similar to the way C++; exceptions allow throwing of user-defined types. Success values are created by calling ``Error::success()``, E.g.:. .. code-block:: c++. Error foo() {; // Do something.; // Return success.; return Error::success();; }. Success values are very cheap to construct and return - they have minimal; impact on program performance. Failure values are constructed using ``make_error<T>``, where ``T`` is any class; that inherits from the ErrorInfo utility, E.g.:. .. code-block:: c++. class BadFileFormat : public ErrorInfo<BadFileFormat> {; public:; static char ID;; std::string Path;. BadFileFormat(StringRef Path) : Path(Path.str()) {}. void log(raw_ostream &OS) const override {; OS << Path << "" is malformed"";; }. std::error_code convertToErrorCode() const override {; return make_error_code(object_error::parse_failed);; }; };. char BadFileFormat::ID; // This should be declared in the C++ file. Error printFormattedFile(StringRef Path) {; if (<check for valid format>); return make_error<BadFileFormat>(Path);; // print file contents.; return Error::success();; }. Error values can be implicitly converted to bool: true for error, false for; success, enabling the following idiom:. .. code-block:: c++. Error mayFail();. Error foo() {; if (auto Err = mayFail()); return Er",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:19162,perform,performance,19162,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,1,['perform'],['performance']
Performance," which might cause an object to be deallocated; before it would otherwise be. Without this, it would be almost; impossible to eliminate any ``retain``/``release`` pairs. For; example, consider the following code:. .. code-block:: objc. id x = _ivar;; [x foo];. If we were not permitted in any event to shorten the lifetime of the; object in ``x``, then we would not be able to eliminate this retain; and release unless we could prove that the message send could not; modify ``_ivar`` (or deallocate ``self``). Since message sends are; opaque to the optimizer, this is not possible, and so ARC's hands; would be almost completely tied. ARC makes no guarantees about the execution of a computation history; which contains undefined behavior. In particular, ARC makes no; guarantees in the presence of race conditions. ARC may assume that any retainable object pointers it receives or; generates are instantaneously valid from that point until a point; which, by the concurrency model of the host language, happens-after; the generation of the pointer and happens-before a release of that; object (possibly via an aliasing pointer or indirectly due to; destruction of a different object). .. admonition:: Rationale. There is very little point in trying to guarantee correctness in the; presence of race conditions. ARC does not have a stack-scanning; garbage collector, and guaranteeing the atomicity of every load and; store operation would be prohibitive and preclude a vast amount of; optimization. ARC may assume that non-ARC code engages in sensible balancing; behavior and does not rely on exact or minimum retain count values; except as guaranteed by ``__strong`` object invariants or +1 transfer; conventions. For example, if an object is provably double-retained; and double-released, ARC may eliminate the inner retain and release;; it does not need to guard against code which performs an unbalanced; release followed by a ""balancing"" retain. .. _arc.optimization.liveness:. Object liveness; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst:77646,concurren,concurrency,77646,interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,1,['concurren'],['concurrency']
Performance," which reproduces opened page with layout and drawn items. ### August 2014; 1. All communication between server and browser done with JSON format.; 2. Fix small error in dtree.js - one should always set; last sibling (_ls) property while tree can be dynamically changed.; 3. In JSRootCore.js provide central function, which handles different kinds; of XMLHttpRequest. Use only async requests, also when getting file header.; 4. Fully reorganize data management in file/tree/directory/collection hierarchical; display. Now complete description collected in HPainter class and decoupled from; visualization, performed with dTree.js.; 5. Remove all global variables from the code.; 6. Automatic scripts/style loading handled via JSROOT.loadScript() function.; One can specify arbitrary scripts list, which asynchronously loaded by browser.; 7. Method to build simple GUI changed and more simplified :). The example in index.htm.; While loadScript and AssertPrerequisites functions moved to JSROOT, one; can easily build many different kinds of GUIs, reusing provided JSRootCore.js functions.; 8. In example.htm also use AssertPrerequisites to load necessary scripts.; This helps to keep code up-to-date even by big changes in JavaScript code.; 9. Provide monitoring of online THttpServer with similar interface as for ROOT files.; 10. Fix several errors in TKey Streamer, use member names as in ROOT itself.; 11. Keep the only version identifier JSROOT.version for JS code; 12. One can specify in JSROOT.AssertPrerequisites functionality which is required.; One could specify '2d', 'io' (default) or '3d'.; 13. Use new AssertPrerequisites functionality to load only required functionality.; 14. When displaying single element, one could specify draw options and monitor property like:; <http://localhost:8080/Files/job1.root/hpxpy/draw.htm?opt=col&monitor=2000>; Such link is best possibility to integrate display into different HTML pages,; using `<iframe/>` tag like:; `<iframe src=""http://localhost:8",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/js/changes.md:74625,load,loadScript,74625,js/changes.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/js/changes.md,1,['load'],['loadScript']
Performance," whole `frameInfo` section is often unnecessary if there is no special; frame usage in the function. `tracksRegLiveness` on the other hand is often; necessary for some passes that care about block livein lists. - The (global) `liveins:` list is typically only interesting for early; instruction selection passes and can be removed when testing later passes.; The per-block `liveins:` on the other hand are necessary if; `tracksRegLiveness` is true. - Branch probability data in block `successors:` lists can be dropped if the; test doesn't depend on it. Example:; `successors: %bb.1(0x40000000), %bb.2(0x40000000)` can be replaced with; `successors: %bb.1, %bb.2`. - MIR code contains a whole IR module. This is necessary because there are; no equivalents in MIR for global variables, references to external functions,; function attributes, metadata, debug info. Instead some MIR data references; the IR constructs. You can often remove them if the test doesn't depend on; them. - Alias Analysis is performed on IR values. These are referenced by memory; operands in MIR. Example: `:: (load 8 from %ir.foobar, !alias.scope !9)`.; If the test doesn't depend on (good) alias analysis the references can be; dropped: `:: (load 8)`. - MIR blocks can reference IR blocks for debug printing, profile information; or debug locations. Example: `bb.42.myblock` in MIR references the IR block; `myblock`. It is usually possible to drop the `.myblock` reference and simply; use `bb.42`. - If there are no memory operands or blocks referencing the IR then the; IR function can be replaced by a parameterless dummy function like; `define @func() { ret void }`. - It is possible to drop the whole IR section of the MIR file if it only; contains dummy functions (see above). The .mir loader will create the; IR functions automatically in this case. .. _limitations:. Limitations; -----------. Currently the MIR format has several limitations in terms of which state it; can serialize:. - The target-specific state i",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MIRLangRef.rst:4421,perform,performed,4421,interpreter/llvm-project/llvm/docs/MIRLangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MIRLangRef.rst,1,['perform'],['performed']
Performance," will exit with a; non-zero value. TUTORIAL; --------. FileCheck is typically used from LLVM regression tests, being invoked on the RUN; line of the test. A simple example of using FileCheck from a RUN line looks; like this:. .. code-block:: llvm. ; RUN: llvm-as < %s | llc -march=x86-64 | FileCheck %s. This syntax says to pipe the current file (""``%s``"") into ``llvm-as``, pipe; that into ``llc``, then pipe the output of ``llc`` into ``FileCheck``. This; means that FileCheck will be verifying its standard input (the llc output); against the filename argument specified (the original ``.ll`` file specified by; ""``%s``""). To see how this works, let's look at the rest of the ``.ll`` file; (after the RUN line):. .. code-block:: llvm. define void @sub1(i32* %p, i32 %v) {; entry:; ; CHECK: sub1:; ; CHECK: subl; %0 = tail call i32 @llvm.atomic.load.sub.i32.p0i32(i32* %p, i32 %v); ret void; }. define void @inc4(i64* %p) {; entry:; ; CHECK: inc4:; ; CHECK: incq; %0 = tail call i64 @llvm.atomic.load.add.i64.p0i64(i64* %p, i64 1); ret void; }. Here you can see some ""``CHECK:``"" lines specified in comments. Now you can; see how the file is piped into ``llvm-as``, then ``llc``, and the machine code; output is what we are verifying. FileCheck checks the machine code output to; verify that it matches what the ""``CHECK:``"" lines specify. The syntax of the ""``CHECK:``"" lines is very simple: they are fixed strings that; must occur in order. FileCheck defaults to ignoring horizontal whitespace; differences (e.g. a space is allowed to match a tab) but otherwise, the contents; of the ""``CHECK:``"" line is required to match some thing in the test file exactly. One nice thing about FileCheck (compared to grep) is that it allows merging; test cases together into logical groups. For example, because the test above; is checking for the ""``sub1:``"" and ""``inc4:``"" labels, it will not match; unless there is a ""``subl``"" in between those labels. If it existed somewhere; else in the file, that would",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/FileCheck.rst:8748,load,load,8748,interpreter/llvm-project/llvm/docs/CommandGuide/FileCheck.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/FileCheck.rst,1,['load'],['load']
Performance," will not be optimized, but; it causes the instantiation of ``twice`` and ``thrice`` with an ``int`` type; of; these two instantiations, ``twice`` will be optimized (because its definition; was outside the region) and ``thrice`` will not be optimized. Clang also implements MSVC's range-based pragma,; ``#pragma optimize(""[optimization-list]"", on | off)``. At the moment, Clang only; supports an empty optimization list, whereas MSVC supports the arguments, ``s``,; ``g``, ``t``, and ``y``. Currently, the implementation of ``pragma optimize`` behaves; the same as ``#pragma clang optimize``. All functions; between ``off`` and ``on`` will be decorated with the ``optnone`` attribute. .. code-block:: c++. #pragma optimize("""", off); // This function will be decorated with optnone.; void f1() {}. #pragma optimize("""", on); // This function will be optimized with whatever was specified on; // the commandline.; void f2() {}. // This will warn with Clang's current implementation.; #pragma optimize(""g"", on); void f3() {}. For MSVC, an empty optimization list and ``off`` parameter will turn off; all optimizations, ``s``, ``g``, ``t``, and ``y``. An empty optimization and; ``on`` parameter will reset the optimizations to the ones specified on the; commandline. .. list-table:: Parameters (unsupported by Clang). * - Parameter; - Type of optimization; * - g; - Deprecated; * - s or t; - Short or fast sequences of machine code; * - y; - Enable frame pointers. Extensions for loop hint optimizations; ======================================. The ``#pragma clang loop`` directive is used to specify hints for optimizing the; subsequent for, while, do-while, or c++11 range-based for loop. The directive; provides options for vectorization, interleaving, predication, unrolling and; distribution. Loop hints can be specified before any loop and will be ignored if; the optimization is not safe to apply. There are loop hints that control transformations (e.g. vectorization, loop; unrolling) and there a",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst:161742,optimiz,optimize,161742,interpreter/llvm-project/clang/docs/LanguageExtensions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst,1,['optimiz'],['optimize']
Performance," with ROOT under the `$ROOTSYS/tutorials` directory. ``` {.cpp}; # Example: displaying a ROOT histogram from Python; from ROOT import gRandom,TCanvas,TH1F. c1 = TCanvas('c1','Example',200,10,700,500); hpx = TH1F('hpx','px',100,-4,4). for i in xrange(25000):; px = gRandom.Gaus(); hpx.Fill(px). hpx.Draw(); c1.Update(); ```. ### Access to Python from ROOT. Access to Python objects from Cling is not completely fleshed out.; Currently, ROOT objects and built-in types can cross the boundary; between the two interpreters, but other objects are much more; restricted. For example, for a Python object to cross, it has to be a; class instance, and its class has to be known to Cling first (i.e. the; class has to cross first, before the instance can). All other; cross-coding is based on strings that are run on the Python interpreter; and vise-versa. With the ROOT v4.00/06 and later, the **`TPython`** class will be loaded; automatically on use, for older editions, the `libPyROOT.so` needs to be; loaded first before use. It is possible to switch between interpreters; by calling **`TPython::Prompt()`** on the ROOT side, while returning with; `^D` (`EOF`). State is preserved between successive switches, and string; based cross calls can nest as long as shared resources are properly; handled. ``` {.cpp}; // Example: accessing the Python interpreter from ROOT; // either load PyROOT explicitly or rely on auto-loading; root[] gSystem->Load( ""libPyROOT"" );; root[] TPython::Exec(""print1+1"");; 2. // create a TBrowser on the Python side, and transfer it back and forth; root[] TBrowser* b = (void*)TPython::Eval(""ROOT.TBrowser()"");; (class TObject*)0x8d1daa0; root[] TPython::Bind(b,""b"");. // builtin variables can cross-over (after the call i==2); root[] int i = TPython::Eval( ""1+1"" );; root[] i; (int)2; ```. ### Installation. There are several ways of obtaining `PyROOT`, and which is best depends; on your specific situation. If you work at CERN, you can use the; installation available on `afs`",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/PythonRuby.md:4599,load,loaded,4599,documentation/users-guide/PythonRuby.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/PythonRuby.md,1,['load'],['loaded']
Performance," with a given shape in one step; TGeoVolume *vol = gGeoManager->MakeBox(""VNAME"",ptrMed,dx,dy,dz);; TGeoVolume *vol = gGeoManager->MakeTubs(""VNAME"",ptrMed,rmin,rmax,; dz,phi1,phi2);. // See class TGeoManager for the rest of shapes.; // Making a volume with a given shape with a unique prototype; TGeoVolume *vol = gGeoManager->Volume(""VNAME"",""XXXX"",nmed,upar,; npar);. // Where XXXX stands for the first 4 letters of the specific shape; // classes, nmed is the medium number, upar is an Double_t * array; // of the shape parameters and npar is the number of parameters.; // This prototype allows (npar = 0) to define volumes with shape; // defined only at positioning time (volumes defined in this way; // need to be positioned using TGeoManager::Node() method); ~~~. \anchor GP01bc; #### Positioned Volumes (Nodes). Geometrical modeling is a difficult task when the number of different; geometrical objects is 106-108. This is more or less the case for; detector geometries of complex experiments, where a ‘flat' CSG model; description cannot scale with the current CPU performances. This is the; reason why models like GEANT [1] introduced an additional dimension; (depth) in order to reduce the complexity of the problem. This concept; is also preserved by the ROOT modeller and introduces a pure geometrical; constraint between objects (volumes in our case) - containment. This; means in fact that any positioned volume has to be contained by another.; Now what means contained and positioned?. - We will say that a volume `contains` a point if this is inside the; shape associated to the volume. For instance, a volume having a box; shape will contain all points `P=(X,Y,Z)` verifying the conditions:; `Abs(Pi)dXi`. The points on the shape boundaries are considered as; inside the volume. The volume contains a daughter if it contains all; the points contained by the daughter.; - The definition of containment works of course only with points; defined in the local coordinate system of the consid",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:26276,perform,performances,26276,geom/geom/doc/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md,1,['perform'],['performances']
Performance," with a single hardening instruction:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; addl (%rsi), %edi # Load and accumulate without leaking.; addl 4(%rsi), %edi # Continue without leaking.; addl 8(%rsi), %edi; orl %eax, %edi # Mask out bits from all three loads.; ```. ###### Preserving the flags while hardening loaded values on Haswell, Zen, and newer processors. Sadly, there are no useful instructions on x86 that apply a mask to all 64 bits; without touching the flag registers. However, we can harden loaded values that; are narrower than a word (fewer than 32-bits on 32-bit systems and fewer than; 64-bits on 64-bit systems) by zero-extending the value to the full word size; and then shifting right by at least the number of original bits using the BMI2; `shrx` instruction:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; addl (%rsi), %edi # Load and accumulate 32 bits of data.; shrxq %rax, %rdi, %rdi # Shift out all 32 bits loaded.; ```. Because on x86 the zero-extend is free, this can efficiently harden the loaded; value. ##### Hardening the address of the load. When hardening the loaded value is inapplicable, most often because the; instruction directly leaks information (like `cmp` or `jmpq`), we switch to; hardening the _address_ of the load instead of the loaded value. This avoids; increasing register pressure by unfolding the load or paying some other high; cost. To understand how this works in practice, we need to examine the exact; semantics of the x86 addressing modes which, in its fully general form, looks; like `(%base,%index,scale)offset`. Here `%base` and `%index` are 64-bit; registers that can potentially be any value, and may be attacker controlled,; and `scale` and `offset` are fixed immediate values. `scale` must be `1`, `2`,; `4`, or `8`, and `offset` can be any 32-bit sign extended value. The exact; computation performed to find the address is then: `%base + (scale ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:27390,load,loaded,27390,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,1,['load'],['loaded']
Performance," with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - s_waitcnt vscnt(0); must happen after; any preceding; global/generic; atomicrmw-no-return-value; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Must happen before; the following; buffer_gl*_inv.; - Ensures that the; fence-paired atomic; has completed; before invalidating; the; caches. Therefore; any following; locations read must; be no older than; the value read by; the; fence-paired-atomic. 2. buffer_gl0_inv;; buffer_gl1_inv. - Must happen before any; following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. **Release Atomic**; ------------------------------------------------------------------------------------; store atomic release - singlethread - global 1. buffer/global/ds/flat_store; - wavefront - local; - generic; store atomic release - workgroup - global 1. s_waitcnt lgkmcnt(0) &; - generic vmcnt(0) & vscnt(0). - If CU wavefront execution; mode, omit vmcnt(0) and; vscnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0), s_waitcnt; vscnt(0) and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/load; atomic/; atomicrmw-with-return-value.; - s_waitcnt vscnt(0); must happen after; any preceding; global/generic; store/store; atomic/; atomicrmw-no-return-value.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must hap",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:354618,load,loads,354618,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['loads']
Performance," with branch probabilities); # PGO data record for BB_3; .uleb128 1000 # BB_3 basic block frequency (only when enabled); .uleb128 0 # BB_3 successors count (only enabled with branch probabilities). ``SHT_LLVM_OFFLOADING`` Section (offloading data); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; This section stores the binary data used to perform offloading device linking; and execution, creating a fat binary. This section is emitted during compilation; of offloading languages such as OpenMP or CUDA. If the data is intended to be; used by the device linker only, it should use the ``SHF_EXCLUDE`` flag so it is; automatically stripped from the final executable or shared library. The binary data stored in this section conforms to a custom binary format used; for storing offloading metadata. This format is effectively a string table; containing metadata accompanied by a device image. ``SHT_LLVM_LTO`` Section (LLVM bitcode for fat LTO); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; This section stores LLVM bitcode used to perform regular LTO or ThinLTO at link; time. This section is generated when the compiler enables fat LTO. This section; has the ``SHF_EXCLUDE`` flag so that it is stripped from the final executable; or shared library. CodeView-Dependent; ------------------. ``.cv_file`` Directive; ^^^^^^^^^^^^^^^^^^^^^^; Syntax:; ``.cv_file`` *FileNumber FileName* [ *checksum* ] [ *checksumkind* ]. ``.cv_func_id`` Directive; ^^^^^^^^^^^^^^^^^^^^^^^^^; Introduces a function ID that can be used with ``.cv_loc``. Syntax:; ``.cv_func_id`` *FunctionId*. ``.cv_inline_site_id`` Directive; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; Introduces a function ID that can be used with ``.cv_loc``. Includes; ``inlined at`` source location information for use in the line table of the; caller, whether the caller is a real function or another inlined call site. Syntax:; ``.cv_inline_site_id`` *FunctionId* ``within`` *Function* ``inlined_at`` *FileNumber Line* [ *Column* ]. ``.cv",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Extensions.rst:18598,perform,perform,18598,interpreter/llvm-project/llvm/docs/Extensions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Extensions.rst,1,['perform'],['perform']
Performance," with the Library, with the complete machine-readable ""work that; uses the Library"", as object code and/or source code, so that the; user can modify the Library and then relink to produce a modified; executable containing the modified Library. (It is understood; that the user who changes the contents of definitions files in the; Library will not necessarily be able to recompile the application; to use the modified definitions.). b) Use a suitable shared library mechanism for linking with the; Library. A suitable mechanism is one that (1) uses at run time a; copy of the library already present on the user's computer system,; rather than copying library functions into the executable, and (2); will operate properly with a modified version of the library, if; the user installs one, as long as the modified version is; interface-compatible with the version that the work was made with. c) Accompany the work with a written offer, valid for at; least three years, to give the same user the materials; specified in Subsection 6a, above, for a charge no more; than the cost of performing this distribution. d) If distribution of the work is made by offering access to copy; from a designated place, offer equivalent access to copy the above; specified materials from the same place. e) Verify that the user has already received a copy of these; materials or that you have already sent this user a copy. For an executable, the required form of the ""work that uses the; Library"" must include any data and utility programs needed for; reproducing the executable from it. However, as a special exception,; the materials to be distributed need not include anything that is; normally distributed (in either source or binary form) with the major; components (compiler, kernel, and so on) of the operating system on; which the executable runs, unless that component itself accompanies; the executable. It may happen that this requirement contradicts the license; restrictions of other proprietary librarie",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/LGPL2_1.txt:16204,perform,performing,16204,LGPL2_1.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/LGPL2_1.txt,2,['perform'],['performing']
Performance," workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_load; 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than the local load; atomic value being; acquired. load atomic acquire - workgroup - generic 1. flat_load glc=1. - If not TgSplit execution; mode, omit glc=1. 2. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit lgkmcnt(0).; - Must happen before; the following; buffer_wbinvl1_vol and any; following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic value being; acquired. 3. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. load atomic acquire - agent - global 1. buffer/global_load; glc=1; 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the load; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale global data. load atomic acquire - system - global 1. buffer/global/flat_load; glc=1; 2. s_waitcnt vmcnt(0). - Must happen before; following buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures the load; has completed; before invalidating; the cache. 3. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. load atomic acquire - agent - generic 1. flat_load glc=1; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0)",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:246759,load,load,246759,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['load']
Performance," would take the previous two and add the Parser library and; some actions for indexing. If you want a refactoring, static analysis, or; source-to-source compiler tool, you would then add the AST building and; semantic analyzer libraries.; For more information about the low-level implementation details of the; various clang libraries, please see the ; clang Internals Manual. Support Diverse Clients. Clang is designed and built with many grand plans for how we can use it. The; driving force is the fact that we use C and C++ daily, and have to suffer due to; a lack of good tools available for it. We believe that the C and C++ tools; ecosystem has been significantly limited by how difficult it is to parse and; represent the source code for these languages, and we aim to rectify this; problem in clang.; The problem with this goal is that different clients have very different; requirements. Consider code generation, for example: a simple front-end that; parses for code generation must analyze the code for validity and emit code; in some intermediate form to pass off to a optimizer or backend. Because; validity analysis and code generation can largely be done on the fly, there is; not hard requirement that the front-end actually build up a full AST for all; the expressions and statements in the code. TCC and GCC are examples of; compilers that either build no real AST (in the former case) or build a stripped; down and simplified AST (in the later case) because they focus primarily on; codegen.; On the opposite side of the spectrum, some clients (like refactoring) want; highly detailed information about the original source code and want a complete; AST to describe it with. Refactoring wants to have information about macro; expansions, the location of every paren expression '(((x)))' vs 'x', full; position information, and much more. Further, refactoring wants to look; across the whole program to ensure that it is making transformations; that are safe. Making this efficient ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/features.html:7110,optimiz,optimizer,7110,interpreter/llvm-project/clang/www/features.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/features.html,2,['optimiz'],['optimizer']
Performance," writeback to; ensure previous; global/generic; store/atomicrmw are; visible at agent scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global have; completed before; performing the; atomicrmw that is; being released. 3. flat_atomic; 4. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_inv.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 5. buffer_inv sc1=1. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acq_rel - system - generic 1. buffer_wbl2 sc0=1 sc1=1. - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at system scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensur",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:323270,cache,cache,323270,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['cache'],['cache']
Performance," writeback; the CPU cache due to the L2 probe filter and and the PTE C-bit being set.; * Since all work-groups on the same agent share the same L2, no L2; invalidation or writeback is required for coherence.; * To ensure coherence of local and remote memory writes of work-groups in; different agents a ``buffer_wbl2`` is required. It will writeback dirty L2; cache lines of MTYPE RW (used for local coarse grain memory) and MTYPE NC; ()used for remote coarse grain memory). Note that MTYPE CC (used for local; fine grain memory) causes write through to DRAM, and MTYPE UC (used for; remote fine grain memory) bypasses the L2, so both will never result in; dirty L2 cache lines.; * To ensure coherence of local and remote memory reads of work-groups in; different agents a ``buffer_invl2`` is required. It will invalidate L2; cache lines with MTYPE NC (used for remote coarse grain memory). Note that; MTYPE CC (used for local fine grain memory) and MTYPE RW (used for local; coarse memory) cause local reads to be invalidated by remote writes with; with the PTE C-bit so these cache lines are not invalidated. Note that; MTYPE UC (used for remote fine grain memory) bypasses the L2, so will; never result in L2 cache lines that need to be invalidated. * PCIe access from the GPU to the CPU memory is kept coherent by using the; MTYPE UC (uncached) which bypasses the L2. Scalar memory operations are only used to access memory that is proven to not; change during the execution of the kernel dispatch. This includes constant; address space and global address space for program scope ``const`` variables.; Therefore, the kernel machine code does not have to maintain the scalar cache to; ensure it is coherent with the vector caches. The scalar and vector caches are; invalidated between kernel dispatches by CP since constant address space data; may change between kernel dispatch executions. See; :ref:`amdgpu-amdhsa-memory-spaces`. The one exception is if scalar writes are used to spill SGPR regi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:239480,cache,cache,239480,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['cache'],['cache']
Performance," x float> @llvm.vp.maximum.v16f32 (<16 x float> <left_op>, <16 x float> <right_op>, <16 x i1> <mask>, i32 <vector_length>); declare <vscale x 4 x float> @llvm.vp.maximum.nxv4f32 (<vscale x 4 x float> <left_op>, <vscale x 4 x float> <right_op>, <vscale x 4 x i1> <mask>, i32 <vector_length>); declare <256 x double> @llvm.vp.maximum.v256f64 (<256 x double> <left_op>, <256 x double> <right_op>, <256 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated floating-point maximum of two vectors of floating-point values,; propagating NaNs and treating -0.0 as less than +0.0. Arguments:; """""""""""""""""""". The first two operands and the result have the same vector of floating-point type. The; third operand is the vector mask and has the same number of elements as the; result vector type. The fourth operand is the explicit vector length of the; operation. Semantics:; """""""""""""""""""". The '``llvm.vp.maximum``' intrinsic performs floating-point maximum (:ref:`maximum <i_maximum>`); of the first and second vector operand on each enabled lane, the result being ; NaN if either operand is a NaN. -0.0 is considered to be less than +0.0 for this; intrinsic. The result on disabled lanes is a :ref:`poison value <poisonvalues>`. ; The operation is performed in the default floating-point environment. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call <4 x float> @llvm.vp.maximum.v4f32(<4 x float> %a, <4 x float> %b, <4 x i1> %mask, i32 %evl); ;; For all lanes below %evl, %r is lane-wise equivalent to %also.r. %t = call <4 x float> @llvm.maximum.v4f32(<4 x float> %a, <4 x float> %b, <4 x i1> %mask, i32 %evl); %also.r = select <4 x i1> %mask, <4 x float> %t, <4 x float> poison. .. _int_vp_fadd:. '``llvm.vp.fadd.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare <16 x float> @llvm.vp.fadd.v16f32 (<16 x float> <left_op>, <16 x float> <right_op>, <16 x i1> <mask>, i32 <vector_length>); declare <vscale x 4 x float> @llvm.vp.",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:731465,perform,performs,731465,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['performs']
Performance," x float> @llvm.vp.minimum.v16f32 (<16 x float> <left_op>, <16 x float> <right_op>, <16 x i1> <mask>, i32 <vector_length>); declare <vscale x 4 x float> @llvm.vp.minimum.nxv4f32 (<vscale x 4 x float> <left_op>, <vscale x 4 x float> <right_op>, <vscale x 4 x i1> <mask>, i32 <vector_length>); declare <256 x double> @llvm.vp.minimum.v256f64 (<256 x double> <left_op>, <256 x double> <right_op>, <256 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated floating-point minimum of two vectors of floating-point values,; propagating NaNs and treating -0.0 as less than +0.0. Arguments:; """""""""""""""""""". The first two operands and the result have the same vector of floating-point type. The; third operand is the vector mask and has the same number of elements as the; result vector type. The fourth operand is the explicit vector length of the; operation. Semantics:; """""""""""""""""""". The '``llvm.vp.minimum``' intrinsic performs floating-point minimum (:ref:`minimum <i_minimum>`); of the first and second vector operand on each enabled lane, the result being ; NaN if either operand is a NaN. -0.0 is considered to be less than +0.0 for this; intrinsic. The result on disabled lanes is a :ref:`poison value <poisonvalues>`. ; The operation is performed in the default floating-point environment. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call <4 x float> @llvm.vp.minimum.v4f32(<4 x float> %a, <4 x float> %b, <4 x i1> %mask, i32 %evl); ;; For all lanes below %evl, %r is lane-wise equivalent to %also.r. %t = call <4 x float> @llvm.minimum.v4f32(<4 x float> %a, <4 x float> %b); %also.r = select <4 x i1> %mask, <4 x float> %t, <4 x float> poison. .. _int_vp_maximum:. '``llvm.vp.maximum.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare <16 x float> @llvm.vp.maximum.v16f32 (<16 x float> <left_op>, <16 x float> <right_op>, <16 x i1> <mask>, i32 <vector_length>); declare <vscale x 4 x float> @llvm.vp.maximum.nxv4f32 (",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:729644,perform,performs,729644,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['performs']
Performance," x i1> %mask, <4 x i32> %t, <4 x i32> poison. .. _int_vp_or:. '``llvm.vp.or.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare <16 x i32> @llvm.vp.or.v16i32 (<16 x i32> <left_op>, <16 x i32> <right_op>, <16 x i1> <mask>, i32 <vector_length>); declare <vscale x 4 x i32> @llvm.vp.or.nxv4i32 (<vscale x 4 x i32> <left_op>, <vscale x 4 x i32> <right_op>, <vscale x 4 x i1> <mask>, i32 <vector_length>); declare <256 x i64> @llvm.vp.or.v256i64 (<256 x i64> <left_op>, <256 x i64> <right_op>, <256 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Vector-predicated or. Arguments:; """""""""""""""""""". The first two operands and the result have the same vector of integer type. The; third operand is the vector mask and has the same number of elements as the; result vector type. The fourth operand is the explicit vector length of the; operation. Semantics:; """""""""""""""""""". The '``llvm.vp.or``' intrinsic performs a bitwise or (:ref:`or <i_or>`) of the; first two operands on each enabled lane. The result on disabled lanes is; a :ref:`poison value <poisonvalues>`. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call <4 x i32> @llvm.vp.or.v4i32(<4 x i32> %a, <4 x i32> %b, <4 x i1> %mask, i32 %evl); ;; For all lanes below %evl, %r is lane-wise equivalent to %also.r. %t = or <4 x i32> %a, %b; %also.r = select <4 x i1> %mask, <4 x i32> %t, <4 x i32> poison. .. _int_vp_and:. '``llvm.vp.and.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare <16 x i32> @llvm.vp.and.v16i32 (<16 x i32> <left_op>, <16 x i32> <right_op>, <16 x i1> <mask>, i32 <vector_length>); declare <vscale x 4 x i32> @llvm.vp.and.nxv4i32 (<vscale x 4 x i32> <left_op>, <vscale x 4 x i32> <right_op>, <vscale x 4 x i1> <mask>, i32 <vector_length>); declare <256 x i64> @llvm.vp.and.v256i64 (<256 x i64> <left_op>, <256 x i64> <right_op>, <256 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Vect",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:712690,perform,performs,712690,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['performs']
Performance," x30, x20, [sp], #16; ret. [...]; __hwasan_check_x0_2_short_v2:; sbfx x16, x0, #4, #52 // shadow offset; ldrb w16, [x20, x16] // load shadow tag; cmp x16, x0, lsr #56 // extract address tag, compare with shadow tag; b.ne .Ltmp0 // jump to short tag handler on mismatch; .Ltmp1:; ret; .Ltmp0:; cmp w16, #15 // is this a short tag?; b.hi .Ltmp2 // if not, error; and x17, x0, #0xf // find the address's position in the short granule; add x17, x17, #3 // adjust to the position of the last byte loaded; cmp w16, w17 // check that position is in bounds; b.ls .Ltmp2 // if not, error; orr x16, x0, #0xf // compute address of last byte of granule; ldrb w16, [x16] // load tag from it; cmp x16, x0, lsr #56 // compare with pointer tag; b.eq .Ltmp1 // if matches, continue; .Ltmp2:; stp x0, x1, [sp, #-256]! // save original x0, x1 on stack (they will be overwritten); stp x29, x30, [sp, #232] // create frame record; mov x1, #2 // set x1 to a constant indicating the type of failure; adrp x16, :got:__hwasan_tag_mismatch_v2 // call runtime function to save remaining registers and report error; ldr x16, [x16, :got_lo12:__hwasan_tag_mismatch_v2] // (load address from GOT to avoid potential register clobbers in delay load handler); br x16. Heap; ----. Tagging the heap memory/pointers is done by `malloc`.; This can be based on any malloc that forces all objects to be TG-aligned.; `free` tags the memory with a different tag. Stack; -----. Stack frames are instrumented by aligning all non-promotable allocas; by `TG` and tagging stack memory in function prologue and epilogue. Tags for different allocas in one function are **not** generated; independently; doing that in a function with `M` allocas would require; maintaining `M` live stack pointers, significantly increasing register; pressure. Instead we generate a single base tag value in the prologue,; and build the tag for alloca number `M` as `ReTag(BaseTag, M)`, where; ReTag can be as simple as exclusive-or with constant `M`. Stack instrument",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/HardwareAssistedAddressSanitizerDesign.rst:5261,load,load,5261,interpreter/llvm-project/clang/docs/HardwareAssistedAddressSanitizerDesign.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/HardwareAssistedAddressSanitizerDesign.rst,2,['load'],['load']
Performance," you; can build and load a shared library containing your script. To load it; use the command `.L` and append the file name with a `+`. ``` {.cpp}; root[] .L MyScript.C+; ```. The + option generates the shared library and names it by taking; the name of the file ""filename"" but replacing the dot before the; extension by an underscore and by adding the shared library extension; for the current platform. For example on most platforms, `hsimple.cxx`; will generate `hsimple_cxx.so`. The + command rebuild the library only if the script or any of the; files it includes are newer than the library. When checking the; timestamp, ACLiC generates a dependency file which name is the same as; the library name, just replacing the 'so' extension by the extension; 'd'. For example on most platforms, `hsimple.cxx` will generate; `hsimple_cxx.d`. To ensure that the shared library is rebuilt you can use the ++; syntax:. ``` {.cpp}; root[] .L MyScript.C++; ```. To build, load, and execute the function with the same name as the; file you can use the `.x` command. This is the same as executing a; named script; you can also provide parameters. The only; difference is you need to append a + or a ++. ``` {.cpp}; root[] .x MyScript.C+(4000); Creating shared library /home/./MyScript_C.so; ```. You can select whether the script in compiled with debug symbol or; with optimization by appending the letter 'g' or 'O' after the '+' or; '++'. Without the specification, the script is compiled with the same; level of debugging symbol and optimization as the currently running; ROOT executable. For example:. ``` {.cpp}; root[] .L MyScript.C++g; ```. will compile `MyScript.C` with debug symbols; usually this means; giving the `-g` option to compiler. ``` {.cpp}; root[] .L MyScript.C++O; ```. will compile `MyScript.C` with optimizations; usually this means; giving the `-O` option to compiler. The syntax:. ``` {.cpp}; root[] .L MyScript.C++; ```. is using the default optimization level. The initial default ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Cling.md:14538,load,load,14538,documentation/users-guide/Cling.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Cling.md,1,['load'],['load']
Performance," your results. \label{f61}][f61]. ## Toy Monte Carlo Experiments ##. Let us look at a simple example of a toy experiment comparing two; methods to fit a function to a histogram, the $\chi^{2}$. method and a method called ""binned log-likelihood fit"", both available in ROOT. As a very simple yet powerful quantity to check the quality of the fit; results, we construct for each pseudo-data set the so-called ""pull"", the; difference of the estimated and the true value of a parameter,; normalised to the estimated error on the parameter,; $\frac{(p_{estim} - p_{true})}{\sigma_{p}}$. If everything is OK, the; distribution of the pull values is a standard normal distribution, i.e.; a Gaussian distribution centred around zero with a standard deviation of one. The macro performs a rather big number of toy experiments, where a; histogram is repeatedly filled with Gaussian distributed numbers,; representing the pseudo-data in this example. Each time, a fit is; performed according to the selected method, and the pull is calculated; and filled into a histogram. Here is the code:. ``` {.cpp .numberLines}; @ROOT_INCLUDE_FILE macros/macro9.C; ```. Your present knowledge of ROOT should be enough to understand all the; technicalities behind the macro. Note that the variable `pull` in line; *61* is different from the definition above: instead of the parameter; error on `mean`, the fitted standard deviation of the distribution; divided by the square root of the number of entries,; `sig/sqrt(n_tot_entries)`, is used. - What method exhibits the better performance with the default; parameters ?. - What happens if you increase the number of entries per histogram by; a factor of ten ? Why ?. The answers to these questions are well beyond the scope of this guide.; Basically all books about statistical methods provide a complete; treatment of the aforementioned topics. [^5]: ""Monte Carlo"" simulation means that random numbers play a role here; which is as crucial as in games of pure chance in the",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/primer/functions_and_parameter_estimation.md:4940,perform,performed,4940,documentation/primer/functions_and_parameter_estimation.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/primer/functions_and_parameter_estimation.md,1,['perform'],['performed']
Performance,"!0 ; Can assume that value under %ptr didn't change; call void @foo(ptr %ptr). %newPtr = call ptr @getPointer(ptr %ptr); %c = load i8, ptr %newPtr, !invariant.group !0 ; Can't assume anything, because we only have information about %ptr. %unknownValue = load i8, ptr @unknownPtr; store i8 %unknownValue, ptr %ptr, !invariant.group !0 ; Can assume that %unknownValue == 42. call void @foo(ptr %ptr); %newPtr2 = call ptr @llvm.launder.invariant.group.p0(ptr %ptr); %d = load i8, ptr %newPtr2, !invariant.group !0 ; Can't step through launder.invariant.group to get value of %ptr. ...; declare void @foo(ptr); declare ptr @getPointer(ptr); declare ptr @llvm.launder.invariant.group.p0(ptr). !0 = !{}. The invariant.group metadata must be dropped when replacing one pointer by; another based on aliasing information. This is because invariant.group is tied; to the SSA value of the pointer operand. .. code-block:: llvm. %v = load i8, ptr %x, !invariant.group !0; ; if %x mustalias %y then we can replace the above instruction with; %v = load i8, ptr %y. Note that this is an experimental feature, which means that its semantics might; change in the future. '``type``' Metadata; ^^^^^^^^^^^^^^^^^^^. See :doc:`TypeMetadata`. '``associated``' Metadata; ^^^^^^^^^^^^^^^^^^^^^^^^^. The ``associated`` metadata may be attached to a global variable definition with; a single argument that references a global object (optionally through an alias). This metadata lowers to the ELF section flag ``SHF_LINK_ORDER`` which prevents; discarding of the global variable in linker GC unless the referenced object is; also discarded. The linker support for this feature is spotty. For best; compatibility, globals carrying this metadata should:. - Be in ``@llvm.compiler.used``.; - If the referenced global variable is in a comdat, be in the same comdat. ``!associated`` can not express many-to-one relationship. A global variable with; the metadata should generally not be referenced by a function: the function may; be",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:317701,load,load,317701,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['load'],['load']
Performance,"!nontemporal !<nontemp_node>][, !invariant.load !<empty_node>][, !invariant.group !<empty_node>][, !nonnull !<empty_node>][, !dereferenceable !<deref_bytes_node>][, !dereferenceable_or_null !<deref_bytes_node>][, !align !<align_node>][, !noundef !<empty_node>]; <result> = load atomic [volatile] <ty>, ptr <pointer> [syncscope(""<target-scope>"")] <ordering>, align <alignment> [, !invariant.group !<empty_node>]; !<nontemp_node> = !{ i32 1 }; !<empty_node> = !{}; !<deref_bytes_node> = !{ i64 <dereferenceable_bytes> }; !<align_node> = !{ i64 <value_alignment> }. Overview:; """""""""""""""""". The '``load``' instruction is used to read from memory. Arguments:; """""""""""""""""""". The argument to the ``load`` instruction specifies the memory address from which; to load. The type specified must be a :ref:`first class <t_firstclass>` type of; known size (i.e. not containing an :ref:`opaque structural type <t_opaque>`). If; the ``load`` is marked as ``volatile``, then the optimizer is not allowed to; modify the number or order of execution of this ``load`` with other; :ref:`volatile operations <volatile>`. If the ``load`` is marked as ``atomic``, it takes an extra :ref:`ordering; <ordering>` and optional ``syncscope(""<target-scope>"")`` argument. The; ``release`` and ``acq_rel`` orderings are not valid on ``load`` instructions.; Atomic loads produce :ref:`defined <memmodel>` results when they may see; multiple atomic stores. The type of the pointee must be an integer, pointer, or; floating-point type whose bit width is a power of two greater than or equal to; eight and less than or equal to a target-specific size limit. ``align`` must be; explicitly specified on atomic loads. Note: if the alignment is not greater or; equal to the size of the `<value>` type, the atomic operation is likely to; require a lock and have poor performance. ``!nontemporal`` does not have any; defined semantics for atomic loads. The optional constant ``align`` argument specifies the alignment of the; operation (that is,",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:412879,load,load,412879,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,3,"['load', 'optimiz']","['load', 'optimizer']"
Performance,""""""""""""""""""". The '``llvm.experimental.constrained.fcmp``' and; '``llvm.experimental.constrained.fcmps``' intrinsics return a boolean; value or vector of boolean values based on comparison of its operands. If the operands are floating-point scalars, then the result type is a; boolean (:ref:`i1 <t_integer>`). If the operands are floating-point vectors, then the result type is a; vector of boolean with the same number of elements as the operands being; compared. The '``llvm.experimental.constrained.fcmp``' intrinsic performs a quiet; comparison operation while the '``llvm.experimental.constrained.fcmps``'; intrinsic performs a signaling comparison operation. Arguments:; """""""""""""""""""". The first two arguments to the '``llvm.experimental.constrained.fcmp``'; and '``llvm.experimental.constrained.fcmps``' intrinsics must be; :ref:`floating-point <t_floating>` or :ref:`vector <t_vector>`; of floating-point values. Both arguments must have identical types. The third argument is the condition code indicating the kind of comparison; to perform. It must be a metadata string with one of the following values:. .. _fcmp_md_cc:. - ""``oeq``"": ordered and equal; - ""``ogt``"": ordered and greater than; - ""``oge``"": ordered and greater than or equal; - ""``olt``"": ordered and less than; - ""``ole``"": ordered and less than or equal; - ""``one``"": ordered and not equal; - ""``ord``"": ordered (no nans); - ""``ueq``"": unordered or equal; - ""``ugt``"": unordered or greater than; - ""``uge``"": unordered or greater than or equal; - ""``ult``"": unordered or less than; - ""``ule``"": unordered or less than or equal; - ""``une``"": unordered or not equal; - ""``uno``"": unordered (either nans). *Ordered* means that neither operand is a NAN while *unordered* means; that either operand may be a NAN. The fourth argument specifies the exception behavior as described above. Semantics:; """""""""""""""""""". ``op1`` and ``op2`` are compared according to the condition code given; as the third argument. If the operands are vectors, ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:884507,perform,perform,884507,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['perform']
Performance,""""""""""""""""""". The '``llvm.experimental.vp.reverse.*``' intrinsic is the vector length; predicated version of the '``llvm.experimental.vector.reverse.*``' intrinsic. Arguments:; """""""""""""""""""". The result and the first argument ``vec`` are vectors with the same type.; The second argument ``mask`` is a vector mask and has the same number of; elements as the result. The third argument is the explicit vector length of; the operation. Semantics:; """""""""""""""""""". This intrinsic reverses the order of the first ``evl`` elements in a vector.; The lanes in the result vector disabled by ``mask`` are ``poison``. The; elements past ``evl`` are poison. .. _int_vp_load:. '``llvm.vp.load``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare <4 x float> @llvm.vp.load.v4f32.p0(ptr %ptr, <4 x i1> %mask, i32 %evl); declare <vscale x 2 x i16> @llvm.vp.load.nxv2i16.p0(ptr %ptr, <vscale x 2 x i1> %mask, i32 %evl); declare <8 x float> @llvm.vp.load.v8f32.p1(ptr addrspace(1) %ptr, <8 x i1> %mask, i32 %evl); declare <vscale x 1 x i64> @llvm.vp.load.nxv1i64.p6(ptr addrspace(6) %ptr, <vscale x 1 x i1> %mask, i32 %evl). Overview:; """""""""""""""""". The '``llvm.vp.load.*``' intrinsic is the vector length predicated version of; the :ref:`llvm.masked.load <int_mload>` intrinsic. Arguments:; """""""""""""""""""". The first operand is the base pointer for the load. The second operand is a; vector of boolean values with the same number of elements as the return type.; The third is the explicit vector length of the operation. The return type and; underlying type of the base pointer are the same vector types. The :ref:`align <attr_align>` parameter attribute can be provided for the first; operand. Semantics:; """""""""""""""""""". The '``llvm.vp.load``' intrinsic reads a vector from memory in the same way as; the '``llvm.masked.load``' intrinsic, where the mask is taken from the; combination of the '``mask``' and '``evl``' operands in the usual VP way.; Certain '``ll",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:783235,load,load,783235,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['load'],['load']
Performance,""""""""""""""""""". The integer operand is the loop trip count of the hardware-loop, and thus; not e.g. the loop back-edge taken count. Semantics:; """""""""""""""""""". The '``llvm.start.loop.iterations.*``' intrinsics do not perform any arithmetic; on their operand. It's a hint to the backend that can use this to set up the; hardware-loop count with a target specific instruction, usually a move of this; value to a special register or a hardware-loop instruction. '``llvm.test.set.loop.iterations.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". This is an overloaded intrinsic. ::. declare i1 @llvm.test.set.loop.iterations.i32(i32); declare i1 @llvm.test.set.loop.iterations.i64(i64). Overview:; """""""""""""""""". The '``llvm.test.set.loop.iterations.*``' intrinsics are used to specify the; the loop trip count, and also test that the given count is not zero, allowing; it to control entry to a while-loop. They are placed in the loop preheader's; predecessor basic block, and are marked as ``IntrNoDuplicate`` to avoid; optimizers duplicating these instructions. Arguments:; """""""""""""""""""". The integer operand is the loop trip count of the hardware-loop, and thus; not e.g. the loop back-edge taken count. Semantics:; """""""""""""""""""". The '``llvm.test.set.loop.iterations.*``' intrinsics do not perform any; arithmetic on their operand. It's a hint to the backend that can use this to; set up the hardware-loop count with a target specific instruction, usually a; move of this value to a special register or a hardware-loop instruction.; The result is the conditional value of whether the given count is not zero. '``llvm.test.start.loop.iterations.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". This is an overloaded intrinsic. ::. declare {i32, i1} @llvm.test.start.loop.iterations.i32(i32); declare {i64, i1} @llvm.test.start.loop.iterations.i64(i64). Overview:; """""""""""""""""". The '``llvm.test.start.loop.iterations.*``' intrinsics are similar to the; '`",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:645823,optimiz,optimizers,645823,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['optimiz'],['optimizers']
Performance,""""""""""""""""". The first operand is the base pointer for the load. The second operand is the alignment of the source location. It must be a power of two constant integer value. The third operand, mask, is a vector of boolean values with the same number of elements as the return type. The fourth is a pass-through value that is used to fill the masked-off lanes of the result. The return type, underlying type of the base pointer and the type of the '``passthru``' operand are the same vector types. Semantics:; """""""""""""""""""". The '``llvm.masked.load``' intrinsic is designed for conditional reading of selected vector elements in a single IR operation. It is useful for targets that support vector masked loads and allows vectorizing predicated basic blocks on these targets. Other targets may support this intrinsic differently, for example by lowering it into a sequence of branches that guard scalar load operations.; The result of this operation is equivalent to a regular vector load instruction followed by a 'select' between the loaded and the passthru values, predicated on the same mask. However, using this intrinsic prevents exceptions on memory access to masked-off lanes. ::. %res = call <16 x float> @llvm.masked.load.v16f32.p0(ptr %ptr, i32 4, <16 x i1>%mask, <16 x float> %passthru). ;; The result of the two following instructions is identical aside from potential memory access exception; %loadlal = load <16 x float>, ptr %ptr, align 4; %res = select <16 x i1> %mask, <16 x float> %loadlal, <16 x float> %passthru. .. _int_mstore:. '``llvm.masked.store.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. The data stored in memory is a vector of any integer, floating-point or pointer data type. ::. declare void @llvm.masked.store.v8i32.p0 (<8 x i32> <value>, ptr <ptr>, i32 <alignment>, <8 x i1> <mask>); declare void @llvm.masked.store.v16f32.p0(<16 x float> <value>, ptr <ptr>, i32 <alignment>, <16 x i1> <mask>); ;; The data is a ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:845020,load,load,845020,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,2,['load'],"['load', 'loaded']"
Performance,""""""""""""""". ::. <result> = frem [fast-math flags]* <ty> <op1>, <op2> ; yields ty:result. Overview:; """""""""""""""""". The '``frem``' instruction returns the remainder from the division of; its two operands. .. note::. 	The instruction is implemented as a call to libm's '``fmod``'; 	for some targets, and using the instruction may thus require linking libm. Arguments:; """""""""""""""""""". The two arguments to the '``frem``' instruction must be; :ref:`floating-point <t_floating>` or :ref:`vector <t_vector>` of; floating-point values. Both arguments must have identical types. Semantics:; """""""""""""""""""". The value produced is the floating-point remainder of the two operands.; This is the same output as a libm '``fmod``' function, but without any; possibility of setting ``errno``. The remainder has the same sign as the; dividend.; This instruction is assumed to execute in the default :ref:`floating-point; environment <floatenv>`.; This instruction can also take any number of :ref:`fast-math; flags <fastmath>`, which are optimization hints to enable otherwise; unsafe floating-point optimizations:. Example:; """""""""""""""". .. code-block:: text. <result> = frem float 4.0, %var ; yields float:result = 4.0 % %var. .. _bitwiseops:. Bitwise Binary Operations; -------------------------. Bitwise binary operators are used to do various forms of bit-twiddling; in a program. They are generally very efficient instructions and can; commonly be strength reduced from other instructions. They require two; operands of the same type, execute an operation on them, and produce a; single value. The resulting value is the same type as its operands. .. _i_shl:. '``shl``' Instruction; ^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. <result> = shl <ty> <op1>, <op2> ; yields ty:result; <result> = shl nuw <ty> <op1>, <op2> ; yields ty:result; <result> = shl nsw <ty> <op1>, <op2> ; yields ty:result; <result> = shl nuw nsw <ty> <op1>, <op2> ; yields ty:result. Overview:; """""""""""""""""". The '``shl``' instruction returns the first opera",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:391736,optimiz,optimization,391736,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,2,['optimiz'],"['optimization', 'optimizations']"
Performance,"""""""""""""""; This is an overloaded intrinsic. ::. declare i32 @llvm.vp.reduce.add.v4i32(i32 <start_value>, <4 x i32> <val>, <4 x i1> <mask>, i32 <vector_length>); declare i16 @llvm.vp.reduce.add.nxv8i16(i16 <start_value>, <vscale x 8 x i16> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated integer ``ADD`` reduction of a vector and a scalar starting value,; returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value of the reduction, which must be a scalar; integer type equal to the result type. The second operand is the vector on; which the reduction is performed and must be a vector of integer values whose; element type is the result/start type. The third operand is the vector mask and; is a vector of boolean values with the same number of elements as the vector; operand. The fourth operand is the explicit vector length of the operation. Semantics:; """""""""""""""""""". The '``llvm.vp.reduce.add``' intrinsic performs the integer ``ADD`` reduction; (:ref:`llvm.vector.reduce.add <int_vector_reduce_add>`) of the vector operand; ``val`` on each enabled lane, adding it to the scalar ``start_value``. Disabled; lanes are treated as containing the neutral value ``0`` (i.e. having no effect; on the reduction operation). If the vector length is zero, the result is equal; to ``start_value``. To ignore the start value, the neutral value can be used. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call i32 @llvm.vp.reduce.add.v4i32(i32 %start, <4 x i32> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equal to %evl; ; are treated as though %mask were false for those lanes. %masked.a = select <4 x i1> %mask, <4 x i32> %a, <4 x i32> zeroinitializer; %reduction = call i32 @llvm.vector.reduce.add.v4i32(<4 x i32> %masked.a); %also.r = add i32 %reduction, %start. .. _int_vp_reduce_fadd:. '``llvm.vp.reduce.fadd.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:749333,perform,performs,749333,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['performs']
Performance,"""""""""""""""; This is an overloaded intrinsic. ::. declare i32 @llvm.vp.reduce.and.v4i32(i32 <start_value>, <4 x i32> <val>, <4 x i1> <mask>, i32 <vector_length>); declare i16 @llvm.vp.reduce.and.nxv8i16(i16 <start_value>, <vscale x 8 x i16> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated integer ``AND`` reduction of a vector and a scalar starting value,; returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value of the reduction, which must be a scalar; integer type equal to the result type. The second operand is the vector on; which the reduction is performed and must be a vector of integer values whose; element type is the result/start type. The third operand is the vector mask and; is a vector of boolean values with the same number of elements as the vector; operand. The fourth operand is the explicit vector length of the operation. Semantics:; """""""""""""""""""". The '``llvm.vp.reduce.and``' intrinsic performs the integer ``AND`` reduction; (:ref:`llvm.vector.reduce.and <int_vector_reduce_and>`) of the vector operand; ``val`` on each enabled lane, performing an '``and``' of that with with the; scalar ``start_value``. Disabled lanes are treated as containing the neutral; value ``UINT_MAX``, or ``-1`` (i.e. having no effect on the reduction; operation). If the vector length is zero, the result is the start value. To ignore the start value, the neutral value can be used. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call i32 @llvm.vp.reduce.and.v4i32(i32 %start, <4 x i32> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equal to %evl; ; are treated as though %mask were false for those lanes. %masked.a = select <4 x i1> %mask, <4 x i32> %a, <4 x i32> <i32 -1, i32 -1, i32 -1, i32 -1>; %reduction = call i32 @llvm.vector.reduce.and.v4i32(<4 x i32> %masked.a); %also.r = and i32 %reduction, %start. .. _int_vp_reduce_or:. '``llvm.vp.reduce.or.*``' Intrinsics; ^^^^^^^",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:757733,perform,performs,757733,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['performs']
Performance,"""""""""""""""; This is an overloaded intrinsic. ::. declare i32 @llvm.vp.reduce.mul.v4i32(i32 <start_value>, <4 x i32> <val>, <4 x i1> <mask>, i32 <vector_length>); declare i16 @llvm.vp.reduce.mul.nxv8i16(i16 <start_value>, <vscale x 8 x i16> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated integer ``MUL`` reduction of a vector and a scalar starting value,; returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value of the reduction, which must be a scalar; integer type equal to the result type. The second operand is the vector on; which the reduction is performed and must be a vector of integer values whose; element type is the result/start type. The third operand is the vector mask and; is a vector of boolean values with the same number of elements as the vector; operand. The fourth operand is the explicit vector length of the operation. Semantics:; """""""""""""""""""". The '``llvm.vp.reduce.mul``' intrinsic performs the integer ``MUL`` reduction; (:ref:`llvm.vector.reduce.mul <int_vector_reduce_mul>`) of the vector operand ``val``; on each enabled lane, multiplying it by the scalar ``start_value``. Disabled; lanes are treated as containing the neutral value ``1`` (i.e. having no effect; on the reduction operation). If the vector length is zero, the result is the; start value. To ignore the start value, the neutral value can be used. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call i32 @llvm.vp.reduce.mul.v4i32(i32 %start, <4 x i32> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equal to %evl; ; are treated as though %mask were false for those lanes. %masked.a = select <4 x i1> %mask, <4 x i32> %a, <4 x i32> <i32 1, i32 1, i32 1, i32 1>; %reduction = call i32 @llvm.vector.reduce.mul.v4i32(<4 x i32> %masked.a); %also.r = mul i32 %reduction, %start. .. _int_vp_reduce_fmul:. '``llvm.vp.reduce.fmul.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:753536,perform,performs,753536,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['performs']
Performance,"""""""""""""""; This is an overloaded intrinsic. ::. declare i32 @llvm.vp.reduce.xor.v4i32(i32 <start_value>, <4 x i32> <val>, <4 x i1> <mask>, i32 <vector_length>); declare i16 @llvm.vp.reduce.xor.nxv8i16(i16 <start_value>, <vscale x 8 x i16> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated integer ``XOR`` reduction of a vector and a scalar starting value,; returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value of the reduction, which must be a scalar; integer type equal to the result type. The second operand is the vector on; which the reduction is performed and must be a vector of integer values whose; element type is the result/start type. The third operand is the vector mask and; is a vector of boolean values with the same number of elements as the vector; operand. The fourth operand is the explicit vector length of the operation. Semantics:; """""""""""""""""""". The '``llvm.vp.reduce.xor``' intrinsic performs the integer ``XOR`` reduction; (:ref:`llvm.vector.reduce.xor <int_vector_reduce_xor>`) of the vector operand; ``val`` on each enabled lane, performing an '``xor``' of that with the scalar; ``start_value``. Disabled lanes are treated as containing the neutral value; ``0`` (i.e. having no effect on the reduction operation). If the vector length; is zero, the result is the start value. To ignore the start value, the neutral value can be used. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call i32 @llvm.vp.reduce.xor.v4i32(i32 %start, <4 x i32> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equal to %evl; ; are treated as though %mask were false for those lanes. %masked.a = select <4 x i1> %mask, <4 x i32> %a, <4 x i32> <i32 0, i32 0, i32 0, i32 0>; %reduction = call i32 @llvm.vector.reduce.xor.v4i32(<4 x i32> %masked.a); %also.r = xor i32 %reduction, %start. .. _int_vp_reduce_smax:. '``llvm.vp.reduce.smax.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:761781,perform,performs,761781,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['performs']
Performance,""""""""". The '``llvm.convert.to.fp16``' intrinsic function performs a conversion from a; conventional floating-point format to half precision floating-point format. The; return value is an ``i16`` which contains the converted number. Examples:; """""""""""""""""". .. code-block:: llvm. %res = call i16 @llvm.convert.to.fp16.f32(float %a); store i16 %res, i16* @x, align 2. .. _int_convert_from_fp16:. '``llvm.convert.from.fp16``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare float @llvm.convert.from.fp16.f32(i16 %a); declare double @llvm.convert.from.fp16.f64(i16 %a). Overview:; """""""""""""""""". The '``llvm.convert.from.fp16``' intrinsic function performs a; conversion from half precision floating-point format to single precision; floating-point format. Arguments:; """""""""""""""""""". The intrinsic function contains single argument - the value to be; converted. Semantics:; """""""""""""""""""". The '``llvm.convert.from.fp16``' intrinsic function performs a; conversion from half single precision floating-point format to single; precision floating-point format. The input half-float value is; represented by an ``i16`` value. Examples:; """""""""""""""""". .. code-block:: llvm. %a = load i16, ptr @x, align 2; %res = call float @llvm.convert.from.fp16(i16 %a). Saturating floating-point to integer conversions; ------------------------------------------------. The ``fptoui`` and ``fptosi`` instructions return a; :ref:`poison value <poisonvalues>` if the rounded-towards-zero value is not; representable by the result type. These intrinsics provide an alternative; conversion, which will saturate towards the smallest and largest representable; integer values instead. '``llvm.fptoui.sat.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". This is an overloaded intrinsic. You can use ``llvm.fptoui.sat`` on any; floating-point argument type and any integer result type, or vectors thereof.; Not all targets may support all types, however. ::. declare i32 @llvm.fptoui.sat.i32.f32",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:682924,perform,performs,682924,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['performs']
Performance,"""""""""; This is an overloaded intrinsic. ::. declare <16 x i32> @llvm.vp.merge.v16i32 (<16 x i1> <condition>, <16 x i32> <on_true>, <16 x i32> <on_false>, i32 <pivot>); declare <vscale x 4 x i64> @llvm.vp.merge.nxv4i64 (<vscale x 4 x i1> <condition>, <vscale x 4 x i64> <on_true>, <vscale x 4 x i64> <on_false>, i32 <pivot>). Overview:; """""""""""""""""". The '``llvm.vp.merge``' intrinsic is used to choose one value based on a; condition vector and an index operand, without IR-level branching. Arguments:; """""""""""""""""""". The first operand is a vector of ``i1`` and indicates the condition. The; second operand is the value that is merged where the condition vector is true.; The third operand is the value that is selected where the condition vector is; false or the lane position is greater equal than the pivot. The fourth operand; is the pivot. #. The optional ``fast-math flags`` marker indicates that the merge has one or; more :ref:`fast-math flags <fastmath>`. These are optimization hints to; enable otherwise unsafe floating-point optimizations. Fast-math flags are; only valid for merges that return a floating-point scalar or vector type,; or an array (nested to any depth) of floating-point scalar or vector types. Semantics:; """""""""""""""""""". The intrinsic selects lanes from the second and third operand depending on a; condition vector and pivot value. For all lanes where the condition vector is true and the lane position is less; than ``%pivot`` the lane is taken from the second operand. Otherwise, the lane; is taken from the third operand. Example:; """""""""""""""". .. code-block:: llvm. %r = call <4 x i32> @llvm.vp.merge.v4i32(<4 x i1> %cond, <4 x i32> %on_true, <4 x i32> %on_false, i32 %pivot). ;;; Expansion.; ;; Lanes at and above %pivot are taken from %on_false; %atfirst = insertelement <4 x i32> undef, i32 %pivot, i32 0; %splat = shufflevector <4 x i32> %atfirst, <4 x i32> poison, <4 x i32> zeroinitializer; %pivotmask = icmp ult <4 x i32> <i32 0, i32 1, i32 2, i32 3>, <4 x i32> %splat; %m",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:696123,optimiz,optimization,696123,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,2,['optimiz'],"['optimization', 'optimizations']"
Performance,""""""". .. code-block:: text. call void @llvm.vp.store.v8i8.p0(<8 x i8> %val, ptr align 4 %ptr, <8 x i1> %mask, i32 %evl); ;; For all lanes below %evl, the call above is lane-wise equivalent to the call below. call void @llvm.masked.store.v8i8.p0(<8 x i8> %val, ptr %ptr, i32 4, <8 x i1> %mask). .. _int_experimental_vp_strided_load:. '``llvm.experimental.vp.strided.load``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare <4 x float> @llvm.experimental.vp.strided.load.v4f32.i64(ptr %ptr, i64 %stride, <4 x i1> %mask, i32 %evl); declare <vscale x 2 x i16> @llvm.experimental.vp.strided.load.nxv2i16.i64(ptr %ptr, i64 %stride, <vscale x 2 x i1> %mask, i32 %evl). Overview:; """""""""""""""""". The '``llvm.experimental.vp.strided.load``' intrinsic loads, into a vector, scalar values from; memory locations evenly spaced apart by '``stride``' number of bytes, starting from '``ptr``'. Arguments:; """""""""""""""""""". The first operand is the base pointer for the load. The second operand is the stride; value expressed in bytes. The third operand is a vector of boolean values; with the same number of elements as the return type. The fourth is the explicit; vector length of the operation. The base pointer underlying type matches the type of the scalar; elements of the return operand. The :ref:`align <attr_align>` parameter attribute can be provided for the first; operand. Semantics:; """""""""""""""""""". The '``llvm.experimental.vp.strided.load``' intrinsic loads, into a vector, multiple scalar; values from memory in the same way as the :ref:`llvm.vp.gather <int_vp_gather>` intrinsic,; where the vector of pointers is in the form:. ``%ptrs = <%ptr, %ptr + %stride, %ptr + 2 * %stride, ... >``,. with '``ptr``' previously casted to a pointer '``i8``', '``stride``' always interpreted as a signed; integer and all arithmetic occurring in the pointer type. Examples:; """""""""""""""""". .. code-block:: text. 	 %r = call <8 x i64> @llvm.experimental.vp",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:787725,load,load,787725,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['load'],['load']
Performance,""""". This function multiplies the first argument by 2 raised to the second; argument's power. If the first argument is NaN or infinite, the same; value is returned. If the result underflows a zero with the same sign; is returned. If the result overflows, the result is an infinity with; the same sign. .. _int_frexp:. '``llvm.frexp.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". This is an overloaded intrinsic. You can use ``llvm.frexp`` on any; floating point or vector of floating point type. Not all targets support; all types however. ::. declare { float, i32 } @llvm.frexp.f32.i32(float %Val); declare { double, i32 } @llvm.frexp.f64.i32(double %Val); declare { x86_fp80, i32 } @llvm.frexp.f80.i32(x86_fp80 %Val); declare { fp128, i32 } @llvm.frexp.f128.i32(fp128 %Val); declare { ppc_fp128, i32 } @llvm.frexp.ppcf128.i32(ppc_fp128 %Val); declare { <2 x float>, <2 x i32> } @llvm.frexp.v2f32.v2i32(<2 x float> %Val). Overview:; """""""""""""""""". The '``llvm.frexp.*``' intrinsics perform the frexp function. Arguments:; """""""""""""""""""". The argument is a :ref:`floating-point <t_floating>` or; :ref:`vector <t_vector>` of floating-point values. Returns two values; in a struct. The first struct field matches the argument type, and the; second field is an integer or a vector of integer values with the same; number of elements as the argument. Semantics:; """""""""""""""""""". This intrinsic splits a floating point value into a normalized; fractional component and integral exponent. For a non-zero argument, returns the argument multiplied by some power; of two such that the absolute value of the returned value is in the; range [0.5, 1.0), with the same sign as the argument. The second; result is an integer such that the first result raised to the power of; the second result is the input argument. If the argument is a zero, returns a zero with the same sign and a 0; exponent. If the argument is a NaN, a NaN is returned and the returned exponent; is unspecified. If the argument is an infin",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:566431,perform,perform,566431,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['perform']
Performance,""""". This is an overloaded intrinsic. You can use ``llvm.sdiv.fix``; on any integer bit width or vectors of integers. ::. declare i16 @llvm.sdiv.fix.i16(i16 %a, i16 %b, i32 %scale); declare i32 @llvm.sdiv.fix.i32(i32 %a, i32 %b, i32 %scale); declare i64 @llvm.sdiv.fix.i64(i64 %a, i64 %b, i32 %scale); declare <4 x i32> @llvm.sdiv.fix.v4i32(<4 x i32> %a, <4 x i32> %b, i32 %scale). Overview; """""""""""""""""". The '``llvm.sdiv.fix``' family of intrinsic functions perform signed; fixed point division on 2 arguments of the same scale. Arguments; """""""""""""""""""". The arguments (%a and %b) and the result may be of integer types of any bit; width, but they must have the same bit width. The arguments may also work with; int vectors of the same length and int size. ``%a`` and ``%b`` are the two; values that will undergo signed fixed point division. The argument; ``%scale`` represents the scale of both operands, and must be a constant; integer. Semantics:; """""""""""""""""""". This operation performs fixed point division on the 2 arguments of a; specified scale. The result will also be returned in the same scale specified; in the third argument. If the result value cannot be precisely represented in the given scale, the; value is rounded up or down to the closest representable value. The rounding; direction is unspecified. It is undefined behavior if the result value does not fit within the range of; the fixed point type, or if the second argument is zero. Examples; """""""""""""""""". .. code-block:: llvm. %res = call i4 @llvm.sdiv.fix.i4(i4 6, i4 2, i32 0) ; %res = 3 (6 / 2 = 3); %res = call i4 @llvm.sdiv.fix.i4(i4 6, i4 4, i32 1) ; %res = 3 (3 / 2 = 1.5); %res = call i4 @llvm.sdiv.fix.i4(i4 3, i4 -2, i32 1) ; %res = -3 (1.5 / -1 = -1.5). ; The result in the following could be rounded up to 1 or down to 0.5; %res = call i4 @llvm.sdiv.fix.i4(i4 3, i4 4, i32 1) ; %res = 2 (or 1) (1.5 / 2 = 0.75). '``llvm.udiv.fix.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax; """""""""""""". This is an overloaded intrins",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:630959,perform,performs,630959,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['performs']
Performance,"""${CMAKE_CURRENT_SOURCE_DIR}/../${proj}""); if(NOT EXISTS ""${PROJ_DIR}"" OR NOT IS_DIRECTORY ""${PROJ_DIR}""); message(FATAL_ERROR ""LLVM_ENABLE_PROJECTS requests ${proj} but directory not found: ${PROJ_DIR}""); endif(); if( LLVM_EXTERNAL_${upper_proj}_SOURCE_DIR STREQUAL """" ); set(LLVM_EXTERNAL_${upper_proj}_SOURCE_DIR ""${CMAKE_CURRENT_SOURCE_DIR}/../${proj}"" CACHE PATH """" FORCE); else(); set(LLVM_EXTERNAL_${upper_proj}_SOURCE_DIR ""${CMAKE_CURRENT_SOURCE_DIR}/../${proj}"" CACHE PATH """"); endif(); elseif (""${proj}"" IN_LIST LLVM_EXTERNAL_PROJECTS); message(STATUS ""${proj} project is enabled""); set(SHOULD_ENABLE_PROJECT TRUE); else(); message(STATUS ""${proj} project is disabled""); set(SHOULD_ENABLE_PROJECT FALSE); endif(); # Force `LLVM_TOOL_${upper_proj}_BUILD` variables to have values that; # corresponds with `LLVM_ENABLE_PROJECTS`. This prevents the user setting; # `LLVM_TOOL_${upper_proj}_BUILD` variables externally. At some point; # we should deprecate allowing users to set these variables by turning them; # into normal CMake variables rather than cache variables.; set(LLVM_TOOL_${upper_proj}_BUILD; ${SHOULD_ENABLE_PROJECT}; CACHE; BOOL ""Whether to build ${upper_proj} as part of LLVM"" FORCE; ); endforeach(); endif(); unset(SHOULD_ENABLE_PROJECT). # Build llvm with ccache if the package is present; set(LLVM_CCACHE_BUILD OFF CACHE BOOL ""Set to ON for a ccache enabled build""); if(LLVM_CCACHE_BUILD); find_program(CCACHE_PROGRAM ccache); if(CCACHE_PROGRAM); set(LLVM_CCACHE_MAXSIZE """" CACHE STRING ""Size of ccache""); set(LLVM_CCACHE_DIR """" CACHE STRING ""Directory to keep ccached data""); set(LLVM_CCACHE_PARAMS ""CCACHE_CPP2=yes CCACHE_HASHDIR=yes""; CACHE STRING ""Parameters to pass through to ccache""). if(NOT CMAKE_SYSTEM_NAME MATCHES ""Windows""); set(CCACHE_PROGRAM ""${LLVM_CCACHE_PARAMS} ${CCACHE_PROGRAM}""); if (LLVM_CCACHE_MAXSIZE); set(CCACHE_PROGRAM ""CCACHE_MAXSIZE=${LLVM_CCACHE_MAXSIZE} ${CCACHE_PROGRAM}""); endif(); if (LLVM_CCACHE_DIR); set(CCACHE_PROGRAM ""CCACHE_DIR=${LLVM_C",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/CMakeLists.txt:10190,cache,cache,10190,interpreter/llvm-project/llvm/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/CMakeLists.txt,1,['cache'],['cache']
Performance,""",-20,20) ;; x.setBins(1000,""cache"") ;. // End point shapes : a gaussian on one end, a polynomial on the other; RooGaussian f1(""f1"",""f1"",x,RooConst(-10),RooConst(2)) ;; RooPolynomial f2(""f2"",""f2"",x,RooArgSet(RooConst(-0.03),RooConst(-0.001))) ;. // Interpolation parameter: rlm=f1 at alpha=0, rlm=f2 at alpha=1; RooRealVar alpha(""alpha"",""alpha"",0,1.0) ;; RooLinearMorph rlm(""rlm"",""rlm"",g1,g2,x,alpha) ;. // Plot halfway shape; alpha=0.5; RooPlot* frame = x.frame() ;; rlm.plotOn(frame) ;. In short the algorithm works as follows: for both f1(x) and f2(x), the cumulative distribution; functions F1(x) and F2(x) are calculated. One finds takes a value 'y' of both c.d.fs and ; determines the corresponding x values x1,x2 at which F1(x1)=F2(x2)=y. The value of the interpolated ; p.d.f fbar(x) is then calculated as fbar(alpha*x1+(1-alpha)*x2) = f1(x1)*f2(x2) / ( alpha*f2(x2) + ; (1-alpha)*f1(x1) ). Given that it is not easily possible to calculate the value of RooLinearMorph; at a given value of x, the value for all values of x are calculated in one by (through a scan over y); and stored in a cache. NB: The range of the interpolation parameter does not need to be [0,1], it can; be anything. New workspace tool RooSimWSTool. A new tool to clone and customize p.d.f.s into a RooSimultaneous p.d.f has been added. This new; tool succeeds the original RooSimPdfBuilder tool which had a similar functionality but; has a much cleaner interface, partly thanks to its use of the RooWorkspace class for both input; of prototype p.d.fs and output of built p.d.f.s. The simplest use case to to take a workspace p.d.f as prototype and 'split' a parameter of that p.d.f ; into two specialized parameters depending on a category in the dataset. ; For example, given a Gaussian p.d.f G(x,m,s) we want to construct a G_a(x,m_a,s) and a G_b(x,m_b,s); with different mean parameters to be fit to a dataset with observables; (x,c) where c is a category with states 'a' and 'b'.; Using RooSimWSTool one can create a",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html:11305,cache,cache,11305,roofit/doc/v520/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html,2,['cache'],['cache']
Performance,"""IEEE""; ""support_math_errno"", ""on"", ""on"", ""off""; ""no_honor_nans"", ""off"", ""off"", ""on""; ""no_honor_infinities"", ""off"", ""off"", ""on""; ""no_signed_zeros"", ""off"", ""off"", ""on""; ""allow_reciprocal"", ""off"", ""off"", ""on""; ""allow_approximate_fns"", ""off"", ""off"", ""on""; ""allow_reassociation"", ""off"", ""off"", ""on"". .. option:: -ffast-math. Enable fast-math mode. This option lets the; compiler make aggressive, potentially-lossy assumptions about; floating-point math. These include:. * Floating-point math obeys regular algebraic rules for real numbers (e.g.; ``+`` and ``*`` are associative, ``x/y == x * (1/y)``, and; ``(a + b) * c == a * c + b * c``),; * Operands to floating-point operations are not equal to ``NaN`` and; ``Inf``, and; * ``+0`` and ``-0`` are interchangeable. ``-ffast-math`` also defines the ``__FAST_MATH__`` preprocessor; macro. Some math libraries recognize this macro and change their behavior.; With the exception of ``-ffp-contract=fast``, using any of the options; below to disable any of the individual optimizations in ``-ffast-math``; will cause ``__FAST_MATH__`` to no longer be set.; ``-ffast-math`` enables ``-fcx-limited-range``. This option implies:. * ``-fno-honor-infinities``. * ``-fno-honor-nans``. * ``-fapprox-func``. * ``-fno-math-errno``. * ``-ffinite-math-only``. * ``-fassociative-math``. * ``-freciprocal-math``. * ``-fno-signed-zeros``. * ``-fno-trapping-math``. * ``-fno-rounding-math``. * ``-ffp-contract=fast``. Note: ``-ffast-math`` causes ``crtfastmath.o`` to be linked with code. See; :ref:`crtfastmath.o` for more details. .. option:: -fno-fast-math. Disable fast-math mode. This options disables unsafe floating-point; optimizations by preventing the compiler from making any transformations that; could affect the results. This option implies:. * ``-fhonor-infinities``. * ``-fhonor-nans``. * ``-fno-approx-func``. * ``-fno-finite-math-only``. * ``-fno-associative-math``. * ``-fno-reciprocal-math``. * ``-fsigned-zeros``. * ``-ffp-contract=on``. Also, this op",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:52490,optimiz,optimizations,52490,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,1,['optimiz'],['optimizations']
Performance,"""Test builder"");; root[] geom->Edit(Option_t *option="""");; ```. The lines above will create a new **`TGeoManager`** class, create an; empty canvas and start the editor in the left-sided editor frame; attached to the canvas. To open the editor in a separate frame one; should provide a non-empty string as option to the `Edit()` method. ![The geometry manager editor](pictures/030001E9.png). ### The Geometry Manager Editor. ![Accessing/creating different categories of editable; objects](pictures/020001EA.jpg) ![Accessing/creating different; categories of editable objects](pictures/020001EB.jpg); ![Accessing/creating different categories of editable; objects](pictures/020001EC.jpg) ![Accessing/creating different; categories of editable objects](pictures/020001ED.jpg); ![Accessing/creating different categories of editable; objects](pictures/020001EE.jpg). The second use case applies when starting to edit an existing geometry.; Supposing the geometry was loaded into memory, besides the first method; that still applies one can also edit drawn geometry objects. For this,; the menu entry View/Editor of the canvas containing for instance a drawn; volume must be activated. For starting the volume editor one can click; on a volume. The GUI of the **`TGeoManager`** class can be started by; clicking on the top-right `40x40` pixels corner of the pad with a drawn; geometry. This is the main entry point for editing the geometry or creating new; objects. Once the interface is created (using one of the methods; described above), several categories can be accessed via a shutter GUI; widget:. - *General.* This allows changing the name/title of the geometry,; setting the top volume, closing the geometry and saving the geometry; in a file. The file name is formed by `geometry_name.C` or `.root`; depending if the geometry need to be saved as a `C` macro or a; `.root` file.; - *Shapes.* The category provides buttons for creation of all; supported shapes. The new shape name is chosen by the in",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md:167207,load,loaded,167207,documentation/users-guide/Geometry.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md,1,['load'],['loaded']
Performance,"""Verdana"", fontsize=""12""];; node [fontname=""Verdana"", fontsize=""12""];; edge [fontname=""Sans"", fontsize=""9""];. manual [label="" Manual PrintF "", shape=""box""];; int1 [label="" int ( &) 42 "", shape=""box""]; auto [label="" Automatic PrintF "", shape=""box""];; int2 [label="" int ( &) 42 "", shape=""box""]. auto -> int2 [label=""int x = 42; \n x""];; manual -> int1 [label=""int x = 42; \n printf(&quot;(int &) %d \\n&quot;, x);""];; }. Significance of this feature; ----------------------------. Inspired by a similar implementation in `Cling <https://github.com/root-project/cling>`_,; this feature added to upstream Clang repo has essentially extended the syntax of; C++, so that it can be more helpful for people that are writing code for data; science applications. This is useful, for example, when you want to experiment with a set of values; against a set of functions, and you'd like to know the results right away.; This is similar to how Python works (hence its popularity in data science; research), but the superior performance of C++, along with this flexibility; makes it a more attractive option. Implementation Details; ======================. Parsing mechanism:; ------------------. The Interpreter in Clang-Repl (``Interpreter.cpp``) includes the function; ``ParseAndExecute()`` that can accept a 'Value' parameter to capture the result.; But if the value parameter is made optional and it is omitted (i.e., that the; user does not want to utilize it elsewhere), then the last value can be; validated and pushed into the ``dump()`` function. .. graphviz::; :name: parsing; :caption: Parsing Mechanism; :alt: Shows the Parsing Mechanism for Pretty Printing; :align: center. digraph ""prettyprint"" {; rankdir=""LR"";; graph [fontname=""Verdana"", fontsize=""12""];; node [fontname=""Verdana"", fontsize=""12""];; edge [fontname=""Verdana"", fontsize=""9""];. parse [label="" ParseAndExecute() \n in Clang "", shape=""box""];; capture [label="" Capture 'Value' parameter \n for processing? "", shape=""diamond""];; use [label",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangRepl.rst:15599,perform,performance,15599,interpreter/llvm-project/clang/docs/ClangRepl.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangRepl.rst,1,['perform'],['performance']
Performance,"""`+`""- add function to the list; without deleting the previous one. When fitting a histogram, the; function is attached to the histogram's list of functions. By default,; the previously fitted function is deleted and replaced with the most; recent one, so the list only contains one function. Setting this; option to On will add the newly fitted function to the existing list; of functions for the histogram. Note that the fitted functions are; saved with the histogram when it is written to a ROOT file. By; default, the function is drawn on the pad displaying the histogram. ### Draw Options. *‘SAME'* sets On/Off function drawing on the same pad. When a fit is; executed, the image of the function is drawn on the current pad. *‘No drawing'* sets On/Off the option ""`0`""- do not draw the fit; results. *‘Do not store/draw'* sets On/Off option ""`N`""- do not store the; function and do not draw it. ### Advances Options. The advance option button is enabled only after having performed the fit and provides; additional drawing options that can be used after having done the fit. These new drawing tools,; which can be selected by the ""Advanced Drawing Tool"" panel that pops up when clicking the ""Advanced"" button, are:. * *Contour*: to plot the confidence contour of two chosen parameters. One can select the number of points to draw the contour; (more points might require more time to compute it), the parameters and the desired confidence level . * *Scan* : to plot a scan of the minimization function (likelihood or chi-squared) around the minimum as function of the chosen parameter. * *Conf Interval* : to plot the confidence interval of the fitted function as a filled coloured band around its central value.; One can select the desired confidence level for the band to be plotted. ### Print Options. This set of options specifies the amount of feedback printed on the; root command line after performed fits. *‘Verbose'* - prints fit results after each iteration. *‘Quiet'* - no fit informat",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/FittingHistograms.md:24551,perform,performed,24551,documentation/users-guide/FittingHistograms.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/FittingHistograms.md,2,['perform'],['performed']
Performance,"""cpu""));. // fit using the CUDA library along with the most efficient library that the computer's CPU can support; RooMyPDF.fitTo(data, BatchMode(""cuda""));; ```; **Note: In case the system does not support vector instructions, the `RooBatchCompute::Cpu` option is guaranteed to work properly by using a generic CPU library. In contrast, users must first make sure that their system supports CUDA in order to use the `RooBatchCompute::Cuda` option. If this is not the case, an exception will be thrown.**. If `""cuda""` is selected, RooFit will launch CUDA kernels for computing likelihoods and potentially other intense computations. At the same time, the most efficient CPU library loaded will also handle parts of the computations in parallel with the GPU (or potentially, if it's faster, all of them), thus gaining full advantage of the available hardware. For this purpose `RooFitDriver`, a newly created RooFit class (in roofitcore) takes over the task of analyzing the computations and assigning each to the correct piece of hardware, taking into consideration the performance boost or penalty that may arise with every method of computing. #### Multithread computations; The CPU instance of the computing library can furthermore execute multithread computations. This also applies for computations handled by the CPU in the `""cuda""` mode. To use them, one needs to set the desired number of parallel tasks before calling `fitTo()` as shown below:; ``` {.cpp}; ROOT::EnableImplicitMT(nThreads);; RooMyPDF.fitTo(data, BatchMode(""cuda"")); // can also use ""cuda""; ```. ### User-made PDFs; The easiest and most efficient way of accelerating your PDFs is to request their addition to the official RooFit by submitting a ticket [here](https://github.com/root-project/root/issues/new). The ROOT team will gladly assist you and take care of the details. While your code is integrated, you are able to significantly improve the speed of fitting (but not take full advantage of the RooBatchCompute library),",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/developers/batchcompute.md:3058,perform,performance,3058,roofit/doc/developers/batchcompute.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/developers/batchcompute.md,1,['perform'],['performance']
Performance,"""global""; ID number space for the current translation unit, providing a 1-1 mapping; between entities (in whatever AST file they inhabit) and global ID numbers.; If that translation unit is then serialized into an AST file, this mapping; will be stored for use when the AST file is imported. Declaration merging; It is possible for a given entity (from the language's perspective) to be; declared multiple times in different places. For example, two different; headers can have the declaration of ``printf`` or could forward-declare; ``struct stat``. If each of those headers is included in a module, and some; third party imports both of those modules, there is a potentially serious; problem: name lookup for ``printf`` or ``struct stat`` will find both; declarations, but the AST nodes are unrelated. This would result in a; compilation error, due to an ambiguity in name lookup. Therefore, the AST; reader performs declaration merging according to the appropriate language; semantics, ensuring that the two disjoint declarations are merged into a; single redeclaration chain (with a common canonical declaration), so that it; is as if one of the headers had been included before the other. Name Visibility; Modules allow certain names that occur during module creation to be ""hidden"",; so that they are not part of the public interface of the module and are not; visible to its clients. The AST reader maintains a ""visible"" bit on various; AST nodes (declarations, macros, etc.) to indicate whether that particular; AST node is currently visible; the various name lookup mechanisms in Clang; inspect the visible bit to determine whether that entity, which is still in; the AST (because other, visible AST nodes may depend on it), can actually be; found by name lookup. When a new (sub)module is imported, it may make; existing, non-visible, already-deserialized AST nodes visible; it is the; responsibility of the AST reader to find and update these AST nodes when it; is notified of the import. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/PCHInternals.rst:28975,perform,performs,28975,interpreter/llvm-project/clang/docs/PCHInternals.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/PCHInternals.rst,1,['perform'],['performs']
Performance,"""stage 1""; compiler. This is done so that the compiler you distribute benefits from all the; bug fixes, performance optimizations and general improvements provided by the; new compiler. In deciding how to build your distribution there are a few trade-offs that you; will need to evaluate. The big two are:. #. Compile time of the distribution against performance of the built compiler. #. Binary size of the distribution against performance of the built compiler. The guidance for maximizing performance of the generated compiler is to use LTO,; PGO, and statically link everything. This will result in an overall larger; distribution, and it will take longer to generate, but it provides the most; opportunity for the compiler to optimize. The guidance for minimizing distribution size is to dynamically link LLVM and; Clang libraries into the tools to reduce code duplication. This will come at a; substantial performance penalty to the generated binary both because it reduces; optimization opportunity, and because dynamic linking requires resolving symbols; at process launch time, which can be very slow for C++ code. .. _shared_libs:. .. warning::; One very important note: Distributions should never be built using the; *BUILD_SHARED_LIBS* CMake option. That option exists for optimizing developer; workflow only. Due to design and implementation decisions, LLVM relies on; global data which can end up being duplicated across shared libraries; resulting in bugs. As such this is not a safe way to distribute LLVM or; LLVM-based tools. The simplest example of building a distribution with reasonable performance is; captured in the DistributionExample CMake cache file located at; clang/cmake/caches/DistributionExample.cmake. The following command will perform; and install the distribution build:. .. code-block:: console. $ cmake -G Ninja -C <path to clang>/cmake/caches/DistributionExample.cmake <path to LLVM source>; $ ninja stage2-distribution; $ ninja stage2-install-distribution. Diff",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst:1858,perform,performance,1858,interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,2,"['optimiz', 'perform']","['optimization', 'performance']"
Performance,"# Architecture of the VecOps library. > This document is meant for ROOT developers, to quickly get their bearings around the VecOps library. The main type in the library is `RVec`. Besides `RVec`, the library only contains helper types and functions. `RVec` is a vector type that tries to be as `std::vector`-like as possible while adding a; few important features, namely:; - the ability to act as a view over an existing memory buffer (see ""Memory adoption"" below); - a small-buffer optimization; - vectorized operator overloads; - a vectorized `operator[](mask)` to allow quick element selection together with vectorized operators; (e.g. `etas[etas > k]` returns a new `RVec` with all elements greater than `k`); - helper functions such as `InvariantMass`, `DeltaR`, `Argsort` are also provided. The current implementation of `RVec` is based on LLVM's SmallVector, extracted; from the head of LLVM's repo around December 2020.; We are not tracking the upstream implementation. Compared to LLVM's SmallVectors:. - memory adoption capabilities have been added; - patches have been applied to make RVec work with (ROOT's version of) cppyy (notably `using` declarations had to be; lowered in the inheritance hierarchy for cppyy to pick them up); - `operator[](mask)` has been added, as well as several other ""numpy-like"" helper; functions (these latter ones are free functions); - logical operators `==`, `<`, `>` etc. return vectors rather than booleans; - the type of fSize and fCapacity is signed rather than unsigned, and fixed to 32 bits; - a number of minor patches have been applied for backward compatibility with the previous; implementation of RVec (which did not have a small buffer optimization and was implemented; in terms of `std::vector` with a custom allocator) and to make the code more consistent; with ROOT's coding conventions. ## RVec design. `SmallVectorBase`; - `fBeginX`; - `fSize`; - `fCapacity`. Basically the same as the corresponding LLVM class, with the template parameter",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/vecops/ARCHITECTURE.md:485,optimiz,optimization,485,math/vecops/ARCHITECTURE.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/vecops/ARCHITECTURE.md,1,['optimiz'],['optimization']
Performance,"# C++ Modules in ROOT. Technology Overview. *Vassil Vassilev, Oksana Shadura, Yuka Takahashi and Raphael Isemann*. ## Overview. ROOT has several features which interact with libraries and require implicit; header inclusion. This can be triggered by reading or writing data on disk,; or user actions at the prompt. Often, the headers are immutable and reparsing is; redundant. C++ Modules are designed to minimize the reparsing of the same; header content by providing an efficient on-disk representation of C++ Code. The ROOT v6.16 release came with a preview of the module technology;; dedicated binaries have been built and can be reproduced by passing; `-Druntime_cxxmodules=On` as configure flag. The goals of this technology are:; * Gain feedback from early adoption -- the technology is being long anticipated; by some of the users of ROOT. It improves correctness of ROOT and improves; performance when carefully adopted.; * Study performance bottlenecks -- the feature is designed with performance; considerations in mind. In this document we describe the current performance; bottlenecks and trade-offs.; * Understand if the gradual migration policy is sufficient -- C++ Modules in; ROOT support gradual migration. In particular, ROOT can enable C++ Modules for; itself and still run in legacy mode for the third-party code (generating; rootmap files and other scaffolding). C++ Modules are here and we would like to give a brief introduction of how the; feature works, what are its pros and cons, what's the current state of the; implementation and how third-party code can use it. Read more [[1]]. C++ Modules in ROOT are default since v6.20 (Unix) and v6.22 (OSX). ## Design Goals. * Coherence with standard C++ -- C++ Modules TS is advancing and will be; likely part the upcoming C++20 standard;; * Performance -- provide performance that is competitive to ROOT with PCH and; advance further the implementation of the C++ Modules in clang to optimize; memory footprint and execution time;",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/README.CXXMODULES.md:893,perform,performance,893,README/README.CXXMODULES.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/README.CXXMODULES.md,4,"['bottleneck', 'perform']","['bottlenecks', 'performance']"
Performance,"# Copyright (C) 1995-2019, Rene Brun and Fons Rademakers.; # All rights reserved.; #; # For the licensing terms see $ROOTSYS/LICENSE.; # For the list of contributors see $ROOTSYS/README/CREDITS. # Test library loads during importing ROOT; # Testing only the Linux systems is sufficient to detect unwanted links to libraries at import time.; # Mac (and potentially Windows) pull in many system libraries which makes this test very complex.; if (NOT APPLE AND NOT WIN32); ROOT_ADD_PYUNITTEST(pyroot_import_load_libs import_load_libs.py); endif(). # Test ROOT module; ROOT_ADD_PYUNITTEST(pyroot_root_module root_module.py). # @pythonization decorator; ROOT_ADD_PYUNITTEST(pyroot_pyz_decorator pythonization_decorator.py). # General pythonizations; ROOT_ADD_PYUNITTEST(pyroot_pyz_pretty_printing pretty_printing.py); ROOT_ADD_PYUNITTEST(pyroot_pyz_array_interface array_interface.py PYTHON_DEPS numpy). # STL containers pythonizations; ROOT_ADD_PYUNITTEST(pyroot_pyz_stl_vector stl_vector.py); ROOT_ADD_PYUNITTEST(pyroot_pyz_stl_set stl_set.py). # TObject and subclasses pythonisations; ROOT_ADD_PYUNITTEST(pyroot_pyz_tobject_contains tobject_contains.py); ROOT_ADD_PYUNITTEST(pyroot_pyz_tobject_comparisonops tobject_comparisonops.py). # TClass pythonisations; ROOT_ADD_PYUNITTEST(pyroot_pyz_tclass_dynamiccast tclass_dynamiccast.py). # TContext pythonizations; ROOT_ADD_PYUNITTEST(pyroot_pyz_tcontext_contextmanager tcontext_contextmanager.py). # TDirectory and subclasses pythonizations; ROOT_ADD_PYUNITTEST(pyroot_pyz_tdirectory_attrsyntax tdirectory_attrsyntax.py); ROOT_ADD_PYUNITTEST(pyroot_pyz_tdirectoryfile_attrsyntax_get tdirectoryfile_attrsyntax_get.py); ROOT_ADD_PYUNITTEST(pyroot_pyz_tfile_attrsyntax_get_writeobject_open tfile_attrsyntax_get_writeobject_open.py); ROOT_ADD_PYUNITTEST(pyroot_pyz_tfile_constructor tfile_constructor.py); ROOT_ADD_PYUNITTEST(pyroot_pyz_tfile_context_manager tfile_context_manager.py). # TTree and subclasses pythonizations; file(COPY TreeHelper.h DESTINATION ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/pythonizations/test/CMakeLists.txt:210,load,loads,210,bindings/pyroot/pythonizations/test/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/pythonizations/test/CMakeLists.txt,1,['load'],['loads']
Performance,"# Copyright (C) 1995-2019, Rene Brun and Fons Rademakers.; # All rights reserved.; #; # For the licensing terms see $ROOTSYS/LICENSE.; # For the list of contributors see $ROOTSYS/README/CREDITS. ############################################################################; # CMakeLists.txt file for building ROOT core/base package; ############################################################################. if(MSVC AND MSVC_VERSION GREATER_EQUAL 1925 AND MSVC_VERSION LESS 1929); # FIXME: since Visual Studio v16.5.0 the /O2 optimization flag makes most of the roofit/roostats tests failing; # Try to re-enable /O2 after the upgrade of llvm & clang, or when upgrading Visual Studio; string(REPLACE ""-O2"" ""-O1 -Oi"" CMAKE_CXX_FLAGS_RELEASE ""${CMAKE_CXX_FLAGS_RELEASE}""); string(REPLACE ""-O2"" ""-O1 -Oi"" CMAKE_CXX_FLAGS_RELWITHDEBINFO ""${CMAKE_CXX_FLAGS_RELWITHDEBINFO}""); endif(). set(BASE_HEADERS; ROOT/TErrorDefaultHandler.hxx; ROOT/TExecutorCRTP.hxx; ROOT/TSequentialExecutor.hxx; ROOT/StringConv.hxx; Buttons.h; Bytes.h; Byteswap.h; KeySymbols.h; MessageTypes.h; Riostream.h; Rtypes.h; TApplication.h; TAtt3D.h; TAttAxis.h; TAttBBox2D.h; TAttBBox.h; TAttFill.h; TAttLine.h; TAttMarker.h; TAttPad.h; TAttText.h; TBase64.h; TBenchmark.h; TBuffer3D.h; TBuffer3DTypes.h; TBuffer.h; TColor.h; TColorGradient.h; TDatime.h; TDirectory.h; TEnv.h; TException.h; TExec.h; TFileCollection.h; TFileInfo.h; TFolder.h; TInetAddress.h; TMacro.h; TMathBase.h; TMD5.h; TMemberInspector.h; TMessageHandler.h; TNamed.h; TNotifyLink.h; TObject.h; TObjString.h; TParameter.h; TPluginManager.h; TPoint.h; TPRegexp.h; TProcessID.h; TProcessUUID.h; TQClass.h; TQCommand.h; TQConnection.h; TQObject.h; TRedirectOutputGuard.h; TRefCnt.h; TRef.h; TRegexp.h; TRemoteObject.h; TROOT.h; TRootIOCtor.h; TStopwatch.h; TStorage.h; TString.h; TStringLong.h; TStyle.h; TSysEvtHandler.h; TSystemDirectory.h; TSystemFile.h; TSystem.h; TTask.h; TThreadSlots.h; TTime.h; TTimer.h; TTimeStamp.h; TUri.h; TUrl.h; TUUID.h; TVersionCheck.h;",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/base/CMakeLists.txt:528,optimiz,optimization,528,core/base/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/base/CMakeLists.txt,1,['optimiz'],['optimization']
Performance,"# Copyright (C) 1995-2019, Rene Brun and Fons Rademakers.; # All rights reserved.; #; # For the licensing terms see $ROOTSYS/LICENSE.; # For the list of contributors see $ROOTSYS/README/CREDITS. ############################################################################; # CMakeLists.txt file for building ROOT math/minuit package; ############################################################################. ROOT_STANDARD_LIBRARY_PACKAGE(Minuit; HEADERS; TFitter.h; TLinearFitter.h; TLinearMinimizer.h; TMinuit.h; TMinuitMinimizer.h; SOURCES; src/TFitter.cxx; src/TLinearFitter.cxx; src/TLinearMinimizer.cxx; src/TMinuit.cxx; src/TMinuitMinimizer.cxx; DEPENDENCIES; Graf; Hist; Matrix; MathCore; DICTIONARY_OPTIONS; -writeEmptyRootPCM; ). if (CMAKE_BUILD_TYPE STREQUAL Optimized); target_compile_options(Minuit PRIVATE ""-fno-fast-math""); endif(); ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/minuit/CMakeLists.txt:773,Optimiz,Optimized,773,math/minuit/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/minuit/CMakeLists.txt,1,['Optimiz'],['Optimized']
Performance,"# Copyright (C) 1995-2019, Rene Brun and Fons Rademakers.; # All rights reserved.; #; # For the licensing terms see $ROOTSYS/LICENSE.; # For the list of contributors see $ROOTSYS/README/CREDITS. ############################################################################; # CMakeLists.txt file for building ROOT misc/minicern package; ############################################################################. ROOT_LINKER_LIBRARY(minicern *.c *.f TYPE STATIC); set_property(TARGET minicern PROPERTY POSITION_INDEPENDENT_CODE ON); target_link_libraries(minicern ${CMAKE_Fortran_IMPLICIT_LINK_LIBRARIES}). # Disable optimization since it some cases was causing crashes.; # Disable warnings, since what has worked for 40 years...; # (see https://sft.its.cern.ch/jira/browse/ROOT-9179 for the warnings); set_target_properties(minicern PROPERTIES COMPILE_FLAGS ""-O0 -w""); ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/misc/minicern/CMakeLists.txt:618,optimiz,optimization,618,misc/minicern/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/misc/minicern/CMakeLists.txt,2,['optimiz'],['optimization']
Performance,"# Copyright (C) 1995-2019, Rene Brun and Fons Rademakers.; # All rights reserved.; #; # For the licensing terms see $ROOTSYS/LICENSE.; # For the list of contributors see $ROOTSYS/README/CREDITS. include(ExternalProject). # Clear cache variables set by find_package(PCRE); # to ensure that we use the builtin version; foreach(var PCRE_FOUND PCRE_VERSION PCRE_INCLUDE_DIR PCRE_PCRE_LIBRARY PCRE_LIBRARIES); unset(${var} CACHE); endforeach(). if(WIN32); if(CMAKE_GENERATOR MATCHES Ninja); if (CMAKE_BUILD_TYPE MATCHES Debug); set(PCRE_POSTFIX d); endif(); else(); if(winrtdebug); set(PCRE_POSTFIX $<$<CONFIG:Debug>:d>); set(pcre_config_kind ""Debug""); else(); set(pcre_config_kind ""Release""); endif(); set(pcre_config ""--config ${pcre_config_kind}""); endif(); endif(). set(PCRE_VERSION ""8.43"" CACHE INTERNAL """" FORCE); set(PCRE_LIBNAME ${CMAKE_STATIC_LIBRARY_PREFIX}pcre${PCRE_POSTFIX}${CMAKE_STATIC_LIBRARY_SUFFIX}). # build byproducts only needed by Ninja; if(""${CMAKE_GENERATOR}"" STREQUAL ""Ninja""); set(PCRE_BYPRODUCTS; <BINARY_DIR>/pcre.h; <BINARY_DIR>/${PCRE_LIBNAME}; ); endif(). ExternalProject_Add(PCRE; URL ${CMAKE_CURRENT_SOURCE_DIR}/pcre-${PCRE_VERSION}.tar.bz2; URL_HASH SHA256=91e762520003013834ac1adb4a938d53b22a216341c061b0cf05603b290faf6b. LOG_DOWNLOAD TRUE; LOG_CONFIGURE TRUE; LOG_BUILD TRUE; LOG_INSTALL TRUE. CMAKE_CACHE_ARGS; -DCMAKE_INSTALL_PREFIX:PATH=<INSTALL_DIR>; -DCMAKE_GENERATOR:STRING=${CMAKE_GENERATOR}; -DCMAKE_BUILD_TYPE:STRING=${CMAKE_BUILD_TYPE}; -DCMAKE_C_COMPILER:STRING=${CMAKE_C_COMPILER}; -DCMAKE_CXX_COMPILER:STRING=${CMAKE_CXX_COMPILER}; -DCMAKE_BUILD_SHARED_LIBS:BOOL=FALSE; -DCMAKE_POSITION_INDEPENDENT_CODE:BOOL=TRUE. BUILD_COMMAND; ${CMAKE_COMMAND} --build <BINARY_DIR> ${pcre_config} --target pcre. BUILD_BYPRODUCTS; ${PCRE_BYPRODUCTS}. INSTALL_COMMAND """"; TIMEOUT 600; ). ExternalProject_Get_Property(PCRE BINARY_DIR). set(PCRE_FOUND TRUE CACHE INTERNAL """" FORCE); set(PCRE_INCLUDE_DIR ""${BINARY_DIR}"" CACHE INTERNAL """" FORCE); if(WIN32); set(PCRE_PCRE_LIBR",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/builtins/pcre/CMakeLists.txt:229,cache,cache,229,builtins/pcre/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/builtins/pcre/CMakeLists.txt,1,['cache'],['cache']
Performance,"# Copyright (C) 1995-2019, Rene Brun and Fons Rademakers.; # All rights reserved.; #; # For the licensing terms see $ROOTSYS/LICENSE.; # For the list of contributors see $ROOTSYS/README/CREDITS. set(py_sources; cppyy_backend/__init__.py; cppyy_backend/_cling_config.py; cppyy_backend/_cppyy_generator.py; cppyy_backend/_genreflex.py; cppyy_backend/_rootcling.py; cppyy_backend/bindings_utils.py; cppyy_backend/loader.py; cppyy_backend/_get_cppflags.py; ). set(cppyy_backendPySrcDir cling/python/cppyy_backend); file(COPY ${cppyy_backendPySrcDir}; DESTINATION ${localruntimedir}; PATTERN ""cmake"" EXCLUDE; PATTERN ""pkg_templates"" EXCLUDE). file(RELATIVE_PATH PYTHONDIR_TO_LIBDIR ""${CMAKE_INSTALL_FULL_PYTHONDIR}"" ""${CMAKE_INSTALL_FULL_LIBDIR}""). set(libname cppyy_backend). add_library(${libname} SHARED clingwrapper/src/clingwrapper.cxx); if(MSVC); set_target_properties(${libname} PROPERTIES WINDOWS_EXPORT_ALL_SYMBOLS TRUE); endif(); # Set the suffix to '.so' and the prefix to 'lib'; set_target_properties(${libname} PROPERTIES ${ROOT_LIBRARY_PROPERTIES}); target_link_libraries(${libname} Core ${CMAKE_DL_LIBS}). # cppyy uses ROOT headers from binary directory; add_dependencies(${libname} move_headers). set_property(GLOBAL APPEND PROPERTY ROOT_EXPORTED_TARGETS ${libname}). # Install library; install(TARGETS ${libname} EXPORT ${CMAKE_PROJECT_NAME}Exports; RUNTIME DESTINATION ${CMAKE_INSTALL_BINDIR} COMPONENT libraries; LIBRARY DESTINATION ${CMAKE_INSTALL_LIBDIR} COMPONENT libraries; ARCHIVE DESTINATION ${CMAKE_INSTALL_LIBDIR} COMPONENT libraries); if (NOT MSVC AND NOT CMAKE_INSTALL_LIBDIR STREQUAL CMAKE_INSTALL_PYTHONDIR); # add a symlink to ${libname} in CMAKE_INSTALL_PYTHONDIR; set(LIB_FILE_NAME ${CMAKE_SHARED_LIBRARY_PREFIX}${libname}.so); install(CODE ""file(CREATE_LINK ${PYTHONDIR_TO_LIBDIR}/${LIB_FILE_NAME}; \$ENV{DESTDIR}${CMAKE_INSTALL_FULL_PYTHONDIR}/${LIB_FILE_NAME} SYMBOLIC)""); endif(). # Compile .py files; foreach(py_source ${py_sources}); install(CODE ""execute_process(CO",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy-backend/CMakeLists.txt:410,load,loader,410,bindings/pyroot/cppyy/cppyy-backend/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy-backend/CMakeLists.txt,1,['load'],['loader']
Performance,"# Copyright (C) 1995-2023, Rene Brun and Fons Rademakers.; # All rights reserved.; #; # For the licensing terms see $ROOTSYS/LICENSE.; # For the list of contributors see $ROOTSYS/README/CREDITS. #####################################################################################################################. # Details about integrating ROOT into CMake projects:; # https://root.cern/manual/integrate_root_into_my_cmake_project/. #####################################################################################################################. # CMakeLists.txt that creates a library with dictionary and a main program; cmake_minimum_required(VERSION 3.10 FATAL_ERROR). project(treeUsingCustomClass). #---Locate the ROOT package and defines a number of variables (e.g. ROOT_INCLUDE_DIRS); find_package(ROOT REQUIRED COMPONENTS Tree TreePlayer ROOTDataFrame). #---Include a CMake module which makes use of the previous variables and loads modules ; # with useful macros or functions such as ROOT_GENERATE_DICTIONARY; # For further details: https://root-forum.cern.ch/t/how-to-integrate-root-into-my-project-with-cmake/37175; include(${ROOT_USE_FILE}). #---Add include directory of ROOT to the build; include_directories(${CMAKE_SOURCE_DIR}). # CMake function provided by ROOT, used to generate the dictionary file, G__data2Tree.cxx; # See this link for further details:; # https://root.cern/manual/io_custom_classes/#using-cmake; ROOT_GENERATE_DICTIONARY(G__data2Tree data2Tree.hxx LINKDEF data2TreeLinkDef.hxx). #---Create a shared library from; # * the previously generated dictionary, G__data2Tree.cxx; # * the class implementation; add_library(data2TreeLib SHARED data2Tree.cxx G__data2Tree.cxx); target_link_libraries(data2TreeLib ${ROOT_LIBRARIES} ) ; add_dependencies(data2TreeLib G__data2Tree ). #--- This is needed on Windows in order to export the symbols and create the data2TreeLib.lib file; if(MSVC); set_target_properties(data2TreeLib PROPERTIES WINDOWS_EXPORT_ALL_SYMBOLS TRUE)",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tutorials/tree/dictionary/CMakeLists.txt:942,load,loads,942,tutorials/tree/dictionary/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tutorials/tree/dictionary/CMakeLists.txt,2,['load'],['loads']
Performance,"# Debug Info Assignment Tracking. Assignment Tracking is an alternative technique for tracking variable location; debug info through optimisations in LLVM. It provides accurate variable; locations for assignments where a local variable (or a field of one) is the; LHS. In rare and complicated circumstances indirect assignments might be; optimized away without being tracked, but otherwise we make our best effort to; track all variable locations. The core idea is to track more information about source assignments in order; and preserve enough information to be able to defer decisions about whether to; use non-memory locations (register, constant) or memory locations until after; middle end optimisations have run. This is in opposition to using; `llvm.dbg.declare` and `llvm.dbg.value`, which is to make the decision for most; variables early on, which can result in suboptimal variable locations that may; be either incorrect or incomplete. A secondary goal of assignment tracking is to cause minimal additional work for; LLVM pass writers, and minimal disruption to LLVM in general. ## Status and usage. **Status**: Experimental work in progress. Enabling is strongly advised against; except for development and testing. **Enable in Clang**: `-Xclang -fexperimental-assignment-tracking`. That causes Clang to get LLVM to run the pass `declare-to-assign`. The pass; converts conventional debug intrinsics to assignment tracking metadata and sets; the module flag `debug-info-assignment-tracking` to the value `i1 true`. To; check whether assignment tracking is enabled for a module call; `isAssignmentTrackingEnabled(const Module &M)` (from `llvm/IR/DebugInfo.h`). ## Design and implementation. ### Assignment markers: `llvm.dbg.assign`. `llvm.dbg.value`, a conventional debug intrinsic, marks out a position in the; IR where a variable takes a particular value. Similarly, Assignment Tracking; marks out the position of assignments with a new intrinsic called; `llvm.dbg.assign`. In order to k",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AssignmentTracking.md:338,optimiz,optimized,338,interpreter/llvm-project/llvm/docs/AssignmentTracking.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AssignmentTracking.md,1,['optimiz'],['optimized']
Performance,"# File I/O and Parallel Analysis #. ## Storing ROOT Objects ##. ROOT offers the possibility to write instances of classes on; disk, into a *ROOT-file* (see the `TFile` class for more details).; One says that the object is made ""persistent"" by storing; it on disk. When reading the file back, the object is reconstructed; in memory. The requirement to be satisfied to perform I/O of instances; of a certain class is that the ROOT type system is aware of the layout; in memory of that class.; This topic is beyond the scope of this document: it is worth to mention; that I/O can be performed out of the box for the almost complete set; of ROOT classes. We can explore this functionality with histograms and two simple macros. ``` {.cpp}; @ROOT_INCLUDE_FILE macros/write_to_file.C; ```. Not bad, eh ? Especially for a language that does not foresees; persistency natively like C++. The *RECREATE* option forces ROOT to; create a new file even if a file with the same name exists on disk. Now, you may use the Cling command line to access information in the file; and draw the previously written histogram:. ``` {.cpp}; > root my_rootfile.root; root [0]; Attaching file my_rootfile.root as _file0...; root [1] _file0->ls(); TFile** my_rootfile.root; TFile* my_rootfile.root; KEY: TH1F	my_histogram;1 My Title; root [2] my_histogram->Draw(); ```; \newpage; Alternatively, you can use a simple macro to carry out the job:. ``` {.cpp}; @ROOT_INCLUDE_FILE macros/read_from_file.C; ```. ## N-tuples in ROOT ##. ### Storing simple N-tuples ###. Up to now we have seen how to manipulate input read from ASCII files.; ROOT offers the possibility to do much better than that, with its own; n-tuple classes. Among the many advantages provided by these classes one; could cite. - Optimised disk I/O. - Possibility to store many n-tuple rows. - Write the n-tuples in ROOT files. - Interactive inspection with `TBrowser`. - Store not only numbers, but also *objects* in the columns. In this section we will discuss bri",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/primer/filio.md:367,perform,perform,367,documentation/primer/filio.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/primer/filio.md,2,['perform'],"['perform', 'performed']"
Performance,"# Functions and Parameter Estimation #. After going through the previous chapters, you already know how to use; analytical functions (class `TF1`), and you got some insight into the; graph (`TGraphErrors`) and histogram classes (`TH1F`) for data; visualisation. In this chapter we will add more detail to the previous; approximate explanations to face the fundamental topic of parameter; estimation by fitting functions to data. For graphs and histograms, ROOT; offers an easy-to-use interface to perform fits - either the fit panel; of the graphical interface, or the `Fit` method. The class `TFitResult`; allows access to the detailed results. Very often it is necessary to study the statistical properties of; analysis procedures. This is most easily achieved by applying the; analysis to many sets of simulated data (or ""pseudo data""), each; representing one possible version of the true experiment. If the; simulation only deals with the final distributions observed in data, and; does not perform a full simulation of the underlying physics and the; experimental apparatus, the name ""Toy Monte Carlo"" is frequently used; [^5]. Since the true values of all parameters are known in the; pseudo-data, the differences between the parameter estimates from the; analysis procedure w.r.t. the true values can be determined, and it is; also possible to check that the analysis procedure provides correct; error estimates. ## Fitting Functions to Pseudo Data ##. In the example below, a pseudo-data set is produced and a model fitted; to it. ROOT offers various minimisation algorithms to minimise a chi2 or a; negative log-likelihood function. The default minimiser is MINUIT, a; package originally implemented in the FORTRAN programming language. A; C++ version is also available, MINUIT2, as well as Fumili [@Fumili] an; algorithm optimised for fitting. The; minimisation algorithms can be selected using the static functions of; the `ROOT::Math::MinimizerOptions` class. Steering options for the; min",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/primer/functions_and_parameter_estimation.md:497,perform,perform,497,documentation/primer/functions_and_parameter_estimation.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/primer/functions_and_parameter_estimation.md,1,['perform'],['perform']
Performance,"# JSROOT changelog. ## Changes in dev; 1. Let use custom time zone for time display, support '&utc' and '&cet' in URL parameters; 2. Support gStyle.fLegendFillStyle; 3. Let change histogram min/max values via context menu; 4. Support Z-scale zooming with TScatter; 5. Implement ""haxis"" draw option for histogram to draw only axes for hbar; 6. Implement ""axisg"" and ""haxisg"" to draw axes with grids; 7. Support TH1 marker, text and line drawing superimposed with ""haxis""; 8. Support `TBox`, `TLatex`, `TLine`, `TMarker` drawing on ""frame"", support drawing on swapped axes; 9. `TProfile` and `TProfile2D` projections https://github.com/root-project/root/issues/15851; 10. Draw total histogram from TEfficiency when draw option starts with 'b'; 11. Let redraw TEfficiency, THStack and TMultiGraph with different draw options via hist context menu; 12. Support 'pads' draw options for TMultiGraph, support context menu for it; 13. Let drop object on sub-pads; 14. Properly loads ES6 modules for web canvas; 15. Improve performance of TH3/RH3 drawing by using THREE.InstancedMesh; 16. Implement batch mode with '&batch' URL parameter to create SVG/PNG images with default GUI; 17. Adjust node.js implementation to produce identical output with normal browser; 18. Create necessary infrastructure for testing with 'puppeteer'; 19. Support inject of ES6 modules via '&inject=path.mjs'; 20. Using importmap for 'jsroot' in all major HTML files and in demos; 21. Implement `settings.CutAxisLabels` flag to remove labels which may exceed graphical range; 22. Let disable usage of TAxis custom labels via context menu; 23. Let configure default draw options via context menu, they can be preserved in the local storage; 24. Let save canvas as JSON file from context menu, object as JSON from inspector; 25. Upgrade three.js r162 -> r168, use r162 only in node.js because of ""gl"" module; 26. Create unified svg2pdf/jspdf ES6 modules, integrate in jsroot builds; 27. Let create multipage PDF document - in TWebCanv",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/js/changes.md:969,load,loads,969,js/changes.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/js/changes.md,1,['load'],['loads']
Performance,"# LLVM TableGen Kernel. This notebook is running `llvm-tblgen`. ```tablegen; %reset; // This is some tablegen; class Foo {}; ```. ------------- Classes -----------------; class Foo {; }; ------------- Defs -----------------. Errors printed to stderr are shown. ```tablegen; %reset; This is not tablegen.; ```. <stdin>:1:1: error: Unexpected token at top level; This is not tablegen.; ^. Add some classes to get some output. ```tablegen; %reset; class Stuff {}; def thing : Stuff {}; ```. ------------- Classes -----------------; class Stuff {; }; ------------- Defs -----------------; def thing {	// Stuff; }. By default cells are connected. Meaning that we cache the code and magic directives from the previously run cells. This means that the next cell still sees the `Stuff` class. ```tablegen; def other_thing : Stuff {}; ```. ------------- Classes -----------------; class Stuff {; }; ------------- Defs -----------------; def other_thing {	// Stuff; }; def thing {	// Stuff; }. You can use the magic `%reset` to clear this cache and start fresh. ```tablegen; %reset; def other_thing : Stuff {}; ```. <stdin>:1:19: error: Couldn't find class 'Stuff'; def other_thing : Stuff {}; ^. You can also configure the default reset behaviour using the `%config` magic. ```tablegen; %config cellreset on; class Thing {}; ```. ------------- Classes -----------------; class Thing {; }; ------------- Defs -----------------. ```tablegen; // The cache is reset here so this is an error.; def AThing: Thing {}; ```. <stdin>:2:13: error: Couldn't find class 'Thing'; def AThing: Thing {}; ^. The default value is `off`, meaning cells are connected. If you want to override the default for one cell only, use the `%reset` or `%noreset` magic. These always override the default. ```tablegen; class Thing {}; ```. ------------- Classes -----------------; class Thing {; }; ------------- Defs -----------------. ```tablegen; %noreset; // This works because of the noreset above.; def AThing: Thing {}; ```. --------",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/LLVM_TableGen.md:658,cache,cache,658,interpreter/llvm-project/llvm/utils/TableGen/jupyter/LLVM_TableGen.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/LLVM_TableGen.md,1,['cache'],['cache']
Performance,"# Latency tests for RWebWindow. Provide round-trip test under different conditions.; To run, execute `root ""ping.cxx(10,0)""`, where first argument is number of connections tested and; second argument is running mode. Can be tested:; 0 - default communication, no extra threads; 1 - minimal timer for THttpServer, should reduce round-trip significantly; 2 - use special thread for process requests in THttpServer, web window also runs in the thread; 3 - in addition to special THttpThread also window starts own thread; 4 - let invoke webwindow callbacks in the civetweb threads, expert mode only. One also can perform same tests with longpoll emulation of web sockets, if adding 10 to second parameter. When running in batch mode, function blocked until 200 round-trip packets send by the client; or 50s elappsed. Therefore ping.cxx test can be used for RWebWindow functionality tests ; like `root -l -b ""ping.cxx(10,2)"" -q`; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tutorials/webgui/ping/Readme.md:610,perform,perform,610,tutorials/webgui/ping/Readme.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tutorials/webgui/ping/Readme.md,1,['perform'],['perform']
Performance,"# Linear Algebra in ROOT. The linear algebra package is supposed to give a complete environment in; ROOT to perform calculations like equation solving and eigenvalue; decompositions. Most calculations are performed in double precision. For; backward compatibility, some classes are also provided in single; precision like **`TMatrixF`**, **`TMatrixFSym`** and **`TVectorF`**.; Copy constructors exist to transform these into their double precision; equivalent, thereby allowing easy access to decomposition and eigenvalue; classes, only available in double precision. The choice was made not to provide the less frequently used complex; matrix classes. If necessary, users can always reformulate the; calculation in 2 parts, a real one and an imaginary part. Although, a; linear equation involving complex numbers will take about a factor of 8; more computations, the alternative of introducing a set of complex; classes in this non-template library would create a major maintenance; challenge. Another choice was to fill in both the upper-right corner and the; bottom-left corner of a symmetric matrix. Although most algorithms use; only the upper-right corner, implementation of the different matrix; views was more straightforward this way. When stored only the; upper-right part is written to file. For a detailed description of the interface, the user should look at the; root reference guide at: <http://root.cern.ch/root/Reference.html>. ## Overview of Matrix Classes. The figure below shows an overview of the classes available in the; linear algebra library,` libMatrix.so`. At the center is the base class; **`TMatrixDBase`** from which three different matrix classes,; **`TMatrixD`**, **`TMatrixDSym`** and **`TMatrixDFSparse`** derive. The; user can define customized matrix operations through the classes; **`TElementActionD`** and **`TElementsPosActionD`**. ![Overview of matrix classes](pictures/0300012D.png). Reference to different views of the matrix can be created through the; clas",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/LinearAlgebra.md:108,perform,perform,108,documentation/users-guide/LinearAlgebra.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/LinearAlgebra.md,2,['perform'],"['perform', 'performed']"
Performance,"# MLGO Python Utilities. This folder contains MLGO Python utilities, particularly infrastructure; to help enable ML applications within LLVM, especially tooling to extract; corpora that can be used in downstream projects to train ML models and perform; other tasks that benefit from having a large amount of data. ### Python Versioning. Due to type annotations, the MLGO tooling currently only supports a Python; version greater than 3.8, deviating from the current LLVM project-wide; minimum supported version of Python 3.6.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/mlgo-utils/README.md:244,perform,perform,244,interpreter/llvm-project/llvm/utils/mlgo-utils/README.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/mlgo-utils/README.md,1,['perform'],['perform']
Performance,"# Math Libraries in ROOT. The aim of Math libraries in ROOT is to provide and to support a; coherent set of mathematical and statistical functions. The latest; developments have been concentrated in providing first versions of the; `MathCore` and `MathMore` libraries, included in ROOT v5.08. Other; recent developments include the new version of `MINUIT`, which has been; re-designed and re-implemented in the C++ language. It is integrated in; ROOT. In addition, an optimized package for describing small matrices; and vector with fixed sizes and their operation has been developed; (`SMatrix`). The structure is shown in the following picture. ![Math libraries and packages](pictures/02000109.jpg). ## MathCore Library. `MathCore` provides a collection of functions and C++ classes for; numerical computing. This library includes only the basic mathematical; functions and algorithms and not all the functionality required by the; physics community. A more advanced mathematical functionality is; provided by the `MathMore` library. The current set of included classes,; which are provided in the `ROOT::Math` namespace are:. - Basic special functions like the gamma, beta and error function. - Mathematical functions used in statistics, such as the probability; density functions and the cumulative distributions functions (lower; and upper integral of the pdf's). - Generic function classes and interfaces; for evaluating one-dimensional (`ROOT::Math::IBaseFunctiononeDim`) and multi-dimensional functions; (`ROOT::Math::IBaseFunctionMultiDim`) and parametric function interfaces for evaluating functions with parameters in one; (`ROOT::Math::IParametricFunctionOneDim`) or multi dimensions (`ROOT::Math::IParametricFunctionMultiDim`).; 	A set of user convenient wrapper classes, such as `ROOT::Math::Functor` is provided for wrapping user-classes in the needed interface,; 	required to use the algorithms of the `ROOT` Mathematical libraries. - Numerical algorithms interfaces and in same cases ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/MathLibraries.md:468,optimiz,optimized,468,documentation/users-guide/MathLibraries.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/MathLibraries.md,1,['optimiz'],['optimized']
Performance,"# PROOF: Parallel Processing; \index{PROOF}; \index{parallel processing}. The Parallel ROOT Facility, PROOF, is an extension of ROOT allowing; transparent analysis of large sets of ROOT files in parallel on remote; computer clusters or multi-core computers. The main design goals for the; PROOF system are:. *Transparency* : there should be as little difference as possible; between a local ROOT based analysis session and a remote parallel PROOF; session, both being interactive and giving the same results. *Scalability* : the basic architecture should not put any implicit; limitations on the number of computers that can be used in parallel. *Adaptability* : the system should be able to adapt itself to variations; in the remote environment (changing load on the cluster nodes, network; interruptions, etc.). Being an extension of the ROOT system, PROOF is designed to work on; objects in ROOT data stores, though, for the time being, it mainly; addresses the case of **`TTree`** based object collections. PROOF is primarily meant as an interactive alternative to batch systems; for Central Analysis Facilities and departmental workgroups (Tier-2's).; However, thanks to a multi-tier architecture allowing multiple levels of; masters, it can be easily adapted to wide range virtual clusters; distributed over geographically separated domains and heterogeneous; machines (GRIDs). While pure interactivity might not always be possible when performing a; complicated analysis on a very large data set, PROOF still tries to give; the user the interactive experience with something we call ""interactive; batch"". With ""interactive batch"" the user can start very long running; queries, disconnect the client and at any time, any location and from; any computer reconnect to the query to monitor its progress or retrieve; the results. This feature gives it a distinct advantage over purely; batch based solutions, that only provide an answer once all sub-jobs; have been finished. ![The Multi-tier struct",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/PROOF.md:756,load,load,756,documentation/users-guide/PROOF.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/PROOF.md,1,['load'],['load']
Performance,"# Physics Vectors. The physics vector classes describe vectors in three and four dimensions; and their rotation algorithms. The classes were ported to root from; CLHEP see:. <http://www.cern.ch/clhep/manual/UserGuide/Vector/vector.html>. ## The Physics Vector Classes. In order to use the physics vector classes you will have to load the; Physics library:. ``` {.cpp}; gSystem.Load(""libPhysics.so"");; ```. There are four classes in this package. They are:. **`TVector3`** is a general three-vector. A **`TVector3`** may be; expressed in Cartesian, polar, or cylindrical coordinates. Methods; include dot and cross products, unit vectors and magnitudes, angles; between vectors, and rotations and boosts. There are also functions of; particular use to HEP, like pseudo-rapidity, projections, and transverse; part of a **`TVector3`**, and kinetic methods on 4-vectors such as; Invariant Mass of pairs or containers of particles`.`. **`TLorentzVector`** is a general four-vector class, which can be used; either for the description of position and time (`x`, `y`, `z`, `t`) or; momentum and energy (`px`, `py`, `pz`, `E`). **`TRotation`** is a class; describing a rotation of a **`TVector3`** object. **`TLorentzRotation`**; is a class to describe the Lorentz transformations including Lorentz; boosts and rotations. In addition, a **`TVector2`** is a basic; implementation of a vector in two dimensions and is not part of the; CLHEP translation. ## TVector3. ![](pictures/030001A9.png). **`TVector3`** is a general three-vector; class, which can be used for description of different vectors in 3D.; Components of three vectors:. - $x$, $y$, $z$ = basic components. - $\theta$ = azimuth angle. - $\phi$ = polar angle. - magnitude = $mag$ = $\sqrt{x^2 + y^2 + z^2}$. - transverse component = $perp$ = $\sqrt{x^2 + y^2}$. Using the **`TVector3`** class, you should remember that it contains; only common features of three vectors and lacks methods specific for; some particular vector values. For example, ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/PhysicsVectors.md:329,load,load,329,documentation/users-guide/PhysicsVectors.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/PhysicsVectors.md,1,['load'],['load']
Performance,"# Python Interface; \index{Python}. Python is a popular, open-source, dynamic programming language with an; interactive interpreter. Its interoperability with other programming; languages, both for extending Python as well as embedding it, is; excellent and many existing third-party applications and libraries have; therefore so-called ""Python bindings."" PyROOT provides Python bindings; for ROOT: it enables cross-calls from ROOT/Cling into Python and vice; versa, the intermingling of the two interpreters, and the transport of; user-level objects from one interpreter to the other. PyROOT enables; access from ROOT to any application or library that itself has Python; bindings, and it makes all ROOT functionality directly available from; the python interpreter. ## PyROOT Overview. The Python scripting language is widely used for scientific programming,; including high performance and distributed parallel code (see; <http://www.scipy.org>). It is the second most popular scripting; language (after Perl) and enjoys a wide-spread use as a ""glue language"":; practically every library and application these days comes with Python; bindings (and if not, they can be easily written or generated). `PyROOT`, a Python extension module, provides the bindings for the ROOT; class library in a generic way using the Cling dictionary. This way, it; allows the use of any ROOT classes from the Python interpreter, and thus; the ""glue-ing"" of ROOT libraries with any non-ROOT library or; applications that provide Python bindings. Further, `PyROOT` can be; loaded into the Cling interpreter to allow (as of now still rudimentary); access to Python classes. The best way to understand the benefits of; `PyROOT` is through a few examples. ### Glue-ing Applications. The `PyQt` library, see <http://www.riverbankcomputing.co.uk/pyqt>,; provides Python bindings for the Qt cross-platform GUI framework (; <http://www.trolltech.com>). With `PyROOT` and `PyQt`, adding ROOT; application layer code to a Qt GUI, ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/PythonRuby.md:877,perform,performance,877,documentation/users-guide/PythonRuby.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/PythonRuby.md,1,['perform'],['performance']
Performance,"# ROOT Development Practice. ## Overview. The development of ROOT almost exclusively happens using the [pull request](https://help.github.com/en/github/collaborating-with-issues-and-pull-requests/about-pull-requests); model of github. A pull request (PR) should contain a set focused changes; organized in one or more [atomic commits](https://en.wikipedia.org/wiki/Atomic_commit#Revision_control).; PRs should be well-documented and well-tested in order to allow other community; members to use, maintain and modify. If the PR contains performance-critical; code consider writing a benchmark against the [rootbench repository](https://github.com/root-project/rootbench). ## Quality Assurance. Each contribution should contain developer documentation in the form of code; comments and sufficient amount of tests in the form of unit and/or integration; tests. Unit tests are relatively small and quick programs focused to check if; small pieces of code and API work as expected. Integration tests are checks; which ensure the synergy between different (unit tested) components. Put in; practice, unit tests verify (member) function behavior whereas integration tests; check classes and their cooperation. The boundary between both kinds of testing; is blurred. ROOT has support for both kinds of tests in the [roottest repository](https://github.com/root-project/roottest); and supports ""inline"" unit tests in each component's `test` folder. Unit testing; uses the [GTest and GMock](https://github.com/google/googletest) infrastructure; along with small ROOT-specific extensions located in; [TestSupport](../core/test_support/). The documentation of GTest; and GMock is rather extensive and we will describe some of the features of; ROOT::TestSupport. In order to write an inline unit test, add a new file in the; nearest to the tested component's `test` folder and call `ROOT_ADD_GTEST` in the; `CMakeLists.txt` file. In many cases using standard GTest facility is sufficient to write a good test.; How",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/DEVELOPMENT.md:536,perform,performance-critical,536,README/DEVELOPMENT.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/DEVELOPMENT.md,1,['perform'],['performance-critical']
Performance,"# ROOT Macros #. You know how other books go on and on about programming fundamentals and; finally work up to building a complete, working program ? Let's skip all; that. In this guide, we will describe macros executed by the ROOT C++; interpreter Cling. It is relatively easy to compile a macro, either as a pre-compiled; library to load into ROOT, or as a stand-alone application, by adding; some include statements for header file or some ""dressing code"" to any; macro. ## General Remarks on ROOT macros ##. If you have a number of lines which you were able to execute at the ROOT; prompt, they can be turned into a ROOT macro by giving them a name which; corresponds to the file name without extension. The general structure; for a macro stored in file `MacroName.C` is. ``` {.cpp}; void MacroName() {; < ...; your lines of C++ code; ... >; }; ```. The macro is executed by typing. ``` {.cpp}; > root MacroName.C; ```. at the system prompt, or executed using `.x`. ``` {.cpp}; > root; root [0] .x MacroName.C; ```. at the ROOT prompt. or it can be loaded into a ROOT session and then; be executed by typing. ``` {.cpp}; root [0].L MacroName.C; root [1] MacroName();; ```. at the ROOT prompt. Note that more than one macro can be loaded this; way, as each macro has a unique name in the ROOT name space. A small set; of options can help making your plot nicer. ``` {.cpp}; gROOT->SetStyle(""Plain""); // set plain TStyle; gStyle->SetOptStat(111111); // draw statistics on plots,; // (0) for no output; gStyle->SetOptFit(1111); // draw fit results on plot,; // (0) for no ouput; gStyle->SetPalette(57); // set color map; gStyle->SetOptTitle(0); // suppress title box; ...; ```. Next, you should create a canvas for graphical output, with size,; subdivisions and format suitable to your needs, see documentation of; class `TCanvas`:. ``` {.cpp}; TCanvas c1(""c1"",""<Title>"",0,0,400,300); // create a canvas, specify position and size in pixels; c1.Divide(2,2); //set subdivisions, called pads; c1.cd(1); ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/primer/your_first_ROOT_macro.md:334,load,load,334,documentation/primer/your_first_ROOT_macro.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/primer/your_first_ROOT_macro.md,1,['load'],['load']
Performance,"# ROOTR Users Guide. ## DESCRIPTION; ROOT R is an interface in ROOT to call R functions using an R C++ interface (Rcpp, see http://dirk.eddelbuettel.com/code/rcpp.html).; This interface opens the possibility in ROOT to use the very large set of mathematical and statistical tools provided by R.; With ROOTR you can perform a conversion from ROOT's C++ objects to R's objects, transform the returned R objects into ROOT's C++ objects, then; the R functionality can be used directly for statistical studies in ROOT. ## ROOTR BASICS; ROOTR creates a working environment to execute R coding called from `C++`. It allows to translate some datatypes from `C++` to R; inside the R environment and vice versa in an easy way to get the most from both R and ROOT.; To ease the sending and receiving of data in both environments, I overloaded the operators `<<`,`>>` and `[]`; which make look the job as a flow of data between environments, we will see more of that later.; With this tool you ca use any library or R package wich allows you to access a big amount of benefits to make statistical analysis.; ROOTR also has a R events processing system, which allows to use the R graphical system from `C++`. ## INSTALLATION; To install ROOTR please read first. - [https://root.cern.ch/building-root](https://root.cern.ch/building-root); - [https://root.cern.ch/build-prerequisites](https://root.cern.ch/build-prerequisites). ### COMPILING ROOTR ON MAC WITH CMAKE:; **NOTE:** Mac OSX Yosemite last xcode and without macports. **Prerequisites**. - xcode; - [xquartz](http://xquartz.macosforge.org/); - [R last version](https://www.r-project.org); - [cmake](https://cmake.org/download/). To compile with cmake added into ~/.profile. ~~~{.sh}; export PATH=$PATH:/Applications/CMake.app/Contents/bin/; ~~~; and. ~~~{.sh}; source ~/.profile; ~~~. Install needed R packages, open R and in the prompt type. ~~~{.sh}; install.packages(c('Rcpp','RInside')); ~~~; select a mirror and install. Install the next additional pac",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/r/doc/users-guide/ROOTR_Users_Guide.md:315,perform,perform,315,bindings/r/doc/users-guide/ROOTR_Users_Guide.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/r/doc/users-guide/ROOTR_Users_Guide.md,1,['perform'],['perform']
Performance,"# Speculative Load Hardening. ## A Spectre Variant #1 Mitigation Technique. Author: Chandler Carruth - [chandlerc@google.com](mailto:chandlerc@google.com). ## Problem Statement. Recently, Google Project Zero and other researchers have found information leak; vulnerabilities by exploiting speculative execution in modern CPUs. These; exploits are currently broken down into three variants:; * GPZ Variant #1 (a.k.a. Spectre Variant #1): Bounds check (or predicate) bypass; * GPZ Variant #2 (a.k.a. Spectre Variant #2): Branch target injection; * GPZ Variant #3 (a.k.a. Meltdown): Rogue data cache load. For more details, see the Google Project Zero blog post and the Spectre research; paper:; * https://googleprojectzero.blogspot.com/2018/01/reading-privileged-memory-with-side.html; * https://spectreattack.com/spectre.pdf. The core problem of GPZ Variant #1 is that speculative execution uses branch; prediction to select the path of instructions speculatively executed. This path; is speculatively executed with the available data, and may load from memory and; leak the loaded values through various side channels that survive even when the; speculative execution is unwound due to being incorrect. Mispredicted paths can; cause code to be executed with data inputs that never occur in correct; executions, making checks against malicious inputs ineffective and allowing; attackers to use malicious data inputs to leak secret data. Here is an example,; extracted and simplified from the Project Zero paper:; ```; struct array {; unsigned long length;; unsigned char data[];; };; struct array *arr1 = ...; // small array; struct array *arr2 = ...; // array of size 0x400; unsigned long untrusted_offset_from_caller = ...;; if (untrusted_offset_from_caller < arr1->length) {; unsigned char value = arr1->data[untrusted_offset_from_caller];; unsigned long index2 = ((value&1)*0x100)+0x200;; unsigned char value2 = arr2->data[index2];; }; ```. The key of the attack is to call this with `untrusted_off",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:591,cache,cache,591,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,2,"['cache', 'load']","['cache', 'load']"
Performance,"# The Geometry Package; \index{Geometry}. The new ROOT geometry package is a tool for building, browsing,; navigating and visualizing detector geometries. The code works; standalone with respect to any tracking Monte-Carlo engine; therefore,; it does not contain any constraints related to physics. However, the; navigation features provided by the package are designed to optimize; particle transport through complex geometries, working in correlation; with simulation packages such as GEANT3, GEANT4 and FLUKA. ## Quick Start: Creating the ""world"". This chapter will provide a detailed description on how to build valid; geometries as well as the ways to optimize them. There are several; components gluing together the geometrical model, but for the time being; let us get used with the most basic concepts. The basic bricks for building-up the model are called; `volumes`**.**These represent the un-positioned pieces of the geometry; puzzle. The difference is just that the relationship between the pieces; is not defined by neighbors, but by `containment`. In other words,; volumes are put one inside another making an in-depth hierarchy. From; outside, the whole thing looks like a big pack that you can open finding; out other smaller packs nicely arranged waiting to be opened at their; turn. The biggest one containing all others defines the ""`world`"" of the; model. We will often call this `master reference system (MARS)`. Going; on and opening our packs, we will obviously find out some empty ones,; otherwise, something is very wrong... We will call these leaves (by; analogy with a tree structure). On the other hand, any volume is a small world by itself - what we need; to do is to take it out and to ignore all the rest since it is a; self-contained object. In fact, the modeller can act like this,; considering a given volume as temporary MARS, but we will describe this; feature later on. Let us focus on the biggest pack - it is mandatory to; define one. Consider the simplest geom",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md:373,optimiz,optimize,373,documentation/users-guide/Geometry.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md,2,['optimiz'],['optimize']
Performance,"# Threads. A thread is an independent flow of control that operates within the same; address space as other independent flows of controls within a process.; In most UNIX systems, thread and process characteristics are grouped; into a single entity called a process. Sometimes, threads are called; ""lightweight processes''. Note: This introduction is adapted from the AIX 4.3 Programmer's Manual. ## Threads and Processes. In traditional single-threaded process systems, a process has a set of; properties. In multi-threaded systems, these properties are divided; between processes and threads. ### Process Properties. A process in a multi-threaded system is the changeable entity. It must; be considered as an execution frame. It has all traditional process; attributes, such as:. - Process ID, process group ID, user ID, and group ID. - Environment. - Working directory. A process also provides a common address space and common system; resources:. - File descriptors. - Signal actions. - Shared libraries. - Inter-process communication tools (such as message queues, pipes,; semaphores, or shared memory). ### Thread Properties. A thread is the schedulable entity. It has only those properties that; are required to ensure its independent flow of control. These include; the following properties:. - Stack. - Scheduling properties (such as policy or priority). - Set of pending and blocked signals. - Some thread-specific data (TSD). An example of thread-specific data is the error indicator, `errno`. In; multi-threaded systems, `errno` is no longer a global variable, but; usually a subroutine returning a thread-specific `errno` value. Some; other systems may provide other implementations of `errno`. With respect; to ROOT, a thread specific data is for example the ***`gPad`*** pointer,; which is treated in a different way, whether it is accessed from any; thread or the main thread. Threads within a process must not be considered as a group of processes; (even though in Linux each thread re",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Threads.md:509,multi-thread,multi-threaded,509,documentation/users-guide/Threads.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Threads.md,2,['multi-thread'],['multi-threaded']
Performance,"# Trees. ## Why Should You Use a Tree?. In the ""Input/Output"" chapter, we saw how objects can be saved in ROOT; files. In case you want to store large quantities of same-class objects,; ROOT has designed the **`TTree`** and **`TNtuple`** classes specifically; for that purpose. The **`TTree`** class is optimized to reduce disk; space and enhance access speed. A **`TNtuple`** is a **`TTree`** that is; limited to only hold floating-point numbers; a **`TTree`** on the other; hand can hold all kind of data, such as objects or arrays in addition to; all the simple types. When using a **`TTree`**, we fill its branch buffers with leaf data and; the buffers are written to disk when it is full. Branches, buffers, and; leafs, are explained a little later in this chapter, but for now, it is; important to realize that each object is not written individually, but; rather collected and written a bunch at a time. This is where the **`TTree`** takes advantage of compression and will; produce a much smaller file than if the objects were written; individually. Since the unit to be compressed is a buffer, and the; **`TTree`** contains many same-class objects, the header of the objects; can be compressed. The **`TTree`** reduces the header of each object, but it still contains; the class name. Using compression, the class name of each same-class; object has a good chance of being compressed, since the compression; algorithm recognizes the bit pattern representing the class name. Using; a **`TTree`** and compression the header is reduced to about 4 bytes; compared to the original 60 bytes. However, if compression is turned; off, you will not see these large savings. The **`TTree`** is also used to optimize the data access. A tree uses a; hierarchy of branches, and each branch can be read independently from; any other branch. Now, assume that `Px` and `Py` are data members of the; event, and we would like to compute `Px2 + Py2` for every event; and histogram the result. If we had saved the",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md:303,optimiz,optimized,303,documentation/users-guide/Trees.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md,1,['optimiz'],['optimized']
Performance,"# Workaround for MSVC ARM64 performance regression:; # https://developercommunity.visualstudio.com/t/Compiling-a-specific-code-for-ARM64-with/10444970; # Since /O1 and /O2 represent a set of optimizations,; # our goal is to disable the /Og flag while retaining the other optimizations from the /O1|/O2 set; if(MSVC AND NOT CMAKE_CXX_COMPILER_ID MATCHES Clang; AND MSVC_VERSION VERSION_GREATER_EQUAL 1932; AND CMAKE_SYSTEM_PROCESSOR MATCHES ""ARM64""). string(TOUPPER ""${CMAKE_BUILD_TYPE}"" uppercase_CMAKE_BUILD_TYPE); string(REGEX MATCHALL ""/[Oo][12]"" opt_flags ""${CMAKE_CXX_FLAGS} ${CMAKE_CXX_FLAGS_${uppercase_CMAKE_BUILD_TYPE}}""); if (opt_flags); if(opt_flags MATCHES ""1$""); set(opt_flags ""/Od;/Os;/Oy;/Ob2;/GF;/Gy""); elseif (opt_flags MATCHES ""2$""); set(opt_flags ""/Od;/Oi;/Ot;/Oy;/Ob2;/GF;/Gy""); endif(); set_source_files_properties(StandardLibrary.cpp PROPERTIES COMPILE_OPTIONS ""${opt_flags}""); endif(); endif(). add_clang_library(clangToolingInclusionsStdlib; StandardLibrary.cpp. LINK_LIBS; clangAST; ); ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Tooling/Inclusions/Stdlib/CMakeLists.txt:28,perform,performance,28,interpreter/llvm-project/clang/lib/Tooling/Inclusions/Stdlib/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Tooling/Inclusions/Stdlib/CMakeLists.txt,3,"['optimiz', 'perform']","['optimizations', 'performance']"
Performance,"# llvm-exegesis. `llvm-exegesis` is a benchmarking tool that accepts or assembles a snippet and; can measure characteristics of that snippet by executing it while keeping track; of performance counters. ### Currently Supported Platforms. `llvm-exegesis` is quite platform-dependent and currently only supports a couple; platform configurations for benchmarking. The limitations are listed below.; Analysis mode in `llvm-exegesis` is supported on all platforms on which LLVM is. #### Currently Supported Operating Systems for Benchmarking. Currently, `llvm-exegesis` only supports benchmarking on Linux. This is mainly; due to a dependency on the Linux perf subsystem for reading performance; counters. The subprocess execution mode and memory annotations currently only supports; Linux due to a heavy reliance on many Linux specific syscalls/syscall; implementations. #### Currently Supported Architectures for Benchmarking. Currently, using `llvm-exegesis` for benchmarking is supported on the following; architectures:; * x86; * 64-bit only due to this being the only implemented calling convention; in `llvm-exegesis` currently.; * ARM; * AArch64 only; * MIPS; * PowerPC (PowerPC64LE only). Note that not benchmarking functionality is guaranteed to work on all platforms. Memory annotations are currently only supported on 64-bit X86. There is no; inherent limitations for porting memory annotations to other architectures, but; parts of the test harness are implemented as MCJITed assembly that is generated; in `./lib/X86/Target.cpp` that would need to be implemented on other architectures; to bring up support.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-exegesis/README.md:181,perform,performance,181,interpreter/llvm-project/llvm/tools/llvm-exegesis/README.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-exegesis/README.md,2,['perform'],['performance']
Performance,"# rlibmap. The tools used to generate rootmap files are rootcling and genreflex. The; rlibmap tool is not present any more in ROOT starting from release 6.00.00. ### Rootmap files. To enhance the set of functionalities offered by ROOT and its new interpreter,; the format of the rootmaps evolved. Rootmap in the old format cannot be; produced anymore but only read. The new rootmaps can be still be concatenated.; A rootmap file now contains:. - One (or more) section for forward declarations. These are real C++; forward declarations of templates and namespaces. This is needed for Cling; to be able to parse templates' instantiations and for some autoloading; functionalities.; - One (or more) libraries sections. These sections describe the ensamble of; the autoload keys related to one or more shared libraries. An autoload key; can be a class name, a namespace name, a typedef or alias or a header file name.; - Single line comments, which start with a ""#"" character. At ROOT startup, a check is performed on autoload keys. If the same key (which is not a template instantiation) refers to two different libraries (or sets of libraries) a warning is issued.; A typical Rootmap file look like:; ``` {.cpp}; { decls }; fwd declaration 1;; fwd declaration 2;; [...]; fwd declaration N;. [ libraryName1 libraryName2 ... ]; class className1; class className2; ...; typedef typedefName1; typedef typedefName2; ...; header headerName1; header headerName2; ... ```. ### TROOT. The list returned by `GetListOfTypes` is no longer filled when the dictionary; are loaded but instead are filled on demand, when the user explicitly (directly; or indirectly) request each typedef. In particular this means that. ``` {.cpp}; gROOT->GetListOfTypes()->ls(); // or Print(); ```. no longer prints the list of all available typedef but instead list only the; typedefs that have been previously accessed throught the list (plus the builtins; types). ### ACliC. ACLiC has the following backward incompatibilities:. - S",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/doc/v600/index.md:10175,perform,performed,10175,core/doc/v600/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/doc/v600/index.md,1,['perform'],['performed']
Performance,"# rootreadspeed. `rootreadspeed` is a tool used to help identify bottlenecks in root analysis programs; by providing an idea of what throughput you can expect when reading ROOT files in; certain configurations. It does this by providing information about the number of bytes read from your files,; how long this takes, and the different throughputs in MB/s, both in total and per thread. ## Compressed vs Uncompressed Throughput:. Throughput speeds are provided as compressed and uncompressed - ROOT files are usually; saved in compressed format, so these will often differ. Compressed bytes is the total; number of bytes read from TFiles during the readspeed test (possibly including meta-data).; Uncompressed bytes is the number of bytes processed by reading the branch values in the TTree.; Throughput is calculated as the total number of bytes over the total runtime (including; decompression time) in the uncompressed and compressed cases. ## Interpreting results:. ### There are three possible scenarios when using rootreadspeed, namely:. - The 'Real Time' is significantly lower than your own analysis runtime.; This would imply your actual application code is dominating the runtime of your analysis,; ie. your analysis logic or framework is taking up the time.; The best way to decrease the runtime would be to optimize your code (or the framework's),; parallelize it onto multiple threads if possible (for example with; [RDataFrame](https://root.cern/doc/master/classROOT_1_1RDataFrame.html); and [EnableImplicitMT](https://root.cern/doc/master/namespaceROOT.html#a06f2b8b216b615e5abbc872c9feff40f)); or switch to a machine with a more performant CPU.; - The 'Real Time' is significantly higher than 'CPU Time / number of threads'*.; If the real time is higher than the CPU time per core it implies the reading of data is the; bottleneck, as the CPU cores are wasting time waiting for data to arrive from your disk/drive; or network connection in order to decompress it.; The best way to dec",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/readspeed/README.md:65,bottleneck,bottlenecks,65,tree/readspeed/README.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/readspeed/README.md,3,"['bottleneck', 'throughput']","['bottlenecks', 'throughput', 'throughputs']"
Performance,"## Core Libraries. ### Interpreter. The new interface `TInterpreter::Declare(const char* code)` will declare the; code to the interpreter with all interpreter extensions disabled, i.e. as; ""proper"" C++ code. No autoloading or synamic lookup will be performed. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/doc/v602/index.md:249,perform,performed,249,core/doc/v602/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/doc/v602/index.md,1,['perform'],['performed']
Performance,"## OPENUI5 Panel example. This is simplest way to use openui5 widget with RWebWindow. It is normal xml::View, but controller should be derived from rootui5/panel/Controller.; This class provides methods, which simplify handling of communication between server and client. First of all, when creating RWebWindow, one should configure panel name. Like:. auto win = ROOT::RWebWindow::Create();. win->SetPanelName(""localapp.view.TestPanel"");. Namespace ""localapp"" in this case corresponds to openui5 files, which will be loaded from current directory.; Therefore `""localapp.view.TestPanel""` means view, which will be loaded from `./view/TestPanel.view.xml` file. Controller is configured in the XML file and called `""localapp.controller.TestPanel""`.; Means it will be loaded from `./controller/TestPanel.controller.js` file. In the controller one use `onPanelInit` and `onPanelExit` methods to handle initialization and close of widget.; Method `panelSend` should be used to send string data to the server. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tutorials/webgui/panel/Readme.md:517,load,loaded,517,tutorials/webgui/panel/Readme.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tutorials/webgui/panel/Readme.md,3,['load'],['loaded']
Performance,"## Tree Libraries. ### TTreeReader. ROOT offers a new class `TTreeReader` that gives simple, safe and fast access to the content of a `TTree`.; Using it is trivial:. ``` {.cpp}; #include ""TFile.h""; #include ""TH1F.h""; #include ""TTreeReader.h""; #include ""TTreeReaderValue.h"". void hsimpleReader() {; TH1F *myHist = new TH1F(""h1"",""ntuple"",100,-4,4);; TFile *myFile = TFile::Open(""hsimple.root"");. // Create a TTreeReader for the tree, for instance by passing the; // TTree's name and the TDirectory / TFile it is in.; TTreeReader myReader(""ntuple"", myFile);. // The branch ""px"" contains floats; access them as myPx.; TTreeReaderValue<Float_t> myPx(myReader, ""px"");; // The branch ""py"" contains floats, too; access those as myPy.; TTreeReaderValue<Float_t> myPy(myReader, ""py"");. // Loop over all entries of the TTree or TChain.; while (myReader.Next()) {; // Just access the data as if myPx and myPy were iterators (note the '*'; // in front of them):; myHist->Fill(*myPx + *myPy);; }. myHist->Draw();; }; ```. TTreeReader checks whether the type that you expect can be extracted from the tree's branch and will clearly complain if not.; It reads on demand: only data that are actually needed are read, there is no need for `SetBranchStatus()`, `SetBranchAddress()`, `LoadTree()` or anything alike.; It uses the memory management of TTree, removing possible double deletions or memory leaks and relieveing you from the need to manage the memory yourself.; It turns on the tree cache, accelerating the reading of data.; It has been extensively tested on all known types of TTree branches and is thus a generic, fits-all access method for data stored in TTrees. ### TTreePlayer. - The TEntryList for ||-Coord plot was not defined correctly. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v600/index.md:1474,cache,cache,1474,tree/doc/v600/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v600/index.md,1,['cache'],['cache']
Performance,"### TTree Behavior change. #### Merging. Added fast cloning support to TTree::MergeTrees and TTree::Merge(TCollection*,Option_t*). #### TTreeCache. The TTreeCache is now enabled by default. The default size of the TTreeCache; is the estimated size of a cluster size for the TTree. The TTreeCache; prefilling is also enabled by default; when in learning phase rather than; reading each requested branch individually, the TTreeCache will read all the; branches thus trading off the latencies inherent to multiple small reads for; the potential of requesting more data than needed by read from the disk or; server the baskets for too many branches. The default behavior can be changed by either updating one of the rootrc files; or by setting environment variables. The rootrc files, both the global and the; local ones, now support the following the resource variable TTreeCache.Size; which set the default size factor for auto sizing TTreeCache for TTrees. The; estimated cluster size for the TTree and this factor is used to give the cache; size. If option is set to zero auto cache creation is disabled and the default; cache size is the historical one (equivalent to factor 1.0). If set to; non zero auto cache creation is enabled and both auto created and; default sized caches will use the configured factor: 0.0 no automatic cache; and greater than 0.0 to enable cache. This value can be overridden by the; environment variable ROOT_TTREECACHE_SIZE. The resource variable TTreeCache.Prefill sets the default TTreeCache prefilling; type. The prefill type may be: 0 for no prefilling and 1 to prefill all; the branches. It can be overridden by the environment variable ROOT_TTREECACHE_PREFILL. In particular the default can be set back to the same as in version 5 by; setting TTreeCache.Size (or ROOT_TTREECACHE_SIZE) and TTreeCache.Prefill; (or ROOT_TTREECACHE_PREFILL) both to zero. TTree methods which are expected to modify a cache, like AddBranchToCache, will; attempt to setup a cache of defa",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md:13435,cache,cache,13435,README/ReleaseNotes/v604/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md,1,['cache'],['cache']
Performance,"############################################################################; # CMakeLists.txt file for building ROOT RooFitMultiProcess package; # @author Patrick Bos, Netherlands eScience Center; ############################################################################. ROOT_LINKER_LIBRARY(RooFitMultiProcess; src/worker.cxx; src/Messenger.cxx; src/ProcessManager.cxx; src/util.cxx; src/Queue.cxx; src/FIFOQueue.cxx; src/PriorityQueue.cxx; src/JobManager.cxx; src/Job.cxx; src/Config.cxx; src/ProcessTimer.cxx; src/HeatmapAnalyzer.cxx; LIBRARIES; Core; DEPENDENCIES; RooFitZMQ; ). target_link_libraries(RooFitMultiProcess PUBLIC Hist RooFitZMQ); set(RooFitMultiProcess_INCLUDE_DIR ""${CMAKE_CURRENT_SOURCE_DIR}/res""); target_include_directories(RooFitMultiProcess; PRIVATE ${RooFitMultiProcess_INCLUDE_DIR}; INTERFACE $<BUILD_INTERFACE:${RooFitMultiProcess_INCLUDE_DIR}>). if(builtin_nlohmannjson); target_include_directories(RooFitMultiProcess PRIVATE ${CMAKE_SOURCE_DIR}/builtins); else(); target_link_libraries(RooFitMultiProcess PRIVATE nlohmann_json::nlohmann_json); endif(). ROOT_ADD_TEST_SUBDIRECTORY(test). ROOT_INSTALL_HEADERS(); ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/multiprocess/CMakeLists.txt:393,Queue,Queue,393,roofit/multiprocess/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/multiprocess/CMakeLists.txt,1,['Queue'],['Queue']
Performance,"%6:gr32 = ADD32rm %4, %2, 4, killed %5, 0, $noreg, implicit-def dead $eflags :: (load 4 from %ir.addr2); %7:gr32 = SUB32rr %6, %0, implicit-def $eflags, debug-location !5; JB_1 %bb.1, implicit $eflags, debug-location !5; JMP_1 %bb.2, debug-location !5. bb.2.bb2:; %8:gr32 = MOV32r0 implicit-def dead $eflags; $eax = COPY %8, debug-location !5; RET 0, $eax, debug-location !5. Observe first that there is a DBG_VALUE instruction for every ``llvm.dbg.value``; intrinsic in the source IR, ensuring no source level assignments go missing.; Then consider the different ways in which variable locations have been recorded:. * For the first dbg.value an immediate operand is used to record a zero value.; * The dbg.value of the PHI instruction leads to a DBG_VALUE of virtual register; ``%0``.; * The first GEP has its effect folded into the first load instruction; (as a 4-byte offset), but the variable location is salvaged by folding; the GEPs effect into the DIExpression.; * The second GEP is also folded into the corresponding load. However, it is; insufficiently simple to be salvaged, and is emitted as a ``$noreg``; DBG_VALUE, indicating that the variable takes on an undefined location.; * The final dbg.value has its Value placed in virtual register ``%1``. Instruction Scheduling; ----------------------. A number of passes can reschedule instructions, notably instruction selection; and the pre-and-post RA machine schedulers. Instruction scheduling can; significantly change the nature of the program -- in the (very unlikely) worst; case the instruction sequence could be completely reversed. In such; circumstances LLVM follows the principle applied to optimizations, that it is; better for the debugger not to display any state than a misleading state.; Thus, whenever instructions are advanced in order of execution, any; corresponding DBG_VALUE is kept in its original position, and if an instruction; is delayed then the variable is given an undefined location for the duration; of the d",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:32408,load,load,32408,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,1,['load'],['load']
Performance,%`; * - llvm/examples/Kaleidoscope/BuildingAJIT/Chapter2; - `2`; - `1`; - `1`; - :part:`50%`; * - llvm/examples/Kaleidoscope/BuildingAJIT/Chapter3; - `2`; - `1`; - `1`; - :part:`50%`; * - llvm/examples/Kaleidoscope/BuildingAJIT/Chapter4; - `2`; - `0`; - `2`; - :none:`0%`; * - llvm/examples/Kaleidoscope/Chapter2; - `1`; - `1`; - `0`; - :good:`100%`; * - llvm/examples/Kaleidoscope/Chapter3; - `1`; - `0`; - `1`; - :none:`0%`; * - llvm/examples/Kaleidoscope/Chapter4; - `1`; - `0`; - `1`; - :none:`0%`; * - llvm/examples/Kaleidoscope/Chapter5; - `1`; - `0`; - `1`; - :none:`0%`; * - llvm/examples/Kaleidoscope/Chapter6; - `1`; - `0`; - `1`; - :none:`0%`; * - llvm/examples/Kaleidoscope/Chapter7; - `1`; - `0`; - `1`; - :none:`0%`; * - llvm/examples/Kaleidoscope/Chapter8; - `1`; - `0`; - `1`; - :none:`0%`; * - llvm/examples/Kaleidoscope/Chapter9; - `1`; - `0`; - `1`; - :none:`0%`; * - llvm/examples/Kaleidoscope/include; - `1`; - `1`; - `0`; - :good:`100%`; * - llvm/examples/Kaleidoscope/MCJIT/cached; - `2`; - `0`; - `2`; - :none:`0%`; * - llvm/examples/Kaleidoscope/MCJIT/complete; - `1`; - `0`; - `1`; - :none:`0%`; * - llvm/examples/Kaleidoscope/MCJIT/initial; - `1`; - `0`; - `1`; - :none:`0%`; * - llvm/examples/Kaleidoscope/MCJIT/lazy; - `2`; - `0`; - `2`; - :none:`0%`; * - llvm/examples/ModuleMaker; - `1`; - `0`; - `1`; - :none:`0%`; * - llvm/examples/OrcV2Examples; - `1`; - `1`; - `0`; - :good:`100%`; * - llvm/examples/OrcV2Examples/LLJITDumpObjects; - `1`; - `1`; - `0`; - :good:`100%`; * - llvm/examples/OrcV2Examples/LLJITWithCustomObjectLinkingLayer; - `1`; - `1`; - `0`; - :good:`100%`; * - llvm/examples/OrcV2Examples/LLJITWithExecutorProcessControl; - `1`; - `1`; - `0`; - :good:`100%`; * - llvm/examples/OrcV2Examples/LLJITWithGDBRegistrationListener; - `1`; - `1`; - `0`; - :good:`100%`; * - llvm/examples/OrcV2Examples/LLJITWithInitializers; - `1`; - `1`; - `0`; - :good:`100%`; * - llvm/examples/OrcV2Examples/LLJITWithLazyReexports; - `1`; - `1`; - `0`; - :good:`100%`; * -,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormattedStatus.rst:59701,cache,cached,59701,interpreter/llvm-project/clang/docs/ClangFormattedStatus.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormattedStatus.rst,1,['cache'],['cached']
Performance,"%d to i64; %j = trunc i64 %i to i32; store i32 %j, ptr @glbi ; %d is captured. ret ptr %e ; %e is captured; }. 2. The call stores any bit of the pointer carrying information into a place,; and the stored bits can be safely read from the place by another thread via; synchronization. .. code-block:: llvm. @lock = global i1 true. define void @f(ptr %a) {; store ptr %a, ptr* @glb; store atomic i1 false, ptr @lock release ; %a is captured because another thread can safely read @glb; store ptr null, ptr @glb; ret void; }. 3. The call's behavior depends on any bit of the pointer carrying information. .. code-block:: llvm. @glb = global i8 0. define void @f(ptr %a) {; %c = icmp eq ptr %a, @glb; br i1 %c, label %BB_EXIT, label %BB_CONTINUE ; escapes %a; BB_EXIT:; call void @exit(); unreachable; BB_CONTINUE:; ret void; }. 4. The pointer is used in a volatile access as its address. .. _volatile:. Volatile Memory Accesses; ------------------------. Certain memory accesses, such as :ref:`load <i_load>`'s,; :ref:`store <i_store>`'s, and :ref:`llvm.memcpy <int_memcpy>`'s may be; marked ``volatile``. The optimizers must not change the number of; volatile operations or change their order of execution relative to other; volatile operations. The optimizers *may* change the order of volatile; operations relative to non-volatile operations. This is not Java's; ""volatile"" and has no cross-thread synchronization behavior. A volatile load or store may have additional target-specific semantics.; Any volatile operation can have side effects, and any volatile operation; can read and/or modify state which is not accessible via a regular load; or store in this module. Volatile operations may use addresses which do; not point to memory (like MMIO registers). This means the compiler may; not use a volatile operation to prove a non-volatile access to that; address has defined behavior. The allowed side-effects for volatile accesses are limited. If a; non-volatile store to a given address would be ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:145869,load,load,145869,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['load'],['load']
Performance,"%eax; ret. GCC knows several different ways to codegen it, one of which is this:. _test1:; movl 4(%esp), %eax; cmpl $-1, %eax; leal 7(%eax), %ecx; cmovle %ecx, %eax; sarl $3, %eax; ret. which is probably slower, but it's interesting at least :). //===---------------------------------------------------------------------===//. We are currently lowering large (1MB+) memmove/memcpy to rep/stosl and rep/movsl; We should leave these as libcalls for everything over a much lower threshold,; since libc is hand tuned for medium and large mem ops (avoiding RFO for large; stores, TLB preheating, etc). //===---------------------------------------------------------------------===//. Optimize this into something reasonable:; x * copysign(1.0, y) * copysign(1.0, z). //===---------------------------------------------------------------------===//. Optimize copysign(x, *y) to use an integer load from y. //===---------------------------------------------------------------------===//. The following tests perform worse with LSR:. lambda, siod, optimizer-eval, ackermann, hash2, nestedloop, strcat, and Treesor. //===---------------------------------------------------------------------===//. Adding to the list of cmp / test poor codegen issues:. int test(__m128 *A, __m128 *B) {; if (_mm_comige_ss(*A, *B)); return 3;; else; return 4;; }. _test:; 	movl 8(%esp), %eax; 	movaps (%eax), %xmm0; 	movl 4(%esp), %eax; 	movaps (%eax), %xmm1; 	comiss %xmm0, %xmm1; 	setae %al; 	movzbl %al, %ecx; 	movl $3, %eax; 	movl $4, %edx; 	cmpl $0, %ecx; 	cmove %edx, %eax; 	ret. Note the setae, movzbl, cmpl, cmove can be replaced with a single cmovae. There; are a number of issues. 1) We are introducing a setcc between the result of the; intrisic call and select. 2) The intrinsic is expected to produce a i32 value; so a any extend (which becomes a zero extend) is added. We probably need some kind of target DAG combine hook to fix this. //===---------------------------------------------------------------------===//. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README.txt:5460,perform,perform,5460,interpreter/llvm-project/llvm/lib/Target/X86/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README.txt,2,['perform'],['perform']
Performance,"%esp), %esi; 	addl	%edx, %esi; 	imull	20(%esp), %ecx; 	movl	%esi, %edx; 	addl	%ecx, %edx; 	popl	%esi; 	ret. This looks like a scheduling deficiency and lack of remat of the load from; the argument area. ICC apparently produces:. movl 8(%esp), %ecx; imull 12(%esp), %ecx; movl 16(%esp), %eax; imull 4(%esp), %eax ; addl %eax, %ecx ; movl 4(%esp), %eax; mull 12(%esp) ; addl %ecx, %edx; ret. Note that it remat'd loads from 4(esp) and 12(esp). See this GCC PR:; http://gcc.gnu.org/bugzilla/show_bug.cgi?id=17236. //===---------------------------------------------------------------------===//. We can fold a store into ""zeroing a reg"". Instead of:. xorl %eax, %eax; movl %eax, 124(%esp). we should get:. movl $0, 124(%esp). if the flags of the xor are dead. Likewise, we isel ""x<<1"" into ""add reg,reg"". If reg is spilled, this should; be folded into: shl [mem], 1. //===---------------------------------------------------------------------===//. In SSE mode, we turn abs and neg into a load from the constant pool plus a xor; or and instruction, for example:. 	xorpd	LCPI1_0, %xmm2. However, if xmm2 gets spilled, we end up with really ugly code like this:. 	movsd	(%esp), %xmm0; 	xorpd	LCPI1_0, %xmm0; 	movsd	%xmm0, (%esp). Since we 'know' that this is a 'neg', we can actually ""fold"" the spill into; the neg/abs instruction, turning it into an *integer* operation, like this:. 	xorl 2147483648, [mem+4] ## 2147483648 = (1 << 31). you could also use xorb, but xorl is less likely to lead to a partial register; stall. Here is a contrived testcase:. double a, b, c;; void test(double *P) {; double X = *P;; a = X;; bar();; X = -X;; b = X;; bar();; c = X;; }. //===---------------------------------------------------------------------===//. The generated code on x86 for checking for signed overflow on a multiply the; obvious way is much longer than it needs to be. int x(int a, int b) {; long long prod = (long long)a*b;; return prod > 0x7FFFFFFF || prod < (-0x7FFFFFFF-1);; }. See PR2053 for more det",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README.txt:22310,load,load,22310,interpreter/llvm-project/llvm/lib/Target/X86/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README.txt,2,['load'],['load']
Performance,"%i\n"", Y);; }. If we want to know how ``function_to_test`` behaves when we change the behavior; of ``function_to_mock`` we can test it by writing a test harness:. .. code-block:: c. void function_to_test();. int function_to_mock(int X) {; printf(""used mock utility function\n"");; return 42;; }. int main(int argc, char *argv[]) {; function_to_test():; return 0;; }. Under normal circumstances these objects could not be linked together:; ``function_to_test`` is static and could not be resolved outside; ``test_code.o``, the two ``function_to_mock`` functions would result in a; duplicate definition error, and ``irrelevant_external`` is undefined.; However, using ``-harness`` and ``-phony-externals`` we can run this code; with:. .. code-block:: sh. % clang -c -o test_code_harness.o test_code_harness.c; % llvm-jitlink -phony-externals test_code.o -harness test_code_harness.o; used mock utility function; Y is 42. The ``-harness`` option may be of interest to people who want to perform some; very late testing on build products to verify that compiled code behaves as; expected. On basic C test cases this is relatively straightforward. Mocks for; more complicated languages (e.g. C++) are much trickier: Any code involving; classes tends to have a lot of non-trivial surface area (e.g. vtables) that; would require great care to mock. Tips for JITLink backend developers; -----------------------------------. #. Make liberal use of assert and ``llvm::Error``. Do *not* assume that the input; object is well formed: Return any errors produced by libObject (or your own; object parsing code) and validate as you construct. Think carefully about the; distinction between contract (which should be validated with asserts and; llvm_unreachable) and environmental errors (which should generate; ``llvm::Error`` instances). #. Don't assume you're linking in-process. Use libSupport's sized,; endian-specific types when reading/writing content in the ``LinkGraph``. As a ""minimum viable"" JITLink wrappe",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/JITLink.rst:42490,perform,perform,42490,interpreter/llvm-project/llvm/docs/JITLink.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/JITLink.rst,1,['perform'],['perform']
Performance,"%indvar, 1; %exitcond = icmp eq i64 %indvar.next, %tmp22; br i1 %exitcond, label %for.cond.for.end_crit_edge, label %for.body. It is good that we hoisted the reloads of numf2's, and Y out of the loop and; sunk the store to winner out. However, this is awful on several levels: the conditional truncate in the loop; (-indvars at fault? why can't we completely promote the IV to i64?). Beyond that, we have a partially redundant load in the loop: if ""winner"" (aka ; %i.01718) isn't updated, we reload Y[winner].y the next time through the loop.; Similarly, the addressing that feeds it (including the sext) is redundant. In; the end we get this generated assembly:. LBB0_2: ## %for.body; ## =>This Inner Loop Header: Depth=1; 	movsd	(%rdi), %xmm0; 	movslq	%edx, %r8; 	shlq	$4, %r8; 	ucomisd	(%rcx,%r8), %xmm0; 	jbe	LBB0_4; 	movl	%esi, %edx; LBB0_4: ## %for.inc; 	addq	$16, %rdi; 	incq	%rsi; 	cmpq	%rsi, %rax; 	jne	LBB0_2. All things considered this isn't too bad, but we shouldn't need the movslq or; the shlq instruction, or the load folded into ucomisd every time through the; loop. On an x86-specific topic, if the loop can't be restructure, the movl should be a; cmov. //===---------------------------------------------------------------------===//. [STORE SINKING]. GCC PR37810 is an interesting case where we should sink load/store reload; into the if block and outside the loop, so we don't reload/store it on the; non-call path. for () {; *P += 1;; if (); call();; else; ...; ->; tmp = *P; for () {; tmp += 1;; if () {; *P = tmp;; call();; tmp = *P;; } else ...; }; *P = tmp;. We now hoist the reload after the call (Transforms/GVN/lpre-call-wrap.ll), but; we don't sink the store. We need partially dead store sinking. //===---------------------------------------------------------------------===//. [LOAD PRE CRIT EDGE SPLITTING]. GCC PR37166: Sinking of loads prevents SROA'ing the ""g"" struct on the stack; leading to excess stack traffic. This could be handled by GVN with some crazy; symbol",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/README.txt:31795,load,load,31795,interpreter/llvm-project/llvm/lib/Target/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/README.txt,2,['load'],['load']
Performance,"%r = call <2 x i1> @llvm.vp.is.fpclass.v2f16(<2 x half> %x, i32 3, <2 x i1> %m, i32 %evl); %t = call <vscale x 2 x i1> @llvm.vp.is.fpclass.nxv2f16(<vscale x 2 x half> %x, i32 3, <vscale x 2 x i1> %m, i32 %evl). .. _int_mload_mstore:. Masked Vector Load and Store Intrinsics; ---------------------------------------. LLVM provides intrinsics for predicated vector load and store operations. The predicate is specified by a mask operand, which holds one bit per vector element, switching the associated vector lane on or off. The memory addresses corresponding to the ""off"" lanes are not accessed. When all bits of the mask are on, the intrinsic is identical to a regular vector load or store. When all bits are off, no memory is accessed. .. _int_mload:. '``llvm.masked.load.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. The loaded data is a vector of any integer, floating-point or pointer data type. ::. declare <16 x float> @llvm.masked.load.v16f32.p0(ptr <ptr>, i32 <alignment>, <16 x i1> <mask>, <16 x float> <passthru>); declare <2 x double> @llvm.masked.load.v2f64.p0(ptr <ptr>, i32 <alignment>, <2 x i1> <mask>, <2 x double> <passthru>); ;; The data is a vector of pointers; declare <8 x ptr> @llvm.masked.load.v8p0.p0(ptr <ptr>, i32 <alignment>, <8 x i1> <mask>, <8 x ptr> <passthru>). Overview:; """""""""""""""""". Reads a vector from memory according to the provided mask. The mask holds a bit for each vector lane, and is used to prevent memory accesses to the masked-off lanes. The masked-off lanes in the result vector are taken from the corresponding lanes of the '``passthru``' operand. Arguments:; """""""""""""""""""". The first operand is the base pointer for the load. The second operand is the alignment of the source location. It must be a power of two constant integer value. The third operand, mask, is a vector of boolean values with the same number of elements as the return type. The fourth is a pass-through value that is used to fil",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:843374,load,load,843374,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['load'],['load']
Performance,"%xmm0; 	movsd	%xmm0, (%esp); 	movl	4(%esp), %eax; 	shrl	$31, %eax; 	addl	$12, %esp; 	ret. We should use movmskp{s|d} instead. //===---------------------------------------------------------------------===//. CodeGen/X86/vec_align.ll tests whether we can turn 4 scalar loads into a single; (aligned) vector load. This functionality has a couple of problems. 1. The code to infer alignment from loads of globals is in the X86 backend,; not the dag combiner. This is because dagcombine2 needs to be able to see; through the X86ISD::Wrapper node, which DAGCombine can't really do.; 2. The code for turning 4 x load into a single vector load is target ; independent and should be moved to the dag combiner.; 3. The code for turning 4 x load into a vector load can only handle a direct ; load from a global or a direct load from the stack. It should be generalized; to handle any load from P, P+4, P+8, P+12, where P can be anything.; 4. The alignment inference code cannot handle loads from globals in non-static; mode because it doesn't look through the extra dyld stub load. If you try; vec_align.ll without -relocation-model=static, you'll see what I mean. //===---------------------------------------------------------------------===//. We should lower store(fneg(load p), q) into an integer load+xor+store, which; eliminates a constant pool load. For example, consider:. define i64 @ccosf(float %z.0, float %z.1) nounwind readonly {; entry:; %tmp6 = fsub float -0.000000e+00, %z.1		; <float> [#uses=1]; %tmp20 = tail call i64 @ccoshf( float %tmp6, float %z.0 ) nounwind readonly; ret i64 %tmp20; }; declare i64 @ccoshf(float %z.0, float %z.1) nounwind readonly. This currently compiles to:. LCPI1_0:					# <4 x float>; 	.long	2147483648	# float -0; 	.long	2147483648	# float -0; 	.long	2147483648	# float -0; 	.long	2147483648	# float -0; _ccosf:; 	subl	$12, %esp; 	movss	16(%esp), %xmm0; 	movss	%xmm0, 4(%esp); 	movss	20(%esp), %xmm0; 	xorps	LCPI1_0, %xmm0; 	movss	%xmm0, (%esp); 	call	L_ccoshf$stub;",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README-SSE.txt:12150,load,loads,12150,interpreter/llvm-project/llvm/lib/Target/X86/README-SSE.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README-SSE.txt,4,['load'],"['load', 'loads']"
Performance,"& 1) | (y & 2);}; Should combine to ""x | (y & 3)"". Currently not optimized with ""clang; -emit-llvm-bc | opt -O3"". //===---------------------------------------------------------------------===//. int a(int a, int b, int c) {return (~a & c) | ((c|a) & b);}; Should fold to ""(~a & c) | (a & b)"". Currently not optimized with; ""clang -emit-llvm-bc | opt -O3"". //===---------------------------------------------------------------------===//. int a(int a,int b) {return (~(a|b))|a;}; Should fold to ""a|~b"". Currently not optimized with ""clang; -emit-llvm-bc | opt -O3"". //===---------------------------------------------------------------------===//. int a(int a, int b) {return (a&&b) || (a&&!b);}; Should fold to ""a"". Currently not optimized with ""clang -emit-llvm-bc; | opt -O3"". //===---------------------------------------------------------------------===//. int a(int a, int b, int c) {return (a&&b) || (!a&&c);}; Should fold to ""a ? b : c"", or at least something sane. Currently not; optimized with ""clang -emit-llvm-bc | opt -O3"". //===---------------------------------------------------------------------===//. int a(int a, int b, int c) {return (a&&b) || (a&&c) || (a&&b&&c);}; Should fold to a && (b || c). Currently not optimized with ""clang; -emit-llvm-bc | opt -O3"". //===---------------------------------------------------------------------===//. int a(int x) {return x | ((x & 8) ^ 8);}; Should combine to x | 8. Currently not optimized with ""clang; -emit-llvm-bc | opt -O3"". //===---------------------------------------------------------------------===//. int a(int x) {return x ^ ((x & 8) ^ 8);}; Should also combine to x | 8. Currently not optimized with ""clang; -emit-llvm-bc | opt -O3"". //===---------------------------------------------------------------------===//. int a(int x) {return ((x | -9) ^ 8) & x;}; Should combine to x & -9. Currently not optimized with ""clang; -emit-llvm-bc | opt -O3"". //===---------------------------------------------------------------------===//. unsig",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/README.txt:24926,optimiz,optimized,24926,interpreter/llvm-project/llvm/lib/Target/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/README.txt,2,['optimiz'],['optimized']
Performance,"' out a top-level declaration; at a time, allowing clients to use decl-at-a-time processing,; build up entire translation units, or even build 'whole; program' ASTs depending on how they use the APIs. This depends; on libast and libparse. librewrite - Fast, scalable rewriting of source code. This operates on; the raw syntactic text of source code, allowing a client; to insert and delete text in very large source files using; the same source location information embedded in ASTs. This; is intended to be a low-level API that is useful for; higher-level clients and libraries such as code refactoring. libanalysis - Source-level dataflow analysis useful for performing analyses; such as computing live variables. It also includes a; path-sensitive ""graph-reachability"" engine for writing; analyses that reason about different possible paths of; execution through source code. This is currently being; employed to write a set of checks for finding bugs in software. libcodegen - Lower the AST to LLVM IR for optimization & codegen. Depends; on libast.; ; clang - An example driver, client of the libraries at various levels.; This depends on all these libraries, and on LLVM VMCore. This front-end has been intentionally built as a DAG of libraries, making it; easy to reuse individual parts or replace pieces if desired. For example, to; build a preprocessor, you take the Basic and Lexer libraries. If you want an; indexer, you take those plus the Parser library and provide some actions for; indexing. If you want a refactoring, static analysis, or source-to-source; compiler tool, it makes sense to take those plus the AST building and semantic; analyzer library. Finally, if you want to use this with the LLVM backend,; you'd take these components plus the AST to LLVM lowering code.; ; In the future I hope this toolkit will grow to include new and interesting; components, including a C++ front-end, ObjC support, and a whole lot of other; things. Finally, it should be pointed out that the ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2007-OriginalClangReadme.txt:2997,optimiz,optimization,2997,interpreter/llvm-project/llvm/docs/HistoricalNotes/2007-OriginalClangReadme.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2007-OriginalClangReadme.txt,1,['optimiz'],['optimization']
Performance,"': argument list whose types match the function; signature argument types and parameter attributes. All arguments must; be of :ref:`first class <t_firstclass>` type. If the function signature; indicates the function accepts a variable number of arguments, the; extra arguments can be specified.; #. '``normal label``': the label reached when the called function; executes a '``ret``' instruction.; #. '``exception label``': the label reached when a callee returns via; the :ref:`resume <i_resume>` instruction or other exception handling; mechanism.; #. The optional :ref:`function attributes <fnattrs>` list.; #. The optional :ref:`operand bundles <opbundles>` list. Semantics:; """""""""""""""""""". This instruction is designed to operate as a standard '``call``'; instruction in most regards. The primary difference is that it; establishes an association with a label, which is used by the runtime; library to unwind the stack. This instruction is used in languages with destructors to ensure that; proper cleanup is performed in the case of either a ``longjmp`` or a; thrown exception. Additionally, this is important for implementation of; '``catch``' clauses in high-level languages that support them. For the purposes of the SSA form, the definition of the value returned; by the '``invoke``' instruction is deemed to occur on the edge from the; current block to the ""normal"" label. If the callee unwinds then no; return value is available. Example:; """""""""""""""". .. code-block:: llvm. %retval = invoke i32 @Test(i32 15) to label %Continue; unwind label %TestCleanup ; i32:retval set; %retval = invoke coldcc i32 %Testfnptr(i32 15) to label %Continue; unwind label %TestCleanup ; i32:retval set. .. _i_callbr:. '``callbr``' Instruction; ^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. <result> = callbr [cconv] [ret attrs] [addrspace(<num>)] <ty>|<fnty> <fnptrval>(<function args>) [fn attrs]; [operand bundles] to label <fallthrough label> [indirect labels]. Overview:; """""""""""""""""". The '``callbr``' instruc",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:365048,perform,performed,365048,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['performed']
Performance,"'; ...; # While this is running, do `killall -SIGUSR1 my_fuzzer` in another console; ==9015== INFO: libFuzzer: exiting as requested. # This will leave the file SomeLocalPath with the partial state of the merge.; # Now, you can continue the merge by executing the same command. The merge; # will continue from where it has been interrupted.; % ./my_fuzzer CORPUS1 CORPUS2 -merge=1 -merge_control_file=SomeLocalPath; ...; MERGE-OUTER: non-empty control file provided: 'SomeLocalPath'; MERGE-OUTER: control file ok, 32 files total, first not processed file 20; ... Options; =======. To run the fuzzer, pass zero or more corpus directories as command line; arguments. The fuzzer will read test inputs from each of these corpus; directories, and any new test inputs that are generated will be written; back to the first corpus directory:. .. code-block:: console. ./fuzzer [-flag1=val1 [-flag2=val2 ...] ] [dir1 [dir2 ...] ]. If a list of files (rather than directories) are passed to the fuzzer program,; then it will re-run those files as test inputs but will not perform any fuzzing.; In this mode the fuzzer binary can be used as a regression test (e.g. on a; continuous integration system) to check the target function and saved inputs; still work. The most important command line options are:. ``-help``; Print help message (``-help=1``).; ``-seed``; Random seed. If 0 (the default), the seed is generated.; ``-runs``; Number of individual test runs, -1 (the default) to run indefinitely.; ``-max_len``; Maximum length of a test input. If 0 (the default), libFuzzer tries to guess; a good value based on the corpus (and reports it).; ``-len_control``; Try generating small inputs first, then try larger inputs over time.; Specifies the rate at which the length limit is increased (smaller == faster).; Default is 100. If 0, immediately try inputs with size up to max_len.; ``-timeout``; Timeout in seconds, default 1200. If an input takes longer than this timeout,; the process is treated as a failur",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LibFuzzer.rst:9882,perform,perform,9882,interpreter/llvm-project/llvm/docs/LibFuzzer.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LibFuzzer.rst,1,['perform'],['perform']
Performance,"'s impossible to trigger a pointer escape from; within the checker. Approach (1): If only we enabled ``ProgramState::bindLoc(..., notifyChanges=true)``; to cause pointer escapes (not only region changes) (which sounds like the right; thing to do anyway) such checker would be able to solve the false positives by; triggering escapes when binding list elements to the list. However, it'd be as; conservative as the current patch's solution. Ideally, we do not want escapes to; happen so early. Instead, we'd prefer them to be delayed until the list itself; escapes. So i believe that escaping metadata symbols whenever their base regions escape; would be the right thing to do. Currently we didn't think about that because we; had neither pointer-type metadatas nor non-pointer escapes. Approach (2): We could teach the Store to scan itself for bindings to; metadata-symbolic-based regions during scanReachableSymbols() whenever a region; turns out to be reachable. This requires no work on checker side, but it sounds; performance-heavy. Approach (3): We could let checkers maintain the set of active metadata symbols; in the program state (ideally somewhere in the Store, which sounds weird but; causes the smallest amount of layering violations), so that the core knew what; to escape. This puts a stress on the checkers, but with a smart data map it; wouldn't be a problem. Approach (4): We could allow checkers to trigger pointer escapes in arbitrary; moments. If we allow doing this within ``checkPointerEscape`` callback itself, we; would be able to express facts like ""when this region escapes, that metadata; symbol attached to it should also escape"". This sounds like an ultimate freedom,; with maximum stress on the checkers - still not too much stress when we have; smart data maps. I'm personally liking the approach (2) - it should be possible to avoid; performance overhead, and clarity seems nice. **Gabor:**. At this point, I am a bit wondering about two questions. * When should somet",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/developer-docs/InitializerLists.rst:3738,perform,performance-heavy,3738,interpreter/llvm-project/clang/docs/analyzer/developer-docs/InitializerLists.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/developer-docs/InitializerLists.rst,1,['perform'],['performance-heavy']
Performance,"'s precompiled; headers (PCH) and modules. If you are interested in the end-user view, please; see the :ref:`User's Manual <usersmanual-precompiled-headers>`. Using Precompiled Headers with ``clang``; ----------------------------------------. The Clang compiler frontend, ``clang -cc1``, supports two command line options; for generating and using PCH files. To generate PCH files using ``clang -cc1``, use the option `-emit-pch`:. .. code-block:: bash. $ clang -cc1 test.h -emit-pch -o test.h.pch. This option is transparently used by ``clang`` when generating PCH files. The; resulting PCH file contains the serialized form of the compiler's internal; representation after it has completed parsing and semantic analysis. The PCH; file can then be used as a prefix header with the `-include-pch`; option:. .. code-block:: bash. $ clang -cc1 -include-pch test.h.pch test.c -o test.s. Design Philosophy; -----------------. Precompiled headers are meant to improve overall compile times for projects, so; the design of precompiled headers is entirely driven by performance concerns.; The use case for precompiled headers is relatively simple: when there is a; common set of headers that is included in nearly every source file in the; project, we *precompile* that bundle of headers into a single precompiled; header (PCH file). Then, when compiling the source files in the project, we; load the PCH file first (as a prefix header), which acts as a stand-in for that; bundle of headers. A precompiled header implementation improves performance when:. * Loading the PCH file is significantly faster than re-parsing the bundle of; headers stored within the PCH file. Thus, a precompiled header design; attempts to minimize the cost of reading the PCH file. Ideally, this cost; should not vary with the size of the precompiled header file. * The cost of generating the PCH file initially is not so large that it; counters the per-source-file performance improvement due to eliminating the; need to parse th",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/PCHInternals.rst:1271,perform,performance,1271,interpreter/llvm-project/clang/docs/PCHInternals.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/PCHInternals.rst,1,['perform'],['performance']
Performance,"'s two bytes; shorter than movl + leal. On a Pentium M, both variants have the same characteristics with regard; to throughput; however, the multiplication has a latency of four cycles, as; opposed to two cycles for the movl+lea variant. //===---------------------------------------------------------------------===//. It appears gcc place string data with linkonce linkage in; .section __TEXT,__const_coal,coalesced instead of; .section __DATA,__const_coal,coalesced.; Take a look at darwin.h, there are other Darwin assembler directives that we; do not make use of. //===---------------------------------------------------------------------===//. define i32 @foo(i32* %a, i32 %t) {; entry:; 	br label %cond_true. cond_true:		; preds = %cond_true, %entry; 	%x.0.0 = phi i32 [ 0, %entry ], [ %tmp9, %cond_true ]		; <i32> [#uses=3]; 	%t_addr.0.0 = phi i32 [ %t, %entry ], [ %tmp7, %cond_true ]		; <i32> [#uses=1]; 	%tmp2 = getelementptr i32* %a, i32 %x.0.0		; <i32*> [#uses=1]; 	%tmp3 = load i32* %tmp2		; <i32> [#uses=1]; 	%tmp5 = add i32 %t_addr.0.0, %x.0.0		; <i32> [#uses=1]; 	%tmp7 = add i32 %tmp5, %tmp3		; <i32> [#uses=2]; 	%tmp9 = add i32 %x.0.0, 1		; <i32> [#uses=2]; 	%tmp = icmp sgt i32 %tmp9, 39		; <i1> [#uses=1]; 	br i1 %tmp, label %bb12, label %cond_true. bb12:		; preds = %cond_true; 	ret i32 %tmp7; }; is pessimized by -loop-reduce and -indvars. //===---------------------------------------------------------------------===//. u32 to float conversion improvement:. float uint32_2_float( unsigned u ) {; float fl = (int) (u & 0xffff);; float fh = (int) (u >> 16);; fh *= 0x1.0p16f;; return fh + fl;; }. 00000000 subl $0x04,%esp; 00000003 movl 0x08(%esp,1),%eax; 00000007 movl %eax,%ecx; 00000009 shrl $0x10,%ecx; 0000000c cvtsi2ss %ecx,%xmm0; 00000010 andl $0x0000ffff,%eax; 00000015 cvtsi2ss %eax,%xmm1; 00000019 mulss 0x00000078,%xmm0; 00000021 addss %xmm1,%xmm0; 00000025 movss %xmm0,(%esp,1); 0000002a flds (%esp,1); 0000002d addl $0x04,%esp; 00000030 ret. //===--------------------",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README.txt:8412,load,load,8412,interpreter/llvm-project/llvm/lib/Target/X86/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README.txt,2,['load'],['load']
Performance,"'t have any; other accesses writing to memory. This is needed for walking Def chains.; The second operand is the optimized access, if there was a previous call on the; walker's ``getClobberingMemoryAccess(MA)``. This API will cache information; as part of ``MA``.; Optimizing all ``MemoryDef``\ s has quadratic time complexity and is not done; by default. A walk of the uses for any MemoryDef can find the accesses that were optimized; to it.; A code snippet for such a walk looks like this:. .. code-block:: c++. MemoryDef *Def; // find who's optimized or defining for this MemoryDef; for (auto& U : Def->uses()) {; MemoryAccess *MA = cast<MemoryAccess>(Use.getUser());; if (auto *DefUser = cast_of_null<MemoryDef>MA); if (DefUser->isOptimized() && DefUser->getOptimized() == Def) {; // User who is optimized to Def; } else {; // User who's defining access is Def; optimized to something else or not optimized.; }; }. When ``MemoryUse``\ s are optimized, for a given store, you can find all loads; clobbered by that store by walking the immediate and transitive uses of; the store. .. code-block:: c++. checkUses(MemoryAccess *Def) { // Def can be a MemoryDef or a MemoryPhi.; for (auto& U : Def->uses()) {; MemoryAccess *MA = cast<MemoryAccess>(Use.getUser());; if (auto *MU = cast_of_null<MemoryUse>MA) {; // Process MemoryUse as needed.; }; else {; // Process MemoryDef or MemoryPhi as needed. // As a user can come up twice, as an optimized access and defining; // access, keep a visited list. // Check transitive uses as needed; checkUses (MA); // use a worklist for an iterative algorithm; }; }; }. An example of similar traversals can be found in the DeadStoreElimination pass. Invalidation and updating; -------------------------. Because ``MemorySSA`` keeps track of LLVM IR, it needs to be updated whenever; the IR is updated. ""Update"", in this case, includes the addition, deletion, and; motion of ``Instructions``. The update API is being made on an as-needed basis.; If you'd like examp",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MemorySSA.rst:13313,optimiz,optimized,13313,interpreter/llvm-project/llvm/docs/MemorySSA.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MemorySSA.rst,2,"['load', 'optimiz']","['loads', 'optimized']"
Performance,"(%eax), %eax; ret. You can also use the GCC compatibility macros ``__seg_fs`` and ``__seg_gs`` for; the same purpose. The preprocessor symbols ``__SEG_FS`` and ``__SEG_GS``; indicate their support. PowerPC Language Extensions; ---------------------------. Set the Floating Point Rounding Mode; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; PowerPC64/PowerPC64le supports the builtin function ``__builtin_setrnd`` to set; the floating point rounding mode. This function will use the least significant; two bits of integer argument to set the floating point rounding mode. .. code-block:: c++. double __builtin_setrnd(int mode);. The effective values for mode are:. - 0 - round to nearest; - 1 - round to zero; - 2 - round to +infinity; - 3 - round to -infinity. Note that the mode argument will modulo 4, so if the integer argument is greater; than 3, it will only use the least significant two bits of the mode.; Namely, ``__builtin_setrnd(102))`` is equal to ``__builtin_setrnd(2)``. PowerPC cache builtins; ^^^^^^^^^^^^^^^^^^^^^^. The PowerPC architecture specifies instructions implementing cache operations.; Clang provides builtins that give direct programmer access to these cache; instructions. Currently the following builtins are implemented in clang:. ``__builtin_dcbf`` copies the contents of a modified block from the data cache; to main memory and flushes the copy from the data cache. **Syntax**:. .. code-block:: c. void __dcbf(const void* addr); /* Data Cache Block Flush */. **Example of Use**:. .. code-block:: c. int a = 1;; __builtin_dcbf (&a);. Extensions for Static Analysis; ==============================. Clang supports additional attributes that are useful for documenting program; invariants and rules for static analysis tools, such as the `Clang Static; Analyzer <https://clang-analyzer.llvm.org/>`_. These attributes are documented; in the analyzer's `list of source-level annotations; <https://clang-analyzer.llvm.org/annotations.html>`_. Extensions for Dynamic Analysis; =====",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst:156887,cache,cache,156887,interpreter/llvm-project/clang/docs/LanguageExtensions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst,1,['cache'],['cache']
Performance,"(%edx); 	movw $257, 8(%edx). It might be better to generate. 	movl $16843009, %eax; 	movl %eax, 4(%edx); 	movl %eax, (%edx); 	movw al, 8(%edx); 	; when we can spare a register. It reduces code size. //===---------------------------------------------------------------------===//. Evaluate what the best way to codegen sdiv X, (2^C) is. For X/8, we currently; get this:. define i32 @test1(i32 %X) {; %Y = sdiv i32 %X, 8; ret i32 %Y; }. _test1:; movl 4(%esp), %eax; movl %eax, %ecx; sarl $31, %ecx; shrl $29, %ecx; addl %ecx, %eax; sarl $3, %eax; ret. GCC knows several different ways to codegen it, one of which is this:. _test1:; movl 4(%esp), %eax; cmpl $-1, %eax; leal 7(%eax), %ecx; cmovle %ecx, %eax; sarl $3, %eax; ret. which is probably slower, but it's interesting at least :). //===---------------------------------------------------------------------===//. We are currently lowering large (1MB+) memmove/memcpy to rep/stosl and rep/movsl; We should leave these as libcalls for everything over a much lower threshold,; since libc is hand tuned for medium and large mem ops (avoiding RFO for large; stores, TLB preheating, etc). //===---------------------------------------------------------------------===//. Optimize this into something reasonable:; x * copysign(1.0, y) * copysign(1.0, z). //===---------------------------------------------------------------------===//. Optimize copysign(x, *y) to use an integer load from y. //===---------------------------------------------------------------------===//. The following tests perform worse with LSR:. lambda, siod, optimizer-eval, ackermann, hash2, nestedloop, strcat, and Treesor. //===---------------------------------------------------------------------===//. Adding to the list of cmp / test poor codegen issues:. int test(__m128 *A, __m128 *B) {; if (_mm_comige_ss(*A, *B)); return 3;; else; return 4;; }. _test:; 	movl 8(%esp), %eax; 	movaps (%eax), %xmm0; 	movl 4(%esp), %eax; 	movaps (%eax), %xmm1; 	comiss %xmm0, %xmm1; 	setae %a",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README.txt:4968,tune,tuned,4968,interpreter/llvm-project/llvm/lib/Target/X86/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README.txt,2,['tune'],['tuned']
Performance,"() now accepts a new argument ShowProgress() that will print a dot for every; function evaluation performed in the process of creating the plot. This can be useful when plotting very expensive; functions such as profile likelihoods; Automatic handling of constraint terms; It is no longer necessary to add a Constrain() argument to fitTo() calls to have internal constraints; applied. Any pdf term appearing in a product that does not contain an observable and shares one or more parameters; with another pdf term in the same product that does contain an observable is automatically picked up as a constraint term.; For example given a dataset D(x) which defines variable x as observable, the default logic works out as follows. F(x,a,b)*G(a,a0,a1) --> G is constraint term (a also appears in F(x)); F(x,a,b)*G(y,c,d) --> G is dropped (factorizing term). A Constrain(y) term in the above example will still force term G(y,c,d) to be interpreted as constraint term; Automatic caching of numeric integral calculations; Integrals that require numeric integrations in two of more dimensions are now automatically cached in the expensive object store.; The expensive object store allows to cache such values between difference instance of integral objects that represent the; same configuration. If integrals are created from an object (function or pdf) that live in a RooWorkspace the ; expensive object cache of the workspace will be used instead of the global store instance, and values stored in the workspace; store will also be persisted if the workspace is persisted. The global caching behavior of integral objects can be ; controlled through RooRealIntegral::setCacheAllNumeric(Int_t nDimNumMin). Miscellaneous improvements data classes. The RooAbsData::tree() method has been restored. It will only return a TTree* pointer for datasets; that are based on a RooTreeDataStore implementation, i.e. not for the composite datasets mentioned below; A new composite data storage class RooCompositeDataS",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html:7819,cache,cached,7819,roofit/doc/v526/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html,2,['cache'],['cached']
Performance,"(). See section ""RooFit Libraries"" for instructions on how to use [`RooAbsReal::evaluateSpan()`](https://root.cern/doc/v624/classRooAbsReal.html#a1e5129ffbc63bfd04c01511fd354b1b8).; - `TTreeProcessorMT::SetMaxTasksPerFilePerWorker` has been deprecated in favour of `TTreeProcessorMT::SetTasksPerWorkerHint`. ## Core Libraries. Due to internal changes required to comply with the deprecation of Intel TBB's `task_scheduler_init` and related; interfaces in recent TBB versions, as of v6.24 ROOT will not honor a maximum concurrency level set with; `tbb::task_scheduler_init` but will require instead the usage of `tbb::global_control`:. ```cpp; //tbb::task_scheduler_init init(2); // does not affect the number of threads ROOT will use anymore. tbb::global_control c(tbb::global_control::max_allowed_parallelism, 2);; ROOT::TThreadExecutor p1; // will use 2 threads; ROOT::TThreadExecutor p2(/*nThreads=*/8); // will still use 2 threads; ```. Note that the preferred way to steer ROOT's concurrency level is still through; [`ROOT::EnableImplicitMT`](https://root.cern/doc/master/namespaceROOT.html#a06f2b8b216b615e5abbc872c9feff40f); or by passing the appropriate parameter to executors' constructors, as in; [`TThreadExecutor::TThreadExecutor`](https://root.cern/doc/master/classROOT_1_1TThreadExecutor.html#ac7783d52c56cc7875d3954cf212247bb). See the discussion at [ROOT-11014](https://sft.its.cern.ch/jira/browse/ROOT-11014) for more context. ### Dynamic Path: `ROOT_LIBRARY_PATH`. A new way to set ROOT's ""Dynamic Path"" was added: the; environment variable `ROOT_LIBRARY_PATH`. On Unix it should contain a colon; separated list of paths, on Windows a semicolon separated list. It is; intended to be cross platform and to be specific to ROOT (and thus not; interfere with the system's shared linker).; The final ""Dynamic Path"" is now composed of these sources in order:; 1. `ROOT_LIBRARY_PATH` environment variable; 2. System specific shared linker environment variables like; `LD_LIBRARY_PATH`, `LIB",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v624/index.md:2457,concurren,concurrency,2457,README/ReleaseNotes/v624/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v624/index.md,1,['concurren'],['concurrency']
Performance,"();; uintptr_t all_zeros_mask = 0;; void leak(int data);; void example(int* pointer1, int* pointer2) {; uintptr_t predicate_state = all_ones_mask;; if (condition) {; // Assuming ?: is implemented using branchless logic...; predicate_state = !condition ? all_zeros_mask : predicate_state;; // ... lots of code ...; //; // Harden the pointer so it can't be loaded; pointer1 &= predicate_state;; leak(*pointer1);; } else {; predicate_state = condition ? all_zeros_mask : predicate_state;; // ... more code ...; //; // Alternative: Harden the loaded value; int value2 = *pointer2 & predicate_state;; leak(value2);; }; }; ```. The result should be that if the `if (condition) {` branch is mis-predicted,; there is a *data* dependency on the condition used to zero out any pointers; prior to loading through them or to zero out all of the loaded bits. Even; though this code pattern may still execute speculatively, *invalid* speculative; executions are prevented from leaking secret data from memory (but note that; this data might still be loaded in safe ways, and some regions of memory are; required to not hold secrets, see below for detailed limitations). This; approach only requires the underlying hardware have a way to implement a; branchless and unpredicted conditional update of a register's value. All modern; architectures have support for this, and in fact such support is necessary to; correctly implement constant time cryptographic primitives. Crucial properties of this approach:; * It is not preventing any particular side-channel from working. This is; important as there are an unknown number of potential side channels and we; expect to continue discovering more. Instead, it prevents the observation of; secret data in the first place.; * It accumulates the predicate state, protecting even in the face of nested; *correctly* predicted control flows.; * It passes this predicate state across function boundaries to provide; [interprocedural protection](#interprocedural-checking).; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:4660,load,loaded,4660,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,1,['load'],['loaded']
Performance,"(...); A; C. This can increase the size of the code exponentially (doubling it every time a; loop is unswitched) so we only unswitch if the resultant code will be smaller; than a threshold. This pass expects :ref:`LICM <passes-licm>` to be run before it to hoist; invariant conditions out of the loop, to make the unswitching opportunity; obvious. ``strip``: Strip all symbols from a module; ------------------------------------------. Performs code stripping. This transformation can delete:. * names for virtual registers; * symbols for internal globals and functions; * debug information. Note that this transformation makes code much less readable, so it should only; be used in situations where the strip utility would be used, such as reducing; code size or making it harder to reverse engineer code. ``strip-dead-debug-info``: Strip debug info for unused symbols; --------------------------------------------------------------. .. FIXME: this description is the same as for -strip. performs code stripping. this transformation can delete:. * names for virtual registers; * symbols for internal globals and functions; * debug information. note that this transformation makes code much less readable, so it should only; be used in situations where the strip utility would be used, such as reducing; code size or making it harder to reverse engineer code. ``strip-dead-prototypes``: Strip Unused Function Prototypes; -----------------------------------------------------------. This pass loops over all of the functions in the input module, looking for dead; declarations and removes them. Dead declarations are declarations of functions; for which no implementation is available (i.e., declarations for unused library; functions). ``strip-debug-declare``: Strip all ``llvm.dbg.declare`` intrinsics; ------------------------------------------------------------------. .. FIXME: this description is the same as for -strip. This pass implements code stripping. Specifically, it can delete:. #. names",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Passes.rst:36706,perform,performs,36706,interpreter/llvm-project/llvm/docs/Passes.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Passes.rst,1,['perform'],['performs']
Performance,"(0) &; - system vmcnt(0) & vscnt(0). - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0), s_waitcnt; vscnt(0) and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/load atomic/; atomicrmw-with-return-value.; - s_waitcnt vscnt(0); must happen after; any preceding; global/generic; store/store atomic/; atomicrmw-no-return-value.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global_atomic; 3. s_waitcnt vm/vscnt(0). - Use vmcnt(0) if atomic with; return and vscnt(0) if; atomic with no-return.; - Must happen before; following; buffer_gl*_inv.; - Ensures the; atomicrmw has; completed before; invalidating the; caches. 4. buffer_gl0_inv;; buffer_gl1_inv. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acq_rel - agent - generic 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0) & vscnt(0). - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0), s_waitcnt; vscnt(0), and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/load atomic; atomicrmw-with-return-value.; - s_waitcnt vscnt(0); must happen after; any preceding; global/generic; store/store atomic/; atomicrmw-no-return-value.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; have; completed befor",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:367935,cache,caches,367935,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['cache'],['caches']
Performance,"(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate; (see comment for; previous fence).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Must happen before; the following buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures that the; fence-paired atomic; has completed; before invalidating; the; cache. Therefore; any following; locations read must; be no older than; the value read by; the; fence-paired-atomic. 2. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before any; following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes.; **Release Atomic**; ------------------------------------------------------------------------------------; store atomic release - singlethread - global 1. buffer/global/flat_store; - wavefront - generic; store atomic release - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; be used.*. 1. ds_store; store atomic release - workgroup - global 1. s_waitcnt lgkm/vmcnt(0); - generic; - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - I",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:256326,cache,cache,256326,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['cache'],['cache']
Performance,"(0) &; vmcnt(0). - If not TgSplit execution; mode, omit vmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Must happen before; the following; buffer_inv and; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic value being; acquired. 3. buffer_inv sc0=1. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. atomicrmw acq_rel - agent - global 1. buffer_wbl2 sc1=1. - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at agent scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global have; completed before; performing the; atomicrmw that is; being released. 3. buffer/global_atomic; 4. s_waitcnt vmcnt(0). - Must happen before; following; buffer_inv.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 5. buffer_inv sc1=1. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acq_rel - system - global 1. buffer_wbl2 sc0=1 sc1=1. - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at system scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:320084,load,load,320084,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],['load']
Performance,"(0x8b03bf0, LLVM BB @0x8b032d0, ID#5):; Predecessors according to CFG: 0x8b0c5f0 (#3) 0x8b0a7c0 (#4); %reg1039 = PHI %reg1070, mbb<bb76.outer,0x8b0c5f0>, %reg1037, mbb<bb27,0x8b0a7c0>. Note ADDri is not a two-address instruction. However, its result %reg1037 is an; operand of the PHI node in bb76 and its operand %reg1039 is the result of the; PHI node. We should treat it as a two-address code and make sure the ADDri is; scheduled after any node that reads %reg1039. //===---------------------------------------------------------------------===//. Use local info (i.e. register scavenger) to assign it a free register to allow; reuse:; ldr r3, [sp, #+4]; add r3, r3, #3; ldr r2, [sp, #+8]; add r2, r2, #2; ldr r1, [sp, #+4] <==; add r1, r1, #1; ldr r0, [sp, #+4]; add r0, r0, #2. //===---------------------------------------------------------------------===//. LLVM aggressively lift CSE out of loop. Sometimes this can be negative side-; effects:. R1 = X + 4; R2 = X + 7; R3 = X + 15. loop:; load [i + R1]; ...; load [i + R2]; ...; load [i + R3]. Suppose there is high register pressure, R1, R2, R3, can be spilled. We need; to implement proper re-materialization to handle this:. R1 = X + 4; R2 = X + 7; R3 = X + 15. loop:; R1 = X + 4 @ re-materialized; load [i + R1]; ...; R2 = X + 7 @ re-materialized; load [i + R2]; ...; R3 = X + 15 @ re-materialized; load [i + R3]. Furthermore, with re-association, we can enable sharing:. R1 = X + 4; R2 = X + 7; R3 = X + 15. loop:; T = i + X; load [T + 4]; ...; load [T + 7]; ...; load [T + 15]; //===---------------------------------------------------------------------===//. It's not always a good idea to choose rematerialization over spilling. If all; the load / store instructions would be folded then spilling is cheaper because; it won't require new live intervals / registers. See 2003-05-31-LongShifts for; an example. //===---------------------------------------------------------------------===//. With a copying garbage collector, derived poin",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/README.txt:1748,load,load,1748,interpreter/llvm-project/llvm/lib/CodeGen/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/README.txt,1,['load'],['load']
Performance,"(C++); A class has dynamically allocated data members but do not define a copy; constructor/assignment operator.; Source: Scott Meyers ""Effective C++"", item 11: Prevent exceptions from; leaving destructors. class C {; int *p; // warn; public:; C() { p = new int; }; ~C() { delete p; }; };. WinAPI. Name, DescriptionExampleProgress. WinAPI.CreateProcess; (C); CreateProcess(): if the first parameter ; lpApplicationName is NULL then the executable name must be in the; white space-delimited string pointed to by lpCommandLine.; If the executable or path name has a space in it, there is a risk that a; different executable could be run because of the way the function parses; spaces.; Source: ; MSDN: CreateProcess function, Security Remarks. #include <windows.h>. void test() {; STARTUPINFO si;; PROCESS_INFORMATION pi;; CreateProcess(NULL, TEXT(""C:\\Program Files\\App -L -S""),; NULL, NULL, TRUE, 0, NULL, NULL, &si, π);; // warn; }. WinAPI.LoadLibrary; (C); The SearchPath() function is used to retrieve a path to a DLL for; a subsequent LoadLibrary() call.; Source: ; MSDN: LoadLibrary function, Security Remarks. #include <windows.h>. HINSTANCE test() {; char filePath[100];; SearchPath(NULL, ""file.dll"", NULL, 100, filePath, NULL);; return LoadLibrary(filePath); // warn; }. WinAPI.WideCharToMultiByte; (C); Buffer overrun while calling WideCharToMultiByte(). The size of; the input buffer equals the number of characters in the Unicode string, while; the size of the output buffer equals the number of bytes.; Source: ; MSDN: WideCharToMultiByte function. #include <windows.h>. void test() {; wchar_t ws[] = L""abc"";; char s[3];; WideCharToMultiByte(CP_UTF8, 0, ws, -1, s,; 3, NULL, NULL); // warn; }. optimization. Name, DescriptionExampleProgress. optimization.PassConstObjByValue; (C, C++); Optimization: It is more effective to pass constant parameter by reference to; avoid unnecessary object copying. struct A {};. void f(const struct A a); // warn. optimization.PostfixIncIter; (C++); Opti",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/potential_checkers.html:26451,Load,LoadLibrary,26451,interpreter/llvm-project/clang/www/analyzer/potential_checkers.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/potential_checkers.html,2,['Load'],['LoadLibrary']
Performance,"(CurTok == ',') {; getNextToken();; Step = ParseExpression();; if (!Step); return nullptr;; }. if (CurTok != tok_in); return LogError(""expected 'in' after for"");; getNextToken(); // eat 'in'. auto Body = ParseExpression();; if (!Body); return nullptr;. return std::make_unique<ForExprAST>(IdName, std::move(Start),; std::move(End), std::move(Step),; std::move(Body));; }. And again we hook it up as a primary expression:. .. code-block:: c++. static std::unique_ptr<ExprAST> ParsePrimary() {; switch (CurTok) {; default:; return LogError(""unknown token when expecting an expression"");; case tok_identifier:; return ParseIdentifierExpr();; case tok_number:; return ParseNumberExpr();; case '(':; return ParseParenExpr();; case tok_if:; return ParseIfExpr();; case tok_for:; return ParseForExpr();; }; }. LLVM IR for the 'for' Loop; --------------------------. Now we get to the good part: the LLVM IR we want to generate for this; thing. With the simple example above, we get this LLVM IR (note that; this dump is generated with optimizations disabled for clarity):. .. code-block:: llvm. declare double @putchard(double). define double @printstar(double %n) {; entry:; ; initial value = 1.0 (inlined into phi); br label %loop. loop: ; preds = %loop, %entry; %i = phi double [ 1.000000e+00, %entry ], [ %nextvar, %loop ]; ; body; %calltmp = call double @putchard(double 4.200000e+01); ; increment; %nextvar = fadd double %i, 1.000000e+00. ; termination test; %cmptmp = fcmp ult double %i, %n; %booltmp = uitofp i1 %cmptmp to double; %loopcond = fcmp one double %booltmp, 0.000000e+00; br i1 %loopcond, label %loop, label %afterloop. afterloop: ; preds = %loop; ; loop always returns 0.0; ret double 0.000000e+00; }. This loop contains all the same constructs we saw before: a phi node,; several expressions, and some basic blocks. Let's see how this fits; together. Code Generation for the 'for' Loop; ----------------------------------. The first part of codegen is very simple: we just output the sta",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl05.rst:19500,optimiz,optimizations,19500,interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl05.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl05.rst,1,['optimiz'],['optimizations']
Performance,(DR); Clang 3.9. Explicit conversion operators; N2437; Clang 3.0. New character types; N2249; Clang 2.9. Unicode string literals; N2442; Clang 3.0. Raw string literals; N2442; Clang 3.0. Universal character names in literals; N2170; Clang 3.1. User-defined literals; N2765; Clang 3.1. Standard Layout Types; N2342; Clang 3.0. Defaulted functions; N2346; Clang 3.0. ; P1286R2 (DR); Clang 9. Deleted functions; N2346; Clang 2.9. Extended friend declarations; N1791; Clang 2.9. Extending sizeof; N2253; DR850; Clang 3.1. Inline namespaces; N2535; Clang 2.9. Unrestricted unions; N2544; Clang 3.1. Local and unnamed types as template arguments; N2657; Clang 2.9. Range-based for; N2930; Clang 3.0. P0962R1 (DR); Clang 8. Explicit virtual overrides; N2928; N3206; N3272; Clang 3.0. Minimal support for garbage collection and reachability-based leak detection; N2670; N/A (2). Allowing move constructors to throw [noexcept]; N3050; Clang 3.0. Defining move special member functions; N3053; Clang 3.0. Concurrency. Sequence points; N2239; Clang 3.3. Atomic operations; N2427; Clang 3.1. Strong Compare and Exchange; N2748; Clang 3.1 (3). Bidirectional Fences; N2752; Clang 3.1. Memory model; N2429; Clang 3.2. Data-dependency ordering: atomics and memory model; N2664; Clang 3.2 (4). Propagating exceptions; N2179; Clang 2.9. Allow atomics use in signal handlers; N2547; Clang 3.1. Thread-local storage; N2659; Clang 3.3 (5). Dynamic initialization and destruction with concurrency; N2660; Clang 2.9. C99 Features in C++11. __func__ predefined identifier; N2340; Clang 2.9. C99 preprocessor; N1653; Clang 2.9. long long; N1811; Clang 2.9. Extended integral types; N1988; N/A (6). (1): The [[carries_dependency]] attribute; has no effect.; (2): No compiler changes are required for an implementation; such as Clang that does not provide garbage collection.; (3): All compare-exchange operations are emitted as; strong compare-exchanges.; (4): memory_order_consume is lowered to; memory_order_acquire.; (5): th,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/cxx_status.html:17508,Concurren,Concurrency,17508,interpreter/llvm-project/clang/www/cxx_status.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/cxx_status.html,1,['Concurren'],['Concurrency']
Performance,"(FIND CMAKE_FIND_LIBRARY_SUFFIXES ${shared_lib_suffix} shared_lib_suffix_idx); if(NOT ${shared_lib_suffix_idx} EQUAL -1); list(REMOVE_AT CMAKE_FIND_LIBRARY_SUFFIXES ${shared_lib_suffix_idx}); endif(); endforeach(); endif(). # Use libtool instead of ar if you are both on an Apple host, and targeting Apple.; if(CMAKE_HOST_APPLE AND APPLE); include(UseLibtool); endif(). # Override the default target with an environment variable named by LLVM_TARGET_TRIPLE_ENV.; set(LLVM_TARGET_TRIPLE_ENV CACHE STRING ""The name of environment variable to override default target. Disabled by blank.""); mark_as_advanced(LLVM_TARGET_TRIPLE_ENV). if(CMAKE_SYSTEM_NAME MATCHES ""BSD|Linux|OS390""); set(LLVM_ENABLE_PER_TARGET_RUNTIME_DIR_default ON); else(); set(LLVM_ENABLE_PER_TARGET_RUNTIME_DIR_default OFF); endif(); set(LLVM_ENABLE_PER_TARGET_RUNTIME_DIR ${LLVM_ENABLE_PER_TARGET_RUNTIME_DIR_default} CACHE BOOL; ""Enable per-target runtimes directory""). set(LLVM_PROFDATA_FILE """" CACHE FILEPATH; ""Profiling data file to use when compiling in order to improve runtime performance.""). if(LLVM_INCLUDE_TESTS); # Lit test suite requires at least python 3.6; set(LLVM_MINIMUM_PYTHON_VERSION 3.6); else(); # FIXME: it is unknown if this is the actual minimum bound; set(LLVM_MINIMUM_PYTHON_VERSION 3.0); endif(). # Find python before including config-ix, since it needs to be able to search; # for python modules.; find_package(Python3 ${LLVM_MINIMUM_PYTHON_VERSION} REQUIRED; COMPONENTS Interpreter). # All options referred to from HandleLLVMOptions have to be specified; # BEFORE this include, otherwise options will not be correctly set on; # first cmake run; include(config-ix). # By default, we target the host, but this can be overridden at CMake; # invocation time. Except on 64-bit AIX, where the system toolchain; # expect 32-bit objects by default.; if(""${LLVM_HOST_TRIPLE}"" MATCHES ""^powerpc64-ibm-aix""); string(REGEX REPLACE ""^powerpc64"" ""powerpc"" LLVM_DEFAULT_TARGET_TRIPLE_DEFAULT ""${LLVM_HOST_TRIPLE}""); els",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/CMakeLists.txt:37310,perform,performance,37310,interpreter/llvm-project/llvm/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/CMakeLists.txt,1,['perform'],['performance']
Performance,"(X1, X2) X3 = phi(X1, X2); ... = X3 + 4 X4 = phi(X3); ... = X4 + 4. This is still valid LLVM; the extra phi nodes are purely redundant, and will be; trivially eliminated by ``InstCombine``. The major benefit of this; transformation is that it makes many other loop optimizations, such as; ``LoopUnswitch``\ ing, simpler. You can read more in the; :ref:`loop terminology section for the LCSSA form <loop-terminology-lcssa>`. .. _passes-licm:. ``licm``: Loop Invariant Code Motion; ------------------------------------. This pass performs loop invariant code motion, attempting to remove as much; code from the body of a loop as possible. It does this by either hoisting code; into the preheader block, or by sinking code to the exit blocks if it is safe.; This pass also promotes must-aliased memory locations in the loop to live in; registers, thus hoisting and sinking ""invariant"" loads and stores. Hoisting operations out of loops is a canonicalization transform. It enables; and simplifies subsequent optimizations in the middle-end. Rematerialization; of hoisted instructions to reduce register pressure is the responsibility of; the back-end, which has more accurate information about register pressure and; also handles other optimizations than LICM that increase live-ranges. This pass uses alias analysis for two purposes:. #. Moving loop invariant loads and calls out of loops. If we can determine; that a load or call inside of a loop never aliases anything stored to, we; can hoist it or sink it like any other instruction. #. Scalar Promotion of Memory. If there is a store instruction inside of the; loop, we try to move the store to happen AFTER the loop instead of inside of; the loop. This can only happen if a few conditions are true:. #. The pointer stored through is loop invariant.; #. There are no stores or loads in the loop which *may* alias the pointer.; There are no calls in the loop which mod/ref the pointer. If these conditions are true, we can promote the loads and store",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Passes.rst:23977,optimiz,optimizations,23977,interpreter/llvm-project/llvm/docs/Passes.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Passes.rst,1,['optimiz'],['optimizations']
Performance,"(a * b) + c. Hardware-Loop Intrinsics; ------------------------. LLVM support several intrinsics to mark a loop as a hardware-loop. They are; hints to the backend which are required to lower these intrinsics further to target; specific instructions, or revert the hardware-loop to a normal loop if target; specific restriction are not met and a hardware-loop can't be generated. These intrinsics may be modified in the future and are not intended to be used; outside the backend. Thus, front-end and mid-level optimizations should not be; generating these intrinsics. '``llvm.set.loop.iterations.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". This is an overloaded intrinsic. ::. declare void @llvm.set.loop.iterations.i32(i32); declare void @llvm.set.loop.iterations.i64(i64). Overview:; """""""""""""""""". The '``llvm.set.loop.iterations.*``' intrinsics are used to specify the; hardware-loop trip count. They are placed in the loop preheader basic block and; are marked as ``IntrNoDuplicate`` to avoid optimizers duplicating these; instructions. Arguments:; """""""""""""""""""". The integer operand is the loop trip count of the hardware-loop, and thus; not e.g. the loop back-edge taken count. Semantics:; """""""""""""""""""". The '``llvm.set.loop.iterations.*``' intrinsics do not perform any arithmetic; on their operand. It's a hint to the backend that can use this to set up the; hardware-loop count with a target specific instruction, usually a move of this; value to a special register or a hardware-loop instruction. '``llvm.start.loop.iterations.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". This is an overloaded intrinsic. ::. declare i32 @llvm.start.loop.iterations.i32(i32); declare i64 @llvm.start.loop.iterations.i64(i64). Overview:; """""""""""""""""". The '``llvm.start.loop.iterations.*``' intrinsics are similar to the; '``llvm.set.loop.iterations.*``' intrinsics, used to specify the; hardware-loop trip count but also produce a value identical to",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:643547,optimiz,optimizers,643547,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['optimiz'],['optimizers']
Performance,"(c1_n/sum_1, c2_n/sum_2). The result overlap distribution is a percentage number, ranging from 0.0% to; 100.0%, where 0.0% means there is no overlap and 100.0% means a perfect; overlap. Here is an example, if *base profile file* has counts of {400, 600}, and; *test profile file* has matched counts of {60000, 40000}. The *overlap* is 80%. OPTIONS; ^^^^^^^. .. option:: --function=<string>. Print details for a function if the function's name contains the given string. .. option:: --help. Print a summary of command line options. .. option:: --output=<output>, -o. Specify the output file name. If *output* is ``-`` or it isn't specified,; then the output is sent to standard output. .. option:: --value-cutoff=<n>. Show only those functions whose max count values are greater or equal to ``n``.; By default, the value-cutoff is set to max of unsigned long long. .. option:: --cs. Only show overlap for the context sensitive profile counts. The default is to show; non-context sensitive profile counts. .. program:: llvm-profdata order. .. _profdata-order:. ORDER; -------. SYNOPSIS; ^^^^^^^^. :program:`llvm-profdata order` [*options*] [*filename*]. DESCRIPTION; ^^^^^^^^^^^. :program:`llvm-profdata order` uses temporal profiling traces from a profile and; finds a function order that reduces the number of page faults for those traces.; This output can be directly passed to ``lld`` via ``--symbol-ordering-file=``; for ELF or ``-order-file`` for Mach-O. If the traces found in the profile are; representative of the real world, then this order should improve startup; performance. OPTIONS; ^^^^^^^. .. option:: --help. Print a summary of command line options. .. option:: --output=<output>, -o. Specify the output file name. If *output* is ``-`` or it isn't specified,; then the output is sent to standard output. EXIT STATUS; -----------. :program:`llvm-profdata` returns 1 if the command is omitted or is invalid,; if it cannot read input files, or if there is a mismatch between their data.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-profdata.rst:14148,perform,performance,14148,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-profdata.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-profdata.rst,1,['perform'],['performance']
Performance,"(c|a) & b);}; Should fold to ""(~a & c) | (a & b)"". Currently not optimized with; ""clang -emit-llvm-bc | opt -O3"". //===---------------------------------------------------------------------===//. int a(int a,int b) {return (~(a|b))|a;}; Should fold to ""a|~b"". Currently not optimized with ""clang; -emit-llvm-bc | opt -O3"". //===---------------------------------------------------------------------===//. int a(int a, int b) {return (a&&b) || (a&&!b);}; Should fold to ""a"". Currently not optimized with ""clang -emit-llvm-bc; | opt -O3"". //===---------------------------------------------------------------------===//. int a(int a, int b, int c) {return (a&&b) || (!a&&c);}; Should fold to ""a ? b : c"", or at least something sane. Currently not; optimized with ""clang -emit-llvm-bc | opt -O3"". //===---------------------------------------------------------------------===//. int a(int a, int b, int c) {return (a&&b) || (a&&c) || (a&&b&&c);}; Should fold to a && (b || c). Currently not optimized with ""clang; -emit-llvm-bc | opt -O3"". //===---------------------------------------------------------------------===//. int a(int x) {return x | ((x & 8) ^ 8);}; Should combine to x | 8. Currently not optimized with ""clang; -emit-llvm-bc | opt -O3"". //===---------------------------------------------------------------------===//. int a(int x) {return x ^ ((x & 8) ^ 8);}; Should also combine to x | 8. Currently not optimized with ""clang; -emit-llvm-bc | opt -O3"". //===---------------------------------------------------------------------===//. int a(int x) {return ((x | -9) ^ 8) & x;}; Should combine to x & -9. Currently not optimized with ""clang; -emit-llvm-bc | opt -O3"". //===---------------------------------------------------------------------===//. unsigned a(unsigned a) {return a * 0x11111111 >> 28 & 1;}; Should combine to ""a * 0x88888888 >> 31"". Currently not optimized; with ""clang -emit-llvm-bc | opt -O3"". //===---------------------------------------------------------------------===//. un",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/README.txt:25167,optimiz,optimized,25167,interpreter/llvm-project/llvm/lib/Target/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/README.txt,2,['optimiz'],['optimized']
Performance,"(e.g., entire applications, benchmarks,; etc) should be added to the ``llvm-test`` test suite. The llvm-test suite is; for coverage (correctness, performance, etc) testing, not feature or regression; testing. Release Notes; -------------. Many projects in LLVM communicate important changes to users through release; notes, typically found in ``docs/ReleaseNotes.rst`` for the project. Changes to; a project that are user-facing, or that users may wish to know about, should be; added to the project's release notes at the author's or code reviewer's; discretion, preferably as part of the commit landing the changes. Examples of; changes that would typically warrant adding a release note (this list is not; exhaustive):. * Adding, removing, or modifying command-line options.; * Adding, removing, or regrouping a diagnostic.; * Fixing a bug that potentially has significant user-facing impact (please link; to the issue fixed in the bug database).; * Adding or removing optimizations that have widespread impact or enables new; programming paradigms.; * Modifying a C stable API.; * Notifying users about a potentially disruptive change expected to be made in; a future release, such as removal of a deprecated feature. In this case, the; release note should be added to a ``Potentially Breaking Changes`` section of; the notes with sufficient information and examples to demonstrate the; potential disruption. Additionally, any new entries to this section should be; announced in the `Announcements <https://discourse.llvm.org/c/announce/>`_; channel on Discourse. See :ref:`breaking` for more details. Code reviewers are encouraged to request a release note if they think one is; warranted when performing a code review. Quality; -------. The minimum quality standards that any change must satisfy before being; committed to the main development branch are:. #. Code must adhere to the `LLVM Coding Standards <CodingStandards.html>`_. #. Code must compile cleanly (no errors, no warnings) on at le",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:11544,optimiz,optimizations,11544,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,1,['optimiz'],['optimizations']
Performance,"(int a, int b) {; int lt = a < b;; int eq = a == b;; if (lt); return 1;; return eq;; }. Is compiled to:. define i32 @test(i32 %a, i32 %b) nounwind readnone ssp {; entry:; %cmp = icmp slt i32 %a, %b; br i1 %cmp, label %return, label %if.end. if.end: ; preds = %entry; %cmp5 = icmp eq i32 %a, %b; %conv6 = zext i1 %cmp5 to i32; ret i32 %conv6. return: ; preds = %entry; ret i32 1; }. it could be:. define i32 @test__(i32 %a, i32 %b) nounwind readnone ssp {; entry:; %0 = icmp sle i32 %a, %b; %retval = zext i1 %0 to i32; ret i32 %retval; }. //===---------------------------------------------------------------------===//. This code can be seen in viterbi:. %64 = call noalias i8* @malloc(i64 %62) nounwind; ...; %67 = call i64 @llvm.objectsize.i64(i8* %64, i1 false) nounwind; %68 = call i8* @__memset_chk(i8* %64, i32 0, i64 %62, i64 %67) nounwind. llvm.objectsize.i64 should be taught about malloc/calloc, allowing it to; fold to %62. This is a security win (overflows of malloc will get caught); and also a performance win by exposing more memsets to the optimizer. This occurs several times in viterbi. Note that this would change the semantics of @llvm.objectsize which by its; current definition always folds to a constant. We also should make sure that; we remove checking in code like. char *p = malloc(strlen(s)+1);; __strcpy_chk(p, s, __builtin_object_size(p, 0));. //===---------------------------------------------------------------------===//. clang -O3 currently compiles this code. int g(unsigned int a) {; unsigned int c[100];; c[10] = a;; c[11] = a;; unsigned int b = c[10] + c[11];; if(b > a*2) a = 4;; else a = 8;; return a + 7;; }. into. define i32 @g(i32 a) nounwind readnone {; %add = shl i32 %a, 1; %mul = shl i32 %a, 1; %cmp = icmp ugt i32 %add, %mul; %a.addr.0 = select i1 %cmp, i32 11, i32 15; ret i32 %a.addr.0; }. The icmp should fold to false. This CSE opportunity is only available; after GVN and InstCombine have run. //===------------------------------------------------",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/README.txt:54299,perform,performance,54299,interpreter/llvm-project/llvm/lib/Target/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/README.txt,4,"['optimiz', 'perform']","['optimizer', 'performance']"
Performance,"(int_ppc_vsx_xxbrw v4i32:$XB)); (set v2i64:$XT, (int_ppc_vsx_xxbrd v2i64:$XB)); (set v1i128:$XT, (int_ppc_vsx_xxbrq v1i128:$XB)). - Vector Permute: xxperm xxpermr; . I have checked ""PPCxxswapd"" in PPCInstrVSX.td, but they are different; . Use intrinsic; (set v16i8:$XT, (int_ppc_vsx_xxperm v16i8:$XA, v16i8:$XB)); (set v16i8:$XT, (int_ppc_vsx_xxpermr v16i8:$XA, v16i8:$XB)). - Vector Splat Immediate Byte: xxspltib; . Similar to XXSPLTW:; def XXSPLTW : XX2Form_2<60, 164,; (outs vsrc:$XT), (ins vsrc:$XB, u2imm:$UIM),; ""xxspltw $XT, $XB, $UIM"", IIC_VecPerm, []>;. . No SDAG, intrinsic, builtin are required?. - Load/Store Vector: lxv stxv; . Has likely SDAG match:; (set v?:$XT, (load ix16addr:$src)); (set v?:$XT, (store ix16addr:$dst)). . Need define ix16addr in PPCInstrInfo.td; ix16addr: 16-byte aligned, see ""def memrix16"" in PPCInstrInfo.td. - Load/Store Vector Indexed: lxvx stxvx; . Has likely SDAG match:; (set v?:$XT, (load xoaddr:$src)); (set v?:$XT, (store xoaddr:$dst)). - Load/Store DWord: lxsd stxsd; . Similar to lxsdx/stxsdx:; def LXSDX : XX1Form<31, 588,; (outs vsfrc:$XT), (ins memrr:$src),; ""lxsdx $XT, $src"", IIC_LdStLFD,; [(set f64:$XT, (load xoaddr:$src))]>;. . (set f64:$XT, (load iaddrX4:$src)); (set f64:$XT, (store iaddrX4:$dst)). - Load/Store SP, with conversion from/to DP: lxssp stxssp; . Similar to lxsspx/stxsspx:; def LXSSPX : XX1Form<31, 524, (outs vssrc:$XT), (ins memrr:$src),; ""lxsspx $XT, $src"", IIC_LdStLFD,; [(set f32:$XT, (load xoaddr:$src))]>;. . (set f32:$XT, (load iaddrX4:$src)); (set f32:$XT, (store iaddrX4:$dst)). - Load as Integer Byte/Halfword & Zero Indexed: lxsibzx lxsihzx; . Similar to lxsiwzx:; def LXSIWZX : XX1Form<31, 12, (outs vsfrc:$XT), (ins memrr:$src),; ""lxsiwzx $XT, $src"", IIC_LdStLFD,; [(set f64:$XT, (PPClfiwzx xoaddr:$src))]>;. . (set f64:$XT, (PPClfiwzx xoaddr:$src)). - Store as Integer Byte/Halfword Indexed: stxsibx stxsihx; . Similar to stxsiwx:; def STXSIWX : XX1Form<31, 140, (outs), (ins vsfrc:$XT, memrr:$dst),; ""stxsiwx $X",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/README_P9.txt:17671,Load,Load,17671,interpreter/llvm-project/llvm/lib/Target/PowerPC/README_P9.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/README_P9.txt,1,['Load'],['Load']
Performance,"(m_A+m_B+m_C)). Constrained split can also be; specified in product of categories. In that case the name of the; remainder state follows the syntax {State1;State2} where State1; and State2 are the state names of the two spitting categories. Additional; functionality exists to work with multiple prototype p.d.f.s simultaneously. ; Improved infrastructure for caching p.d.f and functions. The infrastructure that exists for caching p.d.f.s, i.e. p.d.f that precalculate their value; for all observable values at one and cache those in a histogram that is returned as p.d.f shape; (with optional interpolation), has been expanded. This infrastructure comprises RooAbsCached; the base class for all caching p.d.fs, RooAbsSelfCachedPdf a base class for end-user; caching p.d.f implementations that simply cache the result of evaluate() and RooCachedPdf; that can wrap and cache any input p.d.f specified in its constructor. . By default a p.d.f is sampled and cached in all observables in any; given use context, with no need to specify what those are in advance.; The internal code has also been changed such that all cache; histograms now store pre-normalized p.d.f, which is more efficient; than 'raw' p.d.f histograms that are explicitly post-normalized; through integration. Multiple different use cases (e.g. definitions; of what are observables vs parameters) can be cached; simultaneously. Now it is also possible to specify that p.d.f.s; should be sampled and cached in one or more parameter dimensions; in addition to the automatically determined set of observables.; as well. Also a complete new line of classes with similar functionality has been added inheriting from RooAbsReal.; These are RooAbsCachedReal,RooAbsSelfCachedReal and RooCachedReal. A newly; added class RooHistFunc presents these shapes and is capable of handling negative entries. New PDF error handling structure. New infrastructure has been put into place to propagate and process p.d.f evaluation errors during fitting.;",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html:14079,cache,cached,14079,roofit/doc/v520/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html,2,['cache'],['cached']
Performance,"(non-coherent) with; the PTE C-bit set or MTYPE UC (uncached) for memory not local to the L2. * Any local memory cache lines will be automatically invalidated by writes; from CUs associated with other L2 caches, or writes from the CPU, due to; the cache probe caused by coherent requests. Coherent requests are caused; by GPU accesses to pages with the PTE C-bit set, by CPU accesses over; XGMI, and by PCIe requests that are configured to be coherent requests.; * XGMI accesses from the CPU to local memory may be cached on the CPU.; Subsequent access from the GPU will automatically invalidate or writeback; the CPU cache due to the L2 probe filter and and the PTE C-bit being set.; * Since all work-groups on the same agent share the same L2, no L2; invalidation or writeback is required for coherence.; * To ensure coherence of local and remote memory writes of work-groups in; different agents a ``buffer_wbl2`` is required. It will writeback dirty L2; cache lines of MTYPE RW (used for local coarse grain memory) and MTYPE NC; ()used for remote coarse grain memory). Note that MTYPE CC (used for local; fine grain memory) causes write through to DRAM, and MTYPE UC (used for; remote fine grain memory) bypasses the L2, so both will never result in; dirty L2 cache lines.; * To ensure coherence of local and remote memory reads of work-groups in; different agents a ``buffer_invl2`` is required. It will invalidate L2; cache lines with MTYPE NC (used for remote coarse grain memory). Note that; MTYPE CC (used for local fine grain memory) and MTYPE RW (used for local; coarse memory) cause local reads to be invalidated by remote writes with; with the PTE C-bit so these cache lines are not invalidated. Note that; MTYPE UC (used for remote fine grain memory) bypasses the L2, so will; never result in L2 cache lines that need to be invalidated. * PCIe access from the GPU to the CPU memory is kept coherent by using the; MTYPE UC (uncached) which bypasses the L2. Scalar memory operations are on",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:238762,cache,cache,238762,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['cache'],['cache']
Performance,"(see comment for; previous fence).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Must happen before; the following buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures that the; fence-paired atomic; has completed; before invalidating; the; cache. Therefore; any following; locations read must; be no older than; the value read by; the; fence-paired-atomic. 2. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before any; following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes.; **Release Atomic**; ------------------------------------------------------------------------------------; store atomic release - singlethread - global 1. buffer/global/flat_store; - wavefront - generic; store atomic release - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; be used.*. 1. ds_store; store atomic release - workgroup - global 1. s_waitcnt lgkm/vmcnt(0); - generic; - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit lgkmcnt(0).; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; ato",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:256533,load,load,256533,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],['load']
Performance,"(set v8i16:$XT, (int_ppc_vsx_xxbrh v8i16:$XB)); (set v4i32:$XT, (int_ppc_vsx_xxbrw v4i32:$XB)); (set v2i64:$XT, (int_ppc_vsx_xxbrd v2i64:$XB)); (set v1i128:$XT, (int_ppc_vsx_xxbrq v1i128:$XB)). - Vector Permute: xxperm xxpermr; . I have checked ""PPCxxswapd"" in PPCInstrVSX.td, but they are different; . Use intrinsic; (set v16i8:$XT, (int_ppc_vsx_xxperm v16i8:$XA, v16i8:$XB)); (set v16i8:$XT, (int_ppc_vsx_xxpermr v16i8:$XA, v16i8:$XB)). - Vector Splat Immediate Byte: xxspltib; . Similar to XXSPLTW:; def XXSPLTW : XX2Form_2<60, 164,; (outs vsrc:$XT), (ins vsrc:$XB, u2imm:$UIM),; ""xxspltw $XT, $XB, $UIM"", IIC_VecPerm, []>;. . No SDAG, intrinsic, builtin are required?. - Load/Store Vector: lxv stxv; . Has likely SDAG match:; (set v?:$XT, (load ix16addr:$src)); (set v?:$XT, (store ix16addr:$dst)). . Need define ix16addr in PPCInstrInfo.td; ix16addr: 16-byte aligned, see ""def memrix16"" in PPCInstrInfo.td. - Load/Store Vector Indexed: lxvx stxvx; . Has likely SDAG match:; (set v?:$XT, (load xoaddr:$src)); (set v?:$XT, (store xoaddr:$dst)). - Load/Store DWord: lxsd stxsd; . Similar to lxsdx/stxsdx:; def LXSDX : XX1Form<31, 588,; (outs vsfrc:$XT), (ins memrr:$src),; ""lxsdx $XT, $src"", IIC_LdStLFD,; [(set f64:$XT, (load xoaddr:$src))]>;. . (set f64:$XT, (load iaddrX4:$src)); (set f64:$XT, (store iaddrX4:$dst)). - Load/Store SP, with conversion from/to DP: lxssp stxssp; . Similar to lxsspx/stxsspx:; def LXSSPX : XX1Form<31, 524, (outs vssrc:$XT), (ins memrr:$src),; ""lxsspx $XT, $src"", IIC_LdStLFD,; [(set f32:$XT, (load xoaddr:$src))]>;. . (set f32:$XT, (load iaddrX4:$src)); (set f32:$XT, (store iaddrX4:$dst)). - Load as Integer Byte/Halfword & Zero Indexed: lxsibzx lxsihzx; . Similar to lxsiwzx:; def LXSIWZX : XX1Form<31, 12, (outs vsfrc:$XT), (ins memrr:$src),; ""lxsiwzx $XT, $src"", IIC_LdStLFD,; [(set f64:$XT, (PPClfiwzx xoaddr:$src))]>;. . (set f64:$XT, (PPClfiwzx xoaddr:$src)). - Store as Integer Byte/Halfword Indexed: stxsibx stxsihx; . Similar to stxsiwx:; def STXSIWX : XX1",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/README_P9.txt:17614,load,load,17614,interpreter/llvm-project/llvm/lib/Target/PowerPC/README_P9.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/README_P9.txt,2,['load'],['load']
Performance,"(vic. 1) for this flag enables; the AT&T (vic. Intel) assembly format for the code printed out by the tool in; the analysis report. .. option:: -print-imm-hex. Prefer hex format for numeric literals in the output assembly printed as part; of the report. .. option:: -dispatch=<width>. Specify a different dispatch width for the processor. The dispatch width; defaults to field 'IssueWidth' in the processor scheduling model. If width is; zero, then the default dispatch width is used. .. option:: -register-file-size=<size>. Specify the size of the register file. When specified, this flag limits how; many physical registers are available for register renaming purposes. A value; of zero for this flag means ""unlimited number of physical registers"". .. option:: -iterations=<number of iterations>. Specify the number of iterations to run. If this flag is set to 0, then the; tool sets the number of iterations to a default value (i.e. 100). .. option:: -noalias=<bool>. If set, the tool assumes that loads and stores don't alias. This is the; default behavior. .. option:: -lqueue=<load queue size>. Specify the size of the load queue in the load/store unit emulated by the tool.; By default, the tool assumes an unbound number of entries in the load queue.; A value of zero for this flag is ignored, and the default load queue size is; used instead. .. option:: -squeue=<store queue size>. Specify the size of the store queue in the load/store unit emulated by the; tool. By default, the tool assumes an unbound number of entries in the store; queue. A value of zero for this flag is ignored, and the default store queue; size is used instead. .. option:: -timeline. Enable the timeline view. .. option:: -timeline-max-iterations=<iterations>. Limit the number of iterations to print in the timeline view. By default, the; timeline view prints information for up to 10 iterations. .. option:: -timeline-max-cycles=<cycles>. Limit the number of cycles in the timeline view, or use 0 for no limit. By",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:4046,load,loads,4046,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,1,['load'],['loads']
Performance,"(x, 0.25)``; may be replaced with ``sqrt(sqrt(x))``, despite being an inexact result; in cases where ``x`` is ``-0.0`` or ``-inf``.; Defaults to ``-fno-approx-func``. .. option:: -f[no-]signed-zeros. Allow optimizations that ignore the sign of floating point zeros.; Defaults to ``-fsigned-zeros``. .. option:: -f[no-]associative-math. Allow floating point operations to be reassociated.; Defaults to ``-fno-associative-math``. .. option:: -f[no-]reciprocal-math. Allow division operations to be transformed into multiplication by a; reciprocal. This can be significantly faster than an ordinary division; but can also have significantly less precision. Defaults to; ``-fno-reciprocal-math``. .. option:: -f[no-]unsafe-math-optimizations. Allow unsafe floating-point optimizations.; ``-funsafe-math-optimizations`` also implies:. * ``-fapprox-func``; * ``-fassociative-math``; * ``-freciprocal-math``; * ``-fno-signed-zeros``; * ``-fno-trapping-math``; * ``-ffp-contract=fast``. ``-fno-unsafe-math-optimizations`` implies:. * ``-fno-approx-func``; * ``-fno-associative-math``; * ``-fno-reciprocal-math``; * ``-fsigned-zeros``; * ``-ftrapping-math``; * ``-ffp-contract=on``; * ``-fdenormal-fp-math=ieee``. There is ambiguity about how ``-ffp-contract``,; ``-funsafe-math-optimizations``, and ``-fno-unsafe-math-optimizations``; behave when combined. Explanation in :option:`-fno-fast-math` also applies; to these options. Defaults to ``-fno-unsafe-math-optimizations``. .. option:: -f[no-]finite-math-only. Allow floating-point optimizations that assume arguments and results are; not NaNs or +-Inf. ``-ffinite-math-only`` defines the; ``__FINITE_MATH_ONLY__`` preprocessor macro.; ``-ffinite-math-only`` implies:. * ``-fno-honor-infinities``; * ``-fno-honor-nans``. ``-ffno-inite-math-only`` implies:. * ``-fhonor-infinities``; * ``-fhonor-nans``. Defaults to ``-fno-finite-math-only``. .. option:: -f[no-]rounding-math. Force floating-point operations to honor the dynamically-set rounding mode by de",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:59503,optimiz,optimizations,59503,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,1,['optimiz'],['optimizations']
Performance,") &; vmcnt(0) & vscnt(0). - If CU wavefront execution; mode, omit vmcnt(0) and; vscnt(0).; - If OpenCL, omit lgkmcnt(0).; - Must happen before; the following; buffer_gl0_inv.; - Ensures any; following global; data read is no; older than the load; atomic value being; acquired. 3. buffer_gl0_inv. - If CU wavefront execution; mode, omit.; - Ensures that; following; loads will not see; stale data. atomicrmw acq_rel - agent - global 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0) & vscnt(0). - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0), s_waitcnt; vscnt(0) and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/load atomic/; atomicrmw-with-return-value.; - s_waitcnt vscnt(0); must happen after; any preceding; global/generic; store/store atomic/; atomicrmw-no-return-value.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global_atomic; 3. s_waitcnt vm/vscnt(0). - Use vmcnt(0) if atomic with; return and vscnt(0) if; atomic with no-return.; - Must happen before; following; buffer_gl*_inv.; - Ensures the; atomicrmw has; completed before; invalidating the; caches. 4. buffer_gl0_inv;; buffer_gl1_inv. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acq_rel - agent - generic 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0) & vscnt(0). - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0), s_waitcnt; vscnt(0), and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0);",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:367466,load,load,367466,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],['load']
Performance,") infinite loop should a; server go offline that is subject to a locate request display.Client sideBetter handling of errno, especially for parallel streamsAllow the client to cycle through all the remaining valid security protocols in the list of protocols returned by the serverMake the readahead strategy more conservativeFix a rare race condition happening when destroying instances with outstanding open requestsEnforce cache coherency in the case of reads+writes in the same fileCorrectly guess the filesize of a file opened for writing in sync modeMake server host name check more flexible for GSI authenticationFix some relevant issues with cache handling on the client, including a rare but fatal bug in; determining the cache holes list and the end of a cache lookupMore complete detection of async read errorsGeneralFix problem in handling the return code; of X509_REQ_verify; in XrdCryptosslX509Req.ccAvoid SEGV when doing an lsd admin command with; authenticated xrootd clientsClose race conditions that allowed a supervisor/manager; to subscribe without declaring a data port. Initialize nostage state in; XrdCmsState to prevent erroneous state declaration during; initialization.Fix a problem with the subject name of proxies of level; > 1; this was creating a failure when a Globus application was; trying to use the proxy certificateFix a problem with cache refreshing in XrdSutCache; affecting automatic reloading of password filesFor now, turn off IPV6 processing as it seems to create; several problems.Fix a few issues with the available releases of gcc 4.4Fix a few issues with the 'icc' compilerFix several issues in GSI and PWD authentication modulesNew featuresNew File Residency Manager (frm), replacement for the MPS scriptsScripts are now provided toautomatically donwload a CRL certificate; (utils/getCRLcert)install the recommended verion of OpenSSL and build it; with the options optimal for usage in XROOTD/SCALLA; (utils/installOpenSSL.sh)install the recommended verio",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/net/doc/v524/index.html:2824,race condition,race conditions,2824,net/doc/v524/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/net/doc/v524/index.html,2,['race condition'],['race conditions']
Performance,") rather than comparisons (`==`). Expert users can resort to compiled callables if they absolutely have to assign to column values (not recommended). See [ROOT-11009](https://sft.its.cern.ch/jira/browse/ROOT-11009) for further discussion.; - For some `TTrees`, `RDataFrame::GetColumnNames` might now returns multiple valid spellings for a given column. For example, leaf `""l""` under branch `""b""` might now be mentioned as `""l""` as well as `""b.l""`, while only one of the two spellings might have been recognized before.; - Certain RDF-related types in the `ROOT::Detail` and `ROOT::Internal` namespaces have been renamed, most notably `RCustomColumn` is now `RDefine`. This does not impact code that only makes use of entities in the public ROOT namespace, and should not impact downstream code unless it was patching or reusing internal `RDataFrame` types. ### Notable bug fixes and improvements. - A critical issue has been fixed that could potentially result in wrong data being silently read in multi-thread runs when an input `TChain` contained more than one `TTree` coming from the _same_ input file. More details are available at [#7143](https://github.com/root-project/root/issues/7143).; - The start-up time of event loops with large computation graphs with many just-in-time-compiled expressions (e.g. thousands of string `Filter`s and `Define`s) has been greatly reduced. See [the corresponding pull request](https://github.com/root-project/root/pull/7651) for more details. The full list of bug fixes for this release is available below. ### Distributed computing with RDataFrame; ROOT 6.24 introduces `ROOT.RDF.Experimental.Distributed`, an experimental python package that enhances RDataFrame with distributed computing capabilities. The new package allows distributing RDataFrame applications through one of the supported distributed backends. The package was designed so that different backends can be easily plugged in. Currently the [Apache Spark](http://spark.apache.org/) backend is",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v624/index.md:9473,multi-thread,multi-thread,9473,README/ReleaseNotes/v624/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v624/index.md,1,['multi-thread'],['multi-thread']
Performance,"), %edx; movl 16(%esp), %eax; decl %edx; jle .L7; .L5:; addl $12, %esp; ret; .p2align 4,,7; .L7:; jl .L4; cmpl $0, %eax; .p2align 4,,8; ja .L5; .L4:; .p2align 4,,9; call abort. //===---------------------------------------------------------------------===//. Tail call optimization improvements: Tail call optimization currently; pushes all arguments on the top of the stack (their normal place for; non-tail call optimized calls) that source from the callers arguments; or that source from a virtual register (also possibly sourcing from; callers arguments).; This is done to prevent overwriting of parameters (see example; below) that might be used later. example: . int callee(int32, int64); ; int caller(int32 arg1, int32 arg2) { ; int64 local = arg2 * 2; ; return callee(arg2, (int64)local); ; }. [arg1] [!arg2 no longer valid since we moved local onto it]; [arg2] -> [(int64); [RETADDR] local ]. Moving arg1 onto the stack slot of callee function would overwrite; arg2 of the caller. Possible optimizations:. - Analyse the actual parameters of the callee to see which would; overwrite a caller parameter which is used by the callee and only; push them onto the top of the stack. int callee (int32 arg1, int32 arg2);; int caller (int32 arg1, int32 arg2) {; return callee(arg1,arg2);; }. Here we don't need to write any variables to the top of the stack; since they don't overwrite each other. int callee (int32 arg1, int32 arg2);; int caller (int32 arg1, int32 arg2) {; return callee(arg2,arg1);; }. Here we need to push the arguments because they overwrite each; other. //===---------------------------------------------------------------------===//. main (); {; int i = 0;; unsigned long int z = 0;. do {; z -= 0x00004000;; i++;; if (i > 0x00040000); abort ();; } while (z > 0);; exit (0);; }. gcc compiles this to:. _main:; 	subl	$28, %esp; 	xorl	%eax, %eax; 	jmp	L2; L3:; 	cmpl	$262144, %eax; 	je	L10; L2:; 	addl	$1, %eax; 	cmpl	$262145, %eax; 	jne	L3; 	call	L_abort$stub; L10:; 	movl	$0, (%es",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README.txt:18728,optimiz,optimizations,18728,interpreter/llvm-project/llvm/lib/Target/X86/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README.txt,2,['optimiz'],['optimizations']
Performance,"), %xmm1; xorps %xmm0, %xmm0; movss %xmm1, %xmm0; ret. Now consider if the ... code caused xmm1 to get spilled. This might produce; this code:. movaps c(%esp), %xmm1; movaps %xmm1, c2(%esp); ... xorps %xmm0, %xmm0; movaps c2(%esp), %xmm1; movss %xmm1, %xmm0; ret. However, since the reload is only used by these instructions, we could ; ""fold"" it into the uses, producing something like this:. movaps c(%esp), %xmm1; movaps %xmm1, c2(%esp); ... movss c2(%esp), %xmm0; ret. ... saving two instructions. The basic idea is that a reload from a spill slot, can, if only one 4-byte ; chunk is used, bring in 3 zeros the one element instead of 4 elements.; This can be used to simplify a variety of shuffle operations, where the; elements are fixed zeros. //===---------------------------------------------------------------------===//. This code generates ugly code, probably due to costs being off or something:. define void @test(float* %P, <4 x float>* %P2 ) {; %xFloat0.688 = load float* %P; %tmp = load <4 x float>* %P2; %inFloat3.713 = insertelement <4 x float> %tmp, float 0.0, i32 3; store <4 x float> %inFloat3.713, <4 x float>* %P2; ret void; }. Generates:. _test:; 	movl	8(%esp), %eax; 	movaps	(%eax), %xmm0; 	pxor	%xmm1, %xmm1; 	movaps	%xmm0, %xmm2; 	shufps	$50, %xmm1, %xmm2; 	shufps	$132, %xmm2, %xmm0; 	movaps	%xmm0, (%eax); 	ret. Would it be better to generate:. _test:; movl 8(%esp), %ecx; movaps (%ecx), %xmm0; 	xor %eax, %eax; pinsrw $6, %eax, %xmm0; pinsrw $7, %eax, %xmm0; movaps %xmm0, (%ecx); ret. ?. //===---------------------------------------------------------------------===//. Some useful information in the Apple Altivec / SSE Migration Guide:. http://developer.apple.com/documentation/Performance/Conceptual/; Accelerate_sse_migration/index.html. e.g. SSE select using and, andnot, or. Various SSE compare translations. //===---------------------------------------------------------------------===//. Add hooks to commute some CMPP operations. //===--------------------------",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README-SSE.txt:8304,load,load,8304,interpreter/llvm-project/llvm/lib/Target/X86/README-SSE.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README-SSE.txt,4,['load'],['load']
Performance,"), std::move(Then),; std::move(Else));; }. Next we hook it up as a primary expression:. .. code-block:: c++. static std::unique_ptr<ExprAST> ParsePrimary() {; switch (CurTok) {; default:; return LogError(""unknown token when expecting an expression"");; case tok_identifier:; return ParseIdentifierExpr();; case tok_number:; return ParseNumberExpr();; case '(':; return ParseParenExpr();; case tok_if:; return ParseIfExpr();; }; }. LLVM IR for If/Then/Else; ------------------------. Now that we have it parsing and building the AST, the final piece is; adding LLVM code generation support. This is the most interesting part; of the if/then/else example, because this is where it starts to; introduce new concepts. All of the code above has been thoroughly; described in previous chapters. To motivate the code we want to produce, let's take a look at a simple; example. Consider:. ::. extern foo();; extern bar();; def baz(x) if x then foo() else bar();. If you disable optimizations, the code you'll (soon) get from; Kaleidoscope looks like this:. .. code-block:: llvm. declare double @foo(). declare double @bar(). define double @baz(double %x) {; entry:; %ifcond = fcmp one double %x, 0.000000e+00; br i1 %ifcond, label %then, label %else. then: ; preds = %entry; %calltmp = call double @foo(); br label %ifcont. else: ; preds = %entry; %calltmp1 = call double @bar(); br label %ifcont. ifcont: ; preds = %else, %then; %iftmp = phi double [ %calltmp, %then ], [ %calltmp1, %else ]; ret double %iftmp; }. To visualize the control flow graph, you can use a nifty feature of the; LLVM '`opt <https://llvm.org/cmds/opt.html>`_' tool. If you put this LLVM; IR into ""t.ll"" and run ""``llvm-as < t.ll | opt -passes=view-cfg``"", `a; window will pop up <../../ProgrammersManual.html#viewing-graphs-while-debugging-code>`_ and you'll; see this graph:. .. figure:: LangImpl05-cfg.png; :align: center; :alt: Example CFG. Example CFG. Another way to get this is to call ""``F->viewCFG()``"" or; ""``F->viewCFGOnly()",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl05.rst:5296,optimiz,optimizations,5296,interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl05.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl05.rst,1,['optimiz'],['optimizations']
Performance,"). NCycles No 3000 − Number of training cycles. HiddenLayers No N,N-1 − Specification of hidden layer architecture. Configuration options for MVA method :. Configuration options reference for MVA method: KNN. Option Array Default value Predefined values Description. V No False − Verbose output (short form of VerbosityLevel below - overrides the latter one). VerbosityLevel No Default Default, Debug, Verbose, Info, Warning, Error, Fatal Verbosity level. VarTransform No None − List of variable transformations performed before training, e.g., D_Background,P_Signal,G,N_AllClasses for: Decorrelation, PCA-transformation, Gaussianisation, Normalisation, each for the given class of events ('AllClasses' denotes all events of all classes, if no class indication is given, 'All' is assumed). H No False − Print method-specific help message. CreateMVAPdfs No False − Create PDFs for classifier outputs (signal and background). IgnoreNegWeightsInTraining No False − Events with negative weights are ignored in the training (but are included for testing and performance evaluation). nkNN No 20 − Number of k-nearest neighbors. BalanceDepth No 6 − Binary tree balance depth. ScaleFrac No 0.8 − Fraction of events used to compute variable width. SigmaFact No 1 − Scale factor for sigma in Gaussian kernel. Kernel No Gaus − Use polynomial (=Poln) or Gaussian (=Gaus) kernel. Trim No False − Use equal number of signal and background events. UseKernel No False − Use polynomial kernel weight. UseWeight No True − Use weight to count kNN events. UseLDA No False − Use local linear discriminant - experimental feature. Configuration options for MVA method :. Configuration options reference for MVA method: BDT. Option Array Default value Predefined values Description. V No False − Verbose output (short form of VerbosityLevel below - overrides the latter one). VerbosityLevel No Default Default, Debug, Verbose, Info, Warning, Error, Fatal Verbosity level. VarTransform No None − List of variable transformati",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/tmva/UsersGuide/optionRef.html:10352,perform,performance,10352,documentation/tmva/UsersGuide/optionRef.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/tmva/UsersGuide/optionRef.html,2,['perform'],['performance']
Performance,"). std::multimap is useful if you want to map a key to multiple values, but has all; the drawbacks of std::map. A sorted vector or some other approach is almost; always better. .. _ds_bit:. Bit storage containers; ------------------------------------------------------------------------. There are several bit storage containers, and choosing when to use each is; relatively straightforward. One additional option is ``std::vector<bool>``: we discourage its use for two; reasons 1) the implementation in many common compilers (e.g. commonly; available versions of GCC) is extremely inefficient and 2) the C++ standards; committee is likely to deprecate this container and/or change it significantly; somehow. In any case, please don't use it. .. _dss_bitvector:. BitVector; ^^^^^^^^^. The BitVector container provides a dynamic size set of bits for manipulation.; It supports individual bit setting/testing, as well as set operations. The set; operations take time O(size of bitvector), but operations are performed one word; at a time, instead of one bit at a time. This makes the BitVector very fast for; set operations compared to other containers. Use the BitVector when you expect; the number of set bits to be high (i.e. a dense set). .. _dss_smallbitvector:. SmallBitVector; ^^^^^^^^^^^^^^. The SmallBitVector container provides the same interface as BitVector, but it is; optimized for the case where only a small number of bits, less than 25 or so,; are needed. It also transparently supports larger bit counts, but slightly less; efficiently than a plain BitVector, so SmallBitVector should only be used when; larger counts are rare. At this time, SmallBitVector does not support set operations (and, or, xor), and; its operator[] does not provide an assignable lvalue. .. _dss_sparsebitvector:. SparseBitVector; ^^^^^^^^^^^^^^^. The SparseBitVector container is much like BitVector, with one major difference:; Only the bits that are set, are stored. This makes the SparseBitVector much; m",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:97150,perform,performed,97150,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,1,['perform'],['performed']
Performance,"); blr. We could collapse a bunch of those ORs and ANDs and generate the following; equivalent code:. _foo:; lwz r2, 0(r3); rlwinm r4, r2, 1, 0, 0; or r2, r2, r4; stw r2, 0(r3); blr. ===-------------------------------------------------------------------------===. Consider a function like this:. float foo(float X) { return X + 1234.4123f; }. The FP constant ends up in the constant pool, so we need to get the LR register.; This ends up producing code like this:. _foo:; .LBB_foo_0: ; entry; mflr r11; *** stw r11, 8(r1); bl ""L00000$pb""; ""L00000$pb"":; mflr r2; addis r2, r2, ha16(.CPI_foo_0-""L00000$pb""); lfs f0, lo16(.CPI_foo_0-""L00000$pb"")(r2); fadds f1, f1, f0; *** lwz r11, 8(r1); mtlr r11; blr. This is functional, but there is no reason to spill the LR register all the way; to the stack (the two marked instrs): spilling it to a GPR is quite enough. Implementing this will require some codegen improvements. Nate writes:. ""So basically what we need to support the ""no stack frame save and restore"" is a; generalization of the LR optimization to ""callee-save regs"". Currently, we have LR marked as a callee-save reg. The register allocator sees; that it's callee save, and spills it directly to the stack. Ideally, something like this would happen:. LR would be in a separate register class from the GPRs. The class of LR would be; marked ""unspillable"". When the register allocator came across an unspillable; reg, it would ask ""what is the best class to copy this into that I *can* spill""; If it gets a class back, which it will in this case (the gprs), it grabs a free; register of that class. If it is then later necessary to spill that reg, so be; it. ===-------------------------------------------------------------------------===. We compile this:; int test(_Bool X) {; return X ? 524288 : 0;; }. to: ; _test:; cmplwi cr0, r3, 0; lis r2, 8; li r3, 0; beq cr0, LBB1_2 ;entry; LBB1_1: ;entry; mr r3, r2; LBB1_2: ;entry; blr . instead of:; _test:; addic r2,r3,-1; subfe r0,r2,r3; slwi r3,r0,",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/README.txt:7159,optimiz,optimization,7159,interpreter/llvm-project/llvm/lib/Target/PowerPC/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/README.txt,2,['optimiz'],['optimization']
Performance,");; ```. ### Disable copy assignment for RooAbsArg and derived types. Copy assignment for RooAbsArgs was implemented in an unexpected and; inconsistent way. While one would expect that the copy assignment is copying; the object, it said in the documentation of `RooAbsArg::operator=` that it will; ""assign all boolean and string properties of the original bject. Transient; properties and client-server links are not assigned."" This contradicted with; the implementation, where the server links were actually copied too.; Furthermore, in `RooAbsRealLValue`, the assigment operator was overloaded by a; function that only assigns the value of another `RooAbsReal`. With all these inconsistencies, it was deemed safer to disable copy assignment; of RooAbsArgs from now on. ### RooBrowser: a graphical user interface for workspace exploration, visualization, and analysis. This experimental new feature utilises the technology from ROOT's familiar `TBrowser` in order to create an interface for graphically exploring and visualizing the content of a workspace, as well as perform basic fitting operations with the models and datasets. ![Demonstration of RooBrowser using json workspace from the roofit tutorials directory](RooBrowser.png). ### Removal of deprecated HistFactory functionality. #### Removal of HistoToWorkspaceFactory (non-Fast version). The original `HistoToWorkspaceFactory` produced models that consisted of a; Poisson term for each bin. In this ""number counting form"" the dataset has one; row and the collumns corresponded to the number of events for each bin. This; led to severe performance problems in statistical tools that generated; pseudo-experiments and evaluated likelihood ratio test statistics. Nowadays, everyone uses the faster `HistoToWorkspaceFactoryFast` implementation that; produces a model in the ""standard form"" where the dataset has one row for each; event, and the column corresponds to the value of the observable in the; histogram. Therefore, the original `His",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v628/index.md:22278,perform,perform,22278,README/ReleaseNotes/v628/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v628/index.md,1,['perform'],['perform']
Performance,")`` method does not have ``REQUIRES``, so the; analysis issues a warning. Thread safety analysis is not inter-procedural, so; caller requirements must be explicitly declared.; There is also a warning in ``transferFrom()``, because although the method; locks ``this->mu``, it does not lock ``b.mu``. The analysis understands; that these are two separate mutexes, in two different objects. Finally, there is a warning in the ``withdraw()`` method, because it fails to; unlock ``mu``. Every lock must have a corresponding unlock, and the analysis; will detect both double locks, and double unlocks. A function is allowed to; acquire a lock without releasing it, (or vice versa), but it must be annotated; as such (using ``ACQUIRE``/``RELEASE``). Running The Analysis; --------------------. To run the analysis, simply compile with the ``-Wthread-safety`` flag, e.g. .. code-block:: bash. clang -c -Wthread-safety example.cpp. Note that this example assumes the presence of a suitably annotated; :ref:`mutexheader` that declares which methods perform locking,; unlocking, and so on. Basic Concepts: Capabilities; ============================. Thread safety analysis provides a way of protecting *resources* with; *capabilities*. A resource is either a data member, or a function/method; that provides access to some underlying resource. The analysis ensures that; the calling thread cannot access the *resource* (i.e. call the function, or; read/write the data) unless it has the *capability* to do so. Capabilities are associated with named C++ objects which declare specific; methods to acquire and release the capability. The name of the object serves; to identify the capability. The most common example is a mutex. For example,; if ``mu`` is a mutex, then calling ``mu.Lock()`` causes the calling thread; to acquire the capability to access data that is protected by ``mu``. Similarly,; calling ``mu.Unlock()`` releases that capability. A thread may hold a capability either *exclusively* or *shared",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ThreadSafetyAnalysis.rst:3411,perform,perform,3411,interpreter/llvm-project/clang/docs/ThreadSafetyAnalysis.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ThreadSafetyAnalysis.rst,1,['perform'],['perform']
Performance,")``. ``!div(``\ *a*\ ``,`` *b*\ ``)``; This operator performs signed division of *a* by *b*, and produces the quotient.; Division by 0 produces an error. Division of INT64_MIN by -1 produces an error. ``!empty(``\ *a*\ ``)``; This operator produces 1 if the string, list, or DAG *a* is empty; 0 otherwise.; A dag is empty if it has no arguments; the operator does not count. ``!eq(`` *a*\ `,` *b*\ ``)``; This operator produces 1 if *a* is equal to *b*; 0 otherwise.; The arguments must be ``bit``, ``bits``, ``int``, ``string``, or; record values. Use ``!cast<string>`` to compare other types of objects. ``!exists<``\ *type*\ ``>(``\ *name*\ ``)``; This operator produces 1 if a record of the given *type* whose name is *name*; exists; 0 otherwise. *name* should be of type *string*. ``!filter(``\ *var*\ ``,`` *list*\ ``,`` *predicate*\ ``)``. This operator creates a new ``list`` by filtering the elements in; *list*. To perform the filtering, TableGen binds the variable *var* to each; element and then evaluates the *predicate* expression, which presumably; refers to *var*. The predicate must; produce a boolean value (``bit``, ``bits``, or ``int``). The value is; interpreted as with ``!if``:; if the value is 0, the element is not included in the new list. If the value; is anything else, the element is included. ``!find(``\ *string1*\ ``,`` *string2*\ [``,`` *start*]\ ``)``; This operator searches for *string2* in *string1* and produces its; position. The starting position of the search may be specified by *start*,; which can range between 0 and the length of *string1*; the default is 0.; If the string is not found, the result is -1. ``!foldl(``\ *init*\ ``,`` *list*\ ``,`` *acc*\ ``,`` *var*\ ``,`` *expr*\ ``)``; This operator performs a left-fold over the items in *list*. The; variable *acc* acts as the accumulator and is initialized to *init*.; The variable *var* is bound to each element in the *list*. The; expression is evaluated for each element and presumably uses *acc* a",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TableGen/ProgRef.rst:63112,perform,perform,63112,interpreter/llvm-project/llvm/docs/TableGen/ProgRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TableGen/ProgRef.rst,1,['perform'],['perform']
Performance,"* `SPARC V8 ABI <http://sparc.org/standards/psABI3rd.pdf>`_. SystemZ; -------. * `z/Architecture Principles of Operation (registration required, free sign-up) <http://www-01.ibm.com/support/docview.wss?uid=isg2b9de5f05a9d57819852571c500428f9a>`_. VE; --. * `NEC SX-Aurora TSUBASA ISA Guide <https://www.hpc.nec/documents/guide/pdfs/Aurora_ISA_guide.pdf>`_; * `NEC SX-Aurora TSUBASA manuals and documentation <https://www.hpc.nec/documentation>`_. X86; ---. * `AMD processor manuals <http://developer.amd.com/resources/developer-guides-manuals/>`_; * `Intel 64 and IA-32 manuals <http://www.intel.com/content/www/us/en/processors/architectures-software-developer-manuals.html>`_; * `Intel Itanium documentation <http://www.intel.com/design/itanium/documentation.htm?iid=ipp_srvr_proc_itanium2+techdocs>`_; * `X86 and X86-64 SysV psABI <https://github.com/hjl-tools/x86-psABI/wiki/X86-psABI>`_; * `Calling conventions for different C++ compilers and operating systems <http://www.agner.org/optimize/calling_conventions.pdf>`_. XCore; -----. * `The XMOS XS1 Architecture (ISA) <https://www.xmos.ai/download/The-XMOS-XS1-Architecture%281.0%29.pdf>`_; * `The XMOS XS2 Architecture (ISA) <https://www.xmos.ai/download/xCORE-200:-The-XMOS-XS2-Architecture-%28ISA%29%281.1%29.pdf>`_; * `Tools Development Guide (includes ABI) <https://www.xmos.ai/download/Tools-Development-Guide%282.1%29.pdf>`_. Hexagon; -------. * `Hexagon Programmer's Reference Manuals and Hexagon ABI Specification (registration required, free sign-up) <https://developer.qualcomm.com/software/hexagon-dsp-sdk/tools>`_. Other relevant lists; --------------------. * `GCC reading list <http://gcc.gnu.org/readings.html>`_. ABI; ===. * `System V Application Binary Interface <http://www.sco.com/developers/gabi/latest/contents.html>`_; * `Itanium C++ ABI <http://itanium-cxx-abi.github.io/cxx-abi/>`_ (This is used for all non-Windows targets.). Linux; -----. * `Linux extensions to gabi <https://github.com/hjl-tools/linux-abi/wiki/Linux-",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompilerWriterInfo.rst:6332,optimiz,optimize,6332,interpreter/llvm-project/llvm/docs/CompilerWriterInfo.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompilerWriterInfo.rst,1,['optimiz'],['optimize']
Performance,"**; By default, ORC will compile symbols as soon as they are looked up in the JIT; session object (``ExecutionSession``). Compiling eagerly by default makes it; easy to use ORC as an in-memory compiler for an existing JIT (similar to how; MCJIT is commonly used). However ORC also provides built-in support for lazy; compilation via lazy-reexports (see :ref:`Laziness`). **Support for Custom Compilers and Program Representations**; Clients can supply custom compilers for each symbol that they define in their; JIT session. ORC will run the user-supplied compiler when the a definition of; a symbol is needed. ORC is actually fully language agnostic: LLVM IR is not; treated specially, and is supported via the same wrapper mechanism (the; ``MaterializationUnit`` class) that is used for custom compilers. **Concurrent JIT'd code** and **Concurrent Compilation**; JIT'd code may be executed in multiple threads, may spawn new threads, and may; re-enter the ORC (e.g. to request lazy compilation) concurrently from multiple; threads. Compilers launched my ORC can run concurrently (provided the client; sets up an appropriate dispatcher). Built-in dependency tracking ensures that; ORC does not release pointers to JIT'd code or data until all dependencies; have also been JIT'd and they are safe to call or use. **Removable Code**; Resources for JIT'd program representations. **Orthogonality** and **Composability**; Each of the features above can be used independently. It is possible to put; ORC components together to make a non-lazy, in-process, single threaded JIT; or a lazy, out-of-process, concurrent JIT, or anything in between. LLJIT and LLLazyJIT; ===================. ORC provides two basic JIT classes off-the-shelf. These are useful both as; examples of how to assemble ORC components to make a JIT, and as replacements; for earlier LLVM JIT APIs (e.g. MCJIT). The LLJIT class uses an IRCompileLayer and RTDyldObjectLinkingLayer to support; compilation of LLVM IR and linking of reloc",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ORCv2.rst:2913,concurren,concurrently,2913,interpreter/llvm-project/llvm/docs/ORCv2.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ORCv2.rst,1,['concurren'],['concurrently']
Performance,"**`TPosixThread`** ). **`TMutex`** class implements `mutex` locks. A mutex is a mutually; exclusive lock. The platform dependent implementation is in the; **`TMutexImp`** class and its descendant classes (e.g.; **`TPosixMutex`**). **`TCondition`** class implements a condition variable. Use a condition; variable to signal threads. The platform dependent implementation is in; the **`TConditionImp`** and **`TPosixCondition`** classes . **`TSemaphore`** class implements a counting semaphore. Use a semaphore; to synchronize threads. The platform dependent implementation is in the; **`TMutexImp`** and **`TConditionImp`** classes. ### TThread for Pedestrians. To run a thread in ROOT, follow these steps:. 1. Initialization. Add these lines to your `rootlogon.C`:. ``` {.cpp}; {; ...; // The next line may be unnecessary on some platforms; gSystem->Load(""/usr/lib/libpthread.so"");; gSystem->Load(""$ROOTSYS/lib/libThread.so"");; ...; }; ```. This loads the library with the **`TThread`** class and the `pthread`; specific implementation file for `Posix` threads. 2. Coding. Define a function (e.g. `void* UserFun(void* UserArgs))` that should run; as a thread. The code for the examples is at the web site of the authors; (Jörn Adamczewski, Marc Hemberger). After downloading the code from this; site, you can follow the example below:. <http://www-linux.gsi.de/~go4/HOWTOthreads/howtothreadsbody.html>. 3. Loading. Start an interactive ROOT session. Load the shared library:. ``` {.cpp}; root[] gSystem->Load(""mhs3.so""); // or; root[] gSystem->Load(""CalcPiThread.so"");; ```. 4. Creating. Create a thread instance (see also example `RunMhs3.C `or` RunPi.C`); with:. ``` {.cpp}; root[] TThread *th = new TThread(UserFun,UserArgs);; ```. When called from the interpreter, this gives the name ""`UserFun`"" to the; thread. This name can be used to retrieve the thread later. However,; when called from compiled code, this method does not give any name to; the thread. So give a name to the thread in compile",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Threads.md:4635,load,loads,4635,documentation/users-guide/Threads.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Threads.md,1,['load'],['loads']
Performance,"*. Apple Clang Builds (A More Complex Bootstrap); =============================================. Apple's Clang builds are a slightly more complicated example of the simple; bootstrapping scenario. Apple Clang is built using a 2-stage build. The stage1 compiler is a host-only compiler with some options set. The stage1; compiler is a balance of optimization vs build time because it is a throwaway.; The stage2 compiler is the fully optimized compiler intended to ship to users. Setting up these compilers requires a lot of options. To simplify the; configuration the Apple Clang build settings are contained in CMake Cache files.; You can build an Apple Clang compiler using the following commands:. .. code-block:: console. $ cmake -G Ninja -C <path to source>/clang/cmake/caches/Apple-stage1.cmake <path to source>/llvm; $ ninja stage2-distribution. This CMake invocation configures the stage1 host compiler, and sets; CLANG_BOOTSTRAP_CMAKE_ARGS to pass the Apple-stage2.cmake cache script to the; stage2 configuration step. When you build the stage2-distribution target it builds the minimal stage1; compiler and required tools, then configures and builds the stage2 compiler; based on the settings in Apple-stage2.cmake. This pattern of using cache scripts to set complex settings, and specifically to; make later stage builds include cache scripts is common in our more advanced; build configurations. Multi-stage PGO; ===============. Profile-Guided Optimizations (PGO) is a really great way to optimize the code; clang generates. Our multi-stage PGO builds are a workflow for generating PGO; profiles that can be used to optimize clang. At a high level, the way PGO works is that you build an instrumented compiler,; then you run the instrumented compiler against sample source files. While the; instrumented compiler runs it will output a bunch of files containing; performance counters (.profraw files). After generating all the profraw files; you use llvm-profdata to merge the files into a",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AdvancedBuilds.rst:4276,cache,cache,4276,interpreter/llvm-project/llvm/docs/AdvancedBuilds.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AdvancedBuilds.rst,1,['cache'],['cache']
Performance,"*. However, there; are certain functionalities that work with the assumption that the used; lengths are expressed in centimeters. This is the case for shape; capacity or volume weight computation. The same is valid when using the; ROOT geometry as navigator for an external transport MC package (e.g.; GEANT) via the VMC interface. Other units in use: All angles used for defining rotation matrices or; some shape parameters are expressed in **degrees**. Material density is; expressed in [**g/cm3**]. ### Primitive Shapes. #### Boxes - TGeoBBox Class. Normally a box has to be built only with 3 parameters: `DX,DY,DZ`; representing the half-lengths on X, Y and Z-axes. In this case, the; origin of the box will match the one of its reference frame and the box; will range from: `-DX` to `DX` on X-axis, from `-DY` to `DY` on Y and; from `-DZ` to `DZ` on Z. On the other hand, any other shape needs to; compute and store the parameters of their minimal bounding box. The; bounding boxes are essential to optimize navigation algorithms.; Therefore all other primitives derive from **`TGeoBBox`**. Since the; minimal bounding box is not necessary centered in the origin, any box; allows an origin translation `(Ox`,`Oy`,`Oz)`. All primitive; constructors automatically compute the bounding box parameters. Users; should be aware that building a translated box that will represent a; primitive shape by itself would affect any further positioning of other; shapes inside. Therefore it is highly recommendable to build; non-translated boxes as primitives and translate/rotate their; corresponding volumes only during positioning stage. ``` {.cpp}; TGeoBBox(Double_t dx,Double_t dy,Double_t dz,Double_t *origin=0);; ```. ![TGeoBBox class](pictures/060001B6.png). #### Parallelepiped - TGeoPara class. A parallelepiped is a shape having 3 pairs of parallel faces out of; which one is parallel with the XY plane (Z faces). All faces are; parallelograms in the general case. The Z faces have 2 edges parallel;",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md:26340,optimiz,optimize,26340,documentation/users-guide/Geometry.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md,1,['optimiz'],['optimize']
Performance,"*; ``b`` *or* both. This in turn implies that without the use of `The walker`_,; initially every ``MemoryDef`` clobbers every other ``MemoryDef``. ``MemoryPhi``\ s are ``PhiNode``\ s, but for memory operations. If at any; point we have two (or more) ``MemoryDef``\ s that could flow into a; ``BasicBlock``, the block's top ``MemoryAccess`` will be a; ``MemoryPhi``. As in LLVM IR, ``MemoryPhi``\ s don't correspond to any; concrete operation. As such, ``BasicBlock``\ s are mapped to ``MemoryPhi``\ s; inside ``MemorySSA``, whereas ``Instruction``\ s are mapped to ``MemoryUse``\ s; and ``MemoryDef``\ s. Note also that in SSA, Phi nodes merge must-reach definitions (that is,; definitions that *must* be new versions of variables). In MemorySSA, PHI nodes; merge may-reach definitions (that is, until disambiguated, the versions that; reach a phi node may or may not clobber a given variable). ``MemoryUse``\ s are operations which use but don't modify memory. An example of; a ``MemoryUse`` is a ``load``, or a ``readonly`` function call. Every function that exists has a special ``MemoryDef`` called ``liveOnEntry``.; It dominates every ``MemoryAccess`` in the function that ``MemorySSA`` is being; run on, and implies that we've hit the top of the function. It's the only; ``MemoryDef`` that maps to no ``Instruction`` in LLVM IR. Use of; ``liveOnEntry`` implies that the memory being used is either undefined or; defined before the function begins. An example of all of this overlaid on LLVM IR (obtained by running ``opt; -passes='print<memoryssa>' -disable-output`` on an ``.ll`` file) is below. When; viewing this example, it may be helpful to view it in terms of clobbers.; The operands of a given ``MemoryAccess`` are all (potential) clobbers of said; ``MemoryAccess``, and the value produced by a ``MemoryAccess`` can act as a clobber; for other ``MemoryAccess``\ es. If a ``MemoryAccess`` is a *clobber* of another, it means that these two; ``MemoryAccess``\ es may access the same memory.",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MemorySSA.rst:3717,load,load,3717,interpreter/llvm-project/llvm/docs/MemorySSA.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MemorySSA.rst,1,['load'],['load']
Performance,"*MI)``, and; ``DFAPacketizer::canReserveResources(MachineInstr *MI)``. These functions allow; a target packetizer to add an instruction to an existing packet and to check; whether an instruction can be added to a packet. See; ``llvm/CodeGen/DFAPacketizer.h`` for more information. Implementing a Native Assembler; ===============================. Though you're probably reading this because you want to write or maintain a; compiler backend, LLVM also fully supports building a native assembler.; We've tried hard to automate the generation of the assembler from the .td files; (in particular the instruction syntax and encodings), which means that a large; part of the manual and repetitive data entry can be factored and shared with the; compiler. Instruction Parsing; -------------------. .. note::. To Be Written. Instruction Alias Processing; ----------------------------. Once the instruction is parsed, it enters the MatchInstructionImpl function.; The MatchInstructionImpl function performs alias processing and then does actual; matching. Alias processing is the phase that canonicalizes different lexical forms of the; same instructions down to one representation. There are several different kinds; of alias that are possible to implement and they are listed below in the order; that they are processed (which is in order from simplest/weakest to most; complex/powerful). Generally you want to use the first alias mechanism that; meets the needs of your instruction, because it will allow a more concise; description. Mnemonic Aliases; ^^^^^^^^^^^^^^^^. The first phase of alias processing is simple instruction mnemonic remapping for; classes of instructions which are allowed with two different mnemonics. This; phase is a simple and unconditionally remapping from one input mnemonic to one; output mnemonic. It isn't possible for this form of alias to look at the; operands at all, so the remapping must apply for all forms of a given mnemonic.; Mnemonic aliases are defined simply, for ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:81575,perform,performs,81575,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst,1,['perform'],['performs']
Performance,"*none* 1. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - If OpenCL and; address space is; local, omit; vmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate. If; fence had an; address space then; set to address; space of OpenCL; fence flag, or to; generic if both; local and global; flags are; specified.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Must happen before; any following store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Ensures that all; memory operations; have; completed before; performing the; following; fence-paired-atomic. fence release - agent *none* 1. buffer_wbl2 sc1=1. - If OpenCL and; address space is; local, omit.; - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at agent scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - If OpenCL and; address space is; local, omit; vmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate. If; fence had an; address space then; set to address; space of OpenCL; fence flag, or to; generic if both; local and global; flags are; specified.; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/ge",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:313806,perform,performing,313806,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['perform'],['performing']
Performance,"*none* 1. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - If OpenCL and; address space is; local, omit; vmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate. If; fence had an; address space then; set to address; space of OpenCL; fence flag, or to; generic if both; local and global; flags are; specified.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Must happen before; any following store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Ensures that all; memory operations; have; completed before; performing the; following; fence-paired-atomic. fence release - agent *none* 1. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - If OpenCL and; address space is; local, omit; vmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate. If; fence had an; address space then; set to address; space of OpenCL; fence flag, or to; generic if both; local and global; flags are; specified.; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; any following store",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:263467,perform,performing,263467,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['perform'],['performing']
Performance,"*option="""");; ~~~. The drawing/animation time range is a global variable that can be; directly set:. ~~~{.cpp}; gGeoManager->SetTminTmax(tmin, tmax);; // without arguments resets the time range to the maximum value; ~~~. Once set, the time range will be active both for individual or global; track drawing. For animation, this range is divided to the desired; number of frames and will be automatically updated at each frame in; order to get the animation effect. The option provided to all track-drawing methods can trigger different; track selections:. `default: `A track (or all primary tracks) drawn without daughters. `/D:` Track and first level descendents only are drawn. `/*: ` Track and all descendents are drawn. `/Ntype:` All tracks having `name=type` are drawn. Generally several options can be concatenated in the same string (E.g.; `""/D /Npion-""`). For animating tracks, additional options can be added:. `/G:`Geometry animate. Generally when drawing or animating tracks, one; has to first perform a normal drawing of the geometry as convenient. The; tracks will be drawn over the geometry. The geometry itself will be; animated (camera moving and rotating in order to ""catch"" the majority of; current track segments.). `/S:`Save all frames in gif format in the current folder. This option; allows creating a movie based on individual frames. \anchor GP03; ## Checking the Geometry. Several checking methods are accessible from the context menu of volume; objects or of the manager class. They generally apply only to the; visible parts of the drawn geometry in order to ease geometry checking,; and their implementation is in the TGeoChecker class. The checking; package contains an overlap checker and several utility methods that; generally have visualization outputs. \anchor GP03a; ### The Overlap Checker. An overlap is any region in the Euclidian space being contained by more; than one positioned volume. Due to the containment scheme used by the; modeller, all points inside a ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:89427,perform,perform,89427,geom/geom/doc/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md,1,['perform'],['perform']
Performance,"+ A - P; ``R_AMDGPU_GOTPCREL32_LO`` Static 8 ``word32`` (G + GOT + A - P) & 0xFFFFFFFF; ``R_AMDGPU_GOTPCREL32_HI`` Static 9 ``word32`` (G + GOT + A - P) >> 32; ``R_AMDGPU_REL32_LO`` Static 10 ``word32`` (S + A - P) & 0xFFFFFFFF; ``R_AMDGPU_REL32_HI`` Static 11 ``word32`` (S + A - P) >> 32; *reserved* 12; ``R_AMDGPU_RELATIVE64`` Dynamic 13 ``word64`` B + A; ``R_AMDGPU_REL16`` Static 14 ``word16`` ((S + A - P) - 4) / 4; ========================== ======= ===== ========== ==============================. ``R_AMDGPU_ABS32_LO`` and ``R_AMDGPU_ABS32_HI`` are only supported by; the ``mesa3d`` OS, which does not support ``R_AMDGPU_ABS64``. There is no current OS loader support for 32-bit programs and so; ``R_AMDGPU_ABS32`` is not used. .. _amdgpu-loaded-code-object-path-uniform-resource-identifier:. Loaded Code Object Path Uniform Resource Identifier (URI); ---------------------------------------------------------. The AMD GPU code object loader represents the path of the ELF shared object from; which the code object was loaded as a textual Uniform Resource Identifier (URI).; Note that the code object is the in memory loaded relocated form of the ELF; shared object. Multiple code objects may be loaded at different memory; addresses in the same process from the same ELF shared object. The loaded code object path URI syntax is defined by the following BNF syntax:. .. code::. code_object_uri ::== file_uri | memory_uri; file_uri ::== ""file://"" file_path [ range_specifier ]; memory_uri ::== ""memory://"" process_id range_specifier; range_specifier ::== [ ""#"" | ""?"" ] ""offset="" number ""&"" ""size="" number; file_path ::== URI_ENCODED_OS_FILE_PATH; process_id ::== DECIMAL_NUMBER; number ::== HEX_NUMBER | DECIMAL_NUMBER | OCTAL_NUMBER. **number**; Is a C integral literal where hexadecimal values are prefixed by ""0x"" or ""0X"",; and octal values by ""0"". **file_path**; Is the file's path specified as a URI encoded UTF-8 string. In URI encoding,; every character that is not in the regular expre",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:82856,load,loader,82856,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],"['loaded', 'loader']"
Performance,"++++++. For GFX10-GFX11:. * Each agent has multiple shader arrays (SA).; * Each SA has multiple work-group processors (WGP).; * Each WGP has multiple compute units (CU).; * Each CU has multiple SIMDs that execute wavefronts.; * The wavefronts for a single work-group are executed in the same; WGP. In CU wavefront execution mode the wavefronts may be executed by; different SIMDs in the same CU. In WGP wavefront execution mode the; wavefronts may be executed by different SIMDs in different CUs in the same; WGP.; * Each WGP has a single LDS memory shared by the wavefronts of the work-groups; executing on it.; * All LDS operations of a WGP are performed as wavefront wide operations in a; global order and involve no caching. Completion is reported to a wavefront in; execution order.; * The LDS memory has multiple request queues shared by the SIMDs of a; WGP. Therefore, the LDS operations performed by different wavefronts of a; work-group can be reordered relative to each other, which can result in; reordering the visibility of vector memory operations with respect to LDS; operations of other wavefronts in the same work-group. A ``s_waitcnt; lgkmcnt(0)`` is required to ensure synchronization between LDS operations and; vector memory operations between wavefronts of a work-group, but not between; operations performed by the same wavefront.; * The vector memory operations are performed as wavefront wide operations.; Completion of load/store/sample operations are reported to a wavefront in; execution order of other load/store/sample operations performed by that; wavefront.; * The vector memory operations access a vector L0 cache. There is a single L0; cache per CU. Each SIMD of a CU accesses the same L0 cache. Therefore, no; special action is required for coherence between the lanes of a single; wavefront. However, a ``buffer_gl0_inv`` is required for coherence between; wavefronts executing in the same work-group as they may be executing on SIMDs; of different CUs that access ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:336049,perform,performed,336049,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['perform'],['performed']
Performance,"++; DEFINE_FLAG(std::string, example_flag, """", ""A sample flag."");. void Example() {; bool x = GetFlag(FLAGS_example_flag).empty();; f();; if (x) {; g();; } else {; h();; }; }; ```. The tool would simplify the code to:. ```c++; void Example() {; f();; g();; }; ```. We can solve this problem with a classic constant propagation lattice combined; with symbolic evaluation. ## Example: finding inefficient usages of associative containers. Real-world code often accidentally performs repeated lookups in associative; containers:. ```c++; map<int, Employee> xs;; xs[42]->name = ""..."";; xs[42]->title = ""..."";; ```. To find the above inefficiency we can use the available expressions analysis to; understand that `m[42]` is evaluated twice. ```c++; map<int, Employee> xs;; Employee &e = xs[42];; e->name = ""..."";; e->title = ""..."";; ```. We can also track the `m.contains()` check in the flow condition to find; redundant checks, like in the example below. ```c++; std::map<int, Employee> xs;; if (!xs.contains(42)) {; xs.insert({42, someEmployee});; }; ```. ## Example: refactoring types that implicitly convert to each other. Refactoring one strong type to another is difficult, but the compiler can help:; once you refactor one reference to the type, the compiler will flag other places; where this information flows with type mismatch errors. Unfortunately this; strategy does not work when you are refactoring types that implicitly convert to; each other, for example, replacing `int32_t` with `int64_t`. Imagine that we want to change user IDs from 32 to 64-bit integers. In other; words, we need to find all integers tainted with user IDs. We can use data flow; analysis to implement taint analysis. ```c++; void UseUser(int32_t user_id) {; int32_t id = user_id;; // Variable `id` is tainted with a user ID.; ...; }; ```. Taint analysis is very well suited to this problem because the program rarely; branches on user IDs, and almost certainly does not perform any computation; (like arithmetic).; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md:30341,perform,perform,30341,interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md,1,['perform'],['perform']
Performance,"+-----------------------------------------------+; | reserved | ``3`` | Unused. |; +---------------+--------------+-----------------------------------------------+. EndOfBuffer Records; -------------------. An EndOfBuffer record type indicates that there is no more trace data in this; buffer. The reader is expected to seek past the remaining buffer_size expressed; before the start of buffer and look for either another header or EOF. Format Grammar and Invariants; =============================. Not all sequences of Metadata records and Function records are valid data. A; sequence should be parsed as a state machine. The expectations for a valid; format can be expressed as a context free grammar. This is an attempt to explain the format with statements in EBNF format. - Format := Header ThreadBuffer* EOF. - ThreadBuffer := NewBuffer WallClockTime NewCPUId BodySequence* End. - BodySequence := NewCPUId | TSCWrap | Function | CustomEvent. - Function := (Function_Entry_Args CallArgument*) | Function_Other_Type. - CustomEvent := CustomEventMarker CustomEventUnstructuredMemory. - End := EndOfBuffer RemainingBufferSizeToSkip. Function Record Order; ---------------------. There are a few clarifications that may help understand what is expected of; Function records. - Functions with an Exit are expected to have a corresponding Entry or; Entry_Args function record precede them in the trace. - Tail_Exit Function records record the Function ID of the function whose return; address the program counter will take. In other words, the final function that; would be popped off of the call stack if tail call optimization was not used. - Not all functions marked for instrumentation are necessarily in the trace. The; tracer uses heuristics to preserve the trace for non-trivial functions. - Not every entry must have a traced Exit or Tail Exit. The buffer may run out; of space or the program may request for the tracer to finalize toreturn the; buffer before an instrumented function exits.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRayFDRFormat.rst:16653,optimiz,optimization,16653,interpreter/llvm-project/llvm/docs/XRayFDRFormat.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRayFDRFormat.rst,1,['optimiz'],['optimization']
Performance,"+i) {; if (c1) {; // When reaching this block, we will have exited the loop.; do_something();; break;; }; if (c2) {; // abort(), never returns, so we have exited the loop.; abort();; }; if (c3) {; // The unreachable allows the compiler to assume that this will not rejoin the loop.; do_something();; __builtin_unreachable();; }; if (c4) {; // This statically infinite loop is not nested because control-flow will not continue with the for-loop.; while(true) {; do_something();; }; }; }. * There is no requirement for the control flow to eventually leave the; loop, i.e. a loop can be infinite. A **statically infinite loop** is a; loop that has no exiting edges. A **dynamically infinite loop** has; exiting edges, but it is possible to be never taken. This may happen; only under some circumstances, such as when n == UINT_MAX in the code; below. .. code-block:: C. for (unsigned i = 0; i <= n; ++i); body(i);. It is possible for the optimizer to turn a dynamically infinite loop; into a statically infinite loop, for instance when it can prove that the; exiting condition is always false. Because the exiting edge is never; taken, the optimizer can change the conditional branch into an; unconditional one. If a is loop is annotated with; :ref:`llvm.loop.mustprogress <langref_llvm_loop_mustprogress>` metadata,; the compiler is allowed to assume that it will eventually terminate, even; if it cannot prove it. For instance, it may remove a mustprogress-loop; that does not have any side-effect in its body even though the program; could be stuck in that loop forever. Languages such as C and; `C++ <https://eel.is/c++draft/intro.progress#1>`_ have such; forward-progress guarantees for some loops. Also see the; :ref:`mustprogress <langref_mustprogress>` and; :ref:`willreturn <langref_willreturn>` function attributes, as well as; the older :ref:`llvm.sideeffect <llvm_sideeffect>` intrinsic. * The number of executions of the loop header before leaving the loop is; the **loop trip count** (or **",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LoopTerminology.rst:7160,optimiz,optimizer,7160,interpreter/llvm-project/llvm/docs/LoopTerminology.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LoopTerminology.rst,1,['optimiz'],['optimizer']
Performance,", ""i386"", {3}, object; 5: bind-arch, ""x86_64"", {3}, object; 6: lipo, {4, 5}, object; 7: input, ""t1.c"", c; 8: preprocessor, {7}, cpp-output; 9: compiler, {8}, assembler; 10: assembler, {9}, object; 11: bind-arch, ""i386"", {10}, object; 12: bind-arch, ""x86_64"", {10}, object; 13: lipo, {11, 12}, object. After this stage is complete the compilation process is divided into; a simple set of actions which need to be performed to produce; intermediate or final outputs (in some cases, like ``-fsyntax-only``,; there is no ""real"" final output). Phases are well known compilation; steps, such as ""preprocess"", ""compile"", ""assemble"", ""link"", etc. #. **Bind: Tool & Filename Selection**. This stage (in conjunction with the Translate stage) turns the tree; of Actions into a list of actual subprocess to run. Conceptually, the; driver performs a top down matching to assign Action(s) to Tools. The; ToolChain is responsible for selecting the tool to perform a; particular action; once selected the driver interacts with the tool; to see if it can match additional actions (for example, by having an; integrated preprocessor). Once Tools have been selected for all actions, the driver determines; how the tools should be connected (for example, using an inprocess; module, pipes, temporary files, or user provided filenames). If an; output file is required, the driver also computes the appropriate; file name (the suffix and file location depend on the input types and; options such as ``-save-temps``). The driver interacts with a ToolChain to perform the Tool bindings.; Each ToolChain contains information about all the tools needed for; compilation for a particular architecture, platform, and operating; system. A single driver invocation may query multiple ToolChains; during one compilation in order to interact with tools for separate; architectures. The results of this stage are not computed directly, but the driver; can print the results via the ``-ccc-print-bindings`` option. For; example:. .. c",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DriverInternals.rst:8787,perform,perform,8787,interpreter/llvm-project/clang/docs/DriverInternals.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DriverInternals.rst,1,['perform'],['perform']
Performance,", 4B items (list frame) | Frame preamble encoding |; | Maximum field / type version | 4B | Field meta-data encoding |; | Maximum number of fields, columns | 4B (foreseen: <10M) | 32bit column / field IDs, list frame limit |; | Maximum number of cluster groups | 4B (foreseen: <10k) | List frame limits |; | Maximum number of clusters per group | 4B (foreseen: <10k) | List frame limits, cluster group summary encoding |; | Maximum number of pages per cluster per column | 4B | List frame limits |; | Maximum number of entries per cluster | 2^56 | Cluster summary encoding |; | Maximum string length (meta-data) | 4GB | String encoding |; | Maximum RBlob size | 128 PiB | 1GiB / 8B * 1GiB (with maxKeySize=1GiB, offsetSize=8B) |. ## Glossary. ### Anchor. The anchor is a data block that represents the entry point to an RNTuple.; The anchor is specific to the RNTuple container in which the RNTuple data are embedded (e.g., a ROOT file or an object store).; The anchor must provide the information to load the header and the footer **envelopes**. ### Cluster. A cluster is a set of **pages** that contain all the data belonging to an entry range.; The data set is partitioned in clusters.; A typical cluster size is tens to hundreds of megabytes. ### Column. A column is a storage backed vector of a number of **elements** of a simple type.; Column elements have a fixed bit-length that depends on the column type.; Some column types allow setting the bit lengths within specific limits (e.g. for floats with truncated mantissa). ### Envelope. An envelope is a data block with RNTuple meta-data, such as the header and the footer. ### Field. A field describes a serialized C++ type.; A field can have a hierarchy of subfields representing a composed C++ type (e.g., a vector of integers).; A field has zero, one, or multiple **columns** attached to it.; The columns contain the data related to the field but not to its subfields, which have their own columns. ### Frame. A frame is a byte range with m",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/BinaryFormatSpecification.md:50206,load,load,50206,tree/ntuple/v7/doc/BinaryFormatSpecification.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/BinaryFormatSpecification.md,1,['load'],['load']
Performance,", Arg1 is a compile-time constant.; // These callbacks are emitted by -fsanitize-coverage=trace-cmp since 2017-08-11; void __sanitizer_cov_trace_const_cmp1(uint8_t Arg1, uint8_t Arg2);; void __sanitizer_cov_trace_const_cmp2(uint16_t Arg1, uint16_t Arg2);; void __sanitizer_cov_trace_const_cmp4(uint32_t Arg1, uint32_t Arg2);; void __sanitizer_cov_trace_const_cmp8(uint64_t Arg1, uint64_t Arg2);. // Called before a switch statement.; // Val is the switch operand.; // Cases[0] is the number of case constants.; // Cases[1] is the size of Val in bits.; // Cases[2:] are the case constants.; void __sanitizer_cov_trace_switch(uint64_t Val, uint64_t *Cases);. // Called before a division statement.; // Val is the second argument of division.; void __sanitizer_cov_trace_div4(uint32_t Val);; void __sanitizer_cov_trace_div8(uint64_t Val);. // Called before a GetElemementPtr (GEP) instruction; // for every non-constant array index.; void __sanitizer_cov_trace_gep(uintptr_t Idx);. // Called before a load of appropriate size. Addr is the address of the load.; void __sanitizer_cov_load1(uint8_t *addr);; void __sanitizer_cov_load2(uint16_t *addr);; void __sanitizer_cov_load4(uint32_t *addr);; void __sanitizer_cov_load8(uint64_t *addr);; void __sanitizer_cov_load16(__int128 *addr);; // Called before a store of appropriate size. Addr is the address of the store.; void __sanitizer_cov_store1(uint8_t *addr);; void __sanitizer_cov_store2(uint16_t *addr);; void __sanitizer_cov_store4(uint32_t *addr);; void __sanitizer_cov_store8(uint64_t *addr);; void __sanitizer_cov_store16(__int128 *addr);. Tracing control flow; ====================. With ``-fsanitize-coverage=control-flow`` the compiler will create a table to collect; control flow for each function. More specifically, for each basic block in the function,; two lists are populated. One list for successors of the basic block and another list for; non-intrinsic called functions. **TODO:** in the current implementation, indirect calls are not ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/SanitizerCoverage.rst:11177,load,load,11177,interpreter/llvm-project/clang/docs/SanitizerCoverage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/SanitizerCoverage.rst,1,['load'],['load']
Performance,", IIC_LdStLFD,; [(set f64:$XT, (load xoaddr:$src))]>;. . (set f64:$XT, (load iaddrX4:$src)); (set f64:$XT, (store iaddrX4:$dst)). - Load/Store SP, with conversion from/to DP: lxssp stxssp; . Similar to lxsspx/stxsspx:; def LXSSPX : XX1Form<31, 524, (outs vssrc:$XT), (ins memrr:$src),; ""lxsspx $XT, $src"", IIC_LdStLFD,; [(set f32:$XT, (load xoaddr:$src))]>;. . (set f32:$XT, (load iaddrX4:$src)); (set f32:$XT, (store iaddrX4:$dst)). - Load as Integer Byte/Halfword & Zero Indexed: lxsibzx lxsihzx; . Similar to lxsiwzx:; def LXSIWZX : XX1Form<31, 12, (outs vsfrc:$XT), (ins memrr:$src),; ""lxsiwzx $XT, $src"", IIC_LdStLFD,; [(set f64:$XT, (PPClfiwzx xoaddr:$src))]>;. . (set f64:$XT, (PPClfiwzx xoaddr:$src)). - Store as Integer Byte/Halfword Indexed: stxsibx stxsihx; . Similar to stxsiwx:; def STXSIWX : XX1Form<31, 140, (outs), (ins vsfrc:$XT, memrr:$dst),; ""stxsiwx $XT, $dst"", IIC_LdStSTFD,; [(PPCstfiwx f64:$XT, xoaddr:$dst)]>;. . (PPCstfiwx f64:$XT, xoaddr:$dst). - Load Vector Halfword*8/Byte*16 Indexed: lxvh8x lxvb16x; . Similar to lxvd2x/lxvw4x:; def LXVD2X : XX1Form<31, 844,; (outs vsrc:$XT), (ins memrr:$src),; ""lxvd2x $XT, $src"", IIC_LdStLFD,; [(set v2f64:$XT, (int_ppc_vsx_lxvd2x xoaddr:$src))]>;. . (set v8i16:$XT, (int_ppc_vsx_lxvh8x xoaddr:$src)); (set v16i8:$XT, (int_ppc_vsx_lxvb16x xoaddr:$src)). - Store Vector Halfword*8/Byte*16 Indexed: stxvh8x stxvb16x; . Similar to stxvd2x/stxvw4x:; def STXVD2X : XX1Form<31, 972,; (outs), (ins vsrc:$XT, memrr:$dst),; ""stxvd2x $XT, $dst"", IIC_LdStSTFD,; [(store v2f64:$XT, xoaddr:$dst)]>;. . (store v8i16:$XT, xoaddr:$dst); (store v16i8:$XT, xoaddr:$dst). - Load/Store Vector (Left-justified) with Length: lxvl lxvll stxvl stxvll; . Likely needs an intrinsic; . (set v?:$XT, (int_ppc_vsx_lxvl xoaddr:$src)); (set v?:$XT, (int_ppc_vsx_lxvll xoaddr:$src)). . (int_ppc_vsx_stxvl xoaddr:$dst)); (int_ppc_vsx_stxvll xoaddr:$dst)). - Load Vector Word & Splat Indexed: lxvwsx; . Likely needs an intrinsic; . (set v?:$XT, (int_ppc_vsx_lxvwsx xoad",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/README_P9.txt:18786,Load,Load,18786,interpreter/llvm-project/llvm/lib/Target/PowerPC/README_P9.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/README_P9.txt,1,['Load'],['Load']
Performance,", ROOT objects can be send with POST request and used as arguments of; objects method execution in exe.bin and exe.json requests. Request and response HTTP headers are now directly accessible in THttpCallArg class. When command is registered with THttpServer::RegisterCommand() method,; one could configure additional arguments which should be submitted when; command is executed with cmd.json requests. Introduce restriction rules for objects access with THttpServer::Restrict() method.; Up to now general read-only flag was applied - either; everything read-only or everything is fully accessible.; Now one could restrict access to different parts of; objects hierarchy or even fully 'hide' them from the client.; Restriction based on user account name, which is applied; when htdigest authentication is configured.; One also able to allow execution of selected methods. Implement multi.bin and multi.json requests.; One could request many items with single HTTP request.; Let optimize communication between server and client. With *SNIFF* tag in ClassDef() comments one could expose different properties,; which than exposed by the TRootSniffer to the client with h.json requests.; Such possibility ease implementation of client-side code for custom classes. Allow to bind http port with loopback address.; This restrict access to http server only from localhost.; One could either specify 'loopback' option in constructor:; new THttpServer(""http:8080?loopback""); or in clear text specify IP address to which http socket should be bind:; new THttpServer(""http:127.0.0.1:8080""); If host has several network interfaces, one could select one for binding:; new THttpServer(""http:192.168.1.17:8080""). ### TNetXNGFileStager; Fixed ROOT-7703. This restores the behavior of Locate() to that found with; TXNetFileStager: Rather than return only the xrootd server's reply, the endpoint; hostname is looked up and Locate() returns the full url, including the path. ### TWebFile; Fixed ROOT-7809. Returns an er",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md:19729,optimiz,optimize,19729,README/ReleaseNotes/v606/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md,1,['optimiz'],['optimize']
Performance,", Selu, Sigmoid, Softmax, Tanh, LeakyRelu; - BatchNormalization; - MaxPool, AveragePool, GlobalAverage; - ConvTranspose; - Gather; - Expand, Reduce; - Neg, Exp, Sqrt, Reciprocal; - Add, Sum, Mul, Div; - Reshape, Flatten, Transpose; - Squeeze, Unsqueeze, Slice; - Concat, Reduce; - Identity; - Shape; - Custom; - Error; - Log. #### SOFIE Keras Parser; - The Swish Activation function is now supported in the SOFIE Keras parser. ## 2D Graphics Libraries. - Introduce `TAxis::ChangeLabelByValue` to set custom label defined by axis value. It works also; when axis zooming changes and position and index of correspondent axis label changes as well.; `TAxis::ChangeLabel` method to change axis label by index works as before. - Introduce `TCanvas::SaveAll` method. Allows to store several pads at once into different image file formats.; File name can include printf qualifier to code pad number. Also allows to store all pads in single PDF; or single ROOT file. Significantly improves performance when creating many image files using web graphics. - Introduce `TCanvas::UpdateAsync` method. In case of web-based canvas triggers update of the canvas on the client side,; but does not wait that real update is completed. Avoids blocking of caller thread.; Have to be used if called from other web-based widget to avoid logical dead-locks.; In case of normal canvas just canvas->Update() is performed. - The Delaunay triangles (used by TGraph2D) were computed by the external package `triangle.c`; included in the ROOT distribution. This package had several issues:; - It was not maintained anymore.; - Its license was not compatible with LGPL; This code is now replaced by the [CDT package](https://github.com/artem-ogre/CDT) which is; properly maintained and has a license (MLP) compatible with LGPL. It will appear in 6.03.02. ## Machine Learning integration. - ROOT now offers functionality to extract batches of events out of a dataset for use in common ML training workflows. For example, one can gene",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v630/index.md:19810,perform,performance,19810,README/ReleaseNotes/v630/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v630/index.md,1,['perform'],['performance']
Performance,", TEXT(""C:\\Program Files\\App -L -S""),; NULL, NULL, TRUE, 0, NULL, NULL, &si, π);; // warn; }. WinAPI.LoadLibrary; (C); The SearchPath() function is used to retrieve a path to a DLL for; a subsequent LoadLibrary() call.; Source: ; MSDN: LoadLibrary function, Security Remarks. #include <windows.h>. HINSTANCE test() {; char filePath[100];; SearchPath(NULL, ""file.dll"", NULL, 100, filePath, NULL);; return LoadLibrary(filePath); // warn; }. WinAPI.WideCharToMultiByte; (C); Buffer overrun while calling WideCharToMultiByte(). The size of; the input buffer equals the number of characters in the Unicode string, while; the size of the output buffer equals the number of bytes.; Source: ; MSDN: WideCharToMultiByte function. #include <windows.h>. void test() {; wchar_t ws[] = L""abc"";; char s[3];; WideCharToMultiByte(CP_UTF8, 0, ws, -1, s,; 3, NULL, NULL); // warn; }. optimization. Name, DescriptionExampleProgress. optimization.PassConstObjByValue; (C, C++); Optimization: It is more effective to pass constant parameter by reference to; avoid unnecessary object copying. struct A {};. void f(const struct A a); // warn. optimization.PostfixIncIter; (C++); Optimization: It is more effective to use prefix increment operator with; iterator.; Source: Scott Meyers ""More Effective C++"", item 6:; Distinguish between prefix and postfix forms of increment and decrement; operators. #include <vector>. void test() {; std::vector<int> v;; std::vector<int>::const_iterator it;; for(it = v.begin();; it != v.end(); it++) {}; // warn; }. optimization.MultipleCallsStrlen; (C); Optimization: multiple calls to strlen() for a string in an; expression. It is more effective to hold a value returned; from strlen() in a temporary variable. #include <string.h>. void test(const char* s) {; if (strlen(s) > 0 &&; strlen(s) < 7) {}; // warn; }. optimization.StrLengthCalculation; (C++); Optimization: it is more efficient to use string::length() to; calculate the length of an std::string. #include <string>; #includ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/potential_checkers.html:27308,Optimiz,Optimization,27308,interpreter/llvm-project/clang/www/analyzer/potential_checkers.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/potential_checkers.html,1,['Optimiz'],['Optimization']
Performance,", \; Oksana Shadura, UNL/CMS,\; Enric Tejedor Saavedra, CERN/SFT,\; Christian Tacke, GSI, \; Matevz Tadel, UCSD/CMS,\; Vassil Vassilev, Princeton/CMS,\; Wouter Verkerke, NIKHEF/Atlas,\; Stefan Wunsch, CERN/SFT,\; Anirudh Dagar, CERN-HSF/GSoC. ## Deprecation and Removal. - [`RooAbsReal::evaluateBatch()`](https://root.cern/doc/v624/classRooAbsReal.html#a261580dfe94f2b107f9b9a77cad78a62) has been removed in favour of the faster evaluateSpan(). See section ""RooFit Libraries"" for instructions on how to use [`RooAbsReal::evaluateSpan()`](https://root.cern/doc/v624/classRooAbsReal.html#a1e5129ffbc63bfd04c01511fd354b1b8).; - `TTreeProcessorMT::SetMaxTasksPerFilePerWorker` has been deprecated in favour of `TTreeProcessorMT::SetTasksPerWorkerHint`. ## Core Libraries. Due to internal changes required to comply with the deprecation of Intel TBB's `task_scheduler_init` and related; interfaces in recent TBB versions, as of v6.24 ROOT will not honor a maximum concurrency level set with; `tbb::task_scheduler_init` but will require instead the usage of `tbb::global_control`:. ```cpp; //tbb::task_scheduler_init init(2); // does not affect the number of threads ROOT will use anymore. tbb::global_control c(tbb::global_control::max_allowed_parallelism, 2);; ROOT::TThreadExecutor p1; // will use 2 threads; ROOT::TThreadExecutor p2(/*nThreads=*/8); // will still use 2 threads; ```. Note that the preferred way to steer ROOT's concurrency level is still through; [`ROOT::EnableImplicitMT`](https://root.cern/doc/master/namespaceROOT.html#a06f2b8b216b615e5abbc872c9feff40f); or by passing the appropriate parameter to executors' constructors, as in; [`TThreadExecutor::TThreadExecutor`](https://root.cern/doc/master/classROOT_1_1TThreadExecutor.html#ac7783d52c56cc7875d3954cf212247bb). See the discussion at [ROOT-11014](https://sft.its.cern.ch/jira/browse/ROOT-11014) for more context. ### Dynamic Path: `ROOT_LIBRARY_PATH`. A new way to set ROOT's ""Dynamic Path"" was added: the; environment variable `",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v624/index.md:1990,concurren,concurrency,1990,README/ReleaseNotes/v624/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v624/index.md,1,['concurren'],['concurrency']
Performance,", `Getp2f2funcname(void*)`, `Setgvp(Long_t)`, `SetRTLD_NOW()`, `SetRTLD_LAZY()`.; - `SetFCN(void*)` from TVirtualFitter, TFitter, TBackCompFitter, TMinuit; - `TFoam::SetRhoInt(void*)`. ### Core. - The enum constant `TRef::kNotComputed`, `TLink::kObjIsParent` were never used and have been removed.; - The enum constant `TClonesArray::kNoSplit` has not been used since v2.26 and has been removed. ## Interpreter. - Automatic declaration of variables (`h = new TH1F(...)`) is *only* available at the prompt. The side-effects of relying on this in source files is simply too grave. Due to a bug (ROOT-8538), automatically declared variables must currently reside on the top-most scope, i.e. not inside an `if` block etc.; - Improved the stack frame information generated by the JIT. By avoiding interleaving of the memory associated to multiple JIT module, the generation of stack trace involving jitted code and the catching of exception going through jitted code has been repaired.; - Interpreted code is now optimized; `.O 0/1/2/3` can be used to change the optimization level, as well as `#pragma cling optimize`.; - The prompt colors are now much more visible, both on terminals with light and dark background.; - Significant speedup of `TMethodCall`.; - One can now run `.x 12file-with@funny=name.C`; it will expect a function called `_12file_with_funny_name()`. ## Core Libraries. - See ""Build, Configuration and Testing Infrastructure"" below for changes in the directory structure.; - libCling now exports only a minimal set of symbols.; - Add support for std::array_view also for C++11 builds. The implementation has been modified to work before C++14.; - Added TCollection::Notify to allow notifying more than one object.; ```{.cpp}; TList formulas;; // Add several TTreeFormula to the list;; chain.SetNotify(&formulas);; ```; - For classes that need the `ClassDef` support, `ClassDefInline(ClassName, Version)` now provides it without the need for a dictionary source: all members injected by ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md:1909,optimiz,optimized,1909,README/ReleaseNotes/v610/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md,1,['optimiz'],['optimized']
Performance,", and; each result may be what an analysis wants (IE; TBAA may say no-alias, and something else may say must-alias), it is; not possible to partition the memory the way every optimization wants.; Second, some alias analysis results are not transitive (IE A noalias B,; and B noalias C, does not mean A noalias C), so it is not possible to; come up with a precise partitioning in all cases without variables to; represent every pair of possible aliases. Thus, partitioning; precisely may require introducing at least N^2 new virtual variables,; phi nodes, etc. Each of these variables may be clobbered at multiple def sites. To give an example, if you were to split up struct fields into; individual variables, all aliasing operations that may-def multiple struct; fields, will may-def more than one of them. This is pretty common (calls,; copies, field stores, etc). Experience with SSA forms for memory in other compilers has shown that; it is simply not possible to do this precisely, and in fact, doing it; precisely is not worth it, because now all the optimizations have to; walk tons and tons of virtual variables and phi nodes. So we partition. At the point at which you partition, again,; experience has shown us there is no point in partitioning to more than; one variable. It simply generates more IR, and optimizations still; have to query something to disambiguate further anyway. As a result, LLVM partitions to one variable. Precision in practice; ^^^^^^^^^^^^^^^^^^^^^. In practice, there are implementation details in LLVM that also affect the; results' precision provided by ``MemorySSA``. For example, AliasAnalysis has various; caps, or restrictions on looking through phis which can affect what ``MemorySSA``; can infer. Changes made by different passes may make MemorySSA either ""overly; optimized"" (it can provide a more accurate result than if it were recomputed; from scratch), or ""under optimized"" (it could infer more if it were recomputed).; This can lead to challenges to ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MemorySSA.rst:18073,optimiz,optimizations,18073,interpreter/llvm-project/llvm/docs/MemorySSA.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MemorySSA.rst,1,['optimiz'],['optimizations']
Performance,", has been; developed for this case: it basically contains a list of standard; packetizers (one for each dataset) and loops over them (syntax:; ""dataset1,dataset2,..."" or dataset1 dataset2 ..."").; In; both cases, entry-list can be applied using the syntax; ""dataset<<entrylist"", e.g.; ""dataset1<<el1|dataset2<<el2|"".; The datasets to be processed can also be specified on one or multiple lines in a text file.; Add; support for automatic download of a package when available on the; master but not locally. The downloaded packages are store under <sandbox>/packages/downloaded; and automatically checked for updates against the master repository. If; a local version of the same package is created (using the; UploadPackage) the entry in downloaded is; cleared, so that the behaviour is unchanged.; Add; the possibility to remap the server for the files in a dataset. This; allows, for example, to reuse the dataset information for the same; files stored in a different cluster.; Add a local cache for; TDataSetManagerFile. This is mainly used to improve the speed of; TDataSetManager::ShowDataSets, which is run very often by users and may; be very slow if the number of dataset is large. The cache is also used; to cache frequently received dataset objects.Add the possibility to audit the activity on the nodes via syslog. .; New packetizer TPacketizerFile generating packets which contain a single; file path to be used in processing single files. Used, for example, in; tasks generating files. The files are specified into a TMap - named; 'PROOF_FilesToProcess' - containing the list of files to be generated; per host (the key is the host name, the value the TList of TObjString; (or TFileInfo) with the files names - or a TFileCollection: the output; of TFileCollection::GetFilesPerServer() can be directly passed as files; map). Workers are first assigned files belonging to; the list with host name matching the worker name. The map is; distributed to the master via the input list.Add suppor",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html:1491,cache,cache,1491,proof/doc/v528/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html,2,['cache'],['cache']
Performance,", i32 0, i8 addrspace(1)* %obj); %obj.relocated = call coldcc i8 addrspace(1)* @llvm.experimental.gc.relocate.p1i8(token %0, i32 7, i32 7); ret i8 addrspace(1)* %obj.relocated; }. During lowering, this will result in an instruction selection DAG that looks; something like:. ::. CALLSEQ_START; ...; GC_TRANSITION_START (lowered i32 *@Flag), SRCVALUE i32* Flag; STATEPOINT; GC_TRANSITION_END (lowered i32 *@Flag), SRCVALUE i32 *Flag; ...; CALLSEQ_END. In order to generate the necessary transition code, the backend for each target; supported by ""hypothetical-gc"" must be modified to lower ``GC_TRANSITION_START``; and ``GC_TRANSITION_END`` nodes appropriately when the ""hypothetical-gc""; strategy is in use for a particular function. Assuming that such lowering has; been added for X86, the generated assembly would be:. .. code-block:: gas. 	 .globl	test1; 	 .align	16, 0x90; 	 pushq	%rax; 	 movl $1, %fs:Flag@TPOFF; 	 callq	foo; 	 movl $0, %fs:Flag@TPOFF; .Ltmp1:; 	 movq	(%rsp), %rax # This load is redundant (oops!); 	 popq	%rdx; 	 retq. Note that the design as presented above is not fully implemented: in particular,; strategy-specific lowering is not present, and all GC transitions are emitted as; as single no-op before and after the call instruction. These no-ops are often; removed by the backend during dead machine instruction elimination. Before the abstract machine model is lowered to the explicit statepoint model; of relocations by the :ref:`RewriteStatepointsForGC` pass it is possible for; any derived pointer to get its base pointer and offset from the base pointer; by using the ``gc.get.pointer.base`` and the ``gc.get.pointer.offset``; intrinsics respectively. These intrinsics are inlined by the; :ref:`RewriteStatepointsForGC` pass and must not be used after this pass. .. _statepoint-stackmap-format:. Stack Map Format; ================. Locations for each pointer value which may need read and/or updated by; the runtime or collector are provided in a separate section of ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:19133,load,load,19133,interpreter/llvm-project/llvm/docs/Statepoints.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst,1,['load'],['load']
Performance,", i32 <vector_length>); declare <vscale x 4 x float> @llvm.vp.maxnum.nxv4f32 (<vscale x 4 x float> <left_op>, <vscale x 4 x float> <right_op>, <vscale x 4 x i1> <mask>, i32 <vector_length>); declare <256 x double> @llvm.vp.maxnum.v256f64 (<256 x double> <left_op>, <256 x double> <right_op>, <256 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated floating-point IEEE-754 maxNum of two vectors of floating-point values. Arguments:; """""""""""""""""""". The first two operands and the result have the same vector of floating-point type. The; third operand is the vector mask and has the same number of elements as the; result vector type. The fourth operand is the explicit vector length of the; operation. Semantics:; """""""""""""""""""". The '``llvm.vp.maxnum``' intrinsic performs floating-point maximum (:ref:`maxnum <i_maxnum>`); of the first and second vector operand on each enabled lane. The result on; disabled lanes is a :ref:`poison value <poisonvalues>`. The operation is; performed in the default floating-point environment. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call <4 x float> @llvm.vp.maxnum.v4f32(<4 x float> %a, <4 x float> %b, <4 x i1> %mask, i32 %evl); ;; For all lanes below %evl, %r is lane-wise equivalent to %also.r. %t = call <4 x float> @llvm.maxnum.v4f32(<4 x float> %a, <4 x float> %b, <4 x i1> %mask, i32 %evl); %also.r = select <4 x i1> %mask, <4 x float> %t, <4 x float> poison. .. _int_vp_minimum:. '``llvm.vp.minimum.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare <16 x float> @llvm.vp.minimum.v16f32 (<16 x float> <left_op>, <16 x float> <right_op>, <16 x i1> <mask>, i32 <vector_length>); declare <vscale x 4 x float> @llvm.vp.minimum.nxv4f32 (<vscale x 4 x float> <left_op>, <vscale x 4 x float> <right_op>, <vscale x 4 x i1> <mask>, i32 <vector_length>); declare <256 x double> @llvm.vp.minimum.v256f64 (<256 x double> <left_op>, <256 x double> <right_op>, <256 x i1> <mask>, i32 <ve",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:728123,perform,performed,728123,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['performed']
Performance,", i32 <vector_length>); declare <vscale x 4 x float> @llvm.vp.minnum.nxv4f32 (<vscale x 4 x float> <left_op>, <vscale x 4 x float> <right_op>, <vscale x 4 x i1> <mask>, i32 <vector_length>); declare <256 x double> @llvm.vp.minnum.v256f64 (<256 x double> <left_op>, <256 x double> <right_op>, <256 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated floating-point IEEE-754 minNum of two vectors of floating-point values. Arguments:; """""""""""""""""""". The first two operands and the result have the same vector of floating-point type. The; third operand is the vector mask and has the same number of elements as the; result vector type. The fourth operand is the explicit vector length of the; operation. Semantics:; """""""""""""""""""". The '``llvm.vp.minnum``' intrinsic performs floating-point minimum (:ref:`minnum <i_minnum>`); of the first and second vector operand on each enabled lane. The result on; disabled lanes is a :ref:`poison value <poisonvalues>`. The operation is; performed in the default floating-point environment. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call <4 x float> @llvm.vp.minnum.v4f32(<4 x float> %a, <4 x float> %b, <4 x i1> %mask, i32 %evl); ;; For all lanes below %evl, %r is lane-wise equivalent to %also.r. %t = call <4 x float> @llvm.minnum.v4f32(<4 x float> %a, <4 x float> %b); %also.r = select <4 x i1> %mask, <4 x float> %t, <4 x float> poison. .. _int_vp_maxnum:. '``llvm.vp.maxnum.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare <16 x float> @llvm.vp.maxnum.v16f32 (<16 x float> <left_op>, <16 x float> <right_op>, <16 x i1> <mask>, i32 <vector_length>); declare <vscale x 4 x float> @llvm.vp.maxnum.nxv4f32 (<vscale x 4 x float> <left_op>, <vscale x 4 x float> <right_op>, <vscale x 4 x i1> <mask>, i32 <vector_length>); declare <256 x double> @llvm.vp.maxnum.v256f64 (<256 x double> <left_op>, <256 x double> <right_op>, <256 x i1> <mask>, i32 <vector_length>). Overview:; """"""""""",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:726471,perform,performed,726471,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['performed']
Performance,", location of JSROOT modules should be specified; as `/jsrootsys/modules/main.mjs`. And then trying to access files from local disk, one should specify `/currentdir/` folder:. ```javascript; jQuery.sap.registerModulePath(""NavExample"", ""/currentdir/"");; ```. JSROOT provides [example](https://root.cern/js/latest/demo/openui5/) showing usage of JSROOT drawing in the OpenUI5,; [source code](https://github.com/root-project/jsroot/tree/master/demo/openui5) can be found in repository. ### Migration v6 -> v7. * Core functionality should be imported from `main.mjs` module like:. ```javascript; import { create, parse, createHistogram, redraw } from 'https://root.cern/js/7.0.0/modules/main.mjs';; ```. * It is still possible to use `JSRoot.core.js` script, which provides very similar (but not identical!) functionality as with `v6` via global `JSROOT` object. * `JSROOT.define()` and `JSROOT.require()` functions only available after `JSRoot.core.js` loading. * Support of `require.js` and `openui5` loaders was removed. * Global hierarchy painter `JSROOT.hpainter` no longer existing, one can use `getHPainter` function:. ```javascript; import { getHPainter } from 'https://root.cern/js/7.0.0/modules/main.mjs';; let hpainter = getHPainter();; ```. * All math functions previously available via `JSROOT.Math` should be imported from `base/math.mjs` module:. ```javascript; import * as math from 'https://root.cern/js/7.0.0/modules/base/math.mjs';; ```. * Indication of batch mode `JSROOT.batch_mode` should be accessed via functions:. ```javascript; import { isBatchMode, setBatchMode } from 'https://root.cern/js/7.0.0/modules/main.mjs';; let was_batch = isBatchMode();; if (!was_batch) setBatchMode(true);; ```. * `JSROOT.extend()` function was removed, use `Object.assign()` instead. ### Migration v5 -> v6. * Main script was renamed to `JSRoot.core.js`. Old `JSRootCore.js` was deprecated and removed in v6.2. All URL parameters for main script ignored now, to load JSROOT functionality one shoul",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/JSROOT/JSROOT.md:47785,load,loaders,47785,documentation/JSROOT/JSROOT.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/JSROOT/JSROOT.md,1,['load'],['loaders']
Performance,", omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local; atomicrmw value; being acquired. atomicrmw acquire - agent - global 1. buffer/global_atomic; - system 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - agent - generic 1. flat_atomic; - system 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. fence acquire - singlethread *none* *none*; - wavefront; fence acquire - workgroup *none* 1. s_waitcnt lgkmcnt(0). - If OpenCL and; address space is; not generic, omit.; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate. If; fence had an; address space then; set to address; space of OpenCL; fence flag, or to; generic if both; local and global; flags are; specified.; - Must happen after; any preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than the; value read by the; fence-paired-atomic. fence acquire - agent *none* 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0). - If OpenCL and; address space is; not generic, omit",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:216678,load,loads,216678,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['loads']
Performance,", so a TGeoVolumeAssembly does not need to have a; medium. Due to the self-containment of assemblies, they are very; practical to use when a container is hard to define due to possible; overlaps during positioning. For instance, it is very easy creating; honeycomb structures. A very useful example for creating and using; assemblies can be found at: assembly.C. Creation of an assembly is very easy: one has just to create a; TGeoVolumeAssembly object and position the components inside as; for any volume:. ~~~{.cpp}; TGeoVolume *vol = new TGeoVolumeAssembly(name);; vol->AddNode(vdaughter1, cpy1, matrix1);; vol->AddNode(vdaughter2, cpy2, matrix2);; ~~~. Note that components cannot be declared as ""overlapping"" and that a; component can be an assembly volume. For existing flat volume; structures, one can define assemblies to force a hierarchical structure; therefore optimizing the performance. Usage of assemblies does NOT imply; penalties in performance, but in some cases, it can be observed that it; is not as performing as bounding the structure in a container volume; with a simple shape. Choosing a normal container is therefore; recommended whenever possible. \image html geometry006.png ""Assemblies of volumes"" width=600px. \anchor GP01c; ### Geometrical Transformations. All geometrical transformations handled by the modeller are provided as; a built-in package. This was designed to minimize memory requirements; and optimize performance of point/vector master-to-local and; local-to-master computation. We need to have in mind that a; transformation in **`TGeo`** has two major use-cases. The first one is; for defining the placement of a volume with respect to its container; reference frame. This frame will be called 'master' and the frame of the; positioned volume - 'local'. If `T` is a transformation used for; positioning volume daughters, then: `MASTER = T * LOCAL`. Therefore `T `is used to perform a local to master conversion, while; `T-1` for a master to local conversi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:51002,perform,performance,51002,geom/geom/doc/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md,2,['perform'],"['performance', 'performing']"
Performance,", specify the minimum version supported by your; application. .. option:: --print-supported-cpus. Print out a list of supported processors for the given target (specified; through ``--target=<architecture>`` or :option:`-arch` ``<architecture>``). If no; target is specified, the system default target will be used. .. option:: -mcpu=?, -mtune=?. Acts as an alias for :option:`--print-supported-cpus`. .. option:: -mcpu=help, -mtune=help. Acts as an alias for :option:`--print-supported-cpus`. .. option:: -march=<cpu>. Specify that Clang should generate code for a specific processor family; member and later. For example, if you specify -march=i486, the compiler is; allowed to generate instructions that are valid on i486 and later processors,; but which may not exist on earlier ones. Code Generation Options; ~~~~~~~~~~~~~~~~~~~~~~~. .. option:: -O0, -O1, -O2, -O3, -Ofast, -Os, -Oz, -Og, -O, -O4. Specify which optimization level to use:. :option:`-O0` Means ""no optimization"": this level compiles the fastest and; generates the most debuggable code. :option:`-O1` Somewhere between :option:`-O0` and :option:`-O2`. :option:`-O2` Moderate level of optimization which enables most; optimizations. :option:`-O3` Like :option:`-O2`, except that it enables optimizations that; take longer to perform or that may generate larger code (in an attempt to; make the program run faster). :option:`-Ofast` Enables all the optimizations from :option:`-O3` along; with other aggressive optimizations that may violate strict compliance with; language standards. :option:`-Os` Like :option:`-O2` with extra optimizations to reduce code; size. :option:`-Oz` Like :option:`-Os` (and thus :option:`-O2`), but reduces code; size further. :option:`-Og` Like :option:`-O1`. In future versions, this option might; disable different optimizations in order to improve debuggability. :option:`-O` Equivalent to :option:`-O1`. :option:`-O4` and higher. Currently equivalent to :option:`-O3`. .. option:: -g, -gline-table",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/CommandGuide/clang.rst:10534,optimiz,optimization,10534,interpreter/llvm-project/clang/docs/CommandGuide/clang.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/CommandGuide/clang.rst,1,['optimiz'],['optimization']
Performance,", the implementation of ``pragma optimize`` behaves; the same as ``#pragma clang optimize``. All functions; between ``off`` and ``on`` will be decorated with the ``optnone`` attribute. .. code-block:: c++. #pragma optimize("""", off); // This function will be decorated with optnone.; void f1() {}. #pragma optimize("""", on); // This function will be optimized with whatever was specified on; // the commandline.; void f2() {}. // This will warn with Clang's current implementation.; #pragma optimize(""g"", on); void f3() {}. For MSVC, an empty optimization list and ``off`` parameter will turn off; all optimizations, ``s``, ``g``, ``t``, and ``y``. An empty optimization and; ``on`` parameter will reset the optimizations to the ones specified on the; commandline. .. list-table:: Parameters (unsupported by Clang). * - Parameter; - Type of optimization; * - g; - Deprecated; * - s or t; - Short or fast sequences of machine code; * - y; - Enable frame pointers. Extensions for loop hint optimizations; ======================================. The ``#pragma clang loop`` directive is used to specify hints for optimizing the; subsequent for, while, do-while, or c++11 range-based for loop. The directive; provides options for vectorization, interleaving, predication, unrolling and; distribution. Loop hints can be specified before any loop and will be ignored if; the optimization is not safe to apply. There are loop hints that control transformations (e.g. vectorization, loop; unrolling) and there are loop hints that set transformation options (e.g.; ``vectorize_width``, ``unroll_count``). Pragmas setting transformation options; imply the transformation is enabled, as if it was enabled via the corresponding; transformation pragma (e.g. ``vectorize(enable)``). If the transformation is; disabled (e.g. ``vectorize(disable)``), that takes precedence over; transformations option pragmas implying that transformation. Vectorization, Interleaving, and Predication; ---------------------------------",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst:162239,optimiz,optimizations,162239,interpreter/llvm-project/clang/docs/LanguageExtensions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst,1,['optimiz'],['optimizations']
Performance,", this is the total number of; virtual cores. For some applications and machine configurations this; may be too aggressive, in which case the amount of parallelism can; be reduced to ``N`` via:. - gold:; ``-Wl,-plugin-opt,jobs=N``; - ld64:; ``-Wl,-mllvm,-threads=N``; - ld.lld, ld64.lld:; ``-Wl,--thinlto-jobs=N``; - lld-link:; ``/opt:lldltojobs=N``. Other possible values for ``N`` are:. - 0:; Use one thread per physical core (default); - 1:; Use a single thread only (disable multi-threading); - all:; Use one thread per logical core (uses all hyper-threads). Incremental; -----------; .. _incremental:. ThinLTO supports fast incremental builds through the use of a cache,; which currently must be enabled through a linker option. - gold (as of LLVM 4.0):; ``-Wl,-plugin-opt,cache-dir=/path/to/cache``; - ld64 (supported since clang 3.9 and Xcode 8) and Mach-O ld64.lld (as of LLVM; 15.0):; ``-Wl,-cache_path_lto,/path/to/cache``; - ELF ld.lld (as of LLVM 5.0):; ``-Wl,--thinlto-cache-dir=/path/to/cache``; - COFF lld-link (as of LLVM 6.0):; ``/lldltocache:/path/to/cache``. Cache Pruning; -------------. To help keep the size of the cache under control, ThinLTO supports cache; pruning. Cache pruning is supported with gold, ld64, and lld, but currently only; gold and lld allow you to control the policy with a policy string. The cache; policy must be specified with a linker option. - gold (as of LLVM 6.0):; ``-Wl,-plugin-opt,cache-policy=POLICY``; - ELF ld.lld (as of LLVM 5.0), Mach-O ld64.lld (as of LLVM 15.0):; ``-Wl,--thinlto-cache-policy=POLICY``; - COFF lld-link (as of LLVM 6.0):; ``/lldltocachepolicy:POLICY``. A policy string is a series of key-value pairs separated by ``:`` characters.; Possible key-value pairs are:. - ``cache_size=X%``: The maximum size for the cache directory is ``X`` percent; of the available space on the disk. Set to 100 to indicate no limit,; 50 to indicate that the cache size will not be left over half the available; disk space. A value over 100 is inva",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ThinLTO.rst:4947,cache,cache-dir,4947,interpreter/llvm-project/clang/docs/ThinLTO.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ThinLTO.rst,2,['cache'],"['cache', 'cache-dir']"
Performance,", to declare variables). - **addToCodeBody()**: adds the input string to the squashed code body. If a; class implements a translate function that wants to emit something to the; squashed code body, it must call this function with the code it wants to; emit. In case of loops, it automatically determines if the code needs to be; stored inside or outside the scope of that loop. - **makeValidVarName()**: takes a string (e.g., a variable name) and converts; it into a valid C++ variable name by replacing any forbidden characters with; underscores. - **buildArg()**: helps convert RooFit objects into arrays or other C++; representations for efficient computation. - **addResult()**: adds (or overwrites) the string representing the result of; a node. > For each `translate()` function, it is important to call `addResult()` since; this is what enables the squashing to happen. - **getResult()**: gets the result for the given node using the node name.; This node also performs the necessary code generation through recursive calls; to `translate()`. - **assembleCode()**: combines the generated code statements into the final; code body of the squashed function. These functions will appear again in this document with more contextual; examples. For detailed in-line documentation (code comments), please see:. > [roofit/roofitcore/src/RooFit/Detail/CodeSquashContext.cxx](https://github.com/root-project/root/blob/master/roofit/roofitcore/src/RooFit/Detail/CodeSquashContext.cxx). ### b. RooFuncWrapper. > [roofit/roofitcore/inc/RooFuncWrapper.h](https://github.com/root-project/root/blob/master/roofit/roofitcore/inc/RooFuncWrapper.h). This class wraps the generated C++ code in a RooFit object, so that it can be; used like other RooFit objects. It takes a function body as input and creates a callable function from it.; This allows users to evaluate the function and its derivatives efficiently. #### Helper Functions. - **loadParamsAndData()** extracts parameters and observables from the; prov",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/developers/roofit_ad.md:32617,perform,performs,32617,roofit/doc/developers/roofit_ad.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/developers/roofit_ad.md,1,['perform'],['performs']
Performance,", volatile T *addr);; int __builtin_arm_stlex(T val, volatile T *addr);; void __builtin_arm_clrex(void);. The types ``T`` currently supported are:. * Integer types with width at most 64 bits (or 128 bits on AArch64).; * Floating-point types; * Pointer types. Note that the compiler does not guarantee it will not insert stores which clear; the exclusive monitor in between an ``ldrex`` type operation and its paired; ``strex``. In practice this is only usually a risk when the extra store is on; the same cache line as the variable being modified and Clang will only insert; stack stores on its own, so it is best not to use these operations on variables; with automatic storage duration. Also, loads and stores may be implicit in code written between the ``ldrex`` and; ``strex``. Clang will not necessarily mitigate the effects of these either, so; care should be exercised. For these reasons the higher level atomic primitives should be preferred where; possible. Non-temporal load/store builtins; --------------------------------. Clang provides overloaded builtins allowing generation of non-temporal memory; accesses. .. code-block:: c. T __builtin_nontemporal_load(T *addr);; void __builtin_nontemporal_store(T value, T *addr);. The types ``T`` currently supported are:. * Integer types.; * Floating-point types.; * Vector types. Note that the compiler does not guarantee that non-temporal loads or stores; will be used. C++ Coroutines support builtins; --------------------------------. .. warning::; This is a work in progress. Compatibility across Clang/LLVM releases is not; guaranteed. Clang provides experimental builtins to support C++ Coroutines as defined by; https://wg21.link/P0057. The following four are intended to be used by the; standard library to implement the ``std::coroutine_handle`` type. **Syntax**:. .. code-block:: c. void __builtin_coro_resume(void *addr);; void __builtin_coro_destroy(void *addr);; bool __builtin_coro_done(void *addr);; void *__builtin_coro_promise",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst:144744,load,load,144744,interpreter/llvm-project/clang/docs/LanguageExtensions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst,1,['load'],['load']
Performance,", we see the counter for; SCHEDQ reports 272 cycles. This counter is incremented every time the dispatch; logic is unable to dispatch a full group because the scheduler's queue is full. Looking at the *Dispatch Logic* table, we see that the pipeline was only able to; dispatch two micro opcodes 51.5% of the time. The dispatch group was limited to; one micro opcode 44.6% of the cycles, which corresponds to 272 cycles. The; dispatch statistics are displayed by either using the command option; ``-all-stats`` or ``-dispatch-stats``. The next table, *Schedulers*, presents a histogram displaying a count,; representing the number of micro opcodes issued on some number of cycles. In; this case, of the 610 simulated cycles, single opcodes were issued 306 times; (50.2%) and there were 7 cycles where no opcodes were issued. The *Scheduler's queue usage* table shows that the average and maximum number of; buffer entries (i.e., scheduler queue entries) used at runtime. Resource JFPU01; reached its maximum (18 of 18 queue entries). Note that AMD Jaguar implements; three schedulers:. * JALU01 - A scheduler for ALU instructions.; * JFPU01 - A scheduler floating point operations.; * JLSAGU - A scheduler for address generation. The dot-product is a kernel of three floating point instructions (a vector; multiply followed by two horizontal adds). That explains why only the floating; point scheduler appears to be used. A full scheduler queue is either caused by data dependency chains or by a; sub-optimal usage of hardware resources. Sometimes, resource pressure can be; mitigated by rewriting the kernel using different instructions that consume; different scheduler resources. Schedulers with a small queue are less resilient; to bottlenecks caused by the presence of long data dependencies. The scheduler; statistics are displayed by using the command option ``-all-stats`` or; ``-scheduler-stats``. The next table, *Retire Control Unit*, presents a histogram displaying a count,; representing t",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:31489,queue,queue,31489,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,1,['queue'],['queue']
Performance,", with the aim to provide to the LHC experiments a stand-alone and; high performant matrix package for reconstruction. The API of the current package differs; from the original one, in order to be compliant to the %ROOT coding conventions. SMatrix contains generic \ref SMatrixSVector to describe matrix and vector of arbitrary; dimensions and of arbitrary type. The classes are templated on the scalar type and on the; size of the matrix (number of rows and columns) or the vector. Therefore, the size has to; be known at compile time. Since the release 5.10, SMatrix supports symmetric matrices using; a storage class (ROOT::Math::MatRepSym) which contains only the N*(N+1)/2 independent element; of a NxN symmetric matrix.; It is not in the mandate of this package to provide a complete linear algebra functionality; for these classes. What is provided are basic \ref MatrixFunctions and \ref VectFunction,; such as the matrix-matrix, matrix-vector, vector-vector operations, plus some extra; functionality for square matrices, like inversion, which is based on the optimized Cramer; method for squared matrices of size up to 6x6, and determinant calculation.; For a more detailed descriptions and usage examples see:. * \ref SVectorDoc; * \ref SMatrixDoc; * \ref MatVecFunctions. The SMatrix package contains only header files. Normally one does not need to build any library.; In the %ROOT distribution a library, _libSmatrix_ is produced with the C++ dictionary information; for vectors, symmetric and squared matrices for double, float types up to dimension 7.; The current version of SMatrix can be downloaded from [here](../SMatrix.tar.gz). If you want; to install the header files or run the test _configure_ script and then _make install_ or; _make check_ to build the tests. No dictionary library is built in this case. ## References. 1. T. Veldhuizen, [_Expression Templates_](http://osl.iu.edu/~tveldhui/papers/Expression-Templates/exprtmpl.html),; C++ Report, 1995.; 2. T. Glebe, _SMat",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/smatrix/doc/index.md:1931,optimiz,optimized,1931,math/smatrix/doc/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/smatrix/doc/index.md,1,['optimiz'],['optimized']
Performance,", with the; proviso that of course the object cannot be legally read after the object's; lifetime ends. :arc-term:`Moving` occurs in specific situations where an lvalue is ""moved; from"", meaning that its current pointee will be used but the object may be left; in a different (but still valid) state. This arises with ``__block`` variables; and rvalue references in C++. For ``__strong`` lvalues, moving is equivalent; to loading the lvalue with primitive semantics, writing a null pointer to it; with primitive semantics, and then releasing the result of the load at the end; of the current full-expression. For all other lvalues, moving is equivalent to; reading the object. .. _arc.ownership.restrictions:. Restrictions; ------------. .. _arc.ownership.restrictions.weak:. Weak-unavailable types; ^^^^^^^^^^^^^^^^^^^^^^. It is explicitly permitted for Objective-C classes to not support ``__weak``; references. It is undefined behavior to perform an operation with weak; assignment semantics with a pointer to an Objective-C object whose class does; not support ``__weak`` references. .. admonition:: Rationale. Historically, it has been possible for a class to provide its own; reference-count implementation by overriding ``retain``, ``release``, etc.; However, weak references to an object require coordination with its class's; reference-count implementation because, among other things, weak loads and; stores must be atomic with respect to the final release. Therefore, existing; custom reference-count implementations will generally not support weak; references without additional effort. This is unavoidable without breaking; binary compatibility. A class may indicate that it does not support weak references by providing the; ``objc_arc_weak_reference_unavailable`` attribute on the class's interface declaration. A; retainable object pointer type is **weak-unavailable** if; is a pointer to an (optionally protocol-qualified) Objective-C class ``T`` where; ``T`` or one of its superclas",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst:41153,perform,perform,41153,interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,1,['perform'],['perform']
Performance,", you must use the pointer to the; current **`TTree`** to call the method `GetEntry(entry)`. The; parameter `entry` is always the local entry number in the current; tree. Assuming that `fChain` is the pointer to the **`TChain`**; being processed, use. ``` {.cpp}; fChain->GetTree()->GetEntry(entry);; ```. To create a selector call:. ``` {.cpp}; root[] T->MakeSelector(""MySelector"");; ```. Where `T` is the **`TTree`** and `MySelector` is the name of created; class and the name of the `.h` and `.C` files. The resulting; **`TSelector`** is the argument to **`TTree::Process`**. The argument can; be the file name or a pointer to the selector object. ``` {.cpp}; root[] T->Process(""MySelector.C"","""",1000,100);; ```. This call will interpret the class defined in `MySelector.C` and process; 1000 entries beginning with entry 100. The file name can be appended; with a ""+"" or a ""++"" to use `ACLiC`. ``` {.cpp}; root[] T->Process(""MySelector.C++"","""",1000,100);; ```. When appending a ""++"", the class will be compiled and dynamically; loaded. ``` {.cpp}; root[] T->Process(""MySelector.C+"","""",1000,100);; ```. When appending a ""+"", the class will also be compiled and dynamically; loaded. When it is called again, it recompiles only if the macro; (`MySelector.C`) has changed since it was compiled last. If not, it; loads the existing library. The next example shows how to create a; selector with a pointer:. ``` {.cpp}; MySelector *selector = (MySelector *)TSelector::GetSelector(""MySelector.C+"");; T->Process(selector);; ```. `Using this form, you can do things like:`. ``` {.cpp}; selector->public_attribute1 = init_value;; for (int i=0; i<limit; i++) {; T->Process(selector);; selector->public_attribute1 =; function(selector->public_attribute2);; }; ```. `TTree::Process()` is aware of PROOF, ROOT parallel processing facility.; If PROOF is setup, it divides the processing amongst the slave CPUs. ### Performance Benchmarks; \index{benchmarks}. The program `$ROOTSYS/test/bench.cxx` compares the I/O",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md:134231,load,loaded,134231,documentation/users-guide/Trees.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md,1,['load'],['loaded']
Performance,",...]>. With **kind** being one of the options in the following list. .. code-block:: text. =Base: Base type (integer, boolean, etc).; =Const: Constant specifier.; =Enumerator: Enumerator.; =Import: Import declaration.; =ImportDeclaration: Import declaration.; =ImportModule: Import module.; =Pointer: Pointer type.; =PointerMember: Pointer to member function.; =Reference: Reference type.; =Restrict: Restrict specifier.; =RvalueReference: R-value reference.; =Subrange: Array subrange.; =TemplateParam: Template parameter.; =TemplateTemplateParam: Template template parameter.; =TemplateTypeParam: Template type parameter.; =TemplateValueParam: Template value parameter.; =Typedef: Type definition.; =Unspecified: Unspecified type.; =Volatile: Volatile specifier. .. _compare_:. COMPARE; ~~~~~~~; When dealing with debug information, there are situations when the; printing of the elements is not the correct approach. That is the case,; when we are interested in the effects caused by different versions of; the same toolchain, or the impact of specific compiler optimizations. For those cases, we are looking to see which elements have been added; or removed. Due to the complicated debug information format, it is very; difficult to use a regular diff tool to find those elements; even; impossible when dealing with different debug formats. :program:`llvm-debuginfo-analyzer` supports a logical element comparison,; allowing to find semantic differences between logical views, produced by; different toolchain versions or even debug information formats. When comparing logical views created from different debug formats, its; accuracy depends on how close the debug information represents the; user code. For instance, a logical view created from a binary file with; DWARF debug information may include more detailed data than a logical; view created from a binary file with CodeView/COFF debug information. The following options describe the elements to compare. .. option:: --compare=<value[,v",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-debuginfo-analyzer.rst:19614,optimiz,optimizations,19614,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-debuginfo-analyzer.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-debuginfo-analyzer.rst,1,['optimiz'],['optimizations']
Performance,",10);; TDecompSVD svd(m);; TVectorD sig = svd.GetSig(); sig.Sqr();; // Symmetric matrix EigenVector algorithm; TMatrixDSym mtm(TMatrixDBase::kAtA,m);; const TMatrixDSymEigen eigen(mtm);; const TVectorD eigenVal = eigen.GetEigenValues();; const Bool_t ok = VerifyVectorIdentity(sig,eigenVal,1,1.-e-14);; ```. ## Speed Comparisons. Speed of four matrix operations have been compared between four matrix; libraries, `GSL` `CLHEP`, `ROOT v3.10` and `ROOT v4.0`. Next figure; shows the `CPU` time for these four operations as a function of the; matrix size:. 1. `A*B` The execution time is measured for the sum of A \* Bsym,; Bsym\* A and A \* B. Notice the matrix\_size3 dependence of execution; time. `CLHEP` results are hampered by a poor implementation of symmetric; matrix multiplications. For instance, for general matrices of size; 100x100, the time is 0.015 sec. while A \* Bsym takes 0.028 sec and; Bsym\* A takes 0.059 sec. Both `GSL` and `ROOT v4.0` can be setup to use the hardware-optimized; multiplication routines of the `BLAS` libraries. It was tested on a G4; PowerPC. The improvement becomes clearly visible around sizes of (50x50); were the execution speed improvement of the Altivec processor becomes; more significant than the overhead of filling its pipe. 2. $A^{-1}$ Here, the time is measured for an in-place matrix inversion. Except for `ROOT v3.10`, the algorithms are all based on an; `LU `factorization followed by forward/back-substitution. `ROOT v3.10`; is using the slower Gaussian elimination method. The numerical accuracy; of the `CLHEP` routine is poor:. - up to 6x6 the numerical imprecise Cramer multiplication is hard-coded.; For instance, calculating `U=H*H-1`, where `H` is a (5x5) Hilbert; matrix, results in off-diagonal elements of $10^{-7}$ instead of the $10^{-13}$; using an `LU `according to `Crout`. - scaling protection is non-existent and limits are hard-coded, as a; consequence inversion of a Hilbert matrix for `sizes>(12x12)` fails. In; order to gain s",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/LinearAlgebra.md:50288,optimiz,optimized,50288,documentation/users-guide/LinearAlgebra.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/LinearAlgebra.md,1,['optimiz'],['optimized']
Performance,",m,s one can now do. RooWorkspace w(""w"",true) ; // workspace with CINT interface activated; // ... fill workspace with RooGaussian gauss(x,m,s) ...; RooPlot* frame = w::x.frame() ;; w::gauss.plotOn(frame) ;. to access the workspace contents. Each reference has the correct type, e.g. w::gauss is; a RooGaussian&. If a workspace is deleted from memory, the corresponding CINT namespace; is removed as well. Note that this feature is strictly available in interpreted C++ only; A new tutorial macro has been added to illustrate this functionality in more detail: rf509_wsinteractive.C.; writeToFile -- A new utility method RooWorkspace::writeToFile() has been added; to simplify the process of saving a workspace to file; Named sets and parameter snapshots -- It is now possible to define and retrieve; named RooArgSets of objects that live in the workspace through methods; defineSet() and set(). While named sets merely group objects logically, methods loadSnapshot and; saveSnapshot allow to make copies of the values, errors and 'constant' status of; sets of variable objects that live in the workspace. A newly added tutorial macro rf510_namedsets.C illustrates the functionality of both; of these features.; Improved printing of contents -- Many operator p.d.f. and function components now show; a more intuitive natural representation of their contents (these changes are mostly in the; respective p.d.f.s, but are most relevant in the context of a workspace). New object factory interface to workspace to facilitate script driven model definition; A object factory has been added to RooFit to simplify the process of creating p.d.f.; and function expressions consisting of multiple objects. The factory has two goals:; the first is to provide a back-end for higher level factories and tools to process; the creation of objects. The second is to provide a simple end-user language to; populate a RooWorkspace with function and p.d.f. objects. For the latter purpose the object creation language ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:17548,load,loadSnapshot,17548,roofit/doc/v524/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html,2,['load'],['loadSnapshot']
Performance,"- *Colors*: creates a new canvas showing the color palette. - *Markers*: creates a new canvas showing the various marker styles. - *Iconify*: create the canvas window icon, does not close the; canvas. - *View With...*: If the last selected pad contains a 3-d structure,; a new canvas is created with a 3-D picture according to the; selection made from the cascaded menu: X3D or OpenGL. The 3-D; image can be interactively rotated, zoomed in wire-frame, solid,; hidden line or stereo mode. ![](pictures/0300000C.png). #### Options Menu. - *Auto Resize Canvas*: turns auto-resize of the canvas *on/off*:. - *on* - the canvas fits to the window when changing the window; size;; - *off* - the canvas stays fixed when changing the window size. - *Resize Canvas*: resizes and fits the canvas to the window size. - *Move Opaque*: if selected, graphics objects are moved in opaque; mode; otherwise, only the outline of objects is drawn when moving; them. The option opaque produces the best effect but it requires a; reasonably fast workstation or response time. - *Resize Opaque*: if selected, graphics objects are resized in; opaque mode; otherwise, only the outline of objects is drawn when; resizing them. - *Interrupt*: interrupts the current drawing process. - *Refresh*: redraws the canvas contents. - *Pad Auto Exec*: executes the list of **`TExecs`** in the current; pad. - *Statistics*: toggles the display of the histogram statistics box. - *Histogram Title*: toggles the display of the histogram title. - *Fit Parameters*: toggles the display of the histogram or graph; fit parameters. - *Can Edit Histogram*: enables/disables the possibility to edit; histogram bin contents. ![](pictures/0300000D.png). #### Inspect Menu. - *ROOT*: inspects the top-level ***`gROOT`*** object (in a new; canvas). - *Start Browser*: starts a new object browser (in a separate; window). - *GUI Builder*: starts the GUI builder application (in a separate; window). ![](pictures/0300000E.png). #### Help Menu. - *Can",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/GettingStarted.md:10290,response time,response time,10290,documentation/users-guide/GettingStarted.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/GettingStarted.md,1,['response time'],['response time']
Performance,"- All elements of the vector have identical scalar elements. This; operation may also be known as a ""broadcast"" or ""duplicate"" in target assembly.; The shufflevector IR instruction may change the vector length, so this operation; may map to multiple SelectionDAG nodes including ``shuffle_vector``,; ``concat_vectors``, ``insert_subvector``, and ``extract_subvector``. Prior to the existence of the Legalize passes, we required that every target; `selector`_ supported and handled every operator and type even if they are not; natively supported. The introduction of the Legalize phases allows all of the; canonicalization patterns to be shared across targets, and makes it very easy to; optimize the canonicalized code because it is still in the form of a DAG. .. _optimizations:; .. _Optimize SelectionDAG:; .. _selector:. SelectionDAG Optimization Phase: the DAG Combiner; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The SelectionDAG optimization phase is run multiple times for code generation,; immediately after the DAG is built and once after each legalization. The first; run of the pass allows the initial code to be cleaned up (e.g. performing; optimizations that depend on knowing that the operators have restricted type; inputs). Subsequent runs of the pass clean up the messy code generated by the; Legalize passes, which allows Legalize to be very simple (it can focus on making; code legal instead of focusing on generating *good* and legal code). One important class of optimizations performed is optimizing inserted sign and; zero extension instructions. We currently use ad-hoc techniques, but could move; to more rigorous techniques in the future. Here are some good papers on the; subject:. ""`Widening integer arithmetic <http://www.eecs.harvard.edu/~nr/pubs/widen-abstract.html>`_"" :raw-html:`<br>`; Kevin Redwine and Norman Ramsey :raw-html:`<br>`; International Conference on Compiler Construction (CC) 2004. ""`Effective sign extension elimination <http://portal.acm.org/",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:45245,optimiz,optimization,45245,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst,1,['optimiz'],['optimization']
Performance,"- If OpenCL, omit lgkmcnt(0).; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; have; completed before; performing the; store that is being; released. 2. buffer/global/flat_store; store atomic release - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_store; store atomic release - agent - global 1. s_waitcnt lgkmcnt(0) &; - generic vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; to memory have; completed before; performing the; store that is being; released. 2. buffer/global/flat_store; store atomic release - system - global 1. buffer_wbl2; - generic; - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at system scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after any; preceding; global/generic; load/store/load; atom",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:258297,load,load,258297,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],['load']
Performance,"- If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_inv.; - Ensures the; atomicrmw has; completed before; invalidating the; caches. 5. buffer_inv sc0=1 sc1=1. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; MTYPE NC global data.; MTYPE RW and CC memory will; never be stale due to the; memory probes. fence acq_rel - singlethread *none* *none*; - wavefront; fence acq_rel - workgroup *none* 1. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - If OpenCL and; address space is; local, omit; vmcnt(0).; - However,; since LLVM; currently has no; address space on; the fence need to; conservatively; always generate; (see comment for; previous fence).; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that all; memory operations; have; completed before; performing any; following global; memory operations.; - Ensures that the; preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; acquire-fence-paired-atomic); has completed; before following; global memory; operations. This; satisfies the; requirements of; acquire.; - Ensures that all; previous memory; operations have; completed before a; following; local/generic store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; release-fence-paired-atomic).; This satisfies the; req",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:325444,load,load,325444,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],['load']
Performance,"- Must happen before; the following buffer_gl0_inv; and before any following; global/generic load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than the local load; atomic value being; acquired. 3. buffer_gl0_inv. - If CU wavefront execution; mode, omit.; - If OpenCL, omit.; - Ensures that; following; loads will not see; stale data. load atomic acquire - workgroup - generic 1. flat_load glc=1. - If CU wavefront execution; mode, omit glc=1. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If CU wavefront execution; mode, omit vmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Must happen before; the following; buffer_gl0_inv and any; following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic value being; acquired. 3. buffer_gl0_inv. - If CU wavefront execution; mode, omit.; - Ensures that; following; loads will not see; stale data. load atomic acquire - agent - global 1. buffer/global_load; - system glc=1 dlc=1. - If GFX11, omit dlc=1. 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_gl*_inv.; - Ensures the load; has completed; before invalidating; the caches. 3. buffer_gl0_inv;; buffer_gl1_inv. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale global data. load atomic acquire - agent - generic 1. flat_load glc=1 dlc=1; - system; - If GFX11, omit dlc=1. 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If OpenCL omit; lgkmcnt(0).; - Must happen before; following; buffer_gl*_invl.; - Ensures the flat_load; has completed; before invalidating; the caches. 3. buffer_gl0_inv;; buffer_gl1_inv. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - singlethread - global 1. buffer/global/ds/flat_atomic; - wavefront - local; - generic; atomi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:347734,load,load,347734,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['load']
Performance,"- for 3D vectors implementing the `x()`, `y()` and `z()` methods. - for Lorentz vectors implementing the `x()`, `y()`, `z()` and `t()`; methods. ``` {.cpp}; CLHEP::Hep3Vector hv;; XYZVector v1(hv); //create 3D vector from; //CLHEP 3D Vector; HepGeom::Point3D hp;; XYZPoint p1(hp); //create a 3D p; ```. ## Linear Algebra: SMatrix Package. The ROOT Linear algebra package is documented in a separate chapter (see; ""Linear Algebra in ROOT""). `SMatrix` is a C++ package, for high; performance vector and matrix computations. It has been introduced in; ROOT v5.08. It is optimized for describing small matrices and vectors; and It can be used only in problems when the size of the matrices is; known at compile time, like in the tracking reconstruction of physics; experiments. It is based on a C++ technique, called expression; templates, to achieve an high level optimization. The C++ templates can; be used to implement vector and matrix expressions such that these; expressions can be transformed at compile time to code which is; equivalent to hand optimized code in a low-level language like FORTRAN; or C (see for example T. Veldhuizen, Expression Templates, C++ Report,; 1995). The `SMatrix` has been developed initially by T. Glebe in; Max-Planck-Institut, Heidelberg, as part of the `HeraB` analysis; framework. A subset of the original package has been now incorporated in; the ROOT distribution, with the aim to provide a stand-alone and high; performance matrix package. The API of the current package differs from; the original one, in order to be compliant to the ROOT coding; conventions. `SMatrix` contains the generic **`ROOT::Math::SMatrix`** and; **`ROOT::Math::SVector`** classes for describing matrices and vectors of; arbitrary dimensions and of arbitrary type. The classes are templated on; the scalar type and on the size, like number of rows and columns for a; matrix . Therefore, the matrix/vector dimension has to be known at; compile time. An advantage of using the dimension ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/MathLibraries.md:99637,optimiz,optimized,99637,documentation/users-guide/MathLibraries.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/MathLibraries.md,1,['optimiz'],['optimized']
Performance,"- middle end --------------------┼------ backend ----┤; │ │ │ │; └--- parsing ---- sema -----┴--- optimizations --- IPO ---- optimizations---┴--- optimizations -┘. ┌-----------------------------------------------------------------------------------------------┐; │ │; │ source file │; │ │; └-----------------------------------------------------------------------------------------------┘; ┌---------------------------------------┐; │ │; │ │; │ imported code │; │ │; │ │; └---------------------------------------┘. It would be very unfortunate if we end up with worse performance after using modules.; The main concern is that when we compile a source file, the compiler needs to see the function body; of imported module units so that it can perform IPO (InterProcedural Optimization, primarily inlining; in practice) to optimize functions in current source file with the help of the information provided by; the imported module units.; In other words, the imported code would be processed again and again in importee units; by optimizations (including IPO itself).; The optimizations before IPO and the IPO itself are the most time-consuming part in whole compilation process.; So from this perspective, we might not be able to get the improvements described in the theory.; But we could still save the time for optimizations after IPO and the whole backend. Overall, at ``O0`` the implementations of functions defined in a module will not impact module users,; but at higher optimization levels the definitions of such functions are provided to user compilations for the; purposes of optimization (but definitions of these functions are still not included in the use's object file)-; this means the build speedup at higher optimization levels may be lower than expected given ``O0`` experience,; but does provide by more optimization opportunities. Interoperability with Clang Modules; -----------------------------------. We **wish** to support clang modules and standard c++ modules at the same t",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/StandardCPlusPlusModules.rst:42601,optimiz,optimizations,42601,interpreter/llvm-project/clang/docs/StandardCPlusPlusModules.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/StandardCPlusPlusModules.rst,1,['optimiz'],['optimizations']
Performance,"- wavefront - generic; - workgroup; - agent; atomicrmw monotonic - system - global 1. buffer/global/flat_atomic; - generic; atomicrmw monotonic - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; - workgroup be used.*. 1. ds_atomic; **Acquire Atomic**; ------------------------------------------------------------------------------------; load atomic acquire - singlethread - global 1. buffer/global/ds/flat_load; - wavefront - local; - generic; load atomic acquire - workgroup - global 1. buffer/global_load glc=1. - If not TgSplit execution; mode, omit glc=1. 2. s_waitcnt vmcnt(0). - If not TgSplit execution; mode, omit.; - Must happen before the; following buffer_wbinvl1_vol. 3. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale data. load atomic acquire - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_load; 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than the local load; atomic value being; acquired. load atomic acquire - workgroup - generic 1. flat_load glc=1. - If not TgSplit execution; mode, omit glc=1. 2. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit lgkmcnt(0).; - Must happen before; the following; buffer_wbinvl1_vol and any; following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic value being; acquired. 3. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. load atomic acquire - agent - global 1. buffer/glo",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:245757,load,load,245757,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['load']
Performance,"- wavefront - generic; store atomic monotonic - workgroup - global 1. buffer/global/flat_store; - generic sc0=1; store atomic monotonic - agent - global 1. buffer/global/flat_store; - generic sc1=1; store atomic monotonic - system - global 1. buffer/global/flat_store; - generic sc0=1 sc1=1; store atomic monotonic - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; - workgroup be used.*. 1. ds_store; atomicrmw monotonic - singlethread - global 1. buffer/global/flat_atomic; - wavefront - generic; - workgroup; - agent; atomicrmw monotonic - system - global 1. buffer/global/flat_atomic; - generic sc1=1; atomicrmw monotonic - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; - workgroup be used.*. 1. ds_atomic; **Acquire Atomic**; ------------------------------------------------------------------------------------; load atomic acquire - singlethread - global 1. buffer/global/ds/flat_load; - wavefront - local; - generic; load atomic acquire - workgroup - global 1. buffer/global_load sc0=1; 2. s_waitcnt vmcnt(0). - If not TgSplit execution; mode, omit.; - Must happen before the; following buffer_inv. 3. buffer_inv sc0=1. - If not TgSplit execution; mode, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale data. load atomic acquire - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_load; 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than the local load; atomic value being; acquired. load atomic acquire - workgroup - generic 1. flat_load sc0=1; 2. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit lgkmcnt(0).",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:295656,load,load,295656,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['load']
Performance,"-+; | 0x110000000000|0x200000000000 | origin 2 |; +---------------+---------------+--------------------+; | 0x100000000000|0x110000000000 | unused |; +---------------+---------------+--------------------+; | 0x010000000000|0x100000000000 | shadow 2 |; +---------------+---------------+--------------------+; | 0x000000000000|0x010000000000 | application 1 |; +---------------+---------------+--------------------+. Each byte of application memory corresponds to a single byte of shadow; memory, which is used to store its taint label. We map memory, shadow, and; origin regions to each other with these masks and offsets:. * shadow_addr = memory_addr ^ 0x500000000000. * origin_addr = shadow_addr + 0x100000000000. As for LLVM SSA registers, we have not found it necessary to associate a label; with each byte or bit of data, as some other tools do. Instead, labels are; associated directly with registers. Loads will result in a union of; all shadow labels corresponding to bytes loaded, and stores will; result in a copy of the label of the stored value to the shadow of all; bytes stored to. Propagating labels through arguments; ------------------------------------. In order to propagate labels through function arguments and return values,; DataFlowSanitizer changes the ABI of each function in the translation unit.; There are currently two supported ABIs:. * Args -- Argument and return value labels are passed through additional; arguments and by modifying the return type. * TLS -- Argument and return value labels are passed through TLS variables; ``__dfsan_arg_tls`` and ``__dfsan_retval_tls``. The main advantage of the TLS ABI is that it is more tolerant of ABI mismatches; (TLS storage is not shared with any other form of storage, whereas extra; arguments may be stored in registers which under the native ABI are not used; for parameter passing and thus could contain arbitrary values). On the other; hand the args ABI is more efficient and allows ABI mismatches to be more easily; i",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowSanitizerDesign.rst:9728,load,loaded,9728,interpreter/llvm-project/clang/docs/DataFlowSanitizerDesign.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowSanitizerDesign.rst,1,['load'],['loaded']
Performance,"--'. And the compilation process for module units are like:. .. code-block:: text. src1.cpp ----------------------------------------+> clang++ src1.cpp -------> src1.o -,; (header unit) hdr1.h -> clang++ hdr1.h ... -> hdr1.pcm --' +-> clang++ src1.o mod1.o src2.o -> executable; mod1.cppm -> clang++ mod1.cppm ... -> mod1.pcm --,--> clang++ mod1.pcm ... -> mod1.o -+; src2.cpp ----------------------------------------+> clang++ src2.cpp -------> src2.o -'. As the diagrams show, we need to compile the BMI from module units to object files and link the object files.; (But we can't do this for the BMI from header units. See the later section for the definition of header units). If we want to create a module library, we can't just ship the BMIs in an archive.; We must compile these BMIs(``*.pcm``) into object files(``*.o``) and add those object files to the archive instead. Consistency Requirement; ~~~~~~~~~~~~~~~~~~~~~~~. If we envision modules as a cache to speed up compilation, then - as with other caching techniques -; it is important to keep cache consistency.; So **currently** Clang will do very strict check for consistency. Options consistency; ^^^^^^^^^^^^^^^^^^^. The language option of module units and their non-module-unit users should be consistent.; The following example is not allowed:. .. code-block:: c++. // M.cppm; export module M;. // Use.cpp; import M;. .. code-block:: console. $ clang++ -std=c++20 M.cppm --precompile -o M.pcm; $ clang++ -std=c++23 Use.cpp -fprebuilt-module-path=. The compiler would reject the example due to the inconsistent language options.; Not all options are language options.; For example, the following example is allowed:. .. code-block:: console. $ clang++ -std=c++20 M.cppm --precompile -o M.pcm; # Inconsistent optimization level.; $ clang++ -std=c++20 -O3 Use.cpp -fprebuilt-module-path=.; # Inconsistent debugging level.; $ clang++ -std=c++20 -g Use.cpp -fprebuilt-module-path=. Although the two examples have inconsistent optimization",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/StandardCPlusPlusModules.rst:15364,cache,cache,15364,interpreter/llvm-project/clang/docs/StandardCPlusPlusModules.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/StandardCPlusPlusModules.rst,2,['cache'],['cache']
Performance,"--+---------------------------------------+; | | `TMatrixDColumn(A,j1) *=` | multiply column $j2$ with column $j1$ |; | | `TMatrixDColumn const(A,j2)` | element wise |; +-----------------------+---------------------------------+---------------------------------------+; | multiply matrix slice | `TMatrixDDiag(A) *=` | multiply $B$ diagonal with $A$ |; | | `TMatrixDDiag const(B)` | diagonal element wise |; +-----------------------+---------------------------------+---------------------------------------+; | | `TMatrixDSub(A,i1,l1,j1,k1) *=` | multiply sub matrix of $A$ with |; | | `TMatrixDSub(B,i2,l2,j2,k2)` | sub matrix of $B$ |; +-----------------------+---------------------------------+---------------------------------------+; | | `TMatrixDSub(A,i,l,j,k) *= B` | multiply sub matrix of $A$ with |; | | | matrix of $B$ |; +-----------------------+---------------------------------+---------------------------------------+. In the current implementation of the matrix views, the user could; perform operations on a symmetric matrix that violate the symmetry. No; checking is done. For instance, the following code violates the; symmetry. ``` {.cpp}; TMatrixDSym A(5);; A.UnitMatrix();; TMatrixDRow(A,1)[0] = 1;; TMatrixDRow(A,1)[2] = 1;; ```. ### View Examples. Inserting row `i1 `into row` i2` of matrix $A$; can easily accomplished through:. ``` {.cpp}; TMatrixDRow(A,i1) = TMatrixDRow(A,i2); ```. Which more readable than:. ``` {.cpp}; const Int_t ncols = A.GetNcols();; Double_t *start = A.GetMatrixArray();; Double_t *rp1 = start+i*ncols;; const Double_t *rp2 = start+j*ncols;; while (rp1 < start+ncols) *rp1++ = *rp2++;; ```. Check that the columns of a Haar -matrix of order `order` are indeed; orthogonal:. ``` {.cpp}; const TMatrixD haar = THaarMatrixD(order);; TVectorD colj(1<<order);; TVectorD coll(1<<order);; for (Int_t j = haar.GetColLwb(); j <= haar.GetColUpb(); j++) {; colj = TMatrixDColumn_const(haar,j);; Assert(TMath::Abs(colj*colj-1.0) <= 1.0e-15);. for (Int_t l = j+1;",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/LinearAlgebra.md:32073,perform,perform,32073,documentation/users-guide/LinearAlgebra.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/LinearAlgebra.md,1,['perform'],['perform']
Performance,"--- optimizations---┴--- optimizations -┘. ┌-----------------------------------------------------------------------------------------------┐; │ │; │ source file │; │ │; └-----------------------------------------------------------------------------------------------┘; ┌---------------------------------------┐; │ │; │ │; │ imported code │; │ │; │ │; └---------------------------------------┘. It would be very unfortunate if we end up with worse performance after using modules.; The main concern is that when we compile a source file, the compiler needs to see the function body; of imported module units so that it can perform IPO (InterProcedural Optimization, primarily inlining; in practice) to optimize functions in current source file with the help of the information provided by; the imported module units.; In other words, the imported code would be processed again and again in importee units; by optimizations (including IPO itself).; The optimizations before IPO and the IPO itself are the most time-consuming part in whole compilation process.; So from this perspective, we might not be able to get the improvements described in the theory.; But we could still save the time for optimizations after IPO and the whole backend. Overall, at ``O0`` the implementations of functions defined in a module will not impact module users,; but at higher optimization levels the definitions of such functions are provided to user compilations for the; purposes of optimization (but definitions of these functions are still not included in the use's object file)-; this means the build speedup at higher optimization levels may be lower than expected given ``O0`` experience,; but does provide by more optimization opportunities. Interoperability with Clang Modules; -----------------------------------. We **wish** to support clang modules and standard c++ modules at the same time,; but the mixed using form is not well used/tested yet. Please file new github issues as you find interoperability pr",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/StandardCPlusPlusModules.rst:42644,optimiz,optimizations,42644,interpreter/llvm-project/clang/docs/StandardCPlusPlusModules.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/StandardCPlusPlusModules.rst,1,['optimiz'],['optimizations']
Performance,"--------------+. Neither approach is perfect, and choosing one boils down to choosing the lesser of two evils. The issue with lane ordering, it was decided, would have to change target-agnostic compiler passes and would result in a strange IR in which lane indices were reversed. It was decided that this was worse than the changes that would have to be made to support ``LD1``, so ``LD1`` was chosen as the canonical vector load instruction (and by inference, ``ST1`` for vector stores). Implementation; ==============. There are 3 parts to the implementation:. 1. Predicate ``LDR`` and ``STR`` instructions so that they are never allowed to be selected to generate vector loads and stores. The exception is one-lane vectors [1]_ - these by definition cannot have lane ordering problems so are fine to use ``LDR``/``STR``. 2. Create code generation patterns for bitconverts that create ``REV`` instructions. 3. Make sure appropriate bitconverts are created so that vector values get passed over call boundaries as 1-element vectors (which is the same as if they were loaded with ``LDR``). Bitconverts; -----------. .. image:: ARM-BE-bitcastfail.png; :align: right. The main problem with the ``LD1`` solution is dealing with bitconverts (or bitcasts, or reinterpret casts). These are pseudo instructions that only change the compiler's interpretation of data, not the underlying data itself. A requirement is that if data is loaded and then saved again (called a ""round trip""), the memory contents should be the same after the store as before the load. If a vector is loaded and is then bitconverted to a different vector type before storing, the round trip will currently be broken. Take for example this code sequence::. %0 = load <4 x i32> %x; %1 = bitcast <4 x i32> %0 to <2 x i64>; store <2 x i64> %1, <2 x i64>* %y. This would produce a code sequence such as that in the figure on the right. The mismatched ``LD1`` and ``ST1`` cause the stored data to differ from the loaded data. .. container:",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BigEndianNEON.rst:9733,load,loaded,9733,interpreter/llvm-project/llvm/docs/BigEndianNEON.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BigEndianNEON.rst,1,['load'],['loaded']
Performance,"-------------------------+. To configure LLVM, follow these steps:. #. Change directory into the object root directory:. .. code-block:: console. % cd OBJ_ROOT. #. Run the ``cmake``:. .. code-block:: console. % cmake -G ""Unix Makefiles"" -DCMAKE_BUILD_TYPE=<type> -DCMAKE_INSTALL_PREFIX=/install/path; [other options] SRC_ROOT. Compiling the LLVM Suite Source Code; ------------------------------------. Unlike with autotools, with CMake your build type is defined at configuration.; If you want to change your build type, you can re-run cmake with the following; invocation:. .. code-block:: console. % cmake -G ""Unix Makefiles"" -DCMAKE_BUILD_TYPE=<type> SRC_ROOT. Between runs, CMake preserves the values set for all options. CMake has the; following build types defined:. Debug. These builds are the default. The build system will compile the tools and; libraries unoptimized, with debugging information, and asserts enabled. Release. For these builds, the build system will compile the tools and libraries; with optimizations enabled and not generate debug info. CMakes default; optimization level is -O3. This can be configured by setting the; ``CMAKE_CXX_FLAGS_RELEASE`` variable on the CMake command line. RelWithDebInfo. These builds are useful when debugging. They generate optimized binaries with; debug information. CMakes default optimization level is -O2. This can be; configured by setting the ``CMAKE_CXX_FLAGS_RELWITHDEBINFO`` variable on the; CMake command line. Once you have LLVM configured, you can build it by entering the *OBJ_ROOT*; directory and issuing the following command:. .. code-block:: console. % make. If the build fails, please `check here`_ to see if you are using a version of; GCC that is known not to compile LLVM. If you have multiple processors in your machine, you may wish to use some of the; parallel build options provided by GNU Make. For example, you could use the; command:. .. code-block:: console. % make -j2. There are several special targets which are",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GettingStarted.rst:29110,optimiz,optimizations,29110,interpreter/llvm-project/llvm/docs/GettingStarted.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GettingStarted.rst,1,['optimiz'],['optimizations']
Performance,"---------------------------------------------------------------------+; | .llvm.offloading | Embedded device object file for the target device and architecture |; +----------------------------------+------------------------------------------------------------------------------+. .. _Device Linking:. Linking Target Device Code; --------------------------. Objects containing :ref:`table-offloading_sections` require special handling to; create an executable device image. This is done using a Clang tool, see; :doc:`ClangLinkerWrapper` for more information. This tool works as a wrapper; over the host linking job. It scans the input object files for the offloading; section ``.llvm.offloading``. The device files stored in this section are then; extracted and passed to the appropriate linking job. The linked device image is; then :ref:`wrapped <Device Binary Wrapping>` to create the symbols used to load; the device image and link it with the host. The linker wrapper tool supports linking bitcode files through link time; optimization (LTO). This is used whenever the object files embedded in the host; contain LLVM bitcode. Bitcode will be embedded for architectures that do not; support a relocatable object format, such as AMDGPU or SPIR-V, or if the user; requested it using the ``-foffload-lto`` flag. .. _Device Binary Wrapping:. Device Binary Wrapping; ----------------------. Various structures and functions are used to create the information necessary to; offload code on the device. We use the :ref:`linked device executable <Device; Linking>` with the corresponding offloading entries to create the symbols; necessary to load and execute the device image. Structure Types; ^^^^^^^^^^^^^^^. Several different structures are used to store offloading information. The; :ref:`device image structure <table-device_image_structure>` stores a single; linked device image and its associated offloading entries. The offloading; entries are stored using the ``__start_omp_offloading_entries``",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/OffloadingDesign.rst:14265,optimiz,optimization,14265,interpreter/llvm-project/clang/docs/OffloadingDesign.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/OffloadingDesign.rst,1,['optimiz'],['optimization']
Performance,"---------------------------------------------------------------------------; load atomic monotonic - singlethread - global 1. buffer/global/flat_load; - wavefront - generic; load atomic monotonic - workgroup - global 1. buffer/global/flat_load; - generic glc=1. - If CU wavefront execution; mode, omit glc=1. load atomic monotonic - singlethread - local 1. ds_load; - wavefront; - workgroup; load atomic monotonic - agent - global 1. buffer/global/flat_load; - system - generic glc=1 dlc=1. - If GFX11, omit dlc=1. store atomic monotonic - singlethread - global 1. buffer/global/flat_store; - wavefront - generic; - workgroup; - agent; - system; store atomic monotonic - singlethread - local 1. ds_store; - wavefront; - workgroup; atomicrmw monotonic - singlethread - global 1. buffer/global/flat_atomic; - wavefront - generic; - workgroup; - agent; - system; atomicrmw monotonic - singlethread - local 1. ds_atomic; - wavefront; - workgroup; **Acquire Atomic**; ------------------------------------------------------------------------------------; load atomic acquire - singlethread - global 1. buffer/global/ds/flat_load; - wavefront - local; - generic; load atomic acquire - workgroup - global 1. buffer/global_load glc=1. - If CU wavefront execution; mode, omit glc=1. 2. s_waitcnt vmcnt(0). - If CU wavefront execution; mode, omit.; - Must happen before; the following buffer_gl0_inv; and before any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw. 3. buffer_gl0_inv. - If CU wavefront execution; mode, omit.; - Ensures that; following; loads will not see; stale data. load atomic acquire - workgroup - local 1. ds_load; 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; the following buffer_gl0_inv; and before any following; global/generic load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than the local load; atomic value being; acquired. 3. buffer_gl0_inv. - If CU wavefront execution; mode",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:346104,load,load,346104,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['load']
Performance,"---------------------------------------------------------------------; atomicrmw acq_rel - singlethread - global 1. buffer/global/ds/flat_atomic; - wavefront - local; - generic; atomicrmw acq_rel - workgroup - global 1. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to local have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global_atomic. atomicrmw acq_rel - workgroup - local 1. ds_atomic; 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than the local load; atomic value being; acquired. atomicrmw acq_rel - workgroup - generic 1. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to local have; completed before; performing the; atomicrmw that is; being released. 2. flat_atomic; 3. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic value being; acquired. atomicrmw acq_rel - agent - global 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/ato",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:224658,load,load,224658,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],['load']
Performance,"---------------------------------------------------------------------; load atomic monotonic - singlethread - global 1. buffer/global/ds/flat_load; - wavefront - local; - workgroup - generic; load atomic monotonic - agent - global 1. buffer/global/flat_load; - system - generic glc=1; store atomic monotonic - singlethread - global 1. buffer/global/flat_store; - wavefront - generic; - workgroup; - agent; - system; store atomic monotonic - singlethread - local 1. ds_store; - wavefront; - workgroup; atomicrmw monotonic - singlethread - global 1. buffer/global/flat_atomic; - wavefront - generic; - workgroup; - agent; - system; atomicrmw monotonic - singlethread - local 1. ds_atomic; - wavefront; - workgroup; **Acquire Atomic**; ------------------------------------------------------------------------------------; load atomic acquire - singlethread - global 1. buffer/global/ds/flat_load; - wavefront - local; - generic; load atomic acquire - workgroup - global 1. buffer/global_load; load atomic acquire - workgroup - local 1. ds/flat_load; - generic 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic value being; acquired. load atomic acquire - agent - global 1. buffer/global_load; - system glc=1; 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the load; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale global data. load atomic acquire - agent - generic 1. flat_load glc=1; - system 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If OpenCL omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the flat_load; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - Must happen b",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:214264,load,load,214264,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['load']
Performance,"---------------------------------------------------------------------===//. With a copying garbage collector, derived pointers must not be retained across; collector safe points; the collector could move the objects and invalidate the; derived pointer. This is bad enough in the first place, but safe points can; crop up unpredictably. Consider:. %array = load { i32, [0 x %obj] }** %array_addr; %nth_el = getelementptr { i32, [0 x %obj] }* %array, i32 0, i32 %n; %old = load %obj** %nth_el; %z = div i64 %x, %y; store %obj* %new, %obj** %nth_el. If the i64 division is lowered to a libcall, then a safe point will (must); appear for the call site. If a collection occurs, %array and %nth_el no longer; point into the correct object. The fix for this is to copy address calculations so that dependent pointers; are never live across safe point boundaries. But the loads cannot be copied; like this if there was an intervening store, so may be hard to get right. Only a concurrent mutator can trigger a collection at the libcall safe point.; So single-threaded programs do not have this requirement, even with a copying; collector. Still, LLVM optimizations would probably undo a front-end's careful; work. //===---------------------------------------------------------------------===//. The ocaml frametable structure supports liveness information. It would be good; to support it. //===---------------------------------------------------------------------===//. The FIXME in ComputeCommonTailLength in BranchFolding.cpp needs to be; revisited. The check is there to work around a misuse of directives in inline; assembly. //===---------------------------------------------------------------------===//. It would be good to detect collector/target compatibility instead of silently; doing the wrong thing. //===---------------------------------------------------------------------===//. It would be really nice to be able to write patterns in .td files for copies,; which would eliminate a bunch of e",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/README.txt:3599,concurren,concurrent,3599,interpreter/llvm-project/llvm/lib/CodeGen/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/README.txt,1,['concurren'],['concurrent']
Performance,"-------------------------------------------------------------------===//. clang -O3 -fno-exceptions currently compiles this code:. void f(char* a, int n) {; __builtin_memset(a, 0, n);; for (int i = 0; i < n; ++i); a[i] = 0;; }. into:. define void @_Z1fPci(i8* nocapture %a, i32 %n) nounwind {; entry:; %conv = sext i32 %n to i64; tail call void @llvm.memset.p0i8.i64(i8* %a, i8 0, i64 %conv, i32 1, i1 false); %cmp8 = icmp sgt i32 %n, 0; br i1 %cmp8, label %for.body.lr.ph, label %for.end. for.body.lr.ph: ; preds = %entry; %tmp10 = add i32 %n, -1; %tmp11 = zext i32 %tmp10 to i64; %tmp12 = add i64 %tmp11, 1; call void @llvm.memset.p0i8.i64(i8* %a, i8 0, i64 %tmp12, i32 1, i1 false); ret void. for.end: ; preds = %entry; ret void; }. This shouldn't need the ((zext (%n - 1)) + 1) game, and it should ideally fold; the two memset's together. The issue with the addition only occurs in 64-bit mode, and appears to be at; least partially caused by Scalar Evolution not keeping its cache updated: it; returns the ""wrong"" result immediately after indvars runs, but figures out the; expected result if it is run from scratch on IR resulting from running indvars. //===---------------------------------------------------------------------===//. clang -O3 -fno-exceptions currently compiles this code:. struct S {; unsigned short m1, m2;; unsigned char m3, m4;; };. void f(int N) {; std::vector<S> v(N);; extern void sink(void*); sink(&v);; }. into poor code for zero-initializing 'v' when N is >0. The problem is that; S is only 6 bytes, but each element is 8 byte-aligned. We generate a loop and; 4 stores on each iteration. If the struct were 8 bytes, this gets turned into; a memset. In order to handle this we have to:; A) Teach clang to generate metadata for memsets of structs that have holes in; them.; B) Teach clang to use such a memset for zero init of this struct (since it has; a hole), instead of doing elementwise zeroing. //===---------------------------------------------------------------",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/README.txt:59366,cache,cache,59366,interpreter/llvm-project/llvm/lib/Target/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/README.txt,2,['cache'],['cache']
Performance,"------------------------------------------------------------------===//. From GCC Bug 20192:; #define PMD_MASK (~((1UL << 23) - 1)); void clear_pmd_range(unsigned long start, unsigned long end); {; if (!(start & ~PMD_MASK) && !(end & ~PMD_MASK)); f();; }; The expression should optimize to something like; ""!((start|end)&~PMD_MASK). Currently not optimized with ""clang; -emit-llvm-bc | opt -O3"". //===---------------------------------------------------------------------===//. unsigned int f(unsigned int i, unsigned int n) {++i; if (i == n) ++i; return; i;}; unsigned int f2(unsigned int i, unsigned int n) {++i; i += i == n; return i;}; These should combine to the same thing. Currently, the first function; produces better code on X86. //===---------------------------------------------------------------------===//. From GCC Bug 15784:; #define abs(x) x>0?x:-x; int f(int x, int y); {; return (abs(x)) >= 0;; }; This should optimize to x == INT_MIN. (With -fwrapv.) Currently not; optimized with ""clang -emit-llvm-bc | opt -O3"". //===---------------------------------------------------------------------===//. From GCC Bug 14753:; void; rotate_cst (unsigned int a); {; a = (a << 10) | (a >> 22);; if (a == 123); bar ();; }; void; minus_cst (unsigned int a); {; unsigned int tem;. tem = 20 - a;; if (tem == 5); bar ();; }; void; mask_gt (unsigned int a); {; /* This is equivalent to a > 15. */; if ((a & ~7) > 8); bar ();; }; void; rshift_gt (unsigned int a); {; /* This is equivalent to a > 23. */; if ((a >> 2) > 5); bar ();; }. All should simplify to a single comparison. All of these are; currently not optimized with ""clang -emit-llvm-bc | opt; -O3"". //===---------------------------------------------------------------------===//. From GCC Bug 32605:; int c(int* x) {return (char*)x+2 == (char*)x;}; Should combine to 0. Currently not optimized with ""clang; -emit-llvm-bc | opt -O3"" (although llc can optimize it). //===---------------------------------------------------------------------==",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/README.txt:22623,optimiz,optimized,22623,interpreter/llvm-project/llvm/lib/Target/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/README.txt,2,['optimiz'],['optimized']
Performance,"-----------------------------------------------------------------; store atomic release - singlethread - global 1. buffer/global/ds/flat_store; - wavefront - local; - generic; store atomic release - workgroup - global 1. s_waitcnt lgkmcnt(0); - generic; - If OpenCL, omit.; - Must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; to local have; completed before; performing the; store that is being; released. 2. buffer/global/flat_store; store atomic release - workgroup - local 1. ds_store; store atomic release - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0). - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; to memory have; completed before; performing the; store that is being; released. 2. buffer/global/flat_store; atomicrmw release - singlethread - global 1. buffer/global/ds/flat_atomic; - wavefront - local; - generic; atomicrmw release - workgroup - global 1. s_waitcnt lgkmcnt(0); - generic; - If OpenCL, omit.; - Must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to local have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global/flat_atomic; atomicrmw release - workgroup - local 1. ds_atomic; atomicrmw release - agent - global 1. s_waitcnt lgkmcnt(0) &; -",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:219949,load,load,219949,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],['load']
Performance,"--------------------------------------------------------------===. int foo(int N, int ***W, int **TK, int X) {; int t, i;; ; for (t = 0; t < N; ++t); for (i = 0; i < 4; ++i); W[t / X][i][t % X] = TK[i][t];; ; return 5;; }. We generate relatively atrocious code for this loop compared to gcc. We could also strength reduce the rem and the div:; http://www.lcs.mit.edu/pubs/pdf/MIT-LCS-TM-600.pdf. ===-------------------------------------------------------------------------===. We generate ugly code for this:. void func(unsigned int *ret, float dx, float dy, float dz, float dw) {; unsigned code = 0;; if(dx < -dw) code |= 1;; if(dx > dw) code |= 2;; if(dy < -dw) code |= 4;; if(dy > dw) code |= 8;; if(dz < -dw) code |= 16;; if(dz > dw) code |= 32;; *ret = code;; }. ===-------------------------------------------------------------------------===. %struct.B = type { i8, [3 x i8] }. define void @bar(%struct.B* %b) {; entry:; %tmp = bitcast %struct.B* %b to i32* ; <uint*> [#uses=1]; %tmp = load i32* %tmp ; <uint> [#uses=1]; %tmp3 = bitcast %struct.B* %b to i32* ; <uint*> [#uses=1]; %tmp4 = load i32* %tmp3 ; <uint> [#uses=1]; %tmp8 = bitcast %struct.B* %b to i32* ; <uint*> [#uses=2]; %tmp9 = load i32* %tmp8 ; <uint> [#uses=1]; %tmp4.mask17 = shl i32 %tmp4, i8 1 ; <uint> [#uses=1]; %tmp1415 = and i32 %tmp4.mask17, 2147483648 ; <uint> [#uses=1]; %tmp.masked = and i32 %tmp, 2147483648 ; <uint> [#uses=1]; %tmp11 = or i32 %tmp1415, %tmp.masked ; <uint> [#uses=1]; %tmp12 = and i32 %tmp9, 2147483647 ; <uint> [#uses=1]; %tmp13 = or i32 %tmp12, %tmp11 ; <uint> [#uses=1]; store i32 %tmp13, i32* %tmp8; ret void; }. We emit:. _foo:; lwz r2, 0(r3); slwi r4, r2, 1; or r4, r4, r2; rlwimi r2, r4, 0, 0, 0; stw r2, 0(r3); blr. We could collapse a bunch of those ORs and ANDs and generate the following; equivalent code:. _foo:; lwz r2, 0(r3); rlwinm r4, r2, 1, 0, 0; or r2, r2, r4; stw r2, 0(r3); blr. ===-------------------------------------------------------------------------===. Consider a function ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/README.txt:5397,load,load,5397,interpreter/llvm-project/llvm/lib/Target/PowerPC/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/README.txt,2,['load'],['load']
Performance,"----------------------------------------------------------===//. Use local info (i.e. register scavenger) to assign it a free register to allow; reuse:; ldr r3, [sp, #+4]; add r3, r3, #3; ldr r2, [sp, #+8]; add r2, r2, #2; ldr r1, [sp, #+4] <==; add r1, r1, #1; ldr r0, [sp, #+4]; add r0, r0, #2. //===---------------------------------------------------------------------===//. LLVM aggressively lift CSE out of loop. Sometimes this can be negative side-; effects:. R1 = X + 4; R2 = X + 7; R3 = X + 15. loop:; load [i + R1]; ...; load [i + R2]; ...; load [i + R3]. Suppose there is high register pressure, R1, R2, R3, can be spilled. We need; to implement proper re-materialization to handle this:. R1 = X + 4; R2 = X + 7; R3 = X + 15. loop:; R1 = X + 4 @ re-materialized; load [i + R1]; ...; R2 = X + 7 @ re-materialized; load [i + R2]; ...; R3 = X + 15 @ re-materialized; load [i + R3]. Furthermore, with re-association, we can enable sharing:. R1 = X + 4; R2 = X + 7; R3 = X + 15. loop:; T = i + X; load [T + 4]; ...; load [T + 7]; ...; load [T + 15]; //===---------------------------------------------------------------------===//. It's not always a good idea to choose rematerialization over spilling. If all; the load / store instructions would be folded then spilling is cheaper because; it won't require new live intervals / registers. See 2003-05-31-LongShifts for; an example. //===---------------------------------------------------------------------===//. With a copying garbage collector, derived pointers must not be retained across; collector safe points; the collector could move the objects and invalidate the; derived pointer. This is bad enough in the first place, but safe points can; crop up unpredictably. Consider:. %array = load { i32, [0 x %obj] }** %array_addr; %nth_el = getelementptr { i32, [0 x %obj] }* %array, i32 0, i32 %n; %old = load %obj** %nth_el; %z = div i64 %x, %y; store %obj* %new, %obj** %nth_el. If the i64 division is lowered to a libcall, then a safe poin",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/README.txt:2240,load,load,2240,interpreter/llvm-project/llvm/lib/CodeGen/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/README.txt,1,['load'],['load']
Performance,"--------------------------------------------------------===//. We can definitely do a better job on BB placements to eliminate some branches.; It's very common to see llvm generated assembly code that looks like this:. LBB3:; ...; LBB4:; ...; beq LBB3; b LBB2. If BB4 is the only predecessor of BB3, then we can emit BB3 after BB4. We can; then eliminate beq and turn the unconditional branch to LBB2 to a bne. See McCat/18-imp/ComputeBoundingBoxes for an example. //===---------------------------------------------------------------------===//. Pre-/post- indexed load / stores:. 1) We should not make the pre/post- indexed load/store transform if the base ptr; is guaranteed to be live beyond the load/store. This can happen if the base; ptr is live out of the block we are performing the optimization. e.g. mov r1, r2; ldr r3, [r1], #4; ... vs. ldr r3, [r2]; add r1, r2, #4; ... In most cases, this is just a wasted optimization. However, sometimes it can; negatively impact the performance because two-address code is more restrictive; when it comes to scheduling. Unfortunately, liveout information is currently unavailable during DAG combine; time. 2) Consider spliting a indexed load / store into a pair of add/sub + load/store; to solve #1 (in TwoAddressInstructionPass.cpp). 3) Enhance LSR to generate more opportunities for indexed ops. 4) Once we added support for multiple result patterns, write indexed loads; patterns instead of C++ instruction selection code. 5) Use VLDM / VSTM to emulate indexed FP load / store. //===---------------------------------------------------------------------===//. Implement support for some more tricky ways to materialize immediates. For; example, to get 0xffff8000, we can use:. mov r9, #&3f8000; sub r9, r9, #&400000. //===---------------------------------------------------------------------===//. We sometimes generate multiple add / sub instructions to update sp in prologue; and epilogue if the inc / dec value is too large to fit in a single imm",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/README.txt:8629,perform,performance,8629,interpreter/llvm-project/llvm/lib/Target/ARM/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/README.txt,2,['perform'],['performance']
Performance,"-------------------------------------------------------===//. Consider the following simple C code:. void foo(unsigned char *a, unsigned char *b, int *c) {; if ((*a | *b) == 0) *c = 0;; }. currently llvm-gcc generates something like this (nice branchless code I'd say):. ldrb r0, [r0]; ldrb r1, [r1]; orr r0, r1, r0; tst r0, #255; moveq r0, #0; streq r0, [r2]; bx lr. Note that both ""tst"" and ""moveq"" are redundant. //===---------------------------------------------------------------------===//. When loading immediate constants with movt/movw, if there are multiple; constants needed with the same low 16 bits, and those values are not live at; the same time, it would be possible to use a single movw instruction, followed; by multiple movt instructions to rewrite the high bits to different values.; For example:. volatile store i32 -1, i32* inttoptr (i32 1342210076 to i32*), align 4,; !tbaa; !0; volatile store i32 -1, i32* inttoptr (i32 1342341148 to i32*), align 4,; !tbaa; !0. is compiled and optimized to:. movw r0, #32796; mov.w r1, #-1; movt r0, #20480; str r1, [r0]; movw r0, #32796 @ <= this MOVW is not needed, value is there already; movt r0, #20482; str r1, [r0]. //===---------------------------------------------------------------------===//. Improve codegen for select's:; if (x != 0) x = 1; if (x == 1) x = 1. ARM codegen used to look like this:; mov r1, r0; cmp r1, #1; mov r0, #0; moveq r0, #1. The naive lowering select between two different values. It should recognize the; test is equality test so it's more a conditional move rather than a select:; cmp r0, #1; movne r0, #0. Currently this is a ARM specific dag combine. We probably should make it into a; target-neutral one. //===---------------------------------------------------------------------===//. Optimize unnecessary checks for zero with __builtin_clz/ctz. Those builtins; are specified to be undefined at zero, so portable code must check for zero; and handle it as a special case. That is unnecessary on ARM whe",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/README.txt:19910,optimiz,optimized,19910,interpreter/llvm-project/llvm/lib/Target/ARM/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/README.txt,2,['optimiz'],['optimized']
Performance,"------------------------------------------------------===//. The hot loop of 256.bzip2 contains code that looks a bit like this:. int foo(char *P, char *Q, int x, int y) {; if (P[0] != Q[0]); return P[0] < Q[0];; if (P[1] != Q[1]); return P[1] < Q[1];; if (P[2] != Q[2]); return P[2] < Q[2];; return P[3] < Q[3];; }. In the real code, we get a lot more wrong than this. However, even in this; code we generate:. _foo: ## @foo; ## %bb.0: ## %entry; 	movb	(%rsi), %al; 	movb	(%rdi), %cl; 	cmpb	%al, %cl; 	je	LBB0_2; LBB0_1: ## %if.then; 	cmpb	%al, %cl; 	jmp	LBB0_5; LBB0_2: ## %if.end; 	movb	1(%rsi), %al; 	movb	1(%rdi), %cl; 	cmpb	%al, %cl; 	jne	LBB0_1; ## %bb.3: ## %if.end38; 	movb	2(%rsi), %al; 	movb	2(%rdi), %cl; 	cmpb	%al, %cl; 	jne	LBB0_1; ## %bb.4: ## %if.end60; 	movb	3(%rdi), %al; 	cmpb	3(%rsi), %al; LBB0_5: ## %if.end60; 	setl	%al; 	movzbl	%al, %eax; 	ret. Note that we generate jumps to LBB0_1 which does a redundant compare. The; redundant compare also forces the register values to be live, which prevents; folding one of the loads into the compare. In contrast, GCC 4.2 produces:. _foo:; 	movzbl	(%rsi), %eax; 	cmpb	%al, (%rdi); 	jne	L10; L12:; 	movzbl	1(%rsi), %eax; 	cmpb	%al, 1(%rdi); 	jne	L10; 	movzbl	2(%rsi), %eax; 	cmpb	%al, 2(%rdi); 	jne	L10; 	movzbl	3(%rdi), %eax; 	cmpb	3(%rsi), %al; L10:; 	setl	%al; 	movzbl	%al, %eax; 	ret. which is ""perfect"". //===---------------------------------------------------------------------===//. For the branch in the following code:; int a();; int b(int x, int y) {; if (x & (1<<(y&7))); return a();; return y;; }. We currently generate:; 	movb	%sil, %al; 	andb	$7, %al; 	movzbl	%al, %eax; 	btl	%eax, %edi; 	jae	.LBB0_2. movl+andl would be shorter than the movb+andb+movzbl sequence. //===---------------------------------------------------------------------===//. For the following:; struct u1 {; float x, y;; };; float foo(struct u1 u) {; return u.x + u.y;; }. We currently generate:; 	movdqa	%xmm0, %xmm1; 	pshufd	$1, %xmm0, %xmm0 # xmm0 = ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README.txt:40696,load,loads,40696,interpreter/llvm-project/llvm/lib/Target/X86/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README.txt,2,['load'],['loads']
Performance,"---------------------------------------------------===//. [LOAD PRE CRIT EDGE SPLITTING]. GCC PR37166: Sinking of loads prevents SROA'ing the ""g"" struct on the stack; leading to excess stack traffic. This could be handled by GVN with some crazy; symbolic phi translation. The code we get looks like (g is on the stack):. bb2:		; preds = %bb1; ..; 	%9 = getelementptr %struct.f* %g, i32 0, i32 0		; 	store i32 %8, i32* %9, align bel %bb3. bb3:		; preds = %bb1, %bb2, %bb; 	%c_addr.0 = phi %struct.f* [ %g, %bb2 ], [ %c, %bb ], [ %c, %bb1 ]; 	%b_addr.0 = phi %struct.f* [ %b, %bb2 ], [ %g, %bb ], [ %b, %bb1 ]; 	%10 = getelementptr %struct.f* %c_addr.0, i32 0, i32 0; 	%11 = load i32* %10, align 4. %11 is partially redundant, an in BB2 it should have the value %8. GCC PR33344 and PR35287 are similar cases. //===---------------------------------------------------------------------===//. [LOAD PRE]. There are many load PRE testcases in testsuite/gcc.dg/tree-ssa/loadpre* in the; GCC testsuite, ones we don't get yet are (checked through loadpre25):. [CRIT EDGE BREAKING]; predcom-4.c. [PRE OF READONLY CALL]; loadpre5.c. [TURN SELECT INTO BRANCH]; loadpre14.c loadpre15.c . actually a conditional increment: loadpre18.c loadpre19.c. //===---------------------------------------------------------------------===//. [LOAD PRE / STORE SINKING / SPEC HACK]. This is a chunk of code from 456.hmmer:. int f(int M, int *mc, int *mpp, int *tpmm, int *ip, int *tpim, int *dpp,; int *tpdm, int xmb, int *bp, int *ms) {; int k, sc;; for (k = 1; k <= M; k++) {; mc[k] = mpp[k-1] + tpmm[k-1];; if ((sc = ip[k-1] + tpim[k-1]) > mc[k]) mc[k] = sc;; if ((sc = dpp[k-1] + tpdm[k-1]) > mc[k]) mc[k] = sc;; if ((sc = xmb + bp[k]) > mc[k]) mc[k] = sc;; mc[k] += ms[k];; }; }. It is very profitable for this benchmark to turn the conditional stores to mc[k]; into a conditional move (select instr in IR) and allow the final store to do the; store. See GCC PR27313 for more details. Note that this is valid to xform even; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/README.txt:33479,load,loadpre,33479,interpreter/llvm-project/llvm/lib/Target/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/README.txt,2,['load'],['loadpre']
Performance,"--------------------------------------------------; store atomic release - singlethread - global 1. buffer/global/ds/flat_store; - wavefront - local; - generic; store atomic release - workgroup - global 1. s_waitcnt lgkmcnt(0) &; - generic vmcnt(0) & vscnt(0). - If CU wavefront execution; mode, omit vmcnt(0) and; vscnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0), s_waitcnt; vscnt(0) and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/load; atomic/; atomicrmw-with-return-value.; - s_waitcnt vscnt(0); must happen after; any preceding; global/generic; store/store; atomic/; atomicrmw-no-return-value.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; have; completed before; performing the; store that is being; released. 2. buffer/global/flat_store; store atomic release - workgroup - local 1. s_waitcnt vmcnt(0) & vscnt(0). - If CU wavefront execution; mode, omit.; - If OpenCL, omit.; - Could be split into; separate s_waitcnt; vmcnt(0) and s_waitcnt; vscnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/load; atomic/; atomicrmw-with-return-value.; - s_waitcnt vscnt(0); must happen after; any preceding; global/generic; store/store atomic/; atomicrmw-no-return-value.; - Must happen before; the following; store.; - Ensures that all; global memory; operations have; completed before; performing the; store that is being; released. 2. ds_store; store atomic release - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0) & vscnt(0). - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - Could be split into; separate s_",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:355722,perform,performing,355722,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['perform'],['performing']
Performance,"-------------------------------------------------===//. Implement long long ""X-3"" with instructions that fold the immediate in. These; were disabled due to badness with the ARM carry flag on subtracts. //===---------------------------------------------------------------------===//. More load / store optimizations:; 1) Better representation for block transfer? This is from Olden/power:. 	fldd d0, [r4]; 	fstd d0, [r4, #+32]; 	fldd d0, [r4, #+8]; 	fstd d0, [r4, #+40]; 	fldd d0, [r4, #+16]; 	fstd d0, [r4, #+48]; 	fldd d0, [r4, #+24]; 	fstd d0, [r4, #+56]. If we can spare the registers, it would be better to use fldm and fstm here.; Need major register allocator enhancement though. 2) Can we recognize the relative position of constantpool entries? i.e. Treat. 	ldr r0, LCPI17_3; 	ldr r1, LCPI17_4; 	ldr r2, LCPI17_5. as; 	ldr r0, LCPI17; 	ldr r1, LCPI17+4; 	ldr r2, LCPI17+8. Then the ldr's can be combined into a single ldm. See Olden/power. Note for ARM v4 gcc uses ldmia to load a pair of 32-bit values to represent a; double 64-bit FP constant:. 	adr	r0, L6; 	ldmia	r0, {r0-r1}. 	.align 2; L6:; 	.long	-858993459; 	.long	1074318540. 3) struct copies appear to be done field by field; instead of by words, at least sometimes:. struct foo { int x; short s; char c1; char c2; };; void cpy(struct foo*a, struct foo*b) { *a = *b; }. llvm code (-O2); ldrb r3, [r1, #+6]; ldr r2, [r1]; ldrb r12, [r1, #+7]; ldrh r1, [r1, #+4]; str r2, [r0]; strh r1, [r0, #+4]; strb r3, [r0, #+6]; strb r12, [r0, #+7]; gcc code (-O2); ldmia r1, {r1-r2}; stmia r0, {r1-r2}. In this benchmark poor handling of aggregate copies has shown up as; having a large effect on size, and possibly speed as well (we don't have; a good way to measure on ARM). //===---------------------------------------------------------------------===//. * Consider this silly example:. double bar(double x) {; double r = foo(3.1);; return x+r;; }. _bar:; stmfd sp!, {r4, r5, r7, lr}; add r7, sp, #8; mov r4, r0; mov r5, r1; fldd d0, LCPI1_0; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/README.txt:3517,load,load,3517,interpreter/llvm-project/llvm/lib/Target/ARM/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/README.txt,2,['load'],['load']
Performance,"------------------------------------------------===//. We compile this:. void compare (long long foo) {; if (foo < 4294967297LL); abort();; }. to:. compare:; subl $4, %esp; cmpl $0, 8(%esp); setne %al; movzbw %al, %ax; cmpl $1, 12(%esp); setg %cl; movzbw %cl, %cx; cmove %ax, %cx; testb $1, %cl; jne .LBB1_2 # UnifiedReturnBlock; .LBB1_1: # ifthen; call abort; .LBB1_2: # UnifiedReturnBlock; addl $4, %esp; ret. (also really horrible code on ppc). This is due to the expand code for 64-bit; compares. GCC produces multiple branches, which is much nicer:. compare:; subl $12, %esp; movl 20(%esp), %edx; movl 16(%esp), %eax; decl %edx; jle .L7; .L5:; addl $12, %esp; ret; .p2align 4,,7; .L7:; jl .L4; cmpl $0, %eax; .p2align 4,,8; ja .L5; .L4:; .p2align 4,,9; call abort. //===---------------------------------------------------------------------===//. Tail call optimization improvements: Tail call optimization currently; pushes all arguments on the top of the stack (their normal place for; non-tail call optimized calls) that source from the callers arguments; or that source from a virtual register (also possibly sourcing from; callers arguments).; This is done to prevent overwriting of parameters (see example; below) that might be used later. example: . int callee(int32, int64); ; int caller(int32 arg1, int32 arg2) { ; int64 local = arg2 * 2; ; return callee(arg2, (int64)local); ; }. [arg1] [!arg2 no longer valid since we moved local onto it]; [arg2] -> [(int64); [RETADDR] local ]. Moving arg1 onto the stack slot of callee function would overwrite; arg2 of the caller. Possible optimizations:. - Analyse the actual parameters of the callee to see which would; overwrite a caller parameter which is used by the callee and only; push them onto the top of the stack. int callee (int32 arg1, int32 arg2);; int caller (int32 arg1, int32 arg2) {; return callee(arg1,arg2);; }. Here we don't need to write any variables to the top of the stack; since they don't overwrite each other. int callee ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README.txt:17998,optimiz,optimization,17998,interpreter/llvm-project/llvm/lib/Target/X86/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README.txt,6,['optimiz'],"['optimization', 'optimized']"
Performance,"------------------------------------------------===//. [ALIAS ANALYSIS]. Type based alias analysis:; http://gcc.gnu.org/bugzilla/show_bug.cgi?id=14705. We should do better analysis of posix_memalign. At the least it should; no-capture its pointer argument, at best, we should know that the out-value; result doesn't point to anything (like malloc). One example of this is in; SingleSource/Benchmarks/Misc/dt.c. //===---------------------------------------------------------------------===//. Interesting missed case because of control flow flattening (should be 2 loads):; http://gcc.gnu.org/bugzilla/show_bug.cgi?id=26629; With: llvm-gcc t2.c -S -o - -O0 -emit-llvm | llvm-as | ; opt -mem2reg -gvn -instcombine | llvm-dis; we miss it because we need 1) CRIT EDGE 2) MULTIPLE DIFFERENT; VALS PRODUCED BY ONE BLOCK OVER DIFFERENT PATHS. //===---------------------------------------------------------------------===//. http://gcc.gnu.org/bugzilla/show_bug.cgi?id=19633; We could eliminate the branch condition here, loading from null is undefined:. struct S { int w, x, y, z; };; struct T { int r; struct S s; };; void bar (struct S, int);; void foo (int a, struct T b); {; struct S *c = 0;; if (a); c = &b.s;; bar (*c, a);; }. //===---------------------------------------------------------------------===//. simplifylibcalls should do several optimizations for strspn/strcspn:. strcspn(x, ""a"") -> inlined loop for up to 3 letters (similarly for strspn):. size_t __strcspn_c3 (__const char *__s, int __reject1, int __reject2,; int __reject3) {; register size_t __result = 0;; while (__s[__result] != '\0' && __s[__result] != __reject1 &&; __s[__result] != __reject2 && __s[__result] != __reject3); ++__result;; return __result;; }. This should turn into a switch on the character. See PR3253 for some notes on; codegen. 456.hmmer apparently uses strcspn and strspn a lot. 471.omnetpp uses strspn. //===---------------------------------------------------------------------===//. simplifylibcalls should ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/README.txt:36486,load,loading,36486,interpreter/llvm-project/llvm/lib/Target/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/README.txt,2,['load'],['loading']
Performance,"------------------------------------------===//. Given the following C code:; int f(int a, int b) { return (signed char)a == (signed char)b; }. We generate the following IR with clang:; define i32 @f(i32 %a, i32 %b) nounwind readnone {; entry:; %sext = shl i32 %a, 24 ; <i32> [#uses=1]; %conv1 = ashr i32 %sext, 24 ; <i32> [#uses=1]; %sext6 = shl i32 %b, 24 ; <i32> [#uses=1]; %conv4 = ashr i32 %sext6, 24 ; <i32> [#uses=1]; %cmp = icmp eq i32 %conv1, %conv4 ; <i1> [#uses=1]; %conv5 = zext i1 %cmp to i32 ; <i32> [#uses=1]; ret i32 %conv5; }. And the following x86 code:; 	movsbl	%sil, %eax; 	movsbl	%dil, %ecx; 	cmpl	%eax, %ecx; 	sete	%al; 	movzbl	%al, %eax; 	ret. It should be possible to eliminate the sign extensions. //===---------------------------------------------------------------------===//. LLVM misses a load+store narrowing opportunity in this code:. %struct.bf = type { i64, i16, i16, i32 }. @bfi = external global %struct.bf* ; <%struct.bf**> [#uses=2]. define void @t1() nounwind ssp {; entry:; %0 = load %struct.bf** @bfi, align 8 ; <%struct.bf*> [#uses=1]; %1 = getelementptr %struct.bf* %0, i64 0, i32 1 ; <i16*> [#uses=1]; %2 = bitcast i16* %1 to i32* ; <i32*> [#uses=2]; %3 = load i32* %2, align 1 ; <i32> [#uses=1]; %4 = and i32 %3, -65537 ; <i32> [#uses=1]; store i32 %4, i32* %2, align 1; %5 = load %struct.bf** @bfi, align 8 ; <%struct.bf*> [#uses=1]; %6 = getelementptr %struct.bf* %5, i64 0, i32 1 ; <i16*> [#uses=1]; %7 = bitcast i16* %6 to i32* ; <i32*> [#uses=2]; %8 = load i32* %7, align 1 ; <i32> [#uses=1]; %9 = and i32 %8, -131073 ; <i32> [#uses=1]; store i32 %9, i32* %7, align 1; ret void; }. LLVM currently emits this:. movq bfi(%rip), %rax; andl $-65537, 8(%rax); movq bfi(%rip), %rax; andl $-131073, 8(%rax); ret. It could narrow the loads and stores to emit this:. movq bfi(%rip), %rax; andb $-2, 10(%rax); movq bfi(%rip), %rax; andb $-3, 10(%rax); ret. The trouble is that there is a TokenFactor between the store and the; load, making it non-trivial to dete",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README.txt:37476,load,load,37476,interpreter/llvm-project/llvm/lib/Target/X86/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README.txt,2,['load'],['load']
Performance,"-----------------------------------------===//. WebAssembly registers are implicitly initialized to zero. Explicit zeroing is; therefore often redundant and could be optimized away. //===---------------------------------------------------------------------===//. Small indices may use smaller encodings than large indices.; WebAssemblyRegColoring and/or WebAssemblyRegRenumbering should sort registers; according to their usage frequency to maximize the usage of smaller encodings. //===---------------------------------------------------------------------===//. Many cases of irreducible control flow could be transformed more optimally; than via the transform in WebAssemblyFixIrreducibleControlFlow.cpp. It may also be worthwhile to do transforms before register coloring,; particularly when duplicating code, to allow register coloring to be aware of; the duplication. //===---------------------------------------------------------------------===//. WebAssemblyRegStackify could use AliasAnalysis to reorder loads and stores more; aggressively. //===---------------------------------------------------------------------===//. WebAssemblyRegStackify is currently a greedy algorithm. This means that, for; example, a binary operator will stackify with its user before its operands.; However, if moving the binary operator to its user moves it to a place where; its operands can't be moved to, it would be better to leave it in place, or; perhaps move it up, so that it can stackify its operands. A binary operator; has two operands and one result, so in such cases there could be a net win by; preferring the operands. //===---------------------------------------------------------------------===//. Instruction ordering has a significant influence on register stackification and; coloring. Consider experimenting with the MachineScheduler (enable via; enableMachineScheduler) and determine if it can be configured to schedule; instructions advantageously for this purpose. //===--------------------",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/WebAssembly/README.txt:5184,load,loads,5184,interpreter/llvm-project/llvm/lib/Target/WebAssembly/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/WebAssembly/README.txt,2,['load'],['loads']
Performance,"----------------------------------------. Some collectors need to be informed when the mutator (the program that needs; garbage collection) either reads a pointer from or writes a pointer to a field; of a heap object. The code fragments inserted at these points are called *read; barriers* and *write barriers*, respectively. The amount of code that needs to; be executed is usually quite small and not on the critical path of any; computation, so the overall performance impact of the barrier is tolerable. Barriers often require access to the *object pointer* rather than the *derived; pointer* (which is a pointer to the field within the object). Accordingly,; these intrinsics take both pointers as separate arguments for completeness. In; this snippet, ``%object`` is the object pointer, and ``%derived`` is the derived; pointer:. .. code-block:: llvm. ;; An array type.; %class.Array = type { %class.Object, i32, [0 x %class.Object*] }; ... ;; Load the object pointer from a gcroot.; %object = load %class.Array** %object_addr. ;; Compute the derived pointer.; %derived = getelementptr %object, i32 0, i32 2, i32 %n. LLVM does not enforce this relationship between the object and derived pointer; (although a particular :ref:`collector strategy <plugin>` might). However, it; would be an unusual collector that violated it. The use of these intrinsics is naturally optional if the target GC does not; require the corresponding barrier. The GC strategy used with such a collector; should replace the intrinsic calls with the corresponding ``load`` or; ``store`` instruction if they are used. One known deficiency with the current design is that the barrier intrinsics do; not include the size or alignment of the underlying operation performed. It is; currently assumed that the operation is of pointer size and the alignment is; assumed to be the target machine's default alignment. Write barrier: ``llvm.gcwrite``; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: llvm. void @llvm.gcwrite(i8* ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst:13744,load,load,13744,interpreter/llvm-project/llvm/docs/GarbageCollection.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst,1,['load'],['load']
Performance,"--------------------------------------. Clang can be provided with inputs written in non-C-family languages. In such; cases, an external tool will be used to compile the input. The; currently-supported languages are:. * Ada (``-x ada``, ``.ad[bs]``); * Fortran (``-x f95``, ``.f``, ``.f9[05]``, ``.for``, ``.fpp``, case-insensitive); * Java (``-x java``). In each case, GCC will be invoked to compile the input. Assembler; ---------. Clang can either use LLVM's integrated assembler or an external system-specific; tool (for instance, the GNU Assembler on GNU OSes) to produce machine code from; assembly.; By default, Clang uses LLVM's integrated assembler on all targets where it is; supported. If you wish to use the system assembler instead, use the; ``-fno-integrated-as`` option. Linker; ------. Clang can be configured to use one of several different linkers:. * GNU ld; * GNU gold; * LLVM's `lld <https://lld.llvm.org>`_; * MSVC's link.exe. Link-time optimization is natively supported by lld, and supported via; a `linker plugin <https://llvm.org/docs/GoldPlugin.html>`_ when using gold. The default linker varies between targets, and can be overridden via the; ``-fuse-ld=<linker name>`` flag. Runtime libraries; =================. A number of different runtime libraries are required to provide different; layers of support for C family programs. Clang will implicitly link an; appropriate implementation of each runtime library, selected based on; target defaults or explicitly selected by the ``--rtlib=`` and ``--stdlib=``; flags. The set of implicitly-linked libraries depend on the language mode. As a; consequence, you should use ``clang++`` when linking C++ programs in order; to ensure the C++ runtimes are provided. .. note::. There may exist other implementations for these components not described; below. Please let us know how well those other implementations work with; Clang so they can be added to this list!. .. FIXME: Describe Objective-C runtime libraries; .. FIXME: Des",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Toolchain.rst:4441,optimiz,optimization,4441,interpreter/llvm-project/clang/docs/Toolchain.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Toolchain.rst,1,['optimiz'],['optimization']
Performance,"--------------------------------------===//. Pre-/post- indexed load / stores:. 1) We should not make the pre/post- indexed load/store transform if the base ptr; is guaranteed to be live beyond the load/store. This can happen if the base; ptr is live out of the block we are performing the optimization. e.g. mov r1, r2; ldr r3, [r1], #4; ... vs. ldr r3, [r2]; add r1, r2, #4; ... In most cases, this is just a wasted optimization. However, sometimes it can; negatively impact the performance because two-address code is more restrictive; when it comes to scheduling. Unfortunately, liveout information is currently unavailable during DAG combine; time. 2) Consider spliting a indexed load / store into a pair of add/sub + load/store; to solve #1 (in TwoAddressInstructionPass.cpp). 3) Enhance LSR to generate more opportunities for indexed ops. 4) Once we added support for multiple result patterns, write indexed loads; patterns instead of C++ instruction selection code. 5) Use VLDM / VSTM to emulate indexed FP load / store. //===---------------------------------------------------------------------===//. Implement support for some more tricky ways to materialize immediates. For; example, to get 0xffff8000, we can use:. mov r9, #&3f8000; sub r9, r9, #&400000. //===---------------------------------------------------------------------===//. We sometimes generate multiple add / sub instructions to update sp in prologue; and epilogue if the inc / dec value is too large to fit in a single immediate; operand. In some cases, perhaps it might be better to load the value from a; constantpool instead. //===---------------------------------------------------------------------===//. GCC generates significantly better code for this function. int foo(int StackPtr, unsigned char *Line, unsigned char *Stack, int LineLen) {; int i = 0;. if (StackPtr != 0) {; while (StackPtr != 0 && i < (((LineLen) < (32768))? (LineLen) : (32768))); Line[i++] = Stack[--StackPtr];; if (LineLen > 32768); {; while (S",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/README.txt:9163,load,load,9163,interpreter/llvm-project/llvm/lib/Target/ARM/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/README.txt,2,['load'],['load']
Performance,"---------------------------------; load atomic acquire - singlethread - global 1. buffer/global/ds/flat_load; - wavefront - local; - generic; load atomic acquire - workgroup - global 1. buffer/global_load glc=1. - If not TgSplit execution; mode, omit glc=1. 2. s_waitcnt vmcnt(0). - If not TgSplit execution; mode, omit.; - Must happen before the; following buffer_wbinvl1_vol. 3. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale data. load atomic acquire - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_load; 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than the local load; atomic value being; acquired. load atomic acquire - workgroup - generic 1. flat_load glc=1. - If not TgSplit execution; mode, omit glc=1. 2. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit lgkmcnt(0).; - Must happen before; the following; buffer_wbinvl1_vol and any; following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic value being; acquired. 3. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. load atomic acquire - agent - global 1. buffer/global_load; glc=1; 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the load; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale global data. load atomic ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:246132,load,load,246132,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['load']
Performance,"-------------------------------===//. Use local info (i.e. register scavenger) to assign it a free register to allow; reuse:; ldr r3, [sp, #+4]; add r3, r3, #3; ldr r2, [sp, #+8]; add r2, r2, #2; ldr r1, [sp, #+4] <==; add r1, r1, #1; ldr r0, [sp, #+4]; add r0, r0, #2. //===---------------------------------------------------------------------===//. LLVM aggressively lift CSE out of loop. Sometimes this can be negative side-; effects:. R1 = X + 4; R2 = X + 7; R3 = X + 15. loop:; load [i + R1]; ...; load [i + R2]; ...; load [i + R3]. Suppose there is high register pressure, R1, R2, R3, can be spilled. We need; to implement proper re-materialization to handle this:. R1 = X + 4; R2 = X + 7; R3 = X + 15. loop:; R1 = X + 4 @ re-materialized; load [i + R1]; ...; R2 = X + 7 @ re-materialized; load [i + R2]; ...; R3 = X + 15 @ re-materialized; load [i + R3]. Furthermore, with re-association, we can enable sharing:. R1 = X + 4; R2 = X + 7; R3 = X + 15. loop:; T = i + X; load [T + 4]; ...; load [T + 7]; ...; load [T + 15]; //===---------------------------------------------------------------------===//. It's not always a good idea to choose rematerialization over spilling. If all; the load / store instructions would be folded then spilling is cheaper because; it won't require new live intervals / registers. See 2003-05-31-LongShifts for; an example. //===---------------------------------------------------------------------===//. With a copying garbage collector, derived pointers must not be retained across; collector safe points; the collector could move the objects and invalidate the; derived pointer. This is bad enough in the first place, but safe points can; crop up unpredictably. Consider:. %array = load { i32, [0 x %obj] }** %array_addr; %nth_el = getelementptr { i32, [0 x %obj] }* %array, i32 0, i32 %n; %old = load %obj** %nth_el; %z = div i64 %x, %y; store %obj* %new, %obj** %nth_el. If the i64 division is lowered to a libcall, then a safe point will (must); appear for th",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/README.txt:2259,load,load,2259,interpreter/llvm-project/llvm/lib/CodeGen/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/README.txt,1,['load'],['load']
Performance,"------------------------------===//. Make sure the instruction which starts a loop does not cross a cacheline; boundary. This requires knowning the exact length of each machine instruction.; That is somewhat complicated, but doable. Example 256.bzip2:. In the new trace, the hot loop has an instruction which crosses a cacheline; boundary. In addition to potential cache misses, this can't help decoding as I; imagine there has to be some kind of complicated decoder reset and realignment; to grab the bytes from the next cacheline. 532 532 0x3cfc movb (1809(%esp, %esi), %bl <<<--- spans 2 64 byte lines; 942 942 0x3d03 movl %dh, (1809(%esp, %esi); 937 937 0x3d0a incl %esi; 3 3 0x3d0b cmpb %bl, %dl; 27 27 0x3d0d jnz 0x000062db <main+11707>. //===---------------------------------------------------------------------===//. In c99 mode, the preprocessor doesn't like assembly comments like #TRUNCATE. //===---------------------------------------------------------------------===//. This could be a single 16-bit load. int f(char *p) {; if ((p[0] == 1) & (p[1] == 2)) return 1;; return 0;; }. //===---------------------------------------------------------------------===//. We should inline lrintf and probably other libc functions. //===---------------------------------------------------------------------===//. This code:. void test(int X) {; if (X) abort();; }. is currently compiled to:. _test:; subl $12, %esp; cmpl $0, 16(%esp); jne LBB1_1; addl $12, %esp; ret; LBB1_1:; call L_abort$stub. It would be better to produce:. _test:; subl $12, %esp; cmpl $0, 16(%esp); jne L_abort$stub; addl $12, %esp; ret. This can be applied to any no-return function call that takes no arguments etc.; Alternatively, the stack save/restore logic could be shrink-wrapped, producing; something like this:. _test:; cmpl $0, 4(%esp); jne LBB1_1; ret; LBB1_1:; subl $12, %esp; call L_abort$stub. Both are useful in different situations. Finally, it could be shrink-wrapped; and tail called, like this:. _test:; cmpl",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README.txt:11435,load,load,11435,interpreter/llvm-project/llvm/lib/Target/X86/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README.txt,2,['load'],['load']
Performance,"----------------------------; .. _parallelism:. By default, the ThinLTO link step will launch as many; threads in parallel as there are cores. If the number of; cores can't be computed for the architecture, then it will launch; ``std::thread::hardware_concurrency`` number of threads in parallel.; For machines with hyper-threading, this is the total number of; virtual cores. For some applications and machine configurations this; may be too aggressive, in which case the amount of parallelism can; be reduced to ``N`` via:. - gold:; ``-Wl,-plugin-opt,jobs=N``; - ld64:; ``-Wl,-mllvm,-threads=N``; - ld.lld, ld64.lld:; ``-Wl,--thinlto-jobs=N``; - lld-link:; ``/opt:lldltojobs=N``. Other possible values for ``N`` are:. - 0:; Use one thread per physical core (default); - 1:; Use a single thread only (disable multi-threading); - all:; Use one thread per logical core (uses all hyper-threads). Incremental; -----------; .. _incremental:. ThinLTO supports fast incremental builds through the use of a cache,; which currently must be enabled through a linker option. - gold (as of LLVM 4.0):; ``-Wl,-plugin-opt,cache-dir=/path/to/cache``; - ld64 (supported since clang 3.9 and Xcode 8) and Mach-O ld64.lld (as of LLVM; 15.0):; ``-Wl,-cache_path_lto,/path/to/cache``; - ELF ld.lld (as of LLVM 5.0):; ``-Wl,--thinlto-cache-dir=/path/to/cache``; - COFF lld-link (as of LLVM 6.0):; ``/lldltocache:/path/to/cache``. Cache Pruning; -------------. To help keep the size of the cache under control, ThinLTO supports cache; pruning. Cache pruning is supported with gold, ld64, and lld, but currently only; gold and lld allow you to control the policy with a policy string. The cache; policy must be specified with a linker option. - gold (as of LLVM 6.0):; ``-Wl,-plugin-opt,cache-policy=POLICY``; - ELF ld.lld (as of LLVM 5.0), Mach-O ld64.lld (as of LLVM 15.0):; ``-Wl,--thinlto-cache-policy=POLICY``; - COFF lld-link (as of LLVM 6.0):; ``/lldltocachepolicy:POLICY``. A policy string is a series of key-value p",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ThinLTO.rst:4634,cache,cache,4634,interpreter/llvm-project/clang/docs/ThinLTO.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ThinLTO.rst,1,['cache'],['cache']
Performance,"----------------------------===//. Evaluate what the best way to codegen sdiv X, (2^C) is. For X/8, we currently; get this:. define i32 @test1(i32 %X) {; %Y = sdiv i32 %X, 8; ret i32 %Y; }. _test1:; movl 4(%esp), %eax; movl %eax, %ecx; sarl $31, %ecx; shrl $29, %ecx; addl %ecx, %eax; sarl $3, %eax; ret. GCC knows several different ways to codegen it, one of which is this:. _test1:; movl 4(%esp), %eax; cmpl $-1, %eax; leal 7(%eax), %ecx; cmovle %ecx, %eax; sarl $3, %eax; ret. which is probably slower, but it's interesting at least :). //===---------------------------------------------------------------------===//. We are currently lowering large (1MB+) memmove/memcpy to rep/stosl and rep/movsl; We should leave these as libcalls for everything over a much lower threshold,; since libc is hand tuned for medium and large mem ops (avoiding RFO for large; stores, TLB preheating, etc). //===---------------------------------------------------------------------===//. Optimize this into something reasonable:; x * copysign(1.0, y) * copysign(1.0, z). //===---------------------------------------------------------------------===//. Optimize copysign(x, *y) to use an integer load from y. //===---------------------------------------------------------------------===//. The following tests perform worse with LSR:. lambda, siod, optimizer-eval, ackermann, hash2, nestedloop, strcat, and Treesor. //===---------------------------------------------------------------------===//. Adding to the list of cmp / test poor codegen issues:. int test(__m128 *A, __m128 *B) {; if (_mm_comige_ss(*A, *B)); return 3;; else; return 4;; }. _test:; 	movl 8(%esp), %eax; 	movaps (%eax), %xmm0; 	movl 4(%esp), %eax; 	movaps (%eax), %xmm1; 	comiss %xmm0, %xmm1; 	setae %al; 	movzbl %al, %ecx; 	movl $3, %eax; 	movl $4, %edx; 	cmpl $0, %ecx; 	cmove %edx, %eax; 	ret. Note the setae, movzbl, cmpl, cmove can be replaced with a single cmovae. There; are a number of issues. 1) We are introducing a setcc between the res",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README.txt:5139,Optimiz,Optimize,5139,interpreter/llvm-project/llvm/lib/Target/X86/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README.txt,1,['Optimiz'],['Optimize']
Performance,"---------------------------. This builtin function stores a value in a WebAssembly table.; It takes three arguments.; The first argument is the table to store a value into, the second; argument is the index to which to store the value into, and the; third argument is a value of reference type to store in the table.; It returns nothing. .. code-block:: c++. static __externref_t table[0];; extern __externref_t JSObj;. void store(int index) {; __builtin_wasm_table_set(table, index, JSObj);; }. ``__builtin_wasm_table_get``; ----------------------------. This builtin function is the counterpart to ``__builtin_wasm_table_set``; and loads a value from a WebAssembly table of reference typed values.; It takes 2 arguments.; The first argument is a table of reference typed values and the; second argument is an index from which to load the value. It returns; the loaded reference typed value. .. code-block:: c++. static __externref_t table[0];. __externref_t load(int index) {; __externref_t Obj = __builtin_wasm_table_get(table, index);; return Obj;; }. ``__builtin_wasm_table_size``; -----------------------------. This builtin function returns the size of the WebAssembly table.; Takes the table as an argument and returns an unsigned integer (``size_t``); with the current table size. .. code-block:: c++. typedef void (*__funcref funcref_t)();; static __funcref table[0];. size_t getSize() {; return __builtin_wasm_table_size(table);; }. ``__builtin_wasm_table_grow``; -----------------------------. This builtin function grows the WebAssembly table by a certain amount.; Currently, as all WebAssembly tables created in C/C++ are zero-sized,; this always needs to be called to grow the table. It takes three arguments. The first argument is the WebAssembly table; to grow. The second argument is the reference typed value to store in; the new table entries (the initialization value), and the third argument; is the amount to grow the table by. It returns the previous table size; or -1. It wil",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst:92991,load,load,92991,interpreter/llvm-project/clang/docs/LanguageExtensions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst,1,['load'],['load']
Performance,"--------------------------. For most target platforms, half precision floating-point is a; storage-only format. This means that it is a dense encoding (in memory); but does not support computation in the format. This means that code must first load the half-precision floating-point; value as an i16, then convert it to float with; :ref:`llvm.convert.from.fp16 <int_convert_from_fp16>`. Computation can; then be performed on the float value (including extending to double; etc). To store the value back to memory, it is first converted to float; if needed, then converted to i16 with; :ref:`llvm.convert.to.fp16 <int_convert_to_fp16>`, then storing as an; i16 value. .. _int_convert_to_fp16:. '``llvm.convert.to.fp16``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i16 @llvm.convert.to.fp16.f32(float %a); declare i16 @llvm.convert.to.fp16.f64(double %a). Overview:; """""""""""""""""". The '``llvm.convert.to.fp16``' intrinsic function performs a conversion from a; conventional floating-point type to half precision floating-point format. Arguments:; """""""""""""""""""". The intrinsic function contains single argument - the value to be; converted. Semantics:; """""""""""""""""""". The '``llvm.convert.to.fp16``' intrinsic function performs a conversion from a; conventional floating-point format to half precision floating-point format. The; return value is an ``i16`` which contains the converted number. Examples:; """""""""""""""""". .. code-block:: llvm. %res = call i16 @llvm.convert.to.fp16.f32(float %a); store i16 %res, i16* @x, align 2. .. _int_convert_from_fp16:. '``llvm.convert.from.fp16``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare float @llvm.convert.from.fp16.f32(i16 %a); declare double @llvm.convert.from.fp16.f64(i16 %a). Overview:; """""""""""""""""". The '``llvm.convert.from.fp16``' intrinsic function performs a; conversion from half precision floating-point format to single precision; floating-point format. Arguments:; """""""""""""""""""". The intrinsi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:681744,perform,performs,681744,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['performs']
Performance,"----------------------===//. These should turn into single 16-bit (unaligned?) loads on little/big endian; processors. unsigned short read_16_le(const unsigned char *adr) {; return adr[0] | (adr[1] << 8);; }; unsigned short read_16_be(const unsigned char *adr) {; return (adr[0] << 8) | adr[1];; }. //===---------------------------------------------------------------------===//. -instcombine should handle this transform:; icmp pred (sdiv X / C1 ), C2; when X, C1, and C2 are unsigned. Similarly for udiv and signed operands. . Currently InstCombine avoids this transform but will do it when the signs of; the operands and the sign of the divide match. See the FIXME in ; InstructionCombining.cpp in the visitSetCondInst method after the switch case ; for Instruction::UDiv (around line 4447) for more details. The SingleSource/Benchmarks/Shootout-C++/hash and hash2 tests have examples of; this construct. . //===---------------------------------------------------------------------===//. [LOOP OPTIMIZATION]. SingleSource/Benchmarks/Misc/dt.c shows several interesting optimization; opportunities in its double_array_divs_variable function: it needs loop; interchange, memory promotion (which LICM already does), vectorization and; variable trip count loop unrolling (since it has a constant trip count). ICC; apparently produces this very nice code with -ffast-math:. ..B1.70: # Preds ..B1.70 ..B1.69; mulpd %xmm0, %xmm1 #108.2; mulpd %xmm0, %xmm1 #108.2; mulpd %xmm0, %xmm1 #108.2; mulpd %xmm0, %xmm1 #108.2; addl $8, %edx #; cmpl $131072, %edx #108.2; jb ..B1.70 # Prob 99% #108.2. It would be better to count down to zero, but this is a lot better than what we; do. //===---------------------------------------------------------------------===//. Consider:. typedef unsigned U32;; typedef unsigned long long U64;; int test (U32 *inst, U64 *regs) {; U64 effective_addr2;; U32 temp = *inst;; int r1 = (temp >> 20) & 0xf;; int b2 = (temp >> 16) & 0xf;; effective_addr2 = temp & 0xfff;; if (b2) eff",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/README.txt:8250,OPTIMIZ,OPTIMIZATION,8250,interpreter/llvm-project/llvm/lib/Target/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/README.txt,1,['OPTIMIZ'],['OPTIMIZATION']
Performance,"---------------------. If you encounter a bug that leads to crashes in the LLVM LTO phase when using; the ``-flto`` option, follow these steps to diagnose and report the issue:. Compile your source file to a ``.bc`` (Bitcode) file with the following options,; in addition to your existing compilation options:. .. code-block:: bash. export CFLAGS=""-flto -fuse-ld=lld"" CXXFLAGS=""-flto -fuse-ld=lld"" LDFLAGS=""-Wl,-plugin-opt=save-temps"". These options enable LTO and save temporary files generated during compilation; for later analysis. On Windows, you should be using lld-link as the linker. Adjust your compilation ; flags as follows:; * Add ``/lldsavetemps`` to the linker flags.; * When linking from the compiler driver, add ``/link /lldsavetemps`` in order to forward that flag to the linker. Using the specified flags will generate four intermediate bytecode files:. #. a.out.0.0.preopt.bc (Before any link-time optimizations (LTO) are applied); #. a.out.0.2.internalize.bc (After initial optimizations are applied); #. a.out.0.4.opt.bc (After an extensive set of optimizations); #. a.out.0.5.precodegen.bc (After LTO but before translating into machine code). Execute one of the following commands to identify the source of the problem:. #. ``opt ""-passes=lto<O3>"" a.out.0.2.internalize.bc``; #. ``llc a.out.0.5.precodegen.bc``. If one of these do crash, you should be able to reduce; this with :program:`llvm-reduce`; command line (use the bc file corresponding to the command above that failed):. .. code-block:: bash. llvm-reduce --test reduce.sh a.out.0.2.internalize.bc. Example of reduce.sh script. .. code-block:: bash. $ cat reduce.sh; #!/bin/bash -e. path/to/not --crash path/to/opt ""-passes=lto<O3>"" $1 -o temp.bc 2> err.log; grep -q ""It->second == &Insn"" err.log. Here we have grepped the failed assert message. Please run this, then file a bug with the instructions and reduced .bc file; that llvm-reduce emits. .. _miscompiling:. Miscompilations; ===============. If clang successf",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToSubmitABug.rst:6988,optimiz,optimizations,6988,interpreter/llvm-project/llvm/docs/HowToSubmitABug.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToSubmitABug.rst,1,['optimiz'],['optimizations']
Performance,"--------------------. Once the release process starts, the Release Manager will ask for volunteers,; and it'll be the role of each volunteer to:. * Test and benchmark the previous release. * Test and benchmark each release candidate, comparing to the previous release; and candidates. * Identify, reduce and report every regression found during tests and benchmarks. * Make sure the critical bugs get fixed and merged to the next release candidate. Not all bugs or regressions are show-stoppers and it's a bit of a grey area what; should be fixed before the next candidate and what can wait until the next; release. It'll depend on:. * The severity of the bug, how many people it affects and if it's a regression; or a known bug. Known bugs are ""unsupported features"" and some bugs can be; disabled if they have been implemented recently. * The stage in the release. Less critical bugs should be considered to be; fixed between RC1 and RC2, but not so much at the end of it. * If it's a correctness or a performance regression. Performance regression; tends to be taken more lightly than correctness. .. _scripts:. Scripts; =======. The scripts are in the ``utils/release`` directory. test-release.sh; ---------------. This script will check-out, configure and compile LLVM+Clang (+ most add-ons,; like ``compiler-rt``, ``libcxx``, ``libomp`` and ``clang-extra-tools``) in; three stages, and will test the final stage.; It'll have installed the final binaries on the Phase3/Releasei(+Asserts); directory, and that's the one you should use for the test-suite and other; external tests. To run the script on a specific release candidate run::. ./test-release.sh \; -release 3.3 \; -rc 1 \; -no-64bit \; -test-asserts \; -no-compare-files. Each system will require different options. For instance, x86_64 will; obviously not need ``-no-64bit`` while 32-bit systems will, or the script will; fail. The important flags to get right are:. * On the pre-release, you should change ``-rc 1`` to ``-final``. On ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ReleaseProcess.rst:1424,perform,performance,1424,interpreter/llvm-project/llvm/docs/ReleaseProcess.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ReleaseProcess.rst,1,['perform'],['performance']
Performance,"-----------------===//. LLVM misses a load+store narrowing opportunity in this code:. %struct.bf = type { i64, i16, i16, i32 }. @bfi = external global %struct.bf* ; <%struct.bf**> [#uses=2]. define void @t1() nounwind ssp {; entry:; %0 = load %struct.bf** @bfi, align 8 ; <%struct.bf*> [#uses=1]; %1 = getelementptr %struct.bf* %0, i64 0, i32 1 ; <i16*> [#uses=1]; %2 = bitcast i16* %1 to i32* ; <i32*> [#uses=2]; %3 = load i32* %2, align 1 ; <i32> [#uses=1]; %4 = and i32 %3, -65537 ; <i32> [#uses=1]; store i32 %4, i32* %2, align 1; %5 = load %struct.bf** @bfi, align 8 ; <%struct.bf*> [#uses=1]; %6 = getelementptr %struct.bf* %5, i64 0, i32 1 ; <i16*> [#uses=1]; %7 = bitcast i16* %6 to i32* ; <i32*> [#uses=2]; %8 = load i32* %7, align 1 ; <i32> [#uses=1]; %9 = and i32 %8, -131073 ; <i32> [#uses=1]; store i32 %9, i32* %7, align 1; ret void; }. LLVM currently emits this:. movq bfi(%rip), %rax; andl $-65537, 8(%rax); movq bfi(%rip), %rax; andl $-131073, 8(%rax); ret. It could narrow the loads and stores to emit this:. movq bfi(%rip), %rax; andb $-2, 10(%rax); movq bfi(%rip), %rax; andb $-3, 10(%rax); ret. The trouble is that there is a TokenFactor between the store and the; load, making it non-trivial to determine if there's anything between; the load and the store which would prohibit narrowing. //===---------------------------------------------------------------------===//. This code:; void foo(unsigned x) {; if (x == 0) bar();; else if (x == 1) qux();; }. currently compiles into:; _foo:; 	movl	4(%esp), %eax; 	cmpl	$1, %eax; 	je	LBB0_3; 	testl	%eax, %eax; 	jne	LBB0_4. the testl could be removed:; _foo:; 	movl	4(%esp), %eax; 	cmpl	$1, %eax; 	je	LBB0_3; 	jb	LBB0_4. 0 is the only unsigned number < 1. //===---------------------------------------------------------------------===//. This code:. %0 = type { i32, i1 }. define i32 @add32carry(i32 %sum, i32 %x) nounwind readnone ssp {; entry:; %uadd = tail call %0 @llvm.uadd.with.overflow.i32(i32 %sum, i32 %x); %cmp = extractvalue",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README.txt:38233,load,loads,38233,interpreter/llvm-project/llvm/lib/Target/X86/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README.txt,2,['load'],['loads']
Performance,"----------------. The most basic form of input mutation is to use the built in mutators of; LibFuzzer. These simply treat the input corpus as a bag of bits and make random; mutations. This type of fuzzer is good for stressing the surface layers of a; program, and is good at testing things like lexers, parsers, or binary; protocols. Some of the in-tree fuzzers that use this type of mutator are `clang-fuzzer`_,; `clang-format-fuzzer`_, `llvm-as-fuzzer`_, `llvm-dwarfdump-fuzzer`_,; `llvm-mc-assemble-fuzzer`_, and `llvm-mc-disassemble-fuzzer`_. .. _fuzzing-llvm-protobuf:. Structured Fuzzing using ``libprotobuf-mutator``; ------------------------------------------------. We can use libprotobuf-mutator_ in order to perform structured fuzzing and; stress deeper layers of programs. This works by defining a protobuf class that; translates arbitrary data into structurally interesting input. Specifically, we; use this to work with a subset of the C++ language and perform mutations that; produce valid C++ programs in order to exercise parts of clang that are more; interesting than parser error handling. To build this kind of fuzzer you need `protobuf`_ and its dependencies; installed, and you need to specify some extra flags when configuring the build; with :doc:`CMake <CMake>`. For example, `clang-proto-fuzzer`_ can be enabled by; adding ``-DCLANG_ENABLE_PROTO_FUZZER=ON`` to the flags described in; :ref:`building-fuzzers`. The only in-tree fuzzer that uses ``libprotobuf-mutator`` today is; `clang-proto-fuzzer`_. .. _libprotobuf-mutator: https://github.com/google/libprotobuf-mutator; .. _protobuf: https://github.com/google/protobuf. .. _fuzzing-llvm-ir:. Structured Fuzzing of LLVM IR; -----------------------------. We also use a more direct form of structured fuzzing for fuzzers that take; :doc:`LLVM IR <LangRef>` as input. This is achieved through the ``FuzzMutate``; library, which was `discussed at EuroLLVM 2017`_. The ``FuzzMutate`` library is used to structurally fuzz backen",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FuzzingLLVM.rst:6750,perform,perform,6750,interpreter/llvm-project/llvm/docs/FuzzingLLVM.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FuzzingLLVM.rst,1,['perform'],['perform']
Performance,"----------------===//. clang -O3 currently compiles this code. int g(unsigned int a) {; unsigned int c[100];; c[10] = a;; c[11] = a;; unsigned int b = c[10] + c[11];; if(b > a*2) a = 4;; else a = 8;; return a + 7;; }. into. define i32 @g(i32 a) nounwind readnone {; %add = shl i32 %a, 1; %mul = shl i32 %a, 1; %cmp = icmp ugt i32 %add, %mul; %a.addr.0 = select i1 %cmp, i32 11, i32 15; ret i32 %a.addr.0; }. The icmp should fold to false. This CSE opportunity is only available; after GVN and InstCombine have run. //===---------------------------------------------------------------------===//. memcpyopt should turn this:. define i8* @test10(i32 %x) {; %alloc = call noalias i8* @malloc(i32 %x) nounwind; call void @llvm.memset.p0i8.i32(i8* %alloc, i8 0, i32 %x, i32 1, i1 false); ret i8* %alloc; }. into a call to calloc. We should make sure that we analyze calloc as; aggressively as malloc though. //===---------------------------------------------------------------------===//. clang -O3 doesn't optimize this:. void f1(int* begin, int* end) {; std::fill(begin, end, 0);; }. into a memset. This is PR8942. //===---------------------------------------------------------------------===//. clang -O3 -fno-exceptions currently compiles this code:. void f(int N) {; std::vector<int> v(N);. extern void sink(void*); sink(&v);; }. into. define void @_Z1fi(i32 %N) nounwind {; entry:; %v2 = alloca [3 x i32*], align 8; %v2.sub = getelementptr inbounds [3 x i32*]* %v2, i64 0, i64 0; %tmpcast = bitcast [3 x i32*]* %v2 to %""class.std::vector""*; %conv = sext i32 %N to i64; store i32* null, i32** %v2.sub, align 8, !tbaa !0; %tmp3.i.i.i.i.i = getelementptr inbounds [3 x i32*]* %v2, i64 0, i64 1; store i32* null, i32** %tmp3.i.i.i.i.i, align 8, !tbaa !0; %tmp4.i.i.i.i.i = getelementptr inbounds [3 x i32*]* %v2, i64 0, i64 2; store i32* null, i32** %tmp4.i.i.i.i.i, align 8, !tbaa !0; %cmp.i.i.i.i = icmp eq i32 %N, 0; br i1 %cmp.i.i.i.i, label %_ZNSt12_Vector_baseIiSaIiEEC2EmRKS0_.exit.thread.i.i, la",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/README.txt:55725,optimiz,optimize,55725,interpreter/llvm-project/llvm/lib/Target/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/README.txt,2,['optimiz'],['optimize']
Performance,"---------------; load atomic unordered *any* *any* *Same as non-atomic*.; store atomic unordered *any* *any* *Same as non-atomic*.; atomicrmw unordered *any* *any* *Same as monotonic atomic*.; **Monotonic Atomic**; ------------------------------------------------------------------------------------; load atomic monotonic - singlethread - global 1. buffer/global/ds/flat_load; - wavefront - local; - workgroup - generic; load atomic monotonic - agent - global 1. buffer/global/flat_load; - system - generic glc=1; store atomic monotonic - singlethread - global 1. buffer/global/flat_store; - wavefront - generic; - workgroup; - agent; - system; store atomic monotonic - singlethread - local 1. ds_store; - wavefront; - workgroup; atomicrmw monotonic - singlethread - global 1. buffer/global/flat_atomic; - wavefront - generic; - workgroup; - agent; - system; atomicrmw monotonic - singlethread - local 1. ds_atomic; - wavefront; - workgroup; **Acquire Atomic**; ------------------------------------------------------------------------------------; load atomic acquire - singlethread - global 1. buffer/global/ds/flat_load; - wavefront - local; - generic; load atomic acquire - workgroup - global 1. buffer/global_load; load atomic acquire - workgroup - local 1. ds/flat_load; - generic 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic value being; acquired. load atomic acquire - agent - global 1. buffer/global_load; - system glc=1; 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the load; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale global data. load atomic acquire - agent - generic 1. flat_load glc=1; - system 2",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:214093,load,load,214093,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['load']
Performance,"--------------. The role of debug information is to provide meta information normally stripped; away during the compilation process. This meta information provides an LLVM; user a relationship between generated code and the original program source; code. Currently, there are two backend consumers of debug info: DwarfDebug and; CodeViewDebug. DwarfDebug produces DWARF suitable for use with GDB, LLDB, and; other DWARF-based debuggers. :ref:`CodeViewDebug <codeview>` produces CodeView,; the Microsoft debug info format, which is usable with Microsoft debuggers such; as Visual Studio and WinDBG. LLVM's debug information format is mostly derived; from and inspired by DWARF, but it is feasible to translate into other target; debug info formats such as STABS. It would also be reasonable to use debug information to feed profiling tools; for analysis of generated code, or, tools for reconstructing the original; source from generated code. .. _intro_debugopt:. Debug information and optimizations; -----------------------------------. An extremely high priority of LLVM debugging information is to make it interact; well with optimizations and analysis. In particular, the LLVM debug; information provides the following guarantees:. * LLVM debug information **always provides information to accurately read; the source-level state of the program**, regardless of which LLVM; optimizations have been run. :doc:`HowToUpdateDebugInfo` specifies how debug; info should be updated in various kinds of code transformations to avoid; breaking this guarantee, and how to preserve as much useful debug info as; possible. Note that some optimizations may impact the ability to modify the; current state of the program with a debugger, such as setting program; variables, or calling functions that have been deleted. * As desired, LLVM optimizations can be upgraded to be aware of debugging; information, allowing them to update the debugging information as they; perform aggressive optimizations. This means",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:3619,optimiz,optimizations,3619,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,1,['optimiz'],['optimizations']
Performance,"--------------===//. Consider the expansion of:. define i32 @test3(i32 %X) {; %tmp1 = urem i32 %X, 255; ret i32 %tmp1; }. Currently it compiles to:. ...; movl $2155905153, %ecx; movl 8(%esp), %esi; movl %esi, %eax; mull %ecx; ... This could be ""reassociated"" into:. movl $2155905153, %eax; movl 8(%esp), %ecx; mull %ecx. to avoid the copy. In fact, the existing two-address stuff would do this; except that mul isn't a commutative 2-addr instruction. I guess this has; to be done at isel time based on the #uses to mul?. //===---------------------------------------------------------------------===//. Make sure the instruction which starts a loop does not cross a cacheline; boundary. This requires knowning the exact length of each machine instruction.; That is somewhat complicated, but doable. Example 256.bzip2:. In the new trace, the hot loop has an instruction which crosses a cacheline; boundary. In addition to potential cache misses, this can't help decoding as I; imagine there has to be some kind of complicated decoder reset and realignment; to grab the bytes from the next cacheline. 532 532 0x3cfc movb (1809(%esp, %esi), %bl <<<--- spans 2 64 byte lines; 942 942 0x3d03 movl %dh, (1809(%esp, %esi); 937 937 0x3d0a incl %esi; 3 3 0x3d0b cmpb %bl, %dl; 27 27 0x3d0d jnz 0x000062db <main+11707>. //===---------------------------------------------------------------------===//. In c99 mode, the preprocessor doesn't like assembly comments like #TRUNCATE. //===---------------------------------------------------------------------===//. This could be a single 16-bit load. int f(char *p) {; if ((p[0] == 1) & (p[1] == 2)) return 1;; return 0;; }. //===---------------------------------------------------------------------===//. We should inline lrintf and probably other libc functions. //===---------------------------------------------------------------------===//. This code:. void test(int X) {; if (X) abort();; }. is currently compiled to:. _test:; subl $12, %esp; cmpl $0, 16(%esp); ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README.txt:10787,cache,cache,10787,interpreter/llvm-project/llvm/lib/Target/X86/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README.txt,4,['cache'],"['cache', 'cacheline']"
Performance,"--------------┐; | │; | source file │; | │; └---------------------------------------------------------------------------------------┘. ┌--------┐; │ │; │imported│; │ │; │ code │; │ │; └--------┘. Here we can see that the source file (could be a non-module unit or a module unit) would get processed by the; whole pipeline.; But the imported code would only get involved in semantic analysis, which is mainly about name lookup,; overload resolution and template instantiation.; All of these processes are fast relative to the whole compilation process.; More importantly, the imported code only needs to be processed once in frontend code generation,; as well as the whole middle end and backend.; So we could get a big win for the compilation time in O0. But with optimizations, things are different:. (we omit ``code generation`` part for each end due to the limited space). .. code-block:: none. ├-------- frontend ---------┼--------------- middle end --------------------┼------ backend ----┤; │ │ │ │; └--- parsing ---- sema -----┴--- optimizations --- IPO ---- optimizations---┴--- optimizations -┘. ┌-----------------------------------------------------------------------------------------------┐; │ │; │ source file │; │ │; └-----------------------------------------------------------------------------------------------┘; ┌---------------------------------------┐; │ │; │ │; │ imported code │; │ │; │ │; └---------------------------------------┘. It would be very unfortunate if we end up with worse performance after using modules.; The main concern is that when we compile a source file, the compiler needs to see the function body; of imported module units so that it can perform IPO (InterProcedural Optimization, primarily inlining; in practice) to optimize functions in current source file with the help of the information provided by; the imported module units.; In other words, the imported code would be processed again and again in importee units; by optimizations (including IPO its",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/StandardCPlusPlusModules.rst:41671,optimiz,optimizations,41671,interpreter/llvm-project/clang/docs/StandardCPlusPlusModules.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/StandardCPlusPlusModules.rst,3,['optimiz'],['optimizations']
Performance,"------------===//. Reimplement 'select' in terms of 'SEL'. * We would really like to support UXTAB16, but we need to prove that the; add doesn't need to overflow between the two 16-bit chunks. * Implement pre/post increment support. (e.g. PR935); * Implement smarter constant generation for binops with large immediates. A few ARMv6T2 ops should be pattern matched: BFI, SBFX, and UBFX. Interesting optimization for PIC codegen on arm-linux:; http://gcc.gnu.org/bugzilla/show_bug.cgi?id=43129. //===---------------------------------------------------------------------===//. Crazy idea: Consider code that uses lots of 8-bit or 16-bit values. By the; time regalloc happens, these values are now in a 32-bit register, usually with; the top-bits known to be sign or zero extended. If spilled, we should be able; to spill these to a 8-bit or 16-bit stack slot, zero or sign extending as part; of the reload. Doing this reduces the size of the stack frame (important for thumb etc), and; also increases the likelihood that we will be able to reload multiple values; from the stack with a single load. //===---------------------------------------------------------------------===//. The constant island pass is in good shape. Some cleanups might be desirable,; but there is unlikely to be much improvement in the generated code. 1. There may be some advantage to trying to be smarter about the initial; placement, rather than putting everything at the end. 2. There might be some compile-time efficiency to be had by representing; consecutive islands as a single block rather than multiple blocks. 3. Use a priority queue to sort constant pool users in inverse order of; position so we always process the one closed to the end of functions; first. This may simply CreateNewWater. //===---------------------------------------------------------------------===//. Eliminate copysign custom expansion. We are still generating crappy code with; default expansion + if-conversion. //===-------------------------",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/README.txt:1272,load,load,1272,interpreter/llvm-project/llvm/lib/Target/ARM/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/README.txt,2,['load'],['load']
Performance,"-----------. Unary operators require a single operand, execute an operation on; it, and produce a single value. The operand might represent multiple; data, as is the case with the :ref:`vector <t_vector>` data type. The; result value has the same type as its operand. .. _i_fneg:. '``fneg``' Instruction; ^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. <result> = fneg [fast-math flags]* <ty> <op1> ; yields ty:result. Overview:; """""""""""""""""". The '``fneg``' instruction returns the negation of its operand. Arguments:; """""""""""""""""""". The argument to the '``fneg``' instruction must be a; :ref:`floating-point <t_floating>` or :ref:`vector <t_vector>` of; floating-point values. Semantics:; """""""""""""""""""". The value produced is a copy of the operand with its sign bit flipped.; The value is otherwise completely identical; in particular, if the input is a; NaN, then the quiet/signaling bit and payload are perfectly preserved. This instruction can also take any number of :ref:`fast-math; flags <fastmath>`, which are optimization hints to enable otherwise; unsafe floating-point optimizations:. Example:; """""""""""""""". .. code-block:: text. <result> = fneg float %val ; yields float:result = -%var. .. _binaryops:. Binary Operations; -----------------. Binary operators are used to do most of the computation in a program.; They require two operands of the same type, execute an operation on; them, and produce a single value. The operands might represent multiple; data, as is the case with the :ref:`vector <t_vector>` data type. The; result value has the same type as its operands. There are several different binary operators:. .. _i_add:. '``add``' Instruction; ^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. <result> = add <ty> <op1>, <op2> ; yields ty:result; <result> = add nuw <ty> <op1>, <op2> ; yields ty:result; <result> = add nsw <ty> <op1>, <op2> ; yields ty:result; <result> = add nuw nsw <ty> <op1>, <op2> ; yields ty:result. Overview:; """""""""""""""""". The '``add``' instruction returns the sum of its two",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:376499,optimiz,optimization,376499,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,2,['optimiz'],"['optimization', 'optimizations']"
Performance,"----------. A |generic fuzzer| for the Itanium demangler used in various LLVM tools. We've; fuzzed __cxa_demangle to death, why not fuzz LLVM's implementation of the same; function!. llvm-isel-fuzzer; ----------------. A |LLVM IR fuzzer| aimed at finding bugs in instruction selection. This fuzzer accepts flags after `ignore_remaining_args=1`. The flags match; those of :doc:`llc <CommandGuide/llc>` and the triple is required. For example,; the following command would fuzz AArch64 with :doc:`GlobalISel/index`:. .. code-block:: shell. % bin/llvm-isel-fuzzer <corpus-dir> -ignore_remaining_args=1 -mtriple aarch64 -global-isel -O0. Some flags can also be specified in the binary name itself in order to support; OSS Fuzz, which has trouble with required arguments. To do this, you can copy; or move ``llvm-isel-fuzzer`` to ``llvm-isel-fuzzer--x-y-z``, separating options; from the binary name using ""--"". The valid options are architecture names; (``aarch64``, ``x86_64``), optimization levels (``O0``, ``O2``), or specific; keywords, like ``gisel`` for enabling global instruction selection. In this; mode, the same example could be run like so:. .. code-block:: shell. % bin/llvm-isel-fuzzer--aarch64-O0-gisel <corpus-dir>. llvm-opt-fuzzer; ---------------. A |LLVM IR fuzzer| aimed at finding bugs in optimization passes. It receives optimization pipeline and runs it for each fuzzer input. Interface of this fuzzer almost directly mirrors ``llvm-isel-fuzzer``. Both; ``mtriple`` and ``passes`` arguments are required. Passes are specified in a; format suitable for the new pass manager. You can find some documentation about; this format in the doxygen for ``PassBuilder::parsePassPipeline``. .. code-block:: shell. % bin/llvm-opt-fuzzer <corpus-dir> -ignore_remaining_args=1 -mtriple x86_64 -passes instcombine. Similarly to the ``llvm-isel-fuzzer`` arguments in some predefined configurations; might be embedded directly into the binary file name:. .. code-block:: shell. % bin/llvm-opt-fuzze",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FuzzingLLVM.rst:3056,optimiz,optimization,3056,interpreter/llvm-project/llvm/docs/FuzzingLLVM.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FuzzingLLVM.rst,1,['optimiz'],['optimization']
Performance,"----------. If, in the formal computation history of the program, an object ``X``; has been deallocated by the time of an observable side-effect, then; ARC must cause ``X`` to be deallocated by no later than the occurrence; of that side-effect, except as influenced by the re-ordering of the; destruction of objects. .. admonition:: Rationale. This rule is intended to prohibit ARC from observably extending the; lifetime of a retainable object, other than as specified in this; document. Together with the rule limiting the transformation of; releases, this rule requires ARC to eliminate retains and release; only in pairs. ARC's power to reorder the destruction of objects is critical to its; ability to do any optimization, for essentially the same reason that; it must retain the power to decrease the lifetime of an object.; Unfortunately, while it's generally poor style for the destruction; of objects to have arbitrary side-effects, it's certainly possible.; Hence the caveat. .. _arc.optimization.precise:. Precise lifetime semantics; --------------------------. In general, ARC maintains an invariant that a retainable object pointer held in; a ``__strong`` object will be retained for the full formal lifetime of the; object. Objects subject to this invariant have :arc-term:`precise lifetime; semantics`. By default, local variables of automatic storage duration do not have precise; lifetime semantics. Such objects are simply strong references which hold; values of retainable object pointer type, and these values are still fully; subject to the optimizations on values under local control. .. admonition:: Rationale. Applying these precise-lifetime semantics strictly would be prohibitive.; Many useful optimizations that might theoretically decrease the lifetime of; an object would be rendered impossible. Essentially, it promises too much. A local variable of retainable object owner type and automatic storage duration; may be annotated with the ``objc_precise_lifetime`` attribut",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst:83470,optimiz,optimization,83470,interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,1,['optimiz'],['optimization']
Performance,"----------===//. 186.crafty has this interesting pattern with the ""out.4543"" variable:. call void @llvm.memcpy.i32(; i8* getelementptr ([10 x i8]* @out.4543, i32 0, i32 0),; i8* getelementptr ([7 x i8]* @""\01LC28700"", i32 0, i32 0), i32 7, i32 1) ; %101 = call@printf(i8* ... @out.4543, i32 0, i32 0)) nounwind . It is basically doing:. memcpy(globalarray, ""string"");; printf(..., globalarray);; ; Anyway, by knowing that printf just reads the memory and forward substituting; the string directly into the printf, this eliminates reads from globalarray.; Since this pattern occurs frequently in crafty (due to the ""DisplayTime"" and; other similar functions) there are many stores to ""out"". Once all the printfs; stop using ""out"", all that is left is the memcpy's into it. This should allow; globalopt to remove the ""stored only"" global. //===---------------------------------------------------------------------===//. This code:. define inreg i32 @foo(i8* inreg %p) nounwind {; %tmp0 = load i8* %p; %tmp1 = ashr i8 %tmp0, 5; %tmp2 = sext i8 %tmp1 to i32; ret i32 %tmp2; }. could be dagcombine'd to a sign-extending load with a shift.; For example, on x86 this currently gets this:. 	movb	(%eax), %al; 	sarb	$5, %al; 	movsbl	%al, %eax. while it could get this:. 	movsbl	(%eax), %eax; 	sarl	$5, %eax. //===---------------------------------------------------------------------===//. GCC PR31029:. int test(int x) { return 1-x == x; } // --> return false; int test2(int x) { return 2-x == x; } // --> return x == 1 ?. Always foldable for odd constants, what is the rule for even?. //===---------------------------------------------------------------------===//. PR 3381: GEP to field of size 0 inside a struct could be turned into GEP; for next field in struct (which is at same address). For example: store of float into { {{}}, float } could be turned into a store to; the float directly. //===---------------------------------------------------------------------===//. The arg promotion pass should mak",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/README.txt:42395,load,load,42395,interpreter/llvm-project/llvm/lib/Target/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/README.txt,2,['load'],['load']
