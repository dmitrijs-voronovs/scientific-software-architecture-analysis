quality_attribute,sentence,source,author,repo,version,id,keyword,matched_word,match_idx,wiki,url,total_similar,target_keywords,target_matched_words
Deployability,"It looks like you are issuing . `$cmake .` . rather than . `$cmake ..`. when trying to perform the cmake step. If you could build from source, that would be great. However, I was suggesting you try downloading [this](; https://github.com/COMBINE-lab/salmon/releases/download/v0.11.1/salmon-0.11.1-linux_x86_64.tar.gz) pre-compiled linux binary and running that.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/261#issuecomment-409436938:257,release,releases,257,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/261#issuecomment-409436938,1,['release'],['releases']
Deployability,"It may be a bad alloc error. Do you have a machine with a bit more ram to try it on? Also, you could try installing through bioconda to see if it may be an issue with the precompiled binary (e.g. librar compatibility).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/419#issuecomment-522261180:105,install,installing,105,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/419#issuecomment-522261180,1,['install'],['installing']
Deployability,"It seems FreeBSD prefers to use Docker under an emulator -- I did not try that.; I installed a ubuntu on VirtualBox. There I was able to run salmon index and salmon quant in a conda environment. Same Segmentation Fault crash.; I also get the same crashes if I use only the first 54K reads of the 23.5M in the files. So I do not ; think it is an issue of computer memory size.; Maybe virtual Ubuntu is not the same as hardware Ubuntu. Can you please try the fastq files that I tried, and see if they don't crash for you on Ubuntu 19.04?; If they do not crash for you, I will build a hardware Ubuntu box so I can use your salmon suite.; As you probably know, you can find these mouse brain RNA-seq data at; https://www.ncbi.nlm.nih.gov/sra/?term=SRR1818187. I just noticed that you have posted decoys, thank you.; I indexed one, with your recommended command, and I got many many many warnings; (I could not figure out how to count them) such as; -------------------------------------------------------------; [2019-08-21 13:19:31.122] [jointLog] [warning] Entry with header [ENSMUST00000103739.3], had length less than the k-mer length of 31 (perhaps after poly-A clipping); [2019-08-21 13:19:31.178] [jointLog] [warning] Entry with header [ENSMUST00000200713.1], had length less than the k-mer length of 31 (perhaps after poly-A clipping); [2019-08-21 13:19:31.201] [jointLog] [warning] Entry with header [ENSMUST00000191703.1], had length less than the k-mer length of 31 (perhaps after poly-A clipping); [2019-08-21 13:19:31.344] [jointLog] [warning] Entry with header [ENSMUST00000192089.1], had length less than the k-mer length of 31 (perhaps after poly-A clipping); -------------------------------------- ; Is that expected for the gentome.fa ?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/419#issuecomment-524416706:83,install,installed,83,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/419#issuecomment-524416706,1,['install'],['installed']
Deployability,"It's ignoring the environment variable `$CPPFLAGS` which has the search path for `zlib.h`. ```; $ env |grep CPPFLAGS; CPPFLAGS=-isystem/home/linuxbrew/.linuxbrew/include; ```. This workaround works, but doesn't work on a system without root access. ``` sh; sudo apt-get install libz-dev; ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/45#issuecomment-193960137:270,install,install,270,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/45#issuecomment-193960137,1,['install'],['install']
Deployability,"It's now available in latest stable release, closing the issue but feel free to reopen if you have any issues.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/416#issuecomment-548614903:36,release,release,36,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/416#issuecomment-548614903,2,['release'],['release']
Deployability,"It's now fixed in latest stable release, closing the issue but feel free to reopen if you have any issues.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/413#issuecomment-548614992:32,release,release,32,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/413#issuecomment-548614992,1,['release'],['release']
Deployability,"I’ve noticed the same thing, and have been hard-masking any repetitive sequences in my pipeline (which I’ve been late to open-source and should be available soon): http://mattshirley.com/uploads/2017/11/2017-11-01_Genome_Informatics.pdf",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/217#issuecomment-385393689:87,pipeline,pipeline,87,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/217#issuecomment-385393689,1,['pipeline'],['pipeline']
Deployability,"Jumping on this thread. I received similar Seg faults with conda install on OSX. I tried the binary you posted, but receive this error when I try to execute. dyld: Library not loaded: @rpath/libtbbmalloc_proxy.dylib; Referenced from: /Users/dnb14/Documents/salmon_0.11.4-pre_OSX/./bin/salmon; Reason: image not found; Trace/BPT trap: 5",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/295#issuecomment-421407796:65,install,install,65,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/295#issuecomment-421407796,1,['install'],['install']
Deployability,"Just a bit more information:. I installed through conda salmon=0.11.3 and executed command on two different fastq files. The first one was on a single lane of the data and the second was on a concatenated file across 4 lanes. I managed to run the single lane file but got a seg dump error for the ""big""er file. Both times it seems to output the correct files. . Single lane:; ```; salmon alevin -l ISR -1 hgmm_100_S1_L001_001.fastq.1.gz -2 hgmm_100_S1_L001_001.fastq.2.gz --chromium -i geneset.dir/geneset_coding_exons.salmon.index/ -o salmon.dir/ --tgMap transcript2geneMap.tsv --dumpCsvCounts; Version Info: ### PLEASE UPGRADE SALMON ###; ### A newer version of Salmon with important bug fixes and improvements is available. ####; ###; The newest version, available at https://github.com/COMBINE-lab/salmon/releases; contains new features, improvements, and bug fixes; please upgrade at your; earliest convenience.; ###; Logs will be written to salmon.dir/logs; ### alevin (dscRNA-seq quantification) v0.11.3; ### [ program ] => salmon ; ### [ command ] => alevin ; ### [ libType ] => { ISR }; ### [ mates1 ] => { hgmm_100_S1_L001_001.fastq.1.gz }; ### [ mates2 ] => { hgmm_100_S1_L001_001.fastq.2.gz }; ### [ chromium ] => { }; ### [ index ] => { geneset.dir/geneset_coding_exons.salmon.index/ }; ### [ output ] => { salmon.dir/ }; ### [ tgMap ] => { transcript2geneMap.tsv }; ### [ dumpCsvCounts ] => { }. [2019-01-29 09:54:57.898] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2019-01-29 09:54:57.916] [alevinLog] [info] Processing barcodes files (if Present) . ; processed 0 Million barcodes. [2019-01-29 09:54:59.693] [alevinLog] [info] Done barcode density calculation.; [2019-01-29 09:54:59.693] [alevinLog] [info] # Barcodes Used: 902561 / 912145.; [2019-01-29 09:55:04.490] [alevinLog] [info] Knee found left boundary at 391 ; [2019-01-29 09:55:04.817] [alevinLog] [info] Gauss Corrected Boundary at 99 ; [2019-01-29 09:55:04.81",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/337#issuecomment-458481722:32,install,installed,32,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/337#issuecomment-458481722,4,"['UPGRADE', 'install', 'release', 'upgrade']","['UPGRADE', 'installed', 'releases', 'upgrade']"
Deployability,"Just a heads up, issue #266 has been added and the solution is currently available in the source build from the develop branch. We will include this to master with the next planned release of Salmon v0.11.3. Thanks again for the useful feedbacks and comments.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/253#issuecomment-412352411:181,release,release,181,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/253#issuecomment-412352411,1,['release'],['release']
Deployability,Just an update in case anyone else is encountering this issue. I was able to install salmon using these instructions: CONDA_SUBDIR=osx-64 conda create -n rosetta; conda activate rosetta; conda env config vars set CONDA_SUBDIR=osx-64; conda install salmon,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/912#issuecomment-1954908448:8,update,update,8,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/912#issuecomment-1954908448,3,"['install', 'update']","['install', 'update']"
Deployability,"Looking back to the [earlier post](https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-640962684), I wonder if this stems from CMake not being able to properly find Boost on its own. Granted, the CMake / Boost infrastructure has never been great, partly due to the complexity of salmon's CMake configuration, and partly due to the strange way that CMake, itself, handles Boost versions.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641546215:304,configurat,configuration,304,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641546215,1,['configurat'],['configuration']
Deployability,"Looks like I have some sort of conflict going on:. UnsatisfiableError: The following specifications were found to be in conflict:; - libboost -> libcxx >=4.0.1 -> clangdev ==5.0.0 -> llvmdev ==5.0.0; - libcxx 4.0.0* -> clangdev ==4.0.0 -> llvmdev ==4.0.0; Use ""conda info <package>"" to see the dependencies for each package. [https://sites.google.com/site/ummslogos/_/rsrc/1489610858836/home/apple-icon-76x76.png]. Javier E. Irazoqui, PhD; Associate Professor; Department of Microbiology and Physiological Systems; UMass Medical School. 368 Plantation Street; Albert Sherman Center; Room AS8.1053; Worcester, MA 01605. (774) 455-3797; Skype: javierirazoqui. Confidentiality Notice:; This e-mail message, including any attachments, is for the sole use of the intended recipient(s) and may contain confidential, proprietary and privileged information. Any unauthorized review, use, disclosure or distribution is prohibited. If you are not the intended recipient, please contact the sender immediately and destroy or permanently delete all copies of the original message. On Feb 11, 2018, at 11:01 PM, Rob Patro <notifications@github.com<mailto:notifications@github.com>> wrote:. I can't seem to reproduce this locally (OSX 10.13.1). However, what happens if you try:. > conda install salmon=0.9.1. do you see this version as available? Does it try to install it?. —; You are receiving this because you authored the thread.; Reply to this email directly, view it on GitHub<https://github.com/COMBINE-lab/salmon/issues/194#issuecomment-364824034>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AiohHaDPT6VtnW3toOd9kEKLLo2Zjvvcks5tT7e0gaJpZM4SAonB>.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/194#issuecomment-364941997:1274,install,install,1274,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/194#issuecomment-364941997,2,['install'],['install']
Deployability,"Looks like some progress has been made leading up to 1.6.0. The only thing cmake insists on embedding in the build now is pufferfish. Seems like it should be relatively easy to tweak cmake to use a separate install of this since it's already a separate Github project. However, it appears to use a COMBINE-lab fork of staden-io, which makes it impractical to install that as a separate package, since it would conflict with the mainstream version. The Debian package for staden-io_lib is from [https://github.com/jkbonfield/io_lib](https://github.com/jkbonfield/io_lib). I did get a successful build under FreeBSD ports: [https://github.com/outpaddling/freebsd-ports-wip/tree/master/salmon](https://github.com/outpaddling/freebsd-ports-wip/tree/master/salmon).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/502#issuecomment-989318706:207,install,install,207,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/502#issuecomment-989318706,2,['install'],['install']
Deployability,"Me too! . I tried the commands they suggest at anaconda (https://anaconda.org/bioconda/salmon), but even after installing everything I got with these commands, salmon still wants its update... (my current version after installing and updating via conda (with the channels conda-forge, bioconda, and default) is salmon 0.12.0). Is there an easy way to install it ""manually"" (I just started using Linux and haven't quite figured out how to install stuff on my own yet)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/483#issuecomment-774540738:111,install,installing,111,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/483#issuecomment-774540738,5,"['install', 'update']","['install', 'installing', 'update']"
Deployability,"Mine reports:. ```; ~/S/s/build ❯❯❯ otool -L ../bin/salmon; ../bin/salmon:; /usr/lib/libz.1.dylib (compatibility version 1.0.0, current version 1.2.5); /usr/lib/libSystem.B.dylib (compatibility version 1.0.0, current version 1226.10.1); /usr/lib/libbz2.1.0.dylib (compatibility version 1.0.0, current version 1.0.5); @rpath/libtbb.dylib (compatibility version 0.0.0, current version 0.0.0); @rpath/libtbbmalloc.dylib (compatibility version 0.0.0, current version 0.0.0); /usr/lib/libc++.1.dylib (compatibility version 1.0.0, current version 120.1.0); ```. I think the difference may be that in my build, the salmon build system d/l and installed libtbb (which it does if it's not present on the system already).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/70#issuecomment-239594781:636,install,installed,636,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/70#issuecomment-239594781,1,['install'],['installed']
Deployability,"My guess, and this is a long shot, is that it's a bug in the `tar` library of `cmake`, that's made evident because my system at work has up-to-date Linux headers and glibc but is running an eight-year-old Linux kernel (CentOS 5.10). I can upgrade everything with Linuxbrew except the running kernel. I've seen this situation show bugs before when the software uses compile time kernel feature checks like `HAVE_PIPE2` when it should be using a run time check, namely checking whether the call to `pipe2` fails with `ENOSYS`.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/10#issuecomment-127341230:239,upgrade,upgrade,239,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/10#issuecomment-127341230,1,['upgrade'],['upgrade']
Deployability,"My issue was resolved. Thanks. On Sun, Dec 30, 2018 at 12:07 PM Rob Patro <notifications@github.com> wrote:. > Hi @phickner <https://github.com/phickner>,; >; > Any update on this? How does the BAM file look under ValidateSamFile or; > some such?; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/COMBINE-lab/salmon/issues/323#issuecomment-450573944>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/APvI3l_civHZCPEisrvMD2azctC_EEM1ks5u-PLngaJpZM4Y4K_L>; > .; >",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/323#issuecomment-450704257:165,update,update,165,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/323#issuecomment-450704257,1,['update'],['update']
Deployability,"NAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts/versionInfo.json"", O_RDONLY) = 4; read(4, ""{\n \""indexVersion\"": 2,\n \""ha""..., 8191) = 96; read(4, """", 8191) = 0; close(4) = 0; stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts/versionInfo.json"", {st_mode=S_IFREG|0775, st_size=96, ...}) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts/versionInfo.json"", O_RDONLY) = 4; read(4, ""{\n \""indexVersion\"": 2,\n \""ha""..., 8191) = 96; read(4, """", 8191) = 0; close(4) = 0; clock_gettime(CLOCK_REALTIME, {1491424830, 69887706}) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts/header.json"", O_RDONLY) = 4; read(4, ""{\n \""value0\"": {\n \""Index""..., 8191) = 357; read(4, """", 8191) = 0; close(4) = 0; clock_gettime(CLOCK_REALTIME, {1491424830, 139950818}) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts/header.json"", O_RDONLY) = 4; read(4, ""{\n \""value0\"": {\n \""Index""..., 8191) = 357; read(4, """", 8191) = 0; close(4) = 0; mmap(NULL, 1073745920, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_STACK, -1, 0) = 0x7ffe7e5e8000; mprotect(0x7ffe7e5e8000, 4096, PROT_NONE) = 0; clone(child_stack=0x7ffebe5e7ed0, flags=CLONE_VM|CLONE_FS|CLONE_FILES|CLONE_SIGHAND|CLONE_THREAD|CLONE_SYSVSEM|CLONE_SETTLS|CLONE_PARENT_SETTID|CLONE_CHILD_CLEARTID, parent_tidptr=0x7ffebe5e89d0, tls=0x7ffebe5e8700, child_tidptr=0x7ffebe5e89d0) = 14677; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts/sa.bin"", O_RDONLY) = 4; clock_gettime(CLOCK_REALTIME, {1491424830, 149197282}) = 0; read(4, ""l\n\221\21\0\0\0\0k\n\221\21\373\25\343\20\17\254\r\1\36\27\227\n\37\371\270\4\250\210\307\f""..., 8191) = 8191; mmap(NULL, 1",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:165933,pipeline,pipeline,165933,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,1,['pipeline'],['pipeline']
Deployability,"NC00337-001|LINC00337|1302|l""..., 8191) = 8191; read(4, ""\0\0\0\0ENST00000377728.7|ENSG000001""..., 8191) = 8191; read(4, ""|z\0\0\0\0\0\0\0ENST00000470648.5|ENSG0""..., 8191) = 8191; read(4, [1m[2017-04-05 16:40:33.297] [stderrLog] [info] Loading Transcript Info ; [00mread(4, ""35271.1|ENSG00000234546.3|OTTHUM""..., 8191) = 8191; read(4, ""00005018.1|UBE4B-003|UBE4B|2299|""..., 8191) = 8191; read(4, ""ding|x\0\0\0\0\0\0\0ENST00000468348.1|E""..., 8191) = 8191; read(4, ""005558.1|MTOR-001|MTOR|8677|prot""..., 8191) = 8191; read(4, ""rotein_coding|x\0\0\0\0\0\0\0ENST000004""..., 8191) = 8191; read(4, ""|\177\0\0\0\0\0\0\0ENST00000439324.2|ENSG0""..., 8191) = 8191; read(4, ""36.1|OTTHUMG00000009500.2|OTTHUM""..., 8191) = 8191; read(4, ""G00000175147.11|OTTHUMG000000020""..., 8191) = 8191; read(4, ""rotein_coding|}\0\0\0\0\0\0\0ENST000004""..., 8191) = 8191; read(4, ""ed_transcript|z\0\0\0\0\0\0\0ENST000004""..., 8191) = 8191; read(4, ""1|549|processed_transcript|{\0\0\0\0""..., 8191) = 8191; read(4, ""0006250.3|CROCC-002|CROCC|3931|p""..., 8191) = 8191; read(4, ""nscript|y\0\0\0\0\0\0\0ENST00000466151.""..., 8191) = 8191; read(4, ""R4|536|processed_transcript|q\0\0\0""..., 8191) = 8191; read(4, "".13|OTTHUMG00000002712.2|OTTHUMT""..., 8191) = 8191; read(4, ""0375079.6|ENSG00000158816.15|OTT""..., 8191) = 8191; ```. (First 500 lines, job is running well). ## Next steps. We are hoping that this info will give you an idea on what could be the source of the problem. Maybe `Salmon` requires a newer version of its dependencies than those that we have installed at JHPCE. . Under a scenario where `Salmon` doesn't change (and it's not a dependency issue), we could try running `Salmon` with increasing amounts of memory until we find a point where it doesn't fail for any of our samples (fastq files go to to 13 GB per read in a read pair, so 26 GB total for this particular dataset). We know that 90 GB total memory works, but like I've said before it's a pretty inefficient use of our cluster resources. Best,; Leo",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:170255,install,installed,170255,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,1,['install'],['installed']
Deployability,"NULL, msg_iov(1)=[{""HTTP/1.1 200 OK\r\nServer: GitHub.""..., 512}], msg_controllen=0, msg_flags=0}, 0) = 512; recvmsg(6, {msg_name(0)=NULL, msg_iov(1)=[{""Accept-Encoding\r\nX-Fastly-Reques""..., 512}], msg_controllen=0, msg_flags=0}, 0) = 125; epoll_wait(5, {}, 128, 0) = 0; recvmsg(6, {msg_name(0)=NULL, msg_iov(1)=[{""Server: GitHub.com\r\nContent-Type""..., 1024}], msg_controllen=0, msg_flags=0}, 0) = 0; epoll_wait(5, {}, 128, 0) = 0; close(6) = 0; futex(0x7fffbee4613c, FUTEX_CMP_REQUEUE_PRIVATE, 1, 2147483647, 0x7fffbee46110, 2) = 1; futex(0x7fffbee46110, FUTEX_WAKE_PRIVATE, 1) = 1; futex(0x7fffbedff9d0, FUTEX_WAIT, 10739, NULL) = 0; munmap(0x7fff7edff000, 1073745920) = 0; close(5) = 0; close(3) = 0; close(4) = 0; write(2, ""Version Info: This is the most r""..., 57Version Info: This is the most recent version of Salmon.; ) = 57; write(2, ""### salmon (mapping-based) v0.8.""..., 594### salmon (mapping-based) v0.8.2; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts }; ### [ threads ] => { 1 }; ### [ libType ] => { ISR }; ### [ mates1 ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/merged_fastq/R10002_C29P7ACXX.fastq.gz }; ### [ mates2 ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/merged_fastq/R10002_C29P7ACXX_read2.fastq.gz }; ### [ output ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10002_C29P7ACXX }; ) = 594; stat(""/etc/localtime"", {st_mode=S_IFREG|0644, st_size=3519, ...}) = 0; stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10002_C29P7ACXX"", {st_mode=S_IFDIR|S_ISGID|0755, st_size=33280, ...}) = 0; stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10002_C29P7ACXX"", {st_mode=S_IFDIR|S_ISGID|0755, st_size=33280, ...}) = 0; stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10002_C29P7ACXX/logs"", 0x7fffffff1e50) = -1 ENOENT (No such file or directory",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:66162,pipeline,pipeline,66162,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,1,['pipeline'],['pipeline']
Deployability,"NULL, msg_iov(1)=[{""HTTP/1.1 200 OK\r\nServer: GitHub.""..., 512}], msg_controllen=0, msg_flags=0}, 0) = 512; recvmsg(6, {msg_name(0)=NULL, msg_iov(1)=[{""Accept-Encoding\r\nX-Fastly-Reques""..., 512}], msg_controllen=0, msg_flags=0}, 0) = 125; epoll_wait(5, {}, 128, 0) = 0; recvmsg(6, {msg_name(0)=NULL, msg_iov(1)=[{""Server: GitHub.com\r\nContent-Type""..., 1024}], msg_controllen=0, msg_flags=0}, 0) = 0; epoll_wait(5, {}, 128, 0) = 0; close(6) = 0; futex(0x7fffbee4813c, FUTEX_CMP_REQUEUE_PRIVATE, 1, 2147483647, 0x7fffbee48110, 4) = 1; futex(0x7fffbee48110, FUTEX_WAKE_PRIVATE, 1) = 1; futex(0x7fffbedff9d0, FUTEX_WAIT, 32682, NULL) = 0; munmap(0x7fff7edff000, 1073745920) = 0; close(5) = 0; close(3) = 0; close(4) = 0; write(2, ""Version Info: This is the most r""..., 57Version Info: This is the most recent version of Salmon.; ) = 57; write(2, ""### salmon (mapping-based) v0.8.""..., 594### salmon (mapping-based) v0.8.2; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts }; ### [ threads ] => { 1 }; ### [ libType ] => { ISR }; ### [ mates1 ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/merged_fastq/R10001_D2B1WACXX.fastq.gz }; ### [ mates2 ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/merged_fastq/R10001_D2B1WACXX_read2.fastq.gz }; ### [ output ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10001_D2B1WACXX }; ) = 594; stat(""/etc/localtime"", {st_mode=S_IFREG|0644, st_size=3519, ...}) = 0; stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10001_D2B1WACXX"", {st_mode=S_IFDIR|S_ISGID|0755, st_size=512, ...}) = 0; stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10001_D2B1WACXX"", {st_mode=S_IFDIR|S_ISGID|0755, st_size=512, ...}) = 0; stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10001_D2B1WACXX/logs"", 0x7fffffff1e50) = -1 ENOENT (No such file or directory); s",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:29396,pipeline,pipeline,29396,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,1,['pipeline'],['pipeline']
Deployability,"NULL, msg_iov(1)=[{""HTTP/1.1 200 OK\r\nServer: GitHub.""..., 512}], msg_controllen=0, msg_flags=0}, 0) = 512; recvmsg(6, {msg_name(0)=NULL, msg_iov(1)=[{""ccept-Encoding\r\nX-Fastly-Request""..., 512}], msg_controllen=0, msg_flags=0}, 0) = 124; epoll_wait(5, {}, 128, 0) = 0; recvmsg(6, {msg_name(0)=NULL, msg_iov(1)=[{""Server: GitHub.com\r\nContent-Type""..., 1024}], msg_controllen=0, msg_flags=0}, 0) = 0; epoll_wait(5, {}, 128, 0) = 0; close(6) = 0; futex(0x7fffbee4413c, FUTEX_CMP_REQUEUE_PRIVATE, 1, 2147483647, 0x7fffbee44110, 4) = 1; futex(0x7fffbee44110, FUTEX_WAKE_PRIVATE, 1) = 1; futex(0x7fffbedff9d0, FUTEX_WAIT, 51997, NULL) = 0; munmap(0x7fff7edff000, 1073745920) = 0; close(5) = 0; close(3) = 0; close(4) = 0; write(2, ""Version Info: This is the most r""..., 57Version Info: This is the most recent version of Salmon.; ) = 57; write(2, ""### salmon (mapping-based) v0.8.""..., 594### salmon (mapping-based) v0.8.2; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts }; ### [ threads ] => { 1 }; ### [ libType ] => { ISR }; ### [ mates1 ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/merged_fastq/R10001_D2B1WACXX.fastq.gz }; ### [ mates2 ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/merged_fastq/R10001_D2B1WACXX_read2.fastq.gz }; ### [ output ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10001_D2B1WACXX }; ) = 594; stat(""/etc/localtime"", {st_mode=S_IFREG|0644, st_size=3519, ...}) = 0; stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10001_D2B1WACXX"", {st_mode=S_IFDIR|S_ISGID|0755, st_size=33280, ...}) = 0; stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10001_D2B1WACXX"", {st_mode=S_IFDIR|S_ISGID|0755, st_size=33280, ...}) = 0; stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10001_D2B1WACXX/logs"", 0x7fffffff1e50) = -1 ENOENT (No such file or directory",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:104744,pipeline,pipeline,104744,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,1,['pipeline'],['pipeline']
Deployability,"No updates right now. Consider this issue not reproduced yet, as I haven't had time to dig into the details. Hopefully it's an issue on my end, but expect an update in the next couple of days.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/132#issuecomment-296880535:3,update,updates,3,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/132#issuecomment-296880535,2,['update'],"['update', 'updates']"
Deployability,"No worries; thanks for looping back around. As a side-note, v1.0.0 is quite a few releases old and it’s probably worth updating to the latest (v1.9.0) if that’s not too difficult on your end.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/804#issuecomment-1271477486:82,release,releases,82,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/804#issuecomment-1271477486,1,['release'],['releases']
Deployability,"No, I believe that config.h was it. Otherwise, I just use the already installed headers and the pre-compiled library `libjellyfish-2.0`.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/19#issuecomment-195466899:70,install,installed,70,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/19#issuecomment-195466899,1,['install'],['installed']
Deployability,"No, I take that back. Boost isn't installed in `/usr/` of this system. There's only one boost install.; Perhaps it's mixing compilers GCC 4.8.4 for some modules and 5.3 for others.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/46#issuecomment-193964440:34,install,installed,34,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/46#issuecomment-193964440,2,['install'],"['install', 'installed']"
Deployability,"No, there are no changes here. Further, indices built from version 1.0.0 are *forward-compatible* up through the current release. There is no need to rebuild any indices. Also, though 1.2.1 added a new flag, it made no changes to defaults, so quantifications between 1.2.0 and 1.2.1 are directly comparable.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/505#issuecomment-617940367:121,release,release,121,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/505#issuecomment-617940367,1,['release'],['release']
Deployability,"Nope; nothing special. Once you've installed conda, you simply do:. ```; $ conda config --add channels conda-forge; $ conda config --add channels bioconda; $ conda create -n salmon salmon=0.10.1; ```. then it will give you instructions on how to activate the environment to run salmon.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/232#issuecomment-394755128:35,install,installed,35,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/232#issuecomment-394755128,1,['install'],['installed']
Deployability,"Not a problem @roryk , yes in my understanding of v3 things directly effecting Alevin is just the Umi length increment. Other noticeable changes downstream of Alevin I have observed and seen some comments from @LTLA would be:; * Read length changes from 98 to 91; * The output format of cellranger has changed, [this](https://support.10xgenomics.com/single-cell-gene-expression/software/pipelines/latest/output/matrices) might give full overview.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/324#issuecomment-443237933:387,pipeline,pipelines,387,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/324#issuecomment-443237933,1,['pipeline'],['pipelines']
Deployability,"Note that I do (now) have `cereal` installed, so there is no need for `salmon` to download and build it. It would be nice if this were an option to use the system-provided `cereal` library.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/10#issuecomment-127342739:35,install,installed,35,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/10#issuecomment-127342739,1,['install'],['installed']
Deployability,"Now I am, and I still have the issue.. ; `git clone -b develop https://github.com/COMBINE-lab/salmon`; `git branch -l`; `* develop`. and then I just followed the tutorial: ; ```; cd salmon; mkdir build; cd build; cmake ..; make install; ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/325#issuecomment-443514886:228,install,install,228,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/325#issuecomment-443514886,1,['install'],['install']
Deployability,"OENT (No such file or directory); stat(""/cm/shared/apps/sge/current/lib/linux-x64/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/cm/shared/apps/sge/current/lib/linux-x64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/cm/shared/apps/sge/current/lib/linux-x64"", {st_mode=S_IFDIR|0755, st_size=7, ...}) = 0; open(""/etc/ld.so.cache"", O_RDONLY) = 3; fstat(3, {st_mode=S_IFREG|0644, st_size=100319, ...}) = 0; mmap(NULL, 100319, PROT_READ, MAP_PRIVATE, 3, 0) = 0x7fffbffe4000; close(3) = 0; open(""/lib64/libpthread.so.0"", O_RDONLY) = 3; read(3, ""\177ELF\2\1\1\0\0\0\0\0\0\0\0\0\3\0>\0\1\0\0\0\340]@\3427\0\0\0""..., 832) = 832; fstat(3, {st_mode=S_IFREG|0755, st_size=145896, ...}) = 0; mmap(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7fffbffe3000; mmap(0x37e2400000, 2212848, PROT_READ|PROT_EXEC, MAP_PRIVATE|MAP_DENYWRITE, 3, 0) = 0x37e2400000; mprotect(0x37e2417000, 2097152, PROT_NONE) = 0; mmap(0x37e2617000, 8192, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_DENYWRITE, 3, 0x17000) = 0x37e2617000; mmap(0x37e2619000, 13296, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_ANONYMOUS, -1, 0) = 0x37e2619000; close(3) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/liblzma.so.0"", O_RDONLY) = 3; read(3, ""\177ELF\2\1\1\0\0\0\0\0\0\0\0\0\3\0>\0\1\0\0\0 %\0\0\0\0\0\0""..., 832) = 832; fstat(3, {st_mode=S_IFREG|0644, st_size=130728, ...}) = 0; mmap(NULL, 2226056, PROT_READ|PROT_EXEC, MAP_PRIVATE|MAP_DENYWRITE, 3, 0) = 0x7fffbfdc3000; mprotect(0x7fffbfde2000, 2097152, PROT_NONE) = 0; mmap(0x7fffbffe2000, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_DENYWRITE, 3, 0x1f000) = 0x7fffbffe2000; close(3) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/libtbb.so.2"", O_RDONLY) = 3; read(3, ""\177ELF\2\1\1\0\0\0\0\0\0\0\0\0\3\0>\0\1\0\0\0\320v\1\0\0\0\0\0""..., 832) = 832; fstat(3, {st_mode=S_IFREG|0644, st_si",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:91950,pipeline,pipeline,91950,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,1,['pipeline'],['pipeline']
Deployability,"OENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/tls"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin"", {st_mode=S_IFDIR|0755, st_size=33280, ...}) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/tls/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/tls/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/tls/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/tls"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:8664,pipeline,pipeline,8664,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,4,['pipeline'],['pipeline']
Deployability,"OK --- I think I fixed it; can you re-download the v0.6.0 binary and see if the segfault goes away for you? I think it was the result of failing to give a particular class a default constructor --- a certain variable was being initialized properly on my newer compiler, but that was not the case on the older compiler on the VM where I build the binary. ~~If this resolves the issue for you, I'll probably bump to v0.6.1 just in case anyone tries to build from the source tarball on an older compiler.~~ (I already moved the v0.6.0 tag to point to the new commit and updated the binaries. Hopefully nobody fell through the cracks with the old source tarball, but this doesn't seem like something worth bumping a release for --- assuming my minor change fixes the issue for you as well).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/34#issuecomment-168364366:567,update,updated,567,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/34#issuecomment-168364366,2,"['release', 'update']","['release', 'updated']"
Deployability,"OK, I will try. Do I need to do anything to the binary before installing salmon via bioconda.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/232#issuecomment-394753571:62,install,installing,62,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/232#issuecomment-394753571,1,['install'],['installing']
Deployability,"OK. I successfully installed conda and entered the salmon env and then created the index (I hope correctly, as I am new to the conda env), but now I want to run my samples on our cluster at the university where I do not have permissions to install from source, and therefore the binary version of salmon is installed there. Will there be an incompatibility problem, if I indexed the trasncriptome on my local computer and run salmon using the binary?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/232#issuecomment-395002738:19,install,installed,19,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/232#issuecomment-395002738,3,['install'],"['install', 'installed']"
Deployability,"Oh wow; I had no idea about libgff :). Regarding Jellyfish, there's not a source ""change"" required upstream, rather the fact that I seem to require the `config.h` file that is not installed during the ""normal"" Jellyfish install process. I don't know if you have any idea how one might get around that. Regarding staden, thanks for brining this to my attention. It will probably take a bit for me to wrap my head around the right way to access this information in CMake, but I'll see what I can manage to cobble together on that front (I really wish there was something better, with a less horrendous ""language"" than CMake, but nothing I know of exists that works nearly as well ""out of the box"").",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/19#issuecomment-195436157:180,install,installed,180,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/19#issuecomment-195436157,2,['install'],"['install', 'installed']"
Deployability,"Oh, I also missed that `$prefix/bin/salmon` is marked executable, even for the use who install it.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/761#issuecomment-1067229426:87,install,install,87,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/761#issuecomment-1067229426,1,['install'],['install']
Deployability,"Oh, great, was making a small example data set. I'll stop that then. I was trying to compile, but I can't get Boost installed with linuxbrew for some reason.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/34#issuecomment-168354205:116,install,installed,116,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/34#issuecomment-168354205,1,['install'],['installed']
Deployability,Ok - I will give this a try with` k 31` and `not have keepDuplicates` . Will update soon,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/505#issuecomment-613226597:77,update,update,77,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/505#issuecomment-613226597,1,['update'],['update']
Deployability,Ok --- The sailfish docs should be updated as well [http://sailfish.readthedocs.org/en/master/](http://sailfish.readthedocs.org/en/master/). Let me know if you see something different (i.e. if you still see the salmon instructions over there).,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/27#issuecomment-152844121:35,update,updated,35,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/27#issuecomment-152844121,1,['update'],['updated']
Deployability,"Ok @DarwinAwardWinner, I think it's fixed for real this time. The issue was stemming from an uninitialized prior value in the Gibbs sampler under VBOpt mode (the initialization code was updated on the develop branch, which is where the bug was introduced). This, in turn, was leading to `nan` being passed as the alpha parameter of `std::gamma_distribution`. With the `-Ofast` optimization flags, at least, this leads `std::gamma_distribution()` to hang forever in an infinite loop. Clearly, `nan` should not be passed to `std::gamma_distribution()`, but I'd argue the behavior of looping forever here is not great. Anyway, I fixed the initialization bug, so that this nan should never pop up. Just to be safe, I also changed the default optimization flag to `-O3` so that at least `nan` and `inf` can be properly tested. Since the TBB code and the parallel sampling weren't causing the issue, I've added them back in. Could you please test the latest push (40584e62859fb65463188b50d132c1eb622b21f0) and verify that this resolves the issue for you (*hopefully*!)?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267877253:186,update,updated,186,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267877253,1,['update'],['updated']
Deployability,"Ok @curtisd0886, it should be fixed now! Sorry for the mixup. Everything else (bioconda, docker, etc.) were cut from the tag, but the pre-compiled excitable was mistakenly copied over from the master branch (before the changes were merged in) rather than the tag. I've updated the executable.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/670#issuecomment-860947066:269,update,updated,269,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/670#issuecomment-860947066,1,['update'],['updated']
Deployability,"Ok all; another update. The issue I raise above still exists (differences between calls to `ksw_extz` and `ksw_extz2sse`). *However*, I think that what is happening in this case is actually explained more simply. That is, the positions being reported by salmon are _correct_ given the optimal alignment. Specifically, salmon is performing an end-to-end alignment of the read, and the optimal alignment here includes an indel of length 3 in the initial portion of the read. If we were outputting the CIGAR string along with the position, then the bases would line up because the ""off by 3"" issue that happens above for the reads would be addressed when walking the CIGAR. However, we don't (currently) output the CIGAR — rather, we output a decoy CIGAR that does not represent the optimal alignment as computed by ksw2. So, if we assume all matches / mismatches (an indel-free prefix for this read), then we see the position shift noted in the initial bug report. I think the easiest solution, for the time being at least, is to report the position as if the prefix before the first MEM is indel free under the optimal alignment (even if it is not and the optimal score reflects that). However, if there are other suggestions for the best way to address this, I'm open to those as well.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/475#issuecomment-574719940:16,update,update,16,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/475#issuecomment-574719940,1,['update'],['update']
Deployability,"Ok so 0.8.0 contains the option to turn off all length correction, but I've pushed back the milestone for fully supporting the barcoding. This is because there's already a lot of new stuff in 0.8.0 and I needed to cut a release to coincide with the paper. Just dropping in here to explain the modified milestone and re-iterate my interest in and commitment to this feature ;P.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/108#issuecomment-274638652:220,release,release,220,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/108#issuecomment-274638652,1,['release'],['release']
Deployability,"Ok, I was able to reproduce your issue. Interestingly, it happens for me _only_ with the pre-compiled binary. My guess is that it's a problem with using both default and implicit options with the older version of boost with which the pre-compiled binary was made (I make the binary under a docker image with an old version of CentOS to maximize compatibility). A temporary work-around is to use the form `--writeMapping=test_output/mappings_info`, which seems to solve the issue that was occurring. I'll make a note of this on the release page and see if I can find a way around this when building the next binary release.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/86#issuecomment-244935740:531,release,release,531,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/86#issuecomment-244935740,2,['release'],['release']
Deployability,"Ok, I will update that with a bioconda install under the Docker image, I am also unable to reproduce the issue. I imagine there must be some other difference causing this issue. Might you be able to try inside a docker image on your environment? This would isolate potential library differences, I think.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/250#issuecomment-404315458:11,update,update,11,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/250#issuecomment-404315458,2,"['install', 'update']","['install', 'update']"
Deployability,"Ok, I've tracked down and fixed the bug. I'll be tagging a new release with the fix soon. I'll ping back here and close this issue when the new release is out.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/129#issuecomment-287431196:63,release,release,63,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/129#issuecomment-287431196,2,['release'],['release']
Deployability,"Ok, I've updated the docs and added an explicit note about this in commit 95866337bde0feb57a0c3231efdfa26c847ba141. It has propagated to the documentation now. Thanks again for reporting this and offering this suggestion.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/118#issuecomment-278133154:9,update,updated,9,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/118#issuecomment-278133154,1,['update'],['updated']
Deployability,"Ok, in fact, when I check with the ""older"" reference (from ftp://ftp.ensembl.org/pub/release-79/fasta/homo_sapiens/cdna/Homo_sapiens.GRCh38.cdna.all.fa.gz), I get that these transcripts are _not_ duplicates of each other. To verify it's not salmon's problem, I also checked with [seqkit's rmdup command](https://bioinf.shenwei.me/seqkit/usage/#rmdup), and, in fact, in the older cdna file, these transcripts appear to have distinct sequence.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/301#issuecomment-429504101:85,release,release-,85,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/301#issuecomment-429504101,1,['release'],['release-']
Deployability,"Ok, not urgent. I installed 0.8.2 from source with no problem, so I'll just use that for now. I have just come to take homebrew's convenience for granted!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/142#issuecomment-315820645:18,install,installed,18,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/142#issuecomment-315820645,1,['install'],['installed']
Deployability,"Ok, pushed to [bioconda](https://github.com/bioconda/bioconda-recipes/pull/17922/checks?check_run_id=248588035), should be available in a couple of hours. Once it's available I'll make the official release too on the github. It'd be great if you can quickly test the new release for the bug once it's available. Thanks again !",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/431#issuecomment-538581395:198,release,release,198,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/431#issuecomment-538581395,2,['release'],['release']
Deployability,"Ok, salmon V1.0.0 finished in 5H 15 min, so about 5 times faster, the exact same library and parameters, and achieved almost the same mapping rate (85.1058% with V1.2.0 vs 84.6341% with V1.0.0) attaching log. I must add I did not trim this library for adapters nor quality, nor did anything to it. Just mapped as is. But fastQC showed excellent levels of quality even at the ends and no or minimal adapter content. ; Also no changes have been done one my OS other than regular updates, but still Ubuntu 18.04. I don't remember any specific changes I've done to it. ; Pearson's correlation in transcript abundance (isoform lelvel) is 0.9984013. Spearman's is 0.9899048. ; Also, I did checked that salmon was actually using 4 threads in both cases, and it was fully using those.; [salmon_quant.log](https://github.com/COMBINE-lab/salmon/files/4707443/salmon_quant.log)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/527#issuecomment-636447127:477,update,updates,477,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/527#issuecomment-636447127,1,['update'],['updates']
Deployability,"Ok, so this mapping rate looks perfectly normal. Can you share some of these reads so I can see if I can reproduce the error on my end? Also, do you see this issue when / if you use the pre-compiled binary included on the GitHub release page (i.e. just to make sure the problem isn't specific to the bioconda executable)?. Thanks,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/261#issuecomment-409428971:229,release,release,229,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/261#issuecomment-409428971,1,['release'],['release']
Deployability,"Ok, so using your `while true; do salmon; done` paradigm, I was able to reproduce the issue on your original dataset after a few runs each time. This has made working on the issue much easier. After a lot of debugging and walking through the stack, I'm almost certain the issue is a ""rare"" deadlock bug in the Intel TBB library. They mention having fixed this in the latest release. So, I've updated our CMake file to fetch [that release](https://github.com/01org/tbb/releases/tag/2017_U3). After upgrading to this version of TBB, I've let the data set run all night long (~8 hours so far) and have not seen the hanging behavior. I'll let it keep running for a while, but could you try pulling the latest commit from develop and see if that resolves the problem for you? You'll need to make sure you clean the build directory and remove the previous `CMakeCache.txt` files so that it will pull in and build the new TBB. You'll also need to make sure that these TBB libraries are the ones that are being used by Salmon. Please let me know if this fixes the hanging for you as well (and I'll let you know if I see it again).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267766795:374,release,release,374,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267766795,4,"['release', 'update']","['release', 'releases', 'updated']"
Deployability,"Ok, when I attempt the build the way you say above, I get the following error during CMake:. ```; -- fetch PUFFERFISH exit code 127; CMake Error at CMakeLists.txt:317 (message):; Could not fetch pufferfish source [fetchPufferfish.sh returned exit code; 127]. -- Configuring incomplete, errors occurred!; See also ""/salmon-1.10.0/build/CMakeFiles/CMakeOutput.log"".; ```. It seems `wget`, `curl` and `unzip` were missing, and I had to install them. After that, I was able to build and install. At that point, I was able to reproduce the issue! So, it seems to me the underlying problem is coming from one of the upstream dependencies (i.e. libraries being linked to). I will try see if I can find the offender. In general, we like to statically link salmon for exactly this reason. Outside of package systems with which I am familiar (e.g. conda), we don't have a lot of experience in specifying dependent package version constrains, which I believe to be at fault here.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463973824:433,install,install,433,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463973824,2,['install'],['install']
Deployability,"Okay, now I am on a physical Ubuntu 19.04. I am leaving out most travails. [Don't allow ubuntu gui to install conda.]. Salmon (in the conda evironment) is going differently ! Skip to Try 2. below for success; Try 1.; Index seemed to go the same as before, using the command [from a script]; salmon index -t decoys/gentrome.fa -d decoys/decoys.txt -i salmonIndexDecoyMouse; but then command; salmon quant -p 3 -i salmonIndexDecoyMouse -l A -1 SRR1818187_2.fastq.gz -2 SRR1818187_1.fastq.gz --validateMappings -o Salmontranscripts_quant; Fails as follows, saying it cannot find a .json file(s); ---------------------------------------------------------------------; (salmon) wayne@Ubuntu19:~/rnaseq$ sh salmonQuantDecoy.sh ; Version Info: This is the most recent version of salmon.; ### salmon (mapping-based) v0.14.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ threads ] => { 3 }; ### [ index ] => { salmonIndexDecoyMouse }; ### [ libType ] => { A }; ### [ mates1 ] => { SRR1818187_2.fastq.gz }; ### [ mates2 ] => { SRR1818187_1.fastq.gz }; ### [ validateMappings ] => { }; ### [ output ] => { Salmontranscripts_quant }; Logs will be written to Salmontranscripts_quant/logs; [2019-08-25 11:40:44.518] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2019-08-25 11:40:44.518] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2019-08-25 11:40:44.518] [jointLog] [info] Usage of --validateMappings, without --hardFilter implies use of range factorization. rangeFactorizationBins is being set to 4; [2019-08-25 11:40:44.518] [jointLog] [info] Usage of --validateMappings implies a default consensus slack of 0.2. Setting consensusSlack to 0.2.; [2019-08-25 11:40:44.518] [jointLog] [info] parsing read library format; [2019-08-25 11:40:44.518] [jointLog] [info] There is 1 library.; Exception : [Error: The index version file salmonIndexDeco",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/419#issuecomment-524651435:102,install,install,102,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/419#issuecomment-524651435,1,['install'],['install']
Deployability,"Okay, so I've made some progress. After deleting the Cache.txt file I tried to build again at which point I noticed the following:; **WARNING: Target ""salmon"" requests linking to directory ""/users/work/jake/bin/zlib-1.2.11/"". Targets may link only to libraries. CMake is dropping the item.**; **WARNING: Target ""unitTests"" requests linking to directory ""/users/work/jake/bin/zlib-1.2.11/"". Targets may link only to libraries. CMake is dropping the item.**. So I actually went back a step and check my initial cmake command in the ../salmon-0.8.2/build/ directory. It also had the same issue and therefore wasn't building correctly. I started the install again from ../salmon-0.8.2/build/ using the following: . cmake -DBOOST_ROOT=/users/work/jake/bin/boost_1_64_0/ -DZLIB_LIBRARY=/users/work/jake/bin/zlib-1.2.11/zlib.h .. . It seemed to work nicely and I got all the build files to propagate into the ../salmon-0.8.2/build/ directory. From here I ran 'make' which did a whole bunch of things I hadn't seen it do yet, so assumably it was working as intended. This is until it got to the following stage:. Scanning dependencies of target libbwa; [ 48%] Creating directories for 'libbwa'; [ 49%] Performing download step for 'libbwa'; % Total % Received % Xferd Average Speed Time Time Time Current; Dload Upload Total Spent Left Speed; 100 125 0 125 0 0 167 0 --:--:-- --:--:-- --:--:-- 167; 0 0 0 219k 0 0 123k 0 --:--:-- 0:00:01 --:--:-- 326k; bwa-master.tar.gz: OK; bwa-0.7.12.3/.gitignore; bwa-0.7.12.3/.travis.yml; bwa-0.7.12.3/COPYING; bwa-0.7.12.3/ChangeLog; bwa-0.7.12.3/Makefile; bwa-0.7.12.3/NEWS.md; bwa-0.7.12.3/QSufSort.c; bwa-0.7.12.3/QSufSort.h; bwa-0.7.12.3/README-alt.md; bwa-0.7.12.3/README.md; bwa-0.7.12.3/bamlite.c; bwa-0.7.12.3/bamlite.h; bwa-0.7.12.3/bntseq.c; bwa-0.7.12.3/bntseq.h; bwa-0.7.12.3/bwa.1; bwa-0.7.12.3/bwa.c; bwa-0.7.12.3/bwa.h; bwa-0.7.12.3/bwakit/; bwa-0.7.12.3/bwakit/README.md; bwa-0.7.12.3/bwakit/bwa-postalt.js; bwa-0.7.12.3/bwakit/run-HLA; bwa-0.7.12.3/bwak",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/141#issuecomment-314451873:646,install,install,646,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/141#issuecomment-314451873,1,['install'],['install']
Deployability,"Oki, so I have updated a couple of things in the latest commit on the develop branch, which should make the things more streamlined. . * `maxNumBarcodes`: As you have initially used `maxNumBarcodes` which is by default set to 100k it means. by default alevin quantifies 100k CBs which includes both the low and high confidence CB count. You can change this number accordingly to set the universe of the top CB to quantify.; * `KeepCBFraction` : It defines what fraction of `maxNumBarcodes` to be used as the high confidence barcodes and should definitely generate the quants for. If set to 1 then everything is high confidence and the whitelisting cannot be performed. Thanks to this issue, alevin will not fail without error when there is no low confidence CB is found instead it checks if the number of low confidence CB is less than `lowRegionMinBarcodes` (default to 200), alevin will warn and not perform the whitelisting.; * `freqThreshold`: This is used to filter out most obvious cases to filter out CB with frequency less than set by the parameter (default to 10). Hope this help ! I am also testing on my end for any other potential bug. Please let me know if you get a chance to check the develop branch .",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/379#issuecomment-503396823:15,update,updated,15,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/379#issuecomment-503396823,1,['update'],['updated']
Deployability,"On my system, `cmake` found (somehow, I didn't tell it) TBB that is installed in `/usr/local/opt/tbb/lib/libtbb.dylib`. What does `otool -L salmon` report on your system after `make install`?. ``` sh; ❯❯❯ otool -L ~/tmp/salmon/bin/salmon; /Users/sjackman/tmp/salmon/bin/salmon:; /usr/lib/libz.1.dylib (compatibility version 1.0.0, current version 1.2.5); /usr/lib/libSystem.B.dylib (compatibility version 1.0.0, current version 1226.10.1); /usr/lib/libbz2.1.0.dylib (compatibility version 1.0.0, current version 1.0.5); /usr/local/opt/tbb/lib/libtbb.dylib (compatibility version 0.0.0, current version 0.0.0); /usr/local/opt/tbb/lib/libtbbmalloc.dylib (compatibility version 0.0.0, current version 0.0.0); /usr/lib/libc++.1.dylib (compatibility version 1.0.0, current version 120.1.0); ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/70#issuecomment-239594511:68,install,installed,68,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/70#issuecomment-239594511,2,['install'],"['install', 'installed']"
Deployability,"One fast way using pseudo-alignments should be Kallisto+[Manta|Pizzly], but I haven't tried that myself. We decided to go with full transcriptome alignments instead and integrated EricScript into bcbio. We'd still be interested in something more modern, though.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/52#issuecomment-280827732:169,integrat,integrated,169,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/52#issuecomment-280827732,1,['integrat'],['integrated']
Deployability,"Oops. Just saw that `master` is already pointing at boost 1_59. What branch should one use for a new install ? master, 0.5.0 ?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/23#issuecomment-153149314:101,install,install,101,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/23#issuecomment-153149314,1,['install'],['install']
Deployability,Or it should honour `$MAKEFLAGS` somehow. Patching now in brew: https://github.com/brewsci/homebrew-bio/pull/747. `CMakelist.txt =~ s/-d0 -j2/\$MAKEFLAGS/`,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/412#issuecomment-525503233:42,Patch,Patching,42,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/412#issuecomment-525503233,1,['Patch'],['Patching']
Deployability,"P_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7fffbea00000; fstat(3, {st_mode=S_IFREG|0644, st_size=0, ...}) = 0; lseek(3, 0, SEEK_SET) = 0; mmap(NULL, 8388608, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_NORESERVE, -1, 0) = 0x7fffbe200000; mmap(NULL, 1073745920, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_STACK, -1, 0) = 0x7fff3e5eb000; mprotect(0x7fff3e5eb000, 4096, PROT_NONE) = 0; clone(child_stack=0x7fff7e5eaed0, flags=CLONE_VM|CLONE_FS|CLONE_FILES|CLONE_SIGHAND|CLONE_THREAD|CLONE_SYSVSEM|CLONE_SETTLS|CLONE_PARENT_SETTID|CLONE_CHILD_CLEARTID, parent_tidptr=0x7fff7e5eb9d0, tls=0x7fff7e5eb700, child_tidptr=0x7fff7e5eb9d0) = 10740; mmap(NULL, 8388608, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_NORESERVE, -1, 0) = 0x7fffbda00000; mmap(NULL, 1073745920, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_STACK, -1, 0) = 0x7ffefe5ea000; mprotect(0x7ffefe5ea000, 4096, PROT_NONE) = 0; clone(child_stack=0x7fff3e5e9ed0, flags=CLONE_VM|CLONE_FS|CLONE_FILES|CLONE_SIGHAND|CLONE_THREAD|CLONE_SYSVSEM|CLONE_SETTLS|CLONE_PARENT_SETTID|CLONE_CHILD_CLEARTID, parent_tidptr=0x7fff3e5ea9d0, tls=0x7fff3e5ea700, child_tidptr=0x7fff3e5ea9d0) = 10741; mmap(NULL, 8388608, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_NORESERVE, -1, 0) = 0x7fffbd200000; mmap(NULL, 1073745920, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_STACK, -1, 0) = 0x7ffebe5e9000; mprotect(0x7ffebe5e9000, 4096, PROT_NONE) = 0; clone(child_stack=0x7ffefe5e8ed0, flags=CLONE_VM|CLONE_FS|CLONE_FILES|CLONE_SIGHAND|CLONE_THREAD|CLONE_SYSVSEM|CLONE_SETTLS|CLONE_PARENT_SETTID|CLONE_CHILD_CLEARTID, parent_tidptr=0x7ffefe5e99d0, tls=0x7ffefe5e9700, child_tidptr=0x7ffefe5e99d0) = 10742; clock_gettime(CLOCK_REALTIME, {1491423878, 504035343}) = 0; gettid() = 10693; clock_gettime(CLOCK_REALTIME, {1491423878, 507735356}) = 0; stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts/versionInfo.json"", {st_mode=S_IFREG|0775, st_size=96, ...}) = ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:70962,pipeline,pipeline,70962,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,1,['pipeline'],['pipeline']
Deployability,"P_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7fffbea00000; fstat(3, {st_mode=S_IFREG|0644, st_size=0, ...}) = 0; lseek(3, 0, SEEK_SET) = 0; mmap(NULL, 8388608, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_NORESERVE, -1, 0) = 0x7fffbe200000; mmap(NULL, 1073745920, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_STACK, -1, 0) = 0x7fff3e5eb000; mprotect(0x7fff3e5eb000, 4096, PROT_NONE) = 0; clone(child_stack=0x7fff7e5eaed0, flags=CLONE_VM|CLONE_FS|CLONE_FILES|CLONE_SIGHAND|CLONE_THREAD|CLONE_SYSVSEM|CLONE_SETTLS|CLONE_PARENT_SETTID|CLONE_CHILD_CLEARTID, parent_tidptr=0x7fff7e5eb9d0, tls=0x7fff7e5eb700, child_tidptr=0x7fff7e5eb9d0) = 14650; mmap(NULL, 8388608, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_NORESERVE, -1, 0) = 0x7fffbda00000; mmap(NULL, 1073745920, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_STACK, -1, 0) = 0x7ffefe5ea000; mprotect(0x7ffefe5ea000, 4096, PROT_NONE) = 0; clone(child_stack=0x7fff3e5e9ed0, flags=CLONE_VM|CLONE_FS|CLONE_FILES|CLONE_SIGHAND|CLONE_THREAD|CLONE_SYSVSEM|CLONE_SETTLS|CLONE_PARENT_SETTID|CLONE_CHILD_CLEARTID, parent_tidptr=0x7fff3e5ea9d0, tls=0x7fff3e5ea700, child_tidptr=0x7fff3e5ea9d0) = 14651; mmap(NULL, 8388608, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_NORESERVE, -1, 0) = 0x7fffbd200000; mmap(NULL, 1073745920, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_STACK, -1, 0) = 0x7ffebe5e9000; mprotect(0x7ffebe5e9000, 4096, PROT_NONE) = 0; clone(child_stack=0x7ffefe5e8ed0, flags=CLONE_VM|CLONE_FS|CLONE_FILES|CLONE_SIGHAND|CLONE_THREAD|CLONE_SYSVSEM|CLONE_SETTLS|CLONE_PARENT_SETTID|CLONE_CHILD_CLEARTID, parent_tidptr=0x7ffefe5e99d0, tls=0x7ffefe5e9700, child_tidptr=0x7ffefe5e99d0) = 14652; clock_gettime(CLOCK_REALTIME, {1491424829, 790500042}) = 0; gettid() = 14648; clock_gettime(CLOCK_REALTIME, {1491424829, 791313810}) = 0; stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts/versionInfo.json"", {st_mode=S_IFREG|0775, st_size=96, ...}) = ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:151863,pipeline,pipeline,151863,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,1,['pipeline'],['pipeline']
Deployability,"P_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7fffbea00000; fstat(3, {st_mode=S_IFREG|0644, st_size=0, ...}) = 0; lseek(3, 0, SEEK_SET) = 0; mmap(NULL, 8388608, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_NORESERVE, -1, 0) = 0x7fffbe200000; mmap(NULL, 1073745920, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_STACK, -1, 0) = 0x7fff3e5eb000; mprotect(0x7fff3e5eb000, 4096, PROT_NONE) = 0; clone(child_stack=0x7fff7e5eaed0, flags=CLONE_VM|CLONE_FS|CLONE_FILES|CLONE_SIGHAND|CLONE_THREAD|CLONE_SYSVSEM|CLONE_SETTLS|CLONE_PARENT_SETTID|CLONE_CHILD_CLEARTID, parent_tidptr=0x7fff7e5eb9d0, tls=0x7fff7e5eb700, child_tidptr=0x7fff7e5eb9d0) = 32683; mmap(NULL, 8388608, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_NORESERVE, -1, 0) = 0x7fffbda00000; mmap(NULL, 1073745920, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_STACK, -1, 0) = 0x7ffefe5ea000; mprotect(0x7ffefe5ea000, 4096, PROT_NONE) = 0; clone(child_stack=0x7fff3e5e9ed0, flags=CLONE_VM|CLONE_FS|CLONE_FILES|CLONE_SIGHAND|CLONE_THREAD|CLONE_SYSVSEM|CLONE_SETTLS|CLONE_PARENT_SETTID|CLONE_CHILD_CLEARTID, parent_tidptr=0x7fff3e5ea9d0, tls=0x7fff3e5ea700, child_tidptr=0x7fff3e5ea9d0) = 32684; mmap(NULL, 8388608, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_NORESERVE, -1, 0) = 0x7fffbd200000; mmap(NULL, 1073745920, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_STACK, -1, 0) = 0x7ffebe5e9000; mprotect(0x7ffebe5e9000, 4096, PROT_NONE) = 0; clone(child_stack=0x7ffefe5e8ed0, flags=CLONE_VM|CLONE_FS|CLONE_FILES|CLONE_SIGHAND|CLONE_THREAD|CLONE_SYSVSEM|CLONE_SETTLS|CLONE_PARENT_SETTID|CLONE_CHILD_CLEARTID, parent_tidptr=0x7ffefe5e99d0, tls=0x7ffefe5e9700, child_tidptr=0x7ffefe5e99d0) = 32685; clock_gettime(CLOCK_REALTIME, {1491423877, 940907968}) = 0; gettid() = 32681; clock_gettime(CLOCK_REALTIME, {1491423877, 941299576}) = 0; stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts/versionInfo.json"", {st_mode=S_IFREG|0775, st_size=96, ...}) = ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:34186,pipeline,pipeline,34186,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,1,['pipeline'],['pipeline']
Deployability,"P_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7fffbea00000; fstat(3, {st_mode=S_IFREG|0644, st_size=0, ...}) = 0; lseek(3, 0, SEEK_SET) = 0; mmap(NULL, 8388608, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_NORESERVE, -1, 0) = 0x7fffbe200000; mmap(NULL, 1073745920, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_STACK, -1, 0) = 0x7fff3e5eb000; mprotect(0x7fff3e5eb000, 4096, PROT_NONE) = 0; clone(child_stack=0x7fff7e5eaed0, flags=CLONE_VM|CLONE_FS|CLONE_FILES|CLONE_SIGHAND|CLONE_THREAD|CLONE_SYSVSEM|CLONE_SETTLS|CLONE_PARENT_SETTID|CLONE_CHILD_CLEARTID, parent_tidptr=0x7fff7e5eb9d0, tls=0x7fff7e5eb700, child_tidptr=0x7fff7e5eb9d0) = 51998; mmap(NULL, 8388608, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_NORESERVE, -1, 0) = 0x7fffbda00000; mmap(NULL, 1073745920, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_STACK, -1, 0) = 0x7ffefe5ea000; mprotect(0x7ffefe5ea000, 4096, PROT_NONE) = 0; clone(child_stack=0x7fff3e5e9ed0, flags=CLONE_VM|CLONE_FS|CLONE_FILES|CLONE_SIGHAND|CLONE_THREAD|CLONE_SYSVSEM|CLONE_SETTLS|CLONE_PARENT_SETTID|CLONE_CHILD_CLEARTID, parent_tidptr=0x7fff3e5ea9d0, tls=0x7fff3e5ea700, child_tidptr=0x7fff3e5ea9d0) = 51999; mmap(NULL, 8388608, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_NORESERVE, -1, 0) = 0x7fffbd200000; mmap(NULL, 1073745920, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_STACK, -1, 0) = 0x7ffebe5e9000; mprotect(0x7ffebe5e9000, 4096, PROT_NONE) = 0; clone(child_stack=0x7ffefe5e8ed0, flags=CLONE_VM|CLONE_FS|CLONE_FILES|CLONE_SIGHAND|CLONE_THREAD|CLONE_SYSVSEM|CLONE_SETTLS|CLONE_PARENT_SETTID|CLONE_CHILD_CLEARTID, parent_tidptr=0x7ffefe5e99d0, tls=0x7ffefe5e9700, child_tidptr=0x7ffefe5e99d0) = 52000; clock_gettime(CLOCK_REALTIME, {1491424815, 587265106}) = 0; gettid() = 51996; clock_gettime(CLOCK_REALTIME, {1491424815, 588110132}) = 0; stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts/versionInfo.json"", {st_mode=S_IFREG|0775, st_size=96, ...}) = ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:109544,pipeline,pipeline,109544,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,1,['pipeline'],['pipeline']
Deployability,"Perfect, thank you for the quick update!; Emily",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/118#issuecomment-278461497:33,update,update,33,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/118#issuecomment-278461497,1,['update'],['update']
Deployability,Please see attached patch here. I did not realized my writing was stylized which; wiped out correct syntax. Nadya; [salmon-1.1.0.patch.txt](https://github.com/COMBINE-lab/salmon/files/4382067/salmon-1.1.0.patch.txt),MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/497#issuecomment-603936569:20,patch,patch,20,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/497#issuecomment-603936569,3,['patch'],['patch']
Deployability,"RCm38.86.gtf.gz. all from ensembl version 86. ## Workflow; - I built a STAR index with the GTF and genome FASTA files listed above. ; - The FASTQ files were extracted from the SRA experiment with [fastq-dump](https://trace.ncbi.nlm.nih.gov/Traces/sra/sra.cgi?view=toolkit_doc&f=fastq-dump).; - Reads were aligned with STAR to the index and `unsorted` alignments to the transcriptome were returned (this keeps the paired-ends next to each other). I noticed that the cDNA FASTA files from ensembl include the transcript version, e.g. `ENSMUST00000178537.1` in the FASTA header. The GTF file specifies the transcript id and its version in different fields. Therefore, the STAR index does not include the version suffix. Instead, only the transcript ids are listed, e.g. `ENSMUST00000178537`. To provide a FASTA file with transcript identifiers that match those in STAR's BAM file, I pre-processed Ensembl's FASTA file with the following command:. ```; wget ftp://ftp.ensembl.org/pub/release-86/fasta/mus_musculus/cdna/Mus_musculus.GRCm38.cdna.all.fa.gz; gunzip Mus_musculus.GRCm38.cdna.all.fa.gz; cut -f1 -d ""."" Mus_musculus.GRCm38.cdna.all.fa > transcripts_unversioned.fa. head transcripts_unversioned.fa; >ENSMUST00000178537; GGGACAGGGGGC; >ENSMUST00000178862; GGGACTGGGGGGGC; >ENSMUST00000196221; ATGGCATAT; >ENSMUST00000179664; ATGGCATATCA; >ENSMUST00000177564; ATCGGAGGGATACGAG; [truncated]; ```. Then I try to run `salmon`:. ```; wget ftp://ftp.ensembl.org/pub/release-86/gtf/mus_musculus/Mus_musculus.GRCm38.86.gtf.gz; gunzip Mus_musculus.GRCm38.86.gtf.gz; salmon quant -t transcripts_unversioned.fa -g Mus_musculus.GRCm38.86.gtf -l IU -p 1 -o quantitation -a subsample.bam --seqBias --gcBias; ```. but get the segmentation fault. Omitting the `--seqBias --gcBias` options makes it work. Perhaps you can already spot where I am doing something wrong? If not, you can find the subsample.bam file [here](https://drive.google.com/open?id=0BzX9viKJksNtak0xako0VXptLW8). (The other files are publicall",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/104#issuecomment-261744459:1890,release,release-,1890,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/104#issuecomment-261744459,1,['release'],['release-']
Deployability,"RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/tls/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/tls/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/tls"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin"", {st_mode=S_IFDIR|0755, st_size=33280, ...}) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/tls/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/tls/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/tls/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/tls"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/x86_64",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:8330,pipeline,pipeline,8330,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,4,['pipeline'],['pipeline']
Deployability,"RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin"", {st_mode=S_IFDIR|0755, st_size=33280, ...}) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/tls/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/tls/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/tls/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/tls"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/jhpce/shared/community/core/pcre/8.36/lib/tls/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/jhpce/shared/community/core/pcre/8.36/lib/tls/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/jhpce/",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:9100,install,install,9100,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,8,"['install', 'pipeline']","['install', 'pipeline']"
Deployability,"Rather than hang you up in any way waiting on a release that adds ancillary improvements, I'm just putting an updated binary right here that addresses this issue. Please let me know if this allows you to run your dataset on the large index successfully.; [SalmonBeta-0.6.5-pre_CentOS5.tar.gz](https://github.com/COMBINE-lab/salmon/files/197982/SalmonBeta-0.6.5-pre_CentOS5.tar.gz)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/54#issuecomment-203990167:48,release,release,48,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/54#issuecomment-203990167,2,"['release', 'update']","['release', 'updated']"
Deployability,"Regarding the last point, cc @Gaura. Regarding a description of the read geometry, it can be found in the release notes for salmon 1.4.0 [here](https://github.com/COMBINE-lab/salmon/releases/tag/v1.4.0). Though, we should certainly add something to the full docs.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/816#issuecomment-1344442434:106,release,release,106,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/816#issuecomment-1344442434,2,['release'],"['release', 'releases']"
Deployability,Released in v1.9.0 🎉 ! Let us know if you have any questions about or trouble with the feature.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/756#issuecomment-1164760347:0,Release,Released,0,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/756#issuecomment-1164760347,1,['Release'],['Released']
Deployability,"Rhapsody has introduced a new, shorter cell barcode specification to work with 51bp R1, which looks like this:. ```; 5' PFX - CLS1 - L1 - CLS2 - L2 - CLS3 - UMI - poly(T); 9 4 9 4 9 8 8; [1-9] [14-22] [27-35][36-43]; ```. The linker sequences are as follows:. L1: `GTGA`; L2: `GACA`. In other words,. --umi-geometry '1[36-43]' --bc-geometry '1[1-9,14-22,27-35]' --read-geometry '2[1-end]'. **However...** [update]. In order to remove the need for Lambda spike-ins on Illumina runs, Rhapsody has included a 0-3bp cell barcode prefix, where either nothing, or `A/GT/TCA` are added to the front of some cell barcodes. Here are the full descriptions:. ```; # Long sequence:; # 0123456789012345678901234567890123456789012345678901234567890123456789012345; # [--BC1--][----L1----][--BC2--][----L02----][--BC3--][-UMI1-][TTTTTTTTTTTTTT]; # L1 = ACTGGCCTGCGA; L2 = GGTAGCGGTGACA; # Short sequence:; # 012345678901234567890123456789012345678901234567890; # [--BC1--][L1][--BC2--][L2][--BC3--][-UMI1-][TTTTTT]; # L1 = GTGA; L2 = GACA; # Note: short sequence can also be prepended with A/GT/TCA to improve Illumina base; # call distributions, i.e.; # [--BC1--][L1][--BC2--][L2][--BC3--][-UMI1-][TTTTTT]; # A[--BC1--][L1][--BC2--][L2][--BC3--][-UMI1-][TTTTT]; # GT[--BC1--][L1][--BC2--][L2][--BC3--][-UMI1-][TTTT]; # TCA[--BC1--][L1][--BC2--][L2][--BC3--][-UMI1-][TTT]; ```. This means that the regions defined in the geometry specification above can appear up to 3bp away from their expected region. I've updated my barcode squishing script ([here](https://gitlab.com/gringer/bioinfscripts/-/blob/master/synthSquish.pl)) to account for this. The script identifies the cell barcode regions, corrects cell barcode sequences according to the Rhapsody Bioinformatics manual, and then shifts the linker sequences to after the UMI region, i.e.:. # 012345678901234567890123456789012345678901234567890...; # [--BC1--][--BC2--][--BC3--][-UMI1-][L1][L2][TTTTTT...]. [The prefix sequence is discarded]. After using this scr",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/628#issuecomment-1277030250:406,update,update,406,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/628#issuecomment-1277030250,1,['update'],['update']
Deployability,"Right I've been checking it without the trailing character as well, I changed to leaving that out. . Oddly, my index doesn't have the decimals at all, just continuous ENSTxx, unlike the examples you and Rob provided. I redownloaded the new release, same result. No duplicate in my grep query, which would lead to getting the quant for both transcripts. Not being filtered by salmon as duplicates. I also downloaded the same version in Rob's example above, indexed with latest salmon, with the same result. At a loss right now. I don't know why this is.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/301#issuecomment-429501783:156,continuous,continuous,156,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/301#issuecomment-429501783,2,"['continuous', 'release']","['continuous', 'release']"
Deployability,"Right, in short `salmon index -t txome_fasta -i txome_index` should work and both the versions of salmon (v0.15 and v1.0) is available on bioconda, check [here](https://bioconda.github.io/recipes/salmon/README.html), you may wanna try [force](https://docs.conda.io/projects/conda/en/latest/commands/update.html) update of conda. I think the confusion is you are thinking of the concept of Selective Alignment as the same as aligning to transcriptome w/ decoys (can be genome or mashmap based). Although they are related methods but the concept of Selective Alignment predates the idea of decoy based alignment, checkout [this](https://dl.acm.org/citation.cfm?id=3233589) paper from our lab where we discuss how Selectively Aligning difficult reads to just the transcriptome itself can result in improved quantification estimates compared to quasi or pseduo alignment. To summarize: ; In version 1.0; A) SA: The mashmap and bedtools based pipeline which follows old SalmonTools based pipeline.; B) SAF: Inbuilt salmon pipeline to consume genome and follows this pipeline.; C) If you don't provide any decoys, salmon will do Selective Alignment just on the transcriptome. The Release notes you quoted just means you cannot disable this feature i.e. you cannot fall back to quasi-mapping (in quasi mapping there is no alignment of the reads at all). In version 0.15.0; You cannot provide decoys and the transcriptome based mapping performed in this version would be quasi-mapping i.e. no Alignment of reads. Hope it helps .",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/442#issuecomment-549195321:299,update,update,299,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/442#issuecomment-549195321,7,"['Release', 'pipeline', 'update']","['Release', 'pipeline', 'update']"
Deployability,"Right, so at the end of the quantification pipeline you should have the file `whitelist.txt` which you can use as a high confidence barcodes and filter the full matrix file.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/739#issuecomment-1024658484:43,pipeline,pipeline,43,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/739#issuecomment-1024658484,1,['pipeline'],['pipeline']
Deployability,"Right, the issue seems to be that the right binary is not getting created. My (re)compilation using the same script you shared above seems to be giving different help.; ```; alevin-specific Options:; -v [ --version ] print version string; -h [ --help ] produce help message; -o [ --output ] arg Output quantification directory.; -p [ --threads ] arg (=1) The number of threads to use; concurrently.; --tgMap arg transcript to gene map tsv file; --dropseq Use DropSeq Single Cell protocol for; the library; --chromiumV3 Use 10x chromium v3 Single Cell; protocol for the library.; --chromium Use 10x chromium v2 Single Cell; protocol for the library.; --gemcode Use 10x gemcode v1 Single Cell protocol; for the library.; --celseq Use CEL-Seq Single Cell protocol for; the library.; --celseq2 Use CEL-Seq2 Single Cell protocol for; the library.; ```. May I suggest removing the `CMakeCache.txt` file from the build folder of salmon and running `make -j 4 install` again. After recompilation using the `salmon` binary inside the `bin` folder should ideally give you the above updated help. However, If it doesn't resolve after that, I am compiling a linux binary and will share it to you to be used directly.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/325#issuecomment-443518366:952,install,install,952,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/325#issuecomment-443518366,2,"['install', 'update']","['install', 'updated']"
Deployability,"Right; so this has been fixed upstream and the limitation will be removed in the next release. As @k3yavi says, one option is to modify the reference input names to be of length <255. The other option is to make use of the 0.15.0 release, which does not have this limitation, until the next release that fixes this under the pufferfish-based index.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/451#issuecomment-558449963:86,release,release,86,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/451#issuecomment-558449963,3,['release'],['release']
Deployability,Rob mentioned to us at some point that this was possibly on the roadmap. It would really be a very useful feature. Any updates on this?,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/138#issuecomment-585340775:119,update,updates,119,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/138#issuecomment-585340775,1,['update'],['updates']
Deployability,"Rob, thank you very much for your response. I am already patching the source as i need to work; with stable and not development versions. Best regards, Nadya.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/496#issuecomment-603335132:57,patch,patching,57,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/496#issuecomment-603335132,1,['patch'],['patching']
Deployability,"Rob,. 	I let you know on the forum page, but just ot make sure it worked and I was ; able to index my transcriptome. Thank you!. Best wishes,; Rich; > On Apr 17, 2018, at 9:44 AM, Rob Patro <notifications@github.com> wrote:; > ; > Hi Rich,; > ; > The issue with pre-compiled OSX binaries is that they are difficult to make portable across OSX versions. This is why we strongly suggest installing Salmon (especially for OSX) through Bioconda. This greatly eases installation and updating, and doesn't require admin privileges. On OSX, you can try the following:; > ; > $ conda config --add channels conda-forge; > $ conda config --add channels bioconda; > $ conda create -n salmon salmon=0.9.1; > ; > This should take care of all relevant dependencies as well as e.g. library locations and placement. Could you please give this a try and let me know if it works for you?; > ; > Best,; > Rob; > ; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub, or mute the thread.; > . Richard A. Friedman, PhD; Associate Research Scientist,; Biomedical Informatics Shared Resource; Herbert Irving Comprehensive Cancer Center (HICCC); Lecturer,; Department of Biomedical Informatics (DBMI); Room 825; Irving Cancer Research Center ; Columbia University Herbert and Florence Irving Medical Center; 1130 St. Nicholas Ave; New York, NY 10032; (212)851-4765 (voice); raf4@cumc.columbia.edu. http://www.columbia.edu/~raf4/index.html. “Will there still be ""Classics Illustrated” by the time I have children? I cannot; imagine raising kids without ""Classics Illustrated” .” -Rose Friedman, age 20",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/215#issuecomment-382031768:385,install,installing,385,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/215#issuecomment-382031768,2,['install'],"['installation', 'installing']"
Deployability,"Rob,. Brilliant - I forgot that I built the boost libraries from whatever version of gcc was on the standard distribution. I have included -DFETCH_BOOST=TRUE, do you know why I am receiving the following error regarding a missing when executing make?. [ 5%] Performing configure step for 'libboost'; Building Boost.Build engine with toolset gcc... tools/build/src/engine/bin.linuxx86_64/b2; Detecting Python version... 2.7; Detecting Python root... /usr; Unicode/ICU support for Boost.Regex?... not found.; Generating Boost.Build configuration in project-config.jam... Bootstrapping is done. To build, run:. ./b2. To adjust configuration, edit 'project-config.jam'.; Further information:. - Command line help:; ./b2 --help. - Getting started guide:; http://www.boost.org/more/getting_started/unix-variants.html. - Boost.Build documentation:; http://www.boost.org/build/doc/html/index.html. using gcc : : /opt/gcc-8.2.0/bin/g++ ); [ 6%] Performing build step for 'libboost'; opt.jam: No such file or directory; /opt/salmon/external/boost_1_66_0/tools/build/src/build/toolset.jam:43: in toolset.using; ERROR: rule ""opt.init"" unknown in module ""toolset"".; /opt/salmon/external/boost_1_66_0/tools/build/src/build-system.jam:461: in process-explicit-toolset-requests; /opt/salmon/external/boost_1_66_0/tools/build/src/build-system.jam:527: in load; /opt/salmon/external/boost_1_66_0/tools/build/src/kernel/modules.jam:295: in import; /opt/salmon/external/boost_1_66_0/tools/build/src/kernel/bootstrap.jam:139: in boost-build; /opt/salmon/external/boost_1_66_0/boost-build.jam:17: in module scope; make[2]: *** [libboost-prefix/src/libboost-stamp/libboost-build] Error 1; make[1]: *** [CMakeFiles/libboost.dir/all] Error 2; make: *** [all] Error 2. Thanks for all your help!. Nate",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/309#issuecomment-436834099:530,configurat,configuration,530,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/309#issuecomment-436834099,2,['configurat'],['configuration']
Deployability,"Same error here, with a fresh (this morning) install of anaconda3-4.40 on Linux64-bit and a first-time install of salmon through bioconda. This may be premature / just plain incorrect, but [this post](https://github.com/ContinuumIO/anaconda-recipes/issues/56) mentioned issues with the default version of readline, so on a hunch I installed readline from conda-forge and then reinstalled salmon. The above errors disappear (still waiting on other errors).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/147#issuecomment-324627178:45,install,install,45,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/147#issuecomment-324627178,3,['install'],"['install', 'installed']"
Deployability,"Seems like a similar issue to #480, where the boost-cpp depenendency is supposed to be installed from the conda-forge channel. When you installed salmon, did you have the conda-forge channel installed?. Solution _*may*_ be: `conda uninstall -n salmon salmon && conda install -n salmon -c conda-forge -c bioconda salmon`",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/915#issuecomment-2000571627:87,install,installed,87,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/915#issuecomment-2000571627,4,['install'],"['install', 'installed']"
Deployability,"Since 0.10.2 is now out (and salmon is updated in bioconda), I'm going to close this issue.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/231#issuecomment-395790180:39,update,updated,39,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/231#issuecomment-395790180,1,['update'],['updated']
Deployability,"Slight Correction on the above statement ""It looks like one of the whitelisted CB ended up having no read at all after ~deduplicating~ mapping."" We might have to tweak a bit in the current version of Alevin for use cases like yours where we don't wan't pipeline to fail if the whitelisted CB are either w/ less frequency / mapping rate / deduplication rate.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/253#issuecomment-406657183:253,pipeline,pipeline,253,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/253#issuecomment-406657183,1,['pipeline'],['pipeline']
Deployability,"So after struggling, and failing for a little bit I looked into linuxbrew - its pretty much the best thing ever. I'm honestly not sure what my original issue was derived from but using linuxbrew to install the dependancies and then salmon itself worked perfectly. Honestly much easier to install it this way. . Salmon seems to be working now so I'd say my install issues are resolved. Thanks for your help, and an extra thanks for introducing me to linuxbrew, its going to make my work a lot easier.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/141#issuecomment-314548472:198,install,install,198,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/141#issuecomment-314548472,3,['install'],['install']
Deployability,"So which --chemistry flag in Cell Ranger does the change to -lISF correspond to? Is it `SC5P-R2` or `fiveprime`? https://support.10xgenomics.com/single-cell-gene-expression/software/pipelines/latest/using/count. Also since salmon/alevin can detect the library type automatically, would detect the correct library in the case of 5'-tagged scRNAseq 10X Feature barcode?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/439#issuecomment-622019385:182,pipeline,pipelines,182,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/439#issuecomment-622019385,1,['pipeline'],['pipelines']
Deployability,"So, I've already updated the docs _here_ (i.e. the doc tag in the ReadMe should should point to the link I give above). I believe the right thing to do over in the Sailfish docs is to just remove any documentation about Salmon (since the projects are now maintained in separate repos each with their own docs).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/27#issuecomment-152843180:17,update,updated,17,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/27#issuecomment-152843180,1,['update'],['updated']
Deployability,"So, on a fresh docker image of ubuntu 16.04.4, I was not able to reproduce this yet. Here is my current output:. ```; [100%] Linking CXX executable salmon; ../../external/install/lib/libstaden-read.a(libstaden_read_la-open_trace_file.o): In function `find_file_url':; open_trace_file.c:(.text+0xec4): warning: the use of `tempnam' is dangerous, better use `mkstemp'; [100%] Built target salmon; root@e08cc9670e4a:/salmon-0.10.2/build# make install; [ 6%] Built target libdivsufsort; [ 12%] Built target libbz2; [ 17%] Built target liblzma; [ 24%] Built target libcereal; [ 31%] Built target libgff; [ 36%] Built target libbwa; [ 42%] Built target libstadenio; [ 48%] Built target libspdlog; [ 50%] Built target ksw2pp_sse4; [ 52%] Built target alevin_core; [ 55%] Built target ksw2pp_sse2; [ 60%] Built target ksw2pp_basic; [ 60%] Built target ksw2pp; [ 73%] Built target salmon_core; [ 77%] Built target unitTests; [100%] Built target salmon; Install the project...; -- Install configuration: ""Release""; -- Installing: /salmon-0.10.2/lib; -- Installing: /salmon-0.10.2/lib/libtbb.so; -- Installing: /salmon-0.10.2/lib/libtbbmalloc.so; -- Installing: /salmon-0.10.2/lib/libtbbmalloc_proxy.so; -- Installing: /salmon-0.10.2/lib/libtbbmalloc.so.2; -- Installing: /salmon-0.10.2/lib/libtbb.so.2; -- Installing: /salmon-0.10.2/lib/pkgconfig; -- Installing: /salmon-0.10.2/lib/libtbbmalloc_proxy.so.2; -- Installing: /salmon-0.10.2/bin/salmon; -- Installing: /salmon-0.10.2/lib/libsalmon_core.a. Installation complete. Please ensure the following paths are set properly.; ==========================================================================; Please add /salmon-0.10.2/bin to your PATH; Please add /salmon-0.10.2/lib to your LD_LIBRARY_PATH; ==========================================================================; root@e08cc9670e4a:/salmon-0.10.2/build# make test; Running tests...; Test project /salmon-0.10.2/build; Start 1: unit_tests; 1/3 Test #1: unit_tests ....................... Passed 0.1",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/250#issuecomment-404306268:171,install,install,171,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/250#issuecomment-404306268,7,"['Install', 'Release', 'configurat', 'install']","['Install', 'Installing', 'Release', 'configuration', 'install']"
Deployability,"Solved with ; `-DFETCH_STADEN=TRUE`. to recap, installing on an Ubuntu 20.04: ; ```; git clone --depth=1 https://github.com/COMBINE-lab/salmon.git; cd salmon; git checkout tags/v1.5.2. apt-get build-dep -y salmon; cmake -DFETCH_BOOST=FALSE --log-level=VERBOSE -DCMAKE_INSTALL_PREFIX=/directory_to_place/salmon/1.5.2 -DFETCH_STADEN=TRUE -DNO_IPO=TRUE && make && make install; ```. Please note you can't mkdir build and cd build as the cmake files are bundled under the git's root dir. You'll need to move the files (but i'm not familiar with cmake so i just run it from the git root). Compilation is required as the distributed binaries use the older libc (GLIBC_2.29)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/425#issuecomment-962540229:47,install,installing,47,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/425#issuecomment-962540229,2,['install'],"['install', 'installing']"
Deployability,"Some progress. Found a src rpm for cereal, rebuilt that into an RPM and installed. Then this (ROOT_* env variables come from the respective module load commands):. ```; cmake \; -DCMAKE_INSTALL_PREFIX=$TOPDIR \; -DSTADEN_ROOT=$ROOT_IO_LIB \; -DGFF_ROOT=$ROOT_LIBGFF \; -DTBB_ROOT=$ROOT_LIBTBB \; -DCMAKE_VERBOSE_MAKEFILE:BOOL=ON \; -DBOOST_LIBRARYDIR=/usr/lib64/boost169 \; -DBOOST_INCLUDEDIR=/usr/include/boost169 \; -DBoost_NO_SYSTEM_PATHS=ON \; .. 2>&1 | tee cmake_2020_06_09.log; ```; found everything. The ""make"" went along pretty well until here:; ```; [100%] Linking CXX executable salmon; cd /usr/common/src/salmon-1.2.1/build/src && /usr/common/src/cmake-3.17.1/bin/cmake -E cmake_link_script CMakeFiles/salmon.dir/link.txt --verbose=1; /usr/lib64/ccache/c++ -O3 -DNDEBUG -flto -fno-fat-lto-objects CMakeFiles/salmon.dir/EMUtils.cpp.o CMakeFiles/salmon.dir/CollapsedEMOptimizer.cpp.o CMakeFiles/salmon.dir/CollapsedCellOptimizer.cpp.o CMakeFiles/salmon.dir/CollapsedGibbsSampler.cpp.o CMakeFiles/salmon.dir/Salmon.cpp.o CMakeFiles/salmon.dir/BuildSalmonIndex.cpp.o CMakeFiles/salmon.dir/Graph.cpp.o CMakeFiles/salmon.dir/DedupUMI.cpp.o CMakeFiles/salmon.dir/Alevin.cpp.o CMakeFiles/salmon.dir/AlevinHash.cpp.o CMakeFiles/salmon.dir/SalmonAlevin.cpp.o CMakeFiles/salmon.dir/WhiteList.cpp.o CMakeFiles/salmon.dir/SalmonQuantify.cpp.o CMakeFiles/salmon.dir/FragmentLengthDistribution.cpp.o CMakeFiles/salmon.dir/FragmentStartPositionDistribution.cpp.o CMakeFiles/salmon.dir/GZipWriter.cpp.o CMakeFiles/salmon.dir/SalmonQuantMerge.cpp.o CMakeFiles/salmon.dir/ProgramOptionsGenerator.cpp.o CMakeFiles/salmon.dir/FASTAParser.cpp.o CMakeFiles/salmon.dir/AlignmentModel.cpp.o CMakeFiles/salmon.dir/SalmonQuantifyAlignments.cpp.o CMakeFiles/salmon.dir/BAMUtils.cpp.o -o salmon -L/usr/common/src/salmon-1.2.1/lib -L/usr/common/src/salmon-1.2.1/external/install/lib -Wl,-rpath,""\$ORIGIN/../lib:\$ORIGIN/../../lib:\$ORIGIN/:\$ORIGIN/../../external/install/lib"" ../external/pufferfish/src/libpuffer.a libs",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641531162:72,install,installed,72,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641531162,1,['install'],['installed']
Deployability,Sorry @k3yavi - was away on leave. Seems to be lots of helpful titbits in this release- thank you.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/362#issuecomment-501591974:79,release,release,79,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/362#issuecomment-501591974,1,['release'],['release']
Deployability,Sorry I missed this! It's been on that branch (and committed) since Gaurav's PR. It's now been merged into master and included in the latest release (1.10.0).,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/813#issuecomment-1444418892:141,release,release,141,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/813#issuecomment-1444418892,1,['release'],['release']
Deployability,Sorry it took me so long to get around to this. Thanks for the PR! I merged into develop instead of master since I'm working on a new release.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/92#issuecomment-249087178:134,release,release,134,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/92#issuecomment-249087178,1,['release'],['release']
Deployability,"Sorry,. > Version Info: Could not resolve upgrade information in the alotted time.; Check for upgrades manually at https://combine-lab.github.io/salmon; # salmon (alignment-based) v0.9.1; # [ program ] => salmon; # [ command ] => quant; # [ targets ] => { transcripts.fa }; # [ libType ] => { A }; # [ alignments ] => { A549_S1_001.bam }; # [ output ] => { A549_S1_quant }; Logs will be written to A549_S1_quant/logs; Malformed key:value pair at line 44017: ""@PG ID:OSA IsCdna:True ReferenceLibraryID:Human.B37.3_RefGene20121217 VN:7.2""; ============; Exception : [ERROR: Failed to open file A549_S1_001.bam, exiting!]; ============; ./bin/salmon alignment-quant was invoked improperly.; For usage information, try ./bin/salmon quant --help-alignments; Exiting.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/222#issuecomment-387497883:42,upgrade,upgrade,42,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/222#issuecomment-387497883,2,['upgrade'],"['upgrade', 'upgrades']"
Deployability,"Sounds good! Once it’s in the next release, we can see if we can get the Homebrew formula working.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/348#issuecomment-473479367:35,release,release,35,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/348#issuecomment-473479367,1,['release'],['release']
Deployability,"Sounds good, I will report back as soon as we have the next release. ; Just a quick correction the useful percentage is less than 1% (not 1-4% it's 0.1 - 0.4%), I was off by a magnitude in the percentage reported above.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/362#issuecomment-490864673:60,release,release,60,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/362#issuecomment-490864673,1,['release'],['release']
Deployability,"Sounds good, just wanted to give you the heads up, as we are working on some other part of the salmon pipeline, currently I can't give you an ETA when would the new version of salmon be available. If For the time being the choice are either you can compile the develop branch of salmon or I can forward you a linux usable salmon binary.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/416#issuecomment-523090214:102,pipeline,pipeline,102,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/416#issuecomment-523090214,1,['pipeline'],['pipeline']
Deployability,Strange the updated error message has @PG not @pg,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/222#issuecomment-387498610:12,update,updated,12,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/222#issuecomment-387498610,1,['update'],['updated']
Deployability,"Success???. ```; $ gdb -ex ""attach $(pgrep salmon | head -1)"" -ex bt -ex detach -ex quit; GNU gdb (Ubuntu 7.11.1-0ubuntu1~16.04) 7.11.1; Copyright (C) 2016 Free Software Foundation, Inc.; License GPLv3+: GNU GPL version 3 or later <http://gnu.org/licenses/gpl.html>; This is free software: you are free to change and redistribute it.; There is NO WARRANTY, to the extent permitted by law. Type ""show copying""; and ""show warranty"" for details.; This GDB was configured as ""x86_64-linux-gnu"".; Type ""show configuration"" for configuration details.; For bug reporting instructions, please see:; <http://www.gnu.org/software/gdb/bugs/>.; Find the GDB manual and other documentation resources online at:; <http://www.gnu.org/software/gdb/documentation/>.; For help, type ""help"".; Type ""apropos word"" to search for commands related to ""word"".; Attaching to process 29332; [New LWP 29334]; [New LWP 29335]; [New LWP 29336]; [New LWP 21224]; [New LWP 21225]; [New LWP 21226]; [New LWP 21227]; [New LWP 21228]; [New LWP 21229]; [New LWP 21230]; [Thread debugging using libthread_db enabled]; Using host libthread_db library ""/lib/x86_64-linux-gnu/libthread_db.so.1"".; 0x00007fcb8cf73789 in __ieee754_log_avx (x=<optimized out>) at ../sysdeps/ieee754/dbl-64/e_log.c:193; 193	../sysdeps/ieee754/dbl-64/e_log.c: No such file or directory.; #0 0x00007fcb8cf73789 in __ieee754_log_avx (x=<optimized out>) at ../sysdeps/ieee754/dbl-64/e_log.c:193; #1 0x0000000000637ccc in double std::gamma_distribution<double>::operator()<pcg_detail::engine<unsigned int, unsigned long, pcg_detail::xsh_rr_mixin<unsigned int, unsigned long>, true, pcg_detail::unique_stream<unsigned long>, pcg_detail::default_multiplier<unsigned long> > >(pcg_detail::engine<unsigned int, unsigned long, pcg_detail::xsh_rr_mixin<unsigned int, unsigned long>, true, pcg_detail::unique_stream<unsigned long>, pcg_detail::default_multiplier<unsigned long> >&, std::gamma_distribution<double>::param_type const&) (); #2 0x0000000000634b8d in tbb::inter",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267488748:503,configurat,configuration,503,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267488748,2,['configurat'],['configuration']
Deployability,Successfully installed and ran salmon on Arch Linux using the AUR binary package. Works great[link](https://aur.archlinux.org/packages/salmon),MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/268#issuecomment-2118895156:13,install,installed,13,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/268#issuecomment-2118895156,1,['install'],['installed']
Deployability,"Sure thing, thanks for your help. It's entirely possible the issue is user error, rather than something wrong with the bioconda build. I had to install and run in a py3 env, since our server defaults to py2. Not sure if that's related, but I've used successfully in the past one a server with py3 as the default.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/261#issuecomment-409779737:144,install,install,144,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/261#issuecomment-409779737,1,['install'],['install']
Deployability,Sure!; >wget ftp://ftp.ensembl.org/pub/release-87/fasta/homo_sapiens/ncrna/Homo_sapiens.GRCh38.ncrna.fa.gz; >wget ftp://ftp.ensembl.org/pub/release-87/fasta/homo_sapiens/cdna/Homo_sapiens.GRCh38.cdna.all.fa.gz; # Combine the above two files; >zcat Homo_sapiens.GRCh38.cdna.all.fa.gz Homo_sapiens.GRCh38.ncrna.fa.gz > Homo_sapiens.GRCh38.87.cdna.ncrna.fa; # Get annotation only on known chr; >wget ftp://ftp.ensembl.org/pub/release-87/gtf/homo_sapiens/Homo_sapiens.GRCh38.87.chr.gtf.gz; # Get all annotation; >wget ftp://ftp.ensembl.org/pub/release-87/gtf/homo_sapiens/Homo_sapiens.GRCh38.87.gtf.gz,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/122#issuecomment-283466423:39,release,release-,39,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/122#issuecomment-283466423,4,['release'],['release-']
Deployability,"Sure, thanks for letting me know you were able to install via bioconda. I'll try to make these build errors more informative.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/331#issuecomment-447963407:50,install,install,50,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/331#issuecomment-447963407,1,['install'],['install']
Deployability,"Sure, thanks for pointing this out, we have updated the document now !; We are gonna do testing at our end too, but let us know if you have any other issue.; Happy Weekend !",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-395912965:44,update,updated,44,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-395912965,1,['update'],['updated']
Deployability,"Sure, works for me. Is it possible to add an argument that indicates that the dependencies (like `xz`) should be provided by the host, and any missing dependencies are an error, rather than installing them automatically?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/45#issuecomment-193944377:190,install,installing,190,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/45#issuecomment-193944377,1,['install'],['installing']
Deployability,"T (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../lib/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../lib/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../lib/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../lib"", {st_mode=S_IFDIR|0775, st_size=33280, ...}) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/tls/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/tls/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/tls/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/tls"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin"", {st_mode=S_IFDIR|0755, st_size=33280, ...}) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmo",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:7543,pipeline,pipeline,7543,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,4,['pipeline'],['pipeline']
Deployability,"T (No such file or directory); stat(""/cm/shared/apps/sge/current/lib/linux-x64/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/cm/shared/apps/sge/current/lib/linux-x64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/cm/shared/apps/sge/current/lib/linux-x64"", {st_mode=S_IFDIR|0755, st_size=7, ...}) = 0; open(""/etc/ld.so.cache"", O_RDONLY) = 3; fstat(3, {st_mode=S_IFREG|0644, st_size=101124, ...}) = 0; mmap(NULL, 101124, PROT_READ, MAP_PRIVATE, 3, 0) = 0x7fffbffe4000; close(3) = 0; open(""/lib64/libpthread.so.0"", O_RDONLY) = 3; read(3, ""\177ELF\2\1\1\0\0\0\0\0\0\0\0\0\3\0>\0\1\0\0\0\340]\200\316;\0\0\0""..., 832) = 832; fstat(3, {st_mode=S_IFREG|0755, st_size=145896, ...}) = 0; mmap(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7fffbffe3000; mmap(0x3bce800000, 2212848, PROT_READ|PROT_EXEC, MAP_PRIVATE|MAP_DENYWRITE, 3, 0) = 0x3bce800000; mprotect(0x3bce817000, 2097152, PROT_NONE) = 0; mmap(0x3bcea17000, 8192, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_DENYWRITE, 3, 0x17000) = 0x3bcea17000; mmap(0x3bcea19000, 13296, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_ANONYMOUS, -1, 0) = 0x3bcea19000; close(3) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/liblzma.so.0"", O_RDONLY) = 3; read(3, ""\177ELF\2\1\1\0\0\0\0\0\0\0\0\0\3\0>\0\1\0\0\0 %\0\0\0\0\0\0""..., 832) = 832; fstat(3, {st_mode=S_IFREG|0644, st_size=130728, ...}) = 0; mmap(NULL, 2226056, PROT_READ|PROT_EXEC, MAP_PRIVATE|MAP_DENYWRITE, 3, 0) = 0x7fffbfdc3000; mprotect(0x7fffbfde2000, 2097152, PROT_NONE) = 0; mmap(0x7fffbffe2000, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_DENYWRITE, 3, 0x1f000) = 0x7fffbffe2000; close(3) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/libtbb.so.2"", O_RDONLY) = 3; read(3, ""\177ELF\2\1\1\0\0\0\0\0\0\0\0\0\3\0>\0\1\0\0\0\320v\1\0\0\0\0\0""..., 832) = 832; fstat(3, {st_mode=S_IFREG|0644, st_si",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:53490,pipeline,pipeline,53490,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,2,['pipeline'],['pipeline']
Deployability,"Thank *you* for providing this software to the community.; BTW, it seems you're making an effort to support externally installed dependencies, for which I'm grateful. I did have to patch around a few bundled deps (e.g. libgff), which are downloaded unconditionally. Many package managers (e.g. FreeBSD ports, Gentoo Portage, MacPorts, pkgsrc, ...) do not allow manual downloads by upstream build systems, for obvious security reasons. I'm hoping it will be possible to avoid all such downloads without patching in the future, by preinstalling and having them discovered by find_package(), as you're already doing for things like bzip2. This will make it easier to package salmon in many of the numerous package managers out there (and eliminate the need for you to install dependencies via cmake). Cheers!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/288#issuecomment-420352699:119,install,installed,119,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/288#issuecomment-420352699,4,"['install', 'patch']","['install', 'installed', 'patch', 'patching']"
Deployability,Thank you both very much for working on this issue! I'm looking forward to having Salmon updated in Brewsci/bio. Enjoy your weekend!,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/348#issuecomment-473483470:89,update,updated,89,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/348#issuecomment-473483470,1,['update'],['updated']
Deployability,"Thank you for verifying @zhangchipku, and thank you very much for the kind words! We appreciate the feedback and input from our users like yourself. We'll prioritize the soft-clipping functionality for upcoming releases (maybe even the next if we can make that work in time). For the time being, I can recommend `fastp` as a fairly efficient / fast trimmer that. It might even be able to work in a streaming fashion so that you could pipe the trimmed reads directly to salmon.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-586548443:211,release,releases,211,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-586548443,1,['release'],['releases']
Deployability,"Thank you so much! We are going to use the new version. Of course, we will share you some results of comparing Q2 pipeline with Alevin. We usually used the drop-seq pipeline.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/416#issuecomment-522866012:114,pipeline,pipeline,114,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/416#issuecomment-522866012,2,['pipeline'],['pipeline']
Deployability,"Thanks ! ; When you release the apple silocon version. Is it possible to upload to brew ? Do you want to take in account the gpu with metal or the neural engine ? . > Le 30 juin 2022 à 05:58, Rob Patro ***@***.***> a écrit :; > ; > ﻿; > Hi @BenjaminDEMAILLE,; > ; > I think brew is a bit behind bioconda on this front, and, indeed, the M1 being a completely new architecture complicates things. I have an M1 Max and so there are plans to get a native compile going soon.; > ; > For the time being, the recommended way to get salmon on an M1 (or M2) Mac is as suggested here. Basically, you create an x86 conda environment (running under rosetta2) and install the latest version of salmon there. Rosetta2 is pretty amazing, and everything seems to run without a hitch, with nary a performance hit for the x86 -> ARM translation.; > ; > Best,; > Rob; > ; > —; > Reply to this email directly, view it on GitHub, or unsubscribe.; > You are receiving this because you were mentioned.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/787#issuecomment-1170808558:20,release,release,20,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/787#issuecomment-1170808558,2,"['install', 'release']","['install', 'release']"
Deployability,"Thanks @A-N-Other! I changed the base branch to develop, as we generally pull everything through that branch before it makes it to master. Otherwise, these changes look good. Hopefully we'll get around to pushing out a patch release with this change soon.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/856#issuecomment-1607761575:219,patch,patch,219,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/856#issuecomment-1607761575,2,"['patch', 'release']","['patch', 'release']"
Deployability,"Thanks @ACastanza , I think it's a good idea. I have marked it as a feature request and we'd update you here once we have some progress into the next release. A bit tangential though, I find [refgenie](http://refgenomes.databio.org/) very useful as it has pre-built salmon indices with all the other relevant metadata (such as gtf to generate tgMap file) needed by salmon/alevin for quantifiation, but I agree saving the tgMap while indexing through GTF would be great for consistency.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/595#issuecomment-738166102:93,update,update,93,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/595#issuecomment-738166102,2,"['release', 'update']","['release', 'update']"
Deployability,"Thanks @Ryan-Zhu for your feedbacks and the suggestion.; I apologize for the trouble you had to face while working with the alevin output.; We will prepare better from the next release and try updating the external dependencies first before making an official release. ; Just wanted to give you the heads up that I have also updated the bug for the scientific notation in the `mtx` format. It's in the develop branch of alevin, if you have time please let me know if it works for you. Thanks again.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/380#issuecomment-502828416:177,release,release,177,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/380#issuecomment-502828416,3,"['release', 'update']","['release', 'updated']"
Deployability,"Thanks @Tj-Idowu,. So, indeed, it looks like this is the problem. The mapping is completing, but you seem to be encountering a segmentation fault at the end of the run (before the abundance estimation finishes). Could you tell me what OS and version you're using, and how you installed Salmon? My guess is a binary incompatibility somewhere. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/239#issuecomment-400009534:276,install,installed,276,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/239#issuecomment-400009534,1,['install'],['installed']
Deployability,Thanks @dritoshi for the data and info. Let me play a bit with the data over the weekend. It should be very straightforward to add but I might have to check some unit test. I'll keep you updated.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/416#issuecomment-521863053:187,update,updated,187,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/416#issuecomment-521863053,1,['update'],['updated']
Deployability,"Thanks @jdrnevich for the heads up, I'll update the docs too.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/391#issuecomment-508132261:41,update,update,41,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/391#issuecomment-508132261,1,['update'],['update']
Deployability,"Thanks @juugii for the detailed response and clarifying my doubts.; It surely is possible to lose some information when projecting the data on lower dimensional space since none of the methods, CCA and MNN, are lossless. I do see your point and would like to understand more about the depth normalization problem you are facing with different experiments. . I tried to search the algorithm used by cellranger to aggregate the counts and it looks like the following:; * As I was saying earlier aggregation step was happening downstream of count/quantification of the gene count matrix, at least in cellranger pipeline.; > When doing large studies involving multiple biological samples (or multiple libraries or replicates of the same sample), it is best to run cellranger count on each of the libraries individually, and then pool the results using cellranger aggr. * It looks like they have three different modes to normalize the libraries; > There are three normalization modes:; mapped: (default) Subsample reads from higher-depth libraries until they all have an equal number of confidently mapped reads per cell.; raw: Subsample reads from higher-depth libraries until they all have an equal number of total (i.e. raw, mapping-independent) reads per cell.; none: Do not normalize at all. * Although it's not clear, what do they mean by `equal number of confidently mapped reads per cell`, does it mean median reads per cell ? Like you tried to show in the above plot the distribution can be very uneven. But the part that troubles me more is once `count` information has been generated it has lost the read level information, since we have deduplicated them, then how do they use the read counts to normalize. Unless that is dumped too, not clear. Quoting your text from above:; > Alternatively, could a subsampling covariate be added to the probabilistic quantification model of alevin. I think we can definitely work on correcting the subsampling bias in the probabilistic model of Alevin but we",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/305#issuecomment-433453155:608,pipeline,pipeline,608,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/305#issuecomment-433453155,1,['pipeline'],['pipeline']
Deployability,Thanks @k3yavi - I think those options would really help us use Alevin in production- look forward to the next release. . I'll do some more testing in the meantime.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/362#issuecomment-490859077:111,release,release,111,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/362#issuecomment-490859077,1,['release'],['release']
Deployability,"Thanks @k3yavi - do I need to assume that all of our existing matrices could be corrupted? . We've built Alevin into our production processes, so I'm loath to hack my way to a solution. When is the 0.99 release due?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/431#issuecomment-537071575:203,release,release,203,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/431#issuecomment-537071575,1,['release'],['release']
Deployability,"Thanks @k3yavi and @rob-p . . Regarding the number of mapped reads, everything looks good in aux_info/meta_info.json. That number was indeed an artifact. However, I still could not figure out why there is such a discrepancy between the read counts of these replicates. . How would it be the best way to share my data/pipeline? The data are coming from the Roadmap project (GSM1112836 and GSM916094). I am getting the fasta files from the bed files with `bedtools getfasta`, aligning them to the transcriptome with bowtie2, and then running salmon on the resulting bam files using alignment-based mode. Does it seem to be the correct way to process these data?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/368#issuecomment-504560952:317,pipeline,pipeline,317,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/368#issuecomment-504560952,1,['pipeline'],['pipeline']
Deployability,Thanks @mathog : I've chosen another color that is readable on both light and dark backgrounds. These changes are on develop and will make it into the next release.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/541#issuecomment-650568147:156,release,release,156,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/541#issuecomment-650568147,1,['release'],['release']
Deployability,"Thanks @mcfwoodruff,. The good news is I was able to reproduce this using the conda install in my OSX environment. I can also verify that using a salmon executable compiled on this machine itself, the segfault goes away. This means there is probably some binary incompatibility issue with the specific versions of the libraries being used / pulled in under bioconda. I'll see if I can dig deeper (and maybe also provide a pre-compiled binary from OSX to see if that works for you).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/295#issuecomment-421393355:84,install,install,84,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/295#issuecomment-421393355,1,['install'],['install']
Deployability,"Thanks @mikelove . > we had some people using txi$counts alone and not using the countsFromAbundance argument. Based on the above, I assume that **_doing something like this is wrong_** as DESeqDataSetFromMatrix is being used after countsFromAbundance = ""no"". ```; txi = tximport(files, type=""salmon"", tx2gene=tx2gene,; countsFromAbundance = ""no""). dds <- DESeqDataSetFromMatrix (countData = txi$counts,; colData = coldata, ~ condition); ```. @rob-p and @mikelove -- While on this topic, how would you use salmon quant and DESeq2 for QuantSeq data (which would be 3' tagged RNA-seq)? Would you use `salmon quant without --noLengthCorrection` or would you use` salmon quant with ; --noLengthCorrection`. 1. call salmon quant as before (and **_do not use --noLengthCorrection_**) and then do as suggested/stated in these 2 links ; - https://bioconductor.org/packages/devel/bioc/vignettes/tximport/inst/doc/tximport.html#Downstream_DGE_in_Bioconductor and https://bioconductor.org/packages/devel/bioc/vignettes/tximport/inst/doc/tximport.html#3%E2%80%99_tagged_RNA-seq; - Do not manually pass the original gene-level counts to downstream methods without an offset. The only case where this would make sense is if there is no length bias to the counts, as happens in 3’ tagged RNA-seq data (see section below). The original gene-level counts are in txi$counts when tximport was run with countsFromAbundance=""no"". ; - If you have 3’ tagged RNA-seq data, then correcting the counts for gene length will induce a bias in your analysis, because the counts do not have length bias. Instead of using the default full-transcript-length pipeline, we recommend to use the original counts, e.g. txi$counts as a counts matrix , e.g. providing to DESeqDataSetFromMatrix",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/581#issuecomment-719946865:1625,pipeline,pipeline,1625,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/581#issuecomment-719946865,1,['pipeline'],['pipeline']
Deployability,Thanks @patrickvdb! I'm re-basing on this branch because this will be merged into master soon for a new patch release.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/257#issuecomment-408428738:104,patch,patch,104,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/257#issuecomment-408428738,2,"['patch', 'release']","['patch', 'release']"
Deployability,"Thanks @rfarouni for the updates. > With --minScoreFraction 0.607 I get a way much better mapping rate. I wonder if there is way to determine the optimal value empirically?. Glad to hear that, may I ask what percent of the reads are mapping now ? It's not clear from the alevin logs you shared but I think the total number of deduplicated UMIs are similar to your baseline experiment. I think defining an optimal empirical threshold is a great idea but the issue is that 21 length barcodes are kind of in the middle i.e. a tad longer than the regular barcodes and somewhat smaller than a full read. The full read alignment process indeed allows more erroneous reads to map but 21 is a bit too short to work with. @rob-p might have more thoughts on this one. > But now there are a lot of barcodes that are not in the whitelist. Thanks again for checking this, it is indeed concerning. However, as I was mentioning earlier in a regular single-cell experiment we end up throwing away almost all of these very low frequency count cellular barcodes. I'd say even 45 reads CBs are most probably a noise and will be filtered away, because only a fraction of the reads will map and after deduplication it'll result in significantly low count in 1 cellular barcode. > Also with the default setting of --freqThreshold, no CB correction gets done. I can check why is this happening, let me know once you have a toy dataset to play with.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-640093397:25,update,updates,25,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-640093397,1,['update'],['updates']
Deployability,"Thanks @rob-p and Thanks in advance @mikelove . The original question pertained to using salmon with say ILMN RNA-Seq followed by DGE with DESeq2. @rob-p - I will also use this opportunity to indulge myself on a related question (how to use salmon with QuantSeq and then downstream with DESeq2). I have asked many QuantSeq related questions on this GH forum and I am yet to find the correct recipe for using salmon with quantseq and downstream DGE; - https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-565474848; - https://github.com/COMBINE-lab/salmon/issues/365#issuecomment-499732849; - and many others (do not want to get into a infinite loop here :) . @rob-p @mikelove - Here is my thought process (for salmon-QuantSeq-DESeq):; - I know salmon has the `--noLengthCorrection` feature and the help text says it is ""experimental"" for QuantSeq; - Probably, I should not use `--noLengthCorrection` feature when running salmon quant and just get the counts. ; - One might be wondeing why not to use `--noLengthCorrection` as it was introduced by @rob-p exclusively for QuantSeq -- that idea is based on what I see on [the tximport vignette for 3' tagged RNA-seq](https://bioconductor.org/packages/devel/bioc/vignettes/tximport/inst/doc/tximport.html#3%E2%80%99_tagged_RNA-seq) which has this to state; ```; If you have 3’ tagged RNA-seq data, then correcting the counts for gene length will induce a bias in your analysis, ; because the counts do not have length bias. Instead of using the default full-transcript-length pipeline, ; we recommend to use the original counts, e.g. txi$counts as a counts matrix, e.g. ; providing to DESeqDataSetFromMatrix or to the edgeR or limma functions ; without calculating an offset and without using countsFromAbundance.; ```. Let me know if you would approach the salmon-QuantSeq-DESeq puzzle differently. Thanks in advance.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/581#issuecomment-719150287:1531,pipeline,pipeline,1531,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/581#issuecomment-719150287,1,['pipeline'],['pipeline']
Deployability,"Thanks @roryk and @k3yavi . The issue we have is that we're trying to run a pipeline in a fairly high-throughput manner to get a sensible 'enough' matrix without too much manual intervention. So I'm trying to avoid anything that requires an eyeballing step, accepting that the matrix we get will be less optimal than one you'd get from manual optimisation. Where possible, our curators are extracting the expected cell numbers from publications, so sometimes I have at least a general idea of where to look for an elbow/ feature. @roryk - have you used your alternate view on the data to automatically derive cutoffs? Does it work well?. @k3yavi:. As I say, first point is that this is for cases where I have a rough idea of the target cell number- we're generally working with pre-published data (though cell numbers per run are not always available). . From https://github.com/COMBINE-lab/salmon/issues/340 I'd inferred that --expectCells gives Alevin ballpark to look for a knee within, while --forceCells is a strict cuttoff. Is that correct? . That being the case, my thought was to try --expectCells first, and failing that --forceCells. The problem is that I need to parse the STDOUT/ERR to detect the boundary error from --expectCells, which is not a very robust way of doing things. If you returned informative error codes (anything but 1) on this and other errors, I could detect the error and implement the logic I describe.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/362#issuecomment-490157428:76,pipeline,pipeline,76,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/362#issuecomment-490157428,1,['pipeline'],['pipeline']
Deployability,"Thanks @roryk for the code and @pinin4fjords for the suggestion.; That's correct, `--expectCells` and `--forceCells` flags are designed to use the way you described above. ; re: error codes, It's a good suggestion. Based on the timeline either we can make this into the next release of alevin or we can edit it in a different branch and then you can compile or I can give you a linux binary. Let us know what works for you.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/362#issuecomment-490161277:275,release,release,275,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/362#issuecomment-490161277,1,['release'],['release']
Deployability,"Thanks Jeremy! Yes, that's what I was hinting at with different v1/v2 protocols. From their code, you can see differences in amplicon sequences:; - For v1: 'NNNNNNNNNNIIIIIIIIGTGGCCGATGTTTCGCATCGGCGTACGACTIIIIIIIIATCCACGTGCTTGAGAGGCCAGAGCATTCGIIIIIIII'; - For v2: 'NNNNNNNNNNIIIIIIIIGTGGCCGATGTTTCGCATCGGCGTACGACTIIIIIIIIATCCACGTGCTTGAGACTGTGGIIIIIIII'; where the `IIIIIIII` sequence corresponds to barcode. This is from the pipeline code I mentioned earlier used for [this paper](https://www.nature.com/articles/s41593-021-00872-y). Do you have a the pairing file for the BC1 barcodes? Is it the Supp Table S12 in the Rosenberg paper? It is needed for development and testing.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-951080577:425,pipeline,pipeline,425,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-951080577,1,['pipeline'],['pipeline']
Deployability,"Thanks Matt for the response and fix, unfortunately the error persists;; Might need to re-align using a different pipeline?. > Version Info: Could not resolve upgrade information in the alotted time.; Check for upgrades manually at https://combine-lab.github.io/salmon; # salmon (alignment-based) v0.9.1; # [ program ] => salmon; # [ command ] => quant; # [ targets ] => { transcripts.fa }; # [ libType ] => { A }; # [ alignments ] => { A549_S1_001.bam }; # [ output ] => { A549_S1_quant }; Logs will be written to A549_S1_quant/logs; Malformed key:value pair at line 44017: ""@PG ID:OSA IsCdna:True ReferenceLibraryID:Human.B37.3_RefGene20121217 VN:7.2""; ============; Exception : [ERROR: Failed to open file A549_S1_001.bam, exiting!]; ============; ./bin/salmon alignment-quant was invoked improperly.; For usage information, try ./bin/salmon quant --help-alignments; Exiting.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/222#issuecomment-387497579:114,pipeline,pipeline,114,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/222#issuecomment-387497579,3,"['pipeline', 'upgrade']","['pipeline', 'upgrade', 'upgrades']"
Deployability,"Thanks Rob! I won't be able to get to it until later this week at the earliest because of helping to finish a manuscript, but I'll let you know as soon as I get to it! Looking forward to the new release!. Best,; Warren",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/50#issuecomment-241538721:195,release,release,195,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/50#issuecomment-241538721,1,['release'],['release']
Deployability,Thanks again @alexvpickering .; We have fixed this in the develop branch and it will be part of the salmon from the next release which we plan to release very soon.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/366#issuecomment-497391366:121,release,release,121,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/366#issuecomment-497391366,2,['release'],['release']
Deployability,"Thanks again @jdrnevich for sharing the data for debugging purposes. For anyone seeing similar behavior or following this issue, the resolution is as follows:. The mapping rate difference for between 100bp and 150bp reads (for both single-end and paired-end) becomes very small, and consistent with the ""high"" mapping rate of ~76-79% when using salmon v0.13.1 with `--validateMappings`. Thus, the recommendation here (and in general) is to process the data using the latest version of salmon and ensuring to use the `--validateMappings` option. Also, thanks to @jdrnevich for suggesting that the importance of this feature be highlighted in the documentation to the same extent it is in the release notes.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/349#issuecomment-472994215:691,release,release,691,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/349#issuecomment-472994215,1,['release'],['release']
Deployability,"Thanks for reporting this @alexdhill. There was a bug addressed in version 1.10 (the first bug in the release notes [here](https://github.com/COMBINE-lab/salmon/releases/tag/v1.10.0)) that could be related to this. If you *do* encounter this in any samples under 1.10, please let us know. In which case, keeping track of the offending sample might be the most useful way to try and dig into it further. Thanks!; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/876#issuecomment-1739843386:102,release,release,102,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/876#issuecomment-1739843386,2,['release'],"['release', 'releases']"
Deployability,"Thanks for reporting this. It seems there is an osx bioconda issue (likely related to their massive backend upgrade). Hopefully we can fix this upstream in the next release. I. The meantime, can you see if [this](https://github.com/COMBINE-lab/salmon/files/2383948/salmon_0.11.4-pre_OSX.tar.gz) OSX binary works for you?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/303#issuecomment-432468434:108,upgrade,upgrade,108,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/303#issuecomment-432468434,2,"['release', 'upgrade']","['release', 'upgrade']"
Deployability,"Thanks for so much for tracking down that issue so quickly! These problems have plagued me for years with different tools. There always seems to be a library that does this. I'll try the patched version this weekend and let you know how it goes. Finally, thanks for pointing out the issue about process substitution issue. I usually have 4-12 fastq files per sample and was following the [Alevin documentation](http://salmon.readthedocs.io/en/latest/alevin.html), which had the gzipped example using process substitution.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-395911670:187,patch,patched,187,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-395911670,1,['patch'],['patched']
Deployability,Thanks for the bug report. This has been fixed in develop and should work properly in the next release.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/501#issuecomment-611822688:95,release,release,95,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/501#issuecomment-611822688,1,['release'],['release']
Deployability,"Thanks for the detailed report @idinsmore1,. These are quite different versions of ensembl, and so changes in the underlying transcriptome can absolutely have an effect on estimated abundances. Specifically, as the newer releases of ensemble tend to annotate more and more isoforms, there are more potential explanations for the reads. Reads that may have been previously assigned to an isoform in the old annotation may better match to a new isoform in the new annotation, etc. This will affect the read assignment and TPM both to the isoform to which the reads were originally being assigned and the new isoform to which the reads are now being assigned. . One thing to look at would be to see how much things change at the gene level, where we'd expect mapping uncertainty to be much lower. Once there's an idea of the types of things that are changing, it will be possible to drill down a bit more to try and figure out exactly what's going on. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/653#issuecomment-823560566:221,release,releases,221,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/653#issuecomment-823560566,1,['release'],['releases']
Deployability,"Thanks for the details, David. I wanted to get a broader perspective of what was going on mapping-wise, so I ran the first sample through a STAR->salmon pipeline (the [brand new one in nf-core](https://github.com/nf-core/rnaseq/releases/tag/3.0)). This will also let us get a notion of what is happening in terms of mapping to the genome versus the annotated transcripts. Here's what I found:. The STAR mapping report shows:. ```; Started job on | Dec 15 18:01:41; Started mapping on | Dec 15 18:12:46; Finished on | Dec 15 18:25:37; Mapping speed, Million of reads per hour | 103.29. Number of input reads | 22120369; Average input read length | 290; UNIQUE READS:; Uniquely mapped reads number | 18500061; Uniquely mapped reads % | 83.63%; Average mapped length | 284.22; Number of splices: Total | 5999311; Number of splices: Annotated (sjdb) | 5961890; Number of splices: GT/AG | 5905895; Number of splices: GC/AG | 41312; Number of splices: AT/AC | 11584; Number of splices: Non-canonical | 40520; Mismatch rate per base, % | 0.36%; Deletion rate per base | 0.01%; Deletion average length | 1.46; Insertion rate per base | 0.01%; Insertion average length | 1.72; MULTI-MAPPING READS:; Number of reads mapped to multiple loci | 1805463; % of reads mapped to multiple loci | 8.16%; Number of reads mapped to too many loci | 3745; % of reads mapped to too many loci | 0.02%; UNMAPPED READS:; % of reads unmapped: too many mismatches | 0.00%; % of reads unmapped: too short | 8.07%; % of reads unmapped: other | 0.12%; CHIMERIC READS:; Number of chimeric reads | 0; % of chimeric reads | 0.00%; ```. *yet, only `9,310,303` reads* were determined by STAR to project properly to annotated transcripts (slightly _less_ than are mapped to the transcriptome by salmon, at least without the decoy sequence included). So, there is a very high fraction of the reads that align to the genome, but a much smaller fraction ~45%-50% that align to the transcriptome. There are many reasons something like this cou",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/603#issuecomment-745768992:153,pipeline,pipeline,153,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/603#issuecomment-745768992,2,"['pipeline', 'release']","['pipeline', 'releases']"
Deployability,"Thanks for the fast reply (and detailed explanation). The seg fault is produced regardless of the type (or lack thereof). In case the error below is somehow related to tbb: I haven't had it pre-installed, so the c- / make procedure 'took care of it'. Following output is generated by gdb:. ```Starting program: /usr/local/bin/salmon index -t transcripts.fasta -i sample_salmon_fmd_index --type fmd; [Thread debugging using libthread_db enabled]; Using host libthread_db library ""/lib/x86_64-linux-gnu/libthread_db.so.1"".; [New Thread 0x7ffff62b0700 (LWP 17488)]; Version Info: This is the most recent version of Salmon.; [Thread 0x7ffff62b0700 (LWP 17488) exited]. Thread 1 ""salmon"" received signal SIGSEGV, Segmentation fault.; __GI___libc_free (mem=0x7fff00000002) at malloc.c:2951; 2951	malloc.c: No such file or directory.; ``` ; and the backtrace:; ```; #0 __GI___libc_free (mem=0x7fff00000002) at malloc.c:2951; #1 0x00007ffff79b775d in operator delete[] (ptr=0x7fff00000002); at ../../src/tbbmalloc/proxy.cpp:256; #2 0x0000000000792272 in salmonIndex(int, char**) (); #3 0x000000000065baca in main (); ```. Edit: Similar things happen with conda installation, though the traceback details are slightly different:; `Temporary breakpoint 1 at 0x7ffff6cf2512: file malloc.c, line 2951. `",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/250#issuecomment-404232467:194,install,installed,194,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/250#issuecomment-404232467,2,['install'],"['installation', 'installed']"
Deployability,"Thanks for the fast reply, after many tries I was able to install it with Bioconda.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/331#issuecomment-447960701:58,install,install,58,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/331#issuecomment-447960701,1,['install'],['install']
Deployability,"Thanks for the report @arrowandbead,. Can you say something about the machine that you're running the indexing command on, and the FASTA file you're trying to index? We've seen poor behavior before specifically on cluster nodes with slow (networked) disk, but this should be largely mitigated in recent releases. --Rob. Edit: I saw that you closed the issue and identified the problem. Thanks for closing and for changing the title!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/554#issuecomment-668140567:303,release,releases,303,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/554#issuecomment-668140567,1,['release'],['releases']
Deployability,Thanks for the speedy replies. I tried running alevin with 8 threads and it ends up leading to the same error and backtrace. I can see a large number of threads still spawning through GDB. I have had these kinds of issues before with OpenMP and I usually had to specify an environment variable to limit the threads. I compiled salmon with the download boost etc option:. ```; linux-vdso.so.1 (0x00007ffc90379000); libpthread.so.0 => /lib/x86_64-linux-gnu/libpthread.so.0 (0x00007f859b069000); libtbbmalloc_proxy.so.2 => /u/user/tmp/salmon/build-debug/src/../../external/install/lib/libtbbmalloc_proxy.so.2 (0x00007f859ae66000); libtbbmalloc.so.2 => /u/user/tmp/salmon/build-debug/src/../../external/install/lib/libtbbmalloc.so.2 (0x00007f859ac36000); libtbb.so.2 => /u/user/tmp/salmon/build-debug/src/../../external/install/lib/libtbb.so.2 (0x00007f859aa08000); libgomp.so.1 => /u/user/local/lib64/libgomp.so.1 (0x00007f859a7e7000); librt.so.1 => /lib/x86_64-linux-gnu/librt.so.1 (0x00007f859a5df000); libm.so.6 => /lib/x86_64-linux-gnu/libm.so.6 (0x00007f859a2de000); libgcc_s.so.1 => /u/user/local/lib64/libgcc_s.so.1 (0x00007f859a0c8000); libc.so.6 => /lib/x86_64-linux-gnu/libc.so.6 (0x00007f8599d1d000); /lib64/ld-linux-x86-64.so.2 (0x00007f859b286000); libdl.so.2 => /lib/x86_64-linux-gnu/libdl.so.2 (0x00007f8599b19000); libstdc++.so.6 => /u/user/local/lib64/libstdc++.so.6 (0x00007f859979f000); ```. The linux version and g++ version are listed below:; ```; cat /proc/version; Linux version 4.9.0-0.bpo.6-amd64 (debian-kernel@lists.debian.org) (gcc version 4.9.2 (Debian 4.9.2-10+deb8u1) ) #1 SMP Debian 4.9.82-1+deb9u3~bpo8+1 (2018-03-22). ~/data/PCSI/PC10X/paper/pbmc$ g++ -v; Using built-in specs.; COLLECT_GCC=g++; COLLECT_LTO_WRAPPER=/u/user/local/libexec/gcc/x86_64-unknown-linux-gnu/5.4.0/lto-wrapper; Target: x86_64-unknown-linux-gnu; Configured with: ./configure --prefix=/u/user/local; Thread model: posix; gcc version 5.4.0 (GCC); ```. ```; [Thread debugging using libthread_db enab,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-395836214:570,install,install,570,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-395836214,3,['install'],['install']
Deployability,"Thanks for the super-detailed report, @allyhawkins. We'll fix this in the next point release.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/691#issuecomment-921865678:85,release,release,85,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/691#issuecomment-921865678,1,['release'],['release']
Deployability,"Thanks for the thorough suggestions. Actually, we fall into the easier case since Salmon does not support mixing single and paired-end reads in a single BAM file. When performing quantification on a single sample, the reads for that sample must follow a uniform library type. For paired-end reads, the BAM file can contain paired-end and single-end alignments (i.e. orphans), but the reads must all have been paired _in sequencing_. Mixing different library types in the BAM file makes it difficult to assess the compatibility of a fragment with the expected library type, especially if fragments from the different library types are expected to exist in a specific ratio in the input. Anyway, my main motivation for having the separate `AS` and `AP` types was to prevent the need to ""peek"" in the file, since, currently, there is not an easy way to peek the first read without opening the first file twice. However, I've decided that the benefit of having the same uniform (and simpler) interface of `A` always representing automatic library type detection is probably worth it, so I've pushed this implementation (commit 6116b2a). So, when the user provides the `A` library type, Salmon will peek into the first record in the BAM file to determine if the fragment was paired in sequencing or not, and will then set the single / paired-end status on that basis. The only corollary to this is that, in alignment-based mode, the `A` flag is not compatible with an input stream (i.e. the input must be a regular file). I will be sure to document this when I update the docs for the version bump.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/79#issuecomment-242399463:1556,update,update,1556,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/79#issuecomment-242399463,1,['update'],['update']
Deployability,"Thanks for the update!. I'll try out the updated version and let you know if that helped. Your new preprint sounds very interesting, I'll give it a read",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/328#issuecomment-498787748:15,update,update,15,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/328#issuecomment-498787748,2,['update'],"['update', 'updated']"
Deployability,"Thanks for the update, and I'm glad to hear that you were able to find a local fix!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/710#issuecomment-1165663420:15,update,update,15,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/710#issuecomment-1165663420,1,['update'],['update']
Deployability,"Thanks fornthe details, @silvanopiazza! I wonder if it would be fixed if you *removed* the copy of `libm` in the `lib` subdirectory of the salmon install folder?. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/783#issuecomment-1145876082:146,install,install,146,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/783#issuecomment-1145876082,1,['install'],['install']
Deployability,"Thanks sir. On Thu, Nov 21, 2019 at 9:27 PM Rob Patro <notifications@github.com> wrote:. > Hi @shanmugavadivelps <https://github.com/shanmugavadivelps>,; >; > This is because, to properly find and link libiconv, the build requires a; > version of CMake that ships with FindIConv.cmake. So, to build salmon from; > source, you should have at least CMake version 3.12. Internally and on our; > continuous integration servers, we use version 3.15.; >; > Also, I'll mention that it may not be essential to build from source.; > Salmon is available via Bioconda, and a docker image is available via; > DockerHub. Also, we have a pre-compiled binary that should work on many; > linux distributions available under our releases; > <https://github.com/COMBINE-lab/salmon/releases>.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/COMBINE-lab/salmon/issues/453?email_source=notifications&email_token=AN2V7HW3GLUZR52T4BJKOFLQU2VYHA5CNFSM4JP7NHKKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEE2W3DI#issuecomment-557149581>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AN2V7HTVJB3TCKRKDY6YKI3QU2VYHANCNFSM4JP7NHKA>; > .; >. -- ; *Shanmugavadivel, P. S.*; *Scientist (Agricultural Biotechnology),*. *#216, Block A,*; *ICAR-Indian Institute of Pulses Research,*. *Min. of Agriculture & Farmers Welfare,*. *Govt. of India,Kanpur - 208 024.*; *email: shanmugavadivel.ps@icar.gov.in <shanmugavadivel.ps@icar.gov.in>*; *www.iipr.res.in <http://www.iipr.res.in>*",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/453#issuecomment-557774568:392,continuous,continuous,392,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/453#issuecomment-557774568,4,"['continuous', 'integrat', 'release']","['continuous', 'integration', 'releases']"
Deployability,"Thanks! I don't have a CentOS 5 setup anywhere where I could test, but if it should be fixed then I'll go ahead and update the formula and bug you about it if anyone runs into problems.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/89#issuecomment-245930320:116,update,update,116,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/89#issuecomment-245930320,1,['update'],['update']
Deployability,"Thanks, I was good with linking against external jemalloc after your first reply. Mainly interested in knowing the details of your concern, so thanks for elaborating. We use pkgsrc for most of our CentOS installs, and now I feel safe using devel/jemalloc as a dependency. We also use FreeBSD, and in this case, I just patched out the dependency altogether, since jemalloc is FreeBSD's default allocator. Cheers!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/288#issuecomment-420343097:204,install,installs,204,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/288#issuecomment-420343097,2,"['install', 'patch']","['installs', 'patched']"
Deployability,"Thanks, Rob! Much appreciated. ~brian. On Mon, Mar 20, 2017 at 9:06 AM, Rob Patro <notifications@github.com> wrote:. > Hi @brianjohnhaas <https://github.com/brianjohnhaas> --- I know it's been; > a while (but I didn't gain access to an older OSX machine in that time).; > However, you should now be able to get the latest Salmon release on any OSX; > >= 10.8 via its Bioconda release; > <https://bioconda.github.io/recipes/salmon/README.html>. Let me know if; > this works for you.; >; > Best,; > Rob; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/COMBINE-lab/salmon/issues/117#issuecomment-287753410>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AHMVX9ed1SrEG30OgxTLVaHzGtq20WI0ks5rnnnngaJpZM4L3UvG>; > .; >. -- ; --; Brian J. Haas; The Broad Institute; http://broadinstitute.org/~bhaas <http://broad.mit.edu/~bhaas>",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/117#issuecomment-287756041:329,release,release,329,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/117#issuecomment-287756041,2,['release'],['release']
Deployability,"Thanks, Rob!. I'm running Yosemite 10.10.5. I can look into upgrading my mac, which is overdue. Our primary deployment; is on linux and I'm sure that'll be fine. thx again!. ~b. On Sat, Feb 4, 2017 at 8:49 PM, Rob Patro <notifications@github.com> wrote:. > Hi Brian,; >; > What version of OS X are you running on? The issue you mention with the; > pre-compiled binary is one that arises because of a bug in jemalloc, due; > to Apple trying to be clever; > <https://github.com/Homebrew/homebrew-core/pull/6625>. But that binary; > should be built along with a newer version of jemalloc. While I have a nice; > setup for building widely-compatible linux binaries, I unfortunately, just; > have to build the OS X binaries on one of my 2 Macs (both of which are; > 10.12).; >; > --Rob; >; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/COMBINE-lab/salmon/issues/117#issuecomment-277491570>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AHMVX7Cn4cuE6h0zAgfI0AK0P6ka8Oahks5rZSqqgaJpZM4L3UvG>; > .; >. -- ; --; Brian J. Haas; The Broad Institute; http://broadinstitute.org/~bhaas <http://broad.mit.edu/~bhaas>",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/117#issuecomment-277493942:108,deploy,deployment,108,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/117#issuecomment-277493942,1,['deploy'],['deployment']
Deployability,"Thanks, that's super helpful!. I've been trying to install and compile from source using; `; git clone https://github.com/COMBINE-lab/salmon.git --branch develop; cd salmon; mkdir build; cd build; cmake ..; make install; `. but it's not working. I might just have to wait until the next release.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/324#issuecomment-443354098:51,install,install,51,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/324#issuecomment-443354098,3,"['install', 'release']","['install', 'release']"
Deployability,"Thanks. I noticed that you forked BWA. I'm guessing my substitution of mainline BWA for your forked version is behind the last error. If we get int64_t defined, that might resolve it. I'd be happy to test, and can submit some patches for my other edits to CMakefiles.txt . I will try the Docker image. I was hesitant to use it because it relies on ZFS, and I'm not sure how ZFS will interact with my jail. Probably the easier path right now though.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/162#issuecomment-337616760:226,patch,patches,226,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/162#issuecomment-337616760,1,['patch'],['patches']
Deployability,"Thanks. The ref genie thing might be a little big for me to download to be honest. I talked to my PI and he said it was to be expected that the RNA might be low quality. I ran it against mouse DNA as well and the mouse was multiples worse so I guess that's a good sign. The decoy hits also outnumber the mapped hits by about 6:1. But they never exceed about 7%. Does this indicate something wrong with my indexing?. I also tried mapping indexing against human CDS and NCRNA files from ftp://ftp.ensembl.org/pub/release-100/fasta/homo_sapiens/ and the human genome from the same source. Those had even lower hit rates. That was odd because rRNA wasn't filtered out for this RNA seq, so I would have expected the rRNA parts of the NCRNA to have a lot of hits. But alas.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/558#issuecomment-673153902:511,release,release-,511,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/558#issuecomment-673153902,1,['release'],['release-']
Deployability,"That does not seem very likely in this case. The default C++ compiler mode is C++14 and pretty much everything on the system is compiled that way. Still, I'm not sure how boost169 was compiled (the src.rpm is not available at the moment, waiting for email from the builder). It was used with other packages though, and if it had an incompatible ABI they should not have worked either. Checking my notes there are a couple of specific programs which had to be compiled with older C++ standards, but none of those are linked to Salmon. Also, if that was the problem, shouldn't these have shown up as unresolved references because of the ABI_TAG (""cxx11"" or ""_cxx11"", according to this:. https://developers.redhat.com/blog/2015/02/05/gcc5-and-the-c11-abi/. ) ?. ccache was installed and was active for the salmon build. It was removed and salmon rebuilt. No difference, it still segfaults.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641652976:770,install,installed,770,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641652976,1,['install'],['installed']
Deployability,"That seems to fix it! Any thoughts on these other incantations I have there?. ```; ##; # This ensures that the salmon executable should work with or without `make install`; ##; # Grumble grumble . . . OSX; if (APPLE); # only attempt install_name_tool for tbb if we installed it; if (${TBB_LIBRARY_DIRS} MATCHES ${GAT_SOURCE_DIR}/external/install/lib); add_custom_command(TARGET salmon; POST_BUILD; COMMAND install_name_tool -change libtbb.dylib @rpath/libtbb.dylib ${GAT_SOURCE_DIR}/build/src/salmon; COMMAND install_name_tool -change libtbbmalloc.dylib @rpath/libtbbmalloc.dylib ${GAT_SOURCE_DIR}/build/src/salmon; COMMAND install_name_tool -change libtbbmalloc_proxy.dylib @rpath/libtbbmalloc_proxy.dylib ${GAT_SOURCE_DIR}/build/src/salmon; COMMAND install_name_tool -add_rpath ${GAT_SOURCE_DIR}/external/install/lib ${GAT_SOURCE_DIR}/build/src/salmon; ); add_custom_command(TARGET unitTests; POST_BUILD; COMMAND install_name_tool -change libtbb.dylib @rpath/libtbb.dylib ${GAT_SOURCE_DIR}/build/src/unitTests; COMMAND install_name_tool -change libtbbmalloc.dylib @rpath/libtbbmalloc.dylib ${GAT_SOURCE_DIR}/build/src/unitTests; COMMAND install_name_tool -change libtbbmalloc_proxy.dylib @rpath/libtbbmalloc_proxy.dylib ${GAT_SOURCE_DIR}/build/src/unitTests; COMMAND install_name_tool -add_rpath ${GAT_SOURCE_DIR}/external/install/lib ${GAT_SOURCE_DIR}/build/src/unitTests; ); endif(); else(); # related to complete static linking --- on hold ; set (BOOST_THREAD_LIBRARY); endif(). ```. i.e. is this incantation necessary, or not?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/70#issuecomment-239542406:163,install,install,163,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/70#issuecomment-239542406,5,['install'],"['install', 'installed']"
Deployability,"That would be great. I will upgrade to Mojave now. I don't know if it is helpful, but the last binary of Salmon I could get to work on MacOS 10.12.6 was the provided Salmon-0.8.2_macOX_10.12.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/318#issuecomment-442944958:28,upgrade,upgrade,28,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/318#issuecomment-442944958,1,['upgrade'],['upgrade']
Deployability,"That's amazing @Gaura. This feature has been frequently requested by multiple users but I never got a chance to work on this, thanks a lot for the PR. Give me some time to go over the PR and if everything looks Ok, we can merge it in into the next release cycle. May I ask previous version of inDrop had an issue with variable length barcodes, did they solved that issue in v2 ?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/703#issuecomment-920921204:248,release,release,248,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/703#issuecomment-920921204,1,['release'],['release']
Deployability,That's not to say I don't see the utility of having this built in. I'll try and add this command to the next release ;).,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/77#issuecomment-299711727:109,release,release,109,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/77#issuecomment-299711727,1,['release'],['release']
Deployability,"That's what I thought... But no. Updating conda did not solve the problem. Best wishes,; Javier; (Sent from my iPhone). On Feb 9, 2018, at 6:34 PM, Rob Patro <notifications@github.com<mailto:notifications@github.com>> wrote:. This is really strange; the latest version for Mac should be 0.9.1 (see here<https://anaconda.org/bioconda/salmon>). Does anything change if you do a conda update/upgrade?. —; You are receiving this because you authored the thread.; Reply to this email directly, view it on GitHub<https://github.com/COMBINE-lab/salmon/issues/194#issuecomment-364599820>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AiohHfqVY_pmlr_ho7ab77WhaqSIVP-mks5tTNYAgaJpZM4SAonB>.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/194#issuecomment-364609365:382,update,update,382,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/194#issuecomment-364609365,2,"['update', 'upgrade']","['update', 'upgrade']"
Deployability,The Arabidopsis example in the getting started guide ([https://combine-lab.github.io/salmon/getting_started/](https://combine-lab.github.io/salmon/getting_started/)) seems to work fine on FreeBSD 13.0 with salmon installed via miniconda per instructions above.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/419#issuecomment-989865038:213,install,installed,213,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/419#issuecomment-989865038,1,['install'],['installed']
Deployability,"The gencode option behaves described above, and is implemented as of commit d44df88, so it should make it into the next tagged release.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/15#issuecomment-241235707:127,release,release,127,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/15#issuecomment-241235707,1,['release'],['release']
Deployability,"The implementation to output mapping information from within salmon (not yet full alignments) is almost complete. The feature needs some testing, but it will definitely make it into the next release.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/38#issuecomment-242924562:191,release,release,191,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/38#issuecomment-242924562,1,['release'],['release']
Deployability,The lack of openMP on osx has been terrible so I completely appreciate not requiring it. It looks like your hotfix solved the threading problems now and Alevin ran to completion for me! . Thanks so much for the speedy replies and fixes!,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-396325275:108,hotfix,hotfix,108,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-396325275,1,['hotfix'],['hotfix']
Deployability,The languages of both autotools and CMake are pretty terrible. I actually like the Make language; I think it gets a bad wrap. Other than `config.h` was there any other files of Jellyfish that were missing from the install that you needed?,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/19#issuecomment-195461547:214,install,install,214,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/19#issuecomment-195461547,1,['install'],['install']
Deployability,"The last patch display the error with `std::cerr << ...`, because `log->critical(...)` does not seem to work. Not sure how to fix it.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/617#issuecomment-835404939:9,patch,patch,9,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/617#issuecomment-835404939,1,['patch'],['patch']
Deployability,"The pre-compiled Release now finally seems to work, so nevermind!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/729#issuecomment-993410585:17,Release,Release,17,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/729#issuecomment-993410585,1,['Release'],['Release']
Deployability,"The same with version 1.2.0. Is there a way to disable version check by default, completely? I install Salmon as a module and I wouldn't let it update itself automatically, anyway.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/486#issuecomment-590911530:95,install,install,95,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/486#issuecomment-590911530,2,"['install', 'update']","['install', 'update']"
Deployability,The script was running `cmake && make install` with no `make`. Could that be it? I've added `make` before `make install`. I'll get that log file for you.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/181#issuecomment-367756380:38,install,install,38,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/181#issuecomment-367756380,2,['install'],['install']
Deployability,"The specific error message seems to be coming from [the serialization library we use](https://github.com/USCiLab/cereal/blob/master/include/cereal/archives/portable_binary.hpp#L245). This was upgraded recently, so I'm hoping that they didn't introduce a new bug upstream. As soon as I can reproduce this, I can test if rolling back the version of the serialization library fixes the issue (which I don't believe occurred in 0.7.2).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/129#issuecomment-287255919:192,upgrade,upgraded,192,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/129#issuecomment-287255919,2,"['rolling', 'upgrade']","['rolling', 'upgraded']"
Deployability,"The virtual memory should also be greatly reduced in 1.2.0 (which I am working on finalizing the release of at the moment). There will be detailed release notes describing the improvements. However, getting the pre-built index is probably worth it if it's the right organism and annotation.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/503#issuecomment-612193221:97,release,release,97,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/503#issuecomment-612193221,2,['release'],['release']
Deployability,"There is not a known bug here, but this is certainly strange. Given that version 0.14.1 is very old now, I think the best thing to do is just put a caveat on the release page.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/652#issuecomment-1138630790:162,release,release,162,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/652#issuecomment-1138630790,1,['release'],['release']
Deployability,"There is nothing obvious about the command you provided that looks incorrect. Can you please check if the segmentation fault still occurs with the most recent release of salmon (either 1.10 or 1.10.1)?. Thanks,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/847#issuecomment-1533935566:159,release,release,159,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/847#issuecomment-1533935566,1,['release'],['release']
Deployability,"There is now more stringent checking of the input to the digamma function, and so these issues should be resolved in the current release. Please report back (and re-open this) if you still encounter this issue.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/48#issuecomment-303617709:129,release,release,129,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/48#issuecomment-303617709,1,['release'],['release']
Deployability,"There was previously a bug that could lead to this behavior if the transcript to gene mapping was incomplete (i.e. if there were transcripts without an appropriately mapping gene). This is fixed in the latest release. Nonetheless, I'll note that [tximport](http://bioconductor.org/packages/release/bioc/html/tximport.html) is now the preferred way to aggregate abundances to the gene level.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/60#issuecomment-281436353:209,release,release,209,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/60#issuecomment-281436353,2,['release'],['release']
Deployability,These 1800 transcripts have a degradation signal we are looking to allow other researchers to model. The thought was we could build a pipeline to do so and that by restricting it to the 1800 for salmon it might not be computationally inaccessible.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/681#issuecomment-873058012:134,pipeline,pipeline,134,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/681#issuecomment-873058012,1,['pipeline'],['pipeline']
Deployability,These are resolved in develop and will be fixed in the next release.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/149#issuecomment-335952935:60,release,release,60,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/149#issuecomment-335952935,1,['release'],['release']
Deployability,"Thinking more about it, we can actually throw away a whitelisted CB with 0 frequency w/ a warning .; Once we discuss this w/ the alevin team, I'd happy to add this filter to the alevin pipeline . Thanks again @habilzare for pointing this out .",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/253#issuecomment-406460828:185,pipeline,pipeline,185,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/253#issuecomment-406460828,1,['pipeline'],['pipeline']
Deployability,"This *usually* means that the version of the boost library you have was not compiled with a C++11-compatible ABI. There is a incompatibility between pre C++11 and post C++11 `std::string` representations, and since salmon uses modern C++ (C++14 as of this writing), you need a version of boost compiled in a compatible way. How was boost installed on your system?. Of course, if you don't need to compile from source, it's *much* easier to install via conda, or to grab the pre-built executable (1.10.0 is feature and bugfix identical to 1.10.1). Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/551#issuecomment-1577237260:338,install,installed,338,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/551#issuecomment-1577237260,2,['install'],"['install', 'installed']"
Deployability,This command is implemented in develop and will be in the next release.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/77#issuecomment-335956508:63,release,release,63,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/77#issuecomment-335956508,1,['release'],['release']
Deployability,This fix is in the newest release (v0.8.0).,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/105#issuecomment-281438049:26,release,release,26,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/105#issuecomment-281438049,1,['release'],['release']
Deployability,"This is failing on our local drone CI during runtime. The log output is :. ```; + echo ""[Testing quant]""; [Testing quant]; + ./.drone/test_quant.sh; Holy build box activated; Prefix: /hbb_exe; CFLAGS: -g -O2 -fvisibility=hidden -I/hbb_exe/include ; LDFLAGS: -L/hbb_exe/lib -static-libstdc++; STATICLIB_CFLAGS: -g -O2 -fvisibility=hidden -I/hbb_exe/include ; SHLIB_CFLAGS: -g -O2 -fvisibility=hidden -I/hbb_exe/include ; SHLIB_LDFLAGS: -L/hbb_exe/lib -static-libstdc++; [Drone test] current path : /drone/src/github.com/COMBINE-lab/salmon; [Drone test] making quant test directory; [Drone test] run nextflow pipeline; N E X T F L O W ~ version 0.29.1; Launching `tests/test_quant.nf` [curious_gilbert] - revision: 4f25b30301; [warm up] executor > local; [91/922fac] Submitted process > buildIndex; ERROR ~ Error executing process > 'buildIndex'; Caused by:; Process `buildIndex` terminated with an error exit status (127); Command executed:; /drone/src/github.com/COMBINE-lab/salmon/bin/salmon index -t Homo_sapiens.GRCh37.75.cdna.pc.fa -i nfindex; Command exit status:; 127; Command output:; (empty); Command error:; /drone/src/github.com/COMBINE-lab/salmon/bin/salmon: error while loading shared libraries: libjemalloc.so.2: cannot open shared object file: No such file or directory; Work dir:; /drone/src/github.com/COMBINE-lab/salmon/work/91/922facec25da43edd4a2ce82f2289d; Tip: when you have fixed the problem you can continue the execution appending to the nextflow command line the option `-resume`; -- Check '.nextflow.log' file for detail; ```. So, it seems to be due to failure to find the dynamic shared library for jemalloc. Any idea why that might be?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/348#issuecomment-472495264:607,pipeline,pipeline,607,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/348#issuecomment-472495264,1,['pipeline'],['pipeline']
Deployability,"This is fixed in https://github.com/COMBINE-lab/pufferfish/commit/e7fb924850e2a04793cdd2ace628afa8cf37885c, and should show up in the next (shortly coming) release.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/591#issuecomment-733761227:156,release,release,156,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/591#issuecomment-733761227,1,['release'],['release']
Deployability,This is really strange; the latest version for Mac should be 0.9.1 (see [here](https://anaconda.org/bioconda/salmon)). Does anything change if you do a conda update/upgrade?,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/194#issuecomment-364599820:158,update,update,158,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/194#issuecomment-364599820,2,"['update', 'upgrade']","['update', 'upgrade']"
Deployability,"This is related to the way `--useFSPD` was implemented (see #64). This flag has been deprecated, and a replacement (`--posBias`) has been introduced as of 0.7.0. This should not exhibit the same behavior. The `--posBias` flag is currently experimental, but will move out of that status in the next major release after it has been in the wild for a bit. Please let me know if the [latest release](https://github.com/COMBINE-lab/salmon/releases/tag/v0.7.1) resolves this issue for you.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/50#issuecomment-241465777:304,release,release,304,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/50#issuecomment-241465777,3,['release'],"['release', 'releases']"
Deployability,This is resolved in develop and will make it into the next release.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/148#issuecomment-335953142:59,release,release,59,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/148#issuecomment-335953142,1,['release'],['release']
Deployability,"This seems to be a separate issue than the other (and a more informative exception). Once I've resolved the other issue, I would probably try to bug you for a sample that causes this --- though I have a reasonable idea about how to fix it. It would be nice to have the fix for both issues in the same hotfix. To be more specific : this is, as the exception says, a numeric underflow issue when evaluating the digamma function. The solution here is just to bump up the value that is required before evaluating this function. This should be straightforward, but I suspect the issue is also related to this log message:. > [2018-05-31 17:08:11.488] [jointLog] [info] Marked 1 weighted equivalence classes as degenerate",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/229#issuecomment-393571565:301,hotfix,hotfix,301,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/229#issuecomment-393571565,1,['hotfix'],['hotfix']
Deployability,"This was caught by an end-user, reporting that `salmon` was not found. I just [patched our installation script](https://github.com/HenrikBengtsson/CBI-software/blob/c0ed7c62446b8b26559bb71ff5f55c7d8e751296/CBI/salmon/Makefile#L24-L29) to do:. ```sh; chmod -R go+r $(PREFIX); chmod ugo+x $(PREFIX)/{bin,lib,bin/salmon}; ```. which I decided on looking at what salmon 1.7.0 had, except I skipped setting executable on the `lib/*.so` files (which 1.7.0 has for some of them).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/761#issuecomment-1067244078:79,patch,patched,79,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/761#issuecomment-1067244078,2,"['install', 'patch']","['installation', 'patched']"
Deployability,"To authentic-zz:; You mean you have get the counts into a data frame. I don't know how to transfer the salmon data frame into DESeq2，and I fail to handle data frame from salmon, too. So I have these recommendations to you: ; 1. Get the salmon raw results, the sf files, as the tximport input files.; 2. Run the salmon again or choose other pipeline like HISAT2-Stringtie/featurecounts/HTseq.; 3. Try to generate the salmon sf file. The sf file's row name is ""Name Length EffectiveLength TPM NumReads"". You have the gene ID and counts, so fill the length, effect length, and TPM by tab or something. But I do not sure if this handle is correct. https://salmon.readthedocs.io/en/latest/file_formats.html#fileformats",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/437#issuecomment-782990393:340,pipeline,pipeline,340,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/437#issuecomment-782990393,1,['pipeline'],['pipeline']
Deployability,To reproduce this error:. ``` sh; docker run linuxbrew/linuxbrew brew install gcc homebrew/science/salmon; ```,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/46#issuecomment-193897441:70,install,install,70,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/46#issuecomment-193897441,1,['install'],['install']
Deployability,"UPDATE: On @rob-p 's suggestion, I removed the `--recoverOrphans` option and then all 60 samples did finished without segfaulting. Perhaps there were too many orphans to handle - alignments rates were a dismal 0.5-23%. These were heavily degraded samples that the sequencing center recommended not to sequence but the PI wanted to try it anyway. If you want a pair of fastq files (full or cutdown to ~5 M reads) to test this weird edge case, I can see about getting them to you. Thanks!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/668#issuecomment-862525216:0,UPDATE,UPDATE,0,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/668#issuecomment-862525216,1,['UPDATE'],['UPDATE']
Deployability,"UPPORT -DHAVE_ANSI_TERM -DHAVE_SSTREAM -Wall -Wno-unknown-pragmas -Wno-reorder -Wno-unused-variable -std=c++11 -Wreturn-type -Werror=return-type -Wno-unused-function -Wno-unused-local-typedef -static-libstdc++ -Wno-unused-local-typedefs -pthread -ftree-vectorize -funroll-loops -fPIC -fomit-frame-pointer -O3 -DRAPMAP_SALMON_SUPPORT -DHAVE_ANSI_TERM -DHAVE_SSTREAM -Wall -Wno-unknown-pragmas -Wno-reorder -Wno-unused-variable -std=c++11 -Wreturn-type -Werror=return-type -Wno-unused-function -Wno-unused-local-typedef -static-libstdc++ -Wno-unused-local-typedefs -rdynamic CMakeFiles/unitTests.dir/__/tests/UnitTests.cpp.o CMakeFiles/unitTests.dir/FragmentLengthDistribution.cpp.o CMakeFiles/unitTests.dir/__/external/install/src/rapmap/rank9b.cpp.o CMakeFiles/unitTests.dir/__/external/install/src/rapmap/bit_array.c.o -o unitTests -L/home/mathog/src/salmon/lib -L/home/mathog/src/salmon/external/install/lib -Wl,-rpath,""\$ORIGIN/../lib:\$ORIGIN/../../lib:\$ORIGIN/:\$ORIGIN/../../external/install/lib"" libsalmon_core.a libalevin_core.a -lgff -lpthread ../external/install/lib/libstaden-read.a -lz ../external/install/lib/libdivsufsort.a ../external/install/lib/libdivsufsort64.a ../external/install/lib/libbwa.a -lm -llzma -lbz2 -ltbb -lgomp -lrt ../external/install/lib/libjemalloc.a -lrt -ldl ../external/install/lib/libjemalloc.a -ldl`. Oh, I also had to update automake and autoconf because the 2 year old versions on this system were not new enough. Is there a static binary version of salmon available for download, Linux 64 bit? It looks like the default links are that way anyway, and that would save me what looks like at least another day of fighting with Cmake to force it to actually build a working make file. . You are developing on something like a recent Fedora or Ubuntu? In my experience packages which use boost and cmake inevitably cause a great great deal of pain when they are built on platforms like Centos or RHEL where long term support is one of the goals. They work fine ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/236#issuecomment-397025719:3063,install,install,3063,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/236#issuecomment-397025719,1,['install'],['install']
Deployability,"Uh, why then does ""make test"" fail if the root directory name is changed? That was using the binary/libraries in $WHEREVER, after bin and lib below the root directory were removed. Typically that sort of operation doesn't care what the top level is named. For some future release, perhaps the run time dynamic loading of libraries could look up the path to libtbb.so.2 and try that first, before falling back to LD_LIBRARY_PATH? On my system ldd of salmon shows a link to libtbb.so.2, no LD_LIBRARY_PATH needed. ldd does not show any links to libtbb.malloc*. The program will do at least ""salmon --help' that way without any errors or warnings. That isn't sufficient to pass ""make test"" though (even when the directory has not been renamed). It seems that libtbb.malloc* libraries are used during that test, and that use requires LD_LIBRARY_PATH. Only when they are found that way does ""make test"" work.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/236#issuecomment-397063656:272,release,release,272,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/236#issuecomment-397063656,1,['release'],['release']
Deployability,Unfortunately I can't use apt-get/brew/yum to install zlib since I'm not root on my cluster. This is why I installed zlib-1.2.11 separately. . Make doesn't seem to allow the same commands as cmake so `-DZLIB_LIBRARY=/users/work/jake/bin/zlib-1.2.11/` or any variation of it isn't accepted. I guess I'll keep plugging away to see if I can resolve the issue. There isn't any build files that I could modify to include the directory path to zlib?,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/141#issuecomment-314459160:46,install,install,46,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/141#issuecomment-314459160,2,['install'],"['install', 'installed']"
Deployability,"Unfortunately I don't have much thoughts about the low mapping rates of Drop-seq technology. ; Although, it doesn't necessarily have to be associated with the mapping rate, from what I remember a lot CB are more than one-edit distance away from the high quality barcodes which are excluded from the mapping phase of the pipeline.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/738#issuecomment-1024672260:320,pipeline,pipeline,320,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/738#issuecomment-1024672260,1,['pipeline'],['pipeline']
Deployability,"Unfortunately it's getting into a little under explored territory. ; Retrospectively, it does makes sense to have such a threshold but sadly in the current version we don't have that option. If it may help, I just got some stats for 10x data and generally it's around top < 1% of the data which is useful, which should be even lower in dropseq. Although it's possible my sample size of 5 below dataset is too small. ```; useful -> total; 4k -> 1,239,476; 8k -> 1,877,718; 900 -> 657,180; 2k -> 1,653,795; 9k -> 2,812,291; ```. My guess is keeping the `keepCBFraction` even to 0.1 (i.e. 10%) would get you decent number of empty/low confidence CB to correct for downstream but you might have to explore a little. Another caveat is, having too many CB blows up the memory for downstream whitelisting of alevin and currently there is no option to disable that whitelisting, again a must have feature which is missing. Thanks for this very useful discussion, we will definitely improve/add these options into alevin with the next release.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/362#issuecomment-490857399:1026,release,release,1026,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/362#issuecomment-490857399,1,['release'],['release']
Deployability,"Updated Expected behavior: ; A clear and concise description of what you expected to happen.; I aim to retain all gene IDs, and for those represented by multiple lines, I intend to calculate the sum of values for each unique gene ID. I came across a few posts regarding this issue, but have not found a good solution for salmon quantmerge yet",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/910#issuecomment-1918166379:0,Update,Updated,0,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/910#issuecomment-1918166379,1,['Update'],['Updated']
Deployability,Updated to resolve a short options conflict and fix issue #111 (which only occurred on the develop branch with the combination of `--useVBOpt` and `--numGibbsSamples`). [Salmon-0.7.3-pre_OSX_10.12.tar.gz](https://github.com/COMBINE-lab/salmon/files/665033/Salmon-0.7.3-pre_OSX_10.12.tar.gz),MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/103#issuecomment-268402355:0,Update,Updated,0,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/103#issuecomment-268402355,1,['Update'],['Updated']
Deployability,"Using the rest of the same configure flags without `-DUSE_SHARED_LIBS=TRUE`, the build does not link properly. I think you should try building without these extra flags. Since the LTO seems not to be a problem on this system, a simple `cmake .. && make` should work. In the mean time, I'll try and pare back the configure command line to find the maximum viable interpolation between our different configurations. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1464012294:398,configurat,configurations,398,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1464012294,1,['configurat'],['configurations']
Deployability,Verification that I'm running with the right version of TBB:. ```; $ ls ~/src/salmon/external/tbb* -d; /home/ryan/src/salmon/external/tbb-2017_U3 /home/ryan/src/salmon/external/tbb-2017_U3.tgz; $ ldd `which salmon`; linux-vdso.so.1 => (0x00007ffc739fd000); libpthread.so.0 => /lib/x86_64-linux-gnu/libpthread.so.0 (0x00007f5745a93000); libtbb.so.2 => /home/ryan/src/salmon/external/install/lib/libtbb.so.2 (0x00007f5745864000); libgomp.so.1 => /usr/lib/x86_64-linux-gnu/libgomp.so.1 (0x00007f5745642000); librt.so.1 => /lib/x86_64-linux-gnu/librt.so.1 (0x00007f574543a000); libm.so.6 => /lib/x86_64-linux-gnu/libm.so.6 (0x00007f5745130000); libgcc_s.so.1 => /lib/x86_64-linux-gnu/libgcc_s.so.1 (0x00007f5744f1a000); libc.so.6 => /lib/x86_64-linux-gnu/libc.so.6 (0x00007f5744b51000); /lib64/ld-linux-x86-64.so.2 (0x000055d36c7b0000); libdl.so.2 => /lib/x86_64-linux-gnu/libdl.so.2 (0x00007f574494c000); libstdc++.so.6 => /usr/lib/x86_64-linux-gnu/libstdc++.so.6 (0x00007f57445ca000); ```,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267773540:382,install,install,382,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267773540,1,['install'],['install']
Deployability,"We do no have access to BSD-based systems (apart from the extent to which OSX can be said to be BSD-based) on which to test during development. Bioconda works on many linux distributions; though I do not have a comprehensive list. For example, we regularly run on Ubuntu, CentOS, RedHat and Debian. If you have the facilities to use Docker on this machine, you can also pull down a docker image of the latest release from https://hub.docker.com/r/combinelab/salmon.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/419#issuecomment-522628674:409,release,release,409,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/419#issuecomment-522628674,1,['release'],['release']
Deployability,"We have updated the docs. Thanks for the heads up . We are closing this issue for now,",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/367#issuecomment-498038312:8,update,updated,8,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/367#issuecomment-498038312,1,['update'],['updated']
Deployability,"Well, I was just in the middle of writing a comment saying ""it's been running for 6 hours with no hang, I don't think it's gonna happen"", and then it just hung. Here's the backtrace from gdb:. ```; $ gdb -ex ""attach $(pgrep salmon | head -1)"" -ex bt -ex detach -ex quit; GNU gdb (Ubuntu 7.11.1-0ubuntu1~16.04) 7.11.1; Copyright (C) 2016 Free Software Foundation, Inc.; License GPLv3+: GNU GPL version 3 or later <http://gnu.org/licenses/gpl.html>; This is free software: you are free to change and redistribute it.; There is NO WARRANTY, to the extent permitted by law. Type ""show copying""; and ""show warranty"" for details.; This GDB was configured as ""x86_64-linux-gnu"".; Type ""show configuration"" for configuration details.; For bug reporting instructions, please see:; <http://www.gnu.org/software/gdb/bugs/>.; Find the GDB manual and other documentation resources online at:; <http://www.gnu.org/software/gdb/documentation/>.; For help, type ""help"".; Type ""apropos word"" to search for commands related to ""word"".; Attaching to process 29153; [New LWP 29155]; [New LWP 29156]; [New LWP 29157]; [New LWP 18084]; [New LWP 18085]; [New LWP 18086]; [New LWP 18087]; [New LWP 18088]; [New LWP 18089]; [New LWP 18090]; [Thread debugging using libthread_db enabled]; Using host libthread_db library ""/lib/x86_64-linux-gnu/libthread_db.so.1"".; 0x0000000000578b90 in __log_finite@plt (); #0 0x0000000000578b90 in __log_finite@plt (); #1 0x0000000000637ccc in double std::gamma_distribution<double>::operator()<pcg_detail::engine<unsigned int, unsigned long, pcg_detail::xsh_rr_mixin<unsigned int, unsigned long>, true, pcg_detail::unique_stream<unsigned long>, pcg_detail::default_multiplier<unsigned long> > >(pcg_detail::engine<unsigned int, unsigned long, pcg_detail::xsh_rr_mixin<unsigned int, unsigned long>, true, pcg_detail::unique_stream<unsigned long>, pcg_detail::default_multiplier<unsigned long> >&, std::gamma_distribution<double>::param_type const&) (); #2 0x0000000000634b8d in tbb::interface",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267534520:684,configurat,configuration,684,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267534520,2,['configurat'],['configuration']
Deployability,What is the usage for `quantmerge`? I just installed from the develop branch..,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/77#issuecomment-303569258:43,install,installed,43,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/77#issuecomment-303569258,1,['install'],['installed']
Deployability,"When I do with proxy I got : . ```; Last login: Thu Jun 30 15:10:26 on ttys001; Benjamin@u932-ulm-2-57030119-6834 ~ % all_proxy= url:port conda install salmon; Collecting package metadata (current_repodata.json): failed. # >>>>>>>>>>>>>>>>>>>>>> ERROR REPORT <<<<<<<<<<<<<<<<<<<<<<. Traceback (most recent call last):; File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/conda/exceptions.py"", line 1082, in __call__; return func(*args, **kwargs); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/conda/cli/main.py"", line 87, in _main; exit_code = do_call(args, p); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/conda/cli/conda_argparse.py"", line 84, in do_call; return getattr(module, func_name)(args, parser); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/conda/cli/main_install.py"", line 20, in execute; install(args, parser, 'install'); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/conda/cli/install.py"", line 260, in install; unlink_link_transaction = solver.solve_for_transaction(; File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/conda/core/solve.py"", line 152, in solve_for_transaction; unlink_precs, link_precs = self.solve_for_diff(update_modifier, deps_modifier,; File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/conda/core/solve.py"", line 195, in solve_for_diff; final_precs = self.solve_final_state(update_modifier, deps_modifier, prune, ignore_pinned,; File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/conda/core/solve.py"", line 300, in solve_final_state; ssc = self._collect_all_metadata(ssc); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/conda/common/io.py"", line 88, in decorated; return f(*args, **kwds); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/conda/core/solve.py"", line 463, in _collect_all_metadata; index, r = self._prepare(prepared_specs); File ""/usr/local/Ca",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/724#issuecomment-1171208515:144,install,install,144,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/724#issuecomment-1171208515,4,['install'],['install']
Deployability,"When you compile the program, the last few lines tell you to make links to; the salmon executable and the LIB file. I forgot the lib file and was; getting this error. You can run the executable from the area of install; (works fine) or create a path to /urs/local/bin or any other folder you; want to install. You need to do this for both the files. For making path in linux:; https://stackoverflow.com/questions/14637979/how-to-permanently-set-path-on-linux. Hope this helps. On Mon, May 22, 2017 at 7:03 AM, Darlingfuer <notifications@github.com>; wrote:. > @sudeep71 <https://github.com/sudeep71> Hi there, I run into the same; > error when I use salmon. Would please tell me what you did to set a correct; > PATH ? Thanks!; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/COMBINE-lab/salmon/issues/135#issuecomment-303068916>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AGcbqM0Z1aeqPtMmppyF51gj9DvEJh5Vks5r8WtpgaJpZM4NT7ex>; > .; >",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/135#issuecomment-303152754:211,install,install,211,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/135#issuecomment-303152754,2,['install'],['install']
Deployability,"Where does `extract-libdivsufsort.cmake` live? I don't find it in the `salmon` repository. Is it generated automatically by `cmake`? The following patch/hack using `unzip` works around the `cmake -E tar xfz` bug for me. It seems to only affect extracting the `libdivsufsort.zip`, perhaps because it's a `.zip`. If that is the case, and there's a `.tar.gz` distribution of `libdivsufsort`, then there may be a simple fix. ``` diff; --- libdivsufsort-prefix/src/libdivsufsort-stamp/extract-libdivsufsort.cmake.orig 2016-03-07 22:02:35.000000000 -0800; +++ libdivsufsort-prefix/src/libdivsufsort-stamp/extract-libdivsufsort.cmake 2016-03-07 22:06:49.000000000 -0800; @@ -23,7 +23,7 @@; # Extract it:; #; message(STATUS ""extracting... [tar xfz]""); -execute_process(COMMAND ${CMAKE_COMMAND} -E tar xfz ${filename}; +execute_process(COMMAND unzip ${filename}; WORKING_DIRECTORY ${ut_dir}; RESULT_VARIABLE rv). ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/10#issuecomment-193623757:147,patch,patch,147,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/10#issuecomment-193623757,1,['patch'],['patch']
Deployability,"While I definitely trust the jemalloc devs, I do know that such things are possible, as a release is simply associated with a tagged commit, which _can_ be changed via a forced update to the tags. I know because, in my early days using git + GitHub, I did such a foolish thing. So, while I'm sure that the jemalloc devs wouldn't change the file associated with a tag, and while there are safeguards (e.g. check that the file we get matches the SHA of what we expect), simply pulling from a fork is a convenient way to handle this ""generally"" (for packages not as production-quality as jemalloc, or where the developers might not have tagged a release corresponding to what we need). I completely understand that you don't want to link against a standard jemalloc if we compile some strange version with custom modifications. However, here, we simply want to use the vanilla jemalloc. In fact, when salmon is built under bioconda, this is exactly what we do (we link against the conda jemalloc >= 5.1.0).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/288#issuecomment-420339510:90,release,release,90,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/288#issuecomment-420339510,3,"['release', 'update']","['release', 'update']"
Deployability,"Why am I seeing much higher values for this gene with FeatureCounts?. I have now run FeatureCounts several times with different overlaps (minOverlap =25, minOverlap =50, minOverlap =75min Overlap =100) and indeed the counts have decreased (again the psbI example: 8685 , 6011, 4237, 1805 accordingly). Again, this is a good argument for the hypothesis put forward. >Why does running Salmon outside nf-core lead to much higher values?. Hopefully, after I run Decoy mode, this problem is solved. I also tried mapping mode with the --softclipOverhangs option. That increased the counts (psbI : 4696 counts); playing around with the --minScoreFraction flag in addition to the --softclipOverhangs flag also increased the numbers ( minScoreFraction= 0 ->psbI = 8496; minScoreFraction= 0.5 ->psbI = 5633; minScoreFraction= 0.7 ->psbI =3627 ). . So, in summary, your explanation seems to be completely correct. ; In the case that decoy mode resolves the difference between the pipeline and the run outside the pipeline, I would not give this to the nf-core people. But I will if there are still large discrepancies after the run. I'm still not sure what the best parameters are for my analysis, but the --softclipOverhangs flag seems to be the best option for me now.; So thanks again!. @drpatelh. Thank you very much for your quick reply as well. ; I was a bit inaccurate when I said I used the FeatureCounts from the pipeline. I actually wasn't able to use the resulting .txt files. Instead, I used the resulting bam file from the pipeline to perform a FeatureCounts analysis on R. I hope this information answers the question of how I can compare the two results?; My genome and gtf file are from [EnsemblPlants](https://plants.ensembl.org/Arabidopsis_thaliana/Info/Index), so they should be fine. In the MultiQC file, the vast majority of reads align to protein coding regions according to FeatureCounts, so I hope my primary files are fine. . Thanks again for your help and time!. All the best ; Florian",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/798#issuecomment-1238043213:2365,pipeline,pipeline,2365,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/798#issuecomment-1238043213,2,['pipeline'],['pipeline']
Deployability,With the release of `v1.0` we don't need the gtf/gff any more. Closing this issue.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/384#issuecomment-549141221:9,release,release,9,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/384#issuecomment-549141221,1,['release'],['release']
Deployability,"Wow. Thanks for getting back so fast. I’ll update more info about the machine. It’s got 16GB of RAM and only 3GB of swap, so I do think it was memory pressure. In fact, I just looked through the system kernel messages and found the OOM routine killed my process:. ```Out of memory: Kill process 12997 (R) score 846 or sacrifice child │10-03 22:39 INFO Encountered FastxParser destructor while parser was still marked active (or while parsing threads were ; Killed process 12997, UID 1506502601, (R) total-vm:17105100kB, anon-rss:15306012kB, file-rss:12kB ; ```. Sorry I didn’t check this earlier!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/432#issuecomment-538606398:43,update,update,43,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/432#issuecomment-538606398,1,['update'],['update']
Deployability,"Yea I looked into `10.12.6`, it looks like Sierra. I just upgraded to mojave. I can ask somebody in the lab tomorrow if they have Sierra to compile and make a binary .",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/318#issuecomment-442682687:58,upgrade,upgraded,58,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/318#issuecomment-442682687,1,['upgrade'],['upgraded']
Deployability,Yeah! Salmon compiled! Using Ubuntu Trusty with GCC 4.8.4 and Salmon 0.6.0. No luck with GCC 5.3. My guess as to this issue (undefined reference) is that it's possibly mixing boost headers from one installation of boost that it found in /usr and boost libraries from another installation installed by Linuxbrew.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/46#issuecomment-193963209:198,install,installation,198,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/46#issuecomment-193963209,3,['install'],"['installation', 'installed']"
Deployability,"Yes ! it's other error that I can't find . but I try : . ```; Last login: Thu Jun 30 15:14:51 on ttys002; Benjamin@u932-ulm-2-57030119-6834 ~ % conda config --add channels defaults; conda config --add channels bioconda; conda config --add channels conda-forge; Warning: 'conda-forge' already in 'channels' list, moving to the top; Benjamin@u932-ulm-2-57030119-6834 ~ % conda install salmon; Collecting package metadata (current_repodata.json): failed. CondaHTTPError: HTTP 000 CONNECTION FAILED for url <https://conda.anaconda.org/conda-forge/osx-arm64/current_repodata.json>; Elapsed: -. An HTTP error occurred when trying to retrieve this URL.; HTTP errors are often intermittent, and a simple retry will get you on your way.; 'https://conda.anaconda.org/conda-forge/osx-arm64'; ```. ```; Benjamin@u932-ulm-2-57030119-6834 ~ % conda config --show channels ; channels:; - conda-forge; - bioconda; - defaults; ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/724#issuecomment-1171223414:375,install,install,375,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/724#issuecomment-1171223414,1,['install'],['install']
Deployability,"Yes, I'm aware of refgenie however, I was unable to identify for the hg38 salmon indices which specific transcriptome source (and additionally which version of said source) was used to build them.; Additionally, my use case here isn't entirely personal, I work for GSEA-MSigDB and GenePattern, we're in the process of improving the end-to-end analysis pipeline we offer to users, and one of the things we've been working on were wrapping the Salmon indexer, Salmon quant, and Alevin into GenePattern modules so that we can offer them to users who may want to run them on arbitrary transcriptomes in addition to the ones we offer specifically for GSEA compatibility. This issue was something we encountered when considering potential sources of inconsistency at different points in the pipeline.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/595#issuecomment-738180982:352,pipeline,pipeline,352,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/595#issuecomment-738180982,2,['pipeline'],['pipeline']
Deployability,"Yes, it is in the previous post.. https://www.gencodegenes.org/releases/current.html -> PRI.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/214#issuecomment-410709037:63,release,releases,63,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/214#issuecomment-410709037,1,['release'],['releases']
Deployability,"Yes, shared volumes :( - thanks @rob-p for the update - I'll give it a shot on our large index and hopefully feel the benefit!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/54#issuecomment-204206663:47,update,update,47,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/54#issuecomment-204206663,1,['update'],['update']
Deployability,"Yes, will update it too. Thank you :)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/804#issuecomment-1271753132:10,update,update,10,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/804#issuecomment-1271753132,1,['update'],['update']
Deployability,"You can pull from this commit sha on develop to test the equivalent changes on that branch `bd7096e0fa055e0a71ab03a52d99977bcb61c905`. If this works, I think I'm pretty much good to go for the release. Just doing some last minute clean up and finishing up the release notes.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/70#issuecomment-239632891:193,release,release,193,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/70#issuecomment-239632891,2,['release'],['release']
Deployability,You can try `sudo apt-get install zlib1g-dev`.; If you don't have root privilege then you might have to provide the path to the library file of the zlib.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/141#issuecomment-314423408:26,install,install,26,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/141#issuecomment-314423408,1,['install'],['install']
Deployability,"You can try installing from bioconda, or compiling from source. In the cases above, I presume this has to be resolved via the module system on the cluster / server where this is being run. In the pre-compiled binaries, salmon attempts to link against a specific, old version of libm to maximize compatibility among the operating systems on which it will run. However, given it's availability on bioconda, Dockerhub, and compiled via source, the pre-compiled executable for linux is probably the least preferred way to obtain and run salmon on linux.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/710#issuecomment-1165611828:12,install,installing,12,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/710#issuecomment-1165611828,1,['install'],['installing']
Deployability,Yup --- I see the source of the bug. I will push a fix and cut a patch release.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/123#issuecomment-283458128:65,patch,patch,65,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/123#issuecomment-283458128,2,"['patch', 'release']","['patch', 'release']"
Deployability,"[ 27%] Built target twopaco; [ 29%] Built target ksw2pp_sse2; [ 32%] Built target ksw2pp_sse4; [ 37%] Built target ksw2pp_basic; [ 38%] Built target ksw2pp; [ 59%] Built target puffer; [ 73%] Built target salmon_core; [ 76%] Built target alevin_core; [ 77%] Built target UnitTestsMain; [ 81%] Built target unitTests; [100%] Built target salmon; Install the project...; -- Install configuration: ""Release""; -- Installing: /salmon/lib/libntcard.a; -- Installing: /salmon/lib/ntcard/ntcard-targets.cmake; -- Installing: /salmon/lib/ntcard/ntcard-targets-release.cmake; -- Installing: /salmon/lib/libgraphdump.a; -- Installing: /salmon/lib/graphdump/graphdump-targets.cmake; -- Installing: /salmon/lib/graphdump/graphdump-targets-release.cmake; -- Installing: /salmon/lib/libtwopaco.a; -- Installing: /salmon/lib/twopaco/twopaco-targets.cmake; -- Installing: /salmon/lib/twopaco/twopaco-targets-release.cmake; -- Installing: /salmon/lib/libtbb.so; -- Installing: /salmon/lib/libtbb.so.12; -- Installing: /salmon/lib/libtbb.so.12.5; -- Installing: /salmon/lib/libtbbmalloc.so; -- Installing: /salmon/lib/libtbbmalloc.so.2; -- Installing: /salmon/lib/libtbbmalloc.so.2.5; -- Installing: /salmon/lib/libtbbmalloc_proxy.so; -- Installing: /salmon/lib/libtbbmalloc_proxy.so.2; -- Installing: /salmon/lib/libtbbmalloc_proxy.so.2.5; -- Installing: /salmon/bin/salmon; -- Installing: /salmon/lib/libsalmon_core.a. Installation complete. Please ensure the following paths are set properly.; ==========================================================================; Please add /salmon/bin to your PATH; Please add /salmon/lib to your LD_LIBRARY_PATH; ==========================================================================; root@fd877e359439:/salmon/build# make test; Running tests...; Test project /salmon/build; Start 1: unit_tests; 1/2 Test #1: unit_tests ....................... Passed 0.37 sec; Start 2: salmon_read_test_quasi; 2/2 Test #2: salmon_read_test_quasi ........... Passed 1.80 sec. 100% tests ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463312554:1922,Install,Installing,1922,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463312554,1,['Install'],['Installing']
Deployability,"[2021-12-30 00:46:19.915] [puff::index::jointLog] [warning] Entry with header [ENSMUST00000229312.1|ENSMUSG00000056486.18|OTTMUSG00000013428.7|OTTMUST00000171565.1|Chn1-211|Chn1|20|processed_transcript|], had length less than equal to the k-mer length of 29 (perhaps after poly-A clipping). # [omissis]. [2021-12-30 00:46:27.227] [puff::index::jointLog] [warning] Entry with header [ENSMUST00000226172.1|ENSMUSG00000002249.21|OTTMUSG00000024245.6|OTTMUST00000167695.2|Tead3-208|Tead3|11|processed_transcript|], had length less than equal to the k-mer length of 29 (perhaps after poly-A clipping); [2021-12-30 00:46:28.327] [puff::index::jointLog] [warning] Removed 1612 transcripts that were sequence duplicates of indexed transcripts.; [2021-12-30 00:46:28.327] [puff::index::jointLog] [warning] If you wish to retain duplicate transcripts, please use the `--keepDuplicates` flag; [2021-12-30 00:46:28.327] [puff::index::jointLog] [critical] The decoy file contained the names of 55 decoy sequences, but 0 were matched by sequences in the reference file provided. To prevent unintentional errors downstream, please ensure that the decoy file exactly matches with the fasta file that is being indexed.; [2021-12-30 00:46:28.449] [puff::index::jointLog] [error] The fixFasta phase failed with exit code 1; ```. I believe; - [x] version is correct; - [x] file paths exists; - [x] It is not the k-mer number as now I get the same error with `-k 29`. For the files I've used:; The GTF file I've used for `./generateDecoyTranscriptome.sh ` I've downloaded it from ensembl with:. ```; wget http://ftp.ensembl.org/pub/release-102/gtf/mus_musculus/Mus_musculus.GRCm38.102.gtf.gz; ```; and just renamed it with `mv`. While the genome file I something already present in my lab folder structure. I could download a new original genome fasta file for mm10 if you think it's worth for the troubleshooting. Otherwise I'm not really sure how I could share this file with you. Thanks a lot for your support, ; Nicco",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/731#issuecomment-1002817868:2440,release,release-,2440,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/731#issuecomment-1002817868,1,['release'],['release-']
Deployability,"[alevinLog] [info] Done importing order of barcodes ""quants_mat_rows.txt"" file.; [2019-01-29 09:55:59.107] [alevinLog] [info] Total 138 barcodes found; [2019-01-29 09:55:59.107] [alevinLog] [warning] mrna file not provided; using is 1 less feature for whitelisting; [2019-01-29 09:55:59.107] [alevinLog] [warning] rrna file not provided; using is 1 less feature for whitelisting; [2019-01-29 09:55:59.107] [alevinLog] [info] Starting to make feature Matrix; [2019-01-29 09:55:59.115] [alevinLog] [info] Done making regular featues; [2019-01-29 09:55:59.115] [alevinLog] [info] Done making feature Matrix; [2019-01-29 09:55:59.123] [alevinLog] [info] Finished white listing; [2019-01-29 09:55:59.126] [alevinLog] [info] Finished optimizer; ``` . Concat fastq:; ```; salmon alevin -l ISR -1 big.fastq.1.gz -2 big.fastq.2.gz --chromium -i geneset.dir/geneset_coding_exons.salmon.index/ -o salmon.dir/ --tgMap transcript2geneMap.tsv --dumpCsvCounts; Version Info: ### PLEASE UPGRADE SALMON ###; ### A newer version of Salmon with important bug fixes and improvements is available. ####; ###; The newest version, available at https://github.com/COMBINE-lab/salmon/releases; contains new features, improvements, and bug fixes; please upgrade at your; earliest convenience.; ###; Logs will be written to salmon.dir/logs; ### alevin (dscRNA-seq quantification) v0.11.3; ### [ program ] => salmon ; ### [ command ] => alevin ; ### [ libType ] => { ISR }; ### [ mates1 ] => { big.fastq.1.gz }; ### [ mates2 ] => { big.fastq.2.gz }; ### [ chromium ] => { }; ### [ index ] => { geneset.dir/geneset_coding_exons.salmon.index/ }; ### [ output ] => { salmon.dir/ }; ### [ tgMap ] => { transcript2geneMap.tsv }; ### [ dumpCsvCounts ] => { }. [2019-01-29 09:56:37.731] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2019-01-29 09:56:37.749] [alevinLog] [info] Processing barcodes files (if Present) . ; processed 2 Million barcodes. [2019-01-29 09:56:43.029",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/337#issuecomment-458481722:6049,UPGRADE,UPGRADE,6049,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/337#issuecomment-458481722,1,['UPGRADE'],['UPGRADE']
Deployability,"\1\1\0\0\0\0\0\0\0\0\0\3\0>\0\1\0\0\0\320v\1\0\0\0\0\0""..., 832) = 832; fstat(3, {st_mode=S_IFREG|0644, st_size=2271767, ...}) = 0; mmap(NULL, 2500784, PROT_READ|PROT_EXEC, MAP_PRIVATE|MAP_DENYWRITE, 3, 0) = 0x7fffbfb60000; mprotect(0x7fffbfbac000, 2097152, PROT_NONE) = 0; mmap(0x7fffbfdac000, 16384, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_DENYWRITE, 3, 0x4c000) = 0x7fffbfdac000; mmap(0x7fffbfdb0000, 75952, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_ANONYMOUS, -1, 0) = 0x7fffbfdb0000; close(3) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/libgomp.so.1"", O_RDONLY) = 3; read(3, ""\177ELF\2\1\1\0\0\0\0\0\0\0\0\0\3\0>\0\1\0\0\0\2405\0\0\0\0\0\0""..., 832) = 832; fstat(3, {st_mode=S_IFREG|0644, st_size=56344, ...}) = 0; mmap(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7fffbfb5f000; mmap(NULL, 2151616, PROT_READ|PROT_EXEC, MAP_PRIVATE|MAP_DENYWRITE, 3, 0) = 0x7fffbf951000; mprotect(0x7fffbf95e000, 2097152, PROT_NONE) = 0; mmap(0x7fffbfb5e000, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_DENYWRITE, 3, 0xd000) = 0x7fffbfb5e000; close(3) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/librt.so.1"", O_RDONLY) = 3; read(3, ""\177ELF\2\1\1\0\0\0\0\0\0\0\0\0\3\0>\0\1\0\0\0 \""\0\0\0\0\0\0""..., 832) = 832; fstat(3, {st_mode=S_IFREG|0644, st_size=50288, ...}) = 0; mmap(NULL, 2132936, PROT_READ|PROT_EXEC, MAP_PRIVATE|MAP_DENYWRITE, 3, 0) = 0x7fffbf748000; mprotect(0x7fffbf74f000, 2097152, PROT_NONE) = 0; mmap(0x7fffbf94f000, 8192, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_DENYWRITE, 3, 0x7000) = 0x7fffbf94f000; close(3) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/libm.so.6"", O_RDONLY) = 3; read(3, ""\177ELF\2\1\1\0\0\0\0\0\0\0\0\0\3\0>\0\1\0\0\0`>\0\0\0\0\0\0""..., 832) = 832; fstat(3, {st_mode=S_IFREG|0644, st_size=611736, ...}) = 0; mmap(NULL, 2629816, PROT_READ|PROT_EXEC, ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:18455,pipeline,pipeline,18455,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,4,['pipeline'],['pipeline']
Deployability,"]\200\316;\0\0\0""..., 832) = 832; fstat(3, {st_mode=S_IFREG|0755, st_size=145896, ...}) = 0; mmap(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7fffbffe3000; mmap(0x3bce800000, 2212848, PROT_READ|PROT_EXEC, MAP_PRIVATE|MAP_DENYWRITE, 3, 0) = 0x3bce800000; mprotect(0x3bce817000, 2097152, PROT_NONE) = 0; mmap(0x3bcea17000, 8192, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_DENYWRITE, 3, 0x17000) = 0x3bcea17000; mmap(0x3bcea19000, 13296, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_ANONYMOUS, -1, 0) = 0x3bcea19000; close(3) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/liblzma.so.0"", O_RDONLY) = 3; read(3, ""\177ELF\2\1\1\0\0\0\0\0\0\0\0\0\3\0>\0\1\0\0\0 %\0\0\0\0\0\0""..., 832) = 832; fstat(3, {st_mode=S_IFREG|0644, st_size=130728, ...}) = 0; mmap(NULL, 2226056, PROT_READ|PROT_EXEC, MAP_PRIVATE|MAP_DENYWRITE, 3, 0) = 0x7fffbfdc3000; mprotect(0x7fffbfde2000, 2097152, PROT_NONE) = 0; mmap(0x7fffbffe2000, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_DENYWRITE, 3, 0x1f000) = 0x7fffbffe2000; close(3) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/libtbb.so.2"", O_RDONLY) = 3; read(3, ""\177ELF\2\1\1\0\0\0\0\0\0\0\0\0\3\0>\0\1\0\0\0\320v\1\0\0\0\0\0""..., 832) = 832; fstat(3, {st_mode=S_IFREG|0644, st_size=2271767, ...}) = 0; mmap(NULL, 2500784, PROT_READ|PROT_EXEC, MAP_PRIVATE|MAP_DENYWRITE, 3, 0) = 0x7fffbfb60000; mprotect(0x7fffbfbac000, 2097152, PROT_NONE) = 0; mmap(0x7fffbfdac000, 16384, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_DENYWRITE, 3, 0x4c000) = 0x7fffbfdac000; mmap(0x7fffbfdb0000, 75952, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_ANONYMOUS, -1, 0) = 0x7fffbfdb0000; close(3) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/libgomp.so.1"", O_RDONLY) = 3; read(3, ""\177ELF\2\1\1\0\0\0\0\0\0\0\0\0\3\0>\0\1\0\0\0\2405\0\0\0\0\0\0""..., 832) = 832; fstat(3, {st_mode=S_",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:54033,pipeline,pipeline,54033,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,2,['pipeline'],['pipeline']
Deployability,"__________; From: tamuanand <notifications@github.com>; Sent: Saturday, 14 December 2019 10:53 AM; To: COMBINE-lab/salmon <salmon@noreply.github.com>; Cc: Susan Corley <s.corley@unsw.edu.au>; Mention <mention@noreply.github.com>; Subject: Re: [COMBINE-lab/salmon] Salmon SAF method - Read mapping issue with Lexogen/QuantSeq data?? (#449). Hi @s1corley<https://github.com/s1corley>. As @rob-p<https://github.com/rob-p> mentions, your paper could help assess different methodologies for quantification and also help optimize salmon further for QuantSeq. I would still like you to check if you have used salmon quant command line correctly for QuantSeq data analysis. Your paper briefly alludes to QuantSeq Forward in the Introduction section of the paper. The QuantSeq Forward kit has an oligo (dT) primer which contains the Illumina-specific Read 2 linker ... but the Methods section of your paper does not specify if you have used QuantSeq FWD or REV. Page 14 of the PDF from the Lexogen Website data analysis pipeline for QuantSeq FWD<https://www.bluebee.com/wp-content/uploads/2018/11/015UG108V0201-QuantSeq-Data-Analysis-Pipeline_2018-10-18.pdf> recommends using the below htseq command line. htseq-count -m intersection-nonempty -s yes -f bam -r pos $bam; $resource_dir/annotation.gtf > $bam_dir/read_counts.txt. QuantSeq is a stranded protocol. For the QuantSeq FWD pipeline the argument -s yes indicates; stranded in the sense orientation. For the QuantSeq REV pipeline -s reverse is used. Similar to the above htseq command line arguments, I think if you are using QuantSeq FWD, the libType argument from salmon quant should have been SF. One way I checked these with my datasets was to run the salmon quant command 3 times - once with libType A, once with libType SF and once with libType SR -- with QuantSeq FWD the estimated counts will be almost same with libType A and libType SF. I echo what @rob-p<https://github.com/rob-p> says - Congratulations once again on the paper. —; You are rec",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-565684552:1620,pipeline,pipeline,1620,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-565684552,1,['pipeline'],['pipeline']
Deployability,"_alzheimers/hg38/samples.manifest | awk ""NR==${SGE_TASK_ID}""); fi; ID=$(cat /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk '{print $NF}' | awk ""NR==${SGE_TASK_ID}""). mkdir -p /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test3/${ID}. /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon quant 	-i /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts -p 1 -l ISR 	-1 ${FILE1} -2 ${FILE2} 	-o /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test3/${ID}. echo ""**** Job ends ****""; date; ```. ### Example log file. ```; **** Job starts ****; Wed Mar 29 14:51:10 EDT 2017; **** JHPCE info ****; User: lcollado; Job id: 110315; Job name: step6-salmon_test3.gsk_phaseII; Hostname: compute-061; Task id: ; Version Info: This is the most recent version of Salmon.; ### salmon (mapping-based) v0.8.2; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts }; ### [ threads ] => { 1 }; ### [ libType ] => { ISR }; ### [ mates1 ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/merged_fastq/R10001_D2B1WACXX.fastq.gz }; ### [ mates2 ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/merged_fastq/R10001_D2B1WACXX_read2.fastq.gz }; ### [ output ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test3/R10001_D2B1WACXX }; Logs will be written to /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test3/R10001_D2B1WACXX/logs; [1m[2017-03-29 14:51:11.533] [jointLog] [info] parsing read library format; [00m[1m[2017-03-29 14:51:11.545] [jointLog] [info] There is 1 library.; [00mterminate called without an active exception; /cm/local/apps/sge/var/spool/compute-061/job_scripts/110315: line 31: 54922 Aborted (core dumped) /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon quant -i /dcl0",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-290516965:2166,pipeline,pipeline,2166,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-290516965,1,['pipeline'],['pipeline']
Deployability,"_alzheimers/hg38/samples.manifest | awk ""NR==${SGE_TASK_ID}""); fi; ID=$(cat /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk '{print $NF}' | awk ""NR==${SGE_TASK_ID}""). mkdir -p /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test5/${ID}. /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon quant 	-i /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts -p 1 -l ISR 	-1 ${FILE1} -2 ${FILE2} 	-o /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test5/${ID}. echo ""**** Job ends ****""; date; ```. ### Example log file. ```; **** Job starts ****; Wed Mar 29 23:27:11 EDT 2017; **** JHPCE info ****; User: lcollado; Job id: 110632; Job name: step6-salmon_test5.gsk_phaseII; Hostname: compute-066; Task id: ; Version Info: This is the most recent version of Salmon.; ### salmon (mapping-based) v0.8.2; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts }; ### [ threads ] => { 1 }; ### [ libType ] => { ISR }; ### [ mates1 ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/merged_fastq/R10001_D2B1WACXX.fastq.gz }; ### [ mates2 ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/merged_fastq/R10001_D2B1WACXX_read2.fastq.gz }; ### [ output ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test5/R10001_D2B1WACXX }; Logs will be written to /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test5/R10001_D2B1WACXX/logs; [1m[2017-03-29 23:59:18.699] [jointLog] [info] parsing read library format; [00m[1m[2017-03-29 23:59:18.721] [jointLog] [info] There is 1 library.; [00m[1m[2017-03-30 00:43:17.278] [stderrLog] [info] Loading Suffix Array ; [00m[1m[2017-03-30 00:43:17.237] [jointLog] [info] Loading Quasi index; [00m[1m[2017-03-30 00:43:17.273] [jointLog] [info] Loading 32-bit quasi index; [00m[1m[2017-03-30",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-290516965:9081,pipeline,pipeline,9081,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-290516965,1,['pipeline'],['pipeline']
Deployability,"_fmd_index --type fmd; GNU gdb (GDB) Red Hat Enterprise Linux 8.2-6.el8; Copyright (C) 2018 Free Software Foundation, Inc.; License GPLv3+: GNU GPL version 3 or later <http://gnu.org/licenses/gpl.html>; This is free software: you are free to change and redistribute it.; There is NO WARRANTY, to the extent permitted by law.; Type ""show copying"" and ""show warranty"" for details.; This GDB was configured as ""x86_64-redhat-linux-gnu"".; Type ""show configuration"" for configuration details.; For bug reporting instructions, please see:; <http://www.gnu.org/software/gdb/bugs/>.; Find the GDB manual and other documentation resources online at:; <http://www.gnu.org/software/gdb/documentation/>. For help, type ""help"".; Type ""apropos word"" to search for commands related to ""word""...; Reading symbols from salmon...done.; (gdb) r; Starting program: /home/common/modules/el8/x86_64/software/salmon/1.2.1-CentOS-vanilla/bin/salmon index -t transcripts.fasta -i sample_salmon_fmd_index --type fmd; Missing separate debuginfos, use: yum debuginfo-install glibc-2.28-72.el8_1.1.x86_64; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of EL",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641594410:2259,install,install,2259,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641594410,1,['install'],['install']
Deployability,"_x86_64/bin/../../external/install/lib/tls/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/tls"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/jhpce/shared/community/core/pcre/8.36/lib/tls/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/jhpce/shared/community/core/pcre/8.36/lib/tls/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/jhpce/shared/community/core/pcre/8.36/lib/tls/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/jhpce/shared/community/core/pcre/8.36/lib/tls"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/jhpce/shared/community/core/pcre/8.36/lib/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/jhpce/shared/community/core/pcre/8.36/lib/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/jhpce/shared/community/core/pcre/8.36/lib/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/jhpce/shared/community/core/pcre/8.36/lib"", {st_mode=S_IFDIR|S_ISGID|0755, st_size=19, ...}) = 0; open(""/jhpce/shared/community/core/j",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:9834,install,install,9834,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,4,['install'],['install']
Deployability,"```. Secondly, I created a new transcriptome-only salmon index (`singularity run -B /data $SALMON_SIMG salmon index -t genome.transcripts.fa -i salmon_index -k 31`), then ran `salmon quant` again (as above) but using the new transcriptome-only index. Note: 'genome.transcripts.fa' is the transcripts file created during the `nf-core/rnaseq` pipeline. Again, this analysis completed properly in a reasonable time. Seems like there is something very wrong with the 'gentrome.fa' file that's being created by `nf-core/rnaseq`! It's just so odd that _some_ samples would work and others wouldn't. 2. It's definitely worth noting that I originally opted against using `star_salmon` with the following command:. ```; nextflow run nf-core/rnaseq --max_memory 55.GB --fasta /data/reference_genomes/GRCh38/Homo_sapiens.GRCh38.dna_sm.primary_assembly.fa.gz --gtf /data/reference_genomes/GRCh38/Homo_sapiens.GRCh38.106.gtf.gz --skip_alignment --pseudo_aligner salmon --seq_center 'Ramaciotti Centre for Genomics' --input samplesheet.csv --outdir nf-core_results --save_merged_fastq true --skip_markduplicates true --extra_salmon_quant_args '--seqBias --gcBias --posBias' -profile singularity; ```. I'll re-run (a) using the refgenie salmon index specified; (b) with the `star_salmon` pathway to see if the decoy-aware index created that way is appropriate. 3. Other; I've installed `piscem` and can give it a go, although it does seem more like a salmon index issue with `nf-core/rnaseq` from the debugging above. Do you agree? If so, I'll raise an issue there. Considering this, would it still be useful to have access to the reads? I've got the green light to share them if need be. If so, what's a good contact address to share a OneDrive link?. Thanks!; Charles. p.s. something else odd that I can dig into further later if need be is that the singularity version of salmon created an index in about 5 minutes, yet the conda version has been creating the index for nearly 20 minutes so far with no change...",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/830#issuecomment-1441194948:2446,install,installed,2446,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/830#issuecomment-1441194948,1,['install'],['installed']
Deployability,"```; Benjamin@u932-ulm-2-57030119-6834 ~ % conda install salmon; Collecting package metadata (current_repodata.json): failed. CondaHTTPError: HTTP 000 CONNECTION FAILED for url <https://conda.anaconda.org/conda-forge/osx-arm64/current_repodata.json>; Elapsed: -. An HTTP error occurred when trying to retrieve this URL.; HTTP errors are often intermittent, and a simple retry will get you on your way.; 'https://conda.anaconda.org/conda-forge/osx-arm64'; ```. ```; Benjamin@u932-ulm-2-57030119-6834 ~ % conda config --show channels; channels:; - conda-forge; ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/724#issuecomment-1171204474:49,install,install,49,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/724#issuecomment-1171204474,1,['install'],['install']
Deployability,`cmake && make install` _should_ work --- the fetching should happen during the configuration (i.e. `cmake`) phase.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/181#issuecomment-367760156:15,install,install,15,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/181#issuecomment-367760156,2,"['configurat', 'install']","['configuration', 'install']"
Deployability,`cmake` fails when extracting external dependencies for me. See #10. I'd also like to be able to use the existing installed versions of dependencies. For me they're installed by Linuxbrew.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/19#issuecomment-193514127:114,install,installed,114,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/19#issuecomment-193514127,2,['install'],['installed']
Deployability,"`cmake` is being run with the default Homebrew flags, which are…; ```sh; cmake . -DCMAKE_C_FLAGS_RELEASE=-DNDEBUG -DCMAKE_CXX_FLAGS_RELEASE=-DNDEBUG -DCMAKE_INSTALL_PREFIX=/home/linuxbrew/.linuxbrew/Cellar/salmon/0.9.1 -DCMAKE_BUILD_TYPE=Release -DCMAKE_FIND_FRAMEWORK=LAST -DCMAKE_VERBOSE_MAKEFILE=ON -Wno-dev; ```; Are any of those options related?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/181#issuecomment-367735487:238,Release,Release,238,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/181#issuecomment-367735487,1,['Release'],['Release']
Deployability,"`extract-libdivsufsort.cmake` is auto-generated during configuration. However, the zip itself is grabbed as part of RapMap (specifically, it resides [here](https://github.com/COMBINE-lab/RapMap/tree/master/external)). I can take a look at what would be required to make it a tarball there (or, conversely, if there is a way to force CMake to use `unzip` rather than `cmake -E tar xfz`.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/10#issuecomment-193784017:55,configurat,configuration,55,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/10#issuecomment-193784017,1,['configurat'],['configuration']
Deployability,"ainly be interested in hearing about this and understanding the likely source of this kind of discrepancy. From what you've explained, here is my current hypothesis of what's going on. * Why are the salmon counts much lower for this gene when using alignment-mode and mapping mode under nf-core?. * Though the behavior you observe is similar, I think the cause is somewhat different. **In alignment mode**, STAR is used for alignment. The alignments are made against the genome and then _projected_ onto the annotated transcriptome. STAR has many internal rules for when an alignment can be successfully projected or not. In this case, STAR limits the number of soft clips it will permit in an alignment that it reports to be valid with respect to the annotated transcriptome. I am guessing that many alignments overhang the end of the annotated transcripts, and so STAR does not project them to the transcriptome and so salmon cannot count them. **In mapping mode**, the nf-core pipeline makes use of salmon's selective-alignment _with decoy sequences_. The main purpose of this is to avoid spurious mapping to transcriptomic sequences that may be similar to other unannotated sequences in the genome that are nonetheless a better match for the read (e.g. an unannotated possibly transcribed pseudogene). The way this works in practice is that both the transcript sequences themselves *and the full genome* are indexed. Any read that aligns _strictly better_ to the genome than the transcriptome is considered to map to a decoy, and is not used for the purposes of quantification. Consistent with the behavior I hypothesized above for STAR, if you have many softclipped bases at the end of the read that nonetheless match what is in the genome downstream of the end of the annotated transcript, you'll likely see these reads assigned as decoys. To check this, you can look at salmon's `meta_info.json` output file to see how many reads were mapped best to decoys. * Why do I see much higher counts f",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/798#issuecomment-1237133883:1118,pipeline,pipeline,1118,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/798#issuecomment-1237133883,1,['pipeline'],['pipeline']
Deployability,"ake CMakeFiles/libstadenio.dir/depend; cd /Users/gabriel/Projects/salmon-0.13.1/build && /usr/local/Cellar/cmake/3.13.4/bin/cmake -E cmake_depends ""Unix Makefiles"" /Users/gabriel/Projects/salmon-0.13.1 /Users/gabriel/Projects/salmon-0.13.1 /Users/gabriel/Projects/salmon-0.13.1/build /Users/gabriel/Projects/salmon-0.13.1/build /Users/gabriel/Projects/salmon-0.13.1/build/CMakeFiles/libstadenio.dir/DependInfo.cmake --color=; /Applications/Xcode.app/Contents/Developer/usr/bin/make -f CMakeFiles/libstadenio.dir/build.make CMakeFiles/libstadenio.dir/build; [ 9%] Performing configure step for 'libstadenio'; cd /Users/gabriel/Projects/salmon-0.13.1/external/staden-io_lib && ./configure --enable-shared=no --without-libcurl --prefix=/Users/gabriel/Projects/salmon-0.13.1/external/install LDFLAGS= CFLAGS= CC=/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/cc CXX=/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/c++; checking for a BSD-compatible install... /usr/local/bin/ginstall -c; checking whether build environment is sane... yes; checking for a thread-safe mkdir -p... /usr/local/bin/gmkdir -p; checking for gawk... gawk; checking whether make sets $(MAKE)... yes; checking whether make supports nested variables... yes; checking whether to enable maintainer-specific portions of Makefiles... no; checking for gcc... /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/cc; checking whether the C compiler works... yes; checking for C compiler default output file name... a.out; checking for suffix of executables...; checking whether we are cross compiling... configure: error: in `/Users/gabriel/Projects/salmon-0.13.1/external/staden-io_lib':; configure: error: cannot run C compiled programs.; If you meant to cross compile, use `--host'.; See `config.log' for more details; make[2]: *** [libstadenio-prefix/src/libstadenio-stamp/libstadenio-configure] Error 1; make[1]: *** [CMa",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/348#issuecomment-472500713:2403,install,install,2403,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/348#issuecomment-472500713,1,['install'],['install']
Deployability,"all/lib/tls/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/tls/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/tls/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/tls"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/jhpce/shared/community/core/pcre/8.36/lib/tls/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/jhpce/shared/community/core/pcre/8.36/lib/tls/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/jhpce/shared/community/core/pcre/8.36/lib/tls/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/jhpce/shared/community/core/pcre/8.36/lib/tls"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/jhpce/shared/community/core/pcre/8.36/lib/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/jhpce/shared/commu",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:9469,install,install,9469,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,8,"['install', 'pipeline']","['install', 'pipeline']"
Deployability,"all; [ 6%] Built target libdivsufsort; [ 12%] Built target libbz2; [ 17%] Built target liblzma; [ 24%] Built target libcereal; [ 31%] Built target libgff; [ 36%] Built target libbwa; [ 42%] Built target libstadenio; [ 48%] Built target libspdlog; [ 50%] Built target ksw2pp_sse4; [ 52%] Built target alevin_core; [ 55%] Built target ksw2pp_sse2; [ 60%] Built target ksw2pp_basic; [ 60%] Built target ksw2pp; [ 73%] Built target salmon_core; [ 77%] Built target unitTests; [100%] Built target salmon; Install the project...; -- Install configuration: ""Release""; -- Installing: /salmon-0.10.2/lib; -- Installing: /salmon-0.10.2/lib/libtbb.so; -- Installing: /salmon-0.10.2/lib/libtbbmalloc.so; -- Installing: /salmon-0.10.2/lib/libtbbmalloc_proxy.so; -- Installing: /salmon-0.10.2/lib/libtbbmalloc.so.2; -- Installing: /salmon-0.10.2/lib/libtbb.so.2; -- Installing: /salmon-0.10.2/lib/pkgconfig; -- Installing: /salmon-0.10.2/lib/libtbbmalloc_proxy.so.2; -- Installing: /salmon-0.10.2/bin/salmon; -- Installing: /salmon-0.10.2/lib/libsalmon_core.a. Installation complete. Please ensure the following paths are set properly.; ==========================================================================; Please add /salmon-0.10.2/bin to your PATH; Please add /salmon-0.10.2/lib to your LD_LIBRARY_PATH; ==========================================================================; root@e08cc9670e4a:/salmon-0.10.2/build# make test; Running tests...; Test project /salmon-0.10.2/build; Start 1: unit_tests; 1/3 Test #1: unit_tests ....................... Passed 0.17 sec; Start 2: salmon_read_test_fmd; 2/3 Test #2: salmon_read_test_fmd ............. Passed 1.78 sec; Start 3: salmon_read_test_quasi; 3/3 Test #3: salmon_read_test_quasi ........... Passed 1.59 sec. 100% tests passed, 0 tests failed out of 3. Total Test time (real) = 3.54 sec; root@e08cc9670e4a:/salmon-0.10.2/build# lsb_release -a; LSB Version: core-9.20160110ubuntu0.2-amd64:core-9.20160110ubuntu0.2-noarch:security-9.20160110ubuntu0.2-amd",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/250#issuecomment-404306268:1442,Install,Installing,1442,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/250#issuecomment-404306268,1,['Install'],['Installing']
Deployability,"almon.; Exception : [Error: FMD indexing is not supported in this version of salmon.]; /usr/common/src/salmon-latest_linux_x86_64/bin/salmon index was invoked improperly.; For usage information, try /usr/common/src/salmon-latest_linux_x86_64/bin/salmon index --help; Exiting.; #this worked OK; /usr/common/src/salmon-latest_linux_x86_64/bin/salmon index -t transcripts.fasta -i sample_salmon_fmd_index --type puff. ```; Here is what happens in gdb for the version I built:. ```; gdb --args salmon index -t transcripts.fasta -i sample_salmon_fmd_index --type fmd; GNU gdb (GDB) Red Hat Enterprise Linux 8.2-6.el8; Copyright (C) 2018 Free Software Foundation, Inc.; License GPLv3+: GNU GPL version 3 or later <http://gnu.org/licenses/gpl.html>; This is free software: you are free to change and redistribute it.; There is NO WARRANTY, to the extent permitted by law.; Type ""show copying"" and ""show warranty"" for details.; This GDB was configured as ""x86_64-redhat-linux-gnu"".; Type ""show configuration"" for configuration details.; For bug reporting instructions, please see:; <http://www.gnu.org/software/gdb/bugs/>.; Find the GDB manual and other documentation resources online at:; <http://www.gnu.org/software/gdb/documentation/>. For help, type ""help"".; Type ""apropos word"" to search for commands related to ""word""...; Reading symbols from salmon...done.; (gdb) r; Starting program: /home/common/modules/el8/x86_64/software/salmon/1.2.1-CentOS-vanilla/bin/salmon index -t transcripts.fasta -i sample_salmon_fmd_index --type fmd; Missing separate debuginfos, use: yum debuginfo-install glibc-2.28-72.el8_1.1.x86_64; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable secti",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641594410:1666,configurat,configuration,1666,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641594410,2,['configurat'],['configuration']
Deployability,"alzheimers/hg38/samples.manifest | awk ""NR==${SGE_TASK_ID}""); fi; ID=$(cat /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk '{print $NF}' | awk ""NR==${SGE_TASK_ID}""). mkdir -p /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test4/${ID}. /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon quant 	-i /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts -p 16 -l ISR 	-1 ${FILE1} -2 ${FILE2} 	-o /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test4/${ID}. echo ""**** Job ends ****""; date; ```. ### Example log file. ```; **** Job starts ****; Wed Mar 29 14:53:43 EDT 2017; **** JHPCE info ****; User: lcollado; Job id: 110316; Job name: step6-salmon_test4.gsk_phaseII; Hostname: compute-067; Task id: ; Version Info: This is the most recent version of Salmon.; ### salmon (mapping-based) v0.8.2; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts }; ### [ threads ] => { 16 }; ### [ libType ] => { ISR }; ### [ mates1 ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/merged_fastq/R10001_D2B1WACXX.fastq.gz }; ### [ mates2 ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/merged_fastq/R10001_D2B1WACXX_read2.fastq.gz }; ### [ output ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test4/R10001_D2B1WACXX }; Logs will be written to /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test4/R10001_D2B1WACXX/logs; [1m[2017-03-29 14:56:39.675] [jointLog] [info] parsing read library format; [00m[1m[2017-03-29 14:56:39.733] [jointLog] [info] There is 1 library.; [00mterminate called without an active exception; /cm/local/apps/sge/var/spool/compute-067/job_scripts/110316: line 31: 64339 Aborted (core dumped) /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon quant -i /dcl",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-290516965:5575,pipeline,pipeline,5575,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-290516965,1,['pipeline'],['pipeline']
Deployability,"astq/R10002_C29P7ACXX.fastq.gz"", {st_mode=S_IFREG|0644, st_size=4862610444, ...}) = 0; stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/merged_fastq/R10002_C29P7ACXX_read2.fastq.gz"", {st_mode=S_IFREG|0644, st_size=5004102866, ...}) = 0; stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/merged_fastq/R10002_C29P7ACXX_read2.fastq.gz"", {st_mode=S_IFREG|0644, st_size=5004102866, ...}) = 0; stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/merged_fastq/R10002_C29P7ACXX_read2.fastq.gz"", {st_mode=S_IFREG|0644, st_size=5004102866, ...}) = 0; stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts/versionInfo.json"", {st_mode=S_IFREG|0775, st_size=96, ...}) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts/versionInfo.json"", O_RDONLY) = 4; read(4, ""{\n \""indexVersion\"": 2,\n \""ha""..., 8191) = 96; read(4, """", 8191) = 0; close(4) = 0; stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts/versionInfo.json"", {st_mode=S_IFREG|0775, st_size=96, ...}) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts/versionInfo.json"", O_RDONLY) = 4; read(4, ""{\n \""indexVersion\"": 2,\n \""ha""..., 8191) = 96; read(4, """", 8191) = 0; close(4) = 0; clock_gettime(CLOCK_REALTIME, {1491424830, 69887706}) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts/header.json"", O_RDONLY) = 4; read(4, ""{\n \""value0\"": {\n \""Index""..., 8191) = 357; read(4, """", 8191) = 0; close(4) = 0; clock_gettime(CLOCK_REALTIME, {1491424830, 139950818}) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts/header.json"", O_RDONLY) = 4; read(4, ""{\n \""value0\"": {\n \""Index""..., 8191) = 357; read(4, """", 8191",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:165136,pipeline,pipeline,165136,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,1,['pipeline'],['pipeline']
Deployability,"at my transcript fasta, I noticed a problem with it, as you suggested. Long story short, half the premature transcripts had the wrong orientation and complementarity. Long story:. Oddly, the mature sequences were fine even though I used an identical approach to subset premature and mature transcripts from the genome reference!. Briefly my approach relied on three R packages rtracklayer, GenomicRanges, and Biostrings. 1. I used rtracklayer to load a gtf formatted exon annotations acquired from Ensembl. The file is loaded as a GenomicRanges object which essentially describes the locus of each exon (the transcribed strand [+ or -], chromosome, start and end positions relative to the reference strand) and its associated gene and transcript. 2. I used the GRanges object to generate pre-RNA coordinates that span all exons of a transcript. 3. I loaded the reference genome fasta acquired from Ensembl using the Biostrings package. GRanges and Biostrings are tightly integrated, allowing me to subset sequences from a Biostrings object using the GRanges object. **I believe the problem lies here.** It appears that when subsetting the mature exonic sequences from Biostrings using GRanges, the strand field in the GRanges object **was not** utilized. I.e., I needed to get the reverse complement of the extracted sequences for transcripts on the minus strand. I had done that and assumed that this behaviour would be consistent. However, for reasons I have not been able to pinpoint (potentially a bug), the strand information **was accounted for** when I used GRanges to subset the premature sequences. I **did not** need to get the reverse complement of the premature sequences on the minus strand as I had to do for the mature sequences. Yet, I did that anyway. I initially did test my protocol to ensure it produced identical transcript sequences to Gencode, but I only did this for mature sequences. All seemed fine for both + and - strand transcripts. After your feedback, I compared the pr",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/655#issuecomment-826035191:1514,integrat,integrated,1514,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/655#issuecomment-826035191,1,['integrat'],['integrated']
Deployability,"atible with the appropriate strand type (which may be unstranded if that is the protocol). Salmon is pretty conservative about reporting when there is any ambiguity. By default, if the strand bias is stronger than a few percent. In a stranded protocol, it will report and if it infers more than a few percent of fragments no having a valid alignment. So you can always double-check samples where the strandedness is at all ambiguous. > In addition, if a transcript was aligned in a unstranded manner and ended up aligning to the wrong location due to ambiguity between the positive orientation of one transcript and the negative orientation of another, can salmon correct this by reassigning it to the right transcript based on the joint probability of all the other alignments (if you can't tell I'm at the edge of my BS zone)?. If there is not an alignment to the correct location _in addition to_ the wrong location, then no. If you run salmon in alignment mode, it will assign each fragment probabilistically to the set of transcripts to which it aligns. There is, by definition, a probability of 0 for a fragment being assigned to a location where it doesn't align. That is, the reported alignment positions should contain the true alignment. STAR is pretty good at reporting all equally good alignments, but you could see some corner cases (e.g. if there is an alignment to a pseudogene location that looks _very_ similar to a gene, etc.). However, these are the issues that arise due to the inherent difficulty of spliced alignment. Salmon's built-in [selective alignment](https://genomebiology.biomedcentral.com/articles/10.1186/s13059-020-02151-8) is quite sensitive, but if you're using the STAR alignments for other tasks apart from transcript quantification, it may not be worth it to align the reads twice. Overall, STAR unstranded (using the `--quantMode TranscriptomeSAM`) -> salmon with `-l A` and then checking samples where there are any warnings should be a pretty robust pipeline.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/590#issuecomment-733417813:2822,pipeline,pipeline,2822,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/590#issuecomment-733417813,1,['pipeline'],['pipeline']
Deployability,"azy symbol binding failed: Symbol not found: _os_unfair_lock_lock. Referenced from: /Users/douglasbarrows/Tools/salmon_0.11.4-pre_OSX/bin/./salmon (which was built for Mac OS X 10.13). Expected in: /usr/lib/libSystem.B.dylib. dyld: Symbol not found: _os_unfair_lock_lock. Referenced from: /Users/douglasbarrows/Tools/salmon_0.11.4-pre_OSX/bin/./salmon (which was built for Mac OS X 10.13). Expected in: /usr/lib/libSystem.B.dylib. Trace/BPT trap: 5. Is that something you have seen before?. From: Rob Patro <notifications@github.com>; Reply-To: COMBINE-lab/salmon <reply@reply.github.com>; Date: Tuesday, October 23, 2018 at 8:25 PM; To: COMBINE-lab/salmon <salmon@noreply.github.com>; Cc: dougbarrows <dbarrows@mail.rockefeller.edu>, Author <author@noreply.github.com>; Subject: Re: [COMBINE-lab/salmon] Segmentation fault 11 with bioconda build (#303). Thanks for reporting this. It seems there is an osx bioconda issue (likely related to their massive backend upgrade). Hopefully we can fix this upstream in the next release. I. The meantime, can you see if this<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_COMBINE-2Dlab_salmon_files_2383948_salmon-5F0.11.4-2Dpre-5FOSX.tar.gz&d=DwMFaQ&c=JeTkUgVztGMmhKYjxsy2rfoWYibK1YmxXez1G3oNStg&r=AcsC5BcigO3PFsA0uPOPf6vTyS2zaocuu4GaWSrIemY&m=wLNfpc7aJ_B1oE6XAqYsYKk5m7_TsLrkikeQql9eerg&s=40WTo4E4Odm5ZPLtYzGnDNBOb05l6L5woT7ke2vQ1L4&e=> OSX binary works for you?. —; You are receiving this because you authored the thread.; Reply to this email directly, view it on GitHub<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_COMBINE-2Dlab_salmon_issues_303-23issuecomment-2D432468434&d=DwMFaQ&c=JeTkUgVztGMmhKYjxsy2rfoWYibK1YmxXez1G3oNStg&r=AcsC5BcigO3PFsA0uPOPf6vTyS2zaocuu4GaWSrIemY&m=wLNfpc7aJ_B1oE6XAqYsYKk5m7_TsLrkikeQql9eerg&s=2d8a8eiQ0LuIlgyxoiTnsiwesaQ16X9sju0l7tT1WAw&e=>, or mute the thread<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_notifications_unsubscribe-2Dauth_AYXm7zC7E77igQqcLnRZ1ABIhoVmQ9n",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/303#issuecomment-432469726:1141,release,release,1141,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/303#issuecomment-432469726,1,['release'],['release']
Deployability,"b"", {st_mode=S_IFDIR|0775, st_size=33280, ...}) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/tls/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/tls/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/tls/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/tls"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin"", {st_mode=S_IFDIR|0755, st_size=33280, ...}) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/tls/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/tls/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/tls/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/tls"", 0x7fff",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:8173,pipeline,pipeline,8173,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,4,['pipeline'],['pipeline']
Deployability,"b/tls/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/tls/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/tls"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/jhpce/shared/community/core/pcre/8.36/lib/tls/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/jhpce/shared/community/core/pcre/8.36/lib/tls/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/jhpce/shared/community/core/pcre/8.36/lib/tls/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/jhpce/shared/community/core/pcre/8.36/lib/tls"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/jhpce/shared/community/core/pcre/8.36/lib/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/jhpce/shared/community/core/pcre/8.36/lib/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/jhpce/shared/community/core/pcre/8.36/lib/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or dire",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:9771,pipeline,pipeline,9771,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,4,['pipeline'],['pipeline']
Deployability,"ble difference is because (1) the reads are assumed to arrive in a random order (2) this is only a very small fraction of the total data and (3) if the unoriented reads map to a target in the ""wrong"" direction, they will also align to the proper target in the ""right"" direction and, once the orientation filter is applied for future reads, the weight of evidence should turn the probability of assignment of these unoriented reads toward the proper target. However, I'm guessing there is an edge case you're seeing here where the conditions don't induce this behavior. So, there are 2 immediate solutions to the problem. First, if you know the library type explicitly, you can use that. Second (and some other folks have discussed this here for other reasons), you can do a ""throw-away"" run of salmon on a small prefix of the read file (e.g. `salmon quant ... -lA --skipQuant -r <(gunzip -c reads.fq.gz | head -n 400000)`) to get the output of the automatic library type determination, and then run the full dataset with that library type. Finally, moving forward, I'm happy to consider working on modifying this default behavior. That is, we could (though it would be a little bit of work) modify the default behavior. The idea here is to basically run as we do now for the first 10,000 aligned reads to get the library type and then ""reset"" the whole quantification pipeline. The main challenge here is that salmon is designed to work with streaming FASTQ input, and we don't want to break that. So we can't do something as easy as ""reset the file pointer"". I think the best option is to make a copy of the first X reads in memory, detection the library type with them, and then start quantifying them and continue with the rest of the file. That complicates the logic a bit, because now the input source for reads changes dynamically during quantification --- but I think it could be done. Please let me know if you both have interest in this feature and it's worth putting on the list. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/489#issuecomment-738830213:2669,pipeline,pipeline,2669,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/489#issuecomment-738830213,1,['pipeline'],['pipeline']
Deployability,can you try `make install` before `make test`?,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/229#issuecomment-393690468:18,install,install,18,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/229#issuecomment-393690468,1,['install'],['install']
Deployability,"cc : @k3yavi . Hi @xuesoso, I know that Avi (tagged above) has implemented a flag for this, but I'm not certain if it is exposed in the current release. I'm tagging him here to chime in.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/567#issuecomment-695004138:144,release,release,144,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/567#issuecomment-695004138,1,['release'],['release']
Deployability,"cellranger/salmon/transcripts_index --tgMap tx2gene.txt; [Thread debugging using libthread_db enabled]; Using host libthread_db library ""/lib/x86_64-linux-gnu/libthread_db.so.1"".; warning: File ""/u/user/local/lib64/libstdc++.so.6.0.21-gdb.py"" auto-loading has been declined by your `auto-load safe; -path' set to ""$debugdir:$datadir/auto-load"".; To enable execution of this file add; add-auto-load-safe-path /u/user/local/lib64/libstdc++.so.6.0.21-gdb.py; line to your configuration file ""/u/user/.gdbinit"".; To completely disable this security protection add; set auto-load safe-path /; line to your configuration file ""/u/user/.gdbinit"".; For more information about this security protection see the; ""Auto-loading safe path"" section in the GDB manual. E.g., run from the shell:; info ""(gdb)Auto-loading safe path""; [New Thread 0x7fff7dbff700 (LWP 21437)]; [Thread 0x7fff7dbff700 (LWP 21437) exited]; Version Info: Could not resolve upgrade information in the alotted time.; Check for upgrades manually at https://combine-lab.github.io/salmon; [New Thread 0x7ffefcfff700 (LWP 21653)]; Logs will be written to BM_1/alevin/logs; [New Thread 0x7ffe7cffe700 (LWP 21654)]; [New Thread 0x7ffdfcffd700 (LWP 21655)]; [New Thread 0x7ffd7cffc700 (LWP 21656)]; ### salmon (single-cell-based) v0.10.3; ### [ program ] => salmon; ### [ command ] => alevin; ### [ libType ] => { ISR }; ### [ chromium ] => { }; ### [ threads ] => { 4 }; ### [ output ] => { BM_1/alevin }; ### [ mates1 ] => { ./BM_1/run1/bm_S10_L001_R1_001.fastq.gz }; ### [ mates2 ] => { ./BM_1/run1/bm_S10_L001_R2_001.fastq.gz }; ### [ maxHashResizeThreads ] => { 2 }; ### [ index ] => { /u/user/ref/cellranger/salmon/transcripts_index }; ### [ tgMap ] => { tx2gene.txt }. [2018-06-10 16:07:09.798] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [New Thread 0x7ffcfcffb700 (LWP 21657)]; [Thread 0x7ffcfcffb700 (LWP 21657) exited]; [New Thread 0x7ffc7cffa700 (LWP 21658)]; [New Thread 0x",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-396078627:2456,upgrade,upgrades,2456,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-396078627,1,['upgrade'],['upgrades']
Deployability,"cl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/${ID}. strace /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon quant 	-i /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts -p 1 -l ISR 	-1 ${FILE1} -2 ${FILE2} 	-o /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/${ID} 2> logs/strace_test12_${SGE_TASK_ID}.txt. echo ""**** Job ends ****""; date; ```. Again, here is the `strace` output for task 1 (411 lines):. ```; execve(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon"", [""/dcl01/lieber/ajaffe/Emily/RNAse""..., ""quant"", ""-i"", ""/dcl01/lieber/ajaffe/Emily/RNAse""..., ""-p"", ""1"", ""-l"", ""ISR"", ""-1"", ""/dcl01/lieber/ajaffe/lab/libd_al""..., ""-2"", ""/dcl01/lieber/ajaffe/lab/libd_al""..., ""-o"", ""/dcl01/lieber/ajaffe/lab/libd_al""...], [/* 107 vars */]) = 0; brk(0) = 0xc2c000; mmap(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7fffbfffd000; readlink(""/proc/self/exe"", ""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon"", 4096) = 88; access(""/etc/ld.so.preload"", R_OK) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/tls/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/tls/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/tls/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/tls"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/x86_64/li",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:79725,pipeline,pipeline,79725,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,1,['pipeline'],['pipeline']
Deployability,"code prefix, where either nothing, or `A/GT/TCA` are added to the front of some cell barcodes. Here are the full descriptions:. ```; # Long sequence:; # 0123456789012345678901234567890123456789012345678901234567890123456789012345; # [--BC1--][----L1----][--BC2--][----L02----][--BC3--][-UMI1-][TTTTTTTTTTTTTT]; # L1 = ACTGGCCTGCGA; L2 = GGTAGCGGTGACA; # Short sequence:; # 012345678901234567890123456789012345678901234567890; # [--BC1--][L1][--BC2--][L2][--BC3--][-UMI1-][TTTTTT]; # L1 = GTGA; L2 = GACA; # Note: short sequence can also be prepended with A/GT/TCA to improve Illumina base; # call distributions, i.e.; # [--BC1--][L1][--BC2--][L2][--BC3--][-UMI1-][TTTTTT]; # A[--BC1--][L1][--BC2--][L2][--BC3--][-UMI1-][TTTTT]; # GT[--BC1--][L1][--BC2--][L2][--BC3--][-UMI1-][TTTT]; # TCA[--BC1--][L1][--BC2--][L2][--BC3--][-UMI1-][TTT]; ```. This means that the regions defined in the geometry specification above can appear up to 3bp away from their expected region. I've updated my barcode squishing script ([here](https://gitlab.com/gringer/bioinfscripts/-/blob/master/synthSquish.pl)) to account for this. The script identifies the cell barcode regions, corrects cell barcode sequences according to the Rhapsody Bioinformatics manual, and then shifts the linker sequences to after the UMI region, i.e.:. # 012345678901234567890123456789012345678901234567890...; # [--BC1--][--BC2--][--BC3--][-UMI1-][L1][L2][TTTTTT...]. [The prefix sequence is discarded]. After using this script to pre-process R1, with both the old and new cell barcode format (both use 9x9x9 cell barcodes), the following geometry can be used for `salmon alevin`:. --umi-geometry '1[28-35]' --bc-geometry '1[1-27]' --read-geometry '2[1-end]'. I've attached files containing the 96 barcodes from each region from my most recent Rhapsody single cell sequencing run (with 51bp R1 reads). These were collected by processing reads 2M-12M from R1 of one of our files, and choosing the most abundant sequences:. ```; zgrep '^[ACGT]\+$",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/628#issuecomment-1277030250:1494,update,updated,1494,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/628#issuecomment-1277030250,1,['update'],['updated']
Deployability,"ctory); open(""/jhpce/shared/community/core/jags/4.2.0/lib64/libc.so.6"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/jhpce/shared/community/compiler/gcc/4.4.7/netcdf/4.3.2/lib/libc.so.6"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/jhpce/shared/community/core/curl/7.43.0/lib/libc.so.6"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/cm/shared/apps/sge/2011.11p1/lib/linux-x64/libc.so.6"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/cm/shared/apps/sge/current/lib/linux-x64/libc.so.6"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/lib64/libc.so.6"", O_RDONLY) = 3; read(3, ""\177ELF\2\1\1\3\0\0\0\0\0\0\0\0\3\0>\0\1\0\0\0p\356A\316;\0\0\0""..., 832) = 832; fstat(3, {st_mode=S_IFREG|0755, st_size=1926760, ...}) = 0; mmap(0x3bce400000, 3750152, PROT_READ|PROT_EXEC, MAP_PRIVATE|MAP_DENYWRITE, 3, 0) = 0x3bce400000; mprotect(0x3bce58a000, 2097152, PROT_NONE) = 0; mmap(0x3bce78a000, 20480, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_DENYWRITE, 3, 0x18a000) = 0x3bce78a000; mmap(0x3bce78f000, 18696, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_ANONYMOUS, -1, 0) = 0x3bce78f000; close(3) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/libdl.so.2"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../lib/libdl.so.2"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/libdl.so.2"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/jhpce/shared/community/core/pcre/8.36/lib/libdl.so.2"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/jhpce/shared/community/core/jags/4.2.0/lib64/libdl.so.2"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/jhpce/shared/community/compiler/gcc/4.4.7/netcdf/4.3.2/lib/libdl.so.2"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:58778,pipeline,pipeline,58778,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,2,['pipeline'],['pipeline']
Deployability,"d# make install; [ 7%] Built target libcereal; [ 13%] Built target libtbb; [ 16%] Built target ntcard; [ 19%] Built target graphdump; [ 27%] Built target twopaco; [ 29%] Built target ksw2pp_sse2; [ 32%] Built target ksw2pp_sse4; [ 37%] Built target ksw2pp_basic; [ 38%] Built target ksw2pp; [ 59%] Built target puffer; [ 73%] Built target salmon_core; [ 76%] Built target alevin_core; [ 77%] Built target UnitTestsMain; [ 81%] Built target unitTests; [100%] Built target salmon; Install the project...; -- Install configuration: ""Release""; -- Installing: /salmon/lib/libntcard.a; -- Installing: /salmon/lib/ntcard/ntcard-targets.cmake; -- Installing: /salmon/lib/ntcard/ntcard-targets-release.cmake; -- Installing: /salmon/lib/libgraphdump.a; -- Installing: /salmon/lib/graphdump/graphdump-targets.cmake; -- Installing: /salmon/lib/graphdump/graphdump-targets-release.cmake; -- Installing: /salmon/lib/libtwopaco.a; -- Installing: /salmon/lib/twopaco/twopaco-targets.cmake; -- Installing: /salmon/lib/twopaco/twopaco-targets-release.cmake; -- Installing: /salmon/lib/libtbb.so; -- Installing: /salmon/lib/libtbb.so.12; -- Installing: /salmon/lib/libtbb.so.12.5; -- Installing: /salmon/lib/libtbbmalloc.so; -- Installing: /salmon/lib/libtbbmalloc.so.2; -- Installing: /salmon/lib/libtbbmalloc.so.2.5; -- Installing: /salmon/lib/libtbbmalloc_proxy.so; -- Installing: /salmon/lib/libtbbmalloc_proxy.so.2; -- Installing: /salmon/lib/libtbbmalloc_proxy.so.2.5; -- Installing: /salmon/bin/salmon; -- Installing: /salmon/lib/libsalmon_core.a. Installation complete. Please ensure the following paths are set properly.; ==========================================================================; Please add /salmon/bin to your PATH; Please add /salmon/lib to your LD_LIBRARY_PATH; ==========================================================================; root@fd877e359439:/salmon/build# make test; Running tests...; Test project /salmon/build; Start 1: unit_tests; 1/2 Test #1: unit_tests ................",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463312554:1777,Install,Installing,1777,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463312554,2,"['Install', 'release']","['Installing', 'release']"
Deployability,"d; #$ -pe local 2; #$ -l mem_free=7G,h_vmem=8G,h_fsize=100G; #$ -N step6-salmon_test11.gsk_phaseII; #$ -o ./logs/salmon_test11.$TASK_ID.txt; #$ -e ./logs/salmon_test11.$TASK_ID.txt; #$ -t 1-3; #$ -hold_jid pipeline_setup,step4-featCounts-alzheimer.gsk_phaseII; #$ -m e; echo ""**** Job starts ****""; date. echo ""**** JHPCE info ****""; echo ""User: ${USER}""; echo ""Job id: ${JOB_ID}""; echo ""Job name: ${JOB_NAME}""; echo ""Hostname: ${HOSTNAME}""; echo ""Task id: ${TASK_ID}"". FILE1=$(awk 'BEGIN {FS=""\t""} {print $1}' /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk ""NR==${SGE_TASK_ID}""); if [ TRUE == ""TRUE"" ] ; then; FILE2=$(awk 'BEGIN {FS=""\t""} {print $3}' /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk ""NR==${SGE_TASK_ID}""); fi; ID=$(cat /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk '{print $NF}' | awk ""NR==${SGE_TASK_ID}""). mkdir -p /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/${ID}. strace /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon quant 	-i /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts -p 1 -l ISR 	-1 ${FILE1} -2 ${FILE2} 	-o /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/${ID} 2> logs/strace_${SGE_TASK_ID}.txt. echo ""**** Job ends ****""; date; ```. This requests SGE 2 cores with a total free memory of 2 * 7 = 14 GB and a maximum memory of 16 GB. This is the `strace` output for task 1:. ```; execve(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon"", [""/dcl01/lieber/ajaffe/Emily/RNAse""..., ""quant"", ""-i"", ""/dcl01/lieber/ajaffe/Emily/RNAse""..., ""-p"", ""1"", ""-l"", ""ISR"", ""-1"", ""/dcl01/lieber/ajaffe/lab/libd_al""..., ""-2"", ""/dcl01/lieber/ajaffe/lab/libd_al""..., ""-o"", ""/dcl01/lieber/ajaffe/lab/libd_al""...], [/* 107 vars */]) = 0; brk(0) = 0xc2c000; mmap(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7fffbfffd000; re",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:3339,pipeline,pipeline,3339,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,1,['pipeline'],['pipeline']
Deployability,"dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon quant 	-i /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts -p 1 -l ISR 	-1 ${FILE1} -2 ${FILE2} 	-o /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/${ID} 2> logs/strace_${SGE_TASK_ID}.txt. echo ""**** Job ends ****""; date; ```. This requests SGE 2 cores with a total free memory of 2 * 7 = 14 GB and a maximum memory of 16 GB. This is the `strace` output for task 1:. ```; execve(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon"", [""/dcl01/lieber/ajaffe/Emily/RNAse""..., ""quant"", ""-i"", ""/dcl01/lieber/ajaffe/Emily/RNAse""..., ""-p"", ""1"", ""-l"", ""ISR"", ""-1"", ""/dcl01/lieber/ajaffe/lab/libd_al""..., ""-2"", ""/dcl01/lieber/ajaffe/lab/libd_al""..., ""-o"", ""/dcl01/lieber/ajaffe/lab/libd_al""...], [/* 107 vars */]) = 0; brk(0) = 0xc2c000; mmap(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7fffbfffd000; readlink(""/proc/self/exe"", ""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon"", 4096) = 88; access(""/etc/ld.so.preload"", R_OK) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/tls/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/tls/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/tls/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/tls"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/x86_64/li",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:4392,pipeline,pipeline,4392,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,1,['pipeline'],['pipeline']
Deployability,"dev libbz2-dev cmake zlib1g-dev curl unzip wget libcurl4-openssl-dev. $ git clone https://github.com/COMBINE-lab/salmon.git; $ cd salmon; $ mkdir build && cd build; $ cmake -DNO_IPO=TRUE .. # GCC still doesn't handle LTO robustly; $ make -j8; $ make install; $ make test; ```. which leads to the output. ```; root@fd877e359439:/salmon/build# make install; [ 7%] Built target libcereal; [ 13%] Built target libtbb; [ 16%] Built target ntcard; [ 19%] Built target graphdump; [ 27%] Built target twopaco; [ 29%] Built target ksw2pp_sse2; [ 32%] Built target ksw2pp_sse4; [ 37%] Built target ksw2pp_basic; [ 38%] Built target ksw2pp; [ 59%] Built target puffer; [ 73%] Built target salmon_core; [ 76%] Built target alevin_core; [ 77%] Built target UnitTestsMain; [ 81%] Built target unitTests; [100%] Built target salmon; Install the project...; -- Install configuration: ""Release""; -- Installing: /salmon/lib/libntcard.a; -- Installing: /salmon/lib/ntcard/ntcard-targets.cmake; -- Installing: /salmon/lib/ntcard/ntcard-targets-release.cmake; -- Installing: /salmon/lib/libgraphdump.a; -- Installing: /salmon/lib/graphdump/graphdump-targets.cmake; -- Installing: /salmon/lib/graphdump/graphdump-targets-release.cmake; -- Installing: /salmon/lib/libtwopaco.a; -- Installing: /salmon/lib/twopaco/twopaco-targets.cmake; -- Installing: /salmon/lib/twopaco/twopaco-targets-release.cmake; -- Installing: /salmon/lib/libtbb.so; -- Installing: /salmon/lib/libtbb.so.12; -- Installing: /salmon/lib/libtbb.so.12.5; -- Installing: /salmon/lib/libtbbmalloc.so; -- Installing: /salmon/lib/libtbbmalloc.so.2; -- Installing: /salmon/lib/libtbbmalloc.so.2.5; -- Installing: /salmon/lib/libtbbmalloc_proxy.so; -- Installing: /salmon/lib/libtbbmalloc_proxy.so.2; -- Installing: /salmon/lib/libtbbmalloc_proxy.so.2.5; -- Installing: /salmon/bin/salmon; -- Installing: /salmon/lib/libsalmon_core.a. Installation complete. Please ensure the following paths are set properly.; =================================================",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463312554:1439,Install,Installing,1439,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463312554,2,"['Install', 'release']","['Installing', 'release']"
Deployability,"e of intuition formally into the probabilistic model and (2) is it possible to incorporate this information efficiently?. This is definitely your domain of expertise (and I know it's a rhetorical question but I'd love to throw some ideas out here)... I can think of a few mostly heuristical approaches.... . 1) when apportioning reads to transcripts, after the mapping phase, incorporate a notion of ""evenness"" into the EM step... reads that decrease the variance in coverage are favored over reads that increase the variance (so, define read depth per 10 bp window or something and calculate the variance across all windows for the transcript, then try to assign reads such that they minimize read depth variance per isoform). The problem here is actual coverage biases may then masquerade as alternative transcript isoforms... 2) Use the information from the unique sequences between the transcripts... the read depth over unique regions updates the prior on the overall transcript abundance, and the otherwise non-unique reads get apportioned in accordance with the unique-region-derived prior... . But as I think about it... I realize I don't *really* know the underlying algorithmic details of the existing implements. But it would be **amazing** if you could incorporate this type of information into Salmon. I really hope some progress can be made here! . Thanks again for helping me out and showing interest in the motivating problem!. P.S.,; As a total aside, I've been working with this large yeast RNAseq dataset and eventually reached the same conclusions as the selective alignment paper and other recent ones; that is, the most important aspect for getting good transcript-level quantifications is not aligning to the genome vs. aligning to the transcriptome, but rather having an accurate transcriptome annotation to begin with. I saw **huge** gains from updating my transcriptome annotation to include UTRs, especially given differences in coverage bias between samples... for example,",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-623963851:3445,update,updates,3445,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-623963851,1,['update'],['updates']
Deployability,"e salmon; ../../external/install/lib/libstaden-read.a(libstaden_read_la-open_trace_file.o): In function `find_file_url':; open_trace_file.c:(.text+0xec4): warning: the use of `tempnam' is dangerous, better use `mkstemp'; [100%] Built target salmon; root@e08cc9670e4a:/salmon-0.10.2/build# make install; [ 6%] Built target libdivsufsort; [ 12%] Built target libbz2; [ 17%] Built target liblzma; [ 24%] Built target libcereal; [ 31%] Built target libgff; [ 36%] Built target libbwa; [ 42%] Built target libstadenio; [ 48%] Built target libspdlog; [ 50%] Built target ksw2pp_sse4; [ 52%] Built target alevin_core; [ 55%] Built target ksw2pp_sse2; [ 60%] Built target ksw2pp_basic; [ 60%] Built target ksw2pp; [ 73%] Built target salmon_core; [ 77%] Built target unitTests; [100%] Built target salmon; Install the project...; -- Install configuration: ""Release""; -- Installing: /salmon-0.10.2/lib; -- Installing: /salmon-0.10.2/lib/libtbb.so; -- Installing: /salmon-0.10.2/lib/libtbbmalloc.so; -- Installing: /salmon-0.10.2/lib/libtbbmalloc_proxy.so; -- Installing: /salmon-0.10.2/lib/libtbbmalloc.so.2; -- Installing: /salmon-0.10.2/lib/libtbb.so.2; -- Installing: /salmon-0.10.2/lib/pkgconfig; -- Installing: /salmon-0.10.2/lib/libtbbmalloc_proxy.so.2; -- Installing: /salmon-0.10.2/bin/salmon; -- Installing: /salmon-0.10.2/lib/libsalmon_core.a. Installation complete. Please ensure the following paths are set properly.; ==========================================================================; Please add /salmon-0.10.2/bin to your PATH; Please add /salmon-0.10.2/lib to your LD_LIBRARY_PATH; ==========================================================================; root@e08cc9670e4a:/salmon-0.10.2/build# make test; Running tests...; Test project /salmon-0.10.2/build; Start 1: unit_tests; 1/3 Test #1: unit_tests ....................... Passed 0.17 sec; Start 2: salmon_read_test_fmd; 2/3 Test #2: salmon_read_test_fmd ............. Passed 1.78 sec; Start 3: salmon_read_test_quasi; 3/3 Test #",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/250#issuecomment-404306268:1139,Install,Installing,1139,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/250#issuecomment-404306268,1,['Install'],['Installing']
Deployability,"eII; #$ -o ./logs/salmon_test11.$TASK_ID.txt; #$ -e ./logs/salmon_test11.$TASK_ID.txt; #$ -t 1-3; #$ -hold_jid pipeline_setup,step4-featCounts-alzheimer.gsk_phaseII; #$ -m e; echo ""**** Job starts ****""; date. echo ""**** JHPCE info ****""; echo ""User: ${USER}""; echo ""Job id: ${JOB_ID}""; echo ""Job name: ${JOB_NAME}""; echo ""Hostname: ${HOSTNAME}""; echo ""Task id: ${TASK_ID}"". FILE1=$(awk 'BEGIN {FS=""\t""} {print $1}' /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk ""NR==${SGE_TASK_ID}""); if [ TRUE == ""TRUE"" ] ; then; FILE2=$(awk 'BEGIN {FS=""\t""} {print $3}' /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk ""NR==${SGE_TASK_ID}""); fi; ID=$(cat /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk '{print $NF}' | awk ""NR==${SGE_TASK_ID}""). mkdir -p /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/${ID}. strace /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon quant 	-i /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts -p 1 -l ISR 	-1 ${FILE1} -2 ${FILE2} 	-o /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/${ID} 2> logs/strace_${SGE_TASK_ID}.txt. echo ""**** Job ends ****""; date; ```. This requests SGE 2 cores with a total free memory of 2 * 7 = 14 GB and a maximum memory of 16 GB. This is the `strace` output for task 1:. ```; execve(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon"", [""/dcl01/lieber/ajaffe/Emily/RNAse""..., ""quant"", ""-i"", ""/dcl01/lieber/ajaffe/Emily/RNAse""..., ""-p"", ""1"", ""-l"", ""ISR"", ""-1"", ""/dcl01/lieber/ajaffe/lab/libd_al""..., ""-2"", ""/dcl01/lieber/ajaffe/lab/libd_al""..., ""-o"", ""/dcl01/lieber/ajaffe/lab/libd_al""...], [/* 107 vars */]) = 0; brk(0) = 0xc2c000; mmap(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7fffbfffd000; readlink(""/proc/self/exe"", ""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linu",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:3438,pipeline,pipeline,3438,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,1,['pipeline'],['pipeline']
Deployability,"eII; #$ -o ./logs/salmon_test12.$TASK_ID.txt; #$ -e ./logs/salmon_test12.$TASK_ID.txt; #$ -t 1-3; #$ -hold_jid pipeline_setup,step4-featCounts-alzheimer.gsk_phaseII; #$ -m e; echo ""**** Job starts ****""; date. echo ""**** JHPCE info ****""; echo ""User: ${USER}""; echo ""Job id: ${JOB_ID}""; echo ""Job name: ${JOB_NAME}""; echo ""Hostname: ${HOSTNAME}""; echo ""Task id: ${TASK_ID}"". FILE1=$(awk 'BEGIN {FS=""\t""} {print $1}' /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk ""NR==${SGE_TASK_ID}""); if [ TRUE == ""TRUE"" ] ; then; FILE2=$(awk 'BEGIN {FS=""\t""} {print $3}' /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk ""NR==${SGE_TASK_ID}""); fi; ID=$(cat /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk '{print $NF}' | awk ""NR==${SGE_TASK_ID}""). mkdir -p /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/${ID}. strace /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon quant 	-i /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts -p 1 -l ISR 	-1 ${FILE1} -2 ${FILE2} 	-o /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/${ID} 2> logs/strace_test12_${SGE_TASK_ID}.txt. echo ""**** Job ends ****""; date; ```. Again, here is the `strace` output for task 1 (411 lines):. ```; execve(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon"", [""/dcl01/lieber/ajaffe/Emily/RNAse""..., ""quant"", ""-i"", ""/dcl01/lieber/ajaffe/Emily/RNAse""..., ""-p"", ""1"", ""-l"", ""ISR"", ""-1"", ""/dcl01/lieber/ajaffe/lab/libd_al""..., ""-2"", ""/dcl01/lieber/ajaffe/lab/libd_al""..., ""-o"", ""/dcl01/lieber/ajaffe/lab/libd_al""...], [/* 107 vars */]) = 0; brk(0) = 0xc2c000; mmap(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7fffbfffd000; readlink(""/proc/self/exe"", ""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon"", 4096) = 88; access(""/etc/ld.so.preload"", R_OK) = -1",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:78844,pipeline,pipeline,78844,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,1,['pipeline'],['pipeline']
Deployability,"eads unmapped: too many mismatches | 0.00%; % of reads unmapped: too short | 8.07%; % of reads unmapped: other | 0.12%; CHIMERIC READS:; Number of chimeric reads | 0; % of chimeric reads | 0.00%; ```. *yet, only `9,310,303` reads* were determined by STAR to project properly to annotated transcripts (slightly _less_ than are mapped to the transcriptome by salmon, at least without the decoy sequence included). So, there is a very high fraction of the reads that align to the genome, but a much smaller fraction ~45%-50% that align to the transcriptome. There are many reasons something like this could happen, but it suggests that there are a lot of reads being generated from outside of annotated transcripts. This could be a mix of novel transcripts in this sample (both at entirely novel loci, as well as novel transcripts within annotated loci), as well as of noisy transcription, unannotated transcribed pseudogenes etc. I took a look at the bigwig generated by this pipeline, and STAR seems to be mapping quite a lot of reads to chr21 as well as to the mitochondrial genome (chrM). However, as evidenced by the fact that neither salmon using selective-alignment (and mapping to the transcriptome) nor the STAR->salmon pipeline see these reads mapping to annotated transcripts they must be arising from outside of these regions. There are a few option in this case. You could manually investigate where these reads are coming from by aligning them with e.g. STAR and inspecting the BAM files. Alternatively, you could attempt to assemble novel transcripts (e.g. using StringTie or Scallop) and then add them to the transcriptome for quantification. However, it does seem that getting down to the bottom of the relatively low mapping rate to the annotated transcriptome, in light of the relatively high mapping rate to the whole genome, but outside of annotated transcripts, may require a bit more digging. I'm happy to answer any other specific questions that might arise if you dig into this.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/603#issuecomment-745768992:2374,pipeline,pipeline,2374,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/603#issuecomment-745768992,2,['pipeline'],['pipeline']
Deployability,"eber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../lib/tls/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../lib/tls"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../lib/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../lib/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../lib/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../lib"", {st_mode=S_IFDIR|0775, st_size=33280, ...}) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/tls/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/tls/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/tls/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/tls"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_lin",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:7217,pipeline,pipeline,7217,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,4,['pipeline'],['pipeline']
Deployability,"ection, tells the Salmon model not to consider the effective length of each transcript for computing the conditional probabilities of originating a fragment from a transcript. So, for the RNA-seq data there is no reason to turn off this term of the model, and we highly recommend not to use that flag for the bulk RNA-seq abundance estimation with Salmon. Looking more carefully at the 2nd case you have posted as the failure case, it is interesting to see that there is a very nice visual evidence on the super transcript that the long transcript might not be expressed at all. I am referring to the zero coverage regions on the Super Transcript between the regions corresponding to the smaller transcripts, e. g., between POF1 and EMC1. So, we tried a solution that inspects the coverage profile of all transcripts and calculates the probability of observing a zero coverage region on each transcript. If this probability is too low, this would be counted as an evidence for a transcript not being expressed at all. This approach seems to be working fine on this example that you have shared here. however, one problem was that there were considerable number of reads in the sample that were uniquely mapping only to the Super Transcript and turning of the expression of that transcript would result in treating those reads as un-mapped. Furthermore, this problem was more evident when we tried that approach on other larger samples, it seemed that could effect the expression of a lot transcripts very significantly. Specially, on the real samples where the coverage are often not uniform and detecting a zero coverage region on a transcript is more common due to un-annotated transcripts in the samples and etc. Currently, we are actively looking for more thorough solutions for this problem to deal with the coverage profile of transcripts. I'll try to update you more as we make more progress about this. Thank you again for the detailed explanation, hope to get back at you soon. Best,; Mohsen",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-666512703:2553,update,update,2553,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-666512703,1,['update'],['update']
Deployability,"ence to `libssh2_session_handshake'; /usr/bin/ld: (.text+0x58d): undefined reference to `libssh2_hostkey_hash'; /usr/bin/ld: (.text+0x6a0): undefined reference to `libssh2_hostkey_hash'; /usr/bin/ld: (.text+0x75d): undefined reference to `libssh2_knownhost_free'; ... So somehow this does not build - but I have the impression that the linker issues are caused by some missing CMAKE options (as well as using the build directory). Thus I used the cmake command line as its used in the Debian packaging:. $ docker pull debian:testing; $ docker run -it debian:testing; $ echo ""deb-src http://deb.debian.org/debian unstable main"" > /etc/apt/sources.list.d/10-debsrc.list; $ apt update; $ apt upgrade; $ apt build-dep salmon; $ wget https://github.com/COMBINE-lab/salmon/archive/refs/tags/v1.10.0.tar.gz; $ tar xaf v1.10.0.tar.gz; $ cd salmon-1.10.0; $ cmake -DCMAKE_BUILD_TYPE=Release -DUSE_SHARED_LIBS=TRUE -DBZIP2_LIBRARIES=-lbz2 -DBZIP2_INCLUDE_DIR=/usr/include -DLIBLZMA_INCLUDE_DIR=/usr/include/ -DLIBLZMA_LIBRARY=lzma -DCMAKE_MODULE_PATH=/usr/share/cmake/Modules -DTBB_WILL_RECONFIGURE=FALSE -DBOOST_WILL_RECONFIGURE=FALSE; $ make; $ tar xaf sample_data.tgz; # src/salmon index -t sample_data/transcripts.fasta -i sample_salmon_quasi_index; Version Info: This is the most recent version of salmon.; index [""sample_salmon_quasi_index""] did not previously exist . . . creating it; [2023-03-10 11:56:01.434] [jLog] [warning] The salmon index is being built without any decoy sequences. It is recommended that decoy sequence (either computed auxiliary decoy sequence or the genome of the organism) be rovided during indexing. Further details can be found at https://salmon.readthedocs.io/en/latest/salmon.html#preparing-transcriptome-indices-mapping-based-mode.; [2023-03-10 11:56:01.435] [jLog] [info] building index; out : sample_salmon_quasi_index; [2023-03-10 11:56:01.435] [puff::index::jointLog] [info] Running fixFasta. [Step 1 of 4] : counting k-mers. [2023-03-10 11:56:01.441] [puff::index::jo",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463708855:3474,Release,Release,3474,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463708855,1,['Release'],['Release']
Deployability,"er, you are right that there is no notion of using the coverage profile in estimation (more on this below)!. > Also, my intuition for these transcripts is not really a coverage ""bias"" . My intuition agrees with yours here completely. First, this isn't really a coverage bias as we use the normal definition of the term. Second, the positional bias modeling in salmon is not on a per-transcript level (since that would be an astronomical number of different parameters to learn, and any procedure would almost certainly overfit). Instead, it groups transcripts into length bins, and learns a distinct coverage bias model per-bin. > It would be neat if Salmon could detect these kinds of dramatic dropoffs and add a warning or something... even if not incorporating the information into the quants... it could even be a good QC step to identify large deletions/insertions over a gene body. As far as I know, there are NO rnaseq quant programs that would handle this, because even something like a STAR -> RSEM pipeline just projects read counts to the transcriptome and doesn't incorporate the coverage information. These are **great** points! A couple of thoughts. First, you are right that salmon, RSEM, etc. don't use coverage information in the way you describe here. One piece of software you might look into is [Salmon Anomaly Detection](https://github.com/Kingsford-Group/sad) (paper [here](https://www.cell.com/cell-systems/pdf/S2405-4712(19)30381-3.pdf)). This is sort of akin to what you are suggesting, and post-processes salmon output by looking for anomalous coverage profiles. It can both flag ""suspicious"" transcripts, and can also sometimes move reads around to mitigate anomalous coverage. Another tool / metric you might consider is the junction coverage compatibility (paper [here](https://www.life-science-alliance.org/content/2/1/e201800175)). While both of these approaches get at some of the core intuitions you raise in your response, they are both rather ""heavyweight"", and nei",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-623047035:2001,pipeline,pipeline,2001,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-623047035,1,['pipeline'],['pipeline']
Deployability,"es. Those jobs are still running (it's only been about 4hrs as of this writing, I'll update my post if/when they complete). Current logs are showing that they quickly consume all the available memory, but have not yet crashed. I've also got versions with 128-512GB of memory requested (by powers of 2) for comparison. Some random notes: both the 31-mer index experienced about twice as many soft page reclaims with the new/faster version and experienced a few hard page faults (the previous version saw none of the latter). The 17-mer version experienced fewer page reclaims than any of the 31-mer indices and far fewer than with the prior version. Again, a few page faults crept in, but relatively few by percentage and likely not contributing any significant amount of time overall. [index-qacct-17mer.log](https://github.com/COMBINE-lab/salmon/files/4246516/index-qacct-17mer.log); [index-qacct-31mer.log](https://github.com/COMBINE-lab/salmon/files/4246517/index-qacct-31mer.log). **UPDATE**; The 16GB version finished running. It actually only took a little over 4 hours to run, as well. The troubling thing about this job seems to be that, despite having successfully completed, according to the accounting log it used over 20GB of memory... which should be impossible to do. Our resident experts suspect there's a race condition occurring at the tail end of the job and that all of that extra memory is being allocated before the scheduler can kill it for exceeding the limit. Whatever the case, though, this throws into question some of those numbers that I've been grabbing from the accounting logs --- it's either being misreported, or the memory gobbling is happening so rapidly that it may not, in fact, be being properly recorded. I tested the index anyway. It *appears* to be working just fine. Nothing faulted or crashed when I attempted to quantify some reads against it. [index-qacct-17mer-16gigs.log](https://github.com/COMBINE-lab/salmon/files/4247214/index-qacct-17mer-16gigs.log)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/476#issuecomment-590516702:1796,UPDATE,UPDATE,1796,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/476#issuecomment-590516702,1,['UPDATE'],['UPDATE']
Deployability,"est/salmon_0.8.2_index_gencode.v25.transcripts/versionInfo.json"", O_RDONLY) = 4; read(4, ""{\n \""indexVersion\"": 2,\n \""ha""..., 8191) = 96; read(4, """", 8191) = 0; close(4) = 0; clock_gettime(CLOCK_REALTIME, {1491424830, 69887706}) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts/header.json"", O_RDONLY) = 4; read(4, ""{\n \""value0\"": {\n \""Index""..., 8191) = 357; read(4, """", 8191) = 0; close(4) = 0; clock_gettime(CLOCK_REALTIME, {1491424830, 139950818}) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts/header.json"", O_RDONLY) = 4; read(4, ""{\n \""value0\"": {\n \""Index""..., 8191) = 357; read(4, """", 8191) = 0; close(4) = 0; mmap(NULL, 1073745920, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_STACK, -1, 0) = 0x7ffe7e5e8000; mprotect(0x7ffe7e5e8000, 4096, PROT_NONE) = 0; clone(child_stack=0x7ffebe5e7ed0, flags=CLONE_VM|CLONE_FS|CLONE_FILES|CLONE_SIGHAND|CLONE_THREAD|CLONE_SYSVSEM|CLONE_SETTLS|CLONE_PARENT_SETTID|CLONE_CHILD_CLEARTID, parent_tidptr=0x7ffebe5e89d0, tls=0x7ffebe5e8700, child_tidptr=0x7ffebe5e89d0) = 14677; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts/sa.bin"", O_RDONLY) = 4; clock_gettime(CLOCK_REALTIME, {1491424830, 149197282}) = 0; read(4, ""l\n\221\21\0\0\0\0k\n\221\21\373\25\343\20\17\254\r\1\36\27\227\n\37\371\270\4\250\210\307\f""..., 8191) = 8191; mmap(NULL, 1342177280, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_NORESERVE, -1, 0) = 0x7ffe2e5e8000; munmap(0x7ffe2e5e8000, 1342177280) = 0; mmap(NULL, 1344270336, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_NORESERVE, -1, 0) = 0x7ffe2e3e9000; munmap(0x7ffe2e3e9000, 94208) = 0; munmap(0x7ffe7e400000, 1998848) = 0; [1m[2017-04-05 16:40:30.149] [stderrLog] [info] Loading Suffix Array ; [00m[1m[2017-04-05 16:40:30.069] [jointLog] [info] Loading Quasi index; [00m[1",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:166583,pipeline,pipeline,166583,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,1,['pipeline'],['pipeline']
Deployability,"esting. $ docker run -it debian:testing. $ apt-get update. $ apt-get install build-essential git libboost-all-dev liblzma-dev libbz2-dev cmake zlib1g-dev curl unzip wget libcurl4-openssl-dev. $ git clone https://github.com/COMBINE-lab/salmon.git; $ cd salmon; $ mkdir build && cd build; $ cmake -DNO_IPO=TRUE .. # GCC still doesn't handle LTO robustly; $ make -j8; $ make install; $ make test; ```. which leads to the output. ```; root@fd877e359439:/salmon/build# make install; [ 7%] Built target libcereal; [ 13%] Built target libtbb; [ 16%] Built target ntcard; [ 19%] Built target graphdump; [ 27%] Built target twopaco; [ 29%] Built target ksw2pp_sse2; [ 32%] Built target ksw2pp_sse4; [ 37%] Built target ksw2pp_basic; [ 38%] Built target ksw2pp; [ 59%] Built target puffer; [ 73%] Built target salmon_core; [ 76%] Built target alevin_core; [ 77%] Built target UnitTestsMain; [ 81%] Built target unitTests; [100%] Built target salmon; Install the project...; -- Install configuration: ""Release""; -- Installing: /salmon/lib/libntcard.a; -- Installing: /salmon/lib/ntcard/ntcard-targets.cmake; -- Installing: /salmon/lib/ntcard/ntcard-targets-release.cmake; -- Installing: /salmon/lib/libgraphdump.a; -- Installing: /salmon/lib/graphdump/graphdump-targets.cmake; -- Installing: /salmon/lib/graphdump/graphdump-targets-release.cmake; -- Installing: /salmon/lib/libtwopaco.a; -- Installing: /salmon/lib/twopaco/twopaco-targets.cmake; -- Installing: /salmon/lib/twopaco/twopaco-targets-release.cmake; -- Installing: /salmon/lib/libtbb.so; -- Installing: /salmon/lib/libtbb.so.12; -- Installing: /salmon/lib/libtbb.so.12.5; -- Installing: /salmon/lib/libtbbmalloc.so; -- Installing: /salmon/lib/libtbbmalloc.so.2; -- Installing: /salmon/lib/libtbbmalloc.so.2.5; -- Installing: /salmon/lib/libtbbmalloc_proxy.so; -- Installing: /salmon/lib/libtbbmalloc_proxy.so.2; -- Installing: /salmon/lib/libtbbmalloc_proxy.so.2.5; -- Installing: /salmon/bin/salmon; -- Installing: /salmon/lib/libsalmon_core.a. Ins",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463312554:1306,Install,Install,1306,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463312554,4,"['Install', 'Release', 'configurat']","['Install', 'Installing', 'Release', 'configuration']"
Deployability,"et ksw2pp_sse2; [ 32%] Built target ksw2pp_sse4; [ 37%] Built target ksw2pp_basic; [ 38%] Built target ksw2pp; [ 59%] Built target puffer; [ 73%] Built target salmon_core; [ 76%] Built target alevin_core; [ 77%] Built target UnitTestsMain; [ 81%] Built target unitTests; [100%] Built target salmon; Install the project...; -- Install configuration: ""Release""; -- Installing: /salmon/lib/libntcard.a; -- Installing: /salmon/lib/ntcard/ntcard-targets.cmake; -- Installing: /salmon/lib/ntcard/ntcard-targets-release.cmake; -- Installing: /salmon/lib/libgraphdump.a; -- Installing: /salmon/lib/graphdump/graphdump-targets.cmake; -- Installing: /salmon/lib/graphdump/graphdump-targets-release.cmake; -- Installing: /salmon/lib/libtwopaco.a; -- Installing: /salmon/lib/twopaco/twopaco-targets.cmake; -- Installing: /salmon/lib/twopaco/twopaco-targets-release.cmake; -- Installing: /salmon/lib/libtbb.so; -- Installing: /salmon/lib/libtbb.so.12; -- Installing: /salmon/lib/libtbb.so.12.5; -- Installing: /salmon/lib/libtbbmalloc.so; -- Installing: /salmon/lib/libtbbmalloc.so.2; -- Installing: /salmon/lib/libtbbmalloc.so.2.5; -- Installing: /salmon/lib/libtbbmalloc_proxy.so; -- Installing: /salmon/lib/libtbbmalloc_proxy.so.2; -- Installing: /salmon/lib/libtbbmalloc_proxy.so.2.5; -- Installing: /salmon/bin/salmon; -- Installing: /salmon/lib/libsalmon_core.a. Installation complete. Please ensure the following paths are set properly.; ==========================================================================; Please add /salmon/bin to your PATH; Please add /salmon/lib to your LD_LIBRARY_PATH; ==========================================================================; root@fd877e359439:/salmon/build# make test; Running tests...; Test project /salmon/build; Start 1: unit_tests; 1/2 Test #1: unit_tests ....................... Passed 0.37 sec; Start 2: salmon_read_test_quasi; 2/2 Test #2: salmon_read_test_quasi ........... Passed 1.80 sec. 100% tests passed, 0 tests failed out of 2. Total Test tim",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463312554:1965,Install,Installing,1965,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463312554,1,['Install'],['Installing']
Deployability,"experts tell me that you just need to be darned sure that conda-forge is a high priority channel, above bioconda, as [per instructions](https://bioconda.github.io/user/install.html#set-up-channels); that specifying multiple channels with `-c` explicitly is poor practice because it's so error prone; and that if I'm teaching people that, I'm a bad teacher. :). I'll look at the salmon documentation to make sure it's accurately represented there and then close this issue.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/480#issuecomment-579842099:168,install,install,168,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/480#issuecomment-579842099,1,['install'],['install']
Deployability,"f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/tls/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/tls"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin"", {st_mode=S_IFDIR|0755, st_size=33280, ...}) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/tls/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/tls/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/tls/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/tls"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../..",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:8469,pipeline,pipeline,8469,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,4,['pipeline'],['pipeline']
Deployability,"fe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin"", {st_mode=S_IFDIR|0755, st_size=33280, ...}) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/tls/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/tls/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/tls/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/tls"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/jhpce/shared/community/core/pcre/8.36/lib/tls/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOEN",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:9037,pipeline,pipeline,9037,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,4,['pipeline'],['pipeline']
Deployability,"fffbfb5e000; close(3) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/librt.so.1"", O_RDONLY) = 3; read(3, ""\177ELF\2\1\1\0\0\0\0\0\0\0\0\0\3\0>\0\1\0\0\0 \""\0\0\0\0\0\0""..., 832) = 832; fstat(3, {st_mode=S_IFREG|0644, st_size=50288, ...}) = 0; mmap(NULL, 2132936, PROT_READ|PROT_EXEC, MAP_PRIVATE|MAP_DENYWRITE, 3, 0) = 0x7fffbf748000; mprotect(0x7fffbf74f000, 2097152, PROT_NONE) = 0; mmap(0x7fffbf94f000, 8192, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_DENYWRITE, 3, 0x7000) = 0x7fffbf94f000; close(3) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/libm.so.6"", O_RDONLY) = 3; read(3, ""\177ELF\2\1\1\0\0\0\0\0\0\0\0\0\3\0>\0\1\0\0\0`>\0\0\0\0\0\0""..., 832) = 832; fstat(3, {st_mode=S_IFREG|0644, st_size=611736, ...}) = 0; mmap(NULL, 2629816, PROT_READ|PROT_EXEC, MAP_PRIVATE|MAP_DENYWRITE, 3, 0) = 0x7fffbf4c5000; mprotect(0x7fffbf547000, 2093056, PROT_NONE) = 0; mmap(0x7fffbf746000, 8192, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_DENYWRITE, 3, 0x81000) = 0x7fffbf746000; close(3) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/libgcc_s.so.1"", O_RDONLY) = 3; read(3, ""\177ELF\2\1\1\0\0\0\0\0\0\0\0\0\3\0>\0\1\0\0\0P\36\0\0\0\0\0\0""..., 832) = 832; mmap(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7fffbf4c4000; fstat(3, {st_mode=S_IFREG|0644, st_size=56072, ...}) = 0; mmap(NULL, 2151784, PROT_READ|PROT_EXEC, MAP_PRIVATE|MAP_DENYWRITE, 3, 0) = 0x7fffbf2b6000; mprotect(0x7fffbf2c3000, 2097152, PROT_NONE) = 0; mmap(0x7fffbf4c3000, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_DENYWRITE, 3, 0xd000) = 0x7fffbf4c3000; close(3) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/libc.so.6"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../lib/lib",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:19535,pipeline,pipeline,19535,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,4,['pipeline'],['pipeline']
Deployability,"fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../lib/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../lib"", {st_mode=S_IFDIR|0775, st_size=33280, ...}) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/tls/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/tls/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/tls/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/tls"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin"", {st_mode=S_IFDIR|0755, st_size=33280, ...}) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/tls/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/tls/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory);",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:7855,pipeline,pipeline,7855,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,4,['pipeline'],['pipeline']
Deployability,"files were extracted from the SRA experiment with [fastq-dump](https://trace.ncbi.nlm.nih.gov/Traces/sra/sra.cgi?view=toolkit_doc&f=fastq-dump).; - Reads were aligned with STAR to the index and `unsorted` alignments to the transcriptome were returned (this keeps the paired-ends next to each other). I noticed that the cDNA FASTA files from ensembl include the transcript version, e.g. `ENSMUST00000178537.1` in the FASTA header. The GTF file specifies the transcript id and its version in different fields. Therefore, the STAR index does not include the version suffix. Instead, only the transcript ids are listed, e.g. `ENSMUST00000178537`. To provide a FASTA file with transcript identifiers that match those in STAR's BAM file, I pre-processed Ensembl's FASTA file with the following command:. ```; wget ftp://ftp.ensembl.org/pub/release-86/fasta/mus_musculus/cdna/Mus_musculus.GRCm38.cdna.all.fa.gz; gunzip Mus_musculus.GRCm38.cdna.all.fa.gz; cut -f1 -d ""."" Mus_musculus.GRCm38.cdna.all.fa > transcripts_unversioned.fa. head transcripts_unversioned.fa; >ENSMUST00000178537; GGGACAGGGGGC; >ENSMUST00000178862; GGGACTGGGGGGGC; >ENSMUST00000196221; ATGGCATAT; >ENSMUST00000179664; ATGGCATATCA; >ENSMUST00000177564; ATCGGAGGGATACGAG; [truncated]; ```. Then I try to run `salmon`:. ```; wget ftp://ftp.ensembl.org/pub/release-86/gtf/mus_musculus/Mus_musculus.GRCm38.86.gtf.gz; gunzip Mus_musculus.GRCm38.86.gtf.gz; salmon quant -t transcripts_unversioned.fa -g Mus_musculus.GRCm38.86.gtf -l IU -p 1 -o quantitation -a subsample.bam --seqBias --gcBias; ```. but get the segmentation fault. Omitting the `--seqBias --gcBias` options makes it work. Perhaps you can already spot where I am doing something wrong? If not, you can find the subsample.bam file [here](https://drive.google.com/open?id=0BzX9viKJksNtak0xako0VXptLW8). (The other files are publically available, as shown above.). Does that help? Please let me know if there is anything I can do to help you understand this better.; Best,; Thomas",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/104#issuecomment-261744459:2374,release,release-,2374,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/104#issuecomment-261744459,1,['release'],['release-']
Deployability,"gen3/Eigen/Core:420:0,; from /usr/local/salmon-0.10.2/include/eigen3/Eigen/Dense:1,; from /usr/local/salmon-0.10.2/include/SalmonUtils.hpp:21,; from /usr/local/salmon-0.10.2/include/ReadPair.hpp:7,; from /usr/local/salmon-0.10.2/include/AlignmentGroup.hpp:15,; from /usr/local/salmon-0.10.2/include/AlignmentLibrary.hpp:12,; from /usr/local/salmon-0.10.2/src/SalmonQuantifyAlignments.cpp:39:; /usr/local/salmon-0.10.2/include/eigen3/Eigen/src/Core/AssignEvaluator.h:90:50: warning: enum constant in boolean context [-Wint-in-bool-context]; MaySliceVectorize = bool(MightVectorize) && bool(DstHasDirectAccess); ^~~~~~~~~~~~~~~~~~~~~~~~; At global scope:; cc1plus: warning: unrecognized command line option ‘-Wno-unused-local-typedef’; cc1plus: warning: unrecognized command line option ‘-Wno-unused-local-typedef’; make[2]: *** [src/CMakeFiles/salmon.dir/SalmonQuantifyAlignments.cpp.o] Error 1; make[1]: *** [src/CMakeFiles/salmon.dir/all] Error 2; make: *** [all] Error 2; ```. I also tried installing it through bioconda. Apparently, it installs it correctly, but when I try to use Trinity (I'm installing Salmon as a Trinity requirement) this is what happens: . ```; salmon: /opt/conda/conda-bld/salmon_1528409373758/work/salmon-0.10.2/include/eigen3/Eigen/src/Core/util/Memory.h:161: void* Eigen::internal::aligned_malloc(std::size_t): Assertion `(size<16 || (std::size_t(result)%16)==0) && ""System's malloc returned an unaligned pointer. Compile with EIGEN_MALLOC_ALREADY_ALIGNED=0 to fallback to handmade alignd memory allocator.""' failed.; Error, cmd:; salmon --no-version-check quant -i /home/federicoplazzi/test_Trinity_Assembly/trinity_out_dir/read_partitions/Fb_0/CBin_0/c30.trinity.reads.fa.out/Trinity.fasta.tmp.salmon.idx -l U -r /home/federicoplazzi/test_Trinity_Assembly/trinity_out_dir/read_partitions/Fb_0/CBin_0/c30.trinity.reads.fa.out/single.fa -o salmon_outdir -p 1 --minAssignedFrags 1; died with ret (6) at /usr/local/trinityrnaseq-Trinity-v2.6.6/util/support_scripts/../../Per",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/235#issuecomment-398081403:1151,install,installing,1151,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/235#issuecomment-398081403,1,['install'],['installing']
Deployability,"get(join_url(url, filename), headers=headers, proxies=session.proxies,; File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/requests/sessions.py"", line 542, in get; return self.request('GET', url, **kwargs); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/requests/sessions.py"", line 529, in request; resp = self.send(prep, **send_kwargs); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/requests/sessions.py"", line 645, in send; r = adapter.send(request, **kwargs); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/requests/adapters.py"", line 413, in send; conn = self.get_connection(request.url, proxies); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/requests/adapters.py"", line 308, in get_connection; raise InvalidProxyURL(""Please check proxy URL. It is malformed""; requests.exceptions.InvalidProxyURL: Please check proxy URL. It is malformed and could be missing the host. `$ /usr/local/bin/conda install salmon`. environment variables:; CIO_TEST=<not set>; CONDA_ROOT=/usr/local/Caskroom/miniforge/base; CURL_CA_BUNDLE=<not set>; INFOPATH=/opt/homebrew/share/info:; MANPATH=/opt/homebrew/share/man::; PATH=/opt/homebrew/bin:/opt/homebrew/sbin:/usr/local/bin:/usr/bin:/bin:/usr; /sbin:/sbin; REQUESTS_CA_BUNDLE=<not set>; SSL_CERT_FILE=<not set>; all_proxy=<set>. active environment : None; user config file : /Users/Benjamin/.condarc; populated config files : /usr/local/Caskroom/miniforge/base/.condarc; conda version : 4.12.0; conda-build version : not installed; python version : 3.9.13.final.0; virtual packages : __osx=12.4=0; __unix=0=0; __archspec=1=arm64; base environment : /usr/local/Caskroom/miniforge/base (writable); conda av data dir : /usr/local/Caskroom/miniforge/base/etc/conda; conda av metadata url : None; channel URLs : https://conda.anaconda.org/conda-forge/osx-arm64; https://conda.anaconda.org/conda-forge/noarch; package cache : /usr/local/Caskroom/miniforge/base/pkg",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/724#issuecomment-1171208515:4923,install,install,4923,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/724#issuecomment-1171208515,1,['install'],['install']
Deployability,"good suggestion. [https://sites.google.com/site/ummslogos/_/rsrc/1489610858836/home/apple-icon-76x76.png]. Javier E. Irazoqui, PhD; Associate Professor; Department of Microbiology and Physiological Systems; UMass Medical School. 368 Plantation Street; Albert Sherman Center; Room AS8.1053; Worcester, MA 01605. (774) 455-3797; Skype: javierirazoqui. Confidentiality Notice:; This e-mail message, including any attachments, is for the sole use of the intended recipient(s) and may contain confidential, proprietary and privileged information. Any unauthorized review, use, disclosure or distribution is prohibited. If you are not the intended recipient, please contact the sender immediately and destroy or permanently delete all copies of the original message. On Feb 12, 2018, at 12:21 PM, Marcel Bargull <notifications@github.com<mailto:notifications@github.com>> wrote:. Hi @jirazoqui<https://github.com/jirazoqui> and @pdellorusso<https://github.com/pdellorusso>,; beware that if you install via a .tar.gz file, you make conda ignore all dependencies. It's somewhat equivalent to conda install --no-deps ... and thus I wouldn't recommend doing something like that.; Until we fix the dependencies in Bioconda, can you, if possible, use a separate Conda environment for salmon with conda create -c bioconda -c conda-forge --name salmon salmon. In this new environment you wouldn't have any dependency version conflict. —; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://github.com/COMBINE-lab/salmon/issues/194#issuecomment-364996006>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AiohHe_b7YX4kqzddLHJT7ZK6s1PhJgoks5tUHM1gaJpZM4SAonB>.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/194#issuecomment-364996252:988,install,install,988,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/194#issuecomment-364996252,2,['install'],['install']
Deployability,"h':; (.text+0x3e1): undefined reference to `libssh2_session_abstract'; /usr/bin/ld: /usr/lib/x86_64-linux-gnu/libcurl.a(libcurl_gnutls_la-libssh2.o): in function `ssh_statemach_act':; (.text+0x4b1): undefined reference to `libssh2_session_set_blocking'; /usr/bin/ld: (.text+0x4fb): undefined reference to `libssh2_session_handshake'; /usr/bin/ld: (.text+0x58d): undefined reference to `libssh2_hostkey_hash'; /usr/bin/ld: (.text+0x6a0): undefined reference to `libssh2_hostkey_hash'; /usr/bin/ld: (.text+0x75d): undefined reference to `libssh2_knownhost_free'; ... So somehow this does not build - but I have the impression that the linker issues are caused by some missing CMAKE options (as well as using the build directory). Thus I used the cmake command line as its used in the Debian packaging:. $ docker pull debian:testing; $ docker run -it debian:testing; $ echo ""deb-src http://deb.debian.org/debian unstable main"" > /etc/apt/sources.list.d/10-debsrc.list; $ apt update; $ apt upgrade; $ apt build-dep salmon; $ wget https://github.com/COMBINE-lab/salmon/archive/refs/tags/v1.10.0.tar.gz; $ tar xaf v1.10.0.tar.gz; $ cd salmon-1.10.0; $ cmake -DCMAKE_BUILD_TYPE=Release -DUSE_SHARED_LIBS=TRUE -DBZIP2_LIBRARIES=-lbz2 -DBZIP2_INCLUDE_DIR=/usr/include -DLIBLZMA_INCLUDE_DIR=/usr/include/ -DLIBLZMA_LIBRARY=lzma -DCMAKE_MODULE_PATH=/usr/share/cmake/Modules -DTBB_WILL_RECONFIGURE=FALSE -DBOOST_WILL_RECONFIGURE=FALSE; $ make; $ tar xaf sample_data.tgz; # src/salmon index -t sample_data/transcripts.fasta -i sample_salmon_quasi_index; Version Info: This is the most recent version of salmon.; index [""sample_salmon_quasi_index""] did not previously exist . . . creating it; [2023-03-10 11:56:01.434] [jLog] [warning] The salmon index is being built without any decoy sequences. It is recommended that decoy sequence (either computed auxiliary decoy sequence or the genome of the organism) be rovided during indexing. Further details can be found at https://salmon.readthedocs.io/en/latest/salmon.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463708855:3275,update,update,3275,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463708855,2,"['update', 'upgrade']","['update', 'upgrade']"
Deployability,"hared/apps/sge/current/lib/linux-x64/libc.so.6"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/lib64/libc.so.6"", O_RDONLY) = 3; read(3, ""\177ELF\2\1\1\3\0\0\0\0\0\0\0\0\3\0>\0\1\0\0\0p\356\1\3427\0\0\0""..., 832) = 832; fstat(3, {st_mode=S_IFREG|0755, st_size=1926760, ...}) = 0; mmap(0x37e2000000, 3750152, PROT_READ|PROT_EXEC, MAP_PRIVATE|MAP_DENYWRITE, 3, 0) = 0x37e2000000; mprotect(0x37e218a000, 2097152, PROT_NONE) = 0; mmap(0x37e238a000, 20480, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_DENYWRITE, 3, 0x18a000) = 0x37e238a000; mmap(0x37e238f000, 18696, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_ANONYMOUS, -1, 0) = 0x37e238f000; close(3) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/libdl.so.2"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../lib/libdl.so.2"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/libdl.so.2"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/jhpce/shared/community/core/pcre/8.36/lib/libdl.so.2"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/jhpce/shared/community/core/jags/4.2.0/lib64/libdl.so.2"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/jhpce/shared/community/compiler/gcc/4.4.7/netcdf/4.3.2/lib/libdl.so.2"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/jhpce/shared/community/core/curl/7.43.0/lib/libdl.so.2"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/cm/shared/apps/sge/2011.11p1/lib/linux-x64/libdl.so.2"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/cm/shared/apps/sge/current/lib/linux-x64/libdl.so.2"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/lib64/libdl.so.2"", O_RDONLY) = 3; read(3, ""\177ELF\2\1\1\0\0\0\0\0\0\0\0\0\3\0>\0\1\0\0\0\340\r\300\3417\0\0\0""..., 832) = 832; fstat(3, {st_mode=S",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:97560,pipeline,pipeline,97560,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,1,['pipeline'],['pipeline']
Deployability,"hared/apps/sge/current/lib/linux-x64/libc.so.6"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/lib64/libc.so.6"", O_RDONLY) = 3; read(3, ""\177ELF\2\1\1\3\0\0\0\0\0\0\0\0\3\0>\0\1\0\0\0p\356\201\r5\0\0\0""..., 832) = 832; fstat(3, {st_mode=S_IFREG|0755, st_size=1926760, ...}) = 0; mmap(0x350d800000, 3750152, PROT_READ|PROT_EXEC, MAP_PRIVATE|MAP_DENYWRITE, 3, 0) = 0x350d800000; mprotect(0x350d98a000, 2097152, PROT_NONE) = 0; mmap(0x350db8a000, 20480, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_DENYWRITE, 3, 0x18a000) = 0x350db8a000; mmap(0x350db8f000, 18696, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_ANONYMOUS, -1, 0) = 0x350db8f000; close(3) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/libdl.so.2"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../lib/libdl.so.2"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/libdl.so.2"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/jhpce/shared/community/core/pcre/8.36/lib/libdl.so.2"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/jhpce/shared/community/core/jags/4.2.0/lib64/libdl.so.2"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/jhpce/shared/community/compiler/gcc/4.4.7/netcdf/4.3.2/lib/libdl.so.2"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/jhpce/shared/community/core/curl/7.43.0/lib/libdl.so.2"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/cm/shared/apps/sge/2011.11p1/lib/linux-x64/libdl.so.2"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/cm/shared/apps/sge/current/lib/linux-x64/libdl.so.2"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/lib64/libdl.so.2"", O_RDONLY) = 3; read(3, ""\177ELF\2\1\1\0\0\0\0\0\0\0\0\0\3\0>\0\1\0\0\0\340\r@\r5\0\0\0""..., 832) = 832; fstat(3, {st_mode=S_IFRE",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:22228,pipeline,pipeline,22228,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,1,['pipeline'],['pipeline']
Deployability,"heimers/hg38/samples.manifest | awk ""NR==${SGE_TASK_ID}""); if [ TRUE == ""TRUE"" ] ; then; FILE2=$(awk 'BEGIN {FS=""\t""} {print $3}' /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk ""NR==${SGE_TASK_ID}""); fi; ID=$(cat /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk '{print $NF}' | awk ""NR==${SGE_TASK_ID}""). mkdir -p /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/${ID}. strace /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon quant 	-i /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts -p 1 -l ISR 	-1 ${FILE1} -2 ${FILE2} 	-o /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/${ID} 2> logs/strace_${SGE_TASK_ID}.txt. echo ""**** Job ends ****""; date; ```. This requests SGE 2 cores with a total free memory of 2 * 7 = 14 GB and a maximum memory of 16 GB. This is the `strace` output for task 1:. ```; execve(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon"", [""/dcl01/lieber/ajaffe/Emily/RNAse""..., ""quant"", ""-i"", ""/dcl01/lieber/ajaffe/Emily/RNAse""..., ""-p"", ""1"", ""-l"", ""ISR"", ""-1"", ""/dcl01/lieber/ajaffe/lab/libd_al""..., ""-2"", ""/dcl01/lieber/ajaffe/lab/libd_al""..., ""-o"", ""/dcl01/lieber/ajaffe/lab/libd_al""...], [/* 107 vars */]) = 0; brk(0) = 0xc2c000; mmap(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7fffbfffd000; readlink(""/proc/self/exe"", ""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon"", 4096) = 88; access(""/etc/ld.so.preload"", R_OK) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/tls/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/tls/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory);",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:3886,pipeline,pipeline,3886,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,1,['pipeline'],['pipeline']
Deployability,"hey @kikegoni ,. I'd strongly advise updating to latest salmon. 0.12.0 is a bit old (released 16 cycles back) there were some bugs which we fixed over time. It'd be great if you can verify the issue persists with the latest release ?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/596#issuecomment-737335445:85,release,released,85,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/596#issuecomment-737335445,2,['release'],"['release', 'released']"
Deployability,"hey @pophipi , we have released `v0.11.1` with the fix.; Thanks for reporting this issue. Also, I tried running the `dropseq` mode for Alevin w/ the data you forwarded but it looks like the mapping rate is too low. I am not sure how to interpret the data, but just for sanity `Alevin` mapping rate is ~70% in the original Macosko et. al. paper. We will keep looking for the updates in DropSeq pipeline feel free to reopen this issue or create a new one regarding the low mapping rate if you find out the right location of UMI and CB in the dataset or trouble using #247 .",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/258#issuecomment-408565258:23,release,released,23,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/258#issuecomment-408565258,3,"['pipeline', 'release', 'update']","['pipeline', 'released', 'updates']"
Deployability,"hey try the following command, I double checked on 1.5.1 and it seemed to give the 18 length CBs:; ```; sudo ~/salmon-1.5.1_linux_x86_64/bin/salmon alevin -l ISR -i ~/Data/salmon/cell_hash -1 R1.fq.gz -2 R2.fq.gz --read-geometry 2[1-15] --bc-geometry 1[3-8,24-29,45-50] --umi-geometry 1[51-56] -o /home/cndd3/Data/Multi_3/hash_1.5.1/ —keepCBFraction 1 --tgMap <might have to create a tsv file with feature name tab feature name>; ```. If the program is not exiting with error with the command you shared then probably there is some error on the update as it should throw error when you simultaneously provide with `citeseq` and `geometry` flags.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/670#issuecomment-860927005:545,update,update,545,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/670#issuecomment-860927005,1,['update'],['update']
Deployability,"hi @k3yavi,. Thanks for your help! I'm glad it's a quick fix. As for the dataset, I am not sure why the read length is 25bp. The [paper I pulled it from](https://www.ncbi.nlm.nih.gov/pubmed/29545397) stated that they used the standard DropSeq protocol and did not seem to mention and changes in CB and UMI length. In the case that they did change those lengths, what options can I use to set the pipeline?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/258#issuecomment-408179330:396,pipeline,pipeline,396,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/258#issuecomment-408179330,1,['pipeline'],['pipeline']
Deployability,"hmmmm I re-pasted the updated error twice but it still reverts back to original post?. Malformed key:value pair at line 44017: ""**@PG** ID:OSA IsCdna:True ReferenceLibraryID:Human.B37.3_RefGene20121217 VN:7.2""",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/222#issuecomment-387498342:22,update,updated,22,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/222#issuecomment-387498342,1,['update'],['updated']
Deployability,"hodologies for quantification and also help optimize salmon further for QuantSeq. I would still like you to check if you have used salmon quant command line correctly for QuantSeq data analysis. Your paper briefly alludes to QuantSeq Forward in the Introduction section of the paper. The QuantSeq Forward kit has an oligo (dT) primer which contains the Illumina-specific Read 2 linker ... but the Methods section of your paper does not specify if you have used QuantSeq FWD or REV. Page 14 of the PDF from the Lexogen Website data analysis pipeline for QuantSeq FWD<https://www.bluebee.com/wp-content/uploads/2018/11/015UG108V0201-QuantSeq-Data-Analysis-Pipeline_2018-10-18.pdf> recommends using the below htseq command line. htseq-count -m intersection-nonempty -s yes -f bam -r pos $bam; $resource_dir/annotation.gtf > $bam_dir/read_counts.txt. QuantSeq is a stranded protocol. For the QuantSeq FWD pipeline the argument -s yes indicates; stranded in the sense orientation. For the QuantSeq REV pipeline -s reverse is used. Similar to the above htseq command line arguments, I think if you are using QuantSeq FWD, the libType argument from salmon quant should have been SF. One way I checked these with my datasets was to run the salmon quant command 3 times - once with libType A, once with libType SF and once with libType SR -- with QuantSeq FWD the estimated counts will be almost same with libType A and libType SF. I echo what @rob-p<https://github.com/rob-p> says - Congratulations once again on the paper. —; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://github.com/COMBINE-lab/salmon/issues/449?email_source=notifications&email_token=AC4A5AGWBAOLTI4MOFLAJNDQYQN7FA5CNFSM4JOIEHZ2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEG3S5HQ#issuecomment-565653150>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AC4A5AFB7EMLYHVLVSHVLBDQYQN7FANCNFSM4JOIEHZQ>. Sample S1. meta_info.json. ""salmon_version"":",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-565684552:2077,pipeline,pipeline,2077,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-565684552,1,['pipeline'],['pipeline']
Deployability,"i didn't try to fix the star index, it was created automatically by the; bcbio_nextgen pipeline i was using. i did add my story to the issue in the; star github repo mentioned in the biostars thread:; https://github.com/alexdobin/STAR/issues/1140. On Tue, Aug 2, 2022 at 11:27 AM HeedukOh ***@***.***> wrote:. > i ran into the same problem and apparently it's a STAR issue:; > https://www.biostars.org/p/486346/; >; > ""...it seems STAR is doing something during the indexing step which is; > causing a slight mismatch for 23 of the transcripts.""; >; > Hi,; > Thanks for the reply!; > I see that you used Salmon for indexing to get around this issue. Did you; > figure out a way to make STAR work after that, or did you stick with Salmon?; >; > —; > Reply to this email directly, view it on GitHub; > <https://github.com/COMBINE-lab/salmon/issues/785#issuecomment-1202823526>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/ABGJSQSM6CJ2GDKQF3UOZKLVXE47NANCNFSM5ZOT3OOQ>; > .; > You are receiving this because you commented.Message ID:; > ***@***.***>; >",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/785#issuecomment-1205698238:87,pipeline,pipeline,87,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/785#issuecomment-1205698238,1,['pipeline'],['pipeline']
Deployability,"ibthread_db enabled]; Using host libthread_db library ""/lib/x86_64-linux-gnu/libthread_db.so.1"".; warning: File ""/u/user/local/lib64/libstdc++.so.6.0.21-gdb.py"" auto-loading has been declined by your `auto-load safe-path' set to ""$debugdir:$datadir/auto-load"".; To enable execution of this file add; add-auto-load-safe-path /u/user/local/lib64/libstdc++.so.6.0.21-gdb.py; line to your configuration file ""/u/user/.gdbinit"".; To completely disable this security protection add; set auto-load safe-path /; line to your configuration file ""/u/user/.gdbinit"".; For more information about this security protection see the; ""Auto-loading safe path"" section in the GDB manual. E.g., run from the shell:; info ""(gdb)Auto-loading safe path""; [New Thread 0x7fff7e0f4700 (LWP 14274)]; Version Info: ### A newer version of Salmon is available. ####; [Thread 0x7fff7e0f4700 (LWP 14274) exited]; ###; The newest version, available at https://github.com/COMBINE-lab/salmon/releases; contains new features, improvements, and bug fixes; please upgrade at your; earliest convenience.; ###; [New Thread 0x7fff7d273700 (LWP 14275)]; Logs will be written to pbmc4k/alevin/logs; [New Thread 0x7ffefc3f1700 (LWP 14276)]; [New Thread 0x7ffe7b56f700 (LWP 14277)]; [New Thread 0x7ffdfa6ed700 (LWP 14278)]; ### salmon (single-cell-based) v0.10.1; ### [ program ] => salmon; ### [ command ] => alevin; ### [ libType ] => { ISR }; ### [ chromium ] => { }; ### [ threads ] => { 8 }; ### [ output ] => { pbmc4k/alevin }; ### [ mates1 ] => { /dev/fd/63 }; ### [ mates2 ] => { /dev/fd/62 }; ### [ index ] => { /u/user/ref/cellranger/salmon/transcripts_index }; ### [ tgMap ] => { tx2gene.txt }. [2018-06-08 13:37:41.409] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [New Thread 0x7ffd795e7700 (LWP 14279)]; [New Thread 0x7ffcf95e6700 (LWP 14280)]; [New Thread 0x7ffc795e5700 (LWP 14281)]; [2018-06-08 13:37:41.419] [alevinLog] [info] Processing barcodes files (if Present",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-395836214:2943,release,releases,2943,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-395836214,2,"['release', 'upgrade']","['releases', 'upgrade']"
Deployability,"ich leads to the output. ```; root@fd877e359439:/salmon/build# make install; [ 7%] Built target libcereal; [ 13%] Built target libtbb; [ 16%] Built target ntcard; [ 19%] Built target graphdump; [ 27%] Built target twopaco; [ 29%] Built target ksw2pp_sse2; [ 32%] Built target ksw2pp_sse4; [ 37%] Built target ksw2pp_basic; [ 38%] Built target ksw2pp; [ 59%] Built target puffer; [ 73%] Built target salmon_core; [ 76%] Built target alevin_core; [ 77%] Built target UnitTestsMain; [ 81%] Built target unitTests; [100%] Built target salmon; Install the project...; -- Install configuration: ""Release""; -- Installing: /salmon/lib/libntcard.a; -- Installing: /salmon/lib/ntcard/ntcard-targets.cmake; -- Installing: /salmon/lib/ntcard/ntcard-targets-release.cmake; -- Installing: /salmon/lib/libgraphdump.a; -- Installing: /salmon/lib/graphdump/graphdump-targets.cmake; -- Installing: /salmon/lib/graphdump/graphdump-targets-release.cmake; -- Installing: /salmon/lib/libtwopaco.a; -- Installing: /salmon/lib/twopaco/twopaco-targets.cmake; -- Installing: /salmon/lib/twopaco/twopaco-targets-release.cmake; -- Installing: /salmon/lib/libtbb.so; -- Installing: /salmon/lib/libtbb.so.12; -- Installing: /salmon/lib/libtbb.so.12.5; -- Installing: /salmon/lib/libtbbmalloc.so; -- Installing: /salmon/lib/libtbbmalloc.so.2; -- Installing: /salmon/lib/libtbbmalloc.so.2.5; -- Installing: /salmon/lib/libtbbmalloc_proxy.so; -- Installing: /salmon/lib/libtbbmalloc_proxy.so.2; -- Installing: /salmon/lib/libtbbmalloc_proxy.so.2.5; -- Installing: /salmon/bin/salmon; -- Installing: /salmon/lib/libsalmon_core.a. Installation complete. Please ensure the following paths are set properly.; ==========================================================================; Please add /salmon/bin to your PATH; Please add /salmon/lib to your LD_LIBRARY_PATH; ==========================================================================; root@fd877e359439:/salmon/build# make test; Running tests...; Test project /salmon/build; S",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463312554:1719,Install,Installing,1719,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463312554,1,['Install'],['Installing']
Deployability,"ieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../lib/tls/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../lib/tls/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../lib/tls/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../lib/tls"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../lib/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../lib/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../lib/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../lib"", {st_mode=S_IFDIR|0775, st_size=33280, ...}) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/tls/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/tls/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/tls/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/tls"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipe",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:6901,pipeline,pipeline,6901,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,4,['pipeline'],['pipeline']
Deployability,"ies are, where the include files are, and that boost was found was not sufficient. There must be some other set of symbols which need to be defined. `/opt/rh/devtoolset-4/root/usr/bin/c++ -pthread -ftree-vectorize -funroll-loops -fPIC -fomit-frame-pointer -O3 -DRAPMAP_SALMON_SUPPORT -DHAVE_ANSI_TERM -DHAVE_SSTREAM -Wall -Wno-unknown-pragmas -Wno-reorder -Wno-unused-variable -std=c++11 -Wreturn-type -Werror=return-type -Wno-unused-function -Wno-unused-local-typedef -static-libstdc++ -Wno-unused-local-typedefs -pthread -ftree-vectorize -funroll-loops -fPIC -fomit-frame-pointer -O3 -DRAPMAP_SALMON_SUPPORT -DHAVE_ANSI_TERM -DHAVE_SSTREAM -Wall -Wno-unknown-pragmas -Wno-reorder -Wno-unused-variable -std=c++11 -Wreturn-type -Werror=return-type -Wno-unused-function -Wno-unused-local-typedef -static-libstdc++ -Wno-unused-local-typedefs -rdynamic CMakeFiles/unitTests.dir/__/tests/UnitTests.cpp.o CMakeFiles/unitTests.dir/FragmentLengthDistribution.cpp.o CMakeFiles/unitTests.dir/__/external/install/src/rapmap/rank9b.cpp.o CMakeFiles/unitTests.dir/__/external/install/src/rapmap/bit_array.c.o -o unitTests -L/home/mathog/src/salmon/lib -L/home/mathog/src/salmon/external/install/lib -Wl,-rpath,""\$ORIGIN/../lib:\$ORIGIN/../../lib:\$ORIGIN/:\$ORIGIN/../../external/install/lib"" libsalmon_core.a libalevin_core.a -lgff -lpthread ../external/install/lib/libstaden-read.a -lz ../external/install/lib/libdivsufsort.a ../external/install/lib/libdivsufsort64.a ../external/install/lib/libbwa.a -lm -llzma -lbz2 -ltbb -lgomp -lrt ../external/install/lib/libjemalloc.a -lrt -ldl ../external/install/lib/libjemalloc.a -ldl`. Oh, I also had to update automake and autoconf because the 2 year old versions on this system were not new enough. Is there a static binary version of salmon available for download, Linux 64 bit? It looks like the default links are that way anyway, and that would save me what looks like at least another day of fighting with Cmake to force it to actually build a working make file",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/236#issuecomment-397025719:2790,install,install,2790,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/236#issuecomment-397025719,1,['install'],['install']
Deployability,"ild system will compile libgff; ==================================================================; ==================================================================; Build system will compile Staden IOLib; ==================================================================; Build system will fetch SPDLOG; ==================================================================; -- Found PkgConfig: /apps/gentoo/usr/bin/pkg-config (found version ""0.29.2""); -- Found Jemalloc: /apps/gentoo/usr/lib/libjemalloc.so (found version """"); Found Jemalloc library --- using this memory allocator; CPACK_SOURCE_IGNORE_FILES = /src/PCA.cpp;/src/PCAUtils.cpp;/build/;/scripts/AggregateToGeneLevel.py;/scripts/ExpressionTools.py;/scripts/GenerateExpressionFiles.sh;/scripts/ParseSoftFile.py;/scripts/PlotCorrelation.py;/scripts/junk;/scripts/sfstrace.log;/scripts/SFPipeline.py;/bin/;/lib/;/sample_data/;PublishREADMEToWebsite.sh;/external/;/src/obsolete/;/include/obsolete/;WebsiteHeader.txt;/experimental_configs/;.git/; TBB_LIBRARIES = /apps/gentoo/usr/lib/libtbbmalloc_proxy.so;/apps/gentoo/usr/lib/libtbbmalloc.so;/apps/gentoo/usr/lib/libtbb.so; -- Configuring done; CMake Error at src/CMakeLists.txt:158 (add_executable):; Cannot find source file:. $blah/salmon-0.10.2/external/install/src/rapmap/RapMapFileSystem.cpp. Tried extensions .c .C .c++ .cc .cpp .cxx .cu .m .M .mm .h .hh .h++ .hm; .hpp .hxx .in .txx. CMake Error at src/CMakeLists.txt:160 (add_executable):; Cannot find source file:. $blah/salmon-0.10.2/external/install/src/rapmap/rank9b.cpp. Tried extensions .c .C .c++ .cc .cpp .cxx .cu .m .M .mm .h .hh .h++ .hm; .hpp .hxx .in .txx. CMake Error at src/CMakeLists.txt:158 (add_executable):; No SOURCES given to target: salmon. CMake Error at src/CMakeLists.txt:160 (add_executable):; No SOURCES given to target: unitTests. -- Build files have been written to: $blah/salmon-0.10.2; $blah/salmon-0.10.2 $ make; make: *** No targets specified and no makefile found. Stop.; $blah/salmon-0.10.2 $; ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/19#issuecomment-399775387:5039,install,install,5039,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/19#issuecomment-399775387,2,['install'],['install']
Deployability,"ile or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin"", {st_mode=S_IFDIR|0755, st_size=33280, ...}) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/tls/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/tls/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/tls/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/tls"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:8727,install,install,8727,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,8,"['install', 'pipeline']","['install', 'pipeline']"
Deployability,"ile_url':; open_trace_file.c:(.text+0xec4): warning: the use of `tempnam' is dangerous, better use `mkstemp'; [100%] Built target salmon; root@e08cc9670e4a:/salmon-0.10.2/build# make install; [ 6%] Built target libdivsufsort; [ 12%] Built target libbz2; [ 17%] Built target liblzma; [ 24%] Built target libcereal; [ 31%] Built target libgff; [ 36%] Built target libbwa; [ 42%] Built target libstadenio; [ 48%] Built target libspdlog; [ 50%] Built target ksw2pp_sse4; [ 52%] Built target alevin_core; [ 55%] Built target ksw2pp_sse2; [ 60%] Built target ksw2pp_basic; [ 60%] Built target ksw2pp; [ 73%] Built target salmon_core; [ 77%] Built target unitTests; [100%] Built target salmon; Install the project...; -- Install configuration: ""Release""; -- Installing: /salmon-0.10.2/lib; -- Installing: /salmon-0.10.2/lib/libtbb.so; -- Installing: /salmon-0.10.2/lib/libtbbmalloc.so; -- Installing: /salmon-0.10.2/lib/libtbbmalloc_proxy.so; -- Installing: /salmon-0.10.2/lib/libtbbmalloc.so.2; -- Installing: /salmon-0.10.2/lib/libtbb.so.2; -- Installing: /salmon-0.10.2/lib/pkgconfig; -- Installing: /salmon-0.10.2/lib/libtbbmalloc_proxy.so.2; -- Installing: /salmon-0.10.2/bin/salmon; -- Installing: /salmon-0.10.2/lib/libsalmon_core.a. Installation complete. Please ensure the following paths are set properly.; ==========================================================================; Please add /salmon-0.10.2/bin to your PATH; Please add /salmon-0.10.2/lib to your LD_LIBRARY_PATH; ==========================================================================; root@e08cc9670e4a:/salmon-0.10.2/build# make test; Running tests...; Test project /salmon-0.10.2/build; Start 1: unit_tests; 1/3 Test #1: unit_tests ....................... Passed 0.17 sec; Start 2: salmon_read_test_fmd; 2/3 Test #2: salmon_read_test_fmd ............. Passed 1.78 sec; Start 3: salmon_read_test_quasi; 3/3 Test #3: salmon_read_test_quasi ........... Passed 1.59 sec. 100% tests passed, 0 tests failed out of 3. Total Test ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/250#issuecomment-404306268:1249,Install,Installing,1249,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/250#issuecomment-404306268,1,['Install'],['Installing']
Deployability,"inting to prefixes in the suffix array (similar to the strategy used by STAR, but using much longer k-mers to improve lookup speed). We referred to this index as the quasi-index. As the software evolved and we continued to improve the mapping methodology, we eventually transitioned over to an index based on [our pufferfish data structure](https://github.com/COMBINE-lab/pufferfish). In addition to the new data structure, this coincided with our move over to selective-alignment as the mapping algorithm, and all of this happened at the 1.0.0 release (this is why, for example, indices built before 1.0.0 are not compatible with salmon > 1.0.0; a topic on which there have been a few GitHub issues). However, given the fact that the documentation and software are linked only through manual human intervention (we haven't leveled up to e.g. having salmon be a [literate program](https://en.wikipedia.org/wiki/Literate_programming) yet), these two sometimes get out of sync. This is an instance of that. We have maintained the functionality of the `--writeMappings` feature, and in fact, even augmented it. However, we have not replaced the antiquated `quasi-index` terminology in the documentation. The TLDR is that you can use `--writeMappings` with the index you built with the `salmon index` command, and it should work fine. If you are mapping against an index without decoy sequences, then the output format will be basically the same as older (pre 1.0.0) versions. If you have decoy sequences in your index, then there is an optional SAM flag with each record that tells you if the mapping is to a target or a decoy. Specifically, `XT:A:T` signifies that the mapping was to a non-decoy target and `XT:A:T` specifies that the mapping was to a sequence marked in the index as a decoy. I hope this diversion into historical leakage into the current documentation answers your question. Thanks for reporting this, and we'll try to address it upstream so it's fixed in the next release. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/727#issuecomment-996192524:2549,release,release,2549,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/727#issuecomment-996192524,1,['release'],['release']
Deployability,"ipeline/Software/Salmon-0.8.2_linux_x86_64/bin/tls/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/tls"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin"", {st_mode=S_IFDIR|0755, st_size=33280, ...}) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/tls/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/tls/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/tls/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/tls"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:8532,install,install,8532,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,4,['install'],['install']
Deployability,"ir/CollapsedEMOptimizer.cpp.o CMakeFiles/salmon.dir/CollapsedCellOptimizer.cpp.o CMakeFiles/salmon.dir/CollapsedGibbsSampler.cpp.o CMakeFiles/salmon.dir/Salmon.cpp.o CMakeFiles/salmon.dir/BuildSalmonIndex.cpp.o CMakeFiles/salmon.dir/Graph.cpp.o CMakeFiles/salmon.dir/DedupUMI.cpp.o CMakeFiles/salmon.dir/Alevin.cpp.o CMakeFiles/salmon.dir/AlevinHash.cpp.o CMakeFiles/salmon.dir/SalmonAlevin.cpp.o CMakeFiles/salmon.dir/WhiteList.cpp.o CMakeFiles/salmon.dir/SalmonQuantify.cpp.o CMakeFiles/salmon.dir/FragmentLengthDistribution.cpp.o CMakeFiles/salmon.dir/FragmentStartPositionDistribution.cpp.o CMakeFiles/salmon.dir/GZipWriter.cpp.o CMakeFiles/salmon.dir/SalmonQuantMerge.cpp.o CMakeFiles/salmon.dir/ProgramOptionsGenerator.cpp.o CMakeFiles/salmon.dir/FASTAParser.cpp.o CMakeFiles/salmon.dir/AlignmentModel.cpp.o CMakeFiles/salmon.dir/SalmonQuantifyAlignments.cpp.o CMakeFiles/salmon.dir/BAMUtils.cpp.o -o salmon -L/usr/common/src/salmon-1.2.1/lib -L/usr/common/src/salmon-1.2.1/external/install/lib -Wl,-rpath,""\$ORIGIN/../lib:\$ORIGIN/../../lib:\$ORIGIN/:\$ORIGIN/../../external/install/lib"" ../external/pufferfish/src/libpuffer.a libsalmon_core.a ../external/pufferfish/external/twopaco/graphconstructor/libtwopaco.a ../external/pufferfish/external/twopaco/graphdump/libgraphdump.a ../external/pufferfish/external/ntcard/libntcard.a -lgff /usr/common/modules/el8/x86_64/software/io_lib/1.14.9-CentOS-vanilla/lib/libstaden-read.a /usr/lib64/libcurl.so /usr/lib64/libz.so -lm /usr/lib64/liblzma.so /usr/lib64/libbz2.so /usr/common/modules/el8/x86_64/software/libtbb/2020.5-CentOS-vanilla/lib/libtbbmalloc_proxy.so /usr/common/modules/el8/x86_64/software/libtbb/2020.5-CentOS-vanilla/lib/libtbbmalloc.so /usr/common/modules/el8/x86_64/software/libtbb/2020.5-CentOS-vanilla/lib/libtbb.so -lgomp /usr/lib64/libjemalloc.so -lrt ../external/pufferfish/src/libksw2pp.a libalevin_core.a -ldl -pthread ; /tmp/cc91ASWS.ltrans1.ltrans.o: In function `boost::iostreams::basic_gzip_compressor<std::allocator<cha",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641531162:1852,install,install,1852,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641531162,1,['install'],['install']
Deployability,"irectory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../lib/tls"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../lib/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../lib/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../lib/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../lib"", {st_mode=S_IFDIR|0775, st_size=33280, ...}) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/tls/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/tls/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/tls/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/tls"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Sal",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:7385,pipeline,pipeline,7385,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,4,['pipeline'],['pipeline']
Deployability,"it's not clear if the right fix is to pin the boost version [here](https://github.com/bioconda/bioconda-recipes/blob/master/recipes/salmon/meta.yaml), or just to go with the ""always use conda-forge on installs"" strategy in the documentation. I will consult with experts.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/480#issuecomment-579829090:201,install,installs,201,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/480#issuecomment-579829090,1,['install'],['installs']
Deployability,"k!. On Sun, Nov 01, 2015 at 08:48:45AM -0800, Rob Patro wrote:. > So, I've already updated the docs _here_ (i.e. the doc tag in the ReadMe should should point to the link I give above). I believe the right thing to do over in the Sailfish docs is to just remove any documentation about Salmon (since the projects are now maintained in separate repos each with their own docs).; > ; > ---; > ; > Reply to this email directly or view it on GitHub:; > ; > ## https://github.com/COMBINE-lab/salmon/issues/27#issuecomment-152843180; > ; > C. Titus Brown, ctbrown@ucdavis.edu",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/27#issuecomment-152843296:83,update,updated,83,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/27#issuecomment-152843296,1,['update'],['updated']
Deployability,"keFiles/salmon.dir/CollapsedGibbsSampler.cpp.o CMakeFiles/salmon.dir/Salmon.cpp.o CMakeFiles/salmon.dir/BuildSalmonIndex.cpp.o CMakeFiles/salmon.dir/Graph.cpp.o CMakeFiles/salmon.dir/DedupUMI.cpp.o CMakeFiles/salmon.dir/Alevin.cpp.o CMakeFiles/salmon.dir/AlevinHash.cpp.o CMakeFiles/salmon.dir/SalmonAlevin.cpp.o CMakeFiles/salmon.dir/WhiteList.cpp.o CMakeFiles/salmon.dir/SalmonQuantify.cpp.o CMakeFiles/salmon.dir/FragmentLengthDistribution.cpp.o CMakeFiles/salmon.dir/FragmentStartPositionDistribution.cpp.o CMakeFiles/salmon.dir/GZipWriter.cpp.o CMakeFiles/salmon.dir/SalmonQuantMerge.cpp.o CMakeFiles/salmon.dir/ProgramOptionsGenerator.cpp.o CMakeFiles/salmon.dir/FASTAParser.cpp.o CMakeFiles/salmon.dir/AlignmentModel.cpp.o CMakeFiles/salmon.dir/SalmonQuantifyAlignments.cpp.o CMakeFiles/salmon.dir/BAMUtils.cpp.o -o salmon -L/usr/common/src/salmon-1.2.1/lib -L/usr/common/src/salmon-1.2.1/external/install/lib -Wl,-rpath,""\$ORIGIN/../lib:\$ORIGIN/../../lib:\$ORIGIN/:\$ORIGIN/../../external/install/lib"" ../external/pufferfish/src/libpuffer.a libsalmon_core.a ../external/pufferfish/external/twopaco/graphconstructor/libtwopaco.a ../external/pufferfish/external/twopaco/graphdump/libgraphdump.a ../external/pufferfish/external/ntcard/libntcard.a -lgff /usr/common/modules/el8/x86_64/software/io_lib/1.14.9-CentOS-vanilla/lib/libstaden-read.a /usr/lib64/libcurl.so /usr/lib64/libz.so -lm /usr/lib64/liblzma.so /usr/lib64/libbz2.so /usr/common/modules/el8/x86_64/software/libtbb/2020.5-CentOS-vanilla/lib/libtbbmalloc_proxy.so /usr/common/modules/el8/x86_64/software/libtbb/2020.5-CentOS-vanilla/lib/libtbbmalloc.so /usr/common/modules/el8/x86_64/software/libtbb/2020.5-CentOS-vanilla/lib/libtbb.so -lgomp /usr/lib64/libjemalloc.so -lrt ../external/pufferfish/src/libksw2pp.a libalevin_core.a -ldl -pthread ; /tmp/cc91ASWS.ltrans1.ltrans.o: In function `boost::iostreams::basic_gzip_compressor<std::allocator<char> >::basic_gzip_compressor(boost::iostreams::gzip_params const&, long) [clone .con",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641531162:1945,install,install,1945,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641531162,1,['install'],['install']
Deployability,"lt still segfaults. It still needed an edit of the CMakeLists.txt file. Still, for future reference:. ```; pversion=1.2.1; package=salmon; TOPDIR=/usr/common/modules/el8/x86_64/software/${package}/${pversion}-CentOS-vanilla; wget https://github.com/COMBINE-lab/salmon/archive/v1.2.1.tar.gz; gunzip -c v1.2.1.tar.gz | tar -xf -; /bin/rm v1.2.1.tar.gz; cd ${package}-${pversion}; mv CMakeLists.txt CMakeLists.txt.dist; cat >mypatch <<'EOD'; --- CMakeLists.txt.dist	2020-04-21 22:31:07.000000000 -0700; +++ CMakeLists.txt	2020-06-09 14:55:02.733885772 -0700; @@ -419,6 +419,10 @@; find_package(Boost 1.59.0 COMPONENTS iostreams filesystem system timer chrono program_options); message(""BOOST_INCLUDEDIR = ${BOOST_INCLUDEDIR}""); message(""BOOST_LIBRARYDIR = ${BOOST_LIBRARYDIR}""); +message(""Forcing Boost_FOUND to TRUE""); +set(Boost_FOUND TRUE); +set(Boost_LIBRARY_DIRS ""/usr/lib64/boost169""); +set(Boost_LIBRARIES -lboost_iostreams -lboost_filesystem -lboost_system -lboost_timer -lboost_chrono -lboost_program_options); message(""Boost_FOUND = ${Boost_FOUND}""); endif(); ; EOD; patch -p0 <mypatch; module load cmake; module load io_lib; module load libgff; module load libtbb; mkdir build; cd build; export CFLAGS=""-g -O0""; export CXXFLAGS=""-g -O0""; cmake \; -DCMAKE_INSTALL_PREFIX=$TOPDIR \; -DSTADEN_ROOT=$ROOT_IO_LIB \; -DGFF_ROOT=$ROOT_LIBGFF \; -DTBB_ROOT=$ROOT_LIBTBB \; -DCMAKE_VERBOSE_MAKEFILE:BOOL=ON \; -DBOOST_LIBRARYDIR=/usr/lib64/boost169 \; -DBOOST_INCLUDEDIR=/usr/include/boost169 \; -DBoost_NO_SYSTEM_PATHS=ON \; .. 2>&1 | tee cmake_2020_06_09.log; make -j 4 2>&1 | tee build_2020_06_09.log. ```. Since it was compiled ""-g -O0"" this time it was easier to step through it. Well, somewhat. In Salmon.cpp line 195 is the last place a break point works. If one is set for 197 it segfaults before reaching it. Line 195 is:. `	 po::store(parsed, vm);; `; I tried briefly to trace inward from there but couldn't make heads or tails of the path it was taking through an endless series of headers.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641612831:1122,patch,patch,1122,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641612831,1,['patch'],['patch']
Deployability,"mage. For more detail, here are the steps performed (perhaps taking a look at the installed packages will highlight a difference, as I did this from a clean testing Docker image, so my environment had nothing else in it). ### Attempt to reproduce segfault on Debian:testing. ```{bash}; $ docker pull debian:testing. $ docker run -it debian:testing. $ apt-get update. $ apt-get install build-essential git libboost-all-dev liblzma-dev libbz2-dev cmake zlib1g-dev curl unzip wget libcurl4-openssl-dev. $ git clone https://github.com/COMBINE-lab/salmon.git; $ cd salmon; $ mkdir build && cd build; $ cmake -DNO_IPO=TRUE .. # GCC still doesn't handle LTO robustly; $ make -j8; $ make install; $ make test; ```. which leads to the output. ```; root@fd877e359439:/salmon/build# make install; [ 7%] Built target libcereal; [ 13%] Built target libtbb; [ 16%] Built target ntcard; [ 19%] Built target graphdump; [ 27%] Built target twopaco; [ 29%] Built target ksw2pp_sse2; [ 32%] Built target ksw2pp_sse4; [ 37%] Built target ksw2pp_basic; [ 38%] Built target ksw2pp; [ 59%] Built target puffer; [ 73%] Built target salmon_core; [ 76%] Built target alevin_core; [ 77%] Built target UnitTestsMain; [ 81%] Built target unitTests; [100%] Built target salmon; Install the project...; -- Install configuration: ""Release""; -- Installing: /salmon/lib/libntcard.a; -- Installing: /salmon/lib/ntcard/ntcard-targets.cmake; -- Installing: /salmon/lib/ntcard/ntcard-targets-release.cmake; -- Installing: /salmon/lib/libgraphdump.a; -- Installing: /salmon/lib/graphdump/graphdump-targets.cmake; -- Installing: /salmon/lib/graphdump/graphdump-targets-release.cmake; -- Installing: /salmon/lib/libtwopaco.a; -- Installing: /salmon/lib/twopaco/twopaco-targets.cmake; -- Installing: /salmon/lib/twopaco/twopaco-targets-release.cmake; -- Installing: /salmon/lib/libtbb.so; -- Installing: /salmon/lib/libtbb.so.12; -- Installing: /salmon/lib/libtbb.so.12.5; -- Installing: /salmon/lib/libtbbmalloc.so; -- Installing: /salmon/lib",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463312554:808,install,install,808,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463312554,2,"['Install', 'install']","['Install', 'install']"
Deployability,may be try creating a new environment and/or specify the version of salmon you wan't to install ? it can happen sometimes based on the dependency structure already installed in your environment. You can also the pre build binaries from https://github.com/COMBINE-lab/salmon/releases. It's more of an issue with conda than salmon itself. Closing this one but let us know if you still face any issue.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/461#issuecomment-565296541:88,install,install,88,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/461#issuecomment-565296541,3,"['install', 'release']","['install', 'installed', 'releases']"
Deployability,"ments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; [New Thread 0x7ffff0987700 (LWP 17537)]. Thread 2 ""salmon"" received signal SIGSEGV, Segmentation fault.; [Switching to Thread 0x7ffff0987700 (LWP 17537)]; 0x00007ffff68202ab in je_tcache_bin_flush_small () from /lib64/libjemalloc.so.2; Missing separate debuginfos, use: yum debuginfo-install boost169-filesystem-1.69.0-4.el8.x86_64 boost169-iostreams-1.69.0-4.el8.x86_64 boost169-program-options-1.69.0-4.el8.x86_64 boost169-system-1.69.0-4.el8.x86_64 brotli-1.0.6-1.el8.x86_64 bzip2-libs-1.0.6-26.el8.x86_64 cyrus-sasl-lib-2.1.27-1.el8.x86_64 jemalloc-5.2.1-2.el8.x86_64 keyutils-libs-1.5.10-6.el8.x86_64 krb5-libs-1.17-9.el8.x86_64 libcom_err-1.44.6-3.el8.x86_64 libcurl-7.61.1-11.el8.x86_64 libgcc-8.3.1-4.5.el8.x86_64 libgomp-8.3.1-4.5.el8.x86_64 libidn2-2.2.0-1.el8.x86_64 libnghttp2-1.33.0-1.el8_0.1.x86_64 libpsl-0.20.2-5.el8.x86_64 libselinux-2.9-2.1.el8.x86_64 libssh-0.9.0-4.el8.x86_64 libstdc++-8.3.1-4.5.el8.x86_64 libunistring-0.9.9-3.el8.x86_64 libxcrypt-4.1.1-4.el8.x86_64 openldap-2.4.46-11.el8_1.x86_64 pcre2-10.32-1.el8.x86_64 tbb-devel-2018.2-9.el8.x86_64 xz-libs-5.2.4-3.el8.x86_64 zlib-1.2.11-10.el8.x86_64; (gdb) bt; #0 0x00007ffff68202ab in je_tcache_bin_flush_small () from /lib64/libjemalloc.so.2; #1 0x00007ffff68221ee in tcache_flush_cache () from",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641594410:5137,install,install,5137,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641594410,1,['install'],['install']
Deployability,"mily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon"", 4096) = 88; access(""/etc/ld.so.preload"", R_OK) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/tls/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/tls/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/tls/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/tls"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib"", {st_mode=S_IFDIR|0755, st_size=33280, ...}) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../lib/tls/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../lib/tls/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../lib/tls/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/liebe",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:5414,pipeline,pipeline,5414,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,4,['pipeline'],['pipeline']
Deployability,"mmap(NULL, 1073745920, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_STACK, -1, 0) = -1 ENOMEM (Cannot allocate memory); futex(0x7fffbf4c3350, FUTEX_WAKE_PRIVATE, 2147483647) = 0; write(2, ""terminate called without an acti""..., 45terminate called without an active exception; ) = 45; rt_sigprocmask(SIG_UNBLOCK, [ABRT], NULL, 8) = 0; write(3, ""[2017-04-05 16:24:37.940] [joint""..., 136) = 136; tgkill(32681, 32681, SIGABRT) = 0; --- SIGABRT (Aborted) @ 0 (0) ---; +++ killed by SIGABRT (core dumped) +++; ```; and for task 2:. ```; execve(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon"", [""/dcl01/lieber/ajaffe/Emily/RNAse""..., ""quant"", ""-i"", ""/dcl01/lieber/ajaffe/Emily/RNAse""..., ""-p"", ""1"", ""-l"", ""ISR"", ""-1"", ""/dcl01/lieber/ajaffe/lab/libd_al""..., ""-2"", ""/dcl01/lieber/ajaffe/lab/libd_al""..., ""-o"", ""/dcl01/lieber/ajaffe/lab/libd_al""...], [/* 107 vars */]) = 0; brk(0) = 0xc2c000; mmap(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7fffbfffd000; readlink(""/proc/self/exe"", ""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon"", 4096) = 88; access(""/etc/ld.so.preload"", R_OK) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/tls/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/tls/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/tls/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/tls"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/x86_64/li",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:41262,pipeline,pipeline,41262,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,1,['pipeline'],['pipeline']
Deployability,"mmap(NULL, 1073745920, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_STACK, -1, 0) = -1 ENOMEM (Cannot allocate memory); futex(0x7fffbf4c3350, FUTEX_WAKE_PRIVATE, 2147483647) = 0; write(2, ""terminate called without an acti""..., 45terminate called without an active exception; ) = 45; rt_sigprocmask(SIG_UNBLOCK, [ABRT], NULL, 8) = 0; write(3, ""[2017-04-05 16:40:15.587] [joint""..., 136) = 136; tgkill(51996, 51996, SIGABRT) = 0; --- SIGABRT (Aborted) @ 0 (0) ---; +++ killed by SIGABRT (core dumped) +++; ```. and for task 2:. ```; execve(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon"", [""/dcl01/lieber/ajaffe/Emily/RNAse""..., ""quant"", ""-i"", ""/dcl01/lieber/ajaffe/Emily/RNAse""..., ""-p"", ""1"", ""-l"", ""ISR"", ""-1"", ""/dcl01/lieber/ajaffe/lab/libd_al""..., ""-2"", ""/dcl01/lieber/ajaffe/lab/libd_al""..., ""-o"", ""/dcl01/lieber/ajaffe/lab/libd_al""...], [/* 107 vars */]) = 0; brk(0) = 0xc2c000; mmap(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7fffbfffd000; readlink(""/proc/self/exe"", ""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon"", 4096) = 88; access(""/etc/ld.so.preload"", R_OK) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/tls/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/tls/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/tls/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/tls"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/x86_64/li",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:122225,pipeline,pipeline,122225,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,1,['pipeline'],['pipeline']
Deployability,"my bad about that, just upgraded the alias to change salmon's path (from 0.7.2 to 1.3.0), but changes have not been affected. I'm so sorry about that",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/563#issuecomment-680255521:24,upgrade,upgraded,24,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/563#issuecomment-680255521,1,['upgrade'],['upgraded']
Deployability,"ng 32-bit quasi index; [2019-01-29 09:56:54.551] [stderrLog] [info] Loading Transcript Info ; [2019-01-29 09:56:54.826] [stderrLog] [info] Loading Rank-Select Bit Array; [2019-01-29 09:56:54.883] [stderrLog] [info] There were 80,511 set bits in the bit array; [2019-01-29 09:56:54.908] [stderrLog] [info] Computing transcript lengths; [2019-01-29 09:56:54.908] [stderrLog] [info] Waiting to finish loading hash; [2019-01-29 09:57:09.336] [stderrLog] [info] Done loading index; [2019-01-29 09:57:09.336] [jointLog] [info] done; [2019-01-29 09:57:09.336] [jointLog] [info] Index contained 80,511 targets. processed 2 Million fragments; hits: 812181, hits per frag: 0.326777. [2019-01-29 09:57:36.647] [alevinLog] [info] Starting optimizer; [2019-01-29 09:57:36.587] [jointLog] [info] Computed 12,933 rich equivalence classes for further processing; [2019-01-29 09:57:36.587] [jointLog] [info] Counted 242,520 total reads in the equivalence classes ; [2019-01-29 09:57:36.601] [jointLog] [warning] Only 242520 fragments were mapped, but the number of burn-in fragments was set to 5000000.; The effective lengths have been computed using the observed mappings. [2019-01-29 09:57:36.601] [jointLog] [info] Mapping rate = 8.94141%. [2019-01-29 09:57:36.601] [jointLog] [info] finished quantifyLibrary(). Analyzed 293 cells (100% of all).; [2019-01-29 09:57:40.090] [alevinLog] [info] Total 206902 UMI after deduplicating.; [2019-01-29 09:57:40.091] [alevinLog] [warning] Skipped 71 barcodes due to No mapped read; [2019-01-29 09:57:40.110] [alevinLog] [info] Clearing EqMap; Might take some time.; [2019-01-29 09:57:40.176] [alevinLog] [info] Starting Import of the gene count matrix.; [2019-01-29 09:57:41.168] [alevinLog] [info] Done Importing gene count matrix for dimension 222x19879; [2019-01-29 09:57:41.168] [alevinLog] [info] Starting dumping cell v gene counts in csv format; Segmentation fault (core dumped); ```. I then installed through conda salmon=0.12.0. Both times it failed with core dump.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/337#issuecomment-458481722:10273,install,installed,10273,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/337#issuecomment-458481722,1,['install'],['installed']
Deployability,"ning: the use of `tempnam' is dangerous, better use `mkstemp'; [100%] Built target salmon; root@e08cc9670e4a:/salmon-0.10.2/build# make install; [ 6%] Built target libdivsufsort; [ 12%] Built target libbz2; [ 17%] Built target liblzma; [ 24%] Built target libcereal; [ 31%] Built target libgff; [ 36%] Built target libbwa; [ 42%] Built target libstadenio; [ 48%] Built target libspdlog; [ 50%] Built target ksw2pp_sse4; [ 52%] Built target alevin_core; [ 55%] Built target ksw2pp_sse2; [ 60%] Built target ksw2pp_basic; [ 60%] Built target ksw2pp; [ 73%] Built target salmon_core; [ 77%] Built target unitTests; [100%] Built target salmon; Install the project...; -- Install configuration: ""Release""; -- Installing: /salmon-0.10.2/lib; -- Installing: /salmon-0.10.2/lib/libtbb.so; -- Installing: /salmon-0.10.2/lib/libtbbmalloc.so; -- Installing: /salmon-0.10.2/lib/libtbbmalloc_proxy.so; -- Installing: /salmon-0.10.2/lib/libtbbmalloc.so.2; -- Installing: /salmon-0.10.2/lib/libtbb.so.2; -- Installing: /salmon-0.10.2/lib/pkgconfig; -- Installing: /salmon-0.10.2/lib/libtbbmalloc_proxy.so.2; -- Installing: /salmon-0.10.2/bin/salmon; -- Installing: /salmon-0.10.2/lib/libsalmon_core.a. Installation complete. Please ensure the following paths are set properly.; ==========================================================================; Please add /salmon-0.10.2/bin to your PATH; Please add /salmon-0.10.2/lib to your LD_LIBRARY_PATH; ==========================================================================; root@e08cc9670e4a:/salmon-0.10.2/build# make test; Running tests...; Test project /salmon-0.10.2/build; Start 1: unit_tests; 1/3 Test #1: unit_tests ....................... Passed 0.17 sec; Start 2: salmon_read_test_fmd; 2/3 Test #2: salmon_read_test_fmd ............. Passed 1.78 sec; Start 3: salmon_read_test_quasi; 3/3 Test #3: salmon_read_test_quasi ........... Passed 1.59 sec. 100% tests passed, 0 tests failed out of 3. Total Test time (real) = 3.54 sec; root@e08cc9670e4a:/salm",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/250#issuecomment-404306268:1296,Install,Installing,1296,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/250#issuecomment-404306268,1,['Install'],['Installing']
Deployability,"o such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../lib/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../lib/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../lib"", {st_mode=S_IFDIR|0775, st_size=33280, ...}) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/tls/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/tls/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/tls/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/tls"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin"", {st_mode=S_IFDIR|0755, st_size=33280, ...}) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/tls/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeli",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:7704,pipeline,pipeline,7704,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,4,['pipeline'],['pipeline']
Deployability,"observe the coverage bias in them. I'd suggest can you please try subsampling randomly across the full `Fastq` if you haven't tried that already.; * `re: subsampling coefficient:` If you are looking for per-CB level mapping rate for your sample that would be very easy to calculate, although getting one number for the full sample might be little tricky since the mapping rate might have large variance across the sample, but it would be an interesting plot to generate, do let us know how it looks in your case.; If you run Alevin with `--dumpFeatures` flag, alevin will generate a file `featureDump.txt`, whose first column will be the per CB level mapping rate i.e. `#mapped reads/#raw reads`. If you wan't absolute values for per-CB reads and mapped reads, it should be in the file `filtered_cb_frequency.txt` and `mappedUMI.txt` respectively.; * `re: cellranger subsampling:` Correct me if I am wrong, when you say cellranger subsampling, do you mean the `cellranger aggregate` pipeline? It's possible you are talking about some other step which I am not aware of but if it's `aggregate` then I think it happens downstream of all the quantification. Indeed coverage bias correction is an important part of the aggregation step but in general it's not the only one and that's why we recommend using the `Seurat` package downstream of the Alevin quantified matrices. We will be more than happy to write a tutorial on, ""how to perform batch correction downstream of Alevin"" but in summary the following steps would be the gist of the process.; - Use Alevin w/o any modification to the `fastq` on both of your sample to generate the gene count matrices. (We have made a major upgrade to the Alevin. We'd recommend using [v0.12.0-alpha](https://github.com/COMBINE-lab/salmon/tree/v0.12.0-alpha) for now, we are planning to make an official release before the end of this week, currently you can use pre-release. Unfortunately, not available on conda yet).; - Import Alevin count matrices into R using ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/305#issuecomment-433169468:1501,pipeline,pipeline,1501,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/305#issuecomment-433169468,1,['pipeline'],['pipeline']
Deployability,"oject...; -- Install configuration: ""Release""; -- Installing: /salmon/lib/libntcard.a; -- Installing: /salmon/lib/ntcard/ntcard-targets.cmake; -- Installing: /salmon/lib/ntcard/ntcard-targets-release.cmake; -- Installing: /salmon/lib/libgraphdump.a; -- Installing: /salmon/lib/graphdump/graphdump-targets.cmake; -- Installing: /salmon/lib/graphdump/graphdump-targets-release.cmake; -- Installing: /salmon/lib/libtwopaco.a; -- Installing: /salmon/lib/twopaco/twopaco-targets.cmake; -- Installing: /salmon/lib/twopaco/twopaco-targets-release.cmake; -- Installing: /salmon/lib/libtbb.so; -- Installing: /salmon/lib/libtbb.so.12; -- Installing: /salmon/lib/libtbb.so.12.5; -- Installing: /salmon/lib/libtbbmalloc.so; -- Installing: /salmon/lib/libtbbmalloc.so.2; -- Installing: /salmon/lib/libtbbmalloc.so.2.5; -- Installing: /salmon/lib/libtbbmalloc_proxy.so; -- Installing: /salmon/lib/libtbbmalloc_proxy.so.2; -- Installing: /salmon/lib/libtbbmalloc_proxy.so.2.5; -- Installing: /salmon/bin/salmon; -- Installing: /salmon/lib/libsalmon_core.a. Installation complete. Please ensure the following paths are set properly.; ==========================================================================; Please add /salmon/bin to your PATH; Please add /salmon/lib to your LD_LIBRARY_PATH; ==========================================================================; root@fd877e359439:/salmon/build# make test; Running tests...; Test project /salmon/build; Start 1: unit_tests; 1/2 Test #1: unit_tests ....................... Passed 0.37 sec; Start 2: salmon_read_test_quasi; 2/2 Test #2: salmon_read_test_quasi ........... Passed 1.80 sec. 100% tests passed, 0 tests failed out of 2. Total Test time (real) = 2.17 sec; ```. The `make test` command itself runs the test the builds the index and maps the reads against it. Either way, I can do that explicitly too (from within build):. ```; $ ./src/salmon index -t ../sample_data/transcripts.fasta -i sample_idx; ```. returns succesfully with a built index. ```;",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463312554:2259,Install,Installing,2259,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463312554,2,['Install'],['Installing']
Deployability,"okies, I think I see the issue. So look at the following lines in the log:; ```; [2019-06-17 21:21:44.518] [alevinLog] [info] Total 824863; [2019-06-17 21:22:47.680] [alevinLog] [info] Total Unique barcodes found: 3474567; ```; What it means is alevin found total: `3,474,567` unique CB in the whole sample and keeps `824,863` CB for further processing which is ~23% of the CB. So all the `keepCBFraction` values above 0.23 would have no effect. If you wan't to generate the `whitelist.txt`, alevin has to have some low confidence CB to learn from, so I am guessing in your case any value from 0.15-0.20 should ideally work. Having said that, I am still exploring why even setting `freqThreshold` to 0, alevin not considers all `3M` CB for processing, I guess there is some kind of filter which is coming into the picture but I might need a bit more time to explore that. I will update here once I figure it out. Thanks again for raising the issue and investing your time in improving alevin.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/379#issuecomment-503344686:879,update,update,879,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/379#issuecomment-503344686,1,['update'],['update']
Deployability,"on ""5.2.3""); Found liblzma library: /apps/gentoo/usr/lib/liblzma.a; ===========================================; -- Found BZip2: /apps/gentoo/usr/lib/libbz2.a (found version ""1.0.6""); -- Looking for BZ2_bzCompressInit; -- Looking for BZ2_bzCompressInit - found; Found libbz2 library: /apps/gentoo/usr/lib/libbz2.a; ===========================================; -- Looking for pthread.h; -- Looking for pthread.h - found; -- Looking for pthread_create; -- Looking for pthread_create - not found; -- Looking for pthread_create in pthreads; -- Looking for pthread_create in pthreads - not found; -- Looking for pthread_create in pthread; -- Looking for pthread_create in pthread - found; -- Found Threads: TRUE; -- Could NOT find Boost; BOOST_INCLUDEDIR =; BOOST_LIBRARYDIR =; Boost_FOUND = 0; Build system will fetch and build Boost; ==================================================================; Setting Temporary Boost paths; BOOST INCLUDE DIR = $blah/salmon-0.10.2/external/install/include; BOOST INCLUDE DIRS = $blah/salmon-0.10.2/external/install/include; BOOST LIB DIR = $blah/salmon-0.10.2/external/install/lib; BOOST LIBRARIES =; Build system will build libdivsufsort; ==================================================================; Build system will fetch and build the Cereal serialization library; ==================================================================; Build system will fetch and build BWA (for Salmon); ==================================================================; -- Found TBB: /apps/gentoo/usr/include (found suitable version ""2018.0"", minimum required is ""2018.0"") found components: tbb tbbmalloc tbbmalloc_proxy; TBB_LIBRARIES = /apps/gentoo/usr/lib/libtbbmalloc_proxy.so;/apps/gentoo/usr/lib/libtbbmalloc.so;/apps/gentoo/usr/lib/libtbb.so; Build system will compile libgff; ==================================================================; ==================================================================; Build system will compile Staden IOLib; =======",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/19#issuecomment-399775387:2965,install,install,2965,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/19#issuecomment-399775387,1,['install'],['install']
Deployability,"on for the problems you are facing in alevin. >Your first question was related to alevin quantifying very less number of reads. To answer that,; if you look at the log, at the first few lines, alevin warns about ~91% of the reads being thrown away because; of the noisy CBs. The problem is alevin’s first “knee"" estimation is overshooting in predicting the first boundary. You will find https://github.com/COMBINE-lab/salmon/issues/362 issue to be; very useful in understanding that. As a summary if you look at the plot I attached it has bi-modalities,; which is generally not the case and alevin is greedily finding the threshold at the first ~100 cells. If this; happens the general direction is to help alevin by proving a upper bound, in case of your data; would be ~14000 cells. You can tell alevin with `—expectCells 14000` and alevin start to work; normally and logs ~12% of the data is noisy. >You second question was a little complicated to answer. Seemingly, your salmon index has transcript with; same exact name `ENST00000399966.9`, occurring twice with different sequences. Just by looking at the index,; I am unsure it’s actually present in the reference or its salmon indexing messing up. If I Assume it was actually; present two times in the reference, alevin should report it instead of exiting abruptly in the middle of quantification.; Although, alevin does warns:; ```; [2019-07-04 14:12:32.519] [alevinLog] [warning] Found 1 transcripts with duplicate names; ```; >However, the bug i.e. not being able to distinguish duplicate names of the transcript, has been ; fixed and pushed in the develop branch of salmon. Alevin was reporting the error at the stage of quantification too, ; if you dump the logs in a file, but it was invisible in the console as it was over written my complex progress bar. . >Once I process it through the modified pipeline, alevin finished normally and I am attaching the quants generated; by alevin. >Thanks again for forwarding the data.; Best,; —Avi",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/386#issuecomment-508754845:2078,pipeline,pipeline,2078,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/386#issuecomment-508754845,1,['pipeline'],['pipeline']
Deployability,"ory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib"", {st_mode=S_IFDIR|0755, st_size=33280, ...}) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../lib/tls/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../lib/tls/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../lib/tls/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../lib/tls"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../lib/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../lib/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../lib/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../lib"", {st_mode=S_IFDIR|0775, st_size=33280, ...}) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/tls/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/aja",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:6402,pipeline,pipeline,6402,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,4,['pipeline'],['pipeline']
Deployability,"ose that explicitly tag me, but somehow I missed this one) should go to SPAM. So, I've been missing some of the newer issues here. The short answer is that the documentation needs to be updated. When salmon was originally published, we made use of [RapMap](https://github.com/COMBINE-lab/RapMap) as the underlying mapper, which performed quasi-mapping against an index that consisted of a suffix array and a hash over k-mers pointing to prefixes in the suffix array (similar to the strategy used by STAR, but using much longer k-mers to improve lookup speed). We referred to this index as the quasi-index. As the software evolved and we continued to improve the mapping methodology, we eventually transitioned over to an index based on [our pufferfish data structure](https://github.com/COMBINE-lab/pufferfish). In addition to the new data structure, this coincided with our move over to selective-alignment as the mapping algorithm, and all of this happened at the 1.0.0 release (this is why, for example, indices built before 1.0.0 are not compatible with salmon > 1.0.0; a topic on which there have been a few GitHub issues). However, given the fact that the documentation and software are linked only through manual human intervention (we haven't leveled up to e.g. having salmon be a [literate program](https://en.wikipedia.org/wiki/Literate_programming) yet), these two sometimes get out of sync. This is an instance of that. We have maintained the functionality of the `--writeMappings` feature, and in fact, even augmented it. However, we have not replaced the antiquated `quasi-index` terminology in the documentation. The TLDR is that you can use `--writeMappings` with the index you built with the `salmon index` command, and it should work fine. If you are mapping against an index without decoy sequences, then the output format will be basically the same as older (pre 1.0.0) versions. If you have decoy sequences in your index, then there is an optional SAM flag with each record that ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/727#issuecomment-996192524:1113,release,release,1113,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/727#issuecomment-996192524,1,['release'],['release']
Deployability,"pdate this later). > Why am I seeing much higher values for this gene with FeatureCounts?. I have now run FeatureCounts several times with different overlaps (minOverlap =25, minOverlap =50, minOverlap =75min Overlap =100) and indeed the counts have decreased (again the psbI example: 8685 , 6011, 4237, 1805 accordingly). Again, this is a good argument for the hypothesis put forward. >Why does running Salmon outside nf-core lead to much higher values?. Hopefully, after I run Decoy mode, this problem is solved. I also tried mapping mode with the --softclipOverhangs option. That increased the counts (psbI : 4696 counts); playing around with the --minScoreFraction flag in addition to the --softclipOverhangs flag also increased the numbers ( minScoreFraction= 0 ->psbI = 8496; minScoreFraction= 0.5 ->psbI = 5633; minScoreFraction= 0.7 ->psbI =3627 ). . So, in summary, your explanation seems to be completely correct. ; In the case that decoy mode resolves the difference between the pipeline and the run outside the pipeline, I would not give this to the nf-core people. But I will if there are still large discrepancies after the run. I'm still not sure what the best parameters are for my analysis, but the --softclipOverhangs flag seems to be the best option for me now.; So thanks again!. @drpatelh. Thank you very much for your quick reply as well. ; I was a bit inaccurate when I said I used the FeatureCounts from the pipeline. I actually wasn't able to use the resulting .txt files. Instead, I used the resulting bam file from the pipeline to perform a FeatureCounts analysis on R. I hope this information answers the question of how I can compare the two results?; My genome and gtf file are from [EnsemblPlants](https://plants.ensembl.org/Arabidopsis_thaliana/Info/Index), so they should be fine. In the MultiQC file, the vast majority of reads align to protein coding regions according to FeatureCounts, so I hope my primary files are fine. . Thanks again for your help and time!. A",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/798#issuecomment-1238043213:1923,pipeline,pipeline,1923,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/798#issuecomment-1238043213,2,['pipeline'],['pipeline']
Deployability,"pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts/sa.bin"", O_RDONLY) = 4; clock_gettime(CLOCK_REALTIME, {1491424830, 149197282}) = 0; read(4, ""l\n\221\21\0\0\0\0k\n\221\21\373\25\343\20\17\254\r\1\36\27\227\n\37\371\270\4\250\210\307\f""..., 8191) = 8191; mmap(NULL, 1342177280, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_NORESERVE, -1, 0) = 0x7ffe2e5e8000; munmap(0x7ffe2e5e8000, 1342177280) = 0; mmap(NULL, 1344270336, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_NORESERVE, -1, 0) = 0x7ffe2e3e9000; munmap(0x7ffe2e3e9000, 94208) = 0; munmap(0x7ffe7e400000, 1998848) = 0; [1m[2017-04-05 16:40:30.149] [stderrLog] [info] Loading Suffix Array ; [00m[1m[2017-04-05 16:40:30.069] [jointLog] [info] Loading Quasi index; [00m[1m[2017-04-05 16:40:30.139] [jointLog] [info] Loading 32-bit quasi index; [00mread(4, ""\16'w=\r\320m\306\0\35\26\306\0\224\23\270\10\205]D\0|\3!\4c_-\7\310O\2""..., 1178864057) = 1178864057; close(4) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts/txpInfo.bin"", O_RDONLY) = 4; clock_gettime(CLOCK_REALTIME, {1491424833, 297142816}) = 0; read(4, ""\315\5\3\0\0\0\0\0|\0\0\0\0\0\0\0ENST00000456328.""..., 8191) = 8191; read(4, ""RP4-669L17.8-001|RP4-669L17.8|12""..., 8191) = 8191; read(4, "".2|LINC01128-004|LINC01128|874|l""..., 8191) = 8191; read(4, ""THUMT00000097991.1|AGRN-002|AGRN""..., 8191) = 8191; read(4, ""HUMG00000001412.6|OTTHUMT0000000""..., 8191) = 8191; read(4, ""F3L-007|CPSF3L|1868|protein_codi""..., 8191) = 8191; read(4, ""01413.3|OTTHUMT00000004082.2|AUR""..., 8191) = 8191; read(4, ""UMT00000001363.3|ATAD3A-001|ATAD""..., 8191) = 8191; read(4, ""DK11B-202|CDK11B|2490|protein_co""..., 8191) = 8191; read(4, ""00002763.1|GNB1-002|GNB1|1512|re""..., 8191) = 8191; read(4, ""20-006|FAAP20|569|protein_coding""..., 8191) = 8191; read(4, ""212.1|ENSG00000157881.13|OTTHUMG""..., 8191) = 8191; read(4, ""0563.3|OTTHUMT00000099318.1|LINC""..., 8191) = 8191; rea",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:167601,pipeline,pipeline,167601,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,1,['pipeline'],['pipeline']
Deployability,"probably unrelated, but also unexpected. Make test on my linux and osx box looks like:. ```; $ make test; Running tests...; Test project /Users/rob/salmon/build; Start 1: unit_tests; 1/3 Test #1: unit_tests ....................... Passed 0.13 sec; Start 2: salmon_read_test_fmd; 2/3 Test #2: salmon_read_test_fmd ............. Passed 0.87 sec; Start 3: salmon_read_test_quasi; 3/3 Test #3: salmon_read_test_quasi ........... Passed 0.39 sec. 100% tests passed, 0 tests failed out of 3. Total Test time (real) = 1.41 sec; ```. It looks the same on the continuous integration server : . ```; Running tests...; /usr/local/cmake-3.9.2/bin/ctest --force-new-ctest-process ; Test project /home/travis/build/COMBINE-lab/salmon/build; Start 1: unit_tests; 1/3 Test #1: unit_tests ....................... Passed 0.13 sec; Start 2: salmon_read_test_fmd; 2/3 Test #2: salmon_read_test_fmd ............. Passed 2.55 sec; Start 3: salmon_read_test_quasi; 3/3 Test #3: salmon_read_test_quasi ........... Passed 1.72 sec; 100% tests passed, 0 tests failed out of 3; Total Test time (real) = 4.41 sec; ```. Also, you can look, in the build directory, in the subdirectory `Testing/Temporary/LastTestsFailed.log` which will give details of which specific test failed.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/229#issuecomment-393676260:551,continuous,continuous,551,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/229#issuecomment-393676260,2,"['continuous', 'integrat']","['continuous', 'integration']"
Deployability,"pt/rh/devtoolset-4/root/usr/bin/c++ -pthread -ftree-vectorize -funroll-loops -fPIC -fomit-frame-pointer -O3 -DRAPMAP_SALMON_SUPPORT -DHAVE_ANSI_TERM -DHAVE_SSTREAM -Wall -Wno-unknown-pragmas -Wno-reorder -Wno-unused-variable -std=c++11 -Wreturn-type -Werror=return-type -Wno-unused-function -Wno-unused-local-typedef -static-libstdc++ -Wno-unused-local-typedefs -pthread -ftree-vectorize -funroll-loops -fPIC -fomit-frame-pointer -O3 -DRAPMAP_SALMON_SUPPORT -DHAVE_ANSI_TERM -DHAVE_SSTREAM -Wall -Wno-unknown-pragmas -Wno-reorder -Wno-unused-variable -std=c++11 -Wreturn-type -Werror=return-type -Wno-unused-function -Wno-unused-local-typedef -static-libstdc++ -Wno-unused-local-typedefs -rdynamic CMakeFiles/unitTests.dir/__/tests/UnitTests.cpp.o CMakeFiles/unitTests.dir/FragmentLengthDistribution.cpp.o CMakeFiles/unitTests.dir/__/external/install/src/rapmap/rank9b.cpp.o CMakeFiles/unitTests.dir/__/external/install/src/rapmap/bit_array.c.o -o unitTests -L/home/mathog/src/salmon/lib -L/home/mathog/src/salmon/external/install/lib -Wl,-rpath,""\$ORIGIN/../lib:\$ORIGIN/../../lib:\$ORIGIN/:\$ORIGIN/../../external/install/lib"" libsalmon_core.a libalevin_core.a -lgff -lpthread ../external/install/lib/libstaden-read.a -lz ../external/install/lib/libdivsufsort.a ../external/install/lib/libdivsufsort64.a ../external/install/lib/libbwa.a -lm -llzma -lbz2 -ltbb -lgomp -lrt ../external/install/lib/libjemalloc.a -lrt -ldl ../external/install/lib/libjemalloc.a -ldl`. Oh, I also had to update automake and autoconf because the 2 year old versions on this system were not new enough. Is there a static binary version of salmon available for download, Linux 64 bit? It looks like the default links are that way anyway, and that would save me what looks like at least another day of fighting with Cmake to force it to actually build a working make file. . You are developing on something like a recent Fedora or Ubuntu? In my experience packages which use boost and cmake inevitably cause a great great d",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/236#issuecomment-397025719:2970,install,install,2970,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/236#issuecomment-397025719,1,['install'],['install']
Deployability,"r -xz --strip-components 1; cmake -DBOOST_ROOT=/global/software/sl-7.x86_64/modules/gcc/7.4.0/boost/1.70.0-gcc -DCMAKE_INSTALL_PREFIX=$INSTALL_DIR; make; ```; And the tail of the output from make:. ```; creating: /clusterfs/vector/home/groups/software/sl-7.x86_64/source/salmon/1.5.1/scripts/../external/pufferfish-salmon-v1.5.1/tests/compile_tests/; inflating: /clusterfs/vector/home/groups/software/sl-7.x86_64/source/salmon/1.5.1/scripts/../external/pufferfish-salmon-v1.5.1/tests/compile_tests/int128_numeric_limits.cpp ; -- fetch PUFFERFISH exit code 0; -- Found ZLIB: /usr/lib64/libz.so (found version ""1.2.11"") ; -- Performing Test Iconv_IS_BUILT_IN; -- Performing Test Iconv_IS_BUILT_IN - Failed; CMake Error at /global/home/groups/consultsw/sl-7.x86_64/modules/cmake/3.15.1/share/cmake-3.15/Modules/FindPackageHandleStandardArgs.cmake:137 (message):; Could NOT find Iconv (missing: Iconv_LIBRARY); Call Stack (most recent call first):; /global/home/groups/consultsw/sl-7.x86_64/modules/cmake/3.15.1/share/cmake-3.15/Modules/FindPackageHandleStandardArgs.cmake:378 (_FPHSA_FAILURE_MESSAGE); /global/home/groups/consultsw/sl-7.x86_64/modules/cmake/3.15.1/share/cmake-3.15/Modules/FindIconv.cmake:120 (find_package_handle_standard_args); CMakeLists.txt:362 (find_package). -- Configuring incomplete, errors occurred!; See also ""/clusterfs/vector/home/groups/software/sl-7.x86_64/source/salmon/1.5.1/CMakeFiles/CMakeOutput.log"".; See also ""/clusterfs/vector/home/groups/software/sl-7.x86_64/source/salmon/1.5.1/CMakeFiles/CMakeError.log"".; ```; I'm also attaching the full CMake logs. This is right at the edge of my knowledge, so I'm not 100% sure I got libiconv installed correctly. Compilation completed without error, and I added the bin, include, and lib directories to PATH, CPATH, and LD_LIBRARY_PATH, respectively. [CMakeError.log](https://github.com/COMBINE-lab/salmon/files/6665942/CMakeError.log); [CMakeOutput.log](https://github.com/COMBINE-lab/salmon/files/6665943/CMakeOutput.log)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/453#issuecomment-862737315:2814,install,installed,2814,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/453#issuecomment-862737315,1,['install'],['installed']
Deployability,"r/local/salmon-0.10.2/include/SalmonUtils.hpp:21,; from /usr/local/salmon-0.10.2/include/ReadPair.hpp:7,; from /usr/local/salmon-0.10.2/include/AlignmentGroup.hpp:15,; from /usr/local/salmon-0.10.2/include/AlignmentLibrary.hpp:12,; from /usr/local/salmon-0.10.2/src/SalmonQuantifyAlignments.cpp:39:; /usr/local/salmon-0.10.2/include/eigen3/Eigen/src/Core/AssignEvaluator.h:90:50: warning: enum constant in boolean context [-Wint-in-bool-context]; MaySliceVectorize = bool(MightVectorize) && bool(DstHasDirectAccess); ^~~~~~~~~~~~~~~~~~~~~~~~; At global scope:; cc1plus: warning: unrecognized command line option ‘-Wno-unused-local-typedef’; cc1plus: warning: unrecognized command line option ‘-Wno-unused-local-typedef’; make[2]: *** [src/CMakeFiles/salmon.dir/SalmonQuantifyAlignments.cpp.o] Error 1; make[1]: *** [src/CMakeFiles/salmon.dir/all] Error 2; make: *** [all] Error 2; ```. I also tried installing it through bioconda. Apparently, it installs it correctly, but when I try to use Trinity (I'm installing Salmon as a Trinity requirement) this is what happens: . ```; salmon: /opt/conda/conda-bld/salmon_1528409373758/work/salmon-0.10.2/include/eigen3/Eigen/src/Core/util/Memory.h:161: void* Eigen::internal::aligned_malloc(std::size_t): Assertion `(size<16 || (std::size_t(result)%16)==0) && ""System's malloc returned an unaligned pointer. Compile with EIGEN_MALLOC_ALREADY_ALIGNED=0 to fallback to handmade alignd memory allocator.""' failed.; Error, cmd:; salmon --no-version-check quant -i /home/federicoplazzi/test_Trinity_Assembly/trinity_out_dir/read_partitions/Fb_0/CBin_0/c30.trinity.reads.fa.out/Trinity.fasta.tmp.salmon.idx -l U -r /home/federicoplazzi/test_Trinity_Assembly/trinity_out_dir/read_partitions/Fb_0/CBin_0/c30.trinity.reads.fa.out/single.fa -o salmon_outdir -p 1 --minAssignedFrags 1; died with ret (6) at /usr/local/trinityrnaseq-Trinity-v2.6.6/util/support_scripts/../../PerlLib/Process_cmd.pm line 19.; Process_cmd::process_cmd(""salmon --no-version-check quant -i /h",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/235#issuecomment-398081403:1198,install,installs,1198,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/235#issuecomment-398081403,2,['install'],"['installing', 'installs']"
Deployability,"rder -Wno-unused-variable -std=c++11 -Wreturn-type -Werror=return-type -Wno-unused-function -Wno-unused-local-typedef -static-libstdc++ -Wno-unused-local-typedefs -pthread -ftree-vectorize -funroll-loops -fPIC -fomit-frame-pointer -O3 -DRAPMAP_SALMON_SUPPORT -DHAVE_ANSI_TERM -DHAVE_SSTREAM -Wall -Wno-unknown-pragmas -Wno-reorder -Wno-unused-variable -std=c++11 -Wreturn-type -Werror=return-type -Wno-unused-function -Wno-unused-local-typedef -static-libstdc++ -Wno-unused-local-typedefs -rdynamic CMakeFiles/unitTests.dir/__/tests/UnitTests.cpp.o CMakeFiles/unitTests.dir/FragmentLengthDistribution.cpp.o CMakeFiles/unitTests.dir/__/external/install/src/rapmap/rank9b.cpp.o CMakeFiles/unitTests.dir/__/external/install/src/rapmap/bit_array.c.o -o unitTests -L/home/mathog/src/salmon/lib -L/home/mathog/src/salmon/external/install/lib -Wl,-rpath,""\$ORIGIN/../lib:\$ORIGIN/../../lib:\$ORIGIN/:\$ORIGIN/../../external/install/lib"" libsalmon_core.a libalevin_core.a -lgff -lpthread ../external/install/lib/libstaden-read.a -lz ../external/install/lib/libdivsufsort.a ../external/install/lib/libdivsufsort64.a ../external/install/lib/libbwa.a -lm -llzma -lbz2 -ltbb -lgomp -lrt ../external/install/lib/libjemalloc.a -lrt -ldl ../external/install/lib/libjemalloc.a -ldl`. Oh, I also had to update automake and autoconf because the 2 year old versions on this system were not new enough. Is there a static binary version of salmon available for download, Linux 64 bit? It looks like the default links are that way anyway, and that would save me what looks like at least another day of fighting with Cmake to force it to actually build a working make file. . You are developing on something like a recent Fedora or Ubuntu? In my experience packages which use boost and cmake inevitably cause a great great deal of pain when they are built on platforms like Centos or RHEL where long term support is one of the goals. They work fine on platforms which are cutting edge, but backwards compatibility extends ba",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/236#issuecomment-397025719:3138,install,install,3138,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/236#issuecomment-397025719,1,['install'],['install']
Deployability,"rge/base/lib/python3.9/site-packages/requests/adapters.py"", line 308, in get_connection; raise InvalidProxyURL(""Please check proxy URL. It is malformed""; requests.exceptions.InvalidProxyURL: Please check proxy URL. It is malformed and could be missing the host. `$ /usr/local/bin/conda install salmon`. environment variables:; CIO_TEST=<not set>; CONDA_ROOT=/usr/local/Caskroom/miniforge/base; CURL_CA_BUNDLE=<not set>; INFOPATH=/opt/homebrew/share/info:; MANPATH=/opt/homebrew/share/man::; PATH=/opt/homebrew/bin:/opt/homebrew/sbin:/usr/local/bin:/usr/bin:/bin:/usr; /sbin:/sbin; REQUESTS_CA_BUNDLE=<not set>; SSL_CERT_FILE=<not set>; all_proxy=<set>. active environment : None; user config file : /Users/Benjamin/.condarc; populated config files : /usr/local/Caskroom/miniforge/base/.condarc; conda version : 4.12.0; conda-build version : not installed; python version : 3.9.13.final.0; virtual packages : __osx=12.4=0; __unix=0=0; __archspec=1=arm64; base environment : /usr/local/Caskroom/miniforge/base (writable); conda av data dir : /usr/local/Caskroom/miniforge/base/etc/conda; conda av metadata url : None; channel URLs : https://conda.anaconda.org/conda-forge/osx-arm64; https://conda.anaconda.org/conda-forge/noarch; package cache : /usr/local/Caskroom/miniforge/base/pkgs; /Users/Benjamin/.conda/pkgs; envs directories : /usr/local/Caskroom/miniforge/base/envs; /Users/Benjamin/.conda/envs; platform : osx-arm64; user-agent : conda/4.12.0 requests/2.27.1 CPython/3.9.13 Darwin/21.5.0 OSX/12.4; UID:GID : 501:20; netrc file : None; offline mode : False. An unexpected error has occurred. Conda has prepared the above report. If submitted, this report will be used by core maintainers to improve; future releases of conda.; Would you like conda to send this report to the core maintainers?. [y/N]: y; Upload did not complete. Thank you for helping to improve conda.; Opt-in to always sending reports (and not see this message again); by running. $ conda config --set report_errors true; ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/724#issuecomment-1171208515:6351,release,releases,6351,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/724#issuecomment-1171208515,1,['release'],['releases']
Deployability,"riments consist of multiple samples. In other samples, the same transcript fractions could give rise to a slightly different set of observed fragments that induce exactly the same type of variation under uncertainty; and since that uncertainty is baked into the sample, it cannot and should not be removed. Having exact replication of a sample at a numerical threshold below the inferential uncertainty for a transcript conveys false confidence in the precision of the estimate. This is why, for transcript-level analysis, we highly recommend having salmon produce posterior gibbs samples (with the `--numGibbsSamples` flag). This will draw samples from the posterior distribution over the abundance estimates and allow determination of what inferences can be made robustly and what cannot. We have spent a good deal of time thinking about how to properly perform statistical inference on these uncertain quantities, and so I'd point you at [swish](https://bioconductor.org/packages/release/bioc/vignettes/fishpond/inst/doc/swish.html), which is a tool for differential analysis at the transcript level that makes uses of a non-parametric test over the inferential replicates (Gibbs samples) to incorporate uncertainty into the differential analysis. We also developed a tool [terminus](https://academic.oup.com/bioinformatics/article/36/Supplement_1/i102/5870485) that makes use of the Gibbs samples and point estimates of salmon to group together transcripts whose individual abundances cannot be reliably inferred given the fragments in the sample. While the best way to properly assess, propagate and handle uncertainty in transcript-level inference is still, in my opinion, an active area of research in the field, these are some solutions we've come up with to address this challenge so far. And while, as a computer scientist myself, I _certainly_ appreciate the desire to be able to have e.g. exactly the same numerical output for a particular sample, we feel that doing so might convey a fal",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/613#issuecomment-757989858:3758,release,release,3758,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/613#issuecomment-757989858,1,['release'],['release']
Deployability,"rized equivalence relation group fragments not only by the transcripts to which they map, but also with respect to the conditional probabilities of having generated that fragment & alignment score given each transcript. Practically, what happens is that the space of conditional probabilities is quantized, and an equivalence relation is defined based on both the transcript set and the vector of conditional probability bins into which the mapping falls with respect to each transcript in the equivalence class. This means that range-factorized equivalence classes can have multiple classes of fragments that map to the same set of transcripts, but with different conditional probabilities. Additionally, for each bin, the average conditional probability of fragments arising from that bin is maintained. What you are seeing printed out are the transcript sets, followed by the conditional bin indexes. Starting in the next release (and currently in the develop branch), we've cleaned up the interaction of the range-factorized equivalence classes with the `--dumpEq` and `--dumpEqWeights` flags. If you run with the `--dumpEqWeights` flags, salmon will dump the transcript sets, followed by the conditional probability vector, followed by the fragment count. If you run with the `--dumpEq` flag, it will collapse all of the range-factorized equivalence classes into ""simple"" equivalence classes by combining classes with the same transcript set (but different conditional probability vectors) and summing the corresponding fragment counts. This, of course, is a lossy transformation, and the equivalence classes will no longer represent the relevant conditional probabilities used during inference. Also, since the range-factorized equivalence classes allow for (but probabilistically down-weight) non-optimal mappings of fragments to transcripts, these collapsed equivalence classes will tend to have bigger labels (i.e. more transcripts) which might be difficult to properly interpret without the",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/402#issuecomment-517041654:1462,release,release,1462,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/402#issuecomment-517041654,1,['release'],['release']
Deployability,"rna file not provided; using is 1 less feature for whitelisting; [2019-01-29 09:55:59.107] [alevinLog] [warning] rrna file not provided; using is 1 less feature for whitelisting; [2019-01-29 09:55:59.107] [alevinLog] [info] Starting to make feature Matrix; [2019-01-29 09:55:59.115] [alevinLog] [info] Done making regular featues; [2019-01-29 09:55:59.115] [alevinLog] [info] Done making feature Matrix; [2019-01-29 09:55:59.123] [alevinLog] [info] Finished white listing; [2019-01-29 09:55:59.126] [alevinLog] [info] Finished optimizer; ``` . Concat fastq:; ```; salmon alevin -l ISR -1 big.fastq.1.gz -2 big.fastq.2.gz --chromium -i geneset.dir/geneset_coding_exons.salmon.index/ -o salmon.dir/ --tgMap transcript2geneMap.tsv --dumpCsvCounts; Version Info: ### PLEASE UPGRADE SALMON ###; ### A newer version of Salmon with important bug fixes and improvements is available. ####; ###; The newest version, available at https://github.com/COMBINE-lab/salmon/releases; contains new features, improvements, and bug fixes; please upgrade at your; earliest convenience.; ###; Logs will be written to salmon.dir/logs; ### alevin (dscRNA-seq quantification) v0.11.3; ### [ program ] => salmon ; ### [ command ] => alevin ; ### [ libType ] => { ISR }; ### [ mates1 ] => { big.fastq.1.gz }; ### [ mates2 ] => { big.fastq.2.gz }; ### [ chromium ] => { }; ### [ index ] => { geneset.dir/geneset_coding_exons.salmon.index/ }; ### [ output ] => { salmon.dir/ }; ### [ tgMap ] => { transcript2geneMap.tsv }; ### [ dumpCsvCounts ] => { }. [2019-01-29 09:56:37.731] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2019-01-29 09:56:37.749] [alevinLog] [info] Processing barcodes files (if Present) . ; processed 2 Million barcodes. [2019-01-29 09:56:43.029] [alevinLog] [info] Done barcode density calculation.; [2019-01-29 09:56:43.029] [alevinLog] [info] # Barcodes Used: 2695632 / 2712324.; [2019-01-29 09:56:52.900] [alevinLog] [info] Knee found left b",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/337#issuecomment-458481722:6237,release,releases,6237,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/337#issuecomment-458481722,2,"['release', 'upgrade']","['releases', 'upgrade']"
Deployability,"ry(tximport); library(devtools); library(ggplot2); library(patchwork); # Just install Seurat like normal. Tutorial's allusion to a ""spatial"" branch appears to be outdated.; library(Seurat); }). # navigate to data directory; wkdir <- ""path/to/alevin_data/""; setwd(wkdir). # load in alevin output; files <- file.path(""alevin_out/alevin/quants_mat.gz""); file.exists(files). # set prefix for output files; prefix = ""alevin"". # tximport loads the alevin data into R; txi <- tximport(files = files, type = ""alevin""). # Creating a Seurat object with spatial assay; assay <- ""Spatial""; brain <- CreateSeuratObject(counts = txi$counts, project = ""SPATIAL"", assay = assay); brain. # loading the 10x image data; seqdir <- ""path/to/10x_imaging_data/""; image.data <- Read10X_Image(paste0(seqdir,""spatial/"")). # Since the names of alevin cb is different from 10x; # we rename the cells and filter the image data; # to have the metadata for only quantified cells; image.data@boundaries$centroids@cells <- gsub(""-1"", """", image.data@boundaries$centroids@cells); common.cells <- intersect(Cells(x = brain), image.data@boundaries$centroids@cells). # Subset the centroids object; centroids <- image.data@boundaries$centroids. # Find indices of common cells; common_indices <- which(centroids@cells %in% common.cells). # Subset the cells and coords slots; centroids@cells <- centroids@cells[common_indices]; centroids@coords <- centroids@coords[common_indices, ]. # Update the image.data object with the subsetted centroids; image.data@boundaries$centroids <- centroids. # Update the brain object accordingly; brain <- subset(brain, cells = common.cells). # adding image data to Seurat object; DefaultAssay(object = image.data) <- ""Spatial""; brain@images[['slice']] <- image.data; ```; The rest of the tutorial (plotting and clustering) is fairly standard and should work just fine. Of course, if your setup differs substantially from mine, it is certainly possible you will encounter different behavior so stay vigilent!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/942#issuecomment-2204802696:1675,Update,Update,1675,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/942#issuecomment-2204802696,2,['Update'],['Update']
Deployability,"s, better use `mkstemp'; [100%] Built target salmon; root@e08cc9670e4a:/salmon-0.10.2/build# make install; [ 6%] Built target libdivsufsort; [ 12%] Built target libbz2; [ 17%] Built target liblzma; [ 24%] Built target libcereal; [ 31%] Built target libgff; [ 36%] Built target libbwa; [ 42%] Built target libstadenio; [ 48%] Built target libspdlog; [ 50%] Built target ksw2pp_sse4; [ 52%] Built target alevin_core; [ 55%] Built target ksw2pp_sse2; [ 60%] Built target ksw2pp_basic; [ 60%] Built target ksw2pp; [ 73%] Built target salmon_core; [ 77%] Built target unitTests; [100%] Built target salmon; Install the project...; -- Install configuration: ""Release""; -- Installing: /salmon-0.10.2/lib; -- Installing: /salmon-0.10.2/lib/libtbb.so; -- Installing: /salmon-0.10.2/lib/libtbbmalloc.so; -- Installing: /salmon-0.10.2/lib/libtbbmalloc_proxy.so; -- Installing: /salmon-0.10.2/lib/libtbbmalloc.so.2; -- Installing: /salmon-0.10.2/lib/libtbb.so.2; -- Installing: /salmon-0.10.2/lib/pkgconfig; -- Installing: /salmon-0.10.2/lib/libtbbmalloc_proxy.so.2; -- Installing: /salmon-0.10.2/bin/salmon; -- Installing: /salmon-0.10.2/lib/libsalmon_core.a. Installation complete. Please ensure the following paths are set properly.; ==========================================================================; Please add /salmon-0.10.2/bin to your PATH; Please add /salmon-0.10.2/lib to your LD_LIBRARY_PATH; ==========================================================================; root@e08cc9670e4a:/salmon-0.10.2/build# make test; Running tests...; Test project /salmon-0.10.2/build; Start 1: unit_tests; 1/3 Test #1: unit_tests ....................... Passed 0.17 sec; Start 2: salmon_read_test_fmd; 2/3 Test #2: salmon_read_test_fmd ............. Passed 1.78 sec; Start 3: salmon_read_test_quasi; 3/3 Test #3: salmon_read_test_quasi ........... Passed 1.59 sec. 100% tests passed, 0 tests failed out of 3. Total Test time (real) = 3.54 sec; root@e08cc9670e4a:/salmon-0.10.2/build# lsb_release -a; LSB V",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/250#issuecomment-404306268:1341,Install,Installing,1341,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/250#issuecomment-404306268,1,['Install'],['Installing']
Deployability,salmon 0.14.1. Maybe that is the problem... I am going to update now and try again.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/518#issuecomment-623868804:58,update,update,58,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/518#issuecomment-623868804,1,['update'],['update']
Deployability,"salmon; $ ldd `which salmon`; linux-vdso.so.1 => (0x00007ffd8d9c0000); libpthread.so.0 => /lib/x86_64-linux-gnu/libpthread.so.0 (0x00007f20010a9000); libtbb.so.2 => /usr/lib/x86_64-linux-gnu/libtbb.so.2 (0x00007f2000e6b000); libgomp.so.1 => /usr/lib/x86_64-linux-gnu/libgomp.so.1 (0x00007f2000c49000); librt.so.1 => /lib/x86_64-linux-gnu/librt.so.1 (0x00007f2000a41000); libm.so.6 => /lib/x86_64-linux-gnu/libm.so.6 (0x00007f2000737000); libgcc_s.so.1 => /lib/x86_64-linux-gnu/libgcc_s.so.1 (0x00007f2000521000); libc.so.6 => /lib/x86_64-linux-gnu/libc.so.6 (0x00007f2000158000); /lib64/ld-linux-x86-64.so.2 (0x000055aeef1e1000); libdl.so.2 => /lib/x86_64-linux-gnu/libdl.so.2 (0x00007f1ffff53000); libstdc++.so.6 => /usr/lib/x86_64-linux-gnu/libstdc++.so.6 (0x00007f1fffbd1000); $ ldd ~/src/salmon/build/src/salmon; linux-vdso.so.1 => (0x00007fffdc2d7000); libpthread.so.0 => /lib/x86_64-linux-gnu/libpthread.so.0 (0x00007f990745d000); libtbb.so.2 => /home/ryan/src/salmon/build/src/../../external/install/lib/libtbb.so.2 (0x00007f990722f000); libgomp.so.1 => /usr/lib/x86_64-linux-gnu/libgomp.so.1 (0x00007f990700d000); librt.so.1 => /lib/x86_64-linux-gnu/librt.so.1 (0x00007f9906e05000); libm.so.6 => /lib/x86_64-linux-gnu/libm.so.6 (0x00007f9906afb000); libgcc_s.so.1 => /lib/x86_64-linux-gnu/libgcc_s.so.1 (0x00007f99068e5000); libc.so.6 => /lib/x86_64-linux-gnu/libc.so.6 (0x00007f990651c000); /lib64/ld-linux-x86-64.so.2 (0x0000564b94030000); libdl.so.2 => /lib/x86_64-linux-gnu/libdl.so.2 (0x00007f9906317000); libstdc++.so.6 => /usr/lib/x86_64-linux-gnu/libstdc++.so.6 (0x00007f9905f95000); $ md5sum `which salmon` ~/src/salmon/build/src/salmon; 90831f998ff897969da448043c590f61 /home/ryan/bin/salmon; 90831f998ff897969da448043c590f61 /home/ryan/src/salmon/build/src/salmon; ```. I don't know enough about how dynamic linking works to explain this. Anyway, I did `export LD_LIBRARY_PATH=/home/ryan/src/salmon/external/install/lib` and now I'm running `while true; do salmon ...; done` again.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267493389:1224,install,install,1224,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267493389,2,['install'],['install']
Deployability,same thing happened to me using the conda install,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/194#issuecomment-364822189:42,install,install,42,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/194#issuecomment-364822189,1,['install'],['install']
Deployability,"script set and the vector of conditional probability bins into which the mapping falls with respect to each transcript in the equivalence class. This means that range-factorized equivalence classes can have multiple classes of fragments that map to the same set of transcripts, but with different conditional probabilities. Additionally, for each bin, the average conditional probability of fragments arising from that bin is maintained. What you are seeing printed out are the transcript sets, followed by the conditional bin indexes. Starting in the next release (and currently in the develop branch), we've cleaned up the interaction of the range-factorized equivalence classes with the `--dumpEq` and `--dumpEqWeights` flags. If you run with the `--dumpEqWeights` flags, salmon will dump the transcript sets, followed by the conditional probability vector, followed by the fragment count. If you run with the `--dumpEq` flag, it will collapse all of the range-factorized equivalence classes into ""simple"" equivalence classes by combining classes with the same transcript set (but different conditional probability vectors) and summing the corresponding fragment counts. This, of course, is a lossy transformation, and the equivalence classes will no longer represent the relevant conditional probabilities used during inference. Also, since the range-factorized equivalence classes allow for (but probabilistically down-weight) non-optimal mappings of fragments to transcripts, these collapsed equivalence classes will tend to have bigger labels (i.e. more transcripts) which might be difficult to properly interpret without the relevant conditional probabilities. The `--hardFilter` flag will filter out transcripts that have non-best alignment scores (a big component of the conditional fragment probability), but that can have a negative effect on the modeling and inference. We'll update the documentation accordingly when we cut the next release to make all of these interactions more clear.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/402#issuecomment-517041654:2794,update,update,2794,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/402#issuecomment-517041654,2,"['release', 'update']","['release', 'update']"
Deployability,"se/lib/python3.9/site-packages/requests/adapters.py"", line 413, in send; conn = self.get_connection(request.url, proxies); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/requests/adapters.py"", line 308, in get_connection; raise InvalidProxyURL(""Please check proxy URL. It is malformed""; requests.exceptions.InvalidProxyURL: Please check proxy URL. It is malformed and could be missing the host. `$ /usr/local/bin/conda install salmon`. environment variables:; CIO_TEST=<not set>; CONDA_ROOT=/usr/local/Caskroom/miniforge/base; CURL_CA_BUNDLE=<not set>; INFOPATH=/opt/homebrew/share/info:; MANPATH=/opt/homebrew/share/man::; PATH=/opt/homebrew/bin:/opt/homebrew/sbin:/usr/local/bin:/usr/bin:/bin:/usr; /sbin:/sbin; REQUESTS_CA_BUNDLE=<not set>; SSL_CERT_FILE=<not set>; all_proxy=<set>. active environment : None; user config file : /Users/Benjamin/.condarc; populated config files : /usr/local/Caskroom/miniforge/base/.condarc; conda version : 4.12.0; conda-build version : not installed; python version : 3.9.13.final.0; virtual packages : __osx=12.4=0; __unix=0=0; __archspec=1=arm64; base environment : /usr/local/Caskroom/miniforge/base (writable); conda av data dir : /usr/local/Caskroom/miniforge/base/etc/conda; conda av metadata url : None; channel URLs : https://conda.anaconda.org/conda-forge/osx-arm64; https://conda.anaconda.org/conda-forge/noarch; package cache : /usr/local/Caskroom/miniforge/base/pkgs; /Users/Benjamin/.conda/pkgs; envs directories : /usr/local/Caskroom/miniforge/base/envs; /Users/Benjamin/.conda/envs; platform : osx-arm64; user-agent : conda/4.12.0 requests/2.27.1 CPython/3.9.13 Darwin/21.5.0 OSX/12.4; UID:GID : 501:20; netrc file : None; offline mode : False. An unexpected error has occurred. Conda has prepared the above report. If submitted, this report will be used by core maintainers to improve; future releases of conda.; Would you like conda to send this report to the core maintainers?. [y/N]: y; Upload did not complete. Thank you ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/724#issuecomment-1171208515:5482,install,installed,5482,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/724#issuecomment-1171208515,1,['install'],['installed']
Deployability,"se4; [ 37%] Built target ksw2pp_basic; [ 38%] Built target ksw2pp; [ 59%] Built target puffer; [ 73%] Built target salmon_core; [ 76%] Built target alevin_core; [ 77%] Built target UnitTestsMain; [ 81%] Built target unitTests; [100%] Built target salmon; Install the project...; -- Install configuration: ""Release""; -- Installing: /salmon/lib/libntcard.a; -- Installing: /salmon/lib/ntcard/ntcard-targets.cmake; -- Installing: /salmon/lib/ntcard/ntcard-targets-release.cmake; -- Installing: /salmon/lib/libgraphdump.a; -- Installing: /salmon/lib/graphdump/graphdump-targets.cmake; -- Installing: /salmon/lib/graphdump/graphdump-targets-release.cmake; -- Installing: /salmon/lib/libtwopaco.a; -- Installing: /salmon/lib/twopaco/twopaco-targets.cmake; -- Installing: /salmon/lib/twopaco/twopaco-targets-release.cmake; -- Installing: /salmon/lib/libtbb.so; -- Installing: /salmon/lib/libtbb.so.12; -- Installing: /salmon/lib/libtbb.so.12.5; -- Installing: /salmon/lib/libtbbmalloc.so; -- Installing: /salmon/lib/libtbbmalloc.so.2; -- Installing: /salmon/lib/libtbbmalloc.so.2.5; -- Installing: /salmon/lib/libtbbmalloc_proxy.so; -- Installing: /salmon/lib/libtbbmalloc_proxy.so.2; -- Installing: /salmon/lib/libtbbmalloc_proxy.so.2.5; -- Installing: /salmon/bin/salmon; -- Installing: /salmon/lib/libsalmon_core.a. Installation complete. Please ensure the following paths are set properly.; ==========================================================================; Please add /salmon/bin to your PATH; Please add /salmon/lib to your LD_LIBRARY_PATH; ==========================================================================; root@fd877e359439:/salmon/build# make test; Running tests...; Test project /salmon/build; Start 1: unit_tests; 1/2 Test #1: unit_tests ....................... Passed 0.37 sec; Start 2: salmon_read_test_quasi; 2/2 Test #2: salmon_read_test_quasi ........... Passed 1.80 sec. 100% tests passed, 0 tests failed out of 2. Total Test time (real) = 2.17 sec; ```. The `make test` c",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463312554:2009,Install,Installing,2009,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463312554,1,['Install'],['Installing']
Deployability,sed time: 0.20793s; [2019-07-01 12:33:02.252] [jointLog] [info] Writing sequence data to file . . . ; [2019-07-01 12:33:04.501] [jointLog] [info] done; Elapsed time: 2.24861s; [2019-07-01 12:33:04.572] [jointLog] [info] Building 32-bit suffix array (length of generalized text is 469043886); [2019-07-01 12:33:08.681] [jointLog] [info] Building suffix array . . . ; success; saving to disk . . . done; Elapsed time: 61.4932s; done; Elapsed time: 171.743s; processed 12000000 positionsKilled. I can send log files if required. The problem I have is that I cannot seem to run quant without the quant function. salmon quant --validateMappings ; -i /home/RnaSeq/transcriptome_gencode_v29/human_GENCODEv29/combined_index -l IU ; -1 /home/RnaSeq/fastq/DM_4a_H_1.fq.gz /home/RnaSeq/fastq/DM_4b_H_1.fq.gz /home/RnaSeq/fastq/DM_4c_H_1.fq.gz ; -2 /home/RnaSeq/fastq/DM_4a_H_2.fq.gz /home/RnaSeq/fastq/DM_4b_H_2.fq.gz /home/RnaSeq/fastq/DM_4c_H_2.fq.gz ; -o /home/RnaSeq/salmon_output_files/out/DM4h; Version Info: Could not resolve upgrade information in the alotted time.; Check for upgrades manually at https://combine-lab.github.io/salmon; ### salmon (mapping-based) v0.14.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { /home/RnaSeq/transcriptome_gencode_v29/human_GENCODEv29/combined_index }; ### [ libType ] => { IU }; ### [ mates1 ] => { /home/RnaSeq/fastq/DM_4a_H_1.fq.gz /home/RnaSeq/fastq/DM_4b_H_1.fq.gz /home/RnaSeq/fastq/DM_4c_H_1.fq.gz }; ### [ mates2 ] => { /home/RnaSeq/fastq/DM_4a_H_2.fq.gz /home/RnaSeq/fastq/DM_4b_H_2.fq.gz /home/RnaSeq/fastq/DM_4c_H_2.fq.gz }; ### [ validateMappings ] => { }; ### [ output ] => { /home/RnaSeq/salmon_output_files/out/DM4h }; Logs will be written to /home/RnaSeq/salmon_output_files/out/DM4h/logs; [2019-07-01 12:51:42.856] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2019-07-01 12:51:42.856] [jointLog] [info] Usage of --validateMappings implies use of minScoreFra,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/389#issuecomment-507253562:2269,upgrade,upgrade,2269,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/389#issuecomment-507253562,1,['upgrade'],['upgrade']
Deployability,"shared/apps/sge/current/lib/linux-x64/libc.so.6"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/lib64/libc.so.6"", O_RDONLY) = 3; read(3, ""\177ELF\2\1\1\3\0\0\0\0\0\0\0\0\3\0>\0\1\0\0\0p\356A\316;\0\0\0""..., 832) = 832; fstat(3, {st_mode=S_IFREG|0755, st_size=1926760, ...}) = 0; mmap(0x3bce400000, 3750152, PROT_READ|PROT_EXEC, MAP_PRIVATE|MAP_DENYWRITE, 3, 0) = 0x3bce400000; mprotect(0x3bce58a000, 2097152, PROT_NONE) = 0; mmap(0x3bce78a000, 20480, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_DENYWRITE, 3, 0x18a000) = 0x3bce78a000; mmap(0x3bce78f000, 18696, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_ANONYMOUS, -1, 0) = 0x3bce78f000; close(3) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/libdl.so.2"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../lib/libdl.so.2"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/libdl.so.2"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/jhpce/shared/community/core/pcre/8.36/lib/libdl.so.2"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/jhpce/shared/community/core/jags/4.2.0/lib64/libdl.so.2"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/jhpce/shared/community/compiler/gcc/4.4.7/netcdf/4.3.2/lib/libdl.so.2"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/jhpce/shared/community/core/curl/7.43.0/lib/libdl.so.2"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/cm/shared/apps/sge/2011.11p1/lib/linux-x64/libdl.so.2"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/cm/shared/apps/sge/current/lib/linux-x64/libdl.so.2"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/lib64/libdl.so.2"", O_RDONLY) = 3; read(3, ""\177ELF\2\1\1\0\0\0\0\0\0\0\0\0\3\0>\0\1\0\0\0\340\r\300\316;\0\0\0""..., 832) = 832; fstat(3, {st_mode=S",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:59099,pipeline,pipeline,59099,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,2,['pipeline'],['pipeline']
Deployability,"so.6 (0x00007f859979f000); ```. The linux version and g++ version are listed below:; ```; cat /proc/version; Linux version 4.9.0-0.bpo.6-amd64 (debian-kernel@lists.debian.org) (gcc version 4.9.2 (Debian 4.9.2-10+deb8u1) ) #1 SMP Debian 4.9.82-1+deb9u3~bpo8+1 (2018-03-22). ~/data/PCSI/PC10X/paper/pbmc$ g++ -v; Using built-in specs.; COLLECT_GCC=g++; COLLECT_LTO_WRAPPER=/u/user/local/libexec/gcc/x86_64-unknown-linux-gnu/5.4.0/lto-wrapper; Target: x86_64-unknown-linux-gnu; Configured with: ./configure --prefix=/u/user/local; Thread model: posix; gcc version 5.4.0 (GCC); ```. ```; [Thread debugging using libthread_db enabled]; Using host libthread_db library ""/lib/x86_64-linux-gnu/libthread_db.so.1"".; warning: File ""/u/user/local/lib64/libstdc++.so.6.0.21-gdb.py"" auto-loading has been declined by your `auto-load safe-path' set to ""$debugdir:$datadir/auto-load"".; To enable execution of this file add; add-auto-load-safe-path /u/user/local/lib64/libstdc++.so.6.0.21-gdb.py; line to your configuration file ""/u/user/.gdbinit"".; To completely disable this security protection add; set auto-load safe-path /; line to your configuration file ""/u/user/.gdbinit"".; For more information about this security protection see the; ""Auto-loading safe path"" section in the GDB manual. E.g., run from the shell:; info ""(gdb)Auto-loading safe path""; [New Thread 0x7fff7e0f4700 (LWP 14274)]; Version Info: ### A newer version of Salmon is available. ####; [Thread 0x7fff7e0f4700 (LWP 14274) exited]; ###; The newest version, available at https://github.com/COMBINE-lab/salmon/releases; contains new features, improvements, and bug fixes; please upgrade at your; earliest convenience.; ###; [New Thread 0x7fff7d273700 (LWP 14275)]; Logs will be written to pbmc4k/alevin/logs; [New Thread 0x7ffefc3f1700 (LWP 14276)]; [New Thread 0x7ffe7b56f700 (LWP 14277)]; [New Thread 0x7ffdfa6ed700 (LWP 14278)]; ### salmon (single-cell-based) v0.10.1; ### [ program ] => salmon; ### [ command ] => alevin; ### [ libType ] =",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-395836214:2370,configurat,configuration,2370,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-395836214,1,['configurat'],['configuration']
Deployability,"staden_read_la-open_trace_file.o): In function `find_file_url':; open_trace_file.c:(.text+0xec4): warning: the use of `tempnam' is dangerous, better use `mkstemp'; [100%] Built target salmon; root@e08cc9670e4a:/salmon-0.10.2/build# make install; [ 6%] Built target libdivsufsort; [ 12%] Built target libbz2; [ 17%] Built target liblzma; [ 24%] Built target libcereal; [ 31%] Built target libgff; [ 36%] Built target libbwa; [ 42%] Built target libstadenio; [ 48%] Built target libspdlog; [ 50%] Built target ksw2pp_sse4; [ 52%] Built target alevin_core; [ 55%] Built target ksw2pp_sse2; [ 60%] Built target ksw2pp_basic; [ 60%] Built target ksw2pp; [ 73%] Built target salmon_core; [ 77%] Built target unitTests; [100%] Built target salmon; Install the project...; -- Install configuration: ""Release""; -- Installing: /salmon-0.10.2/lib; -- Installing: /salmon-0.10.2/lib/libtbb.so; -- Installing: /salmon-0.10.2/lib/libtbbmalloc.so; -- Installing: /salmon-0.10.2/lib/libtbbmalloc_proxy.so; -- Installing: /salmon-0.10.2/lib/libtbbmalloc.so.2; -- Installing: /salmon-0.10.2/lib/libtbb.so.2; -- Installing: /salmon-0.10.2/lib/pkgconfig; -- Installing: /salmon-0.10.2/lib/libtbbmalloc_proxy.so.2; -- Installing: /salmon-0.10.2/bin/salmon; -- Installing: /salmon-0.10.2/lib/libsalmon_core.a. Installation complete. Please ensure the following paths are set properly.; ==========================================================================; Please add /salmon-0.10.2/bin to your PATH; Please add /salmon-0.10.2/lib to your LD_LIBRARY_PATH; ==========================================================================; root@e08cc9670e4a:/salmon-0.10.2/build# make test; Running tests...; Test project /salmon-0.10.2/build; Start 1: unit_tests; 1/3 Test #1: unit_tests ....................... Passed 0.17 sec; Start 2: salmon_read_test_fmd; 2/3 Test #2: salmon_read_test_fmd ............. Passed 1.78 sec; Start 3: salmon_read_test_quasi; 3/3 Test #3: salmon_read_test_quasi ........... Passed 1.59 sec. 10",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/250#issuecomment-404306268:1196,Install,Installing,1196,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/250#issuecomment-404306268,1,['Install'],['Installing']
Deployability,"t libbz2; [ 17%] Built target liblzma; [ 24%] Built target libcereal; [ 31%] Built target libgff; [ 36%] Built target libbwa; [ 42%] Built target libstadenio; [ 48%] Built target libspdlog; [ 50%] Built target ksw2pp_sse4; [ 52%] Built target alevin_core; [ 55%] Built target ksw2pp_sse2; [ 60%] Built target ksw2pp_basic; [ 60%] Built target ksw2pp; [ 73%] Built target salmon_core; [ 77%] Built target unitTests; [100%] Built target salmon; Install the project...; -- Install configuration: ""Release""; -- Installing: /salmon-0.10.2/lib; -- Installing: /salmon-0.10.2/lib/libtbb.so; -- Installing: /salmon-0.10.2/lib/libtbbmalloc.so; -- Installing: /salmon-0.10.2/lib/libtbbmalloc_proxy.so; -- Installing: /salmon-0.10.2/lib/libtbbmalloc.so.2; -- Installing: /salmon-0.10.2/lib/libtbb.so.2; -- Installing: /salmon-0.10.2/lib/pkgconfig; -- Installing: /salmon-0.10.2/lib/libtbbmalloc_proxy.so.2; -- Installing: /salmon-0.10.2/bin/salmon; -- Installing: /salmon-0.10.2/lib/libsalmon_core.a. Installation complete. Please ensure the following paths are set properly.; ==========================================================================; Please add /salmon-0.10.2/bin to your PATH; Please add /salmon-0.10.2/lib to your LD_LIBRARY_PATH; ==========================================================================; root@e08cc9670e4a:/salmon-0.10.2/build# make test; Running tests...; Test project /salmon-0.10.2/build; Start 1: unit_tests; 1/3 Test #1: unit_tests ....................... Passed 0.17 sec; Start 2: salmon_read_test_fmd; 2/3 Test #2: salmon_read_test_fmd ............. Passed 1.78 sec; Start 3: salmon_read_test_quasi; 3/3 Test #3: salmon_read_test_quasi ........... Passed 1.59 sec. 100% tests passed, 0 tests failed out of 3. Total Test time (real) = 3.54 sec; root@e08cc9670e4a:/salmon-0.10.2/build# lsb_release -a; LSB Version: core-9.20160110ubuntu0.2-amd64:core-9.20160110ubuntu0.2-noarch:security-9.20160110ubuntu0.2-amd64:security-9.20160110ubuntu0.2-noarch; Distributor ID: U",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/250#issuecomment-404306268:1491,Install,Installation,1491,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/250#issuecomment-404306268,1,['Install'],['Installation']
Deployability,"t ntcard; [ 19%] Built target graphdump; [ 27%] Built target twopaco; [ 29%] Built target ksw2pp_sse2; [ 32%] Built target ksw2pp_sse4; [ 37%] Built target ksw2pp_basic; [ 38%] Built target ksw2pp; [ 59%] Built target puffer; [ 73%] Built target salmon_core; [ 76%] Built target alevin_core; [ 77%] Built target UnitTestsMain; [ 81%] Built target unitTests; [100%] Built target salmon; Install the project...; -- Install configuration: ""Release""; -- Installing: /salmon/lib/libntcard.a; -- Installing: /salmon/lib/ntcard/ntcard-targets.cmake; -- Installing: /salmon/lib/ntcard/ntcard-targets-release.cmake; -- Installing: /salmon/lib/libgraphdump.a; -- Installing: /salmon/lib/graphdump/graphdump-targets.cmake; -- Installing: /salmon/lib/graphdump/graphdump-targets-release.cmake; -- Installing: /salmon/lib/libtwopaco.a; -- Installing: /salmon/lib/twopaco/twopaco-targets.cmake; -- Installing: /salmon/lib/twopaco/twopaco-targets-release.cmake; -- Installing: /salmon/lib/libtbb.so; -- Installing: /salmon/lib/libtbb.so.12; -- Installing: /salmon/lib/libtbb.so.12.5; -- Installing: /salmon/lib/libtbbmalloc.so; -- Installing: /salmon/lib/libtbbmalloc.so.2; -- Installing: /salmon/lib/libtbbmalloc.so.2.5; -- Installing: /salmon/lib/libtbbmalloc_proxy.so; -- Installing: /salmon/lib/libtbbmalloc_proxy.so.2; -- Installing: /salmon/lib/libtbbmalloc_proxy.so.2.5; -- Installing: /salmon/bin/salmon; -- Installing: /salmon/lib/libsalmon_core.a. Installation complete. Please ensure the following paths are set properly.; ==========================================================================; Please add /salmon/bin to your PATH; Please add /salmon/lib to your LD_LIBRARY_PATH; ==========================================================================; root@fd877e359439:/salmon/build# make test; Running tests...; Test project /salmon/build; Start 1: unit_tests; 1/2 Test #1: unit_tests ....................... Passed 0.37 sec; Start 2: salmon_read_test_quasi; 2/2 Test #2: salmon_read_test_quasi",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463312554:1881,Install,Installing,1881,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463312554,1,['Install'],['Installing']
Deployability,"t results similar to if you had aligned to the target transcriptome using Bowtie2. In this case, you perform indexing by simply not providing any `--decoy` flag to the `index` command. In that case, all of the records in the target fasta will be treated as valid and quantifiable targets. Of course, for reasons detailed in the pre-print --- the high _sensitivity_ of both Bowtie2 and selective-alignment --- we recommend including either mashmap-derived decoys or the organism's genome as a decoy whenever possible. . 4) Related to @k3yavi's response and my elaboration above: we have dropped quasi-mapping from 1.0.0 (though something akin to it may return in the future if there is sufficient demand and if the shortcomings described in the manuscript can be overcome). However, as I mention in part 3 above, this doesn't mean it's not possible to use v1.0.0 without an explicit decoy sequence. The `--decoy` flag of the indexing command is optional, not required. We will update this in the documentation making it more explicit. However, as @k3yavi points out, it is true that if you wish to use quasi-mapping and selective-alignment against the full genome on the same machine, you will need both versions, as quasi-mapping is supported only in the [RapMap](https://github.com/COMBINE-lab/RapMap/tree/develop-salmon), while indexing something on the scale of the genome when not using the [pufferfish-based](https://github.com/COMBINE-lab/pufferfish/tree/develop) index has tremendous memory requirements (as is not recommended ). 5 & 6) To re-iterate @k3yavi's answer --- the extra flags used in the pre-print were only for the purpose of holding as many variables fixed as possible when comparing different approaches. It continues to be recommended to use the VBEM over the EM; it seems to perform better with respect to the ways in which we can measure and such improvements have also been documented in [other work](https://www.ncbi.nlm.nih.gov/pubmed/23821651). The _main_ effect of `--mi",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/442#issuecomment-549195390:1916,update,update,1916,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/442#issuecomment-549195390,1,['update'],['update']
Deployability,"talling: /salmon/lib/libntcard.a; -- Installing: /salmon/lib/ntcard/ntcard-targets.cmake; -- Installing: /salmon/lib/ntcard/ntcard-targets-release.cmake; -- Installing: /salmon/lib/libgraphdump.a; -- Installing: /salmon/lib/graphdump/graphdump-targets.cmake; -- Installing: /salmon/lib/graphdump/graphdump-targets-release.cmake; -- Installing: /salmon/lib/libtwopaco.a; -- Installing: /salmon/lib/twopaco/twopaco-targets.cmake; -- Installing: /salmon/lib/twopaco/twopaco-targets-release.cmake; -- Installing: /salmon/lib/libtbb.so; -- Installing: /salmon/lib/libtbb.so.12; -- Installing: /salmon/lib/libtbb.so.12.5; -- Installing: /salmon/lib/libtbbmalloc.so; -- Installing: /salmon/lib/libtbbmalloc.so.2; -- Installing: /salmon/lib/libtbbmalloc.so.2.5; -- Installing: /salmon/lib/libtbbmalloc_proxy.so; -- Installing: /salmon/lib/libtbbmalloc_proxy.so.2; -- Installing: /salmon/lib/libtbbmalloc_proxy.so.2.5; -- Installing: /salmon/bin/salmon; -- Installing: /salmon/lib/libsalmon_core.a. Installation complete. Please ensure the following paths are set properly.; ==========================================================================; Please add /salmon/bin to your PATH; Please add /salmon/lib to your LD_LIBRARY_PATH; ==========================================================================; root@fd877e359439:/salmon/build# make test; Running tests...; Test project /salmon/build; Start 1: unit_tests; 1/2 Test #1: unit_tests ....................... Passed 0.37 sec; Start 2: salmon_read_test_quasi; 2/2 Test #2: salmon_read_test_quasi ........... Passed 1.80 sec. 100% tests passed, 0 tests failed out of 2. Total Test time (real) = 2.17 sec; ```. The `make test` command itself runs the test the builds the index and maps the reads against it. Either way, I can do that explicitly too (from within build):. ```; $ ./src/salmon index -t ../sample_data/transcripts.fasta -i sample_idx; ```. returns succesfully with a built index. ```; ...; [2023-03-10 05:51:33.748] [puff::index::jointLog",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463312554:2336,Install,Installation,2336,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463312554,1,['Install'],['Installation']
Deployability,"ted to ""word""...; Reading symbols from /u/user/local/bin/salmon...done.; (gdb) run alevin -l ISR --chromium -p 4 -o BM_1/alevin -1 ./BM_1/run1/bm_S10_L001_R1_001.fastq.gz -2 ./BM_1/run1/bm_S10_L001_R2_001.fastq.gz --maxHashResizeThreads 2 -i /u/user/ref/cellranger/salmon/transcripts_index --tgMap tx2gene.txt; Starting program: /u/user/local/bin/salmon alevin -l ISR --chromium -p 4 -o BM_1/alevin -1 ./BM_1/run1/bm_S10_L001_R1_001.fastq.gz -2 ./BM_1/run1/bm_S10_L001_R2_001.fastq.gz --maxHashResizeThreads 2 -i /u/user/ref/cellranger/salmon/transcripts_index --tgMap tx2gene.txt; [Thread debugging using libthread_db enabled]; Using host libthread_db library ""/lib/x86_64-linux-gnu/libthread_db.so.1"".; warning: File ""/u/user/local/lib64/libstdc++.so.6.0.21-gdb.py"" auto-loading has been declined by your `auto-load safe; -path' set to ""$debugdir:$datadir/auto-load"".; To enable execution of this file add; add-auto-load-safe-path /u/user/local/lib64/libstdc++.so.6.0.21-gdb.py; line to your configuration file ""/u/user/.gdbinit"".; To completely disable this security protection add; set auto-load safe-path /; line to your configuration file ""/u/user/.gdbinit"".; For more information about this security protection see the; ""Auto-loading safe path"" section in the GDB manual. E.g., run from the shell:; info ""(gdb)Auto-loading safe path""; [New Thread 0x7fff7dbff700 (LWP 21437)]; [Thread 0x7fff7dbff700 (LWP 21437) exited]; Version Info: Could not resolve upgrade information in the alotted time.; Check for upgrades manually at https://combine-lab.github.io/salmon; [New Thread 0x7ffefcfff700 (LWP 21653)]; Logs will be written to BM_1/alevin/logs; [New Thread 0x7ffe7cffe700 (LWP 21654)]; [New Thread 0x7ffdfcffd700 (LWP 21655)]; [New Thread 0x7ffd7cffc700 (LWP 21656)]; ### salmon (single-cell-based) v0.10.3; ### [ program ] => salmon; ### [ command ] => alevin; ### [ libType ] => { ISR }; ### [ chromium ] => { }; ### [ threads ] => { 4 }; ### [ output ] => { BM_1/alevin }; ### [ mates1 ] =",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-396078627:1939,configurat,configuration,1939,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-396078627,1,['configurat'],['configuration']
Deployability,"terminate called without an active exception; ) = 45; rt_sigprocmask(SIG_UNBLOCK, [ABRT], NULL, 8) = 0; write(3, ""[2017-04-05 16:24:37.940] [joint""..., 136) = 136; tgkill(32681, 32681, SIGABRT) = 0; --- SIGABRT (Aborted) @ 0 (0) ---; +++ killed by SIGABRT (core dumped) +++; ```; and for task 2:. ```; execve(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon"", [""/dcl01/lieber/ajaffe/Emily/RNAse""..., ""quant"", ""-i"", ""/dcl01/lieber/ajaffe/Emily/RNAse""..., ""-p"", ""1"", ""-l"", ""ISR"", ""-1"", ""/dcl01/lieber/ajaffe/lab/libd_al""..., ""-2"", ""/dcl01/lieber/ajaffe/lab/libd_al""..., ""-o"", ""/dcl01/lieber/ajaffe/lab/libd_al""...], [/* 107 vars */]) = 0; brk(0) = 0xc2c000; mmap(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7fffbfffd000; readlink(""/proc/self/exe"", ""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon"", 4096) = 88; access(""/etc/ld.so.preload"", R_OK) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/tls/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/tls/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/tls/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/tls"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:41447,pipeline,pipeline,41447,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,1,['pipeline'],['pipeline']
Deployability,"terminate called without an active exception; ) = 45; rt_sigprocmask(SIG_UNBLOCK, [ABRT], NULL, 8) = 0; write(3, ""[2017-04-05 16:40:15.587] [joint""..., 136) = 136; tgkill(51996, 51996, SIGABRT) = 0; --- SIGABRT (Aborted) @ 0 (0) ---; +++ killed by SIGABRT (core dumped) +++; ```. and for task 2:. ```; execve(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon"", [""/dcl01/lieber/ajaffe/Emily/RNAse""..., ""quant"", ""-i"", ""/dcl01/lieber/ajaffe/Emily/RNAse""..., ""-p"", ""1"", ""-l"", ""ISR"", ""-1"", ""/dcl01/lieber/ajaffe/lab/libd_al""..., ""-2"", ""/dcl01/lieber/ajaffe/lab/libd_al""..., ""-o"", ""/dcl01/lieber/ajaffe/lab/libd_al""...], [/* 107 vars */]) = 0; brk(0) = 0xc2c000; mmap(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7fffbfffd000; readlink(""/proc/self/exe"", ""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon"", 4096) = 88; access(""/etc/ld.so.preload"", R_OK) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/tls/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/tls/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/tls/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/tls"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:122410,pipeline,pipeline,122410,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,1,['pipeline'],['pipeline']
Deployability,"th and trying to run “salmon –version” I get the following error:. dyld: lazy symbol binding failed: Symbol not found: _os_unfair_lock_lock. Referenced from: /Users/douglasbarrows/Tools/salmon_0.11.4-pre_OSX/bin/./salmon (which was built for Mac OS X 10.13). Expected in: /usr/lib/libSystem.B.dylib. dyld: Symbol not found: _os_unfair_lock_lock. Referenced from: /Users/douglasbarrows/Tools/salmon_0.11.4-pre_OSX/bin/./salmon (which was built for Mac OS X 10.13). Expected in: /usr/lib/libSystem.B.dylib. Trace/BPT trap: 5. Is that something you have seen before?. From: Rob Patro <notifications@github.com>; Reply-To: COMBINE-lab/salmon <reply@reply.github.com>; Date: Tuesday, October 23, 2018 at 8:25 PM; To: COMBINE-lab/salmon <salmon@noreply.github.com>; Cc: dougbarrows <dbarrows@mail.rockefeller.edu>, Author <author@noreply.github.com>; Subject: Re: [COMBINE-lab/salmon] Segmentation fault 11 with bioconda build (#303). Thanks for reporting this. It seems there is an osx bioconda issue (likely related to their massive backend upgrade). Hopefully we can fix this upstream in the next release. I. The meantime, can you see if this<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_COMBINE-2Dlab_salmon_files_2383948_salmon-5F0.11.4-2Dpre-5FOSX.tar.gz&d=DwMFaQ&c=JeTkUgVztGMmhKYjxsy2rfoWYibK1YmxXez1G3oNStg&r=AcsC5BcigO3PFsA0uPOPf6vTyS2zaocuu4GaWSrIemY&m=wLNfpc7aJ_B1oE6XAqYsYKk5m7_TsLrkikeQql9eerg&s=40WTo4E4Odm5ZPLtYzGnDNBOb05l6L5woT7ke2vQ1L4&e=> OSX binary works for you?. —; You are receiving this because you authored the thread.; Reply to this email directly, view it on GitHub<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_COMBINE-2Dlab_salmon_issues_303-23issuecomment-2D432468434&d=DwMFaQ&c=JeTkUgVztGMmhKYjxsy2rfoWYibK1YmxXez1G3oNStg&r=AcsC5BcigO3PFsA0uPOPf6vTyS2zaocuu4GaWSrIemY&m=wLNfpc7aJ_B1oE6XAqYsYKk5m7_TsLrkikeQql9eerg&s=2d8a8eiQ0LuIlgyxoiTnsiwesaQ16X9sju0l7tT1WAw&e=>, or mute the thread<https://urldefense.proofpoint.com/v2/url?u=https-3A__gi",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/303#issuecomment-432469726:1084,upgrade,upgrade,1084,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/303#issuecomment-432469726,1,['upgrade'],['upgrade']
Deployability,"thank you @alpapan, your post in this open issue had the information that helped me build the latest version of salmon (1.10.0 at this time) on Ubuntu 20 and 22. The documentation at https://salmon.readthedocs.io/en/latest/building.html#requirements-for-building-from-source was not helping with the build errors reported here, which is what I encountered too. . In my case the problem was that I had a custom build of libstaden installed (that I did not want to remove) that cmake was picking up, but which triggered those many libcurl linking errors (misleadingly I would say, since it seems to be related to the way libstaden is installed, not directly libcurl related, which is fine on my system). Here it is the build recipe that worked for me on Ubuntu 20/22:; ```; sudo apt install libboost-iostreams-dev libboost-chrono-dev libboost-filesystem-dev \; libboost-timer-dev libboost-program-options-dev ; PREFIX=$HOME/sw # or wherever you want it; mkdir build && cd build; cmake -DNO_IPO=TRUE -DFETCH_STADEN=TRUE -DCMAKE_INSTALL_PREFIX=${PREFIX} ..; make -j6; make install; ```; Note that the installation message states:; `Please add $PREFIX/lib to your LD_LIBRARY_PATH` ; .. but that does not seem to be needed, the linker seems to resolve those libraries properly in the installation directory.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/425#issuecomment-1445139922:429,install,installed,429,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/425#issuecomment-1445139922,6,['install'],"['install', 'installation', 'installed']"
Deployability,"thanks. From: Rob Patro ***@***.***>; Reply-To: COMBINE-lab/salmon ***@***.***>; Date: Thursday, May 6, 2021 at 1:53 PM; To: COMBINE-lab/salmon ***@***.***>; Cc: ""andrew e. davidson"" ***@***.***>, Mention ***@***.***>; Subject: Re: [COMBINE-lab/salmon] salmon --writeUnmappedNames produced undocumented result (#657). Hi @aedavids<https://github.com/aedavids>,. Thanks for catching that this is undocumented! This means that the mapping type was determined as mapping to a decoy sequence. When we added this output into the code, the documentation wasn't updated accordingly. We'll update the documentation. Best,; Rob. —; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://github.com/COMBINE-lab/salmon/issues/657#issuecomment-833857753>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AN3VWAQ35L6PU3DKXYIM4ODTML6TPANCNFSM44HLOFXQ>.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/657#issuecomment-833861332:555,update,updated,555,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/657#issuecomment-833861332,2,['update'],"['update', 'updated']"
Deployability,"the most recent version of Salmon.; ### salmon (mapping-based) v0.8.2; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts }; ### [ threads ] => { 16 }; ### [ libType ] => { ISR }; ### [ mates1 ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/merged_fastq/R10001_D2B1WACXX.fastq.gz }; ### [ mates2 ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/merged_fastq/R10001_D2B1WACXX_read2.fastq.gz }; ### [ output ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test4/R10001_D2B1WACXX }; Logs will be written to /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test4/R10001_D2B1WACXX/logs; [1m[2017-03-29 14:56:39.675] [jointLog] [info] parsing read library format; [00m[1m[2017-03-29 14:56:39.733] [jointLog] [info] There is 1 library.; [00mterminate called without an active exception; /cm/local/apps/sge/var/spool/compute-067/job_scripts/110316: line 31: 64339 Aborted (core dumped) /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon quant -i /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts -p 16 -l ISR -1 ${FILE1} -2 ${FILE2} -o /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test4/${ID}; **** Job ends ****; Wed Mar 29 14:58:05 EDT 2017. ```. ### SGE email example info. ```; Job-array task 110316.1 (step6-salmon_test4.gsk_phaseII) Complete; User = lcollado; Queue = shared.q@compute-067.cm.cluster; Host = compute-067.cm.cluster; Start Time = 03/29/2017 14:53:42; End Time = 03/29/2017 14:58:05; User Time = 00:00:00; System Time = 00:05:39; Wallclock Time = 00:04:23; CPU = 00:05:39; Max vmem = 24.202G; Exit Status = 0; ```. Note that in this case, it didn't read the maximum memory requested (16 * 3 = 48 GB). ## Large memory, p 1. ### Bash. ```bash; #!/bin/bash; #$ -cwd; #$ -l mem_free=80G,h_vmem=90G,h_fsize=100G; #$",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-290516965:6475,pipeline,pipeline,6475,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-290516965,1,['pipeline'],['pipeline']
Deployability,"the suggestion, I've now been investigating the potential of an index-related issue. Firstly, I downloaded the pre-built salmon index from refgenie using `refgenie pull hg38/salmon_sa_index`. I then ran `salmon quant` using this index and the singularity image of salmon v1.9.0. What, would you know: it worked in about 11 minutes. ```; <truncated>; [2023-02-23 14:46:31.892] [jointLog] [info] Aggregating expressions to gene level; [2023-02-23 14:46:32.452] [jointLog] [info] done; ```. This pre-built index does appear to be decoy-aware:. ```; [2023-02-23 14:38:21.709] [jointLog] [info] Number of decoys : 195; [2023-02-23 14:38:21.709] [jointLog] [info] First decoy index : 177412 ; ```. Secondly, I created a new transcriptome-only salmon index (`singularity run -B /data $SALMON_SIMG salmon index -t genome.transcripts.fa -i salmon_index -k 31`), then ran `salmon quant` again (as above) but using the new transcriptome-only index. Note: 'genome.transcripts.fa' is the transcripts file created during the `nf-core/rnaseq` pipeline. Again, this analysis completed properly in a reasonable time. Seems like there is something very wrong with the 'gentrome.fa' file that's being created by `nf-core/rnaseq`! It's just so odd that _some_ samples would work and others wouldn't. 2. It's definitely worth noting that I originally opted against using `star_salmon` with the following command:. ```; nextflow run nf-core/rnaseq --max_memory 55.GB --fasta /data/reference_genomes/GRCh38/Homo_sapiens.GRCh38.dna_sm.primary_assembly.fa.gz --gtf /data/reference_genomes/GRCh38/Homo_sapiens.GRCh38.106.gtf.gz --skip_alignment --pseudo_aligner salmon --seq_center 'Ramaciotti Centre for Genomics' --input samplesheet.csv --outdir nf-core_results --save_merged_fastq true --skip_markduplicates true --extra_salmon_quant_args '--seqBias --gcBias --posBias' -profile singularity; ```. I'll re-run (a) using the refgenie salmon index specified; (b) with the `star_salmon` pathway to see if the decoy-aware index c",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/830#issuecomment-1441194948:1426,pipeline,pipeline,1426,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/830#issuecomment-1441194948,1,['pipeline'],['pipeline']
Deployability,"ting the index. It ensures that the index (and hence the resulting quantifications) contain the shortened names for gencode transcripts. In alignment-based mode, the behavior of the flag would have to be slightly different. It would have to re-normalize not only the names of the reference sequences in the fasta file, but it would also have to re-normalize the names in the BAM header so that they match. Specifically, the requirement is that the names of the sequences in the input fasta file are a 1-1 match with the names in the BAM header so that transcripts can be matched up properly with their sequences for training and applying the error model. However, if your BAM file already contains the stripped transcript names (i.e. if the BAM file header has the names without everything past the initial `|`), then I believe you can use the following command to have salmon do the same to the fasta file on the fly, so that the names match. ```{bash}; salmon-1.5.1_linux_x86_64/bin/salmon quant --ont -p 4 -t <(awk '{ if ($0 ~ ""^>"") { split($0,a,""|""); print a[1] } else { print $0 } }' Genome_files/gencode.vM24.transcripts.fa) -l U -a Documents/Day2_03_DRS_pass.bam -o Documents/counts/Day2_03_DRS_pass; ```. If the BAM file contains the ""full"" transcript name however, I think the current options are either to let salmon use the full transcript name from the fasta file, or to modify the GTF when running with minimap2, so that the BAM file itself contains the shortened names. Finally, I'd like to mention that the way you _intended_ to use the `--gencode` flag in alignment mode actually makes _a lot_ of sense, and I think it would be a very nice feature. Basically, the idea would be to apply stripping everything after the first `|` from *both* the fasta header and the BAM header, and using the reduced names for `quant.sf` outputs. We'll certainly. look into adding this functionality in a future release. Apologies for confusion caused by the ambiguous documentation of this flag. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/671#issuecomment-860792782:2101,release,release,2101,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/671#issuecomment-860792782,1,['release'],['release']
Deployability,"tory); open(""/jhpce/shared/community/core/jags/4.2.0/lib64/libc.so.6"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/jhpce/shared/community/compiler/gcc/4.4.7/netcdf/4.3.2/lib/libc.so.6"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/jhpce/shared/community/core/curl/7.43.0/lib/libc.so.6"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/cm/shared/apps/sge/2011.11p1/lib/linux-x64/libc.so.6"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/cm/shared/apps/sge/current/lib/linux-x64/libc.so.6"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/lib64/libc.so.6"", O_RDONLY) = 3; read(3, ""\177ELF\2\1\1\3\0\0\0\0\0\0\0\0\3\0>\0\1\0\0\0p\356\1\3427\0\0\0""..., 832) = 832; fstat(3, {st_mode=S_IFREG|0755, st_size=1926760, ...}) = 0; mmap(0x37e2000000, 3750152, PROT_READ|PROT_EXEC, MAP_PRIVATE|MAP_DENYWRITE, 3, 0) = 0x37e2000000; mprotect(0x37e218a000, 2097152, PROT_NONE) = 0; mmap(0x37e238a000, 20480, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_DENYWRITE, 3, 0x18a000) = 0x37e238a000; mmap(0x37e238f000, 18696, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_ANONYMOUS, -1, 0) = 0x37e238f000; close(3) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/libdl.so.2"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../lib/libdl.so.2"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/libdl.so.2"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/jhpce/shared/community/core/pcre/8.36/lib/libdl.so.2"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/jhpce/shared/community/core/jags/4.2.0/lib64/libdl.so.2"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/jhpce/shared/community/compiler/gcc/4.4.7/netcdf/4.3.2/lib/libdl.so.2"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:97239,pipeline,pipeline,97239,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,1,['pipeline'],['pipeline']
Deployability,"tory); open(""/jhpce/shared/community/core/jags/4.2.0/lib64/libc.so.6"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/jhpce/shared/community/compiler/gcc/4.4.7/netcdf/4.3.2/lib/libc.so.6"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/jhpce/shared/community/core/curl/7.43.0/lib/libc.so.6"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/cm/shared/apps/sge/2011.11p1/lib/linux-x64/libc.so.6"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/cm/shared/apps/sge/current/lib/linux-x64/libc.so.6"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/lib64/libc.so.6"", O_RDONLY) = 3; read(3, ""\177ELF\2\1\1\3\0\0\0\0\0\0\0\0\3\0>\0\1\0\0\0p\356\201\r5\0\0\0""..., 832) = 832; fstat(3, {st_mode=S_IFREG|0755, st_size=1926760, ...}) = 0; mmap(0x350d800000, 3750152, PROT_READ|PROT_EXEC, MAP_PRIVATE|MAP_DENYWRITE, 3, 0) = 0x350d800000; mprotect(0x350d98a000, 2097152, PROT_NONE) = 0; mmap(0x350db8a000, 20480, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_DENYWRITE, 3, 0x18a000) = 0x350db8a000; mmap(0x350db8f000, 18696, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_ANONYMOUS, -1, 0) = 0x350db8f000; close(3) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/libdl.so.2"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../lib/libdl.so.2"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/libdl.so.2"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/jhpce/shared/community/core/pcre/8.36/lib/libdl.so.2"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/jhpce/shared/community/core/jags/4.2.0/lib64/libdl.so.2"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/jhpce/shared/community/compiler/gcc/4.4.7/netcdf/4.3.2/lib/libdl.so.2"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:21907,pipeline,pipeline,21907,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,1,['pipeline'],['pipeline']
Deployability,"tory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/tls/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/tls/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/tls"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib"", {st_mode=S_IFDIR|0755, st_size=33280, ...}) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../lib/tls/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../lib/tls/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../lib/tls/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../lib/tls"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../lib/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/d",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:5739,pipeline,pipeline,5739,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,4,['pipeline'],['pipeline']
Deployability,"transcripts, whose estimated number of reads simply have _tremendous_ inferential uncertainty — and small perturbations in the initial conditions of the optimization will lead to different estimated values for their abundances. For those transcripts where you observe such fluctuations between runs, this is simply evidence that the precision that can be confidently placed on those estimates is below the degree of variation you observe. Treating these transcripts in downstream analysis as more certain can easily lead to spurious inferences regarding things like differential transcript expression or usage. . One can make an argument for trying to provide a way to enforce removal of this variation (which, granted, would be a challenge). However, the reason we decided against even attempting this is because it doesn't properly address any issue with respect to an actual biological analysis. That is, even if you could fix, precisely, the update order and initialization conditions for a specific sample to eliminate any variation between runs, almost all experiments consist of multiple samples. In other samples, the same transcript fractions could give rise to a slightly different set of observed fragments that induce exactly the same type of variation under uncertainty; and since that uncertainty is baked into the sample, it cannot and should not be removed. Having exact replication of a sample at a numerical threshold below the inferential uncertainty for a transcript conveys false confidence in the precision of the estimate. This is why, for transcript-level analysis, we highly recommend having salmon produce posterior gibbs samples (with the `--numGibbsSamples` flag). This will draw samples from the posterior distribution over the abundance estimates and allow determination of what inferences can be made robustly and what cannot. We have spent a good deal of time thinking about how to properly perform statistical inference on these uncertain quantities, and so I'd point ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/613#issuecomment-757989858:2654,update,update,2654,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/613#issuecomment-757989858,1,['update'],['update']
Deployability,"tting the reads 50/50 or, with the default settings, giving nearly all the reads to the longer transcript. I realized that, as a human, the reason the short transcript is obviously the dominant one is how the reads pileup in the alignment. There are hundreds of reads mapping to both transcripts, but NO reads map to the 5' of the long transcript. As I understand the selective alignment, the alignment scores are passed to the quantification step, but the *position* of the reads is not used downstream. In order to pass my human intuition along here, the software would need to pay attention to the coverage bias of the reads mapping to the transcripts and assign a penalty when two otherwise identical transcripts have a different coverage variance across the transcript. This sounds like what the --posBias flag should incorporate into the effective lengths, but it doesn't have much effect on these transcripts for me (FYI, I am getting a segfault when I run only --posBias in the current salmon version, but if I run all the models together like --gcBias --seqBias --posBias, it completes fine). . Also, my intuition for these transcripts is not really a coverage ""bias"" as much as the read depth absolutely plummeting at the 5' end of the long transcript. It would be neat if Salmon could detect these kinds of dramatic dropoffs and add a warning or something... even if not incorporating the information into the quants... it could even be a good QC step to identify large deletions/insertions over a gene body. As far as I know, there are NO rnaseq quant programs that would handle this, because even something like a STAR -> RSEM pipeline just projects read counts to the transcriptome and doesn't incorporate the coverage information. So, for now my workaround is to just modify the transcripts so they are non-overlapping in the transcriptome fasta or to manually count reads after looking at the alignments, but I'd love to hear any more thoughts you have on this problem. Thanks,; Jason",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-623043651:2158,pipeline,pipeline,2158,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-623043651,1,['pipeline'],['pipeline']
Deployability,"was not able to reproduce this yet. Here is my current output:. ```; [100%] Linking CXX executable salmon; ../../external/install/lib/libstaden-read.a(libstaden_read_la-open_trace_file.o): In function `find_file_url':; open_trace_file.c:(.text+0xec4): warning: the use of `tempnam' is dangerous, better use `mkstemp'; [100%] Built target salmon; root@e08cc9670e4a:/salmon-0.10.2/build# make install; [ 6%] Built target libdivsufsort; [ 12%] Built target libbz2; [ 17%] Built target liblzma; [ 24%] Built target libcereal; [ 31%] Built target libgff; [ 36%] Built target libbwa; [ 42%] Built target libstadenio; [ 48%] Built target libspdlog; [ 50%] Built target ksw2pp_sse4; [ 52%] Built target alevin_core; [ 55%] Built target ksw2pp_sse2; [ 60%] Built target ksw2pp_basic; [ 60%] Built target ksw2pp; [ 73%] Built target salmon_core; [ 77%] Built target unitTests; [100%] Built target salmon; Install the project...; -- Install configuration: ""Release""; -- Installing: /salmon-0.10.2/lib; -- Installing: /salmon-0.10.2/lib/libtbb.so; -- Installing: /salmon-0.10.2/lib/libtbbmalloc.so; -- Installing: /salmon-0.10.2/lib/libtbbmalloc_proxy.so; -- Installing: /salmon-0.10.2/lib/libtbbmalloc.so.2; -- Installing: /salmon-0.10.2/lib/libtbb.so.2; -- Installing: /salmon-0.10.2/lib/pkgconfig; -- Installing: /salmon-0.10.2/lib/libtbbmalloc_proxy.so.2; -- Installing: /salmon-0.10.2/bin/salmon; -- Installing: /salmon-0.10.2/lib/libsalmon_core.a. Installation complete. Please ensure the following paths are set properly.; ==========================================================================; Please add /salmon-0.10.2/bin to your PATH; Please add /salmon-0.10.2/lib to your LD_LIBRARY_PATH; ==========================================================================; root@e08cc9670e4a:/salmon-0.10.2/build# make test; Running tests...; Test project /salmon-0.10.2/build; Start 1: unit_tests; 1/3 Test #1: unit_tests ....................... Passed 0.17 sec; Start 2: salmon_read_test_fmd; 2/3 Test #",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/250#issuecomment-404306268:1043,Install,Installing,1043,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/250#issuecomment-404306268,1,['Install'],['Installing']
Deployability,"x81000) = 0x7fffbf746000; close(3) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/libgcc_s.so.1"", O_RDONLY) = 3; read(3, ""\177ELF\2\1\1\0\0\0\0\0\0\0\0\0\3\0>\0\1\0\0\0P\36\0\0\0\0\0\0""..., 832) = 832; mmap(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7fffbf4c4000; fstat(3, {st_mode=S_IFREG|0644, st_size=56072, ...}) = 0; mmap(NULL, 2151784, PROT_READ|PROT_EXEC, MAP_PRIVATE|MAP_DENYWRITE, 3, 0) = 0x7fffbf2b6000; mprotect(0x7fffbf2c3000, 2097152, PROT_NONE) = 0; mmap(0x7fffbf4c3000, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_DENYWRITE, 3, 0xd000) = 0x7fffbf4c3000; close(3) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/libc.so.6"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../lib/libc.so.6"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/libc.so.6"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/jhpce/shared/community/core/pcre/8.36/lib/libc.so.6"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/jhpce/shared/community/core/jags/4.2.0/lib64/libc.so.6"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/jhpce/shared/community/compiler/gcc/4.4.7/netcdf/4.3.2/lib/libc.so.6"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/jhpce/shared/community/core/curl/7.43.0/lib/libc.so.6"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/cm/shared/apps/sge/2011.11p1/lib/linux-x64/libc.so.6"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/cm/shared/apps/sge/current/lib/linux-x64/libc.so.6"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/lib64/libc.so.6"", O_RDONLY) = 3; read(3, ""\177ELF\2\1\1\3\0\0\0\0\0\0\0\0\3\0>\0\1\0\0\0p\356A\316;\0\0\0""..., 832) = 832; fstat(3, {st_mode=S_IFREG|0755,",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:57361,pipeline,pipeline,57361,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,2,['pipeline'],['pipeline']
Deployability,"x81000) = 0x7fffbf746000; close(3) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/libgcc_s.so.1"", O_RDONLY) = 3; read(3, ""\177ELF\2\1\1\0\0\0\0\0\0\0\0\0\3\0>\0\1\0\0\0P\36\0\0\0\0\0\0""..., 832) = 832; mmap(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7fffbf4c4000; fstat(3, {st_mode=S_IFREG|0644, st_size=56072, ...}) = 0; mmap(NULL, 2151784, PROT_READ|PROT_EXEC, MAP_PRIVATE|MAP_DENYWRITE, 3, 0) = 0x7fffbf2b6000; mprotect(0x7fffbf2c3000, 2097152, PROT_NONE) = 0; mmap(0x7fffbf4c3000, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_DENYWRITE, 3, 0xd000) = 0x7fffbf4c3000; close(3) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/libc.so.6"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../lib/libc.so.6"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/libc.so.6"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/jhpce/shared/community/core/pcre/8.36/lib/libc.so.6"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/jhpce/shared/community/core/jags/4.2.0/lib64/libc.so.6"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/jhpce/shared/community/compiler/gcc/4.4.7/netcdf/4.3.2/lib/libc.so.6"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/jhpce/shared/community/core/curl/7.43.0/lib/libc.so.6"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/cm/shared/apps/sge/2011.11p1/lib/linux-x64/libc.so.6"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/cm/shared/apps/sge/current/lib/linux-x64/libc.so.6"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/lib64/libc.so.6"", O_RDONLY) = 3; read(3, ""\177ELF\2\1\1\3\0\0\0\0\0\0\0\0\3\0>\0\1\0\0\0p\356\1\3427\0\0\0""..., 832) = 832; fstat(3, {st_mode=S_IFREG|0755",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:95821,pipeline,pipeline,95821,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,1,['pipeline'],['pipeline']
Deployability,"x81000) = 0x7fffbf746000; close(3) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/libgcc_s.so.1"", O_RDONLY) = 3; read(3, ""\177ELF\2\1\1\0\0\0\0\0\0\0\0\0\3\0>\0\1\0\0\0P\36\0\0\0\0\0\0""..., 832) = 832; mmap(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7fffbf4c4000; fstat(3, {st_mode=S_IFREG|0644, st_size=56072, ...}) = 0; mmap(NULL, 2151784, PROT_READ|PROT_EXEC, MAP_PRIVATE|MAP_DENYWRITE, 3, 0) = 0x7fffbf2b6000; mprotect(0x7fffbf2c3000, 2097152, PROT_NONE) = 0; mmap(0x7fffbf4c3000, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_DENYWRITE, 3, 0xd000) = 0x7fffbf4c3000; close(3) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/libc.so.6"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../lib/libc.so.6"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/libc.so.6"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/jhpce/shared/community/core/pcre/8.36/lib/libc.so.6"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/jhpce/shared/community/core/jags/4.2.0/lib64/libc.so.6"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/jhpce/shared/community/compiler/gcc/4.4.7/netcdf/4.3.2/lib/libc.so.6"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/jhpce/shared/community/core/curl/7.43.0/lib/libc.so.6"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/cm/shared/apps/sge/2011.11p1/lib/linux-x64/libc.so.6"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/cm/shared/apps/sge/current/lib/linux-x64/libc.so.6"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/lib64/libc.so.6"", O_RDONLY) = 3; read(3, ""\177ELF\2\1\1\3\0\0\0\0\0\0\0\0\3\0>\0\1\0\0\0p\356\201\r5\0\0\0""..., 832) = 832; fstat(3, {st_mode=S_IFREG|0755",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:20489,pipeline,pipeline,20489,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,1,['pipeline'],['pipeline']
Deployability,"x_test/salmon_0.8.2_index_gencode.v25.transcripts -p 1 -l ISR 	-1 ${FILE1} -2 ${FILE2} 	-o /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/${ID} 2> logs/strace_test12_${SGE_TASK_ID}.txt. echo ""**** Job ends ****""; date; ```. Again, here is the `strace` output for task 1 (411 lines):. ```; execve(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon"", [""/dcl01/lieber/ajaffe/Emily/RNAse""..., ""quant"", ""-i"", ""/dcl01/lieber/ajaffe/Emily/RNAse""..., ""-p"", ""1"", ""-l"", ""ISR"", ""-1"", ""/dcl01/lieber/ajaffe/lab/libd_al""..., ""-2"", ""/dcl01/lieber/ajaffe/lab/libd_al""..., ""-o"", ""/dcl01/lieber/ajaffe/lab/libd_al""...], [/* 107 vars */]) = 0; brk(0) = 0xc2c000; mmap(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7fffbfffd000; readlink(""/proc/self/exe"", ""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon"", 4096) = 88; access(""/etc/ld.so.preload"", R_OK) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/tls/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/tls/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/tls/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/tls"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:79910,pipeline,pipeline,79910,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,1,['pipeline'],['pipeline']
Deployability,"y precisely what you mean by reproducible? Do you mean that the values in the .sf file are not identical? If so, this is expected behavior. It exists for a number of reasons. The big one is that the initial phase of salmon uses an online inference algorithm so that specific details of the solution are dependent on the order in which the reads are processed (which is random given that multiple threads parse reads and update estimates asynchronously). However, the more important point here is that the inference estimates returned by Salmon (and, for that matter, every other transcript-level expression tool) are the result of a statistical optimization procedure that cannot guarantee a unique global optimal solution (and, in fact, even if a global optimum could be guaranteed, there may be multiple different optima). Thus, there is uncertainty inherent in the statistical problem being solved. Of course, if one ordered updates in the same way and set up the initial conditions precisely the same, there would be convergence to the same result, but any sense of confidence there is illusory. However, Salmon does provide a way to quantify, statistically, confidence in the result. The `--numBootstraps` option will do bootstrap sampling, or the `--numGibbsSamples` option will perform posterior Gibbs sampling. Both of these techniques will provide samples from the posterior distribution, and the variance of these samples will give you some information about the variance in the results that are due purely to the inherent statistical uncertainty in the problem. In the `scripts` folder there is a python script `ConvertBootstrapsToTSV.py` that will convert either the bootstrap or gibbs samples to a easily readable tsv format. These samples represent the estimated number of reads coming from each transcript when sampling from the posterior. These can be used to empirically estimate that statistical uncertainty in the abundance estimates of the different transcripts. Finally, I'll not",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/102#issuecomment-259464248:955,update,updates,955,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/102#issuecomment-259464248,1,['update'],['updates']
Deployability,"y); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/tls/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/tls/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/tls/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/tls"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib"", {st_mode=S_IFDIR|0755, st_size=33280, ...}) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../lib/tls/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../lib/tls/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../lib/tls/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../lib/tls"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:5575,pipeline,pipeline,5575,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,4,['pipeline'],['pipeline']
Deployability,"yes `--no-version-check` does the trick, but among all the users of the cluster I'm pretty sure some of them will forgot ;-). on our local installation I disabled the getVersionMessage even if salmon handle the no network cleanly. (I tested using `unshare -n salmon whatever you want`); NB debian maintainer also disabled the phone home call in their packages. sorry if it it may sound harsh",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/486#issuecomment-617310271:139,install,installation,139,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/486#issuecomment-617310271,1,['install'],['installation']
Deployability,"} -2 ${FILE2} 	-o /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/${ID} 2> logs/strace_${SGE_TASK_ID}.txt. echo ""**** Job ends ****""; date; ```. This requests SGE 2 cores with a total free memory of 2 * 7 = 14 GB and a maximum memory of 16 GB. This is the `strace` output for task 1:. ```; execve(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon"", [""/dcl01/lieber/ajaffe/Emily/RNAse""..., ""quant"", ""-i"", ""/dcl01/lieber/ajaffe/Emily/RNAse""..., ""-p"", ""1"", ""-l"", ""ISR"", ""-1"", ""/dcl01/lieber/ajaffe/lab/libd_al""..., ""-2"", ""/dcl01/lieber/ajaffe/lab/libd_al""..., ""-o"", ""/dcl01/lieber/ajaffe/lab/libd_al""...], [/* 107 vars */]) = 0; brk(0) = 0xc2c000; mmap(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7fffbfffd000; readlink(""/proc/self/exe"", ""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon"", 4096) = 88; access(""/etc/ld.so.preload"", R_OK) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/tls/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/tls/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/tls/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/tls"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:4577,pipeline,pipeline,4577,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,1,['pipeline'],['pipeline']
Energy Efficiency," --noLengthCorrection --validateMappings --numBootstraps 100 -l SF -i <path_to_SAF_Gentrome_Index> -r <SE_READ_1.fq> -o <salmon_SE_READ_1>`. I chose the above command line options (`especially --noLengthCorrection`) based on [Rob's message here](https://groups.google.com/d/msg/sailfish-users/VIfqBwgF6xQ/fw-rgC_kAwAJ) and a [thread here](https://github.com/COMBINE-lab/salmon/issues/108). Let me elaborate the big picture of my analyses and give more details about how I came up with the mapping numbers in my original post. Big Picture - DEG identification for samples sequenced by ILMN (whole transcript method) and QS (3' method) - [something similar to this paper](https://bmcgenomics.biomedcentral.com/articles/10.1186/s12864-018-5393-3). Bioinformatics Pipeline(s) for both ILMN and QS :. 1. HISAT Method : Adapter/Quality Trimming, Hisat2-HTSEQ, Get_Count_Table, DESeq; 2. STAR_RSEM Method: Adapter/Quality Trimming, STAR_RSEM, Get_Count_Table, DESeq; 3. SAF Method: Adapter/Quality Trimming, SAF_SALMON, Get_Count_Table, DESeq; 4. Quasi-Mapping or TXOME Method: Adapter/Quality Trimming, TXOME_SALMON, Get_Count_Table, DESeq. I used UpSetR plots for comparisons of sets of DEGs from each method just [as you have shown in your recent preprint](https://www.biorxiv.org/content/10.1101/657874v1.full). In the ILMN analyses, there is great concordance between the SAF method and HISAT/STAR_RSEM method. However, in the QS analyses, there is very limited concordance between SAF and the HISAT/STAR_RSEM method. For QS analyses, the TXOME method shows great concordance with HISAT/STAR_RSEM. This finding made me wonder if this has to be something with my salmon quant command line options for QS. Therefore, I wanted to check how the QS expected counts for SAF method show up for all samples in my final summarized table (after tximport). I got a colSum for all my samples and then checked the numbers for the transcripts and the decoys - this lead me to post my original question on this thread.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-554768195:1177,Adapt,Adapter,1177,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-554768195,1,['Adapt'],['Adapter']
Energy Efficiency," described in the Bowtie2 manual)](http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-dovetail) are considered discordant. This is the same default behavior imposed by Bowtie2. If you look in the `meta_info.json` file for some of these samples (which is in the `aux_info` subdirectory of the quantification directory for a sample), you can see how many mappings are being discarded by virtue of being dovetail mappings. It is possible to allow such alignments (consider them as concordant) by passing the `--allowDovetail` flag. It is not the case that such alignments are always ""bad"", its simply that one would not expect many fragments to align in such a way, and if these constitute the overwhelming majority of the mappings, one might be suspicious about the underlying data. * Selective alignment actually _aligns_ the reads to the transcriptome. For this purpose, it performs end-to-end alignment. This means that if you suspect that the sample may contain adapters or very low-quality read ends, the reads should be trimmed prior to quantification. It is, therefore, worth checking how the mapping rate changes for some of these samples if the reads are trimmed first. * Selective alignment is more robust than quasi-mapping to the chosen value of `-k`, the minimum match length used when searching for alignments. I noticed that some of the samples contain relatively short reads, so you might see if the mapping rate changes if you adopt a smaller value of `-k` in the index (e.g. we use `23` in the [pre-print](https://www.biorxiv.org/content/10.1101/657874v2.full.pdf)). * You mention that this index doesn't contain any decoy sequence. This of course, should not affect the mapping rate. However, I'd be quite curious to see if you index the reference using the _whole genome_ as decoy (i.e. the SAF method from the pre-print), how many reads are discarded because they map better to a decoy sequence (this information can also be obtained from `meta_info.json`). Thi",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/482#issuecomment-582734798:2780,adapt,adapters,2780,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/482#issuecomment-582734798,1,['adapt'],['adapters']
Energy Efficiency," it to some degree and matches the corresponding location on the genome. Again, you can test this by changing the required overlap fraction of FeatureCounts. * Why does running salmon outside of nf-core produce much higher counts?. * Since you are indexing *just* the transcriptome, and not including the genome as decoy sequence (as is done in nf-core), then the only thing that will prevent reads from being assigned to the gene in question is if so much of the read overhangs off the end of the annotated transcript that no mapping matches the minimum required alignment score. This is likely to be a much more liberal threshold than what STAR allows, so it also explains why you see higher counts than when alignment mode is used. * Other thoughts / suggestions?. * So, there are several things that you might consider doing if you believe the correct behavior in your case is to assign these reads to such genes. First, when run in mapping mode, salmon has a `--softclipOverhangs` flag that will further reduce the penalty for reads overhanging the annotated end of a transcript. This will allow more reads to map to the transcript even if they can't obtain a good alignment score. Likewise, you can combine this with further reducing the required minimum score using the `--minScoreFraction` [parameter](https://salmon.readthedocs.io/en/latest/salmon.html#minscorefraction). Finally, looking forward, we have developed and been testing even more comprehensive solutions to cases when one wants to allow large amounts of soft-clipping (see e.g. [this tutorial](https://combine-lab.github.io/salmon-tutorials/2021/softclip/)). While those features have not yet been migrated into the main salmon branch, you may find the tutorial instructive and the corresponding feature branch useful. If you believe that the annotations themselves are incomplete/incorrect and that may be leading to some of this behavior, you might consider augmenting or updating those annotations. Finally, I'd be reticent to",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/798#issuecomment-1237133883:3548,reduce,reduce,3548,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/798#issuecomment-1237133883,1,['reduce'],['reduce']
Energy Efficiency," low, but now there's somewhat of an explanation, the average read is shorter than a single k-mer. So, the next thing I tried was indexing with a smaller k; a _really_ small one in this case,`k=15`. Then, I re-ran on the _trimmed_ reads (the fact that the trimming took us from 51-21bp suggests that the reads had a lot of low quality bases, adapter contamination, or both). Under this setting, I still get a very low mapping rate, but it was _much_ higher — `16.766993524863488%`. The final thing I tried was seeing how the mapping rate changed as I altered `--minScoreFraction`, which is the salmon parameter that determines the alignment score that a read must achieve in order to be mapped validly. The default is 0.65. This means that the read cannot have a score < 0.65 * the maximum achievable score for the read given it's length. In the case of a 21bp read, the best score would be a score of 42, so a read must obtain a score >= 27 in order to be mapped. This is already a pretty poor mapping, but I reduced it even more to 0.3 (so any read with a score > 12 would pass). This led to a mapping rate of `~46%`. However, at this point, I'm not sure I would be confident in such mappings. For example, the situation here would be a 21bp read with multiple mismatches and, much of the time, one or more indels. So, my conclusion, at least on this sample, is that the main issue is data quality. Trimming the reads and indexing with a smaller k can lead to a mapping rate `~16%`, and then allowing _really bad_ alignments can take it up to `~45%` (and even more — when I set `--minScoreFraction` to 0.1, I get a mapping rate of `57%`). But the level of confidence that one might derive from poorly-aligned 21bp reads is (and probably should be) quite low. I can't say, of course, that this is the situation with the other samples, as I've not looked at them. However, for this sample, and likely for some or all of the others, there is likely a data quality issue. So, perhaps the first order of",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/482#issuecomment-583799668:2120,reduce,reduced,2120,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/482#issuecomment-583799668,1,['reduce'],['reduced']
Energy Efficiency," transcript by salmon) as well as to the genome. It is quite common that the mapping rate to the genome is higher than that to the transcriptome. This is much more a result of what you are aligning _to_ than the aligner. If you were to take the transcriptome, and align to it using Hisat2 with `--no-spliced-alignment` and `--end-to-end` (since there won't be splice junctions when you align to the transcriptome), I'd expect you to get a similar mapping rate as you see in salmon. > I also noticed a high number of mappings discarded because of alignment score. I also wonder why the number of mappings discarded can be larger than num of processed (57113760, the reads number in 1_1.fq.gz). . Good question. The number you are looking at is the number of discarded _mappings_, not the number of discarded _fragments_. The difference is that every fragment can have many potential mappings. The number you are looking at is the total number of attempted _alignments_ that failed to achieve the threshold score. Luckily, salmon reports both numbers. The number of fragments for which _all_ alignments failed to reach the score threshold is `4,196,417`; given in `aux_info.json` by ` ""num_fragments_filtered_vm"": 4196417`. One point to note is that these are all fragments for which mapping is attempted (they had at least one k-mer match the reference), but no alignment was valid up to the threshold. You could try running the quantification again with `--softclip` to allow softclipping of the reads and see if any considerable fraction of these `4196417` failed to align because they overhang the annotated transcripts or contain adapters etc. Nonetheless, even if all of these mapped, the rate would still be ~72%. The remainder of the reads didn't even have a matching k-mer in common with the reference transcriptome, which means they are exceedingly unlikely to have come from the transcripts that were indexed. > Thanks. You're welcome! Please let me know if you have any follow-up questions.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/533#issuecomment-697125235:2029,adapt,adapters,2029,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/533#issuecomment-697125235,1,['adapt'],['adapters']
Energy Efficiency," v0.8 and 1.2.1. The one that seems most relevant here is the introduction of selective-alignment to replace the quasi-mapping procedure that was originally used in salmon. Selective-alignment actually scores the mappings found to the transcriptome, and rejects alignments whose quality is below a (user-specified) threshold. Here, you can see that, in 1.2.1. * 39 fragments are mapped within the score threshold; * 216 fragments are discarded because no mapping location has an alignment score above the threshold. all together, this means that the total number of ""mapped"" fragments in 1.2.1 is very similar to 0.8 (1.2.1 maps 39+216 = 255, while 0.8 maps 254). However, 1.2.1 discards 216 of the fragments because no mapping is sufficiently good. The default for ""sufficiently good"", by the way, is to have an alignment score of at least 65% of the maximum possible for a read of the given length. For typical RNA-seq data, this is actually quite liberal / generous, and is similar to the type of noise in alignment that Bowtie2 allows with the sensitive flag. In general, the heuristics used in 1.2.1 (selective-alignment) tend to be more sensitive than those used in 0.8 (quasi-mapping), since the mappings are then validated using alignment scoring. However, this does mean that the quality of the alignment along the whole read matters. Thus, it is more important to do quality / adapter trimming in the newer version compared to the older one. There is also a flag in 1.2.1 (`--softclip`) that will allow mismatches / gaps at the ends of reads to not detract from the alignment score. So, these are the main differences. However, looking at the output logs you provided, a couple of basic questions did come to mind. Why are there so few reads to begin with? Even in 0.8, only 254 reads mapped, which is obviously a very small number of reads. Is there something non-typical about this sample? Is it a full RNA-seq sample? Are these reads something atypical (like long reads — ONT or PacBio)?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/542#issuecomment-651332239:1497,adapt,adapter,1497,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/542#issuecomment-651332239,1,['adapt'],['adapter']
Energy Efficiency," you linked (see attached logs). This certainly helped, although I'm still nowhere near a time-frame of ~30min. Here are my results:. The 31-mer running took a bit over an hour and consumed ~17GB of memory. This is about half the running time as the previous version, but approx. the same amount of memory requirement (more on that below). The 17-mer running, took 4.5hrs to complete and consumed ~64GB of memory. This particular running is again, about twice as fast, although the time really depends on the memory limitations I gave it. Since it appears that this version no longer crashes when given less than about 250GB of memory, I also tested with 32G and 16GB of memory, just to see what impact this would have on the times. Those jobs are still running (it's only been about 4hrs as of this writing, I'll update my post if/when they complete). Current logs are showing that they quickly consume all the available memory, but have not yet crashed. I've also got versions with 128-512GB of memory requested (by powers of 2) for comparison. Some random notes: both the 31-mer index experienced about twice as many soft page reclaims with the new/faster version and experienced a few hard page faults (the previous version saw none of the latter). The 17-mer version experienced fewer page reclaims than any of the 31-mer indices and far fewer than with the prior version. Again, a few page faults crept in, but relatively few by percentage and likely not contributing any significant amount of time overall. [index-qacct-17mer.log](https://github.com/COMBINE-lab/salmon/files/4246516/index-qacct-17mer.log); [index-qacct-31mer.log](https://github.com/COMBINE-lab/salmon/files/4246517/index-qacct-31mer.log). **UPDATE**; The 16GB version finished running. It actually only took a little over 4 hours to run, as well. The troubling thing about this job seems to be that, despite having successfully completed, according to the accounting log it used over 20GB of memory... which should be impossib",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/476#issuecomment-590516702:1098,power,powers,1098,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/476#issuecomment-590516702,1,['power'],['powers']
Energy Efficiency,"**_I could be wrong here with my next line_** - [Based on Figure 1 of this paper, it looks to me as though quality trimming is done before adapter trimming](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6129281/figure/bty560-F1/). - [To quote Brian Bushnell (author of BBTools)]( http://seqanswers.com/forums/showpost.php?p=140819&postcount=5), . > It's best to do adapter-trimming first, then quality-trimming, because if you do quality-trimming first, sometimes adapters will be partially trimmed and become too short to be recognized as adapter sequence. When you run BBDuk with both quality-trimming and adapter-trimming in the same run, it will do adapter-trimming first, then quality-trimming. 2. I very well know that the advantage of using fastp is that it can do adapter trimming, etc in a automatic fashion - no need to provide external sequences (example adapter sequences). Yes, I know one can also provide a fasta file of adapters and fatsp will work off it. There are many fatsp issues in GH about adapter detection:. - fail to detect adpaters automatically - (https://github.com/OpenGene/fastp/issues/222 and https://github.com/OpenGene/fastp/issues/205). - [incorrect automatic adapter detection](https://github.com/OpenGene/fastp/issues/240). - [inconsistent behavior with different runs](https://github.com/OpenGene/fastp/issues/231). 3. When I see the above, I am bit skeptical using fastp for qc/adapter trimming. . After lot of trials with bbduk and fastp, I have decided to use bbduk and bbmap for my high throughput analysis. Below, I explain my reasoning behind those choices: . **_```Note - edited this on 02-Apr-2020 to have the correct order of operations ```_** . 1. **_STEP 1 - run bbmap.sh on raw fatsq file to remove contaminants as appropriate (rRNA, mitochondrial, chloroplast)_**; - You have alluded to the importance of removing contaminants [in this post](https://github.com/COMBINE-lab/salmon/issues/160#issuecomment-334762498); >However, the other thing to try is",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-597393209:1401,adapt,adapter,1401,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-597393209,1,['adapt'],['adapter']
Energy Efficiency,", sampleRoundNonCollapsedMultithreaded_(std::vector<std::pair<TranscriptGroup const, TGValue>, std::allocator<std::pair<TranscriptGroup const, TGValue> > >&, std::vector<bool, std::allocator<bool> >&, std::vector<unsigned long, std::allocator<unsigned long> >&, std::vector<double, std::allocator<double> >&, std::vector<double, std::allocator<double> >&, Eigen::Matrix<double, -1, 1, 0, -1, 1>&, std::vector<double, std::allocator<double> > const&, std::vector<double, std::allocator<double> >&, std::vector<unsigned int, std::allocator<unsigned int> >&)::{lambda(tbb::blocked_range<unsigned long> const&)#2}, tbb::auto_partitioner const>::execute() (); #3 0x00007f20171ca492 in tbb::internal::custom_scheduler<tbb::internal::IntelSchedulerTraits>::local_wait_for_all (this=0x7f1fd8dc0c00, parent=..., child=<optimized out>); at ../../src/tbb/custom_scheduler.h:469; #4 0x00007f20171c85a0 in tbb::internal::generic_scheduler::local_spawn_root_and_wait (this=0x7f1fd8dc0c00, first=..., next=@0x7f1fd8db7d38: 0x7f1fd8db7340); at ../../src/tbb/scheduler.cpp:649; #5 0x0000000000632eba in sampleRoundNonCollapsedMultithreaded_(std::vector<std::pair<TranscriptGroup const, TGValue>, std::allocator<std::pair<TranscriptGroup const, TGValue> > >&, std::vector<bool, std::allocator<bool> >&, std::vector<unsigned long, std::allocator<unsigned long> >&, std::vector<double, std::allocator<double> >&, std::vector<double, std::allocator<double> >&, Eigen::Matrix<double, -1, 1, 0, -1, 1>&, std::vector<double, std::allocator<double> > const&, std::vector<double, std::allocator<double> >&, std::vector<unsigned int, std::allocator<unsigned int> >&) (); #6 0x000000000063936f in bool CollapsedGibbsSampler::sample<ReadExperiment>(ReadExperiment&, SalmonOpts&, std::function<bool (std::vector<double, std::allocator<double> > const&)>&, unsigned int) (); #7 0x000000000065d783 in salmonQuantify(int, char**) (); #8 0x000000000057dbcf in main (); Detaching from program: /home/ryan/bin/salmon, process 29153; ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267534520:3099,schedul,scheduler,3099,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267534520,1,['schedul'],['scheduler']
Energy Efficiency,"--noLengthCorrection --validateMappings --numBootstraps 100 -l SF -i <path_to_SAF_Gentrome_Index> -r <SE_READ_1.fq> -o <salmon_SE_READ_1>`. I chose the above command line options (`especially --noLengthCorrection`) based on [Rob's message here](https://groups.google.com/d/msg/sailfish-users/VIfqBwgF6xQ/fw-rgC_kAwAJ) and a [thread here](https://github.com/COMBINE-lab/salmon/issues/108). Let me elaborate the big picture of my analyses and give more details about how I came up with the mapping numbers in my original post. Big Picture - DEG identification for samples sequenced by ILMN (whole transcript method) and QS (3' method) - [something similar to this paper](https://bmcgenomics.biomedcentral.com/articles/10.1186/s12864-018-5393-3). Bioinformatics Pipeline(s) for both ILMN and QS :. 1. HISAT Method : Adapter/Quality Trimming, Hisat2-HTSEQ, Get_Count_Table, DESeq; 2. STAR_RSEM Method: Adapter/Quality Trimming, STAR_RSEM, Get_Count_Table, DESeq; 3. SAF Method: Adapter/Quality Trimming, SAF_SALMON, Get_Count_Table, DESeq; 4. Quasi-Mapping or TXOME Method: Adapter/Quality Trimming, TXOME_SALMON, Get_Count_Table, DESeq. I used UpSetR plots for comparisons of sets of DEGs from each method just [as you have shown in your recent preprint](https://www.biorxiv.org/content/10.1101/657874v1.full). In the ILMN analyses, there is great concordance between the SAF method and HISAT/STAR_RSEM method. However, in the QS analyses, there is very limited concordance between SAF and the HISAT/STAR_RSEM method. For QS analyses, the TXOME method shows great concordance with HISAT/STAR_RSEM. This finding made me wonder if this has to be something with my salmon quant command line options for QS. Therefore, I wanted to check how the QS expected counts for SAF method show up for all samples in my final summarized table (after tximport). I got a colSum for all my samples and then checked the numbers for the transcripts and the decoys - this lead me to post my original question on this thread.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-554768195:1273,Adapt,Adapter,1273,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-554768195,1,['Adapt'],['Adapter']
Energy Efficiency,"-zero). Thus, if the only mapping for a read disagrees with the expected type, it will still be used. There is a way to modify this behavior, but since stranded library prep is imperfect, the default behavior is the most reasonable for most situations. The reason that you'll see consistency in most cases, regardless of the library type, is as follows. Imagine that I have a read that maps to transcript 1 in the forward orientation and transcript 2 in the reverse orientation. Further, imagine I have a stranded library, and I expect all reads to map in the reverse orientation. If the mapping to transcript 1 is ""spurious"", there are unlikely to be many othe reads mapping to that transcript in this manner, while we would expect other reads to map to transcript 2 in the prescribed manner. Since Salmon considers all of the reads in its probabilistic model when deciding how each read should be allocated, the fact that many reads map to transcript 2 will increase its abundance and, likewise, increase the probability that we assign this read to transcript 2 --- that is, the other mappings will help us make the right choice, regardless of the fact that we neglected to assign a stranded library type. That said, there are situations where the library type makes a difference. This is most often for a few transcripts that are very sequence similar (e.g. Paralogs that happen to be on opposite strands). In this case, most of the reads that map to one transcript will map to the other as well. In this case, the much larger conditional probability of agreeing with the prescribed library type will cause these reads to be allocated to the transcript to which they map in the expected orientation. However, the fraction of such transcripts is usually a small proportion of all expressed transcripts in an experiment, which is why, even if you do have a stranded library and some strand-specific expression, you'd expect the overall concordance to be very high between runs with different provide",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/67#issuecomment-238090033:1479,allocate,allocated,1479,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/67#issuecomment-238090033,1,['allocate'],['allocated']
Energy Efficiency,"/PMC6129281/figure/bty560-F1/). - [To quote Brian Bushnell (author of BBTools)]( http://seqanswers.com/forums/showpost.php?p=140819&postcount=5), . > It's best to do adapter-trimming first, then quality-trimming, because if you do quality-trimming first, sometimes adapters will be partially trimmed and become too short to be recognized as adapter sequence. When you run BBDuk with both quality-trimming and adapter-trimming in the same run, it will do adapter-trimming first, then quality-trimming. 2. I very well know that the advantage of using fastp is that it can do adapter trimming, etc in a automatic fashion - no need to provide external sequences (example adapter sequences). Yes, I know one can also provide a fasta file of adapters and fatsp will work off it. There are many fatsp issues in GH about adapter detection:. - fail to detect adpaters automatically - (https://github.com/OpenGene/fastp/issues/222 and https://github.com/OpenGene/fastp/issues/205). - [incorrect automatic adapter detection](https://github.com/OpenGene/fastp/issues/240). - [inconsistent behavior with different runs](https://github.com/OpenGene/fastp/issues/231). 3. When I see the above, I am bit skeptical using fastp for qc/adapter trimming. . After lot of trials with bbduk and fastp, I have decided to use bbduk and bbmap for my high throughput analysis. Below, I explain my reasoning behind those choices: . **_```Note - edited this on 02-Apr-2020 to have the correct order of operations ```_** . 1. **_STEP 1 - run bbmap.sh on raw fatsq file to remove contaminants as appropriate (rRNA, mitochondrial, chloroplast)_**; - You have alluded to the importance of removing contaminants [in this post](https://github.com/COMBINE-lab/salmon/issues/160#issuecomment-334762498); >However, the other thing to try is simply to align one of these samples to the genome with a tool like STAR or HISAT2 and look at their mapping rate to known features. If it's similar, then the other reads could be accounted for by ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-597393209:1583,adapt,adapter,1583,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-597393209,1,['adapt'],['adapter']
Energy Efficiency,"/conda/core/subdir_data.py"", line 210, in load; _internal_state = self._load(); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/conda/core/subdir_data.py"", line 375, in _load; raw_repodata_str = fetch_repodata_remote_request(; File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/conda/core/subdir_data.py"", line 701, in fetch_repodata_remote_request; resp = session.get(join_url(url, filename), headers=headers, proxies=session.proxies,; File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/requests/sessions.py"", line 542, in get; return self.request('GET', url, **kwargs); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/requests/sessions.py"", line 529, in request; resp = self.send(prep, **send_kwargs); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/requests/sessions.py"", line 645, in send; r = adapter.send(request, **kwargs); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/requests/adapters.py"", line 413, in send; conn = self.get_connection(request.url, proxies); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/requests/adapters.py"", line 308, in get_connection; raise InvalidProxyURL(""Please check proxy URL. It is malformed""; requests.exceptions.InvalidProxyURL: Please check proxy URL. It is malformed and could be missing the host. `$ /usr/local/bin/conda install salmon`. environment variables:; CIO_TEST=<not set>; CONDA_ROOT=/usr/local/Caskroom/miniforge/base; CURL_CA_BUNDLE=<not set>; INFOPATH=/opt/homebrew/share/info:; MANPATH=/opt/homebrew/share/man::; PATH=/opt/homebrew/bin:/opt/homebrew/sbin:/usr/local/bin:/usr/bin:/bin:/usr; /sbin:/sbin; REQUESTS_CA_BUNDLE=<not set>; SSL_CERT_FILE=<not set>; all_proxy=<set>. active environment : None; user config file : /Users/Benjamin/.condarc; populated config files : /usr/local/Caskroom/miniforge/base/.condarc; conda version : 4.12.0; conda-build version : not installed; python version : 3.9.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/724#issuecomment-1171208515:4522,adapt,adapters,4522,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/724#issuecomment-1171208515,1,['adapt'],['adapters']
Energy Efficiency,"; mmap(NULL, 1073745920, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_STACK, -1, 0) = 0x7ffbbe5dd000; mprotect(0x7ffbbe5dd000, 4096, PROT_NONE) = 0; clone(child_stack=0x7ffbfe5dced0, flags=CLONE_VM|CLONE_FS|CLONE_FILES|CLONE_SIGHAND|CLONE_THREAD|CLONE_SYSVSEM|CLONE_SETTLS|CLONE_PARENT_SETTID|CLONE_CHILD_CLEARTID, parent_tidptr=0x7ffbfe5dd9d0, tls=0x7ffbfe5dd700, child_tidptr=0x7ffbfe5dd9d0) = 10754; mmap(NULL, 1073745920, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_STACK, -1, 0) = -1 ENOMEM (Cannot allocate memory); futex(0x7fffbf4c3350, FUTEX_WAKE_PRIVATE, 2147483647) = 0; write(2, ""terminate called without an acti""..., 45terminate called without an active exception; ) = 45; rt_sigprocmask(SIG_UNBLOCK, [ABRT], NULL, 8) = 0; write(3, ""[2017-04-05 16:24:38.504] [joint""..., 136) = 136; tgkill(10693, 10693, SIGABRT) = 0; --- SIGABRT (Aborted) @ 0 (0) ---; +++ killed by SIGABRT (core dumped) +++; ```. (371 lines for task 1, 368 for task 2). Basically, both fail at a point where `mmap()` cannot allocate memory. So it definitely looks like a memory issue and I don't know if these information gives you any hints. . ## Bumping memory. Bumping the memory request to 28/30GB. This is a scenario where task 2 seems to work ok but tasks 1 and 3 fail. ```bash; #!/bin/bash; #$ -cwd; #$ -pe local 2; #$ -l mem_free=14G,h_vmem=15G,h_fsize=100G; #$ -N step6-salmon_test12.gsk_phaseII; #$ -o ./logs/salmon_test12.$TASK_ID.txt; #$ -e ./logs/salmon_test12.$TASK_ID.txt; #$ -t 1-3; #$ -hold_jid pipeline_setup,step4-featCounts-alzheimer.gsk_phaseII; #$ -m e; echo ""**** Job starts ****""; date. echo ""**** JHPCE info ****""; echo ""User: ${USER}""; echo ""Job id: ${JOB_ID}""; echo ""Job name: ${JOB_NAME}""; echo ""Hostname: ${HOSTNAME}""; echo ""Task id: ${TASK_ID}"". FILE1=$(awk 'BEGIN {FS=""\t""} {print $1}' /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk ""NR==${SGE_TASK_ID}""); if [ TRUE == ""TRUE"" ] ; then; FILE2=$(awk 'BEGIN {FS=""\t""} {print $3}' /dcl01/lieber/ajaffe/lab/",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:77455,allocate,allocate,77455,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,1,['allocate'],['allocate']
Energy Efficiency,"@GWW,. First, thanks for trying this out and for filing the report. We're eager to reproduce this, figure out what's going on, and fix it. It's theoretically possible to use something like [cgroups](http://man7.org/linux/man-pages/man7/cgroups.7.html) to limit the number of threads that the process could even allocate. However, it really should not be allocating more threads than are being given (+1 for the asynchronous logger thread). Can you please provide some details about the specific OS and version you're running on where you are seeing this behavior?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-395826503:311,allocate,allocate,311,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-395826503,1,['allocate'],['allocate']
Energy Efficiency,"@ctb — One thing that would be required for this (apart from some engineering of the command-line parsing / validation code) is a trustworthy, efficient, _multithreaded_ `FAST(A/Q)` parser for interleaved format reads. Right now, Salmon (& Sailfish, &RapMap, & most of the other HTS-centric methods we're developing) use the Jellyfish 2 read parser. I've made this choice since it's fairly simple to use, yet provides nice parallel performance and, most importantly, is fairly well-tested and trust-worthy. Can you suggest a reliable, well-tested, concurrency-enabled library for parsing reads in interleaved format?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/29#issuecomment-152827801:143,efficient,efficient,143,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/29#issuecomment-152827801,1,['efficient'],['efficient']
Energy Efficiency,"@k3yavi It seems like indexing both mature and un-spliced transcripts in one index, quantifying them jointly, and then post processing (re-normalizing) the two feature types could be a bit more efficient. Is there any obvious advantage to explicitly specifying which features are decoys vs. mapping and quantifying everything in one go?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/450#issuecomment-555288890:194,efficient,efficient,194,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/450#issuecomment-555288890,1,['efficient'],['efficient']
Energy Efficiency,"@rob-p I would request that you try out bbduk and bbmap for quality/adapter trimming and contaminant removal.; > Thank you for verifying @zhangchipku, For the time being, I can recommend `fastp` as a fairly efficient / fast trimmer that. It might even be able to work in a streaming fashion so that you could pipe the trimmed reads directly to salmon.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-592995074:68,adapt,adapter,68,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-592995074,2,"['adapt', 'efficient']","['adapter', 'efficient']"
Energy Efficiency,"@rob-p thanks for merging! I wish the Travis CI's lint task helps to fix the warnings, and keep the consistent format of `cmake` files!; Eventually we will see the green color passing the lint check on the Travis CI page :)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/293#issuecomment-424512831:164,green,green,164,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/293#issuecomment-424512831,1,['green'],['green']
Energy Efficiency,"@zhangchipku,. Yes, it seems that the biggest culprit here is `num_fragments_filtered_vm`. That is the number of fragments filtered because the best alignment failed to reach the threshold for a ""valid"" alignment. Here, `47,470,013` fragments are discarded entirely because they didn't have an alignment meeting the required quality. If these fragments (which do have matching MEMs, because alignment was carried out for them) were mapped, then the overall mapping rate would go up to `50,729,814 + 47,470,013 = 98,199,827 / 107,275,750 = ~91.5%`. Now, I wouldn't expect _all_ of these to be mappable, and some alignments might not be feasible at any reasonable quality whatsoever. My recommendation would be as follows. First, have you trimmed these reads (using e.g. `fastp` or `TrimGalore` or some such)? Very low quality read ends or (more likely) adapter contamination could cause the reads that have matching MEMs to fail to align within the required score threshold. My first recommendation would be to trim the reads and see how the mapping rate changes. Second, the required alignment score is a user-alterable parameter. By changing `--minScoreFraction` to be lower, you can allow reads with even lower alignment scores to be counted for quantification. The default value is `0.65`, so you could explore what happens if you lower this number. The number represents the fraction of the maximum achievable alignment score that a read must obtain to be considered a valid alignment. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-586473052:852,adapt,adapter,852,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-586473052,1,['adapt'],['adapter']
Energy Efficiency,"A follow up on this (with a lot of help from @raungar; thanks!) led to the conclusion that the problem was that insufficient memory was allocated to the cluster job during indexing (indexing this transcriptome takes ~4.3G). Allocating more memory to the job resolves the issue. The strange thing is that the cluster manager seemed to kill the job rather than refuse to allocate the memory (which would have resulted in a `bad_alloc` exception that would have made the problem clear). So, if you're indexing with salmon on a cluster and see this behavior, be aware of the memory allocation and that the cluster software may surreptitiously kill the process rather than simply fail to allocate the memory!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/197#issuecomment-467720836:136,allocate,allocated,136,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/197#issuecomment-467720836,3,['allocate'],"['allocate', 'allocated']"
Energy Efficiency,"Actually that's a very nice idea! Thanks for sharing it. If we can modularize it into multiple independent components that would reduce the overall complexity and might help differentiate the use cases. I'll definitely raise this in our next alevin meeting. Although, it might take some time to get back regarding this but I will poke back here once we have some progress. Thanks again !",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/379#issuecomment-503646040:129,reduce,reduce,129,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/379#issuecomment-503646040,1,['reduce'],['reduce']
Energy Efficiency,"Actually, ; I was wondering if I could use this method to help me quantify my Nanopore library with barcode sequence?; I have already demultiplexed the ONT library to each individual barcode by using some other tools and generated a meta table with matched barcode and readID.; It would be great if you guys have any ideas on how can I generate a barcode-gene count matrix from it.; My current workflow is aligning via minimap2 and subset the bam file to each barcode by matching the readID, and use Salmon or other tools to quantify the counts, and compile the matrix together. But it took a very long time and memory.; Maybe there's another more efficient way.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/920#issuecomment-2014070596:648,efficient,efficient,648,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/920#issuecomment-2014070596,1,['efficient'],['efficient']
Energy Efficiency,"B_INCLUDE_DIRS-ADVANCED:INTERNAL=1; //ADVANCED property for variable: TBB_LIBRARY; TBB_LIBRARY-ADVANCED:INTERNAL=1; //ADVANCED property for variable: TBB_LIBRARY_DEBUG; TBB_LIBRARY_DEBUG-ADVANCED:INTERNAL=1; //ADVANCED property for variable: TBB_LIBRARY_DIRS; TBB_LIBRARY_DIRS-ADVANCED:INTERNAL=1; //ADVANCED property for variable: TBB_MALLOC_LIBRARY; TBB_MALLOC_LIBRARY-ADVANCED:INTERNAL=1; //ADVANCED property for variable: TBB_MALLOC_LIBRARY_DEBUG; TBB_MALLOC_LIBRARY_DEBUG-ADVANCED:INTERNAL=1; ```. Also, here's the output of every hardware/OS reporting command I can think of:. ```; $ cat /proc/cpuinfo; processor : 0; vendor_id : GenuineIntel; cpu family : 6; model : 63; model name : Intel(R) Xeon(R) CPU E5-2623 v3 @ 3.00GHz; stepping : 2; microcode : 0x36; cpu MHz : 3300.000; cache size : 10240 KB; physical id : 0; siblings : 8; core id : 0; cpu cores : 4; apicid : 0; initial apicid : 0; fpu : yes; fpu_exception : yes; cpuid level : 15; wp : yes; flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36; clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc; arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqd; q dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid dca sse4_1 sse4; _2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm epb tpr_sh; adow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid cqm x; saveopt cqm_llc cqm_occup_llc dtherm ida arat pln pts; bugs :; bogomips : 5985.57; clflush size : 64; cache_alignment : 64; address sizes : 46 bits physical, 48 bits virtual; power management:; ...; [And 7 more cores]; $ uname -a; Linux salomon24 4.4.0-51-generic #72-Ubuntu SMP Thu Nov 24 18:29:54 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux; $ lsb_release -d; Description: Ubuntu 16.04.1 LTS; ```. lshw output: [salomon24-lshw.txt](https://github.com/COMBINE-lab/salmon/files/650904/salomon24-lshw.txt)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-266953657:2266,monitor,monitor,2266,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-266953657,2,"['monitor', 'power']","['monitor', 'power']"
Energy Efficiency,"E_SETTLS|CLONE_PARENT_SETTID|CLONE_CHILD_CLEARTID, parent_tidptr=0x7ff97e5d39d0, tls=0x7ff97e5d3700, child_tidptr=0x7ff97e5d39d0) = 52022; mmap(NULL, 1073745920, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_STACK, -1, 0) = 0x7ff8fe5d2000; mprotect(0x7ff8fe5d2000, 4096, PROT_NONE) = 0; clone(child_stack=0x7ff93e5d1ed0, flags=CLONE_VM|CLONE_FS|CLONE_FILES|CLONE_SIGHAND|CLONE_THREAD|CLONE_SYSVSEM|CLONE_SETTLS|CLONE_PARENT_SETTID|CLONE_CHILD_CLEARTID, parent_tidptr=0x7ff93e5d29d0, tls=0x7ff93e5d2700, child_tidptr=0x7ff93e5d29d0) = 52023; mmap(NULL, 1073745920, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_STACK, -1, 0) = 0x7ff8be5d1000; mprotect(0x7ff8be5d1000, 4096, PROT_NONE) = 0; clone(child_stack=0x7ff8fe5d0ed0, flags=CLONE_VM|CLONE_FS|CLONE_FILES|CLONE_SIGHAND|CLONE_THREAD|CLONE_SYSVSEM|CLONE_SETTLS|CLONE_PARENT_SETTID|CLONE_CHILD_CLEARTID, parent_tidptr=0x7ff8fe5d19d0, tls=0x7ff8fe5d1700, child_tidptr=0x7ff8fe5d19d0) = 52024; mmap(NULL, 1073745920, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_STACK, -1, 0) = 0x7ff87e5d0000; mprotect(0x7ff87e5d0000, 4096, PROT_NONE) = 0; clone(child_stack=0x7ff8be5cfed0, flags=CLONE_VM|CLONE_FS|CLONE_FILES|CLONE_SIGHAND|CLONE_THREAD|CLONE_SYSVSEM|CLONE_SETTLS|CLONE_PARENT_SETTID|CLONE_CHILD_CLEARTID, parent_tidptr=0x7ff8be5d09d0, tls=0x7ff8be5d0700, child_tidptr=0x7ff8be5d09d0) = 52025; mmap(NULL, 1073745920, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_STACK, -1, 0) = 0x7ff83e5cf000; mprotect(0x7ff83e5cf000, 4096, PROT_NONE) = 0; clone(child_stack=0x7ff87e5ceed0, flags=CLONE_VM|CLONE_FS|CLONE_FILES|CLONE_SIGHAND|CLONE_THREAD|CLONE_SYSVSEM|CLONE_SETTLS|CLONE_PARENT_SETTID|CLONE_CHILD_CLEARTID, parent_tidptr=0x7ff87e5cf9d0, tls=0x7ff87e5cf700, child_tidptr=0x7ff87e5cf9d0) = 52026; mmap(NULL, 1073745920, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_STACK, -1, 0) = -1 ENOMEM (Cannot allocate memory); futex(0x7fffbf4c3350, FUTEX_WAKE_PRIVATE, 2147483647) = 0; write(2, ""terminate called without an acti"".",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:121248,allocate,allocate,121248,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,1,['allocate'],['allocate']
Energy Efficiency,"E_SETTLS|CLONE_PARENT_SETTID|CLONE_CHILD_CLEARTID, parent_tidptr=0x7ffcfe5e19d0, tls=0x7ffcfe5e1700, child_tidptr=0x7ffcfe5e19d0) = 10750; mmap(NULL, 1073745920, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_STACK, -1, 0) = 0x7ffc7e5e0000; mprotect(0x7ffc7e5e0000, 4096, PROT_NONE) = 0; clone(child_stack=0x7ffcbe5dfed0, flags=CLONE_VM|CLONE_FS|CLONE_FILES|CLONE_SIGHAND|CLONE_THREAD|CLONE_SYSVSEM|CLONE_SETTLS|CLONE_PARENT_SETTID|CLONE_CHILD_CLEARTID, parent_tidptr=0x7ffcbe5e09d0, tls=0x7ffcbe5e0700, child_tidptr=0x7ffcbe5e09d0) = 10751; mmap(NULL, 1073745920, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_STACK, -1, 0) = 0x7ffc3e5df000; mprotect(0x7ffc3e5df000, 4096, PROT_NONE) = 0; clone(child_stack=0x7ffc7e5deed0, flags=CLONE_VM|CLONE_FS|CLONE_FILES|CLONE_SIGHAND|CLONE_THREAD|CLONE_SYSVSEM|CLONE_SETTLS|CLONE_PARENT_SETTID|CLONE_CHILD_CLEARTID, parent_tidptr=0x7ffc7e5df9d0, tls=0x7ffc7e5df700, child_tidptr=0x7ffc7e5df9d0) = 10752; mmap(NULL, 1073745920, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_STACK, -1, 0) = 0x7ffbfe5de000; mprotect(0x7ffbfe5de000, 4096, PROT_NONE) = 0; clone(child_stack=0x7ffc3e5dded0, flags=CLONE_VM|CLONE_FS|CLONE_FILES|CLONE_SIGHAND|CLONE_THREAD|CLONE_SYSVSEM|CLONE_SETTLS|CLONE_PARENT_SETTID|CLONE_CHILD_CLEARTID, parent_tidptr=0x7ffc3e5de9d0, tls=0x7ffc3e5de700, child_tidptr=0x7ffc3e5de9d0) = 10753; mmap(NULL, 1073745920, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_STACK, -1, 0) = 0x7ffbbe5dd000; mprotect(0x7ffbbe5dd000, 4096, PROT_NONE) = 0; clone(child_stack=0x7ffbfe5dced0, flags=CLONE_VM|CLONE_FS|CLONE_FILES|CLONE_SIGHAND|CLONE_THREAD|CLONE_SYSVSEM|CLONE_SETTLS|CLONE_PARENT_SETTID|CLONE_CHILD_CLEARTID, parent_tidptr=0x7ffbfe5dd9d0, tls=0x7ffbfe5dd700, child_tidptr=0x7ffbfe5dd9d0) = 10754; mmap(NULL, 1073745920, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_STACK, -1, 0) = -1 ENOMEM (Cannot allocate memory); futex(0x7fffbf4c3350, FUTEX_WAKE_PRIVATE, 2147483647) = 0; write(2, ""terminate called without an acti"".",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:76954,allocate,allocate,76954,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,1,['allocate'],['allocate']
Energy Efficiency,"E_SETTLS|CLONE_PARENT_SETTID|CLONE_CHILD_CLEARTID, parent_tidptr=0x7ffcfe5e19d0, tls=0x7ffcfe5e1700, child_tidptr=0x7ffcfe5e19d0) = 32693; mmap(NULL, 1073745920, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_STACK, -1, 0) = 0x7ffc7e5e0000; mprotect(0x7ffc7e5e0000, 4096, PROT_NONE) = 0; clone(child_stack=0x7ffcbe5dfed0, flags=CLONE_VM|CLONE_FS|CLONE_FILES|CLONE_SIGHAND|CLONE_THREAD|CLONE_SYSVSEM|CLONE_SETTLS|CLONE_PARENT_SETTID|CLONE_CHILD_CLEARTID, parent_tidptr=0x7ffcbe5e09d0, tls=0x7ffcbe5e0700, child_tidptr=0x7ffcbe5e09d0) = 32694; mmap(NULL, 1073745920, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_STACK, -1, 0) = 0x7ffc3e5df000; mprotect(0x7ffc3e5df000, 4096, PROT_NONE) = 0; clone(child_stack=0x7ffc7e5deed0, flags=CLONE_VM|CLONE_FS|CLONE_FILES|CLONE_SIGHAND|CLONE_THREAD|CLONE_SYSVSEM|CLONE_SETTLS|CLONE_PARENT_SETTID|CLONE_CHILD_CLEARTID, parent_tidptr=0x7ffc7e5df9d0, tls=0x7ffc7e5df700, child_tidptr=0x7ffc7e5df9d0) = 32695; mmap(NULL, 1073745920, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_STACK, -1, 0) = 0x7ffbfe5de000; mprotect(0x7ffbfe5de000, 4096, PROT_NONE) = 0; clone(child_stack=0x7ffc3e5dded0, flags=CLONE_VM|CLONE_FS|CLONE_FILES|CLONE_SIGHAND|CLONE_THREAD|CLONE_SYSVSEM|CLONE_SETTLS|CLONE_PARENT_SETTID|CLONE_CHILD_CLEARTID, parent_tidptr=0x7ffc3e5de9d0, tls=0x7ffc3e5de700, child_tidptr=0x7ffc3e5de9d0) = 32696; mmap(NULL, 1073745920, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_STACK, -1, 0) = 0x7ffbbe5dd000; mprotect(0x7ffbbe5dd000, 4096, PROT_NONE) = 0; clone(child_stack=0x7ffbfe5dced0, flags=CLONE_VM|CLONE_FS|CLONE_FILES|CLONE_SIGHAND|CLONE_THREAD|CLONE_SYSVSEM|CLONE_SETTLS|CLONE_PARENT_SETTID|CLONE_CHILD_CLEARTID, parent_tidptr=0x7ffbfe5dd9d0, tls=0x7ffbfe5dd700, child_tidptr=0x7ffbfe5dd9d0) = 32697; mmap(NULL, 1073745920, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_STACK, -1, 0) = -1 ENOMEM (Cannot allocate memory); futex(0x7fffbf4c3350, FUTEX_WAKE_PRIVATE, 2147483647) = 0; write(2, ""terminate called without an acti"".",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:40285,allocate,allocate,40285,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,1,['allocate'],['allocate']
Energy Efficiency,"Hello,. I've actually been thinking of a different method that would require very stringent mapping. By providing transcripts of only exon 1 & 2, exon 2 & 3, and exon 1 & 3 I could get a better idea of the number of reads that skip exon 2 all together. Also, by averaging the read counts that map to the junctions of exon 1 & 2 and exon 2 & 3, I can help eliminate polyA tail bias that is heavily positioned towards exon 1 and would also allow me to get a more accurate prediction of the two gene versions since 1 read mapped to exon 1 & 2 and 1 read mapped to exon 2 & 3 would essentially tell me twice that the gene is there while a read mapped to exon 1 & 3 would only tell me once that the gene is there. However, doing so would force me to bring ```AuxSampleNumber``` down to very low numbers such as 10 - 100 as using stringent coverage parameters drastically reduces my reads mapped. . I do wonder though how these low AUX numbers might affect your model development and algorithm. Any input into the aspect of low AUX numbers?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/401#issuecomment-512905804:866,reduce,reduces,866,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/401#issuecomment-512905804,1,['reduce'],['reduces']
Energy Efficiency,"Hi @AndrewSkelton,. There is currently no easy way to keep the index in RAM as STAR/Bowtie2 do. This is a feature we've been interested in for a _long_ time, but it's a feature that is very hard to justify spending a PhD student's time on since it's not going to contribute directly to any paper. But, this is a feature we'd like to add and maybe we can swing it with some of the CZI round-3 funding we just got. Nonetheless, the capability currently doesn't exist. Salmon can take multiple fastq files as input, but then it assumes they all derive from the same library, so you get one ""aggregate"" quant.sf, which isn't what you want here. So, I think the only approach currently would be to schedule a number of small jobs. I get why this isn't ideal. One small saving grace is that recent versions of salmon (>= 1.0.0) adopt the pufferfish index which is _much_ smaller than the previous RapMap index. Thus, the index loading time is quite small for a typical transcriptome. Also, this often allows operating system cache to keep the index around, even if it's not explicitly stored in shared memory. Thanks for both of the suggestions, and I'll be sure to keep you in the loop if we acquire either of the capabilities you mention above!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/589#issuecomment-733215735:693,schedul,schedule,693,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/589#issuecomment-733215735,1,['schedul'],['schedule']
Energy Efficiency,"Hi @AnnaAMonaco ,. Thanks for reaching out and I agree it'd be super useful to have alevin working for both scRNA-seq and scATAC-seq multiome datasets. In short I'd say the framework is not ready yet and there are multiple challenges which we are still working-on to find the right solution. The Central issue is that the technologies to profile open-chromatin regions expects the read to align majorly to non-coding regions and salmon/alevin framework is designed to work (generally) with transcriptomic data. Having said that, one can potentially index the full genome using salmon indexing but we have not yet extensively validated the genomic alignment generated from alevin framework. Once settled, we can certainly figure out ways to run alevin without UMI, that's the easier part. What do I do now ? Basically since the scRNA-seq and scATAC-seq are two different library preps (along with the fastq), I'd still recommend using alevin for scRNA-seq, however, one might have to run other tools (like bwa-mem) to align scATAC-seq data. The are multiple reasons to recommend that, the significant power of alevin comes in with (1) multi-mapping reads but we generally expect low number of such reads with ATAC-seq data (2) UMI deduplication which is absent in the ATAC-seq data and the deduplication happens based on the aligned position. Again, I agree it's great to have a uniform workflow for the multiome data but we are thinking about the challenges in designing such workflow and how solve them. We'd let you know once we have a vignette / tutorial. -- Avi",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/611#issuecomment-758028858:1100,power,power,1100,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/611#issuecomment-758028858,1,['power'],['power']
Energy Efficiency,"Hi @Ci-TJ,. This suggests that the FASTQ files were ""desynchronized"" during / after trimming somehow. Salmon requires that the FASTQ files are synchronized. So, if the trimmer decides to discard a read from the first read file, it must also discard the corresponding read from the second read file. I'm not specifically familiar with RabbitQC, but most quality / adapter trimmers have an option to separate out any reads that become orphaned during trimming so that the output paired FASTQ files remain synchronized. You should make sure that any such options are passed during QC. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/660#issuecomment-846252372:363,adapt,adapter,363,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/660#issuecomment-846252372,1,['adapt'],['adapter']
Energy Efficiency,"Hi @GWW ,. Ok, we figured out where the threads are coming from. Deep inside the concurrent hash map we are using, there is a [function that grows the hash map](https://github.com/COMBINE-lab/salmon/blob/master/include/cuckoohash_map.hh#L1558). This function uses a function called [`parallel_exec`](https://github.com/COMBINE-lab/salmon/blob/master/include/cuckoohash_map.hh#L1751) to move the items from the old table to the new one. Here, they greedily use as many threads as available for that process. We can't see this behavior on our end by monitoring top/htop, because the hash table doubling happens so fast it's below the monitoring resolution. There are a couple ways to address this, one of which is hacking inside the hashmap library to modify this behavior. However, it would be nice if there was a way to do this without modifying the code (e.g. by limiting the number of threads the process was allowed to spawn concurrently from outside of the process itself). We are looking to see if this is doable using e.g. cgroups or some such.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-395890018:548,monitor,monitoring,548,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-395890018,2,['monitor'],['monitoring']
Energy Efficiency,"Hi @Ray6283,. The `bootstraps.gz` file is not designed to be read as plain text. The file encodes information in binary. If you are interested in extract the information encoded in those files, the easiest thing to do is likely to read them in using the [`fishpond`](https://bioconductor.org/packages/release/bioc/html/fishpond.html) package. Looking at the code there will also show you exactly how those files are packed. The same is true for the bias files. The format for those is documented [here](https://salmon.readthedocs.io/en/latest/file_formats.html#sequence-specific-bias-files) and [here](https://salmon.readthedocs.io/en/latest/file_formats.html#fragment-gc-bias-files), those these are binary encoded files and not designed for human consumption. For the bias files, even if you did read them in, the information is not trivially interpretable (e.g. the parameters of the variable length Markov model, etc.). --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/47#issuecomment-1792970641:749,consumption,consumption,749,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/47#issuecomment-1792970641,1,['consumption'],['consumption']
Energy Efficiency,"Hi @annajbott ,. Thanks for your question.; It's an expected behavior. The idea is to dump some low confidence CB as well for certain kind of downstream processing. You'd see a file `whitelist.txt` as well in the output alevin folder which should contain whitelisted CB names (4340 in your case). You might have to filter those matrix out after loading the full matrix to get cells only passes the whitelisting filter. Please checkout [tximport](https://github.com/mikelove/tximport) to import the matrix in R, it's very efficient to load. In case you need some stats regarding the resource usage check [EDS](https://github.com/COMBINE-lab/EDS).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/428#issuecomment-530430735:521,efficient,efficient,521,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/428#issuecomment-530430735,1,['efficient'],['efficient']
Energy Efficiency,"Hi @diyang1354,. It is recommended to do adapter trimming prior to mapping and quantification (standard practices actually involve adapter and _light_ quality trimming of reads). Adapter contamination could affect the mapping rate, especially if selective-alignment, which is recommended, is being used.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/398#issuecomment-511428337:41,adapt,adapter,41,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/398#issuecomment-511428337,3,"['Adapt', 'adapt']","['Adapter', 'adapter']"
Energy Efficiency,"Hi @diyang1354,. To answer your questions as directly as possible:. 1.) Yes, you cannot align to a transcript of less than the k-mer length.; 2.) If you are processing bulk RNA-seq data, and therefore using `selective-alignment`, using a smaller `k` is unlikely to reduce your alignment accuracy, but it *can* increase the runtime of mapping if you make it too small. If you are processing single-cell RNA-seq data and using `--sketch` mode, then a reduction in the value of `k` can negatively impact accuracy. Finally, I'll mention that RNA-seq, in general, isn't a great assay for measuring very small molecules, so you probably want to be somewhat suspicious of the quantification results for *very short* transcripts anyway. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/754#issuecomment-1050469681:265,reduce,reduce,265,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/754#issuecomment-1050469681,1,['reduce'],['reduce']
Energy Efficiency,"Hi @euduca,. This is a good idea. Currently, there is no easy way to do this apart from hacking the CMake file. If salmon doesnt find jellyfish in a standard location, it just ferches its own copy. Fortunately, in the newest release (scheduled to drop this coming week), we've dropped the dependency on libjellyfish. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/225#issuecomment-392336913:234,schedul,scheduled,234,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/225#issuecomment-392336913,1,['schedul'],['scheduled']
Energy Efficiency,"Hi @gnaisha,. Thank you for providing the file to reproduce the issue. So, the difference here is all in the default fragment length mean and standard deviation that salmon and eXpress use. This really only matters in single-end libraries like this, since in paired-end libraries both tools will estimate the fragment length distribution from the data itself. Nonetheless, if not given specific parameters to override the default, salmon assumes μ = 250 and σ = 25, while eXpress assumes μ = 200 and σ = 80. If you run salmon like:. ```; salmon quant -lU -t transcriptome.fa -a sample_nested_transcripts_ENST00000364953-1_ENST00000375633-5.bam --fldMean 200 --fldSD 80 -o quant_directory; ```. Then you will see the following behavior for these transcripts:. ```; ENST00000364953.1 64 23.127 1000000.000000 49.000; ENST00000375633.5 586 384.567 0.000000 0.000; ```. So that the all of the reads are, indeed, allocated to the former. The effect of the transcript length on the assignment probabilities is a direct result of the probabilistic model (and due to the length effect that actually exists in the full-length RNA-seq assay). It's unfortunate that there's not a good way to estimate the fragment length distribution in single-end data, and so we are left with having to set some defaults. Depending on the actual library, different defaults will match better or worse. On the plus side, it's easy to change these values if you have better knowledge of the parameters or reason to believe that one value will work better than another.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/605#issuecomment-749739255:908,allocate,allocated,908,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/605#issuecomment-749739255,1,['allocate'],['allocated']
Energy Efficiency,"Hi @jan-g1,. The length of a feature is used during inference to determine the likelihood that multimapping reads should be allocated to different targets. You're describing what is essentially a simplified model where P(f | t) (i.e., the probability of a fragment given a transcript) is independent of length(t). There's currently no option to disable length normalization completely in Salmon, and you can't ""de-normalize"" by simply multiplying by a factor because those weights are considered during each and every round of the EM (or VBEM) algorithm. However, supporting this should actually be very straight-forward. We simply assign a uniform and identical length to all transcripts for the purpose of inference. I can add such a flag in the next release, though it will initially have to be incompatible with bias correction (since it's not clear right now how the biases for which we account interact with this type of sequencing). Also, it would be possible to run salmon with `--dumpEq`, and then to have a little script / tool that simply re-runs the EM, but without different length factors, using the equivalence class file. I might be able to hack something like that together on short notice if you'd be interested in testing it out. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/108#issuecomment-264659889:124,allocate,allocated,124,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/108#issuecomment-264659889,1,['allocate'],['allocated']
Energy Efficiency,"Hi @jeremymsimon — @Gaura is going to take a look at unfiltered permit listing and will share those results here later. Regarding frameshift errors, I think that's certainly out of scope for the alevin -> fry phase, but that type of thing *could* be in scope for `splitp`. Basically, my logic / reasoning is this: I'd like to avoid further complicating the already immense salmon/alevin codebase with special implementations handling problems outside of their core function (e.g. mapping reads to the reference efficiently and quantifying UMIs/barcode). Since most protocols (and the most common) have quite simple barcode geometry, it makes sense for this code to live there. I'm fully supportive of enabling support for more complex barcode geometries and preprocessing requirements if there are folks whom it would help, but it feels like that essential complexity belongs upstream of alevin / fry, so that by the time the reads get to alevin, it can assume a straightforward geometry. So TLDR : I think we'd be willing to investigate what is required to address potential frameshift errors, and how much of a difference that makes, but I think that analysis and eventual implementation (if we decide it's worth it), belongs in `splitp`.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-988030837:511,efficient,efficiently,511,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-988030837,1,['efficient'],['efficiently']
Energy Efficiency,"Hi @jeremymsimon, . Somehow, the notification for this in my e-mail got classified as SPAM. Anyway, thank you for the detailed description! I'm going to ping @Gaura here. @Gaura — this is the alternative protocol I was discussing with you yesterday. As you can see, the main issue here is the ""noisy"" barcodes. Let me know what you think would be necessary to add support for this, and I'm happy to schedule a technical discussion if you want to discuss some options.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-921879305:399,schedul,schedule,399,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-921879305,1,['schedul'],['schedule']
Energy Efficiency,"Hi @k3yavi, ; I just re-read this post and I believe that in the CEL-Seq2 protocol, read_1 has first the UMI and then the CB and then polyT... because the sequencing starts with the Illumina adapter (see image below from paper). . Thanks!; ![13059_2016_938_fig1_html](https://user-images.githubusercontent.com/39304679/49376447-edbda900-f70f-11e8-85d7-b86b15c477d5.gif)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/311#issuecomment-443709804:191,adapt,adapter,191,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/311#issuecomment-443709804,1,['adapt'],['adapter']
Energy Efficiency,"Hi @k3yavi,. Thanks for the reply!. Let's take the PBMC 4K as example. Looking at the summary sheet from 10x: ; http://cf.10xgenomics.com/samples/cell-exp/2.1.0/pbmc4k/pbmc4k_web_summary.html. They detected 4,340 cells with a median UMI count of 3,866 per cell. That means ~17M UMIs in the count matrix, which is in the same order what I find with Alevin. I am not sure if/where Alevin reports the number of mapped reads (maybe it is the number of hits?), but this is not of much importance. Indeed, the total UMI count is **much** lower than the number of sequenced/mapped/barcoded reads (~190M), which is expected. However, using the `--dumpUmiGraph` option provides a file ""MappedUMI.txt"" which I assume are the number of deduplicated UMIs mapped per cell/barcode (summed over all genes). The sum of over all the barcodes = 17M in this case and the sum per barcode = the sum in the quant_mat. This does not hold for the adapted cel-seq2 protocol. sum mapped UMI != summed quant_mat.gz. I am making a mistake, or is there something wrong?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/361#issuecomment-490098177:923,adapt,adapted,923,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/361#issuecomment-490098177,1,['adapt'],['adapted']
Energy Efficiency,"Hi @kvittingseerup,. Basic adapter and quality trimming should be done. There's some [nice work by Matt MacManes](https://www.frontiersin.org/articles/10.3389/fgene.2014.00013/full) showing that you should be careful about aggressive quality trimming, but light quality trimming is usually beneficial. This is particularly important if the underlying aligner isn't doing local alignment (e.g. STAR will likely just softclip bad bases).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/390#issuecomment-506744431:27,adapt,adapter,27,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/390#issuecomment-506744431,1,['adapt'],['adapter']
Energy Efficiency,"Hi @kvittingseerup,. No need to apologize, I think it was I who was not clear. What I am saying is that this is *already* the way that Salmon handles such a case. That is, if you have a paired-end read, and one of the reads maps but the other doesn't (due to e.g., adapter contamination or just very low quality), then Salmon will consider the remaining (mapping) end of the read as representative of an entire fragment, and will resolve the fragment origin accordingly during optimization. Generally, not having both ends of a paired-end read leads to increased ambiguity, but this isn't a particularly big problem if it only happens to a generally small fraction of the reads. Further, since you cannot reliably infer the implied fragment length on a transcript from only a single-end read, such mappings will not contribute to the bias model. Again, however, as long as this doesn't happen to the vast majority of fragments, it should have only a negligible effect on quantification and bias correction. Please let me know if this description makes sense. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/150#issuecomment-355881997:265,adapt,adapter,265,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/150#issuecomment-355881997,1,['adapt'],['adapter']
Energy Efficiency,"Hi @kzkedzierska,. I'm not sure why the virtual memory usage here is so high, and am also not aware of a great way to predict it. One thing I might ask is if you could test this executable on your system ( [salmon-1.2.0-beta](https://drive.google.com/open?id=1QHYCT3Vs9bRD7UmJY6JJKjlzmmUE4wRl)). This is the near-final beta version of 1.2.0 whose release is imminent. One of the big changes in this version is a considerably more memory-efficient construction. We have been measuring this in terms of resident memory, but it may also apply to virtual memory. Would you mind giving it a try if you have a chance?. Thanks!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/441#issuecomment-605106040:437,efficient,efficient,437,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/441#issuecomment-605106040,1,['efficient'],['efficient']
Energy Efficiency,"Hi @lauraht,. So I decided to explore just one of these to see if I could figure out what might be going on. The below is with respect to `SRR9007475`. So first, even though I processed the data with the latest version of the develop branch (which will become 1.2.0), I got basically identical results to what you reported. Simply aligning the data against an index built on a human Gencode v26 transcriptome (with no decoys) gives me a mapping rate of `0.00378202832148367%`. The first thing I did was to quality and adapter trim the data (using `fastp -i SRR9007475.fastq.gz -o SRR9007475_trimmed.fastq.gz -q 10 -w 8`) and ... whoa. This is the fastp html report [fastp.html.zip](https://github.com/COMBINE-lab/salmon/files/4176345/fastp.html.zip). So the first astounding statistic, the mean read length before trimming is 51bp (these are relatively short single-end reads). The mean read length after trimming is 21bp! So, the average read length is, in fact, less than the k-mer length used for indexing (default is k=31). On the trimmed data, the mapping rate goes up to `2.3545475882931305%`, still very low, but now there's somewhat of an explanation, the average read is shorter than a single k-mer. So, the next thing I tried was indexing with a smaller k; a _really_ small one in this case,`k=15`. Then, I re-ran on the _trimmed_ reads (the fact that the trimming took us from 51-21bp suggests that the reads had a lot of low quality bases, adapter contamination, or both). Under this setting, I still get a very low mapping rate, but it was _much_ higher — `16.766993524863488%`. The final thing I tried was seeing how the mapping rate changed as I altered `--minScoreFraction`, which is the salmon parameter that determines the alignment score that a read must achieve in order to be mapped validly. The default is 0.65. This means that the read cannot have a score < 0.65 * the maximum achievable score for the read given it's length. In the case of a 21bp read, the best score would be ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/482#issuecomment-583799668:518,adapt,adapter,518,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/482#issuecomment-583799668,1,['adapt'],['adapter']
Energy Efficiency,"Hi @lcolladotor,. That's really strange. It *is* the case that it's possible for Salmon to use more than one thread if you set `-p 1` --- it will use up to 2 threads in this case (1 is always dedicated for parsing). However, none of this would explain the memory usage you see. Adding more threads should not substantially change the memory burden in any way, as the main memory usage is in memory shared between threads and the amount of thread local memory is very small (a few MB at most). I would recommend updating to the latest version of Salmon (v0.8.2), as it does reduce the memory usage even more. I commonly quantify on the human transcriptome, and this uses 3-4G on my machine (with 16 threads). If you're still seeing this behavior with the newest version, we can try and debug further --- though I'm not sure exactly where to look next.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-289310854:573,reduce,reduce,573,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-289310854,1,['reduce'],['reduce']
Energy Efficiency,"Hi @lubios,. This suggests that the machine was not able to allocate enough memory to perform the requested operation. I would try the following things in order to see if they fix the issue. First, try quantifying without the decoy-aware index. This doesn't provide the benefits of the decoy sequence, but it will ensure that this is, in fact, the problem you are having. If that works, try building the decoy-aware index with the `--sparse` parameter. This will build the sparse index instead of the dense index, which is a bit smaller and may therefore fit in RAM on the machine where you are doing quantification. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/717#issuecomment-962058307:60,allocate,allocate,60,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/717#issuecomment-962058307,1,['allocate'],['allocate']
Energy Efficiency,"Hi @matthew-valentine,. In general, extra non-primary alignments are OK. This can, of course, slow down quantification somewhat because many more alignments are being evaluated. However, salmon (with the `--ont` flag) is designed to consider the provided alignments and allocate the corresponding read proportionally according to all of the relevant probabilities (including alignment quality). If, under this aligner setting, there are many *highly* sub-optimal alignments being reported, you may consider filtering them out, but that shouldn't be strictly necessary. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/796#issuecomment-1235769651:270,allocate,allocate,270,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/796#issuecomment-1235769651,1,['allocate'],['allocate']
Energy Efficiency,"Hi @mdshw5,. Thanks for sharing the file. I was able to build the transcriptome. The final index on this is ~15G. Here are the stats from the run on our machine:. ```; ~/salmon/build/issue432$ du -h big_idx/; 15G big_idx/; ~/salmon/build/issue432$ cat indexing_time.txt; 9737.34user 339.95system 21:11.51elapsed 792%CPU (0avgtext+0avgdata 14894700maxresident)k; 1232inputs+150622584outputs (0major+99352946minor)pagefaults 0swaps; ```. so the peak construction memory was about the same and the build took 21m with 16 threads. If you have a place, I can share the built index. What were the stats of the machine on which you were building? Was there sufficient RAM allocated?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/432#issuecomment-538602738:665,allocate,allocated,665,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/432#issuecomment-538602738,1,['allocate'],['allocated']
Energy Efficiency,"Hi @rhlampe,. Currently, there is no way to prevent the salmon indexer from using more memory if it is needed ot build the index. However, if there is a limit placed by the cluster, it will likely just result in a `bad_alloc` exception from the indexer. The number of sequences alone can tell you a bit about scaling, but the total number of nuclotides being indexed is actually a better predictor of resource usage. How many nucleotides, total, are the references you're considering? While we are working on ways to make the indexing scheme highly scalable, it's worth noting that, to achieve some of it's speed, salmon pre-computes a lot of information it its index (so that the index can become fairly large). One thing I might suggest, if you want to attempt to index and quantify on a very large reference, is to use the `--perfectHash` index in the newest development version of Salmon (pre-release tarball attached below). The latest version (for which the official version should appear soon) represents a number of improvements to index construction. The default indexer has reduced memory usage by ~40%, and the new `--perfectHash` indexer, while somewhat slower, reduces the memory usage even more (by an additional 40-50%). With a fixed memory budget, then, it should allow you to index ever larger references. --Rob. [Salmon-v0.7.3-pre_linux_x86_64.tar.gz](https://github.com/COMBINE-lab/salmon/files/512019/Salmon-v0.7.3-pre_linux_x86_64.tar.gz)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/97#issuecomment-251759242:1084,reduce,reduced,1084,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/97#issuecomment-251759242,2,['reduce'],"['reduced', 'reduces']"
Energy Efficiency,"Hi @rob-p . Before I answer your question and layout my logic, I want to mention that I am **_not_** suggesting fastp is not doing its job, **_neither am I stating that fastp is working incorrectly_**. Now to my answer(s) and logic:; 1. With fastp, I am not sure if adapter trimming happens first and then quality trimming OR vice-versa. I could not find info on this from their README and **_I could be wrong here with my next line_** - [Based on Figure 1 of this paper, it looks to me as though quality trimming is done before adapter trimming](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6129281/figure/bty560-F1/). - [To quote Brian Bushnell (author of BBTools)]( http://seqanswers.com/forums/showpost.php?p=140819&postcount=5), . > It's best to do adapter-trimming first, then quality-trimming, because if you do quality-trimming first, sometimes adapters will be partially trimmed and become too short to be recognized as adapter sequence. When you run BBDuk with both quality-trimming and adapter-trimming in the same run, it will do adapter-trimming first, then quality-trimming. 2. I very well know that the advantage of using fastp is that it can do adapter trimming, etc in a automatic fashion - no need to provide external sequences (example adapter sequences). Yes, I know one can also provide a fasta file of adapters and fatsp will work off it. There are many fatsp issues in GH about adapter detection:. - fail to detect adpaters automatically - (https://github.com/OpenGene/fastp/issues/222 and https://github.com/OpenGene/fastp/issues/205). - [incorrect automatic adapter detection](https://github.com/OpenGene/fastp/issues/240). - [inconsistent behavior with different runs](https://github.com/OpenGene/fastp/issues/231). 3. When I see the above, I am bit skeptical using fastp for qc/adapter trimming. . After lot of trials with bbduk and fastp, I have decided to use bbduk and bbmap for my high throughput analysis. Below, I explain my reasoning behind those choices: . **_```Not",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-597393209:266,adapt,adapter,266,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-597393209,5,['adapt'],"['adapter', 'adapter-trimming', 'adapters']"
Energy Efficiency,Hi @rob-p . Thanks for the elaborate answer - makes a lot of sense. The problem is that adapter contamination typically occures because the fragments were smaller than the sequence length we sequence into the adapters - and it can occur for a larger fraction of the reads (I've seen up to 50% of reads affected in the 3'end) making it non-negligible. That is why I suggested the extension in the first place. I think it makes a lot of sense to trim adapters away - both because they reduce the number of compatible reads - mostly because the failure to do so will result in an overestimation of the fragment length. . Now that I think about it I don't think we should trim reads based on quality as that will lead to an underestimation of the read length - or what do you think?,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/150#issuecomment-355909325:88,adapt,adapter,88,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/150#issuecomment-355909325,4,"['adapt', 'reduce']","['adapter', 'adapters', 'reduce']"
Energy Efficiency,"Hi @rob-p . Thanks for the quick reply. Indeed my salmon index does not include lncRNAs, but my sequencing does. For indexing, I only used UCSC RefSeq transcripts (which I believe contains only protein coding transcripts that exclude most of lncRNAs). But this does not seem to suffice to explain the low mapping rate as Wikipedia says ""[Quantitatively, lncRNAs demonstrate ~10-fold lower abundance than mRNAs in a population of cells.](https://en.wikipedia.org/wiki/Long_non-coding_RNA#Abundance)"". To answer your questions:; 1. I used `htseq-count`, and here are the overall statistics (out of 149347870 record pairs processed):; ```; stat	""-s yes""	""-s reverse""; __no_feature	135258158	44917653; __ambiguous	39301	594958; __too_low_aQual	0	0; __not_aligned	0	0; __alignment_not_unique	7430169	7430169; ```. 2. I haven't done quality/adapter trimming as the data really looks clean and of high quality according to FastQC report. 3. Unfortunately I can't share the raw data yet but I will try your suggestion to quantify with STAR at the transcript level.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/661#issuecomment-847091597:835,adapt,adapter,835,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/661#issuecomment-847091597,1,['adapt'],['adapter']
Energy Efficiency,"Hi @rob-p . Totally understood (even more severe current limitations here) - survey completed. I think there'll ""always"" be Illumina-level coding (we use it to multiplex samples or cells), but I suspect most (all?) wild-west method will be some form of using the one read for barcoding. So as long as I can stipulate which bases in the read are which kind of barcode (cell/molecular) that'd be a good start. Of course having more mature methods than the current [drop-seq protocol](http://mccarrolllab.com/wp-content/uploads/2016/03/Drop-seqAlignmentCookbookv1.2Jan2016.pdf) to error correct, remove poly-A, remove adaptor sequences etc. always very welcome. (I suspect @vals is onto something... I still struggle to be entirely convinced that UMIs, as currently used, have the long-term legs that some people think.)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/93#issuecomment-282741659:615,adapt,adaptor,615,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/93#issuecomment-282741659,1,['adapt'],['adaptor']
Energy Efficiency,"Hi @rob-p,. thank you for your quick answer. As mentioned already, I started with the full set of options (at least I thought so) and then reduced them to the minimal case to reproduce the error for reporting the problem.; I was mislead by the term 'unrecognized option' and didn't expect the program to ""forget"" options from other modes. But now that you stated that this is the case, I realized that the '-a' in front of the BAM file name was missing, which I overlooked before. After adding it the program at least started to run. (Although it ran into another crirical error, appearantly misinterpreting chromosome and supercontig names from the BAM file header generated by STAR as transcript names.). Maybe it would be a good idea to distinguish in the error messages between 'unrecognised' and 'inappropriate' options to provide a better clue to the user what went wrong.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/343#issuecomment-462761900:139,reduce,reduced,139,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/343#issuecomment-462761900,1,['reduce'],['reduced']
Energy Efficiency,"Hi @rob-p. I'm using a SGE-based cluster. The disk I'm writing to is a networked disk that is mounted via NFS on the machines the cluster runs on. I've attached the output of running `qconf -sconf`, which provides details on how the cluster has been configured (I've edited out some lines about the admin e-mails, etc.). I'm not sure how useful much of this information is. A lot of it has to do with scheduling of jobs -- how many jobs/resources users can attempt to claim, that kind of thing. Let me know if there's something else that would be more useful in this context. I've also attached the log that was generated by the indexing run itself (just for the 17mer index), just in case. I can say one thing from having inspected the logs of these things failing a number of times before I finally caved and started giving it insane amounts of memory: by far the longest time and (most likely) the biggest resource hog is between the first and second pass. Even with only 16GB, it manages to complete the first pass (it still takes quite a while, though):. ```; Pass	Filling	Filtering; 1	718	3236	; 2	1839	237; ```. [qconf-sconf.txt](https://github.com/COMBINE-lab/salmon/files/4172585/qconf-sconf.txt); [index_GRCm38_GENCODE_M23_PRI_17mer.log.txt](https://github.com/COMBINE-lab/salmon/files/4172594/index_GRCm38_GENCODE_M23_PRI_17mer.log.txt). EDIT: Oh, I should also probably say, that I'm only seeing this slowdown on index creation. I'm sure that was implied, but I just wanted to be clear that at the moment, I'm happy enough to let the index build for a few hours every once in a while. I'm still saving huge amounts of mapping time, relative to ""full"" aligners.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/476#issuecomment-583567362:401,schedul,scheduling,401,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/476#issuecomment-583567362,1,['schedul'],['scheduling']
Energy Efficiency,"Hi @roryk,. Salmon doesn't currently have the ability to output a pseudobam, but that is definitely possible (and not too difficult). We have a related feature planned; perhaps you could tell me if it suits your use case. However, first, I should mention that if you'd simply like a pseudobam for _all_ the mapping locations of the reads, you can use [RapMap](https://github.com/COMBINE-lab/RapMap). RapMap implements the quasi-mapping algorithm upon which Salmon and Sailfish are based (and RapMap is used as a library in the Salmon and Sailfish codebases). Given an index and set of reads, RapMap will report all of the multi-mapping locations that Salmon and Sailfish would consider during quantification. The other feature we have in the works is to have Salmon optionally output a `.bam` file (with actual alignments) post-quantification. It turns out that, given the quasi-mapping information and the quantification results, taking the extra step from quasi-mapping to an actual _alignment_ can be done fairly efficiently. In this mode, Salmon would make one more pass over the reads and, considering the estimated abundances, sample a single alignment for each multi-mapping read proportional to the relative abundance of the different multi-mapping targets (i.e. it would perform a sampling over the multi-mapping locations that would, in expectation, give the same abundances as the _soft_ assignments computed by the optimization algorithm). This feature will be very useful for [transrate](https://github.com/Blahah/transrate). However, given that your goal is to use outside information to perform the filtering yourself, this option may not be ideal for you.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/38#issuecomment-175092553:1016,efficient,efficiently,1016,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/38#issuecomment-175092553,1,['efficient'],['efficiently']
Energy Efficiency,"Hi @tamuanand ,. Thanks for pointing this out. You are right, we missed to update the salmon doc with this details. You can find the latest preprint [here](https://www.biorxiv.org/content/10.1101/657874v2). The new version don't require the GTF because now we don't generate the decoys explicitly i.e. you don't have to run mashmap. With the latest version salmon, it can consume the full genome and transcriptome without the explicit need of annotation. It's much more efficient and takes significantly less memory to align/quantify compared to other genome based method. Please checkout the preprint for more details and [this](https://combine-lab.github.io/alevin-tutorial/2019/selective-alignment/) tutorial for how to index the gentrome (genome + transcriptome) index. We will update the salmon docs too, to reflect the same.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/384#issuecomment-549183799:470,efficient,efficient,470,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/384#issuecomment-549183799,1,['efficient'],['efficient']
Energy Efficiency,"Hi @tamuanand,. Sure; is there anything specific about bbduk and bbmap for quality / adapter trimming that you think would be provided beyond or in addition to what fastp provides? Also, we have a beta implementation of soft-clipping and are looking for a wide net of testing data. Any suggestions to that end would be welcome!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-597344801:85,adapt,adapter,85,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-597344801,1,['adapt'],['adapter']
Energy Efficiency,"Hi @tamuanand,. Thanks for the suggestion. You're right, of course, and we should change the wording in that readme. The cause of the sequence similarity is not always known, and frankly, not important for our particular application. We adopted this term as shorthand given it's common use and also because the version of MashMap used to compute these sequence-similar regions was introduced in the paper [A fast adaptive algorithm for computing whole-genome homology maps](https://academic.oup.com/bioinformatics/article/34/17/i748/5093242). In the preprint itself, we're generally careful to simply refer to these as sequence-similar regions ;).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/365#issuecomment-499476462:413,adapt,adaptive,413,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/365#issuecomment-499476462,1,['adapt'],['adaptive']
Energy Efficiency,"Hi @vd4mmind,. Indeed, @mdshw5 is spot on. The issue you're seeing is a result of the hash table doubling failing to allocate sufficient memory when attempting to build a hash table for all 31-mers in the mouse genome. In addition to the memory requirements of building a quasi-index on the genome (which we're actually working to mitigate b/c we think it could be useful in another context), this won't be particularly useful for quantification. Salmon treats each entry in the multifasta file as a distinct transcriptional target. Thus, here, even if the index did build successfully, you'd be quantifying the abundance of different chromosomes & contigs, rather than the transcripts. What you should do (as pointed out by @mdshw5 above), is to grab a file that contains the mouse transcripts (or take your mm9 genome and an appropriate gtf file and use a tool like `gffread` to extract the transcript sequences).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/49#issuecomment-197873003:117,allocate,allocate,117,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/49#issuecomment-197873003,1,['allocate'],['allocate']
Energy Efficiency,"Hi @xinbindai,. What you are seeing in both Salmon and RSEM is the expected behavior. This is because, to a large extent, the entire purpose of these tools is to appropriately allocate mulit-mapping reads. In your case, it is likely the case that one of the two very similar transcripts could account for all of the reads, while the other could not. For example, image I have a simple scenario where I have two transcripts:. ```; ACACACTGTGTGTG; ACACACGGTGTGTG; ```. Now, imagine I observe the ""reads"":. ```; ACAC; ACAC; CACA; CACA; ACTG; CTGT; GTGT; TGTG; TGTG; ```. The majority of these reads could have come from either transcript (and are equally likely to have come from both). However, the fact that we observe `ACGT` and `CTGT` is rather strong evidence that we could explain all of the reads via the first transcript while positing 0 (or close to 0) abundance for the second. On a much larger scale, this is what Salmon and RSEM are doing --- they are finding the most likely abundances of the transcripts given the observed data (the reads). When there is unique evidence of one of the two variants, and no unique evidence of the other, the maximum likelihood estimate for the variant with no unique evidence is very small. I'm not sure how many reads you are mapping, but you likely got a somewhat different estimate from eXpress since it tends to regularize it's abundance estimates a bit more strongly than Salmon or RSEM. That being said, this is the intended behavior of these tools, they are meant to probabilistically allocate multi-mapping fragments to similar transcripts in a manner that maximizes a global likelihood, so I don't think that what you are seeing is un-expected. In fact, it is consistent with the probabilistic model that underlies all three tools.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/107#issuecomment-263408444:176,allocate,allocate,176,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/107#issuecomment-263408444,2,['allocate'],['allocate']
Energy Efficiency,"Hi @yeodynasty,. There are two different ways to tackle this question. The first relies on the fact that the correction employed by salmon for GC bias is done via the adjustment of transcript effective lengths. Here, you could compare the effective length in the quant.sf file to the effective length you would get ignoring GC-fragment (or other bias). Granted, the latter is not written down in the file here, but it is straightforward to calculate since salmon also writes out the fragment length distribution. ; The effective length discarding bias estimates is simply the transcript length, minus the mean of the conditional fragment length distribution (the fragment length distribution from 0 up to the transcript length, re-normalized to be an appropriate probability distribution). If you look at the differences between these values, you can infer how much bias correction was applied. Specifically, when the bias-corrected length is longer than the non bias-corrected length, then these transcripts are over-represented in sequencing and the bias correction aims to reduce their estimated abundance. On the other hand, when the bias-corrected length is shorter than the non bias-corrected length, then these transcripts are under-represented in sequencing and the bias correction aims to increase their estimated abundance.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/578#issuecomment-717267531:1076,reduce,reduce,1076,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/578#issuecomment-717267531,1,['reduce'],['reduce']
Energy Efficiency,"Hi Avi,. Yes I just asked and the guide sequences were reverse complemented. I was looking through the results and comparing it with the output of another alignment software. I noticed that there are substantially fewer UMI per guide (in cell) throughout ( see figures for comparison). . ![image](https://user-images.githubusercontent.com/9895004/83803410-7eb16f80-a67a-11ea-832d-562c88dafef3.png) ; ![image](https://user-images.githubusercontent.com/9895004/83803427-8709aa80-a67a-11ea-9ea4-f66ca447a65c.png). Also, the number of UMIs per cell barcode is consistently lower and there is around 796 barcodes that are not found in the 10X whitelist, the majority of which tend to have 1 UMI count only. Here is tally, where the TRUE column indicates the barcode is found in the whitelist. The row names indicate the total number of UMIs; ; ![image](https://user-images.githubusercontent.com/9895004/83803984-7279e200-a67b-11ea-8578-fc863f94f714.png). It would be great if you can implement the index hopping correction in Alevin. The software we have works fine if the number of samples is not too large. If had known how to code in C++, I would have implemented part of the code more efficiently using Rcpp. Please let me know if you ever decide to add this feature to Salmon. I am more than happy to help. Rick,",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-639088909:1184,efficient,efficiently,1184,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-639088909,1,['efficient'],['efficiently']
Energy Efficiency,"Hi Mohsen and Rob,. So sorry if you've already been troubleshooting the example data I gave you. I realized that that is not a good example of the problem. In this example, there are snR40 and snR40_genomic transcripts, representing processed and pre-processed isoforms. However, it just so happens that there is residual adapter on some of the reads I provided and the first nucleotide of the adapter sequence actually matches the first nucleotide of the longer, genomic version of this transcript, therefore, the genomic variant gets a slightly better alignment score, as it should. After hard trimming any residual adapter the results for this transcript were a lot better (although still not quite the ratio I would expect). I have quite a few examples like this and I'm fairly sure they are not *all* explained by alignment of adapter sequences. However, I just wanted to let you know in case you were already troubleshooting my example data. I'm aggregating a handful more general examples of the same problem, but ones without a trivial solution like the one I provided. The files are too large to attach on github directly, though, do you have a preferred way to share the files? Maybe a google drive?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-642954815:322,adapt,adapter,322,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-642954815,4,['adapt'],['adapter']
Energy Efficiency,"Hi Rob,. Thanks for the clarity regarding the effect of insert size distribution on quantification. That does resolve this issue, and gives me a path going forward using Salmon for this data. However, I am trying to use Salmon for small RNA-Seq data, where the insert size is equal to read length for most reads after adapter trimming. Would it be possible to add a flag to use read length as a proxy for insert size, potentially with a fallback to fldMean/fldSD in the case of full-length, untrimmed reads? This is something I would be willing to contribute myself, if it sounds appropriate. Thanks,; Gautam",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/605#issuecomment-752064194:318,adapt,adapter,318,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/605#issuecomment-752064194,1,['adapt'],['adapter']
Energy Efficiency,"Hi Ryan,. The difficulty is, indeed, exactly as you specify. Given a single-end read, one does not know the length of the _fragment_ from which it originates. In this case the ""right"" thing to do (the best thing we can do) is to consider the read as starting / ending a fragment of every possible length allowed by the user-provided fragment length distribution (with the contribution of each possible fragment weighted by the probability of observing a fragment of that length). In order to make this computationally feasible, one would have to do some clever pre-computation and thing a bit more about how to efficiently update the observed GC model (right now, each mapping contributes a single weight to the model, but under the naive implementation in the single-end case, each mapping would contribute different weights to each bin of the observed GC-bias curve, which would slow things down considerably). Also, as you point out, the quality of the correction would depend somewhat on the user providing appropriate parameters for the fragment length distribution mean and standard deviation — but this seems reasonable in the single-end case. That being said, I'm sure there's a way to handle this efficiently, I'd just have to think about it a bit. Regarding your second question; Salmon learns the fragment length distribution in paired-end data, but not with single-end data. Single-end data can provide a little bit of information (e.g. there is in upper bound on fragment lengths that one can infer based on single-end reads based on how far they map from the end of the transcript), but not enough information to reliably infer a fragment length distribution. cc @mikelove in case he has any thoughts on this.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/83#issuecomment-243833424:611,efficient,efficiently,611,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/83#issuecomment-243833424,2,['efficient'],['efficiently']
Energy Efficiency,"Hi, I am running salmon-1.9.0, but in quant bulk mode for rat from *.bam files it stops with this error `Segmentation fault (core dumped)`. --threads 10 and 10 cpu (each core is 5.3 GB) are allocated for this job. Thanks for your solution(s) in advance!. Hi again, I found this issue is related to multiple bam input files which I've done by -a parameter with a (space-separated) list of these files. It is fixed now if just run salmon per file individually.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/261#issuecomment-1239714634:190,allocate,allocated,190,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/261#issuecomment-1239714634,1,['allocate'],['allocated']
Energy Efficiency,"Hi,. If I don't trim the adaptors and still use --ont will I still get correct quantification? Is adaptor trimming very essential? Is there a way I can use salmon without adaptor trimming?. Also, can you please clarify about the secondary alignmenmts if these are included in Salmon or not?. Thanks,; Harsha; ________________________________; From: Feng Yan ***@***.***>; Sent: 08 January 2024 23:30; To: COMBINE-lab/salmon ***@***.***>; Cc: Harshangda Karan Puri ***@***.***>; Author ***@***.***>; Subject: Re: [COMBINE-lab/salmon] Quantification in Alignment mode for Nanopore Data (Issue #903). also interested to know how Salmon uses secondary alignment. Because I found this tutorial https://combine-lab.github.io/salmon-tutorials/2021/ont-long-read-quantification/ [combine-lab.github.io]<https://urldefense.com/v3/__https://combine-lab.github.io/salmon-tutorials/2021/ont-long-read-quantification/__;!!PDiH4ENfjr2_Jw!GTZeAEdMSJcSBTPXhWuSsmLuX2WDzuNuNgqT04lADpRqOWyHssr_JALdqVa1JBOS9RHGRa9M6SeJKoxo6T7o5_O0bvsV-KkgNb45i4uTnGob8fw$> actually includes secondary alignments.; And based on my experience, secondary alignments are used by Salmon, because when I give a BAM before and after removing secondary (-F 256 flag in samtools), the results are different. —; Reply to this email directly, view it on GitHub [github.com]<https://urldefense.com/v3/__https://github.com/COMBINE-lab/salmon/issues/903*issuecomment-1881982972__;Iw!!PDiH4ENfjr2_Jw!GTZeAEdMSJcSBTPXhWuSsmLuX2WDzuNuNgqT04lADpRqOWyHssr_JALdqVa1JBOS9RHGRa9M6SeJKoxo6T7o5_O0bvsV-KkgNb45i4uTEiG0xQE$>, or unsubscribe [github.com]<https://urldefense.com/v3/__https://github.com/notifications/unsubscribe-auth/A3SZAPCLOZYB72ZEIEEXH43YNR6S7AVCNFSM6AAAAABANBCPNSVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMYTQOBRHE4DEOJXGI__;!!PDiH4ENfjr2_Jw!GTZeAEdMSJcSBTPXhWuSsmLuX2WDzuNuNgqT04lADpRqOWyHssr_JALdqVa1JBOS9RHGRa9M6SeJKoxo6T7o5_O0bvsV-KkgNb45i4uTntkMlxE$>.; You are receiving this because you authored the thread.Message ID: ***@***.***>",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/903#issuecomment-1884769339:25,adapt,adaptors,25,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/903#issuecomment-1884769339,3,['adapt'],"['adaptor', 'adaptors']"
Energy Efficiency,Holy cloud-computing charges! I'm sorry to hear about this. We can certainly rate-limit this message. I'll work on fixing this upstream. Sorry for the trouble.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/152#issuecomment-328981463:21,charge,charges,21,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/152#issuecomment-328981463,1,['charge'],['charges']
Energy Efficiency,"How big is the index directory? The fact that it hasn't used up all of the memory doesn't mean that the allocator should be able to allocate more. If the next chunk it needs to allocate is large (e.g. the position table), and it needs that memory in contiguous space, the allocation might fail. I'd recommend either trying this on a larger memory machine, or trying a smaller index (e.g. the selective alignment index with custom decoys rather than the whole genome) on this machine. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/518#issuecomment-629842095:132,allocate,allocate,132,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/518#issuecomment-629842095,2,['allocate'],['allocate']
Energy Efficiency,"I also have had to submit indexing jobs with much larger resources and times since the switch to the new indexing method with whole genome decoys. Prior to this I could built and index asking for only 16GB of ram in minutes. Now, I have to request ~256GB of memory and it runs for 7-10 hours. These are just ""standard"" mouse transcriptomes (GENCODE M23). I should note that using 17-mers as my kmer length dramatically increased these requirements. I re-ran using 31-mers, and the time reduces to a couple of hours and only used ~20GB of memory. I've attached two files that have summaries of the resources used in the jobs I ran in the above. Everything about these jobs is the same, except for the k-mer lengths. I requested the same amount of resources for each, but you can see that the one labeled 31mer has drastically less ""ru_maxrss"", which is the maximum amount of memory used by the process (it's in KB, although it's not labeled in the log). I also noted that there weren't any hard page faults for either of the jobs (""ru_majflt""). The longer job did have more soft page faults/page reclaims (""ru_minflt""). I don't know if that's useful information or not. [qacct-17mer.log](https://github.com/COMBINE-lab/salmon/files/4172209/qacct-17mer.log); [qacct-31mer.log](https://github.com/COMBINE-lab/salmon/files/4172210/qacct-31mer.log)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/476#issuecomment-583526416:486,reduce,reduces,486,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/476#issuecomment-583526416,1,['reduce'],['reduces']
Energy Efficiency,"I gave it another try, as I wasn't monitoring resources before. It's trying to make a liar of me! It is working fine now after wasting my entire day. :/ It took under a minute. I had tried to run it a dozen times by the time I gave up and posted. Oh well, thanks for the help! I'll go hide in shame somewhere now and convince myself I didn't imagine the whole thing :D",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/100#issuecomment-258491545:35,monitor,monitoring,35,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/100#issuecomment-258491545,1,['monitor'],['monitoring']
Energy Efficiency,"I see, we might have to tweak a bit based on the use case for `longranger basic`.; In `v0.10`, alevin should still be able to do CB correction, and attach the corrected CBs to the header of the second file, although the remaining template sequence (128 bases) from the first file might get loss, since `cellranger` was using template sequencing in only one file. Like @rob-p was saying we can work on making this step more generalized, once we confirm that the error-correction model for `cellranger` and `longranger` can be used interchangeably. In theory we can still concatenate the remaining 128 bases into an interleaved format since alevin has hidden options to provide the lengths explicitly but we have not tested this feature extensively. We will keep this at the top of our feature-request list and would inform you as soon as we have a stable version with this feature. Thanks again for the interest !!. re: *interleaved format* -- indeed an interleave format does makes sense and should be the default dumping format, but I believe since the default mode of 10x's `mkfastq` is to dump separate `FASTQ`, we should not use resources to create an interim interleaved format and then consume it downstream (since`FASTQ` itself is not very efficient), instead, in alevin we just consume the two separate `FASTQ` into our own interim data-structure to perform the downstream analysis.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/233#issuecomment-395195411:1247,efficient,efficient,1247,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/233#issuecomment-395195411,1,['efficient'],['efficient']
Energy Efficiency,"I was trying to troubleshoot the contemplation period of salmon with monitoring utilities and just stumbled upon this issue upon submitting my own. The failed version check gets buried by the spew of warnings for too short/long transcripts for hg38 mrna.fna in my case. The current behaviour is particularly irritating as I assumed, that `salmon index -h` just runs into a loop accidentally. The check takes multiple minutes to timeout. I am behind a proxy. Please remove the version check by default, as this is not common behaviour of command line tools or anticipated by the user. Or at least please add a verbose message before checking ""Checking for upgrades online..."".",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/277#issuecomment-474388032:69,monitor,monitoring,69,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/277#issuecomment-474388032,1,['monitor'],['monitoring']
Energy Efficiency,"No problem! We're actually working now on an optional use of a perfect hash in the quasi-index. It increases index construction times, but provides the same speed of lookup as the current hash. Also, it reduces the memory usage by a factor of ~2. We just have to figure out how to implement this cleanly in the code base.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/37#issuecomment-187748517:203,reduce,reduces,203,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/37#issuecomment-187748517,1,['reduce'],['reduces']
Energy Efficiency,No worries - and that is exactly what I thought could be possible :-). Just out of curiosity - how would Salmon currently handle if half of a read could be quasi-mapped to a transcript but the second half did not fit anywhere (due to it being very low quality or sequencing adapter contamination)?,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/150#issuecomment-353287536:274,adapt,adapter,274,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/150#issuecomment-353287536,1,['adapt'],['adapter']
Energy Efficiency,"Oh, I should've pushed my PR sooner!; Thanks!; I'll take a look how it compares to what I did. ; One thing to note is that it'd be useful to be able to specify the length of the CB - we use 8 bp in our slightly-adapted CEL-Seq2 protocol.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/269#issuecomment-418579796:211,adapt,adapted,211,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/269#issuecomment-418579796,1,['adapt'],['adapted']
Energy Efficiency,"Ok, salmon V1.0.0 finished in 5H 15 min, so about 5 times faster, the exact same library and parameters, and achieved almost the same mapping rate (85.1058% with V1.2.0 vs 84.6341% with V1.0.0) attaching log. I must add I did not trim this library for adapters nor quality, nor did anything to it. Just mapped as is. But fastQC showed excellent levels of quality even at the ends and no or minimal adapter content. ; Also no changes have been done one my OS other than regular updates, but still Ubuntu 18.04. I don't remember any specific changes I've done to it. ; Pearson's correlation in transcript abundance (isoform lelvel) is 0.9984013. Spearman's is 0.9899048. ; Also, I did checked that salmon was actually using 4 threads in both cases, and it was fully using those.; [salmon_quant.log](https://github.com/COMBINE-lab/salmon/files/4707443/salmon_quant.log)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/527#issuecomment-636447127:252,adapt,adapters,252,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/527#issuecomment-636447127,2,['adapt'],"['adapter', 'adapters']"
Energy Efficiency,"Ok, thank you very much.; The problem I had was RAM availability. I enlarged it for 48 and it works.; However, to quantify I had another problem.; I use this command line and I increase to 56 RAM. srun ./salmon-1.5.2_linux_x86_64/bin/salmon quant -i salmon_index \; -l A \; -1 ERR3537668_1.fastq.gz \; -2 ERR3537668_2.fastq.gz \; -o transcripts_DecoyQuant \; --validateMappings \; --numBootstraps 100 \; --gcBias \; --seqBias\; -p 12. And I got this error message:; [2021-11-08 14:35:28.348] [jointLog] [info] Finished Bootstrapping; ERROR: Could not create the directory [""transcripts_quant""]. Please check; that. But actually, it was created.; I really don't understand the message error. Best wishes,; Luciana. On Fri, Nov 5, 2021 at 5:56 PM Rob Patro ***@***.***> wrote:. > Hi @lubios <https://github.com/lubios>,; >; > This suggests that the machine was not able to allocate enough memory to; > perform the requested operation. I would try the following things in order; > to see if they fix the issue. First, try quantifying without the; > decoy-aware index. This doesn't provide the benefits of the decoy sequence,; > but it will ensure that this is, in fact, the problem you are having. If; > that works, try building the decoy-aware index with the --sparse; > parameter. This will build the sparse index instead of the dense index,; > which is a bit smaller and may therefore fit in RAM on the machine where; > you are doing quantification.; >; > Best,; > Rob; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/COMBINE-lab/salmon/issues/717#issuecomment-962058307>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/ADRT5CUYGXBSY3UOX24RTYDUKQLETANCNFSM5HOIMSQQ>; > .; > Triage notifications on the go with GitHub Mobile for iOS; > <https://apps.apple.com/app/apple-store/id1477376905?ct=notification-email&mt=8&pt=524675>; > or Android; > <https://play.google.com/store/apps/details?id",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/717#issuecomment-963995631:871,allocate,allocate,871,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/717#issuecomment-963995631,1,['allocate'],['allocate']
Energy Efficiency,"Thank you for verifying @zhangchipku, and thank you very much for the kind words! We appreciate the feedback and input from our users like yourself. We'll prioritize the soft-clipping functionality for upcoming releases (maybe even the next if we can make that work in time). For the time being, I can recommend `fastp` as a fairly efficient / fast trimmer that. It might even be able to work in a streaming fashion so that you could pipe the trimmed reads directly to salmon.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-586548443:332,efficient,efficient,332,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-586548443,1,['efficient'],['efficient']
Energy Efficiency,"Thanks for the recommendation. I'll definitely take a look at it. It is true that we typically suggest that you drop singletons if they are created during e.g. adapter / quality trimming etc.. However, it is also the case that one really may only want to consider very ""light"" quality trimming for RNA-seq data [as suggested by Matt MacManes](https://www.frontiersin.org/articles/10.3389/fgene.2014.00013/full). . If the trimming leads to the loss of a large number of reads, my initial reaction would be to try an understand why. One could always ""re-synchronize"" the singletons by providing them with fake mates, which would cause them to be mapped and treated as orphans during quantification. However, again, it's probably worth understanding why an experiment ends up with a lot of singletons before going through the trouble of accounting for them.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/240#issuecomment-400061755:160,adapt,adapter,160,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/240#issuecomment-400061755,1,['adapt'],['adapter']
Energy Efficiency,"Thanks, I usually do not trim reads. I am surprised to see such a difference from version 0.8.3. Do you have a recommendation for --minScoreFraction if I do not trim reads? Or maybe I should go back to NOT using --validateMappings?; For testing purposes, I will try trimming the reads for this sample. Will report back.; Oh, and this sample was prepared by ultra-low RNA input protocol, so the issues of adapter contamination could be present.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-586475673:404,adapt,adapter,404,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-586475673,1,['adapt'],['adapter']
Energy Efficiency,"Thanks, both, for your thoughts here. . As I understand it, current UMI quantification approaches take a BAM file with read alignments and then (hopefully in some smart way) count unique UMIs from reads aligned to (overlapping?) genomic features of interest. In the first instance, can Salmon produce output compatible with those sorts of approaches? (I seem to recall it's possible to output (pseudo)BAMs, but I have not yet had a need for this.). @vals: your suggestion of just ignoring UMIs is interesting - hadn't thought about that. It would be cool to figure out if that actually works as you suggest it might. I don't have any brilliant brainwaves to offer at the moment, but to you first point, Rob, I _definitely_ think the desire is/will be there. The sheer number of cells being sequenced demands very computationally efficient quantification, and since Salmon is at least as accurate as competitors while being extremely fast, in my mind Salmon is the leading contender for very wide use. Apparently 10X is about to drop a dataset of 1.3M cells, so yeah...fast methods needed. D.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/93#issuecomment-255853373:829,efficient,efficient,829,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/93#issuecomment-255853373,1,['efficient'],['efficient']
Energy Efficiency,That sounds like a very good way of doing it :-). I'm sorry I was not clear enough - my question was acutally meant for a single sequence - let me try again:; Lets say we have a read pair where one mate maps fine - but the other mate have a problem - half of it is an adapter (or low quality sequence with to many errors). How would Salmon currently handle this situation where the first half of a sequence (e.g. nt 1-50) could be quasi-mapped to a transcript but the second half (nt 51-100) did not match anywhere? Would the the second half cause the whole sequence to be discarded or would it be enough that the first half matched for it to be considered/counted?,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/150#issuecomment-354955072:268,adapt,adapter,268,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/150#issuecomment-354955072,1,['adapt'],['adapter']
Energy Efficiency,"That works!. I wrote something very similar yesterday but using a here document generated from a Makefile in to job scheduler, and I couldn't get it to work. I'll file that under overcomplicating things...",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/29#issuecomment-168620775:116,schedul,scheduler,116,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/29#issuecomment-168620775,1,['schedul'],['scheduler']
Energy Efficiency,"The virtual memory should also be greatly reduced in 1.2.0 (which I am working on finalizing the release of at the moment). There will be detailed release notes describing the improvements. However, getting the pre-built index is probably worth it if it's the right organism and annotation.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/503#issuecomment-612193221:42,reduce,reduced,42,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/503#issuecomment-612193221,1,['reduce'],['reduced']
Energy Efficiency,"This is a different issue. This means that your BAM-file is ill-formed for consumption by salmon. Basically, the BAM input requirements for salmon are the same as those for RSEM. Specifically,. * All alignments for a given read must appear contiguously in the BAM file.; * If you have paired-end data, then the alignments must be of the form:; ```; alignment_1 for left read; alignment_1 for right read; alignment_2 for left read; alignment_2 for right read; ...; alignment_k for left read; alignment_k for right read; ```. * You cannot mix alignments for paired-end and single-end reads in the same BAM file. These requirements must be satisfied or the BAM file cannot be properly parsed / interpreted. Typically, this is done by passing the proper arguments to the aligner used upstream of salmon (for which we recommend Bowtie2 if you are aligning to a _de novo_ transcriptome or STAR if you are doing reference-based quantification against a genome assembly and annotation).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/822#issuecomment-1376659692:75,consumption,consumption,75,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/822#issuecomment-1376659692,1,['consumption'],['consumption']
Energy Efficiency,Using the --reduceGCMemory flag fixed it.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/708#issuecomment-923452593:12,reduce,reduceGCMemory,12,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/708#issuecomment-923452593,1,['reduce'],['reduceGCMemory']
Energy Efficiency,"Very interesting @gmarcais. I wonder if/how allocations have an effect here. Are all methods using pre-allocated space to store their captures? Also, is xpressive drunk?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/734#issuecomment-1024188974:103,allocate,allocated,103,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/734#issuecomment-1024188974,1,['allocate'],['allocated']
Energy Efficiency,"Well, one can certainly use a tool (like gffread or rsem-prepare-reference) to take a genome and a (possibly custom/augmented) GTF to extract a set of target transcripts. Above, it looks like you were only processing between 90 and 100k transcripts. Given the overall size of the overall reference — ~2.4 billion nucleotides — my guess would be that some of these transcripts may be exceedingly long (and perhaps extracted incorrectly from the underlying tool). I should note that an index can be built on large references (which is why we support 64-bit index construction), but it's a very rare use-case as most transcriptomes (even large _de novo_ transcriptomes) rarely cross the 2^31 barrier, and I would expect it to consume quite a bit of memory. The default `quasi` indexer of Salmon is optimized to be very fast for typical sized transcriptomes (usually a few hundred mega-bases) at the cost of using more memory. The alternative `fmd` index can be made more memory efficient, by setting a larger sampling factor, but the resulting mapping will be slower (though still much faster than standard alignment). I would first check to see if the transcripts.fa file contains what you were expecting (i.e. the normal transcriptome + the auxiliary transcripts you were interested in quantifying), and that you actually have close to 2.4Gb of non-redundant transcriptome sequence that you want to quantify. If this is the case, the options are to try and build the quasi-index on a large memory machine (building the index requires more memory than mapping with the constructed index), or using the fmd-index with a large sampling factor. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/39#issuecomment-176802594:975,efficient,efficient,975,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/39#issuecomment-176802594,1,['efficient'],['efficient']
Energy Efficiency,"What's wrong with actually running salmon, monitoring stderr for what you need, and then killing the process?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/189#issuecomment-361717344:43,monitor,monitoring,43,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/189#issuecomment-361717344,1,['monitor'],['monitoring']
Energy Efficiency,"Yep that should work too, although a couple of minor things, you might wanna use 10 reads since that's the lower bound. Secondly, those reads should be mapped too, I guess copy the 98 length sequence from the transposons's region. Lastly the UMI, if the UMI sequence overlap w/ already present UMI sequence then it can potentially effect the deduplication of cell having more than 10 counts, you might wanna chose a disjoint UMI sequence *not* in your dataset and reduce the count by 1 in the count matrix since if all newly added UMI are same and get mapped to same gene then it will be deduplicated to 1.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/253#issuecomment-406664115:464,reduce,reduce,464,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/253#issuecomment-406664115,1,['reduce'],['reduce']
Energy Efficiency,"You are right on the spot. ; After trimming, every problem went away:; ""num_processed"": 102482661,; ""num_mapped"": 85812375,; ""num_decoy_fragments"": 760387,; ""num_dovetail_fragments"": 1265734,; ""num_fragments_filtered_vm"": 7722295,; ""num_alignments_below_threshold_for_mapped_fragments_vm"": 293676436,; ""percent_mapped"": 83.7335546937057,. I would really like to have the soft clipping feature though. With salmon being so fast, trimming step basically takes more time than the salmon quantification step. A lot of us are now turning to cloud platforms and are charged by the the computing time. Some other questions unrelated to this topic:; For snRNA-seq like 10X platform, do you recommend just trimming read2?; From what I read out of documentation, decoy enhanced index would only work with --validateMapping. Would Alevin only work with non-decoy index then?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-586530740:560,charge,charged,560,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-586530740,1,['charge'],['charged']
Energy Efficiency,"You're very welcome! Sorry for the console spam in the first place; I wasn't anticipating usage scenarios with that type of imbalance between producers and consumers. My guess is that the newest version of Salmon will also consume slightly less user-time as well, since now the parsing thread will backoff rather than busy wait when it wants to produce more reads for consumption.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/152#issuecomment-349406690:368,consumption,consumption,368,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/152#issuecomment-349406690,1,['consumption'],['consumption']
Energy Efficiency,"```. Secondly, I created a new transcriptome-only salmon index (`singularity run -B /data $SALMON_SIMG salmon index -t genome.transcripts.fa -i salmon_index -k 31`), then ran `salmon quant` again (as above) but using the new transcriptome-only index. Note: 'genome.transcripts.fa' is the transcripts file created during the `nf-core/rnaseq` pipeline. Again, this analysis completed properly in a reasonable time. Seems like there is something very wrong with the 'gentrome.fa' file that's being created by `nf-core/rnaseq`! It's just so odd that _some_ samples would work and others wouldn't. 2. It's definitely worth noting that I originally opted against using `star_salmon` with the following command:. ```; nextflow run nf-core/rnaseq --max_memory 55.GB --fasta /data/reference_genomes/GRCh38/Homo_sapiens.GRCh38.dna_sm.primary_assembly.fa.gz --gtf /data/reference_genomes/GRCh38/Homo_sapiens.GRCh38.106.gtf.gz --skip_alignment --pseudo_aligner salmon --seq_center 'Ramaciotti Centre for Genomics' --input samplesheet.csv --outdir nf-core_results --save_merged_fastq true --skip_markduplicates true --extra_salmon_quant_args '--seqBias --gcBias --posBias' -profile singularity; ```. I'll re-run (a) using the refgenie salmon index specified; (b) with the `star_salmon` pathway to see if the decoy-aware index created that way is appropriate. 3. Other; I've installed `piscem` and can give it a go, although it does seem more like a salmon index issue with `nf-core/rnaseq` from the debugging above. Do you agree? If so, I'll raise an issue there. Considering this, would it still be useful to have access to the reads? I've got the green light to share them if need be. If so, what's a good contact address to share a OneDrive link?. Thanks!; Charles. p.s. something else odd that I can dig into further later if need be is that the singularity version of salmon created an index in about 5 minutes, yet the conda version has been creating the index for nearly 20 minutes so far with no change...",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/830#issuecomment-1441194948:2721,green,green,2721,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/830#issuecomment-1441194948,1,['green'],['green']
Energy Efficiency,"e *full* decoy index is substantially larger than the index on just the transcriptome (after all, it is indexing the entire human genome in addition to the transcriptome). One thing you might try to test this hypothesis, other than requesting to build on a node with more RAM, is to compute a hash (e.g. md5 or sha256 sum) on all of the files in the index, and also record their sizes. Then we can build the index on the same version of the files on our end and compare. Second — and perhaps more importantly for your end goal — the main purpose of the decoy-aware index is to improve specificity rather than sensitivity. That is, the decoys are designed to help avoid _spurious_ mapping of reads to an annotated transcript when a better explanation for the read exists elsewhere in the genome. However, the reads that are mapped to decoys are not otherwise used for quantification. Thus, using the decoy aware transcriptome index is unlikely to improve your mapping rate. I agree that your mapping rate does seem rather low. There are a few potential culprits here, and some diagnostics we can look at to see what might be going wrong. First, you can take a look at the file `aux_info/meta_info.json` in the salmon quantification directories to get a few more details about why reads were not mapped. If you share one of those files here I can describe the relevant fields. Also, I have two more rather common things to consider that might affect the mapping rate. One is to add the sequence for the ribosomal RNAs to your transcriptome before indexing and then quantifying. If your mapping rate increases considerably, this is evidence of rather inefficient depletion prior to sequencing. The other thing to consider is to do basic adapter / quality trimming on the reads to see if that affects your mapping rate at all. I hope these two different responses are useful, and I'll keep this issue open so feel free to reply here with any further questions or discoveries you make regarding the above.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/603#issuecomment-744162850:2071,adapt,adapter,2071,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/603#issuecomment-744162850,1,['adapt'],['adapter']
Energy Efficiency,"e I answer your question and layout my logic, I want to mention that I am **_not_** suggesting fastp is not doing its job, **_neither am I stating that fastp is working incorrectly_**. Now to my answer(s) and logic:; 1. With fastp, I am not sure if adapter trimming happens first and then quality trimming OR vice-versa. I could not find info on this from their README and **_I could be wrong here with my next line_** - [Based on Figure 1 of this paper, it looks to me as though quality trimming is done before adapter trimming](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6129281/figure/bty560-F1/). - [To quote Brian Bushnell (author of BBTools)]( http://seqanswers.com/forums/showpost.php?p=140819&postcount=5), . > It's best to do adapter-trimming first, then quality-trimming, because if you do quality-trimming first, sometimes adapters will be partially trimmed and become too short to be recognized as adapter sequence. When you run BBDuk with both quality-trimming and adapter-trimming in the same run, it will do adapter-trimming first, then quality-trimming. 2. I very well know that the advantage of using fastp is that it can do adapter trimming, etc in a automatic fashion - no need to provide external sequences (example adapter sequences). Yes, I know one can also provide a fasta file of adapters and fatsp will work off it. There are many fatsp issues in GH about adapter detection:. - fail to detect adpaters automatically - (https://github.com/OpenGene/fastp/issues/222 and https://github.com/OpenGene/fastp/issues/205). - [incorrect automatic adapter detection](https://github.com/OpenGene/fastp/issues/240). - [inconsistent behavior with different runs](https://github.com/OpenGene/fastp/issues/231). 3. When I see the above, I am bit skeptical using fastp for qc/adapter trimming. . After lot of trials with bbduk and fastp, I have decided to use bbduk and bbmap for my high throughput analysis. Below, I explain my reasoning behind those choices: . **_```Note - edited this ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-597393209:997,adapt,adapter-trimming,997,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-597393209,2,['adapt'],['adapter-trimming']
Energy Efficiency,"e correct command line `salmon quant` options for Lexogen/QuantSeq _(this will be referred to as QS in the rest of the message(s))_ ?. `salmon quant --threads 16 --noLengthCorrection --validateMappings --numBootstraps 100 -l SF -i <path_to_SAF_Gentrome_Index> -r <SE_READ_1.fq> -o <salmon_SE_READ_1>`. I chose the above command line options (`especially --noLengthCorrection`) based on [Rob's message here](https://groups.google.com/d/msg/sailfish-users/VIfqBwgF6xQ/fw-rgC_kAwAJ) and a [thread here](https://github.com/COMBINE-lab/salmon/issues/108). Let me elaborate the big picture of my analyses and give more details about how I came up with the mapping numbers in my original post. Big Picture - DEG identification for samples sequenced by ILMN (whole transcript method) and QS (3' method) - [something similar to this paper](https://bmcgenomics.biomedcentral.com/articles/10.1186/s12864-018-5393-3). Bioinformatics Pipeline(s) for both ILMN and QS :. 1. HISAT Method : Adapter/Quality Trimming, Hisat2-HTSEQ, Get_Count_Table, DESeq; 2. STAR_RSEM Method: Adapter/Quality Trimming, STAR_RSEM, Get_Count_Table, DESeq; 3. SAF Method: Adapter/Quality Trimming, SAF_SALMON, Get_Count_Table, DESeq; 4. Quasi-Mapping or TXOME Method: Adapter/Quality Trimming, TXOME_SALMON, Get_Count_Table, DESeq. I used UpSetR plots for comparisons of sets of DEGs from each method just [as you have shown in your recent preprint](https://www.biorxiv.org/content/10.1101/657874v1.full). In the ILMN analyses, there is great concordance between the SAF method and HISAT/STAR_RSEM method. However, in the QS analyses, there is very limited concordance between SAF and the HISAT/STAR_RSEM method. For QS analyses, the TXOME method shows great concordance with HISAT/STAR_RSEM. This finding made me wonder if this has to be something with my salmon quant command line options for QS. Therefore, I wanted to check how the QS expected counts for SAF method show up for all samples in my final summarized table (after tximpo",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-554768195:1016,Adapt,Adapter,1016,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-554768195,1,['Adapt'],['Adapter']
Energy Efficiency,"ed. There is a way to modify this behavior, but since stranded library prep is imperfect, the default behavior is the most reasonable for most situations. The reason that you'll see consistency in most cases, regardless of the library type, is as follows. Imagine that I have a read that maps to transcript 1 in the forward orientation and transcript 2 in the reverse orientation. Further, imagine I have a stranded library, and I expect all reads to map in the reverse orientation. If the mapping to transcript 1 is ""spurious"", there are unlikely to be many othe reads mapping to that transcript in this manner, while we would expect other reads to map to transcript 2 in the prescribed manner. Since Salmon considers all of the reads in its probabilistic model when deciding how each read should be allocated, the fact that many reads map to transcript 2 will increase its abundance and, likewise, increase the probability that we assign this read to transcript 2 --- that is, the other mappings will help us make the right choice, regardless of the fact that we neglected to assign a stranded library type. That said, there are situations where the library type makes a difference. This is most often for a few transcripts that are very sequence similar (e.g. Paralogs that happen to be on opposite strands). In this case, most of the reads that map to one transcript will map to the other as well. In this case, the much larger conditional probability of agreeing with the prescribed library type will cause these reads to be allocated to the transcript to which they map in the expected orientation. However, the fraction of such transcripts is usually a small proportion of all expressed transcripts in an experiment, which is why, even if you do have a stranded library and some strand-specific expression, you'd expect the overall concordance to be very high between runs with different provided library types. Let me know if this answers your question, and if you have any others. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/67#issuecomment-238090033:2208,allocate,allocated,2208,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/67#issuecomment-238090033,1,['allocate'],['allocated']
Energy Efficiency,"es. Those jobs are still running (it's only been about 4hrs as of this writing, I'll update my post if/when they complete). Current logs are showing that they quickly consume all the available memory, but have not yet crashed. I've also got versions with 128-512GB of memory requested (by powers of 2) for comparison. Some random notes: both the 31-mer index experienced about twice as many soft page reclaims with the new/faster version and experienced a few hard page faults (the previous version saw none of the latter). The 17-mer version experienced fewer page reclaims than any of the 31-mer indices and far fewer than with the prior version. Again, a few page faults crept in, but relatively few by percentage and likely not contributing any significant amount of time overall. [index-qacct-17mer.log](https://github.com/COMBINE-lab/salmon/files/4246516/index-qacct-17mer.log); [index-qacct-31mer.log](https://github.com/COMBINE-lab/salmon/files/4246517/index-qacct-31mer.log). **UPDATE**; The 16GB version finished running. It actually only took a little over 4 hours to run, as well. The troubling thing about this job seems to be that, despite having successfully completed, according to the accounting log it used over 20GB of memory... which should be impossible to do. Our resident experts suspect there's a race condition occurring at the tail end of the job and that all of that extra memory is being allocated before the scheduler can kill it for exceeding the limit. Whatever the case, though, this throws into question some of those numbers that I've been grabbing from the accounting logs --- it's either being misreported, or the memory gobbling is happening so rapidly that it may not, in fact, be being properly recorded. I tested the index anyway. It *appears* to be working just fine. Nothing faulted or crashed when I attempted to quantify some reads against it. [index-qacct-17mer-16gigs.log](https://github.com/COMBINE-lab/salmon/files/4247214/index-qacct-17mer-16gigs.log)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/476#issuecomment-590516702:2225,allocate,allocated,2225,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/476#issuecomment-590516702,2,"['allocate', 'schedul']","['allocated', 'scheduler']"
Energy Efficiency,"hello! have you by any chance figured it out? I have quite similiar problem. . I am running salmon v.1.1.0 on my ubuntu machine with 128GB of RAM. I set the limit for vitrual memory at ~75GB to not overload the system:. ```bash; ○ → ulimit -a; core file size (blocks, -c) 0; data seg size (kbytes, -d) unlimited; scheduling priority (-e) 0; file size (blocks, -f) unlimited; pending signals (-i) 514510; max locked memory (kbytes, -l) 65536; max memory size (kbytes, -m) unlimited; open files (-n) 1024; pipe size (512 bytes, -p) 8; POSIX message queues (bytes, -q) 819200; real-time priority (-r) 0; stack size (kbytes, -s) 8192; cpu time (seconds, -t) unlimited; max user processes (-u) 514510; virtual memory (kbytes, -v) 75331648; file locks (-x) unlimited; ```. I am building the index with the following command:. ```bash; salmon index \; -t /mnt/rescomp/ref/hg38/gentrome.fa.gz \; -i /mnt/rescomp/ref/hg38/salmon_index -k 31 \; --decoys /mnt/rescomp/ref/hg38/decoys.txt \; --threads 16 \; --gencode |& tee logs/salmon_index.log; ```. gentrome is created based on the gencode transcriptome (v33) and genome primary algnment sequence (GRCh38.p13). [salmon_index.log](https://github.com/COMBINE-lab/salmon/files/4392725/salmon_index.log). The output directory:; ```; ○ → ll /mnt/rescomp/ref/hg38/salmon_index; total 7.9G; drwxr-sr-x 1 37304 723 4.0K Mar 27 01:36 ./; drwxr-sr-x 1 37304 723 4.0K Mar 26 22:13 ../; -rw-r--r-- 1 37304 723 888K Mar 27 00:32 complete_ref_lens.bin; -rw-r--r-- 1 37304 723 31K Mar 27 00:27 duplicate_clusters.tsv; -rw-r--r-- 1 37304 723 674M Mar 27 01:46 path.bin; -rw-r--r-- 1 37304 723 55 Mar 27 01:46 pre_indexing.log; -rw-r--r-- 1 37304 723 40K Mar 27 01:46 ref_indexing.log; -rw-r--r-- 1 37304 723 3.3G Mar 27 00:32 ref_k31_fixed.fa; -rw-r--r-- 1 37304 723 703 Mar 27 00:32 ref_sigs.json; -rw-r--r-- 1 37304 723 4.1G Mar 27 01:36 tmp_dbg.bin; ```; I know for a fact that the memory usage did not go over 16GB. Any hints how to proceed?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/441#issuecomment-604919589:313,schedul,scheduling,313,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/441#issuecomment-604919589,1,['schedul'],['scheduling']
Energy Efficiency,"ing incorrectly_**. Now to my answer(s) and logic:; 1. With fastp, I am not sure if adapter trimming happens first and then quality trimming OR vice-versa. I could not find info on this from their README and **_I could be wrong here with my next line_** - [Based on Figure 1 of this paper, it looks to me as though quality trimming is done before adapter trimming](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6129281/figure/bty560-F1/). - [To quote Brian Bushnell (author of BBTools)]( http://seqanswers.com/forums/showpost.php?p=140819&postcount=5), . > It's best to do adapter-trimming first, then quality-trimming, because if you do quality-trimming first, sometimes adapters will be partially trimmed and become too short to be recognized as adapter sequence. When you run BBDuk with both quality-trimming and adapter-trimming in the same run, it will do adapter-trimming first, then quality-trimming. 2. I very well know that the advantage of using fastp is that it can do adapter trimming, etc in a automatic fashion - no need to provide external sequences (example adapter sequences). Yes, I know one can also provide a fasta file of adapters and fatsp will work off it. There are many fatsp issues in GH about adapter detection:. - fail to detect adpaters automatically - (https://github.com/OpenGene/fastp/issues/222 and https://github.com/OpenGene/fastp/issues/205). - [incorrect automatic adapter detection](https://github.com/OpenGene/fastp/issues/240). - [inconsistent behavior with different runs](https://github.com/OpenGene/fastp/issues/231). 3. When I see the above, I am bit skeptical using fastp for qc/adapter trimming. . After lot of trials with bbduk and fastp, I have decided to use bbduk and bbmap for my high throughput analysis. Below, I explain my reasoning behind those choices: . **_```Note - edited this on 02-Apr-2020 to have the correct order of operations ```_** . 1. **_STEP 1 - run bbmap.sh on raw fatsq file to remove contaminants as appropriate (rRNA, mitochondri",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-597393209:1161,adapt,adapter,1161,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-597393209,2,['adapt'],['adapter']
Energy Efficiency,"inly does seem very low. To answer your specific questions first:; 1) I'm not sure --- let's try tor find out; 2) I don't think so (if they are part of your index, they should be aligned against); 3) If there are many transcripts / targets you expect to be sequenced but which aren't present in this set, that can affect the mapping rate, but not likely to take it down to 6%. Here are the things I'd investigate --- roughly in order: . 1) In addition to the fraction of reads STAR mapped (which you report above), what fraction of the reads are assigned to features by featureCounts? In some cases, when there is a failure of rRNA depletion of polyA selection, you can end up with an experiment where most of the sequenced RNA comes from rRNA not present in the reference transcriptome. In this case, STAR will be able to align the reads to the genome, but you won't see these reads mapping to annotated features (and you also won't see them showing up in your transcript level quantifications). So, it may be worth to take a look at the count of reads assigned to the feature set of genes by featureCounts. 2) Above, it looks like a considerable number of fragments were discarded due to no alignment reaching the required alignment score (`11,448,458` fragments discarded because of this). Have you tried to adapter / quality trim the data? Does this have any effect on the mapping rate?. 3) If the above don't reveal any clues, I'd be happy to try to take a look at the data if you can share it. I'd be quite surprised if STAR is aligning a lot of reads *to transcriptome features* that are being missed by salmon. Nonetheless, if you pass the proper flags to STAR (including `--quantMode TranscriptomeSAM`), then you can use the SAM/BAM file generated by STAR to perform quantification with salmon (i.e. use STAR's alignments to do _transcript-level_ quantification). I'd be happy to help dig further on any of these, so please feel free to reach out if you find anything interesting. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/661#issuecomment-846251054:1381,adapt,adapter,1381,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/661#issuecomment-846251054,1,['adapt'],['adapter']
Energy Efficiency,"input gentrome file, replace ambiguous characters (e.g. `N`) with pseudo-random nucleotides. It will also report any transcripts smaller than the chosen k-mer size, and it will detect and remove (unless `--keepDuplicates` is passed) any identical / duplicate sequences. After all of this, it will begin constructing the index in earnest. This is done by running a modified version of [TwoPaCo](https://github.com/medvedevgroup/TwoPaCo) to construct the compacted colored de Bruijn graph on the gentrome, which is then indexed using our [pufferfish index](https://github.com/COMBINE-lab/pufferfish). The TwoPaCo algorithm that generates the compacted colored de Bruijn graph from the input sequence is based on a very elegant algorithm that couples a Bloom filter with an exact hash table, and makes two (or more) passes over the input to identify all of the junctions in the reference (which directly implies all unitigs). To make the algorithm work efficiently, one needs to have an estimate for the number of distinct k-mers that will be encountered in the reference sequence. If the estimate is too big, one wastes memory. If the estimate is too small, the Bloom filter is not big enough, it doesn't filter efficiently, and the algorithm ends up putting way too much data in the exact hash table. In order to determine how to set the Bloom filter size appropriately, we take the following approach. If the Bloom filter size isn't provided directly (_note_: this is _not_ the same as the k-mer size, this is an estimate of the total number of distinct k-mers in the entire input data), then we make a call to a function defined in the [ntCard](https://github.com/bcgsc/ntCard) library. This is a program designed specifically for cardinality estimation of k-mers in sequencing data. Based on the estimated number of distinct k-mers, we use the standard equations (derived from the theory behind Bloom filters) to set the Bloom filter to be of the smallest possible size that still achieves a relati",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/510#issuecomment-616713186:1318,efficient,efficiently,1318,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/510#issuecomment-616713186,1,['efficient'],['efficiently']
Energy Efficiency,"ion](https://github.com/Kingsford-Group/sad) (paper [here](https://www.cell.com/cell-systems/pdf/S2405-4712(19)30381-3.pdf)). This is sort of akin to what you are suggesting, and post-processes salmon output by looking for anomalous coverage profiles. It can both flag ""suspicious"" transcripts, and can also sometimes move reads around to mitigate anomalous coverage. Another tool / metric you might consider is the junction coverage compatibility (paper [here](https://www.life-science-alliance.org/content/2/1/e201800175)). While both of these approaches get at some of the core intuitions you raise in your response, they are both rather ""heavyweight"", and neither, of course, is built into salmon. So, I **completely agree** that a lightweight version of something like SAD would be great to have built _into_ salmon. Specifically, it makes a lot of sense to have some component of the likelihood account for the coverage profile of transcripts. While I don't know of any widely-used and actively maintained quantification tools that do this, the idea for this was proposed in the [iReckon paper](https://www.ncbi.nlm.nih.gov/pubmed/23204306) and a coverage-based heuristic was introduced. However, the coverage was not directly incorporated into the likelihood. Rather, a variant of the normal likelihood function was used and then coverage was used to select between different potential solutions that were otherwise of similar likelihood. Given issues like the one you see here, and the ones that we observed in the JCC paper and that Cong and Carl observed in the SAD paper, it seems clear that it would be a big win for a quantification tool to include some sort of built-in lightweight model for things like this. The big questions are (1) how do you fold this type of intuition formally into the probabilistic model and (2) is it possible to incorporate this information efficiently? I'm _very_ interested in pursuing something like this if it can be made to work efficiently. Thanks!; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-623047035:4212,efficient,efficiently,4212,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-623047035,2,['efficient'],['efficiently']
Energy Efficiency,"l have neighboring genomic DNA). I wanted to see how this ratio changes between samples (for example, in a snoRNA processing-defective mutant strain), but quickly realized this is not easily done in salmon or any other quant tools because the processed transcript is entirely a subset of the sequence of the pre-processed transcript. The only way to accurately quantify it is to use the coverage information, which as you agreed is not really taken into account downstream. If Salmon could incorporate the coverage information to solve this class of problem, that would indeed be a **huge win**. I think the ncRNA example would be both a great biologically-interesting motivating problem, as well as a good technical benchmark for implementing any new methods. It could even be used as a secondary RNA velocity measure in scRNA seq data, provided the method used can detect these (non-polyadenylated) transcripts. > The big questions are (1) how do you fold this type of intuition formally into the probabilistic model and (2) is it possible to incorporate this information efficiently?. This is definitely your domain of expertise (and I know it's a rhetorical question but I'd love to throw some ideas out here)... I can think of a few mostly heuristical approaches.... . 1) when apportioning reads to transcripts, after the mapping phase, incorporate a notion of ""evenness"" into the EM step... reads that decrease the variance in coverage are favored over reads that increase the variance (so, define read depth per 10 bp window or something and calculate the variance across all windows for the transcript, then try to assign reads such that they minimize read depth variance per isoform). The problem here is actual coverage biases may then masquerade as alternative transcript isoforms... 2) Use the information from the unique sequences between the transcripts... the read depth over unique regions updates the prior on the overall transcript abundance, and the otherwise non-unique reads get ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-623963851:2613,efficient,efficiently,2613,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-623963851,1,['efficient'],['efficiently']
Energy Efficiency,"mber of splices: GC/AG |	39101; Number of splices: AT/AC |	13983; Number of splices: Non-canonical |	478779; Mismatch rate per base, % |	0.56%; Deletion rate per base |	0.03%; Deletion average length |	4.89; Insertion rate per base |	0.03%; Insertion average length |	4.88; MULTI-MAPPING READS:; Number of reads mapped to multiple loci |	1029261; % of reads mapped to multiple loci |	1.20%; Number of reads mapped to too many loci |	565; % of reads mapped to too many loci |	0.00%; UNMAPPED READS:; Number of reads unmapped: too many mismatches |	0; % of reads unmapped: too many mismatches |	0.00%; Number of reads unmapped: too short |	47533174; % of reads unmapped: too short |	55.56%; Number of reads unmapped: other |	4006; % of reads unmapped: other |	0.00%; CHIMERIC READS:; Number of chimeric reads |	0; % of chimeric reads |	0.00%. ```. I filtered it by samtools -f 2 -F 3840 . and Salmon gave me this result which is still very weak: 24323638 counts. So I decided to reduce the parameters as indicated in this link: https://github.com/alexdobin/STAR/issues/169; Because I trimmed my sequence and some can have a size between 100pb -150pb. ` ""STAR --runThreadN {threads} --runMode alignReads --genomeDir {input.ref} --readFilesIn {input.fq1} {input.fq2} --readFilesCommand zcat --outSAMtype BAM Unsorted SortedByCoordinate --outFilterScoreMinOverLread 0 --outFilterMatchNminOverLread 0 --quantMode TranscriptomeSAM GeneCounts --outFileNamePrefix {output} --outStd Log {log} ""`. I got this final.out:; ```; Started job on |	Jul 05 14:25:19; Started mapping on |	Jul 05 14:25:23; Finished on |	Jul 05 16:37:44; Mapping speed, Million of reads per hour |	38.78. Number of input reads |	85547657; Average input read length |	298; UNIQUE READS:; Uniquely mapped reads number |	70090369; Uniquely mapped reads % |	81.93%; Average mapped length |	191.51; Number of splices: Total |	1068826; Number of splices: Annotated (sjdb) |	0; Number of splices: GT/AG |	470490; Number of splices: GC/AG |	43525",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/676#issuecomment-874540664:1867,reduce,reduce,1867,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/676#issuecomment-874540664,1,['reduce'],['reduce']
Energy Efficiency,"mming OR vice-versa. I could not find info on this from their README and **_I could be wrong here with my next line_** - [Based on Figure 1 of this paper, it looks to me as though quality trimming is done before adapter trimming](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6129281/figure/bty560-F1/). - [To quote Brian Bushnell (author of BBTools)]( http://seqanswers.com/forums/showpost.php?p=140819&postcount=5), . > It's best to do adapter-trimming first, then quality-trimming, because if you do quality-trimming first, sometimes adapters will be partially trimmed and become too short to be recognized as adapter sequence. When you run BBDuk with both quality-trimming and adapter-trimming in the same run, it will do adapter-trimming first, then quality-trimming. 2. I very well know that the advantage of using fastp is that it can do adapter trimming, etc in a automatic fashion - no need to provide external sequences (example adapter sequences). Yes, I know one can also provide a fasta file of adapters and fatsp will work off it. There are many fatsp issues in GH about adapter detection:. - fail to detect adpaters automatically - (https://github.com/OpenGene/fastp/issues/222 and https://github.com/OpenGene/fastp/issues/205). - [incorrect automatic adapter detection](https://github.com/OpenGene/fastp/issues/240). - [inconsistent behavior with different runs](https://github.com/OpenGene/fastp/issues/231). 3. When I see the above, I am bit skeptical using fastp for qc/adapter trimming. . After lot of trials with bbduk and fastp, I have decided to use bbduk and bbmap for my high throughput analysis. Below, I explain my reasoning behind those choices: . **_```Note - edited this on 02-Apr-2020 to have the correct order of operations ```_** . 1. **_STEP 1 - run bbmap.sh on raw fatsq file to remove contaminants as appropriate (rRNA, mitochondrial, chloroplast)_**; - You have alluded to the importance of removing contaminants [in this post](https://github.com/COMBINE-lab/salmo",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-597393209:1324,adapt,adapters,1324,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-597393209,1,['adapt'],['adapters']
Energy Efficiency,"omatic adapter detection](https://github.com/OpenGene/fastp/issues/240). - [inconsistent behavior with different runs](https://github.com/OpenGene/fastp/issues/231). 3. When I see the above, I am bit skeptical using fastp for qc/adapter trimming. . After lot of trials with bbduk and fastp, I have decided to use bbduk and bbmap for my high throughput analysis. Below, I explain my reasoning behind those choices: . **_```Note - edited this on 02-Apr-2020 to have the correct order of operations ```_** . 1. **_STEP 1 - run bbmap.sh on raw fatsq file to remove contaminants as appropriate (rRNA, mitochondrial, chloroplast)_**; - You have alluded to the importance of removing contaminants [in this post](https://github.com/COMBINE-lab/salmon/issues/160#issuecomment-334762498); >However, the other thing to try is simply to align one of these samples to the genome with a tool like STAR or HISAT2 and look at their mapping rate to known features. If it's similar, then the other reads could be accounted for by e.g. intron retention or even contamination. Finally, [@vals has an excellent series of blog posts on investigating and addressing low mapping rates](http://www.nxn.se/valent/2017/9/18/low-mapping-rate-5-human-dna-contamination); - bbmap Command ([based of this biostars post](https://www.biostars.org/p/143019/#210890)):; `bbmap.sh in=read_1.fq.gz ref=rRNA_Chlor_Mito.fa maxindel=1 minid=0.95 outu=clean_read_1.fq.gz nodisk`; - Strategy:; `use the rRNA+Mito+Chloroplast file and map the reads using bbmap, then collect the unmapped reads (clean_read_1.fq.gz) for my downstream analysis`. 2. **_STEP 2 - run bbduk.sh on the outu files from bbmap step -- the outu stands for output unmapped - as stated in the logic above, anything that is unmapped to the rRNA_Chlor_Mito.fa is a clean read for downstream analysis_**. I use bbduk with adapter trimming and quality trimming in same command line - also, the adapters.fa file that ships with BBTools can be used in all runs. Hope that helps.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-597393209:3423,adapt,adapter,3423,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-597393209,2,['adapt'],"['adapter', 'adapters']"
Energy Efficiency,"plicates` is passed) any identical / duplicate sequences. After all of this, it will begin constructing the index in earnest. This is done by running a modified version of [TwoPaCo](https://github.com/medvedevgroup/TwoPaCo) to construct the compacted colored de Bruijn graph on the gentrome, which is then indexed using our [pufferfish index](https://github.com/COMBINE-lab/pufferfish). The TwoPaCo algorithm that generates the compacted colored de Bruijn graph from the input sequence is based on a very elegant algorithm that couples a Bloom filter with an exact hash table, and makes two (or more) passes over the input to identify all of the junctions in the reference (which directly implies all unitigs). To make the algorithm work efficiently, one needs to have an estimate for the number of distinct k-mers that will be encountered in the reference sequence. If the estimate is too big, one wastes memory. If the estimate is too small, the Bloom filter is not big enough, it doesn't filter efficiently, and the algorithm ends up putting way too much data in the exact hash table. In order to determine how to set the Bloom filter size appropriately, we take the following approach. If the Bloom filter size isn't provided directly (_note_: this is _not_ the same as the k-mer size, this is an estimate of the total number of distinct k-mers in the entire input data), then we make a call to a function defined in the [ntCard](https://github.com/bcgsc/ntCard) library. This is a program designed specifically for cardinality estimation of k-mers in sequencing data. Based on the estimated number of distinct k-mers, we use the standard equations (derived from the theory behind Bloom filters) to set the Bloom filter to be of the smallest possible size that still achieves a relatively low, pre-specified, false positive rate. The message you are seeing is that the estimates suggest the Bloom filter should be of size 2^28 *bits*, which is ~ 33.55MB — pretty small, actually. This is because ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/510#issuecomment-616713186:1578,efficient,efficiently,1578,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/510#issuecomment-616713186,1,['efficient'],['efficiently']
Energy Efficiency,"quality-trimming, because if you do quality-trimming first, sometimes adapters will be partially trimmed and become too short to be recognized as adapter sequence. When you run BBDuk with both quality-trimming and adapter-trimming in the same run, it will do adapter-trimming first, then quality-trimming. 2. I very well know that the advantage of using fastp is that it can do adapter trimming, etc in a automatic fashion - no need to provide external sequences (example adapter sequences). Yes, I know one can also provide a fasta file of adapters and fatsp will work off it. There are many fatsp issues in GH about adapter detection:. - fail to detect adpaters automatically - (https://github.com/OpenGene/fastp/issues/222 and https://github.com/OpenGene/fastp/issues/205). - [incorrect automatic adapter detection](https://github.com/OpenGene/fastp/issues/240). - [inconsistent behavior with different runs](https://github.com/OpenGene/fastp/issues/231). 3. When I see the above, I am bit skeptical using fastp for qc/adapter trimming. . After lot of trials with bbduk and fastp, I have decided to use bbduk and bbmap for my high throughput analysis. Below, I explain my reasoning behind those choices: . **_```Note - edited this on 02-Apr-2020 to have the correct order of operations ```_** . 1. **_STEP 1 - run bbmap.sh on raw fatsq file to remove contaminants as appropriate (rRNA, mitochondrial, chloroplast)_**; - You have alluded to the importance of removing contaminants [in this post](https://github.com/COMBINE-lab/salmon/issues/160#issuecomment-334762498); >However, the other thing to try is simply to align one of these samples to the genome with a tool like STAR or HISAT2 and look at their mapping rate to known features. If it's similar, then the other reads could be accounted for by e.g. intron retention or even contamination. Finally, [@vals has an excellent series of blog posts on investigating and addressing low mapping rates](http://www.nxn.se/valent/2017/9/18/low-mappin",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-597393209:1805,adapt,adapter,1805,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-597393209,1,['adapt'],['adapter']
Energy Efficiency,"r resulting from the same sample using selective alignment, we could compare and contrast the two. At that point, there are a few options depending on how deeply you want to dive. You could try to see how STAR and selective alignment are mapping differently to these transcripts. One potential difference is that STAR is _a lot_ more happy to softclip reads, which selective alignment won't do by default (you can test the effect with the `--softclipOverhangs` to allow selective alignment to softclip reads that hang off the transcript end or `--softclip` to allow softclips anywhere). Note that selective alignment may _still_ be a bit more conservative than STAR about softclips simply because of the nature of the scoring function it uses. This might give you a sense if one of these alignment methodologies is more consistent with your expectations in this case. Another option is to consider doing a grouping with `terminus`. This will reduce the set of ""genes"" that you can call as DE, because it will be happy to group together transcripts from different genes. However, it should help considerably in eliminating DE from highly-uncertain point estimates. Finally, you might consider performing DE with swish (cc @mikelove as he might have some input here) rather than DESeq2 (though we've typically been using swish at the transcript level rather than the gene level). Unlike DESeq2, swish will explicitly take into account the inferential uncertainty in the abundance estimates, using the Gibbs samples produced by salmon. This will allow it to avoid spurious DE calls that might otherwise occur when you have highly uncertain transcripts that, by chance, end up being assigned very different abundances in different samples / over different runs. Sorry for the information dump, but I wanted to lay out what might be going on, how to assess it, and what some potential solutions might be. If you dive in to start investigating this, feel free to reach out in this issue along the way if yo",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/600#issuecomment-740363115:4127,reduce,reduce,4127,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/600#issuecomment-740363115,1,['reduce'],['reduce']
Energy Efficiency,"r_data.py"", line 145, in query; self.load(); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/conda/core/subdir_data.py"", line 210, in load; _internal_state = self._load(); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/conda/core/subdir_data.py"", line 375, in _load; raw_repodata_str = fetch_repodata_remote_request(; File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/conda/core/subdir_data.py"", line 701, in fetch_repodata_remote_request; resp = session.get(join_url(url, filename), headers=headers, proxies=session.proxies,; File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/requests/sessions.py"", line 542, in get; return self.request('GET', url, **kwargs); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/requests/sessions.py"", line 529, in request; resp = self.send(prep, **send_kwargs); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/requests/sessions.py"", line 645, in send; r = adapter.send(request, **kwargs); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/requests/adapters.py"", line 413, in send; conn = self.get_connection(request.url, proxies); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/requests/adapters.py"", line 308, in get_connection; raise InvalidProxyURL(""Please check proxy URL. It is malformed""; requests.exceptions.InvalidProxyURL: Please check proxy URL. It is malformed and could be missing the host. `$ /usr/local/bin/conda install salmon`. environment variables:; CIO_TEST=<not set>; CONDA_ROOT=/usr/local/Caskroom/miniforge/base; CURL_CA_BUNDLE=<not set>; INFOPATH=/opt/homebrew/share/info:; MANPATH=/opt/homebrew/share/man::; PATH=/opt/homebrew/bin:/opt/homebrew/sbin:/usr/local/bin:/usr/bin:/bin:/usr; /sbin:/sbin; REQUESTS_CA_BUNDLE=<not set>; SSL_CERT_FILE=<not set>; all_proxy=<set>. active environment : None; user config file : /Users/Benjamin/.condarc; populated config files : /usr/local/Cas",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/724#issuecomment-1171208515:4411,adapt,adapter,4411,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/724#issuecomment-1171208515,1,['adapt'],['adapter']
Energy Efficiency,"ranscriptome (with no decoys) gives me a mapping rate of `0.00378202832148367%`. The first thing I did was to quality and adapter trim the data (using `fastp -i SRR9007475.fastq.gz -o SRR9007475_trimmed.fastq.gz -q 10 -w 8`) and ... whoa. This is the fastp html report [fastp.html.zip](https://github.com/COMBINE-lab/salmon/files/4176345/fastp.html.zip). So the first astounding statistic, the mean read length before trimming is 51bp (these are relatively short single-end reads). The mean read length after trimming is 21bp! So, the average read length is, in fact, less than the k-mer length used for indexing (default is k=31). On the trimmed data, the mapping rate goes up to `2.3545475882931305%`, still very low, but now there's somewhat of an explanation, the average read is shorter than a single k-mer. So, the next thing I tried was indexing with a smaller k; a _really_ small one in this case,`k=15`. Then, I re-ran on the _trimmed_ reads (the fact that the trimming took us from 51-21bp suggests that the reads had a lot of low quality bases, adapter contamination, or both). Under this setting, I still get a very low mapping rate, but it was _much_ higher — `16.766993524863488%`. The final thing I tried was seeing how the mapping rate changed as I altered `--minScoreFraction`, which is the salmon parameter that determines the alignment score that a read must achieve in order to be mapped validly. The default is 0.65. This means that the read cannot have a score < 0.65 * the maximum achievable score for the read given it's length. In the case of a 21bp read, the best score would be a score of 42, so a read must obtain a score >= 27 in order to be mapped. This is already a pretty poor mapping, but I reduced it even more to 0.3 (so any read with a score > 12 would pass). This led to a mapping rate of `~46%`. However, at this point, I'm not sure I would be confident in such mappings. For example, the situation here would be a 21bp read with multiple mismatches and, much of",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/482#issuecomment-583799668:1452,adapt,adapter,1452,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/482#issuecomment-583799668,1,['adapt'],['adapter']
Energy Efficiency,"referred to as QS in the rest of the message(s))_ ?. `salmon quant --threads 16 --noLengthCorrection --validateMappings --numBootstraps 100 -l SF -i <path_to_SAF_Gentrome_Index> -r <SE_READ_1.fq> -o <salmon_SE_READ_1>`. I chose the above command line options (`especially --noLengthCorrection`) based on [Rob's message here](https://groups.google.com/d/msg/sailfish-users/VIfqBwgF6xQ/fw-rgC_kAwAJ) and a [thread here](https://github.com/COMBINE-lab/salmon/issues/108). Let me elaborate the big picture of my analyses and give more details about how I came up with the mapping numbers in my original post. Big Picture - DEG identification for samples sequenced by ILMN (whole transcript method) and QS (3' method) - [something similar to this paper](https://bmcgenomics.biomedcentral.com/articles/10.1186/s12864-018-5393-3). Bioinformatics Pipeline(s) for both ILMN and QS :. 1. HISAT Method : Adapter/Quality Trimming, Hisat2-HTSEQ, Get_Count_Table, DESeq; 2. STAR_RSEM Method: Adapter/Quality Trimming, STAR_RSEM, Get_Count_Table, DESeq; 3. SAF Method: Adapter/Quality Trimming, SAF_SALMON, Get_Count_Table, DESeq; 4. Quasi-Mapping or TXOME Method: Adapter/Quality Trimming, TXOME_SALMON, Get_Count_Table, DESeq. I used UpSetR plots for comparisons of sets of DEGs from each method just [as you have shown in your recent preprint](https://www.biorxiv.org/content/10.1101/657874v1.full). In the ILMN analyses, there is great concordance between the SAF method and HISAT/STAR_RSEM method. However, in the QS analyses, there is very limited concordance between SAF and the HISAT/STAR_RSEM method. For QS analyses, the TXOME method shows great concordance with HISAT/STAR_RSEM. This finding made me wonder if this has to be something with my salmon quant command line options for QS. Therefore, I wanted to check how the QS expected counts for SAF method show up for all samples in my final summarized table (after tximport). I got a colSum for all my samples and then checked the numbers for the transc",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-554768195:1101,Adapt,Adapter,1101,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-554768195,1,['Adapt'],['Adapter']
Energy Efficiency,"ting the index. It ensures that the index (and hence the resulting quantifications) contain the shortened names for gencode transcripts. In alignment-based mode, the behavior of the flag would have to be slightly different. It would have to re-normalize not only the names of the reference sequences in the fasta file, but it would also have to re-normalize the names in the BAM header so that they match. Specifically, the requirement is that the names of the sequences in the input fasta file are a 1-1 match with the names in the BAM header so that transcripts can be matched up properly with their sequences for training and applying the error model. However, if your BAM file already contains the stripped transcript names (i.e. if the BAM file header has the names without everything past the initial `|`), then I believe you can use the following command to have salmon do the same to the fasta file on the fly, so that the names match. ```{bash}; salmon-1.5.1_linux_x86_64/bin/salmon quant --ont -p 4 -t <(awk '{ if ($0 ~ ""^>"") { split($0,a,""|""); print a[1] } else { print $0 } }' Genome_files/gencode.vM24.transcripts.fa) -l U -a Documents/Day2_03_DRS_pass.bam -o Documents/counts/Day2_03_DRS_pass; ```. If the BAM file contains the ""full"" transcript name however, I think the current options are either to let salmon use the full transcript name from the fasta file, or to modify the GTF when running with minimap2, so that the BAM file itself contains the shortened names. Finally, I'd like to mention that the way you _intended_ to use the `--gencode` flag in alignment mode actually makes _a lot_ of sense, and I think it would be a very nice feature. Basically, the idea would be to apply stripping everything after the first `|` from *both* the fasta header and the BAM header, and using the reduced names for `quant.sf` outputs. We'll certainly. look into adding this functionality in a future release. Apologies for confusion caused by the ambiguous documentation of this flag. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/671#issuecomment-860792782:1998,reduce,reduced,1998,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/671#issuecomment-860792782,1,['reduce'],['reduced']
Energy Efficiency,"ubdir_data.py"", line 375, in _load; raw_repodata_str = fetch_repodata_remote_request(; File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/conda/core/subdir_data.py"", line 701, in fetch_repodata_remote_request; resp = session.get(join_url(url, filename), headers=headers, proxies=session.proxies,; File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/requests/sessions.py"", line 542, in get; return self.request('GET', url, **kwargs); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/requests/sessions.py"", line 529, in request; resp = self.send(prep, **send_kwargs); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/requests/sessions.py"", line 645, in send; r = adapter.send(request, **kwargs); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/requests/adapters.py"", line 413, in send; conn = self.get_connection(request.url, proxies); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/requests/adapters.py"", line 308, in get_connection; raise InvalidProxyURL(""Please check proxy URL. It is malformed""; requests.exceptions.InvalidProxyURL: Please check proxy URL. It is malformed and could be missing the host. `$ /usr/local/bin/conda install salmon`. environment variables:; CIO_TEST=<not set>; CONDA_ROOT=/usr/local/Caskroom/miniforge/base; CURL_CA_BUNDLE=<not set>; INFOPATH=/opt/homebrew/share/info:; MANPATH=/opt/homebrew/share/man::; PATH=/opt/homebrew/bin:/opt/homebrew/sbin:/usr/local/bin:/usr/bin:/bin:/usr; /sbin:/sbin; REQUESTS_CA_BUNDLE=<not set>; SSL_CERT_FILE=<not set>; all_proxy=<set>. active environment : None; user config file : /Users/Benjamin/.condarc; populated config files : /usr/local/Caskroom/miniforge/base/.condarc; conda version : 4.12.0; conda-build version : not installed; python version : 3.9.13.final.0; virtual packages : __osx=12.4=0; __unix=0=0; __archspec=1=arm64; base environment : /usr/local/Caskroom/miniforge/base (writable); conda av data dir ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/724#issuecomment-1171208515:4683,adapt,adapters,4683,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/724#issuecomment-1171208515,1,['adapt'],['adapters']
Energy Efficiency,"umGibbsSamples 100`) and to dump the range-factorized equivalence classes used for offline quantification (`-d`). The Gibbs sampling files will contain the traces for the transcripts in question over the various iterations of the sampling procedure. Transcripts where there is a tremendous amount of ambiguity will tend to have highly anti-correlated posterior samples, and similarly, if you were to consider the abundance output of these transcripts as a *group*, there would be a large reduction in inferential relative variance. In fact, we [wrote a whole paper on this topic](https://academic.oup.com/bioinformatics/article/36/Supplement_1/i102/5870485). Consider this example from that paper:. ![image](https://user-images.githubusercontent.com/361470/101438021-706d3600-38df-11eb-9ada-a54ea9092d2d.png). The x-axis is samples from the Gibbs chains, and the y-values denote the estimated number of reads assigned to both transcripts in each sample. The green line at the top is what you get if you sum the abundances of these two transcripts. The main point is that the inferential relative variance (adjusted ratio of the variance over the mean) is _much_ smaller for the sum of these transcripts than for either individually. This is strong evidence that they are _inherently_ uncertain given the read evidence and alignments used for quantification. The tool described in that paper, called [`terminus`](https://github.com/COMBINE-lab/terminus), is a tool for automatically finding such groups of transcripts. Anyway, once you have the Gibbs samples in hand, we can walk you though how to do some assessment of these transcripts (tagging @hiraksarkar here since he's most likely to have access to scripts that will let us look at the posterior samples from individual transcripts). Similarly, if you can provide the quantification directory, we can help examine this too. If this is the case, that the posterior distributions are highly anti-correlated, it is likely that the ambiguity you ar",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/600#issuecomment-740363115:2032,green,green,2032,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/600#issuecomment-740363115,1,['green'],['green']
Integrability," --noLengthCorrection --validateMappings --numBootstraps 100 -l SF -i <path_to_SAF_Gentrome_Index> -r <SE_READ_1.fq> -o <salmon_SE_READ_1>`. I chose the above command line options (`especially --noLengthCorrection`) based on [Rob's message here](https://groups.google.com/d/msg/sailfish-users/VIfqBwgF6xQ/fw-rgC_kAwAJ) and a [thread here](https://github.com/COMBINE-lab/salmon/issues/108). Let me elaborate the big picture of my analyses and give more details about how I came up with the mapping numbers in my original post. Big Picture - DEG identification for samples sequenced by ILMN (whole transcript method) and QS (3' method) - [something similar to this paper](https://bmcgenomics.biomedcentral.com/articles/10.1186/s12864-018-5393-3). Bioinformatics Pipeline(s) for both ILMN and QS :. 1. HISAT Method : Adapter/Quality Trimming, Hisat2-HTSEQ, Get_Count_Table, DESeq; 2. STAR_RSEM Method: Adapter/Quality Trimming, STAR_RSEM, Get_Count_Table, DESeq; 3. SAF Method: Adapter/Quality Trimming, SAF_SALMON, Get_Count_Table, DESeq; 4. Quasi-Mapping or TXOME Method: Adapter/Quality Trimming, TXOME_SALMON, Get_Count_Table, DESeq. I used UpSetR plots for comparisons of sets of DEGs from each method just [as you have shown in your recent preprint](https://www.biorxiv.org/content/10.1101/657874v1.full). In the ILMN analyses, there is great concordance between the SAF method and HISAT/STAR_RSEM method. However, in the QS analyses, there is very limited concordance between SAF and the HISAT/STAR_RSEM method. For QS analyses, the TXOME method shows great concordance with HISAT/STAR_RSEM. This finding made me wonder if this has to be something with my salmon quant command line options for QS. Therefore, I wanted to check how the QS expected counts for SAF method show up for all samples in my final summarized table (after tximport). I got a colSum for all my samples and then checked the numbers for the transcripts and the decoys - this lead me to post my original question on this thread.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-554768195:1177,Adapter,Adapter,1177,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-554768195,1,['Adapter'],['Adapter']
Integrability," ; libboost-all-dev ; liblzma-dev ; libbz2-dev ; cmake ; zlib1g-dev ; curl ; unzip ; wget ; libcurl4-openssl-dev ; libtbb-dev ; libtbb12 ; liblzma-dev ; libjemalloc2 ; pkg-config ; libgff-dev; ```. One thing I noticed during build is that, while I included `libjemalloc2` here, the salmon build procedure still downloaded and built `jemalloc`. However, I don't _think_ jemalloc is the thing causing the segfault. Regarding dependencies that can't be used — the current `libstaden` is behind the upstream release. The upstream release contains an important bug fix for a bug (and suggested fix that we proposed to the developer) upon which we rely. More importantly, afaik there is no relevant `libpufferfish-dev` package (we certainly have not made one), and so there is not even e.g. a check in the `CMakeLists.txt` file. Salmon's build always tries to run `fetchPufferfish.sh` to download the relevant `pufferfish` source files needed to build `salmon`. Critically, the relevant `pufferfish` dependencies and `salmon` releases move in lockstep. Each new `salmon` release it accompanied by a new tag in the `pufferfish` repo (so that the specific source used to build a given `salmon` release is fixed and easily trackable). So, I think the easiest way to move forward is to:. * do a diff of my list of packages above with what is pulled in by `apt build-dep salmon`. * figure out why, even when `libjemalloc2` is installed, the build system tries to build `jemalloc` itself (maybe we need the dev package?). * determine what folks want to do upstream about the lockstep pufferfish dependency. Right now, the `fetchPufferfish.sh` script pulls a tagged tarball from github and checks that the sha matches, and moves the relevant source files into place. This is true both when we build our own releases as well as when `salmon` is built for other distribution channels like `conda`. While I am happy to have someone figure out how to package that up as a package that can be put into the repo and depe",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1464538233:1182,depend,dependencies,1182,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1464538233,1,['depend'],['dependencies']
Integrability, [info] Index contained 182608 targets. processed 19000000 fragments; hits: 65897209; hits per frag: 3.47349. [2016-12-13 22:40:22.572] [jointLog] [info] Computed 137534 rich equivalence classes for further processing; [2016-12-13 22:40:22.572] [jointLog] [info] Counted 16265961 total reads in the equivalence classes; [2016-12-13 22:40:22.618] [jointLog] [info] Mapping rate = 83.509%. [2016-12-13 22:40:22.618] [jointLog] [info] finished quantifyLibrary(); [2016-12-13 22:40:22.619] [jointLog] [info] Starting optimizer; [2016-12-13 22:40:22.904] [jointLog] [info] Marked 0 weighted equivalence classes as degenerate; [2016-12-13 22:40:22.911] [jointLog] [info] iteration = 0 | max rel diff. = 299.976; [2016-12-13 22:40:23.620] [jointLog] [info] iteration = 100 | max rel diff. = 0.121769; [2016-12-13 22:40:24.367] [jointLog] [info] iteration = 200 | max rel diff. = 0.103587; [2016-12-13 22:40:25.102] [jointLog] [info] iteration = 300 | max rel diff. = 0.144748; [2016-12-13 22:40:25.815] [jointLog] [info] iteration = 400 | max rel diff. = 0.231057; [2016-12-13 22:40:26.505] [jointLog] [info] iteration = 500 | max rel diff. = 0.0156154; [2016-12-13 22:40:27.020] [jointLog] [info] iteration = 570 | max rel diff. = 0.00955966; [2016-12-13 22:40:27.052] [jointLog] [info] Finished optimizer; [2016-12-13 22:40:27.052] [jointLog] [info] writing output. [2016-12-13 22:40:27.523] [jointLog] [info] Starting Gibbs Sampler 1 week; 100% [=====================================================] in 44s; [2016-12-13 22:41:12.189] [jointLog] [info] Finished Gibbs Sampler; [2016-12-13 22:41:12.190] [jointLog] [warning] NOTE: Read Lib [SRR2454059.fq.gz] :. Detected a *potential* strand bias > 1% in an unstranded protocol check the file: test_quant/lib_format_counts.json for details; ```. edit: One note is that I was using my build of the same commit number. I'm running the executable you compiled now (since I had to put the appropriate libraries in the `LD_LIBRARY_PATH` to get it to be happy).,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-266934878:3787,protocol,protocol,3787,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-266934878,1,['protocol'],['protocol']
Integrability," dependencies that can't be used — the current `libstaden` is behind the upstream release. The upstream release contains an important bug fix for a bug (and suggested fix that we proposed to the developer) upon which we rely. More importantly, afaik there is no relevant `libpufferfish-dev` package (we certainly have not made one), and so there is not even e.g. a check in the `CMakeLists.txt` file. Salmon's build always tries to run `fetchPufferfish.sh` to download the relevant `pufferfish` source files needed to build `salmon`. Critically, the relevant `pufferfish` dependencies and `salmon` releases move in lockstep. Each new `salmon` release it accompanied by a new tag in the `pufferfish` repo (so that the specific source used to build a given `salmon` release is fixed and easily trackable). So, I think the easiest way to move forward is to:. * do a diff of my list of packages above with what is pulled in by `apt build-dep salmon`. * figure out why, even when `libjemalloc2` is installed, the build system tries to build `jemalloc` itself (maybe we need the dev package?). * determine what folks want to do upstream about the lockstep pufferfish dependency. Right now, the `fetchPufferfish.sh` script pulls a tagged tarball from github and checks that the sha matches, and moves the relevant source files into place. This is true both when we build our own releases as well as when `salmon` is built for other distribution channels like `conda`. While I am happy to have someone figure out how to package that up as a package that can be put into the repo and depended upon, we currently don't have the capacity to tackle that ourselves and don't have a suitable mechanism to replace the current approach to obtaining the dependent pufferfish files. However, this question is very important as e.g. a segfault exactly like the one you are encountering was actually a bug in the pufferfish source used in the 1.9.0 release of `salmon` that was _fixed_ for the 1.10.0 release. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1464538233:1771,depend,dependency,1771,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1464538233,3,['depend'],"['depended', 'dependency', 'dependent']"
Integrability," described in the Bowtie2 manual)](http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-dovetail) are considered discordant. This is the same default behavior imposed by Bowtie2. If you look in the `meta_info.json` file for some of these samples (which is in the `aux_info` subdirectory of the quantification directory for a sample), you can see how many mappings are being discarded by virtue of being dovetail mappings. It is possible to allow such alignments (consider them as concordant) by passing the `--allowDovetail` flag. It is not the case that such alignments are always ""bad"", its simply that one would not expect many fragments to align in such a way, and if these constitute the overwhelming majority of the mappings, one might be suspicious about the underlying data. * Selective alignment actually _aligns_ the reads to the transcriptome. For this purpose, it performs end-to-end alignment. This means that if you suspect that the sample may contain adapters or very low-quality read ends, the reads should be trimmed prior to quantification. It is, therefore, worth checking how the mapping rate changes for some of these samples if the reads are trimmed first. * Selective alignment is more robust than quasi-mapping to the chosen value of `-k`, the minimum match length used when searching for alignments. I noticed that some of the samples contain relatively short reads, so you might see if the mapping rate changes if you adopt a smaller value of `-k` in the index (e.g. we use `23` in the [pre-print](https://www.biorxiv.org/content/10.1101/657874v2.full.pdf)). * You mention that this index doesn't contain any decoy sequence. This of course, should not affect the mapping rate. However, I'd be quite curious to see if you index the reference using the _whole genome_ as decoy (i.e. the SAF method from the pre-print), how many reads are discarded because they map better to a decoy sequence (this information can also be obtained from `meta_info.json`). Thi",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/482#issuecomment-582734798:2780,adapter,adapters,2780,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/482#issuecomment-582734798,1,['adapter'],['adapters']
Integrability," library type. When I change the ""A"" to ""ISR"" or ""IU"", the % mapped changes a lot. That does seem strange, but I honestly don't know much about `Evigene` or what it's doing in combining these assemblies. When you specify ""IU"", the mappings will generally be _more_ lenient (i.e. you'd expect to get more mappings) than when you specify ""ISR"". The ""A"" flag just looks at how the first 10,000 reads map and guesses the library type based on that. On thing to make sure of is that your reads aren't ""ordered"" in any way, such that you'd expect the first 10,000 to deviate in any meaningful way from the statistics of the reads of the reads. > Is it better to build assemblies with strand-aware flags? If so, does it usually make a large difference to quantification results, or a minor one? I don't know what protocol the sequencing facility used, but I am sure I could ask them. I gather from my recent reading that the extra information gained by using a stranded protocol is worthwhile, so I would expect that the sequencing facility used one, but why doesn't Trinity or MEGAHIT detect the sequecing protocol that was used? . So there are really 2 questions here. *If* the data are stranded, then yes, it's worthwhile to use stranded flags in both assembly and quantification. This is because stranded protocols will allow you to better disambiguate (a) overlapping genes and (b) reads that are ambiguous between sequence-similar genes that happen to reside on different strands. The *second* question is why Trinity or MEGAHIT wouldn't detect this. The main reason for this is that these are assembly tools. Without access to a reference genome, there is no principled way for these tools to know what the orientation of a read is _a priori_, so they generally rely on the user to specify if the reads are stranded or unstranded. > Or, if you have to specify it, why do none of the example Trinity commands I've come across include this option? It doesn't strike me as a commonly used specification i",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/840#issuecomment-1493034427:1147,protocol,protocol,1147,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/840#issuecomment-1493034427,2,['protocol'],['protocol']
Integrability," main purpose of this is to avoid spurious mapping to transcriptomic sequences that may be similar to other unannotated sequences in the genome that are nonetheless a better match for the read (e.g. an unannotated possibly transcribed pseudogene). The way this works in practice is that both the transcript sequences themselves *and the full genome* are indexed. Any read that aligns _strictly better_ to the genome than the transcriptome is considered to map to a decoy, and is not used for the purposes of quantification. Consistent with the behavior I hypothesized above for STAR, if you have many softclipped bases at the end of the read that nonetheless match what is in the genome downstream of the end of the annotated transcript, you'll likely see these reads assigned as decoys. To check this, you can look at salmon's `meta_info.json` output file to see how many reads were mapped best to decoys. * Why do I see much higher counts for this gene with FeatureCounts?. * It depends on the specific behavior you invoke. However, my guess is that FeatureCounts is being run with flags such that reads that only somewhat overlap a feature are nonetheless assigned to it. This suggests that while no good alignment may actually exist to the annotated transcript, FeatureCounts is still assigning the read to that feature because it overlaps it to some degree and matches the corresponding location on the genome. Again, you can test this by changing the required overlap fraction of FeatureCounts. * Why does running salmon outside of nf-core produce much higher counts?. * Since you are indexing *just* the transcriptome, and not including the genome as decoy sequence (as is done in nf-core), then the only thing that will prevent reads from being assigned to the gene in question is if so much of the read overhangs off the end of the annotated transcript that no mapping matches the minimum required alignment score. This is likely to be a much more liberal threshold than what STAR allows, so",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/798#issuecomment-1237133883:2177,depend,depends,2177,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/798#issuecomment-1237133883,1,['depend'],['depends']
Integrability," parse reads and update estimates asynchronously). However, the more important point here is that the inference estimates returned by Salmon (and, for that matter, every other transcript-level expression tool) are the result of a statistical optimization procedure that cannot guarantee a unique global optimal solution (and, in fact, even if a global optimum could be guaranteed, there may be multiple different optima). Thus, there is uncertainty inherent in the statistical problem being solved. Of course, if one ordered updates in the same way and set up the initial conditions precisely the same, there would be convergence to the same result, but any sense of confidence there is illusory. However, Salmon does provide a way to quantify, statistically, confidence in the result. The `--numBootstraps` option will do bootstrap sampling, or the `--numGibbsSamples` option will perform posterior Gibbs sampling. Both of these techniques will provide samples from the posterior distribution, and the variance of these samples will give you some information about the variance in the results that are due purely to the inherent statistical uncertainty in the problem. In the `scripts` folder there is a python script `ConvertBootstrapsToTSV.py` that will convert either the bootstrap or gibbs samples to a easily readable tsv format. These samples represent the estimated number of reads coming from each transcript when sampling from the posterior. These can be used to empirically estimate that statistical uncertainty in the abundance estimates of the different transcripts. Finally, I'll note that while, for the reasons described above, the output is not purely deterministic. The difference between subsequent runs of salmon (with differences changing depending on the order in which reads are parsed and processed) is typically small (and much smaller than the statistical uncertainty in the abundance estimates of the transcripts). I'd be happy to answer any other questions you have. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/102#issuecomment-259464248:2190,depend,depending,2190,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/102#issuecomment-259464248,1,['depend'],['depending']
Integrability," protocols, it is usually the case that we get 1 read -> 1 transcript, even if we don't read the whole thing. We have tested the effect of this in ONT data with spike ins, and have verified that using `--noLengthCorrection` does generally lead to improved accuracy with respect to quantification estimates. We have informed ONT of this, and I would guess they may optimize the flags that are used soon (we have also developed an error model that works correctly for these long reads, and that should make it into the next release of salmon). Regarding the effect this has on the `NumReads` values reported by salmon, it's not as simple as with the `TPM` estimates. The length affects the assigned reads through the probabilistic model on which inference is done. With the length effect we have that P(f | t_i) ∝ P( position | f, t_i ) * P( alignment | f, t_i) --- forgetting the alignment term for the time being, we have that with length correction P( position | f, t_i ) ∝ 1 / l_i and without length correction the l_i term goes away. In other words, the probability of allocating reads has a term that depends on the effective length when the `--noLengthCorrection` flag is not passed, but that term goes away when it is passed. This is not quite as drastic as with TPM where the normalization includes the length directly in the normalization (note, however, that when the `--noLengthCorrection` flag is passed, this adjusts the TPM as well). Further, the `NumReads` is still better than TPM in this regard because it still encodes the effect size (i.e. `NumReads` will sum to the total number of aligned reads). Anyway TLDR: Passing the `--noLengthCorrection` flag *is* better for ONT data, though results without this flag are sub-optimal, they are not unusable. We have let ONT know about this, and I would suspect they will address it (perhaps they'll even accept a PR?). Finally, a long read error model has been created and will _hopefully_ make it to the next version of salmon. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/651#issuecomment-821995147:1444,depend,depends,1444,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/651#issuecomment-821995147,1,['depend'],['depends']
Integrability," std::char_traits<char>, std::allocator<char> > const, unsigned int> >, 4ul>::cuckoo_status cuckoohash_map<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, unsigned int, BarcodeGroupStringHasher, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, unsigned int> >, 4ul>::cuckoo_expand_simple<std::integral_constant<bool, false>, std::integral_constant<bool, false> >(unsigned long)::{lambda(unsigned long, unsigned long, std::__exception_ptr::exception_ptr&)#1}) (); #7 0x00000000007af2a3 in bool cuckoohash_map<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, unsigned int, BarcodeGroupStringHasher, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, unsigned int> >, 4ul>::cuckoo_reserve<std::integral_constant<bool, false> >(unsigned long) [clone .constprop.984] (); #8 0x00000000007d3e29 in void initiatePipeline<alevin::protocols::Chromium, boost::program_options::basic_parsed_options<char> >(AlevinOpts<alevin::protocols::Chromium>&, SalmonOpts&, boost::program_options::basic_parsed_options<char>&, boost::program_options::variables_map&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >, std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >) (); #9 0x00000000007b0935 in salmonBarcoding(int, char**) (); #10 0x000000000065d57c in main (); (gdb); ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-396078627:8698,protocol,protocols,8698,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-396078627,2,['protocol'],['protocols']
Integrability," subsetting from Biostrings, but in the premature case the strand information is used. Of course, this problem is out of the scope of this forum so it will be okay to close this issue. I will reach out to the developers of GenomicRanges and Biostrings to point out this potential problem and seek their guidance. Thank you again for all your help. Rached. ```; # setwd('wd'). options(scipen = 9999). libraries <- lapply(; X = c('data.table', 'magrittr', 'rtracklayer', 'Biostrings', 'reshape2', 'ggplot2'),; FUN = library, character.only = TRUE; ). ### Inputs ####; anot.gtf <- '../../shared_data/annotations/Ensembl/Homo_sapiens.GRCh38.101.gtf.gz' # Ensembl GTF; genome.fasta <- '../../shared_data/annotations/Ensembl/Homo_sapiens.GRCh38.dna.primary_assembly.fa.gz' # Genome fasta from Ensembl; gencode.tx.fasta <- '../../shared_data/annotations/Gencode/gencode.v35.transcripts.fa.gz' # Gencode transcript FASTA. dotPlot.fname <- '../ouput/dotPlots.pdf'. ### Read exon annotations ####; message('Loading Ensembl exon annotation (1-22, X, Y, MT)...'). chromosomes <- c(1:22, 'X', 'Y', 'MT'). anot <- import(anot.gtf, feature = 'exon') %>% sort; anot <- anot[seqnames(anot) %in% chromosomes, ]. # append gene and transcript version numbers to IDs; anot$gene_id <- paste(anot$gene_id, anot$gene_version, sep = '.'); anot$transcript_id <- paste(anot$transcript_id, anot$transcript_version, sep = '.'). ### Create premature transcript annotations ####; message('Creating premature transcript annotation...'). anot.pre <- split(anot, anot$transcript_id); anot.pre <- anot.pre[lengths(anot.pre) > 1] %>% range %>% unlist %>% sort # only consider transcripts with > 1 exon. anot.pre$transcript_range <- as.character(anot.pre); anot.pre$gene_id <- anot[match(names(anot.pre), anot$transcript_id), ]$gene_id. # collapse replicate pre-mature transcripts per gene...; names(anot.pre) <- anot.pre$premature_group <- sapply(; split(; names(anot.pre),; paste(anot.pre$gene_id, anot.pre$transcript_range, sep = '_');",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/655#issuecomment-826035191:4276,message,message,4276,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/655#issuecomment-826035191,1,['message'],['message']
Integrability," the right end of the transcript which is inconsistent with the coverage profile and, as hoped, salmon did not assign any reads to that variant. So, in these two scenarios the default options produce nice results in line with our human intuition. 2. **Failure scenario with default options:** ; ![PDI1_example](https://user-images.githubusercontent.com/10292386/86509895-3df36600-bda0-11ea-8f0b-df0de4fefa31.png); <img width=""383"" alt=""PDI1_table"" src=""https://user-images.githubusercontent.com/10292386/86509897-40ee5680-bda0-11ea-9566-9f2bdab464f0.png"">. In this example there are four genes (oriented in the same direction) with wildly different expression levels. I added a ""PDI1_SuperTranscript"" which stretches from the 5' end of PDI1 to the 3' end of POF1 (so, all reads from all 4 genes would multimap to the super transcript). This is a contrived example to illustrate the technical details, but you could imagine similar biological scenarios, especially regarding splicing isoforms. With the default options, you get the counterintuitive result that all of the reads from just MGR1 and POF1 (the two lowest abundance transcripts) are assigned to the super transcript. EMC1 loses ~50% of its reads to the super transcript, and PDI1 only loses ~10%. I'm not showing it, but if you remove the default PDI1 transcript from the index (so it's just the super transcript + the 3 genes MGR1/EMC1/POF1), all three of them lose all of their reads to the super transcript... meaning that whether or not EMC1 gets assigned any reads depends entirely on the presence of a non-overlapping gene, PDI1, in the salmon index. This is definitely at odds with our intuition from looking at the coverage plots, but makes sense when you break all the transcripts down to a simple reads per kb equation. As before, if you turn off length modeling then all of the reads get assigned to the super transcript. I hope this was insightful and cleared up the issue a bit. Feel free to e-mail or reply here. Best,; Jason",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-653747847:6417,depend,depends,6417,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-653747847,1,['depend'],['depends']
Integrability," transcript by salmon) as well as to the genome. It is quite common that the mapping rate to the genome is higher than that to the transcriptome. This is much more a result of what you are aligning _to_ than the aligner. If you were to take the transcriptome, and align to it using Hisat2 with `--no-spliced-alignment` and `--end-to-end` (since there won't be splice junctions when you align to the transcriptome), I'd expect you to get a similar mapping rate as you see in salmon. > I also noticed a high number of mappings discarded because of alignment score. I also wonder why the number of mappings discarded can be larger than num of processed (57113760, the reads number in 1_1.fq.gz). . Good question. The number you are looking at is the number of discarded _mappings_, not the number of discarded _fragments_. The difference is that every fragment can have many potential mappings. The number you are looking at is the total number of attempted _alignments_ that failed to achieve the threshold score. Luckily, salmon reports both numbers. The number of fragments for which _all_ alignments failed to reach the score threshold is `4,196,417`; given in `aux_info.json` by ` ""num_fragments_filtered_vm"": 4196417`. One point to note is that these are all fragments for which mapping is attempted (they had at least one k-mer match the reference), but no alignment was valid up to the threshold. You could try running the quantification again with `--softclip` to allow softclipping of the reads and see if any considerable fraction of these `4196417` failed to align because they overhang the annotated transcripts or contain adapters etc. Nonetheless, even if all of these mapped, the rate would still be ~72%. The remainder of the reads didn't even have a matching k-mer in common with the reference transcriptome, which means they are exceedingly unlikely to have come from the transcripts that were indexed. > Thanks. You're welcome! Please let me know if you have any follow-up questions.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/533#issuecomment-697125235:2029,adapter,adapters,2029,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/533#issuecomment-697125235,1,['adapter'],['adapters']
Integrability," v0.8 and 1.2.1. The one that seems most relevant here is the introduction of selective-alignment to replace the quasi-mapping procedure that was originally used in salmon. Selective-alignment actually scores the mappings found to the transcriptome, and rejects alignments whose quality is below a (user-specified) threshold. Here, you can see that, in 1.2.1. * 39 fragments are mapped within the score threshold; * 216 fragments are discarded because no mapping location has an alignment score above the threshold. all together, this means that the total number of ""mapped"" fragments in 1.2.1 is very similar to 0.8 (1.2.1 maps 39+216 = 255, while 0.8 maps 254). However, 1.2.1 discards 216 of the fragments because no mapping is sufficiently good. The default for ""sufficiently good"", by the way, is to have an alignment score of at least 65% of the maximum possible for a read of the given length. For typical RNA-seq data, this is actually quite liberal / generous, and is similar to the type of noise in alignment that Bowtie2 allows with the sensitive flag. In general, the heuristics used in 1.2.1 (selective-alignment) tend to be more sensitive than those used in 0.8 (quasi-mapping), since the mappings are then validated using alignment scoring. However, this does mean that the quality of the alignment along the whole read matters. Thus, it is more important to do quality / adapter trimming in the newer version compared to the older one. There is also a flag in 1.2.1 (`--softclip`) that will allow mismatches / gaps at the ends of reads to not detract from the alignment score. So, these are the main differences. However, looking at the output logs you provided, a couple of basic questions did come to mind. Why are there so few reads to begin with? Even in 0.8, only 254 reads mapped, which is obviously a very small number of reads. Is there something non-typical about this sample? Is it a full RNA-seq sample? Are these reads something atypical (like long reads — ONT or PacBio)?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/542#issuecomment-651332239:1497,adapter,adapter,1497,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/542#issuecomment-651332239,1,['adapter'],['adapter']
Integrability,"!grepl(';', anot.pre$premature_group) & anot.pre$premature_group %in% names(gencode) & !duplicated(anot.pre$premature_group) &; anot.pre$premature_group %in% anot[anot$transcript_source == 'ensembl_havana']$transcript_id; ]$premature_group[1]. chosenOnes <- c(chosenOnesP, chosenOnesM). # subset chosed ones; anot.ori <- anot; anot.pre.ori <- anot.pre. anot <- anot[anot$transcript_id %in% chosenOnes, ]; anot.pre <- anot.pre[anot.pre$premature_group %in% chosenOnes, ]. # sanity check (make sure strand information is the same for pre and mature RNA counterparts); all(; sort(paste(strand(anot), anot$transcript_id) %>% unique) ==; sort(paste(strand(anot.pre), anot.pre$premature_group) %>% unique); ) %>% print. ### Mature transcript sequences ####; message('Creating mature transcript sequences...'). # subset pos sorted exons, split by tx ID, concatenate exon seq per transcript using unlist; mature.tx <- lapply(; X = split(dna[anot], anot$transcript_id),; FUN = unlist; ) %>% DNAStringSet. message('... now getting reverse complements of mature transcripts on the minus strand...'). mature.tx[names(mature.tx) %in% anot[strand(anot) == '-', ]$transcript_id] <- reverseComplement(; mature.tx[names(mature.tx) %in% anot[strand(anot) == '-', ]$transcript_id]; ). ### Premature transcript sequences ####; message('Creating premature transcript sequences...'). premature.tx <- dna[anot.pre]. message('... now getting reverse complements of premature transcripts on the minus strand...'). premature.tx[names(premature.tx) %in% anot.pre[strand(anot.pre) == '-', ]$premature_group] <- reverseComplement(; premature.tx[names(premature.tx) %in% anot.pre[strand(anot.pre) == '-', ]$premature_group]; ). names(premature.tx) <- anot.pre$premature_group # paste0(anot.pre$premature_group, '_premature') # premature rna indicator. ### Dot plots ####; smoothDot <- function(s1, s2, w = 10) {. s1a <- sapply(; X = 1:(length(s1) - w + 1),; function(z) paste(s1[ z:(z + w - 1) ], collapse = ''); ). s2a <- sapply(;",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/655#issuecomment-826035191:7632,message,message,7632,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/655#issuecomment-826035191,1,['message'],['message']
Integrability,"# Create premature transcript annotations ####; message('Creating premature transcript annotation...'). anot.pre <- split(anot, anot$transcript_id); anot.pre <- anot.pre[lengths(anot.pre) > 1] %>% range %>% unlist %>% sort # only consider transcripts with > 1 exon. anot.pre$transcript_range <- as.character(anot.pre); anot.pre$gene_id <- anot[match(names(anot.pre), anot$transcript_id), ]$gene_id. # collapse replicate pre-mature transcripts per gene...; names(anot.pre) <- anot.pre$premature_group <- sapply(; split(; names(anot.pre),; paste(anot.pre$gene_id, anot.pre$transcript_range, sep = '_'); ),; paste, collapse = ';'; )[; paste(anot.pre$gene_id, anot.pre$transcript_range, sep = '_'); ]. # ... need to convert GR to data.table before unique because unique method for GR class ignores metadata and rownames; anot.pre <- as.data.table(anot.pre) %>% unique %>% makeGRangesFromDataFrame(., keep.extra.columns = T); names(anot.pre) <- anot.pre$premature_group. ### Read human genome sequence ####; message('Loading genome sequence...'). dna <- readDNAStringSet(filepath = genome.fasta). # simplify chromosome names; names(dna) <- sapply(strsplit(names(dna), ' '), '[', 1). dna <- dna[chromosomes] # subset chrom 1-22, X, Y, MT. ### Read Gencode transcript sequences ####; gencode <- readDNAStringSet(gencode.tx.fasta); names(gencode) <- gsub(; pattern = '\\|.*', replacement = '',; x = names(gencode); ). ### Sample transcripts on + and - strand (and avoid premature transcripts with multiple mature counterparts for simplicity); anot.pre <- anot.pre[order(width(anot.pre), decreasing = F), ]. chosenOnesP <- anot.pre[; strand(anot.pre) == '+' & !grepl(';', anot.pre$premature_group) & anot.pre$premature_group %in% names(gencode) & !duplicated(anot.pre$premature_group) &; anot.pre$premature_group %in% anot[anot$transcript_source == 'ensembl_havana']$transcript_id; ]$premature_group[1]. chosenOnesM <- anot.pre[; strand(anot.pre) == '-' & !grepl(';', anot.pre$premature_group) & anot.pre$prema",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/655#issuecomment-826035191:5692,message,message,5692,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/655#issuecomment-826035191,1,['message'],['message']
Integrability,"#449). Hi @s1corley<https://github.com/s1corley>. As @rob-p<https://github.com/rob-p> mentions, your paper could help assess different methodologies for quantification and also help optimize salmon further for QuantSeq. I would still like you to check if you have used salmon quant command line correctly for QuantSeq data analysis. Your paper briefly alludes to QuantSeq Forward in the Introduction section of the paper. The QuantSeq Forward kit has an oligo (dT) primer which contains the Illumina-specific Read 2 linker ... but the Methods section of your paper does not specify if you have used QuantSeq FWD or REV. Page 14 of the PDF from the Lexogen Website data analysis pipeline for QuantSeq FWD<https://www.bluebee.com/wp-content/uploads/2018/11/015UG108V0201-QuantSeq-Data-Analysis-Pipeline_2018-10-18.pdf> recommends using the below htseq command line. htseq-count -m intersection-nonempty -s yes -f bam -r pos $bam; $resource_dir/annotation.gtf > $bam_dir/read_counts.txt. QuantSeq is a stranded protocol. For the QuantSeq FWD pipeline the argument -s yes indicates; stranded in the sense orientation. For the QuantSeq REV pipeline -s reverse is used. Similar to the above htseq command line arguments, I think if you are using QuantSeq FWD, the libType argument from salmon quant should have been SF. One way I checked these with my datasets was to run the salmon quant command 3 times - once with libType A, once with libType SF and once with libType SR -- with QuantSeq FWD the estimated counts will be almost same with libType A and libType SF. I echo what @rob-p<https://github.com/rob-p> says - Congratulations once again on the paper. —; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://github.com/COMBINE-lab/salmon/issues/449?email_source=notifications&email_token=AC4A5AGWBAOLTI4MOFLAJNDQYQN7FA5CNFSM4JOIEHZ2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEG3S5HQ#issuecomment-565653150>, or unsubscribe<http",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-565684552:1950,protocol,protocol,1950,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-565684552,1,['protocol'],['protocol']
Integrability,"**Hi all,; Just an update:; I also got same warning message (as @rbenel talk about it here) when creating index along with decoy sequences I took @kvittingseerup's advice and made a transcripts.fa file by gffread command. Here is my input files and commend:; All gtf and genome references were downloaded from GENCODE: GRCh38.primary_assembly.genome.fa.gz, gencode.v36.annotation.gtf (CHR) and gencode.v36.transcripts.fa.gz.; commends:; grep ""^>"" <(gunzip -c GRCh38.primary_assembly.genome.fa.gz) | cut -d "" "" -f 1 > decoys.txt; sed -i.bak -e 's/>//g' decoys.txt; cat salmon_transcripts.fa.gz GRCh38.primary_assembly.genome.fa.gz > gentrome.fa.gz; salmon index -t gentrome.fa.gz -d decoys.txt -p 12 -i salmon-decoy-sa-index --gencode; warnings:**. [Step 1 of 4] : counting k-mers; [2020-12-26 10:47:50.823] [puff::index::jointLog] [warning] Entry with header [ENST00000473810.1|ENSG00000239255.1|OTTHUMG00000157482|OTTHUMT00000348942.1|AC007620.1-201|AC007620.1|25|processed_pseudogene|], had length less than equal to the k-mer length of 31 (perhaps after poly-A clipping); [2020-12-26 10:47:50.973] [puff::index::jointLog] [warning] Entry with header [ENST00000603775.1|ENSG00000271544.1|OTTHUMG00000184300|OTTHUMT00000468575.1|AC006499.8-201|AC006499.8|23|processed_pseudogene|], had length less than equal to the k-mer length of 31 (perhaps after poly-A clipping); [2020-12-26 10:47:52.758] [puff::index::jointLog] [warning] Entry with header [ENST00000632684.1|ENSG00000282431.1|OTTHUMG00000190602|OTTHUMT00000485301.1|TRBD1-201|TRBD1|12|TR_D_gene|], had length less than equal to the k-mer length of 31 (perhaps after poly-A clipping); [2020-12-26 10:47:54.950] [puff::index::jointLog] [warning] Entry with header [ENST00000543745.1|ENSG00000255972.1|OTTHUMG00000168883|OTTHUMT00000401485.1|AC026333.1-201|AC026333.1|28|processed_pseudogene|], had length less than equal to the k-mer length of 31 (perhaps after poly-A clipping); [2020-12-26 10:47:55.202] [puff::index::jointLog] [warning] Entry",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/214#issuecomment-751354991:52,message,message,52,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/214#issuecomment-751354991,1,['message'],['message']
Integrability,"**Hi all,; Just an update:; I also got same warning message (as @rbenel talk about it here) when creating index along with decoy sequences I took @kvittingseerup's suggestion and made a transcripts.fa file by gffread command. Here is my input files and commend:; All gtf and genome references were downloaded from GENCODE: GRCh38.primary_assembly.genome.fa.gz, gencode.v36.annotation.gtf (CHR), gencode.v36.transcripts.fa.gz.; commends:; grep ""^>"" <(gunzip -c GRCh38.primary_assembly.genome.fa.gz) | cut -d "" "" -f 1 > decoys.txt; sed -i.bak -e 's/>//g' decoys.txt; cat salmon_transcripts.fa.gz GRCh38.primary_assembly.genome.fa.gz > gentrome.fa.gz; salmon index -t gentrome.fa.gz -d decoys.txt -p 12 -i salmon-decoy-sa-index --gencode; warnings:**; [Step 1 of 4] : counting k-mers; [2020-12-26 10:47:50.823] [puff::index::jointLog] [warning] Entry with header [ENST00000473810.1|ENSG00000239255.1|OTTHUMG00000157482|OTTHUMT00000348942.1|AC007620.1-201|AC007620.1|25|processed_pseudogene|], had length less than equal to the k-mer length of 31 (perhaps after poly-A clipping); [2020-12-26 10:47:50.973] [puff::index::jointLog] [warning] Entry with header [ENST00000603775.1|ENSG00000271544.1|OTTHUMG00000184300|OTTHUMT00000468575.1|AC006499.8-201|AC006499.8|23|processed_pseudogene|], had length less than equal to the k-mer length of 31 (perhaps after poly-A clipping); [2020-12-26 10:47:52.758] [puff::index::jointLog] [warning] Entry with header [ENST00000632684.1|ENSG00000282431.1|OTTHUMG00000190602|OTTHUMT00000485301.1|TRBD1-201|TRBD1|12|TR_D_gene|], had length less than equal to the k-mer length of 31 (perhaps after poly-A clipping); [2020-12-26 10:47:54.950] [puff::index::jointLog] [warning] Entry with header [ENST00000543745.1|ENSG00000255972.1|OTTHUMG00000168883|OTTHUMT00000401485.1|AC026333.1-201|AC026333.1|28|processed_pseudogene|], had length less than equal to the k-mer length of 31 (perhaps after poly-A clipping); [2020-12-26 10:47:55.202] [puff::index::jointLog] [warning] Entr",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/214#issuecomment-751354493:52,message,message,52,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/214#issuecomment-751354493,1,['message'],['message']
Integrability,"**_I could be wrong here with my next line_** - [Based on Figure 1 of this paper, it looks to me as though quality trimming is done before adapter trimming](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6129281/figure/bty560-F1/). - [To quote Brian Bushnell (author of BBTools)]( http://seqanswers.com/forums/showpost.php?p=140819&postcount=5), . > It's best to do adapter-trimming first, then quality-trimming, because if you do quality-trimming first, sometimes adapters will be partially trimmed and become too short to be recognized as adapter sequence. When you run BBDuk with both quality-trimming and adapter-trimming in the same run, it will do adapter-trimming first, then quality-trimming. 2. I very well know that the advantage of using fastp is that it can do adapter trimming, etc in a automatic fashion - no need to provide external sequences (example adapter sequences). Yes, I know one can also provide a fasta file of adapters and fatsp will work off it. There are many fatsp issues in GH about adapter detection:. - fail to detect adpaters automatically - (https://github.com/OpenGene/fastp/issues/222 and https://github.com/OpenGene/fastp/issues/205). - [incorrect automatic adapter detection](https://github.com/OpenGene/fastp/issues/240). - [inconsistent behavior with different runs](https://github.com/OpenGene/fastp/issues/231). 3. When I see the above, I am bit skeptical using fastp for qc/adapter trimming. . After lot of trials with bbduk and fastp, I have decided to use bbduk and bbmap for my high throughput analysis. Below, I explain my reasoning behind those choices: . **_```Note - edited this on 02-Apr-2020 to have the correct order of operations ```_** . 1. **_STEP 1 - run bbmap.sh on raw fatsq file to remove contaminants as appropriate (rRNA, mitochondrial, chloroplast)_**; - You have alluded to the importance of removing contaminants [in this post](https://github.com/COMBINE-lab/salmon/issues/160#issuecomment-334762498); >However, the other thing to try is",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-597393209:1401,adapter,adapter,1401,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-597393209,1,['adapter'],['adapter']
Integrability,"--noLengthCorrection --validateMappings --numBootstraps 100 -l SF -i <path_to_SAF_Gentrome_Index> -r <SE_READ_1.fq> -o <salmon_SE_READ_1>`. I chose the above command line options (`especially --noLengthCorrection`) based on [Rob's message here](https://groups.google.com/d/msg/sailfish-users/VIfqBwgF6xQ/fw-rgC_kAwAJ) and a [thread here](https://github.com/COMBINE-lab/salmon/issues/108). Let me elaborate the big picture of my analyses and give more details about how I came up with the mapping numbers in my original post. Big Picture - DEG identification for samples sequenced by ILMN (whole transcript method) and QS (3' method) - [something similar to this paper](https://bmcgenomics.biomedcentral.com/articles/10.1186/s12864-018-5393-3). Bioinformatics Pipeline(s) for both ILMN and QS :. 1. HISAT Method : Adapter/Quality Trimming, Hisat2-HTSEQ, Get_Count_Table, DESeq; 2. STAR_RSEM Method: Adapter/Quality Trimming, STAR_RSEM, Get_Count_Table, DESeq; 3. SAF Method: Adapter/Quality Trimming, SAF_SALMON, Get_Count_Table, DESeq; 4. Quasi-Mapping or TXOME Method: Adapter/Quality Trimming, TXOME_SALMON, Get_Count_Table, DESeq. I used UpSetR plots for comparisons of sets of DEGs from each method just [as you have shown in your recent preprint](https://www.biorxiv.org/content/10.1101/657874v1.full). In the ILMN analyses, there is great concordance between the SAF method and HISAT/STAR_RSEM method. However, in the QS analyses, there is very limited concordance between SAF and the HISAT/STAR_RSEM method. For QS analyses, the TXOME method shows great concordance with HISAT/STAR_RSEM. This finding made me wonder if this has to be something with my salmon quant command line options for QS. Therefore, I wanted to check how the QS expected counts for SAF method show up for all samples in my final summarized table (after tximport). I got a colSum for all my samples and then checked the numbers for the transcripts and the decoys - this lead me to post my original question on this thread.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-554768195:1273,Adapter,Adapter,1273,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-554768195,1,['Adapter'],['Adapter']
Integrability,"-4}"" --incompatPrior 1e-20 --biasSpeedSamp 1 --fldMax 1000 --fldMean 200 --fldSD 80 --forgettingFactor 0.65 --maxReadOcc 100 --numBiasSamples 2000000 --numAuxModelSamples 5000000 --numPreAuxModelSamples 1000000 --numGibbsSamples 0 --numBootstraps 0 --consensusSlack 0 --vbPrior 0.001 --sigDigits 3; ```. - `syslog`; ```; Aug 27 20:14:23 ip-172-31-16-139 kernel: [ 2134.447133] traps: salmon[7495] general protection ip:7ff9ce320dca sp:7ffd6e497020 error:0 in libtbb.so.2[7ff9ce2fe000+37000]; ```. **`salmon 0.11.2 run with: NativeSpecification --ntasks=1 --nodes=1 --mem-per-cpu=100000`**; - `scontrol show job 99`; ```; JobId=99 Name=g995_salmon_refinery_stemcellcommons_org; UserId=galaxy(1001) GroupId=users(100); Priority=4294901662 Account=(null) QOS=(null); JobState=COMPLETED Reason=None Dependency=(null); Requeue=1 Restarts=0 BatchFlag=1 ExitCode=0:0; RunTime=00:07:36 TimeLimit=UNLIMITED TimeMin=N/A; SubmitTime=2018-08-27T20:20:26 EligibleTime=2018-08-27T20:20:26; StartTime=2018-08-27T20:20:26 EndTime=2018-08-27T20:28:02; PreemptTime=None SuspendTime=None SecsPreSuspend=0; Partition=main AllocNode:Sid=ip-172-31-24-127:7975; ReqNodeList=(null) ExcNodeList=(null); NodeList=w21; BatchHost=w21; NumNodes=1 NumCPUs=1 CPUs/Task=1 ReqS:C:T=*:*:*; MinCPUsNode=1 MinMemoryNode=100000M MinTmpDiskNode=0; Features=(null) Gres=(null) Reservation=(null); Shared=OK Contiguous=0 Licenses=(null) Network=(null); Command=(null); WorkDir=/mnt/galaxy/tmp/job_working_directory/000/995; ```. - `Galaxy stderr`; ```; Fatal error: Exit code 139 (); ...; /mnt/galaxy/tmp/job_working_directory/000/995/tool_script.sh: line 50: 9700 Segmentation fault (core dumped) salmon quant --index ./index --libType U --unmatedReads ./single.fastq --output ./output --allowOrphans --ma 2 --mp 4 --go 5 --ge 3 --minScoreFraction 0.65 --threads ""${GALAXY_SLOTS:-4}"" --incompatPrior 1e-20 --biasSpeedSamp 1 --fldMax 1000 --fldMean 200 --fldSD 80 --forgettingFactor 0.65 --maxReadOcc 100 --numBiasSamples 2000000 --numAuxMo",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/271#issuecomment-416364238:4204,Depend,Dependency,4204,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/271#issuecomment-416364238,1,['Depend'],['Dependency']
Integrability,"-p modfiles/$PACKAGE_NAME. cd source/$PACKAGE_NAME/$VERSION; wget $LATEST_RELEASE -O - | tar -xz --strip-components 1; cmake -DBOOST_ROOT=/global/software/sl-7.x86_64/modules/gcc/7.4.0/boost/1.70.0-gcc -DCMAKE_INSTALL_PREFIX=$INSTALL_DIR; make; ```; And the tail of the output from make:. ```; creating: /clusterfs/vector/home/groups/software/sl-7.x86_64/source/salmon/1.5.1/scripts/../external/pufferfish-salmon-v1.5.1/tests/compile_tests/; inflating: /clusterfs/vector/home/groups/software/sl-7.x86_64/source/salmon/1.5.1/scripts/../external/pufferfish-salmon-v1.5.1/tests/compile_tests/int128_numeric_limits.cpp ; -- fetch PUFFERFISH exit code 0; -- Found ZLIB: /usr/lib64/libz.so (found version ""1.2.11"") ; -- Performing Test Iconv_IS_BUILT_IN; -- Performing Test Iconv_IS_BUILT_IN - Failed; CMake Error at /global/home/groups/consultsw/sl-7.x86_64/modules/cmake/3.15.1/share/cmake-3.15/Modules/FindPackageHandleStandardArgs.cmake:137 (message):; Could NOT find Iconv (missing: Iconv_LIBRARY); Call Stack (most recent call first):; /global/home/groups/consultsw/sl-7.x86_64/modules/cmake/3.15.1/share/cmake-3.15/Modules/FindPackageHandleStandardArgs.cmake:378 (_FPHSA_FAILURE_MESSAGE); /global/home/groups/consultsw/sl-7.x86_64/modules/cmake/3.15.1/share/cmake-3.15/Modules/FindIconv.cmake:120 (find_package_handle_standard_args); CMakeLists.txt:362 (find_package). -- Configuring incomplete, errors occurred!; See also ""/clusterfs/vector/home/groups/software/sl-7.x86_64/source/salmon/1.5.1/CMakeFiles/CMakeOutput.log"".; See also ""/clusterfs/vector/home/groups/software/sl-7.x86_64/source/salmon/1.5.1/CMakeFiles/CMakeError.log"".; ```; I'm also attaching the full CMake logs. This is right at the edge of my knowledge, so I'm not 100% sure I got libiconv installed correctly. Compilation completed without error, and I added the bin, include, and lib directories to PATH, CPATH, and LD_LIBRARY_PATH, respectively. [CMakeError.log](https://github.com/COMBINE-lab/salmon/files/6665942/CMakeError.l",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/453#issuecomment-862737315:1994,message,message,1994,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/453#issuecomment-862737315,1,['message'],['message']
Integrability,"/PMC6129281/figure/bty560-F1/). - [To quote Brian Bushnell (author of BBTools)]( http://seqanswers.com/forums/showpost.php?p=140819&postcount=5), . > It's best to do adapter-trimming first, then quality-trimming, because if you do quality-trimming first, sometimes adapters will be partially trimmed and become too short to be recognized as adapter sequence. When you run BBDuk with both quality-trimming and adapter-trimming in the same run, it will do adapter-trimming first, then quality-trimming. 2. I very well know that the advantage of using fastp is that it can do adapter trimming, etc in a automatic fashion - no need to provide external sequences (example adapter sequences). Yes, I know one can also provide a fasta file of adapters and fatsp will work off it. There are many fatsp issues in GH about adapter detection:. - fail to detect adpaters automatically - (https://github.com/OpenGene/fastp/issues/222 and https://github.com/OpenGene/fastp/issues/205). - [incorrect automatic adapter detection](https://github.com/OpenGene/fastp/issues/240). - [inconsistent behavior with different runs](https://github.com/OpenGene/fastp/issues/231). 3. When I see the above, I am bit skeptical using fastp for qc/adapter trimming. . After lot of trials with bbduk and fastp, I have decided to use bbduk and bbmap for my high throughput analysis. Below, I explain my reasoning behind those choices: . **_```Note - edited this on 02-Apr-2020 to have the correct order of operations ```_** . 1. **_STEP 1 - run bbmap.sh on raw fatsq file to remove contaminants as appropriate (rRNA, mitochondrial, chloroplast)_**; - You have alluded to the importance of removing contaminants [in this post](https://github.com/COMBINE-lab/salmon/issues/160#issuecomment-334762498); >However, the other thing to try is simply to align one of these samples to the genome with a tool like STAR or HISAT2 and look at their mapping rate to known features. If it's similar, then the other reads could be accounted for by ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-597393209:1583,adapter,adapter,1583,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-597393209,1,['adapter'],['adapter']
Integrability,"/build/CMakeFiles/progress.marks; /Applications/Xcode.app/Contents/Developer/usr/bin/make -f CMakeFiles/Makefile2 all; /Applications/Xcode.app/Contents/Developer/usr/bin/make -f CMakeFiles/libcereal.dir/build.make CMakeFiles/libcereal.dir/depend; cd /Users/gabriel/Projects/salmon-0.13.1/build && /usr/local/Cellar/cmake/3.13.4/bin/cmake -E cmake_depends ""Unix Makefiles"" /Users/gabriel/Projects/salmon-0.13.1 /Users/gabriel/Projects/salmon-0.13.1 /Users/gabriel/Projects/salmon-0.13.1/build /Users/gabriel/Projects/salmon-0.13.1/build /Users/gabriel/Projects/salmon-0.13.1/build/CMakeFiles/libcereal.dir/DependInfo.cmake --color=; /Applications/Xcode.app/Contents/Developer/usr/bin/make -f CMakeFiles/libcereal.dir/build.make CMakeFiles/libcereal.dir/build; make[2]: Nothing to be done for `CMakeFiles/libcereal.dir/build'.; [ 8%] Built target libcereal; /Applications/Xcode.app/Contents/Developer/usr/bin/make -f CMakeFiles/libstadenio.dir/build.make CMakeFiles/libstadenio.dir/depend; cd /Users/gabriel/Projects/salmon-0.13.1/build && /usr/local/Cellar/cmake/3.13.4/bin/cmake -E cmake_depends ""Unix Makefiles"" /Users/gabriel/Projects/salmon-0.13.1 /Users/gabriel/Projects/salmon-0.13.1 /Users/gabriel/Projects/salmon-0.13.1/build /Users/gabriel/Projects/salmon-0.13.1/build /Users/gabriel/Projects/salmon-0.13.1/build/CMakeFiles/libstadenio.dir/DependInfo.cmake --color=; /Applications/Xcode.app/Contents/Developer/usr/bin/make -f CMakeFiles/libstadenio.dir/build.make CMakeFiles/libstadenio.dir/build; [ 9%] Performing configure step for 'libstadenio'; cd /Users/gabriel/Projects/salmon-0.13.1/external/staden-io_lib && ./configure --enable-shared=no --without-libcurl --prefix=/Users/gabriel/Projects/salmon-0.13.1/external/install LDFLAGS= CFLAGS= CC=/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/cc CXX=/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/c++; checking for a BSD-compatible install... /usr/local/bin/g",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/348#issuecomment-472500713:1410,depend,depend,1410,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/348#issuecomment-472500713,1,['depend'],['depend']
Integrability,"/conda/core/subdir_data.py"", line 210, in load; _internal_state = self._load(); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/conda/core/subdir_data.py"", line 375, in _load; raw_repodata_str = fetch_repodata_remote_request(; File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/conda/core/subdir_data.py"", line 701, in fetch_repodata_remote_request; resp = session.get(join_url(url, filename), headers=headers, proxies=session.proxies,; File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/requests/sessions.py"", line 542, in get; return self.request('GET', url, **kwargs); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/requests/sessions.py"", line 529, in request; resp = self.send(prep, **send_kwargs); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/requests/sessions.py"", line 645, in send; r = adapter.send(request, **kwargs); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/requests/adapters.py"", line 413, in send; conn = self.get_connection(request.url, proxies); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/requests/adapters.py"", line 308, in get_connection; raise InvalidProxyURL(""Please check proxy URL. It is malformed""; requests.exceptions.InvalidProxyURL: Please check proxy URL. It is malformed and could be missing the host. `$ /usr/local/bin/conda install salmon`. environment variables:; CIO_TEST=<not set>; CONDA_ROOT=/usr/local/Caskroom/miniforge/base; CURL_CA_BUNDLE=<not set>; INFOPATH=/opt/homebrew/share/info:; MANPATH=/opt/homebrew/share/man::; PATH=/opt/homebrew/bin:/opt/homebrew/sbin:/usr/local/bin:/usr/bin:/bin:/usr; /sbin:/sbin; REQUESTS_CA_BUNDLE=<not set>; SSL_CERT_FILE=<not set>; all_proxy=<set>. active environment : None; user config file : /Users/Benjamin/.condarc; populated config files : /usr/local/Caskroom/miniforge/base/.condarc; conda version : 4.12.0; conda-build version : not installed; python version : 3.9.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/724#issuecomment-1171208515:4522,adapter,adapters,4522,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/724#issuecomment-1171208515,1,['adapter'],['adapters']
Integrability,"1) So `--celseq2` isn't there, I had initially checked here, to make sure that there wasn't something wrong with my command.. ; ```; alevin; ==========; salmon-based processing of single-cell RNA-seq data. alevin options:. mapping input options:; -l [ --libType ] arg Format string describing the library ; type; -i [ --index ] arg salmon index; -r [ --unmatedReads ] arg List of files containing unmated reads ; of (e.g. single-end reads); -1 [ --mates1 ] arg File containing the #1 mates; -2 [ --mates2 ] arg File containing the #2 mates. alevin-specific Options:; --noDedup Stops the pipeline after CB sequence ; correction and quasi-mapping reads.; --dropseq Use DropSeq Single Cell protocol for ; the library; --chromium Use 10x chromium v2 Single Cell ; protocol for the library.; --gemcode Use 10x gemcode v1 Single Cell protocol; for the library.; --whitelist arg File containing white-list barcodes; --noQuant Don't run downstream barcode-salmon ; model.; --naive Run Gene level naive deduplication; --noSoftMap Don't use soft-assignment for quant ; instead do hard-assignment.; --mrna arg path to a file containing mito-RNA ; gene, one per line; --rrna arg path to a file containing ribosomal ; RNA, one per line; --useCorrelation Use pair-wise pearson correlation with ; True barcodes as a feature for ; white-list creation.; --dumpfq Dump barcode modified fastq file for ; downstream analysis by using coin toss ; for multi-mapping.; --debug Enabling this mode mode will try to ; ignore segfaults based on no whitelist ; mapping or no whitelist deduplicated ; count; --dumpBfh dump the big hash with all the barcodes; and the UMI sequence.; --dumpFeatures Dump features for whitelist and ; downstream analysis.; --dumpCsvCounts Dump cell v transcripts count matrix in; csv format.; --lowRegionMinNumBarcodes arg (=200) Minimum Number of CB to use for ; learning Low confidence region ; (Default: 200).; --maxNumBarcodes arg (=100000) Maximum allowable limit to process the ; cell barcodes.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/325#issuecomment-443517536:687,protocol,protocol,687,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/325#issuecomment-443517536,3,['protocol'],['protocol']
Integrability,"12; approximateContigTotalLength: 132160289; counters for complex kmers:; (prec>1 & succ>1)=181344 | (succ>1 & isStart)=714 | (prec>1 & isEnd)=800 | (isStart & isEnd)=42; contig count: 2077595 element count: 297242564 complex nodes: 182900; # of ones in rank vector: 2077594; [2021-12-31 11:28:32.554] [puff::index::jointLog] [info] Starting the Pufferfish indexing by reading the GFA binary file.; [2021-12-31 11:28:32.554] [puff::index::jointLog] [info] Setting the index/BinaryGfa directory /no_backup/indexes/salmon/mm10_gencode; size = 297242564; -----------------------------------------; | Loading contigs | Time = 135.18 ms; -----------------------------------------; size = 297242564; -----------------------------------------; | Loading contig boundaries | Time = 61.18 ms; -----------------------------------------; Number of ones: 2077594; Number of ones per inventory item: 512; Inventory entries filled: 4058; 2077594; [2021-12-31 11:28:33.532] [puff::index::jointLog] [info] Done wrapping the rank vector with a rank9sel structure.; [2021-12-31 11:28:33.566] [puff::index::jointLog] [info] contig count for validation: 2,077,594; [2021-12-31 11:28:34.693] [puff::index::jointLog] [info] Total # of Contigs : 2,077,594; [2021-12-31 11:28:34.693] [puff::index::jointLog] [info] Total # of numerical Contigs : 2,077,594; [2021-12-31 11:28:34.787] [puff::index::jointLog] [info] Total # of contig vec entries: 13,003,859; [2021-12-31 11:28:34.787] [puff::index::jointLog] [info] bits per offset entry 24; [2021-12-31 11:28:35.409] [puff::index::jointLog] [info] Done constructing the contig vector. 2077595; [2021-12-31 11:28:36.870] [puff::index::jointLog] [info] # segments = 2,077,594; [2021-12-31 11:28:36.870] [puff::index::jointLog] [info] total length = 297,242,564; [2021-12-31 11:28:36.999] [puff::index::jointLog] [info] Reading the reference files ...; [2021-12-31 11:28:38.719] [puff::index::jointLog] [info] positional integer width = 29; [2021-12-31 11:28:38.719] [puff::inde",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/731#issuecomment-1003342883:2840,wrap,wrapping,2840,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/731#issuecomment-1003342883,1,['wrap'],['wrapping']
Integrability,"65 --threads ""${GALAXY_SLOTS:-4}"" --incompatPrior 1e-20 --biasSpeedSamp 1 --fldMax 1000 --fldMean 200 --fldSD 80 --forgettingFactor 0.65 --maxReadOcc 100 --numBiasSamples 2000000 --numAuxModelSamples 5000000 --numPreAuxModelSamples 1000000 --numGibbsSamples 0 --numBootstraps 0 --consensusSlack 0 --vbPrior 0.001 --sigDigits 3; ```. - `syslog`; ```; ip-172-31-30-93 kernel: [ 681.083866] salmon[4167]: segfault at 2641a ip 00007fe2fcdc2dca sp 00007fff27128b90 error 4 in libtbb.so.2[7fe2fcda0000+37000]; ```. **`salmon 0.11.2 run with: NativeSpecification --ntasks=1 --nodes=1 --mem=100000`**; - `scontrol show job 98`; ```; JobId=98 Name=g994_salmon_refinery_stemcellcommons_org; UserId=galaxy(1001) GroupId=users(100); Priority=4294901663 Account=(null) QOS=(null); JobState=RUNNING Reason=None Dependency=(null); Requeue=1 Restarts=0 BatchFlag=1 ExitCode=0:0; RunTime=00:08:19 TimeLimit=UNLIMITED TimeMin=N/A; SubmitTime=2018-08-27T20:06:23 EligibleTime=2018-08-27T20:06:23; StartTime=2018-08-27T20:06:23 EndTime=Unknown; PreemptTime=None SuspendTime=None SecsPreSuspend=0; Partition=main AllocNode:Sid=ip-172-31-24-127:2236; ReqNodeList=(null) ExcNodeList=(null); NodeList=w21; BatchHost=w21; NumNodes=1 NumCPUs=1 CPUs/Task=1 ReqS:C:T=*:*:*; MinCPUsNode=1 MinMemoryCPU=100000M MinTmpDiskNode=0; Features=(null) Gres=(null) Reservation=(null); Shared=OK Contiguous=0 Licenses=(null) Network=(null); Command=(null); WorkDir=/mnt/galaxy/tmp/job_working_directory/000/994; ```. - `Galaxy stderr`; ```; Fatal error: Exit code 139 (); ...; /mnt/galaxy/tmp/job_working_directory/000/994/tool_script.sh: line 50: 7495 Segmentation fault (core dumped) salmon quant --index ./index --libType U --unmatedReads ./single.fastq --output ./output --allowOrphans --ma 2 --mp 4 --go 5 --ge 3 --minScoreFraction 0.65 --threads ""${GALAXY_SLOTS:-4}"" --incompatPrior 1e-20 --biasSpeedSamp 1 --fldMax 1000 --fldMean 200 --fldSD 80 --forgettingFactor 0.65 --maxReadOcc 100 --numBiasSamples 2000000 --numAuxModelSamples 5",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/271#issuecomment-416364238:2377,Depend,Dependency,2377,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/271#issuecomment-416364238,1,['Depend'],['Dependency']
Integrability,": +001 310 415 7145; ________________________________; From: Rob Patro ***@***.***>; Sent: Sunday, October 29, 2023 11:01 AM; To: COMBINE-lab/salmon ***@***.***>; Cc: Freedman, Adam ***@***.***>; Mention ***@***.***>; Subject: Re: [COMBINE-lab/salmon] anaconda version of salmon outdated, missing decoys option (Issue #895). Hi @adamfreedman<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_adamfreedman&d=DwMCaQ&c=WO-RGvefibhHBZq3fL85hQ&r=MITI_LEJgyr1a24IMFAlSaZIPxMpOUT21T7L3fg4CjA&m=40O3raH84f_BIZ3HF7nqTYSO2FehGrGHL9b7sqT7LIpWZjFmA3BLxNDTHoz420jp&s=kxY9gCLGWZJp-dp7l31S6M5u2RuUTeWXVrKmaydpo5o&e=>,. I think this is just conda being very very very slow (and potentially broken). The following works fine for me (and finishes in ~1 minute):. mamba create -n salmon -c conda-forge -c bioconda salmon=1.10.2. Can you use the mamba resolver in your environment? Conda has become hardly usable over the years, but mamba works quite well as a fast replacement. I'll also note that I swapped the order of conda-forge and bioconda as the docs specify that bioconda should preferably come last in the list of channels. --Rob. —; Reply to this email directly, view it on GitHub<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_COMBINE-2Dlab_salmon_issues_895-23issuecomment-2D1784137337&d=DwMCaQ&c=WO-RGvefibhHBZq3fL85hQ&r=MITI_LEJgyr1a24IMFAlSaZIPxMpOUT21T7L3fg4CjA&m=40O3raH84f_BIZ3HF7nqTYSO2FehGrGHL9b7sqT7LIpWZjFmA3BLxNDTHoz420jp&s=GNiCXqUbJLM16QBJ5PNAqv-rsgDdpCpcvezPXO_riWk&e=>, or unsubscribe<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_notifications_unsubscribe-2Dauth_ADBMMUCOMVRRPOAZQL2EIITYBZVT5AVCNFSM6AAAAAA6UYYPGOVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMYTOOBUGEZTOMZTG4&d=DwMCaQ&c=WO-RGvefibhHBZq3fL85hQ&r=MITI_LEJgyr1a24IMFAlSaZIPxMpOUT21T7L3fg4CjA&m=40O3raH84f_BIZ3HF7nqTYSO2FehGrGHL9b7sqT7LIpWZjFmA3BLxNDTHoz420jp&s=54-iPwwQkGRgqbmGQptKb39rCEfDF7oE_8NSR2kN4Xs&e=>.; You are receiving this because you were mentioned.Message ID: ***@***.***>",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/895#issuecomment-1784196835:2454,Message,Message,2454,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/895#issuecomment-1784196835,1,['Message'],['Message']
Integrability,":1458040 approximateContigTotalLength: 96596288 ; counters for complex kmers: ; (prec>1 & succ>1)=163493 | (succ>1 & isStart)=1600 | (prec>1 & isEnd)=1705 | (isStart & isEnd)=136 contig count: 2046804 element count: 189087548 complex nodes: 166934 ; number of ones in rank vector: 2046803 ; [2022-04-16 11:19:37.060] [puff::index::jointLog] [info] Starting the Pufferfish indexing by reading the GFA binary file. [2022-04-16 11:19:37.060] [puff::index::jointLog] [info] Setting the index/BinaryGfa directory salmon_index_23 ; size = 189087548 ; ----------------------------------------- ; | Loading contigs | Time = 43.37 ms ----------------------------------------- ; size = 189087548 ; ----------------------------------------- ; | Loading contig boundaries | Time = 19.565 ms ----------------------------------------- ; Number of ones: 2046803 ; Number of ones per inventory item: 512 ; Inventory entries filled: 3998 ; 2046803 ; [2022-04-16 11:19:37.638] [puff::index::jointLog] [info] Done wrapping the rank vector with a rank9sel structure. [2022-04-16 11:19:37.687] [puff::index::jointLog] [info] contig count for validation: 2,046,803 ; [2022-04-16 11:19:38.556] [puff::index::jointLog] [info] Total # of Contigs : 2,046,803 ; [2022-04-16 11:19:38.556] [puff::index::jointLog] [info] Total # of numerical Contigs : 2,046,803 ; [2022-04-16 11:19:38.774] [puff::index::jointLog] [info] Total # of contig vec entries: 15,036,896 ; [2022-04-16 11:19:38.774] [puff::index::jointLog] [info] bits per offset entry 24 ; [2022-04-16 11:19:39.637] [puff::index::jointLog] [info] Done constructing the contig vector. 2046804 [2022-04-16 11:19:40.720] [puff::index::jointLog] [info] # segments = 2,046,803 ; [2022-04-16 11:19:40.720] [puff::index::jointLog] [info] total length = 189,087,548 ; [2022-04-16 11:19:40.878] [puff::index::jointLog] [info] Reading the reference files ... ; [2022-04-16 11:19:42.562] [puff::index::jointLog] [info] positional integer width = 28 ; [2022-04-16 11:19:42.562] [puf",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/768#issuecomment-1100734317:12073,wrap,wrapping,12073,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/768#issuecomment-1100734317,1,['wrap'],['wrapping']
Integrability,":49:06.436] [puff::index::jointLog] [warning] If you wish to retain duplicate transcripts, please use the `--keepDuplicates` flag; [2020-12-26 10:49:06.448] [puff::index::jointLog] [info] Replaced 151,122,967 non-ATCG nucleotides; [2020-12-26 10:49:06.448] [puff::index::jointLog] [info] Clipped poly-A tails from 1,829 transcripts; wrote 231443 cleaned references; [2020-12-26 10:49:09.969] [puff::index::jointLog] [info] Filter size not provided; estimating from number of distinct k-mers; [2020-12-26 10:49:40.159] [puff::index::jointLog] [info] ntHll estimated 2628436199 distinct k-mers, setting filter size to 2^36; Threads = 12; Vertex length = 31; Hash functions = 5; Filter size = 68719476736; Capacity = 2; Files:; salmon-decoy-sa-index/ref_k31_fixed.fa. **So using gffread I created a transcripts.fa file:; gffread -w salmon_transcripts.fa -g GRCh38.primary_assembly.genome.fa gencode.v36.annotation.gtf. using this new transcripts.fa I run again the above mentioned salmon index with decoy command, but the warning message was shown up again:**. [Step 1 of 4] : counting k-mers; [2020-12-26 11:30:08.799] [puff::index::jointLog] [warning] Entry with header [ENST00000473810.1], had length less than equal to the k-mer length of 31 (perhaps after poly-A clipping); [2020-12-26 11:30:08.951] [puff::index::jointLog] [warning] Entry with header [ENST00000603775.1], had length less than equal to the k-mer length of 31 (perhaps after poly-A clipping); [2020-12-26 11:30:10.751] [puff::index::jointLog] [warning] Entry with header [ENST00000632684.1], had length less than equal to the k-mer length of 31 (perhaps after poly-A clipping); [2020-12-26 11:30:12.936] [puff::index::jointLog] [warning] Entry with header [ENST00000543745.1], had length less than equal to the k-mer length of 31 (perhaps after poly-A clipping); [2020-12-26 11:30:13.188] [puff::index::jointLog] [warning] Entry with header [ENST00000415118.1], had length less than equal to the k-mer length of 31 (perhaps after po",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/214#issuecomment-751354991:14924,message,message,14924,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/214#issuecomment-751354991,1,['message'],['message']
Integrability,"> And for us, who have blocked download on a computational cluster `cmake` silently continues even when `scripts/fetchRapMap.sh` failed (see error code `403` below). Dists downloading their own dependencies is also forbidden in package managers such as FreeBSD ports and pkgsrc (which is cross-platform and I personally use on Mac, NetBSD, and RHEL). Trusting upstream scripts to pull stuff off the Internet is a security risk, so the package managers perform and validate (via checksum) all downloads in a separate stage. It would be nice not to have to hack out the download code from a build system in order to create and maintain a package.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/19#issuecomment-989326040:194,depend,dependencies,194,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/19#issuecomment-989326040,1,['depend'],['dependencies']
Integrability,"> Can you try doing:; > ; > ```; > export DYLD_LIBRARY_PATH=$DYLD_LIBRARY_PATH:/Users/maysonlin/Downloads/salmon-1.2.1-h2072146_0 2/lib; > ```; > ; > before running salmon? The problem is that the executable is looking for `libtbb` and `libtbb_proxy`, but they are not in the library path. Hi, Rob, thank you for replying, do you mean type those code in ""Terminal""? ; I tried it, and I got this message:. -bash: export: `2/lib': not a valid identifier",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/517#issuecomment-623073440:395,message,message,395,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/517#issuecomment-623073440,1,['message'],['message']
Integrability,"> Hello, Thank you for your message. However, I am working with fission yeast transcriptome and since I am not expecting a lot of splicing junctions with this organism, I read that people recommended using -ax map-ont in this case?. Ye, it is. If there are not many splicing junctions, then it is like runging with genomic reads. But still, I do not see any recommantion of doing it. . For your first questions, is `7ff17d41-0678-447f - acd0-57b53d35ba32` an ID of a read from your `fastq` file? For me, It does not look like a gene name. If it is an ID, how do you get this?. After I ran the quantificaton, what I get is like this：; gens, length and so on.; ![image](https://user-images.githubusercontent.com/14146871/179023113-d06ee0a3-4efd-406e-8736-895345cafae5.png). I import Genomes and bam file inoto IGV to check `ATMG01170.1`:; ![image](https://user-images.githubusercontent.com/14146871/179024217-63f8920f-0ab3-4c42-b4cf-24dbd9de1134.png). I am not familiar with IGV so I did not know how to import the .gtf file to see what you showed. ![image](https://user-images.githubusercontent.com/14146871/179024687-9aed6cfd-e203-415f-9f9f-c6501a915c27.png)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/786#issuecomment-1184610671:28,message,message,28,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/786#issuecomment-1184610671,1,['message'],['message']
Integrability,"> Hi @tamuanand ,; > ; > I am not well versed in Lexongen Quantseq but the following paper is worth checking.; > https://www.nature.com/articles/s41598-019-55434-x , let us know if you have any thoughts. @k3yavi You mention that you are not well-versed in Lexogen Quantseq. Just to clarify, Lexogen is the company, Quantseq is the technology. . It is the same Quantseq that is mentioned in the salmon quant help text . ```; salmon quant --help-reads; ................................; --noLengthCorrection [experimental] : Entirely disables; length correction when estimating the; abundance of transcripts. This option; can be used with protocols where one; expects that fragments derive from; their underlying targets without regard; to that target's length (e.g. QuantSeq); ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-565245678:637,protocol,protocols,637,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-565245678,1,['protocol'],['protocols']
Integrability,"> In STAR there is an option to use stranded alignment (--readStrand, which can take ""Unstranded"", ""Forward"", or ""Reverse""). For the pipeline I'm building it would be ideal if I didn't have to specify the strandedness of the library as I'm not the one preparing the samples and it's not always easy to get that information from the scientist in the lab. As such, it would be great if I can use the default strandedness argument to STAR (""Unstranded"") and let salmon ""do the right thing"" by letting it choose the libType for me. With that in mind, if I let salmon choose for me (-l A) am I risking throwing out any data?. Right, so in this case, STAR should produce all highest-scoring valid alignments regardless of orientation. Then, when running salmon with `-l A` it will detect the strandedness and only discard alignments compatible with the appropriate strand type (which may be unstranded if that is the protocol). Salmon is pretty conservative about reporting when there is any ambiguity. By default, if the strand bias is stronger than a few percent. In a stranded protocol, it will report and if it infers more than a few percent of fragments no having a valid alignment. So you can always double-check samples where the strandedness is at all ambiguous. > In addition, if a transcript was aligned in a unstranded manner and ended up aligning to the wrong location due to ambiguity between the positive orientation of one transcript and the negative orientation of another, can salmon correct this by reassigning it to the right transcript based on the joint probability of all the other alignments (if you can't tell I'm at the edge of my BS zone)?. If there is not an alignment to the correct location _in addition to_ the wrong location, then no. If you run salmon in alignment mode, it will assign each fragment probabilistically to the set of transcripts to which it aligns. There is, by definition, a probability of 0 for a fragment being assigned to a location where it doesn't align.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/590#issuecomment-733417813:911,protocol,protocol,911,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/590#issuecomment-733417813,1,['protocol'],['protocol']
Integrability,"> Is this read set & reference txome available to try and reproduce this?. Unfortunately no, it's a generated fasta file (it used to work with 0.9.1 without ""validateMappings"" though). [info] Building 32-bit suffix array (length of generalized text is 462349554); processed 462000000 positions; khash had 208056876 keys. > Also, would it be possible to check if this occurs using the bioconda-packaged release?. Still a seg fault but I now have the following message:; WARNING: Could not associate known library type with read!; WARNING: PE compatibility function called with SE read!; expected: Library format { type:paired end, relative orientation:inward, strandedness:unstranded }, observed: Library format { type:, relative orientation:, strandedness: }; Segmentation fault: 11",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/228#issuecomment-393236903:459,message,message,459,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/228#issuecomment-393236903,1,['message'],['message']
Integrability,"> Ok, when I attempt the build the way you say above, I get the following error during CMake:; > ; > ```; > -- fetch PUFFERFISH exit code 127; > CMake Error at CMakeLists.txt:317 (message):; > Could not fetch pufferfish source [fetchPufferfish.sh returned exit code; > 127]. Did you do the. ```; apt build-dep salmon; ```. step? I can't imagine that you get this problem if you follow my log step by step. Debian is usually using dynamic linking. By having all Build-Dependencies (which is ensured in the step above) the existence of the libraries is granted and the options for cmake I specified are ensuring that the libs are found. Kind regards, Andreas.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1464176548:180,message,message,180,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1464176548,2,"['Depend', 'message']","['Dependencies', 'message']"
Integrability,"> The same with version 1.2.0.; > ; > Is there a way to disable version check by default, completely? I install Salmon as a module and I wouldn't let it update itself automatically, anyway. ```; --- Salmon.cpp.ori 2020-04-21 15:12:29.916219870 +0000; +++ Salmon.cpp 2020-04-21 15:16:48.488926415 +0000; @@ -53,7 +53,7 @@; ""Usage: salmon -h|--help or \n""; "" salmon -v|--version or \n""; "" salmon -c|--cite or \n""; - "" salmon [--no-version-check] <COMMAND> [-h | options]\n\n"");; + "" salmon <COMMAND> [-h | options]\n\n"");; helpMsg.write(""Commands:\n"");; helpMsg.write("" index Create a salmon index\n"");; helpMsg.write("" quant Quantify a sample\n"");; @@ -171,8 +171,6 @@; // https://gist.github.com/randomphrase/10801888; po::options_description sfopts(""Allowed Options"");; sfopts.add_options()(""version,v"", ""print version string"")(; - ""no-version-check"",; - ""don't check with the server to see if this is the latest version"")(; ""cite,c"", ""show citation information"")(; ""help,h"", ""produce help message"")(""command"", po::value<string>(),; ""command to run {index, quant, sf}"")(; @@ -209,11 +207,6 @@; std::exit(0);; }. - if (!vm.count(""no-version-check"")) {; - std::string versionMessage = getVersionMessage();; - std::cerr << versionMessage;; - }; -; // po::notify(vm);. std::string cmd = vm[""command""].as<std::string>();; ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/486#issuecomment-617250297:991,message,message,991,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/486#issuecomment-617250297,1,['message'],['message']
Integrability,> but I suspect the issue is also related to this log message. I wondered about that too but other samples gave me 2 and 3 degenerate classes and still passed...,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/229#issuecomment-393579057:54,message,message,54,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/229#issuecomment-393579057,1,['message'],['message']
Integrability,"@Gaura So with the changes implemented, custom geometry is ~19% slower here than the hand-coded sci-seq3 protocol (improved from ~1/3 slower); is that correct? That's a nice improvement. @gmarcais — do you think it's worth testing out PCRE2? Most of these regexes are *very* short — and if boost is ~20% slower than PCRE2 and we are ~20% slower than the custom parsing code .... maybe that's the whole gap? Any idea how difficult this would be to try?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/734#issuecomment-1023346183:105,protocol,protocol,105,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/734#issuecomment-1023346183,1,['protocol'],['protocol']
Integrability,"@HenrikBengtsson,. Good catch. We had to update the continuous integration image used because we bumped some libraries (and the compiler version). Apparently the permissions are not set up in the same way by default. Can you share what you think the permissions should be for the relevant files / folders?. Thanks,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/761#issuecomment-1067239060:63,integrat,integration,63,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/761#issuecomment-1067239060,1,['integrat'],['integration']
Integrability,"@Miserlou : it's also worth noting that the error message preceding the segfault in #323 is coming from the library (libstaden) that we use to parse SAM/BAM files. So, it's something where I think we will need a BAM that exhibits whatever triggers that behavior.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/320#issuecomment-444994980:50,message,message,50,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/320#issuecomment-444994980,1,['message'],['message']
Integrability,"@PeteHaitch Thanks for making the pull request and correcting the barcode length for the celseq2 protocol. We'll review it soon and merge it to the develop (which will be merged to master in next release). @rob-p I think we already have that capability of specifying the CB and UMI length, it's just CelSeq2 was little difference in the *order* of them. Basically the flags like `--chromium` or any other protocols are wrapper around using the standard CB and UMI lengths. If one wants a customization we can always use `--umiLength` and `--barcodeLength`. I am thinking of tweaking the `--end` part of the `struct` to select the order of the CB and UMI which incase of CelSeq2 is reverse.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/269#issuecomment-418772038:97,protocol,protocol,97,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/269#issuecomment-418772038,3,"['protocol', 'wrap']","['protocol', 'protocols', 'wrapper']"
Integrability,"@bgruening So I've tried some runs today with higher memory configurations and can still reproduce the segfault. I'm going to continue on and try to write up a reproducer for @dpryan79 [here](https://github.com/bioconda/bioconda-recipes/issues/10662#issuecomment-415967622). **`salmon 0.11.2 run with: NativeSpecification --ntasks=1 --nodes=1 --mem=25000`**; - `scontrol show job 94`; ```; JobId=94 Name=g990_salmon_refinery_stemcellcommons_org; UserId=galaxy(1001) GroupId=users(100); Priority=4294901667 Account=(null) QOS=(null); JobState=COMPLETED Reason=None Dependency=(null); Requeue=1 Restarts=0 BatchFlag=1 ExitCode=0:0; RunTime=00:07:32 TimeLimit=UNLIMITED TimeMin=N/A; SubmitTime=2018-08-27T15:36:41 EligibleTime=2018-08-27T15:36:41; StartTime=2018-08-27T15:36:41 EndTime=2018-08-27T15:44:13; PreemptTime=None SuspendTime=None SecsPreSuspend=0; Partition=main AllocNode:Sid=ip-172-31-24-127:21595; ReqNodeList=(null) ExcNodeList=(null); NodeList=w19; BatchHost=w19; NumNodes=1 NumCPUs=1 CPUs/Task=1 ReqS:C:T=*:*:*; MinCPUsNode=1 MinMemoryNode=25000M MinTmpDiskNode=0; Features=(null) Gres=(null) Reservation=(null); Shared=OK Contiguous=0 Licenses=(null) Network=(null); Command=(null); WorkDir=/mnt/galaxy/tmp/job_working_directory/000/990; ```. - `Galaxy stderr`; ```; Fatal error: Exit code 139 (); ...; /mnt/galaxy/tmp/job_working_directory/000/990/tool_script.sh: line 50: 5713 Segmentation fault (core dumped) salmon quant --index ./index --libType U --unmatedReads ./single.fastq --output ./output --allowOrphans --ma 2 --mp 4 --go 5 --ge 3 --minScoreFraction 0.65 --threads ""${GALAXY_SLOTS:-4}"" --incompatPrior 1e-20 --biasSpeedSamp 1 --fldMax 1000 --fldMean 200 --fldSD 80 --forgettingFactor 0.65 --maxReadOcc 100 --numBiasSamples 2000000 --numAuxModelSamples 5000000 --numPreAuxModelSamples 1000000 --numGibbsSamples 0 --numBootstraps 0 --consensusSlack 0 --vbPrior 0.001 --sigDigits 3; ```. - `syslog`; ```; ip-172-31-30-93 kernel: [ 681.083866] salmon[4167]: segfault at 2641a i",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/271#issuecomment-416364238:564,Depend,Dependency,564,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/271#issuecomment-416364238,1,['Depend'],['Dependency']
Integrability,"@k3yavi To follow up on this dataset:; The reads were generated using a modified protocol with a 9bp barcode followed by an 8bp UMI. I used the custom length mode to align this data and alignment rate went up to about 45%. I tried the alignment using DropSeq Tools and STAR and got similar alignment rates, so I think the custom length alignment is working properly. I may try using some other reference databases instead of GRCh38.p12 to see if alignment improves. Otherwise it may just be an issue regarding the dataset itself.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/258#issuecomment-415101431:81,protocol,protocol,81,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/258#issuecomment-415101431,1,['protocol'],['protocol']
Integrability,"@kikegoni this is something I started to work on but then quickly abandoned. I've uploaded the utility (`transcoorder`) that I started writing (https://github.com/mdshw5/transcoorder) for this purpose. If you find it useful and want to help finish the work please do. Currently the `transcoord` command will take a SAM/BAM, a GTF and matching genomic FASTA, and will convert reads from transcript to genomic coordinates, with appropriate reference names and offsets. However, it is not tested, and will only properly handle reads that fall entirely within an exon. Spliced reads shouldn't be too hard to add, but I just don't have the time right now. . ```; $ transcoord -h; usage: transcoord [-h] [-o OUT] [-t TAG_NAME] [--debug] [--version] gtf bam fasta. positional arguments:; gtf GTF file containing transcripts; bam SAM or BAM files aligned to transcriptome; fasta FASTA format assembly coresponding to GTF. optional arguments:; -h, --help show this help message and exit; -o OUT, --out OUT output file for genomic SAM (default: stdout); -t TAG_NAME, --tag-name TAG_NAME; SAM tag name for storing transcript identifier. default: ZT; --debug enable debugging; --version display version number; ```. The command is veeeeeery slow, but should process a typical RNAseq library in a few hours.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/193#issuecomment-736948709:961,message,message,961,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/193#issuecomment-736948709,1,['message'],['message']
Integrability,"@mdshw5 --- Salmon has definitely become less ""complain-y"" in the newer versions. That is, it will no longer spew out error messages for all of the fragments that show up in an unexpected orientation. However, the summary statistics are currently very ""summary"". There is a file in the quantification directory called `libFormatCounts.txt` that summarizes the number of alignments seen in the different orientations etc. However, I _really_ like your idea of recording the ""violating"" transcripts. That is, we could maintain some ""threshold"" beyond which if there are these many ""incorrectly"" mapping fragments for a transcript, the transcript is recorded and reported to the user as potentially being in the wrong orientation in the index.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/16#issuecomment-144479133:124,message,messages,124,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/16#issuecomment-144479133,1,['message'],['messages']
Integrability,"@rbenel,. If you are using a version prior to 0.14.0, you will also have to pass `--no-version-check` to avoid contamination of stdout by the versioning message.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/38#issuecomment-507241631:153,message,message,153,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/38#issuecomment-507241631,1,['message'],['message']
Integrability,"@rob-p Could it be that I am not using the correct command line `salmon quant` options for Lexogen/QuantSeq _(this will be referred to as QS in the rest of the message(s))_ ?. `salmon quant --threads 16 --noLengthCorrection --validateMappings --numBootstraps 100 -l SF -i <path_to_SAF_Gentrome_Index> -r <SE_READ_1.fq> -o <salmon_SE_READ_1>`. I chose the above command line options (`especially --noLengthCorrection`) based on [Rob's message here](https://groups.google.com/d/msg/sailfish-users/VIfqBwgF6xQ/fw-rgC_kAwAJ) and a [thread here](https://github.com/COMBINE-lab/salmon/issues/108). Let me elaborate the big picture of my analyses and give more details about how I came up with the mapping numbers in my original post. Big Picture - DEG identification for samples sequenced by ILMN (whole transcript method) and QS (3' method) - [something similar to this paper](https://bmcgenomics.biomedcentral.com/articles/10.1186/s12864-018-5393-3). Bioinformatics Pipeline(s) for both ILMN and QS :. 1. HISAT Method : Adapter/Quality Trimming, Hisat2-HTSEQ, Get_Count_Table, DESeq; 2. STAR_RSEM Method: Adapter/Quality Trimming, STAR_RSEM, Get_Count_Table, DESeq; 3. SAF Method: Adapter/Quality Trimming, SAF_SALMON, Get_Count_Table, DESeq; 4. Quasi-Mapping or TXOME Method: Adapter/Quality Trimming, TXOME_SALMON, Get_Count_Table, DESeq. I used UpSetR plots for comparisons of sets of DEGs from each method just [as you have shown in your recent preprint](https://www.biorxiv.org/content/10.1101/657874v1.full). In the ILMN analyses, there is great concordance between the SAF method and HISAT/STAR_RSEM method. However, in the QS analyses, there is very limited concordance between SAF and the HISAT/STAR_RSEM method. For QS analyses, the TXOME method shows great concordance with HISAT/STAR_RSEM. This finding made me wonder if this has to be something with my salmon quant command line options for QS. Therefore, I wanted to check how the QS expected counts for SAF method show up for all samples in",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-554768195:160,message,message,160,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-554768195,2,['message'],['message']
Integrability,"@rob-p I would request that you try out bbduk and bbmap for quality/adapter trimming and contaminant removal.; > Thank you for verifying @zhangchipku, For the time being, I can recommend `fastp` as a fairly efficient / fast trimmer that. It might even be able to work in a streaming fashion so that you could pipe the trimmed reads directly to salmon.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-592995074:68,adapter,adapter,68,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-592995074,1,['adapter'],['adapter']
Integrability,"@rob-p I've taken the time to [update salmon to 0.11.2 in it's respective Galaxy Tool wrapper](https://github.com/bgruening/galaxytools/pull/778) and am still seeing the `salmon quant` segfault when running through SLURM. . bioconda installs of salmon 0.9.1 & 0.11.2 run to completion outside of SLURM on the same machine. I've seen that #268 was opened and closed recently, but I don't have the liberty to resolve the salmon dependency outside of conda (at least very easily/in a timely fashion). Update: Have since filed https://github.com/bioconda/bioconda-recipes/issues/10662",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/271#issuecomment-415831123:86,wrap,wrapper,86,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/271#issuecomment-415831123,2,"['depend', 'wrap']","['dependency', 'wrapper']"
Integrability,"@rob-p This is not running twice on same sample. I can see that this run generates a exit code of 1 for that run - however all files are there as needed. Other samples have a exit code 0. I looked up sample runs before and after - they seem to have correct exit codes and ran fine. Even this runs fine, but what triggers that error message - I am not sure. ```; failed to read 8 bytes; salmon quant invoked improperly; ```. I also reran my whole pipeline (qc_trimming etc and finally salmon) - this time with 5 samples only (and included the above sample) - the pipeline runs successfully. Not sure where to investigate",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/512#issuecomment-618044865:332,message,message,332,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/512#issuecomment-618044865,1,['message'],['message']
Integrability,"@rob-p can you elaborate on this a bit more: . > The effect of --minScoreFraction depends, to some extent, on how you set the match/mismatch/gap parameters. With the default parameters, 0.9 is actually higher than 90% sequence identity, because the default mismatch penalty is twice the match score. If you assume only matches and mismatches, then the --minScoreFraction you want to set is the one such that x * (match_score * read_length) <= (match_score * read_length) - (m * read_length * match_score) + (m * read_length * mismatch_penalty), where m is the mismatch fraction (0.1 in your case). So, for example, if the match_score is 2 and mismatch penalty is -4, and the read length is 100, you want to set it so that: x * 200 = 200 - (0.1 * 100 * 2) + (0.1 * 100 * -4) = 200 - 20 - 40 = 140 so, the appropriate x would be ~0.7. Of course, if you want to make the calculation simple, you can set the match score to 1 and mismatch penalty to 0, and then the interpretation (modulo gaps) is straightforward (and 0.9 means what you want). Would the two parameter sets mentioned above have the same effect assuming read length 100?. Also, it says Alevin has a default minScoreFraction of 0.87. Would it be safe to assume differentiating between isoforms with Alevin is a similar problem to differentiating between orthologous genes in metagenomics/transcriptomics?. Which parameters would be relevant to control for this?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/330#issuecomment-2249029869:82,depend,depends,82,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/330#issuecomment-2249029869,1,['depend'],['depends']
Integrability,"@roryk I don't think an R package is the right answer :) . My real motivation is to load into Degust: http://www.vicbioinformatics.com/degust/. It can be done with simple Unix cut/paste or with a python script too. But I don't want to depend on R for the pipeline, or even littler. @vals I'll take a look at your script, but still be better if part of Salmon.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/77#issuecomment-240556885:235,depend,depend,235,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/77#issuecomment-240556885,1,['depend'],['depend']
Integrability,"@zhangchipku,. The default value of `--minScoreFraction` is quite reasonable, I think. It depends on the read length, but for a 100-bp read, it corresponds to 8 mismatches under the default scoring parameters. So the read pair could have up to 16 mismatches before being discarded. I understand that the recommendation to trim reads is a new one, but I think it is a standard best-practice anyway. However, we are looking at the possibility of allowing read-end soft-clipping in future releases, which could mitigate this need in the most common case. It is worth noting that, if you *don't* want to use selective alignment, then the last version of salmon that you can use is the one tagged as `0.15.0`. As of version 1.0.0, the index structure and default mapping algorithm changed, so that selective alignment is ""always on"". This is discussed in some detail in the release notes for version 1.0.0. Generally, we think that the benefits offered by selective-alignment are important, and, unless there is a very strong reason not to, one should generally ensure that reads sharing some exact matches with the reference also produce reasonable quality alignments at the implied loci. However, we also try to be very receptive and responsive to our users' workflows and desiderata, so if the soft-clipping feature is something that would make your experience much smoother, we will certainly consider prioritizing that feature for a future release.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-586478704:90,depend,depends,90,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-586478704,1,['depend'],['depends']
Integrability,"@zhangchipku,. Yes, it seems that the biggest culprit here is `num_fragments_filtered_vm`. That is the number of fragments filtered because the best alignment failed to reach the threshold for a ""valid"" alignment. Here, `47,470,013` fragments are discarded entirely because they didn't have an alignment meeting the required quality. If these fragments (which do have matching MEMs, because alignment was carried out for them) were mapped, then the overall mapping rate would go up to `50,729,814 + 47,470,013 = 98,199,827 / 107,275,750 = ~91.5%`. Now, I wouldn't expect _all_ of these to be mappable, and some alignments might not be feasible at any reasonable quality whatsoever. My recommendation would be as follows. First, have you trimmed these reads (using e.g. `fastp` or `TrimGalore` or some such)? Very low quality read ends or (more likely) adapter contamination could cause the reads that have matching MEMs to fail to align within the required score threshold. My first recommendation would be to trim the reads and see how the mapping rate changes. Second, the required alignment score is a user-alterable parameter. By changing `--minScoreFraction` to be lower, you can allow reads with even lower alignment scores to be counted for quantification. The default value is `0.65`, so you could explore what happens if you lower this number. The number represents the fraction of the maximum achievable alignment score that a read must obtain to be considered a valid alignment. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-586473052:852,adapter,adapter,852,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-586473052,1,['adapter'],['adapter']
Integrability,"Ahh, serves me right for trying to write that help message by hand! I'll remove `cite` from the list of ""commands"" in the next release.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/149#issuecomment-325170015:51,message,message,51,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/149#issuecomment-325170015,1,['message'],['message']
Integrability,"Ahh, that's the number of *mappings* discarded. No need to worry about that. Basically, that's the number of places where seeding was tried, but alignment failed. This is very common in alignment (a seed can't be extended to a high quality alignment). The number of fragments discarded is what matters (number of fragments where all alignment locations failed). The strand bias signifies that your library is likely strand specific, though you are mapping in unstranded mode. This means that even alignments that don't agree with the stranded protocol will be allowed. This looks like ISR (first read from the reverse strand) by the looks of it. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/775#issuecomment-1126583954:543,protocol,protocol,543,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/775#issuecomment-1126583954,1,['protocol'],['protocol']
Integrability,Appears to work that route. Thanks!,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/261#issuecomment-409439396:21,rout,route,21,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/261#issuecomment-409439396,1,['rout'],['route']
Integrability,"Argghh --- that's gonna be a thinker. Can you try running it under GDB?. ```; $ gdb salmon; (gdb) r quant \; -i mouse_cdna_38.p3.78_repbase_ercc.fa \; -l IU \; -1 SRP057125_SRS936134_1.fastq \; -2 SRP057125_SRS936134_2.fastq \; -o SRP057125_SRS936134_salmon_out \; -g /nfs/research2/teichmann/reference/mus-musculus/salmon/mouse_cdna38.78_repbase_ercc_index_gene_map.txt \; --biasCorrect \; --useFSPD; ```. when it segfaults, you can issue the `bt` command to at least see where. If its still inside of JeMalloc, I can build another binary with just the standard allocator to see if the problem persists there (its strange that it depends on where the file is coming from! I don't have any NFS mounts either to test on).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/34#issuecomment-168428123:631,depend,depends,631,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/34#issuecomment-168428123,1,['depend'],['depends']
Integrability,Could it be coming from some other part of the code or some dependency?,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/229#issuecomment-393623521:60,depend,dependency,60,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/229#issuecomment-393623521,1,['depend'],['dependency']
Integrability,"Counting (transcript, UMIs) is what ""kallisto pseudo"" with the --umi option; does, right?. Yes, there are a few errors in the UMIs. The Kallisto wrapper tries to; correct them. But this is really very rare. Not sure if it's worth the; time. Like ~100 out of 200.000 reads? I would have to check again.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/108#issuecomment-269043952:145,wrap,wrapper,145,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/108#issuecomment-269043952,1,['wrap'],['wrapper']
Integrability,"Damn. There are random numbers, but even setting the seed, the multi-threaded nature of almost all steps leads to non-deterministic behavior. The behavior you describe sounds like some sort of race condition that gets triggered depending on when threads get to different parts of the code. I couldn't get the hanging with the other dataset over multiple (~10) runs. So even if it's completely non-deterministic you seem to be getting it with higher frequency in your system. Is it always in the Gibbs phase? One question / thought, did salmon fetch and build the Intel TBB dependency, or are you using a system version?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-266951967:228,depend,depending,228,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-266951967,2,['depend'],"['dependency', 'depending']"
Integrability,"Damn; I get the same behavior on ~~16.10~~ (actually, my box is 16.04, but I'm skeptical that this specific version issue is the cause of the behavior) as I get on 14.10 (using the executable you provided). It runs to completion and modulo our less-than-ideal handling of the `--libType` flag coming after the `--unmatedReads` flag, it completes without the Gibbs warning. When I run with `--seqBias` and `--gcBias`, I get the same behavior (it runs and finishes w/o hanging or outputting the error messages). I'm going to take a look at the relevant code path to see if anything stands out to me.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-266938104:499,message,messages,499,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-266938104,1,['message'],['messages']
Integrability,"Dear @callumparr,. Thank you for bringing this up. So you are correct that the `--noLengthCorrection` flag should be passed to salmon when quantifying data that does not have a ""fragmentation effect"", that is, where the number of fragments we expect to draw from a transcript is not dependent upon the length of that transcript. In the ONT protocols, it is usually the case that we get 1 read -> 1 transcript, even if we don't read the whole thing. We have tested the effect of this in ONT data with spike ins, and have verified that using `--noLengthCorrection` does generally lead to improved accuracy with respect to quantification estimates. We have informed ONT of this, and I would guess they may optimize the flags that are used soon (we have also developed an error model that works correctly for these long reads, and that should make it into the next release of salmon). Regarding the effect this has on the `NumReads` values reported by salmon, it's not as simple as with the `TPM` estimates. The length affects the assigned reads through the probabilistic model on which inference is done. With the length effect we have that P(f | t_i) ∝ P( position | f, t_i ) * P( alignment | f, t_i) --- forgetting the alignment term for the time being, we have that with length correction P( position | f, t_i ) ∝ 1 / l_i and without length correction the l_i term goes away. In other words, the probability of allocating reads has a term that depends on the effective length when the `--noLengthCorrection` flag is not passed, but that term goes away when it is passed. This is not quite as drastic as with TPM where the normalization includes the length directly in the normalization (note, however, that when the `--noLengthCorrection` flag is passed, this adjusts the TPM as well). Further, the `NumReads` is still better than TPM in this regard because it still encodes the effect size (i.e. `NumReads` will sum to the total number of aligned reads). Anyway TLDR: Passing the `--noLengthCorrectio",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/651#issuecomment-821995147:283,depend,dependent,283,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/651#issuecomment-821995147,2,"['depend', 'protocol']","['dependent', 'protocols']"
Integrability,"Dear Rob, thank you for the fast replay. a) I tried to compile but it is not working for me either; ....; _[100%] Linking CXX executable salmon; /usr/bin/ld: ../../external/install/lib/libstaden-read.a(libstaden_read_la-open_trace_file.o): in function `find_file_url':; open_trace_file.c:(.text+0xf74): warning: the use of `tempnam' is dangerous, better use `mkstemp'; during IPA pass: icf; lto1: internal compiler error: Segmentation fault; 0xd12487 internal_error(char const*, ...); 	???:0; 0xe4f0b6 varpool_node::get_constructor(); 	???:0; 0xea01ff ipa_icf::sem_item_optimizer::subdivide_classes_by_equality(bool); 	???:0; 0x12ab4cb ipa_icf::sem_item_optimizer::execute(); 	???:0; Please submit a full bug report,; with preprocessed source if appropriate.; Please include the complete backtrace with any bug report.; See <file:///usr/share/doc/gcc-11/README.Bugs> for instructions.; lto-wrapper: fatal error: /usr/bin/c++ returned 1 exit status; compilation terminated.; /usr/bin/ld: error: lto-wrapper failed; collect2: error: ld returned 1 exit status; make[2]: *** [src/CMakeFiles/salmon.dir/build.make:486: src/salmon] Error 1; make[1]: *** [CMakeFiles/Makefile2:665: src/CMakeFiles/salmon.dir/all] Error 2; make: *** [Makefile:166: all] Error 2_. 2) bioconda on a server is a mess. it will be my last resort. 3) I am trying the Docker version and it seems to work!!!; ; PS It seems to me a be a little strange though that the binary version is not working. I tried on three different systems (all with ubuntu 22.04) with Xeon gold and intel i7 . thank you again",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/783#issuecomment-1144000013:890,wrap,wrapper,890,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/783#issuecomment-1144000013,2,['wrap'],['wrapper']
Integrability,"Depending on what environment you install in (other conda software), the default resolver in conda is messed up. You should just explicitly ask for 1.10.2 with “ conda install salmon=1.10.2”. You can also try installing it in a clean conda env which is how I install most of my conda software anyway. Best,; Rob. note: these resolver issues are a conda problem, and there’s nothin we as the salmon devs can do. So if you’d like to be able to avoid specifying the version, even when you put it in an env with arbitrary other software, I suggest making aMWE and opening an issue upstream in conda/bioconda.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/895#issuecomment-1784085120:0,Depend,Depending,0,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/895#issuecomment-1784085120,1,['Depend'],['Depending']
Integrability,"Drone is awesome! The problem seems to be related to the ancient image on which we do CI (holy build box) having a version of curl that, just now (in the last day?), became incompatible with github's OpenSSL protocol. I guess they did an update, and now my version of curl is too old. I think we need to update the image.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/199#issuecomment-368083042:208,protocol,protocol,208,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/199#issuecomment-368083042,1,['protocol'],['protocol']
Integrability,"Exactly, I meant that if the dep is not already satisfied, I'll pull the source and compile and install it locally (not that I would bundle the dependency with salmon).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/45#issuecomment-193942045:144,depend,dependency,144,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/45#issuecomment-193942045,1,['depend'],['dependency']
Integrability,"FYI, I'm taking another crack at an official FreeBSD port, but still hitting some gnarly issues with 1.5.2, so it might be a while. https://github.com/outpaddling/freebsd-ports-wip/tree/master/salmon; https://github.com/outpaddling/freebsd-ports-wip/tree/master/pufferfish; https://github.com/COMBINE-lab/salmon/issues/502. 1. The cmake system still forces downloading pufferfish during configure, which is forbidden in the ports system (like many other package managers). All downloads must occur during fetch phase and be verified using locally stored checksums. This would be easy to work around using GH_TUPLE, which downloads additional distfiles during fetch phase, except that fetchPufferfish.sh doesn't just extract the pufferfish dist, but has a long list of ""cp"" commands to copy pieces of it to ${INSTALL_DIR}. That's not something I'm inclined to tamper with since it will likely change with new versions and hence be a headache to maintain over time. It would be ideal if salmon could work with a separately installed pufferfish as it does with many other dependencies. This would make the port much cleaner.; 2. The code is not compatible with onetbb 2021.3, which is the current FreeBSD ports version.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/162#issuecomment-917642392:1069,depend,dependencies,1069,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/162#issuecomment-917642392,1,['depend'],['dependencies']
Integrability,"FYI: [https://github.com/outpaddling/freebsd-ports-wip/tree/master/salmon](https://github.com/outpaddling/freebsd-ports-wip/tree/master/salmon). It would be good to update to onetbb 2021 soon. FreeBSD ports still has a 2020.3 legacy port, but we're trying to update everything that depends on it so it can be retired. I think maybe this issue can be closed at this point?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/162#issuecomment-989322122:282,depend,depends,282,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/162#issuecomment-989322122,1,['depend'],['depends']
Integrability,"Finalky i found that my transcript file was crashed during uploading to my; server; I repeated the process. It works now; Thank you so much. في الاثنين، ٢٢ أغسطس ٢٠٢٢ ٣:٢١ م Rob Patro ***@***.***> كتب:. > Hi @esraagithub <https://github.com/esraagithub>,; >; > Thanks for the bug report. Can you tell me how the specific version of; > salmon you are using was installed (e.g. via source, downloaded from the; > ""releases page"", or installed via bioconda)? Would it be possible to share; > the contigs that cause this error?; >; > Thanks,; > Rob; >; > —; > Reply to this email directly, view it on GitHub; > <https://github.com/COMBINE-lab/salmon/issues/795#issuecomment-1222353941>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AMY4XZX6ZGAO5DOU5YOWTG3V2N5DZANCNFSM57HUQWJQ>; > .; > You are receiving this because you were mentioned.Message ID:; > ***@***.***>; >",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/795#issuecomment-1223885767:859,Message,Message,859,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/795#issuecomment-1223885767,1,['Message'],['Message']
Integrability,"Fwiw, the conda resolver is not the only issue:. >conda create -n salmon -c bioconda -c conda-forge salmon=1.10.2. Collecting package metadata (current_repodata.json): done; Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.; Collecting package metadata (repodata.json): / Killed. Adam H. Freedman, PhD; Data Scientist; Faculty of Arts & Sciences Informatics Group; Harvard University; 38 Oxford St; Cambridge, MA 02138; phone: +001 310 415 7145; ________________________________; From: Rob Patro ***@***.***>; Sent: Sunday, October 29, 2023 8:04 AM; To: COMBINE-lab/salmon ***@***.***>; Cc: Freedman, Adam ***@***.***>; Author ***@***.***>; Subject: Re: [COMBINE-lab/salmon] anaconda version of salmon outdated, missing decoys option (Issue #895). Depending on what environment you install in (other conda software), the default resolver in conda is messed up. You should just explicitly ask for 1.10.2 with “ conda install salmon=1.10.2”. You can also try installing it in a clean conda env which is how I install most of my conda software anyway. Best,; Rob. —; Reply to this email directly, view it on GitHub<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_COMBINE-2Dlab_salmon_issues_895-23issuecomment-2D1784085120&d=DwMFaQ&c=WO-RGvefibhHBZq3fL85hQ&r=MITI_LEJgyr1a24IMFAlSaZIPxMpOUT21T7L3fg4CjA&m=BuO8x-09ODKHZCV2IlEsuaycWlFfWjCrfXJ-22PbmV0x8PssZEMVgCYeWBbR1GlW&s=Ea4-F5juBTywwyjamWmiXQu3PVrQ4kCnIg-68wR1Pa4&e=>, or unsubscribe<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_notifications_unsubscribe-2Dauth_ADBMMUHDLECWA4NGVBBX7R3YBZA5HAVCNFSM6AAAAAA6UYYPGOVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMYTOOBUGA4DKMJSGA&d=DwMFaQ&c=WO-RGvefibhHBZq3fL85hQ&r=MITI_LEJgyr1a24IMFAlSaZIPxMpOUT21T7L3fg4CjA&m=BuO8x-09ODKHZCV2IlEsuaycWlFfWjCrfXJ-22PbmV0x8PssZEMVgCYeWBbR1GlW&s=UIOMil_E-TPQw6P8DHvvV7-jaFu1apAxBIJgLzjUtvs&e=>.; You are receiving this because you authored the thread.Message ID: ***@***.***>",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/895#issuecomment-1784119351:806,Depend,Depending,806,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/895#issuecomment-1784119351,2,"['Depend', 'Message']","['Depending', 'Message']"
Integrability,"GitHub supports uploading files directly in the issues, so I'll compile the updated binary and I'll drop it right here (I'll do this today, but it might be an hour or so). Once you have it, you can confirm if it works for you (I'm still on 10.11, so I'll have to build it there, but with the updated dependency).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/103#issuecomment-259466544:300,depend,dependency,300,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/103#issuecomment-259466544,1,['depend'],['dependency']
Integrability,"Great suggestion, thanks @rob-p and @gmarcais . Somehow, I missed it. I added it in the latest commit. Speed now from 3 runs:; ```; real 1m19.884s 1m15.891s 1m21.462s ; user 8m9.189s 9m1.100s 9m48.764s ; sys 0m5.079s 0m5.170s 0m3.477s; ```; 50% improvement over the past results, i.e., about 33% slower than specific protocol flag now. Although, ideally I should have ran the earlier tests thrice but the sd is small so results should be valid. Nonetheless, I'll do more speed tests with versions in the future. . Let me know what other thoughts you have and what else have I missed. I have some minor improvements in mind too.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/734#issuecomment-1013326966:317,protocol,protocol,317,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/734#issuecomment-1013326966,1,['protocol'],['protocol']
Integrability,"Great; would you like help testing the pipeline, and integrating it into bcbio? We could help with both :)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/52#issuecomment-255123178:53,integrat,integrating,53,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/52#issuecomment-255123178,1,['integrat'],['integrating']
Integrability,"HI @Acribbs ,. Thanks for the very interesting question.; I think the first question in my mind is, do you need intron level deduplicated counts ? If yes, then sadly concatenating the pre-mrna sequence into the transcriptome sequences is probably not a good idea, as in general, the length of intronic sequences are much longer than that of exonic sequence and it may bias alevin deduplication algorithm. However, if you don't need the number of unspliced deduplicated counts and as the nuceli scRNA-seq has more pre-mRNA data if the question is regarding the aligning to genome v transcriptome then we just proposed a solution in our latest [preprint](https://www.biorxiv.org/content/10.1101/657874v1?rss=1). The new SA method is already integrated into salmon but you may have to index the genome+transcriptome using our scripts from [here](https://github.com/COMBINE-lab/SalmonTools). Hope it helps !",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/370#issuecomment-499513288:739,integrat,integrated,739,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/370#issuecomment-499513288,1,['integrat'],['integrated']
Integrability,"HI @gianfilippo ,; I think #245 might help understanding the problem better.; Specifically to answer your questions, I am guessing `737K-august-2016.txt` is all the set of Cellular Barcodes(CB) being whitelisted by 10xGenomics protocol while in Alevin when you are giving external whitelist it assumes that the user is pretty confident about the presence of *all* the given CBs in their experiment. for example if you want to compare Alevin and cellranger apple to apple then you might have to give the `barcodes.tsv`(usually is present along with the `mtx` file) generated by the cellranger. (after removing `-1` from the CB names). ; `[alevinLog] [error] Barcode not found in frequency table`: This error means some of the CB given externally through the whitelist command seems to have no reads at all which violates the above assumption, you can potentially skip this error by using `--debug` flag with alevin (only if have version v0.11.3) but this mode has is yet to be extensively tested.; In case where you don't externally give whitelist CB, Alevin uses knee and KDE based method to identify the cutoff on the knee (and later correct for it) of the CB distribution. Based on your specific dataset it is possible that the method might be overshooting and aggressively identifying less number of clusters. If you can share the log and some part of your data then we can take a look what's going on. Hope this helps.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/284#issuecomment-417964393:227,protocol,protocol,227,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/284#issuecomment-417964393,1,['protocol'],['protocol']
Integrability,"HI @mfansler ,; Thanks for asking the very important question.; Alevin is primarily (till current release) designed to work with 3'-tagged end, droplet based sequencing where the primary assumption is that most of the reads would ideally be sequenced from the 3'-end of the molecule. Although, Salmon is a transcript quantification tool for *bulk* RNA-seq but we believe in singe-cell (3'-tagged) sequencing, generating quantification at transcript level is fundamentally hard problem to solve. Specifically, one of the reason is, a lot of transcripts share the terminal exon, and the features like length effect which are used in bulk RNA-seq to resolve ambiguity is not directly usable in single-cell for resolving the transcript ambiguity making the problem hard.; It's possible in the future that assays are designed to help incorporate more information e.g. sequencing from both 5' or 3' end sequencing or use SMART-seq2 which sequence the full molecule. In latter case people have been using Salmon as-is for generating the transcript level quantification. . _In summary_: We believe it's a trade-off based on your use case i.e. if you wan't to generate transcript level counts then most-likely single cell protocols which sequence from the full length of the molecules like smart-seq2 is better suited but if the motivation is to get higher number of cell coverage w/ decent gene-level molecule counts that's where 3'-end tagged end sequencing protocols shines most. _One Liner_; Alevin generates only gene-level counts for droplet based sequencing (til latest release v0.11.2).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/287#issuecomment-420627713:1213,protocol,protocols,1213,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/287#issuecomment-420627713,2,['protocol'],['protocols']
Integrability,"Hello Again,. I just ran the command and got the same error message as before. Here is my; command:. ```#!/bin/bash -l; #SBATCH -J male_salmon_map; #SBATCH -t 150:00:00; #SBATCH -p high; #SBATCH --cpus-per-task=24; source ~/.bashrc; source activate salmon; cd /home/seboles/abaloneraw/salmon_quantification/SALMON_MALE/; for i in *.qc.fq.gz; do; salmon quant -i maleredabalone_index --libType IU -1; mgonad-2_S121_L006_R1_001.qc.fq.gz; lightreceptor-1_S114_L006_R1_001.qc.fq.gz; mgonad-1_S120_L006_R1_001.qc.fq.gz; lightreceptor-2_S115_L006_R1_001.qc.fq.gz; mgonad-2_S121_L005_R1_001.qc.fq.gz mgonad-1_S120_L005_R1_001.qc.fq.gz; lightreceptor-2_S115_L005_R1_001.qc.fq.gz; lightreceptor-1_S114_L005_R1_001.qc.fq.gz; mgonad-2_S121_L004_R1_001.qc.fq.gz mgonad-1_S120_L004_R1_001.qc.fq.gz; lightreceptor-2_S115_L004_R1_001.qc.fq.gz; lightreceptor-1_S114_L004_R1_001.qc.fq.gz -2; mgonad-2_S121_L006_R2_001.qc.fq.gz; lightreceptor-1_S114_L006_R2_001.qc.fq.gz; mgonad-1_S120_L006_R2_001.qc.fq.gz; lightreceptor-2_S115_L006_R2_001.qc.fq.gz; mgonad-2_S121_L005_R2_001.qc.fq.gz mgonad-1_S120_L005_R2_001.qc.fq.gz; lightreceptor-2_S115_L005_R2_001.qc.fq.gz; lightreceptor-1_S114_L005_R2_001.qc.fq.gz; mgonad-2_S121_L004_R2_001.qc.fq.gz mgonad-1_S120_L004_R2_001.qc.fq.gz; lightreceptor-2_S115_L004_R2_001.qc.fq.gz; lightreceptor-1_S114_L004_R2_001.qc.fq.gz ${i} -o ${i}_quant --seqBias; --gcBias --validateMappings; done```. And here is my output from salmon.log. [2019-07-30 10:40:14.624] [jointLog] [info] Fragment incompatibility prior; below threshold. Incompatible fragments will be ignored.; [2019-07-30 10:40:14.624] [jointLog] [error] You passed paired-end files to; salmon, but you passed 12 files to --mates1 and 13 files to --mates2. You; must pass the same number of files to both flags. Thank you in advance for any tips you may have for me. Sara. On Tue, Jul 30, 2019 at 10:30 AM Sara Boles <seboles@ucdavis.edu> wrote:. > Hi Avi,; >; > Here is the salmon log from one of my PE libraries. There are",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/408#issuecomment-516521791:60,message,message,60,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/408#issuecomment-516521791,1,['message'],['message']
Integrability,"Hello Rob,. Thank you for your quick reply to my question. My MEGAHIT and Trinity assemblies were not built with strand-aware flags. I made decoy-aware transcriptomes using a MEGAHIT assembly, a Trinity Assembly, and a published transcriptome from the same species, and when I ran my read files through salmon using ""A"" as the library type and each of the three indexes, all three were detected as ""most likely library type IU"". It's strange that once all three have been compiled into a single assembly using Evigene, salmon detects the ISR library type. When I change the ""A"" to ""ISR"" or ""IU"", the % mapped changes a lot. ; Is it better to build assemblies with strand-aware flags? If so, does it usually make a large difference to quantification results, or a minor one? I don't know what protocol the sequencing facility used, but I am sure I could ask them. I gather from my recent reading that the extra information gained by using a stranded protocol _is_ worthwhile, so I would expect that the sequencing facility used one, but why doesn't Trinity or MEGAHIT detect the sequecing protocol that was used? Or, if you have to specify it, why do none of the example Trinity commands I've come across include this option? It doesn't strike me as a commonly used specification in making assemblies. Thanks for answering my noobie questions. Holly",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/840#issuecomment-1492849365:792,protocol,protocol,792,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/840#issuecomment-1492849365,3,['protocol'],['protocol']
Integrability,"Hello, ; Thank you for your message. However, I am working with fission yeast transcriptome and since I am not expecting a lot of splicing junctions with this organism, I read that people recommended using -ax map-ont in this case?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/786#issuecomment-1184348921:28,message,message,28,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/786#issuecomment-1184348921,1,['message'],['message']
Integrability,"Hey @TobiTekath ,. Thanks for the very interesting question. You are right, the unmated reads are not supported yet, but the basic idea was to consume a file with cb and umi attached to the read name, however it's a wip and is not properly supported. . re: any SE single-cell protocol - I am not aware of any.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/522#issuecomment-634378224:276,protocol,protocol,276,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/522#issuecomment-634378224,1,['protocol'],['protocol']
Integrability,"Hey @jeremymsimon! I checked the protocol and the [pipeline code](https://github.com/yjzhang/split-seq-pipeline/blob/master/split_seq/tools.py). The protocol you described is v1 and the Parsebio is v2. I have implemented v2 in salmon and would be testing it this week. v1 can be similarly implemented. I read the paper and other available resources but I am not clear about the random hexamer usage and it's effects on the barcode. Can you please explain what you meant by BC1s being paired and what's the use of random hexamer, please? Thanks.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-936331597:33,protocol,protocol,33,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-936331597,2,['protocol'],['protocol']
Integrability,"Hey @jeremymsimon! I figured out what the issue was. Alevin is fine, but my implementation of the split-seq protocol had an issue. I was able to get good correlation with the submitted counts and good match between barcodes. Here's what I did: . - Used fastp to clean the fastq files. ; - Ran `salmon alevin` with custom geometry flags and `--justAlign`. For index I used human GENCODE v31 reference. ; ```; salmon alevin -i /biodb/human/gencode/v31/salmon_index_wo_decoy/ -l A -1 SRR10174292_trimmed_1.fastq.gz -2 SRR10174292_trimmed_2.fastq.gz -p 44 --bc-geometry 2[11-18,49-56,87-94] --umi-geo 2[1-10] --read-geo 1[1-end] -o runtestdata_custombc --justAlign; ``` ; - Used `alevin-fry` on the output; ```; $ cd runtestdata_custombc; $ alevin-fry generate-permit-list -i ./ -d both --output-dir run -k; 2021-12-06 15:36:39 INFO paired : false, ref_count : 226,030, num_chunks : 7,9282021-12-06 15:36:39 INFO read 2 file-level tags2021-12-06 15:36:39 INFO read 2 read-level tags; 2021-12-06 15:36:39 INFO read 1 alignemnt-level tags; 2021-12-06 15:36:39 INFO File-level tag values FileTags { bclen: 24, umilen: 10 }2021-12-06 15:36:45 INFO observed 39,536,527 reads in 7,928 chunks --- max ambiguity read occurs in 196 refs2021-12-06 15:36:45 INFO max_idx = 170639; 2021-12-06 15:36:45 INFO max_idx = 59128; 2021-12-06 15:36:45 INFO max_idx = 21206; 2021-12-06 15:36:45 INFO max_idx = 10151; 2021-12-06 15:36:45 INFO max_idx = 7852; 2021-12-06 15:36:45 INFO max_idx = 72462021-12-06 15:36:45 INFO max_idx = 70432021-12-06 15:36:45 INFO max_idx = 69602021-12-06 15:36:45 INFO max_idx = 6937; 2021-12-06 15:36:45 INFO max_idx = 6925; 2021-12-06 15:36:45 INFO knee-finding iter = 10; 2021-12-06 15:36:45 INFO max_idx = 6922; 2021-12-06 15:36:45 INFO knee distance method resulted in the selection of 6923 permitted barcodes.; 2021-12-06 15:36:46 INFO total number of distinct corrected barcodes : 333,352; $ alevin-fry collate -i run/ -t 16 -r ./ ; 2021-12-06 15:37:02 INFO filter_type = Filtered; 2021-1",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-987334414:108,protocol,protocol,108,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-987334414,1,['protocol'],['protocol']
Integrability,"Hey @rob-p ,. Thanks for your response. I agree with your suggestion - to have a flag for gff/bed and run either GTF or a BED/GFF file depending on what the end user has. In my case, I have mostly gff files and I need to do some reformatting if I have to use the current shell script.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/384#issuecomment-503632945:135,depend,depending,135,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/384#issuecomment-503632945,1,['depend'],['depending']
Integrability,"Hey Rob,. Regarding file pairs, in some cases e.g. the FW read contains the mRNA Tag and a Cell Barcode, while the RV read contains the UMI and some non-informative sequence. In particular in the 10X Chromium (V1) protocol there are 4 files! FW, RV as well as I5 and I7 index reads. I don't remember exactly which read contains what information right now though.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/108#issuecomment-269658634:214,protocol,protocol,214,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/108#issuecomment-269658634,1,['protocol'],['protocol']
Integrability,"Hey Rob. It looks like this was an error in the way I was calling `salmon index`. I've wrapped salmon in a python based pipeline where I manage creation of index files using configuration files. To call `salmon index` I was previously iterating on standard error, capturing your err and logging it after reformatting a bit. It looks like what was happening is:. 1. I opened a subprocess and executed salmon; 2. Salmon worked properly; 3. Salmon stopped producing output on stderr (and sent an EOF marker?) and so my script exited; - killing salmon prematurely; - truncating the salmon index (In a way that salmon found perfectly acceptable during `salmon quant`; - frustrating me quite a bit. I fixed this by doing the right thing and blocking for the process to return an exit code:. ```diff; p = Popen(cmd, stderr=PIPE); - for line in p.stderr:; - line = line.decode(); - if line.endswith('\n'):; - logging.info(line.rstrip()); - else:; - logging.info(line); + _, err = p.communicate(); + logging.info(err); ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/132#issuecomment-303738589:87,wrap,wrapped,87,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/132#issuecomment-303738589,1,['wrap'],['wrapped']
Integrability,"Hey,. What is your cutoff for considering a gene expressed? Salmon puts a small > 0 expression on most genes. Usually we count genes over e.g. 5 reads, or e.g. > 1 TPM, depending analysis.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/120#issuecomment-279958203:169,depend,depending,169,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/120#issuecomment-279958203,1,['depend'],['depending']
Integrability,"Hi @ACastanza,. Thanks for reporting both of these. For the first, I think it is just the case that the message needs to be updated. In fact, the `--validateMappings` flag is now deprecated since selective-alignment is used by default (and can't be turned off, except in the single-cell mapping context, with the `--sketchMode` flag, which is currently only in the develop branch). We'll update that message.; Regarding the misplaced newline, the issue is that the other messages are written by the logger, which is asynchronous. So, sometimes it will get to the appropriate place and write a newline before the fragment counter starts, and sometimes it won't. I'll look into if there is a way to better clear the line, even if the update is asynchronous. Thanks!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/587#issuecomment-729044670:104,message,message,104,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/587#issuecomment-729044670,3,['message'],"['message', 'messages']"
Integrability,"Hi @Anto007,. Sounds like an interesting experiment! A couple of questions: (1) are you quantifying the meta-transcriptome or the metagenomes? What I mean is, are your target sequences the specific genes from the microbes, or the entire microbial genomes? Is the sequencing data RNA-seq from sequencing the mixture of expressed gene transcripts, or DNA-seq of the microbes? This will have an effect on how you expect reads to be generated. The effect of `--minScoreFraction` depends, to some extent, on how you set the match/mismatch/gap parameters. With the default parameters, `0.9` is actually higher than 90% sequence identity, because the default mismatch penalty is twice the match score. If you assume only matches and mismatches, then the `--minScoreFraction` you want to set is the one such that ; x * (match_score * read_length) <= (match_score * read_length) - (m * read_length * match_score) + (m * read_length * mismatch_penalty), where m is the mismatch fraction (0.1 in your case). So, for example, if the match_score is 2 and mismatch penalty is -4, and the read length is 100, you want to set it so that:. x * 200 = 200 - (0.1 * 100 * 2) + (0.1 * 100 * -4) = 200 - 20 - 40 = 140 . so, the appropriate x would be ~0.7. Of course, if you want to make the calculation simple, you can set the match score to 1 and mismatch penalty to 0, and then the interpretation (modulo gaps) is straightforward (and 0.9 means what you want). Finally, I'd typically avoid using `--mimicStrictBT2`, since those are pretty harsh parameters. Of course, you could try mapping both with and without that flag and see how it affects your mapping rate.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/330#issuecomment-447589060:475,depend,depends,475,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/330#issuecomment-447589060,1,['depend'],['depends']
Integrability,"Hi @BW15061999,. I’m not aware of any tagged-end single-cell protocol that uses only 1 read. The most common data types place the UMI and Barcode on one of the reads, while the other “biological” reads are drawn from the transcriptome. This is the case with the Chromimum protocol. The reason you are seeing 0 assigned reads is that no barcodes can be extracted, because the second read is missing. Therefore, no reads can be assigned to any cell. What specific protocol are you using? Do you not have the full read pairs for each sample? Cc @k3yavi as the resident protocol guru. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/769#issuecomment-1107467832:61,protocol,protocol,61,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/769#issuecomment-1107467832,4,['protocol'],['protocol']
Integrability,"Hi @Ci-TJ,. This suggests that the FASTQ files were ""desynchronized"" during / after trimming somehow. Salmon requires that the FASTQ files are synchronized. So, if the trimmer decides to discard a read from the first read file, it must also discard the corresponding read from the second read file. I'm not specifically familiar with RabbitQC, but most quality / adapter trimmers have an option to separate out any reads that become orphaned during trimming so that the output paired FASTQ files remain synchronized. You should make sure that any such options are passed during QC. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/660#issuecomment-846252372:143,synchroniz,synchronized,143,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/660#issuecomment-846252372,3,"['adapter', 'synchroniz']","['adapter', 'synchronized']"
Integrability,"Hi @ECuris,. Indeed, this seems to be a case where the code evolved and the documentation has yet to catch up. The defaults are `fldMean` = 250 and `fldSD` = 25. The relevant code is here (https://github.com/COMBINE-lab/salmon/blob/master/src/SalmonQuantify.cpp#L2260). This defines how default values are set for these parameters. I'll make a note to update the documentation to be consistent with these changes (which were made to be more in line with modern protocols, though there's still no good universal parameters for things that can vary so widely between experiments).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/127#issuecomment-286760710:461,protocol,protocols,461,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/127#issuecomment-286760710,1,['protocol'],['protocols']
Integrability,"Hi @Hoohm , ; Thanks for the quick reply and the explanation . I personally am not very well versed in the working of `SCRBseq`. But, as you explained, knowing a set of whitelist CB beforehand is always a plus for the downstream working of the pipeline. Currently, Alevin merge all the observed CB which are 1-edit distance from a known whitelist CB towards the whitelist. The underlying assumption being that the sequencing error (although with low probability) can change CB sequence and we can correct for that. I wonder, is this right to do for your experiment ?. re: >Is there an option for max distance allowed between BC or UMI?; Sorry, but I don't completely understand this question. When you say distance allowed between CB and UMI, do you mean there is a sequence between CB and UMI ( like in in-drop seq)? If that's the case then we might have to tweak a bit in alevin command line flags again. But I suspect what you meant by above statement is -- max distance allowed between CB among themselves. If that's the question then unfortunately we currently allow correcting for only 1-edit distance for both CB and UMI. But if you think more correction is needed by your protocol then we can put this on the feature request list and discuss about working on this on the next release.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/247#issuecomment-402543751:1180,protocol,protocol,1180,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/247#issuecomment-402543751,1,['protocol'],['protocol']
Integrability,"Hi @KS751515,. It appears that you have quantified the *genome* (i.e. you have computed an abundance for each chromosome) rather than the transcriptome (i.e. an abundance for each gene transcript). The reference should be the reference transcriptome rather than the reference genome (depending on the specific annotation, this should have on the order of ~150,000-200,000 reference sequences. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/824#issuecomment-1386426735:284,depend,depending,284,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/824#issuecomment-1386426735,1,['depend'],['depending']
Integrability,"Hi @PeteHaitch ,; Thanks for your interest in *Alevin*.; Although in current Alevin we have concentrated mainly on learning more about Droplet based 3'-tagged single cell protocols, especially 10x; we are very much interested in extending it towards other protocols like CEL-seq.; However, there are couple of challenges/difference which should be considered before incorporating it into the Alevin pipeline. Currently Alevin relies on the fact that the droplet based protocols use PCR amplification of the library and the UMI deduplication phase of Alevin assumes an exponential model, I am not sure how true is this with CEL-seq? Another issue is that CEL-seq is a Fluidigm based system while the current application for Alevin is for microfluidics based. In general we have observed that the 10x cell isolation step is pretty robust in reporting the Cellular Barcodes(CB) and although we have a probabilisitic model to handle the CB based uncertainty but the ambiguous case like that are very less frequent, (although not true for Drop-Seq). Having said that, we might have to do some analysis to actually figure out the right model for Barcode correction in Fluidigm based system. Also, please do let us know of your experience in using the solution proposed in #247 . Looking forward to hearing back from you.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/269#issuecomment-414162302:171,protocol,protocols,171,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/269#issuecomment-414162302,3,['protocol'],['protocols']
Integrability,"Hi @PeteHaitch! I agree with @PeteHaitch here --- I think we should provide an easy way to specify custom cb & umi parameters paired with a particular protocol. For 10x v2, since it's a very standard commercial protocol, I think simply having a `--chromium` flag is probably OK. But we should make it easy for ppl to tweak their CB & UMI lengths.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/269#issuecomment-418580112:151,protocol,protocol,151,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/269#issuecomment-418580112,2,['protocol'],['protocol']
Integrability,"Hi @Rhinogradentia,. This error occurs when there is a binary mismatch between the library used to compile salmon versus that used to run it. Specifically, this occurs when the boost library is _not_ compiled with a modern ABI (Application Binary Interface) — when boost was not compiled in a way compatible with C++11/14/17/20. Are you using the version installed via bioconda, or the pre-compiled binary from github, or have you compiled this yourself? You can [use the `LD_LIBRARY_PATH`](https://stackoverflow.com/questions/13428910/how-to-set-the-environmental-variable-ld-library-path-in-linux) to set things so that the appropriate version of the library is discovered first. You want the version of boost that is found first (the one appearing earliest in the `LD_LIBRARY_PATH`) to be matched to the one with which salmon was compiled.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/565#issuecomment-696812977:247,Interface,Interface,247,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/565#issuecomment-696812977,1,['Interface'],['Interface']
Integrability,"Hi @SSaleem94,. As the message suggests, your command is missing the required `--output` argument. Of course, it seems your command includes `-o`. The rest of the errors suggest that the command line is not being properly parsed. It looks like the part after the first line break is not being interpreted as a continuation of the same line. I think this is because the line extension character in the shell is not `/`, but is `\`. Maybe try the following:; ; ```; F=$(cat file_names.txt); for i in ${F}; do; F1=../processed_fastq/${i}_R1_001_val_1.fastq.gz; F2=../processed_fastq/${i}_R2_001_val_2.fastq.gz; echo ""performing salmon quant on ${i}""; salmon quant -i gencode_v43_index -l A -1 ${F1} -2 ${F2} -p 64 \; --validateMappings --writeUnmappedNames -o ${i}; echo ""finish quantifying ${i}""; done; ```. **Also**, as is suggested by the `salmon` message itself, you may want to consider upgrading to the latest version of `salmon`. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/854#issuecomment-1599169394:23,message,message,23,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/854#issuecomment-1599169394,2,['message'],['message']
Integrability,"Hi @Tima-Ze,. This should not cause any trouble with downstream analysis. The indexing procedure is simply informing you that these transcripts (about which you are being warned) are shorter than the seed length used for alignment. This means that it simply won't be possible for fragments to align to these transcripts, and so they will always have a 0 abundance in the resulting `quant.sf` files. This isn't a problem, as these transcripts are too short to be measured via RNA-seq anyway. The indexing messages just let you know this in advance. You can safely ignore these warnings for your downstream analysis.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/214#issuecomment-751366278:504,message,messages,504,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/214#issuecomment-751366278,1,['message'],['messages']
Integrability,"Hi @Tima-Ze,. Yes, salmon can be used to quantify these reads, but the results will depend (somewhat) on the `--fldMean` and `--fldSD` flags that are used. It's important to note that this is not a unique characteristic of salmon, and any transcript-level quantification tool using a probabilistic model (e.g. RSEM, eXpress, BitSeq, etc.) have the same requirement. That is, the fragment length distribution should be known so that _effective_ transcript lengths can be estimated, which have an effect on fragment assignment probabilities. If the wrong fragment length distribution is specified, then the _effective_ transcript lengths will be off and this can affect the assignment of some fragments. This is only a requirement with single-end reads, since with paired-end reads the fragment length distribution is learned from the data. Further, the inference procedure is somewhat robust to these choices (small changes in fld mean and sd don't generally lead to drastically different results). If you have access to the BioAnalyzer results for the sequencing run, those can give information about the fragment length distribution (even in a single end experiment). If not, you can proceed with the default values. Even if they don't exactly match the true distribution in the single-end sample, at least the same values will be applied in all samples and so, ideally, most results of misspecification will wash out in subsequent differential analysis. . Finally, it's worth noting that the same restriction holds in both alignment-based and mapping-based modes. This is because in neither mode do single-end fragments provide sufficient information to estimate the fragment length distribution from the data. We only know where one end of a fragment mapped and cannot infer where the other end would be. This is not an alignment versus mapping (versus selective-alignment) issue, but rather is fundamental to having only observed one side of the entire fragment generated during fragmentation and ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/127#issuecomment-750920243:84,depend,depend,84,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/127#issuecomment-750920243,1,['depend'],['depend']
Integrability,"Hi @Tj-Idowu,. Thanks for the details. The fact that the bioconda install is giving problems is disconcerting, as that should be properly linked against all of the correct libraries etc. I do wonder if it might have something to do with all of the package rebuilding and upgrading that has been going on in bioconda. Would you be able to give [this binary](https://github.com/COMBINE-lab/salmon/files/2099291/salmon-latest_linux_x86_64.tar.gz) a try, and let me know if it works? It was built on our continuous integration server, and should be compatible with a wide variety of different platforms.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/239#issuecomment-400679476:511,integrat,integration,511,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/239#issuecomment-400679476,1,['integrat'],['integration']
Integrability,"Hi @alexg9010,. This is absolutely a cryptic error message. I'm *guessing* it may have something to do with the de-serialization of the index. Would you be able to provide the file on which you build the index? I can see if I can reproduce this error locally. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/210#issuecomment-376005422:51,message,message,51,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/210#issuecomment-376005422,1,['message'],['message']
Integrability,"Hi @antonkulaga,. Indeed. Sailfish-cir was developed by another group, but it has a procedure for linerizing circular RNAs and quantifying them using Sailfish. I believe it would be nice to see support for Salmon added to the same strategy. I believe their tool contains a wrapper tha calls out to Sailfish with a modified transcriptome index, so that should be fairly easy to port to Salmon.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/220#issuecomment-386882962:273,wrap,wrapper,273,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/220#issuecomment-386882962,1,['wrap'],['wrapper']
Integrability,"Hi @antonkulaga,. This is not a particularly useful error message (_sorry for that_), but this is a result of passing both un-paired (`-r`) and paired-end (`-1,-2`) reads to salmon together. This is actually not supported, as the single-end and paired-end models are actually a bit different. I will fix the error checking so that a useful message is printed out if these options are passed in together. Can you let me know if the program runs correctly if you use just the paired-end reads?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/175#issuecomment-346899958:58,message,message,58,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/175#issuecomment-346899958,2,['message'],['message']
Integrability,"Hi @asher1234,. Thanks for the detailed bug report. The detection of the library type as `MU` certainly does raise some flags as that is not something that would be expected. Moreover, in the v0.12.0 log you posted, we see messages like:. ```; Thread saw mini-batch with a maximum of 90.16% zero probability fragments; ```. Which means that e.g. ~90% of the fragments, even though they map, are being assigned a 0 probability under the model (because of e.g. incompatibility with the library type). Would you be able to share one of these samples and the reference transcriptome against which you are quantifying? Also, do things look any different if you force the library type to be something more common (e.g. `-l IU`)?. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/346#issuecomment-469108517:223,message,messages,223,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/346#issuecomment-469108517,1,['message'],['messages']
Integrability,"Hi @avocado851,. No worries, and welcome to the RNA-seq analysis world! Thanks for choosing salmon :). There's a detailed discussion over in [this](https://github.com/COMBINE-lab/salmon/issues/533) issue describing some reasons you might be seeing a lower than expected mapping rate. The TLDR is, make sure you trim your reads (and / or try mapping with the `--softclip` option) and see if your mapping rate improves to your satisfaction. Even then, it's not uncommon when aligning RNA-seq data to see the kind of mapping rate you're describing *to the annotated transcriptome*. In any given sample, you might see a non-trivial number of reads from outside of the annotation, and the level of this can depend on your tissue type, condition, annotation completeness etc. If there are no issues in your quality report (e.g. are you running this through FastQC / MultiQC etc.?), then this mapping rate alone need not be conclusive evidence of a bad sample.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/571#issuecomment-704947451:702,depend,depend,702,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/571#issuecomment-704947451,1,['depend'],['depend']
Integrability,"Hi @bounlu,. None of these dependencies are explicitly declared for the salmon build. In fact, salmon is one of the packages already migrated to the new conda build 3 system. Could you please raise this issue over in the bioconda repository?. Thanks!. Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/286#issuecomment-419195164:27,depend,dependencies,27,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/286#issuecomment-419195164,1,['depend'],['dependencies']
Integrability,"Hi @citron96,. The patch is quite simple and i have verified it and it works for salmon-1.1.0 version that i compiled. Here is the patch content:. --- salmon-1.1.0/CMakeLists.txt.orig 2020-03-24 08:50:22.681000000 -0700; +++ salmon-1.1.0/CMakeLists.txt 2020-03-24 08:51:41.786000000 -0700; @@ -596,7 +596,7 @@; message(""Build system will fetch and build Intel Threading Building Blocks""); message(""==================================================================""); # These are useful for the custom install step we'll do later; -set(TBB_SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/tbb-2019_U8); +set(TBB_SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/oneTBB-2019_U8); set(TBB_INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install). if(""${TBB_COMPILER}"" STREQUAL ""gcc""); @@ -610,9 +610,9 @@; externalproject_add(libtbb; DOWNLOAD_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external; DOWNLOAD_COMMAND curl -k -L https://github.com/intel/tbb/archive/2019_U8.tar.gz -o tbb-2019_U8.tgz &&; - ${SHASUM} 7b1fd8caea14be72ae4175896510bf99c809cd7031306a1917565e6de7382fba tbb-2019_U8.tgz &&; + ${SHASUM} 6b540118cbc79f9cbc06a35033c18156c21b84ab7b6cf56d773b168ad2b68566 tbb-2019_U8.tgz &&; tar -xzvf tbb-2019_U8.tgz; - SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/tbb-2019_U8; + SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/oneTBB-2019_U8; INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install; PATCH_COMMAND ""${TBB_PATCH_STEP}""; CONFIGURE_COMMAND """". Rob, ; I understand that you don't want to push changes to older releases but perhaps one; can issue a README/NOTE for all prior releases that are affected by this. The explanation of; what changed will allow people to create their own patches for their specific releases. Regards,; Nadya",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/497#issuecomment-603916394:311,message,message,311,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/497#issuecomment-603916394,2,['message'],['message']
Integrability,"Hi @davidaknowles,. Assuming that the total size of all cell barcodes doesn't exceed 32 nucleotides, then it should be possible to simply specify them using a custom geometry string. Of course for that to work, we need to know where the 4th barcode is located, so that we can generate the correct custom geometry string to extract it. I'll ping @DongzeHE and @k3yavi here to see if either of them are familiar with this chemistry already. As always, I'd also suggest running this through `alevin-fry` (or using the `simpleaf` wrapper). While we continue to support `alevin`, `alevin-fry` (largely interfaced by `simpleaf`) is where most of our development effort is currently going, and hopefully we can make the user experience there as smooth and easy as possible!. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/874#issuecomment-1732428996:526,wrap,wrapper,526,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/874#issuecomment-1732428996,2,"['interface', 'wrap']","['interfaced', 'wrapper']"
Integrability,"Hi @davidaknowles,. Indeed — the barcode extraction will happen either in `salmon alevin` or, if you are using the new `piscem` module for mapping prior to quantification (both are exposed in the `simpleaf` wrapper tool to simplify single-cell processing with `alevin-fry`), then it will happen there. We have a new very general and much more capable module in the works that will be able to handle all manners of single-cell geometry, but nothing about the Parse library seems beyond the capabilities of the current geometry processing code. If you share some reads, we can also try and take a look and figure out where the last BC resides. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/874#issuecomment-1733872331:207,wrap,wrapper,207,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/874#issuecomment-1733872331,1,['wrap'],['wrapper']
Integrability,"Hi @davidnboone and @mcfwoodruff,. So, I should have mentioned that if you want to use the pre-compiled binary I provide, you have to put the `lib` folder in your path. One way to accomplish this is to run salmon as follows:. ```; DYLD_FALLBACK_LIBRARY_PATH=<path_to_salmon_folder>/lib <path_to_salmon_folder>/bin/salmon ; ```; Where `<path_to_salmon_folder>` is simply the top-level directory where you decompressed salmon. You can, of course, make a little wrapper script to make launching it less ugly.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/295#issuecomment-421417111:459,wrap,wrapper,459,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/295#issuecomment-421417111,1,['wrap'],['wrapper']
Integrability,"Hi @davismcc, . Yes; this is very high-up on our to-do list. Right now, we are primarily limited by people (students and myself) able to actually hack away on the codebase. I would say that adding support for single-cell data is in the top 1-3 features on our todo list right now. I'd also encourage you to voice your support for this feature on our [survey](https://docs.google.com/forms/d/e/1FAIpQLSeWhBNE_fA_0uVHvbAlAulDmfmowv7rAYla879DZpqCARyRTQ/viewform), which we will use to prioritize feature development. In addition to the implementation, the other big ""question"" will be how to support the broadest variety of such data with the most uniform interface and implementation. It seems like barcoding / UMI tagging is a bit ""wild-west"" right now where every protocol uses it's own format to encode the relevant information. I think that, in that case, some form of pre-processing (a la @vals work), might be the best solution.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/93#issuecomment-282336377:653,interface,interface,653,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/93#issuecomment-282336377,2,"['interface', 'protocol']","['interface', 'protocol']"
Integrability,"Hi @dhy2002,. The message at the beginning is just a result of salmon not being able to complete the version check — that is not related to any issues building the index. What is at the end of the log file?. Also, I'll note that we've seen before some issues related to building the index directly on a network file system mounted partition — the tool we use for compacted de Bruijn graph construction, TwoPaCo, can create many small intermediate files that causes issues for NFS. If this is the problem, I might suggest building the index on the local scratch disk of a node, and then copying over the completed index when it's finished. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/755#issuecomment-1050468212:18,message,message,18,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/755#issuecomment-1050468212,1,['message'],['message']
Integrability,"Hi @diyang1354,. It is recommended to do adapter trimming prior to mapping and quantification (standard practices actually involve adapter and _light_ quality trimming of reads). Adapter contamination could affect the mapping rate, especially if selective-alignment, which is recommended, is being used.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/398#issuecomment-511428337:41,adapter,adapter,41,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/398#issuecomment-511428337,3,"['Adapter', 'adapter']","['Adapter', 'adapter']"
Integrability,"Hi @dritoshi ,. As per your request I've added the support for Quartz-seq2 data in the alevin framework with https://github.com/COMBINE-lab/salmon/commit/f6905b1d1dc6cf6bc4597927ad3be637ba615c9a and should be available with next salmon release. Currently the develop branch has to be compile from source to use the following command line argument.; ![image](https://user-images.githubusercontent.com/8772521/63282768-8df73600-c27d-11e9-832d-f4a1232f17f6.png). Currently I just have on flag i.e. quartzseq2 which assumes 15 length CB and 8 length UMI. Unfortunately adding multiple versioned is gonna be little complicated as I might have to discuss with the alevin team and that might take some time. As you can check through the new code through the commit (linked above) adding just the Rule of new protocol is not enough and we might have to add some helper code with each new protocol which increases the redundancy in the code. Currently we are in the process of figuring out a better way to handle new protocols.; Having said that it should not stop users from using alevin with previous version of quartzseq2, you can use the following command line triplet as `--end 5 --barcodeLength 14 --umiLength 8` along with you other alevin flag and it's gonna behave just like `QuartzSeq2v31` you specified above. If possible, It'd be great if you can share some of the results you get while comparing Quartz-seq2 pipeline with alevin. Hope this helps !",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/416#issuecomment-522658541:801,protocol,protocol,801,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/416#issuecomment-522658541,3,['protocol'],"['protocol', 'protocols']"
Integrability,"Hi @dritoshi ,. Thanks for your request. I'd be happy to add the support for Quartz-seq2 into alevin but it'd be great if you can answer a few questions for us. Is it possible to share some reads/fastq file on which we can test alevin ? Also, please excuse my ignorance, what type of PCR amplification is performed in `Quartz-seq2` protocol, is it CelSeq type IVT (linear) amplification or Drop-Seq type template switching PCR amplification ?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/416#issuecomment-521747003:332,protocol,protocol,332,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/416#issuecomment-521747003,1,['protocol'],['protocol']
Integrability,"Hi @euduca,. This is a good idea. Currently, there is no easy way to do this apart from hacking the CMake file. If salmon doesnt find jellyfish in a standard location, it just ferches its own copy. Fortunately, in the newest release (scheduled to drop this coming week), we've dropped the dependency on libjellyfish. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/225#issuecomment-392336913:289,depend,dependency,289,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/225#issuecomment-392336913,1,['depend'],['dependency']
Integrability,"Hi @evofish,. Unless you have a particular reason to build from source, it is much easier to install salmon via bioconda, or to simply download our pre-compiled executable from the releases page. Nonetheless, your error stems from not having the `curl` program installed, which is used by the build system to automatically fetch all dependencies.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/331#issuecomment-447689917:333,depend,dependencies,333,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/331#issuecomment-447689917,1,['depend'],['dependencies']
Integrability,"Hi @gnaisha,. Thank you for providing the file to reproduce the issue. So, the difference here is all in the default fragment length mean and standard deviation that salmon and eXpress use. This really only matters in single-end libraries like this, since in paired-end libraries both tools will estimate the fragment length distribution from the data itself. Nonetheless, if not given specific parameters to override the default, salmon assumes μ = 250 and σ = 25, while eXpress assumes μ = 200 and σ = 80. If you run salmon like:. ```; salmon quant -lU -t transcriptome.fa -a sample_nested_transcripts_ENST00000364953-1_ENST00000375633-5.bam --fldMean 200 --fldSD 80 -o quant_directory; ```. Then you will see the following behavior for these transcripts:. ```; ENST00000364953.1 64 23.127 1000000.000000 49.000; ENST00000375633.5 586 384.567 0.000000 0.000; ```. So that the all of the reads are, indeed, allocated to the former. The effect of the transcript length on the assignment probabilities is a direct result of the probabilistic model (and due to the length effect that actually exists in the full-length RNA-seq assay). It's unfortunate that there's not a good way to estimate the fragment length distribution in single-end data, and so we are left with having to set some defaults. Depending on the actual library, different defaults will match better or worse. On the plus side, it's easy to change these values if you have better knowledge of the parameters or reason to believe that one value will work better than another.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/605#issuecomment-749739255:1296,Depend,Depending,1296,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/605#issuecomment-749739255,1,['Depend'],['Depending']
Integrability,"Hi @izaakm,. This segfault is unlikely related to the issue here, since that happened in ""mapping mode"" (salmon performing mapping itself), and yours is happening in alignment-based mode (you're feeding SAM files to salmon). Does it fail to occur when you provide _either_ of the SAM files to salmon? That is, does it run to completion with both `data/processed/bwa-mem/SRR10571655.sam` and `data/processed/bwa-mem/SRR10571656.sam` individually? Also, what if you combine them via a pipe (i.e. something like):. ```; ./src/salmon-latest_linux_x86_64/bin/salmon quant --threads $(nproc) --libType U -t GRCh38_latest_rna.fa -a <(cat data/processed/bwa-mem/SRR10571655.sam <(samtools view data/processed/bwa-mem/SRR10571656.sam)) -o _tmp/ ; ```. the double redirect is just to make sure the header isn't included in the second sam file. Also, is the reference that you are passing to the `-t` option identical to the one with which bwa-mem was run? If the problem persists, we might need the sam/bam files to track it down further, since I imagine it may be data-dependent. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/271#issuecomment-707338358:1060,depend,dependent,1060,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/271#issuecomment-707338358,1,['depend'],['dependent']
Integrability,"Hi @jeremymsimon --- I am noticing this as jumping out:. ```; ""num_frags_with_inconsistent_or_orphan_mappings"": 61866895,; ```. Is `ISR` the right protocol for this data, in the manner in which the reads are provided to `alevin`? @Gaura is doing a run with alevin-fry and we'll discuss those results here when we have them. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-985043620:147,protocol,protocol,147,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-985043620,1,['protocol'],['protocol']
Integrability,"Hi @jeremymsimon — @Gaura is going to take a look at unfiltered permit listing and will share those results here later. Regarding frameshift errors, I think that's certainly out of scope for the alevin -> fry phase, but that type of thing *could* be in scope for `splitp`. Basically, my logic / reasoning is this: I'd like to avoid further complicating the already immense salmon/alevin codebase with special implementations handling problems outside of their core function (e.g. mapping reads to the reference efficiently and quantifying UMIs/barcode). Since most protocols (and the most common) have quite simple barcode geometry, it makes sense for this code to live there. I'm fully supportive of enabling support for more complex barcode geometries and preprocessing requirements if there are folks whom it would help, but it feels like that essential complexity belongs upstream of alevin / fry, so that by the time the reads get to alevin, it can assume a straightforward geometry. So TLDR : I think we'd be willing to investigate what is required to address potential frameshift errors, and how much of a difference that makes, but I think that analysis and eventual implementation (if we decide it's worth it), belongs in `splitp`.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-988030837:565,protocol,protocols,565,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-988030837,1,['protocol'],['protocols']
Integrability,"Hi @jeremymsimon! In order to test and validate the implementation I would need a count matrix generated on samples. Do you have a sample and count matrix from that? The Rosenberg submission of the data has an unclear way of specifying barcodes and I have emailed him about it. If you have count matrix and matching fastqs that we can use to validate, we can wrap it up soon.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-982878463:359,wrap,wrap,359,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-982878463,1,['wrap'],['wrap']
Integrability,"Hi @jeremymsimon, . Somehow, the notification for this in my e-mail got classified as SPAM. Anyway, thank you for the detailed description! I'm going to ping @Gaura here. @Gaura — this is the alternative protocol I was discussing with you yesterday. As you can see, the main issue here is the ""noisy"" barcodes. Let me know what you think would be necessary to add support for this, and I'm happy to schedule a technical discussion if you want to discuss some options.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-921879305:204,protocol,protocol,204,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-921879305,1,['protocol'],['protocol']
Integrability,"Hi @jeremymsimon, to answer your last question:. > As for the barcode detection - my usual approach with alevin at least is to let it try to estimate a ""real"" cell number, but if it's way off from our experimental expectations, to inject --expectCells ncells and let that serve as a starting point (with subsequent filtering). That has worked reasonably well in the past for me , and seems to be an option for alevin-fry as well. I don't know whether that is poor practice in the long run...it came from a place of seeing far too many weak knee plots early in the droplet scRNA-seq days. Are you generally more trusting of these estimates these days?. So one of the nice aspects of the alevin to alevin-fry pipeline is that it's relatively easy to try different filtering approaches since the initial mapping process only has to happen once. In general, the knee detection method is pretty good, and often gives a reasonable cell count. However, this isn't always the case. What we find in the alevin-fry pre-print is that it tends to be slightly more conservative than if you did e.g. unfiltered quantification followed by filtering with something like `DropletUtils` (but usually only slightly). The knee method is basically the iterative knee finding procedure from UMI-tools, with some slight tweaks to the parameters. However, unlike alevin, alevin-fry also supports unfiltered quantification. In this case, you provide an `unfiltered-permitlist`, which is a set of acceptable barcodes (not necessarily all expected to be present), and alevin-fry will correct against this. This will tend to produce a _lot_ of quantified cells, since we quantify any barcode matching 10 or more reads (by default, this value is modifiable on the command line). So, such unfiltered matrices definitely need to be filtered after quantification. However, for protocols with an external permit list, or those where you can reasonably derive a list of potential expected barcodes, it's less stringent and therefore po",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-988967759:231,inject,inject,231,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-988967759,1,['inject'],['inject']
Integrability,"Hi @jeremymsimon,. Both `--splitseqV1` and `--splitseqV2` assume that cDNA is on R1 and UMI + barcodes are on R2. The geometries used are:; - For `--splitseqV1`:; `NNNNNNNNNNIIIIIIIIGTGGCCGATGTTTCGCATCGGCGTACGACTIIIIIIIIATCCACGTGCTTGAGAGGCCAGAGCATTCGIIIIIIII`, or; UMI-BC1-FixedSeq-BC2-FixedSeq-BC3; Barcode positions (0-based index): 10, 48, 86; - For `--splitseqV2`: ; `NNNNNNNNNNIIIIIIIIGTGGCCGATGTTTCGCATCGGCGTACGACTIIIIIIIIATCCACGTGCTTGAGACTGTGGIIIIIIII` or ; UMI-BC1-FixedSeq-BC2-FixedSeq-BC3; Barcode positions (0-based index): 10, 48, 78. where the `IIIIIIII` sequence corresponds to barcode and `NNNNNNNNNN` to UMI. This is from the [pipeline code](https://github.com/yjzhang/split-seq-pipeline/blob/master/split_seq/tools.py) used in [this paper](https://www.nature.com/articles/s41593-021-00872-y) co-authored by the lab that developed the protocol. I previously mentioned this in our initial discussions [here](https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-951080577). I think adding this to the documentation is a good idea. I will discuss with Rob and add the information. Thank you. :). Now it seems like it's not behaving as expected for `splitseqV1`? Can you share the command you used and the salmon version?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/774#issuecomment-1184412691:851,protocol,protocol,851,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/774#issuecomment-1184412691,1,['protocol'],['protocol']
Integrability,"Hi @jeremymsimon,. I think this is something that we do want to support. Are you familiar with the protocol and what types of changes / additions might need to be made in order to support processing this type of data?. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/861#issuecomment-1642782444:99,protocol,protocol,99,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/861#issuecomment-1642782444,1,['protocol'],['protocol']
Integrability,"Hi @jirazoqui and @pdellorusso,; beware that if you install via a `.tar.gz` file, you make `conda` ignore *all* dependencies. It's somewhat equivalent to `conda install --no-deps ...` and thus I wouldn't recommend doing something like that.; Until we fix the dependencies in Bioconda, can you, if possible, use a separate Conda environment for `salmon` with `conda create -c bioconda -c conda-forge --name salmon salmon`. In this new environment you wouldn't have any dependency version conflict.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/194#issuecomment-364996006:112,depend,dependencies,112,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/194#issuecomment-364996006,3,['depend'],"['dependencies', 'dependency']"
Integrability,"Hi @joshstolz,. Is there a reason you want to restrict the possible mapping to this set of 1800 transcripts? In general, mapping to a small subset of the reference is not ideal, because alignment works based on asking if the ""best hit"" for a read is good enough, so its easy to come up with scenarios where the is a read that matches some transcript very well, and another transcript ""alright"" --- if the transcript it matches very well is in the reference, then it will map there, otherwise it will likely map to the transcript where the match is just ""alright"". TLDR; the set of references included can affect the mappings. That being said, if there is a good technical reason you have for only including a subset of transcripts, that's easy to do. You just build your index on only those transcripts. Salmon treats the reference sequences you feed to it as the ""transcriptome"" and will map to that. Also, you could map to the full transcriptome and just extract the rows for these targets from the `quant.sf` files at the end. Of course, depending on what you want to do downstream, you'll have to be aware of how these 1800 transcripts fit into the bigger picture and how the reads that mapped to the other transcripts affect your belief about things like the effective library size etc.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/681#issuecomment-873025258:1041,depend,depending,1041,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/681#issuecomment-873025258,1,['depend'],['depending']
Integrability,"Hi @juugii , it looks like you are using 10x data and you might need `--chromium` flag to tell alevin the type of datasets. Although it should have given error message much before starting reading the CB. I'll look into this but can you please confirm if you have given the flag to alevin or not?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/264#issuecomment-410321746:160,message,message,160,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/264#issuecomment-410321746,1,['message'],['message']
Integrability,"Hi @k3yavi , thank you for the reply. Yes, you are right, it seems the problem is indeed in the whitelist `known_cb.txt`. However, I cannot seem to find out what exactly is going on with the file. When I wrote a python script to check the length of each cell barcode in `known_cb.txt`, _all_ of them are 16 bp long. This is the python script:. ```; $ cat print_length.py; with open('known_cb.txt') as fh:; for i in fh:; print(len(i)); ```. since each line has 16 bp barcode and a `\n` character, it outputs 17, which is expected. However, when I used `awk` to check the length, I expected `awk` to output 16, but it actually output 17:. ```; $ awk '{print length($0);}' known_cb.txt | head -2; 17; 17; ```. There might be some hidden characters that I missed. Any idea what's going?. Now, I have cleaned the `known_cb.txt`, and `alevin` runs without problem. For combinatorial indexing, good to known that it will be supported in future. I guess depending on assays, it needs to be a bit more flexible than the current options. The current options have only `--chromium` and `--dropseq` available. However, there are a few different combinatorial indexing assays. For `sci-RNA-seq`, the cell barcodes are within `I1.fastq`, `I2.fastq` and `R1.fastq`. Only `R2.fastq` is useful for gene quantification. For `sci-ATAC-seq`, the cell barcodes (this is just my educational guess) are within `I1.fastq` and `I2.fastq`, and both `R1.fastq` and `R2.fastq` contain useful information from the genome. For other plate-based method, there will be well barcodes and plate barcodes, which could be located in any of those 4 fastq files depends on the design. The cell barcodes will be a combination of well barcodes and plate barcodes. Thank you very much for the help. Regards,; Xi",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/291#issuecomment-420807198:946,depend,depending,946,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/291#issuecomment-420807198,2,['depend'],"['depending', 'depends']"
Integrability,"Hi @k3yavi ,; Thanks for the info!. We are working on an optimized version of SCRBseq and one of the problems we had with the original protocol is the minimum distance between the cell barcodes being too low. So we increased the number of bases. The original protocol was 6 bc and 10 umi. We just switched the 7 position from umi to barcode. We use a known whitelist of barcodes since it's a well plate based protocol. We know that any other barcode are not cells. Is there an option for max distance allowed between BC or UMI?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/247#issuecomment-402440401:135,protocol,protocol,135,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/247#issuecomment-402440401,3,['protocol'],['protocol']
Integrability,"Hi @k3yavi . Thanks for pointing me to the paper. . Some findings/questions from that paper:. 1. The authors do not mention which version of salmon they are using and whether they are using the TXOME or SA or SAF method. I am assuming they are using salmon v.0.12 or a prior version since they submitted their paper in May 2019 and hence, they are probably using the TXOME method; ; 2. The authors do not mention whether they use QuantSeq FWD or QuantSeq REV protocol. I am assuming they are using QuantSeq REV as they have the` salmon quant libtype to be SR`. 3. I think the authors should have used `-noLengthCorrection` with QuantSeq Data. @rob-p and @k3yavi Isn't this flag/option a salmon unique feature that [Rob introduced exclusively for QuantSeq](https://groups.google.com/forum/#!msg/sailfish-users/VIfqBwgF6xQ/fw-rgC_kAwAJ). . Also @rob-p , weren't you referring to the RSEM caveat with QuantSeq data analysis wherein one cannot ask RSEM to disable lengthCorrection and hence the count statistics might be misleading?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-564848220:459,protocol,protocol,459,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-564848220,1,['protocol'],['protocol']
Integrability,"Hi @k3yavi, ; I just re-read this post and I believe that in the CEL-Seq2 protocol, read_1 has first the UMI and then the CB and then polyT... because the sequencing starts with the Illumina adapter (see image below from paper). . Thanks!; ![13059_2016_938_fig1_html](https://user-images.githubusercontent.com/39304679/49376447-edbda900-f70f-11e8-85d7-b86b15c477d5.gif)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/311#issuecomment-443709804:74,protocol,protocol,74,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/311#issuecomment-443709804,2,"['adapter', 'protocol']","['adapter', 'protocol']"
Integrability,"Hi @k3yavi,. Thanks for the reply!. Let's take the PBMC 4K as example. Looking at the summary sheet from 10x: ; http://cf.10xgenomics.com/samples/cell-exp/2.1.0/pbmc4k/pbmc4k_web_summary.html. They detected 4,340 cells with a median UMI count of 3,866 per cell. That means ~17M UMIs in the count matrix, which is in the same order what I find with Alevin. I am not sure if/where Alevin reports the number of mapped reads (maybe it is the number of hits?), but this is not of much importance. Indeed, the total UMI count is **much** lower than the number of sequenced/mapped/barcoded reads (~190M), which is expected. However, using the `--dumpUmiGraph` option provides a file ""MappedUMI.txt"" which I assume are the number of deduplicated UMIs mapped per cell/barcode (summed over all genes). The sum of over all the barcodes = 17M in this case and the sum per barcode = the sum in the quant_mat. This does not hold for the adapted cel-seq2 protocol. sum mapped UMI != summed quant_mat.gz. I am making a mistake, or is there something wrong?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/361#issuecomment-490098177:940,protocol,protocol,940,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/361#issuecomment-490098177,1,['protocol'],['protocol']
Integrability,"Hi @k3yavi,; Many thanks for you prompt answer, once again. >When you say you try subsampling the Fastq, did you sample randomly across the full Fastq or chose the top X reads. Yes, I did perform a random subsampling, ie. taking a read with a p probability while reading the fastq files, p being the subsampling coefficient I did mention (pE[0;1]). An implementation of this approach as an option during the transcript quantification would be great. I can provide you with the simple python script I use for the subsampling, but I am not sure if it is the proper way to subsample during alevin quantification. >when you say cellranger subsampling, do you mean the cellranger aggregate pipeline?. Yes, sorry for not clearly stating it. I did use the cellranger aggregate function indeed, which by default subsample the expression matrices with high sequencing depth depending on amount of mapped reads, if I understand well. >Use Alevin w/o any modification to the fastq on both of your sample to generate the gene count matrices. I already did that, in downstream analyses I have a batch effect issue related to the sequencing depth. >that's why we recommend using the Seurat package downstream of the Alevin quantified matrices. I have some experience with downstream analyses with Seurat, Pagoda, Scater, scanpy and a few other tools, and I am aware of batch correction methods like CCA or MNN. But that is not what I am looking for here. I did both CCA and MNN but I loose some important information in the resulting eigenspaces or corrected matrix. I believe the proper way to correct my batch effect is to simply fix the difference between my two libraries, ie. the sequencing depth in this case. As I explained in my first message, cellranger aggregate (subsampling based on the amount of mapped reads) works very well in my case, correct the effect without any loss or modification of important genes in our scientific question. Not CCA or MNN. I would like to be able to do the same from the a",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/305#issuecomment-433319913:865,depend,depending,865,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/305#issuecomment-433319913,1,['depend'],['depending']
Integrability,"Hi @k3yavi,; There is no more message error. Once the message occurs, it abruptly ends and that's it. > weren't you using the whitelisted CB instead of ""knee"" thresholding?. Yeap, but in the previous dataset. In this one the CB is provided in the dataset, and I don't have to create a whitelist. . The error does not always happen. I have created other random datasets, and they do not always fail. I will try to create a small dataset which fails, for you to replicate. Is there anyway I can privately send it to you?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/386#issuecomment-505504105:30,message,message,30,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/386#issuecomment-505504105,2,['message'],['message']
Integrability,"Hi @kai2june,. Thank you for the _detailed_ report! It's interesting because (a) those functions aren't doing anything too exotic and (b) CentOS is the OS we use on our continuous integration. We'll try and get a better handle of what is going on here. In the mean time, could you tell us if you see the same behavior with the [pre-compiled binary](https://github.com/COMBINE-lab/salmon/releases/download/v1.4.0/salmon-1.4.0_linux_x86_64.tar.gz) available from the downloads page?. P.S. One other thing worth trying. We've noticed that compiler support for interprocedural optimization isn't terrific. You can try building salmon without this option by passing `-DNO_IPO=TRUE` as an additional cmake flag.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/609#issuecomment-751366046:180,integrat,integration,180,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/609#issuecomment-751366046,1,['integrat'],['integration']
Integrability,"Hi @kbchoi-jax — the index size (i.e. 32 or 64-bit) is dependent only on how long the reference is, not the width of the machine on which you're running Salmon. That is, if the reference is < 2.1G, then a 32-bit index will always be used (even on a 64-bit machine). The purpose of the ""64-bit"" index is that it uses 64-bit indices when building the suffix array, so that it can distinguish positions on much larger reference sequences (up to 9223372036854775808 characters . . . but you'd run out of memory long before that ;P).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/54#issuecomment-220451342:55,depend,dependent,55,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/54#issuecomment-220451342,1,['depend'],['dependent']
Integrability,"Hi @kdorman,. Ok, let me refine my response a little bit. When you said that the files were ""unpaired"" I was under the assumption that the synchronization between the left and right files was broken; that is that the read names in the left file are in a different order than the right file. In this case, `salmon` doesn't check explicitly, and it doesn't store reads internally and wait for the mate in the other file. Every time it reads a record from the left and right file together, it assumes they constitute a pair during sequencing. If the files become desynchronized, you will likely observe the behavior I mentioned in my initial response.; ; However, if the reads remain properly paired, then they will be mapped as such. Judging from the total number of reported fragments in the output above, it looks as though it's attempted to map the first `17361911` reads from both files, treating them as paired-end reads (ignoring the extra records in file 1 that have no mate in file 2). You could check if it's the case that these reads are properly paired, and that file 1 just contains some extra reads that were unpaired after filtering.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/793#issuecomment-1220773109:139,synchroniz,synchronization,139,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/793#issuecomment-1220773109,1,['synchroniz'],['synchronization']
Integrability,"Hi @keithgmitchell,. Alevin is designed for droplet-based, tagged-end protocols, and in the vast majority of these protocols, transcript-level quantification isn't really reliable enough to be useful. Since most tagged-end protocols sequence information from only the 3' end of the transcripts, there is a highly-biased coverage signal, and discerning UMI assignment at the transcript level is usually not possible. Therefore, I wouldn't generally recommend trying to obtain transcript-level counts from alevin and we haven't tested it in this context. If you have a particular reason you want to look at transcript counts and believe it may be reasonable in your specific use-case, you can alway pass in a gene-to-transcript map that just maps each transcript to itself, which will result in a transcript-level output matrix. However, I anticipate that the resolution problem will become more difficult in this case, and there will be much more uncertainty in the assignments. @k3yavi, please feel free to add anything you think I may have missed. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/588#issuecomment-729974232:70,protocol,protocols,70,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/588#issuecomment-729974232,3,['protocol'],['protocols']
Integrability,"Hi @kieranrcampbell,. Indeed, such reads will be un-mappable. The only tricky question here is at which point we should (1) do nothing (2) issue a warning (3) issue an error. Since the reads may not all be of the same size (perhaps the user has quality-trimmed the reads first and not opted to discard the short ones), it's possible we may see some reads too short to consider, but others would not be. We could choose arbitrary cutoffs (warning if greater than 1,000 such reads and an error if greater than 1,000,000), but this will, of course, depend on how large the input data set is. Anyway, I agree that we should notify the user of this and will be happy to add it; do you have any suggestions on the default behavior?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/41#issuecomment-181394180:546,depend,depend,546,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/41#issuecomment-181394180,1,['depend'],['depend']
Integrability,"Hi @knokknok,. Would it be possible to share a small subset of these reads that reproduce the issue? Basic thoughts : does it work without `--validateMappings`? Are the read files synchronized (i.e. are there the same number of left and right reads)?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/228#issuecomment-393240942:180,synchroniz,synchronized,180,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/228#issuecomment-393240942,1,['synchroniz'],['synchronized']
Integrability,"Hi @kvittingseerup,. Basic adapter and quality trimming should be done. There's some [nice work by Matt MacManes](https://www.frontiersin.org/articles/10.3389/fgene.2014.00013/full) showing that you should be careful about aggressive quality trimming, but light quality trimming is usually beneficial. This is particularly important if the underlying aligner isn't doing local alignment (e.g. STAR will likely just softclip bad bases).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/390#issuecomment-506744431:27,adapter,adapter,27,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/390#issuecomment-506744431,1,['adapter'],['adapter']
Integrability,"Hi @kvittingseerup,. No need to apologize, I think it was I who was not clear. What I am saying is that this is *already* the way that Salmon handles such a case. That is, if you have a paired-end read, and one of the reads maps but the other doesn't (due to e.g., adapter contamination or just very low quality), then Salmon will consider the remaining (mapping) end of the read as representative of an entire fragment, and will resolve the fragment origin accordingly during optimization. Generally, not having both ends of a paired-end read leads to increased ambiguity, but this isn't a particularly big problem if it only happens to a generally small fraction of the reads. Further, since you cannot reliably infer the implied fragment length on a transcript from only a single-end read, such mappings will not contribute to the bias model. Again, however, as long as this doesn't happen to the vast majority of fragments, it should have only a negligible effect on quantification and bias correction. Please let me know if this description makes sense. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/150#issuecomment-355881997:265,adapter,adapter,265,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/150#issuecomment-355881997,1,['adapter'],['adapter']
Integrability,"Hi @kvittingseerup,. Sorry for letting this sit for so long without responding. Currently, Salmon does not support mixed paired-end and single-end library types, so this is presumably what is causing the error (granted, the error message here could be considerably better). Practically, I'd be curious what the difference is between allowing this and simply running Salmon with the _non-quality-trimmed_ paired-end reads. Specifically, if Salmon is not able to map a pair concordantly, but it can map one of the ends of the read, then it will already do so. . However, in the case that there's a really compelling reason to want to quality trim the reads prior to quantification (and to include the reads such that the mate has been completely quality-trimmed away), we would be able to support this. It will require a bit of modification to allow different library types to be processed back to back and to contribute to the same quantification estimates. In this case, I imagine what we would want to do for the orphans is essentially what Salmon would do internally if it can't map the mate. That is, we would learn essentially all of the parameters and biases from the pairs that do map concordantly, and then just include the orphaned reads as indicating an entire fragment but of unknown length. Let me know if you have any thoughts about the above, and sorry again for the delay!. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/150#issuecomment-353196630:230,message,message,230,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/150#issuecomment-353196630,1,['message'],['message']
Integrability,"Hi @lauraht,. So I decided to explore just one of these to see if I could figure out what might be going on. The below is with respect to `SRR9007475`. So first, even though I processed the data with the latest version of the develop branch (which will become 1.2.0), I got basically identical results to what you reported. Simply aligning the data against an index built on a human Gencode v26 transcriptome (with no decoys) gives me a mapping rate of `0.00378202832148367%`. The first thing I did was to quality and adapter trim the data (using `fastp -i SRR9007475.fastq.gz -o SRR9007475_trimmed.fastq.gz -q 10 -w 8`) and ... whoa. This is the fastp html report [fastp.html.zip](https://github.com/COMBINE-lab/salmon/files/4176345/fastp.html.zip). So the first astounding statistic, the mean read length before trimming is 51bp (these are relatively short single-end reads). The mean read length after trimming is 21bp! So, the average read length is, in fact, less than the k-mer length used for indexing (default is k=31). On the trimmed data, the mapping rate goes up to `2.3545475882931305%`, still very low, but now there's somewhat of an explanation, the average read is shorter than a single k-mer. So, the next thing I tried was indexing with a smaller k; a _really_ small one in this case,`k=15`. Then, I re-ran on the _trimmed_ reads (the fact that the trimming took us from 51-21bp suggests that the reads had a lot of low quality bases, adapter contamination, or both). Under this setting, I still get a very low mapping rate, but it was _much_ higher — `16.766993524863488%`. The final thing I tried was seeing how the mapping rate changed as I altered `--minScoreFraction`, which is the salmon parameter that determines the alignment score that a read must achieve in order to be mapped validly. The default is 0.65. This means that the read cannot have a score < 0.65 * the maximum achievable score for the read given it's length. In the case of a 21bp read, the best score would be ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/482#issuecomment-583799668:518,adapter,adapter,518,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/482#issuecomment-583799668,1,['adapter'],['adapter']
Integrability,"Hi @lauraht,. Sure; let me answer these in order. (1) Salmon does not really make use of the read id (we assume the fasta files are synchronized in the input). The one place that not using the `-l` option might raise a complication is if you wish to dump the mappings and examine them (using `--writeMappings`), in which case it will be difficult in the SAM file to discern which read is which just from the names (though the flags should still be valid). (2) Yes, this is normal and expected behavior. Since the online phase of salmon is asynchronous, the online updates may arrive in a slightly different order. This can lead to a slightly different starting condition for the offline phase and, subsequently, small differences in the abundances. However, these differences are generally small and are _inherent_ to the uncertainty in the inference itself. That is, the estimates have inherent uncertainty that is greater than the variation you might see between runs. To assess this you can (and, perhaps should) estimate this uncertainty by asking salmon to draw inferential samples (e.g. Gibbs samples with `--numGibbsSamples`). Best,; Rob. P.S. As a general note, I'd recommending upgrading to the latest version of salmon. We update salmon quite regularly with both small and large improvements (and bug fixes where relevant). There has been quite a lot of progress since version 0.9.1.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/478#issuecomment-578326494:132,synchroniz,synchronized,132,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/478#issuecomment-578326494,1,['synchroniz'],['synchronized']
Integrability,"Hi @lubios,. I'm glad that you were able to address the first issue. The thing that's strange about the second is that somehow the output path you are providing in the command doesn't match the directory name in the error message. Specifically, your command has the output directory as `transcripts_DecoyQuant`, but the error reports not being able to create the directory `transcripts_quant`. Are the command and error here properly paired?. The only situations under which one might expect this issue to occur is if either (1) your user doesn't have sufficient permission to create the location where the output is to be written or (2) the disk on which the output is to be written has insufficient space. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/717#issuecomment-964546340:222,message,message,222,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/717#issuecomment-964546340,1,['message'],['message']
Integrability,"Hi @mathog, . You can give ; [this liunux binary](https://github.com/COMBINE-lab/salmon/files/2099291/salmon-latest_linux_x86_64.tar.gz) a try. It's built on our Drone CI box, which uses CentOS 6. You are absolutely right that Boost is a giant PITA. The recommended way to grab the binary is via [bioconda](https://anaconda.org/bioconda/salmon), since that takes care of libraries, dependencies etc. Please let me know if either of these work for you.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/236#issuecomment-397029798:382,depend,dependencies,382,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/236#issuecomment-397029798,1,['depend'],['dependencies']
Integrability,"Hi @mojakab ,; Thanks for your interest in Alevin. Currently most of our research efforts have gone into developing Alevin for droplet based 3' tag sequencing like 10x chromium and DropSeq. Although similar but Cel-Seq2 relies on a different cell isolation step which can potentially create assay specific bias between the experiments. Basically Alevin is designed to work with single-cell protocols which follows the following criteria:; * Droplet based cell isolation.; * 3' tag sequencing.; * Fragmentation post Amplification. We have similar such request in https://github.com/COMBINE-lab/salmon/issues/269, where the user was able to use Alevin with Cel-Seq2 but currently we have not explored the full potential of Alevin with Cel-Seq2 and might require more careful consideration. If you happen to use Alevin on Cel-Seq2 data we'd appreciate your feedback based on your experience.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/311#issuecomment-439527284:390,protocol,protocols,390,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/311#issuecomment-439527284,1,['protocol'],['protocols']
Integrability,"Hi @moschmi ,. Thanks for sharing the file.; You are right the transcript id `PB.40054.21` is indeed present & has the gene mapping in the file you forwarded. Unfortunately, the specific error message was not useful here but the issue is the following: ; ![image](https://user-images.githubusercontent.com/8772521/85436584-45706f00-b557-11ea-9ba2-95ebf4e43bc4.png). If you check the file you forwarded from line number 12,133 - 12,137, it seems a bunch of transcript ids are blank and has no assigned gene-ids. In this case the file parser was not intelligent enough to ignore such empty mappings and end up using the next line (before) tab as the wrong mapped gene-mappings. Later, when alevin sanity checks for the mappings of all transcripts, alevin complaints about not being able to find it for a random transcript much lower in the order. In short, I know you used the bioawk script for making the transcript to gene mapping file, but the script was written with the gencode generated GTF in mind, it seems the one you have has some small difference which is creating the issue. Currently, the easiest fix is to parse the GFF file again and generate the mappings for all the transcript in the proper format. In the future, we will add a sanity check for these type of corner cases, thanks for reporting this.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/540#issuecomment-648319730:193,message,message,193,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/540#issuecomment-648319730,1,['message'],['message']
Integrability,"Hi @mugpeng,. This is because it is covered by the custom geometry specification (as laid out in the docs). I agree it's nice to have a specific flag for each geometry, rather than to have to e.g. specify the custom geometry each time. We are working on good solutions to that at a higher level (e.g. in our `simpleaf` tool where users can register their own custom geometry specifications and refer to them by name). However, in `salmon`/`alevin` right now, the named geometries are hard-coded, and so to have a specific `--indropV2` flag, that would have to be added to the argument parser and then mapped to the specific underlying geometry in the code. This isn't hard, but as the number of different chemistries proliferates, it's not ultimately a scalable solution. So, the current recommendation would be to use the custom geometry flags as specified in the documentation, or adopt a wrapper like `simpleaf` and add `indropV2` to your custom geometry specification library. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/878#issuecomment-1758171139:891,wrap,wrapper,891,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/878#issuecomment-1758171139,1,['wrap'],['wrapper']
Integrability,"Hi @nh13,. This is not something for which we currently have support or something that we currently plan. I'd be open to it, but I'm honestly not sure how to cleanly do it in the current architecture, and doing so would certainly incur a performance hit. Salmon runs 2 phases of inference; and online phase and an offline phase. The online phase has access to _fragment-level_ information that is then summarized away during the offline phase (like the specific locations of each read, the length of each observed fragment, etc.). That information goes away when the reads are summarized into range-factorized equivalence classes. Moreover, some of the model parameters learned during the online phase will depend (in their details) on the order in which observations are made. Ostensibly, observing the same data in the same order **and issuing updates to shared model parameters from worker threads in the same order** should result in identical values, however this has never been tested and was never a design goal. The reason for this is that differences between runs are within the bounds of the inherent inferential uncertainty of the estimated parameters anyway. That is, if one is relying on a specific value at a level of precision such that a different run of salmon would produce a value different enough to change a downstream analysis, then one is imparting more precision on the estimates than they can provide. Other methods that produce identical results between runs for these values may produce the same output, but the accuracy of the output at that level shouldn't be trusted in this case. The uncertainty of the parameter estimates can be evaluated based on the Gibb samples (or bootstrap replicates) that salmon computes. Of course, the small differences between runs rarely lead to differences in downstream analysis (almost certainly at the gene level and also at the transcript level if you use a differential testing method that is aware of inferential uncertainty). On the ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/102#issuecomment-2159300538:707,depend,depend,707,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/102#issuecomment-2159300538,1,['depend'],['depend']
Integrability,"Hi @nskbe,. The issue you're seeing with the mapping file name is related to this note in the release notes:. > Note: In the 0.7.2 release, the file provided to --writeMappings must use a qualified path (e.g. --writeMappings=./out.sam rather than --writeMappings=out.sam), this constraint is already addressed on develop and will be fixed in the next release. . Essentially, the code should internally qualify the filepath before checking if a directory exists, but it doesn't. The fix for this is to pass the file name as a qualified path (i.e. adding `./` before the file name when you want it in the current directory). This is already resolved in develop and the fix for this annoyance will make it into the next release. Regarding the issue with writing the information to `stdout`; actually, all of the logging messages are written to `stderr`. If you don't redirect `stdout`, then you'll see everything, but the intended usage for that mode is something like:. ```; salmon quant -i idx [other options] --writeMappings > out.sam; ```. This will redirect standard out to out.sam. You'll still see the logging messages on the console, since they are written to `stderr`, but all of the mapping contents are redirected to the file. Let me know if this resolves your issue. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/90#issuecomment-247072758:817,message,messages,817,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/90#issuecomment-247072758,2,['message'],['messages']
Integrability,"Hi @pabloaledo,. Thanks for the report! I am not familiar with spack. However, the bigget issue here is that I don't believe that salmon, by itself, should require/depend upon libhts. It uses libstaden for its sam/bam parsing, but that should be a self-contained dependency. We should figure out why libhts is being pulled in here. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/866#issuecomment-1664067688:164,depend,depend,164,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/866#issuecomment-1664067688,2,['depend'],"['depend', 'dependency']"
Integrability,"Hi @phickner,. The error message seems to be coming from the library we use to parse the BAM file (https://github.com/jkbonfield/io_lib/blob/master/io_lib/bam.c#L329). Is it possible that somehow the BAM itself is ill-formed? Maybe as determined by [picard ValidateSamFile](https://broadinstitute.github.io/picard/command-line-overview.html#ValidateSamFile) or some such?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/323#issuecomment-442697747:25,message,message,25,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/323#issuecomment-442697747,1,['message'],['message']
Integrability,"Hi @pinin4fjords ,. Apologies for the delayed response and thanks for your interest in Alevin.; Unfortunately, there is no one straight answer for your question. ; Other people have been using Alevin for various microwell based protocols like (CEL-seq https://github.com/COMBINE-lab/salmon/issues/269 ) but from our side we have not extensively tested alevin on non-droplet based protocols. However, we are open to provide any kind of help you may need to test the microwell-seq protocol and extend the support for alevin. If you happen to have been already testing alevin please let us know of your experience and how we can improve aleivn.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/358#issuecomment-490089165:228,protocol,protocols,228,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/358#issuecomment-490089165,3,['protocol'],"['protocol', 'protocols']"
Integrability,"Hi @pinin4fjords ,; Thanks for raising an important question and running alevin for the training.; I think there is a confusion regarding the `quantmerge` command. That command works only with bulk RNA-seq quants not with alevin output. To answer your question of running multiple alevin instance for multiple file pair, might depend on what are the separate files from, are they from separate lanes or are they separated based on cellular barcode ? The basic intuition is after initial barcode assignment, alevin works on each cell disjointly meaning as long as you are confident that each file pair is cell disjoint then at the end you can just cat the output of the alevin quants. Also, depending on what's the training about you can think of multiple workarounds like you can use very small 100 cell (7 million reads) datasets from 10x and combine it all together in one file if size and multiple files is a problem.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/434#issuecomment-540033932:327,depend,depend,327,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/434#issuecomment-540033932,2,['depend'],"['depend', 'depending']"
Integrability,"Hi @pophipi ,; Sorry for the late response.; We have updated some of the steps for the `v1` pipeline and the relevant How to [document](https://combine-lab.github.io/alevin-tutorial/2018/running-alevin/) has been updated too. Please refer to the tutorial and let us know if you still face the problem. Specifically in your case you might have to do the following things: ; * compile the `wrapper.cpp` file in `salmon/scripts/v1_10x` folder with the command:; ```; g++ -std=c++11 -O3 -I \<PATH TO SALMON INCLUDE DIRECTORY\>-o wrapper wrapper.cpp -lz; ```; * Update the `run.sh` file [here](https://github.com/COMBINE-lab/salmon/blob/master/scripts/v1_10x/run.sh#L17) with the path to the `wrapper` binary created in the above step.; * Use following command to run alevin in v1 mode:; ```; ./run.sh salmon alevin -l ISR -b ./reads/ --gemcode -i ./index_15_pc -p 10 -o ./alevin_15_pc --tgMap ./txp2gene.tsv --dumpCsvCounts --dumpFeatures --end 5 --umiLength 5 --barcodeLength 14; ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/294#issuecomment-422198746:388,wrap,wrapper,388,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/294#issuecomment-422198746,4,['wrap'],['wrapper']
Integrability,"Hi @pophipi ,; Thanks for the interesting question, but unfortunately in the current version of Alevin you can't tweak the mismatch rate option although based on the type of error/noise in the reads you can try reducing the size of the k from default 31 to something smaller and see if it helps. We are working on tweaking the mapping algorithm for Alevin allowing mismatches but it's still in testing phase and has not been integrated yet. We'll let you know as soon as we have version supporting that.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/280#issuecomment-416969420:425,integrat,integrated,425,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/280#issuecomment-416969420,1,['integrat'],['integrated']
Integrability,"Hi @ramezrawas,. Can you say precisely what you mean by reproducible? Do you mean that the values in the .sf file are not identical? If so, this is expected behavior. It exists for a number of reasons. The big one is that the initial phase of salmon uses an online inference algorithm so that specific details of the solution are dependent on the order in which the reads are processed (which is random given that multiple threads parse reads and update estimates asynchronously). However, the more important point here is that the inference estimates returned by Salmon (and, for that matter, every other transcript-level expression tool) are the result of a statistical optimization procedure that cannot guarantee a unique global optimal solution (and, in fact, even if a global optimum could be guaranteed, there may be multiple different optima). Thus, there is uncertainty inherent in the statistical problem being solved. Of course, if one ordered updates in the same way and set up the initial conditions precisely the same, there would be convergence to the same result, but any sense of confidence there is illusory. However, Salmon does provide a way to quantify, statistically, confidence in the result. The `--numBootstraps` option will do bootstrap sampling, or the `--numGibbsSamples` option will perform posterior Gibbs sampling. Both of these techniques will provide samples from the posterior distribution, and the variance of these samples will give you some information about the variance in the results that are due purely to the inherent statistical uncertainty in the problem. In the `scripts` folder there is a python script `ConvertBootstrapsToTSV.py` that will convert either the bootstrap or gibbs samples to a easily readable tsv format. These samples represent the estimated number of reads coming from each transcript when sampling from the posterior. These can be used to empirically estimate that statistical uncertainty in the abundance estimates of the different tran",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/102#issuecomment-259464248:330,depend,dependent,330,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/102#issuecomment-259464248,1,['depend'],['dependent']
Integrability,"Hi @rbenel,. This message is just salmon letting you know a newer version is available. The installed version should function perfectly fine. If you really want to avoid the message, you can pass `--no-version-check` *before* the salmon command; e.g.:. ` salmon --no-version-check index ...`. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/262#issuecomment-409903345:18,message,message,18,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/262#issuecomment-409903345,2,['message'],['message']
Integrability,"Hi @rfarouni ,. Is it possible to visualize the above two plots on the same scale ? ; Regarding the few cells not from 10x whitelist, I should have been more clear last time. ; Basically, what I meant earlier when I said that 10x data is clean is that we do observe some cells from the non whitelist file _but_ they have very few UMI and we discard them anyway. I am guessing here your motivation is a bit different i.e. considering very low confidence (even with 1 UMI) barcodes, while generally we discard anything below 10 as noise. Thanks a lot for offering to help with index-hopping idea. I agree, it'd be great to include the model in the alevin framework. Currently I just got the gist of your paper, let us go through the paper in a bit more detail and we'll get back to you as soon as we have some free cycles for the integration.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-639137897:828,integrat,integration,828,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-639137897,1,['integrat'],['integration']
Integrability,"Hi @rfarouni ,. Thanks a lot for raising the issue.; It looks like a corner case with the custom barcode length and I'd have to push a hot-fix for it. Basically, it's failing in the initial sanity check stage where it assumes we can provide only one single-cell protocol type. Give me like half an hour to make the changes and I'll push the fix to the develop. If you can compile salmon from source that's great, otherwise I can also forward a linux portable binary.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-638385340:262,protocol,protocol,262,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-638385340,1,['protocol'],['protocol']
Integrability,"Hi @rmurray2,. Thanks again for the detailed question (I answered them in reverse order, so that's why I'm saying ""again"" here). There are a few things going on that could be leading to differences. They are, in the order I think they will have an effect on the result:. * You are using RSEM in a mode that is mapping the reads to the entire genome (using STAR) and then projecting the resulting alignments to the transcriptome. You are using salmon in a way that is performing selective alignment against the transcriptome only. We have recently published [a paper](https://genomebiology.biomedcentral.com/articles/10.1186/s13059-020-02151-8) discussing in detail the effect that some of these choices can have on transcript and gene-level abundance estimation. In general, if you don't include the genome as a mapping target, depending on your sample, there may be certain reads that are assigned to the transcriptome even though they have a better alignment to some other genomic location. This is independent of e.g. salmon and RSEM, and you'd observe the same thing if you ran RSEM using e.g. Bowtie2 as the aligner aligning against the transcriptome. Luckily, you can control this source of variation. Salmon, like RSEM, can accept alignments to the transcriptome produced by STAR. If you want to see how big of an effect this is having in your sample, you can align reads to the genome using STAR (and project them to the transcriptome) to produce a BAM file that salmon can quantify. You can check RSEM's script to see exactly how it invokes STAR, but the parameters are something like `--outFilterType BySJout --alignSJoverhangMin 8 --outFilterMultimapNmax 20 --alignSJDBoverhangMin 1 --outFilterMismatchNmax 999 --outFilterMismatchNoverReadLmax 0.04 --alignIntronMin 20 --alignIntronMax 1000000 --alignMatesGapMax 1000000 --eadFilesCommand zcat --outSAMtype BAM Unsorted --quantMode TranscriptomeSAM --outSAMattributes NH HI AS NM MD --quantTranscriptomeBan IndelSoftclipSingleend`; note tha",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/612#issuecomment-758004590:828,depend,depending,828,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/612#issuecomment-758004590,1,['depend'],['depending']
Integrability,"Hi @rob-p ,. The data downloaded from sra database and use `fastq-dump` to split it only generate one fastq file, and EBI database only show one fastq file per sample. I am not sure if I process the file correctly. And here is a part of the description of the file on the sra database, and the link of one of the file <br class=""Apple-interchange-newline"">[SRR8453531](https://www.ncbi.nlm.nih.gov/sra/SRX5260234[accn]). ```; Instrument: Illumina HiSeq 3000; Strategy: RNA-Seq; Source: TRANSCRIPTOMIC; Selection: cDNA; Layout: SINGLE; Construction protocol: The scRNA-seq libraries were generated using Chromium Single Cell 3' Library & Gel Bead Kit v2 (10X Genomic) according to manufacturer's protocol. Briefly, 10,000-15,000 live cells were FACS-sorted and used to generate single-cell gel-bead in emulsion (GEM). After reverse transcription, GEMs were disrupted. Barcoded cDNA was isolated and amplified by PCR (12 cycles). Following fragmentation, end repair, and A-tailing, sample indexes were added during index PCR (8 cycles). Indexed libraries were multiplexed and sequenced on Illumina HiSeq 3000 instruments according to the manufacturer's instructions (26 cycles of Read 1, 8 cycles of i7 Index, and 98 cycles of Read2).; ```. Best",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/769#issuecomment-1107684572:548,protocol,protocol,548,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/769#issuecomment-1107684572,2,['protocol'],['protocol']
Integrability,"Hi @rob-p . Before I answer your question and layout my logic, I want to mention that I am **_not_** suggesting fastp is not doing its job, **_neither am I stating that fastp is working incorrectly_**. Now to my answer(s) and logic:; 1. With fastp, I am not sure if adapter trimming happens first and then quality trimming OR vice-versa. I could not find info on this from their README and **_I could be wrong here with my next line_** - [Based on Figure 1 of this paper, it looks to me as though quality trimming is done before adapter trimming](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6129281/figure/bty560-F1/). - [To quote Brian Bushnell (author of BBTools)]( http://seqanswers.com/forums/showpost.php?p=140819&postcount=5), . > It's best to do adapter-trimming first, then quality-trimming, because if you do quality-trimming first, sometimes adapters will be partially trimmed and become too short to be recognized as adapter sequence. When you run BBDuk with both quality-trimming and adapter-trimming in the same run, it will do adapter-trimming first, then quality-trimming. 2. I very well know that the advantage of using fastp is that it can do adapter trimming, etc in a automatic fashion - no need to provide external sequences (example adapter sequences). Yes, I know one can also provide a fasta file of adapters and fatsp will work off it. There are many fatsp issues in GH about adapter detection:. - fail to detect adpaters automatically - (https://github.com/OpenGene/fastp/issues/222 and https://github.com/OpenGene/fastp/issues/205). - [incorrect automatic adapter detection](https://github.com/OpenGene/fastp/issues/240). - [inconsistent behavior with different runs](https://github.com/OpenGene/fastp/issues/231). 3. When I see the above, I am bit skeptical using fastp for qc/adapter trimming. . After lot of trials with bbduk and fastp, I have decided to use bbduk and bbmap for my high throughput analysis. Below, I explain my reasoning behind those choices: . **_```Not",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-597393209:266,adapter,adapter,266,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-597393209,5,['adapter'],"['adapter', 'adapter-trimming', 'adapters']"
Integrability,Hi @rob-p . Thanks for the elaborate answer - makes a lot of sense. The problem is that adapter contamination typically occures because the fragments were smaller than the sequence length we sequence into the adapters - and it can occur for a larger fraction of the reads (I've seen up to 50% of reads affected in the 3'end) making it non-negligible. That is why I suggested the extension in the first place. I think it makes a lot of sense to trim adapters away - both because they reduce the number of compatible reads - mostly because the failure to do so will result in an overestimation of the fragment length. . Now that I think about it I don't think we should trim reads based on quality as that will lead to an underestimation of the read length - or what do you think?,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/150#issuecomment-355909325:88,adapter,adapter,88,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/150#issuecomment-355909325,3,['adapter'],"['adapter', 'adapters']"
Integrability,"Hi @rob-p . Thanks for the quick reply. Indeed my salmon index does not include lncRNAs, but my sequencing does. For indexing, I only used UCSC RefSeq transcripts (which I believe contains only protein coding transcripts that exclude most of lncRNAs). But this does not seem to suffice to explain the low mapping rate as Wikipedia says ""[Quantitatively, lncRNAs demonstrate ~10-fold lower abundance than mRNAs in a population of cells.](https://en.wikipedia.org/wiki/Long_non-coding_RNA#Abundance)"". To answer your questions:; 1. I used `htseq-count`, and here are the overall statistics (out of 149347870 record pairs processed):; ```; stat	""-s yes""	""-s reverse""; __no_feature	135258158	44917653; __ambiguous	39301	594958; __too_low_aQual	0	0; __not_aligned	0	0; __alignment_not_unique	7430169	7430169; ```. 2. I haven't done quality/adapter trimming as the data really looks clean and of high quality according to FastQC report. 3. Unfortunately I can't share the raw data yet but I will try your suggestion to quantify with STAR at the transcript level.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/661#issuecomment-847091597:835,adapter,adapter,835,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/661#issuecomment-847091597,1,['adapter'],['adapter']
Integrability,"Hi @rob-p . Totally understood (even more severe current limitations here) - survey completed. I think there'll ""always"" be Illumina-level coding (we use it to multiplex samples or cells), but I suspect most (all?) wild-west method will be some form of using the one read for barcoding. So as long as I can stipulate which bases in the read are which kind of barcode (cell/molecular) that'd be a good start. Of course having more mature methods than the current [drop-seq protocol](http://mccarrolllab.com/wp-content/uploads/2016/03/Drop-seqAlignmentCookbookv1.2Jan2016.pdf) to error correct, remove poly-A, remove adaptor sequences etc. always very welcome. (I suspect @vals is onto something... I still struggle to be entirely convinced that UMIs, as currently used, have the long-term legs that some people think.)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/93#issuecomment-282741659:472,protocol,protocol,472,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/93#issuecomment-282741659,1,['protocol'],['protocol']
Integrability,"Hi @rob-p @Gaura and @k3yavi - I actually just had this problem myself, and would now like to confirm what `--splitseqV1` and `--splitseqV2` are doing. I can't seem to find the UMI or barcode geometries these settings assume, can one of you clarify that here? Usually the cDNA is on R1 and UMI + barcodes are on R2, but it seems as though `--splitseqV1` may be assuming the opposite. It's okay and easy enough to reverse the input files like recommended above, but many users may face a similar issue if so. On a related note, it would be great to add these presets to the `alevin` docs, and for these and other geometry presets, spell out exactly which nucleotides on which reads are being extracted. `--splitseqV1` and `--splitseqV2` are not currently mentioned among the other protocol-specific setups in the `alevin` docs. . Thanks!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/774#issuecomment-1181068459:780,protocol,protocol-specific,780,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/774#issuecomment-1181068459,1,['protocol'],['protocol-specific']
Integrability,"Hi @rob-p,. I think I have figured out the issue. It seems like there's a dependency conflict with the ICU (international components for unicode) package between Salmon and R. It's been mentioned in this issue as well: https://github.com/COMBINE-lab/salmon/issues/594. I cannot have both the newest version of R and Salmon in the same environment. For context I've been installing Salmon>=1.10.1 through the bioconda channel, and base-r>=4.3.2 through conda-forge. Whenever I have R in the same environment, Salmon defaults to v0.14.1 during use (but the newest version when on the command line). If I remove R, Salmon defaults to the newest version during use and on the command line and works as normal.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/881#issuecomment-1944356621:74,depend,dependency,74,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/881#issuecomment-1944356621,1,['depend'],['dependency']
Integrability,"Hi @rob-p,. I was finally able to grab some time to try running the beta version you linked (see attached logs). This certainly helped, although I'm still nowhere near a time-frame of ~30min. Here are my results:. The 31-mer running took a bit over an hour and consumed ~17GB of memory. This is about half the running time as the previous version, but approx. the same amount of memory requirement (more on that below). The 17-mer running, took 4.5hrs to complete and consumed ~64GB of memory. This particular running is again, about twice as fast, although the time really depends on the memory limitations I gave it. Since it appears that this version no longer crashes when given less than about 250GB of memory, I also tested with 32G and 16GB of memory, just to see what impact this would have on the times. Those jobs are still running (it's only been about 4hrs as of this writing, I'll update my post if/when they complete). Current logs are showing that they quickly consume all the available memory, but have not yet crashed. I've also got versions with 128-512GB of memory requested (by powers of 2) for comparison. Some random notes: both the 31-mer index experienced about twice as many soft page reclaims with the new/faster version and experienced a few hard page faults (the previous version saw none of the latter). The 17-mer version experienced fewer page reclaims than any of the 31-mer indices and far fewer than with the prior version. Again, a few page faults crept in, but relatively few by percentage and likely not contributing any significant amount of time overall. [index-qacct-17mer.log](https://github.com/COMBINE-lab/salmon/files/4246516/index-qacct-17mer.log); [index-qacct-31mer.log](https://github.com/COMBINE-lab/salmon/files/4246517/index-qacct-31mer.log). **UPDATE**; The 16GB version finished running. It actually only took a little over 4 hours to run, as well. The troubling thing about this job seems to be that, despite having successfully completed, accordi",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/476#issuecomment-590516702:574,depend,depends,574,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/476#issuecomment-590516702,1,['depend'],['depends']
Integrability,"Hi @rob-p,. Thanks for the tip, using `--noErrorModel` indeed got rid of the error messages. Also, any advice regarding the best practices using salmon on nanopore data are welcome. Best,; Botond",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/289#issuecomment-420553174:83,message,messages,83,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/289#issuecomment-420553174,1,['message'],['messages']
Integrability,"Hi @rob-p,. thank you for the attention. . I noticed that Salmon tries to fetch and install dependencies. It's just that I tried to install a newer version in my home, but the HPC I'm using does not allow an external connection to the Internet. The installed version is a bit obsolete, so I need to wait for administrators to install the newer version (and usually the wait takes days and I like to settle things for myself. haha). Thank you very much. Best, Duca.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/225#issuecomment-392344952:92,depend,dependencies,92,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/225#issuecomment-392344952,1,['depend'],['dependencies']
Integrability,"Hi @rob-p,. thank you for your quick answer. As mentioned already, I started with the full set of options (at least I thought so) and then reduced them to the minimal case to reproduce the error for reporting the problem.; I was mislead by the term 'unrecognized option' and didn't expect the program to ""forget"" options from other modes. But now that you stated that this is the case, I realized that the '-a' in front of the BAM file name was missing, which I overlooked before. After adding it the program at least started to run. (Although it ran into another crirical error, appearantly misinterpreting chromosome and supercontig names from the BAM file header generated by STAR as transcript names.). Maybe it would be a good idea to distinguish in the error messages between 'unrecognised' and 'inappropriate' options to provide a better clue to the user what went wrong.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/343#issuecomment-462761900:765,message,messages,765,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/343#issuecomment-462761900,1,['message'],['messages']
Integrability,"Hi @rob-p,. you wrote that the first phase of the algorithm may yield different results dependent on the order in which reads are observed / processed. How is the order determined? Could you point me to the location in the source where this happens?. Asynchronicity doesn't necessarily have to lead to non-determinism if we can ensure that the assignment of threads of execution to reads is deterministic. I'd be happy to work on this, if you can point me to the locations of interest (and maybe some overview on how the code is supposed to behave). (Note: I'm not a biologist, just a silly hacker, so please be patient when I have silly questions.)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/185#issuecomment-392759884:88,depend,dependent,88,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/185#issuecomment-392759884,1,['depend'],['dependent']
Integrability,"Hi @rob-p,; thanks a lot for your investigation. Could you please be more verbose on those incorrect Build-Depends? What dependencies can be removed (if not used they should not really harm, thought but you are correct that it makes sense to remove these) and more importantly which can not be used. For instance if we can't use libstaden as packaged we have a problem. All preconditions for a Debian package have to be packaged first. Fetching something from network is not permitted at package build time.; Thus I simply tried changing the cmake options to. ```; $ cmake -DCMAKE_BUILD_TYPE=Release -DUSE_SHARED_LIBS=TRUE -DBZIP2_LIBRARIES=-lbz2 -DBZIP2_INCLUDE_DIR=/usr/include -DLIBLZMA_INCLUDE_DIR=/usr/include/ -DLIBLZMA_LIBRARY=lzma -DCMAKE_MODULE_PATH=/usr/share/cmake/Modules -DTBB_WILL_RECONFIGURE=FALSE -DBOOST_WILL_RECONFIGURE=FALSE ..; ```. which does not change the SEGFAULT problem. If the issue belongs to something we need to download from somewhere please let me know what looks suspicious to you. This would be helpful since we could either add it to the Debian package source in debian/missing-sources ... or rather fix the predependency that would break salmon.; Kind regards, Andreas.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1464471988:107,Depend,Depends,107,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1464471988,2,"['Depend', 'depend']","['Depends', 'dependencies']"
Integrability,"Hi @rudondamba,. The problem is that the sequence on line `30403` is parsed as ""empty"", since there is a space after the initial `>` and before the sequence name. This messes up the state of the underlying parser leading to the (in this case, uninformative) error message you are observing. If you fix the name online `30403`, then you should be able to index the transcriptome as expected. Let me know if this works for you. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/683#issuecomment-880059577:264,message,message,264,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/683#issuecomment-880059577,1,['message'],['message']
Integrability,"Hi @rudondamba,. There are a few options. If it's less than ~10MB, then you can just drop the file into the text box in the GitHub web interface here, and it will upload it and provide a link. If it's a few hundred MB or so, as is typical of many transcriptomes, the best thing to do might be to put it up on Google Drive or Box or Dropbox (whatever you have access to) and share a link. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/683#issuecomment-879989898:135,interface,interface,135,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/683#issuecomment-879989898,1,['interface'],['interface']
Integrability,"Hi @s1corley . As @rob-p mentions, your paper could help assess different methodologies for quantification and also help optimize salmon further for QuantSeq. I would still like you to check if you have used salmon quant command line correctly for QuantSeq data analysis. Your paper briefly alludes to QuantSeq Forward in the Introduction section of the paper; >The QuantSeq Forward kit has an oligo (dT) primer which contains the Illumina-specific Read 2 linker ... but the Methods section of your paper does not specify if you have used QuantSeq FWD or REV. Page 14 of the PDF from the [Lexogen Website data analysis pipeline for QuantSeq FWD](https://www.bluebee.com/wp-content/uploads/2018/11/015UG108V0201-QuantSeq-Data-Analysis-Pipeline_2018-10-18.pdf) recommends using the below htseq command line. ```; htseq-count -m intersection-nonempty -s yes -f bam -r pos $bam; $resource_dir/annotation.gtf > $bam_dir/read_counts.txt; ```; > QuantSeq is a stranded protocol. For the QuantSeq FWD pipeline the argument -s yes indicates; > stranded in the sense orientation. For the QuantSeq REV pipeline -s reverse is used. Similar to the above htseq command line arguments, I think if you are using QuantSeq FWD, the` libType argument from salmon quant should have been SF` . One way I checked these with my datasets was to run the salmon quant command 3 times - once with `libType A`, once with` libType SF` and once with `libType SR` -- with QuantSeq FWD the estimated counts will be almost same with libType A and libType SF. I echo what @rob-p says - Congratulations once again on the paper.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-565653150:962,protocol,protocol,962,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-565653150,1,['protocol'],['protocol']
Integrability,Hi @s1corley . Thanks for your inputs and thanks for taking the time to respond here. You mention you attached the Salmon meta_info output - I guess the attachment did Not come through. @k3yavi @rob-p - any ideas why the attachment did not make it . Yes - I am surprised with the results using the SR salmon quant option with the QuantSeq FWD protocol.; >I was advised that a FWD library was used - this is a bit confusing given the success of running the SR option. @rob-p What should be the libType option one should set with the QuantSeq FWD protocol - I have explained above why the SF option would be appropriate one (based on what Lexogen recommends for use with htseq-count for QuantSeq FWD),MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-565686395:343,protocol,protocol,343,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-565686395,2,['protocol'],['protocol']
Integrability,"Hi @s1corley,. Congratulations on your publication! The `--noLengthCorrection` flag has been around for a long time (e.g. where it is suggested in the post to which @tamuanand [links](https://groups.google.com/forum/#!msg/sailfish-users/VIfqBwgF6xQ/fw-rgC_kAwAJ)). However, given our limited access to QuantSeq and our limited (student) bandwidth to do extensive testing on alternative tech, we have kept this flag marked as experimental. As I mention above, it was introduced since, _conceptually_, the QuantSeq protocol should not exhibit a length effect and so the one may not wish to account for the length when determining assignment probabilities during the variational Bayesian optimization. However, the empirical testing of this has been limited. Now that your paper is published, and contains what look to be some _very through_ assessment methodologies, we may be able to look into this and determine if there is anything we can do to, perhaps, optimize salmon even more for accurate quantification from the QuantSeq protocol. We would welcome any suggestions or feedback you may have. Congratulations again on the paper!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-565474848:513,protocol,protocol,513,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-565474848,2,['protocol'],['protocol']
Integrability,"Hi @satta,. Thanks for bringing this to my attention. I am of two minds on this proposal. On one hand, I agree that it is cleaner, in theory, to have a RapMap shared library to which Salmon could simply link. Currently, Salmon pulls in the relevant portions of the RapMap code to call what is essentially an ill-defined public API for mapping. On the other hand, I have two concerns about separating the code at this point, one is major the other minor. The major concern is that both Salmon and RapMap are still very much under active development, core code and even the interfaces are undergoing reasonably rapid changes (thus the versioning < 1.0). This allows me to easily add features that may potentially benefit Salmon to the RapMap codebase, and then to synchronize Salmon releases with particular commits (tags) in the RapMap codebase. The current build system makes it very easy to pull in the appropriately versioned RapMap code. On the other hand, I have very little experience in properly versioning shared libraries so I would have to understand that better and how this could be done without complicating the build process. My _minor_ concern is that I don't know what effect, if any, separating the code into a separate shared library might have on compiler optimizations. Right now, since the relevant RapMap code is compiled alongside Salmon and they are linked together into the same module, certain optimizations may be possible that would not be so when linking to a shared library. My educated guess is that the effect of such optimizations would be negligible, but it's something that may be worth some exploration first. Overall, I'm very open to this idea, but I think I need to do some homework on it before we can commit and undertake the change.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/87#issuecomment-246027704:572,interface,interfaces,572,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/87#issuecomment-246027704,2,"['interface', 'synchroniz']","['interfaces', 'synchronize']"
Integrability,"Hi @seanken,. Thank you for reporting this. I agree this error message should always show up. My guess is that this is related to the fact that the error is reported through the asynchronous logger, which is notoriously picky about how it must be torn down to avoid dropping messages on atypical (non-zero) program exit. I'll see if I can make this one show up reliably. By the way, do you have a small pair of FASTQ files that will trigger this error?. Thanks,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/736#issuecomment-1018119606:63,message,message,63,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/736#issuecomment-1018119606,2,['message'],"['message', 'messages']"
Integrability,"Hi @shanmugavadivelps,. This is because, to properly find and link libiconv, the build requires a version of CMake that ships with FindIConv.cmake. So, to build salmon from source, you should have at least CMake version 3.12. Internally and on our continuous integration servers, we use version 3.15. . Also, I'll mention that it may not be essential to build from source. Salmon is available via Bioconda, and a docker image is available via DockerHub. Also, we have a pre-compiled binary that should work on many linux distributions available under our [releases](https://github.com/COMBINE-lab/salmon/releases).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/453#issuecomment-557149581:259,integrat,integration,259,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/453#issuecomment-557149581,1,['integrat'],['integration']
Integrability,"Hi @sudeep71,. Can you upload the JSON files in your index directory? The problem seems to be that fields that are expected to exist in the index are missing. Since you built Salmon from source yourself, if you built it in the same directory as a previous version, did you run `cmake ..` first? Since the newest version depends on upstream changes in RapMap, those external dependences need to be re-fetched. In fact, I'd suggest that you remove (or move) the entire build directory, and then make a new one to start the build process from scratch. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/135#issuecomment-299870076:320,depend,depends,320,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/135#issuecomment-299870076,2,['depend'],"['dependences', 'depends']"
Integrability,"Hi @summerrfair ,. I can't see anything obviously wrong with the command line. Do you have a small example of the transcripts.fa and myseq.bam file you could share? The message indicates that salmon thinks its running in mapping-based mode (with input fastq files), but you are clearly running in alignment based mode. Is the behavior any different if you put the -a argument first?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/511#issuecomment-616870047:169,message,message,169,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/511#issuecomment-616870047,1,['message'],['message']
Integrability,"Hi @tamuanand ,; Thanks for raising this doubt. SA is already integrated into the salmon environment i.e. you just have to re index salmon using the `generateDecoyTranscriptome.sh` script from [here](https://github.com/COMBINE-lab/SalmonTools) and run salmon quant as you usually do w/ the `--validateMappings` additional command line flag.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/365#issuecomment-499297622:62,integrat,integrated,62,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/365#issuecomment-499297622,1,['integrat'],['integrated']
Integrability,"Hi @tamuanand,. Sure; is there anything specific about bbduk and bbmap for quality / adapter trimming that you think would be provided beyond or in addition to what fastp provides? Also, we have a beta implementation of soft-clipping and are looking for a wide net of testing data. Any suggestions to that end would be welcome!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-597344801:85,adapter,adapter,85,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-597344801,1,['adapter'],['adapter']
Integrability,"Hi @tamuanand,. Thank you for the detailed questions! Let me elaborate a bit on a few of @k3yavi's answers. 1&2) Yes; if you want to use SAF, you no longer need mashmap, as what you are essentially doing is treating the entire genome as a ""decoy"". As @k3yavi alludes, SA is still useful when you need to run in a very memory-constrained environment. After adopting the new [pufferfish-based](https://github.com/COMBINE-lab/pufferfish/tree/develop) index, the size of the transcriptome plush mashmap 2 decoys becomes considerably smaller than the previous size of the transcriptome in earlier versions of salmon (<= 0.15.0). However, depending on the organism, indexing the entire genome as decoy, even though it yields the best accuracy, does require a bit more memory, as specified in the release notes for the 0.99 betas and 1.0.0. 3) Yes; it is still possible to use `salmon index` without any decoy sequence. In this case, one can expect results similar to if you had aligned to the target transcriptome using Bowtie2. In this case, you perform indexing by simply not providing any `--decoy` flag to the `index` command. In that case, all of the records in the target fasta will be treated as valid and quantifiable targets. Of course, for reasons detailed in the pre-print --- the high _sensitivity_ of both Bowtie2 and selective-alignment --- we recommend including either mashmap-derived decoys or the organism's genome as a decoy whenever possible. . 4) Related to @k3yavi's response and my elaboration above: we have dropped quasi-mapping from 1.0.0 (though something akin to it may return in the future if there is sufficient demand and if the shortcomings described in the manuscript can be overcome). However, as I mention in part 3 above, this doesn't mean it's not possible to use v1.0.0 without an explicit decoy sequence. The `--decoy` flag of the indexing command is optional, not required. We will update this in the documentation making it more explicit. However, as @k3yavi points ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/442#issuecomment-549195390:633,depend,depending,633,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/442#issuecomment-549195390,1,['depend'],['depending']
Integrability,"Hi @tamuanand,. Thanks again for your detailed questions and thoughts on this issue. Just to follow-up / expand a bit on what @k3yavi has said (and to answer your other question): Yes, one would imagine that, given the details of the QuantSeq protocol, turning off length correction would make the most sense. The main reason this flag is listed as _experimental_, is simply that it was designed based on the expected characteristics of the protocol. Conceptually, the protocol is performing tagged-end sequencing, and so there should be little-to-no length effect. However, since we haven't done extensive internal validation on QuantSeq data, we have left this flag as experimental until it is further tested by ourselves or others. > Also @rob-p , weren't you referring to the RSEM caveat with QuantSeq data analysis wherein one cannot ask RSEM to disable lengthCorrection and hence the count statistics might be misleading?. Correct; as far as we are aware, there is no way to disable the built-in length-dependent assumptions of RSEM. One could use the `--estimate-rspd` flag to allow learning of a non-uniform read distribution (the equivalent of `--posBias` in salmon), though it's unclear / unlikely if this would be as effective as fully disabling the length correction for this type of tagged-end data. If you have any good empirical assessment mechanism for QuantSeq data, and a chance to test out these different salmon options, we'd be happy to get feedback and discuss details further!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-565285540:243,protocol,protocol,243,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-565285540,4,"['depend', 'protocol']","['dependent', 'protocol']"
Integrability,"Hi @thu1911,. The strand bias here is actually quite moderate. The calibration of `strand_bias` is such that a value of 0.5 means there is no bias (i.e. half of the fragments start with read 1 on the forward strand and half start with read 1 on the reverse complement strand). Your value is `""strand_mapping_bias"": 0.5258466052704426`, so you are pretty close to the ideal value of 0.5, though there is a _slight_ bias in the data. I wouldn't be concerned about this assuming you were assuming an unstranded protocol. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/422#issuecomment-524643119:508,protocol,protocol,508,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/422#issuecomment-524643119,1,['protocol'],['protocol']
Integrability,"Hi @tillea and @nileshpatra,. Ok, I dug deeper and found out what's going on. The culprit is, in fact, `libcereal`. The problem is that `libcereal` bumped patch versions only since the version corresponding to the headers included in `pufferfish`, but their changes are not, in fact, backwards compatible! This lead to a version mismatch between the headers used in `pufferfish` and the headers found from the installed package, ultimately resulting in an assertion failure in `rapidjson` (which cereal is using) and a segfault. On the plus side, this was relatively easy to fix by bumping the included cereal headers in pufferfish. I also updated the `Findcereal.cmake` module and added a version constraint so that we now require the new version (1.3.2). This is now tagged and released as `salmon 1.10.1`. Please give that a go when you have a chance. I'll note that, before this is added upstream in debian, I'd still advocate for fixing the `libstaden` package to update to the new version. I'd also recommend moving to dependencies like the ones I've included above to remove some really antiquated dependencies that salmon no longer requires but are still being pulled in. Thanks!; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1465096711:1025,depend,dependencies,1025,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1465096711,2,['depend'],['dependencies']
Integrability,"Hi @tillea,. It seems this is exactly the problem. The build deps here are not quite correct. There are dependencies that salmon no longer has, and some of the dependencies it does have are out of date and can't be used from upstream (e.g. libstaden in the latest version, among others). On the bright side, it's not the dynamic linking alone that is problematic. The following works fine on my end:. ```{bash}; $ docker pull debian:testing; $ docker run -it debian:testing; $ echo ""deb-src http://deb.debian.org/debian unstable main"" > /etc/apt/sources.list.d/10-debsrc.list; $ apt-get update; $ apt-get upgrade; $ apt-get install build-essential git libboost-all-dev liblzma-dev libbz2-dev cmake zlib1g-dev curl unzip wget libcurl4-openssl-dev libtbb-dev libtbb12 liblzma-dev libjemalloc2 pkg-config libgff-dev; $ wget https://github.com/COMBINE-lab/salmon/archive/refs/tags/v1.10.0.tar.gz; $ tar xaf v1.10.0.tar.gz; $ cd salmon-1.10.0; $ mkdir build && cd build; $ cmake -DCMAKE_BUILD_TYPE=Release -DUSE_SHARED_LIBS=TRUE -DBZIP2_LIBRARIES=-lbz2 -DBZIP2_INCLUDE_DIR=/usr/include -DLIBLZMA_INCLUDE_DIR=/usr/include/ -DLIBLZMA_LIBRARY=lzma -DCMAKE_MODULE_PATH=/usr/share/cmake/Modules -DTBB_WILL_RECONFIGURE=FALSE -DBOOST_WILL_RECONFIGURE=FALSE ..; $ make -j8; $ make install; $ make test; ```. This is preferring dynamic linking, and the resulting installed executable runs fine without a segfault. Can you try this on your end? Then the thing to do may be to find what is discordant between the packages I install above and what gets pulled in by `apt build-dep salmon`. Thanks,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1464182279:104,depend,dependencies,104,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1464182279,2,['depend'],['dependencies']
Integrability,"Hi @tillea,. So I went through the list of deps pulled in by `apt build-dep salmon` and the minimal set I gave above. I tried to make the smallest number of changes I could to the `apt build-dep salmon` list while also removing things that are clearly outdated (we no longer use jellyfish, rapmap, etc. and we use the header-only version of spdlog). As a result I came up with this list of dependencies. The offending dependency seems to be `libcereal-dev`. Specifically, I was able to install just this list of dependencies (minus `libcereal-dev`) atop a clean `debian:testing` and get a working version where the only thing downloaded from the internet was the appropriate version of the pufferfish files grabbed by `fetchPufferfish.sh` in the `1.10.0` release. Once I installed `libcereal-dev` with `apt-get install`, and rebuilt, then I got the segfault mentioned at the top of this issue. So, it seems that we either have to let `salmon` build it's own libcereal, or figure out what the problem is with the library upstream. Please let me know if this you observe this same behavior as well (also @nileshpatra may want to try this out). If so, perhaps we can get `libstaden` updated upstream, and then use this as the new dep list for `salmon`. I installed these deps with a simple `xargs apt-get install -y < deps_sorted_updated.txt` (without `libcereal-dev` for the working version, and with it included, as below, for the segfault). Best,; Rob. [deps_sorted_updated.txt](https://github.com/COMBINE-lab/salmon/files/10949233/deps_sorted_updated.txt)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1464986376:390,depend,dependencies,390,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1464986376,3,['depend'],"['dependencies', 'dependency']"
Integrability,"Hi @tmms1 ,. > I think that each such line corresponds to an equivalence class (EC). The first entry on each row is the number of transcripts in the EC. This is followed by the transcripts (more correctly, indices you can use to obtain the transcripts). Then you have the number of reads with in the EC, followed by the number of barcodes (~cells). For each barcode, you have an index that can be used to retrieve the identity of the barcode, followed by the number of UMIs within that barcode, the sequence of the UMI and lastly the number of reads associated with that UMI. This is correct !. Unfortunately you goal is not very clear to me and the output matrix depends on that. I understand that you wan't a matrix of dimension |eq_class X cells| but if you wan't the values in the matrix to be read count then you have to add the counts of all the UMIs in class across the cells; and if you wan't the values in the matrix to be the frequency of the unique UMIs then just count the UMIs you wan't instead of reads.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/728#issuecomment-1029328067:664,depend,depends,664,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/728#issuecomment-1029328067,1,['depend'],['depends']
Integrability,"Hi @tomsing1 ,; Apologies for the slow response, I was out of country for a while. Thanks for your kind words and starting a very interesting suggestion.; It’s fascinating to see, how methods being used in single-cell RNA-seq is coming full circle back to the bulk RNA-seq experiments. We have to do some more digging to say clearly about the caveats of using Alevin with the mentioned 3’ bulk RNA-seq experiments but given the understanding from the picture of the shared image we don’t see any obvious show stoppers; although below mentioned concerns should be kept in mind while using Alevin for bulk data deduplication:. Alevin solves the problem pretty well for protocols where fragmentation of the cDNA molecule happens post PCR amplification. There might be some concerns about over-deduplication of the UMI if fragmenation happens before amplification. Although in current form, Illumina sample index can be given as an external whitelist to Alevin but user should be aware that Alevin performs a sequence correction step before starting any optimizations.; Alevin is designed for droplets based protocols, where one end of Paired end read is just the CB/UMI (i.e. no read sequence) and therefore Alevin can’t optimally use the full paired end information of the bulk 3' protocol if its both end has read-sequence for example the ambiguous mapping resolution based on a previously/empirically known approximate fragment length. We would be more than happy to help/discuss, how does the results look in bulk 3’ tagged protocols or if you have particular suggestions about what improvements can be done in Alevin.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/306#issuecomment-439530193:667,protocol,protocols,667,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/306#issuecomment-439530193,4,['protocol'],"['protocol', 'protocols']"
Integrability,"Hi @uros-sipetic!. Unfortunately, as you suggest, there really is no good way to infer the fragment length distribution from only single-end reads. Rather, this flag determines how the conditional probability of single-end fragments near the beginning (if in the rc orientation) or end (if in the forward orientation) of the transcript are determined. A single-end read does not have any known fragment length. But we do know that e.g. fragments very close to the end or beginning of the transcript are rather unlikely. In this case, we can integrate (sum) over all possibilities to assign a conditional probability. This is what salmon does. For a single-end read (assume forward orientation for simplicity) at position i on a transcript of length n, we consider the conditional fragment length probability to be given by F_n(n-i), where f_n is the conditional fragment length distribution conditioned on the transcript length (maximum observable length) being n and F_n is the cumulative distribution function of f_n. Intuitively, this means that fragments very close to transcript ends will get a smaller conditional probability, while those farther from the end will get larger conditional probabilities. The `--noSingleFragProb` flag simply turns off this conditional probability all together. It is _not_ recommended to disable the single-end fragment length probability modeling. We have evidence from testing that it improves quantification accuracy. Thus, I would suggest _not_ setting the `--noSingleFragProb` flag. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/575#issuecomment-711061553:541,integrat,integrate,541,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/575#issuecomment-711061553,1,['integrat'],['integrate']
Integrability,"Hi @uros-sipetic,. RSEM _does not_ collapse duplicates. This means that it will return quantification estimates for all of the sequence identical transcripts separately. A common scenario may be that it will split the abundances evenly, but this may not always be the case, depending on e.g. the initialization of the EM algorithm etc. The easiest way to try and compare the estimates as closely as possible would probably be to use the `duplicate_clusters.tsv` file produced by salmon to explicitly collapse (add up) the abundances of the duplicate transcripts from the RSEM quantifications before comparing. As always, we'd be interested to hear if you find anything interesting!. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/255#issuecomment-628760746:274,depend,depending,274,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/255#issuecomment-628760746,1,['depend'],['depending']
Integrability,"Hi @uveksamoosmeh,. Can you explain a bit your usecase? The `--features` option is designed for indexing short features for specific single-cell protocols (e.g. HTO tags etc.). If you are trying to index a standard transcriptome, this is not the purpose of this option. Rather, for that you should pass the transcriptome `FASTA` file as the input to the regular `salmon index` command. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/865#issuecomment-1664415328:145,protocol,protocols,145,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/865#issuecomment-1664415328,1,['protocol'],['protocols']
Integrability,"Hi @vertesy ,. Thanks for asking the very interesting question.; I'd say the answer might depend on what's your downstream use case. Traditionally, no quantification pipeline, in my knowledge, has used the pre-mRNA counts alone to bump up the gene counts, however, recent method of estimating RNA-velocity does utilizes the intronic counts for extracting the ratio of spliced/unspliced counts. If you are interested in disjoint signals (gene count matrix) for spliced and unspliced molecules you can use the recent scheme of decoy indexing from our latest [preprint](https://www.biorxiv.org/content/10.1101/657874v2). We (mostly @csoneson) have been testing alevin with following scheme for generating spliced and unspliced counts. 1.) Spliced Counts: Index transcriptome w/ pre-mRNA sequence as the decoys.; 2) Unspliced Counts: Index pre-mRNA sequence w/ transcriptome as the decoys. The third case is a little tricky because if you index both pre-mRNA and transcriptome, due to relatively longer length of pre-mRNA sequence compared to transcripts it might end-up biasing the UMI deduplication algorithm towards unspliced counts. To summarize, the best way to have an additive spliced and unspliced counts is still an open area of research.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/450#issuecomment-555136444:90,depend,depend,90,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/450#issuecomment-555136444,1,['depend'],['depend']
Integrability,"Hi @wdecoster,. Thanks for reporting this. One restriction that needs to be better documented (actually, I have to make sure it is properly documented at all!) is that the library type should come _before_ the reads they describe. That is, you should consider passing `-l SF -r {}` rather than `-r {} -l SF`. The reason for this is that the `-r` and `-1,-2` parameters are repeatable so you could, conceivably, pass multiple reads of different library types. However, this is a feature that nobody uses and frankly doesn't make too much sense (so I'll consider removing it in the future to simplify library type parsing). For the time being, I'll also consider printing a warning message when a read file is encountered without an explicitly pre-defined library type (in that case, the behavior, as you saw, is to assume an unstranded library). Could you let me know if passing `-l` before `-r` resolves the issue for you. As to your other suggestion. The internal capitalization rules follow those for camel-case naming of variables (as opposed to separating words with`_`). However, I realize this is somewhat esoteric and even among those who are familiar with such conventions, an arbitrary preference. I'll look into aliasing this flag (and maybe others) to be usable with different names as well. I just have to check how to do this (and if it is possible) with boost's program options.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/177#issuecomment-347524360:680,message,message,680,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/177#issuecomment-347524360,1,['message'],['message']
Integrability,"Hi Amy,. Unfortunately, when you reply to github via e-mail, it doesn't include attachments. Could you please either upload the files here (the github web interface supports drag-and-drop), or just send me an email. Thanks,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/96#issuecomment-250982842:155,interface,interface,155,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/96#issuecomment-250982842,1,['interface'],['interface']
Integrability,"Hi Andrea,. The bias correction time depends on the number of expressed transcripts. There is a flag to speed it up `--biasSpeedSamp`. It takes a value by which to downsample the fragment length pmf for bias modeling. The larger this number, the faster bias correction will become. The default is 1, and is super conservative (we are probably going to make the default 5 in the next release because it is much faster with no real difference in modeling quality). In fact, values up to at least 10 seem to work quite well with respect to the baseline. So, I'd recommend testing this parameter on a sample until you are happy with the speed, and then using that on all samples. Let me know how it goes, and if my description makes sense. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/201#issuecomment-369766969:37,depend,depends,37,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/201#issuecomment-369766969,1,['depend'],['depends']
Integrability,"Hi Andreas,. So I don't know if there is a easy way to get the specific list of reverse dependencies, but then we can cross-check it with my explicit list above:. ```; build-essential; git ; libboost-all-dev ; liblzma-dev ; libbz2-dev ; cmake ; zlib1g-dev ; curl ; unzip ; wget ; libcurl4-openssl-dev ; libtbb-dev ; libtbb12 ; liblzma-dev ; libjemalloc2 ; pkg-config ; libgff-dev; ```. One thing I noticed during build is that, while I included `libjemalloc2` here, the salmon build procedure still downloaded and built `jemalloc`. However, I don't _think_ jemalloc is the thing causing the segfault. Regarding dependencies that can't be used — the current `libstaden` is behind the upstream release. The upstream release contains an important bug fix for a bug (and suggested fix that we proposed to the developer) upon which we rely. More importantly, afaik there is no relevant `libpufferfish-dev` package (we certainly have not made one), and so there is not even e.g. a check in the `CMakeLists.txt` file. Salmon's build always tries to run `fetchPufferfish.sh` to download the relevant `pufferfish` source files needed to build `salmon`. Critically, the relevant `pufferfish` dependencies and `salmon` releases move in lockstep. Each new `salmon` release it accompanied by a new tag in the `pufferfish` repo (so that the specific source used to build a given `salmon` release is fixed and easily trackable). So, I think the easiest way to move forward is to:. * do a diff of my list of packages above with what is pulled in by `apt build-dep salmon`. * figure out why, even when `libjemalloc2` is installed, the build system tries to build `jemalloc` itself (maybe we need the dev package?). * determine what folks want to do upstream about the lockstep pufferfish dependency. Right now, the `fetchPufferfish.sh` script pulls a tagged tarball from github and checks that the sha matches, and moves the relevant source files into place. This is true both when we build our own releases as well as",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1464538233:88,depend,dependencies,88,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1464538233,2,['depend'],['dependencies']
Integrability,"Hi Assa,. The problem is that you've not provided the input files via the appropriate `-1` and `-2` flags. For your particular command, the command line should look like . ``` bash; $ salmon quant -p 16 --biasCorrect --libType IU -1 <(zcat ${base}_1.fastq.gz ) -2 <(zcat ${base}_2.fastq.gz) -i ~./Salmon/Salmon.index/Homo_sapiens.GRCh38.rel79/ --numBootstraps 100 -o $base ; ```. Notice this looks almost the same as what you had before, except that the reads are prefixed by the relevant `-1` and `-2` flags, and come directly after the library type flags. Please let me know if this fixes the issue for you. I'll add a more informative message in such a situation.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/65#issuecomment-231729597:638,message,message,638,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/65#issuecomment-231729597,1,['message'],['message']
Integrability,"Hi Carlos,. This is quite interesting, and I have a few hypotheses. My first hypothesis is that the difference could be arising from differences in the annotation --- for salmon you are using reference cdna, and for STAR+RSEM you are mapping against the genome with, presumably, some gtf file used for annotation (I believe that what RSEM does internally is to run STAR with the proper flags to ""project"" mapped reads onto the transcriptome). Are these transcriptomes equivalent? For example, are there differences in annotated rRNAs, which can make a big difference depending on the prep protocol. The other question is the difference in the total assigned number of reads. What do you get when you add up the `NumReads` column from salmon versus the `expected_count` column from RSEM --- there could be some difference in terms of reads mapped to the genome but not properly annotated and, therefore, not contributing to quantification. Finally, you can always pass the BAM file generated by STAR+RSEM to salmon (in alignment mode) to see how that affects the total number of mapped reads. Though there is always the possibility that something unforeseen is causing these differences, they usually seem to wind up being due to something mundane but non-obvious. Here, slight differences in the annotation --- particularly the inclusion or not of rRNA and other RNA species --- would be my first guess.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/212#issuecomment-378954000:567,depend,depending,567,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/212#issuecomment-378954000,2,"['depend', 'protocol']","['depending', 'protocol']"
Integrability,"Hi Dan,. Can you share an example of a dataset where you encounter this? It's a pretty generic message, and I'm not actually certain where it's coming from without some more context. Thanks,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/632#issuecomment-779409595:95,message,message,95,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/632#issuecomment-779409595,1,['message'],['message']
Integrability,"Hi Gert,. Indeed, the CMake build uses `curl` for downloading relevant dependencies. Presumably, it would be possible to have a fallback to `wget` if `curl` is not available. I will look into the best way to do this. In the meantime, you should be able to use the pre-compiled binary for linux (x86-64) or install Salmon via [bioconda](https://anaconda.org/bioconda/salmon). Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/181#issuecomment-354673470:71,depend,dependencies,71,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/181#issuecomment-354673470,1,['depend'],['dependencies']
Integrability,"Hi Holley,. Thanks for the response: Here are some followup thoughts . >It's strange that once all three have been compiled into a single assembly using Evigene, salmon detects the ISR library type. When I change the ""A"" to ""ISR"" or ""IU"", the % mapped changes a lot. That does seem strange, but I honestly don't know much about `Evigene` or what it's doing in combining these assemblies. When you specify ""IU"", the mappings will generally be _more_ lenient (i.e. you'd expect to get more mappings) than when you specify ""ISR"". The ""A"" flag just looks at how the first 10,000 reads map and guesses the library type based on that. On thing to make sure of is that your reads aren't ""ordered"" in any way, such that you'd expect the first 10,000 to deviate in any meaningful way from the statistics of the reads of the reads. > Is it better to build assemblies with strand-aware flags? If so, does it usually make a large difference to quantification results, or a minor one? I don't know what protocol the sequencing facility used, but I am sure I could ask them. I gather from my recent reading that the extra information gained by using a stranded protocol is worthwhile, so I would expect that the sequencing facility used one, but why doesn't Trinity or MEGAHIT detect the sequecing protocol that was used? . So there are really 2 questions here. *If* the data are stranded, then yes, it's worthwhile to use stranded flags in both assembly and quantification. This is because stranded protocols will allow you to better disambiguate (a) overlapping genes and (b) reads that are ambiguous between sequence-similar genes that happen to reside on different strands. The *second* question is why Trinity or MEGAHIT wouldn't detect this. The main reason for this is that these are assembly tools. Without access to a reference genome, there is no principled way for these tools to know what the orientation of a read is _a priori_, so they generally rely on the user to specify if the reads are stranded o",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/840#issuecomment-1493034427:990,protocol,protocol,990,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/840#issuecomment-1493034427,1,['protocol'],['protocol']
Integrability,"Hi Mike,. Glad to hear this fixes it. I pushed a commit that does the check, prints out a useful error message (that suggests how you can make a compatible transcriptome fasta) and then bails. Regarding the `libParams` directory --- that is actually a somewhat anachronistic directory anyway. Currently, I've been moving all of the parameters into their own (gzipped) files in the `aux_info` directory. I've kept `libParams` there for backward compatibility sake, but I think it's confusing if the fld appears in multiple places, but the other parameters appear somewhere else, so perhaps it's time to remove it (and note such in the next version's release notes).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/104#issuecomment-267610178:103,message,message,103,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/104#issuecomment-267610178,1,['message'],['message']
Integrability,"Hi Mohsen and Rob,. So sorry if you've already been troubleshooting the example data I gave you. I realized that that is not a good example of the problem. In this example, there are snR40 and snR40_genomic transcripts, representing processed and pre-processed isoforms. However, it just so happens that there is residual adapter on some of the reads I provided and the first nucleotide of the adapter sequence actually matches the first nucleotide of the longer, genomic version of this transcript, therefore, the genomic variant gets a slightly better alignment score, as it should. After hard trimming any residual adapter the results for this transcript were a lot better (although still not quite the ratio I would expect). I have quite a few examples like this and I'm fairly sure they are not *all* explained by alignment of adapter sequences. However, I just wanted to let you know in case you were already troubleshooting my example data. I'm aggregating a handful more general examples of the same problem, but ones without a trivial solution like the one I provided. The files are too large to attach on github directly, though, do you have a preferred way to share the files? Maybe a google drive?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-642954815:322,adapter,adapter,322,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-642954815,4,['adapter'],['adapter']
Integrability,"Hi Paul,. Did you reply to the github issue via e-mail and attach it there? In that case, it won't show up. If you post a response via the github interface, you can just drag and drop the file into the text box to have it uploaded.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/323#issuecomment-442575438:146,interface,interface,146,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/323#issuecomment-442575438,1,['interface'],['interface']
Integrability,"Hi Rachel,. So it looks like `output/hs.grch39.index/versionInfo.json` doesn't exist here? Are there any other messages that show up during indexing? Also, v0.8.1 is very outdated at this point. It might be worth checking if this issue is still popping up if you grab the latest version (available both as a linux binary from the releases page, as well as via bioconda).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/197#issuecomment-467194457:111,message,messages,111,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/197#issuecomment-467194457,1,['message'],['messages']
Integrability,"Hi Rich,. The issue with pre-compiled OSX binaries is that they are difficult to make portable across OSX versions. This is why we strongly suggest installing Salmon (especially for OSX) through [Bioconda](https://bioconda.github.io/). This greatly eases installation and updating, and doesn't require admin privileges. On OSX, you can try the following:. ```; $ conda config --add channels conda-forge; $ conda config --add channels bioconda; $ conda create -n salmon salmon=0.9.1; ```. This should take care of all relevant dependencies as well as e.g. library locations and placement. Could you please give this a try and let me know if it works for you?. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/215#issuecomment-381997508:526,depend,dependencies,526,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/215#issuecomment-381997508,1,['depend'],['dependencies']
Integrability,"Hi Rob, . For example, here is the log output when I try to index the GENCODE Human transcript set v36, using the below code;. salmon index --keepDuplicates -k 35 --gencode -t gencode.v36.transcripts.fa -i Human_v36_Index_k35. Here is where the phrase is found in the log, and is then repeated a lot until the end. Number of ones: 1309432; Number of ones per inventory item: 512; Inventory entries filled: 2558; 1309432; [2021-02-15 04:42:27.548] [puff::index::jointLog] [info] Done wrapping the rank vector with a rank9sel structure.; [2021-02-15 04:42:27.565] [puff::index::jointLog] [info] contig count for validation: 1,309,432; [2021-02-15 04:42:28.338] [puff::index::jointLog] [info] Total # of Contigs : 1,309,432; [2021-02-15 04:42:28.339] [puff::index::jointLog] [info] Total # of numerical Contigs : 1,309,432; [2021-02-15 04:42:28.404] [puff::index::jointLog] [info] Total # of contig vec entries: 7,119,643; [2021-02-15 04:42:28.404] [puff::index::jointLog] [info] bits per offset entry 23; [2021-02-15 04:42:28.590] [puff::index::jointLog] [info] Done constructing the contig vector. 1309433; [2021-02-15 04:42:29.459] [puff::index::jointLog] [info] # segments = 1,309,432; [2021-02-15 04:42:29.459] [puff::index::jointLog] [info] total length = 188,284,293; [2021-02-15 04:42:29.548] [puff::index::jointLog] [info] Reading the reference files ...; [2021-02-15 04:42:31.594] [puff::index::jointLog] [info] positional integer width = 28; [2021-02-15 04:42:31.594] [puff::index::jointLog] [info] seqSize = 188,284,293; [2021-02-15 04:42:31.595] [puff::index::jointLog] [info] rankSize = 188,284,293; [2021-02-15 04:42:31.595] [puff::index::jointLog] [info] edgeVecSize = 0; [2021-02-15 04:42:31.595] [puff::index::jointLog] [info] num keys = 143,763,605; len should not be greater than 64.; ...; ...; ...; len should not be greater than 64.; [2021-02-15 05:07:13.459] [puff::index::jointLog] [info] finished populating pos vector; [2021-02-15 05:07:13.460] [puff::index::jointLog] [info] wr",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/632#issuecomment-779416548:483,wrap,wrapping,483,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/632#issuecomment-779416548,1,['wrap'],['wrapping']
Integrability,"Hi Rob, After posting yesterdays message, I generated the vM23 index, and the alignments/quants worked. I had to use mem_free=34G for building index. Is that expected?; I will try building the vM25 index again and and post the update.; In the meantime, sha256sum of my vM25 index that I had generated has some mismatches from the one you created. Below is my sha256sum on vM25 index:; `306e9d98b3460859f579059bf876aa3b6e264c8f38c04cde332b03632edc6dfb complete_ref_lens.bin; 636b3df7e097d58fa846bd85ce650ce5bf72c66dc5b2d7566fc9e3db087c5c9c ctable.bin; 1c7501deaa4524f4700152713228cb03949775dce481384eac67bb45458508be ctg_offsets.bin; dbc575fed0d589b4671c26bd8cbcb4b3d52ef41c299a90de978ab940abb751fc duplicate_clusters.tsv; c3ec09a30adc9d47bc95839157cb2ff66530353106a4fd8e75b167ac5db67820 info.json; 430be78bae99a4592fcedc5c800a42313f2b1252e3953f89f347779056c1ee5b mphf.bin; 2fb0b5151f9f2544c06a9f95d03075f7af0494d0fe31745504a5a7da43edc1b1 pos.bin; 15d3bb6a16bcd8c1a6814852bd3dcfa439b60ec84c706f868ee7ec2d5a90581d pre_indexing.log; 8e665e5fdee5af6fcedabc69fd04eda6e66055ef811ebde6de6f86a66521198a rank.bin; 793c79f5fd6046dfea07bbc9587d2835088e54c78197d652d1b1f205c6b16983 refAccumLengths.bin; c5ea8eccca3fdc299ad7c9d2f07a4ed14c8c830940e83c315e7eaad6905a40aa ref_indexing.log; b580b9c6257254a018a9ae22291a64892c1a3715c69272637f5c504fc5545a70 reflengths.bin; 89679603ac0b28042275e5ff04b222bad3fd431cab573f0c2b61e7455aec43e7 refseq.bin; 46bf28001e00d491b68bf8758b99c1f304523c79bd94a97d7797888856594e84 seq.bin; 4c7e56ba28383774e786826099ef412761326fe18ce69f29033ad2886542985d versionInfo.json; `; Following are different.; `ctable.bin; info.json; mphf.bin; pos.bin; pre_indexing.log; ref_indexing.log; seq.bin; versionInfo.json`. I will try creating the vM25 index with increased memory. Wonder if its not building. Just FYI, my sha256sum on vM23 index is:; `9788716f4ce42b049fe7e865108f45392bb8a5847cfcd47369512783dc918239 complete_ref_lens.bin; 9c2453a47ce1808f54733f049b8c4cf38634c9116eb55ed725b73219caa",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/561#issuecomment-674527480:33,message,message,33,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/561#issuecomment-674527480,1,['message'],['message']
Integrability,"Hi Rob,. I did some follow up using your suggestions, and I had indexed my; transcriptome incorrectly, but now it appears that I am having a separate; issue and was hoping that you might be able to point me in the right; direction? Here is my command:. ```#!/bin/bash -l; #SBATCH -J male_salmon_map; #SBATCH -t 150:00:00; #SBATCH -p high; #SBATCH --cpus-per-task=24; source ~/.bashrc; source activate salmon; cd /home/seboles/abaloneraw/salmon_quantification/SALMON_MALE/; for i in *.qc.fq.gz; do; salmon quant -i maleredabalone_index --libType IU -1 *R1_001.qc.fq.gz -2; *R2_001.qc.fq.gz ${i} -o ${i}_quant --seqBias --gcBias --validateMappings; done```. And here is the error message that I receive:. ```[2019-07-29 14:31:12.352] [jointLog] [error] You passed paired-end files; to salmon, but you passed 12 files to --mates1 and 13 files to --mates2.; You must pass the same number of files to both flags; Name : male_salmon_map; User : seboles; Partition : high; Nodes : c11-71; Cores : 24; GPUs : 0; State : FAILED; Submit : 2019-07-29T14:31:01; Start : 2019-07-29T14:31:02; End : 2019-07-29T14:31:13; Reserved walltime : 6-06:00:00; Used walltime : 00:00:11; Used CPU time : 00:00:09; % User (Computation): 54.66%; % System (I/O) : 45.33%; Mem reserved : 2000M/core; Max Mem used : 0.00 (c11-71); Max Disk Write : 0.00 (c11-71); Max Disk Read : 0.00 (c11-71)```. I have gone back and checked the directory containing the PE reads, and; they are all accounted for, so I am a little stumped at the moment. I; appreciate any advice you may have. Happy Monday,. Sara. On Wed, Jul 24, 2019 at 3:04 PM Rob Patro <notifications@github.com> wrote:. > Hi @seboles <https://github.com/seboles> ,; >; > My guess is that the issue is related to this (non-salmon) error appearing; > before each salmon output:; >; > basename: extra operand ‘lightreceptor-1_S114_L005_R1_001.qc.fq.gz’; >; > Try 'basename --help' for more information.; >; >; > it looks like there is an error in the way the paths to the files ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/408#issuecomment-516173395:678,message,message,678,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/408#issuecomment-516173395,1,['message'],['message']
Integrability,"Hi Rob,. I don't have git (don't have root access on the red hat server im on). I downloaded the salmon-master.zip, and then tried running the following:. ```; [bernsteinnj@lngnode1 salmon-master]$ cmake . . -- The C compiler identification is GNU 4.4.7; -- The CXX compiler identification is GNU 4.4.7; -- Check for working C compiler: /usr/bin/cc; -- Check for working C compiler: /usr/bin/cc -- works; -- Detecting C compiler ABI info; -- Detecting C compiler ABI info - done; -- Check for working CXX compiler: /usr/bin/c++; -- Check for working CXX compiler: /usr/bin/c++ -- works; -- Detecting CXX compiler ABI info; -- Detecting CXX compiler ABI info - done; CMake Error at CMakeLists.txt:69 (message):; Salmon requires g++ 4.7 or greater.; ```. I'm trying now with -k 27 with the original build I had. Keep you updated. Best",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/53#issuecomment-203018082:700,message,message,700,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/53#issuecomment-203018082,1,['message'],['message']
Integrability,"Hi Rob,. Thank you for your swift and elaborate response! It would be most satisfying for me to compare your branch with selective-alignment to the other mappers I used. I had some dependency-issues last time I wanted to compile Salmon on my ubuntu on windows system, so a linux executable would be very welcome. Currently, we aim to only map on a limited number of microbial genomes and the abundance estimation is quite important to us. Thank you for your time!; Klaas",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/196#issuecomment-365534279:181,depend,dependency-issues,181,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/196#issuecomment-365534279,1,['depend'],['dependency-issues']
Integrability,"Hi Rob,. Thanks for the clarity regarding the effect of insert size distribution on quantification. That does resolve this issue, and gives me a path going forward using Salmon for this data. However, I am trying to use Salmon for small RNA-Seq data, where the insert size is equal to read length for most reads after adapter trimming. Would it be possible to add a flag to use read length as a proxy for insert size, potentially with a fallback to fldMean/fldSD in the case of full-length, untrimmed reads? This is something I would be willing to contribute myself, if it sounds appropriate. Thanks,; Gautam",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/605#issuecomment-752064194:318,adapter,adapter,318,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/605#issuecomment-752064194,1,['adapter'],['adapter']
Integrability,"Hi Ryan,. The difficulty is, indeed, exactly as you specify. Given a single-end read, one does not know the length of the _fragment_ from which it originates. In this case the ""right"" thing to do (the best thing we can do) is to consider the read as starting / ending a fragment of every possible length allowed by the user-provided fragment length distribution (with the contribution of each possible fragment weighted by the probability of observing a fragment of that length). In order to make this computationally feasible, one would have to do some clever pre-computation and thing a bit more about how to efficiently update the observed GC model (right now, each mapping contributes a single weight to the model, but under the naive implementation in the single-end case, each mapping would contribute different weights to each bin of the observed GC-bias curve, which would slow things down considerably). Also, as you point out, the quality of the correction would depend somewhat on the user providing appropriate parameters for the fragment length distribution mean and standard deviation — but this seems reasonable in the single-end case. That being said, I'm sure there's a way to handle this efficiently, I'd just have to think about it a bit. Regarding your second question; Salmon learns the fragment length distribution in paired-end data, but not with single-end data. Single-end data can provide a little bit of information (e.g. there is in upper bound on fragment lengths that one can infer based on single-end reads based on how far they map from the end of the transcript), but not enough information to reliably infer a fragment length distribution. cc @mikelove in case he has any thoughts on this.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/83#issuecomment-243833424:973,depend,depend,973,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/83#issuecomment-243833424,1,['depend'],['depend']
Integrability,"Hi Ryan,. You're right. This fact is not documented and it should be. I'll update the docs to address this. Using the `A` library type with pre-computed alignments has one additional complication that doesn't arise in the quasi-mapping mode. That is, many aligners offer the user the capability of aligning the reads with a prescribed library type (e.g. TopHat, HISAT, etc.), so that in this case the implied library type depends not only on how the reads map to the underlying transcriptome, but also on the parameters with which the reads were aligned with the upstream alignment tool. . However, I don't suppose this needs to be a ""blocking"" technicality. I'll add this feature to the list for the next minor release.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/79#issuecomment-241603077:422,depend,depends,422,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/79#issuecomment-241603077,1,['depend'],['depends']
Integrability,"Hi again,. Together with Mark Miller (JHPCE's admin) we ran more tests. We verified that `Salmon` does indeed use at least 2 threads so now I'm always requesting 2 from SGE. We also noticed that when the jobs fail due to memory (the actual issue in this thread) they fail after the `There is 1 library` message as shown below for one test:. ```; [2017-04-05 14:28:09.021] [jointLog] [info] parsing read library format; [2017-04-05 14:28:09.035] [jointLog] [info] There is 1 library.; terminate called without an active exception; /cm/local/apps/sge/var/spool/compute-064/job_scripts/420662: line 31: 28651 Aborted (core dumped) /dcl01/lieber/ajaffe/Emily/RNAseq-pipelin; e/Software/Salmon-0.8.2_linux_x86_64/bin/salmon quant -i /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode; .v25.transcripts -p 1 -l ISR -1 ${FILE1} -2 ${FILE2} -o /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test7/${ID}; ```. Files that work well, keep on going:. ```; [2017-04-05 14:30:23.757] [jointLog] [info] parsing read library format; [2017-04-05 14:30:23.767] [jointLog] [info] There is 1 library.; [2017-04-05 14:30:24.378] [jointLog] [info] Loading Quasi index; ```. I don't know if that hint makes you suspect anything in `Salmon`. . Now, for some tests only task 2 runs and it turns out that task 2 has a smaller fastq file than the other 2:. ```bash; $ ls -lh merged_fastq/R1000[1-3]*; -rw-r--r-- 1 lcollado lieber_jaffe 6.2G Feb 20 12:39 merged_fastq/R10001_D2B1WACXX.fastq.gz; -rw-r--r-- 1 lcollado lieber_jaffe 6.3G Feb 20 12:40 merged_fastq/R10001_D2B1WACXX_read2.fastq.gz; -rw-r--r-- 1 lcollado lieber_jaffe 4.6G Feb 20 12:42 merged_fastq/R10002_C29P7ACXX.fastq.gz; -rw-r--r-- 1 lcollado lieber_jaffe 4.7G Feb 20 12:44 merged_fastq/R10002_C29P7ACXX_read2.fastq.gz; -rw-r--r-- 1 lcollado lieber_jaffe 7.1G Feb 20 12:47 merged_fastq/R10003_D19KGACXX.fastq.gz; -rw-r--r-- 1 lcollado lieber_jaffe 7.1G Feb 20 12:50 merged_fastq/R10003_D19KGACXX_read2.fastq.g",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:303,message,message,303,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,1,['message'],['message']
Integrability,"Hi all - this looks like an old version of Trinity. I'd suggest upgrading. For any version of Trinity, you can look at the Dockerfile to see what the; corresponding compatibilities are for versions that get co-installed for a; fully functional package. For example, in the current release, you'll find:. https://github.com/trinityrnaseq/trinityrnaseq/blob/5ce78d2b6d63aaae9fe491408311ebaf158deaa6/Docker/Dockerfile#L235. best,. ~brian. On Fri, Feb 24, 2023 at 1:19 PM Rob Patro ***@***.***> wrote:. > I am not sure how the index here was created, but the actual error; > signifies that you are attempting to quantify the assembled transcripts; > using a recent version of salmon (1.9.0 in this case) against an index; > that was created by a *very old* version of salmon (pre 1.0). This is not; > supported, as the index format completely changed between pre v1.0 and post; > v1.0, and newer versions rely on a completely different data structure.; >; > —; > Reply to this email directly, view it on GitHub; > <https://github.com/COMBINE-lab/salmon/issues/832#issuecomment-1444189059>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/ABZRKX5M6TN6DEQJQCP2AALWZD3TRANCNFSM6AAAAAAVHFUQRA>; > .; > You are receiving this because you were mentioned.Message ID:; > ***@***.***>; >. -- ; --; Brian J. Haas; The Broad Institute; http://broadinstitute.org/~bhaas <http://broad.mit.edu/~bhaas>",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/832#issuecomment-1444289845:1268,Message,Message,1268,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/832#issuecomment-1444289845,1,['Message'],['Message']
Integrability,"Hi all,. Thanks for reporting this. It's strange (and unfortunate), since managing the shared libraries on which the programs depend correctly is supposed to be a major raison d'etre for Bioconda to begin with. I'll try and take a look to see if there is e.g. another version of the SO that can be used for Salmon to resolve this conflict.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/147#issuecomment-324679973:126,depend,depend,126,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/147#issuecomment-324679973,1,['depend'],['depend']
Integrability,"Hi guys,. Which existing dependencies would you like to be able to use? There are some of these libraries that cannot be replaced by already installed variants. Specifically,; - BWA --- since the version that is pulled in and used actually requires we expose certain functionality for our lightweight alignment procedure (though this dependency may go away all together if we deprecate lightweight alignment in favor of quasi-mapping).; - Jellyfish --- here, we require the ability to use jellyfish as a library. Specifically, we rely on some headers that are not installed with the standard package. Perhaps here there could be some synergy with Guillaume on making all of the things Salmon uses part of the standard Jellyfish install, but, at least currently, this isn't the case. The CMake build system already looks for existing versions of the following before fetching them:; - Boost; - tbb; - jemalloc. So, the the remaining guys are `libgff` (which is just some small libraryification of a gff parser that I put together a while ago, I don't know that it's in any package manager --- is it? It doesn't even have an associated install script) and `staden IO lib`. For Staden, I'd be happy to have it look for an existing installation, but there is no FindStaden.cmake that I know of, and I don't really know how to write FindX.cmake files appropriately. However, I'd be happy to learn and / or accept pull requests.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/19#issuecomment-193559957:25,depend,dependencies,25,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/19#issuecomment-193559957,2,['depend'],"['dependencies', 'dependency']"
Integrability,"Hi rob-p,; `gcc -version ` tells me its version `6.3.0` of the GCC compiler. . ```; c+\+ -v; Using built-in specs.; COLLECT_GCC=c++; COLLECT_LTO_WRAPPER=/usr/libexec/gcc/x86_64-alpine-linux-musl/6.3.0/lto-wrapper; Target: x86_64-alpine-linux-musl; Configured with: /home/buildozer/aports/main/gcc/src/gcc-6.3.0/configure --prefix=/usr --mandir=/usr/share/man --infodir=/usr/share/info --build=x86_64-alpine-linux-musl --host=x86_64-alpine-linux-musl --target=x86_64-alpine-linux-musl --with-pkgversion='Alpine 6.3.0' --enable-checking=release --disable-fixed-point --disable-libstdcxx-pch --disable-multilib --disable-nls --disable-werror --disable-symvers --enable-__cxa_atexit --enable-default-pie --enable-cloog-backend --enable-languages=c,c++,objc,java,fortran,ada --disable-libssp --disable-libmpx --disable-libmudflap --disable-libsanitizer --enable-shared --enable-threads --enable-tls --with-system-zlib --with-linker-hash-style=gnu; Thread model: posix; gcc version 6.3.0 (Alpine 6.3.0); ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/162#issuecomment-343658308:205,wrap,wrapper,205,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/162#issuecomment-343658308,1,['wrap'],['wrapper']
Integrability,"Hi, ; I am writing here, because I think this issue is relevant to both @rob-p and @kvittingseerup. I ran my salmon analysis twice with the most recent gencode annotation [https://www.gencodegenes.org/releases/current.html](url) -> PRI. Once with the `--keepDuplicates` option in the indexing and once without (bec I read this post late..). ; When loadind the data into IsoformSwithcAnalyzer the first time (w/o `--keepDuplicates`), I received the following warning message, ""The annotation (count matrix and isoform annotation) contain differences in which isoforms are analyzed... 875 more isoforms than the count matrix..."". Following the run with `--keepDuplicates`, I now receive ""67 more isoforms than the count matrix"". If I am using the `--keepDuplicates` option, what exactly are there 67 isforms?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/214#issuecomment-410512481:466,message,message,466,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/214#issuecomment-410512481,1,['message'],['message']
Integrability,"Hi, I have some kind the same error. I download the prebuild index from refgenie and I got exactly the same error message. . refgenie pull hg38/salmon_sa_index <- I downloaded the 16Gb of the index files. [2020-05-04 21:30:58.648] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2020-05-04 21:30:58.648] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2020-05-04 21:30:58.648] [jointLog] [info] Usage of --validateMappings, without --hardFilter implies use of range factorization. rangeFactorizationBins is being set to 4; [2020-05-04 21:30:58.648] [jointLog] [info] Usage of --validateMappings implies a default consensus slack of 0.2. Setting consensusSlack to 0.2.; [2020-05-04 21:30:58.648] [jointLog] [info] parsing read library format; [2020-05-04 21:30:58.648] [jointLog] [info] There is 1 library.; [2020-05-04 21:30:58.701] [jointLog] [info] Loading Quasi index; Exception : [rapidjson internal assertion failure: IsObject()]; salmon quant was invoked improperly.; For usage information, try salmon quant --help; Exiting. The son files of the index show this;; ls -lrth *json; -rwxrwxrwx 1 usr usr 1007 dic 14 00:41 info.json; -rwxrwxrwx 1 usr usr 96 dic 14 00:44 versionInfo.json. Any idea would be really appreciated,. Kind regards, ; Fer",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/251#issuecomment-623664770:114,message,message,114,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/251#issuecomment-623664770,1,['message'],['message']
Integrability,"Hi, Rob, thanks for the quick reply! By the way, great job on salmon!. Using ./ did fix the issue. About the stdout issue, I'm running:. ~/programs/Salmon-0.7.2_linux_x86_64/bin/salmon quant -i /data/reference/salmon/gencode.grch37.v19/ -r test.fastq --seqBias --gcBias --posBias -p 12 --geneMap /data/reference/salmon/gencode.grch37.v19/geneMap.txt --libType U -o x --writeMappings > out.sam. and not all messages are output to stderr (I'm not using 2> ). The ones starting with ### do, but others end up in out.sam. out.sam starts with:. ESC[1m[2016-09-14 11:37:38.908] [jointLog] [info] parsing read library format; ESC[00mESC[1m[2016-09-14 11:37:38.908] [jointLog] [info] There is 1 library.; ESC[00mESC[1m[2016-09-14 11:37:43.996] [jointLog] [info] Loading Quasi index; ESC[00mESC[1m[2016-09-14 11:37:43.996] [jointLog] [info] Loading 32-bit quasi index; ESC[00mESC[1m[2016-09-14 11:37:43.996] [stderrLog] [info] Loading Suffix Array ; ESC[00mESC[1m[2016-09-14 11:38:06.669] [stderrLog] [info] Loading Transcript Info ; ESC[00mESC[1m[2016-09-14 11:38:12.374] [stderrLog] [info] Loading Rank-Select Bit Array; ESC[00mESC[1m[2016-09-14 11:38:12.444] [stderrLog] [info] There were 95309 set bits in the bit array; ESC[00mESC[1m[2016-09-14 11:38:12.700] [stderrLog] [info] Computing transcript lengths; ESC[00mESC[1m[2016-09-14 11:38:12.700] [stderrLog] [info] Waiting to finish loading hash; ESC[00mESC[1m[2016-09-14 11:39:49.792] [stderrLog] [info] Successfully loaded position hash; ESC[00mESC[1m[2016-09-14 11:39:49.792] [stderrLog] [info] Done loading index; ESC[00mESC[1m[2016-09-14 11:39:49.792] [jointLog] [info] done; ESC[00mESC[1m[2016-09-14 11:39:49.792] [jointLog] [info] Index contained 95309 targets; ESC[00mESC[33mESC[1m[2016-09-14 11:40:18.128] [jointLog] [warning] Fragment GC bias correction is currently only implemented for paired-end libraries. Disabling fragment GC bias correction for this run; ESC[00m@HD VN:1.0 SO:unknown",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/90#issuecomment-247078586:406,message,messages,406,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/90#issuecomment-247078586,1,['message'],['messages']
Integrability,"Hi, Rob.; I've been trying to compile ""salmon"" 1.1.0 from source under Ubuntu 18.04 and managed to get a newer version of ""cmake"" from KitWare, but there are many other dependency problems...",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/500#issuecomment-610578989:169,depend,dependency,169,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/500#issuecomment-610578989,1,['depend'],['dependency']
Integrability,"Hi, thank you for your reply, I prefer to use the pre-built version 1.10.0. * J. Eduardo Martinez-Hernandez*; *PhD Integrative Genomics*. El lun, 5 jun 2023 a las 14:02, Rob Patro ***@***.***>); escribió:. > This *usually* means that the version of the boost library you have was; > not compiled with a C++11-compatible ABI. There is a incompatibility; > between pre C++11 and post C++11 std::string representations, and since; > salmon uses modern C++ (C++14 as of this writing), you need a version of; > boost compiled in a compatible way. How was boost installed on your system?; >; > Of course, if you don't need to compile from source, it's *much* easier; > to install via conda, or to grab the pre-built executable (1.10.0 is; > feature and bugfix identical to 1.10.1).; >; > Best,; > Rob; >; > —; > Reply to this email directly, view it on GitHub; > <https://github.com/COMBINE-lab/salmon/issues/551#issuecomment-1577237260>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AM6EVFLJX45SB67GSQ3RYO3XJYNLBANCNFSM4PG7JFPQ>; > .; > You are receiving this because you commented.Message ID:; > ***@***.***>; >",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/551#issuecomment-1577285952:115,Integrat,Integrative,115,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/551#issuecomment-1577285952,2,"['Integrat', 'Message']","['Integrative', 'Message']"
Integrability,"Hi, you did not say which lab protocol has been used. I assume Illumina Nextera Long-Mate pair protocol? This one gives you RF (reverse&forward) reads but highly contaminated with FR (forward&reverse) reads (ordinary paired-end reads). From normal paired-end sequencing libraries I have just 100% FR reads, as expected (I used `ISF` for salmon).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/206#issuecomment-400077831:30,protocol,protocol,30,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/206#issuecomment-400077831,2,['protocol'],['protocol']
Integrability,"Hi,. If I don't trim the adaptors and still use --ont will I still get correct quantification? Is adaptor trimming very essential? Is there a way I can use salmon without adaptor trimming?. Also, can you please clarify about the secondary alignmenmts if these are included in Salmon or not?. Thanks,; Harsha; ________________________________; From: Feng Yan ***@***.***>; Sent: 08 January 2024 23:30; To: COMBINE-lab/salmon ***@***.***>; Cc: Harshangda Karan Puri ***@***.***>; Author ***@***.***>; Subject: Re: [COMBINE-lab/salmon] Quantification in Alignment mode for Nanopore Data (Issue #903). also interested to know how Salmon uses secondary alignment. Because I found this tutorial https://combine-lab.github.io/salmon-tutorials/2021/ont-long-read-quantification/ [combine-lab.github.io]<https://urldefense.com/v3/__https://combine-lab.github.io/salmon-tutorials/2021/ont-long-read-quantification/__;!!PDiH4ENfjr2_Jw!GTZeAEdMSJcSBTPXhWuSsmLuX2WDzuNuNgqT04lADpRqOWyHssr_JALdqVa1JBOS9RHGRa9M6SeJKoxo6T7o5_O0bvsV-KkgNb45i4uTnGob8fw$> actually includes secondary alignments.; And based on my experience, secondary alignments are used by Salmon, because when I give a BAM before and after removing secondary (-F 256 flag in samtools), the results are different. —; Reply to this email directly, view it on GitHub [github.com]<https://urldefense.com/v3/__https://github.com/COMBINE-lab/salmon/issues/903*issuecomment-1881982972__;Iw!!PDiH4ENfjr2_Jw!GTZeAEdMSJcSBTPXhWuSsmLuX2WDzuNuNgqT04lADpRqOWyHssr_JALdqVa1JBOS9RHGRa9M6SeJKoxo6T7o5_O0bvsV-KkgNb45i4uTEiG0xQE$>, or unsubscribe [github.com]<https://urldefense.com/v3/__https://github.com/notifications/unsubscribe-auth/A3SZAPCLOZYB72ZEIEEXH43YNR6S7AVCNFSM6AAAAABANBCPNSVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMYTQOBRHE4DEOJXGI__;!!PDiH4ENfjr2_Jw!GTZeAEdMSJcSBTPXhWuSsmLuX2WDzuNuNgqT04lADpRqOWyHssr_JALdqVa1JBOS9RHGRa9M6SeJKoxo6T7o5_O0bvsV-KkgNb45i4uTntkMlxE$>.; You are receiving this because you authored the thread.Message ID: ***@***.***>",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/903#issuecomment-1884769339:1968,Message,Message,1968,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/903#issuecomment-1884769339,1,['Message'],['Message']
Integrability,"Hi,; Thank you vey much for explaining the reasons in detail. So, the main challenge in deduplication at the read level is that some reads are aligned to multiple positions, right?. I also have a question regrading the third point. My understanding is that reads that map to the same genomic location and have the same UMI and CB will be treated as PCR duplicates, and only one of such reads will be retained in the deduplication process. Can you elaborate on why ""a UMI from a single gene can come from a range of genomic loci""? Do 3' scRNA-seq protocols also involve CDNA fragmentation?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/574#issuecomment-713083907:546,protocol,protocols,546,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/574#issuecomment-713083907,1,['protocol'],['protocols']
Integrability,Holy cloud-computing charges! I'm sorry to hear about this. We can certainly rate-limit this message. I'll work on fixing this upstream. Sorry for the trouble.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/152#issuecomment-328981463:93,message,message,93,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/152#issuecomment-328981463,1,['message'],['message']
Integrability,How do I apply the custom length settings if I am utilizing the wrapper for v1 10x data? I have v1 data that has a 5bp instead of 10bp UMI but everything else is the same. Can i just add `--umiLength 5`?; Data:; [https://support.10xgenomics.com/single-cell-gene-expression/datasets/1.1.0/cd14_monocytes](url),MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/247#issuecomment-418803087:64,wrap,wrapper,64,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/247#issuecomment-418803087,1,['wrap'],['wrapper']
Integrability,"I actually think that (as @mr-c points out), the `config.h` file isn't necessary with newer versions of Jellyfish. I'm removing the dependency upstream.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/19#issuecomment-195644865:132,depend,dependency,132,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/19#issuecomment-195644865,1,['depend'],['dependency']
Integrability,I am also seeing this. The most highly estimated and shortest isoform of KIT has no supporting read but a TPM of 40. ![image](https://github.com/COMBINE-lab/salmon/assets/631218/f250e8cd-3f99-4fcb-8032-bc1897ca9322). Using DRAGEN RNA version 4.2.4 which I think wraps Salmon. In any of your BAM files?,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/133#issuecomment-2048928795:262,wrap,wraps,262,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/133#issuecomment-2048928795,1,['wrap'],['wraps']
Integrability,"I am trying to quantify these data at the transcript level which is why the number of features is this big. For the PBMC3k I was trying with a transcript to gene --tgMap but was still seeing the same error. I realized I forgot to update the path to the run.sh script when calling the 0.12.0 binary (I updated the path to the binary but no to the script). When running the wrapper in the 0.12.0 folder I could succesfully run alevin on the CD14 dataset, with or without the --forceCells 4000 flag. I tried to run alevin-0.12.0 on the PBMC 3k dataset but I got the same error. I am now trying to run it on all the FACS-sorted samples and I will see how that goes. I feel this is happening slightly inconsistently (although very frequently). Notably, it either happens after `Clearing EqMap; Might take some time.` or `Starting Import of the gene count matrix of size 5344x167268.`. I have had it happen once in the middle of the `Analyzed xxx cells (yy% of all)` phase. I just managed to succesfully process the CD19+ B cells from the 10x v1 dataset, I'll attempt to process the other FACS sorted samples overnight and let you know how it went. Thank you",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/328#issuecomment-445109075:372,wrap,wrapper,372,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/328#issuecomment-445109075,1,['wrap'],['wrapper']
Integrability,"I appreciate to your answer.; Thanks a lot; ; ; Ki-Wook Lee; Student; Department of Integrative Biotechnology; College of Biotechnology & Bioengineering; Sungkyunkwan University; Biotechnology and Bioengineering Building 2, Rm 62156; 2066 Seobu-ro, Jangan-gu, Suwon, Gyeonggi, 16419, Republic of Korea; Tel: +82-10-5580-1770 Fax:+82-31-290-7870; ; -----Original Message-----; From: ""Anthony S. ***@***.***>; To: ***@***.***>;; Cc: ***@***.***>; ***@***.***>;; Sent: 2021-06-09 (수) 05:16:26 (GMT+09:00); Subject: Re: [COMBINE-lab/salmon] Quant.sf index issue (#640); ; Not affiliated with the Salmon team, but since you didn't get an answer here...; When building an index with transcriptomes from Gencode, you should pass the flag ""--gencode"" to the indexer. This allows salmon to split the record names on the | character and gives you the expected ""ENST00000456328.2 or ENSG00000223972.5"" style names.; —; You are receiving this because you authored the thread.; Reply to this email directly, view it on GitHub, or unsubscribe.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/640#issuecomment-857337814:84,Integrat,Integrative,84,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/640#issuecomment-857337814,2,"['Integrat', 'Message']","['Integrative', 'Message']"
Integrability,I can try that later today. Does your list of installed dependencies look different?. The thing that's strange about this is that the main motivation for releasing 1.10 was a discovery of an intermittent segfault due to UB at exactly this spot. But that was resolved in the associated tagged pufferfish upstream and checked further with both valgrind and asan.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463629042:56,depend,dependencies,56,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463629042,1,['depend'],['dependencies']
Integrability,"I do have an explanation. The data was generated using an rRNA-depletion protocol. From what I've seen elsewhere, it turns out that the mapping rate is expected to be 30-40% because many of the reads are intronic, or otherwise map outside the known transcriptome, since you have all non-rRNA (PolyA+ and PolyA-). Hope that helps! Happy Easter!. > On Mar 27, 2016, at 09:31, Rob Patro notifications@github.com wrote:; > ; > Great; one thing I did notice is that the mapping rates for this data seemed surprisingly low. I don't think that's related to the NaNs you were seeing, but it did catch my attention, since we don't normally see mapping rates like that. Is there a hypothesis why this may be the case (e.g. it's not just Salmon's quasi-mapping, the mapping rate remains the same (or even becomes lower) when I use an aligner)?; > ; > —; > You are receiving this because you were mentioned.; > Reply to this email directly or view it on GitHub",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/50#issuecomment-202127752:73,protocol,protocol,73,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/50#issuecomment-202127752,1,['protocol'],['protocol']
Integrability,"I don't know how difficult it would be to use PCRE2, I have never used it directly. Can we write a thin struct wrapper structure that is defined as the boost object by default, but with` #ifdef ` can be implemented by PCRE2 if we wish? (well, if cmake finds pcre2). Keeping with boost, we should also try https://www.boost.org/doc/libs/1_78_0/doc/html/xpressive.html . That does not add a new dependency. Don't know about the speed.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/734#issuecomment-1023366519:111,wrap,wrapper,111,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/734#issuecomment-1023366519,2,"['depend', 'wrap']","['dependency', 'wrapper']"
Integrability,I have the same issue. But doing 'cmake -DFETCH_BOOST=TRUE ..' or 'cmake ..' gives the same error message 'does not appear to contain CMakeLists.txt'. I downloaded version 'salmon-0.12.0_linux_x86_64'.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/139#issuecomment-449017473:98,message,message,98,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/139#issuecomment-449017473,1,['message'],['message']
Integrability,I haven't kept up with khmer so I'm not sure what it does. Can I do something equivalent of this with khmer?. ```; mkfifo /tmp/1.fastq && \; mkfifo /tmp/2.fastq && \; samtools sort -n input.cram | samtools fastq -1 /tmp/1.fastq -2 /tmp/2.fastq & salmon -i index -l IU -1 /tmp/1.fastq -2 /tmp/2.fastq -o /tmp/salmon_out && \; mv /tmp/salmon_out && \; rm /tmp/1.fastq && \; rm /tmp/2.fastq; ```. I just want to be able to do these sorts of things without wrapper scripts that obfuscate and complicate things... But maybe a robust bash wrapper is the best way to go.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/29#issuecomment-168534703:453,wrap,wrapper,453,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/29#issuecomment-168534703,2,['wrap'],['wrapper']
Integrability,"I just conda installed salmon fresh. I got error when I ran it. . ```; $ conda create -n salmon salmon; Collecting package metadata (current_repodata.json): done; Solving environment: done. ## Package Plan ##. environment location:~/miniconda3/envs/salmon. added / updated specs:; - salmon. The following NEW packages will be INSTALLED:. _libgcc_mutex conda-forge/linux-64::_libgcc_mutex-0.1-conda_forge; _openmp_mutex conda-forge/linux-64::_openmp_mutex-4.5-1_gnu; bzip2 conda-forge/linux-64::bzip2-1.0.8-h7f98852_4; icu conda-forge/linux-64::icu-64.2-he1b5a44_1; jemalloc conda-forge/linux-64::jemalloc-5.2.1-h9c3ff4c_5; libgcc-ng conda-forge/linux-64::libgcc-ng-9.3.0-h2828fa1_18; libgomp conda-forge/linux-64::libgomp-9.3.0-h2828fa1_18; libstdcxx-ng conda-forge/linux-64::libstdcxx-ng-9.3.0-h6de172a_18; salmon bioconda/linux-64::salmon-1.4.0-hf69c8f4_0; tbb conda-forge/linux-64::tbb-2021.1.1-h4bd325d_1; zlib conda-forge/linux-64::zlib-1.2.11-h516909a_1010. Proceed ([y]/n)? y. Preparing transaction: done; Verifying transaction: done; Executing transaction: done; #; # To activate this environment, use; #; # $ conda activate salmon; #; # To deactivate an active environment, use; #; # $ conda deactivate. $ conda activate salmon; $ salmon; salmon: symbol lookup error: salmon: undefined symbol: _ZN3tbb8internal24concurrent_queue_base_v818internal_push_moveEPKv; ```. I think this is related with rob-p commented on Sep 22, 2020. ; I have a naive question: Is it possible to fix this in the recipe by adding the problematic dependencies?; I am using centOS 8.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/565#issuecomment-805608173:1532,depend,dependencies,1532,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/565#issuecomment-805608173,1,['depend'],['dependencies']
Integrability,"I just noticed there is something wrong with my input file, sorry for my mistake. . The basic question stays the same: Are unmated reads supported by Alevin? Is there a single-cell protocol that produces 'single-end' files?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/522#issuecomment-632647047:181,protocol,protocol,181,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/522#issuecomment-632647047,1,['protocol'],['protocol']
Integrability,"I just tried it on a fresh docker image of ubuntu 16.04 and am unable to install salmon. After `apt-get install build-essential cmake g++ gcc curl autoconfig libdevsufsort-dev`, `cmake -DFETCH_BOOST=TRUE` passes, but `make install` fails with following output:; ```; [ 6%] Built target liblzma; [ 12%] Built target libbz2; [ 18%] Built target libjemalloc; [ 19%] Performing download step (verify and extract) for 'libdivsufsort'; -- verifying file...; file='/home/salmon-0.10.2/external/libdivsufsort.zip'; -- verifying file... warning: did not verify file - no URL_HASH specified?; -- extracting...; src='/home/salmon-0.10.2/external/libdivsufsort.zip'; dst='/home/salmon-0.10.2/external/libdivsufsort-master'; CMake Error at /home/salmon-0.10.2/libdivsufsort-prefix/src/libdivsufsort-stamp/extract-libdivsufsort.cmake:11 (message):; error: file to extract does not exist:; '/home/salmon-0.10.2/external/libdivsufsort.zip'. CMakeFiles/libdivsufsort.dir/build.make:90: recipe for target 'libdivsufsort-prefix/src/libdivsufsort-stamp/libdivsufsort-download' failed; make[2]: *** [libdivsufsort-prefix/src/libdivsufsort-stamp/libdivsufsort-download] Error 1; CMakeFiles/Makefile2:137: recipe for target 'CMakeFiles/libdivsufsort.dir/all' failed; make[1]: *** [CMakeFiles/libdivsufsort.dir/all] Error 2; Makefile:160: recipe for target 'all' failed; make: *** [all] Error 2; ```; It confuses me, as the error seems to be in the libdevsufsort, which should be installed.; (sorry for all the mess, really)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/250#issuecomment-404455397:824,message,message,824,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/250#issuecomment-404455397,1,['message'],['message']
Integrability,"I mean the additional barcodes you can get with this protocol if people use CITE-seq like approaches, see https://www.10xgenomics.com/solutions/single-cell/. . On 18 June 2019 23:53:55 BST, Avi Srivastava <notifications@github.com> wrote:; >Hi @pinin4fjords ,; >; >Thanks for the question, do you mean the longer UMI/CB length or you; >are talking about some other feature ?; >; >; >; >-- ; >You are receiving this because you were mentioned.; >Reply to this email directly or view it on GitHub:; >https://github.com/COMBINE-lab/salmon/issues/381#issuecomment-503341361. -- ; Sent from my Android device with K-9 Mail. Please excuse my brevity.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/381#issuecomment-503442543:53,protocol,protocol,53,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/381#issuecomment-503442543,1,['protocol'],['protocol']
Integrability,"I realize my mistake, I was confused by the error message.; Pseudoaligment seems to work now. [...]; [2018-08-03 20:13:23.083] [jointLog] [info] Computed 312565 rich; equivalence classes for further processing; [2018-08-03 20:13:23.083] [jointLog] [info] Counted 120065952 total; reads in the equivalence classes; [2018-08-03 20:13:23.084] [jointLog] [warning] Found 9775 reads with `N`; in the UMI sequence and ignored the reads.; Please report on github if this number is too large; [2018-08-03 20:13:23.084] [jointLog] [info] Mapping rate = 63.2442%. [2018-08-03 20:13:23.084] [jointLog] [info] finished quantifyLibrary(); [2018-08-03 20:13:26.208] [alevinLog] [info] Starting optimizer. ERROR: Txp to Gene Map not found for 203027 transcripts. Exiting(salmon). I just have a problem with my tx2gene file. Here is the head of my file:. ENST00000013125	MAP4K5; ENST00000215368	EFNA2; ENST00000200453	PPP1R15A; ENST00000202028	EPB41L1; ENST00000204679	GNPTG; ENST00000175506	ASNS; ENST00000215574	CDC34; ENST00000167106	VASH1; ENST00000074304	INPP4A; ENST00000055077	RFC2. The transcript ID is probably not consistent with the one from the; alevin output. However, I used to perform some pseudo-alignments using; salmon on bulk RNAseq with the same transcriptome references and the; same tx2gene file that I used here (postprocessed using R) and it work.; What could be wrong here? Could you provide me with an example of the; tx2gene file needed?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/264#issuecomment-410337209:50,message,message,50,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/264#issuecomment-410337209,1,['message'],['message']
Integrability,"I suspect you're running this on a Mac, correct? ; I had the same issue, Salmon would index for the better part of a day, use ~30 gb of swap space, then die (killed 9 message). The versionInfo.json error is slightly misleading, most likely what happened is that the indexing didn't finish and since that file is only created if it finishes correctly, that's the error you get.; Running the indexing with the same code, with similar resources completed on our AWS node so I wonder if this is a Mac specific problem...",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/559#issuecomment-738480434:167,message,message,167,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/559#issuecomment-738480434,1,['message'],['message']
Integrability,"I tested changing the parameters, and I am still getting the same error message:. ```; [2021-07-08 16:05:50.979] [alevinLog] [info] Done importing white-list Barcodes; [2021-07-08 16:05:50.979] [alevinLog] [error] Wrong whitelist provided; Please check https://salmon.readthedocs.io/en/develop/alevin.html#whitelist; ```. However, I will look into the other information and see if I can understand what is happening. I can also test not using a white list and see if that changes the number to be something like an order of magnitude different that what I would expect from the other sample. So, I will post an update when I can run alevin without an error message, and try to give some sense of the results that are quantified.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/682#issuecomment-877303669:72,message,message,72,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/682#issuecomment-877303669,2,['message'],['message']
Integrability,"I think that's the right binary. You can check the sha256 sum:. ```; rob at Robs-MacBook-Pro in ~/Salmon-0.8.2_macOX_10.12; $ shasum -a256 bin/salmon; 7be1c57e1a83956cc9c18f75aed3b2376c93595de7dec215041fe3065528b527 bin/salmon; ```. You can also check the libraries that `salmon` is seeing:. ```; rob at Robs-MacBook-Pro in ~/Salmon-0.8.2_macOX_10.12; $ otool -L bin/salmon; 	bin/salmon:; 	/usr/lib/libz.1.dylib (compatibility version 1.0.0, current version 1.2.8); 	/usr/lib/libSystem.B.dylib (compatibility version 1.0.0, current version 1238.0.0); 	/usr/lib/libbz2.1.0.dylib (compatibility version 1.0.0, current version 1.0.5); 	@rpath/libtbbmalloc_proxy.dylib (compatibility version 0.0.0, current version 0.0.0); 	@rpath/libtbbmalloc.dylib (compatibility version 0.0.0, current version 0.0.0); 	@rpath/libtbb.dylib (compatibility version 0.0.0, current version 0.0.0); 	/usr/lib/libc++.1.dylib (compatibility version 1.0.0, current version 307.4.0); ```. but, again, the library of interest with respect to this message (jemalloc) is linked statically. Out of curiosity, is this message a warning or error (i.e. does salmon run or return a non-zero exit code). The message you're seeing is actually expected if jemalloc was compiled without debug mode turned off (because apple did some funny business with the allocator in OS X 10.12).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/103#issuecomment-294852033:1018,message,message,1018,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/103#issuecomment-294852033,3,['message'],['message']
Integrability,I tried re-installing salmon today after seeing your message. A simple `conda install salmon` worked for me this time. I don't know why it was giving me an error back then and not one now though....,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/724#issuecomment-1137154359:53,message,message,53,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/724#issuecomment-1137154359,1,['message'],['message']
Integrability,"I tried this again today with salmon 1.2.1 on CentOS 8 (with cmake 3.17.1). This time it could find libtbb but it still could not find Staden IO_LIB and libgff. In addition for it to use Boost169 it was necessary to modify the CmakeLists.txt file like so. ```; --- CMakeLists.txt.dist 2020-04-21 22:31:07.000000000 -0700; +++ CMakeLists.txt 2020-06-08 17:13:23.295499154 -0700; @@ -419,6 +419,8 @@; find_package(Boost 1.59.0 COMPONENTS iostreams filesystem system timer chrono program_options); message(""BOOST_INCLUDEDIR = ${BOOST_INCLUDEDIR}""); message(""BOOST_LIBRARYDIR = ${BOOST_LIBRARYDIR}""); +message(""Forcing Boost_FOUND to TRUE""); +set(Boost_FOUND TRUE); message(""Boost_FOUND = ${Boost_FOUND}""); endif(); ; ```. and to invoke cmake with:. ```; module load cmake; module load io_lib; module load libgff; module load libtbb; mkdir build; cd build; cmake \; -DCMAKE_VERBOSE_MAKEFILE:BOOL=ON \; -DBOOST_LIBRARYDIR=/usr/lib64/boost169 \; -DBOOST_INCLUDEDIR=/usr/include/boost169 \; -DBoost_NO_SYSTEM_PATHS=ON \; .. 2>&1 | tee cmake_2020_06_08.log; ```; Inkscape was built using cmake a couple of weeks ago on the same system and the -D flags for Boost in the cmake invocation were sufficient, there was no need to modify its CMakeLists.txt. Perhaps you might to compare that CMakeLIsts.txt with salmon's to see why theirs works and salmon's does not. I reiterate my plea for salmon's cmake file to accept some form of ROOT_LIBGFF, ROOT_LIBSTADEN, and ROOT_LIBTBB. Those modules ; were all defined but cmake could only figure out TBB this time, and for all I know it won't next time around (since it failed to do so for no apparent reason on CentOS 7). Salmon is a useful program but it has so far failed to build using existing libraries on this OS (unless extraordinary measures were applied) for CO 6, 7, and now 8! This is the information it had to work with:. ```; echo $PATH; /usr/common/modules/el8/x86_64/software/libgff/1.2-CentOS-vanilla/bin:/usr/common/modules/el8/x86_64/software/io_lib/1",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-640962684:495,message,message,495,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-640962684,4,['message'],['message']
Integrability,"I tried using Homo_sapiens.GRCh38.94.chr_patch_hapl_scaff.gtf.gz for the annotation file and ftp://ftp.ensembl.org/pub/release-94/fasta/homo_sapiens/cdna/Homo_sapiens.GRCh38.cdna.all.fa.gz to build the index but got a similar error. Here are the logs (I modified the salmon log a bit because it didn't have the error message that printed to stdout). [alevin.log](https://github.com/COMBINE-lab/salmon/files/3224429/alevin.log); [salmon_quant.log](https://github.com/COMBINE-lab/salmon/files/3224440/salmon_quant.log). One curious thing that I noticed:. ```; Index contained 175,775 targets; ...; ERROR: Txp to Gene Map not found for 175775 transcripts; ```; It seems to not be finding any of the transcripts? This was also the case for the gencode attempt that I made previously.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/336#issuecomment-496258062:317,message,message,317,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/336#issuecomment-496258062,1,['message'],['message']
Integrability,"I tried wrapping the code around alphaSum but it didn't work.; I also set digammaMin to 1e-9 but no change.; What I find weird is that the following code works... ```cpp; #include <boost/math/special_functions/digamma.hpp>. int main() {; double logNorm = boost::math::digamma(1e-50);; printf(""%f\n"", logNorm);; return logNorm;; }; ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/229#issuecomment-393598770:8,wrap,wrapping,8,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/229#issuecomment-393598770,1,['wrap'],['wrapping']
Integrability,"I was trying to troubleshoot the contemplation period of salmon with monitoring utilities and just stumbled upon this issue upon submitting my own. The failed version check gets buried by the spew of warnings for too short/long transcripts for hg38 mrna.fna in my case. The current behaviour is particularly irritating as I assumed, that `salmon index -h` just runs into a loop accidentally. The check takes multiple minutes to timeout. I am behind a proxy. Please remove the version check by default, as this is not common behaviour of command line tools or anticipated by the user. Or at least please add a verbose message before checking ""Checking for upgrades online..."".",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/277#issuecomment-474388032:617,message,message,617,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/277#issuecomment-474388032,1,['message'],['message']
Integrability,"I'd rather not bundle the dependency. Troubleshooting bundled dependencies is crazy making. The `cmake` script could check that the dependency is satisfied and report an error message if it's not. Or I suppose install the dependency if it's not satisfied. Perhaps that's what you were thinking.; In any case, here's the web site: http://tukaani.org/xz/; and git repository: http://git.tukaani.org/; Here's a GitHub mirror. I don't know whether it's current: https://github.com/nobled/xz",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/45#issuecomment-193941254:26,depend,dependency,26,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/45#issuecomment-193941254,5,"['depend', 'message']","['dependencies', 'dependency', 'message']"
Integrability,"I'm interested in this as well. Note that the (Harvard) inDrops v3 library protocol differs from v2, and is documented here: https://iccb.med.harvard.edu/files/iccb/files/sequencing_indrops_libraries_02_28_18.pdf. For reference, bcbio supports inDrops and Dropseq barcodes, but it'd be great it if we could better integrate this workflow with alevin: https://bcbio-nextgen.readthedocs.io/en/latest/contents/pipelines.html",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/339#issuecomment-474551107:75,protocol,protocol,75,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/339#issuecomment-474551107,2,"['integrat', 'protocol']","['integrate', 'protocol']"
Integrability,I'm still experiencing this `cmake` error:. ```; -- extracting... [tar xfz]; CMake Error: Problem with archive_write_finish_entry(): Can't restore time; CMake Error: Problem extracting tar: /var/tmp/sjackman/salmon20160307-4399-1vksuoo/salmon-0.6.0/external/libdivsufsort.zip; -- extracting... [error clean up]; CMake Error at /var/tmp/sjackman/salmon20160307-4399-1vksuoo/salmon-0.6.0/libdivsufsort-prefix/src/libdivsufsort-stamp/extract-libdivsufsort.cmake:33 (message):; error: extract of; '/var/tmp/sjackman/salmon20160307-4399-1vksuoo/salmon-0.6.0/external/libdivsufsort.zip'; failed; ```. Here's a gist of the logs:; https://gist.github.com/sjackman/2bbfcf212c555fb20505#file-02-make-L397-L404,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/10#issuecomment-193515060:463,message,message,463,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/10#issuecomment-193515060,1,['message'],['message']
Integrability,"I'm surprised that the `@rpath` showed up, when I thought that we had disabled that. So long as `brew install salmon` works on Mac, I wouldn't worry about downloading and installing dependencies. Leave that chore to the package manager.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/70#issuecomment-239604008:182,depend,dependencies,182,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/70#issuecomment-239604008,1,['depend'],['dependencies']
Integrability,"I've addressed this in a recent [commit](https://github.com/COMBINE-lab/salmon/commit/05859ef8412687be14de5084f3b1e0e688fb3e76). Now, `version`, `help`, `cite` and `swim` will print to stdout, while other normal logging messages will print to stderr. Basically, if it was specifically requested by the user, send it to stdout; otherwise send it to stderr.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/148#issuecomment-378405708:220,message,messages,220,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/148#issuecomment-378405708,1,['message'],['messages']
Integrability,"I've run into this (or a similar) issue attempting to install Salmon on the UC Berkeley HPC cluster. Iconv was present within one of our Python installs, but that didn't seem to have the header files, so I installed libiconv/1.16 thinking this was a dependency issue. Unfortunately this didn't seem to help. Any guidance would be greatly appreciated. Here is my build script to the point of failure:; ```sh; #!/bin/sh ; MODULE_HOME=/clusterfs/vector/home/groups/software/sl-7.x86_64; PACKAGE_NAME=salmon; GITHUB_URL=https://api.github.com/repos/COMBINE-lab/salmon/releases/latest; VERSION=$(curl -s $GITHUB_URL | \; grep '""tag_name"":' | \; cut -d : -f 2,3 | \; tr -d \"",v | \; xargs); LATEST_RELEASE=$(curl -s $GITHUB_URL | \; grep '""tarball_url""' | \; cut -d : -f 2,3 | \; tr -d \"", | \; xargs); module load gcc/7.4.0 cmake/3.15.1 boost/1.70.0-gcc libiconv/1.16; export CC=`which gcc`; export CXX=`which c++`. cd $MODULE_HOME; mkdir -p source/$PACKAGE_NAME/$VERSION; INSTALL_DIR=$MODULE_HOME/modules/$PACKAGE_NAME/$VERSION; mkdir -p $INSTALL_DIR; mkdir -p modfiles/$PACKAGE_NAME. cd source/$PACKAGE_NAME/$VERSION; wget $LATEST_RELEASE -O - | tar -xz --strip-components 1; cmake -DBOOST_ROOT=/global/software/sl-7.x86_64/modules/gcc/7.4.0/boost/1.70.0-gcc -DCMAKE_INSTALL_PREFIX=$INSTALL_DIR; make; ```; And the tail of the output from make:. ```; creating: /clusterfs/vector/home/groups/software/sl-7.x86_64/source/salmon/1.5.1/scripts/../external/pufferfish-salmon-v1.5.1/tests/compile_tests/; inflating: /clusterfs/vector/home/groups/software/sl-7.x86_64/source/salmon/1.5.1/scripts/../external/pufferfish-salmon-v1.5.1/tests/compile_tests/int128_numeric_limits.cpp ; -- fetch PUFFERFISH exit code 0; -- Found ZLIB: /usr/lib64/libz.so (found version ""1.2.11"") ; -- Performing Test Iconv_IS_BUILT_IN; -- Performing Test Iconv_IS_BUILT_IN - Failed; CMake Error at /global/home/groups/consultsw/sl-7.x86_64/modules/cmake/3.15.1/share/cmake-3.15/Modules/FindPackageHandleStandardArgs.cmake:137 (message",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/453#issuecomment-862737315:250,depend,dependency,250,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/453#issuecomment-862737315,1,['depend'],['dependency']
Integrability,"I've tried to reproduce the issue in docker by using the Build-Depends that are used in Debian:. $ docker pull debian:testing; $ docker run -it debian:testing; $ echo ""deb-src http://deb.debian.org/debian unstable main"" > /etc/apt/sources.list.d/10-debsrc.list; $ apt update; $ apt upgrade; $ apt build-dep salmon; $ wget https://github.com/COMBINE-lab/salmon/archive/refs/tags/v1.10.0.tar.gz; $ tar xaf v1.10.0.tar.gz; $ cd salmon-1.10.0; $ mkdir build && cd build; $ cmake -DNO_IPO=TRUE ..; $ make -j8; make -j8; [ 3%] Built target ksw2pp_sse4; [ 6%] Built target ntcard; [ 15%] Built target twopaco; [ 18%] Built target graphdump; [ 21%] Built target ksw2pp_sse2; [ 27%] Built target ksw2pp_basic; [ 43%] Built target salmon_core; [ 67%] Built target puffer; [ 68%] Built target ksw2pp; [ 69%] Built target UnitTestsMain; [ 73%] Built target alevin_core; [ 74%] Linking CXX executable unitTests; /usr/bin/ld: /usr/lib/x86_64-linux-gnu/libcurl.a(libcurl_gnutls_la-psl.o): in function `Curl_psl_destroy':; (.text+0x21): undefined reference to `psl_free'; /usr/bin/ld: /usr/lib/x86_64-linux-gnu/libcurl.a(libcurl_gnutls_la-psl.o): in function `Curl_psl_use':; (.text+0xbc): undefined reference to `psl_latest'; /usr/bin/ld: (.text+0x157): undefined reference to `psl_builtin'; /usr/bin/ld: /usr/lib/x86_64-linux-gnu/libcurl.a(libcurl_gnutls_la-version.o): in function `curl_version':; (.text+0x129): undefined reference to `BrotliDecoderVersion'; /usr/bin/ld: (.text+0x16f): undefined reference to `ZSTD_versionNumber'; /usr/bin/ld: (.text+0x1e3): undefined reference to `idn2_check_version'; /usr/bin/ld: (.text+0x20e): undefined reference to `psl_get_version'; /usr/bin/ld: /usr/lib/x86_64-linux-gnu/libcurl.a(libcurl_gnutls_la-version.o): in function `curl_version_info':; (.text+0x386): undefined reference to `idn2_check_version'; /usr/bin/ld: (.text+0x3ad): undefined reference to `BrotliDecoderVersion'; /usr/bin/ld: (.text+0x3b8): undefined reference to `BrotliDecoderVersion'; /usr/bin/ld: (.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463708855:63,Depend,Depends,63,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463708855,1,['Depend'],['Depends']
Integrability,"If I install Salmon Binary:; [100%] Building CXX object src/CMakeFiles/salmon.dir/BAMUtils.cpp.o; [100%] Linking CXX executable salmon; /usr/bin/ld: ../../external/install/lib/libstaden-read.a(libstaden_read_la-open_trace_file.o): in function `find_file_url':; open_trace_file.c:(.text+0xf4e): warning: the use of `tempnam' is dangerous, better use `mkstemp'; during IPA pass: icf; lto1: internal compiler error: Segmentation fault; Please submit a full bug report,; with preprocessed source if appropriate.; See <file:///usr/share/doc/gcc-9/README.Bugs> for instructions.; lto-wrapper: fatal error: /usr/bin/c++ returned 1 exit status; compilation terminated.; /usr/bin/ld: error: lto-wrapper failed; collect2: error: ld returned 1 exit status; make[2]: *** [src/CMakeFiles/salmon.dir/build.make:421: src/salmon] Error 1; make[1]: *** [CMakeFiles/Makefile2:659: src/CMakeFiles/salmon.dir/all] Error 2; make: *** [Makefile:163: all] Error 2",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/592#issuecomment-734935424:578,wrap,wrapper,578,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/592#issuecomment-734935424,2,['wrap'],['wrapper']
Integrability,"If i use the smaller set of barcodes, then I progress further. However, I still receive an error message (and there no **quants_mat_rows.txt** file):. ```; [2021-07-13 13:59:07.109] [alevinLog] [info] Total 0.00 UMI after deduplicating.; [2021-07-13 13:59:07.109] [alevinLog] [info] Total 0 BiDirected Edges.; [2021-07-13 13:59:07.109] [alevinLog] [info] Total 0 UniDirected Edges.; [2021-07-13 13:59:07.134] [alevinLog] [info] Finished optimizer; /var/spool/slurmd/job3050767/slurm_script: line 23: 10494 Floating point exception../../Ref_Generation/salmon-1.5.1_linux_x86_64/bin/salmon alevin -l ISF --chromium -1 $R1 -2 $R2 -i $REF -p 4 -o $ID --tgMap $MAP --whitelist $CBWL. ```. If the barcode is on the opposite read, then I am not sure if I should really be using the reverse or reverse complement (possibly even for the full barcode list)?. However, for the sake of this discussion, I will now test not providing any white list. If that works, then I will close the ticket again. **Update (7/14/2021)**: I have added the full log file here: [cluster_log.log](https://github.com/COMBINE-lab/salmon/files/6819402/cluster_log.log)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/682#issuecomment-879497561:97,message,message,97,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/682#issuecomment-879497561,1,['message'],['message']
Integrability,"If you are not building from source, then `0.10.1` is identical to `0.10.0`, there are no new features, behavior changes, or bug fixes. The entire purpose of `0.10.1` is to fix the source build on specific versions of Debian linux using system versions of dependencies. Thus, the pre-compiled versions of `0.10.0` and `0.10.1` (which are not build on a Debian system and which downloads and builds the dependencies directly) will not have any differences.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/841#issuecomment-1542672313:256,depend,dependencies,256,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/841#issuecomment-1542672313,2,['depend'],['dependencies']
Integrability,"If you wish to retain duplicate transcripts, please use the `--keepDuplicates` flag; [2020-12-26 10:49:06.448] [puff::index::jointLog] [info] Replaced 151,122,967 non-ATCG nucleotides; [2020-12-26 10:49:06.448] [puff::index::jointLog] [info] Clipped poly-A tails from 1,829 transcripts; wrote 231443 cleaned references; [2020-12-26 10:49:09.969] [puff::index::jointLog] [info] Filter size not provided; estimating from number of distinct k-mers; [2020-12-26 10:49:40.159] [puff::index::jointLog] [info] ntHll estimated 2628436199 distinct k-mers, setting filter size to 2^36; Threads = 12; Vertex length = 31; Hash functions = 5; Filter size = 68719476736; Capacity = 2; Files:; salmon-decoy-sa-index/ref_k31_fixed.fa; --------------------------------------------. **So using gffread I created a transcripts.fa file:; gffread -w salmon_transcripts.fa -g GRCh38.primary_assembly.genome.fa gencode.v36.annotation.gtf. using this new transcripts.fa I run again the above mentioned salmon index with decoy command, but the warning message was shown up again:**. [Step 1 of 4] : counting k-mers; [2020-12-26 11:30:08.799] [puff::index::jointLog] [warning] Entry with header [ENST00000473810.1], had length less than equal to the k-mer length of 31 (perhaps after poly-A clipping); [2020-12-26 11:30:08.951] [puff::index::jointLog] [warning] Entry with header [ENST00000603775.1], had length less than equal to the k-mer length of 31 (perhaps after poly-A clipping); [2020-12-26 11:30:10.751] [puff::index::jointLog] [warning] Entry with header [ENST00000632684.1], had length less than equal to the k-mer length of 31 (perhaps after poly-A clipping); [2020-12-26 11:30:12.936] [puff::index::jointLog] [warning] Entry with header [ENST00000543745.1], had length less than equal to the k-mer length of 31 (perhaps after poly-A clipping); [2020-12-26 11:30:13.188] [puff::index::jointLog] [warning] Entry with header [ENST00000415118.1], had length less than equal to the k-mer length of 31 (perhaps after po",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/214#issuecomment-751354493:14971,message,message,14971,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/214#issuecomment-751354493,1,['message'],['message']
Integrability,"In Salmon v1.2.0, `--posBias` is listed in the help message without any hints on being ""experimental"". At the same time, the read the docs manual still lists it as an experimental feature. Does someone know if it is now considered as a stable feature?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/474#issuecomment-615160502:52,message,message,52,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/474#issuecomment-615160502,1,['message'],['message']
Integrability,"In my experience it is normal to get a **much lower** transcriptome mapping rate for rRNA-depleted samples vs polyA-selected samples. . I'm getting ~21% mapping rate (using Gencode 41 transcripts) on human brain RNAseq samples sequenced several years ago using rRNA-depletion protocol (older Illumina Ribo Zero kits).; I was initially shocked (being used to seeing >90% mapping rates from HISAT2/STAR for these samples) but it turns out **this is normal** for this kind of samples, in this context.; HISAT2 reports 96% mapping rate on the same samples, but QC metrics (rnaseqc) for these HISAT2 alignments (using the same Gencode annotation) show a **65% intronic rate** and a **%23.5 exonic rate** (the rest being intergenic etc). So the _exonic rate_ is getting close to what Salmon is showing (and what it measures), thus I suppose it makes sense to see such a low mapping rate for Salmon on these samples.; (kallisto also reports ~21% pseudoaligned percentage on the same samples). I am only a bit disappointed that when I use `--validateMappings` with decoy sequences (whole genome) added, the mapping rate goes down to about **16.7%** -- as some reads map better to the decoys in that case (partially intronic reads etc.), but I also see a `higher number of fragments entirely discarded because of alignment score` (higher `num_fragments_filtered_vm` and much higher `num_alignments_below_threshold_for_mapped_fragments_vm`).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/779#issuecomment-1474291747:276,protocol,protocol,276,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/779#issuecomment-1474291747,1,['protocol'],['protocol']
Integrability,"In terms of an intermediate update:. **Setting 1**:. _Command 1_:; `/path/to/salmon alevin -l ISF --chromium -1 $R1 -2 $R2 -i $REF -p 4 -o $ID --tgMap $MAP`; _End of Log 1_:; ```; [2021-07-13 20:12:34.651] [alevinLog] [info] Starting white listing of 814 cells; [2021-07-13 20:12:34.651] [alevinLog] [info] Starting to make feature Matrix; [2021-07-13 20:12:34.654] [alevinLog] [info] Done making feature Matrix; [2021-07-13 20:12:35.447] [alevinLog] [info] Finished white listing; [2021-07-13 20:12:36.158] [alevinLog] [info] Finished optimizer; 0.0408521	8.9925e-05	0.000114595	636780	18682.9	; 0.0290163	6.61624e-05	0.000111685	230922	8010.3	; ```; _Size of quants_mat_rows.txt 1_: 814 lines/barcodes. **Setting 2:**:; _Command 1_:; `/path/to/salmon alevin -l ISR --chromium -1 $R1 -2 $R2 -i $REF -p 4 -o $ID --tgMap $MAP`; _End of Log 1_:; ```; [2021-07-14 09:51:38.564] [alevinLog] [info] Starting white listing of 814 cells; [2021-07-14 09:51:38.564] [alevinLog] [info] Starting to make feature Matrix; [2021-07-14 09:51:38.566] [alevinLog] [info] Done making feature Matrix; [2021-07-14 09:51:39.347] [alevinLog] [info] Finished white listing; [2021-07-14 09:51:39.541] [alevinLog] [info] Finished optimizer; [2021-07-14 09:51:39.564] [jointLog] [warning] NOTE: Read Lib [[ ../Reads/5309-CT-2_S01_L005_R1_001.fastq.gz, ../Reads/5309-CT-2_S01_L005_R2_001.fastq.gz]] :. Greater than 5% of the fragments disagreed with the provided library type; check the file: 5309-CT-2/lib_format_counts.json for details. 0.0408521	8.9925e-05	0.000114595	636780	18682.9	; 0.0290163	6.61624e-05	0.000111685	230922	8010.3	; ```; _Size of quants_mat_rows.txt 1_: 814 lines/barcodes. Technically, this means that the program ran without generating an error message, but this seems strange to me. So, I think I would prefer to keep the issue open a little bit longer.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/682#issuecomment-880273749:1743,message,message,1743,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/682#issuecomment-880273749,1,['message'],['message']
Integrability,"Including '^' didn't change the speed, and '$' can't be added as there are extra bases (not in protocol spec) at end which can vary in number.; ```; real 1m19.392s; user 9m38.357s; sys 0m4.176s; ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/734#issuecomment-1013381545:95,protocol,protocol,95,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/734#issuecomment-1013381545,1,['protocol'],['protocol']
Integrability,Interesting. One thing that changed is that we finally upgraded the Docker image used in our continuous integration server from CentOS5 to CentOS6; I wonder if that might cause some portability issues. Could you try installing via Bioconda to see if that executable gives you the same trouble?,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/232#issuecomment-394752905:104,integrat,integration,104,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/232#issuecomment-394752905,1,['integrat'],['integration']
Integrability,"Is salmon suggesting this is stranded?. `Detected a *potential* strand bias > 1% in an unstranded protocol check the file: 142-salmon-quant/lib_format_counts.json for details`. . The libraries are generated using the [smart-seq2](http://www.nature.com/nmeth/journal/v10/n11/full/nmeth.2639.html) protocol which as far I know does not retain strand information. From the article . ""Currently, Smart-seq2 is limited to poly(A)+ RNAs and does not retain strand or molecule information, although it is compatible with partial-molecule counting.""",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/144#issuecomment-319669636:98,protocol,protocol,98,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/144#issuecomment-319669636,2,['protocol'],['protocol']
Integrability,"It appears that you're trying to index the entire mm9 genome using salmon. Both salmon and rapmap are designed to work with a smaller sequence space such as what you would find in a transcriptome. Your log file shows that salmon processes 615,000,000 bases from the genome and then aborts. Depending on how many transcripts are in your feature file, a human transcriptome [might be 5-10X smaller](http://seqanswers.com/forums/showthread.php?t=5298).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/49#issuecomment-197862096:290,Depend,Depending,290,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/49#issuecomment-197862096,1,['Depend'],['Depending']
Integrability,"It depends what type of ""replicates"" these are. If these are biological replicates, then they should _definitely_ be run separately. Biological replicates contain crucial information about the variability of expression that can be expected in a given condition, and all downstream differential expression tools will use this information. If these are ""technical"" replicates, then there should be little harm in quantifying them together (of course, then one has a 2 condition experiment with only 1 biological replicate per-condition ... which is a big problem if one wishes to analyze e.g. differential expression).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/190#issuecomment-400080695:3,depend,depends,3,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/190#issuecomment-400080695,1,['depend'],['depends']
Integrability,"It does run with each of the two files separately, but when I try the command with the double redirect I get a message like the one below for many/all[?] of the sequences in the reference and quant.sf is empty (except the header). ```; [2020-10-12 17:05:47.406] [jointLog] [warning] Transcript XM_024446103.1 appears in the reference but did not appear in the BAM; ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/271#issuecomment-707347734:111,message,message,111,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/271#issuecomment-707347734,1,['message'],['message']
Integrability,"It doesn’t have a problem with a single bam file. Which is the reason make; me wonder maybe my command is wrong.; Sure, I can share some of the bam files later today. On Thu, Mar 21, 2024 at 4:48 PM Alex D Hill ***@***.***>; wrote:. > Can you head any of the bam files? The fact that they are all *.txt.bam; > seems suspiciously like they are renamed text files.; >; > Does this happen if you run a single bam file at once?; >; > Would also be helpful to fill out the rest of the missing info requested; > (To Reproduce, Expected Behavior, Desktop, etc.); >; > —; > Reply to this email directly, view it on GitHub; > <https://github.com/COMBINE-lab/salmon/issues/920#issuecomment-2013705067>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AHJBWLH4NQP66UEUFSFESXDYZNBRHAVCNFSM6AAAAABFBYUNKOVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZDAMJTG4YDKMBWG4>; > .; > You are receiving this because you authored the thread.Message ID:; > ***@***.***>; >",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/920#issuecomment-2013709916:936,Message,Message,936,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/920#issuecomment-2013709916,1,['Message'],['Message']
Integrability,"It is possible to output gene counts directly, but using `tximport` is the preferred and officially supported method. The reason for this is that the gene-level aggregation built into salmon is _per-sample_, that is each sample is aggregated to the gene level independently. On the other hand, `tximport` considers all samples in an experiment to determine e.g. the average expressed length of a gene over all samples. This leads to better aggregation. Likewise, `tximport` (specifically via `tximeta`) provides a nice interface to track and propagate reference annotation provenance, which ultimately leads to more reproducible analyses.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/437#issuecomment-1535065239:519,interface,interface,519,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/437#issuecomment-1535065239,1,['interface'],['interface']
Integrability,"It's still not working. If I type ./bin/salmon I get:. salmon(68460,0x7fffdb32f3c0) malloc: **\* malloc_zone_unregister() failed for 0x7fffdb325000; version : 0.7.1. So maybe it's working okay but it's still printing the error message.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/103#issuecomment-259472964:227,message,message,227,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/103#issuecomment-259472964,1,['message'],['message']
Integrability,"Just chiming in, we have bulk RNA-seq data using a NuGen protocol that has the UMI (for paired end data) in the index read. This is very common in the DNA-seq circles so not a one-off protocol. Would be nice if UMIs could be used for PE reads in distinguishing duplicates.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/108#issuecomment-277223659:57,protocol,protocol,57,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/108#issuecomment-277223659,2,['protocol'],['protocol']
Integrability,Just here to upvote support for inDrop v2 protocol 👍,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/339#issuecomment-464872433:42,protocol,protocol,42,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/339#issuecomment-464872433,1,['protocol'],['protocol']
Integrability,"Looks like I have some sort of conflict going on:. UnsatisfiableError: The following specifications were found to be in conflict:; - libboost -> libcxx >=4.0.1 -> clangdev ==5.0.0 -> llvmdev ==5.0.0; - libcxx 4.0.0* -> clangdev ==4.0.0 -> llvmdev ==4.0.0; Use ""conda info <package>"" to see the dependencies for each package. [https://sites.google.com/site/ummslogos/_/rsrc/1489610858836/home/apple-icon-76x76.png]. Javier E. Irazoqui, PhD; Associate Professor; Department of Microbiology and Physiological Systems; UMass Medical School. 368 Plantation Street; Albert Sherman Center; Room AS8.1053; Worcester, MA 01605. (774) 455-3797; Skype: javierirazoqui. Confidentiality Notice:; This e-mail message, including any attachments, is for the sole use of the intended recipient(s) and may contain confidential, proprietary and privileged information. Any unauthorized review, use, disclosure or distribution is prohibited. If you are not the intended recipient, please contact the sender immediately and destroy or permanently delete all copies of the original message. On Feb 11, 2018, at 11:01 PM, Rob Patro <notifications@github.com<mailto:notifications@github.com>> wrote:. I can't seem to reproduce this locally (OSX 10.13.1). However, what happens if you try:. > conda install salmon=0.9.1. do you see this version as available? Does it try to install it?. —; You are receiving this because you authored the thread.; Reply to this email directly, view it on GitHub<https://github.com/COMBINE-lab/salmon/issues/194#issuecomment-364824034>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AiohHaDPT6VtnW3toOd9kEKLLo2Zjvvcks5tT7e0gaJpZM4SAonB>.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/194#issuecomment-364941997:294,depend,dependencies,294,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/194#issuecomment-364941997,3,"['depend', 'message']","['dependencies', 'message']"
Integrability,Maybe SLURM is killing your job because of too less memory allocation and the error message is just really wired?,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/271#issuecomment-415887826:84,message,message,84,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/271#issuecomment-415887826,1,['message'],['message']
Integrability,"Maybe it is a little off-topic, but here is the code for the v3 sample that ran without generating error messages:. ```; ID=5k_pbmc_v3. R1a=../Reads/5k_pbmc_v3_S1_L001_R1_001.fastq.gz; R1b=../Reads/5k_pbmc_v3_S1_L002_R1_001.fastq.gz; R1c=../Reads/5k_pbmc_v3_S1_L003_R1_001.fastq.gz; R1d=../Reads/5k_pbmc_v3_S1_L004_R1_001.fastq.gz. R2a=../Reads/5k_pbmc_v3_S1_L001_R2_001.fastq.gz; R2b=../Reads/5k_pbmc_v3_S1_L002_R2_001.fastq.gz; R2c=../Reads/5k_pbmc_v3_S1_L003_R2_001.fastq.gz; R2d=../Reads/5k_pbmc_v3_S1_L004_R2_001.fastq.gz. TYPE=10xV3; #for MAP, download from UCSC Table Browser, and remove 1st line (and then manually add SARS-COV-2 genes); MAP=../../Ref_Generation/SARS_COV_2-hg38_RefSeq_2column.txt; REF=../../Ref_Generation/SARS_COV_2-hg38_salmon; CBWL=/net/isi-dcnl/ifs/user_data/Seq/Chromium_data/3M-february-2018.txt. ../../Ref_Generation/salmon-1.5.1_linux_x86_64/bin/salmon alevin -l ISR --chromium -1 $R1a $R1b $R1c $R1d -2 $R2a $R2b $R2c $R2d -i $REF -p 4 -o $ID --tgMap $MAP --whitelist $CBWL; ```. That v3 white list is even **larger** than the v2 white list:. ```; cwarden$ wc -l /net/isi-dcnl/ifs/user_data/Seq/Chromium_data/3M-february-2018.txt; 6794880 /net/isi-dcnl/ifs/user_data/Seq/Chromium_data/3M-february-2018.txt; ```. So, that is part of why I was confused. However, before I start running the analysis with the shorter set of barcodes unique for this sample, here are the commands that I believe you were asking about. ```; cwarden$ wc -l ../CellRanger/5309-CT-2/outs/raw_feature_bc_matrix/barcodes.tsv; 737280 ../CellRanger/5309-CT-2/outs/raw_feature_bc_matrix/barcodes.tsv; cwarden$ wc -l ../CellRanger/5309-CT-2/outs/filtered_feature_bc_matrix/barcodes.tsv; 9974 ../CellRanger/5309-CT-2/outs/filtered_feature_bc_matrix/barcodes.tsv; ```. I would prefer to have an option where I could potentially conclude the cell count is different than provided by CellRanger. . However, I will at least check to confirm this solves the problem with the error message that I am seei",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/682#issuecomment-879347665:105,message,messages,105,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/682#issuecomment-879347665,1,['message'],['messages']
Integrability,"Modified the CMakeLists.txt file to use dynamic libraries unconditionally, edited that section down to:. `set (Boost_USE_STATIC_LIBS OFF); `; Changed the CMakeLists.txt to try everything I could think of and then finally force the issue:. ```; set(Boost_ADDITIONAL_VERSIONS ""1.57"" ""1.57.0"" ""1.59.0"" ""1.60.0"" ""1.61.0"" ""1.62"" ""1.63"" ""1.64"" ""1.65"" ""1.66""); find_package(Boost 1.57 COMPONENTS iostreams filesystem system thread timer chrono program_options); message(""Boost_FOUND 1.57 = ${Boost_FOUND}""); find_package(Boost 1.57.0 COMPONENTS iostreams filesystem system thread timer chrono program_options); message(""BOOST_INCLUDEDIR = ${BOOST_INCLUDEDIR}""); message(""BOOST_LIBRARYDIR = ${BOOST_LIBRARYDIR}""); message(""Boost_FOUND 1.57.0 = ${Boost_FOUND}""); set(Boost_FOUND ""1""); message(""Boost_FOUND FORCED = ${Boost_FOUND}""); include(ExternalProject); ```; This emits:; ```. -- Could NOT find Boost; Boost_FOUND 1.57 = 0; -- Could NOT find Boost; BOOST_INCLUDEDIR = /usr/include/boost157; BOOST_LIBRARYDIR = /usr/lib64; Boost_FOUND 1.57.0 = 0; Boost_FOUND FORCED = 1; BOOST INCLUDE DIR = /usr/include/boost157; BOOST INCLUDE DIRS = /usr/include/boost157; BOOST LIB DIR = /usr/lib64; BOOST LIBRARIES = ; ```; That at least allowed cmake to complete when it was run with:. `nice scl enable devtoolset-4 '~/bin/cmake -DCMAKE_VERBOSE_MAKEFILE:BOOL=ON -DBoost_NO_BOOST_CMAKE=BOOL:ON -DBOOST_LIBRARYDIR=/usr/lib64 -DBOOST_INCLUDEDIR=/usr/include/boost157 ../CMakeLists.txt' >try_cmake.log 2>&1 &; `. Then tried to build it. ```; cd ..; nice scl enable devtoolset-4 'make' >build_2018_06_13d.log 2>&1 &. ```. It failed at this command because of missing boost symbols in a link operation, my reading is that the command does not include anything to link boost libraries. So telling cmake where the libraries are, where the include files are, and that boost was found was not sufficient. There must be some other set of symbols which need to be defined. `/opt/rh/devtoolset-4/root/usr/bin/c++ -pthread -ftree-ve",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/236#issuecomment-397025719:455,message,message,455,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/236#issuecomment-397025719,5,['message'],['message']
Integrability,"My preference would be to throw a warning if any reads are shorter than the; kmer length and throw an error if all are. So if any reads are less then; k-mer length report ""Warning: x% of reads were found to be less than k used; to build index. Consider rebuilding index with smaller k. Minimum read size; found was [min read size]"" and then halt execution if x% is 100%. Would; that sound reasonable?. Thanks,. Kieran. On 8 February 2016 at 14:25, Rob Patro notifications@github.com wrote:. > Hi @kieranrcampbell https://github.com/kieranrcampbell,; > ; > Indeed, such reads will be un-mappable. The only tricky question here is; > at which point we should (1) do nothing (2) issue a warning (3) issue an; > error. Since the reads may not all be of the same size (perhaps the user; > has quality-trimmed the reads first and not opted to discard the short; > ones), it's possible we may see some reads too short to consider, but; > others would not be. We could choose arbitrary cutoffs (warning if greater; > than 1,000 such reads and an error if greater than 1,000,000), but this; > will, of course, depend on how large the input data set is. Anyway, I agree; > that we should notify the user of this and will be happy to add it; do you; > have any suggestions on the default behavior?; > ; > —; > Reply to this email directly or view it on GitHub; > https://github.com/COMBINE-lab/salmon/issues/41#issuecomment-181394180.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/41#issuecomment-181396844:1101,depend,depend,1101,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/41#issuecomment-181396844,1,['depend'],['depend']
Integrability,"NC00337-001|LINC00337|1302|l""..., 8191) = 8191; read(4, ""\0\0\0\0ENST00000377728.7|ENSG000001""..., 8191) = 8191; read(4, ""|z\0\0\0\0\0\0\0ENST00000470648.5|ENSG0""..., 8191) = 8191; read(4, [1m[2017-04-05 16:40:33.297] [stderrLog] [info] Loading Transcript Info ; [00mread(4, ""35271.1|ENSG00000234546.3|OTTHUM""..., 8191) = 8191; read(4, ""00005018.1|UBE4B-003|UBE4B|2299|""..., 8191) = 8191; read(4, ""ding|x\0\0\0\0\0\0\0ENST00000468348.1|E""..., 8191) = 8191; read(4, ""005558.1|MTOR-001|MTOR|8677|prot""..., 8191) = 8191; read(4, ""rotein_coding|x\0\0\0\0\0\0\0ENST000004""..., 8191) = 8191; read(4, ""|\177\0\0\0\0\0\0\0ENST00000439324.2|ENSG0""..., 8191) = 8191; read(4, ""36.1|OTTHUMG00000009500.2|OTTHUM""..., 8191) = 8191; read(4, ""G00000175147.11|OTTHUMG000000020""..., 8191) = 8191; read(4, ""rotein_coding|}\0\0\0\0\0\0\0ENST000004""..., 8191) = 8191; read(4, ""ed_transcript|z\0\0\0\0\0\0\0ENST000004""..., 8191) = 8191; read(4, ""1|549|processed_transcript|{\0\0\0\0""..., 8191) = 8191; read(4, ""0006250.3|CROCC-002|CROCC|3931|p""..., 8191) = 8191; read(4, ""nscript|y\0\0\0\0\0\0\0ENST00000466151.""..., 8191) = 8191; read(4, ""R4|536|processed_transcript|q\0\0\0""..., 8191) = 8191; read(4, "".13|OTTHUMG00000002712.2|OTTHUMT""..., 8191) = 8191; read(4, ""0375079.6|ENSG00000158816.15|OTT""..., 8191) = 8191; ```. (First 500 lines, job is running well). ## Next steps. We are hoping that this info will give you an idea on what could be the source of the problem. Maybe `Salmon` requires a newer version of its dependencies than those that we have installed at JHPCE. . Under a scenario where `Salmon` doesn't change (and it's not a dependency issue), we could try running `Salmon` with increasing amounts of memory until we find a point where it doesn't fail for any of our samples (fastq files go to to 13 GB per read in a read pair, so 26 GB total for this particular dataset). We know that 90 GB total memory works, but like I've said before it's a pretty inefficient use of our cluster resources. Best,; Leo",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:170218,depend,dependencies,170218,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,2,['depend'],"['dependencies', 'dependency']"
Integrability,No worries - and that is exactly what I thought could be possible :-). Just out of curiosity - how would Salmon currently handle if half of a read could be quasi-mapped to a transcript but the second half did not fit anywhere (due to it being very low quality or sequencing adapter contamination)?,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/150#issuecomment-353287536:274,adapter,adapter,274,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/150#issuecomment-353287536,1,['adapter'],['adapter']
Integrability,No worries. I've had issues with grabbing Jellyfish from the existing URL depending on the network setup as well. I may just copy that tarball to a GitHub artifact an have the makefile pull from GitHub instead. --Rob,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/5#issuecomment-110493426:74,depend,depending,74,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/5#issuecomment-110493426,1,['depend'],['depending']
Integrability,"Oh wow; I had no idea about libgff :). Regarding Jellyfish, there's not a source ""change"" required upstream, rather the fact that I seem to require the `config.h` file that is not installed during the ""normal"" Jellyfish install process. I don't know if you have any idea how one might get around that. Regarding staden, thanks for brining this to my attention. It will probably take a bit for me to wrap my head around the right way to access this information in CMake, but I'll see what I can manage to cobble together on that front (I really wish there was something better, with a less horrendous ""language"" than CMake, but nothing I know of exists that works nearly as well ""out of the box"").",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/19#issuecomment-195436157:399,wrap,wrap,399,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/19#issuecomment-195436157,1,['wrap'],['wrap']
Integrability,"Oh, I should've pushed my PR sooner!; Thanks!; I'll take a look how it compares to what I did. ; One thing to note is that it'd be useful to be able to specify the length of the CB - we use 8 bp in our slightly-adapted CEL-Seq2 protocol.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/269#issuecomment-418579796:228,protocol,protocol,228,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/269#issuecomment-418579796,1,['protocol'],['protocol']
Integrability,"Ok, I pushed a commit to develop that wraps this in try/catch (and also tries to print out the relevant value of the argument from the context). Please let me know if (1) this averts the uncaught exception and (2) what argument to digamma is triggering this strange behavior :)!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/229#issuecomment-393610533:38,wrap,wraps,38,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/229#issuecomment-393610533,1,['wrap'],['wraps']
Integrability,"Ok, salmon V1.0.0 finished in 5H 15 min, so about 5 times faster, the exact same library and parameters, and achieved almost the same mapping rate (85.1058% with V1.2.0 vs 84.6341% with V1.0.0) attaching log. I must add I did not trim this library for adapters nor quality, nor did anything to it. Just mapped as is. But fastQC showed excellent levels of quality even at the ends and no or minimal adapter content. ; Also no changes have been done one my OS other than regular updates, but still Ubuntu 18.04. I don't remember any specific changes I've done to it. ; Pearson's correlation in transcript abundance (isoform lelvel) is 0.9984013. Spearman's is 0.9899048. ; Also, I did checked that salmon was actually using 4 threads in both cases, and it was fully using those.; [salmon_quant.log](https://github.com/COMBINE-lab/salmon/files/4707443/salmon_quant.log)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/527#issuecomment-636447127:252,adapter,adapters,252,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/527#issuecomment-636447127,2,['adapter'],"['adapter', 'adapters']"
Integrability,"Ok, thank you very much.; The problem I had was RAM availability. I enlarged it for 48 and it works.; However, to quantify I had another problem.; I use this command line and I increase to 56 RAM. srun ./salmon-1.5.2_linux_x86_64/bin/salmon quant -i salmon_index \; -l A \; -1 ERR3537668_1.fastq.gz \; -2 ERR3537668_2.fastq.gz \; -o transcripts_DecoyQuant \; --validateMappings \; --numBootstraps 100 \; --gcBias \; --seqBias\; -p 12. And I got this error message:; [2021-11-08 14:35:28.348] [jointLog] [info] Finished Bootstrapping; ERROR: Could not create the directory [""transcripts_quant""]. Please check; that. But actually, it was created.; I really don't understand the message error. Best wishes,; Luciana. On Fri, Nov 5, 2021 at 5:56 PM Rob Patro ***@***.***> wrote:. > Hi @lubios <https://github.com/lubios>,; >; > This suggests that the machine was not able to allocate enough memory to; > perform the requested operation. I would try the following things in order; > to see if they fix the issue. First, try quantifying without the; > decoy-aware index. This doesn't provide the benefits of the decoy sequence,; > but it will ensure that this is, in fact, the problem you are having. If; > that works, try building the decoy-aware index with the --sparse; > parameter. This will build the sparse index instead of the dense index,; > which is a bit smaller and may therefore fit in RAM on the machine where; > you are doing quantification.; >; > Best,; > Rob; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/COMBINE-lab/salmon/issues/717#issuecomment-962058307>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/ADRT5CUYGXBSY3UOX24RTYDUKQLETANCNFSM5HOIMSQQ>; > .; > Triage notifications on the go with GitHub Mobile for iOS; > <https://apps.apple.com/app/apple-store/id1477376905?ct=notification-email&mt=8&pt=524675>; > or Android; > <https://play.google.com/store/apps/details?id",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/717#issuecomment-963995631:456,message,message,456,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/717#issuecomment-963995631,2,['message'],['message']
Integrability,"Ok, when I attempt the build the way you say above, I get the following error during CMake:. ```; -- fetch PUFFERFISH exit code 127; CMake Error at CMakeLists.txt:317 (message):; Could not fetch pufferfish source [fetchPufferfish.sh returned exit code; 127]. -- Configuring incomplete, errors occurred!; See also ""/salmon-1.10.0/build/CMakeFiles/CMakeOutput.log"".; ```. It seems `wget`, `curl` and `unzip` were missing, and I had to install them. After that, I was able to build and install. At that point, I was able to reproduce the issue! So, it seems to me the underlying problem is coming from one of the upstream dependencies (i.e. libraries being linked to). I will try see if I can find the offender. In general, we like to statically link salmon for exactly this reason. Outside of package systems with which I am familiar (e.g. conda), we don't have a lot of experience in specifying dependent package version constrains, which I believe to be at fault here.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463973824:168,message,message,168,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463973824,3,"['depend', 'message']","['dependencies', 'dependent', 'message']"
Integrability,"On 11/04/2020 01:04, Rob Patro wrote:; > I saw no performance regressions, so 1.2.0 is built without the ; > offending flag. Thanks for the heads up. Hi, Rob. Thanks for fixing the problem so quickly!. Tony. -- ; Minke Informatics Limited, Registered in Scotland - Company No. SC419028; Registered Office: 3 Donview, Bridge of Alford, AB33 8QJ, Scotland (UK); tel. +44(0)19755 63548 http://minke-informatics.co.uk; mob. +44(0)7985 078324 mailto:tony.travis@minke-informatics.co.uk",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/500#issuecomment-612423808:317,Bridg,Bridge,317,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/500#issuecomment-612423808,1,['Bridg'],['Bridge']
Integrability,"One fast way using pseudo-alignments should be Kallisto+[Manta|Pizzly], but I haven't tried that myself. We decided to go with full transcriptome alignments instead and integrated EricScript into bcbio. We'd still be interested in something more modern, though.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/52#issuecomment-280827732:169,integrat,integrated,169,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/52#issuecomment-280827732,1,['integrat'],['integrated']
Integrability,"Pinging @k3yavi / @DongzeHE here in case they have an idea of what would be used for this protocol. If we know the fragment geometry, I imagine we could just use the custom geometry flag.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/878#issuecomment-1753070571:90,protocol,protocol,90,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/878#issuecomment-1753070571,1,['protocol'],['protocol']
Integrability,"Right, the issue seems to be that the right binary is not getting created. My (re)compilation using the same script you shared above seems to be giving different help.; ```; alevin-specific Options:; -v [ --version ] print version string; -h [ --help ] produce help message; -o [ --output ] arg Output quantification directory.; -p [ --threads ] arg (=1) The number of threads to use; concurrently.; --tgMap arg transcript to gene map tsv file; --dropseq Use DropSeq Single Cell protocol for; the library; --chromiumV3 Use 10x chromium v3 Single Cell; protocol for the library.; --chromium Use 10x chromium v2 Single Cell; protocol for the library.; --gemcode Use 10x gemcode v1 Single Cell protocol; for the library.; --celseq Use CEL-Seq Single Cell protocol for; the library.; --celseq2 Use CEL-Seq2 Single Cell protocol for; the library.; ```. May I suggest removing the `CMakeCache.txt` file from the build folder of salmon and running `make -j 4 install` again. After recompilation using the `salmon` binary inside the `bin` folder should ideally give you the above updated help. However, If it doesn't resolve after that, I am compiling a linux binary and will share it to you to be used directly.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/325#issuecomment-443518366:266,message,message,266,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/325#issuecomment-443518366,7,"['message', 'protocol']","['message', 'protocol']"
Integrability,"Rob,. 	I let you know on the forum page, but just ot make sure it worked and I was ; able to index my transcriptome. Thank you!. Best wishes,; Rich; > On Apr 17, 2018, at 9:44 AM, Rob Patro <notifications@github.com> wrote:; > ; > Hi Rich,; > ; > The issue with pre-compiled OSX binaries is that they are difficult to make portable across OSX versions. This is why we strongly suggest installing Salmon (especially for OSX) through Bioconda. This greatly eases installation and updating, and doesn't require admin privileges. On OSX, you can try the following:; > ; > $ conda config --add channels conda-forge; > $ conda config --add channels bioconda; > $ conda create -n salmon salmon=0.9.1; > ; > This should take care of all relevant dependencies as well as e.g. library locations and placement. Could you please give this a try and let me know if it works for you?; > ; > Best,; > Rob; > ; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub, or mute the thread.; > . Richard A. Friedman, PhD; Associate Research Scientist,; Biomedical Informatics Shared Resource; Herbert Irving Comprehensive Cancer Center (HICCC); Lecturer,; Department of Biomedical Informatics (DBMI); Room 825; Irving Cancer Research Center ; Columbia University Herbert and Florence Irving Medical Center; 1130 St. Nicholas Ave; New York, NY 10032; (212)851-4765 (voice); raf4@cumc.columbia.edu. http://www.columbia.edu/~raf4/index.html. “Will there still be ""Classics Illustrated” by the time I have children? I cannot; imagine raising kids without ""Classics Illustrated” .” -Rose Friedman, age 20",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/215#issuecomment-382031768:738,depend,dependencies,738,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/215#issuecomment-382031768,1,['depend'],['dependencies']
Integrability,"Rob,; Rob,. Thank you. It worked. I was able to make my index without error messages. Best wishes,; Rich",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/215#issuecomment-382031294:76,message,messages,76,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/215#issuecomment-382031294,1,['message'],['messages']
Integrability,Salmon also depends on `libz` when compiling `bwa`.; https://gist.github.com/anonymous/a50569adddca1b8605f7#file-02-make-L118-L120. ```; /usr/bin/gcc-4.8 -c -g -Wall -Wno-unused-function -O2 -DHAVE_PTHREAD -DUSE_MALLOC_WRAPPERS utils.c -o utils.o; utils.c:33:18: fatal error: zlib.h: No such file or directory; #include <zlib.h>; ```,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/45#issuecomment-193959265:12,depend,depends,12,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/45#issuecomment-193959265,1,['depend'],['depends']
Integrability,"Salmon is version 0.9.1. This is happening for lots of samples, the error message is always `Exception : [Failed to read 879238456 bytes from input stream! Read 851443704]` regardless of the fastq files that are provided. . Nothing else too special is going on. It doesn't seem to have this problem with other indexes. Can you try to load and map again with 0.9.1?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/321#issuecomment-442569984:74,message,message,74,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/321#issuecomment-442569984,1,['message'],['message']
Integrability,"Seems to work on some of the test at my end, let me know if its still a problem. The command to use would be; ```; salmon alevin -l ISR --citeseq --barcodeLength 16 --umiLength 10 --end 5 --featureStart 19 --featureLength 21; ```. One thing to note, since it's a 5' protocol, you might have to change `-lISR` to `-lISF` since the 5` protocol expects the single-cell reads from the forward strand, unlike 3' where we expect the reads from reverse. It should not be a problem for the guide/feature barcodes though.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-638444905:266,protocol,protocol,266,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-638444905,2,['protocol'],['protocol']
Integrability,"So I got the data and am trying to repro the issue now (thanks!). Quick question. I noticed in your example command you have `--libType ISF`. However, you have single-end reads, so the appropriate library type would be `SF` (i.e., they can't be ""inward"" facing reads, b/c there is no mate for each read). When I run your command as is, but replace `ISF` as `SF`, my run completes successfully, and I don't get any `errorminEQClassWeight` output. Could you let me know if this makes any difference for you (also, sorry that, apparently, we're not outputting a useful error message when one passes in a paired-end library type with single-end data). edit: Actually, it's even stranger. I noticed that in your command the library type comes *after* the reads to which it refers, but in this case, Salmon will not apply that library type to those reads (which explains why you're not getting a warning message). The restriction that the `--libType` flag comes before the reads it describes is buried in [the docs](http://salmon.readthedocs.io/en/latest/salmon.html#using-salmon), but I definitely need to make that clearer. Anyway, the point is that, in this case, Salmon should apply the ""default"" single-end library type (i.e., `U`) to your reads. So, presumably, that was what was happening when you saw the strange behavior during Gibbs sampling (and is also what was happening when my Gibbs sampling run completed successfully).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-266927204:572,message,message,572,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-266927204,2,['message'],['message']
Integrability,"So after struggling, and failing for a little bit I looked into linuxbrew - its pretty much the best thing ever. I'm honestly not sure what my original issue was derived from but using linuxbrew to install the dependancies and then salmon itself worked perfectly. Honestly much easier to install it this way. . Salmon seems to be working now so I'd say my install issues are resolved. Thanks for your help, and an extra thanks for introducing me to linuxbrew, its going to make my work a lot easier.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/141#issuecomment-314548472:210,depend,dependancies,210,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/141#issuecomment-314548472,1,['depend'],['dependancies']
Integrability,"So, it turns out that with the dependency setup that is pulled in, I can't even get `salmon` to build without `USE_SHARED=TRUE`. I think at this point, it's not clear the segfault is due to something that is broken / can be fixed in the salmon code itself. Rather, it's likely due to a misversioning of a dependency that is pulled in and then linked against. For the time being, I think the options are to do a more ""standard"" build (i.e. like the first one I suggested that pull in only that minimal set of dependencies and let salmon itself statically link the rest), or to try and look at the upstream shared libraries being linked and figure out which of them is misversioned. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1464124885:31,depend,dependency,31,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1464124885,3,['depend'],"['dependencies', 'dependency']"
Integrability,Strange the updated error message has @PG not @pg,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/222#issuecomment-387498610:26,message,message,26,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/222#issuecomment-387498610,1,['message'],['message']
Integrability,"Strangely enough - with the above error message of mine. when I go to the logs directory and look up salmon_quant.log, it has correct info (last line below); ```; [2020-04-22 19:45:18.487] [jointLog] [info] Finished Bootstrapping; ```. And the output directory has a `quant.sf` file and it has all the records I want -- however, salmon is exiting with the above error message",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/512#issuecomment-618027626:40,message,message,40,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/512#issuecomment-618027626,2,['message'],['message']
Integrability,"Strictly speaking, barcodes.tsv**.gz** files are provided. I was viewing the uncompressed file in Notepad++, so I think that number (from the line numbers on the left) should be correct. I will double-check the next time that I am on my work computer. I will test using the smaller number of barcodes. However, unlike the larger file, I think this would be different for every sample. If part of the reason that I wanted to run Alevin is that I wanted an independent quantification (which takes less time), then that may be a notable limitation. However, for whatever reason, this seems to only be an issue with the v2 sample (the v3 sample worked fine). So, I will test that, and I will at least confirm if I see the same error message or not.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/682#issuecomment-878693769:729,message,message,729,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/682#issuecomment-878693769,1,['message'],['message']
Integrability,"Strictly speaking, if I use the barcodes.tsv (decompressed) files from CellRanger (for the _same sample_), I still get the same error message. I get the error message below, with or without ""-1"" at the end of the barcodes:. ```; [2021-07-12 15:55:48.717] [alevinLog] [info] Done importing white-list Barcodes; [2021-07-12 15:55:48.717] [alevinLog] [error] Wrong whitelist provided; Please check https://salmon.readthedocs.io/en/develop/alevin.html#whitelist; ```. If I **don't** use any white list, then I think that should be one possible resolution (mentioned before). However, in case others have a similar question, I have at least temporarily re-opened the ticket. This is the command that I am currently using:. ```; ID=5309-CT-2; R1=../Reads/5309-CT-2_S01_L005_R1_001.fastq.gz; R2=../Reads/5309-CT-2_S01_L005_R2_001.fastq.gz. TYPE=10xV2; #for MAP, download from UCSC Table Browser, and remove 1st line (and then manually add SARS-COV-2 genes); MAP=../../Ref_Generation/SARS_COV_2-hg38_RefSeq_2column.txt; REF=../../Ref_Generation/SARS_COV_2-hg38_salmon; CBWL=../CellRanger/5309-CT-2/outs/raw_feature_bc_matrix/barcodes.tsv. /path/to/salmon-1.5.1_linux_x86_64/bin/salmon alevin -l ISF --chromium -1 $R1 -2 $R2 -i $REF -p 4 -o $ID --tgMap $MAP --whitelist $CBWL; ```. **Is there anything that you think I should change, if I wanted to confirm that I can run the analysis with some sort of white list?**",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/682#issuecomment-878688294:134,message,message,134,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/682#issuecomment-878688294,2,['message'],['message']
Integrability,"Sure --- since, at this point, I don't seem able to reproduce the issue any more. Just for a sanity check, can you md5sum the binary you have? I have `fc39599b6c027eb97bb2f4c7bdd361f3`. Previously, I was getting the same segfault as you, but now it finishes cleanly:. ```; [2016-01-02 13:13:10.643] [jointLog] [info] iteration = 4500 | max rel diff. = 0.0100814; [2016-01-02 13:13:10.703] [jointLog] [info] iteration = 4508 | max rel diff. = 0.00999839; [2016-01-02 13:13:10.714] [jointLog] [info] Finished optimizer; [2016-01-02 13:13:10.714] [jointLog] [info] writing output. [2016-01-02 13:13:10.871] [jointLog] [warning] NOTE: Read Lib [( /dev/fd/63, /dev/fd/62 )] :. Detected a strand bias > 1% in an unstranded protocol check the file: salmon_flux_quant_nofspd/libFormatCounts.txt for details. [2016-01-02 13:13:10.871] [jointLog] [warning] NOTE: Read Lib [( /dev/fd/63, /dev/fd/62 )] :. Greater than 5% of the alignments (but not, necessarily reads) disagreed with the provided library type; check the file: salmon_flux_quant_nofspd/libFormatCounts.txt for details. rob@feynman:~/SoftwareStaging/salmon/build/tmp; ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/34#issuecomment-168413403:717,protocol,protocol,717,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/34#issuecomment-168413403,1,['protocol'],['protocol']
Integrability,"Sure, works for me. Is it possible to add an argument that indicates that the dependencies (like `xz`) should be provided by the host, and any missing dependencies are an error, rather than installing them automatically?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/45#issuecomment-193944377:78,depend,dependencies,78,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/45#issuecomment-193944377,2,['depend'],['dependencies']
Integrability,"Sure; the other thing you may want to consider is what is in your index. For example, if you had a ribo-zero protocol here, you may get a higher mapping rate if you include rRNA. Otherwise, is there a significant degree of intron retention?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/170#issuecomment-341735839:109,protocol,protocol,109,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/170#issuecomment-341735839,1,['protocol'],['protocol']
Integrability,"Thank *you* for providing this software to the community.; BTW, it seems you're making an effort to support externally installed dependencies, for which I'm grateful. I did have to patch around a few bundled deps (e.g. libgff), which are downloaded unconditionally. Many package managers (e.g. FreeBSD ports, Gentoo Portage, MacPorts, pkgsrc, ...) do not allow manual downloads by upstream build systems, for obvious security reasons. I'm hoping it will be possible to avoid all such downloads without patching in the future, by preinstalling and having them discovered by find_package(), as you're already doing for things like bzip2. This will make it easier to package salmon in many of the numerous package managers out there (and eliminate the need for you to install dependencies via cmake). Cheers!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/288#issuecomment-420352699:129,depend,dependencies,129,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/288#issuecomment-420352699,2,['depend'],['dependencies']
Integrability,"Thank @rob-p and @gmarcais, that clarifies it. There's only a handful of reads that seem to fall in this category.; Just a suggestion would it better to have just a one line summary on the amount of reads that are categorised as such and then make quite the error messages?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/701#issuecomment-1422213426:264,message,messages,264,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/701#issuecomment-1422213426,1,['message'],['messages']
Integrability,Thank you for the response. I suspect the same. mapping works fine normally but keeps giving me this error when I follow their protocol. They have this .R file that they say is bundled up with the index. Anyways I am not an expert in the field. Thank you for your quick response.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/833#issuecomment-1451389744:127,protocol,protocol,127,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/833#issuecomment-1451389744,1,['protocol'],['protocol']
Integrability,"Thanks @Gaura! Sounds promising. . Can you clarify what differences you saw between v1/v2 protocols? My understanding was that the only changes were slight differences in barcode positions within the barcode read, ie something that could be handled with different `bc-geometry`, but maybe that's all you meant in terms of differing implementations. Regarding the BC1 and how it could be two sequences for the same sample - this is confusing to explain in text format, but all comes down to the sequential nature of how the cells acquire barcodes in this protocol. We start with a 96-well plate, where each of the top 48 wells contain BOTH an oligo-dT barcode and random hexamer barcode. The samples then get added to each well. Biochemistry happens. Then you pool all the cells together, split them back out into 48 wells again, and each well gets its own BC2. Then repeat for BC3. . So a given transcript may get amplified via one of two amplification primers (oligo-dT or random hexamer), but after that, will get a single BC2 sequence and BC3 sequence added after that. In Fig 1A of the Rosenberg paper, it's as though there isn't _just_ an orange sequence carrying out reverse transcription, there are actually two different (known) sequences associated with different routes of amplification per cell. . The net effect is that a given cell can contain transcripts that have a sequence like this:; AACGTGAT-CTGTAGCC-ACACAGAA. or like this:; GATAGACA-CTGTAGCC-ACACAGAA. where maybe the first sequence was amplified by oligo-dT and the second was amplified via a random hexamer. Because they have the same BC2 and BC3 sequence, and the BC1 sequences match a known pairing, we know they come from the same cell and therefore the data should be merged. . Any lab running these experiments will have a table of known pairings (ie the two barcodes added to each of first 48 wells), so that they can be merged and treated as though they came from the same cell. This can either be handled upstream of sal",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-937918722:90,protocol,protocols,90,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-937918722,2,['protocol'],"['protocol', 'protocols']"
Integrability,"Thanks @Ryan-Zhu for your feedbacks and the suggestion.; I apologize for the trouble you had to face while working with the alevin output.; We will prepare better from the next release and try updating the external dependencies first before making an official release. ; Just wanted to give you the heads up that I have also updated the bug for the scientific notation in the `mtx` format. It's in the develop branch of alevin, if you have time please let me know if it works for you. Thanks again.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/380#issuecomment-502828416:215,depend,dependencies,215,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/380#issuecomment-502828416,1,['depend'],['dependencies']
Integrability,"Thanks @molwizard,. We've added a more informative error message in 0.13.0. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/343#issuecomment-469843098:57,message,message,57,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/343#issuecomment-469843098,1,['message'],['message']
Integrability,"Thanks @rob-p I am glad you and others have found it useful. The actual bbmap.sh and bbduk.sh commands for SE data are in the links to Phil Ewels' multiqc GH. . Just like salmon indexing kmer size choice, one can tinker with the **_```k, hdist, minq and other parameters```_** of bbduk depending on how good/bad the data is. Needless to state, bbduk is the swiss-army-knife for sequence reads quality assessment with whole range of parameters to tweak . https://jgi.doe.gov/data-and-tools/bbtools/bb-tools-user-guide/bbduk-guide/ suggests; ![image](https://user-images.githubusercontent.com/8467214/78302368-a3695980-7508-11ea-990d-4b6e008e3f07.png)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-608105756:286,depend,depending,286,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-608105756,1,['depend'],['depending']
Integrability,"Thanks Jeremy! Yes, that's what I was hinting at with different v1/v2 protocols. From their code, you can see differences in amplicon sequences:; - For v1: 'NNNNNNNNNNIIIIIIIIGTGGCCGATGTTTCGCATCGGCGTACGACTIIIIIIIIATCCACGTGCTTGAGAGGCCAGAGCATTCGIIIIIIII'; - For v2: 'NNNNNNNNNNIIIIIIIIGTGGCCGATGTTTCGCATCGGCGTACGACTIIIIIIIIATCCACGTGCTTGAGACTGTGGIIIIIIII'; where the `IIIIIIII` sequence corresponds to barcode. This is from the pipeline code I mentioned earlier used for [this paper](https://www.nature.com/articles/s41593-021-00872-y). Do you have a the pairing file for the BC1 barcodes? Is it the Supp Table S12 in the Rosenberg paper? It is needed for development and testing.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-951080577:70,protocol,protocols,70,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-951080577,1,['protocol'],['protocols']
Integrability,Thanks Rob - haven't had the message pop up in the last few days. All seems to be running smoothly. Thanks again!,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/152#issuecomment-349358819:29,message,message,29,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/152#issuecomment-349358819,1,['message'],['message']
Integrability,"Thanks a lot @k3yavi for the code.; It doesn't seems to work, I don't think it normalize in a proper way: genes that are highly expressed (RPS/L, ACTB, B2M, etc...) are much more duplicated during the PCR than lowly expressed genes. So lots of reads, but less much counts after quantification (and summarization at the UMI level). So if one sequences deeply any sample, it would affect in a very uneven way both the cells and genes, depending on the level of transcriptional activity of the cell (cycling...) and the level of expression of a given gene. Then subsampling the fastq files before any quantification would be more fair, what do you think?. You can also see the notes on:; https://github.com/theislab/scanpy/pull/340",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/305#issuecomment-435356841:433,depend,depending,433,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/305#issuecomment-435356841,1,['depend'],['depending']
Integrability,Thanks for the detailed report! I wonder if we can bump the max version on salmon 1.4.0. I seem to remember icu 67 conflicting with another dependency before. We'll have to look into that.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/594#issuecomment-736155340:140,depend,dependency,140,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/594#issuecomment-736155340,1,['depend'],['dependency']
Integrability,"Thanks for the recommendation. I'll definitely take a look at it. It is true that we typically suggest that you drop singletons if they are created during e.g. adapter / quality trimming etc.. However, it is also the case that one really may only want to consider very ""light"" quality trimming for RNA-seq data [as suggested by Matt MacManes](https://www.frontiersin.org/articles/10.3389/fgene.2014.00013/full). . If the trimming leads to the loss of a large number of reads, my initial reaction would be to try an understand why. One could always ""re-synchronize"" the singletons by providing them with fake mates, which would cause them to be mapped and treated as orphans during quantification. However, again, it's probably worth understanding why an experiment ends up with a lot of singletons before going through the trouble of accounting for them.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/240#issuecomment-400061755:160,adapter,adapter,160,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/240#issuecomment-400061755,2,"['adapter', 'synchroniz']","['adapter', 'synchronize']"
Integrability,"Thanks for the thorough suggestions. Actually, we fall into the easier case since Salmon does not support mixing single and paired-end reads in a single BAM file. When performing quantification on a single sample, the reads for that sample must follow a uniform library type. For paired-end reads, the BAM file can contain paired-end and single-end alignments (i.e. orphans), but the reads must all have been paired _in sequencing_. Mixing different library types in the BAM file makes it difficult to assess the compatibility of a fragment with the expected library type, especially if fragments from the different library types are expected to exist in a specific ratio in the input. Anyway, my main motivation for having the separate `AS` and `AP` types was to prevent the need to ""peek"" in the file, since, currently, there is not an easy way to peek the first read without opening the first file twice. However, I've decided that the benefit of having the same uniform (and simpler) interface of `A` always representing automatic library type detection is probably worth it, so I've pushed this implementation (commit 6116b2a). So, when the user provides the `A` library type, Salmon will peek into the first record in the BAM file to determine if the fragment was paired in sequencing or not, and will then set the single / paired-end status on that basis. The only corollary to this is that, in alignment-based mode, the `A` flag is not compatible with an input stream (i.e. the input must be a regular file). I will be sure to document this when I update the docs for the version bump.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/79#issuecomment-242399463:988,interface,interface,988,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/79#issuecomment-242399463,1,['interface'],['interface']
Integrability,"Thanks for your patience Rob - I am new to github.; Here are the files you requested. On Sun, Oct 2, 2016 at 1:20 PM, Rob Patro notifications@github.com wrote:. > Hi Amy,; > ; > Unfortunately, when you reply to github via e-mail, it doesn't include; > attachments. Could you please either upload the files here (the github web; > interface supports drag-and-drop), or just send me an email.; > ; > Thanks,; > Rob; > ; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > https://github.com/COMBINE-lab/salmon/issues/96#issuecomment-250982842,; > or mute the thread; > https://github.com/notifications/unsubscribe-auth/AVgEwlnL21CDlhAcRpCEHgNo2UcN-mpPks5qv-fCgaJpZM4KLJrJ; > . ## . Amy K. Voltz, Ph.D.; avoltz@umd.edu; Assistant Clinical Professor; First-Year Innovation & Research Experience; Terrapin Genome Project; Office: Microbiology 1126B; **\* check out our new lab space in BioPsych Building room 2217 ***",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/96#issuecomment-250983890:330,interface,interface,330,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/96#issuecomment-250983890,1,['interface'],['interface']
Integrability,"Thanks sir. On Thu, Nov 21, 2019 at 9:27 PM Rob Patro <notifications@github.com> wrote:. > Hi @shanmugavadivelps <https://github.com/shanmugavadivelps>,; >; > This is because, to properly find and link libiconv, the build requires a; > version of CMake that ships with FindIConv.cmake. So, to build salmon from; > source, you should have at least CMake version 3.12. Internally and on our; > continuous integration servers, we use version 3.15.; >; > Also, I'll mention that it may not be essential to build from source.; > Salmon is available via Bioconda, and a docker image is available via; > DockerHub. Also, we have a pre-compiled binary that should work on many; > linux distributions available under our releases; > <https://github.com/COMBINE-lab/salmon/releases>.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/COMBINE-lab/salmon/issues/453?email_source=notifications&email_token=AN2V7HW3GLUZR52T4BJKOFLQU2VYHA5CNFSM4JP7NHKKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEE2W3DI#issuecomment-557149581>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AN2V7HTVJB3TCKRKDY6YKI3QU2VYHANCNFSM4JP7NHKA>; > .; >. -- ; *Shanmugavadivel, P. S.*; *Scientist (Agricultural Biotechnology),*. *#216, Block A,*; *ICAR-Indian Institute of Pulses Research,*. *Min. of Agriculture & Farmers Welfare,*. *Govt. of India,Kanpur - 208 024.*; *email: shanmugavadivel.ps@icar.gov.in <shanmugavadivel.ps@icar.gov.in>*; *www.iipr.res.in <http://www.iipr.res.in>*",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/453#issuecomment-557774568:403,integrat,integration,403,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/453#issuecomment-557774568,1,['integrat'],['integration']
Integrability,"Thanks, @lgautier! I think that ideally, we will create a github repo for all dependencies, so that we can control such availability issues.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/23#issuecomment-152302062:78,depend,dependencies,78,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/23#issuecomment-152302062,1,['depend'],['dependencies']
Integrability,"Thanks, I usually do not trim reads. I am surprised to see such a difference from version 0.8.3. Do you have a recommendation for --minScoreFraction if I do not trim reads? Or maybe I should go back to NOT using --validateMappings?; For testing purposes, I will try trimming the reads for this sample. Will report back.; Oh, and this sample was prepared by ultra-low RNA input protocol, so the issues of adapter contamination could be present.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-586475673:377,protocol,protocol,377,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-586475673,2,"['adapter', 'protocol']","['adapter', 'protocol']"
Integrability,"Thanks, I was good with linking against external jemalloc after your first reply. Mainly interested in knowing the details of your concern, so thanks for elaborating. We use pkgsrc for most of our CentOS installs, and now I feel safe using devel/jemalloc as a dependency. We also use FreeBSD, and in this case, I just patched out the dependency altogether, since jemalloc is FreeBSD's default allocator. Cheers!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/288#issuecomment-420343097:260,depend,dependency,260,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/288#issuecomment-420343097,2,['depend'],['dependency']
Integrability,"Thanks, Rob. I'll add `unzip` to the build dependencies of `salmon`.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/181#issuecomment-367802780:43,depend,dependencies,43,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/181#issuecomment-367802780,1,['depend'],['dependencies']
Integrability,That sounds like a very good way of doing it :-). I'm sorry I was not clear enough - my question was acutally meant for a single sequence - let me try again:; Lets say we have a read pair where one mate maps fine - but the other mate have a problem - half of it is an adapter (or low quality sequence with to many errors). How would Salmon currently handle this situation where the first half of a sequence (e.g. nt 1-50) could be quasi-mapped to a transcript but the second half (nt 51-100) did not match anywhere? Would the the second half cause the whole sequence to be discarded or would it be enough that the first half matched for it to be considered/counted?,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/150#issuecomment-354955072:268,adapter,adapter,268,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/150#issuecomment-354955072,1,['adapter'],['adapter']
Integrability,"The Klein group has a new inDrop protocol that has the 4 file format as well that should be cropping up in publications sometime soon. Not sure if it is nicked from the 10x folks but it is:. ```; {; ""read1"": ""(?P<name>[^\\s]+).*\\n(?P<seq>.*)\\n\\+(.*)\\n(?P<qual>.*)\\n"",; ""read2"": ""(.*)\\n(?P<CB1>.*)\\n(.*)\\n(.*)\\n"",; ""read3"": ""(.*)\\n(?P<SB>.*)\\n(.*)\\n(.*)\\n"",; ""read4"": ""(.*)\\n(?P<CB2>.{8})(?P<MB>.{6})\\n(.*)\\n(.*)\\n""; }; ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/108#issuecomment-269662717:33,protocol,protocol,33,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/108#issuecomment-269662717,1,['protocol'],['protocol']
Integrability,"The current behavior, which I think is the most reasonable for now, is to keep logging messages to stderr, even if they are not errors. This lets us use stdout for output which may need to be redirected to other programs (e.g. mapping results).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/55#issuecomment-245804636:87,message,messages,87,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/55#issuecomment-245804636,1,['message'],['messages']
Integrability,"The issue relates to the error message, so maybe I will close the issue in terms of being able to run the program without generating the error message. However, I think something still doesn't seem right, and I thought I should make that clear. <table>; <tbody>; <tr>; <th align=""center"">Method</th>; <th align=""center"">SRR13313130</th>; <th align=""center"">10x_pbmc_5k</th>; </tr>; <tr>; 	 <td align=""left"">CellRanger</td>; <td align=""center"">9,974 cells</td>; <td align=""center"">4,956 cells</td>; </tr>; <tr>; 	 <td align=""left"">STARsolo</td>; <td align=""center"">7,587 cells</br><i>(Summary.csv)</i></td>; <td align=""center"">4,586 cells</br><i>(Summary.csv)</i></td>; </tr>; <tr>; 	 <td align=""left"">Alevin</td>; <td align=""center""><b>814 cell barcodes?</b></td>; <td align=""center""> 856,224 cell barcodes</td>; </tr>; <tr>; 	 <td align=""left"">Kallisto</td>; <td align=""center"">79,254 cells</br><i>(BUSpaRse)</i></td>; <td align=""center"">47,598 cells</br><i>(BUSpaRse)</i></td>; </tr>; <tr>. </tbody>; </table>. For Alevin and Kallisto, I am not so worried about the exact values for cell barcodes (versus cells), since I was expecting extra work was needed to estimate a cell count from a distribution of measurements for each cell barcode. However, the number of cell barcodes should be larger than the number of cells, and that seems to match for everything except Alevin for this sample (SRR13313130). In other words, for sample, I think that this is the command that generates the fewest errors/warnings/notes:. `/path/to/salmon alevin -l ISF --chromium -1 $R1 -2 $R2 -i $REF -p 4 -o $ID --tgMap $MAP`. However, I think the cell barcode count is too small. **Is there anything else that you would recommend trying?**",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/682#issuecomment-882751952:31,message,message,31,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/682#issuecomment-882751952,2,['message'],['message']
Integrability,The languages of both autotools and CMake are pretty terrible. I actually like the Make language; I think it gets a bad wrap. Other than `config.h` was there any other files of Jellyfish that were missing from the install that you needed?,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/19#issuecomment-195461547:120,wrap,wrap,120,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/19#issuecomment-195461547,1,['wrap'],['wrap']
Integrability,"The response by genomax [here](https://www.biostars.org/p/444853/) is spot on too. There are many, independent, overlapping reads here. If you have some other reason to believe this is wrong, we’d be happy to investigate further. However, I’m going to close the issue for the time being. . P.S. Yes, salmon is the right tool for full-length, plate-based protocols. Alevin is for tagged end (mostly droplet-based) protocols.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/539#issuecomment-647038324:354,protocol,protocols,354,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/539#issuecomment-647038324,2,['protocol'],['protocols']
Integrability,The segfault seems to be happening with Jemalloc (an external dependency). I'm going to see if switching to tcmalloc in the binary build fixes it.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/34#issuecomment-168361093:62,depend,dependency,62,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/34#issuecomment-168361093,1,['depend'],['dependency']
Integrability,"The specific error message seems to be coming from [the serialization library we use](https://github.com/USCiLab/cereal/blob/master/include/cereal/archives/portable_binary.hpp#L245). This was upgraded recently, so I'm hoping that they didn't introduce a new bug upstream. As soon as I can reproduce this, I can test if rolling back the version of the serialization library fixes the issue (which I don't believe occurred in 0.7.2).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/129#issuecomment-287255919:19,message,message,19,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/129#issuecomment-287255919,1,['message'],['message']
Integrability,"The standard is the code chunk in the vignette:. ```; txi <- tximport(files, type = ""salmon"", tx2gene = tx2gene); # then below...; dds <- DESeqDataSetFromTximport(txi, sampleTable, ~condition); ```. Or even better, you can use tximeta:. ```; se <- tximeta(coldata); gse <- summarizeToGene(se); dds <- DESeqDataSet(gse, ~condition); ```. If you have a special protocol which does not involve fragmentation of a full length transcript, then you do something else. But if you are fragmenting molecules and sequencing from along the entire transcript, use those code chunks from the vignette.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/581#issuecomment-719734272:359,protocol,protocol,359,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/581#issuecomment-719734272,1,['protocol'],['protocol']
Integrability,"There should be easy ways to handle reading line-buffered input from two file descriptors, where both file descriptors could be identical, and then passing these streams internally to buffers to be chunked for multithreaded processing. This would give you one code path for ingesting data, and the command line interface could remain the same as it is currently, with the possible addition of mapping the `-` symbol to `/dev/fd/0`. Is there really much to be gained from buffering all input in byte chunks up front? Remembering that unix pipes are buffered somewhat by default anyway? There has to be an acceptable way to handle line-based input in a more flexible way. In Python I would do:. ``` python; import argparse. example_parser = argparse.ArgumentParser(); example_parser.add_argument('-fq1', type=argparse.FileType('r')); example_parser.add_argument('-fq2', type=argparse.FileType('r')); args = parser.parse_args(). for line1, line2 in zip(args.fq1, args.fq2):; do_stuff_with_lines(); ```. You could then call the program flexibly:. ``` bash; $ example -fq1 file1.fq -fq2 file2.fq; $ example -fq1 <(gzip -dc file1.fq.gz) -fq2 <(gzip -dc file2.fq.gz); $ other_interleaved_process | example -fq1 - -fq2 -; ```. The caveat for the code above is that you would want to replace `argparse.FileType` with some class that reads 4 lines at a time - I'm sure there's no shortage of Python FASTQ readers that do that. And I know that you're looking for C++ libraries that perform well for your purposes, and my Python example is just a toy, but I think designing the option parser to at least **accept** streams and file-like objects and handle them using the same code path would be a worthy reason to refactor a bit.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/29#issuecomment-168545456:311,interface,interface,311,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/29#issuecomment-168545456,1,['interface'],['interface']
Integrability,"These messages have been removed in 0.9.0. Also, the read parser has had a considerable overhaul to avoid simply busy waiting in a situation like this where the processing is much slower than the disk. Let me know if this problem is resolved on your end.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/152#issuecomment-346981211:6,message,messages,6,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/152#issuecomment-346981211,1,['message'],['messages']
Integrability,This doesn't necessarily mean the protocol is stranded. You can inspect the contents of lib_format_counts.json to see the exact extent of the mapping bias.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/144#issuecomment-319676557:34,protocol,protocol,34,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/144#issuecomment-319676557,1,['protocol'],['protocol']
Integrability,"This in the compile error I get for the Staden package, FYI:. ```; ❯ make VERBOSE=1 [12:30:35]; /usr/local/Cellar/cmake/3.13.4/bin/cmake -S/Users/gabriel/Projects/salmon-0.13.1 -B/Users/gabriel/Projects/salmon-0.13.1/build --check-build-system CMakeFiles/Makefile.cmake 0; /usr/local/Cellar/cmake/3.13.4/bin/cmake -E cmake_progress_start /Users/gabriel/Projects/salmon-0.13.1/build/CMakeFiles /Users/gabriel/Projects/salmon-0.13.1/build/CMakeFiles/progress.marks; /Applications/Xcode.app/Contents/Developer/usr/bin/make -f CMakeFiles/Makefile2 all; /Applications/Xcode.app/Contents/Developer/usr/bin/make -f CMakeFiles/libcereal.dir/build.make CMakeFiles/libcereal.dir/depend; cd /Users/gabriel/Projects/salmon-0.13.1/build && /usr/local/Cellar/cmake/3.13.4/bin/cmake -E cmake_depends ""Unix Makefiles"" /Users/gabriel/Projects/salmon-0.13.1 /Users/gabriel/Projects/salmon-0.13.1 /Users/gabriel/Projects/salmon-0.13.1/build /Users/gabriel/Projects/salmon-0.13.1/build /Users/gabriel/Projects/salmon-0.13.1/build/CMakeFiles/libcereal.dir/DependInfo.cmake --color=; /Applications/Xcode.app/Contents/Developer/usr/bin/make -f CMakeFiles/libcereal.dir/build.make CMakeFiles/libcereal.dir/build; make[2]: Nothing to be done for `CMakeFiles/libcereal.dir/build'.; [ 8%] Built target libcereal; /Applications/Xcode.app/Contents/Developer/usr/bin/make -f CMakeFiles/libstadenio.dir/build.make CMakeFiles/libstadenio.dir/depend; cd /Users/gabriel/Projects/salmon-0.13.1/build && /usr/local/Cellar/cmake/3.13.4/bin/cmake -E cmake_depends ""Unix Makefiles"" /Users/gabriel/Projects/salmon-0.13.1 /Users/gabriel/Projects/salmon-0.13.1 /Users/gabriel/Projects/salmon-0.13.1/build /Users/gabriel/Projects/salmon-0.13.1/build /Users/gabriel/Projects/salmon-0.13.1/build/CMakeFiles/libstadenio.dir/DependInfo.cmake --color=; /Applications/Xcode.app/Contents/Developer/usr/bin/make -f CMakeFiles/libstadenio.dir/build.make CMakeFiles/libstadenio.dir/build; [ 9%] Performing configure step for 'libstadenio'; cd /Users/gabr",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/348#issuecomment-472500713:669,depend,depend,669,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/348#issuecomment-472500713,1,['depend'],['depend']
Integrability,"This seems to be a separate issue than the other (and a more informative exception). Once I've resolved the other issue, I would probably try to bug you for a sample that causes this --- though I have a reasonable idea about how to fix it. It would be nice to have the fix for both issues in the same hotfix. To be more specific : this is, as the exception says, a numeric underflow issue when evaluating the digamma function. The solution here is just to bump up the value that is required before evaluating this function. This should be straightforward, but I suspect the issue is also related to this log message:. > [2018-05-31 17:08:11.488] [jointLog] [info] Marked 1 weighted equivalence classes as degenerate",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/229#issuecomment-393571565:608,message,message,608,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/229#issuecomment-393571565,1,['message'],['message']
Integrability,This should be fixed with the [seurat_wrapper](https://github.com/satijalab/seurat-wrappers) repo.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/436#issuecomment-821498452:83,wrap,wrappers,83,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/436#issuecomment-821498452,1,['wrap'],['wrappers']
Integrability,We fix it by adding the tbb package (I also added the libgcc but I think it is not mandatory) :. ```; name: salmon; channels:; - bioconda; - conda-forge; - defaults; dependencies:; - libgcc-ng=9.1.0=hdf63c60_0; - tbb=2020.2=hc9558a2_0; - salmon=1.4.0=hf69c8f4_0; ```,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/565#issuecomment-802751914:166,depend,dependencies,166,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/565#issuecomment-802751914,1,['depend'],['dependencies']
Integrability,"We have that here, right? https://salmon.readthedocs.io/en/latest/alevin.html#single-cell-protocol-specific-notes",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/878#issuecomment-1753075151:90,protocol,protocol-specific-notes,90,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/878#issuecomment-1753075151,1,['protocol'],['protocol-specific-notes']
Integrability,"Where does `extract-libdivsufsort.cmake` live? I don't find it in the `salmon` repository. Is it generated automatically by `cmake`? The following patch/hack using `unzip` works around the `cmake -E tar xfz` bug for me. It seems to only affect extracting the `libdivsufsort.zip`, perhaps because it's a `.zip`. If that is the case, and there's a `.tar.gz` distribution of `libdivsufsort`, then there may be a simple fix. ``` diff; --- libdivsufsort-prefix/src/libdivsufsort-stamp/extract-libdivsufsort.cmake.orig 2016-03-07 22:02:35.000000000 -0800; +++ libdivsufsort-prefix/src/libdivsufsort-stamp/extract-libdivsufsort.cmake 2016-03-07 22:06:49.000000000 -0800; @@ -23,7 +23,7 @@; # Extract it:; #; message(STATUS ""extracting... [tar xfz]""); -execute_process(COMMAND ${CMAKE_COMMAND} -E tar xfz ${filename}; +execute_process(COMMAND unzip ${filename}; WORKING_DIRECTORY ${ut_dir}; RESULT_VARIABLE rv). ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/10#issuecomment-193623757:701,message,message,701,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/10#issuecomment-193623757,1,['message'],['message']
Integrability,"With the extra `--expectCells 10000` parameter, Alevin finished running without error messages and 10,641 cell barcodes in **quants_mat_rows.txt**. I am not sure how much of a difference it makes if I expect 8,000 cells versus 10,000 cells. However, this looks much closer to the expected number, and I am closing the ticket. Thanks again!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/682#issuecomment-884309748:86,message,messages,86,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/682#issuecomment-884309748,1,['message'],['messages']
Integrability,"Wow. Thanks for getting back so fast. I’ll update more info about the machine. It’s got 16GB of RAM and only 3GB of swap, so I do think it was memory pressure. In fact, I just looked through the system kernel messages and found the OOM routine killed my process:. ```Out of memory: Kill process 12997 (R) score 846 or sacrifice child │10-03 22:39 INFO Encountered FastxParser destructor while parser was still marked active (or while parsing threads were ; Killed process 12997, UID 1506502601, (R) total-vm:17105100kB, anon-rss:15306012kB, file-rss:12kB ; ```. Sorry I didn’t check this earlier!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/432#issuecomment-538606398:209,message,messages,209,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/432#issuecomment-538606398,2,"['message', 'rout']","['messages', 'routine']"
Integrability,"Yea. Both are frustrating, which is why we spam warning messages to the console when we remove duplicates. Sorry if this default behavior caused you any trouble, but hopefully its easy to recover these quants without rerunning anything using the map of collapsed transcripts.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/214#issuecomment-381584892:56,message,messages,56,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/214#issuecomment-381584892,1,['message'],['messages']
Integrability,"Yes, I'm aware of refgenie however, I was unable to identify for the hg38 salmon indices which specific transcriptome source (and additionally which version of said source) was used to build them.; Additionally, my use case here isn't entirely personal, I work for GSEA-MSigDB and GenePattern, we're in the process of improving the end-to-end analysis pipeline we offer to users, and one of the things we've been working on were wrapping the Salmon indexer, Salmon quant, and Alevin into GenePattern modules so that we can offer them to users who may want to run them on arbitrary transcriptomes in addition to the ones we offer specifically for GSEA compatibility. This issue was something we encountered when considering potential sources of inconsistency at different points in the pipeline.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/595#issuecomment-738180982:429,wrap,wrapping,429,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/595#issuecomment-738180982,1,['wrap'],['wrapping']
Integrability,"Yes, but it was a while ago. I think I had realised that I aligned to the; genome (Step 2 in my original post), when Salmon documentation specifically; says you should align to the transcriptome. So I redid the alignment and it; worked, if I'm remembering correctly. On Thu, 18 Jul 2024, 16:41 YIGUIz, ***@***.***> wrote:. > Hi, I encountered the same issue. Have you managed to solve it?; >; > —; > Reply to this email directly, view it on GitHub; > <https://github.com/COMBINE-lab/salmon/issues/863#issuecomment-2236553993>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AOFX65IGY6W3PKGRNNK7WOLZM7AY5AVCNFSM6AAAAABLCWZAB2VHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZDEMZWGU2TGOJZGM>; > .; > You are receiving this because you authored the thread.Message ID:; > ***@***.***>; >",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/863#issuecomment-2241619736:770,Message,Message,770,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/863#issuecomment-2241619736,1,['Message'],['Message']
Integrability,"Yes, this is a set of transcripts assembled using a few different Trinity and Velvet/Oases protocols, merged together. I'm testing reduction with different tools along with relative abundance estimation.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/54#issuecomment-204098008:91,protocol,protocols,91,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/54#issuecomment-204098008,1,['protocol'],['protocols']
Integrability,"Yup this geometry is correct! As for a pairing file for the BC1 barcodes, this _may_ depend on the version and/or implementation in the lab. For ParseBio (""v2""), it seems to be consistent thus far, and I've linked a pairing table for that below. For homemade SPLiT-seq (""v1""), which barcodes end up in which wells, and which wells actually get utilized may vary. Additionally, some other labs may not use random hexamers at all, meaning we should have some flexibility such that users provide their own table and also an option for whether this pairing table is strictly required. In [this barcode sharing file](https://github.com/COMBINE-lab/salmon/files/7418722/ParseBio_barcodeSharing.txt), the first column represents the oligo-dT BC1 sequences, and the second column are the paired random hexamer BC1 sequences. Note this file is the same as [this one here on my github](https://github.com/jeremymsimon/SPLITseq).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-951974369:85,depend,depend,85,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-951974369,1,['depend'],['depend']
Integrability,"[I confirmed with the developer of zUMIs](https://github.com/sdparekh/zUMIs/issues/298) that no frameshift detection/correction is happening in their approach for SPLiT-seq libraries, so the barcode discovery should be fairly consistent with what alevin is already doing (ie with fixed geometry positions). So, likely no need to incorporate this into `splitp` at the moment but if we/others determine that frameshifts are frequent enough and the data can improve in some noticeable way with correcting them, we can revisit later as you suggested. . As for the barcode detection - my usual approach with `alevin` at least is to let it try to estimate a ""real"" cell number, but if it's way off from our experimental expectations, to inject `--expectCells ncells` and let that serve as a starting point (with subsequent filtering). That has worked reasonably well in the past for me , and seems to be an option for `alevin-fry` as well. I don't know whether that is poor practice in the long run...it came from a place of seeing far too many weak knee plots early in the droplet scRNA-seq days. Are you generally more trusting of these estimates these days?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-988184912:731,inject,inject,731,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-988184912,1,['inject'],['inject']
Integrability,"________________________________; From: tamuanand <notifications@github.com>; Sent: Saturday, 14 December 2019 4:42 PM; To: COMBINE-lab/salmon <salmon@noreply.github.com>; Cc: Susan Corley <s.corley@unsw.edu.au>; Mention <mention@noreply.github.com>; Subject: Re: [COMBINE-lab/salmon] Salmon SAF method - Read mapping issue with Lexogen/QuantSeq data?? (#449). Hi @s1corley<https://github.com/s1corley>. Thanks for your inputs and thanks for taking the time to respond here. You mention you attached the Salmon meta_info output - I guess the attachment did Not come through. @k3yavi<https://github.com/k3yavi> @rob-p<https://github.com/rob-p> - any ideas why the attachment did not make it. Yes - I am surprised with the results using the SR salmon quant option with the QuantSeq FWD protocol. I was advised that a FWD library was used - this is a bit confusing given the success of running the SR option. @rob-p<https://github.com/rob-p> What should be the libType option one should set with the QuantSeq FWD protocol - I have explained above why the SF option would be appropriate one (based on what Lexogen recommends for use with htseq-count for QuantSeq FWD). —; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://github.com/COMBINE-lab/salmon/issues/449?email_source=notifications&email_token=AC4A5AHH5I66447AJKAIA6LQYRW4BA5CNFSM4JOIEHZ2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEG33A6Y#issuecomment-565686395>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AC4A5AEBKTGGPZ22F7IVIA3QYRW4BANCNFSM4JOIEHZQ>. Sample S1. meta_info.json. ""salmon_version"": ""0.9.1"",; ""samp_type"": ""none"",; ""quant_errors"": [],; ""num_libraries"": 1,; ""library_types"": [; ""SR""; ],; ""frag_dist_length"": 1001,; ""seq_bias_correct"": true,; ""gc_bias_correct"": true,; ""num_bias_bins"": 4096,; ""mapping_type"": ""mapping"",; ""num_targets"": 202863,; ""serialized_eq_classes"": false,; ""eq_class_properties"": [],; ""length_classes"": [; 513,; 656",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-565692581:784,protocol,protocol,784,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-565692581,1,['protocol'],['protocol']
Integrability,"```; > ; > ```; > Version Info: This is the most recent version of salmon.; > # salmon (alignment-based) v1.4.0; > # [ program ] => salmon ; > # [ command ] => quant ; > # [ targets ] => { mRNA.fasta }; > # [ threads ] => { 20 }; > # [ libType ] => { A }; > # [ alignments ] => { SRR3212847.Aligned.SortedByName.bam }; > # [ output ] => { SRR3212847.Aligned.SortedByName }; > Logs will be written to SRR3212847.Aligned.SortedByName/logs; > [2021-01-08 13:02:04.845] [jointLog] [info] setting maxHashResizeThreads to 20; > [2021-01-08 13:02:04.845] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; > Library format { type:paired end, relative orientation:inward, strandedness:unstranded }; > [2021-01-08 13:02:04.878] [jointLog] [info] numQuantThreads = 14; > parseThreads = 6; > Checking that provided alignment files have consistent headers . . . done; > Populating targets from aln = ""SRR3212847.Aligned.SortedByName.bam"", fasta = ""mRNA.fasta"" . . .done; > ; > processed 0 reads in current roundSegmentation fault (core dumped); > ```; > ; > (Which is the same as the 1st error. Actually, each time I re-run those two errors switched.); > ; > I tried running Salmon on the sorted-by-coordinates bam, and it didn't fail:; > ; > ```; > nohup salmon quant \; > -t mRNA.fasta \; > -p 20 \; > -l A \; > -a SRR3212847.Aligned.SortedByCoord.bam \; > -o SRR3212847.Aligned.SortedByCoord \; > > SRR3212847.Aligned.SortedByCoord.out &; > ```; > ; > Even so, `SRR3212847.Aligned.SortedByCoord.out` contained ~3.5GB worth of the warnings above.; > ; > Any help would be much appreciated. Thanks!. hello,i have the same problem,thanks for your answer. Your SRR3212847.Aligned.SortedByCoord.out contained ~3.5GB worth of the warnings above, What is the warning message? And in my log file,the warning as follow:. ![image](https://user-images.githubusercontent.com/45484925/206608510-b5cc88bd-18ac-42eb-bfa1-a5be862b0873.png); Can i ignore these warnings?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/582#issuecomment-1343749456:5242,message,message,5242,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/582#issuecomment-1343749456,1,['message'],['message']
Integrability,`cmake` fails when extracting external dependencies for me. See #10. I'd also like to be able to use the existing installed versions of dependencies. For me they're installed by Linuxbrew.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/19#issuecomment-193514127:39,depend,dependencies,39,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/19#issuecomment-193514127,2,['depend'],['dependencies']
Integrability,"and <notifications@github.com>; Sent: Saturday, 14 December 2019 4:42 PM; To: COMBINE-lab/salmon <salmon@noreply.github.com>; Cc: Susan Corley <s.corley@unsw.edu.au>; Mention <mention@noreply.github.com>; Subject: Re: [COMBINE-lab/salmon] Salmon SAF method - Read mapping issue with Lexogen/QuantSeq data?? (#449). Hi @s1corley<https://github.com/s1corley>. Thanks for your inputs and thanks for taking the time to respond here. You mention you attached the Salmon meta_info output - I guess the attachment did Not come through. @k3yavi<https://github.com/k3yavi> @rob-p<https://github.com/rob-p> - any ideas why the attachment did not make it. Yes - I am surprised with the results using the SR salmon quant option with the QuantSeq FWD protocol. I was advised that a FWD library was used - this is a bit confusing given the success of running the SR option. @rob-p<https://github.com/rob-p> What should be the libType option one should set with the QuantSeq FWD protocol - I have explained above why the SF option would be appropriate one (based on what Lexogen recommends for use with htseq-count for QuantSeq FWD). —; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://github.com/COMBINE-lab/salmon/issues/449?email_source=notifications&email_token=AC4A5AHH5I66447AJKAIA6LQYRW4BA5CNFSM4JOIEHZ2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEG33A6Y#issuecomment-565686395>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AC4A5AEBKTGGPZ22F7IVIA3QYRW4BANCNFSM4JOIEHZQ>. Sample S1. meta_info.json. ""salmon_version"": ""0.9.1"",; ""samp_type"": ""none"",; ""quant_errors"": [],; ""num_libraries"": 1,; ""library_types"": [; ""SR""; ],; ""frag_dist_length"": 1001,; ""seq_bias_correct"": true,; ""gc_bias_correct"": true,; ""num_bias_bins"": 4096,; ""mapping_type"": ""mapping"",; ""num_targets"": 202863,; ""serialized_eq_classes"": false,; ""eq_class_properties"": [],; ""length_classes"": [; 513,; 656,; 1013,; 2240,; 104301; ],; ""index_seq_hash""",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-565692581:1010,protocol,protocol,1010,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-565692581,1,['protocol'],['protocol']
Integrability,"at my transcript fasta, I noticed a problem with it, as you suggested. Long story short, half the premature transcripts had the wrong orientation and complementarity. Long story:. Oddly, the mature sequences were fine even though I used an identical approach to subset premature and mature transcripts from the genome reference!. Briefly my approach relied on three R packages rtracklayer, GenomicRanges, and Biostrings. 1. I used rtracklayer to load a gtf formatted exon annotations acquired from Ensembl. The file is loaded as a GenomicRanges object which essentially describes the locus of each exon (the transcribed strand [+ or -], chromosome, start and end positions relative to the reference strand) and its associated gene and transcript. 2. I used the GRanges object to generate pre-RNA coordinates that span all exons of a transcript. 3. I loaded the reference genome fasta acquired from Ensembl using the Biostrings package. GRanges and Biostrings are tightly integrated, allowing me to subset sequences from a Biostrings object using the GRanges object. **I believe the problem lies here.** It appears that when subsetting the mature exonic sequences from Biostrings using GRanges, the strand field in the GRanges object **was not** utilized. I.e., I needed to get the reverse complement of the extracted sequences for transcripts on the minus strand. I had done that and assumed that this behaviour would be consistent. However, for reasons I have not been able to pinpoint (potentially a bug), the strand information **was accounted for** when I used GRanges to subset the premature sequences. I **did not** need to get the reverse complement of the premature sequences on the minus strand as I had to do for the mature sequences. Yet, I did that anyway. I initially did test my protocol to ensure it produced identical transcript sequences to Gencode, but I only did this for mature sequences. All seemed fine for both + and - strand transcripts. After your feedback, I compared the pr",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/655#issuecomment-826035191:1514,integrat,integrated,1514,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/655#issuecomment-826035191,1,['integrat'],['integrated']
Integrability,"can you share the contents of the file `../../alevin_15_pc/lib_format_counts.json` ?; Basically what it's saying is that the assumption made to explicitly define the library type in the command line flag i.e. `-lISR` which means that the library is stranded and the reads are coming from the reverse strand is getting violated. In 10x protocols we generally expects that the read follow the `ISR` standard but it looks like some 5% of the reads are not following this property and that's what Alevin is complaining. It is possible since this is v1, we might expect some non-trivial fraction of reads to be non-stranded but too hard to say .",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/294#issuecomment-422618229:335,protocol,protocols,335,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/294#issuecomment-422618229,1,['protocol'],['protocols']
Integrability,"cript. 3. I loaded the reference genome fasta acquired from Ensembl using the Biostrings package. GRanges and Biostrings are tightly integrated, allowing me to subset sequences from a Biostrings object using the GRanges object. **I believe the problem lies here.** It appears that when subsetting the mature exonic sequences from Biostrings using GRanges, the strand field in the GRanges object **was not** utilized. I.e., I needed to get the reverse complement of the extracted sequences for transcripts on the minus strand. I had done that and assumed that this behaviour would be consistent. However, for reasons I have not been able to pinpoint (potentially a bug), the strand information **was accounted for** when I used GRanges to subset the premature sequences. I **did not** need to get the reverse complement of the premature sequences on the minus strand as I had to do for the mature sequences. Yet, I did that anyway. I initially did test my protocol to ensure it produced identical transcript sequences to Gencode, but I only did this for mature sequences. All seemed fine for both + and - strand transcripts. After your feedback, I compared the premature sequences in my transcript fasta against the transcript fasta from Gencode. As you can see in the smoothed dot plots below, the premature sequences of transcripts on the minus strand are in the wrong orientation and have the wrong complementarity!. ![Screenshot from 2021-04-24 00-35-05](https://user-images.githubusercontent.com/10429333/115947355-0d96c880-a495-11eb-92a6-d8d2233c8d2b.png). I included my R code below for this test case for anyone who might stumble upon this issue. Under the code headers “Mature transcript sequences” and “Premature transcript sequences”, you can observe that I used identical protocols for sequence subsetting, yet in the mature case the strand information in the GRanges seems to be disregarded when subsetting from Biostrings, but in the premature case the strand information is used. Of cou",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/655#issuecomment-826035191:2336,protocol,protocol,2336,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/655#issuecomment-826035191,1,['protocol'],['protocol']
Integrability,"e *full* decoy index is substantially larger than the index on just the transcriptome (after all, it is indexing the entire human genome in addition to the transcriptome). One thing you might try to test this hypothesis, other than requesting to build on a node with more RAM, is to compute a hash (e.g. md5 or sha256 sum) on all of the files in the index, and also record their sizes. Then we can build the index on the same version of the files on our end and compare. Second — and perhaps more importantly for your end goal — the main purpose of the decoy-aware index is to improve specificity rather than sensitivity. That is, the decoys are designed to help avoid _spurious_ mapping of reads to an annotated transcript when a better explanation for the read exists elsewhere in the genome. However, the reads that are mapped to decoys are not otherwise used for quantification. Thus, using the decoy aware transcriptome index is unlikely to improve your mapping rate. I agree that your mapping rate does seem rather low. There are a few potential culprits here, and some diagnostics we can look at to see what might be going wrong. First, you can take a look at the file `aux_info/meta_info.json` in the salmon quantification directories to get a few more details about why reads were not mapped. If you share one of those files here I can describe the relevant fields. Also, I have two more rather common things to consider that might affect the mapping rate. One is to add the sequence for the ribosomal RNAs to your transcriptome before indexing and then quantifying. If your mapping rate increases considerably, this is evidence of rather inefficient depletion prior to sequencing. The other thing to consider is to do basic adapter / quality trimming on the reads to see if that affects your mapping rate at all. I hope these two different responses are useful, and I'll keep this issue open so feel free to reply here with any further questions or discoveries you make regarding the above.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/603#issuecomment-744162850:2071,adapter,adapter,2071,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/603#issuecomment-744162850,1,['adapter'],['adapter']
Integrability,"e I answer your question and layout my logic, I want to mention that I am **_not_** suggesting fastp is not doing its job, **_neither am I stating that fastp is working incorrectly_**. Now to my answer(s) and logic:; 1. With fastp, I am not sure if adapter trimming happens first and then quality trimming OR vice-versa. I could not find info on this from their README and **_I could be wrong here with my next line_** - [Based on Figure 1 of this paper, it looks to me as though quality trimming is done before adapter trimming](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6129281/figure/bty560-F1/). - [To quote Brian Bushnell (author of BBTools)]( http://seqanswers.com/forums/showpost.php?p=140819&postcount=5), . > It's best to do adapter-trimming first, then quality-trimming, because if you do quality-trimming first, sometimes adapters will be partially trimmed and become too short to be recognized as adapter sequence. When you run BBDuk with both quality-trimming and adapter-trimming in the same run, it will do adapter-trimming first, then quality-trimming. 2. I very well know that the advantage of using fastp is that it can do adapter trimming, etc in a automatic fashion - no need to provide external sequences (example adapter sequences). Yes, I know one can also provide a fasta file of adapters and fatsp will work off it. There are many fatsp issues in GH about adapter detection:. - fail to detect adpaters automatically - (https://github.com/OpenGene/fastp/issues/222 and https://github.com/OpenGene/fastp/issues/205). - [incorrect automatic adapter detection](https://github.com/OpenGene/fastp/issues/240). - [inconsistent behavior with different runs](https://github.com/OpenGene/fastp/issues/231). 3. When I see the above, I am bit skeptical using fastp for qc/adapter trimming. . After lot of trials with bbduk and fastp, I have decided to use bbduk and bbmap for my high throughput analysis. Below, I explain my reasoning behind those choices: . **_```Note - edited this ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-597393209:997,adapter,adapter-trimming,997,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-597393209,2,['adapter'],['adapter-trimming']
Integrability,"e Staden package, FYI:. ```; ❯ make VERBOSE=1 [12:30:35]; /usr/local/Cellar/cmake/3.13.4/bin/cmake -S/Users/gabriel/Projects/salmon-0.13.1 -B/Users/gabriel/Projects/salmon-0.13.1/build --check-build-system CMakeFiles/Makefile.cmake 0; /usr/local/Cellar/cmake/3.13.4/bin/cmake -E cmake_progress_start /Users/gabriel/Projects/salmon-0.13.1/build/CMakeFiles /Users/gabriel/Projects/salmon-0.13.1/build/CMakeFiles/progress.marks; /Applications/Xcode.app/Contents/Developer/usr/bin/make -f CMakeFiles/Makefile2 all; /Applications/Xcode.app/Contents/Developer/usr/bin/make -f CMakeFiles/libcereal.dir/build.make CMakeFiles/libcereal.dir/depend; cd /Users/gabriel/Projects/salmon-0.13.1/build && /usr/local/Cellar/cmake/3.13.4/bin/cmake -E cmake_depends ""Unix Makefiles"" /Users/gabriel/Projects/salmon-0.13.1 /Users/gabriel/Projects/salmon-0.13.1 /Users/gabriel/Projects/salmon-0.13.1/build /Users/gabriel/Projects/salmon-0.13.1/build /Users/gabriel/Projects/salmon-0.13.1/build/CMakeFiles/libcereal.dir/DependInfo.cmake --color=; /Applications/Xcode.app/Contents/Developer/usr/bin/make -f CMakeFiles/libcereal.dir/build.make CMakeFiles/libcereal.dir/build; make[2]: Nothing to be done for `CMakeFiles/libcereal.dir/build'.; [ 8%] Built target libcereal; /Applications/Xcode.app/Contents/Developer/usr/bin/make -f CMakeFiles/libstadenio.dir/build.make CMakeFiles/libstadenio.dir/depend; cd /Users/gabriel/Projects/salmon-0.13.1/build && /usr/local/Cellar/cmake/3.13.4/bin/cmake -E cmake_depends ""Unix Makefiles"" /Users/gabriel/Projects/salmon-0.13.1 /Users/gabriel/Projects/salmon-0.13.1 /Users/gabriel/Projects/salmon-0.13.1/build /Users/gabriel/Projects/salmon-0.13.1/build /Users/gabriel/Projects/salmon-0.13.1/build/CMakeFiles/libstadenio.dir/DependInfo.cmake --color=; /Applications/Xcode.app/Contents/Developer/usr/bin/make -f CMakeFiles/libstadenio.dir/build.make CMakeFiles/libstadenio.dir/build; [ 9%] Performing configure step for 'libstadenio'; cd /Users/gabriel/Projects/salmon-0.13.1/external/st",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/348#issuecomment-472500713:1035,Depend,DependInfo,1035,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/348#issuecomment-472500713,1,['Depend'],['DependInfo']
Integrability,"e code for the v3 sample that ran without generating error messages:. ```; ID=5k_pbmc_v3. R1a=../Reads/5k_pbmc_v3_S1_L001_R1_001.fastq.gz; R1b=../Reads/5k_pbmc_v3_S1_L002_R1_001.fastq.gz; R1c=../Reads/5k_pbmc_v3_S1_L003_R1_001.fastq.gz; R1d=../Reads/5k_pbmc_v3_S1_L004_R1_001.fastq.gz. R2a=../Reads/5k_pbmc_v3_S1_L001_R2_001.fastq.gz; R2b=../Reads/5k_pbmc_v3_S1_L002_R2_001.fastq.gz; R2c=../Reads/5k_pbmc_v3_S1_L003_R2_001.fastq.gz; R2d=../Reads/5k_pbmc_v3_S1_L004_R2_001.fastq.gz. TYPE=10xV3; #for MAP, download from UCSC Table Browser, and remove 1st line (and then manually add SARS-COV-2 genes); MAP=../../Ref_Generation/SARS_COV_2-hg38_RefSeq_2column.txt; REF=../../Ref_Generation/SARS_COV_2-hg38_salmon; CBWL=/net/isi-dcnl/ifs/user_data/Seq/Chromium_data/3M-february-2018.txt. ../../Ref_Generation/salmon-1.5.1_linux_x86_64/bin/salmon alevin -l ISR --chromium -1 $R1a $R1b $R1c $R1d -2 $R2a $R2b $R2c $R2d -i $REF -p 4 -o $ID --tgMap $MAP --whitelist $CBWL; ```. That v3 white list is even **larger** than the v2 white list:. ```; cwarden$ wc -l /net/isi-dcnl/ifs/user_data/Seq/Chromium_data/3M-february-2018.txt; 6794880 /net/isi-dcnl/ifs/user_data/Seq/Chromium_data/3M-february-2018.txt; ```. So, that is part of why I was confused. However, before I start running the analysis with the shorter set of barcodes unique for this sample, here are the commands that I believe you were asking about. ```; cwarden$ wc -l ../CellRanger/5309-CT-2/outs/raw_feature_bc_matrix/barcodes.tsv; 737280 ../CellRanger/5309-CT-2/outs/raw_feature_bc_matrix/barcodes.tsv; cwarden$ wc -l ../CellRanger/5309-CT-2/outs/filtered_feature_bc_matrix/barcodes.tsv; 9974 ../CellRanger/5309-CT-2/outs/filtered_feature_bc_matrix/barcodes.tsv; ```. I would prefer to have an option where I could potentially conclude the cell count is different than provided by CellRanger. . However, I will at least check to confirm this solves the problem with the error message that I am seeing (with the much smaller cell barcode list).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/682#issuecomment-879347665:1979,message,message,1979,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/682#issuecomment-879347665,1,['message'],['message']
Integrability,"e correct command line `salmon quant` options for Lexogen/QuantSeq _(this will be referred to as QS in the rest of the message(s))_ ?. `salmon quant --threads 16 --noLengthCorrection --validateMappings --numBootstraps 100 -l SF -i <path_to_SAF_Gentrome_Index> -r <SE_READ_1.fq> -o <salmon_SE_READ_1>`. I chose the above command line options (`especially --noLengthCorrection`) based on [Rob's message here](https://groups.google.com/d/msg/sailfish-users/VIfqBwgF6xQ/fw-rgC_kAwAJ) and a [thread here](https://github.com/COMBINE-lab/salmon/issues/108). Let me elaborate the big picture of my analyses and give more details about how I came up with the mapping numbers in my original post. Big Picture - DEG identification for samples sequenced by ILMN (whole transcript method) and QS (3' method) - [something similar to this paper](https://bmcgenomics.biomedcentral.com/articles/10.1186/s12864-018-5393-3). Bioinformatics Pipeline(s) for both ILMN and QS :. 1. HISAT Method : Adapter/Quality Trimming, Hisat2-HTSEQ, Get_Count_Table, DESeq; 2. STAR_RSEM Method: Adapter/Quality Trimming, STAR_RSEM, Get_Count_Table, DESeq; 3. SAF Method: Adapter/Quality Trimming, SAF_SALMON, Get_Count_Table, DESeq; 4. Quasi-Mapping or TXOME Method: Adapter/Quality Trimming, TXOME_SALMON, Get_Count_Table, DESeq. I used UpSetR plots for comparisons of sets of DEGs from each method just [as you have shown in your recent preprint](https://www.biorxiv.org/content/10.1101/657874v1.full). In the ILMN analyses, there is great concordance between the SAF method and HISAT/STAR_RSEM method. However, in the QS analyses, there is very limited concordance between SAF and the HISAT/STAR_RSEM method. For QS analyses, the TXOME method shows great concordance with HISAT/STAR_RSEM. This finding made me wonder if this has to be something with my salmon quant command line options for QS. Therefore, I wanted to check how the QS expected counts for SAF method show up for all samples in my final summarized table (after tximpo",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-554768195:1016,Adapter,Adapter,1016,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-554768195,1,['Adapter'],['Adapter']
Integrability,"e relative tradeoffs and merits of different alignment approaches). * Salmon and RSEM use related but distinct optimization algorithms by default. RSEM uses the EM algorithm, and salmon uses the variational Bayesian EM algorithm. The latter tends to induce more sparse solutions. This is simply because they are optimizing slightly different objectives. It is very difficult to say in general if one is ""better"" than the other in a blanket way, but [there is previous literature to support that the VBEM may be more accurate](https://academic.oup.com/bioinformatics/article/29/18/2292/239795). However, while RSEM only implements the EM algorithm, salmon actually implements and provides a switch to use either. So, if you want to test the effect of this difference, you can run salmon with the `--useEM` algorithm. This will tell salmon to use the ""classic"" EM algorithm and will eliminate this source of variation. * As with the other question you asked, there may be a _small_ discrepancy depending on when enforcement of a stranded library kicks in under salmon's `A` library type. You can eliminate that variable by simply providing `-l SF` to match the library type being used with RSEM. * Coming back to the `IndelSoftclipSingleend` parameter I mentioned in the first point; RSEM disallows indels in the alignments that it quantifies. This means that to produce RSEM-compatible input, STAR must not align reads that contain indels. While this won't generally have a big effect for many transcripts, it can certainly affect the abundance estimates for transcripts in your sample where the sample you are quantifying has (indel) variation with respect to the reference annotation. We touch upon that a bit as well in the [paper I mentioned above](https://genomebiology.biomedcentral.com/articles/10.1186/s13059-020-02151-8). * Finally, and likely the smallest source of potential differences, is that there are other implementation details that differ between salmon and RSEM (e.g. exactly how th",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/612#issuecomment-758004590:3543,depend,depending,3543,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/612#issuecomment-758004590,1,['depend'],['depending']
Integrability,"e""). For the pipeline I'm building it would be ideal if I didn't have to specify the strandedness of the library as I'm not the one preparing the samples and it's not always easy to get that information from the scientist in the lab. As such, it would be great if I can use the default strandedness argument to STAR (""Unstranded"") and let salmon ""do the right thing"" by letting it choose the libType for me. With that in mind, if I let salmon choose for me (-l A) am I risking throwing out any data?. Right, so in this case, STAR should produce all highest-scoring valid alignments regardless of orientation. Then, when running salmon with `-l A` it will detect the strandedness and only discard alignments compatible with the appropriate strand type (which may be unstranded if that is the protocol). Salmon is pretty conservative about reporting when there is any ambiguity. By default, if the strand bias is stronger than a few percent. In a stranded protocol, it will report and if it infers more than a few percent of fragments no having a valid alignment. So you can always double-check samples where the strandedness is at all ambiguous. > In addition, if a transcript was aligned in a unstranded manner and ended up aligning to the wrong location due to ambiguity between the positive orientation of one transcript and the negative orientation of another, can salmon correct this by reassigning it to the right transcript based on the joint probability of all the other alignments (if you can't tell I'm at the edge of my BS zone)?. If there is not an alignment to the correct location _in addition to_ the wrong location, then no. If you run salmon in alignment mode, it will assign each fragment probabilistically to the set of transcripts to which it aligns. There is, by definition, a probability of 0 for a fragment being assigned to a location where it doesn't align. That is, the reported alignment positions should contain the true alignment. STAR is pretty good at reporting all equa",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/590#issuecomment-733417813:1074,protocol,protocol,1074,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/590#issuecomment-733417813,1,['protocol'],['protocol']
Integrability,"emature_group %in% names(gencode) & !duplicated(anot.pre$premature_group) &; anot.pre$premature_group %in% anot[anot$transcript_source == 'ensembl_havana']$transcript_id; ]$premature_group[1]. chosenOnesM <- anot.pre[; strand(anot.pre) == '-' & !grepl(';', anot.pre$premature_group) & anot.pre$premature_group %in% names(gencode) & !duplicated(anot.pre$premature_group) &; anot.pre$premature_group %in% anot[anot$transcript_source == 'ensembl_havana']$transcript_id; ]$premature_group[1]. chosenOnes <- c(chosenOnesP, chosenOnesM). # subset chosed ones; anot.ori <- anot; anot.pre.ori <- anot.pre. anot <- anot[anot$transcript_id %in% chosenOnes, ]; anot.pre <- anot.pre[anot.pre$premature_group %in% chosenOnes, ]. # sanity check (make sure strand information is the same for pre and mature RNA counterparts); all(; sort(paste(strand(anot), anot$transcript_id) %>% unique) ==; sort(paste(strand(anot.pre), anot.pre$premature_group) %>% unique); ) %>% print. ### Mature transcript sequences ####; message('Creating mature transcript sequences...'). # subset pos sorted exons, split by tx ID, concatenate exon seq per transcript using unlist; mature.tx <- lapply(; X = split(dna[anot], anot$transcript_id),; FUN = unlist; ) %>% DNAStringSet. message('... now getting reverse complements of mature transcripts on the minus strand...'). mature.tx[names(mature.tx) %in% anot[strand(anot) == '-', ]$transcript_id] <- reverseComplement(; mature.tx[names(mature.tx) %in% anot[strand(anot) == '-', ]$transcript_id]; ). ### Premature transcript sequences ####; message('Creating premature transcript sequences...'). premature.tx <- dna[anot.pre]. message('... now getting reverse complements of premature transcripts on the minus strand...'). premature.tx[names(premature.tx) %in% anot.pre[strand(anot.pre) == '-', ]$premature_group] <- reverseComplement(; premature.tx[names(premature.tx) %in% anot.pre[strand(anot.pre) == '-', ]$premature_group]; ). names(premature.tx) <- anot.pre$premature_group # paste0(a",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/655#issuecomment-826035191:7388,message,message,7388,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/655#issuecomment-826035191,1,['message'],['message']
Integrability,"ensure the following paths are set properly.; ==========================================================================; Please add /salmon/bin to your PATH; Please add /salmon/lib to your LD_LIBRARY_PATH; ==========================================================================; root@fd877e359439:/salmon/build# make test; Running tests...; Test project /salmon/build; Start 1: unit_tests; 1/2 Test #1: unit_tests ....................... Passed 0.37 sec; Start 2: salmon_read_test_quasi; 2/2 Test #2: salmon_read_test_quasi ........... Passed 1.80 sec. 100% tests passed, 0 tests failed out of 2. Total Test time (real) = 2.17 sec; ```. The `make test` command itself runs the test the builds the index and maps the reads against it. Either way, I can do that explicitly too (from within build):. ```; $ ./src/salmon index -t ../sample_data/transcripts.fasta -i sample_idx; ```. returns succesfully with a built index. ```; ...; [2023-03-10 05:51:33.748] [puff::index::jointLog] [info] Done wrapping the rank vector with a rank9sel structure.; [2023-03-10 05:51:33.748] [puff::index::jointLog] [info] contig count for validation: 23; [2023-03-10 05:51:33.748] [puff::index::jointLog] [info] Total # of Contigs : 23; [2023-03-10 05:51:33.748] [puff::index::jointLog] [info] Total # of numerical Contigs : 23; [2023-03-10 05:51:33.748] [puff::index::jointLog] [info] Total # of contig vec entries: 36; [2023-03-10 05:51:33.748] [puff::index::jointLog] [info] bits per offset entry 6; [2023-03-10 05:51:33.748] [puff::index::jointLog] [info] Done constructing the contig vector. 24; [2023-03-10 05:51:33.748] [puff::index::jointLog] [info] # segments = 23; [2023-03-10 05:51:33.748] [puff::index::jointLog] [info] total length = 19592; [2023-03-10 05:51:33.748] [puff::index::jointLog] [info] Reading the reference files ...; [2023-03-10 05:51:33.750] [puff::index::jointLog] [info] positional integer width = 15; [2023-03-10 05:51:33.750] [puff::index::jointLog] [info] seqSize = 19592; [2023-03-10",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463312554:3361,wrap,wrapping,3361,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463312554,1,['wrap'],['wrapping']
Integrability,"expression matrices with high sequencing depth depending on amount of mapped reads, if I understand well. >Use Alevin w/o any modification to the fastq on both of your sample to generate the gene count matrices. I already did that, in downstream analyses I have a batch effect issue related to the sequencing depth. >that's why we recommend using the Seurat package downstream of the Alevin quantified matrices. I have some experience with downstream analyses with Seurat, Pagoda, Scater, scanpy and a few other tools, and I am aware of batch correction methods like CCA or MNN. But that is not what I am looking for here. I did both CCA and MNN but I loose some important information in the resulting eigenspaces or corrected matrix. I believe the proper way to correct my batch effect is to simply fix the difference between my two libraries, ie. the sequencing depth in this case. As I explained in my first message, cellranger aggregate (subsampling based on the amount of mapped reads) works very well in my case, correct the effect without any loss or modification of important genes in our scientific question. Not CCA or MNN. I would like to be able to do the same from the alevin quantifications. So I am looking for a proper way to apply a correction before/during/after the alevin quantification, in a way similar to what cellranger do with STAR. Alternatively, could a subsampling covariate be added to the probalistic quantification model of alevin (if I understand it well), in sort that such a discrepency bewteen samples would be corrected?. I did look at the mappedUMI file:. ![image](https://user-images.githubusercontent.com/34892073/47551835-85ef9380-d903-11e8-893f-2a684576437b.png). So an option you would recommend is to simply compute the subsampling coefficient for a median ratio bewteen samples? I am expecting quite uneven distributions/variance in the mappedUMI between samples (partly due to a huge difference in term of proliferation that occur with a fraction of cells",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/305#issuecomment-433319913:1729,message,message,1729,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/305#issuecomment-433319913,1,['message'],['message']
Integrability,"good suggestion. [https://sites.google.com/site/ummslogos/_/rsrc/1489610858836/home/apple-icon-76x76.png]. Javier E. Irazoqui, PhD; Associate Professor; Department of Microbiology and Physiological Systems; UMass Medical School. 368 Plantation Street; Albert Sherman Center; Room AS8.1053; Worcester, MA 01605. (774) 455-3797; Skype: javierirazoqui. Confidentiality Notice:; This e-mail message, including any attachments, is for the sole use of the intended recipient(s) and may contain confidential, proprietary and privileged information. Any unauthorized review, use, disclosure or distribution is prohibited. If you are not the intended recipient, please contact the sender immediately and destroy or permanently delete all copies of the original message. On Feb 12, 2018, at 12:21 PM, Marcel Bargull <notifications@github.com<mailto:notifications@github.com>> wrote:. Hi @jirazoqui<https://github.com/jirazoqui> and @pdellorusso<https://github.com/pdellorusso>,; beware that if you install via a .tar.gz file, you make conda ignore all dependencies. It's somewhat equivalent to conda install --no-deps ... and thus I wouldn't recommend doing something like that.; Until we fix the dependencies in Bioconda, can you, if possible, use a separate Conda environment for salmon with conda create -c bioconda -c conda-forge --name salmon salmon. In this new environment you wouldn't have any dependency version conflict. —; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://github.com/COMBINE-lab/salmon/issues/194#issuecomment-364996006>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AiohHe_b7YX4kqzddLHJT7ZK6s1PhJgoks5tUHM1gaJpZM4SAonB>.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/194#issuecomment-364996252:387,message,message,387,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/194#issuecomment-364996252,5,"['depend', 'message']","['dependencies', 'dependency', 'message']"
Integrability,"he premature sequences on the minus strand as I had to do for the mature sequences. Yet, I did that anyway. I initially did test my protocol to ensure it produced identical transcript sequences to Gencode, but I only did this for mature sequences. All seemed fine for both + and - strand transcripts. After your feedback, I compared the premature sequences in my transcript fasta against the transcript fasta from Gencode. As you can see in the smoothed dot plots below, the premature sequences of transcripts on the minus strand are in the wrong orientation and have the wrong complementarity!. ![Screenshot from 2021-04-24 00-35-05](https://user-images.githubusercontent.com/10429333/115947355-0d96c880-a495-11eb-92a6-d8d2233c8d2b.png). I included my R code below for this test case for anyone who might stumble upon this issue. Under the code headers “Mature transcript sequences” and “Premature transcript sequences”, you can observe that I used identical protocols for sequence subsetting, yet in the mature case the strand information in the GRanges seems to be disregarded when subsetting from Biostrings, but in the premature case the strand information is used. Of course, this problem is out of the scope of this forum so it will be okay to close this issue. I will reach out to the developers of GenomicRanges and Biostrings to point out this potential problem and seek their guidance. Thank you again for all your help. Rached. ```; # setwd('wd'). options(scipen = 9999). libraries <- lapply(; X = c('data.table', 'magrittr', 'rtracklayer', 'Biostrings', 'reshape2', 'ggplot2'),; FUN = library, character.only = TRUE; ). ### Inputs ####; anot.gtf <- '../../shared_data/annotations/Ensembl/Homo_sapiens.GRCh38.101.gtf.gz' # Ensembl GTF; genome.fasta <- '../../shared_data/annotations/Ensembl/Homo_sapiens.GRCh38.dna.primary_assembly.fa.gz' # Genome fasta from Ensembl; gencode.tx.fasta <- '../../shared_data/annotations/Gencode/gencode.v35.transcripts.fa.gz' # Gencode transcript FASTA. do",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/655#issuecomment-826035191:3164,protocol,protocols,3164,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/655#issuecomment-826035191,1,['protocol'],['protocols']
Integrability,"hello! have you by any chance figured it out? I have quite similiar problem. . I am running salmon v.1.1.0 on my ubuntu machine with 128GB of RAM. I set the limit for vitrual memory at ~75GB to not overload the system:. ```bash; ○ → ulimit -a; core file size (blocks, -c) 0; data seg size (kbytes, -d) unlimited; scheduling priority (-e) 0; file size (blocks, -f) unlimited; pending signals (-i) 514510; max locked memory (kbytes, -l) 65536; max memory size (kbytes, -m) unlimited; open files (-n) 1024; pipe size (512 bytes, -p) 8; POSIX message queues (bytes, -q) 819200; real-time priority (-r) 0; stack size (kbytes, -s) 8192; cpu time (seconds, -t) unlimited; max user processes (-u) 514510; virtual memory (kbytes, -v) 75331648; file locks (-x) unlimited; ```. I am building the index with the following command:. ```bash; salmon index \; -t /mnt/rescomp/ref/hg38/gentrome.fa.gz \; -i /mnt/rescomp/ref/hg38/salmon_index -k 31 \; --decoys /mnt/rescomp/ref/hg38/decoys.txt \; --threads 16 \; --gencode |& tee logs/salmon_index.log; ```. gentrome is created based on the gencode transcriptome (v33) and genome primary algnment sequence (GRCh38.p13). [salmon_index.log](https://github.com/COMBINE-lab/salmon/files/4392725/salmon_index.log). The output directory:; ```; ○ → ll /mnt/rescomp/ref/hg38/salmon_index; total 7.9G; drwxr-sr-x 1 37304 723 4.0K Mar 27 01:36 ./; drwxr-sr-x 1 37304 723 4.0K Mar 26 22:13 ../; -rw-r--r-- 1 37304 723 888K Mar 27 00:32 complete_ref_lens.bin; -rw-r--r-- 1 37304 723 31K Mar 27 00:27 duplicate_clusters.tsv; -rw-r--r-- 1 37304 723 674M Mar 27 01:46 path.bin; -rw-r--r-- 1 37304 723 55 Mar 27 01:46 pre_indexing.log; -rw-r--r-- 1 37304 723 40K Mar 27 01:46 ref_indexing.log; -rw-r--r-- 1 37304 723 3.3G Mar 27 00:32 ref_k31_fixed.fa; -rw-r--r-- 1 37304 723 703 Mar 27 00:32 ref_sigs.json; -rw-r--r-- 1 37304 723 4.1G Mar 27 01:36 tmp_dbg.bin; ```; I know for a fact that the memory usage did not go over 16GB. Any hints how to proceed?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/441#issuecomment-604919589:539,message,message,539,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/441#issuecomment-604919589,1,['message'],['message']
Integrability,"hey @kvittingseerup, glad to hear you find refgenie useful. . Currently, there is no way to view the recipe inputs using the web interface or server API. That said, it is possible to track this information down... For example, for [`hg38/salmon_sa_index`](http://refgenomes.databio.org/v2/asset/hg38/salmon_sa_index/splash?tag=default) asset look at the ""asset_parents"" section to find out what assets were used to create the salmon index. Then, by looking at [this file](https://github.com/refgenie/refgenomes.databio.org/blob/master/asset_pep/recipe_inputs.csv) you can find out what are the sources of the files we used to create the parent `fasta*` assets in question. . As an aside, we're working on a [new recipe system](https://github.com/refgenie/refgenie/issues/198) that will enable serving this kind of data on http://refgenomes.databio.org/.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/614#issuecomment-770049957:129,interface,interface,129,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/614#issuecomment-770049957,1,['interface'],['interface']
Integrability,"hi @k3yavi,. Thanks for your help! I'm glad it's a quick fix. As for the dataset, I am not sure why the read length is 25bp. The [paper I pulled it from](https://www.ncbi.nlm.nih.gov/pubmed/29545397) stated that they used the standard DropSeq protocol and did not seem to mention and changes in CB and UMI length. In the case that they did change those lengths, what options can I use to set the pipeline?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/258#issuecomment-408179330:243,protocol,protocol,243,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/258#issuecomment-408179330,1,['protocol'],['protocol']
Integrability,"i didn't try to fix the star index, it was created automatically by the; bcbio_nextgen pipeline i was using. i did add my story to the issue in the; star github repo mentioned in the biostars thread:; https://github.com/alexdobin/STAR/issues/1140. On Tue, Aug 2, 2022 at 11:27 AM HeedukOh ***@***.***> wrote:. > i ran into the same problem and apparently it's a STAR issue:; > https://www.biostars.org/p/486346/; >; > ""...it seems STAR is doing something during the indexing step which is; > causing a slight mismatch for 23 of the transcripts.""; >; > Hi,; > Thanks for the reply!; > I see that you used Salmon for indexing to get around this issue. Did you; > figure out a way to make STAR work after that, or did you stick with Salmon?; >; > —; > Reply to this email directly, view it on GitHub; > <https://github.com/COMBINE-lab/salmon/issues/785#issuecomment-1202823526>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/ABGJSQSM6CJ2GDKQF3UOZKLVXE47NANCNFSM5ZOT3OOQ>; > .; > You are receiving this because you commented.Message ID:; > ***@***.***>; >",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/785#issuecomment-1205698238:1047,Message,Message,1047,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/785#issuecomment-1205698238,1,['Message'],['Message']
Integrability,"ing incorrectly_**. Now to my answer(s) and logic:; 1. With fastp, I am not sure if adapter trimming happens first and then quality trimming OR vice-versa. I could not find info on this from their README and **_I could be wrong here with my next line_** - [Based on Figure 1 of this paper, it looks to me as though quality trimming is done before adapter trimming](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6129281/figure/bty560-F1/). - [To quote Brian Bushnell (author of BBTools)]( http://seqanswers.com/forums/showpost.php?p=140819&postcount=5), . > It's best to do adapter-trimming first, then quality-trimming, because if you do quality-trimming first, sometimes adapters will be partially trimmed and become too short to be recognized as adapter sequence. When you run BBDuk with both quality-trimming and adapter-trimming in the same run, it will do adapter-trimming first, then quality-trimming. 2. I very well know that the advantage of using fastp is that it can do adapter trimming, etc in a automatic fashion - no need to provide external sequences (example adapter sequences). Yes, I know one can also provide a fasta file of adapters and fatsp will work off it. There are many fatsp issues in GH about adapter detection:. - fail to detect adpaters automatically - (https://github.com/OpenGene/fastp/issues/222 and https://github.com/OpenGene/fastp/issues/205). - [incorrect automatic adapter detection](https://github.com/OpenGene/fastp/issues/240). - [inconsistent behavior with different runs](https://github.com/OpenGene/fastp/issues/231). 3. When I see the above, I am bit skeptical using fastp for qc/adapter trimming. . After lot of trials with bbduk and fastp, I have decided to use bbduk and bbmap for my high throughput analysis. Below, I explain my reasoning behind those choices: . **_```Note - edited this on 02-Apr-2020 to have the correct order of operations ```_** . 1. **_STEP 1 - run bbmap.sh on raw fatsq file to remove contaminants as appropriate (rRNA, mitochondri",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-597393209:1161,adapter,adapter,1161,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-597393209,2,['adapter'],['adapter']
Integrability,"inly does seem very low. To answer your specific questions first:; 1) I'm not sure --- let's try tor find out; 2) I don't think so (if they are part of your index, they should be aligned against); 3) If there are many transcripts / targets you expect to be sequenced but which aren't present in this set, that can affect the mapping rate, but not likely to take it down to 6%. Here are the things I'd investigate --- roughly in order: . 1) In addition to the fraction of reads STAR mapped (which you report above), what fraction of the reads are assigned to features by featureCounts? In some cases, when there is a failure of rRNA depletion of polyA selection, you can end up with an experiment where most of the sequenced RNA comes from rRNA not present in the reference transcriptome. In this case, STAR will be able to align the reads to the genome, but you won't see these reads mapping to annotated features (and you also won't see them showing up in your transcript level quantifications). So, it may be worth to take a look at the count of reads assigned to the feature set of genes by featureCounts. 2) Above, it looks like a considerable number of fragments were discarded due to no alignment reaching the required alignment score (`11,448,458` fragments discarded because of this). Have you tried to adapter / quality trim the data? Does this have any effect on the mapping rate?. 3) If the above don't reveal any clues, I'd be happy to try to take a look at the data if you can share it. I'd be quite surprised if STAR is aligning a lot of reads *to transcriptome features* that are being missed by salmon. Nonetheless, if you pass the proper flags to STAR (including `--quantMode TranscriptomeSAM`), then you can use the SAM/BAM file generated by STAR to perform quantification with salmon (i.e. use STAR's alignments to do _transcript-level_ quantification). I'd be happy to help dig further on any of these, so please feel free to reach out if you find anything interesting. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/661#issuecomment-846251054:1381,adapter,adapter,1381,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/661#issuecomment-846251054,1,['adapter'],['adapter']
Integrability,"latest commit https://github.com/COMBINE-lab/salmon/commit/093b5a98e16cab7c3934c0a7c222549644c39728 will generalize the `write_fastq` for all the protocols. @PeteHaitch Thanks again for making the pull request, do let us know how does the quantified matrix looks at the end for the Cel-Seq2 protocol or what more we can do in Alevin to help improve the results. Closing this issue for now but feel free to open it again if have any other problem.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/269#issuecomment-418789461:146,protocol,protocols,146,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/269#issuecomment-418789461,2,['protocol'],"['protocol', 'protocols']"
Integrability,"lt still segfaults. It still needed an edit of the CMakeLists.txt file. Still, for future reference:. ```; pversion=1.2.1; package=salmon; TOPDIR=/usr/common/modules/el8/x86_64/software/${package}/${pversion}-CentOS-vanilla; wget https://github.com/COMBINE-lab/salmon/archive/v1.2.1.tar.gz; gunzip -c v1.2.1.tar.gz | tar -xf -; /bin/rm v1.2.1.tar.gz; cd ${package}-${pversion}; mv CMakeLists.txt CMakeLists.txt.dist; cat >mypatch <<'EOD'; --- CMakeLists.txt.dist	2020-04-21 22:31:07.000000000 -0700; +++ CMakeLists.txt	2020-06-09 14:55:02.733885772 -0700; @@ -419,6 +419,10 @@; find_package(Boost 1.59.0 COMPONENTS iostreams filesystem system timer chrono program_options); message(""BOOST_INCLUDEDIR = ${BOOST_INCLUDEDIR}""); message(""BOOST_LIBRARYDIR = ${BOOST_LIBRARYDIR}""); +message(""Forcing Boost_FOUND to TRUE""); +set(Boost_FOUND TRUE); +set(Boost_LIBRARY_DIRS ""/usr/lib64/boost169""); +set(Boost_LIBRARIES -lboost_iostreams -lboost_filesystem -lboost_system -lboost_timer -lboost_chrono -lboost_program_options); message(""Boost_FOUND = ${Boost_FOUND}""); endif(); ; EOD; patch -p0 <mypatch; module load cmake; module load io_lib; module load libgff; module load libtbb; mkdir build; cd build; export CFLAGS=""-g -O0""; export CXXFLAGS=""-g -O0""; cmake \; -DCMAKE_INSTALL_PREFIX=$TOPDIR \; -DSTADEN_ROOT=$ROOT_IO_LIB \; -DGFF_ROOT=$ROOT_LIBGFF \; -DTBB_ROOT=$ROOT_LIBTBB \; -DCMAKE_VERBOSE_MAKEFILE:BOOL=ON \; -DBOOST_LIBRARYDIR=/usr/lib64/boost169 \; -DBOOST_INCLUDEDIR=/usr/include/boost169 \; -DBoost_NO_SYSTEM_PATHS=ON \; .. 2>&1 | tee cmake_2020_06_09.log; make -j 4 2>&1 | tee build_2020_06_09.log. ```. Since it was compiled ""-g -O0"" this time it was easier to step through it. Well, somewhat. In Salmon.cpp line 195 is the last place a break point works. If one is set for 197 it segfaults before reaching it. Line 195 is:. `	 po::store(parsed, vm);; `; I tried briefly to trace inward from there but couldn't make heads or tails of the path it was taking through an endless series of headers.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641612831:722,message,message,722,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641612831,4,['message'],['message']
Integrability,may be try creating a new environment and/or specify the version of salmon you wan't to install ? it can happen sometimes based on the dependency structure already installed in your environment. You can also the pre build binaries from https://github.com/COMBINE-lab/salmon/releases. It's more of an issue with conda than salmon itself. Closing this one but let us know if you still face any issue.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/461#issuecomment-565296541:135,depend,dependency,135,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/461#issuecomment-565296541,1,['depend'],['dependency']
Integrability,"mming OR vice-versa. I could not find info on this from their README and **_I could be wrong here with my next line_** - [Based on Figure 1 of this paper, it looks to me as though quality trimming is done before adapter trimming](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6129281/figure/bty560-F1/). - [To quote Brian Bushnell (author of BBTools)]( http://seqanswers.com/forums/showpost.php?p=140819&postcount=5), . > It's best to do adapter-trimming first, then quality-trimming, because if you do quality-trimming first, sometimes adapters will be partially trimmed and become too short to be recognized as adapter sequence. When you run BBDuk with both quality-trimming and adapter-trimming in the same run, it will do adapter-trimming first, then quality-trimming. 2. I very well know that the advantage of using fastp is that it can do adapter trimming, etc in a automatic fashion - no need to provide external sequences (example adapter sequences). Yes, I know one can also provide a fasta file of adapters and fatsp will work off it. There are many fatsp issues in GH about adapter detection:. - fail to detect adpaters automatically - (https://github.com/OpenGene/fastp/issues/222 and https://github.com/OpenGene/fastp/issues/205). - [incorrect automatic adapter detection](https://github.com/OpenGene/fastp/issues/240). - [inconsistent behavior with different runs](https://github.com/OpenGene/fastp/issues/231). 3. When I see the above, I am bit skeptical using fastp for qc/adapter trimming. . After lot of trials with bbduk and fastp, I have decided to use bbduk and bbmap for my high throughput analysis. Below, I explain my reasoning behind those choices: . **_```Note - edited this on 02-Apr-2020 to have the correct order of operations ```_** . 1. **_STEP 1 - run bbmap.sh on raw fatsq file to remove contaminants as appropriate (rRNA, mitochondrial, chloroplast)_**; - You have alluded to the importance of removing contaminants [in this post](https://github.com/COMBINE-lab/salmo",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-597393209:1324,adapter,adapters,1324,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-597393209,1,['adapter'],['adapters']
Integrability,"nds ""Unix Makefiles"" /Users/gabriel/Projects/salmon-0.13.1 /Users/gabriel/Projects/salmon-0.13.1 /Users/gabriel/Projects/salmon-0.13.1/build /Users/gabriel/Projects/salmon-0.13.1/build /Users/gabriel/Projects/salmon-0.13.1/build/CMakeFiles/libcereal.dir/DependInfo.cmake --color=; /Applications/Xcode.app/Contents/Developer/usr/bin/make -f CMakeFiles/libcereal.dir/build.make CMakeFiles/libcereal.dir/build; make[2]: Nothing to be done for `CMakeFiles/libcereal.dir/build'.; [ 8%] Built target libcereal; /Applications/Xcode.app/Contents/Developer/usr/bin/make -f CMakeFiles/libstadenio.dir/build.make CMakeFiles/libstadenio.dir/depend; cd /Users/gabriel/Projects/salmon-0.13.1/build && /usr/local/Cellar/cmake/3.13.4/bin/cmake -E cmake_depends ""Unix Makefiles"" /Users/gabriel/Projects/salmon-0.13.1 /Users/gabriel/Projects/salmon-0.13.1 /Users/gabriel/Projects/salmon-0.13.1/build /Users/gabriel/Projects/salmon-0.13.1/build /Users/gabriel/Projects/salmon-0.13.1/build/CMakeFiles/libstadenio.dir/DependInfo.cmake --color=; /Applications/Xcode.app/Contents/Developer/usr/bin/make -f CMakeFiles/libstadenio.dir/build.make CMakeFiles/libstadenio.dir/build; [ 9%] Performing configure step for 'libstadenio'; cd /Users/gabriel/Projects/salmon-0.13.1/external/staden-io_lib && ./configure --enable-shared=no --without-libcurl --prefix=/Users/gabriel/Projects/salmon-0.13.1/external/install LDFLAGS= CFLAGS= CC=/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/cc CXX=/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/c++; checking for a BSD-compatible install... /usr/local/bin/ginstall -c; checking whether build environment is sane... yes; checking for a thread-safe mkdir -p... /usr/local/bin/gmkdir -p; checking for gawk... gawk; checking whether make sets $(MAKE)... yes; checking whether make supports nested variables... yes; checking whether to enable maintainer-specific portions of Makefiles... no; checking for gcc... /A",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/348#issuecomment-472500713:1778,Depend,DependInfo,1778,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/348#issuecomment-472500713,1,['Depend'],['DependInfo']
Integrability,"nerates the compacted colored de Bruijn graph from the input sequence is based on a very elegant algorithm that couples a Bloom filter with an exact hash table, and makes two (or more) passes over the input to identify all of the junctions in the reference (which directly implies all unitigs). To make the algorithm work efficiently, one needs to have an estimate for the number of distinct k-mers that will be encountered in the reference sequence. If the estimate is too big, one wastes memory. If the estimate is too small, the Bloom filter is not big enough, it doesn't filter efficiently, and the algorithm ends up putting way too much data in the exact hash table. In order to determine how to set the Bloom filter size appropriately, we take the following approach. If the Bloom filter size isn't provided directly (_note_: this is _not_ the same as the k-mer size, this is an estimate of the total number of distinct k-mers in the entire input data), then we make a call to a function defined in the [ntCard](https://github.com/bcgsc/ntCard) library. This is a program designed specifically for cardinality estimation of k-mers in sequencing data. Based on the estimated number of distinct k-mers, we use the standard equations (derived from the theory behind Bloom filters) to set the Bloom filter to be of the smallest possible size that still achieves a relatively low, pre-specified, false positive rate. The message you are seeing is that the estimates suggest the Bloom filter should be of size 2^28 *bits*, which is ~ 33.55MB — pretty small, actually. This is because ntCard estimated 12,754,610 distinct k-mers (31-mers) in your input dataset, which doesn't seem unreasonable. In short, I think the output you observe here seems completely reasonable and in line with the data you are providing. However, I understand how all of this output might to make sense if you're not familiar with everything going on behind the scenes. Please let me know if this answers your question. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/510#issuecomment-616713186:2418,message,message,2418,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/510#issuecomment-616713186,1,['message'],['message']
Integrability,"nes, ]; anot.pre <- anot.pre[anot.pre$premature_group %in% chosenOnes, ]. # sanity check (make sure strand information is the same for pre and mature RNA counterparts); all(; sort(paste(strand(anot), anot$transcript_id) %>% unique) ==; sort(paste(strand(anot.pre), anot.pre$premature_group) %>% unique); ) %>% print. ### Mature transcript sequences ####; message('Creating mature transcript sequences...'). # subset pos sorted exons, split by tx ID, concatenate exon seq per transcript using unlist; mature.tx <- lapply(; X = split(dna[anot], anot$transcript_id),; FUN = unlist; ) %>% DNAStringSet. message('... now getting reverse complements of mature transcripts on the minus strand...'). mature.tx[names(mature.tx) %in% anot[strand(anot) == '-', ]$transcript_id] <- reverseComplement(; mature.tx[names(mature.tx) %in% anot[strand(anot) == '-', ]$transcript_id]; ). ### Premature transcript sequences ####; message('Creating premature transcript sequences...'). premature.tx <- dna[anot.pre]. message('... now getting reverse complements of premature transcripts on the minus strand...'). premature.tx[names(premature.tx) %in% anot.pre[strand(anot.pre) == '-', ]$premature_group] <- reverseComplement(; premature.tx[names(premature.tx) %in% anot.pre[strand(anot.pre) == '-', ]$premature_group]; ). names(premature.tx) <- anot.pre$premature_group # paste0(anot.pre$premature_group, '_premature') # premature rna indicator. ### Dot plots ####; smoothDot <- function(s1, s2, w = 10) {. s1a <- sapply(; X = 1:(length(s1) - w + 1),; function(z) paste(s1[ z:(z + w - 1) ], collapse = ''); ). s2a <- sapply(; X = 1:(length(s2) - w + 1),; function(z) paste(s2[ z:(z + w - 1) ], collapse = ''); ). s2b <- sapply( # considering the reversed y sequence per window; X = 1:(length(s2) - w + 1),; function(z) paste(s2[ z:(z + w - 1) ] %>% rev, collapse = ''); ). outer(s1a, s2a, FUN = '==') | outer(s1a, s2b, FUN = '=='); }. to.plot <- lapply(; setNames(nm = chosenOnes),; function(x) {. # out <- outer(as.vector",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/655#issuecomment-826035191:8029,message,message,8029,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/655#issuecomment-826035191,1,['message'],['message']
Integrability,"not.ori <- anot; anot.pre.ori <- anot.pre. anot <- anot[anot$transcript_id %in% chosenOnes, ]; anot.pre <- anot.pre[anot.pre$premature_group %in% chosenOnes, ]. # sanity check (make sure strand information is the same for pre and mature RNA counterparts); all(; sort(paste(strand(anot), anot$transcript_id) %>% unique) ==; sort(paste(strand(anot.pre), anot.pre$premature_group) %>% unique); ) %>% print. ### Mature transcript sequences ####; message('Creating mature transcript sequences...'). # subset pos sorted exons, split by tx ID, concatenate exon seq per transcript using unlist; mature.tx <- lapply(; X = split(dna[anot], anot$transcript_id),; FUN = unlist; ) %>% DNAStringSet. message('... now getting reverse complements of mature transcripts on the minus strand...'). mature.tx[names(mature.tx) %in% anot[strand(anot) == '-', ]$transcript_id] <- reverseComplement(; mature.tx[names(mature.tx) %in% anot[strand(anot) == '-', ]$transcript_id]; ). ### Premature transcript sequences ####; message('Creating premature transcript sequences...'). premature.tx <- dna[anot.pre]. message('... now getting reverse complements of premature transcripts on the minus strand...'). premature.tx[names(premature.tx) %in% anot.pre[strand(anot.pre) == '-', ]$premature_group] <- reverseComplement(; premature.tx[names(premature.tx) %in% anot.pre[strand(anot.pre) == '-', ]$premature_group]; ). names(premature.tx) <- anot.pre$premature_group # paste0(anot.pre$premature_group, '_premature') # premature rna indicator. ### Dot plots ####; smoothDot <- function(s1, s2, w = 10) {. s1a <- sapply(; X = 1:(length(s1) - w + 1),; function(z) paste(s1[ z:(z + w - 1) ], collapse = ''); ). s2a <- sapply(; X = 1:(length(s2) - w + 1),; function(z) paste(s2[ z:(z + w - 1) ], collapse = ''); ). s2b <- sapply( # considering the reversed y sequence per window; X = 1:(length(s2) - w + 1),; function(z) paste(s2[ z:(z + w - 1) ] %>% rev, collapse = ''); ). outer(s1a, s2a, FUN = '==') | outer(s1a, s2b, FUN = '=='); }. ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/655#issuecomment-826035191:7943,message,message,7943,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/655#issuecomment-826035191,1,['message'],['message']
Integrability,"nt algorithms like Bowtie2 and BWA-MEM with respect to both sensitivity and specificity. Here, you are likely seeing a manifestation of the former. Specifically, greedy behavior can lead to spurious matches. Many of these spurious matches are filtered out when applying a consensus mechanism to the series of matches produced by a read; however, this can result in the read going unmapped. We have noticed this behavior where spurious matches can ""mask"" better overall mappings, and we have developed an algorithm to overcome these limitations (called selective-alignment). This is currently implemented in [this branch](https://github.com/COMBINE-lab/salmon/tree/rescue-orphan) of the Salmon repo (if you want to test it out and have trouble building, we can build you a linux executable). This algorithm explores more potential mappings and then applies a fast algorithm for filtering potentially poor ones. In our benchmarks, it exhibits sensitivity and specificity very close to Bowtie2 (which is among the best of the alignment-based methods we considered). Also, I will note that, though the speed and statistical optimization procedures used in fast transcript abundance estimation tools make them a potentially desirable choice for microbiomic / metagenomic abundance estimation, their indices are typically optimized for speed and not size. For small numbers of bacterial species this can be okay, but if one wishes to index large collections of species, the memory usage can become a problem. To this end, we have developed a new indexing scheme (software [here](https://github.com/COMBINE-lab/pufferfish), slightly out-of-date pre-print [here](https://www.biorxiv.org/content/early/2017/09/21/191874)). That code already implements a tool for taxonomic read assignment (a la the excellent [Kraken](https://github.com/DerrickWood/kraken)), but not yet abundance estimation (that is coming soon). So, depending on how much you want to scale up, you might want to keep an eye on that as well.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/196#issuecomment-365337297:2237,depend,depending,2237,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/196#issuecomment-365337297,1,['depend'],['depending']
Integrability,"odel for data generated from any technology and that's what we have been trying to do with salmon for years, piece by piece. Having said that, we don't mean to discourage people from trying salmon, that's one of the way we learn how can we improve the model even further. Now, coming back to your original question about using QuantSeq with salmon and how the paper above approach to solve it. I have a couple of thoughts:; 1.) Like you said, from the reading of their command line argument they didn't use the `nolengthcorrection` and I am surprised about the results myself. Since you have experience with the technology, you are best person to explore the difference in using and not using the length correction with salmon, that's why I shared.; 2.) Salmon models the transcript lengths in its quantification model. The basic intuition being longer length transcripts have higher probability of a read being sampled from them and has to be corrected for when using relative count metrices (like TPM) to avoid length bias. The logic behind `noLengthCorrection` is to _not_ correct for length for 3' protocol since we expect all the reads from one end of the transcript and if we do length correction, I hypothesize, we might end up biasing the estimates on the opposite direction; however the effect size of this hypothesis is still an open question and seemingly from the results from the paper it has minor effect. On the flip side may be it does have effect but their baseline estimates were not great and any improvement is good, for that again since you have experience with the data it's good to know / test what's going on.; 3.) A little experimental thought, although `noLengthCorrection` flag can generate decent estimates, it's actually fully disabling the length effect, which in my opinion we can do better as you look at Figure 1B of the paper it shows some length based affect but again we don't know how much difference it can create in generating the estimates. . I Hope it helps .",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-565256512:2085,protocol,protocol,2085,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-565256512,1,['protocol'],['protocol']
Integrability,"omatic adapter detection](https://github.com/OpenGene/fastp/issues/240). - [inconsistent behavior with different runs](https://github.com/OpenGene/fastp/issues/231). 3. When I see the above, I am bit skeptical using fastp for qc/adapter trimming. . After lot of trials with bbduk and fastp, I have decided to use bbduk and bbmap for my high throughput analysis. Below, I explain my reasoning behind those choices: . **_```Note - edited this on 02-Apr-2020 to have the correct order of operations ```_** . 1. **_STEP 1 - run bbmap.sh on raw fatsq file to remove contaminants as appropriate (rRNA, mitochondrial, chloroplast)_**; - You have alluded to the importance of removing contaminants [in this post](https://github.com/COMBINE-lab/salmon/issues/160#issuecomment-334762498); >However, the other thing to try is simply to align one of these samples to the genome with a tool like STAR or HISAT2 and look at their mapping rate to known features. If it's similar, then the other reads could be accounted for by e.g. intron retention or even contamination. Finally, [@vals has an excellent series of blog posts on investigating and addressing low mapping rates](http://www.nxn.se/valent/2017/9/18/low-mapping-rate-5-human-dna-contamination); - bbmap Command ([based of this biostars post](https://www.biostars.org/p/143019/#210890)):; `bbmap.sh in=read_1.fq.gz ref=rRNA_Chlor_Mito.fa maxindel=1 minid=0.95 outu=clean_read_1.fq.gz nodisk`; - Strategy:; `use the rRNA+Mito+Chloroplast file and map the reads using bbmap, then collect the unmapped reads (clean_read_1.fq.gz) for my downstream analysis`. 2. **_STEP 2 - run bbduk.sh on the outu files from bbmap step -- the outu stands for output unmapped - as stated in the logic above, anything that is unmapped to the rRNA_Chlor_Mito.fa is a clean read for downstream analysis_**. I use bbduk with adapter trimming and quality trimming in same command line - also, the adapters.fa file that ships with BBTools can be used in all runs. Hope that helps.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-597393209:3423,adapter,adapter,3423,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-597393209,2,['adapter'],"['adapter', 'adapters']"
Integrability,"ou'd expect to get more mappings) than when you specify ""ISR"". The ""A"" flag just looks at how the first 10,000 reads map and guesses the library type based on that. On thing to make sure of is that your reads aren't ""ordered"" in any way, such that you'd expect the first 10,000 to deviate in any meaningful way from the statistics of the reads of the reads. > Is it better to build assemblies with strand-aware flags? If so, does it usually make a large difference to quantification results, or a minor one? I don't know what protocol the sequencing facility used, but I am sure I could ask them. I gather from my recent reading that the extra information gained by using a stranded protocol is worthwhile, so I would expect that the sequencing facility used one, but why doesn't Trinity or MEGAHIT detect the sequecing protocol that was used? . So there are really 2 questions here. *If* the data are stranded, then yes, it's worthwhile to use stranded flags in both assembly and quantification. This is because stranded protocols will allow you to better disambiguate (a) overlapping genes and (b) reads that are ambiguous between sequence-similar genes that happen to reside on different strands. The *second* question is why Trinity or MEGAHIT wouldn't detect this. The main reason for this is that these are assembly tools. Without access to a reference genome, there is no principled way for these tools to know what the orientation of a read is _a priori_, so they generally rely on the user to specify if the reads are stranded or unstranded. > Or, if you have to specify it, why do none of the example Trinity commands I've come across include this option? It doesn't strike me as a commonly used specification in making assemblies. The Trinity command to specify the strandedness is `--SS_lib_type` (see e.g. [here](https://scilifelab.github.io/courses/ngsintro/1604/labs/rnaseqDenovo)). By default, Trinity will assume unstranded reads (as that's the safest default assumption). Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/840#issuecomment-1493034427:1486,protocol,protocols,1486,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/840#issuecomment-1493034427,1,['protocol'],['protocols']
Integrability,"owcell1/read-I1_si-CGAAGTTG_lane-001-chunk-001.fastq.gz; ./fastq/fastqs/flowcell1/read-I1_si-CGAAGTTG_lane-002-chunk-000.fastq.gz; ./fastq/fastqs/flowcell1/read-I1_si-CGAAGTTG_lane-003-chunk-003.fastq.gz; ./fastq/fastqs/flowcell1/read-I1_si-CGAAGTTG_lane-004-chunk-002.fastq.gz; ./fastq/fastqs/flowcell1/read-I1_si-GAGCACGC_lane-001-chunk-001.fastq.gz; ./fastq/fastqs/flowcell1/read-I1_si-GAGCACGC_lane-002-chunk-000.fastq.gz; ./fastq/fastqs/flowcell1/read-I1_si-GAGCACGC_lane-003-chunk-003.fastq.gz; ./fastq/fastqs/flowcell1/read-I1_si-GAGCACGC_lane-004-chunk-002.fastq.gz; ./fastq/fastqs/flowcell1/read-I1_si-TTCGTGAA_lane-001-chunk-001.fastq.gz; ./fastq/fastqs/flowcell1/read-I1_si-TTCGTGAA_lane-002-chunk-000.fastq.gz; ./fastq/fastqs/flowcell1/read-I1_si-TTCGTGAA_lane-003-chunk-003.fastq.gz; ./fastq/fastqs/flowcell1/read-I1_si-TTCGTGAA_lane-004-chunk-002.fastq.gz]; Version Info: This is the most recent version of salmon.; [2018-12-06 11:14:56.513] [alevinLog] [info] A custom protocol (END, BC length, UMI length) = (5, 14, 5) is being used. Updating UMI k-mer length accordingly.; Logs will be written to ./fastq/test/logs; [2018-12-06 11:14:56.533] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; ### alevin (dscRNA-seq quantification) v0.12.0; ### [ program ] => salmon ; ### [ command ] => alevin ; ### [ libType ] => { ISR }; ### [ gemcode ] => { }; ### [ index ] => { ./transcripts_index_salmon/ }; ### [ threads ] => { 8 }; ### [ output ] => { ./fastq/test/ }; ### [ tgMap ] => { ./hg_transcriptome/tx2tx.tsv }; ### [ end ] => { 5 }; ### [ umiLength ] => { 5 }; ### [ barcodeLength ] => { 14 }; ### [ dumpCsvCounts ] => { }; ### [ mates1 ] => { /tmp/tmp.p28w2nGvAn/p1.fa }; ### [ mates2 ] => { /tmp/tmp.p28w2nGvAn/p2.fa }; ### [ unmatedReads ] => { ./fastq/fastqs/flowcell1/read-I1_si-ACTTCACT_lane-001-chunk-001.fastq.gz ./fastq/fastqs/flowcell1/read-I1_si-ACTTCACT_lane-002-chunk-000.fastq.gz ./fastq/fastqs/flowcell1/read-I",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/328#issuecomment-445008548:2046,protocol,protocol,2046,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/328#issuecomment-445008548,1,['protocol'],['protocol']
Integrability,"probably unrelated, but also unexpected. Make test on my linux and osx box looks like:. ```; $ make test; Running tests...; Test project /Users/rob/salmon/build; Start 1: unit_tests; 1/3 Test #1: unit_tests ....................... Passed 0.13 sec; Start 2: salmon_read_test_fmd; 2/3 Test #2: salmon_read_test_fmd ............. Passed 0.87 sec; Start 3: salmon_read_test_quasi; 3/3 Test #3: salmon_read_test_quasi ........... Passed 0.39 sec. 100% tests passed, 0 tests failed out of 3. Total Test time (real) = 1.41 sec; ```. It looks the same on the continuous integration server : . ```; Running tests...; /usr/local/cmake-3.9.2/bin/ctest --force-new-ctest-process ; Test project /home/travis/build/COMBINE-lab/salmon/build; Start 1: unit_tests; 1/3 Test #1: unit_tests ....................... Passed 0.13 sec; Start 2: salmon_read_test_fmd; 2/3 Test #2: salmon_read_test_fmd ............. Passed 2.55 sec; Start 3: salmon_read_test_quasi; 3/3 Test #3: salmon_read_test_quasi ........... Passed 1.72 sec; 100% tests passed, 0 tests failed out of 3; Total Test time (real) = 4.41 sec; ```. Also, you can look, in the build directory, in the subdirectory `Testing/Temporary/LastTestsFailed.log` which will give details of which specific test failed.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/229#issuecomment-393676260:562,integrat,integration,562,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/229#issuecomment-393676260,1,['integrat'],['integration']
Integrability,"quality-trimming, because if you do quality-trimming first, sometimes adapters will be partially trimmed and become too short to be recognized as adapter sequence. When you run BBDuk with both quality-trimming and adapter-trimming in the same run, it will do adapter-trimming first, then quality-trimming. 2. I very well know that the advantage of using fastp is that it can do adapter trimming, etc in a automatic fashion - no need to provide external sequences (example adapter sequences). Yes, I know one can also provide a fasta file of adapters and fatsp will work off it. There are many fatsp issues in GH about adapter detection:. - fail to detect adpaters automatically - (https://github.com/OpenGene/fastp/issues/222 and https://github.com/OpenGene/fastp/issues/205). - [incorrect automatic adapter detection](https://github.com/OpenGene/fastp/issues/240). - [inconsistent behavior with different runs](https://github.com/OpenGene/fastp/issues/231). 3. When I see the above, I am bit skeptical using fastp for qc/adapter trimming. . After lot of trials with bbduk and fastp, I have decided to use bbduk and bbmap for my high throughput analysis. Below, I explain my reasoning behind those choices: . **_```Note - edited this on 02-Apr-2020 to have the correct order of operations ```_** . 1. **_STEP 1 - run bbmap.sh on raw fatsq file to remove contaminants as appropriate (rRNA, mitochondrial, chloroplast)_**; - You have alluded to the importance of removing contaminants [in this post](https://github.com/COMBINE-lab/salmon/issues/160#issuecomment-334762498); >However, the other thing to try is simply to align one of these samples to the genome with a tool like STAR or HISAT2 and look at their mapping rate to known features. If it's similar, then the other reads could be accounted for by e.g. intron retention or even contamination. Finally, [@vals has an excellent series of blog posts on investigating and addressing low mapping rates](http://www.nxn.se/valent/2017/9/18/low-mappin",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-597393209:1805,adapter,adapter,1805,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-597393209,1,['adapter'],['adapter']
Integrability,"r_data.py"", line 145, in query; self.load(); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/conda/core/subdir_data.py"", line 210, in load; _internal_state = self._load(); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/conda/core/subdir_data.py"", line 375, in _load; raw_repodata_str = fetch_repodata_remote_request(; File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/conda/core/subdir_data.py"", line 701, in fetch_repodata_remote_request; resp = session.get(join_url(url, filename), headers=headers, proxies=session.proxies,; File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/requests/sessions.py"", line 542, in get; return self.request('GET', url, **kwargs); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/requests/sessions.py"", line 529, in request; resp = self.send(prep, **send_kwargs); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/requests/sessions.py"", line 645, in send; r = adapter.send(request, **kwargs); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/requests/adapters.py"", line 413, in send; conn = self.get_connection(request.url, proxies); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/requests/adapters.py"", line 308, in get_connection; raise InvalidProxyURL(""Please check proxy URL. It is malformed""; requests.exceptions.InvalidProxyURL: Please check proxy URL. It is malformed and could be missing the host. `$ /usr/local/bin/conda install salmon`. environment variables:; CIO_TEST=<not set>; CONDA_ROOT=/usr/local/Caskroom/miniforge/base; CURL_CA_BUNDLE=<not set>; INFOPATH=/opt/homebrew/share/info:; MANPATH=/opt/homebrew/share/man::; PATH=/opt/homebrew/bin:/opt/homebrew/sbin:/usr/local/bin:/usr/bin:/bin:/usr; /sbin:/sbin; REQUESTS_CA_BUNDLE=<not set>; SSL_CERT_FILE=<not set>; all_proxy=<set>. active environment : None; user config file : /Users/Benjamin/.condarc; populated config files : /usr/local/Cas",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/724#issuecomment-1171208515:4411,adapter,adapter,4411,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/724#issuecomment-1171208515,1,['adapter'],['adapter']
Integrability,"ranscriptome (with no decoys) gives me a mapping rate of `0.00378202832148367%`. The first thing I did was to quality and adapter trim the data (using `fastp -i SRR9007475.fastq.gz -o SRR9007475_trimmed.fastq.gz -q 10 -w 8`) and ... whoa. This is the fastp html report [fastp.html.zip](https://github.com/COMBINE-lab/salmon/files/4176345/fastp.html.zip). So the first astounding statistic, the mean read length before trimming is 51bp (these are relatively short single-end reads). The mean read length after trimming is 21bp! So, the average read length is, in fact, less than the k-mer length used for indexing (default is k=31). On the trimmed data, the mapping rate goes up to `2.3545475882931305%`, still very low, but now there's somewhat of an explanation, the average read is shorter than a single k-mer. So, the next thing I tried was indexing with a smaller k; a _really_ small one in this case,`k=15`. Then, I re-ran on the _trimmed_ reads (the fact that the trimming took us from 51-21bp suggests that the reads had a lot of low quality bases, adapter contamination, or both). Under this setting, I still get a very low mapping rate, but it was _much_ higher — `16.766993524863488%`. The final thing I tried was seeing how the mapping rate changed as I altered `--minScoreFraction`, which is the salmon parameter that determines the alignment score that a read must achieve in order to be mapped validly. The default is 0.65. This means that the read cannot have a score < 0.65 * the maximum achievable score for the read given it's length. In the case of a 21bp read, the best score would be a score of 42, so a read must obtain a score >= 27 in order to be mapped. This is already a pretty poor mapping, but I reduced it even more to 0.3 (so any read with a score > 12 would pass). This led to a mapping rate of `~46%`. However, at this point, I'm not sure I would be confident in such mappings. For example, the situation here would be a 21bp read with multiple mismatches and, much of",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/482#issuecomment-583799668:1452,adapter,adapter,1452,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/482#issuecomment-583799668,1,['adapter'],['adapter']
Integrability,"referred to as QS in the rest of the message(s))_ ?. `salmon quant --threads 16 --noLengthCorrection --validateMappings --numBootstraps 100 -l SF -i <path_to_SAF_Gentrome_Index> -r <SE_READ_1.fq> -o <salmon_SE_READ_1>`. I chose the above command line options (`especially --noLengthCorrection`) based on [Rob's message here](https://groups.google.com/d/msg/sailfish-users/VIfqBwgF6xQ/fw-rgC_kAwAJ) and a [thread here](https://github.com/COMBINE-lab/salmon/issues/108). Let me elaborate the big picture of my analyses and give more details about how I came up with the mapping numbers in my original post. Big Picture - DEG identification for samples sequenced by ILMN (whole transcript method) and QS (3' method) - [something similar to this paper](https://bmcgenomics.biomedcentral.com/articles/10.1186/s12864-018-5393-3). Bioinformatics Pipeline(s) for both ILMN and QS :. 1. HISAT Method : Adapter/Quality Trimming, Hisat2-HTSEQ, Get_Count_Table, DESeq; 2. STAR_RSEM Method: Adapter/Quality Trimming, STAR_RSEM, Get_Count_Table, DESeq; 3. SAF Method: Adapter/Quality Trimming, SAF_SALMON, Get_Count_Table, DESeq; 4. Quasi-Mapping or TXOME Method: Adapter/Quality Trimming, TXOME_SALMON, Get_Count_Table, DESeq. I used UpSetR plots for comparisons of sets of DEGs from each method just [as you have shown in your recent preprint](https://www.biorxiv.org/content/10.1101/657874v1.full). In the ILMN analyses, there is great concordance between the SAF method and HISAT/STAR_RSEM method. However, in the QS analyses, there is very limited concordance between SAF and the HISAT/STAR_RSEM method. For QS analyses, the TXOME method shows great concordance with HISAT/STAR_RSEM. This finding made me wonder if this has to be something with my salmon quant command line options for QS. Therefore, I wanted to check how the QS expected counts for SAF method show up for all samples in my final summarized table (after tximport). I got a colSum for all my samples and then checked the numbers for the transc",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-554768195:1101,Adapter,Adapter,1101,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-554768195,1,['Adapter'],['Adapter']
Integrability,"rge/base/lib/python3.9/site-packages/requests/adapters.py"", line 308, in get_connection; raise InvalidProxyURL(""Please check proxy URL. It is malformed""; requests.exceptions.InvalidProxyURL: Please check proxy URL. It is malformed and could be missing the host. `$ /usr/local/bin/conda install salmon`. environment variables:; CIO_TEST=<not set>; CONDA_ROOT=/usr/local/Caskroom/miniforge/base; CURL_CA_BUNDLE=<not set>; INFOPATH=/opt/homebrew/share/info:; MANPATH=/opt/homebrew/share/man::; PATH=/opt/homebrew/bin:/opt/homebrew/sbin:/usr/local/bin:/usr/bin:/bin:/usr; /sbin:/sbin; REQUESTS_CA_BUNDLE=<not set>; SSL_CERT_FILE=<not set>; all_proxy=<set>. active environment : None; user config file : /Users/Benjamin/.condarc; populated config files : /usr/local/Caskroom/miniforge/base/.condarc; conda version : 4.12.0; conda-build version : not installed; python version : 3.9.13.final.0; virtual packages : __osx=12.4=0; __unix=0=0; __archspec=1=arm64; base environment : /usr/local/Caskroom/miniforge/base (writable); conda av data dir : /usr/local/Caskroom/miniforge/base/etc/conda; conda av metadata url : None; channel URLs : https://conda.anaconda.org/conda-forge/osx-arm64; https://conda.anaconda.org/conda-forge/noarch; package cache : /usr/local/Caskroom/miniforge/base/pkgs; /Users/Benjamin/.conda/pkgs; envs directories : /usr/local/Caskroom/miniforge/base/envs; /Users/Benjamin/.conda/envs; platform : osx-arm64; user-agent : conda/4.12.0 requests/2.27.1 CPython/3.9.13 Darwin/21.5.0 OSX/12.4; UID:GID : 501:20; netrc file : None; offline mode : False. An unexpected error has occurred. Conda has prepared the above report. If submitted, this report will be used by core maintainers to improve; future releases of conda.; Would you like conda to send this report to the core maintainers?. [y/N]: y; Upload did not complete. Thank you for helping to improve conda.; Opt-in to always sending reports (and not see this message again); by running. $ conda config --set report_errors true; ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/724#issuecomment-1171208515:6565,message,message,6565,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/724#issuecomment-1171208515,1,['message'],['message']
Integrability,"salmon does run and completes normally so I guess it's just the warning; from jemalloc. . Is this expected for sailfish also? I get the same message about malloc.; . On 2017-04-18 09:55, Rob Patro wrote:. > I think that's the right binary. You can check the sha256 sum:; > ; > rob at Robs-MacBook-Pro in ~/Salmon-0.8.2_macOX_10.12; > $ shasum -a256 bin/salmon; > 7be1c57e1a83956cc9c18f75aed3b2376c93595de7dec215041fe3065528b527 bin/salmon; > ; > You can also check the libraries that salmon is seeing:; > ; > rob at Robs-MacBook-Pro in ~/Salmon-0.8.2_macOX_10.12; > $ otool -L bin/salmon; > bin/salmon:; > /usr/lib/libz.1.dylib (compatibility version 1.0.0, current version 1.2.8); > /usr/lib/libSystem.B.dylib (compatibility version 1.0.0, current version 1238.0.0); > /usr/lib/libbz2.1.0.dylib (compatibility version 1.0.0, current version 1.0.5); > @rpath/libtbbmalloc_proxy.dylib (compatibility version 0.0.0, current version 0.0.0); > @rpath/libtbbmalloc.dylib (compatibility version 0.0.0, current version 0.0.0); > @rpath/libtbb.dylib (compatibility version 0.0.0, current version 0.0.0); > /usr/lib/libc++.1.dylib (compatibility version 1.0.0, current version 307.4.0); > ; > but, again, the library of interest with respect to this message (jemalloc) is linked statically. Out of curiosity, is this message a warning or error (i.e. does salmon run or return a non-zero exit code). The message you're seeing is actually expected if jemalloc was compiled without debug mode turned off (because apple did some funny business with the allocator in OS X 10.12). ; > ; > --; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub [1], or mute the thread [2].; . Links:; ------; [1]; https://github.com/COMBINE-lab/salmon/issues/103#issuecomment-294852033; [2]; https://github.com/notifications/unsubscribe-auth/AA45u0ozBxeE-i6orJcGrgIw4NstAXNvks5rxMDegaJpZM4Ktuq4",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/103#issuecomment-294858583:141,message,message,141,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/103#issuecomment-294858583,4,['message'],['message']
Integrability,"so.2 (0x00007f859aa08000); libgomp.so.1 => /u/user/local/lib64/libgomp.so.1 (0x00007f859a7e7000); librt.so.1 => /lib/x86_64-linux-gnu/librt.so.1 (0x00007f859a5df000); libm.so.6 => /lib/x86_64-linux-gnu/libm.so.6 (0x00007f859a2de000); libgcc_s.so.1 => /u/user/local/lib64/libgcc_s.so.1 (0x00007f859a0c8000); libc.so.6 => /lib/x86_64-linux-gnu/libc.so.6 (0x00007f8599d1d000); /lib64/ld-linux-x86-64.so.2 (0x00007f859b286000); libdl.so.2 => /lib/x86_64-linux-gnu/libdl.so.2 (0x00007f8599b19000); libstdc++.so.6 => /u/user/local/lib64/libstdc++.so.6 (0x00007f859979f000); ```. The linux version and g++ version are listed below:; ```; cat /proc/version; Linux version 4.9.0-0.bpo.6-amd64 (debian-kernel@lists.debian.org) (gcc version 4.9.2 (Debian 4.9.2-10+deb8u1) ) #1 SMP Debian 4.9.82-1+deb9u3~bpo8+1 (2018-03-22). ~/data/PCSI/PC10X/paper/pbmc$ g++ -v; Using built-in specs.; COLLECT_GCC=g++; COLLECT_LTO_WRAPPER=/u/user/local/libexec/gcc/x86_64-unknown-linux-gnu/5.4.0/lto-wrapper; Target: x86_64-unknown-linux-gnu; Configured with: ./configure --prefix=/u/user/local; Thread model: posix; gcc version 5.4.0 (GCC); ```. ```; [Thread debugging using libthread_db enabled]; Using host libthread_db library ""/lib/x86_64-linux-gnu/libthread_db.so.1"".; warning: File ""/u/user/local/lib64/libstdc++.so.6.0.21-gdb.py"" auto-loading has been declined by your `auto-load safe-path' set to ""$debugdir:$datadir/auto-load"".; To enable execution of this file add; add-auto-load-safe-path /u/user/local/lib64/libstdc++.so.6.0.21-gdb.py; line to your configuration file ""/u/user/.gdbinit"".; To completely disable this security protection add; set auto-load safe-path /; line to your configuration file ""/u/user/.gdbinit"".; For more information about this security protection see the; ""Auto-loading safe path"" section in the GDB manual. E.g., run from the shell:; info ""(gdb)Auto-loading safe path""; [New Thread 0x7fff7e0f4700 (LWP 14274)]; Version Info: ### A newer version of Salmon is available. ####; [Thread 0x7ff",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-395836214:1808,wrap,wrapper,1808,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-395836214,1,['wrap'],['wrapper']
Integrability,tLog] [info] done; [2016-12-13 22:44:20.485] [jointLog] [info] Index contained 182608 targets. processed 19000001 fragments; hits: 65897764; hits per frag: 3.48152. [2016-12-13 22:45:33.192] [jointLog] [info] Computed 137534 rich equivalence classes for further processing; [2016-12-13 22:45:33.192] [jointLog] [info] Counted 16265961 total reads in the equivalence classes; [2016-12-13 22:45:33.233] [jointLog] [info] Mapping rate = 83.509%. [2016-12-13 22:45:33.233] [jointLog] [info] finished quantifyLibrary(); [2016-12-13 22:45:33.234] [jointLog] [info] Starting optimizer; [2016-12-13 22:45:33.516] [jointLog] [info] Marked 0 weighted equivalence classes as degenerate; [2016-12-13 22:45:33.523] [jointLog] [info] iteration = 0 | max rel diff. = 299.95; [2016-12-13 22:45:34.217] [jointLog] [info] iteration = 100 | max rel diff. = 0.122252; [2016-12-13 22:45:34.912] [jointLog] [info] iteration = 200 | max rel diff. = 0.102915; [2016-12-13 22:45:35.612] [jointLog] [info] iteration = 300 | max rel diff. = 0.145792; [2016-12-13 22:45:36.357] [jointLog] [info] iteration = 400 | max rel diff. = 0.217489; [2016-12-13 22:45:37.055] [jointLog] [info] iteration = 500 | max rel diff. = 0.0159298; [2016-12-13 22:45:37.628] [jointLog] [info] iteration = 569 | max rel diff. = 0.00958049; [2016-12-13 22:45:37.653] [jointLog] [info] Finished optimizer; [2016-12-13 22:45:37.653] [jointLog] [info] writing output. [2016-12-13 22:45:38.213] [jointLog] [info] Starting Gibbs Sampler; 100% [=====================================================] in 31s; [2016-12-13 22:46:10.451] [jointLog] [info] Finished Gibbs Sampler; [2016-12-13 22:46:10.451] [jointLog] [warning] NOTE: Read Lib [SRR2454059.fq.gz] :. Detected a *potential* strand bias > 1% in an unstranded protocol check the file: test_quant/lib_format_counts.json for details; ```. i.e. I don't seem to get the complaints from the Gibbs sampler and all output files look to be created properly. I'm trying to figure out what could be different.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-266935584:3652,protocol,protocol,3652,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-266935584,1,['protocol'],['protocol']
Integrability,"ta.json, will retry with next repodata source.; Collecting package metadata (repodata.json): / Killed. this is the first time I've encountered an issue where something that is ""supposed"" to be there can't be found. Adam H. Freedman, PhD; Data Scientist; Faculty of Arts & Sciences Informatics Group; Harvard University; 38 Oxford St; Cambridge, MA 02138; phone: +001 310 415 7145; ________________________________; From: Rob Patro ***@***.***>; Sent: Sunday, October 29, 2023 10:01 AM; To: COMBINE-lab/salmon ***@***.***>; Cc: Freedman, Adam ***@***.***>; State change ***@***.***>; Subject: Re: [COMBINE-lab/salmon] anaconda version of salmon outdated, missing decoys option (Issue #895). I'm going to cc @dpryan79<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_dpryan79&d=DwMFaQ&c=WO-RGvefibhHBZq3fL85hQ&r=MITI_LEJgyr1a24IMFAlSaZIPxMpOUT21T7L3fg4CjA&m=mSC4skssR3kpqIDO5fXv00Vk9PrFQeVf0OH62EOgXZ9hbM31qjkaQra0z60JiEA_&s=hPsmfTmSAfiwDhS2JFQyD0EUHl5m5sbj_n46DYj6tdM&e=> on this — does it just not finish? It seems to work within our GitHub CI, where we have to grab the prebuilt salmon to test simpleaf. —; Reply to this email directly, view it on GitHub<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_COMBINE-2Dlab_salmon_issues_895-23issuecomment-2D1784122719&d=DwMFaQ&c=WO-RGvefibhHBZq3fL85hQ&r=MITI_LEJgyr1a24IMFAlSaZIPxMpOUT21T7L3fg4CjA&m=mSC4skssR3kpqIDO5fXv00Vk9PrFQeVf0OH62EOgXZ9hbM31qjkaQra0z60JiEA_&s=6Y-rQOzzAA-t9QV8NyfcMVeySD2an4xeN1HsDqa6VpQ&e=>, or unsubscribe<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_notifications_unsubscribe-2Dauth_ADBMMUDFRQIHN4AMNBHWCN3YBZOUTAVCNFSM6AAAAAA6UYYPGOVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMYTOOBUGEZDENZRHE&d=DwMFaQ&c=WO-RGvefibhHBZq3fL85hQ&r=MITI_LEJgyr1a24IMFAlSaZIPxMpOUT21T7L3fg4CjA&m=mSC4skssR3kpqIDO5fXv00Vk9PrFQeVf0OH62EOgXZ9hbM31qjkaQra0z60JiEA_&s=ckSFRx1FekMV-wL0KtdZFPdtgCB1DiAziHIsdrF0cKQ&e=>.; You are receiving this because you modified the open/close state.Message ID: ***@***.***>",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/895#issuecomment-1784126021:2291,Message,Message,2291,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/895#issuecomment-1784126021,1,['Message'],['Message']
Integrability,"ter poly-A clipping); counted k-mers for 80000 transcripts[2016-11-04 12:41:39.926] [jointLog] [warning] Entry with header [ENST00000436204], had length less than the k-mer length of 31 (perhaps after poly-A clipping); counted k-mers for 90000 transcripts[2016-11-04 12:41:40.016] [jointLog] [warning] Entry with header [ENST00000473810], had length less than the k-mer length of 31 (perhaps after poly-A clipping); counted k-mers for 140000 transcripts[2016-11-04 12:41:40.568] [jointLog] [warning] Entry with header [ENST00000437226], had length less than the k-mer length of 31 (perhaps after poly-A clipping); [2016-11-04 12:41:40.570] [jointLog] [warning] Entry with header [ENST00000428001], had length less than the k-mer length of 31 (perhaps after poly-A clipping); [2016-11-04 12:41:40.574] [jointLog] [warning] Entry with header [ENST00000445788], had length less than the k-mer length of 31 (perhaps after poly-A clipping); [2016-11-04 12:41:40.576] [jointLog] [warning] Entry with header [ENST00000489969], had length less than the k-mer length of 31 (perhaps after poly-A clipping); [2016-11-04 12:41:40.578] [jointLog] [warning] Entry with header [ENST00000411692], had length less than the k-mer length of 31 (perhaps after poly-A clipping); counted k-mers for 150000 transcriptsElapsed time: 2.85251s. Replaced 6009 non-ATCG nucleotides; Clipped poly-A tails from 1120 transcripts; Building rank-select dictionary and saving to disk done; Elapsed time: 0.0151688s; Writing sequence data to file . . . done; Elapsed time: 0.13411s; [info] Building 32-bit suffix array (length of generalized text is 258980005); ...; ...; [more messages here]; ...; ...; khash had 99651131 keys; saving hash to disk . . . done; Elapsed time: 4.98016s; [2016-11-04 12:45:45.948] [jLog] [info] done building index; ```. So the index builds successfully. The process took ~3 min on my local machine. I wonder what could be happening on your end. Is the process using any resources, or just hanging?. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/100#issuecomment-258484912:6130,message,messages,6130,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/100#issuecomment-258484912,1,['message'],['messages']
Integrability,"thank you @alpapan, your post in this open issue had the information that helped me build the latest version of salmon (1.10.0 at this time) on Ubuntu 20 and 22. The documentation at https://salmon.readthedocs.io/en/latest/building.html#requirements-for-building-from-source was not helping with the build errors reported here, which is what I encountered too. . In my case the problem was that I had a custom build of libstaden installed (that I did not want to remove) that cmake was picking up, but which triggered those many libcurl linking errors (misleadingly I would say, since it seems to be related to the way libstaden is installed, not directly libcurl related, which is fine on my system). Here it is the build recipe that worked for me on Ubuntu 20/22:; ```; sudo apt install libboost-iostreams-dev libboost-chrono-dev libboost-filesystem-dev \; libboost-timer-dev libboost-program-options-dev ; PREFIX=$HOME/sw # or wherever you want it; mkdir build && cd build; cmake -DNO_IPO=TRUE -DFETCH_STADEN=TRUE -DCMAKE_INSTALL_PREFIX=${PREFIX} ..; make -j6; make install; ```; Note that the installation message states:; `Please add $PREFIX/lib to your LD_LIBRARY_PATH` ; .. but that does not seem to be needed, the linker seems to resolve those libraries properly in the installation directory.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/425#issuecomment-1445139922:1110,message,message,1110,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/425#issuecomment-1445139922,1,['message'],['message']
Integrability,"the barcode detection - my usual approach with alevin at least is to let it try to estimate a ""real"" cell number, but if it's way off from our experimental expectations, to inject --expectCells ncells and let that serve as a starting point (with subsequent filtering). That has worked reasonably well in the past for me , and seems to be an option for alevin-fry as well. I don't know whether that is poor practice in the long run...it came from a place of seeing far too many weak knee plots early in the droplet scRNA-seq days. Are you generally more trusting of these estimates these days?. So one of the nice aspects of the alevin to alevin-fry pipeline is that it's relatively easy to try different filtering approaches since the initial mapping process only has to happen once. In general, the knee detection method is pretty good, and often gives a reasonable cell count. However, this isn't always the case. What we find in the alevin-fry pre-print is that it tends to be slightly more conservative than if you did e.g. unfiltered quantification followed by filtering with something like `DropletUtils` (but usually only slightly). The knee method is basically the iterative knee finding procedure from UMI-tools, with some slight tweaks to the parameters. However, unlike alevin, alevin-fry also supports unfiltered quantification. In this case, you provide an `unfiltered-permitlist`, which is a set of acceptable barcodes (not necessarily all expected to be present), and alevin-fry will correct against this. This will tend to produce a _lot_ of quantified cells, since we quantify any barcode matching 10 or more reads (by default, this value is modifiable on the command line). So, such unfiltered matrices definitely need to be filtered after quantification. However, for protocols with an external permit list, or those where you can reasonably derive a list of potential expected barcodes, it's less stringent and therefore potentially a bit more sensitive than knee-based filtering.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-988967759:1845,protocol,protocols,1845,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-988967759,1,['protocol'],['protocols']
Integrability,"the item.**; **WARNING: Target ""unitTests"" requests linking to directory ""/users/work/jake/bin/zlib-1.2.11/"". Targets may link only to libraries. CMake is dropping the item.**. So I actually went back a step and check my initial cmake command in the ../salmon-0.8.2/build/ directory. It also had the same issue and therefore wasn't building correctly. I started the install again from ../salmon-0.8.2/build/ using the following: . cmake -DBOOST_ROOT=/users/work/jake/bin/boost_1_64_0/ -DZLIB_LIBRARY=/users/work/jake/bin/zlib-1.2.11/zlib.h .. . It seemed to work nicely and I got all the build files to propagate into the ../salmon-0.8.2/build/ directory. From here I ran 'make' which did a whole bunch of things I hadn't seen it do yet, so assumably it was working as intended. This is until it got to the following stage:. Scanning dependencies of target libbwa; [ 48%] Creating directories for 'libbwa'; [ 49%] Performing download step for 'libbwa'; % Total % Received % Xferd Average Speed Time Time Time Current; Dload Upload Total Spent Left Speed; 100 125 0 125 0 0 167 0 --:--:-- --:--:-- --:--:-- 167; 0 0 0 219k 0 0 123k 0 --:--:-- 0:00:01 --:--:-- 326k; bwa-master.tar.gz: OK; bwa-0.7.12.3/.gitignore; bwa-0.7.12.3/.travis.yml; bwa-0.7.12.3/COPYING; bwa-0.7.12.3/ChangeLog; bwa-0.7.12.3/Makefile; bwa-0.7.12.3/NEWS.md; bwa-0.7.12.3/QSufSort.c; bwa-0.7.12.3/QSufSort.h; bwa-0.7.12.3/README-alt.md; bwa-0.7.12.3/README.md; bwa-0.7.12.3/bamlite.c; bwa-0.7.12.3/bamlite.h; bwa-0.7.12.3/bntseq.c; bwa-0.7.12.3/bntseq.h; bwa-0.7.12.3/bwa.1; bwa-0.7.12.3/bwa.c; bwa-0.7.12.3/bwa.h; bwa-0.7.12.3/bwakit/; bwa-0.7.12.3/bwakit/README.md; bwa-0.7.12.3/bwakit/bwa-postalt.js; bwa-0.7.12.3/bwakit/run-HLA; bwa-0.7.12.3/bwakit/run-bwamem; bwa-0.7.12.3/bwakit/run-gen-ref; bwa-0.7.12.3/bwakit/typeHLA-selctg.js; bwa-0.7.12.3/bwakit/typeHLA.js; bwa-0.7.12.3/bwakit/typeHLA.sh; bwa-0.7.12.3/bwamem.c; bwa-0.7.12.3/bwamem.h; bwa-0.7.12.3/bwamem_extra.c; bwa-0.7.12.3/bwamem_pair.c; bwa-0.7.12.3/bwape.c; bwa",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/141#issuecomment-314451873:1114,depend,dependencies,1114,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/141#issuecomment-314451873,1,['depend'],['dependencies']
Integrability,"the unique-region-derived prior... . But as I think about it... I realize I don't *really* know the underlying algorithmic details of the existing implements. But it would be **amazing** if you could incorporate this type of information into Salmon. I really hope some progress can be made here! . Thanks again for helping me out and showing interest in the motivating problem!. P.S.,; As a total aside, I've been working with this large yeast RNAseq dataset and eventually reached the same conclusions as the selective alignment paper and other recent ones; that is, the most important aspect for getting good transcript-level quantifications is not aligning to the genome vs. aligning to the transcriptome, but rather having an accurate transcriptome annotation to begin with. I saw **huge** gains from updating my transcriptome annotation to include UTRs, especially given differences in coverage bias between samples... for example, if the actual transcript is 500 bp but the gene body is only 200 bp, slight coverage biases can propagate non-linearly and cause huge problems downstream. This got me thinking... if the end goal is differential expression analysis (and obviously this is not *always* the end goal), what if we just discard the notion of a pre-defined transcriptome and stick with equivalence classes, then do differential expression analysis on the equivalence classes themselves (perhaps calculated against the whole genome... this is feasible in yeast, maybe not in humans), then only after discovering significant differential expression one could work backwards to interpret the changes. Is this a crazy idea? Or not crazy at all and already routine? I know salmon can dump the counts to each equivalence class already so it's not hard for me to *do* what I just described, but I'm wondering if you have any opinions/insights into this idea. Thanks again!. ![snr40_isoforms](https://user-images.githubusercontent.com/10292386/81047610-a17c1880-8e6f-11ea-8012-a6695afd68db.png)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-623963851:5236,rout,routine,5236,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-623963851,1,['rout'],['routine']
Integrability,"true, write: false }; 2021-12-06 15:37:20 INFO paired : false, ref_count : 226,030, num_chunks : 6,923; 2021-12-06 15:37:21 INFO tg-map contained 60,603 genes mapping to 226,030 transcripts.; 2021-12-06 15:37:21 INFO read 2 file-level tags; 2021-12-06 15:37:21 INFO read 2 read-level tags; 2021-12-06 15:37:21 INFO read 1 alignemnt-level tags; 2021-12-06 15:37:21 INFO File-level tag values FileTags { bclen: 24, umilen: 10 }; ⠓ [00:00:00] [╢╢▌╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟] ⠐ [00:00:00] [╢╢╢╢╢▌╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟] ⠁ [00:00:00] [╢╢╢╢╢╢╢╢▌╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟] ⠴ [00:00:01] [╢╢╢╢╢╢╢╢╢╢╢▌╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟] ⠤ [00:00:01] [╢╢╢╢╢╢╢╢╢╢╢╢╢╢▌╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟] ⠁ [00:00:01] [╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢▌╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟] ⠤ [00:00:01] [╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢▌╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟] ⠠ [00:00:02] [╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢░╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟] ⠐ [00:00:03] [╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢░╟╟╟╟╟╟╟╟╟╟╟╟╟] ⠋ [00:00:03] [╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢░╟╟╟╟╟╟╟╟╟╟] ⠄ [00:00:04] [╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢░╟╟╟╟╟╟╟] ⠈ [00:00:04] [╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢▌╟╟╟╟╟] ⠙ [00:00:04] [╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢▌╟╟] 6551/6923 ; 2021-12-06 15:37:26 WARN ; found connected component with 30679 vertices, resolved into 18 UMIs over 10 genes with trivial resolution.; [00:00:07] [╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢] 6923/6923 finished quantifying 6,923 cells.2021-12-06 15:37:28 INFO processed 26,250,078 total read records; ```. - Found that 6913 out of 6923 (>99%) barcodes are present in the submitted data.; - Finally ran a correlation b/w the alevin-fry output (located in `res/alevin`) and submitted data. Here are the results:. ![image](https://user-images.githubusercontent.com/12998572/144936078-b4e0ab3e-de1e-4b5d-8000-8c71109f27ae.png). ```; Min. 1st Qu. Median Mean 3rd Qu. Max. ; 0.03701 0.74469 0.88377 0.83131 0.94898 1.00000 ; ```. This demonstrates that alevin performs well with split-seq protocol. Let me know what you think, @jeremymsimon.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-987334414:6647,protocol,protocol,6647,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-987334414,1,['protocol'],['protocol']
Integrability,"ttr', 'rtracklayer', 'Biostrings', 'reshape2', 'ggplot2'),; FUN = library, character.only = TRUE; ). ### Inputs ####; anot.gtf <- '../../shared_data/annotations/Ensembl/Homo_sapiens.GRCh38.101.gtf.gz' # Ensembl GTF; genome.fasta <- '../../shared_data/annotations/Ensembl/Homo_sapiens.GRCh38.dna.primary_assembly.fa.gz' # Genome fasta from Ensembl; gencode.tx.fasta <- '../../shared_data/annotations/Gencode/gencode.v35.transcripts.fa.gz' # Gencode transcript FASTA. dotPlot.fname <- '../ouput/dotPlots.pdf'. ### Read exon annotations ####; message('Loading Ensembl exon annotation (1-22, X, Y, MT)...'). chromosomes <- c(1:22, 'X', 'Y', 'MT'). anot <- import(anot.gtf, feature = 'exon') %>% sort; anot <- anot[seqnames(anot) %in% chromosomes, ]. # append gene and transcript version numbers to IDs; anot$gene_id <- paste(anot$gene_id, anot$gene_version, sep = '.'); anot$transcript_id <- paste(anot$transcript_id, anot$transcript_version, sep = '.'). ### Create premature transcript annotations ####; message('Creating premature transcript annotation...'). anot.pre <- split(anot, anot$transcript_id); anot.pre <- anot.pre[lengths(anot.pre) > 1] %>% range %>% unlist %>% sort # only consider transcripts with > 1 exon. anot.pre$transcript_range <- as.character(anot.pre); anot.pre$gene_id <- anot[match(names(anot.pre), anot$transcript_id), ]$gene_id. # collapse replicate pre-mature transcripts per gene...; names(anot.pre) <- anot.pre$premature_group <- sapply(; split(; names(anot.pre),; paste(anot.pre$gene_id, anot.pre$transcript_range, sep = '_'); ),; paste, collapse = ';'; )[; paste(anot.pre$gene_id, anot.pre$transcript_range, sep = '_'); ]. # ... need to convert GR to data.table before unique because unique method for GR class ignores metadata and rownames; anot.pre <- as.data.table(anot.pre) %>% unique %>% makeGRangesFromDataFrame(., keep.extra.columns = T); names(anot.pre) <- anot.pre$premature_group. ### Read human genome sequence ####; message('Loading genome sequence...'). dna <-",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/655#issuecomment-826035191:4737,message,message,4737,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/655#issuecomment-826035191,1,['message'],['message']
Integrability,"ubdir_data.py"", line 375, in _load; raw_repodata_str = fetch_repodata_remote_request(; File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/conda/core/subdir_data.py"", line 701, in fetch_repodata_remote_request; resp = session.get(join_url(url, filename), headers=headers, proxies=session.proxies,; File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/requests/sessions.py"", line 542, in get; return self.request('GET', url, **kwargs); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/requests/sessions.py"", line 529, in request; resp = self.send(prep, **send_kwargs); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/requests/sessions.py"", line 645, in send; r = adapter.send(request, **kwargs); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/requests/adapters.py"", line 413, in send; conn = self.get_connection(request.url, proxies); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/requests/adapters.py"", line 308, in get_connection; raise InvalidProxyURL(""Please check proxy URL. It is malformed""; requests.exceptions.InvalidProxyURL: Please check proxy URL. It is malformed and could be missing the host. `$ /usr/local/bin/conda install salmon`. environment variables:; CIO_TEST=<not set>; CONDA_ROOT=/usr/local/Caskroom/miniforge/base; CURL_CA_BUNDLE=<not set>; INFOPATH=/opt/homebrew/share/info:; MANPATH=/opt/homebrew/share/man::; PATH=/opt/homebrew/bin:/opt/homebrew/sbin:/usr/local/bin:/usr/bin:/bin:/usr; /sbin:/sbin; REQUESTS_CA_BUNDLE=<not set>; SSL_CERT_FILE=<not set>; all_proxy=<set>. active environment : None; user config file : /Users/Benjamin/.condarc; populated config files : /usr/local/Caskroom/miniforge/base/.condarc; conda version : 4.12.0; conda-build version : not installed; python version : 3.9.13.final.0; virtual packages : __osx=12.4=0; __unix=0=0; __archspec=1=arm64; base environment : /usr/local/Caskroom/miniforge/base (writable); conda av data dir ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/724#issuecomment-1171208515:4683,adapter,adapters,4683,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/724#issuecomment-1171208515,1,['adapter'],['adapters']
Integrability,"vidence that they are _inherently_ uncertain given the read evidence and alignments used for quantification. The tool described in that paper, called [`terminus`](https://github.com/COMBINE-lab/terminus), is a tool for automatically finding such groups of transcripts. Anyway, once you have the Gibbs samples in hand, we can walk you though how to do some assessment of these transcripts (tagging @hiraksarkar here since he's most likely to have access to scripts that will let us look at the posterior samples from individual transcripts). Similarly, if you can provide the quantification directory, we can help examine this too. If this is the case, that the posterior distributions are highly anti-correlated, it is likely that the ambiguity you are seeing is simply inherent given the alignments salmon is being provided. If you have the quantification folder resulting from the same sample using selective alignment, we could compare and contrast the two. At that point, there are a few options depending on how deeply you want to dive. You could try to see how STAR and selective alignment are mapping differently to these transcripts. One potential difference is that STAR is _a lot_ more happy to softclip reads, which selective alignment won't do by default (you can test the effect with the `--softclipOverhangs` to allow selective alignment to softclip reads that hang off the transcript end or `--softclip` to allow softclips anywhere). Note that selective alignment may _still_ be a bit more conservative than STAR about softclips simply because of the nature of the scoring function it uses. This might give you a sense if one of these alignment methodologies is more consistent with your expectations in this case. Another option is to consider doing a grouping with `terminus`. This will reduce the set of ""genes"" that you can call as DE, because it will be happy to group together transcripts from different genes. However, it should help considerably in eliminating DE from highly-un",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/600#issuecomment-740363115:3323,depend,depending,3323,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/600#issuecomment-740363115,1,['depend'],['depending']
Integrability,"within the barcode read, ie something that could be handled with different `bc-geometry`, but maybe that's all you meant in terms of differing implementations. Regarding the BC1 and how it could be two sequences for the same sample - this is confusing to explain in text format, but all comes down to the sequential nature of how the cells acquire barcodes in this protocol. We start with a 96-well plate, where each of the top 48 wells contain BOTH an oligo-dT barcode and random hexamer barcode. The samples then get added to each well. Biochemistry happens. Then you pool all the cells together, split them back out into 48 wells again, and each well gets its own BC2. Then repeat for BC3. . So a given transcript may get amplified via one of two amplification primers (oligo-dT or random hexamer), but after that, will get a single BC2 sequence and BC3 sequence added after that. In Fig 1A of the Rosenberg paper, it's as though there isn't _just_ an orange sequence carrying out reverse transcription, there are actually two different (known) sequences associated with different routes of amplification per cell. . The net effect is that a given cell can contain transcripts that have a sequence like this:; AACGTGAT-CTGTAGCC-ACACAGAA. or like this:; GATAGACA-CTGTAGCC-ACACAGAA. where maybe the first sequence was amplified by oligo-dT and the second was amplified via a random hexamer. Because they have the same BC2 and BC3 sequence, and the BC1 sequences match a known pairing, we know they come from the same cell and therefore the data should be merged. . Any lab running these experiments will have a table of known pairings (ie the two barcodes added to each of first 48 wells), so that they can be merged and treated as though they came from the same cell. This can either be handled upstream of salmon/alevin as a preprocessing step, like what my slow perl script can do, or it can be handled internally. Having alevin do the collapsing would likely be a lot faster and means the FASTQs",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-937918722:1273,rout,routes,1273,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-937918722,1,['rout'],['routes']
Integrability,"x (which is the colored De Bruijn graph). I understand that this index (along with all the equivalence class) remains the same even when gene counts of different RNA-Seq samples are estimated. But I am a bit confused about the alignment-based method. In this case, salmon does not require an index since it has the actual alignments. If we have multiple samples, which are mapped to the same transcriptome will Salmon return the same set of equivalence classes? Since the samples are different the weights will change and so will the reads mapped to each equivalence class but will the set of eq. classes change?. The index remains the same when different samples are processed, just as with a traditional alignment tool like STAR or HISAT2. However, the set of equivalence classes are _not_ fixed between samples. The equivalence classes are induced by the specific set of aligned or mapped reads. Further, salmon adopts a notion of [range-factorized equivalence classes](https://academic.oup.com/bioinformatics/article/33/14/i142/3953977) in which the equivalence relation depends not only on the transcripts to which a read aligns or maps, but also on the conditional probabilities of the fragment being generated from these transcripts, which itself depends on experiment-specific parameters like the fragment length distribution. Thus, it is not the case under either its own builtin lightweight (selective) alignment, nor when operating with an external BAM file, that the set of equivalence classes produced by salmon will be the same across samples. The equivalence classes are _based_ on the underlying reference sequence, but are sample specific and induced both by the specific patterns of multimapping as well as by the sample-specific parameters (like the fragment length distribution). Thus, if you wish to perform some type of equivalence-class type analysis over multiple samples, you'll need to take the union over the equivalence classes observed in each of them. I hope this helps!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/579#issuecomment-717279405:2657,depend,depends,2657,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/579#issuecomment-717279405,2,['depend'],['depends']
Integrability,"yep, at least in my understanding, the 3' single cell 10x protocol goes through the process of cDNA fragmentation post amplification. I think you can more information from [here](https://assets.ctfassets.net/an68im79xiti/4tjk4KvXzTWgTs8f3tvUjq/2259891d68c53693e753e1b45e42de2d/CG000183_ChromiumSingleCell3__v3_UG_Rev_C.pdf)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/574#issuecomment-713246157:58,protocol,protocol,58,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/574#issuecomment-713246157,1,['protocol'],['protocol']
Modifiability," --noLengthCorrection --validateMappings --numBootstraps 100 -l SF -i <path_to_SAF_Gentrome_Index> -r <SE_READ_1.fq> -o <salmon_SE_READ_1>`. I chose the above command line options (`especially --noLengthCorrection`) based on [Rob's message here](https://groups.google.com/d/msg/sailfish-users/VIfqBwgF6xQ/fw-rgC_kAwAJ) and a [thread here](https://github.com/COMBINE-lab/salmon/issues/108). Let me elaborate the big picture of my analyses and give more details about how I came up with the mapping numbers in my original post. Big Picture - DEG identification for samples sequenced by ILMN (whole transcript method) and QS (3' method) - [something similar to this paper](https://bmcgenomics.biomedcentral.com/articles/10.1186/s12864-018-5393-3). Bioinformatics Pipeline(s) for both ILMN and QS :. 1. HISAT Method : Adapter/Quality Trimming, Hisat2-HTSEQ, Get_Count_Table, DESeq; 2. STAR_RSEM Method: Adapter/Quality Trimming, STAR_RSEM, Get_Count_Table, DESeq; 3. SAF Method: Adapter/Quality Trimming, SAF_SALMON, Get_Count_Table, DESeq; 4. Quasi-Mapping or TXOME Method: Adapter/Quality Trimming, TXOME_SALMON, Get_Count_Table, DESeq. I used UpSetR plots for comparisons of sets of DEGs from each method just [as you have shown in your recent preprint](https://www.biorxiv.org/content/10.1101/657874v1.full). In the ILMN analyses, there is great concordance between the SAF method and HISAT/STAR_RSEM method. However, in the QS analyses, there is very limited concordance between SAF and the HISAT/STAR_RSEM method. For QS analyses, the TXOME method shows great concordance with HISAT/STAR_RSEM. This finding made me wonder if this has to be something with my salmon quant command line options for QS. Therefore, I wanted to check how the QS expected counts for SAF method show up for all samples in my final summarized table (after tximport). I got a colSum for all my samples and then checked the numbers for the transcripts and the decoys - this lead me to post my original question on this thread.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-554768195:1177,Adapt,Adapter,1177,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-554768195,1,['Adapt'],['Adapter']
Modifiability," /proc/version; Linux version 4.9.0-0.bpo.6-amd64 (debian-kernel@lists.debian.org) (gcc version 4.9.2 (Debian 4.9.2-10+deb8u1) ) #1 SMP Debian 4.9.82-1+deb9u3~bpo8+1 (2018-03-22). ~/data/PCSI/PC10X/paper/pbmc$ g++ -v; Using built-in specs.; COLLECT_GCC=g++; COLLECT_LTO_WRAPPER=/u/user/local/libexec/gcc/x86_64-unknown-linux-gnu/5.4.0/lto-wrapper; Target: x86_64-unknown-linux-gnu; Configured with: ./configure --prefix=/u/user/local; Thread model: posix; gcc version 5.4.0 (GCC); ```. ```; [Thread debugging using libthread_db enabled]; Using host libthread_db library ""/lib/x86_64-linux-gnu/libthread_db.so.1"".; warning: File ""/u/user/local/lib64/libstdc++.so.6.0.21-gdb.py"" auto-loading has been declined by your `auto-load safe-path' set to ""$debugdir:$datadir/auto-load"".; To enable execution of this file add; add-auto-load-safe-path /u/user/local/lib64/libstdc++.so.6.0.21-gdb.py; line to your configuration file ""/u/user/.gdbinit"".; To completely disable this security protection add; set auto-load safe-path /; line to your configuration file ""/u/user/.gdbinit"".; For more information about this security protection see the; ""Auto-loading safe path"" section in the GDB manual. E.g., run from the shell:; info ""(gdb)Auto-loading safe path""; [New Thread 0x7fff7e0f4700 (LWP 14274)]; Version Info: ### A newer version of Salmon is available. ####; [Thread 0x7fff7e0f4700 (LWP 14274) exited]; ###; The newest version, available at https://github.com/COMBINE-lab/salmon/releases; contains new features, improvements, and bug fixes; please upgrade at your; earliest convenience.; ###; [New Thread 0x7fff7d273700 (LWP 14275)]; Logs will be written to pbmc4k/alevin/logs; [New Thread 0x7ffefc3f1700 (LWP 14276)]; [New Thread 0x7ffe7b56f700 (LWP 14277)]; [New Thread 0x7ffdfa6ed700 (LWP 14278)]; ### salmon (single-cell-based) v0.10.1; ### [ program ] => salmon; ### [ command ] => alevin; ### [ libType ] => { ISR }; ### [ chromium ] => { }; ### [ threads ] => { 8 }; ### [ output ] => { pbmc4k/alevi",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-395836214:2502,config,configuration,2502,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-395836214,1,['config'],['configuration']
Modifiability," arise in some instances (like with many splicing isoforms or alternative transcriptional start/stop sites). . I'm curious to know how things progress on the issue. It seems like using the coverage as evidence of the transcript ""not being expressed at all"" may be too binary for this problem, certainly in real data, including my own, there are serious coverage dropoffs with long genes or low sequencing depth, and it doesn't mean the transcript is not expressed. Second, regarding unique mappers to the ""super transcript,"" this highlights the problem with using gene bodies that do not incorporate UTRs as in my examples above. The quantification can only be as good as the ground truth transcriptome you're working with, and so every gene is going to be a bit wrong if UTRs are not included in the transcriptome sequence. For my real data analysis, I've dealt with this by 1) adding UTRs to all genes whenever possible, and if no UTR data is given, then extending each gene body by ~100 bp in either direction (if two genes end up overlapping a bit, this ends up not being problematic at all because of how salmon apportions reads in accordance with the length bias model). Second, I set the mapping flags to --softclip and --minScoreFraction 0.3; this helps a LOT since if one read mate pair maps perfectly within a gene and the other is in an unannotated UTR region, it will still assign the read correctly to the gene. . Lastly, for solving the problem at hand with the ""super transcript"" scenario and using coverage... perhaps instead of looking for regions of zero coverage, you could keep track of the overall variance in read depth over a gene and assign reads in a way that minimizes variance; in my example, since the super transcripts has regions of very high read depth, zero read depth, and intermediate, the total variance in read depth across the gene would be quite high, while the variance over the sub-transcripts would be much lower. Similarly, in a scenario with a gene that has",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-670495465:1233,extend,extending,1233,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-670495465,1,['extend'],['extending']
Modifiability," decoys or the organism's genome as a decoy whenever possible. . 4) Related to @k3yavi's response and my elaboration above: we have dropped quasi-mapping from 1.0.0 (though something akin to it may return in the future if there is sufficient demand and if the shortcomings described in the manuscript can be overcome). However, as I mention in part 3 above, this doesn't mean it's not possible to use v1.0.0 without an explicit decoy sequence. The `--decoy` flag of the indexing command is optional, not required. We will update this in the documentation making it more explicit. However, as @k3yavi points out, it is true that if you wish to use quasi-mapping and selective-alignment against the full genome on the same machine, you will need both versions, as quasi-mapping is supported only in the [RapMap](https://github.com/COMBINE-lab/RapMap/tree/develop-salmon), while indexing something on the scale of the genome when not using the [pufferfish-based](https://github.com/COMBINE-lab/pufferfish/tree/develop) index has tremendous memory requirements (as is not recommended ). 5 & 6) To re-iterate @k3yavi's answer --- the extra flags used in the pre-print were only for the purpose of holding as many variables fixed as possible when comparing different approaches. It continues to be recommended to use the VBEM over the EM; it seems to perform better with respect to the ways in which we can measure and such improvements have also been documented in [other work](https://www.ncbi.nlm.nih.gov/pubmed/23821651). The _main_ effect of `--mimicBT2` is to discard orphan alignments for the purposes of quantification. This is a more strict requirement than the default behavior of allowing orphans if there is no satisfactory alignment of both ends of a fragment. However, there is no obvious reason why it is better behavior than accounting for these orphan fragments (when appropriately adjusting the conditional probability given their distance from the transcript boundaries, as salmon does).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/442#issuecomment-549195390:2602,variab,variables,2602,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/442#issuecomment-549195390,1,['variab'],['variables']
Modifiability," described in the Bowtie2 manual)](http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-dovetail) are considered discordant. This is the same default behavior imposed by Bowtie2. If you look in the `meta_info.json` file for some of these samples (which is in the `aux_info` subdirectory of the quantification directory for a sample), you can see how many mappings are being discarded by virtue of being dovetail mappings. It is possible to allow such alignments (consider them as concordant) by passing the `--allowDovetail` flag. It is not the case that such alignments are always ""bad"", its simply that one would not expect many fragments to align in such a way, and if these constitute the overwhelming majority of the mappings, one might be suspicious about the underlying data. * Selective alignment actually _aligns_ the reads to the transcriptome. For this purpose, it performs end-to-end alignment. This means that if you suspect that the sample may contain adapters or very low-quality read ends, the reads should be trimmed prior to quantification. It is, therefore, worth checking how the mapping rate changes for some of these samples if the reads are trimmed first. * Selective alignment is more robust than quasi-mapping to the chosen value of `-k`, the minimum match length used when searching for alignments. I noticed that some of the samples contain relatively short reads, so you might see if the mapping rate changes if you adopt a smaller value of `-k` in the index (e.g. we use `23` in the [pre-print](https://www.biorxiv.org/content/10.1101/657874v2.full.pdf)). * You mention that this index doesn't contain any decoy sequence. This of course, should not affect the mapping rate. However, I'd be quite curious to see if you index the reference using the _whole genome_ as decoy (i.e. the SAF method from the pre-print), how many reads are discarded because they map better to a decoy sequence (this information can also be obtained from `meta_info.json`). Thi",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/482#issuecomment-582734798:2780,adapt,adapters,2780,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/482#issuecomment-582734798,1,['adapt'],['adapters']
Modifiability," transcript by salmon) as well as to the genome. It is quite common that the mapping rate to the genome is higher than that to the transcriptome. This is much more a result of what you are aligning _to_ than the aligner. If you were to take the transcriptome, and align to it using Hisat2 with `--no-spliced-alignment` and `--end-to-end` (since there won't be splice junctions when you align to the transcriptome), I'd expect you to get a similar mapping rate as you see in salmon. > I also noticed a high number of mappings discarded because of alignment score. I also wonder why the number of mappings discarded can be larger than num of processed (57113760, the reads number in 1_1.fq.gz). . Good question. The number you are looking at is the number of discarded _mappings_, not the number of discarded _fragments_. The difference is that every fragment can have many potential mappings. The number you are looking at is the total number of attempted _alignments_ that failed to achieve the threshold score. Luckily, salmon reports both numbers. The number of fragments for which _all_ alignments failed to reach the score threshold is `4,196,417`; given in `aux_info.json` by ` ""num_fragments_filtered_vm"": 4196417`. One point to note is that these are all fragments for which mapping is attempted (they had at least one k-mer match the reference), but no alignment was valid up to the threshold. You could try running the quantification again with `--softclip` to allow softclipping of the reads and see if any considerable fraction of these `4196417` failed to align because they overhang the annotated transcripts or contain adapters etc. Nonetheless, even if all of these mapped, the rate would still be ~72%. The remainder of the reads didn't even have a matching k-mer in common with the reference transcriptome, which means they are exceedingly unlikely to have come from the transcripts that were indexed. > Thanks. You're welcome! Please let me know if you have any follow-up questions.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/533#issuecomment-697125235:2029,adapt,adapters,2029,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/533#issuecomment-697125235,1,['adapt'],['adapters']
Modifiability," v0.8 and 1.2.1. The one that seems most relevant here is the introduction of selective-alignment to replace the quasi-mapping procedure that was originally used in salmon. Selective-alignment actually scores the mappings found to the transcriptome, and rejects alignments whose quality is below a (user-specified) threshold. Here, you can see that, in 1.2.1. * 39 fragments are mapped within the score threshold; * 216 fragments are discarded because no mapping location has an alignment score above the threshold. all together, this means that the total number of ""mapped"" fragments in 1.2.1 is very similar to 0.8 (1.2.1 maps 39+216 = 255, while 0.8 maps 254). However, 1.2.1 discards 216 of the fragments because no mapping is sufficiently good. The default for ""sufficiently good"", by the way, is to have an alignment score of at least 65% of the maximum possible for a read of the given length. For typical RNA-seq data, this is actually quite liberal / generous, and is similar to the type of noise in alignment that Bowtie2 allows with the sensitive flag. In general, the heuristics used in 1.2.1 (selective-alignment) tend to be more sensitive than those used in 0.8 (quasi-mapping), since the mappings are then validated using alignment scoring. However, this does mean that the quality of the alignment along the whole read matters. Thus, it is more important to do quality / adapter trimming in the newer version compared to the older one. There is also a flag in 1.2.1 (`--softclip`) that will allow mismatches / gaps at the ends of reads to not detract from the alignment score. So, these are the main differences. However, looking at the output logs you provided, a couple of basic questions did come to mind. Why are there so few reads to begin with? Even in 0.8, only 254 reads mapped, which is obviously a very small number of reads. Is there something non-typical about this sample? Is it a full RNA-seq sample? Are these reads something atypical (like long reads — ONT or PacBio)?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/542#issuecomment-651332239:1497,adapt,adapter,1497,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/542#issuecomment-651332239,1,['adapt'],['adapter']
Modifiability,"$ sudo make install; [ 7%] Built target libcereal; [ 14%] Built target libdivsufsort; [ 21%] Built target libstadenio; [ 28%] Built target libbwa; [ 36%] Built target libgff; [ 42%] Built target libspdlog; [ 47%] Built target ksw2pp_basic; [ 49%] Built target ksw2pp_sse4; [ 52%] Built target ksw2pp_sse2; [ 53%] Built target ksw2pp; [ 55%] Built target alevin_core; [ 69%] Built target salmon_core; [ 74%] Built target unitTests; [100%] Built target salmon; Install the project...; -- Install configuration: ""Release""; -- Up-to-date: /usr/local/lib; -- Up-to-date: /usr/local/lib/libtbbmalloc.so; -- Up-to-date: /usr/local/lib/pkgconfig; -- Up-to-date: /usr/local/lib/libtbb.so; -- Up-to-date: /usr/local/lib/libtbb.so.2; -- Up-to-date: /usr/local/lib/libtbbmalloc_proxy.so.2; -- Up-to-date: /usr/local/lib/libtbbmalloc_proxy.so; -- Up-to-date: /usr/local/lib/libtbbmalloc.so.2; -- Up-to-date: /usr/local/bin/salmon; -- Up-to-date: /usr/local/lib/libsalmon_core.a. Installation complete. Please ensure the following paths are set properly. Please add /usr/local/bin to your PATH; Please add /usr/local/lib to your LD_LIBRARY_PATH. $ make test; Running tests...; Test project salmon/build; Start 1: unit_tests; 1/3 Test #1: unit_tests .......................***Failed 0.02 sec; Start 2: salmon_read_test_fmd; 2/3 Test #2: salmon_read_test_fmd ............. Passed 1.67 sec; Start 3: salmon_read_test_quasi; 3/3 Test #3: salmon_read_test_quasi ........... Passed 1.62 sec. 67% tests passed, 1 tests failed out of 3. Total Test time (real) = 3.32 sec. The following tests FAILED:; 	 1 - unit_tests (Failed); Errors while running CTest; Makefile:151: recipe for target 'test' failed; make: *** [test] Error 8",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/229#issuecomment-393691425:494,config,configuration,494,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/229#issuecomment-393691425,1,['config'],['configuration']
Modifiability,"**_I could be wrong here with my next line_** - [Based on Figure 1 of this paper, it looks to me as though quality trimming is done before adapter trimming](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6129281/figure/bty560-F1/). - [To quote Brian Bushnell (author of BBTools)]( http://seqanswers.com/forums/showpost.php?p=140819&postcount=5), . > It's best to do adapter-trimming first, then quality-trimming, because if you do quality-trimming first, sometimes adapters will be partially trimmed and become too short to be recognized as adapter sequence. When you run BBDuk with both quality-trimming and adapter-trimming in the same run, it will do adapter-trimming first, then quality-trimming. 2. I very well know that the advantage of using fastp is that it can do adapter trimming, etc in a automatic fashion - no need to provide external sequences (example adapter sequences). Yes, I know one can also provide a fasta file of adapters and fatsp will work off it. There are many fatsp issues in GH about adapter detection:. - fail to detect adpaters automatically - (https://github.com/OpenGene/fastp/issues/222 and https://github.com/OpenGene/fastp/issues/205). - [incorrect automatic adapter detection](https://github.com/OpenGene/fastp/issues/240). - [inconsistent behavior with different runs](https://github.com/OpenGene/fastp/issues/231). 3. When I see the above, I am bit skeptical using fastp for qc/adapter trimming. . After lot of trials with bbduk and fastp, I have decided to use bbduk and bbmap for my high throughput analysis. Below, I explain my reasoning behind those choices: . **_```Note - edited this on 02-Apr-2020 to have the correct order of operations ```_** . 1. **_STEP 1 - run bbmap.sh on raw fatsq file to remove contaminants as appropriate (rRNA, mitochondrial, chloroplast)_**; - You have alluded to the importance of removing contaminants [in this post](https://github.com/COMBINE-lab/salmon/issues/160#issuecomment-334762498); >However, the other thing to try is",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-597393209:1401,adapt,adapter,1401,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-597393209,1,['adapt'],['adapter']
Modifiability,"--noLengthCorrection --validateMappings --numBootstraps 100 -l SF -i <path_to_SAF_Gentrome_Index> -r <SE_READ_1.fq> -o <salmon_SE_READ_1>`. I chose the above command line options (`especially --noLengthCorrection`) based on [Rob's message here](https://groups.google.com/d/msg/sailfish-users/VIfqBwgF6xQ/fw-rgC_kAwAJ) and a [thread here](https://github.com/COMBINE-lab/salmon/issues/108). Let me elaborate the big picture of my analyses and give more details about how I came up with the mapping numbers in my original post. Big Picture - DEG identification for samples sequenced by ILMN (whole transcript method) and QS (3' method) - [something similar to this paper](https://bmcgenomics.biomedcentral.com/articles/10.1186/s12864-018-5393-3). Bioinformatics Pipeline(s) for both ILMN and QS :. 1. HISAT Method : Adapter/Quality Trimming, Hisat2-HTSEQ, Get_Count_Table, DESeq; 2. STAR_RSEM Method: Adapter/Quality Trimming, STAR_RSEM, Get_Count_Table, DESeq; 3. SAF Method: Adapter/Quality Trimming, SAF_SALMON, Get_Count_Table, DESeq; 4. Quasi-Mapping or TXOME Method: Adapter/Quality Trimming, TXOME_SALMON, Get_Count_Table, DESeq. I used UpSetR plots for comparisons of sets of DEGs from each method just [as you have shown in your recent preprint](https://www.biorxiv.org/content/10.1101/657874v1.full). In the ILMN analyses, there is great concordance between the SAF method and HISAT/STAR_RSEM method. However, in the QS analyses, there is very limited concordance between SAF and the HISAT/STAR_RSEM method. For QS analyses, the TXOME method shows great concordance with HISAT/STAR_RSEM. This finding made me wonder if this has to be something with my salmon quant command line options for QS. Therefore, I wanted to check how the QS expected counts for SAF method show up for all samples in my final summarized table (after tximport). I got a colSum for all my samples and then checked the numbers for the transcripts and the decoys - this lead me to post my original question on this thread.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-554768195:1273,Adapt,Adapter,1273,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-554768195,1,['Adapt'],['Adapter']
Modifiability,"-0.7.12.3/bwamem.c; bwa-0.7.12.3/bwamem.h; bwa-0.7.12.3/bwamem_extra.c; bwa-0.7.12.3/bwamem_pair.c; bwa-0.7.12.3/bwape.c; bwa-0.7.12.3/bwase.c; bwa-0.7.12.3/bwase.h; bwa-0.7.12.3/bwaseqio.c; bwa-0.7.12.3/bwashm.c; bwa-0.7.12.3/bwt.c; bwa-0.7.12.3/bwt.h; bwa-0.7.12.3/bwt_gen.c; bwa-0.7.12.3/bwt_lite.c; bwa-0.7.12.3/bwt_lite.h; bwa-0.7.12.3/bwtaln.c; bwa-0.7.12.3/bwtaln.h; bwa-0.7.12.3/bwtgap.c; bwa-0.7.12.3/bwtgap.h; bwa-0.7.12.3/bwtindex.c; bwa-0.7.12.3/bwtsw2.h; bwa-0.7.12.3/bwtsw2_aux.c; bwa-0.7.12.3/bwtsw2_chain.c; bwa-0.7.12.3/bwtsw2_core.c; bwa-0.7.12.3/bwtsw2_main.c; bwa-0.7.12.3/bwtsw2_pair.c; bwa-0.7.12.3/example.c; bwa-0.7.12.3/fastmap.c; bwa-0.7.12.3/is.c; bwa-0.7.12.3/kbtree.h; bwa-0.7.12.3/khash.h; bwa-0.7.12.3/kopen.c; bwa-0.7.12.3/kseq.h; bwa-0.7.12.3/ksort.h; bwa-0.7.12.3/kstring.c; bwa-0.7.12.3/kstring.h; bwa-0.7.12.3/ksw.c; bwa-0.7.12.3/ksw.h; bwa-0.7.12.3/kthread.c; bwa-0.7.12.3/kvec.h; bwa-0.7.12.3/main.c; bwa-0.7.12.3/malloc_wrap.c; bwa-0.7.12.3/malloc_wrap.h; bwa-0.7.12.3/maxk.c; bwa-0.7.12.3/pemerge.c; bwa-0.7.12.3/qualfa2fq.pl; bwa-0.7.12.3/utils.c; bwa-0.7.12.3/utils.h; bwa-0.7.12.3/xa2multi.pl; [ 50%] No patch step for 'libbwa'; [ 50%] No update step for 'libbwa'; [ 51%] No configure step for 'libbwa'; [ 51%] Performing build step for 'libbwa'; /bin/ld: cannot find -lz; collect2: error: ld returned 1 exit status; make[3]: *** [bwa] Error 1; make[2]: *** [libbwa-prefix/src/libbwa-stamp/libbwa-build] Error 2; make[1]: *** [CMakeFiles/libbwa.dir/all] Error 2; make: *** [all] Error 2. So as you said I'd say its having issued finding the zlibs library. Similar to how I used 'DZLIB_LIBRARY=/users/work/jake/bin/zlib-1.2.11/zlib.h' to specify the zlib library for 'cmake', is there a way to do it for the 'make' command? I've tried using the following but haven't had success:; make -I /users/work/jake/bin/zlib-1.2.11/zlib.h; make --include-dir=/users/work/jake/bin/zlib-1.2.11/zlib.h. Sorry for the very basic questions.... I'm kind of learning as I go.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/141#issuecomment-314451873:3373,config,configure,3373,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/141#issuecomment-314451873,1,['config'],['configure']
Modifiability,"/PMC6129281/figure/bty560-F1/). - [To quote Brian Bushnell (author of BBTools)]( http://seqanswers.com/forums/showpost.php?p=140819&postcount=5), . > It's best to do adapter-trimming first, then quality-trimming, because if you do quality-trimming first, sometimes adapters will be partially trimmed and become too short to be recognized as adapter sequence. When you run BBDuk with both quality-trimming and adapter-trimming in the same run, it will do adapter-trimming first, then quality-trimming. 2. I very well know that the advantage of using fastp is that it can do adapter trimming, etc in a automatic fashion - no need to provide external sequences (example adapter sequences). Yes, I know one can also provide a fasta file of adapters and fatsp will work off it. There are many fatsp issues in GH about adapter detection:. - fail to detect adpaters automatically - (https://github.com/OpenGene/fastp/issues/222 and https://github.com/OpenGene/fastp/issues/205). - [incorrect automatic adapter detection](https://github.com/OpenGene/fastp/issues/240). - [inconsistent behavior with different runs](https://github.com/OpenGene/fastp/issues/231). 3. When I see the above, I am bit skeptical using fastp for qc/adapter trimming. . After lot of trials with bbduk and fastp, I have decided to use bbduk and bbmap for my high throughput analysis. Below, I explain my reasoning behind those choices: . **_```Note - edited this on 02-Apr-2020 to have the correct order of operations ```_** . 1. **_STEP 1 - run bbmap.sh on raw fatsq file to remove contaminants as appropriate (rRNA, mitochondrial, chloroplast)_**; - You have alluded to the importance of removing contaminants [in this post](https://github.com/COMBINE-lab/salmon/issues/160#issuecomment-334762498); >However, the other thing to try is simply to align one of these samples to the genome with a tool like STAR or HISAT2 and look at their mapping rate to known features. If it's similar, then the other reads could be accounted for by ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-597393209:1583,adapt,adapter,1583,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-597393209,1,['adapt'],['adapter']
Modifiability,"/conda/core/subdir_data.py"", line 210, in load; _internal_state = self._load(); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/conda/core/subdir_data.py"", line 375, in _load; raw_repodata_str = fetch_repodata_remote_request(; File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/conda/core/subdir_data.py"", line 701, in fetch_repodata_remote_request; resp = session.get(join_url(url, filename), headers=headers, proxies=session.proxies,; File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/requests/sessions.py"", line 542, in get; return self.request('GET', url, **kwargs); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/requests/sessions.py"", line 529, in request; resp = self.send(prep, **send_kwargs); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/requests/sessions.py"", line 645, in send; r = adapter.send(request, **kwargs); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/requests/adapters.py"", line 413, in send; conn = self.get_connection(request.url, proxies); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/requests/adapters.py"", line 308, in get_connection; raise InvalidProxyURL(""Please check proxy URL. It is malformed""; requests.exceptions.InvalidProxyURL: Please check proxy URL. It is malformed and could be missing the host. `$ /usr/local/bin/conda install salmon`. environment variables:; CIO_TEST=<not set>; CONDA_ROOT=/usr/local/Caskroom/miniforge/base; CURL_CA_BUNDLE=<not set>; INFOPATH=/opt/homebrew/share/info:; MANPATH=/opt/homebrew/share/man::; PATH=/opt/homebrew/bin:/opt/homebrew/sbin:/usr/local/bin:/usr/bin:/bin:/usr; /sbin:/sbin; REQUESTS_CA_BUNDLE=<not set>; SSL_CERT_FILE=<not set>; all_proxy=<set>. active environment : None; user config file : /Users/Benjamin/.condarc; populated config files : /usr/local/Caskroom/miniforge/base/.condarc; conda version : 4.12.0; conda-build version : not installed; python version : 3.9.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/724#issuecomment-1171208515:4522,adapt,adapters,4522,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/724#issuecomment-1171208515,1,['adapt'],['adapters']
Modifiability,"/miniforge/base/lib/python3.9/site-packages/requests/sessions.py"", line 645, in send; r = adapter.send(request, **kwargs); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/requests/adapters.py"", line 413, in send; conn = self.get_connection(request.url, proxies); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/requests/adapters.py"", line 308, in get_connection; raise InvalidProxyURL(""Please check proxy URL. It is malformed""; requests.exceptions.InvalidProxyURL: Please check proxy URL. It is malformed and could be missing the host. `$ /usr/local/bin/conda install salmon`. environment variables:; CIO_TEST=<not set>; CONDA_ROOT=/usr/local/Caskroom/miniforge/base; CURL_CA_BUNDLE=<not set>; INFOPATH=/opt/homebrew/share/info:; MANPATH=/opt/homebrew/share/man::; PATH=/opt/homebrew/bin:/opt/homebrew/sbin:/usr/local/bin:/usr/bin:/bin:/usr; /sbin:/sbin; REQUESTS_CA_BUNDLE=<not set>; SSL_CERT_FILE=<not set>; all_proxy=<set>. active environment : None; user config file : /Users/Benjamin/.condarc; populated config files : /usr/local/Caskroom/miniforge/base/.condarc; conda version : 4.12.0; conda-build version : not installed; python version : 3.9.13.final.0; virtual packages : __osx=12.4=0; __unix=0=0; __archspec=1=arm64; base environment : /usr/local/Caskroom/miniforge/base (writable); conda av data dir : /usr/local/Caskroom/miniforge/base/etc/conda; conda av metadata url : None; channel URLs : https://conda.anaconda.org/conda-forge/osx-arm64; https://conda.anaconda.org/conda-forge/noarch; package cache : /usr/local/Caskroom/miniforge/base/pkgs; /Users/Benjamin/.conda/pkgs; envs directories : /usr/local/Caskroom/miniforge/base/envs; /Users/Benjamin/.conda/envs; platform : osx-arm64; user-agent : conda/4.12.0 requests/2.27.1 CPython/3.9.13 Darwin/21.5.0 OSX/12.4; UID:GID : 501:20; netrc file : None; offline mode : False. An unexpected error has occurred. Conda has prepared the above report. If submitted, this report will be used by core m",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/724#issuecomment-1171208515:5322,config,config,5322,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/724#issuecomment-1171208515,1,['config'],['config']
Modifiability,"1 -Wreturn-type -Werror=return-type -Wno-unused-function -Wno-unused-local-typedef -static-libstdc++ -Wno-unused-local-typedefs -pthread -ftree-vectorize -funroll-loops -fPIC -fomit-frame-pointer -O3 -DRAPMAP_SALMON_SUPPORT -DHAVE_ANSI_TERM -DHAVE_SSTREAM -Wall -Wno-unknown-pragmas -Wno-reorder -Wno-unused-variable -std=c++11 -Wreturn-type -Werror=return-type -Wno-unused-function -Wno-unused-local-typedef -static-libstdc++ -Wno-unused-local-typedefs -rdynamic CMakeFiles/unitTests.dir/__/tests/UnitTests.cpp.o CMakeFiles/unitTests.dir/FragmentLengthDistribution.cpp.o CMakeFiles/unitTests.dir/__/external/install/src/rapmap/rank9b.cpp.o CMakeFiles/unitTests.dir/__/external/install/src/rapmap/bit_array.c.o -o unitTests -L/home/mathog/src/salmon/lib -L/home/mathog/src/salmon/external/install/lib -Wl,-rpath,""\$ORIGIN/../lib:\$ORIGIN/../../lib:\$ORIGIN/:\$ORIGIN/../../external/install/lib"" libsalmon_core.a libalevin_core.a -lgff -lpthread ../external/install/lib/libstaden-read.a -lz ../external/install/lib/libdivsufsort.a ../external/install/lib/libdivsufsort64.a ../external/install/lib/libbwa.a -lm -llzma -lbz2 -ltbb -lgomp -lrt ../external/install/lib/libjemalloc.a -lrt -ldl ../external/install/lib/libjemalloc.a -ldl`. Oh, I also had to update automake and autoconf because the 2 year old versions on this system were not new enough. Is there a static binary version of salmon available for download, Linux 64 bit? It looks like the default links are that way anyway, and that would save me what looks like at least another day of fighting with Cmake to force it to actually build a working make file. . You are developing on something like a recent Fedora or Ubuntu? In my experience packages which use boost and cmake inevitably cause a great great deal of pain when they are built on platforms like Centos or RHEL where long term support is one of the goals. They work fine on platforms which are cutting edge, but backwards compatibility extends back maybe 6 months or a year, tops.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/236#issuecomment-397025719:4137,extend,extends,4137,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/236#issuecomment-397025719,1,['extend'],['extends']
Modifiability,"> > Hmm strange! But `conda install salmon` still gives the same error for me.; > ; > Hi @charlotte-west,; > ; > Can you please try the following?; > ; > ```; > CONDA_SUBDIR=osx-64 conda create -n rosetta # create a new environment; > conda activate rosetta; > conda env config vars set CONDA_SUBDIR=osx-64 # subsequent commands use intel packages; > conda install salmon; > ```; > ; > These instructions came from (here)[https://github.com/Haydnspass/miniforge#rosetta-on-mac-with-apple-silicon-hardware] and have worked for me on my M1 laptop. My understanding is that conda / bioconda are still working on having worker nodes that can pre-compile native M1 executables. So, until that work is complete, it may be necessary to run certain native packages in a Rosetta environment. Let me know if this works for you.; > ; > Best, Rob. it worked for me but i had to remove the comments starting with the `#`",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/724#issuecomment-1384299365:271,config,config,271,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/724#issuecomment-1384299365,1,['config'],['config']
Modifiability,"> Hi Brian,; > ; > In general, I would argue that one should be cautious with removing PCR duplicates in RNA-seq data (unless you are dealing with reads with UMI tags). This is because reads that align to the same reference position can easily have come from alternative transcripts sharing the same underlying sequence. Hence, the normal tests used to infer PCR duplicates with e.g. DNA-seq reads can yield false-positives in RNA-seq. This is particularly true for highly abundant transcripts (or transcripts from highly-abundant genes).; > ; > We are currently working on the code that will do duplicate removal when UMI tags are present. That methodology can be extended to remove duplicates even without UMI tags --- though I'd generally caution against that for the reasons mentioned above. However, for the time being, if you have a strong need or desire to filter PCR duplicates, you could use alignment-based Salmon with a BAM file that has duplicates removed.; > ; > Finally, regarding the error you are getting during SAM validation; this sounds like a different issue. Would you mind providing a piece of that SAM file for me to take a look at? Specifically, I don't believe the quasi-mapping output file should even contain unmapped reads (unless you consider unmapped mates of orphaned reads).; > ; > --Rob. It is in the latest Salmon release?. Thanks",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/136#issuecomment-446191570:665,extend,extended,665,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/136#issuecomment-446191570,1,['extend'],['extended']
Modifiability,"> Hmm strange! But `conda install salmon` still gives the same error for me. Hi @charlotte-west,. Can you please try the following?. ```; CONDA_SUBDIR=osx-64 conda create -n rosetta # create a new environment; conda activate rosetta; conda env config vars set CONDA_SUBDIR=osx-64 # subsequent commands use intel packages; conda install salmon; ```. These instructions came from (here)[https://github.com/Haydnspass/miniforge#rosetta-on-mac-with-apple-silicon-hardware] and have worked for me on my M1 laptop. My understanding is that conda / bioconda are still working on having worker nodes that can pre-compile native M1 executables. So, until that work is complete, it may be necessary to run certain native packages in a Rosetta environment. Let me know if this works for you. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/724#issuecomment-1137183671:244,config,config,244,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/724#issuecomment-1137183671,1,['config'],['config']
Modifiability,"> Thanks!! Looking into it, replied. Hi,. I am having a similar issue when running salmon 1.4 on stranded single end data. Transcript count is over 4,000 for certain genes when analyzed by STAR, but salmon does not detect the transcript. Is there any newer version of this branch or suggested configuration that I can use to test my data? Thank you.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/218#issuecomment-1145373488:293,config,configuration,293,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/218#issuecomment-1145373488,1,['config'],['configuration']
Modifiability,"@Gaura this sort of frameshift in the barcodes is a known issue, and can be computationally challenging (at least for existing methods). zUMIs, for example, does an automatic barcode detection based on fixed barcode positions like we're doing here with alevin, so it would mis-detect cells like the shifted ones you pasted above. For SPLiT-seq, we do know exactly which barcodes go into the wells, however, so it is technically possible to restrict based on all possible known combinations of barcodes instead and be more positionally flexible. But deciding how many indel bases are allowable, and presumably doing multiple passes through the data to establish an include-list could be time-consuming. Further, the zUMIs developer rightly mentions [in this thread](https://github.com/sdparekh/zUMIs/issues/63) that there are likely going to be _many_ unused barcode combinations this way, so lots of time could be spent looking for ""cells"" that don't actually exist in the data. The authors of the paper from which our test dataset was derived describe in their methods using a Drop-seq computational framework, so I'm not sure which approach theirs is more similar to. . The simplest approach here is certainly the automatic detection, but it will come at the cost of losing meaningful reads to frameshift errors. . My guess is this falls well out of the scope of alevin, but if you're interested in improving on that, there may be a middle ground between the two approaches above, one that I'm not sure if your group or others have attempted for other methods: we could essentially do a 2-pass barcode detection. The first pass would restrict based on positions like we're already doing, and establish an include-list of possible barcodes seen in the data. Then we could pass through the barcode sequences a second time, looking only for those sequence combinations, but allowing 1-2bp flexibility in the positions they occur, potentially rescuing some of the ones missed during the first pass. This",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-985554883:535,flexible,flexible,535,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-985554883,1,['flexible'],['flexible']
Modifiability,"@bgruening So I've tried some runs today with higher memory configurations and can still reproduce the segfault. I'm going to continue on and try to write up a reproducer for @dpryan79 [here](https://github.com/bioconda/bioconda-recipes/issues/10662#issuecomment-415967622). **`salmon 0.11.2 run with: NativeSpecification --ntasks=1 --nodes=1 --mem=25000`**; - `scontrol show job 94`; ```; JobId=94 Name=g990_salmon_refinery_stemcellcommons_org; UserId=galaxy(1001) GroupId=users(100); Priority=4294901667 Account=(null) QOS=(null); JobState=COMPLETED Reason=None Dependency=(null); Requeue=1 Restarts=0 BatchFlag=1 ExitCode=0:0; RunTime=00:07:32 TimeLimit=UNLIMITED TimeMin=N/A; SubmitTime=2018-08-27T15:36:41 EligibleTime=2018-08-27T15:36:41; StartTime=2018-08-27T15:36:41 EndTime=2018-08-27T15:44:13; PreemptTime=None SuspendTime=None SecsPreSuspend=0; Partition=main AllocNode:Sid=ip-172-31-24-127:21595; ReqNodeList=(null) ExcNodeList=(null); NodeList=w19; BatchHost=w19; NumNodes=1 NumCPUs=1 CPUs/Task=1 ReqS:C:T=*:*:*; MinCPUsNode=1 MinMemoryNode=25000M MinTmpDiskNode=0; Features=(null) Gres=(null) Reservation=(null); Shared=OK Contiguous=0 Licenses=(null) Network=(null); Command=(null); WorkDir=/mnt/galaxy/tmp/job_working_directory/000/990; ```. - `Galaxy stderr`; ```; Fatal error: Exit code 139 (); ...; /mnt/galaxy/tmp/job_working_directory/000/990/tool_script.sh: line 50: 5713 Segmentation fault (core dumped) salmon quant --index ./index --libType U --unmatedReads ./single.fastq --output ./output --allowOrphans --ma 2 --mp 4 --go 5 --ge 3 --minScoreFraction 0.65 --threads ""${GALAXY_SLOTS:-4}"" --incompatPrior 1e-20 --biasSpeedSamp 1 --fldMax 1000 --fldMean 200 --fldSD 80 --forgettingFactor 0.65 --maxReadOcc 100 --numBiasSamples 2000000 --numAuxModelSamples 5000000 --numPreAuxModelSamples 1000000 --numGibbsSamples 0 --numBootstraps 0 --consensusSlack 0 --vbPrior 0.001 --sigDigits 3; ```. - `syslog`; ```; ip-172-31-30-93 kernel: [ 681.083866] salmon[4167]: segfault at 2641a i",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/271#issuecomment-416364238:60,config,configurations,60,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/271#issuecomment-416364238,1,['config'],['configurations']
Modifiability,"@cihanerkut and @EricDeveaud,. We just released 1.2.1, which is on the release page, and dockerhub, and should propagate to bioconda soon. It adds support for the `SALMON_NO_VERSION_CHECK` environment variable. If you set `SALMON_NO_VERSION_CHECK` to either `1` or `TRUE` in the environment where salmon is running, it will skip the version check. I hope this helps!. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/486#issuecomment-617830312:201,variab,variable,201,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/486#issuecomment-617830312,1,['variab'],['variable']
Modifiability,"@cliftonlewis: could you tell us version of alevin-fry are you using? ; @rob-p: The cellbarcode length should be 21. It is variable b/w 19 or 20 so AC or A is added to make it 21. It could be the odd-even error we saw on previous version of alevin-fry. Wrt the run without `--justAlign`, I would need to take a closer look.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/813#issuecomment-1332726376:123,variab,variable,123,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/813#issuecomment-1332726376,1,['variab'],['variable']
Modifiability,@k3yavi . I cannot get it to update even on new env. My command is; ```; conda install -c bioconda salmon=1.0.0; ```; and it freezes everytime; ```; Collecting package metadata (current_repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; ```,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/461#issuecomment-567461956:277,flexible,flexible,277,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/461#issuecomment-567461956,1,['flexible'],['flexible']
Modifiability,"@rob-p . I did notice that the header was missing so I am looking into getting the original. I downloaded/unzipped the files you sent and seem to still have the same issue, though. ; ```; $ conda activate salmon; $ cd ~/opt/anaconda2/envs/salmon; $ ./bin/salmon quant -l IU -t transcripts.fa -a sample_alignments.sam -o quant_directory; Version Info: This is the most recent version of salmon.; # salmon (alignment-based) v1.2.0; # [ program ] => salmon ; # [ command ] => quant ; # [ libType ] => { IU }; # [ targets ] => { transcripts.fa }; # [ alignments ] => { sample_alignments.sam }; # [ output ] => { quant_directory }; Logs will be written to quant_directory/logs; [2020-04-21 11:46:41.365] [jointLog] [critical] Note: Alignment-free mapping (i.e. mapping without subsequent selective-alignment) has not yet been throughly tested under the pufferfish-based index and using the pufferfish-based mapping strategies. Thus, disabling of selective-alignment is not currently allowed. We may, potentially explore re-enabling this option in future versions of salmon. ```. To set up Salmon, I entered the following per the Getting Started Guide:; `$ conda config --add channels conda-forge`; `$ conda config --add channels bioconda`; `$ conda create -n salmon salmon`. Then, set the wd to `~opt/anaconda2/envs/salmon`. To run, I dropped the `transcripts.fa` and `seq.bam`/`seq.sam` file into the ~opt/anaconda2/envs/salmon and ran it. I noticed that if I moved the files to an entirely separate directory or deleted them all together and ran `./bin/salmon quant -l IU -t transcripts.fa -a sample_alignments.sam -o quant_directory`, the same error came up. Is it possible that there is an issue with Salmon reading the files?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/511#issuecomment-617263834:1157,config,config,1157,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/511#issuecomment-617263834,2,['config'],['config']
Modifiability,"@rob-p I would request that you try out bbduk and bbmap for quality/adapter trimming and contaminant removal.; > Thank you for verifying @zhangchipku, For the time being, I can recommend `fastp` as a fairly efficient / fast trimmer that. It might even be able to work in a streaming fashion so that you could pipe the trimmed reads directly to salmon.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-592995074:68,adapt,adapter,68,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-592995074,1,['adapt'],['adapter']
Modifiability,"@sjackman ,. Thanks for raising this question. I actually think that making the barcode processing phase of alevin a bit more general sounds like an excellent idea. Right now, the barcode processing is parameterized by a class that describes the barcode layout etc. These are represented, basically, as C++ policy classes. However, having a custom policy (specified in e.g. a YAML file or some such) wouldn't be too difficult to do, and might make the barcode processing useful in a larger context. We'd be happy to help implement this and see if it works in your context. One question to resolve first, though (please chime in here @k3yavi) is what assumptions make sense for bar code correction in each datatype. That is, do we expect similar-ish numbers and distributions of barcodes, etc. so that our ""knee-in-the-curve"" heuristics still make sense?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/233#issuecomment-395180151:202,parameteriz,parameterized,202,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/233#issuecomment-395180151,1,['parameteriz'],['parameterized']
Modifiability,"@vbontempi96,. Thanks to @genomax, working from an M1, it seems likely that the issue is your order of Conda channels. Given an empty channel list, try the following:. ```; conda config --add channels defaults; conda config --add channels bioconda; conda config --add channels conda-forge; conda create -n salmon salmon; ```. This should allow you to get the latest salmon (currently 1.6.0) on an M1 from bioconda. Please feel free to re-open if this doesn't work for you.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/724#issuecomment-984952328:179,config,config,179,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/724#issuecomment-984952328,3,['config'],['config']
Modifiability,"@zhangchipku,. Yes, it seems that the biggest culprit here is `num_fragments_filtered_vm`. That is the number of fragments filtered because the best alignment failed to reach the threshold for a ""valid"" alignment. Here, `47,470,013` fragments are discarded entirely because they didn't have an alignment meeting the required quality. If these fragments (which do have matching MEMs, because alignment was carried out for them) were mapped, then the overall mapping rate would go up to `50,729,814 + 47,470,013 = 98,199,827 / 107,275,750 = ~91.5%`. Now, I wouldn't expect _all_ of these to be mappable, and some alignments might not be feasible at any reasonable quality whatsoever. My recommendation would be as follows. First, have you trimmed these reads (using e.g. `fastp` or `TrimGalore` or some such)? Very low quality read ends or (more likely) adapter contamination could cause the reads that have matching MEMs to fail to align within the required score threshold. My first recommendation would be to trim the reads and see how the mapping rate changes. Second, the required alignment score is a user-alterable parameter. By changing `--minScoreFraction` to be lower, you can allow reads with even lower alignment scores to be counted for quantification. The default value is `0.65`, so you could explore what happens if you lower this number. The number represents the fraction of the maximum achievable alignment score that a read must obtain to be considered a valid alignment. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-586473052:852,adapt,adapter,852,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-586473052,1,['adapt'],['adapter']
Modifiability,"Ah, my bad. I assumed you were running featureCounts via the pipeline. Thanks for clarifying. Happy to incorporate changes into the pipeline in the future if they improve the default behaviour. For now, you can tweak the settings you provide the pipeline to incorporate the `--softclipOverhangs` parameter. You can put the snippet below in a file called `custom.config` and pass to the pipeline on the CLI with `-c custom.config`:. ```; process {; withName: '.*:QUANTIFY_SALMON:SALMON_QUANT' {; ext.args = '--softclipOverhangs'; }; }; ```. Let me know if you have any problems with this.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/798#issuecomment-1239100429:362,config,config,362,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/798#issuecomment-1239100429,2,['config'],['config']
Modifiability,"Ahh, that's the number of *mappings* discarded. No need to worry about that. Basically, that's the number of places where seeding was tried, but alignment failed. This is very common in alignment (a seed can't be extended to a high quality alignment). The number of fragments discarded is what matters (number of fragments where all alignment locations failed). The strand bias signifies that your library is likely strand specific, though you are mapping in unstranded mode. This means that even alignments that don't agree with the stranded protocol will be allowed. This looks like ISR (first read from the reverse strand) by the looks of it. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/775#issuecomment-1126583954:213,extend,extended,213,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/775#issuecomment-1126583954,1,['extend'],['extended']
Modifiability,"Also, I assumed (according to the documentation) that these underflow and overflow errors inherit from `std::runtime_error`, but I've updated the try/catch with a more generic exception class just in case they are not.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/229#issuecomment-393631624:90,inherit,inherit,90,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/229#issuecomment-393631624,1,['inherit'],['inherit']
Modifiability,"Could you please share one of the output directories? It's not immediately obvious what the problem might be, since the log ends with . ```; [2020-06-03 23:47:15.955] [jointLog] [info] Computing gene-level abundance estimates; ```. which suggests the function to aggregate abundances to the gene level should be activated. On a related note, though we are definitely interesting in figuring out what might being going awry here, the recommended way to aggregate transcript-level abundances from salmon to the gene level is to use [tximport](https://bioconductor.org/packages/release/bioc/html/tximport.html), as it accounts for across-sample variability in expressed gene length, and makes it trivial to get your corresponding gene counts into a downstream DE tool like DESeq2, EdgeR, etc.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/530#issuecomment-638453196:642,variab,variability,642,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/530#issuecomment-638453196,1,['variab'],['variability']
Modifiability,"Excellent! Now we should do some internal testing to see if this has any negative performance impact on machines that _do_ have SSE4. Then we can determine if we can just make this the default, or if it's worth cutting a release under 2 configurations.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/500#issuecomment-610602162:237,config,configurations,237,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/500#issuecomment-610602162,1,['config'],['configurations']
Modifiability,"FYI, I'm taking another crack at an official FreeBSD port, but still hitting some gnarly issues with 1.5.2, so it might be a while. https://github.com/outpaddling/freebsd-ports-wip/tree/master/salmon; https://github.com/outpaddling/freebsd-ports-wip/tree/master/pufferfish; https://github.com/COMBINE-lab/salmon/issues/502. 1. The cmake system still forces downloading pufferfish during configure, which is forbidden in the ports system (like many other package managers). All downloads must occur during fetch phase and be verified using locally stored checksums. This would be easy to work around using GH_TUPLE, which downloads additional distfiles during fetch phase, except that fetchPufferfish.sh doesn't just extract the pufferfish dist, but has a long list of ""cp"" commands to copy pieces of it to ${INSTALL_DIR}. That's not something I'm inclined to tamper with since it will likely change with new versions and hence be a headache to maintain over time. It would be ideal if salmon could work with a separately installed pufferfish as it does with many other dependencies. This would make the port much cleaner.; 2. The code is not compatible with onetbb 2021.3, which is the current FreeBSD ports version.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/162#issuecomment-917642392:387,config,configure,387,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/162#issuecomment-917642392,1,['config'],['configure']
Modifiability,"FYI, miniconda works fine on FreeBSD. It's not too difficult to configure manually, but to make it even easier:. As root:. ```; pkg install auto-admin linux-miniconda-installer; auto-install-linux_base; ```; As a non-root user:. ```; miniconda-installer; conda-shell; conda config --add channels conda-forge; conda config --add channels bioconda; conda create -n salmon salmon; ```; Note: Just running `conda install salmon` instead of `conda create -n salmon salmon` will install a very old version rather than the latest. This utilizes the Linux compatibility module, which simply adds Linux system calls to the FreeBSD kernel. Unlike a virtual machine, there's no performance penalty and memory overhead is trivial. In fact, Linux binaries sometimes run slightly faster on FreeBSD than they do on Linux. Average speed is about the same. I'd only use conda as a stop-gap, though. There's a large and growing selection of bioinformatics software in FreeBSD ports that can be more easily installed and used, e.g. 'pkg install samtools bwa'. Also I'm working on a native FreeBSD port for salmon:. https://github.com/COMBINE-lab/salmon/issues/162. Best,. Jason",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/419#issuecomment-917648051:64,config,configure,64,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/419#issuecomment-917648051,3,['config'],"['config', 'configure']"
Modifiability,"For clarification: From memory, using the same cluster, I had the same error at the same stage but only with particular data sets and confirmed this was not an issue of available memory. @k3yavi may remember some more of the details but we never got to the bottom of it. . @Acribbs Testing on another cluster would be a good idea in case this is a very specific cluster configuration issue",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/337#issuecomment-458160685:370,config,configuration,370,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/337#issuecomment-458160685,1,['config'],['configuration']
Modifiability,"Hey Rob. It looks like this was an error in the way I was calling `salmon index`. I've wrapped salmon in a python based pipeline where I manage creation of index files using configuration files. To call `salmon index` I was previously iterating on standard error, capturing your err and logging it after reformatting a bit. It looks like what was happening is:. 1. I opened a subprocess and executed salmon; 2. Salmon worked properly; 3. Salmon stopped producing output on stderr (and sent an EOF marker?) and so my script exited; - killing salmon prematurely; - truncating the salmon index (In a way that salmon found perfectly acceptable during `salmon quant`; - frustrating me quite a bit. I fixed this by doing the right thing and blocking for the process to return an exit code:. ```diff; p = Popen(cmd, stderr=PIPE); - for line in p.stderr:; - line = line.decode(); - if line.endswith('\n'):; - logging.info(line.rstrip()); - else:; - logging.info(line); + _, err = p.communicate(); + logging.info(err); ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/132#issuecomment-303738589:174,config,configuration,174,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/132#issuecomment-303738589,1,['config'],['configuration']
Modifiability,"Hi @Beatzekatze,. The issue with test 1 seems to be from CMake being unable to find the unit test to execute under certain configurations. I'll consider this a bug in the CMake file, and look into fixing it. The failure of tests 2 and 3 is more interesting, as one would definitely not expect this given that the program compiled without error. Does indexing fail only with `--type fmd`, or also with `--type quasi` (or no `--type` as that is the default)? Would it be possible to run the command under gdb and report the stack trace? That would be something like:. ```; $ gdb --args salmon index -t transcripts.fasta -i sample_salmon_fmd_index --type fmd; ```. and then, when you encounter the segfault issuing the back-trace `bt` command. This would give insight into where, exactly this is showing up. One issue I've seen before is when the resident installation of Boost is _not_ compiled with `--std=c++11` (or 14 or 17), since this leads to an incompatible ABI between salmon and the Boost library. If that's what's going on, it should be evident from the backtrace. Finally, while I'd want to figure out what's going on with this build from source, it would also be useful to know if you encounter the same behavior when installing via bioconda. Thanks for the detailed report!. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/250#issuecomment-404223014:123,config,configurations,123,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/250#issuecomment-404223014,1,['config'],['configurations']
Modifiability,"Hi @Ci-TJ,. This suggests that the FASTQ files were ""desynchronized"" during / after trimming somehow. Salmon requires that the FASTQ files are synchronized. So, if the trimmer decides to discard a read from the first read file, it must also discard the corresponding read from the second read file. I'm not specifically familiar with RabbitQC, but most quality / adapter trimmers have an option to separate out any reads that become orphaned during trimming so that the output paired FASTQ files remain synchronized. You should make sure that any such options are passed during QC. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/660#issuecomment-846252372:363,adapt,adapter,363,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/660#issuecomment-846252372,1,['adapt'],['adapter']
Modifiability,"Hi @ECuris,. Indeed, this seems to be a case where the code evolved and the documentation has yet to catch up. The defaults are `fldMean` = 250 and `fldSD` = 25. The relevant code is here (https://github.com/COMBINE-lab/salmon/blob/master/src/SalmonQuantify.cpp#L2260). This defines how default values are set for these parameters. I'll make a note to update the documentation to be consistent with these changes (which were made to be more in line with modern protocols, though there's still no good universal parameters for things that can vary so widely between experiments).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/127#issuecomment-286760710:60,evolve,evolved,60,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/127#issuecomment-286760710,1,['evolve'],['evolved']
Modifiability,"Hi @PeteHaitch ,; Thanks for your interest in *Alevin*.; Although in current Alevin we have concentrated mainly on learning more about Droplet based 3'-tagged single cell protocols, especially 10x; we are very much interested in extending it towards other protocols like CEL-seq.; However, there are couple of challenges/difference which should be considered before incorporating it into the Alevin pipeline. Currently Alevin relies on the fact that the droplet based protocols use PCR amplification of the library and the UMI deduplication phase of Alevin assumes an exponential model, I am not sure how true is this with CEL-seq? Another issue is that CEL-seq is a Fluidigm based system while the current application for Alevin is for microfluidics based. In general we have observed that the 10x cell isolation step is pretty robust in reporting the Cellular Barcodes(CB) and although we have a probabilisitic model to handle the CB based uncertainty but the ambiguous case like that are very less frequent, (although not true for Drop-Seq). Having said that, we might have to do some analysis to actually figure out the right model for Barcode correction in Fluidigm based system. Also, please do let us know of your experience in using the solution proposed in #247 . Looking forward to hearing back from you.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/269#issuecomment-414162302:229,extend,extending,229,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/269#issuecomment-414162302,1,['extend'],['extending']
Modifiability,"Hi @PlantDr430,. Thanks for the detailed report. I have a general thought, and then a more specific thought given your use case and parameter settings. The general thought is that it is _not_ true, broadly, that one should expect transcript (or even gene) abundances to stay the same under a change of annotation. The estimates computed by salmon (and by all transcript-level abundance estimation tools) is one that maximizes the likelihood of the data (or maximizes the ELBO in the case of VI) _conditioned on_ the observed fragments and the _transcripts_. When one changes the transcripts, they change the variable upon which the inference is conditioned, and the results, in general, can change (a lot, or a little bit). This is specifically most prone to happen when transcripts / genes are added to the annotation that are similar to other transcripts or genes in the annotation. Now, my specific thought based on your settings of parameters. They are _quite_ different, but the three big factors I see here are (1) the setting for `--scoreExp`, (2) the setting(s) for dovetail and softclipOverhangs and (3) the setting for `--consensusSlack` Why are they a big deal?. * `--scoreExp` determines how much we down-weight scores sub-optimal alignments. Setting `--scoreExp` to 0 says that a sub-optimal alignment, at least in terms of the alignment probability is _just as good as the optimal alignment_. So, imagine you had a few read length regions of a pair of genes that each differed by 1 or 2 SNPs. When `--scoreExp` is 0, then the model considers alignments (say to transcript 2) with 2 substitutions to be just as likely as alignments (say to transcript 1) that are perfect (with no substitutions). While you can play around with different values of `--scoreExp` to determine how differences from the optimal alignment should be weighted, I'd strongly suggest against setting `--scoreExp` equal to 0. * `--allowDovetail` and `--softclipOverhangs` may or may not have a significant effect bas",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/523#issuecomment-632953613:608,variab,variable,608,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/523#issuecomment-632953613,1,['variab'],['variable']
Modifiability,"Hi @Ray6283,. The `bootstraps.gz` file is not designed to be read as plain text. The file encodes information in binary. If you are interested in extract the information encoded in those files, the easiest thing to do is likely to read them in using the [`fishpond`](https://bioconductor.org/packages/release/bioc/html/fishpond.html) package. Looking at the code there will also show you exactly how those files are packed. The same is true for the bias files. The format for those is documented [here](https://salmon.readthedocs.io/en/latest/file_formats.html#sequence-specific-bias-files) and [here](https://salmon.readthedocs.io/en/latest/file_formats.html#fragment-gc-bias-files), those these are binary encoded files and not designed for human consumption. For the bias files, even if you did read them in, the information is not trivially interpretable (e.g. the parameters of the variable length Markov model, etc.). --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/47#issuecomment-1792970641:887,variab,variable,887,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/47#issuecomment-1792970641,1,['variab'],['variable']
Modifiability,"Hi @Rhinogradentia,. This error occurs when there is a binary mismatch between the library used to compile salmon versus that used to run it. Specifically, this occurs when the boost library is _not_ compiled with a modern ABI (Application Binary Interface) — when boost was not compiled in a way compatible with C++11/14/17/20. Are you using the version installed via bioconda, or the pre-compiled binary from github, or have you compiled this yourself? You can [use the `LD_LIBRARY_PATH`](https://stackoverflow.com/questions/13428910/how-to-set-the-environmental-variable-ld-library-path-in-linux) to set things so that the appropriate version of the library is discovered first. You want the version of boost that is found first (the one appearing earliest in the `LD_LIBRARY_PATH`) to be matched to the one with which salmon was compiled.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/565#issuecomment-696812977:565,variab,variable-ld-library-path-in-linux,565,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/565#issuecomment-696812977,1,['variab'],['variable-ld-library-path-in-linux']
Modifiability,"Hi @RoebideBruijn,. If you've already run `cmake ..`, you must `rm CMakeCache.txt` and `rm -fr CMakeFiles` before running `cmake -DFETCH_BOOST=TRUE`. This is because CMake will cache variables between runs, and it won't properly interpret the flag to fetch boost. Also, can you show the entire sequence of steps you're executing to build? It looks like the camke file can't be found. Are you running cmake from within a build directory, or are you running it from the top-level directory?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/139#issuecomment-449035144:183,variab,variables,183,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/139#issuecomment-449035144,1,['variab'],['variables']
Modifiability,"Hi @SFonsecaCosta , . Some variability is expected since the read alignment methods are different. It's worth checking and generating summary stats for the unquantified genes, for example, their expression across samples, or if all the unquantified genes are mitochondrial/ribosomal of some sort.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/803#issuecomment-1263615944:27,variab,variability,27,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/803#issuecomment-1263615944,1,['variab'],['variability']
Modifiability,"Hi @TizianaS92,. One problem is that CMake is rather annoying with caching environment variables and versions. Could you see what happens if you `rm -fr` your `build` directory and then try again (this will obliterate `CMakeCache.txt` and the `CMakeFiles` subdirectory.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/388#issuecomment-505859344:87,variab,variables,87,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/388#issuecomment-505859344,1,['variab'],['variables']
Modifiability,"Hi @Toseph,. Thank you for the detailed report. I am actually surprised that it agreed to compile, since the CMake file should check for GCC >= 5.2 (https://github.com/COMBINE-lab/salmon/blob/master/CMakeLists.txt#L102). The reason for that check is that this is the version of GCC we have on our CI servers, and GCC 5 is, I believe, the first C++14 feature-complete version of GCC. Nonetheless, the gcc release pages suggest that 4.9 does support polymorphic lambdas. What concerns me though is that your backtrace has references to e.g. `/usr/include/c++/4.8.2/bits/unique_ptr.h:262:16`. GCC 4.8.2 is _not_ C++14 compatible, and does not support polymorphic lambdas. Do you have any idea why the compiler might be looking into headers included from GCC 4.8.2?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/296#issuecomment-422878261:448,polymorphi,polymorphic,448,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/296#issuecomment-422878261,2,['polymorphi'],['polymorphic']
Modifiability,"Hi @diyang1354,. It is recommended to do adapter trimming prior to mapping and quantification (standard practices actually involve adapter and _light_ quality trimming of reads). Adapter contamination could affect the mapping rate, especially if selective-alignment, which is recommended, is being used.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/398#issuecomment-511428337:41,adapt,adapter,41,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/398#issuecomment-511428337,3,"['Adapt', 'adapt']","['Adapter', 'adapter']"
Modifiability,"Hi @francicco ,. Can you try the following?. ```; $ conda config --add channels conda-forge; $ conda config --add channels bioconda; $ conda create -n salmon salmon=0.10.1; ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/231#issuecomment-394452979:58,config,config,58,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/231#issuecomment-394452979,2,['config'],['config']
Modifiability,"Hi @gaberoo,. I rebased this in develop since this is where we make changes, so that this will be in the next release. There was one change I had to make. There was a place where a string variable was being checked to determine the existence of a library (e.g. `if (${SUFFARRAY_LIB})` I believe). It seems CMake interprets even the empty string as TRUE here, so I had to change this to the corresponding `FOUND` variable. Otherwise, the changes all seem to have worked beautifully. Thanks again.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/348#issuecomment-473300118:188,variab,variable,188,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/348#issuecomment-473300118,2,['variab'],['variable']
Modifiability,"Hi @gringer,. Yes, we can add a section for this in the docs. It will replace the old way for specifying geometry soon, as its just easier and more flexible. We talk about it in the 1.4.0 release notes. I copy the relevant info below (@k3yavi pulled for the 1-based indexing and won out ... this time):. generic barcode / umi / read geometry syntax : Alevin learned to support a generic syntax to specify the read sequence that should be used for barcodes, UMIs and the read sequence. The syntax allows one to specify how the pattern corresponding to the barcode, UMI, and read sequence should be pieced together, and the syntax is meant to be intuitive and general. For example, one can specify the 10Xv2 geometry in the following manner using the generic syntax:. --read-geometry 2[1-end] --bc-geometry 1[1-16] --umi-geometry 1[17-26]. This specifies that the ""sequence"" read (the biological sequence to be aligned) comes from read 2, and it spans from the first index 1 (this syntax used 1-based indexing) until the end of the read. Likewise, the barcode derives from read 1 and occupies positions 1-16, and the UMI comes from read 1 and occupies positions 17-26. The syntax can specify multiple ranges, and they will simply be concatenated together to produce the string. For example, one could specify --bc-geometry 1[1-8,16-23] to designate that the barcode should be taken from the substring in positions 1-8 of read 1 followed by the substring in positions 16-23 of read 1. It is even possible to have the string pieced together across both reads, but that functionality is only available if you are running with --rad or --sketch and preparing a RAD file for alevin-fry. If you are running classic alevin, the barcode must reside on a single read. The robust parsing of the flexible geometry syntax is made possible by the cpp-peglib project.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/445#issuecomment-777884823:148,flexible,flexible,148,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/445#issuecomment-777884823,2,['flexible'],['flexible']
Modifiability,"Hi @guidohooiveld, . Regarding your questions:. (1) The motivation behind asking users to use Bioconda to install the binary is to limit the number of variables we may encounter when someone is reporting a bug --- i.e. if there are fewer distribution channels there is less maintenance overhead. Nonetheless, as you can see, I've had to make the binary available anyway, because it was the only way some people could easily get the program. Therefore, I think I'll start attaching binaries to releases again. (2) Yes, though this functionality is not part of Salmon itself. I *highly* recommend the [MultiQC](http://multiqc.info/) tool. MultiQC has a salmon module, which will parse all of the salmon log files in an experiment directory and produce a report. This report will contain the mapping percentages for all of the samples extracted from the salmon logs (and will color them nicely). It will also produce other QC information from the salmon runs. We are currently working on an improved multi-QC module, which will also provide summaries for things like GC / seq bias by analyzing the models that salmon learns, but this module isn't yet complete. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/252#issuecomment-405442271:151,variab,variables,151,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/252#issuecomment-405442271,1,['variab'],['variables']
Modifiability,"Hi @k3yavi , thank you for the reply. Yes, you are right, it seems the problem is indeed in the whitelist `known_cb.txt`. However, I cannot seem to find out what exactly is going on with the file. When I wrote a python script to check the length of each cell barcode in `known_cb.txt`, _all_ of them are 16 bp long. This is the python script:. ```; $ cat print_length.py; with open('known_cb.txt') as fh:; for i in fh:; print(len(i)); ```. since each line has 16 bp barcode and a `\n` character, it outputs 17, which is expected. However, when I used `awk` to check the length, I expected `awk` to output 16, but it actually output 17:. ```; $ awk '{print length($0);}' known_cb.txt | head -2; 17; 17; ```. There might be some hidden characters that I missed. Any idea what's going?. Now, I have cleaned the `known_cb.txt`, and `alevin` runs without problem. For combinatorial indexing, good to known that it will be supported in future. I guess depending on assays, it needs to be a bit more flexible than the current options. The current options have only `--chromium` and `--dropseq` available. However, there are a few different combinatorial indexing assays. For `sci-RNA-seq`, the cell barcodes are within `I1.fastq`, `I2.fastq` and `R1.fastq`. Only `R2.fastq` is useful for gene quantification. For `sci-ATAC-seq`, the cell barcodes (this is just my educational guess) are within `I1.fastq` and `I2.fastq`, and both `R1.fastq` and `R2.fastq` contain useful information from the genome. For other plate-based method, there will be well barcodes and plate barcodes, which could be located in any of those 4 fastq files depends on the design. The cell barcodes will be a combination of well barcodes and plate barcodes. Thank you very much for the help. Regards,; Xi",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/291#issuecomment-420807198:993,flexible,flexible,993,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/291#issuecomment-420807198,1,['flexible'],['flexible']
Modifiability,"Hi @k3yavi ,. Thanks a lot for you reply. ; Yes I agree that variability is expected, but my point is why these ~ 400 genes did not appear/exported in the quant.genes.sf file? some reason in special? Because they should be reported as well no?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/803#issuecomment-1263626603:61,variab,variability,61,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/803#issuecomment-1263626603,1,['variab'],['variability']
Modifiability,"Hi @k3yavi, ; I just re-read this post and I believe that in the CEL-Seq2 protocol, read_1 has first the UMI and then the CB and then polyT... because the sequencing starts with the Illumina adapter (see image below from paper). . Thanks!; ![13059_2016_938_fig1_html](https://user-images.githubusercontent.com/39304679/49376447-edbda900-f70f-11e8-85d7-b86b15c477d5.gif)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/311#issuecomment-443709804:191,adapt,adapter,191,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/311#issuecomment-443709804,1,['adapt'],['adapter']
Modifiability,"Hi @k3yavi,. Thanks for the reply!. Let's take the PBMC 4K as example. Looking at the summary sheet from 10x: ; http://cf.10xgenomics.com/samples/cell-exp/2.1.0/pbmc4k/pbmc4k_web_summary.html. They detected 4,340 cells with a median UMI count of 3,866 per cell. That means ~17M UMIs in the count matrix, which is in the same order what I find with Alevin. I am not sure if/where Alevin reports the number of mapped reads (maybe it is the number of hits?), but this is not of much importance. Indeed, the total UMI count is **much** lower than the number of sequenced/mapped/barcoded reads (~190M), which is expected. However, using the `--dumpUmiGraph` option provides a file ""MappedUMI.txt"" which I assume are the number of deduplicated UMIs mapped per cell/barcode (summed over all genes). The sum of over all the barcodes = 17M in this case and the sum per barcode = the sum in the quant_mat. This does not hold for the adapted cel-seq2 protocol. sum mapped UMI != summed quant_mat.gz. I am making a mistake, or is there something wrong?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/361#issuecomment-490098177:923,adapt,adapted,923,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/361#issuecomment-490098177,1,['adapt'],['adapted']
Modifiability,"Hi @kayDaramola ,. The download you will get from the releases page is the source. You will either need to build / compile it from source or, alternatively, install the binary using bioconda (recommended). Finally, you can try [this](https://github.com/COMBINE-lab/salmon/files/2099291/salmon-latest_linux_x86_64.tar.gz) pre-compiled binary for Linux, though we are trying to move to bioconda for all binary distribution as it makes support easier by removing a major variable.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/238#issuecomment-398558525:468,variab,variable,468,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/238#issuecomment-398558525,1,['variab'],['variable']
Modifiability,"Hi @kvittingseerup,. Basic adapter and quality trimming should be done. There's some [nice work by Matt MacManes](https://www.frontiersin.org/articles/10.3389/fgene.2014.00013/full) showing that you should be careful about aggressive quality trimming, but light quality trimming is usually beneficial. This is particularly important if the underlying aligner isn't doing local alignment (e.g. STAR will likely just softclip bad bases).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/390#issuecomment-506744431:27,adapt,adapter,27,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/390#issuecomment-506744431,1,['adapt'],['adapter']
Modifiability,"Hi @kvittingseerup,. No need to apologize, I think it was I who was not clear. What I am saying is that this is *already* the way that Salmon handles such a case. That is, if you have a paired-end read, and one of the reads maps but the other doesn't (due to e.g., adapter contamination or just very low quality), then Salmon will consider the remaining (mapping) end of the read as representative of an entire fragment, and will resolve the fragment origin accordingly during optimization. Generally, not having both ends of a paired-end read leads to increased ambiguity, but this isn't a particularly big problem if it only happens to a generally small fraction of the reads. Further, since you cannot reliably infer the implied fragment length on a transcript from only a single-end read, such mappings will not contribute to the bias model. Again, however, as long as this doesn't happen to the vast majority of fragments, it should have only a negligible effect on quantification and bias correction. Please let me know if this description makes sense. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/150#issuecomment-355881997:265,adapt,adapter,265,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/150#issuecomment-355881997,1,['adapt'],['adapter']
Modifiability,"Hi @lauraht,. So I decided to explore just one of these to see if I could figure out what might be going on. The below is with respect to `SRR9007475`. So first, even though I processed the data with the latest version of the develop branch (which will become 1.2.0), I got basically identical results to what you reported. Simply aligning the data against an index built on a human Gencode v26 transcriptome (with no decoys) gives me a mapping rate of `0.00378202832148367%`. The first thing I did was to quality and adapter trim the data (using `fastp -i SRR9007475.fastq.gz -o SRR9007475_trimmed.fastq.gz -q 10 -w 8`) and ... whoa. This is the fastp html report [fastp.html.zip](https://github.com/COMBINE-lab/salmon/files/4176345/fastp.html.zip). So the first astounding statistic, the mean read length before trimming is 51bp (these are relatively short single-end reads). The mean read length after trimming is 21bp! So, the average read length is, in fact, less than the k-mer length used for indexing (default is k=31). On the trimmed data, the mapping rate goes up to `2.3545475882931305%`, still very low, but now there's somewhat of an explanation, the average read is shorter than a single k-mer. So, the next thing I tried was indexing with a smaller k; a _really_ small one in this case,`k=15`. Then, I re-ran on the _trimmed_ reads (the fact that the trimming took us from 51-21bp suggests that the reads had a lot of low quality bases, adapter contamination, or both). Under this setting, I still get a very low mapping rate, but it was _much_ higher — `16.766993524863488%`. The final thing I tried was seeing how the mapping rate changed as I altered `--minScoreFraction`, which is the salmon parameter that determines the alignment score that a read must achieve in order to be mapped validly. The default is 0.65. This means that the read cannot have a score < 0.65 * the maximum achievable score for the read given it's length. In the case of a 21bp read, the best score would be ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/482#issuecomment-583799668:518,adapt,adapter,518,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/482#issuecomment-583799668,1,['adapt'],['adapter']
Modifiability,"Hi @lparsons,. Thanks for bringing this to our attention. There are just too many different places to remember to bump the version. This one was in the Python configuration script for the ReadTheDocs pages. Anyway, I've finally properly scripted the ""version_bump"" process, so this should happen automatically in the future (and is fixes as of 0.11.1). Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/259#issuecomment-408574511:159,config,configuration,159,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/259#issuecomment-408574511,1,['config'],['configuration']
Modifiability,"Hi @mishaprochazka and @jdidion,. Thanks @jdidion for pinging me on this. Somehow, Gmail has decided that all GitHub notifications (except those that explicitly tag me, but somehow I missed this one) should go to SPAM. So, I've been missing some of the newer issues here. The short answer is that the documentation needs to be updated. When salmon was originally published, we made use of [RapMap](https://github.com/COMBINE-lab/RapMap) as the underlying mapper, which performed quasi-mapping against an index that consisted of a suffix array and a hash over k-mers pointing to prefixes in the suffix array (similar to the strategy used by STAR, but using much longer k-mers to improve lookup speed). We referred to this index as the quasi-index. As the software evolved and we continued to improve the mapping methodology, we eventually transitioned over to an index based on [our pufferfish data structure](https://github.com/COMBINE-lab/pufferfish). In addition to the new data structure, this coincided with our move over to selective-alignment as the mapping algorithm, and all of this happened at the 1.0.0 release (this is why, for example, indices built before 1.0.0 are not compatible with salmon > 1.0.0; a topic on which there have been a few GitHub issues). However, given the fact that the documentation and software are linked only through manual human intervention (we haven't leveled up to e.g. having salmon be a [literate program](https://en.wikipedia.org/wiki/Literate_programming) yet), these two sometimes get out of sync. This is an instance of that. We have maintained the functionality of the `--writeMappings` feature, and in fact, even augmented it. However, we have not replaced the antiquated `quasi-index` terminology in the documentation. The TLDR is that you can use `--writeMappings` with the index you built with the `salmon index` command, and it should work fine. If you are mapping against an index without decoy sequences, then the output format will be basically ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/727#issuecomment-996192524:763,evolve,evolved,763,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/727#issuecomment-996192524,1,['evolve'],['evolved']
Modifiability,"Hi @mr-c,. First of all, **thank you** for your monumental effort in supporting salmon as a Debian package. I think this is fantastic. I'm also not a CMake expert, but I've failed with it enough times to start to get a handle. I have actually moved to the latest version of Jellyfish (v2.2.3) in the [quasimapping branch](https://github.com/COMBINE-lab/salmon/tree/quasimapping), which will be merged back into master as soon as we've finished porting the bootstrapping feature from [sailfish-master](https://github.com/kingsfordgroup/sailfish). Regarding supporting external versions of the libraries — this absolutely makes sense. What is the standard location where they are assumed to be installed? In this case I can search with a `FindPackage` before I attempt to download them. From the list above, I see two potential problem libraries:; - bwa — We actually use a modified version of bwa that accepts and uses an extra parameter that specifies the suffix array sampling frequency. Specifically, we, by default, use a denser sampling of the suffix array to trade off extra space usage for more speed in lookup. The standard bwa, therefore, probably wouldn't work.; - jellyfish — I actually tried to use jellyfish without obtaining the source and building it early on in development. I ran into an issue where the config.h file generated during compile wasn't installed by Jellyfish, and this caused runtime failures when Salmon was running. It seems to me that either (1) config.h should be installed with jellyfish by default or (2) it shouldn't be necessary to use jellyfish as a library. However, as far as I know, this issue persists in the latest version of jellyfish (if you want to use it as a library as we do, and not just as a k-mer counter). For the remaining libraries, we just use the standard versions, so this should be _OK_.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/19#issuecomment-144721158:1320,config,config,1320,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/19#issuecomment-144721158,2,['config'],['config']
Modifiability,"Hi @oligomyeggo,. Thank you for the **incredibly** detailed report :). The problem is the following (derived from your `B13_MeOH_cells_Jurkat_Cas9_EGR1_1_simulated.out.err.txt` log above):. ```; ### [ index ] => { /beevol/home/winklerc/projects/scifi_pipeline/scifi/ref/idx/complete_ref_lens.bin }; ```. So it looks like what your rule is passing to the mapping command is not the path to the index directory, but the path to this specific file, `complete_ref_lens.bin` **within** the index directory. The argument passed to the `-i` flag of `salmon alevin` must be the directory where all of the index files live. I think you just need to have the directory itself stored in a variable upon index creation, and then you can pass it to the mapping rule. Let me know if this helps!. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/713#issuecomment-941839528:678,variab,variable,678,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/713#issuecomment-941839528,1,['variab'],['variable']
Modifiability,"Hi @pinin4fjords ,. Apologies for the delayed response and thanks for your interest in Alevin.; Unfortunately, there is no one straight answer for your question. ; Other people have been using Alevin for various microwell based protocols like (CEL-seq https://github.com/COMBINE-lab/salmon/issues/269 ) but from our side we have not extensively tested alevin on non-droplet based protocols. However, we are open to provide any kind of help you may need to test the microwell-seq protocol and extend the support for alevin. If you happen to have been already testing alevin please let us know of your experience and how we can improve aleivn.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/358#issuecomment-490089165:492,extend,extend,492,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/358#issuecomment-490089165,1,['extend'],['extend']
Modifiability,"Hi @rfarouni ,. Thanks a lot for raising the issue.; It looks like a corner case with the custom barcode length and I'd have to push a hot-fix for it. Basically, it's failing in the initial sanity check stage where it assumes we can provide only one single-cell protocol type. Give me like half an hour to make the changes and I'll push the fix to the develop. If you can compile salmon from source that's great, otherwise I can also forward a linux portable binary.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-638385340:450,portab,portable,450,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-638385340,1,['portab'],['portable']
Modifiability,"Hi @rob-p . Before I answer your question and layout my logic, I want to mention that I am **_not_** suggesting fastp is not doing its job, **_neither am I stating that fastp is working incorrectly_**. Now to my answer(s) and logic:; 1. With fastp, I am not sure if adapter trimming happens first and then quality trimming OR vice-versa. I could not find info on this from their README and **_I could be wrong here with my next line_** - [Based on Figure 1 of this paper, it looks to me as though quality trimming is done before adapter trimming](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6129281/figure/bty560-F1/). - [To quote Brian Bushnell (author of BBTools)]( http://seqanswers.com/forums/showpost.php?p=140819&postcount=5), . > It's best to do adapter-trimming first, then quality-trimming, because if you do quality-trimming first, sometimes adapters will be partially trimmed and become too short to be recognized as adapter sequence. When you run BBDuk with both quality-trimming and adapter-trimming in the same run, it will do adapter-trimming first, then quality-trimming. 2. I very well know that the advantage of using fastp is that it can do adapter trimming, etc in a automatic fashion - no need to provide external sequences (example adapter sequences). Yes, I know one can also provide a fasta file of adapters and fatsp will work off it. There are many fatsp issues in GH about adapter detection:. - fail to detect adpaters automatically - (https://github.com/OpenGene/fastp/issues/222 and https://github.com/OpenGene/fastp/issues/205). - [incorrect automatic adapter detection](https://github.com/OpenGene/fastp/issues/240). - [inconsistent behavior with different runs](https://github.com/OpenGene/fastp/issues/231). 3. When I see the above, I am bit skeptical using fastp for qc/adapter trimming. . After lot of trials with bbduk and fastp, I have decided to use bbduk and bbmap for my high throughput analysis. Below, I explain my reasoning behind those choices: . **_```Not",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-597393209:266,adapt,adapter,266,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-597393209,5,['adapt'],"['adapter', 'adapter-trimming', 'adapters']"
Modifiability,Hi @rob-p . Thanks for the elaborate answer - makes a lot of sense. The problem is that adapter contamination typically occures because the fragments were smaller than the sequence length we sequence into the adapters - and it can occur for a larger fraction of the reads (I've seen up to 50% of reads affected in the 3'end) making it non-negligible. That is why I suggested the extension in the first place. I think it makes a lot of sense to trim adapters away - both because they reduce the number of compatible reads - mostly because the failure to do so will result in an overestimation of the fragment length. . Now that I think about it I don't think we should trim reads based on quality as that will lead to an underestimation of the read length - or what do you think?,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/150#issuecomment-355909325:88,adapt,adapter,88,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/150#issuecomment-355909325,3,['adapt'],"['adapter', 'adapters']"
Modifiability,"Hi @rob-p . Thanks for the quick reply. Indeed my salmon index does not include lncRNAs, but my sequencing does. For indexing, I only used UCSC RefSeq transcripts (which I believe contains only protein coding transcripts that exclude most of lncRNAs). But this does not seem to suffice to explain the low mapping rate as Wikipedia says ""[Quantitatively, lncRNAs demonstrate ~10-fold lower abundance than mRNAs in a population of cells.](https://en.wikipedia.org/wiki/Long_non-coding_RNA#Abundance)"". To answer your questions:; 1. I used `htseq-count`, and here are the overall statistics (out of 149347870 record pairs processed):; ```; stat	""-s yes""	""-s reverse""; __no_feature	135258158	44917653; __ambiguous	39301	594958; __too_low_aQual	0	0; __not_aligned	0	0; __alignment_not_unique	7430169	7430169; ```. 2. I haven't done quality/adapter trimming as the data really looks clean and of high quality according to FastQC report. 3. Unfortunately I can't share the raw data yet but I will try your suggestion to quantify with STAR at the transcript level.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/661#issuecomment-847091597:835,adapt,adapter,835,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/661#issuecomment-847091597,1,['adapt'],['adapter']
Modifiability,"Hi @rob-p . Thanks for the quick reply. Salmon was installed through bioconda. I'm pretty new to working in the console, but these are the commands I used:. `$ conda config --add channels conda-forge`; `$ conda config --add channels bioconda`; `$ conda create -n salmon salmon`",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/295#issuecomment-421376969:166,config,config,166,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/295#issuecomment-421376969,2,['config'],['config']
Modifiability,"Hi @rob-p . Thanks for the thanksgiving release of salmon. We saw salmon 1.3.0 for July 4th, salmon 1.4.0 for Thanksgiving, hopefully we would see 1.5.0 for Christmas and 1.6.0 for New Year :) . Keep up the great work. I see that you have salmon now available for ARM machines - https://github.com/COMBINE-lab/salmon/releases/tag/v1.4.0. As myself and @patrick-douglas has requested here - https://github.com/COMBINE-lab/salmon/issues/424 - the ability to compile salmon on ARM is great. A question: Will this work if I do a bioconda install or do I need to compile using the tar.gz file. I am using the ARM based conda from https://github.com/Archiconda/build-tools/releases/download/0.2.3/Archiconda3-0.2.3-Linux-aarch64.sh and with that I could do ; ``` ; conda config --add channels c4aarch64 && conda config --add channels defaults && conda config --add channels anaconda && conda config --add channels bioconda && conda config --add channels conda-forge ; ; conda install -c bioconda -c conda-forge -y nextflow bbmap numpy fastqc. ```. I don't see arch64 for salmon in bioconda here - https://anaconda.org/bioconda/salmon",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/556#issuecomment-734442247:765,config,config,765,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/556#issuecomment-734442247,5,['config'],['config']
Modifiability,"Hi @rob-p . Totally understood (even more severe current limitations here) - survey completed. I think there'll ""always"" be Illumina-level coding (we use it to multiplex samples or cells), but I suspect most (all?) wild-west method will be some form of using the one read for barcoding. So as long as I can stipulate which bases in the read are which kind of barcode (cell/molecular) that'd be a good start. Of course having more mature methods than the current [drop-seq protocol](http://mccarrolllab.com/wp-content/uploads/2016/03/Drop-seqAlignmentCookbookv1.2Jan2016.pdf) to error correct, remove poly-A, remove adaptor sequences etc. always very welcome. (I suspect @vals is onto something... I still struggle to be entirely convinced that UMIs, as currently used, have the long-term legs that some people think.)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/93#issuecomment-282741659:615,adapt,adaptor,615,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/93#issuecomment-282741659,1,['adapt'],['adaptor']
Modifiability,"Hi @rob-p,. I'm not seeing any links in your post (I assume that the references to ""this file"" were meant to be pointers to GENCODE's FTP files). Just to make sure, here are links to the files I've been working with:. - Decoy FASTA: [GRCm38.p6](http://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_mouse/release_M24/GRCm38.p6.genome.fa.gz); - Transcriptome: [GENCODE vM24](http://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_mouse/release_M24/gencode.vM24.primary_assembly.annotation.gtf.gz). In order to create the requisite FASTA of the transcripts from this GTF, I used [gffread](https://github.com/gpertea/gffread) (version 0.11.6). I'll look into trying to write the index to a local scratch directory. The temporary directory for these nodes is similarly mounted via NFS and we are actively discouraged from writing anything to `/tmp` itself (`$TMPDIR` points to to the mounted drive for programs that obey this environment variable).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/476#issuecomment-590575743:927,variab,variable,927,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/476#issuecomment-590575743,1,['variab'],['variable']
Modifiability,"Hi @rob-p. I'm using a SGE-based cluster. The disk I'm writing to is a networked disk that is mounted via NFS on the machines the cluster runs on. I've attached the output of running `qconf -sconf`, which provides details on how the cluster has been configured (I've edited out some lines about the admin e-mails, etc.). I'm not sure how useful much of this information is. A lot of it has to do with scheduling of jobs -- how many jobs/resources users can attempt to claim, that kind of thing. Let me know if there's something else that would be more useful in this context. I've also attached the log that was generated by the indexing run itself (just for the 17mer index), just in case. I can say one thing from having inspected the logs of these things failing a number of times before I finally caved and started giving it insane amounts of memory: by far the longest time and (most likely) the biggest resource hog is between the first and second pass. Even with only 16GB, it manages to complete the first pass (it still takes quite a while, though):. ```; Pass	Filling	Filtering; 1	718	3236	; 2	1839	237; ```. [qconf-sconf.txt](https://github.com/COMBINE-lab/salmon/files/4172585/qconf-sconf.txt); [index_GRCm38_GENCODE_M23_PRI_17mer.log.txt](https://github.com/COMBINE-lab/salmon/files/4172594/index_GRCm38_GENCODE_M23_PRI_17mer.log.txt). EDIT: Oh, I should also probably say, that I'm only seeing this slowdown on index creation. I'm sure that was implied, but I just wanted to be clear that at the moment, I'm happy enough to let the index build for a few hours every once in a while. I'm still saving huge amounts of mapping time, relative to ""full"" aligners.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/476#issuecomment-583567362:250,config,configured,250,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/476#issuecomment-583567362,1,['config'],['configured']
Modifiability,"Hi @silvanopiazza,. It would seem that this pre-compiled binary is making use of an instruction that is not available on the CPU on which you are executing `salmon`. In this case, there are a few alternatives:. * Try and run the command through a Docker image — the latest salmon is always available on [Dockerhub](https://hub.docker.com/layers/8712688/combinelab/salmon/latest/images/sha256-1c0b7e5b8a0996b6080cfc76fcd4e565f8c92689fe3cf1debc8b7493ae964c14?context=repo).; * Try and [install salmon via bioconda](https://anaconda.org/bioconda/salmon). The bioconda build may be making fewer assumptions about the target architecture than the pre-compiled github binary.; * Compile salmon from source locally. This will, of course, guarantee to only use instructions available on your hardware, though it's the most involved of these options.; ; Let me know if any of these work for you. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/783#issuecomment-1143871440:338,layers,layers,338,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/783#issuecomment-1143871440,1,['layers'],['layers']
Modifiability,"Hi @tamuanand,. Sure; is there anything specific about bbduk and bbmap for quality / adapter trimming that you think would be provided beyond or in addition to what fastp provides? Also, we have a beta implementation of soft-clipping and are looking for a wide net of testing data. Any suggestions to that end would be welcome!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-597344801:85,adapt,adapter,85,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-597344801,1,['adapt'],['adapter']
Modifiability,"Hi @tamuanand,. Thanks for the suggestion. You're right, of course, and we should change the wording in that readme. The cause of the sequence similarity is not always known, and frankly, not important for our particular application. We adopted this term as shorthand given it's common use and also because the version of MashMap used to compute these sequence-similar regions was introduced in the paper [A fast adaptive algorithm for computing whole-genome homology maps](https://academic.oup.com/bioinformatics/article/34/17/i748/5093242). In the preprint itself, we're generally careful to simply refer to these as sequence-similar regions ;).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/365#issuecomment-499476462:413,adapt,adaptive,413,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/365#issuecomment-499476462,1,['adapt'],['adaptive']
Modifiability,"Hi @tillea! Thanks for the added details, I'll try and repro with these. I noticed 2 other differences and wonder if they matter. The first is that your configure does `DUSE_SHARED_LIBS=TRUE`. Could there be shared libs found at runtime other than what is linked during compile?. The other is that you seem to be doing an in source build. I.e. building directly in the salmon dir rather than in a build directory. I'm actually a bit surprised the build works in that way, as it isn't designed to be an in source build. I can try and see if either of those matter on my end, but wonder if you have insight into either. Thanks,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463775612:153,config,configure,153,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463775612,1,['config'],['configure']
Modifiability,"Hi @tillea,. It seems this is exactly the problem. The build deps here are not quite correct. There are dependencies that salmon no longer has, and some of the dependencies it does have are out of date and can't be used from upstream (e.g. libstaden in the latest version, among others). On the bright side, it's not the dynamic linking alone that is problematic. The following works fine on my end:. ```{bash}; $ docker pull debian:testing; $ docker run -it debian:testing; $ echo ""deb-src http://deb.debian.org/debian unstable main"" > /etc/apt/sources.list.d/10-debsrc.list; $ apt-get update; $ apt-get upgrade; $ apt-get install build-essential git libboost-all-dev liblzma-dev libbz2-dev cmake zlib1g-dev curl unzip wget libcurl4-openssl-dev libtbb-dev libtbb12 liblzma-dev libjemalloc2 pkg-config libgff-dev; $ wget https://github.com/COMBINE-lab/salmon/archive/refs/tags/v1.10.0.tar.gz; $ tar xaf v1.10.0.tar.gz; $ cd salmon-1.10.0; $ mkdir build && cd build; $ cmake -DCMAKE_BUILD_TYPE=Release -DUSE_SHARED_LIBS=TRUE -DBZIP2_LIBRARIES=-lbz2 -DBZIP2_INCLUDE_DIR=/usr/include -DLIBLZMA_INCLUDE_DIR=/usr/include/ -DLIBLZMA_LIBRARY=lzma -DCMAKE_MODULE_PATH=/usr/share/cmake/Modules -DTBB_WILL_RECONFIGURE=FALSE -DBOOST_WILL_RECONFIGURE=FALSE ..; $ make -j8; $ make install; $ make test; ```. This is preferring dynamic linking, and the resulting installed executable runs fine without a segfault. Can you try this on your end? Then the thing to do may be to find what is discordant between the packages I install above and what gets pulled in by `apt build-dep salmon`. Thanks,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1464182279:795,config,config,795,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1464182279,1,['config'],['config']
Modifiability,"Hi @tseemann, you can now use `-DBOOST_BUILD_THREADS=<desired threads>` during configuration to control this. Let me know if it works.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/412#issuecomment-549180097:79,config,configuration,79,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/412#issuecomment-549180097,1,['config'],['configuration']
Modifiability,"Hi @wdecoster,. Thanks for reporting this. One restriction that needs to be better documented (actually, I have to make sure it is properly documented at all!) is that the library type should come _before_ the reads they describe. That is, you should consider passing `-l SF -r {}` rather than `-r {} -l SF`. The reason for this is that the `-r` and `-1,-2` parameters are repeatable so you could, conceivably, pass multiple reads of different library types. However, this is a feature that nobody uses and frankly doesn't make too much sense (so I'll consider removing it in the future to simplify library type parsing). For the time being, I'll also consider printing a warning message when a read file is encountered without an explicitly pre-defined library type (in that case, the behavior, as you saw, is to assume an unstranded library). Could you let me know if passing `-l` before `-r` resolves the issue for you. As to your other suggestion. The internal capitalization rules follow those for camel-case naming of variables (as opposed to separating words with`_`). However, I realize this is somewhat esoteric and even among those who are familiar with such conventions, an arbitrary preference. I'll look into aliasing this flag (and maybe others) to be usable with different names as well. I just have to check how to do this (and if it is possible) with boost's program options.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/177#issuecomment-347524360:1024,variab,variables,1024,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/177#issuecomment-347524360,1,['variab'],['variables']
Modifiability,"Hi Andreas,. So I don't know if there is a easy way to get the specific list of reverse dependencies, but then we can cross-check it with my explicit list above:. ```; build-essential; git ; libboost-all-dev ; liblzma-dev ; libbz2-dev ; cmake ; zlib1g-dev ; curl ; unzip ; wget ; libcurl4-openssl-dev ; libtbb-dev ; libtbb12 ; liblzma-dev ; libjemalloc2 ; pkg-config ; libgff-dev; ```. One thing I noticed during build is that, while I included `libjemalloc2` here, the salmon build procedure still downloaded and built `jemalloc`. However, I don't _think_ jemalloc is the thing causing the segfault. Regarding dependencies that can't be used — the current `libstaden` is behind the upstream release. The upstream release contains an important bug fix for a bug (and suggested fix that we proposed to the developer) upon which we rely. More importantly, afaik there is no relevant `libpufferfish-dev` package (we certainly have not made one), and so there is not even e.g. a check in the `CMakeLists.txt` file. Salmon's build always tries to run `fetchPufferfish.sh` to download the relevant `pufferfish` source files needed to build `salmon`. Critically, the relevant `pufferfish` dependencies and `salmon` releases move in lockstep. Each new `salmon` release it accompanied by a new tag in the `pufferfish` repo (so that the specific source used to build a given `salmon` release is fixed and easily trackable). So, I think the easiest way to move forward is to:. * do a diff of my list of packages above with what is pulled in by `apt build-dep salmon`. * figure out why, even when `libjemalloc2` is installed, the build system tries to build `jemalloc` itself (maybe we need the dev package?). * determine what folks want to do upstream about the lockstep pufferfish dependency. Right now, the `fetchPufferfish.sh` script pulls a tagged tarball from github and checks that the sha matches, and moves the relevant source files into place. This is true both when we build our own releases as well as",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1464538233:360,config,config,360,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1464538233,1,['config'],['config']
Modifiability,"Hi Brian,. In general, I would argue that one should be cautious with removing PCR duplicates in RNA-seq data (unless you are dealing with reads with UMI tags). This is because reads that align to the same reference position can easily have come from alternative transcripts sharing the same underlying sequence. Hence, the normal tests used to infer PCR duplicates with e.g. DNA-seq reads can yield false-positives in RNA-seq. This is particularly true for highly abundant transcripts (or transcripts from highly-abundant genes). We are currently working on the code that will do duplicate removal when UMI tags are present. That methodology can be extended to remove duplicates even without UMI tags --- though I'd generally caution against that for the reasons mentioned above. However, for the time being, if you have a strong need or desire to filter PCR duplicates, you could use alignment-based Salmon with a BAM file that has duplicates removed. Finally, regarding the error you are getting during SAM validation; this sounds like a different issue. Would you mind providing a piece of that SAM file for me to take a look at? Specifically, I don't believe the quasi-mapping output file should even contain unmapped reads (unless you consider unmapped mates of orphaned reads). --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/136#issuecomment-305317281:650,extend,extended,650,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/136#issuecomment-305317281,1,['extend'],['extended']
Modifiability,"Hi George,. This will require some upstream changes to the SAM writing code, but I don't think it should be too hard. We could add this to the roadmap. I'll tag this as an enhancement. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/756#issuecomment-1068650251:172,enhance,enhancement,172,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/756#issuecomment-1068650251,1,['enhance'],['enhancement']
Modifiability,"Hi Hari,. Some thoughts on your questions:. > I had to use mem_free=34G for building index. Is that expected?. Certainly, it is _not_ the case that index creation should require 34G of physical memory. When indexing the genome and transcriptome in dense mode, we typically expect it to require <20G of physical RAM (and <4 for just the transcriptome). However, we have noticed some strange behavior in the past about how compute clusters manage process allocation — sometimes, it seems, one must overcommit. Given the diversity of different software on which different compute clusters run, as well as the manifold way sysadmins may configure these things, we've not found a universal explanation / conclusion yet, but it does seem that the resources actually required (e.g. if you run salmon index under `/usr/bin/time` and look at the resources) are less than what should be requested. The differences in the sha256 sums are a bit strange and I don't have a great explanation for them. One difference is that I built with the head of the develop branch (which has version tag 1.3.1). That describes a difference in `versionInfo.json` but nothing upstream in the index building should have changed, so I am not sure why the other files would have different sha256 sums. I can try with the pre-compiled binary and see if my results match yours. In the meantime, please keep me posted. If index building ends up worth for you with a different configuration, it would be good to check this off of our list of TODOs, and if not, it would be good to get to the bottom of it. Thanks!; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/561#issuecomment-674528707:633,config,configure,633,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/561#issuecomment-674528707,2,['config'],"['configuration', 'configure']"
Modifiability,"Hi Mohsen and Rob,. So sorry if you've already been troubleshooting the example data I gave you. I realized that that is not a good example of the problem. In this example, there are snR40 and snR40_genomic transcripts, representing processed and pre-processed isoforms. However, it just so happens that there is residual adapter on some of the reads I provided and the first nucleotide of the adapter sequence actually matches the first nucleotide of the longer, genomic version of this transcript, therefore, the genomic variant gets a slightly better alignment score, as it should. After hard trimming any residual adapter the results for this transcript were a lot better (although still not quite the ratio I would expect). I have quite a few examples like this and I'm fairly sure they are not *all* explained by alignment of adapter sequences. However, I just wanted to let you know in case you were already troubleshooting my example data. I'm aggregating a handful more general examples of the same problem, but ones without a trivial solution like the one I provided. The files are too large to attach on github directly, though, do you have a preferred way to share the files? Maybe a google drive?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-642954815:322,adapt,adapter,322,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-642954815,4,['adapt'],['adapter']
Modifiability,"Hi Nate,. Can you tell me / do you know how boost was compiled? The error you're getting looks like what happens when the version of boost against which salmon is attempting to link was not built with >= C++11. Basically, the newest version of salmon requires C++14 (which GCC 8 obviously supports). However, there are binary incompatibilities between pre-C++11 and post-C++11 code libraries. So, whatever version of boost you link against must have been compiled with at least `--std=c++11`. One option is to let salmon fetch and build boost for you by putting `-DFETCH_BOOST=TRUE` in the cmake configuration flags when calling `cmake`. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/309#issuecomment-436830925:596,config,configuration,596,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/309#issuecomment-436830925,1,['config'],['configuration']
Modifiability,"Hi Nazeeefa,. Is the relevant file `libtbbmalloc_proxy.so.2` actually present in that directory? What are the contents of `path/to/salmondir/lib`? If you are in an environment with bioconda, you can also try installing tbb through that system as well to ensure you have the shared library. Unfortunately, TBB is pretty much the one library that is not possible to link statically. Also, which shell are you using? The syntax for exporting an environment variable is different in different shells.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/219#issuecomment-386299893:454,variab,variable,454,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/219#issuecomment-386299893,1,['variab'],['variable']
Modifiability,"Hi Rich,. The issue with pre-compiled OSX binaries is that they are difficult to make portable across OSX versions. This is why we strongly suggest installing Salmon (especially for OSX) through [Bioconda](https://bioconda.github.io/). This greatly eases installation and updating, and doesn't require admin privileges. On OSX, you can try the following:. ```; $ conda config --add channels conda-forge; $ conda config --add channels bioconda; $ conda create -n salmon salmon=0.9.1; ```. This should take care of all relevant dependencies as well as e.g. library locations and placement. Could you please give this a try and let me know if it works for you?. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/215#issuecomment-381997508:86,portab,portable,86,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/215#issuecomment-381997508,3,"['config', 'portab']","['config', 'portable']"
Modifiability,"Hi Rob, . Thanks for the quick reply. I'm looking into it and will try this with an updated install of GCC >= 5.2.; The system default gcc is 4.8.5 but I set it to use a different install using environment modules to load gcc-4.9.2 but some environment variables may not have been set correctly, hence why the build file switches to a lower-version GCC but it isn't clear why it looks for 4.8.2 despite that.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/296#issuecomment-422891645:253,variab,variables,253,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/296#issuecomment-422891645,1,['variab'],['variables']
Modifiability,"Hi Rob, thanks for the quick reply.; I tried what you suggested and I tried with adding the bioconda channel but still got the same error, however adding the conda-forge and bioconda channels to the conda config solved it. Maybe it needed access to conda-forge to find the boost and libcxx packages?. ```; $ conda config --add channels conda-forge; $ conda config --add channels bioconda; $ conda create -n salmon salmon=0.9.1; Solving environment: done. ## Package Plan ##. environment location: /Users/Jb_Macbook/miniconda3/envs/salmon. added / updated specs: ; - salmon=0.9.1. The following packages will be downloaded:. package | build; ---------------------------|-----------------; tk-8.6.7 | 0 3.0 MB conda-forge; mkl_random-1.0.1 | py36_0 371 KB conda-forge; boost-1.64.0 | py36_4 304 KB conda-forge; libiconv-1.15 | 0 1.3 MB conda-forge; clangdev-4.0.0 | default_0 62.8 MB conda-forge; bzip2-1.0.6 | 1 145 KB conda-forge; xz-5.2.3 | 0 304 KB conda-forge; certifi-2018.1.18 | py36_0 143 KB conda-forge; pip-9.0.3 | py36_0 1.7 MB conda-forge; tbb-2018_20171205 | 0 404 KB conda-forge; boost-cpp-1.64.0 | 1 16.2 MB conda-forge; ncurses-5.9 | 10 1.1 MB conda-forge; jemalloc-4.5.0 | 0 4.1 MB bioconda; salmon-0.9.1 | 1 2.6 MB bioconda; numpy-1.14.2 | py36ha9ae307_1 4.0 MB; sqlite-3.20.1 | 2 1.4 MB conda-forge; setuptools-39.0.1 | py36_0 552 KB conda-forge; llvmdev-4.0.0 | default_0 100.9 MB conda-forge; icu-58.2 | 0 22.7 MB conda-forge; readline-7.0 | 0 383 KB conda-forge; libcxx-4.0.0 | 1 1.1 MB conda-forge; zlib-1.2.11 | 0 95 KB conda-forge; libxml2-2.9.8 | 0 1.9 MB conda-forge; wheel-0.31.0 | py36_0 62 KB conda-forge; python-3.6.5 | 1 13.9 MB conda-forge; mkl_fft-1.0.1 | py36_1 146 KB conda-forge; ------------------------------------------------------------; Total: 241.7 MB; ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/192#issuecomment-379821279:205,config,config,205,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/192#issuecomment-379821279,3,['config'],['config']
Modifiability,"Hi Rob,. Thanks for the clarity regarding the effect of insert size distribution on quantification. That does resolve this issue, and gives me a path going forward using Salmon for this data. However, I am trying to use Salmon for small RNA-Seq data, where the insert size is equal to read length for most reads after adapter trimming. Would it be possible to add a flag to use read length as a proxy for insert size, potentially with a fallback to fldMean/fldSD in the case of full-length, untrimmed reads? This is something I would be willing to contribute myself, if it sounds appropriate. Thanks,; Gautam",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/605#issuecomment-752064194:318,adapt,adapter,318,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/605#issuecomment-752064194,1,['adapt'],['adapter']
Modifiability,"Hi rob-p,; `gcc -version ` tells me its version `6.3.0` of the GCC compiler. . ```; c+\+ -v; Using built-in specs.; COLLECT_GCC=c++; COLLECT_LTO_WRAPPER=/usr/libexec/gcc/x86_64-alpine-linux-musl/6.3.0/lto-wrapper; Target: x86_64-alpine-linux-musl; Configured with: /home/buildozer/aports/main/gcc/src/gcc-6.3.0/configure --prefix=/usr --mandir=/usr/share/man --infodir=/usr/share/info --build=x86_64-alpine-linux-musl --host=x86_64-alpine-linux-musl --target=x86_64-alpine-linux-musl --with-pkgversion='Alpine 6.3.0' --enable-checking=release --disable-fixed-point --disable-libstdcxx-pch --disable-multilib --disable-nls --disable-werror --disable-symvers --enable-__cxa_atexit --enable-default-pie --enable-cloog-backend --enable-languages=c,c++,objc,java,fortran,ada --disable-libssp --disable-libmpx --disable-libmudflap --disable-libsanitizer --enable-shared --enable-threads --enable-tls --with-system-zlib --with-linker-hash-style=gnu; Thread model: posix; gcc version 6.3.0 (Alpine 6.3.0); ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/162#issuecomment-343658308:248,Config,Configured,248,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/162#issuecomment-343658308,2,"['Config', 'config']","['Configured', 'configure']"
Modifiability,"Hi, Rob. I'm seeing this same error `Cannot find source file`; ```; -- Configuring done; CMake Error at src/CMakeLists.txt:113 (add_executable):; Cannot find source file:; /tmp/salmon-20180222-8345-abjxc0/salmon-0.8.2/external/install/src/rapmap/RapMapFileSystem.cpp; Tried extensions .c .C .c++ .cc .cpp .cxx .m .M .mm .h .hh .h++ .hm .hpp; .hxx .in .txx; ```; See the complete build log at https://circleci.com/gh/brewsci/homebrew-bio/491; Any ideas?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/181#issuecomment-367590842:71,Config,Configuring,71,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/181#issuecomment-367590842,1,['Config'],['Configuring']
Modifiability,"Hi,. I thought I would extend this issue rather than creating a new issue. Happy to create new if that would be better. I'm using the docker version of Salmon (latest version). I have also mounted a local directory. I'm getting the same error. (Note I have tried several different versions of the command, including the --no-version-check command). salmon index --gencode ; -t /home/RnaSeq/transcriptome_gencode_v29/human_GENCODEv29/gentrome.fa ; -d /home/RnaSeq/transcriptome_gencode_v29/human_GENCODEv29/decoys.txt ; -i /home/RnaSeq/transcriptome_gencode_v29/human_GENCODEv29/combined_index. Version Info: Could not resolve upgrade information in the alotted time.; Check for upgrades manually at https://combine-lab.github.io/salmon; [2019-07-01 12:32:42.622] [jLog] [info] building index; [2019-07-01 12:32:42.628] [jointLog] [info] [Step 1 of 4] : counting k-mers. <Several warnings about transcripts that are disliked>. [2019-07-01 12:33:02.020] [jointLog] [info] Replaced 3801867 non-ATCG nucleotides; [2019-07-01 12:33:02.020] [jointLog] [info] Clipped poly-A tails from 1630 transcripts; [2019-07-01 12:33:02.041] [jointLog] [info] Building rank-select dictionary and saving to disk; [2019-07-01 12:33:02.248] [jointLog] [info] done; Elapsed time: 0.20793s; [2019-07-01 12:33:02.252] [jointLog] [info] Writing sequence data to file . . . ; [2019-07-01 12:33:04.501] [jointLog] [info] done; Elapsed time: 2.24861s; [2019-07-01 12:33:04.572] [jointLog] [info] Building 32-bit suffix array (length of generalized text is 469043886); [2019-07-01 12:33:08.681] [jointLog] [info] Building suffix array . . . ; success; saving to disk . . . done; Elapsed time: 61.4932s; done; Elapsed time: 171.743s; processed 12000000 positionsKilled. I can send log files if required. The problem I have is that I cannot seem to run quant without the quant function. salmon quant --validateMappings ; -i /home/RnaSeq/transcriptome_gencode_v29/human_GENCODEv29/combined_index -l IU ; -1 /home/RnaSeq/fastq/DM_4a_H_",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/389#issuecomment-507253562:23,extend,extend,23,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/389#issuecomment-507253562,1,['extend'],['extend']
Modifiability,"Hi,. If I don't trim the adaptors and still use --ont will I still get correct quantification? Is adaptor trimming very essential? Is there a way I can use salmon without adaptor trimming?. Also, can you please clarify about the secondary alignmenmts if these are included in Salmon or not?. Thanks,; Harsha; ________________________________; From: Feng Yan ***@***.***>; Sent: 08 January 2024 23:30; To: COMBINE-lab/salmon ***@***.***>; Cc: Harshangda Karan Puri ***@***.***>; Author ***@***.***>; Subject: Re: [COMBINE-lab/salmon] Quantification in Alignment mode for Nanopore Data (Issue #903). also interested to know how Salmon uses secondary alignment. Because I found this tutorial https://combine-lab.github.io/salmon-tutorials/2021/ont-long-read-quantification/ [combine-lab.github.io]<https://urldefense.com/v3/__https://combine-lab.github.io/salmon-tutorials/2021/ont-long-read-quantification/__;!!PDiH4ENfjr2_Jw!GTZeAEdMSJcSBTPXhWuSsmLuX2WDzuNuNgqT04lADpRqOWyHssr_JALdqVa1JBOS9RHGRa9M6SeJKoxo6T7o5_O0bvsV-KkgNb45i4uTnGob8fw$> actually includes secondary alignments.; And based on my experience, secondary alignments are used by Salmon, because when I give a BAM before and after removing secondary (-F 256 flag in samtools), the results are different. —; Reply to this email directly, view it on GitHub [github.com]<https://urldefense.com/v3/__https://github.com/COMBINE-lab/salmon/issues/903*issuecomment-1881982972__;Iw!!PDiH4ENfjr2_Jw!GTZeAEdMSJcSBTPXhWuSsmLuX2WDzuNuNgqT04lADpRqOWyHssr_JALdqVa1JBOS9RHGRa9M6SeJKoxo6T7o5_O0bvsV-KkgNb45i4uTEiG0xQE$>, or unsubscribe [github.com]<https://urldefense.com/v3/__https://github.com/notifications/unsubscribe-auth/A3SZAPCLOZYB72ZEIEEXH43YNR6S7AVCNFSM6AAAAABANBCPNSVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMYTQOBRHE4DEOJXGI__;!!PDiH4ENfjr2_Jw!GTZeAEdMSJcSBTPXhWuSsmLuX2WDzuNuNgqT04lADpRqOWyHssr_JALdqVa1JBOS9RHGRa9M6SeJKoxo6T7o5_O0bvsV-KkgNb45i4uTntkMlxE$>.; You are receiving this because you authored the thread.Message ID: ***@***.***>",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/903#issuecomment-1884769339:25,adapt,adaptors,25,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/903#issuecomment-1884769339,3,['adapt'],"['adaptor', 'adaptors']"
Modifiability,"Hi,. Yes, I did install with bioconda. Thanks for the link to the precompiled; version, which I downloaded and unzipped. I'm sorry to be so ignorant (my; unix knowledge is 25 years out of date) but how/where should I install; this?. Also, currently ""which salmon"" gives me the bioconda version. I guess I; will need to add the path to the precompiled version on the end of my PATH; environment variable?. Thanks,; Michael. On Sat, Nov 24, 2018 at 3:51 PM Rob Patro <notifications@github.com> wrote:. > Hi @michael-brent <https://github.com/michael-brent> ,; >; > Did you, by any chance, install via bioconda? There is a known issue with; > the bioconda build on OSX. Can you try this; > <https://github.com/COMBINE-lab/salmon/files/2383948/salmon_0.11.4-pre_OSX.tar.gz>; > pre-compiled binary in the meantime to see if it works for you?; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/COMBINE-lab/salmon/issues/318#issuecomment-441398017>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ArM27mCF3NQcGVuZHpU3-8mb2_6WI7NIks5uyb9egaJpZM4YxmdA>; > .; >",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/318#issuecomment-441447779:394,variab,variable,394,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/318#issuecomment-441447779,1,['variab'],['variable']
Modifiability,"Hi,; it goes literally in panic: . ```; panic: runtime error: slice bounds out of range. goroutine 1 [running]:; github.com/sylabs/singularity/internal/pkg/util/uri.Split(0x7ffd422b2b65, 0x1f, 0xc00003c195, 0xc0004852f0, 0xc0004e5c78, 0x929217); 	/tools/others_tools/Go/go-1.11.2/src/github.com/sylabs/singularity/internal/pkg/util/uri/uri.go:104 +0x13e; github.com/sylabs/singularity/cmd/singularity/cli.replaceURIWithImage(0x19d2a60, 0xc0000b8900, 0x11, 0x12); 	/tools/others_tools/Go/go-1.11.2/src/github.com/sylabs/singularity/cmd/singularity/cli/actions.go:189 +0x5d; github.com/sylabs/singularity/vendor/github.com/spf13/cobra.(*Command).execute(0x19d2a60, 0xc000030160, 0x12, 0x12, 0x19d2a60, 0xc000030160); 	/tools/others_tools/Go/go-1.11.2/src/github.com/sylabs/singularity/vendor/github.com/spf13/cobra/command.go:755 +0x4ed; github.com/sylabs/singularity/vendor/github.com/spf13/cobra.(*Command).ExecuteC(0x19d65c0, 0x0, 0xf6, 0xfc0b01); 	/tools/others_tools/Go/go-1.11.2/src/github.com/sylabs/singularity/vendor/github.com/spf13/cobra/command.go:852 +0x2fd; github.com/sylabs/singularity/vendor/github.com/spf13/cobra.(*Command).Execute(0x19d65c0, 0x4, 0x1133611); 	/tools/others_tools/Go/go-1.11.2/src/github.com/sylabs/singularity/vendor/github.com/spf13/cobra/command.go:800 +0x2b; github.com/sylabs/singularity/cmd/singularity/cli.ExecuteSingularity(); 	/tools/others_tools/Go/go-1.11.2/src/github.com/sylabs/singularity/cmd/singularity/cli/singularity.go:114 +0x110; main.main(); 	/tools/others_tools/Go/go-1.11.2/src/github.com/sylabs/singularity/cmd/singularity/cli.go:16 +0x20; ```; with -e you clean environment before running container.; I haven't found how to add the environmental variable, but logging in as shell and exporting the variable, it works ( or at least, I discover that I have to rebuild the index since it was built with the old verision in RapMap). I'll see if there is another way to import the variable or I'll build an image with the env; Thanks ; Claudio",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/447#issuecomment-553005722:1705,variab,variable,1705,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/447#issuecomment-553005722,3,['variab'],['variable']
Modifiability,"Hrmm --- [this](https://github.com/COMBINE-lab/salmon/blob/master/CMakeLists.txt#L366) is the relevant part of the CMakeFile that builds this. It uses the `CC` and `CXX` variables, but doesn't explicitly pass along any others. The first thing to check is what variables the bwa makefile respects, and then to propagate these along via CMake.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/89#issuecomment-246025112:170,variab,variables,170,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/89#issuecomment-246025112,2,['variab'],['variables']
Modifiability,"I actually think that (as @mr-c points out), the `config.h` file isn't necessary with newer versions of Jellyfish. I'm removing the dependency upstream.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/19#issuecomment-195644865:50,config,config,50,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/19#issuecomment-195644865,1,['config'],['config']
Modifiability,"I changed the BUILD_COMMAND to use gmake. I also ran 'export MAKE=gmake', and used gmake to run the output of cmake. . BUILD_COMMAND sh -c ""gmake ${QUIET_MAKE} CC=${CMAKE_C_COMPILER} CXX=${CMAKE_CXX_COMPILER}"". Unfortunately, the BWA included with Salmon is broken on FreeBSD. . kthread.c:70:2: error: unknown type name 'int64_t'. The one on Git (https://github.com/lh3/bwa) works though. So I modified DOWNLOAD_COMMAND to grab the one from Git. . DOWNLOAD_COMMAND git clone https://github.com/lh3/bwa bwa-master. Next problem, it tries to build TBB and fails. This is two problems, because I have TBB, I passed it the path, and it fails to use it. The output of cmake says:. -- Could NOT find TBB (missing: tbbmalloc_proxy) (found suitable version ""2018.0"", minimum required is ""4.4""). tbbmalloc_proxy.h is present in /usr/local/include/tbb. Moving on, TBB fails to build because it's hard coded to use make. I fixed this and it built. BUILD_COMMAND gmake ${QUIET_MAKE} CXXFLAGS=${TBB_CXXFLAGS} lambdas=1 compiler=${TBB_COMPILER} cfg=release tbb_build_prefix=LIBS. Staden-io_lib fails to build with: ; /usr/bin/ld: undefined reference to symbol `pthread_create@@FBSD_1.0' (try adding -lthr); //lib/libthr.so.3: could not read symbols: Bad value. As advertised, -lthr fixed this issue. ; CONFIGURE_COMMAND ./configure --enable-shared=no --without-libcurl --prefix=<INSTALL_DIR> LDFLAGS=-lthr CFLAGS=${LIBSTADEN_CFLAGS} CC=${CMAKE_C_COMPILER} CXX=${CMAKE_CXX_COMPILER}. This leads me to an error I can't fix on my own. /home/esiefker/salmon/fresh-salmon/include/BWAMemStaticFuncs.hpp:36:36: error:; use of undeclared identifier 'MEM_F_SELF_OVLP'; int start_width = (opt->flag & MEM_F_SELF_OVLP)? 2 : 1;. There is a similar Debian bug which is fixed: https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=818397. I could not find the fix mentioned. https://github.com/COMBINE-lab/salmon/commits/master?author=satta. I have done my best, but I am stuck. I hope this is helpful for those more skilled than I.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/162#issuecomment-337390415:1434,config,configure,1434,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/162#issuecomment-337390415,1,['config'],['configure']
Modifiability,I don't think `config.h` is needed when compiling against prebuilt `libjellyfish*.so`; when building salmon for Debian I explicitly patched out the include and everything built just fine. http://anonscm.debian.org/cgit/debian-med/salmon.git/plain/debian/patches/jellyfish-update,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/19#issuecomment-195452002:15,config,config,15,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/19#issuecomment-195452002,1,['config'],['config']
Modifiability,"I have used ""U"" as was default in config.yml for pipeline-transcriptome-de but now I am thinking it should be stranded but i am not understanding the reverse part? Should it not be SF as this is essentially single-read and the baseball sequence is output as 5' to 3' of original RNA molecule despite being sequenced in the reverse from 3' to 5'.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/211#issuecomment-822139485:34,config,config,34,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/211#issuecomment-822139485,1,['config'],['config']
Modifiability,"I increased ram to 24G. Segmentation fault happens even faster. I have fiddled with swap memory, to no avail, but I am not a good swap fiddler.; libs with malloc in their name, installed in directory /salmon-latest_linux_x86_64/ib adjacent to /salmon-latest_linux_x86_64/bin, are the same as elsewhere already on my system. conda and bioconda are not available for FreeBSD. What OS would work?; I have looked through the published papers and find no mention of which OS should work. My attempted command for compiling the sources from unzipped directory salmon-0.14.1 is: cmake -S src -B build; Many errors result, starting with:; TBB_LIBRARIES = ; Setting libdivsufsort = /external/install/lib/libdivsufsort.a; Setting libdivsufsort64 = /external/install/lib/libdivsufsort64.a; -- Configuring done; CMake Error at CMakeLists.txt:196 (add_executable):; Cannot find source file:. /tests/UnitTests.cpp. Tried extensions .c .C .c++ .cc .cpp .cxx .cu .m .M .mm .h .hh .h++ .hm; .hpp .hxx .in .txx. CMake Error at CMakeLists.txt:196 (add_executable):; Target ""unitTests"" links to target ""Threads::Threads"" but the target was; not found. Perhaps a find_package() call is missing for an IMPORTED; target, or an ALIAS target is missing?. CMake Error at CMakeLists.txt:162 (add_library):; Cannot find source file:. /src/jellyfish/mer_dna.cc. Tried extensions .c .C .c++ .cc .cpp .cxx .cu .m .M .mm .h .hh .h++ .hm; .hpp .hxx .in .txx. Apparently the so-called sources do not include many files ending in .cpp, for instance. Please, I repeat, what linux OS should be able to install salmon? ; And/Or what command could compile salmon?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/419#issuecomment-522626638:782,Config,Configuring,782,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/419#issuecomment-522626638,1,['Config'],['Configuring']
Modifiability,I made myself a plot to illustrate @roryk 's approach (hopefully got it right)- just leaving it here in case others are interested. ![compare_droplet_threshold](https://user-images.githubusercontent.com/5775915/57373557-9032fa00-7190-11e9-9cec-15b0a32f88aa.png). Code here: https://github.com/ebi-gene-expression-group/jon-sandbox/tree/master/droplet_cutoffs.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/362#issuecomment-490391990:323,sandbox,sandbox,323,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/362#issuecomment-490391990,1,['sandbox'],['sandbox']
Modifiability,I think the longer-term solution is for us to _directly_ support BAM writing. This would obviate the need of passing the output through `samtools`. I will mark this issue as an enhancement to remind us to look into what will be involved in doing that (while we work on addressing the more obvious issues you raise).,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/242#issuecomment-400067553:177,enhance,enhancement,177,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/242#issuecomment-400067553,1,['enhance'],['enhancement']
Modifiability,"I think you're right wrt conda. I was able to install 1.10.2 with mamba fairly easily. We've been moving away from conda (towards mamba) but this didn't cross my mind when I was playing in my sandbox. Might be some cluster latency issues combined with conda's snail's pace causing the problem on our end. Thx for the quick replies!. Adam H. Freedman, PhD; Data Scientist; Faculty of Arts & Sciences Informatics Group; Harvard University; 38 Oxford St; Cambridge, MA 02138; phone: +001 310 415 7145; ________________________________; From: Rob Patro ***@***.***>; Sent: Sunday, October 29, 2023 11:01 AM; To: COMBINE-lab/salmon ***@***.***>; Cc: Freedman, Adam ***@***.***>; Mention ***@***.***>; Subject: Re: [COMBINE-lab/salmon] anaconda version of salmon outdated, missing decoys option (Issue #895). Hi @adamfreedman<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_adamfreedman&d=DwMCaQ&c=WO-RGvefibhHBZq3fL85hQ&r=MITI_LEJgyr1a24IMFAlSaZIPxMpOUT21T7L3fg4CjA&m=40O3raH84f_BIZ3HF7nqTYSO2FehGrGHL9b7sqT7LIpWZjFmA3BLxNDTHoz420jp&s=kxY9gCLGWZJp-dp7l31S6M5u2RuUTeWXVrKmaydpo5o&e=>,. I think this is just conda being very very very slow (and potentially broken). The following works fine for me (and finishes in ~1 minute):. mamba create -n salmon -c conda-forge -c bioconda salmon=1.10.2. Can you use the mamba resolver in your environment? Conda has become hardly usable over the years, but mamba works quite well as a fast replacement. I'll also note that I swapped the order of conda-forge and bioconda as the docs specify that bioconda should preferably come last in the list of channels. --Rob. —; Reply to this email directly, view it on GitHub<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_COMBINE-2Dlab_salmon_issues_895-23issuecomment-2D1784137337&d=DwMCaQ&c=WO-RGvefibhHBZq3fL85hQ&r=MITI_LEJgyr1a24IMFAlSaZIPxMpOUT21T7L3fg4CjA&m=40O3raH84f_BIZ3HF7nqTYSO2FehGrGHL9b7sqT7LIpWZjFmA3BLxNDTHoz420jp&s=GNiCXqUbJLM16QBJ5PNAqv-rsgDdpCpcvezPXO_riWk&e=>, or unsubscribe<",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/895#issuecomment-1784196835:192,sandbox,sandbox,192,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/895#issuecomment-1784196835,1,['sandbox'],['sandbox']
Modifiability,"I think your first suggestion would be the best option - although not sure you want worm transcripts in your decoy file. An alternative is to just quantify the entire collection of sequences. This is what [our pipeline](https://github.com/Novartis/pisces) does. This mostly just consists of running salmon plus some functionality for building custom index files and splitting output for multi-species analysis. You can specify your GTF/FASTA pairs using a [config file](https://github.com/Novartis/pisces/blob/9936079ac75d4b75be95bad5bc962465e8c5f458/pisces/config.json#L46-L49) and the pipeline builds index files, helps run salmon and some basic QC, and outputs separate expression matrices for each individual organism - normalized back to TPM space. The approach seems to work well and is flexible enough for users to specify custom transcriptomes for chimeric/mixed samples or extensive genetic engineering.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/901#issuecomment-1828116329:457,config,config,457,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/901#issuecomment-1828116329,3,"['config', 'flexible']","['config', 'flexible']"
Modifiability,"I tried running Alevin again from the new branch and it still seems to be spawning a large number of unexpected threads. Thanks again for all of the help I really appreciate it and I hope you both have a great weekend. ```; GNU gdb (Debian 7.7.1+dfsg-5) 7.7.1; Copyright (C) 2014 Free Software Foundation, Inc.; License GPLv3+: GNU GPL version 3 or later <http://gnu.org/licenses/gpl.html>; This is free software: you are free to change and redistribute it.; There is NO WARRANTY, to the extent permitted by law. Type ""show copying""; and ""show warranty"" for details.; This GDB was configured as ""x86_64-linux-gnu"".; Type ""show configuration"" for configuration details.; For bug reporting instructions, please see:; <http://www.gnu.org/software/gdb/bugs/>.; Find the GDB manual and other documentation resources online at:; <http://www.gnu.org/software/gdb/documentation/>.; For help, type ""help"".; Type ""apropos word"" to search for commands related to ""word""...; Reading symbols from /u/user/local/bin/salmon...done.; (gdb) run alevin -l ISR --chromium -p 4 -o BM_1/alevin -1 ./BM_1/run1/bm_S10_L001_R1_001.fastq.gz -2 ./BM_1/run1/bm_S10_L001_R2_001.fastq.gz --maxHashResizeThreads 2 -i /u/user/ref/cellranger/salmon/transcripts_index --tgMap tx2gene.txt; Starting program: /u/user/local/bin/salmon alevin -l ISR --chromium -p 4 -o BM_1/alevin -1 ./BM_1/run1/bm_S10_L001_R1_001.fastq.gz -2 ./BM_1/run1/bm_S10_L001_R2_001.fastq.gz --maxHashResizeThreads 2 -i /u/user/ref/cellranger/salmon/transcripts_index --tgMap tx2gene.txt; [Thread debugging using libthread_db enabled]; Using host libthread_db library ""/lib/x86_64-linux-gnu/libthread_db.so.1"".; warning: File ""/u/user/local/lib64/libstdc++.so.6.0.21-gdb.py"" auto-loading has been declined by your `auto-load safe; -path' set to ""$debugdir:$datadir/auto-load"".; To enable execution of this file add; add-auto-load-safe-path /u/user/local/lib64/libstdc++.so.6.0.21-gdb.py; line to your configuration file ""/u/user/.gdbinit"".; To completely disable ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-396078627:581,config,configured,581,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-396078627,3,['config'],"['configuration', 'configured']"
Modifiability,"I used autotools back in 2008 or so (when I was still working in computer graphics). I found it to be horribly archaic (not that CMake is a bastion of clarity). Also, as opaque as CMake sometimes is, I at least found it easier to discover how to force it to do what I wanted than with autotools. That being said, I feel like it is one of these situations where, if you are a wizard with the tool, everything seems relatively easy and straightforward (e.g. Guillaume uses autotools for Jellyfish, and he seems to have internalized all of the quirks fairly well). I guess I long for a configuration and build DSL that has an actual nice language, rather than the somewhat crazy invocations required by autotools and CMake. Then again, the annals of history are strewn with the wreckage of deprecated and defunct attempts to make better build systems.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/19#issuecomment-195457891:583,config,configuration,583,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/19#issuecomment-195457891,1,['config'],['configuration']
Modifiability,"I wonder if the max 1-edit distance restriction is too stringent for 21 length barcodes. One important flag to play with is the `--minScoreFraction`. The basic rule to set that is define [here](https://github.com/COMBINE-lab/salmon/blob/91091fc3650a3220f657a9f31616916513f0ad02/src/SalmonUtils.cpp#L3242-L3253). The gist being say if we wan't max k-edit we allow all the reads above the following threshold score (as in the log ):. ```; [2020-06-04 17:55:11.700] [alevinLog] [info] set CITE-seq minScoreFraction parameter to : 0.797619; ```; i.e. we use the equation `(max_score + edit_cost) - 0.5) / max_score`; where `max_score` = 2 * length of barcode = 2 * 21 = 42,; and `edit_cost`= `min( k * (mismatch - match), k * (go + ge - match)`;; `mismatch` penalty = -4; `match` = 2; `go` gap open penalty = -4; `ge` gap extend penalty = -2. For k=1, we had `edit_cost = 8` leading to automatic setting of `minScoreFraction` of 0.797619.; we have looked at 15 length barcodes, but it's possible longer barcodes might have more sequencing error. Let's try allowing more edits i.e. k=2, by setting `--minScoreFraction 0.607` and see if it improves the mapping rate.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-639235133:818,extend,extend,818,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-639235133,1,['extend'],['extend']
Modifiability,I'll check that Homebrew installs the Jellyfish config.h file.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/19#issuecomment-195604141:48,config,config,48,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/19#issuecomment-195604141,1,['config'],['config']
Modifiability,"I'm having a similar problem, also using an M1 mac. I've tried your solution @rob-p, as well as updating conda, creating a new environment specifically for salmon, it still doesn't work. I get the following error:. ```; $ conda install -c bioconda salmon 3s Py salmon; Collecting package metadata (current_repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Collecting package metadata (repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve. PackagesNotFoundError: The following packages are not available from current channels:. - salmon. Current channels:. - https://conda.anaconda.org/bioconda/osx-arm64; - https://conda.anaconda.org/bioconda/noarch; - https://conda.anaconda.org/conda-forge/osx-arm64; - https://conda.anaconda.org/conda-forge/noarch; - https://repo.anaconda.com/pkgs/main/osx-arm64; - https://repo.anaconda.com/pkgs/main/noarch; - https://repo.anaconda.com/pkgs/r/osx-arm64; - https://repo.anaconda.com/pkgs/r/noarch. To search for alternate channels that may provide the conda package you're; looking for, navigate to. https://anaconda.org. and use the search bar at the top of the page.; ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/724#issuecomment-1137109855:397,flexible,flexible,397,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/724#issuecomment-1137109855,2,['flexible'],['flexible']
Modifiability,"ISR --chromium -p 4 -o BM_1/alevin -1 ./BM_1/run1/bm_S10_L001_R1_001.fastq.gz -2 ./BM_1/run1/bm_S10_L001_R2_001.fastq.gz --maxHashResizeThreads 2 -i /u/user/ref/cellranger/salmon/transcripts_index --tgMap tx2gene.txt; Starting program: /u/user/local/bin/salmon alevin -l ISR --chromium -p 4 -o BM_1/alevin -1 ./BM_1/run1/bm_S10_L001_R1_001.fastq.gz -2 ./BM_1/run1/bm_S10_L001_R2_001.fastq.gz --maxHashResizeThreads 2 -i /u/user/ref/cellranger/salmon/transcripts_index --tgMap tx2gene.txt; [Thread debugging using libthread_db enabled]; Using host libthread_db library ""/lib/x86_64-linux-gnu/libthread_db.so.1"".; warning: File ""/u/user/local/lib64/libstdc++.so.6.0.21-gdb.py"" auto-loading has been declined by your `auto-load safe; -path' set to ""$debugdir:$datadir/auto-load"".; To enable execution of this file add; add-auto-load-safe-path /u/user/local/lib64/libstdc++.so.6.0.21-gdb.py; line to your configuration file ""/u/user/.gdbinit"".; To completely disable this security protection add; set auto-load safe-path /; line to your configuration file ""/u/user/.gdbinit"".; For more information about this security protection see the; ""Auto-loading safe path"" section in the GDB manual. E.g., run from the shell:; info ""(gdb)Auto-loading safe path""; [New Thread 0x7fff7dbff700 (LWP 21437)]; [Thread 0x7fff7dbff700 (LWP 21437) exited]; Version Info: Could not resolve upgrade information in the alotted time.; Check for upgrades manually at https://combine-lab.github.io/salmon; [New Thread 0x7ffefcfff700 (LWP 21653)]; Logs will be written to BM_1/alevin/logs; [New Thread 0x7ffe7cffe700 (LWP 21654)]; [New Thread 0x7ffdfcffd700 (LWP 21655)]; [New Thread 0x7ffd7cffc700 (LWP 21656)]; ### salmon (single-cell-based) v0.10.3; ### [ program ] => salmon; ### [ command ] => alevin; ### [ libType ] => { ISR }; ### [ chromium ] => { }; ### [ threads ] => { 4 }; ### [ output ] => { BM_1/alevin }; ### [ mates1 ] => { ./BM_1/run1/bm_S10_L001_R1_001.fastq.gz }; ### [ mates2 ] => { ./BM_1/run1/bm_S10_L001_R2_",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-396078627:2071,config,configuration,2071,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-396078627,1,['config'],['configuration']
Modifiability,Interesting. One thing that changed is that we finally upgraded the Docker image used in our continuous integration server from CentOS5 to CentOS6; I wonder if that might cause some portability issues. Could you try installing via Bioconda to see if that executable gives you the same trouble?,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/232#issuecomment-394752905:182,portab,portability,182,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/232#issuecomment-394752905,1,['portab'],['portability']
Modifiability,"It depends what type of ""replicates"" these are. If these are biological replicates, then they should _definitely_ be run separately. Biological replicates contain crucial information about the variability of expression that can be expected in a given condition, and all downstream differential expression tools will use this information. If these are ""technical"" replicates, then there should be little harm in quantifying them together (of course, then one has a 2 condition experiment with only 1 biological replicate per-condition ... which is a big problem if one wishes to analyze e.g. differential expression).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/190#issuecomment-400080695:193,variab,variability,193,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/190#issuecomment-400080695,1,['variab'],['variability']
Modifiability,"It looks like #734 would allow this barcode method to be specified directly:. Long original read geometry - `1{b[9]f[ACTGGCCTGCGA]b[9]f[GGTAGCGGTGACA]b[9]u[8]}2{r}`; Short ""enhanced"" read geometry - `1{x[0-3]b[9]f[GTGA]b[9]f[GACA]b[9]u[8]}2{r}`",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/628#issuecomment-1298023583:173,enhance,enhanced,173,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/628#issuecomment-1298023583,1,['enhance'],['enhanced']
Modifiability,"It would be good to get your modifications accepted into BWA & Jellyfish. Re: `libgff` I did indeed package it as a separate library for Debian: https://packages.debian.org/source/sid/libgff. staden-io ships `io_lib-config` which reports on how to compile against the library. ```; mcrusoe@mrcdev:~$ io_lib-config ; Usage: io_lib-config [option]. where 'option' is any one of:. --cflags C and preprocessor flags (eg -I/foo/include); --libs Link-line parameters, eg -L/foo/lib -lstaden-read; --version List io_lib version number. mcrusoe@mrcdev:~$ io_lib-config --cflags; -I/usr/include; mcrusoe@mrcdev:~$ io_lib-config --libs; -L/usr/lib/x86_64-linux-gnu -lstaden-read -Wl,-z,relro -lm -lpthread -lcurl -lz; mcrusoe@mrcdev:~$ io_lib-config --version; 1.14.7; ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/19#issuecomment-195346502:216,config,config,216,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/19#issuecomment-195346502,6,['config'],['config']
Modifiability,"It's ignoring the environment variable `$CPPFLAGS` which has the search path for `zlib.h`. ```; $ env |grep CPPFLAGS; CPPFLAGS=-isystem/home/linuxbrew/.linuxbrew/include; ```. This workaround works, but doesn't work on a system without root access. ``` sh; sudo apt-get install libz-dev; ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/45#issuecomment-193960137:30,variab,variable,30,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/45#issuecomment-193960137,1,['variab'],['variable']
Modifiability,It's quite unfortunate that TBB doesn't have an environment variable that can be used to limit the number of threads like openMP does.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-396092938:60,variab,variable,60,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-396092938,1,['variab'],['variable']
Modifiability,"Just an idea. Would it be possible to assign an environment variable, such as SALMON_NO_VERSION_CHECK, whose existence overrides version checking? This wouldn't break compatibility with older scripts because they wouldn't have the variable in the first place. In non-networked nodes, an admin can simply set this variable and users will run salmon as usual.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/486#issuecomment-617326919:60,variab,variable,60,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/486#issuecomment-617326919,3,['variab'],['variable']
Modifiability,Just an update in case anyone else is encountering this issue. I was able to install salmon using these instructions: CONDA_SUBDIR=osx-64 conda create -n rosetta; conda activate rosetta; conda env config vars set CONDA_SUBDIR=osx-64; conda install salmon,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/912#issuecomment-1954908448:197,config,config,197,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/912#issuecomment-1954908448,1,['config'],['config']
Modifiability,"LUDE DIRS = $blah/salmon-0.10.2/external/install/include; BOOST LIB DIR = $blah/salmon-0.10.2/external/install/lib; BOOST LIBRARIES =; Build system will build libdivsufsort; ==================================================================; Build system will fetch and build the Cereal serialization library; ==================================================================; Build system will fetch and build BWA (for Salmon); ==================================================================; -- Found TBB: /apps/gentoo/usr/include (found suitable version ""2018.0"", minimum required is ""2018.0"") found components: tbb tbbmalloc tbbmalloc_proxy; TBB_LIBRARIES = /apps/gentoo/usr/lib/libtbbmalloc_proxy.so;/apps/gentoo/usr/lib/libtbbmalloc.so;/apps/gentoo/usr/lib/libtbb.so; Build system will compile libgff; ==================================================================; ==================================================================; Build system will compile Staden IOLib; ==================================================================; Build system will fetch SPDLOG; ==================================================================; -- Found PkgConfig: /apps/gentoo/usr/bin/pkg-config (found version ""0.29.2""); -- Found Jemalloc: /apps/gentoo/usr/lib/libjemalloc.so (found version """"); Found Jemalloc library --- using this memory allocator; CPACK_SOURCE_IGNORE_FILES = /src/PCA.cpp;/src/PCAUtils.cpp;/build/;/scripts/AggregateToGeneLevel.py;/scripts/ExpressionTools.py;/scripts/GenerateExpressionFiles.sh;/scripts/ParseSoftFile.py;/scripts/PlotCorrelation.py;/scripts/junk;/scripts/sfstrace.log;/scripts/SFPipeline.py;/bin/;/lib/;/sample_data/;PublishREADMEToWebsite.sh;/external/;/src/obsolete/;/include/obsolete/;WebsiteHeader.txt;/experimental_configs/;.git/; TBB_LIBRARIES = /apps/gentoo/usr/lib/libtbbmalloc_proxy.so;/apps/gentoo/usr/lib/libtbbmalloc.so;/apps/gentoo/usr/lib/libtbb.so; -- Configuring done; CMake Error at src/CMakeLists.txt:158 (add_executable):; Cannot ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/19#issuecomment-399775387:4192,config,config,4192,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/19#issuecomment-399775387,1,['config'],['config']
Modifiability,"Looking back to the [earlier post](https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-640962684), I wonder if this stems from CMake not being able to properly find Boost on its own. Granted, the CMake / Boost infrastructure has never been great, partly due to the complexity of salmon's CMake configuration, and partly due to the strange way that CMake, itself, handles Boost versions.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641546215:304,config,configuration,304,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641546215,1,['config'],['configuration']
Modifiability,Looks like it's not in 1.54 - http://www.boost.org/doc/libs/1_54_0/libs/config/doc/html/boost_config/boost_macro_reference.html,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/24#issuecomment-152767712:72,config,config,72,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/24#issuecomment-152767712,1,['config'],['config']
Modifiability,No worries - and that is exactly what I thought could be possible :-). Just out of curiosity - how would Salmon currently handle if half of a read could be quasi-mapped to a transcript but the second half did not fit anywhere (due to it being very low quality or sequencing adapter contamination)?,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/150#issuecomment-353287536:274,adapt,adapter,274,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/150#issuecomment-353287536,1,['adapt'],['adapter']
Modifiability,"No, I believe that config.h was it. Otherwise, I just use the already installed headers and the pre-compiled library `libjellyfish-2.0`.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/19#issuecomment-195466899:19,config,config,19,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/19#issuecomment-195466899,1,['config'],['config']
Modifiability,"Nominally, you can use `info locals` and `p x` (where x is a specific variable name) to look at the value of variables in the stack. However, without debug flags, the ability to peek at such values is questionable. Alternatively we could log the values that gamma is being called with before each call . . . but that's going to lead to some crazy logs until the hang occurs.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267842038:70,variab,variable,70,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267842038,2,['variab'],"['variable', 'variables']"
Modifiability,"Nope; nothing special. Once you've installed conda, you simply do:. ```; $ conda config --add channels conda-forge; $ conda config --add channels bioconda; $ conda create -n salmon salmon=0.10.1; ```. then it will give you instructions on how to activate the environment to run salmon.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/232#issuecomment-394755128:81,config,config,81,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/232#issuecomment-394755128,2,['config'],['config']
Modifiability,"OK --- I think I fixed it; can you re-download the v0.6.0 binary and see if the segfault goes away for you? I think it was the result of failing to give a particular class a default constructor --- a certain variable was being initialized properly on my newer compiler, but that was not the case on the older compiler on the VM where I build the binary. ~~If this resolves the issue for you, I'll probably bump to v0.6.1 just in case anyone tries to build from the source tarball on an older compiler.~~ (I already moved the v0.6.0 tag to point to the new commit and updated the binaries. Hopefully nobody fell through the cracks with the old source tarball, but this doesn't seem like something worth bumping a release for --- assuming my minor change fixes the issue for you as well).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/34#issuecomment-168364366:208,variab,variable,208,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/34#issuecomment-168364366,1,['variab'],['variable']
Modifiability,"Oh wow; I had no idea about libgff :). Regarding Jellyfish, there's not a source ""change"" required upstream, rather the fact that I seem to require the `config.h` file that is not installed during the ""normal"" Jellyfish install process. I don't know if you have any idea how one might get around that. Regarding staden, thanks for brining this to my attention. It will probably take a bit for me to wrap my head around the right way to access this information in CMake, but I'll see what I can manage to cobble together on that front (I really wish there was something better, with a less horrendous ""language"" than CMake, but nothing I know of exists that works nearly as well ""out of the box"").",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/19#issuecomment-195436157:153,config,config,153,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/19#issuecomment-195436157,1,['config'],['config']
Modifiability,"Oh, I should've pushed my PR sooner!; Thanks!; I'll take a look how it compares to what I did. ; One thing to note is that it'd be useful to be able to specify the length of the CB - we use 8 bp in our slightly-adapted CEL-Seq2 protocol.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/269#issuecomment-418579796:211,adapt,adapted,211,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/269#issuecomment-418579796,1,['adapt'],['adapted']
Modifiability,"Ok, salmon V1.0.0 finished in 5H 15 min, so about 5 times faster, the exact same library and parameters, and achieved almost the same mapping rate (85.1058% with V1.2.0 vs 84.6341% with V1.0.0) attaching log. I must add I did not trim this library for adapters nor quality, nor did anything to it. Just mapped as is. But fastQC showed excellent levels of quality even at the ends and no or minimal adapter content. ; Also no changes have been done one my OS other than regular updates, but still Ubuntu 18.04. I don't remember any specific changes I've done to it. ; Pearson's correlation in transcript abundance (isoform lelvel) is 0.9984013. Spearman's is 0.9899048. ; Also, I did checked that salmon was actually using 4 threads in both cases, and it was fully using those.; [salmon_quant.log](https://github.com/COMBINE-lab/salmon/files/4707443/salmon_quant.log)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/527#issuecomment-636447127:252,adapt,adapters,252,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/527#issuecomment-636447127,2,['adapt'],"['adapter', 'adapters']"
Modifiability,"Ok, when I attempt the build the way you say above, I get the following error during CMake:. ```; -- fetch PUFFERFISH exit code 127; CMake Error at CMakeLists.txt:317 (message):; Could not fetch pufferfish source [fetchPufferfish.sh returned exit code; 127]. -- Configuring incomplete, errors occurred!; See also ""/salmon-1.10.0/build/CMakeFiles/CMakeOutput.log"".; ```. It seems `wget`, `curl` and `unzip` were missing, and I had to install them. After that, I was able to build and install. At that point, I was able to reproduce the issue! So, it seems to me the underlying problem is coming from one of the upstream dependencies (i.e. libraries being linked to). I will try see if I can find the offender. In general, we like to statically link salmon for exactly this reason. Outside of package systems with which I am familiar (e.g. conda), we don't have a lot of experience in specifying dependent package version constrains, which I believe to be at fault here.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463973824:262,Config,Configuring,262,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463973824,1,['Config'],['Configuring']
Modifiability,"Rob,. 	I let you know on the forum page, but just ot make sure it worked and I was ; able to index my transcriptome. Thank you!. Best wishes,; Rich; > On Apr 17, 2018, at 9:44 AM, Rob Patro <notifications@github.com> wrote:; > ; > Hi Rich,; > ; > The issue with pre-compiled OSX binaries is that they are difficult to make portable across OSX versions. This is why we strongly suggest installing Salmon (especially for OSX) through Bioconda. This greatly eases installation and updating, and doesn't require admin privileges. On OSX, you can try the following:; > ; > $ conda config --add channels conda-forge; > $ conda config --add channels bioconda; > $ conda create -n salmon salmon=0.9.1; > ; > This should take care of all relevant dependencies as well as e.g. library locations and placement. Could you please give this a try and let me know if it works for you?; > ; > Best,; > Rob; > ; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub, or mute the thread.; > . Richard A. Friedman, PhD; Associate Research Scientist,; Biomedical Informatics Shared Resource; Herbert Irving Comprehensive Cancer Center (HICCC); Lecturer,; Department of Biomedical Informatics (DBMI); Room 825; Irving Cancer Research Center ; Columbia University Herbert and Florence Irving Medical Center; 1130 St. Nicholas Ave; New York, NY 10032; (212)851-4765 (voice); raf4@cumc.columbia.edu. http://www.columbia.edu/~raf4/index.html. “Will there still be ""Classics Illustrated” by the time I have children? I cannot; imagine raising kids without ""Classics Illustrated” .” -Rose Friedman, age 20",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/215#issuecomment-382031768:323,portab,portable,323,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/215#issuecomment-382031768,3,"['config', 'portab']","['config', 'portable']"
Modifiability,"Rob,. Brilliant - I forgot that I built the boost libraries from whatever version of gcc was on the standard distribution. I have included -DFETCH_BOOST=TRUE, do you know why I am receiving the following error regarding a missing when executing make?. [ 5%] Performing configure step for 'libboost'; Building Boost.Build engine with toolset gcc... tools/build/src/engine/bin.linuxx86_64/b2; Detecting Python version... 2.7; Detecting Python root... /usr; Unicode/ICU support for Boost.Regex?... not found.; Generating Boost.Build configuration in project-config.jam... Bootstrapping is done. To build, run:. ./b2. To adjust configuration, edit 'project-config.jam'.; Further information:. - Command line help:; ./b2 --help. - Getting started guide:; http://www.boost.org/more/getting_started/unix-variants.html. - Boost.Build documentation:; http://www.boost.org/build/doc/html/index.html. using gcc : : /opt/gcc-8.2.0/bin/g++ ); [ 6%] Performing build step for 'libboost'; opt.jam: No such file or directory; /opt/salmon/external/boost_1_66_0/tools/build/src/build/toolset.jam:43: in toolset.using; ERROR: rule ""opt.init"" unknown in module ""toolset"".; /opt/salmon/external/boost_1_66_0/tools/build/src/build-system.jam:461: in process-explicit-toolset-requests; /opt/salmon/external/boost_1_66_0/tools/build/src/build-system.jam:527: in load; /opt/salmon/external/boost_1_66_0/tools/build/src/kernel/modules.jam:295: in import; /opt/salmon/external/boost_1_66_0/tools/build/src/kernel/bootstrap.jam:139: in boost-build; /opt/salmon/external/boost_1_66_0/boost-build.jam:17: in module scope; make[2]: *** [libboost-prefix/src/libboost-stamp/libboost-build] Error 1; make[1]: *** [CMakeFiles/libboost.dir/all] Error 2; make: *** [all] Error 2. Thanks for all your help!. Nate",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/309#issuecomment-436834099:269,config,configure,269,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/309#issuecomment-436834099,5,['config'],"['config', 'configuration', 'configure']"
Modifiability,"So, on a fresh docker image of ubuntu 16.04.4, I was not able to reproduce this yet. Here is my current output:. ```; [100%] Linking CXX executable salmon; ../../external/install/lib/libstaden-read.a(libstaden_read_la-open_trace_file.o): In function `find_file_url':; open_trace_file.c:(.text+0xec4): warning: the use of `tempnam' is dangerous, better use `mkstemp'; [100%] Built target salmon; root@e08cc9670e4a:/salmon-0.10.2/build# make install; [ 6%] Built target libdivsufsort; [ 12%] Built target libbz2; [ 17%] Built target liblzma; [ 24%] Built target libcereal; [ 31%] Built target libgff; [ 36%] Built target libbwa; [ 42%] Built target libstadenio; [ 48%] Built target libspdlog; [ 50%] Built target ksw2pp_sse4; [ 52%] Built target alevin_core; [ 55%] Built target ksw2pp_sse2; [ 60%] Built target ksw2pp_basic; [ 60%] Built target ksw2pp; [ 73%] Built target salmon_core; [ 77%] Built target unitTests; [100%] Built target salmon; Install the project...; -- Install configuration: ""Release""; -- Installing: /salmon-0.10.2/lib; -- Installing: /salmon-0.10.2/lib/libtbb.so; -- Installing: /salmon-0.10.2/lib/libtbbmalloc.so; -- Installing: /salmon-0.10.2/lib/libtbbmalloc_proxy.so; -- Installing: /salmon-0.10.2/lib/libtbbmalloc.so.2; -- Installing: /salmon-0.10.2/lib/libtbb.so.2; -- Installing: /salmon-0.10.2/lib/pkgconfig; -- Installing: /salmon-0.10.2/lib/libtbbmalloc_proxy.so.2; -- Installing: /salmon-0.10.2/bin/salmon; -- Installing: /salmon-0.10.2/lib/libsalmon_core.a. Installation complete. Please ensure the following paths are set properly.; ==========================================================================; Please add /salmon-0.10.2/bin to your PATH; Please add /salmon-0.10.2/lib to your LD_LIBRARY_PATH; ==========================================================================; root@e08cc9670e4a:/salmon-0.10.2/build# make test; Running tests...; Test project /salmon-0.10.2/build; Start 1: unit_tests; 1/3 Test #1: unit_tests ....................... Passed 0.1",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/250#issuecomment-404306268:979,config,configuration,979,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/250#issuecomment-404306268,1,['config'],['configuration']
Modifiability,"Some progress. Found a src rpm for cereal, rebuilt that into an RPM and installed. Then this (ROOT_* env variables come from the respective module load commands):. ```; cmake \; -DCMAKE_INSTALL_PREFIX=$TOPDIR \; -DSTADEN_ROOT=$ROOT_IO_LIB \; -DGFF_ROOT=$ROOT_LIBGFF \; -DTBB_ROOT=$ROOT_LIBTBB \; -DCMAKE_VERBOSE_MAKEFILE:BOOL=ON \; -DBOOST_LIBRARYDIR=/usr/lib64/boost169 \; -DBOOST_INCLUDEDIR=/usr/include/boost169 \; -DBoost_NO_SYSTEM_PATHS=ON \; .. 2>&1 | tee cmake_2020_06_09.log; ```; found everything. The ""make"" went along pretty well until here:; ```; [100%] Linking CXX executable salmon; cd /usr/common/src/salmon-1.2.1/build/src && /usr/common/src/cmake-3.17.1/bin/cmake -E cmake_link_script CMakeFiles/salmon.dir/link.txt --verbose=1; /usr/lib64/ccache/c++ -O3 -DNDEBUG -flto -fno-fat-lto-objects CMakeFiles/salmon.dir/EMUtils.cpp.o CMakeFiles/salmon.dir/CollapsedEMOptimizer.cpp.o CMakeFiles/salmon.dir/CollapsedCellOptimizer.cpp.o CMakeFiles/salmon.dir/CollapsedGibbsSampler.cpp.o CMakeFiles/salmon.dir/Salmon.cpp.o CMakeFiles/salmon.dir/BuildSalmonIndex.cpp.o CMakeFiles/salmon.dir/Graph.cpp.o CMakeFiles/salmon.dir/DedupUMI.cpp.o CMakeFiles/salmon.dir/Alevin.cpp.o CMakeFiles/salmon.dir/AlevinHash.cpp.o CMakeFiles/salmon.dir/SalmonAlevin.cpp.o CMakeFiles/salmon.dir/WhiteList.cpp.o CMakeFiles/salmon.dir/SalmonQuantify.cpp.o CMakeFiles/salmon.dir/FragmentLengthDistribution.cpp.o CMakeFiles/salmon.dir/FragmentStartPositionDistribution.cpp.o CMakeFiles/salmon.dir/GZipWriter.cpp.o CMakeFiles/salmon.dir/SalmonQuantMerge.cpp.o CMakeFiles/salmon.dir/ProgramOptionsGenerator.cpp.o CMakeFiles/salmon.dir/FASTAParser.cpp.o CMakeFiles/salmon.dir/AlignmentModel.cpp.o CMakeFiles/salmon.dir/SalmonQuantifyAlignments.cpp.o CMakeFiles/salmon.dir/BAMUtils.cpp.o -o salmon -L/usr/common/src/salmon-1.2.1/lib -L/usr/common/src/salmon-1.2.1/external/install/lib -Wl,-rpath,""\$ORIGIN/../lib:\$ORIGIN/../../lib:\$ORIGIN/:\$ORIGIN/../../external/install/lib"" ../external/pufferfish/src/libpuffer.a libs",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641531162:105,variab,variables,105,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641531162,1,['variab'],['variables']
Modifiability,"Success???. ```; $ gdb -ex ""attach $(pgrep salmon | head -1)"" -ex bt -ex detach -ex quit; GNU gdb (Ubuntu 7.11.1-0ubuntu1~16.04) 7.11.1; Copyright (C) 2016 Free Software Foundation, Inc.; License GPLv3+: GNU GPL version 3 or later <http://gnu.org/licenses/gpl.html>; This is free software: you are free to change and redistribute it.; There is NO WARRANTY, to the extent permitted by law. Type ""show copying""; and ""show warranty"" for details.; This GDB was configured as ""x86_64-linux-gnu"".; Type ""show configuration"" for configuration details.; For bug reporting instructions, please see:; <http://www.gnu.org/software/gdb/bugs/>.; Find the GDB manual and other documentation resources online at:; <http://www.gnu.org/software/gdb/documentation/>.; For help, type ""help"".; Type ""apropos word"" to search for commands related to ""word"".; Attaching to process 29332; [New LWP 29334]; [New LWP 29335]; [New LWP 29336]; [New LWP 21224]; [New LWP 21225]; [New LWP 21226]; [New LWP 21227]; [New LWP 21228]; [New LWP 21229]; [New LWP 21230]; [Thread debugging using libthread_db enabled]; Using host libthread_db library ""/lib/x86_64-linux-gnu/libthread_db.so.1"".; 0x00007fcb8cf73789 in __ieee754_log_avx (x=<optimized out>) at ../sysdeps/ieee754/dbl-64/e_log.c:193; 193	../sysdeps/ieee754/dbl-64/e_log.c: No such file or directory.; #0 0x00007fcb8cf73789 in __ieee754_log_avx (x=<optimized out>) at ../sysdeps/ieee754/dbl-64/e_log.c:193; #1 0x0000000000637ccc in double std::gamma_distribution<double>::operator()<pcg_detail::engine<unsigned int, unsigned long, pcg_detail::xsh_rr_mixin<unsigned int, unsigned long>, true, pcg_detail::unique_stream<unsigned long>, pcg_detail::default_multiplier<unsigned long> > >(pcg_detail::engine<unsigned int, unsigned long, pcg_detail::xsh_rr_mixin<unsigned int, unsigned long>, true, pcg_detail::unique_stream<unsigned long>, pcg_detail::default_multiplier<unsigned long> >&, std::gamma_distribution<double>::param_type const&) (); #2 0x0000000000634b8d in tbb::inter",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267488748:457,config,configured,457,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267488748,3,['config'],"['configuration', 'configured']"
Modifiability,"Thank you @rob-p for commenting, I presumed that could be the case for reads from unspliced pre-mRNAs that are even extending a small fraction into the introns (hence better scoring on the decoys). The 2 FASTQ files for one of the samples I was describing above can be found as R4171*.fastq.gz at this globus link: http://research.libd.org/globus/jhpce_bsp2-dlpfc/index.html. I used just the main chromosomes with Gencode v41 annotation (slightly ""curated"" to remove read-through and ""retained intron"" annotated transcripts). I am attaching 3 `meta_info.json` outputs for the 3 ways I ran salmon on this sample:. - [tx_only.meta_info.json.gz](https://github.com/COMBINE-lab/salmon/files/11006627/tx_only.meta_info.json.gz) : no decoys, **without** `--validateMappings`; - [gentrome_full.meta_info.json.gz](https://github.com/COMBINE-lab/salmon/files/11006628/gentrome_full.meta_info.json.gz) : with `--validateMappings`, decoys are full chromosome sequences appended to the transcripts file, ; - [gentrome_mashed.meta_info.json.gz](https://github.com/COMBINE-lab/salmon/files/11006629/gentrome_mashed.meta_info.json.gz) : with `--validateMappings`, decoys prepared with mashmap as instructed [here](https://github.com/COMBINE-lab/SalmonTools/blob/master/README.md). It would be great to be able to use Salmon's ""wicked fast"" mapping engine to estimate intronic and intergenic reads at the same time, so I'm considering to make better use of the `writeMappings` output for that purpose, by preparing the decoys in a specific way (extracting intronic and intergenic sequences as distinctively labeled decoys and count the mappings to each label from Salmon's SAM output -- would that work?). I am wondering, due to pre-mRNAs found in rRNA-depletion (ribo-zero) samples, it might be better to artifically add the unspliced transcripts into the mix along with the ""reference"" annotation transcripts, so they also get quantified during the EM-guided probabilistic distribution of reads across this mix of p",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/779#issuecomment-1474451463:116,extend,extending,116,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/779#issuecomment-1474451463,1,['extend'],['extending']
Modifiability,"Thanks @k3yavi !If you can forward me a Linux portable binary that would be great. Whenever I try to compile something on my computer, I fail half of the time . I have Ubuntu 18.04. I will ask permission to share with you part of the data and get back to you. Also, does Alevin use 10x cell barcode whitelist internally to correct barcodes? And do you recommend using the `--naiveEqclass`; option when there are only 64 guide sequences as features?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-638487530:46,portab,portable,46,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-638487530,1,['portab'],['portable']
Modifiability,"Thanks @mikelove . I believe tximeta can be used only for human/mouse? In my case, it is not human/mouse. @rob-p and @mikelove - Based on my reading of the salmon documentation, isn't it that the NumReads/TPM etc made available after lengthCorrection. Extending this, the NumReads in quant.sf corresponds to the estimated count value for each transcript and correlated by effective length. My idea is to therefore use the countsFromAbundance=“lengthScaledTPM” to compute counts that are on the same scale as original counts and not correlated with transcript length across samples. Given this - Is this below also valid (after salmon quant). ```; salmon_tx2gene_data = tximport(files, type=""salmon"", tx2gene=tx2gene,; countsFromAbundance = ""lengthScaledTPM""). # generate CSV for archival/use-for-other-purposes ; # then read in the csv and use with DESeq. write.csv(as.data.frame(salmon_tx2gene_data$counts),; file = ""lengthScaledTPM_tx2gene_counts.csv""). # other code for reading in csv, design_metadata etc. dds <- DESeqDataSetFromMatrix (countData = salmon_tx2gene_data$counts,; colData = coldata, ~ condition). ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/581#issuecomment-719784814:252,Extend,Extending,252,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/581#issuecomment-719784814,1,['Extend'],['Extending']
Modifiability,"Thanks @rob-p,. Your explanations are helpful, and I think it may my concern may just be more associated with your general thought as I've tested this with multiple parameters. The one I represented here was just an example, but I also can see how the parameters can be affecting these results. It was just strange to see such a huge shift with the addition/removal of one gene, which makes me think it more associated with how the inference of the variables are conditioned. . As for providing the meta_info.json files, I currently have thousands of them as I am running triplicates of ~150 parameter combinations for multiple tissue types and stages. In the end I don't think it will be necessary as we will likely be changing our approach a bit, which should be fine with the system I have in place. . Also, as for `--scoreExp` our main goal is to try and use Salmon to get quantification of individual genes (primary versus spliced forms). From my analysis, it appears that some genes perform better with scores > 0, however, some genes do perform better with a `--scoreExp` of 0. Although, this could be a factor in running Salmon with such a narrow view (i.e. two transcripts and some housekeeping genes) and might not be the case as more genes are added to the run.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/523#issuecomment-633062608:449,variab,variables,449,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/523#issuecomment-633062608,1,['variab'],['variables']
Modifiability,"Thanks for the details @cljacobs. We'll see if we can get a Docker image up to reproduce this under RH7. Our development machine is ubuntu based, and our CI is CentOS. It also builds on the environment used by bioconda. So it looks like we'll need a RH image to reproduce this. Out of curiosity, does anything happen differently if you pass `-DNO_IPO=TRUE` during the `cmake` configure step? That disables interprocedural optimization (whole program link-time optimization).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/455#issuecomment-558716670:376,config,configure,376,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/455#issuecomment-558716670,1,['config'],['configure']
Modifiability,"Thanks for the recommendation. I'll definitely take a look at it. It is true that we typically suggest that you drop singletons if they are created during e.g. adapter / quality trimming etc.. However, it is also the case that one really may only want to consider very ""light"" quality trimming for RNA-seq data [as suggested by Matt MacManes](https://www.frontiersin.org/articles/10.3389/fgene.2014.00013/full). . If the trimming leads to the loss of a large number of reads, my initial reaction would be to try an understand why. One could always ""re-synchronize"" the singletons by providing them with fake mates, which would cause them to be mapped and treated as orphans during quantification. However, again, it's probably worth understanding why an experiment ends up with a lot of singletons before going through the trouble of accounting for them.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/240#issuecomment-400061755:160,adapt,adapter,160,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/240#issuecomment-400061755,1,['adapt'],['adapter']
Modifiability,Thanks for the speedy replies. I tried running alevin with 8 threads and it ends up leading to the same error and backtrace. I can see a large number of threads still spawning through GDB. I have had these kinds of issues before with OpenMP and I usually had to specify an environment variable to limit the threads. I compiled salmon with the download boost etc option:. ```; linux-vdso.so.1 (0x00007ffc90379000); libpthread.so.0 => /lib/x86_64-linux-gnu/libpthread.so.0 (0x00007f859b069000); libtbbmalloc_proxy.so.2 => /u/user/tmp/salmon/build-debug/src/../../external/install/lib/libtbbmalloc_proxy.so.2 (0x00007f859ae66000); libtbbmalloc.so.2 => /u/user/tmp/salmon/build-debug/src/../../external/install/lib/libtbbmalloc.so.2 (0x00007f859ac36000); libtbb.so.2 => /u/user/tmp/salmon/build-debug/src/../../external/install/lib/libtbb.so.2 (0x00007f859aa08000); libgomp.so.1 => /u/user/local/lib64/libgomp.so.1 (0x00007f859a7e7000); librt.so.1 => /lib/x86_64-linux-gnu/librt.so.1 (0x00007f859a5df000); libm.so.6 => /lib/x86_64-linux-gnu/libm.so.6 (0x00007f859a2de000); libgcc_s.so.1 => /u/user/local/lib64/libgcc_s.so.1 (0x00007f859a0c8000); libc.so.6 => /lib/x86_64-linux-gnu/libc.so.6 (0x00007f8599d1d000); /lib64/ld-linux-x86-64.so.2 (0x00007f859b286000); libdl.so.2 => /lib/x86_64-linux-gnu/libdl.so.2 (0x00007f8599b19000); libstdc++.so.6 => /u/user/local/lib64/libstdc++.so.6 (0x00007f859979f000); ```. The linux version and g++ version are listed below:; ```; cat /proc/version; Linux version 4.9.0-0.bpo.6-amd64 (debian-kernel@lists.debian.org) (gcc version 4.9.2 (Debian 4.9.2-10+deb8u1) ) #1 SMP Debian 4.9.82-1+deb9u3~bpo8+1 (2018-03-22). ~/data/PCSI/PC10X/paper/pbmc$ g++ -v; Using built-in specs.; COLLECT_GCC=g++; COLLECT_LTO_WRAPPER=/u/user/local/libexec/gcc/x86_64-unknown-linux-gnu/5.4.0/lto-wrapper; Target: x86_64-unknown-linux-gnu; Configured with: ./configure --prefix=/u/user/local; Thread model: posix; gcc version 5.4.0 (GCC); ```. ```; [Thread debugging using libthread_db enab,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-395836214:285,variab,variable,285,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-395836214,1,['variab'],['variable']
Modifiability,"Thanks, I usually do not trim reads. I am surprised to see such a difference from version 0.8.3. Do you have a recommendation for --minScoreFraction if I do not trim reads? Or maybe I should go back to NOT using --validateMappings?; For testing purposes, I will try trimming the reads for this sample. Will report back.; Oh, and this sample was prepared by ultra-low RNA input protocol, so the issues of adapter contamination could be present.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-586475673:404,adapt,adapter,404,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-586475673,1,['adapt'],['adapter']
Modifiability,That sounds like a very good way of doing it :-). I'm sorry I was not clear enough - my question was acutally meant for a single sequence - let me try again:; Lets say we have a read pair where one mate maps fine - but the other mate have a problem - half of it is an adapter (or low quality sequence with to many errors). How would Salmon currently handle this situation where the first half of a sequence (e.g. nt 1-50) could be quasi-mapped to a transcript but the second half (nt 51-100) did not match anywhere? Would the the second half cause the whole sequence to be discarded or would it be enough that the first half matched for it to be considered/counted?,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/150#issuecomment-354955072:268,adapt,adapter,268,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/150#issuecomment-354955072,1,['adapt'],['adapter']
Modifiability,"That's amazing @Gaura. This feature has been frequently requested by multiple users but I never got a chance to work on this, thanks a lot for the PR. Give me some time to go over the PR and if everything looks Ok, we can merge it in into the next release cycle. May I ask previous version of inDrop had an issue with variable length barcodes, did they solved that issue in v2 ?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/703#issuecomment-920921204:318,variab,variable,318,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/703#issuecomment-920921204,1,['variab'],['variable']
Modifiability,The GCC compiler has a long standing bug. You should clean the build directory and pass `-DNO_IPO=TRUE` to the `cmake` configure step. This will disable LTO and allow the compilation to complete.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/860#issuecomment-1620414936:119,config,configure,119,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/860#issuecomment-1620414936,1,['config'],['configure']
Modifiability,The languages of both autotools and CMake are pretty terrible. I actually like the Make language; I think it gets a bad wrap. Other than `config.h` was there any other files of Jellyfish that were missing from the install that you needed?,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/19#issuecomment-195461547:138,config,config,138,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/19#issuecomment-195461547,1,['config'],['config']
Modifiability,"There should be easy ways to handle reading line-buffered input from two file descriptors, where both file descriptors could be identical, and then passing these streams internally to buffers to be chunked for multithreaded processing. This would give you one code path for ingesting data, and the command line interface could remain the same as it is currently, with the possible addition of mapping the `-` symbol to `/dev/fd/0`. Is there really much to be gained from buffering all input in byte chunks up front? Remembering that unix pipes are buffered somewhat by default anyway? There has to be an acceptable way to handle line-based input in a more flexible way. In Python I would do:. ``` python; import argparse. example_parser = argparse.ArgumentParser(); example_parser.add_argument('-fq1', type=argparse.FileType('r')); example_parser.add_argument('-fq2', type=argparse.FileType('r')); args = parser.parse_args(). for line1, line2 in zip(args.fq1, args.fq2):; do_stuff_with_lines(); ```. You could then call the program flexibly:. ``` bash; $ example -fq1 file1.fq -fq2 file2.fq; $ example -fq1 <(gzip -dc file1.fq.gz) -fq2 <(gzip -dc file2.fq.gz); $ other_interleaved_process | example -fq1 - -fq2 -; ```. The caveat for the code above is that you would want to replace `argparse.FileType` with some class that reads 4 lines at a time - I'm sure there's no shortage of Python FASTQ readers that do that. And I know that you're looking for C++ libraries that perform well for your purposes, and my Python example is just a toy, but I think designing the option parser to at least **accept** streams and file-like objects and handle them using the same code path would be a worthy reason to refactor a bit.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/29#issuecomment-168545456:656,flexible,flexible,656,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/29#issuecomment-168545456,2,"['flexible', 'refactor']","['flexible', 'refactor']"
Modifiability,"To partially answer my own question, I think [you need 50k reads](https://github.com/COMBINE-lab/salmon/blob/a2f6912b3f9f9af91e3a4b0d74adcb3bdc4c9a32/include/LibraryTypeDetector.hpp#L157) to get a proper strandedness assessment, and I don't think it's configurable.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/938#issuecomment-2166074428:252,config,configurable,252,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/938#issuecomment-2166074428,1,['config'],['configurable']
Modifiability,"Using the rest of the same configure flags without `-DUSE_SHARED_LIBS=TRUE`, the build does not link properly. I think you should try building without these extra flags. Since the LTO seems not to be a problem on this system, a simple `cmake .. && make` should work. In the mean time, I'll try and pare back the configure command line to find the maximum viable interpolation between our different configurations. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1464012294:27,config,configure,27,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1464012294,3,['config'],"['configurations', 'configure']"
Modifiability,"Well, I was just in the middle of writing a comment saying ""it's been running for 6 hours with no hang, I don't think it's gonna happen"", and then it just hung. Here's the backtrace from gdb:. ```; $ gdb -ex ""attach $(pgrep salmon | head -1)"" -ex bt -ex detach -ex quit; GNU gdb (Ubuntu 7.11.1-0ubuntu1~16.04) 7.11.1; Copyright (C) 2016 Free Software Foundation, Inc.; License GPLv3+: GNU GPL version 3 or later <http://gnu.org/licenses/gpl.html>; This is free software: you are free to change and redistribute it.; There is NO WARRANTY, to the extent permitted by law. Type ""show copying""; and ""show warranty"" for details.; This GDB was configured as ""x86_64-linux-gnu"".; Type ""show configuration"" for configuration details.; For bug reporting instructions, please see:; <http://www.gnu.org/software/gdb/bugs/>.; Find the GDB manual and other documentation resources online at:; <http://www.gnu.org/software/gdb/documentation/>.; For help, type ""help"".; Type ""apropos word"" to search for commands related to ""word"".; Attaching to process 29153; [New LWP 29155]; [New LWP 29156]; [New LWP 29157]; [New LWP 18084]; [New LWP 18085]; [New LWP 18086]; [New LWP 18087]; [New LWP 18088]; [New LWP 18089]; [New LWP 18090]; [Thread debugging using libthread_db enabled]; Using host libthread_db library ""/lib/x86_64-linux-gnu/libthread_db.so.1"".; 0x0000000000578b90 in __log_finite@plt (); #0 0x0000000000578b90 in __log_finite@plt (); #1 0x0000000000637ccc in double std::gamma_distribution<double>::operator()<pcg_detail::engine<unsigned int, unsigned long, pcg_detail::xsh_rr_mixin<unsigned int, unsigned long>, true, pcg_detail::unique_stream<unsigned long>, pcg_detail::default_multiplier<unsigned long> > >(pcg_detail::engine<unsigned int, unsigned long, pcg_detail::xsh_rr_mixin<unsigned int, unsigned long>, true, pcg_detail::unique_stream<unsigned long>, pcg_detail::default_multiplier<unsigned long> >&, std::gamma_distribution<double>::param_type const&) (); #2 0x0000000000634b8d in tbb::interface",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267534520:638,config,configured,638,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267534520,3,['config'],"['configuration', 'configured']"
Modifiability,"Yep, it aligns with https://github.com/COMBINE-lab/salmon/issues/328, where the user confirms it works out for him in a local computer while failing on his cluster environment. We should figure out this cluster config which is making `alevin` segfault as its becoming recurrent issue.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/337#issuecomment-458197495:211,config,config,211,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/337#issuecomment-458197495,1,['config'],['config']
Modifiability,"Yes ! it's other error that I can't find . but I try : . ```; Last login: Thu Jun 30 15:14:51 on ttys002; Benjamin@u932-ulm-2-57030119-6834 ~ % conda config --add channels defaults; conda config --add channels bioconda; conda config --add channels conda-forge; Warning: 'conda-forge' already in 'channels' list, moving to the top; Benjamin@u932-ulm-2-57030119-6834 ~ % conda install salmon; Collecting package metadata (current_repodata.json): failed. CondaHTTPError: HTTP 000 CONNECTION FAILED for url <https://conda.anaconda.org/conda-forge/osx-arm64/current_repodata.json>; Elapsed: -. An HTTP error occurred when trying to retrieve this URL.; HTTP errors are often intermittent, and a simple retry will get you on your way.; 'https://conda.anaconda.org/conda-forge/osx-arm64'; ```. ```; Benjamin@u932-ulm-2-57030119-6834 ~ % conda config --show channels ; channels:; - conda-forge; - bioconda; - defaults; ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/724#issuecomment-1171223414:150,config,config,150,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/724#issuecomment-1171223414,4,['config'],['config']
Modifiability,"You are right on the spot. ; After trimming, every problem went away:; ""num_processed"": 102482661,; ""num_mapped"": 85812375,; ""num_decoy_fragments"": 760387,; ""num_dovetail_fragments"": 1265734,; ""num_fragments_filtered_vm"": 7722295,; ""num_alignments_below_threshold_for_mapped_fragments_vm"": 293676436,; ""percent_mapped"": 83.7335546937057,. I would really like to have the soft clipping feature though. With salmon being so fast, trimming step basically takes more time than the salmon quantification step. A lot of us are now turning to cloud platforms and are charged by the the computing time. Some other questions unrelated to this topic:; For snRNA-seq like 10X platform, do you recommend just trimming read2?; From what I read out of documentation, decoy enhanced index would only work with --validateMapping. Would Alevin only work with non-decoy index then?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-586530740:759,enhance,enhanced,759,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-586530740,1,['enhance'],['enhanced']
Modifiability,"```; Benjamin@u932-ulm-2-57030119-6834 ~ % conda install salmon; Collecting package metadata (current_repodata.json): failed. CondaHTTPError: HTTP 000 CONNECTION FAILED for url <https://conda.anaconda.org/conda-forge/osx-arm64/current_repodata.json>; Elapsed: -. An HTTP error occurred when trying to retrieve this URL.; HTTP errors are often intermittent, and a simple retry will get you on your way.; 'https://conda.anaconda.org/conda-forge/osx-arm64'; ```. ```; Benjamin@u932-ulm-2-57030119-6834 ~ % conda config --show channels; channels:; - conda-forge; ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/724#issuecomment-1171204474:509,config,config,509,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/724#issuecomment-1171204474,1,['config'],['config']
Modifiability,`cmake && make install` _should_ work --- the fetching should happen during the configuration (i.e. `cmake`) phase.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/181#issuecomment-367760156:80,config,configuration,80,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/181#issuecomment-367760156,1,['config'],['configuration']
Modifiability,"`extract-libdivsufsort.cmake` is auto-generated during configuration. However, the zip itself is grabbed as part of RapMap (specifically, it resides [here](https://github.com/COMBINE-lab/RapMap/tree/master/external)). I can take a look at what would be required to make it a tarball there (or, conversely, if there is a way to force CMake to use `unzip` rather than `cmake -E tar xfz`.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/10#issuecomment-193784017:55,config,configuration,55,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/10#issuecomment-193784017,1,['config'],['configuration']
Modifiability,"abriel/Projects/salmon-0.13.1/build/CMakeFiles/libcereal.dir/DependInfo.cmake --color=; /Applications/Xcode.app/Contents/Developer/usr/bin/make -f CMakeFiles/libcereal.dir/build.make CMakeFiles/libcereal.dir/build; make[2]: Nothing to be done for `CMakeFiles/libcereal.dir/build'.; [ 8%] Built target libcereal; /Applications/Xcode.app/Contents/Developer/usr/bin/make -f CMakeFiles/libstadenio.dir/build.make CMakeFiles/libstadenio.dir/depend; cd /Users/gabriel/Projects/salmon-0.13.1/build && /usr/local/Cellar/cmake/3.13.4/bin/cmake -E cmake_depends ""Unix Makefiles"" /Users/gabriel/Projects/salmon-0.13.1 /Users/gabriel/Projects/salmon-0.13.1 /Users/gabriel/Projects/salmon-0.13.1/build /Users/gabriel/Projects/salmon-0.13.1/build /Users/gabriel/Projects/salmon-0.13.1/build/CMakeFiles/libstadenio.dir/DependInfo.cmake --color=; /Applications/Xcode.app/Contents/Developer/usr/bin/make -f CMakeFiles/libstadenio.dir/build.make CMakeFiles/libstadenio.dir/build; [ 9%] Performing configure step for 'libstadenio'; cd /Users/gabriel/Projects/salmon-0.13.1/external/staden-io_lib && ./configure --enable-shared=no --without-libcurl --prefix=/Users/gabriel/Projects/salmon-0.13.1/external/install LDFLAGS= CFLAGS= CC=/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/cc CXX=/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/c++; checking for a BSD-compatible install... /usr/local/bin/ginstall -c; checking whether build environment is sane... yes; checking for a thread-safe mkdir -p... /usr/local/bin/gmkdir -p; checking for gawk... gawk; checking whether make sets $(MAKE)... yes; checking whether make supports nested variables... yes; checking whether to enable maintainer-specific portions of Makefiles... no; checking for gcc... /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/cc; checking whether the C compiler works... yes; checking for C compiler default output file name... a.out",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/348#issuecomment-472500713:1953,config,configure,1953,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/348#issuecomment-472500713,1,['config'],['configure']
Modifiability,"almon-0.13.1/build && /usr/local/Cellar/cmake/3.13.4/bin/cmake -E cmake_depends ""Unix Makefiles"" /Users/gabriel/Projects/salmon-0.13.1 /Users/gabriel/Projects/salmon-0.13.1 /Users/gabriel/Projects/salmon-0.13.1/build /Users/gabriel/Projects/salmon-0.13.1/build /Users/gabriel/Projects/salmon-0.13.1/build/CMakeFiles/libstadenio.dir/DependInfo.cmake --color=; /Applications/Xcode.app/Contents/Developer/usr/bin/make -f CMakeFiles/libstadenio.dir/build.make CMakeFiles/libstadenio.dir/build; [ 9%] Performing configure step for 'libstadenio'; cd /Users/gabriel/Projects/salmon-0.13.1/external/staden-io_lib && ./configure --enable-shared=no --without-libcurl --prefix=/Users/gabriel/Projects/salmon-0.13.1/external/install LDFLAGS= CFLAGS= CC=/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/cc CXX=/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/c++; checking for a BSD-compatible install... /usr/local/bin/ginstall -c; checking whether build environment is sane... yes; checking for a thread-safe mkdir -p... /usr/local/bin/gmkdir -p; checking for gawk... gawk; checking whether make sets $(MAKE)... yes; checking whether make supports nested variables... yes; checking whether to enable maintainer-specific portions of Makefiles... no; checking for gcc... /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/cc; checking whether the C compiler works... yes; checking for C compiler default output file name... a.out; checking for suffix of executables...; checking whether we are cross compiling... configure: error: in `/Users/gabriel/Projects/salmon-0.13.1/external/staden-io_lib':; configure: error: cannot run C compiled programs.; If you meant to cross compile, use `--host'.; See `config.log' for more details; make[2]: *** [libstadenio-prefix/src/libstadenio-stamp/libstadenio-configure] Error 1; make[1]: *** [CMakeFiles/libstadenio.dir/all] Error 2; make: *** [all] Error 2; ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/348#issuecomment-472500713:2666,variab,variables,2666,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/348#issuecomment-472500713,5,"['config', 'variab']","['config', 'configure', 'variables']"
Modifiability,"almon.; Exception : [Error: FMD indexing is not supported in this version of salmon.]; /usr/common/src/salmon-latest_linux_x86_64/bin/salmon index was invoked improperly.; For usage information, try /usr/common/src/salmon-latest_linux_x86_64/bin/salmon index --help; Exiting.; #this worked OK; /usr/common/src/salmon-latest_linux_x86_64/bin/salmon index -t transcripts.fasta -i sample_salmon_fmd_index --type puff. ```; Here is what happens in gdb for the version I built:. ```; gdb --args salmon index -t transcripts.fasta -i sample_salmon_fmd_index --type fmd; GNU gdb (GDB) Red Hat Enterprise Linux 8.2-6.el8; Copyright (C) 2018 Free Software Foundation, Inc.; License GPLv3+: GNU GPL version 3 or later <http://gnu.org/licenses/gpl.html>; This is free software: you are free to change and redistribute it.; There is NO WARRANTY, to the extent permitted by law.; Type ""show copying"" and ""show warranty"" for details.; This GDB was configured as ""x86_64-redhat-linux-gnu"".; Type ""show configuration"" for configuration details.; For bug reporting instructions, please see:; <http://www.gnu.org/software/gdb/bugs/>.; Find the GDB manual and other documentation resources online at:; <http://www.gnu.org/software/gdb/documentation/>. For help, type ""help"".; Type ""apropos word"" to search for commands related to ""word""...; Reading symbols from salmon...done.; (gdb) r; Starting program: /home/common/modules/el8/x86_64/software/salmon/1.2.1-CentOS-vanilla/bin/salmon index -t transcripts.fasta -i sample_salmon_fmd_index --type fmd; Missing separate debuginfos, use: yum debuginfo-install glibc-2.28-72.el8_1.1.x86_64; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable secti",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641594410:1666,config,configuration,1666,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641594410,2,['config'],['configuration']
Modifiability,"e *full* decoy index is substantially larger than the index on just the transcriptome (after all, it is indexing the entire human genome in addition to the transcriptome). One thing you might try to test this hypothesis, other than requesting to build on a node with more RAM, is to compute a hash (e.g. md5 or sha256 sum) on all of the files in the index, and also record their sizes. Then we can build the index on the same version of the files on our end and compare. Second — and perhaps more importantly for your end goal — the main purpose of the decoy-aware index is to improve specificity rather than sensitivity. That is, the decoys are designed to help avoid _spurious_ mapping of reads to an annotated transcript when a better explanation for the read exists elsewhere in the genome. However, the reads that are mapped to decoys are not otherwise used for quantification. Thus, using the decoy aware transcriptome index is unlikely to improve your mapping rate. I agree that your mapping rate does seem rather low. There are a few potential culprits here, and some diagnostics we can look at to see what might be going wrong. First, you can take a look at the file `aux_info/meta_info.json` in the salmon quantification directories to get a few more details about why reads were not mapped. If you share one of those files here I can describe the relevant fields. Also, I have two more rather common things to consider that might affect the mapping rate. One is to add the sequence for the ribosomal RNAs to your transcriptome before indexing and then quantifying. If your mapping rate increases considerably, this is evidence of rather inefficient depletion prior to sequencing. The other thing to consider is to do basic adapter / quality trimming on the reads to see if that affects your mapping rate at all. I hope these two different responses are useful, and I'll keep this issue open so feel free to reply here with any further questions or discoveries you make regarding the above.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/603#issuecomment-744162850:2071,adapt,adapter,2071,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/603#issuecomment-744162850,1,['adapt'],['adapter']
Modifiability,"e I answer your question and layout my logic, I want to mention that I am **_not_** suggesting fastp is not doing its job, **_neither am I stating that fastp is working incorrectly_**. Now to my answer(s) and logic:; 1. With fastp, I am not sure if adapter trimming happens first and then quality trimming OR vice-versa. I could not find info on this from their README and **_I could be wrong here with my next line_** - [Based on Figure 1 of this paper, it looks to me as though quality trimming is done before adapter trimming](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6129281/figure/bty560-F1/). - [To quote Brian Bushnell (author of BBTools)]( http://seqanswers.com/forums/showpost.php?p=140819&postcount=5), . > It's best to do adapter-trimming first, then quality-trimming, because if you do quality-trimming first, sometimes adapters will be partially trimmed and become too short to be recognized as adapter sequence. When you run BBDuk with both quality-trimming and adapter-trimming in the same run, it will do adapter-trimming first, then quality-trimming. 2. I very well know that the advantage of using fastp is that it can do adapter trimming, etc in a automatic fashion - no need to provide external sequences (example adapter sequences). Yes, I know one can also provide a fasta file of adapters and fatsp will work off it. There are many fatsp issues in GH about adapter detection:. - fail to detect adpaters automatically - (https://github.com/OpenGene/fastp/issues/222 and https://github.com/OpenGene/fastp/issues/205). - [incorrect automatic adapter detection](https://github.com/OpenGene/fastp/issues/240). - [inconsistent behavior with different runs](https://github.com/OpenGene/fastp/issues/231). 3. When I see the above, I am bit skeptical using fastp for qc/adapter trimming. . After lot of trials with bbduk and fastp, I have decided to use bbduk and bbmap for my high throughput analysis. Below, I explain my reasoning behind those choices: . **_```Note - edited this ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-597393209:997,adapt,adapter-trimming,997,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-597393209,2,['adapt'],['adapter-trimming']
Modifiability,"e correct command line `salmon quant` options for Lexogen/QuantSeq _(this will be referred to as QS in the rest of the message(s))_ ?. `salmon quant --threads 16 --noLengthCorrection --validateMappings --numBootstraps 100 -l SF -i <path_to_SAF_Gentrome_Index> -r <SE_READ_1.fq> -o <salmon_SE_READ_1>`. I chose the above command line options (`especially --noLengthCorrection`) based on [Rob's message here](https://groups.google.com/d/msg/sailfish-users/VIfqBwgF6xQ/fw-rgC_kAwAJ) and a [thread here](https://github.com/COMBINE-lab/salmon/issues/108). Let me elaborate the big picture of my analyses and give more details about how I came up with the mapping numbers in my original post. Big Picture - DEG identification for samples sequenced by ILMN (whole transcript method) and QS (3' method) - [something similar to this paper](https://bmcgenomics.biomedcentral.com/articles/10.1186/s12864-018-5393-3). Bioinformatics Pipeline(s) for both ILMN and QS :. 1. HISAT Method : Adapter/Quality Trimming, Hisat2-HTSEQ, Get_Count_Table, DESeq; 2. STAR_RSEM Method: Adapter/Quality Trimming, STAR_RSEM, Get_Count_Table, DESeq; 3. SAF Method: Adapter/Quality Trimming, SAF_SALMON, Get_Count_Table, DESeq; 4. Quasi-Mapping or TXOME Method: Adapter/Quality Trimming, TXOME_SALMON, Get_Count_Table, DESeq. I used UpSetR plots for comparisons of sets of DEGs from each method just [as you have shown in your recent preprint](https://www.biorxiv.org/content/10.1101/657874v1.full). In the ILMN analyses, there is great concordance between the SAF method and HISAT/STAR_RSEM method. However, in the QS analyses, there is very limited concordance between SAF and the HISAT/STAR_RSEM method. For QS analyses, the TXOME method shows great concordance with HISAT/STAR_RSEM. This finding made me wonder if this has to be something with my salmon quant command line options for QS. Therefore, I wanted to check how the QS expected counts for SAF method show up for all samples in my final summarized table (after tximpo",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-554768195:1016,Adapt,Adapter,1016,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-554768195,1,['Adapt'],['Adapter']
Modifiability,"efault. RSEM uses the EM algorithm, and salmon uses the variational Bayesian EM algorithm. The latter tends to induce more sparse solutions. This is simply because they are optimizing slightly different objectives. It is very difficult to say in general if one is ""better"" than the other in a blanket way, but [there is previous literature to support that the VBEM may be more accurate](https://academic.oup.com/bioinformatics/article/29/18/2292/239795). However, while RSEM only implements the EM algorithm, salmon actually implements and provides a switch to use either. So, if you want to test the effect of this difference, you can run salmon with the `--useEM` algorithm. This will tell salmon to use the ""classic"" EM algorithm and will eliminate this source of variation. * As with the other question you asked, there may be a _small_ discrepancy depending on when enforcement of a stranded library kicks in under salmon's `A` library type. You can eliminate that variable by simply providing `-l SF` to match the library type being used with RSEM. * Coming back to the `IndelSoftclipSingleend` parameter I mentioned in the first point; RSEM disallows indels in the alignments that it quantifies. This means that to produce RSEM-compatible input, STAR must not align reads that contain indels. While this won't generally have a big effect for many transcripts, it can certainly affect the abundance estimates for transcripts in your sample where the sample you are quantifying has (indel) variation with respect to the reference annotation. We touch upon that a bit as well in the [paper I mentioned above](https://genomebiology.biomedcentral.com/articles/10.1186/s13059-020-02151-8). * Finally, and likely the smallest source of potential differences, is that there are other implementation details that differ between salmon and RSEM (e.g. exactly how the fragment length distribution is used to compute the effective transcript length, exactly how the alignment score of a read is used to as",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/612#issuecomment-758004590:3660,variab,variable,3660,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/612#issuecomment-758004590,1,['variab'],['variable']
Modifiability,"esting. $ docker run -it debian:testing. $ apt-get update. $ apt-get install build-essential git libboost-all-dev liblzma-dev libbz2-dev cmake zlib1g-dev curl unzip wget libcurl4-openssl-dev. $ git clone https://github.com/COMBINE-lab/salmon.git; $ cd salmon; $ mkdir build && cd build; $ cmake -DNO_IPO=TRUE .. # GCC still doesn't handle LTO robustly; $ make -j8; $ make install; $ make test; ```. which leads to the output. ```; root@fd877e359439:/salmon/build# make install; [ 7%] Built target libcereal; [ 13%] Built target libtbb; [ 16%] Built target ntcard; [ 19%] Built target graphdump; [ 27%] Built target twopaco; [ 29%] Built target ksw2pp_sse2; [ 32%] Built target ksw2pp_sse4; [ 37%] Built target ksw2pp_basic; [ 38%] Built target ksw2pp; [ 59%] Built target puffer; [ 73%] Built target salmon_core; [ 76%] Built target alevin_core; [ 77%] Built target UnitTestsMain; [ 81%] Built target unitTests; [100%] Built target salmon; Install the project...; -- Install configuration: ""Release""; -- Installing: /salmon/lib/libntcard.a; -- Installing: /salmon/lib/ntcard/ntcard-targets.cmake; -- Installing: /salmon/lib/ntcard/ntcard-targets-release.cmake; -- Installing: /salmon/lib/libgraphdump.a; -- Installing: /salmon/lib/graphdump/graphdump-targets.cmake; -- Installing: /salmon/lib/graphdump/graphdump-targets-release.cmake; -- Installing: /salmon/lib/libtwopaco.a; -- Installing: /salmon/lib/twopaco/twopaco-targets.cmake; -- Installing: /salmon/lib/twopaco/twopaco-targets-release.cmake; -- Installing: /salmon/lib/libtbb.so; -- Installing: /salmon/lib/libtbb.so.12; -- Installing: /salmon/lib/libtbb.so.12.5; -- Installing: /salmon/lib/libtbbmalloc.so; -- Installing: /salmon/lib/libtbbmalloc.so.2; -- Installing: /salmon/lib/libtbbmalloc.so.2.5; -- Installing: /salmon/lib/libtbbmalloc_proxy.so; -- Installing: /salmon/lib/libtbbmalloc_proxy.so.2; -- Installing: /salmon/lib/libtbbmalloc_proxy.so.2.5; -- Installing: /salmon/bin/salmon; -- Installing: /salmon/lib/libsalmon_core.a. Ins",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463312554:1314,config,configuration,1314,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463312554,1,['config'],['configuration']
Modifiability,"fmd; Version Info: This is the most recent version of salmon.; Exception : [Error: FMD indexing is not supported in this version of salmon.]; /usr/common/src/salmon-latest_linux_x86_64/bin/salmon index was invoked improperly.; For usage information, try /usr/common/src/salmon-latest_linux_x86_64/bin/salmon index --help; Exiting.; #this worked OK; /usr/common/src/salmon-latest_linux_x86_64/bin/salmon index -t transcripts.fasta -i sample_salmon_fmd_index --type puff. ```; Here is what happens in gdb for the version I built:. ```; gdb --args salmon index -t transcripts.fasta -i sample_salmon_fmd_index --type fmd; GNU gdb (GDB) Red Hat Enterprise Linux 8.2-6.el8; Copyright (C) 2018 Free Software Foundation, Inc.; License GPLv3+: GNU GPL version 3 or later <http://gnu.org/licenses/gpl.html>; This is free software: you are free to change and redistribute it.; There is NO WARRANTY, to the extent permitted by law.; Type ""show copying"" and ""show warranty"" for details.; This GDB was configured as ""x86_64-redhat-linux-gnu"".; Type ""show configuration"" for configuration details.; For bug reporting instructions, please see:; <http://www.gnu.org/software/gdb/bugs/>.; Find the GDB manual and other documentation resources online at:; <http://www.gnu.org/software/gdb/documentation/>. For help, type ""help"".; Type ""apropos word"" to search for commands related to ""word""...; Reading symbols from salmon...done.; (gdb) r; Starting program: /home/common/modules/el8/x86_64/software/salmon/1.2.1-CentOS-vanilla/bin/salmon index -t transcripts.fasta -i sample_salmon_fmd_index --type fmd; Missing separate debuginfos, use: yum debuginfo-install glibc-2.28-72.el8_1.1.x86_64; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.prop",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641594410:1613,config,configured,1613,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641594410,1,['config'],['configured']
Modifiability,"here, for instance. What do the flags and qualities represent?. It is just a SAM file without CIGAR strings. The flags have the same (normal) interpretation for SAM records. However the CIGAR strings are not meaningful (apart from what is required for the file to undergo valid processing with samtools). The records additionally contain tags about the number of targets to which a fragment multi-maps, and the alignment score of the read pair to the current target (in the `AS` flag). The records themself are just normal SAM records, but with a trivial CIGAR strong. > More importantly, is there a way to filter the pseudobam files to find the reads corresponding to the counts/NumReads in the quant.sf output file? Do the normal samtools quality and flag filters work to subset e.g. uniquely-mapped reads, or do those concepts not really apply to these pseudobams?. There is no easy way to filter so the above condition is satisfied, as the NumReads are obtained by proportional allocation of the reads according to the underlying probabilistic model of salmon. Specifically, the NumReads column of the quantification file corresponds to summing over the _expectation_ of all of the latent variables that represent fragment to transcript assignment so that, apart from uniquely-mapped reads, there is no way to say that a fragment _definitely_ came from a transcript. However, you should still be able to easily filter out uniquely mapped reads, and you can interpret them in a relatively unambiguous way. Also, you could filter on the `AS` tag as well. For a given read, if there is a single transcript where the `AS` value is much larger than the others for this read, it is overwhelmingly likely that the read originated from the transcript with the unique best `AS` score. @shangguandong1996 : The SAM file _does_ contain positions (and orientations, and alignment scores) for each read. It is simply that the positions are with respect to the transcriptome and not with respect to the genome.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/528#issuecomment-639065653:2438,variab,variables,2438,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/528#issuecomment-639065653,1,['variab'],['variables']
Modifiability,"ild system will compile libgff; ==================================================================; ==================================================================; Build system will compile Staden IOLib; ==================================================================; Build system will fetch SPDLOG; ==================================================================; -- Found PkgConfig: /apps/gentoo/usr/bin/pkg-config (found version ""0.29.2""); -- Found Jemalloc: /apps/gentoo/usr/lib/libjemalloc.so (found version """"); Found Jemalloc library --- using this memory allocator; CPACK_SOURCE_IGNORE_FILES = /src/PCA.cpp;/src/PCAUtils.cpp;/build/;/scripts/AggregateToGeneLevel.py;/scripts/ExpressionTools.py;/scripts/GenerateExpressionFiles.sh;/scripts/ParseSoftFile.py;/scripts/PlotCorrelation.py;/scripts/junk;/scripts/sfstrace.log;/scripts/SFPipeline.py;/bin/;/lib/;/sample_data/;PublishREADMEToWebsite.sh;/external/;/src/obsolete/;/include/obsolete/;WebsiteHeader.txt;/experimental_configs/;.git/; TBB_LIBRARIES = /apps/gentoo/usr/lib/libtbbmalloc_proxy.so;/apps/gentoo/usr/lib/libtbbmalloc.so;/apps/gentoo/usr/lib/libtbb.so; -- Configuring done; CMake Error at src/CMakeLists.txt:158 (add_executable):; Cannot find source file:. $blah/salmon-0.10.2/external/install/src/rapmap/RapMapFileSystem.cpp. Tried extensions .c .C .c++ .cc .cpp .cxx .cu .m .M .mm .h .hh .h++ .hm; .hpp .hxx .in .txx. CMake Error at src/CMakeLists.txt:160 (add_executable):; Cannot find source file:. $blah/salmon-0.10.2/external/install/src/rapmap/rank9b.cpp. Tried extensions .c .C .c++ .cc .cpp .cxx .cu .m .M .mm .h .hh .h++ .hm; .hpp .hxx .in .txx. CMake Error at src/CMakeLists.txt:158 (add_executable):; No SOURCES given to target: salmon. CMake Error at src/CMakeLists.txt:160 (add_executable):; No SOURCES given to target: unitTests. -- Build files have been written to: $blah/salmon-0.10.2; $blah/salmon-0.10.2 $ make; make: *** No targets specified and no makefile found. Stop.; $blah/salmon-0.10.2 $; ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/19#issuecomment-399775387:4909,Config,Configuring,4909,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/19#issuecomment-399775387,1,['Config'],['Configuring']
Modifiability,"ing incorrectly_**. Now to my answer(s) and logic:; 1. With fastp, I am not sure if adapter trimming happens first and then quality trimming OR vice-versa. I could not find info on this from their README and **_I could be wrong here with my next line_** - [Based on Figure 1 of this paper, it looks to me as though quality trimming is done before adapter trimming](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6129281/figure/bty560-F1/). - [To quote Brian Bushnell (author of BBTools)]( http://seqanswers.com/forums/showpost.php?p=140819&postcount=5), . > It's best to do adapter-trimming first, then quality-trimming, because if you do quality-trimming first, sometimes adapters will be partially trimmed and become too short to be recognized as adapter sequence. When you run BBDuk with both quality-trimming and adapter-trimming in the same run, it will do adapter-trimming first, then quality-trimming. 2. I very well know that the advantage of using fastp is that it can do adapter trimming, etc in a automatic fashion - no need to provide external sequences (example adapter sequences). Yes, I know one can also provide a fasta file of adapters and fatsp will work off it. There are many fatsp issues in GH about adapter detection:. - fail to detect adpaters automatically - (https://github.com/OpenGene/fastp/issues/222 and https://github.com/OpenGene/fastp/issues/205). - [incorrect automatic adapter detection](https://github.com/OpenGene/fastp/issues/240). - [inconsistent behavior with different runs](https://github.com/OpenGene/fastp/issues/231). 3. When I see the above, I am bit skeptical using fastp for qc/adapter trimming. . After lot of trials with bbduk and fastp, I have decided to use bbduk and bbmap for my high throughput analysis. Below, I explain my reasoning behind those choices: . **_```Note - edited this on 02-Apr-2020 to have the correct order of operations ```_** . 1. **_STEP 1 - run bbmap.sh on raw fatsq file to remove contaminants as appropriate (rRNA, mitochondri",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-597393209:1161,adapt,adapter,1161,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-597393209,2,['adapt'],['adapter']
Modifiability,"inly does seem very low. To answer your specific questions first:; 1) I'm not sure --- let's try tor find out; 2) I don't think so (if they are part of your index, they should be aligned against); 3) If there are many transcripts / targets you expect to be sequenced but which aren't present in this set, that can affect the mapping rate, but not likely to take it down to 6%. Here are the things I'd investigate --- roughly in order: . 1) In addition to the fraction of reads STAR mapped (which you report above), what fraction of the reads are assigned to features by featureCounts? In some cases, when there is a failure of rRNA depletion of polyA selection, you can end up with an experiment where most of the sequenced RNA comes from rRNA not present in the reference transcriptome. In this case, STAR will be able to align the reads to the genome, but you won't see these reads mapping to annotated features (and you also won't see them showing up in your transcript level quantifications). So, it may be worth to take a look at the count of reads assigned to the feature set of genes by featureCounts. 2) Above, it looks like a considerable number of fragments were discarded due to no alignment reaching the required alignment score (`11,448,458` fragments discarded because of this). Have you tried to adapter / quality trim the data? Does this have any effect on the mapping rate?. 3) If the above don't reveal any clues, I'd be happy to try to take a look at the data if you can share it. I'd be quite surprised if STAR is aligning a lot of reads *to transcriptome features* that are being missed by salmon. Nonetheless, if you pass the proper flags to STAR (including `--quantMode TranscriptomeSAM`), then you can use the SAM/BAM file generated by STAR to perform quantification with salmon (i.e. use STAR's alignments to do _transcript-level_ quantification). I'd be happy to help dig further on any of these, so please feel free to reach out if you find anything interesting. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/661#issuecomment-846251054:1381,adapt,adapter,1381,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/661#issuecomment-846251054,1,['adapt'],['adapter']
Modifiability,"line 645, in send; r = adapter.send(request, **kwargs); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/requests/adapters.py"", line 413, in send; conn = self.get_connection(request.url, proxies); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/requests/adapters.py"", line 308, in get_connection; raise InvalidProxyURL(""Please check proxy URL. It is malformed""; requests.exceptions.InvalidProxyURL: Please check proxy URL. It is malformed and could be missing the host. `$ /usr/local/bin/conda install salmon`. environment variables:; CIO_TEST=<not set>; CONDA_ROOT=/usr/local/Caskroom/miniforge/base; CURL_CA_BUNDLE=<not set>; INFOPATH=/opt/homebrew/share/info:; MANPATH=/opt/homebrew/share/man::; PATH=/opt/homebrew/bin:/opt/homebrew/sbin:/usr/local/bin:/usr/bin:/bin:/usr; /sbin:/sbin; REQUESTS_CA_BUNDLE=<not set>; SSL_CERT_FILE=<not set>; all_proxy=<set>. active environment : None; user config file : /Users/Benjamin/.condarc; populated config files : /usr/local/Caskroom/miniforge/base/.condarc; conda version : 4.12.0; conda-build version : not installed; python version : 3.9.13.final.0; virtual packages : __osx=12.4=0; __unix=0=0; __archspec=1=arm64; base environment : /usr/local/Caskroom/miniforge/base (writable); conda av data dir : /usr/local/Caskroom/miniforge/base/etc/conda; conda av metadata url : None; channel URLs : https://conda.anaconda.org/conda-forge/osx-arm64; https://conda.anaconda.org/conda-forge/noarch; package cache : /usr/local/Caskroom/miniforge/base/pkgs; /Users/Benjamin/.conda/pkgs; envs directories : /usr/local/Caskroom/miniforge/base/envs; /Users/Benjamin/.conda/envs; platform : osx-arm64; user-agent : conda/4.12.0 requests/2.27.1 CPython/3.9.13 Darwin/21.5.0 OSX/12.4; UID:GID : 501:20; netrc file : None; offline mode : False. An unexpected error has occurred. Conda has prepared the above report. If submitted, this report will be used by core maintainers to improve; future releases of conda.; Would you like co",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/724#issuecomment-1171208515:5372,config,config,5372,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/724#issuecomment-1171208515,1,['config'],['config']
Modifiability,"mming OR vice-versa. I could not find info on this from their README and **_I could be wrong here with my next line_** - [Based on Figure 1 of this paper, it looks to me as though quality trimming is done before adapter trimming](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6129281/figure/bty560-F1/). - [To quote Brian Bushnell (author of BBTools)]( http://seqanswers.com/forums/showpost.php?p=140819&postcount=5), . > It's best to do adapter-trimming first, then quality-trimming, because if you do quality-trimming first, sometimes adapters will be partially trimmed and become too short to be recognized as adapter sequence. When you run BBDuk with both quality-trimming and adapter-trimming in the same run, it will do adapter-trimming first, then quality-trimming. 2. I very well know that the advantage of using fastp is that it can do adapter trimming, etc in a automatic fashion - no need to provide external sequences (example adapter sequences). Yes, I know one can also provide a fasta file of adapters and fatsp will work off it. There are many fatsp issues in GH about adapter detection:. - fail to detect adpaters automatically - (https://github.com/OpenGene/fastp/issues/222 and https://github.com/OpenGene/fastp/issues/205). - [incorrect automatic adapter detection](https://github.com/OpenGene/fastp/issues/240). - [inconsistent behavior with different runs](https://github.com/OpenGene/fastp/issues/231). 3. When I see the above, I am bit skeptical using fastp for qc/adapter trimming. . After lot of trials with bbduk and fastp, I have decided to use bbduk and bbmap for my high throughput analysis. Below, I explain my reasoning behind those choices: . **_```Note - edited this on 02-Apr-2020 to have the correct order of operations ```_** . 1. **_STEP 1 - run bbmap.sh on raw fatsq file to remove contaminants as appropriate (rRNA, mitochondrial, chloroplast)_**; - You have alluded to the importance of removing contaminants [in this post](https://github.com/COMBINE-lab/salmo",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-597393209:1324,adapt,adapters,1324,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-597393209,1,['adapt'],['adapters']
Modifiability,"n/cmake -DCMAKE_VERBOSE_MAKEFILE:BOOL=ON -DBoost_NO_BOOST_CMAKE=BOOL:ON -DBOOST_LIBRARYDIR=/usr/lib64 -DBOOST_INCLUDEDIR=/usr/include/boost157 ../CMakeLists.txt' >try_cmake.log 2>&1 &; `. Then tried to build it. ```; cd ..; nice scl enable devtoolset-4 'make' >build_2018_06_13d.log 2>&1 &. ```. It failed at this command because of missing boost symbols in a link operation, my reading is that the command does not include anything to link boost libraries. So telling cmake where the libraries are, where the include files are, and that boost was found was not sufficient. There must be some other set of symbols which need to be defined. `/opt/rh/devtoolset-4/root/usr/bin/c++ -pthread -ftree-vectorize -funroll-loops -fPIC -fomit-frame-pointer -O3 -DRAPMAP_SALMON_SUPPORT -DHAVE_ANSI_TERM -DHAVE_SSTREAM -Wall -Wno-unknown-pragmas -Wno-reorder -Wno-unused-variable -std=c++11 -Wreturn-type -Werror=return-type -Wno-unused-function -Wno-unused-local-typedef -static-libstdc++ -Wno-unused-local-typedefs -pthread -ftree-vectorize -funroll-loops -fPIC -fomit-frame-pointer -O3 -DRAPMAP_SALMON_SUPPORT -DHAVE_ANSI_TERM -DHAVE_SSTREAM -Wall -Wno-unknown-pragmas -Wno-reorder -Wno-unused-variable -std=c++11 -Wreturn-type -Werror=return-type -Wno-unused-function -Wno-unused-local-typedef -static-libstdc++ -Wno-unused-local-typedefs -rdynamic CMakeFiles/unitTests.dir/__/tests/UnitTests.cpp.o CMakeFiles/unitTests.dir/FragmentLengthDistribution.cpp.o CMakeFiles/unitTests.dir/__/external/install/src/rapmap/rank9b.cpp.o CMakeFiles/unitTests.dir/__/external/install/src/rapmap/bit_array.c.o -o unitTests -L/home/mathog/src/salmon/lib -L/home/mathog/src/salmon/external/install/lib -Wl,-rpath,""\$ORIGIN/../lib:\$ORIGIN/../../lib:\$ORIGIN/:\$ORIGIN/../../external/install/lib"" libsalmon_core.a libalevin_core.a -lgff -lpthread ../external/install/lib/libstaden-read.a -lz ../external/install/lib/libdivsufsort.a ../external/install/lib/libdivsufsort64.a ../external/install/lib/libbwa.a -lm -llzma -lbz2 -l",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/236#issuecomment-397025719:2163,variab,variable,2163,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/236#issuecomment-397025719,2,['variab'],['variable']
Modifiability,"naseq-Trinity-v2.6.6/util/support_scripts/../../PerlLib/Process_cmd.pm line 19.; Process_cmd::process_cmd(""salmon --no-version-check quant -i /home/federicoplazzi/test_""...) called at /usr/local/trinityrnaseq-Trinity-v2.6.6/util/support_scripts/salmon_runner.pl line 26; Trinity run failed. Must investigate error above.; warning, cmd: /usr/local/trinityrnaseq-Trinity-v2.6.6/util/support_scripts/../../Trinity --single ""/home/federicoplazzi/test_Trinity_Assembly/trinity_out_dir/read_partitions/Fb_0/CBin_0/c30.trinity.reads.fa"" --output ""/home/federicoplazzi/test_Trinity_Assembly/trinity_out_dir/read_partitions/Fb_0/CBin_0/c30.trinity.reads.fa.out"" --CPU 1 --max_memory 1G --run_as_paired --SS_lib_type F --seqType fa --trinity_complete --full_cleanup failed with ret: 512, going to retry.; succeeded(0), failed(1) 100% completed. We are sorry, commands in file: [FailedCommands] failed. :-(. Error, cmd: /usr/local/trinityrnaseq-Trinity-v2.6.6/trinity-plugins/BIN/ParaFly -c recursive_trinity.cmds -CPU 4 -v -shuffle died with ret 256 at /usr/local/bin/Trinity line 2581.; main::process_cmd(""/usr/local/trinityrnaseq-Trinity-v2.6.6/trinity-plugins/BIN/P""...) called at /usr/local/bin/Trinity line 3244; main::run_partitioned_cmds(""recursive_trinity.cmds"") called at /usr/local/bin/Trinity line 2239; main::run_recursive_trinity(""/home/federicoplazzi/test_Trinity_Assembly/trinity_out_dir/ch""...) called at /usr/local/bin/Trinity line 2001; main::run_chrysalis(""/home/federicoplazzi/test_Trinity_Assembly/trinity_out_dir/in""..., ""/home/federicoplazzi/test_Trinity_Assembly/trinity_out_dir/bo""..., 200, 500, ""RF"", ""/home/federicoplazzi/test_Trinity_Assembly/trinity_out_dir/bo""..., ""/home/federicoplazzi/test_Trinity_Assembly/trinity_out_dir/bo""...) called at /usr/local/bin/Trinity line 1664; main::run_Trinity() called at /usr/local/bin/Trinity line 1317; eval {...} called at /usr/local/bin/Trinity line 1316. Trinity run failed. Must investigate error above.; ```. Do you have any suggestions?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/235#issuecomment-398081403:3254,plugin,plugins,3254,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/235#issuecomment-398081403,1,['plugin'],['plugins']
Modifiability,"omatic adapter detection](https://github.com/OpenGene/fastp/issues/240). - [inconsistent behavior with different runs](https://github.com/OpenGene/fastp/issues/231). 3. When I see the above, I am bit skeptical using fastp for qc/adapter trimming. . After lot of trials with bbduk and fastp, I have decided to use bbduk and bbmap for my high throughput analysis. Below, I explain my reasoning behind those choices: . **_```Note - edited this on 02-Apr-2020 to have the correct order of operations ```_** . 1. **_STEP 1 - run bbmap.sh on raw fatsq file to remove contaminants as appropriate (rRNA, mitochondrial, chloroplast)_**; - You have alluded to the importance of removing contaminants [in this post](https://github.com/COMBINE-lab/salmon/issues/160#issuecomment-334762498); >However, the other thing to try is simply to align one of these samples to the genome with a tool like STAR or HISAT2 and look at their mapping rate to known features. If it's similar, then the other reads could be accounted for by e.g. intron retention or even contamination. Finally, [@vals has an excellent series of blog posts on investigating and addressing low mapping rates](http://www.nxn.se/valent/2017/9/18/low-mapping-rate-5-human-dna-contamination); - bbmap Command ([based of this biostars post](https://www.biostars.org/p/143019/#210890)):; `bbmap.sh in=read_1.fq.gz ref=rRNA_Chlor_Mito.fa maxindel=1 minid=0.95 outu=clean_read_1.fq.gz nodisk`; - Strategy:; `use the rRNA+Mito+Chloroplast file and map the reads using bbmap, then collect the unmapped reads (clean_read_1.fq.gz) for my downstream analysis`. 2. **_STEP 2 - run bbduk.sh on the outu files from bbmap step -- the outu stands for output unmapped - as stated in the logic above, anything that is unmapped to the rRNA_Chlor_Mito.fa is a clean read for downstream analysis_**. I use bbduk with adapter trimming and quality trimming in same command line - also, the adapters.fa file that ships with BBTools can be used in all runs. Hope that helps.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-597393209:3423,adapt,adapter,3423,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-597393209,2,['adapt'],"['adapter', 'adapters']"
Modifiability,"oper/usr/bin/make -f CMakeFiles/libcereal.dir/build.make CMakeFiles/libcereal.dir/build; make[2]: Nothing to be done for `CMakeFiles/libcereal.dir/build'.; [ 8%] Built target libcereal; /Applications/Xcode.app/Contents/Developer/usr/bin/make -f CMakeFiles/libstadenio.dir/build.make CMakeFiles/libstadenio.dir/depend; cd /Users/gabriel/Projects/salmon-0.13.1/build && /usr/local/Cellar/cmake/3.13.4/bin/cmake -E cmake_depends ""Unix Makefiles"" /Users/gabriel/Projects/salmon-0.13.1 /Users/gabriel/Projects/salmon-0.13.1 /Users/gabriel/Projects/salmon-0.13.1/build /Users/gabriel/Projects/salmon-0.13.1/build /Users/gabriel/Projects/salmon-0.13.1/build/CMakeFiles/libstadenio.dir/DependInfo.cmake --color=; /Applications/Xcode.app/Contents/Developer/usr/bin/make -f CMakeFiles/libstadenio.dir/build.make CMakeFiles/libstadenio.dir/build; [ 9%] Performing configure step for 'libstadenio'; cd /Users/gabriel/Projects/salmon-0.13.1/external/staden-io_lib && ./configure --enable-shared=no --without-libcurl --prefix=/Users/gabriel/Projects/salmon-0.13.1/external/install LDFLAGS= CFLAGS= CC=/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/cc CXX=/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/c++; checking for a BSD-compatible install... /usr/local/bin/ginstall -c; checking whether build environment is sane... yes; checking for a thread-safe mkdir -p... /usr/local/bin/gmkdir -p; checking for gawk... gawk; checking whether make sets $(MAKE)... yes; checking whether make supports nested variables... yes; checking whether to enable maintainer-specific portions of Makefiles... no; checking for gcc... /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/cc; checking whether the C compiler works... yes; checking for C compiler default output file name... a.out; checking for suffix of executables...; checking whether we are cross compiling... configure: error: in `/Users/gabriel/Proje",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/348#issuecomment-472500713:2056,config,configure,2056,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/348#issuecomment-472500713,1,['config'],['configure']
Modifiability,"p TBB CMakeCache.txt; //TBB debug library directory; TBB_DEBUG_LIBRARY_DIRS:PATH=; TBB_INCLUDE_DIR:PATH=/home/ryan/src/salmon/external/install/include; //TBB include directory; TBB_INCLUDE_DIRS:PATH=/home/ryan/src/salmon/external/install/include; TBB_LIBRARY:FILEPATH=/home/ryan/src/salmon/external/install/lib/libtbb.so; TBB_LIBRARY_DEBUG:FILEPATH=TBB_LIBRARY_DEBUG-NOTFOUND; //TBB library directory; TBB_LIBRARY_DIRS:PATH=/home/ryan/src/salmon/external/install/lib; TBB_MALLOC_LIBRARY:FILEPATH=/home/ryan/src/salmon/external/install/lib/libtbbmalloc.so; TBB_MALLOC_LIBRARY_DEBUG:FILEPATH=TBB_MALLOC_LIBRARY_DEBUG-NOTFOUND; TBB_RECONFIGURE:UNINITIALIZED=TRUE; TBB_WILL_RECONFIGURE:UNINITIALIZED=FALSE; //ADVANCED property for variable: TBB_DEBUG_LIBRARY_DIRS; TBB_DEBUG_LIBRARY_DIRS-ADVANCED:INTERNAL=1; //ADVANCED property for variable: TBB_INCLUDE_DIR; TBB_INCLUDE_DIR-ADVANCED:INTERNAL=1; //ADVANCED property for variable: TBB_INCLUDE_DIRS; TBB_INCLUDE_DIRS-ADVANCED:INTERNAL=1; //ADVANCED property for variable: TBB_LIBRARY; TBB_LIBRARY-ADVANCED:INTERNAL=1; //ADVANCED property for variable: TBB_LIBRARY_DEBUG; TBB_LIBRARY_DEBUG-ADVANCED:INTERNAL=1; //ADVANCED property for variable: TBB_LIBRARY_DIRS; TBB_LIBRARY_DIRS-ADVANCED:INTERNAL=1; //ADVANCED property for variable: TBB_MALLOC_LIBRARY; TBB_MALLOC_LIBRARY-ADVANCED:INTERNAL=1; //ADVANCED property for variable: TBB_MALLOC_LIBRARY_DEBUG; TBB_MALLOC_LIBRARY_DEBUG-ADVANCED:INTERNAL=1; ```. Also, here's the output of every hardware/OS reporting command I can think of:. ```; $ cat /proc/cpuinfo; processor : 0; vendor_id : GenuineIntel; cpu family : 6; model : 63; model name : Intel(R) Xeon(R) CPU E5-2623 v3 @ 3.00GHz; stepping : 2; microcode : 0x36; cpu MHz : 3300.000; cache size : 10240 KB; physical id : 0; siblings : 8; core id : 0; cpu cores : 4; apicid : 0; initial apicid : 0; fpu : yes; fpu_exception : yes; cpuid level : 15; wp : yes; flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36; clflush dts a",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-266953657:813,variab,variable,813,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-266953657,8,['variab'],['variable']
Modifiability,"p.so.1 (0x00007f859a7e7000); librt.so.1 => /lib/x86_64-linux-gnu/librt.so.1 (0x00007f859a5df000); libm.so.6 => /lib/x86_64-linux-gnu/libm.so.6 (0x00007f859a2de000); libgcc_s.so.1 => /u/user/local/lib64/libgcc_s.so.1 (0x00007f859a0c8000); libc.so.6 => /lib/x86_64-linux-gnu/libc.so.6 (0x00007f8599d1d000); /lib64/ld-linux-x86-64.so.2 (0x00007f859b286000); libdl.so.2 => /lib/x86_64-linux-gnu/libdl.so.2 (0x00007f8599b19000); libstdc++.so.6 => /u/user/local/lib64/libstdc++.so.6 (0x00007f859979f000); ```. The linux version and g++ version are listed below:; ```; cat /proc/version; Linux version 4.9.0-0.bpo.6-amd64 (debian-kernel@lists.debian.org) (gcc version 4.9.2 (Debian 4.9.2-10+deb8u1) ) #1 SMP Debian 4.9.82-1+deb9u3~bpo8+1 (2018-03-22). ~/data/PCSI/PC10X/paper/pbmc$ g++ -v; Using built-in specs.; COLLECT_GCC=g++; COLLECT_LTO_WRAPPER=/u/user/local/libexec/gcc/x86_64-unknown-linux-gnu/5.4.0/lto-wrapper; Target: x86_64-unknown-linux-gnu; Configured with: ./configure --prefix=/u/user/local; Thread model: posix; gcc version 5.4.0 (GCC); ```. ```; [Thread debugging using libthread_db enabled]; Using host libthread_db library ""/lib/x86_64-linux-gnu/libthread_db.so.1"".; warning: File ""/u/user/local/lib64/libstdc++.so.6.0.21-gdb.py"" auto-loading has been declined by your `auto-load safe-path' set to ""$debugdir:$datadir/auto-load"".; To enable execution of this file add; add-auto-load-safe-path /u/user/local/lib64/libstdc++.so.6.0.21-gdb.py; line to your configuration file ""/u/user/.gdbinit"".; To completely disable this security protection add; set auto-load safe-path /; line to your configuration file ""/u/user/.gdbinit"".; For more information about this security protection see the; ""Auto-loading safe path"" section in the GDB manual. E.g., run from the shell:; info ""(gdb)Auto-loading safe path""; [New Thread 0x7fff7e0f4700 (LWP 14274)]; Version Info: ### A newer version of Salmon is available. ####; [Thread 0x7fff7e0f4700 (LWP 14274) exited]; ###; The newest version, available at",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-395836214:1870,config,configure,1870,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-395836214,1,['config'],['configure']
Modifiability,"quality-trimming, because if you do quality-trimming first, sometimes adapters will be partially trimmed and become too short to be recognized as adapter sequence. When you run BBDuk with both quality-trimming and adapter-trimming in the same run, it will do adapter-trimming first, then quality-trimming. 2. I very well know that the advantage of using fastp is that it can do adapter trimming, etc in a automatic fashion - no need to provide external sequences (example adapter sequences). Yes, I know one can also provide a fasta file of adapters and fatsp will work off it. There are many fatsp issues in GH about adapter detection:. - fail to detect adpaters automatically - (https://github.com/OpenGene/fastp/issues/222 and https://github.com/OpenGene/fastp/issues/205). - [incorrect automatic adapter detection](https://github.com/OpenGene/fastp/issues/240). - [inconsistent behavior with different runs](https://github.com/OpenGene/fastp/issues/231). 3. When I see the above, I am bit skeptical using fastp for qc/adapter trimming. . After lot of trials with bbduk and fastp, I have decided to use bbduk and bbmap for my high throughput analysis. Below, I explain my reasoning behind those choices: . **_```Note - edited this on 02-Apr-2020 to have the correct order of operations ```_** . 1. **_STEP 1 - run bbmap.sh on raw fatsq file to remove contaminants as appropriate (rRNA, mitochondrial, chloroplast)_**; - You have alluded to the importance of removing contaminants [in this post](https://github.com/COMBINE-lab/salmon/issues/160#issuecomment-334762498); >However, the other thing to try is simply to align one of these samples to the genome with a tool like STAR or HISAT2 and look at their mapping rate to known features. If it's similar, then the other reads could be accounted for by e.g. intron retention or even contamination. Finally, [@vals has an excellent series of blog posts on investigating and addressing low mapping rates](http://www.nxn.se/valent/2017/9/18/low-mappin",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-597393209:1805,adapt,adapter,1805,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-597393209,1,['adapt'],['adapter']
Modifiability,"quest('GET', url, **kwargs); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/requests/sessions.py"", line 529, in request; resp = self.send(prep, **send_kwargs); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/requests/sessions.py"", line 645, in send; r = adapter.send(request, **kwargs); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/requests/adapters.py"", line 413, in send; conn = self.get_connection(request.url, proxies); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/requests/adapters.py"", line 308, in get_connection; raise InvalidProxyURL(""Please check proxy URL. It is malformed""; requests.exceptions.InvalidProxyURL: Please check proxy URL. It is malformed and could be missing the host. `$ /usr/local/bin/conda install salmon`. environment variables:; CIO_TEST=<not set>; CONDA_ROOT=/usr/local/Caskroom/miniforge/base; CURL_CA_BUNDLE=<not set>; INFOPATH=/opt/homebrew/share/info:; MANPATH=/opt/homebrew/share/man::; PATH=/opt/homebrew/bin:/opt/homebrew/sbin:/usr/local/bin:/usr/bin:/bin:/usr; /sbin:/sbin; REQUESTS_CA_BUNDLE=<not set>; SSL_CERT_FILE=<not set>; all_proxy=<set>. active environment : None; user config file : /Users/Benjamin/.condarc; populated config files : /usr/local/Caskroom/miniforge/base/.condarc; conda version : 4.12.0; conda-build version : not installed; python version : 3.9.13.final.0; virtual packages : __osx=12.4=0; __unix=0=0; __archspec=1=arm64; base environment : /usr/local/Caskroom/miniforge/base (writable); conda av data dir : /usr/local/Caskroom/miniforge/base/etc/conda; conda av metadata url : None; channel URLs : https://conda.anaconda.org/conda-forge/osx-arm64; https://conda.anaconda.org/conda-forge/noarch; package cache : /usr/local/Caskroom/miniforge/base/pkgs; /Users/Benjamin/.conda/pkgs; envs directories : /usr/local/Caskroom/miniforge/base/envs; /Users/Benjamin/.conda/envs; platform : osx-arm64; user-agent : conda/4.12.0 requests/2.27.1 CPython/3.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/724#issuecomment-1171208515:4952,variab,variables,4952,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/724#issuecomment-1171208515,1,['variab'],['variables']
Modifiability,"r -xz --strip-components 1; cmake -DBOOST_ROOT=/global/software/sl-7.x86_64/modules/gcc/7.4.0/boost/1.70.0-gcc -DCMAKE_INSTALL_PREFIX=$INSTALL_DIR; make; ```; And the tail of the output from make:. ```; creating: /clusterfs/vector/home/groups/software/sl-7.x86_64/source/salmon/1.5.1/scripts/../external/pufferfish-salmon-v1.5.1/tests/compile_tests/; inflating: /clusterfs/vector/home/groups/software/sl-7.x86_64/source/salmon/1.5.1/scripts/../external/pufferfish-salmon-v1.5.1/tests/compile_tests/int128_numeric_limits.cpp ; -- fetch PUFFERFISH exit code 0; -- Found ZLIB: /usr/lib64/libz.so (found version ""1.2.11"") ; -- Performing Test Iconv_IS_BUILT_IN; -- Performing Test Iconv_IS_BUILT_IN - Failed; CMake Error at /global/home/groups/consultsw/sl-7.x86_64/modules/cmake/3.15.1/share/cmake-3.15/Modules/FindPackageHandleStandardArgs.cmake:137 (message):; Could NOT find Iconv (missing: Iconv_LIBRARY); Call Stack (most recent call first):; /global/home/groups/consultsw/sl-7.x86_64/modules/cmake/3.15.1/share/cmake-3.15/Modules/FindPackageHandleStandardArgs.cmake:378 (_FPHSA_FAILURE_MESSAGE); /global/home/groups/consultsw/sl-7.x86_64/modules/cmake/3.15.1/share/cmake-3.15/Modules/FindIconv.cmake:120 (find_package_handle_standard_args); CMakeLists.txt:362 (find_package). -- Configuring incomplete, errors occurred!; See also ""/clusterfs/vector/home/groups/software/sl-7.x86_64/source/salmon/1.5.1/CMakeFiles/CMakeOutput.log"".; See also ""/clusterfs/vector/home/groups/software/sl-7.x86_64/source/salmon/1.5.1/CMakeFiles/CMakeError.log"".; ```; I'm also attaching the full CMake logs. This is right at the edge of my knowledge, so I'm not 100% sure I got libiconv installed correctly. Compilation completed without error, and I added the bin, include, and lib directories to PATH, CPATH, and LD_LIBRARY_PATH, respectively. [CMakeError.log](https://github.com/COMBINE-lab/salmon/files/6665942/CMakeError.log); [CMakeOutput.log](https://github.com/COMBINE-lab/salmon/files/6665943/CMakeOutput.log)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/453#issuecomment-862737315:2427,Config,Configuring,2427,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/453#issuecomment-862737315,1,['Config'],['Configuring']
Modifiability,"r_data.py"", line 145, in query; self.load(); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/conda/core/subdir_data.py"", line 210, in load; _internal_state = self._load(); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/conda/core/subdir_data.py"", line 375, in _load; raw_repodata_str = fetch_repodata_remote_request(; File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/conda/core/subdir_data.py"", line 701, in fetch_repodata_remote_request; resp = session.get(join_url(url, filename), headers=headers, proxies=session.proxies,; File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/requests/sessions.py"", line 542, in get; return self.request('GET', url, **kwargs); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/requests/sessions.py"", line 529, in request; resp = self.send(prep, **send_kwargs); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/requests/sessions.py"", line 645, in send; r = adapter.send(request, **kwargs); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/requests/adapters.py"", line 413, in send; conn = self.get_connection(request.url, proxies); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/requests/adapters.py"", line 308, in get_connection; raise InvalidProxyURL(""Please check proxy URL. It is malformed""; requests.exceptions.InvalidProxyURL: Please check proxy URL. It is malformed and could be missing the host. `$ /usr/local/bin/conda install salmon`. environment variables:; CIO_TEST=<not set>; CONDA_ROOT=/usr/local/Caskroom/miniforge/base; CURL_CA_BUNDLE=<not set>; INFOPATH=/opt/homebrew/share/info:; MANPATH=/opt/homebrew/share/man::; PATH=/opt/homebrew/bin:/opt/homebrew/sbin:/usr/local/bin:/usr/bin:/bin:/usr; /sbin:/sbin; REQUESTS_CA_BUNDLE=<not set>; SSL_CERT_FILE=<not set>; all_proxy=<set>. active environment : None; user config file : /Users/Benjamin/.condarc; populated config files : /usr/local/Cas",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/724#issuecomment-1171208515:4411,adapt,adapter,4411,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/724#issuecomment-1171208515,1,['adapt'],['adapter']
Modifiability,"ranscriptome (with no decoys) gives me a mapping rate of `0.00378202832148367%`. The first thing I did was to quality and adapter trim the data (using `fastp -i SRR9007475.fastq.gz -o SRR9007475_trimmed.fastq.gz -q 10 -w 8`) and ... whoa. This is the fastp html report [fastp.html.zip](https://github.com/COMBINE-lab/salmon/files/4176345/fastp.html.zip). So the first astounding statistic, the mean read length before trimming is 51bp (these are relatively short single-end reads). The mean read length after trimming is 21bp! So, the average read length is, in fact, less than the k-mer length used for indexing (default is k=31). On the trimmed data, the mapping rate goes up to `2.3545475882931305%`, still very low, but now there's somewhat of an explanation, the average read is shorter than a single k-mer. So, the next thing I tried was indexing with a smaller k; a _really_ small one in this case,`k=15`. Then, I re-ran on the _trimmed_ reads (the fact that the trimming took us from 51-21bp suggests that the reads had a lot of low quality bases, adapter contamination, or both). Under this setting, I still get a very low mapping rate, but it was _much_ higher — `16.766993524863488%`. The final thing I tried was seeing how the mapping rate changed as I altered `--minScoreFraction`, which is the salmon parameter that determines the alignment score that a read must achieve in order to be mapped validly. The default is 0.65. This means that the read cannot have a score < 0.65 * the maximum achievable score for the read given it's length. In the case of a 21bp read, the best score would be a score of 42, so a read must obtain a score >= 27 in order to be mapped. This is already a pretty poor mapping, but I reduced it even more to 0.3 (so any read with a score > 12 would pass). This led to a mapping rate of `~46%`. However, at this point, I'm not sure I would be confident in such mappings. For example, the situation here would be a 21bp read with multiple mismatches and, much of",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/482#issuecomment-583799668:1452,adapt,adapter,1452,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/482#issuecomment-583799668,1,['adapt'],['adapter']
Modifiability,"referred to as QS in the rest of the message(s))_ ?. `salmon quant --threads 16 --noLengthCorrection --validateMappings --numBootstraps 100 -l SF -i <path_to_SAF_Gentrome_Index> -r <SE_READ_1.fq> -o <salmon_SE_READ_1>`. I chose the above command line options (`especially --noLengthCorrection`) based on [Rob's message here](https://groups.google.com/d/msg/sailfish-users/VIfqBwgF6xQ/fw-rgC_kAwAJ) and a [thread here](https://github.com/COMBINE-lab/salmon/issues/108). Let me elaborate the big picture of my analyses and give more details about how I came up with the mapping numbers in my original post. Big Picture - DEG identification for samples sequenced by ILMN (whole transcript method) and QS (3' method) - [something similar to this paper](https://bmcgenomics.biomedcentral.com/articles/10.1186/s12864-018-5393-3). Bioinformatics Pipeline(s) for both ILMN and QS :. 1. HISAT Method : Adapter/Quality Trimming, Hisat2-HTSEQ, Get_Count_Table, DESeq; 2. STAR_RSEM Method: Adapter/Quality Trimming, STAR_RSEM, Get_Count_Table, DESeq; 3. SAF Method: Adapter/Quality Trimming, SAF_SALMON, Get_Count_Table, DESeq; 4. Quasi-Mapping or TXOME Method: Adapter/Quality Trimming, TXOME_SALMON, Get_Count_Table, DESeq. I used UpSetR plots for comparisons of sets of DEGs from each method just [as you have shown in your recent preprint](https://www.biorxiv.org/content/10.1101/657874v1.full). In the ILMN analyses, there is great concordance between the SAF method and HISAT/STAR_RSEM method. However, in the QS analyses, there is very limited concordance between SAF and the HISAT/STAR_RSEM method. For QS analyses, the TXOME method shows great concordance with HISAT/STAR_RSEM. This finding made me wonder if this has to be something with my salmon quant command line options for QS. Therefore, I wanted to check how the QS expected counts for SAF method show up for all samples in my final summarized table (after tximport). I got a colSum for all my samples and then checked the numbers for the transc",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-554768195:1101,Adapt,Adapter,1101,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-554768195,1,['Adapt'],['Adapter']
Modifiability,"rge/base/lib/python3.9/site-packages/requests/adapters.py"", line 308, in get_connection; raise InvalidProxyURL(""Please check proxy URL. It is malformed""; requests.exceptions.InvalidProxyURL: Please check proxy URL. It is malformed and could be missing the host. `$ /usr/local/bin/conda install salmon`. environment variables:; CIO_TEST=<not set>; CONDA_ROOT=/usr/local/Caskroom/miniforge/base; CURL_CA_BUNDLE=<not set>; INFOPATH=/opt/homebrew/share/info:; MANPATH=/opt/homebrew/share/man::; PATH=/opt/homebrew/bin:/opt/homebrew/sbin:/usr/local/bin:/usr/bin:/bin:/usr; /sbin:/sbin; REQUESTS_CA_BUNDLE=<not set>; SSL_CERT_FILE=<not set>; all_proxy=<set>. active environment : None; user config file : /Users/Benjamin/.condarc; populated config files : /usr/local/Caskroom/miniforge/base/.condarc; conda version : 4.12.0; conda-build version : not installed; python version : 3.9.13.final.0; virtual packages : __osx=12.4=0; __unix=0=0; __archspec=1=arm64; base environment : /usr/local/Caskroom/miniforge/base (writable); conda av data dir : /usr/local/Caskroom/miniforge/base/etc/conda; conda av metadata url : None; channel URLs : https://conda.anaconda.org/conda-forge/osx-arm64; https://conda.anaconda.org/conda-forge/noarch; package cache : /usr/local/Caskroom/miniforge/base/pkgs; /Users/Benjamin/.conda/pkgs; envs directories : /usr/local/Caskroom/miniforge/base/envs; /Users/Benjamin/.conda/envs; platform : osx-arm64; user-agent : conda/4.12.0 requests/2.27.1 CPython/3.9.13 Darwin/21.5.0 OSX/12.4; UID:GID : 501:20; netrc file : None; offline mode : False. An unexpected error has occurred. Conda has prepared the above report. If submitted, this report will be used by core maintainers to improve; future releases of conda.; Would you like conda to send this report to the core maintainers?. [y/N]: y; Upload did not complete. Thank you for helping to improve conda.; Opt-in to always sending reports (and not see this message again); by running. $ conda config --set report_errors true; ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/724#issuecomment-1171208515:6601,config,config,6601,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/724#issuecomment-1171208515,1,['config'],['config']
Modifiability,"so.2 (0x00007f859aa08000); libgomp.so.1 => /u/user/local/lib64/libgomp.so.1 (0x00007f859a7e7000); librt.so.1 => /lib/x86_64-linux-gnu/librt.so.1 (0x00007f859a5df000); libm.so.6 => /lib/x86_64-linux-gnu/libm.so.6 (0x00007f859a2de000); libgcc_s.so.1 => /u/user/local/lib64/libgcc_s.so.1 (0x00007f859a0c8000); libc.so.6 => /lib/x86_64-linux-gnu/libc.so.6 (0x00007f8599d1d000); /lib64/ld-linux-x86-64.so.2 (0x00007f859b286000); libdl.so.2 => /lib/x86_64-linux-gnu/libdl.so.2 (0x00007f8599b19000); libstdc++.so.6 => /u/user/local/lib64/libstdc++.so.6 (0x00007f859979f000); ```. The linux version and g++ version are listed below:; ```; cat /proc/version; Linux version 4.9.0-0.bpo.6-amd64 (debian-kernel@lists.debian.org) (gcc version 4.9.2 (Debian 4.9.2-10+deb8u1) ) #1 SMP Debian 4.9.82-1+deb9u3~bpo8+1 (2018-03-22). ~/data/PCSI/PC10X/paper/pbmc$ g++ -v; Using built-in specs.; COLLECT_GCC=g++; COLLECT_LTO_WRAPPER=/u/user/local/libexec/gcc/x86_64-unknown-linux-gnu/5.4.0/lto-wrapper; Target: x86_64-unknown-linux-gnu; Configured with: ./configure --prefix=/u/user/local; Thread model: posix; gcc version 5.4.0 (GCC); ```. ```; [Thread debugging using libthread_db enabled]; Using host libthread_db library ""/lib/x86_64-linux-gnu/libthread_db.so.1"".; warning: File ""/u/user/local/lib64/libstdc++.so.6.0.21-gdb.py"" auto-loading has been declined by your `auto-load safe-path' set to ""$debugdir:$datadir/auto-load"".; To enable execution of this file add; add-auto-load-safe-path /u/user/local/lib64/libstdc++.so.6.0.21-gdb.py; line to your configuration file ""/u/user/.gdbinit"".; To completely disable this security protection add; set auto-load safe-path /; line to your configuration file ""/u/user/.gdbinit"".; For more information about this security protection see the; ""Auto-loading safe path"" section in the GDB manual. E.g., run from the shell:; info ""(gdb)Auto-loading safe path""; [New Thread 0x7fff7e0f4700 (LWP 14274)]; Version Info: ### A newer version of Salmon is available. ####; [Thread 0x7ff",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-395836214:1851,Config,Configured,1851,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-395836214,1,['Config'],['Configured']
Modifiability,"so.6 (0x00007f859979f000); ```. The linux version and g++ version are listed below:; ```; cat /proc/version; Linux version 4.9.0-0.bpo.6-amd64 (debian-kernel@lists.debian.org) (gcc version 4.9.2 (Debian 4.9.2-10+deb8u1) ) #1 SMP Debian 4.9.82-1+deb9u3~bpo8+1 (2018-03-22). ~/data/PCSI/PC10X/paper/pbmc$ g++ -v; Using built-in specs.; COLLECT_GCC=g++; COLLECT_LTO_WRAPPER=/u/user/local/libexec/gcc/x86_64-unknown-linux-gnu/5.4.0/lto-wrapper; Target: x86_64-unknown-linux-gnu; Configured with: ./configure --prefix=/u/user/local; Thread model: posix; gcc version 5.4.0 (GCC); ```. ```; [Thread debugging using libthread_db enabled]; Using host libthread_db library ""/lib/x86_64-linux-gnu/libthread_db.so.1"".; warning: File ""/u/user/local/lib64/libstdc++.so.6.0.21-gdb.py"" auto-loading has been declined by your `auto-load safe-path' set to ""$debugdir:$datadir/auto-load"".; To enable execution of this file add; add-auto-load-safe-path /u/user/local/lib64/libstdc++.so.6.0.21-gdb.py; line to your configuration file ""/u/user/.gdbinit"".; To completely disable this security protection add; set auto-load safe-path /; line to your configuration file ""/u/user/.gdbinit"".; For more information about this security protection see the; ""Auto-loading safe path"" section in the GDB manual. E.g., run from the shell:; info ""(gdb)Auto-loading safe path""; [New Thread 0x7fff7e0f4700 (LWP 14274)]; Version Info: ### A newer version of Salmon is available. ####; [Thread 0x7fff7e0f4700 (LWP 14274) exited]; ###; The newest version, available at https://github.com/COMBINE-lab/salmon/releases; contains new features, improvements, and bug fixes; please upgrade at your; earliest convenience.; ###; [New Thread 0x7fff7d273700 (LWP 14275)]; Logs will be written to pbmc4k/alevin/logs; [New Thread 0x7ffefc3f1700 (LWP 14276)]; [New Thread 0x7ffe7b56f700 (LWP 14277)]; [New Thread 0x7ffdfa6ed700 (LWP 14278)]; ### salmon (single-cell-based) v0.10.1; ### [ program ] => salmon; ### [ command ] => alevin; ### [ libType ] =",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-395836214:2370,config,configuration,2370,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-395836214,1,['config'],['configuration']
Modifiability,"ssue and comments therein](https://github.com/COMBINE-lab/salmon/issues/489)). The second and more fundamental thing going on is that the observed behavior is intended. Even with a single thread of execution provided to salmon for mapping and quantification, there is a separate background thread that simply consumes reads from file and puts them in memory for quantification, and while e.g. pairing information between files is guaranteed to be preserved, exact read order is not. This can lead to differences in the order in which reads are processed and, as a result, differences in the initialization conditions of the optimization. The ultimate result is that for transcripts that have large inferential uncertainty, different numbers of reads can be assigned between runs. We have thought *a lot* about this behavior, what it means, and how the `NumRead` values should best be communicated to users. At the end of the day, the `NumReads` constitute the expected value of latent variables inferred in a _very_ high-dimensional space (# of parameters is at least the number of transcripts). Therefore, there are certain transcripts, whose estimated number of reads simply have _tremendous_ inferential uncertainty — and small perturbations in the initial conditions of the optimization will lead to different estimated values for their abundances. For those transcripts where you observe such fluctuations between runs, this is simply evidence that the precision that can be confidently placed on those estimates is below the degree of variation you observe. Treating these transcripts in downstream analysis as more certain can easily lead to spurious inferences regarding things like differential transcript expression or usage. . One can make an argument for trying to provide a way to enforce removal of this variation (which, granted, would be a challenge). However, the reason we decided against even attempting this is because it doesn't properly address any issue with respect to an actua",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/613#issuecomment-757989858:1568,variab,variables,1568,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/613#issuecomment-757989858,1,['variab'],['variables']
Modifiability,"t (6) at /usr/local/trinityrnaseq-Trinity-v2.6.6/util/support_scripts/../../PerlLib/Process_cmd.pm line 19.; Process_cmd::process_cmd(""salmon --no-version-check quant -i /home/federicoplazzi/test_""...) called at /usr/local/trinityrnaseq-Trinity-v2.6.6/util/support_scripts/salmon_runner.pl line 26; Trinity run failed. Must investigate error above.; warning, cmd: /usr/local/trinityrnaseq-Trinity-v2.6.6/util/support_scripts/../../Trinity --single ""/home/federicoplazzi/test_Trinity_Assembly/trinity_out_dir/read_partitions/Fb_0/CBin_0/c30.trinity.reads.fa"" --output ""/home/federicoplazzi/test_Trinity_Assembly/trinity_out_dir/read_partitions/Fb_0/CBin_0/c30.trinity.reads.fa.out"" --CPU 1 --max_memory 1G --run_as_paired --SS_lib_type F --seqType fa --trinity_complete --full_cleanup failed with ret: 512, going to retry.; succeeded(0), failed(1) 100% completed. We are sorry, commands in file: [FailedCommands] failed. :-(. Error, cmd: /usr/local/trinityrnaseq-Trinity-v2.6.6/trinity-plugins/BIN/ParaFly -c recursive_trinity.cmds -CPU 4 -v -shuffle died with ret 256 at /usr/local/bin/Trinity line 2581.; main::process_cmd(""/usr/local/trinityrnaseq-Trinity-v2.6.6/trinity-plugins/BIN/P""...) called at /usr/local/bin/Trinity line 3244; main::run_partitioned_cmds(""recursive_trinity.cmds"") called at /usr/local/bin/Trinity line 2239; main::run_recursive_trinity(""/home/federicoplazzi/test_Trinity_Assembly/trinity_out_dir/ch""...) called at /usr/local/bin/Trinity line 2001; main::run_chrysalis(""/home/federicoplazzi/test_Trinity_Assembly/trinity_out_dir/in""..., ""/home/federicoplazzi/test_Trinity_Assembly/trinity_out_dir/bo""..., 200, 500, ""RF"", ""/home/federicoplazzi/test_Trinity_Assembly/trinity_out_dir/bo""..., ""/home/federicoplazzi/test_Trinity_Assembly/trinity_out_dir/bo""...) called at /usr/local/bin/Trinity line 1664; main::run_Trinity() called at /usr/local/bin/Trinity line 1317; eval {...} called at /usr/local/bin/Trinity line 1316. Trinity run failed. Must investigate error above.; ```. D",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/235#issuecomment-398081403:3066,plugin,plugins,3066,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/235#issuecomment-398081403,1,['plugin'],['plugins']
Modifiability,"ted to ""word""...; Reading symbols from /u/user/local/bin/salmon...done.; (gdb) run alevin -l ISR --chromium -p 4 -o BM_1/alevin -1 ./BM_1/run1/bm_S10_L001_R1_001.fastq.gz -2 ./BM_1/run1/bm_S10_L001_R2_001.fastq.gz --maxHashResizeThreads 2 -i /u/user/ref/cellranger/salmon/transcripts_index --tgMap tx2gene.txt; Starting program: /u/user/local/bin/salmon alevin -l ISR --chromium -p 4 -o BM_1/alevin -1 ./BM_1/run1/bm_S10_L001_R1_001.fastq.gz -2 ./BM_1/run1/bm_S10_L001_R2_001.fastq.gz --maxHashResizeThreads 2 -i /u/user/ref/cellranger/salmon/transcripts_index --tgMap tx2gene.txt; [Thread debugging using libthread_db enabled]; Using host libthread_db library ""/lib/x86_64-linux-gnu/libthread_db.so.1"".; warning: File ""/u/user/local/lib64/libstdc++.so.6.0.21-gdb.py"" auto-loading has been declined by your `auto-load safe; -path' set to ""$debugdir:$datadir/auto-load"".; To enable execution of this file add; add-auto-load-safe-path /u/user/local/lib64/libstdc++.so.6.0.21-gdb.py; line to your configuration file ""/u/user/.gdbinit"".; To completely disable this security protection add; set auto-load safe-path /; line to your configuration file ""/u/user/.gdbinit"".; For more information about this security protection see the; ""Auto-loading safe path"" section in the GDB manual. E.g., run from the shell:; info ""(gdb)Auto-loading safe path""; [New Thread 0x7fff7dbff700 (LWP 21437)]; [Thread 0x7fff7dbff700 (LWP 21437) exited]; Version Info: Could not resolve upgrade information in the alotted time.; Check for upgrades manually at https://combine-lab.github.io/salmon; [New Thread 0x7ffefcfff700 (LWP 21653)]; Logs will be written to BM_1/alevin/logs; [New Thread 0x7ffe7cffe700 (LWP 21654)]; [New Thread 0x7ffdfcffd700 (LWP 21655)]; [New Thread 0x7ffd7cffc700 (LWP 21656)]; ### salmon (single-cell-based) v0.10.3; ### [ program ] => salmon; ### [ command ] => alevin; ### [ libType ] => { ISR }; ### [ chromium ] => { }; ### [ threads ] => { 4 }; ### [ output ] => { BM_1/alevin }; ### [ mates1 ] =",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-396078627:1939,config,configuration,1939,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-396078627,1,['config'],['configuration']
Modifiability,"ubdir_data.py"", line 375, in _load; raw_repodata_str = fetch_repodata_remote_request(; File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/conda/core/subdir_data.py"", line 701, in fetch_repodata_remote_request; resp = session.get(join_url(url, filename), headers=headers, proxies=session.proxies,; File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/requests/sessions.py"", line 542, in get; return self.request('GET', url, **kwargs); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/requests/sessions.py"", line 529, in request; resp = self.send(prep, **send_kwargs); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/requests/sessions.py"", line 645, in send; r = adapter.send(request, **kwargs); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/requests/adapters.py"", line 413, in send; conn = self.get_connection(request.url, proxies); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/requests/adapters.py"", line 308, in get_connection; raise InvalidProxyURL(""Please check proxy URL. It is malformed""; requests.exceptions.InvalidProxyURL: Please check proxy URL. It is malformed and could be missing the host. `$ /usr/local/bin/conda install salmon`. environment variables:; CIO_TEST=<not set>; CONDA_ROOT=/usr/local/Caskroom/miniforge/base; CURL_CA_BUNDLE=<not set>; INFOPATH=/opt/homebrew/share/info:; MANPATH=/opt/homebrew/share/man::; PATH=/opt/homebrew/bin:/opt/homebrew/sbin:/usr/local/bin:/usr/bin:/bin:/usr; /sbin:/sbin; REQUESTS_CA_BUNDLE=<not set>; SSL_CERT_FILE=<not set>; all_proxy=<set>. active environment : None; user config file : /Users/Benjamin/.condarc; populated config files : /usr/local/Caskroom/miniforge/base/.condarc; conda version : 4.12.0; conda-build version : not installed; python version : 3.9.13.final.0; virtual packages : __osx=12.4=0; __unix=0=0; __archspec=1=arm64; base environment : /usr/local/Caskroom/miniforge/base (writable); conda av data dir ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/724#issuecomment-1171208515:4683,adapt,adapters,4683,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/724#issuecomment-1171208515,1,['adapt'],['adapters']
Performance,"[32mprocessed[31m 66000000 [32mfragments[0m; hits: 92174292, hits per frag: 1.39669[A. [32mprocessed[31m 66500000 [32mfragments[0m; hits: 92872684, hits per frag: 1.39669[A. [32mprocessed[31m 67000000 [32mfragments[0m; hits: 93570589, hits per frag: 1.39668[A. [32mprocessed[31m 67500000 [32mfragments[0m; hits: 94262793, hits per frag: 1.39659[A. [32mprocessed[31m 68000000 [32mfragments[0m; hits: 94956043, hits per frag: 1.39652[A. [32mprocessed[31m 68500000 [32mfragments[0m; hits: 95648744, hits per frag: 1.39643. [1m[2017-03-30 11:30:33.005] [jointLog] [info] Computed 505448 rich equivalence classes for further processing; [00m[1m[2017-03-30 11:30:33.005] [jointLog] [info] Counted 30438349 total reads in the equivalence classes ; [00m. [1m[2017-03-30 11:30:50.309] [jointLog] [info] Mapping rate = 44.3635%. [00m[1m[2017-03-30 11:30:50.309] [jointLog] [info] finished quantifyLibrary(); [00m[1m[2017-03-30 11:30:56.208] [jointLog] [info] Starting optimizer; [00m[1m[2017-03-30 11:32:15.204] [jointLog] [info] Marked 4 weighted equivalence classes as degenerate; [00m[1m[2017-03-30 11:32:15.413] [jointLog] [info] iteration = 0 | max rel diff. = 13.3708; [00m[1m[2017-03-30 11:32:31.128] [jointLog] [info] iteration = 100 | max rel diff. = 0.096809; [00m[1m[2017-03-30 11:32:46.546] [jointLog] [info] iteration = 200 | max rel diff. = 0.0617045; [00m[1m[2017-03-30 11:33:01.476] [jointLog] [info] iteration = 300 | max rel diff. = 0.0375335; [00m[1m[2017-03-30 11:33:16.917] [jointLog] [info] iteration = 400 | max rel diff. = 0.0281626; [00m[1m[2017-03-30 11:33:32.635] [jointLog] [info] iteration = 500 | max rel diff. = 0.0213515; [00m[1m[2017-03-30 11:33:48.229] [jointLog] [info] iteration = 600 | max rel diff. = 0.0163419; [00m[1m[2017-03-30 11:34:05.482] [jointLog] [info] iteration = 700 | max rel diff. = 0.0161512; [00m[1m[2017-03-30 11:34:22.202] [jointLog] [info] iteration = 800 | max rel diff. = 0.0161512; [00m[1m[2",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-290516965:23684,optimiz,optimizer,23684,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-290516965,1,['optimiz'],['optimizer']
Performance," # [ index ] => { /nfs/research2/teichmann/reference/mus-musculus/salmon/quasi/mouse_cdna_38.p3.78_repbase_ercc.fa }; # [ libType ] => { IU }; # [ mates1 ] => { /nfs/research2/teichmann/valentine/detection-comparison/salmon0.4.2-comparison/mouse/SRP057125_SRS936134_1.fastq }; # [ mates2 ] => { /nfs/research2/teichmann/valentine/detection-comparison/salmon0.4.2-comparison/mouse/SRP057125_SRS936134_2.fastq }; # [ output ] => { SRP057125_SRS936134_salmon_out }; # [ geneMap ] => { /nfs/research2/teichmann/reference/mus-musculus/salmon/mouse_cdna38.78_repbase_ercc_index_gene_map.txt }; # [ biasCorrect ] => { }; # [ useFSPD ] => { }; Logs will be written to SRP057125_SRS936134_salmon_out/logs; [2016-01-02 20:22:59.800] [jointLog] [info] parsing read library format; there is 1 lib; Loading 32-bit quasi index[2016-01-02 20:23:00.830] [stderrLog] [info] Loading Suffix Array; [2016-01-02 20:23:00.830] [stderrLog] [info] Loading Position Hash; [2016-01-02 20:23:00.829] [jointLog] [info] Loading Quasi index; [2016-01-02 20:23:03.751] [stderrLog] [info] Loading Transcript Info; [2016-01-02 20:23:04.776] [stderrLog] [info] Loading Rank-Select Bit Array; [2016-01-02 20:23:05.009] [stderrLog] [info] There were 104534 set bits in the bit array; [2016-01-02 20:23:05.325] [stderrLog] [info] Computing transcript lengths; [2016-01-02 20:23:05.325] [stderrLog] [info] Waiting to finish loading hash; Index contained 104534 targets; [2016-01-02 20:23:16.571] [stderrLog] [info] Done loading index; [2016-01-02 20:23:16.571] [jointLog] [info] done. processed 12000001 fragments; hits: 24367128, hits per frag: 2.04044. [2016-01-02 20:23:49.850] [jointLog] [info] Computed 102251 rich equivalence classes for further processing; [2016-01-02 20:23:49.850] [jointLog] [info] Counted 10033689 total reads in the equivalence classes; [2016-01-02 20:23:49.875] [jointLog] [info] Mapping rate = 83.0244%. [2016-01-02 20:23:49.875] [jointLog] [info] finished quantifyLibrary(); [2016-01-02 20:23:49.875] [jointL",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/34#issuecomment-168426741:7809,Load,Loading,7809,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/34#issuecomment-168426741,1,['Load'],['Loading']
Performance," #1 SMP Debian 4.9.82-1+deb9u3~bpo8+1 (2018-03-22). ~/data/PCSI/PC10X/paper/pbmc$ g++ -v; Using built-in specs.; COLLECT_GCC=g++; COLLECT_LTO_WRAPPER=/u/user/local/libexec/gcc/x86_64-unknown-linux-gnu/5.4.0/lto-wrapper; Target: x86_64-unknown-linux-gnu; Configured with: ./configure --prefix=/u/user/local; Thread model: posix; gcc version 5.4.0 (GCC); ```. ```; [Thread debugging using libthread_db enabled]; Using host libthread_db library ""/lib/x86_64-linux-gnu/libthread_db.so.1"".; warning: File ""/u/user/local/lib64/libstdc++.so.6.0.21-gdb.py"" auto-loading has been declined by your `auto-load safe-path' set to ""$debugdir:$datadir/auto-load"".; To enable execution of this file add; add-auto-load-safe-path /u/user/local/lib64/libstdc++.so.6.0.21-gdb.py; line to your configuration file ""/u/user/.gdbinit"".; To completely disable this security protection add; set auto-load safe-path /; line to your configuration file ""/u/user/.gdbinit"".; For more information about this security protection see the; ""Auto-loading safe path"" section in the GDB manual. E.g., run from the shell:; info ""(gdb)Auto-loading safe path""; [New Thread 0x7fff7e0f4700 (LWP 14274)]; Version Info: ### A newer version of Salmon is available. ####; [Thread 0x7fff7e0f4700 (LWP 14274) exited]; ###; The newest version, available at https://github.com/COMBINE-lab/salmon/releases; contains new features, improvements, and bug fixes; please upgrade at your; earliest convenience.; ###; [New Thread 0x7fff7d273700 (LWP 14275)]; Logs will be written to pbmc4k/alevin/logs; [New Thread 0x7ffefc3f1700 (LWP 14276)]; [New Thread 0x7ffe7b56f700 (LWP 14277)]; [New Thread 0x7ffdfa6ed700 (LWP 14278)]; ### salmon (single-cell-based) v0.10.1; ### [ program ] => salmon; ### [ command ] => alevin; ### [ libType ] => { ISR }; ### [ chromium ] => { }; ### [ threads ] => { 8 }; ### [ output ] => { pbmc4k/alevin }; ### [ mates1 ] => { /dev/fd/63 }; ### [ mates2 ] => { /dev/fd/62 }; ### [ index ] => { /u/user/ref/cellranger/salmon/trans",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-395836214:2609,load,loading,2609,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-395836214,1,['load'],['loading']
Performance," /proc/version; Linux version 4.9.0-0.bpo.6-amd64 (debian-kernel@lists.debian.org) (gcc version 4.9.2 (Debian 4.9.2-10+deb8u1) ) #1 SMP Debian 4.9.82-1+deb9u3~bpo8+1 (2018-03-22). ~/data/PCSI/PC10X/paper/pbmc$ g++ -v; Using built-in specs.; COLLECT_GCC=g++; COLLECT_LTO_WRAPPER=/u/user/local/libexec/gcc/x86_64-unknown-linux-gnu/5.4.0/lto-wrapper; Target: x86_64-unknown-linux-gnu; Configured with: ./configure --prefix=/u/user/local; Thread model: posix; gcc version 5.4.0 (GCC); ```. ```; [Thread debugging using libthread_db enabled]; Using host libthread_db library ""/lib/x86_64-linux-gnu/libthread_db.so.1"".; warning: File ""/u/user/local/lib64/libstdc++.so.6.0.21-gdb.py"" auto-loading has been declined by your `auto-load safe-path' set to ""$debugdir:$datadir/auto-load"".; To enable execution of this file add; add-auto-load-safe-path /u/user/local/lib64/libstdc++.so.6.0.21-gdb.py; line to your configuration file ""/u/user/.gdbinit"".; To completely disable this security protection add; set auto-load safe-path /; line to your configuration file ""/u/user/.gdbinit"".; For more information about this security protection see the; ""Auto-loading safe path"" section in the GDB manual. E.g., run from the shell:; info ""(gdb)Auto-loading safe path""; [New Thread 0x7fff7e0f4700 (LWP 14274)]; Version Info: ### A newer version of Salmon is available. ####; [Thread 0x7fff7e0f4700 (LWP 14274) exited]; ###; The newest version, available at https://github.com/COMBINE-lab/salmon/releases; contains new features, improvements, and bug fixes; please upgrade at your; earliest convenience.; ###; [New Thread 0x7fff7d273700 (LWP 14275)]; Logs will be written to pbmc4k/alevin/logs; [New Thread 0x7ffefc3f1700 (LWP 14276)]; [New Thread 0x7ffe7b56f700 (LWP 14277)]; [New Thread 0x7ffdfa6ed700 (LWP 14278)]; ### salmon (single-cell-based) v0.10.1; ### [ program ] => salmon; ### [ command ] => alevin; ### [ libType ] => { ISR }; ### [ chromium ] => { }; ### [ threads ] => { 8 }; ### [ output ] => { pbmc4k/alevi",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-395836214:2471,load,load,2471,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-395836214,1,['load'],['load']
Performance," 0 reads; Assuming this is the required behavior.; [2018-12-12 15:08:51.141] [alevinLog] [info] Total 95 white-listed Barcodes; [2018-12-12 15:08:51.144] [alevinLog] [info] Done populating Z matrix; [2018-12-12 15:08:51.146] [alevinLog] [info] Done indexing Barcodes; [2018-12-12 15:08:51.146] [alevinLog] [info] Total Unique barcodes found: 4096; [2018-12-12 15:08:51.146] [alevinLog] [info] Used Barcodes except Whitelist: 1864; [2018-12-12 15:08:51.272] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify. [2018-12-12 15:08:51.272] [alevinLog] [info] parsing read library format; [2018-12-12 15:08:51.375] [stderrLog] [info] Loading Suffix Array ; [2018-12-12 15:08:51.272] [jointLog] [info] There is 1 library.; [2018-12-12 15:08:51.375] [jointLog] [info] Loading Quasi index; [2018-12-12 15:08:51.375] [jointLog] [info] Loading 32-bit quasi index; [2018-12-12 15:09:10.216] [stderrLog] [info] Loading Transcript Info ; [2018-12-12 15:09:15.719] [stderrLog] [info] Loading Rank-Select Bit Array; [2018-12-12 15:09:16.330] [stderrLog] [info] There were 205,870 set bits in the bit array; [2018-12-12 15:09:16.343] [stderrLog] [info] Computing transcript lengths; [2018-12-12 15:09:16.343] [stderrLog] [info] Waiting to finish loading hash; [2018-12-12 15:09:21.460] [stderrLog] [info] Done loading index; [2018-12-12 15:09:21.460] [jointLog] [info] done; [2018-12-12 15:09:21.460] [jointLog] [info] Index contained 205,870 targets. processed 0 Million fragments; processed 1 Million fragments; processed 1 Million fragments; ..............; processed 74 Million fragments; hits: 111594303, hits per frag: 1.50848[2018-12-12 15:12:07.666] [jointLog] [info] Thread saw mini-batch with a maximum of 5.34% zero probability fragments; [2018-12-12 15:12:07.677] [jointLog] [info] Thread saw mini-batch with a maximum of 5.48% zero probability fragments. [2018-12-12 15:12:07.721] [jointLog] [info] Computed 173,365 rich equivalence classes for further processing; [2018-12-12 15:12:07.7",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/329#issuecomment-446668422:4530,Load,Loading,4530,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/329#issuecomment-446668422,1,['Load'],['Loading']
Performance," 4096, PROT_NONE) = 0; clone(child_stack=0x7ffebe5e7ed0, flags=CLONE_VM|CLONE_FS|CLONE_FILES|CLONE_SIGHAND|CLONE_THREAD|CLONE_SYSVSEM|CLONE_SETTLS|CLONE_PARENT_SETTID|CLONE_CHILD_CLEARTID, parent_tidptr=0x7ffebe5e89d0, tls=0x7ffebe5e8700, child_tidptr=0x7ffebe5e89d0) = 14677; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts/sa.bin"", O_RDONLY) = 4; clock_gettime(CLOCK_REALTIME, {1491424830, 149197282}) = 0; read(4, ""l\n\221\21\0\0\0\0k\n\221\21\373\25\343\20\17\254\r\1\36\27\227\n\37\371\270\4\250\210\307\f""..., 8191) = 8191; mmap(NULL, 1342177280, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_NORESERVE, -1, 0) = 0x7ffe2e5e8000; munmap(0x7ffe2e5e8000, 1342177280) = 0; mmap(NULL, 1344270336, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_NORESERVE, -1, 0) = 0x7ffe2e3e9000; munmap(0x7ffe2e3e9000, 94208) = 0; munmap(0x7ffe7e400000, 1998848) = 0; [1m[2017-04-05 16:40:30.149] [stderrLog] [info] Loading Suffix Array ; [00m[1m[2017-04-05 16:40:30.069] [jointLog] [info] Loading Quasi index; [00m[1m[2017-04-05 16:40:30.139] [jointLog] [info] Loading 32-bit quasi index; [00mread(4, ""\16'w=\r\320m\306\0\35\26\306\0\224\23\270\10\205]D\0|\3!\4c_-\7\310O\2""..., 1178864057) = 1178864057; close(4) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts/txpInfo.bin"", O_RDONLY) = 4; clock_gettime(CLOCK_REALTIME, {1491424833, 297142816}) = 0; read(4, ""\315\5\3\0\0\0\0\0|\0\0\0\0\0\0\0ENST00000456328.""..., 8191) = 8191; read(4, ""RP4-669L17.8-001|RP4-669L17.8|12""..., 8191) = 8191; read(4, "".2|LINC01128-004|LINC01128|874|l""..., 8191) = 8191; read(4, ""THUMT00000097991.1|AGRN-002|AGRN""..., 8191) = 8191; read(4, ""HUMG00000001412.6|OTTHUMT0000000""..., 8191) = 8191; read(4, ""F3L-007|CPSF3L|1868|protein_codi""..., 8191) = 8191; read(4, ""01413.3|OTTHUMT00000004082.2|AUR""..., 8191) = 8191; read(4, ""UMT00000001363.3|ATAD3A-001|ATAD""..., 8191)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:167252,Load,Loading,167252,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,1,['Load'],['Loading']
Performance," => salmon; # [ command ] => quant; # [ libType ] => { IU }; # [ alignments ] => { sample_alignments.sam }; # [ targets ] => { ../sample_data/transcripts.fasta }; # [ output ] => { sample_aln_quant }; Logs will be written to sample_aln_quant/logs; Library format { type:paired end, relative orientation:inward, strandedness:unstranded }; [2020-04-21 10:11:42.553] [jointLog] [info] setting maxHashResizeThreads to 8; [2020-04-21 10:11:42.553] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2020-04-21 10:11:42.553] [jointLog] [info] numQuantThreads = 4; parseThreads = 4; Checking that provided alignment files have consistent headers . . . done; Populating targets from aln = ""sample_alignments.sam"", fasta = ""../sample_data/transcripts.fasta"" . . .done; [2020-04-21 10:11:43.180] [jointLog] [info] replaced 0 non-ACGT nucleotides with random nucleotides. processed 0 reads in current round; killing thread 3 . . . done. Freeing memory used by read queue . . . 00; Joined parsing thread . . . ""sample_alignments.sam""; Closed all files . . .; Emptied frag queue. . . [2020-04-21 10:11:43.477] [jointLog] [info]. Completed first pass through the alignment file.; Total # of mapped reads : 10000; # of uniquely mapped reads : 6913; # ambiguously mapped reads : 3087. [2020-04-21 10:11:43.489] [jointLog] [info] Computed 27 rich equivalence classes for further processing; [2020-04-21 10:11:43.489] [jointLog] [info] Counted 10,000 total reads in the equivalence classes; [2020-04-21 10:11:43.490] [jointLog] [warning] Only 10000 fragments were mapped, but the number of burn-in fragments was set to 5000000.; The effective lengths have been computed using the observed mappings. [2020-04-21 10:11:43.492] [jointLog] [info] starting optimizer; [2020-04-21 10:11:43.493] [jointLog] [info] Marked 0 weighted equivalence classes as degenerate; [2020-04-21 10:11:43.493] [jointLog] [info] iteration = 0 | max rel diff. = 14.87; [2020-04-21 10:11:",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/511#issuecomment-617206094:1930,queue,queue,1930,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/511#issuecomment-617206094,1,['queue'],['queue']
Performance, => { SRR2454059.fq.gz }; ### [ libType ] => { ISF }; ### [ useVBOpt ] => { }; ### [ output ] => { test_quant }; ### [ numGibbsSamples ] => { 100 }; ### [ threads ] => { 16 }; Logs will be written to test_quant/logs; [2016-12-13 22:38:54.413] [jointLog] [info] parsing read library format; [2016-12-13 22:38:54.413] [jointLog] [info] There is 1 library.; [2016-12-13 22:38:56.240] [stderrLog] [info] Loading Suffix Array; [2016-12-13 22:38:56.240] [jointLog] [info] Loading Quasi index; [2016-12-13 22:38:56.240] [jointLog] [info] Loading 32-bit quasi index; [2016-12-13 22:39:01.268] [stderrLog] [info] Loading Transcript Info; [2016-12-13 22:39:02.630] [stderrLog] [info] Loading Rank-Select Bit Array; [2016-12-13 22:39:03.041] [stderrLog] [info] There were 182608 set bits in the bit array; [2016-12-13 22:39:03.159] [stderrLog] [info] Computing transcript lengths; [2016-12-13 22:39:03.160] [stderrLog] [info] Waiting to finish loading hash; [2016-12-13 22:39:07.653] [stderrLog] [info] Done loading index; [2016-12-13 22:39:07.653] [jointLog] [info] done; [2016-12-13 22:39:07.653] [jointLog] [info] Index contained 182608 targets. processed 19000000 fragments; hits: 65897209; hits per frag: 3.47349. [2016-12-13 22:40:22.572] [jointLog] [info] Computed 137534 rich equivalence classes for further processing; [2016-12-13 22:40:22.572] [jointLog] [info] Counted 16265961 total reads in the equivalence classes; [2016-12-13 22:40:22.618] [jointLog] [info] Mapping rate = 83.509%. [2016-12-13 22:40:22.618] [jointLog] [info] finished quantifyLibrary(); [2016-12-13 22:40:22.619] [jointLog] [info] Starting optimizer; [2016-12-13 22:40:22.904] [jointLog] [info] Marked 0 weighted equivalence classes as degenerate; [2016-12-13 22:40:22.911] [jointLog] [info] iteration = 0 | max rel diff. = 299.976; [2016-12-13 22:40:23.620] [jointLog] [info] iteration = 100 | max rel diff. = 0.121769; [2016-12-13 22:40:24.367] [jointLog] [info] iteration = 200 | max rel diff. = 0.103587; [2016-12-13 22:40:25.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-266934878:1972,load,loading,1972,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-266934878,1,['load'],['loading']
Performance, => { SRR2454059.fq.gz }; ### [ libType ] => { ISF }; ### [ useVBOpt ] => { }; ### [ output ] => { test_quant }; ### [ numGibbsSamples ] => { 100 }; ### [ threads ] => { 16 }; Logs will be written to test_quant/logs; [2016-12-13 22:44:07.409] [jointLog] [info] parsing read library format; [2016-12-13 22:44:07.409] [jointLog] [info] There is 1 library.; [2016-12-13 22:44:09.318] [jointLog] [info] Loading Quasi index; [2016-12-13 22:44:09.318] [jointLog] [info] Loading 32-bit quasi index; [2016-12-13 22:44:09.318] [stderrLog] [info] Loading Suffix Array; [2016-12-13 22:44:15.002] [stderrLog] [info] Loading Transcript Info; [2016-12-13 22:44:16.278] [stderrLog] [info] Loading Rank-Select Bit Array; [2016-12-13 22:44:16.625] [stderrLog] [info] There were 182608 set bits in the bit array; [2016-12-13 22:44:16.680] [stderrLog] [info] Computing transcript lengths; [2016-12-13 22:44:16.681] [stderrLog] [info] Waiting to finish loading hash; [2016-12-13 22:44:20.485] [stderrLog] [info] Done loading index; [2016-12-13 22:44:20.485] [jointLog] [info] done; [2016-12-13 22:44:20.485] [jointLog] [info] Index contained 182608 targets. processed 19000001 fragments; hits: 65897764; hits per frag: 3.48152. [2016-12-13 22:45:33.192] [jointLog] [info] Computed 137534 rich equivalence classes for further processing; [2016-12-13 22:45:33.192] [jointLog] [info] Counted 16265961 total reads in the equivalence classes; [2016-12-13 22:45:33.233] [jointLog] [info] Mapping rate = 83.509%. [2016-12-13 22:45:33.233] [jointLog] [info] finished quantifyLibrary(); [2016-12-13 22:45:33.234] [jointLog] [info] Starting optimizer; [2016-12-13 22:45:33.516] [jointLog] [info] Marked 0 weighted equivalence classes as degenerate; [2016-12-13 22:45:33.523] [jointLog] [info] iteration = 0 | max rel diff. = 299.95; [2016-12-13 22:45:34.217] [jointLog] [info] iteration = 100 | max rel diff. = 0.122252; [2016-12-13 22:45:34.912] [jointLog] [info] iteration = 200 | max rel diff. = 0.102915; [2016-12-13 22:45:35.6,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-266935584:1845,load,loading,1845,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-266935584,1,['load'],['loading']
Performance," BAM Unsorted --quantMode TranscriptomeSAM --outSAMattributes NH HI AS NM MD --quantTranscriptomeBan IndelSoftclipSingleend`; note that last parameter that I will come back to later. Also, the paper referenced above also describes a new capability present in recent versions of salmon that allow it to index the entire genome (as well as the transcriptome) to have the former act as a decoy. This allows avoiding what might otherwise be spurious mappings that result when one considers only the transcriptome as a source of mapping. There are a number of ways to proceed on this front, but this is a good place to first check for discrepancy (and the paper gives a good overview of the relative tradeoffs and merits of different alignment approaches). * Salmon and RSEM use related but distinct optimization algorithms by default. RSEM uses the EM algorithm, and salmon uses the variational Bayesian EM algorithm. The latter tends to induce more sparse solutions. This is simply because they are optimizing slightly different objectives. It is very difficult to say in general if one is ""better"" than the other in a blanket way, but [there is previous literature to support that the VBEM may be more accurate](https://academic.oup.com/bioinformatics/article/29/18/2292/239795). However, while RSEM only implements the EM algorithm, salmon actually implements and provides a switch to use either. So, if you want to test the effect of this difference, you can run salmon with the `--useEM` algorithm. This will tell salmon to use the ""classic"" EM algorithm and will eliminate this source of variation. * As with the other question you asked, there may be a _small_ discrepancy depending on when enforcement of a stranded library kicks in under salmon's `A` library type. You can eliminate that variable by simply providing `-l SF` to match the library type being used with RSEM. * Coming back to the `IndelSoftclipSingleend` parameter I mentioned in the first point; RSEM disallows indels in the align",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/612#issuecomment-758004590:2863,optimiz,optimizing,2863,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/612#issuecomment-758004590,1,['optimiz'],['optimizing']
Performance," Boundary at 100 ; [2019-01-29 09:56:53.219] [alevinLog] [info] Learned InvCov: 114.414 normfactor: 148.807; [2019-01-29 09:56:53.219] [alevinLog] [info] Total 293(has 193 low confidence) barcodes; [2019-01-29 09:56:53.224] [alevinLog] [info] Done True Barcode Sampling; [2019-01-29 09:56:53.254] [alevinLog] [info] Done populating Z matrix; [2019-01-29 09:56:53.255] [alevinLog] [info] Done indexing Barcodes; [2019-01-29 09:56:53.255] [alevinLog] [info] Total Unique barcodes found: 125401; [2019-01-29 09:56:53.255] [alevinLog] [info] Used Barcodes except Whitelist: 1256; [2019-01-29 09:56:53.281] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify. [2019-01-29 09:56:53.281] [alevinLog] [info] parsing read library format; [2019-01-29 09:56:53.412] [stderrLog] [info] Loading Suffix Array ; [2019-01-29 09:56:53.281] [jointLog] [info] There is 1 library.; [2019-01-29 09:56:53.410] [jointLog] [info] Loading Quasi index; [2019-01-29 09:56:53.411] [jointLog] [info] Loading 32-bit quasi index; [2019-01-29 09:56:54.551] [stderrLog] [info] Loading Transcript Info ; [2019-01-29 09:56:54.826] [stderrLog] [info] Loading Rank-Select Bit Array; [2019-01-29 09:56:54.883] [stderrLog] [info] There were 80,511 set bits in the bit array; [2019-01-29 09:56:54.908] [stderrLog] [info] Computing transcript lengths; [2019-01-29 09:56:54.908] [stderrLog] [info] Waiting to finish loading hash; [2019-01-29 09:57:09.336] [stderrLog] [info] Done loading index; [2019-01-29 09:57:09.336] [jointLog] [info] done; [2019-01-29 09:57:09.336] [jointLog] [info] Index contained 80,511 targets. processed 2 Million fragments; hits: 812181, hits per frag: 0.326777. [2019-01-29 09:57:36.647] [alevinLog] [info] Starting optimizer; [2019-01-29 09:57:36.587] [jointLog] [info] Computed 12,933 rich equivalence classes for further processing; [2019-01-29 09:57:36.587] [jointLog] [info] Counted 242,520 total reads in the equivalence classes ; [2019-01-29 09:57:36.601] [jointLog] [warning] Only 242520 f",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/337#issuecomment-458481722:8343,Load,Loading,8343,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/337#issuecomment-458481722,1,['Load'],['Loading']
Performance," Done indexing Barcodes; [2019-01-29 09:56:53.255] [alevinLog] [info] Total Unique barcodes found: 125401; [2019-01-29 09:56:53.255] [alevinLog] [info] Used Barcodes except Whitelist: 1256; [2019-01-29 09:56:53.281] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify. [2019-01-29 09:56:53.281] [alevinLog] [info] parsing read library format; [2019-01-29 09:56:53.412] [stderrLog] [info] Loading Suffix Array ; [2019-01-29 09:56:53.281] [jointLog] [info] There is 1 library.; [2019-01-29 09:56:53.410] [jointLog] [info] Loading Quasi index; [2019-01-29 09:56:53.411] [jointLog] [info] Loading 32-bit quasi index; [2019-01-29 09:56:54.551] [stderrLog] [info] Loading Transcript Info ; [2019-01-29 09:56:54.826] [stderrLog] [info] Loading Rank-Select Bit Array; [2019-01-29 09:56:54.883] [stderrLog] [info] There were 80,511 set bits in the bit array; [2019-01-29 09:56:54.908] [stderrLog] [info] Computing transcript lengths; [2019-01-29 09:56:54.908] [stderrLog] [info] Waiting to finish loading hash; [2019-01-29 09:57:09.336] [stderrLog] [info] Done loading index; [2019-01-29 09:57:09.336] [jointLog] [info] done; [2019-01-29 09:57:09.336] [jointLog] [info] Index contained 80,511 targets. processed 2 Million fragments; hits: 812181, hits per frag: 0.326777. [2019-01-29 09:57:36.647] [alevinLog] [info] Starting optimizer; [2019-01-29 09:57:36.587] [jointLog] [info] Computed 12,933 rich equivalence classes for further processing; [2019-01-29 09:57:36.587] [jointLog] [info] Counted 242,520 total reads in the equivalence classes ; [2019-01-29 09:57:36.601] [jointLog] [warning] Only 242520 fragments were mapped, but the number of burn-in fragments was set to 5000000.; The effective lengths have been computed using the observed mappings. [2019-01-29 09:57:36.601] [jointLog] [info] Mapping rate = 8.94141%. [2019-01-29 09:57:36.601] [jointLog] [info] finished quantifyLibrary(). Analyzed 293 cells (100% of all).; [2019-01-29 09:57:40.090] [alevinLog] [info] Total 206902 UMI ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/337#issuecomment-458481722:8746,load,loading,8746,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/337#issuecomment-458481722,1,['load'],['loading']
Performance," Done indexing Barcodes; [2019-07-09 09:17:08.067] [alevinLog] [info] Total Unique barcodes found: 7881525; [2019-07-09 09:17:08.067] [alevinLog] [info] Used Barcodes except Whitelist: 84951; [2019-07-09 09:17:08.128] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify. [2019-07-09 09:17:08.128] [alevinLog] [info] parsing read library format; [2019-07-09 10:02:26.992] [alevinLog] [info] Starting optimizer. [2019-07-09 10:13:56.661] [alevinLog] [info] Total 99488568.00 UMI after deduplicating.; [2019-07-09 10:13:56.701] [alevinLog] [info] Clearing EqMap; Might take some time.; [2019-07-09 10:14:11.020] [alevinLog] [info] Starting Import of the gene count matrix of size 1192x60053.; [2019-07-09 10:14:11.286] [alevinLog] [info] Done initializing the empty matrix.; [2019-07-09 10:14:13.421] [alevinLog] [info] Done Importing gene count matrix for dimension 1192x60053; [2019-07-09 10:14:13.622] [alevinLog] [info] Starting white listing; [2019-07-09 10:14:13.627] [alevinLog] [info] Done importing order of barcodes ""quants_mat_rows.txt"" file.; [2019-07-09 10:14:13.627] [alevinLog] [info] Total 1192 barcodes found; [2019-07-09 10:14:13.627] [alevinLog] [warning] mrna file not provided; using is 1 less feature for whitelisting; [2019-07-09 10:14:13.627] [alevinLog] [warning] rrna file not provided; using is 1 less feature for whitelisting; [2019-07-09 10:14:13.627] [alevinLog] [info] Starting to make feature Matrix; [2019-07-09 10:14:13.885] [alevinLog] [info] Done making regular featues; [2019-07-09 10:14:13.885] [alevinLog] [info] Done making feature Matrix; [2019-07-09 10:14:13.891] [alevinLog] [info] Finished white listing; [2019-07-09 10:14:13.909] [alevinLog] [info] Finished optimizer; ```. Indeed the fractions of BC thrown away is huge. I might need to try your `--expectCells/--forceCells` option - but not sure how this parameter influences final output? i.e. how to select a feasible number - 8000 might not be optimal strictly speaking. Thanks!; Chelsea",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/396#issuecomment-510547693:2703,optimiz,optimizer,2703,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/396#issuecomment-510547693,1,['optimiz'],['optimizer']
Performance," ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; [Thread debugging using libthread_db enabled]; Using host libthread_db library ""/lib64/libthread_db.so.1"".; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warni",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641594410:3422,Load,Loadable,3422,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641594410,1,['Load'],['Loadable']
Performance," Info: This is the most recent version of salmon.; -----------------------------------------; | Loading contig table | Time = 13.512 s; -----------------------------------------; size = 16145665; -----------------------------------------; | Loading contig offsets | Time = 382.03 ms; -----------------------------------------; -----------------------------------------; | Loading reference lengths | Time = 9.4861 ms; -----------------------------------------; -----------------------------------------; | Loading mphf table | Time = 2.4236 s; -----------------------------------------; size = 1057188904; Number of ones: 16145664; Number of ones per inventory item: 512; Inventory entries filled: 31535; -----------------------------------------; | Loading contig boundaries | Time = 4.031 s; -----------------------------------------; size = 1057188904; -----------------------------------------; | Loading sequence | Time = 1.983 s; -----------------------------------------; size = 572818984; -----------------------------------------; | Loading positions | Time = 14.658 s; -----------------------------------------; size = 942318702; -----------------------------------------; | Loading reference sequence | Time = 1.4932 s; -----------------------------------------; -----------------------------------------; | Loading reference accumulative lengths | Time = 10.959 ms; -----------------------------------------; Error: invalid feature coordinates (end<start!) at line:; NC_029855.1	RefSeq	gene	406748	107842	.	+	.	gene_id ""A5N79_gp28""; db_xref ""GeneID:27215502""; exception ""trans-splicing""; gbkey ""Gene""; gene ""nad2""; gene_biotype ""protein_coding""; locus_tag ""A5N79_gp28""; ; --- . After I remove the erroneous entry, there is no more complaint:. ---; Version Info: This is the most recent version of salmon.; -----------------------------------------; | Loading contig table | Time = 14.648 s; -----------------------------------------; size = 16145665; --------------------------------------",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/569#issuecomment-709699746:1135,Load,Loading,1135,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/569#issuecomment-709699746,1,['Load'],['Loading']
Performance," InvCov: 114.414 normfactor: 148.807; [2019-01-29 09:56:53.219] [alevinLog] [info] Total 293(has 193 low confidence) barcodes; [2019-01-29 09:56:53.224] [alevinLog] [info] Done True Barcode Sampling; [2019-01-29 09:56:53.254] [alevinLog] [info] Done populating Z matrix; [2019-01-29 09:56:53.255] [alevinLog] [info] Done indexing Barcodes; [2019-01-29 09:56:53.255] [alevinLog] [info] Total Unique barcodes found: 125401; [2019-01-29 09:56:53.255] [alevinLog] [info] Used Barcodes except Whitelist: 1256; [2019-01-29 09:56:53.281] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify. [2019-01-29 09:56:53.281] [alevinLog] [info] parsing read library format; [2019-01-29 09:56:53.412] [stderrLog] [info] Loading Suffix Array ; [2019-01-29 09:56:53.281] [jointLog] [info] There is 1 library.; [2019-01-29 09:56:53.410] [jointLog] [info] Loading Quasi index; [2019-01-29 09:56:53.411] [jointLog] [info] Loading 32-bit quasi index; [2019-01-29 09:56:54.551] [stderrLog] [info] Loading Transcript Info ; [2019-01-29 09:56:54.826] [stderrLog] [info] Loading Rank-Select Bit Array; [2019-01-29 09:56:54.883] [stderrLog] [info] There were 80,511 set bits in the bit array; [2019-01-29 09:56:54.908] [stderrLog] [info] Computing transcript lengths; [2019-01-29 09:56:54.908] [stderrLog] [info] Waiting to finish loading hash; [2019-01-29 09:57:09.336] [stderrLog] [info] Done loading index; [2019-01-29 09:57:09.336] [jointLog] [info] done; [2019-01-29 09:57:09.336] [jointLog] [info] Index contained 80,511 targets. processed 2 Million fragments; hits: 812181, hits per frag: 0.326777. [2019-01-29 09:57:36.647] [alevinLog] [info] Starting optimizer; [2019-01-29 09:57:36.587] [jointLog] [info] Computed 12,933 rich equivalence classes for further processing; [2019-01-29 09:57:36.587] [jointLog] [info] Counted 242,520 total reads in the equivalence classes ; [2019-01-29 09:57:36.601] [jointLog] [warning] Only 242520 fragments were mapped, but the number of burn-in fragments was set to 500",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/337#issuecomment-458481722:8416,Load,Loading,8416,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/337#issuecomment-458481722,1,['Load'],['Loading']
Performance," Run B. ![image](https://cloud.githubusercontent.com/assets/361470/20741292/4f8243a0-b697-11e6-93ae-29d4b48327cd.png). ![image](https://cloud.githubusercontent.com/assets/361470/20741299/60f84c1a-b697-11e6-9f83-1554ff471e94.png). So, as you can see, there is a substantial amount of uncertainty in RunA, especially for `MSAD_200218.t1`. This can explain how you see this transcript obtaining different numbers of reads over different executions for Run A. Specifically, the inferential uncertainty for this transcript is high, and though the mean of the posterior is close to the value you report above, the range is quite large (200 - 1200) reads (potentially even larger with more bootstraps, but 100 gives us a reasonable window on posterior variance). On the other hand, the EM algorithm *really* wants to assign ~0.8 reads to `MSAD_157177.t1` in Run B. To test how much this might be the result of the tendency of the EM algorithm toward sparsity, I tried processing both samples with Salmon's `--useVBOpt` flag --- causing it to use the variational bayesian optimization algorithm, which yields considerably more *regularized* estimates. The posterior distributions obtained using the VB optimizer are:. ### Run A (VB Opt). ![image](https://cloud.githubusercontent.com/assets/361470/20741629/916b3446-b699-11e6-9f92-b8b6d3519981.png). ![image](https://cloud.githubusercontent.com/assets/361470/20741636/98510f06-b699-11e6-8d9f-34f1c353c3e6.png). ### Run B (VB Opt). ![image](https://cloud.githubusercontent.com/assets/361470/20741642/a1341686-b699-11e6-9a87-8a30f87cd49c.png). ![image](https://cloud.githubusercontent.com/assets/361470/20741645/a7340d5c-b699-11e6-90dd-55f9795bac8f.png). So, while there are some small differences for Run A and transcript `MSAD_200218.t1` in Run B, you can see that the most striking difference is `MSAD_157177.t1` in Run B. The number of estimated reads isn't quite as high as with eXpress, but a considerable number of reads map to `MSAD_157177.t1` (and the ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/107#issuecomment-263793798:1720,optimiz,optimization,1720,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/107#issuecomment-263793798,1,['optimiz'],['optimization']
Performance, Transcript Info; [2016-12-13 22:39:02.630] [stderrLog] [info] Loading Rank-Select Bit Array; [2016-12-13 22:39:03.041] [stderrLog] [info] There were 182608 set bits in the bit array; [2016-12-13 22:39:03.159] [stderrLog] [info] Computing transcript lengths; [2016-12-13 22:39:03.160] [stderrLog] [info] Waiting to finish loading hash; [2016-12-13 22:39:07.653] [stderrLog] [info] Done loading index; [2016-12-13 22:39:07.653] [jointLog] [info] done; [2016-12-13 22:39:07.653] [jointLog] [info] Index contained 182608 targets. processed 19000000 fragments; hits: 65897209; hits per frag: 3.47349. [2016-12-13 22:40:22.572] [jointLog] [info] Computed 137534 rich equivalence classes for further processing; [2016-12-13 22:40:22.572] [jointLog] [info] Counted 16265961 total reads in the equivalence classes; [2016-12-13 22:40:22.618] [jointLog] [info] Mapping rate = 83.509%. [2016-12-13 22:40:22.618] [jointLog] [info] finished quantifyLibrary(); [2016-12-13 22:40:22.619] [jointLog] [info] Starting optimizer; [2016-12-13 22:40:22.904] [jointLog] [info] Marked 0 weighted equivalence classes as degenerate; [2016-12-13 22:40:22.911] [jointLog] [info] iteration = 0 | max rel diff. = 299.976; [2016-12-13 22:40:23.620] [jointLog] [info] iteration = 100 | max rel diff. = 0.121769; [2016-12-13 22:40:24.367] [jointLog] [info] iteration = 200 | max rel diff. = 0.103587; [2016-12-13 22:40:25.102] [jointLog] [info] iteration = 300 | max rel diff. = 0.144748; [2016-12-13 22:40:25.815] [jointLog] [info] iteration = 400 | max rel diff. = 0.231057; [2016-12-13 22:40:26.505] [jointLog] [info] iteration = 500 | max rel diff. = 0.0156154; [2016-12-13 22:40:27.020] [jointLog] [info] iteration = 570 | max rel diff. = 0.00955966; [2016-12-13 22:40:27.052] [jointLog] [info] Finished optimizer; [2016-12-13 22:40:27.052] [jointLog] [info] writing output. [2016-12-13 22:40:27.523] [jointLog] [info] Starting Gibbs Sampler 1 week; 100% [=====================================================] in 44s; [2016-12,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-266934878:2586,optimiz,optimizer,2586,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-266934878,1,['optimiz'],['optimizer']
Performance, Transcript Info; [2016-12-13 22:44:16.278] [stderrLog] [info] Loading Rank-Select Bit Array; [2016-12-13 22:44:16.625] [stderrLog] [info] There were 182608 set bits in the bit array; [2016-12-13 22:44:16.680] [stderrLog] [info] Computing transcript lengths; [2016-12-13 22:44:16.681] [stderrLog] [info] Waiting to finish loading hash; [2016-12-13 22:44:20.485] [stderrLog] [info] Done loading index; [2016-12-13 22:44:20.485] [jointLog] [info] done; [2016-12-13 22:44:20.485] [jointLog] [info] Index contained 182608 targets. processed 19000001 fragments; hits: 65897764; hits per frag: 3.48152. [2016-12-13 22:45:33.192] [jointLog] [info] Computed 137534 rich equivalence classes for further processing; [2016-12-13 22:45:33.192] [jointLog] [info] Counted 16265961 total reads in the equivalence classes; [2016-12-13 22:45:33.233] [jointLog] [info] Mapping rate = 83.509%. [2016-12-13 22:45:33.233] [jointLog] [info] finished quantifyLibrary(); [2016-12-13 22:45:33.234] [jointLog] [info] Starting optimizer; [2016-12-13 22:45:33.516] [jointLog] [info] Marked 0 weighted equivalence classes as degenerate; [2016-12-13 22:45:33.523] [jointLog] [info] iteration = 0 | max rel diff. = 299.95; [2016-12-13 22:45:34.217] [jointLog] [info] iteration = 100 | max rel diff. = 0.122252; [2016-12-13 22:45:34.912] [jointLog] [info] iteration = 200 | max rel diff. = 0.102915; [2016-12-13 22:45:35.612] [jointLog] [info] iteration = 300 | max rel diff. = 0.145792; [2016-12-13 22:45:36.357] [jointLog] [info] iteration = 400 | max rel diff. = 0.217489; [2016-12-13 22:45:37.055] [jointLog] [info] iteration = 500 | max rel diff. = 0.0159298; [2016-12-13 22:45:37.628] [jointLog] [info] iteration = 569 | max rel diff. = 0.00958049; [2016-12-13 22:45:37.653] [jointLog] [info] Finished optimizer; [2016-12-13 22:45:37.653] [jointLog] [info] writing output. [2016-12-13 22:45:38.213] [jointLog] [info] Starting Gibbs Sampler; 100% [=====================================================] in 31s; [2016-12-13 22:4,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-266935584:2459,optimiz,optimizer,2459,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-266935584,1,['optimiz'],['optimizer']
Performance, [info] Index contained 182608 targets. processed 19000000 fragments; hits: 65897209; hits per frag: 3.47349. [2016-12-13 22:40:22.572] [jointLog] [info] Computed 137534 rich equivalence classes for further processing; [2016-12-13 22:40:22.572] [jointLog] [info] Counted 16265961 total reads in the equivalence classes; [2016-12-13 22:40:22.618] [jointLog] [info] Mapping rate = 83.509%. [2016-12-13 22:40:22.618] [jointLog] [info] finished quantifyLibrary(); [2016-12-13 22:40:22.619] [jointLog] [info] Starting optimizer; [2016-12-13 22:40:22.904] [jointLog] [info] Marked 0 weighted equivalence classes as degenerate; [2016-12-13 22:40:22.911] [jointLog] [info] iteration = 0 | max rel diff. = 299.976; [2016-12-13 22:40:23.620] [jointLog] [info] iteration = 100 | max rel diff. = 0.121769; [2016-12-13 22:40:24.367] [jointLog] [info] iteration = 200 | max rel diff. = 0.103587; [2016-12-13 22:40:25.102] [jointLog] [info] iteration = 300 | max rel diff. = 0.144748; [2016-12-13 22:40:25.815] [jointLog] [info] iteration = 400 | max rel diff. = 0.231057; [2016-12-13 22:40:26.505] [jointLog] [info] iteration = 500 | max rel diff. = 0.0156154; [2016-12-13 22:40:27.020] [jointLog] [info] iteration = 570 | max rel diff. = 0.00955966; [2016-12-13 22:40:27.052] [jointLog] [info] Finished optimizer; [2016-12-13 22:40:27.052] [jointLog] [info] writing output. [2016-12-13 22:40:27.523] [jointLog] [info] Starting Gibbs Sampler 1 week; 100% [=====================================================] in 44s; [2016-12-13 22:41:12.189] [jointLog] [info] Finished Gibbs Sampler; [2016-12-13 22:41:12.190] [jointLog] [warning] NOTE: Read Lib [SRR2454059.fq.gz] :. Detected a *potential* strand bias > 1% in an unstranded protocol check the file: test_quant/lib_format_counts.json for details; ```. edit: One note is that I was using my build of the same commit number. I'm running the executable you compiled now (since I had to put the appropriate libraries in the `LD_LIBRARY_PATH` to get it to be happy).,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-266934878:3363,optimiz,optimizer,3363,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-266934878,1,['optimiz'],['optimizer']
Performance," [info] Mapping rate = 21.8083%. [2016-01-03 00:37:31.905] [jointLog] [info] finished quantifyLibrary(); [2016-01-03 00:37:31.905] [jointLog] [info] Starting optimizer; [2016-01-03 00:37:33.275] [jointLog] [info] Marked 0 weighted equivalence classes as degenerate; [2016-01-03 00:37:33.279] [jointLog] [info] iteration = 0 | max rel diff. = 35.6186; [2016-01-03 00:37:33.533] [jointLog] [info] iteration = 100 | max rel diff. = 0.12044; [2016-01-03 00:37:33.755] [jointLog] [info] iteration = 200 | max rel diff. = 0.0493504; [2016-01-03 00:37:33.970] [jointLog] [info] iteration = 300 | max rel diff. = 0.0275491; [2016-01-03 00:37:34.194] [jointLog] [info] iteration = 400 | max rel diff. = 0.0216294; [2016-01-03 00:37:34.418] [jointLog] [info] iteration = 500 | max rel diff. = 0.0214024; [2016-01-03 00:37:34.640] [jointLog] [info] iteration = 600 | max rel diff. = 0.0132335; [2016-01-03 00:37:34.850] [jointLog] [info] iteration = 700 | max rel diff. = 0.0132363; [2016-01-03 00:37:35.066] [jointLog] [info] iteration = 800 | max rel diff. = 0.0122673; [2016-01-03 00:37:35.287] [jointLog] [info] iteration = 900 | max rel diff. = 0.012951; [2016-01-03 00:37:35.510] [jointLog] [info] iteration = 1000 | max rel diff. = 0.0131479; [2016-01-03 00:37:35.643] [jointLog] [info] iteration = 1062 | max rel diff. = 0.00666119; [2016-01-03 00:37:35.653] [jointLog] [info] Finished optimizer; [2016-01-03 00:37:35.653] [jointLog] [info] writing output. [2016-01-03 00:37:35.920] [jointLog] [warning] NOTE: Read Lib [( /dev/fd/0, /dev/fd/0 )] :. Greater than 5% of the alignments (but not, necessarily reads) disagreed with the provided library type; check the file: interlaced_salmon_out/libFormatCounts.txt for details; ```. (FYI, this might be a failed sample, I just grabbed on at random, hence the low mapping rate). There's a discrepancy of about 800k observed reads. The number of mapped fragments is roughly twice for the interleaved version. So it seems this strategy doesn't work right now.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/29#issuecomment-168447784:5052,optimiz,optimizer,5052,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/29#issuecomment-168447784,1,['optimiz'],['optimizer']
Performance," [info] Marked 0 weighted equivalence classes as degenerate; [2016-01-03 00:34:21.030] [jointLog] [info] iteration = 0 | max rel diff. = 23.4889; [2016-01-03 00:34:21.167] [jointLog] [info] iteration = 100 | max rel diff. = 0.150549; [2016-01-03 00:34:21.304] [jointLog] [info] iteration = 200 | max rel diff. = 0.0517672; [2016-01-03 00:34:21.447] [jointLog] [info] iteration = 300 | max rel diff. = 0.0368208; [2016-01-03 00:34:21.578] [jointLog] [info] iteration = 400 | max rel diff. = 0.0237254; [2016-01-03 00:34:21.705] [jointLog] [info] iteration = 500 | max rel diff. = 0.0147784; [2016-01-03 00:34:21.834] [jointLog] [info] iteration = 600 | max rel diff. = 0.0131134; [2016-01-03 00:34:21.961] [jointLog] [info] iteration = 700 | max rel diff. = 0.0130094; [2016-01-03 00:34:22.092] [jointLog] [info] iteration = 800 | max rel diff. = 0.0100546; [2016-01-03 00:34:22.196] [jointLog] [info] iteration = 882 | max rel diff. = 0.00861472; [2016-01-03 00:34:22.205] [jointLog] [info] Finished optimizer; [2016-01-03 00:34:22.205] [jointLog] [info] writing output. [2016-01-03 00:34:22.433] [jointLog] [warning] NOTE: Read Lib [( reads_1.fastq, reads_2.fastq )] :. Greater than 5% of the alignments (but not, necessarily reads) disagreed with the provided library type; check the file: normal_salmon_out/libFormatCounts.txt for details; ```. Then I ran. ```; cat all_reads.fastq | salmon quant -i /nfs/research2/teichmann/reference/mus-musculus/salmon/quasi/mouse_cdna_38.p3.78_repbase_ercc.fa -l IU -1 /dev/fd/0 -2 /dev/fd/0 -o interlaced_salmon_out; ```. Now I get. ```; [2016-01-03 00:36:48.844] [jointLog] [info] parsing read library format; [2016-01-03 00:36:49.995] [jointLog] [info] Loading Quasi index; [2016-01-03 00:37:08.293] [jointLog] [info] done; [2016-01-03 00:37:25.106] [jointLog] [info] Computed 23484 rich equivalence classes for further processing; [2016-01-03 00:37:25.106] [jointLog] [info] Counted 667333 total reads in the equivalence classes; [2016-01-03 00:37:25.106] ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/29#issuecomment-168447784:2302,optimiz,optimizer,2302,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/29#issuecomment-168447784,1,['optimiz'],['optimizer']
Performance," [jointLog] [info] iteration = 100 | max rel diff. = 17.2222; [2022-05-14 01:26:09.253] [jointLog] [info] iteration = 200 | max rel diff. = 12.5822; [2022-05-14 01:26:10.641] [jointLog] [info] iteration = 300 | max rel diff. = 12.6466; [2022-05-14 01:26:11.976] [jointLog] [info] iteration = 400 | max rel diff. = 4.95752; [2022-05-14 01:26:13.272] [jointLog] [info] iteration = 500 | max rel diff. = 0.754259; [2022-05-14 01:26:14.546] [jointLog] [info] iteration = 600 | max rel diff. = 0.148902; [2022-05-14 01:26:15.788] [jointLog] [info] iteration = 700 | max rel diff. = 0.117727; [2022-05-14 01:26:17.074] [jointLog] [info] iteration = 800 | max rel diff. = 0.166671; [2022-05-14 01:26:18.385] [jointLog] [info] iteration = 900 | max rel diff. = 0.068019; [2022-05-14 01:26:19.646] [jointLog] [info] iteration = 1,000 | max rel diff. = 0.00671654; [2022-05-14 01:26:19.646] [jointLog] [info] iteration = 1,001 | max rel diff. = 0.00671654; [2022-05-14 01:26:19.655] [jointLog] [info] Finished optimizer; [2022-05-14 01:26:19.655] [jointLog] [info] writing output . Then I generated another index similar to [using a full decoy of the genome](https://combine-lab.github.io/alevin-tutorial/2019/selective-alignment/) as suggested above but I got this report. [2022-05-14 00:49:06.636] [jointLog] [info] Number of mappings discarded because of alignment score : 7,179,799; [2022-05-14 00:49:06.636] [jointLog] [info] Number of fragments entirely discarded because of alignment score : 3,986,275; [2022-05-14 00:49:06.636] [jointLog] [info] Number of fragments discarded because they are best-mapped to decoys : 3,572,798; [2022-05-14 00:49:06.636] [jointLog] [info] Number of fragments discarded because they have only dovetail (discordant) mappings to valid targets : 54,775; [2022-05-14 00:49:06.636] [jointLog] [info] Mapping rate = 62.2613%. [2022-05-14 00:49:06.636] [jointLog] [info] finished quantifyLibrary(); [2022-05-14 00:49:06.643] [jointLog] [info] Starting optimizer; [2022-05-14 00",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/775#issuecomment-1126593943:3527,optimiz,optimizer,3527,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/775#issuecomment-1126593943,1,['optimiz'],['optimizer']
Performance, ] => { Salmon_index_hg38.analysisSet_knownGene }; ### [ unmatedReads ] => { SRR2454059.fq.gz }; ### [ libType ] => { ISF }; ### [ useVBOpt ] => { }; ### [ output ] => { test_quant }; ### [ numGibbsSamples ] => { 100 }; ### [ threads ] => { 16 }; Logs will be written to test_quant/logs; [2016-12-13 22:38:54.413] [jointLog] [info] parsing read library format; [2016-12-13 22:38:54.413] [jointLog] [info] There is 1 library.; [2016-12-13 22:38:56.240] [stderrLog] [info] Loading Suffix Array; [2016-12-13 22:38:56.240] [jointLog] [info] Loading Quasi index; [2016-12-13 22:38:56.240] [jointLog] [info] Loading 32-bit quasi index; [2016-12-13 22:39:01.268] [stderrLog] [info] Loading Transcript Info; [2016-12-13 22:39:02.630] [stderrLog] [info] Loading Rank-Select Bit Array; [2016-12-13 22:39:03.041] [stderrLog] [info] There were 182608 set bits in the bit array; [2016-12-13 22:39:03.159] [stderrLog] [info] Computing transcript lengths; [2016-12-13 22:39:03.160] [stderrLog] [info] Waiting to finish loading hash; [2016-12-13 22:39:07.653] [stderrLog] [info] Done loading index; [2016-12-13 22:39:07.653] [jointLog] [info] done; [2016-12-13 22:39:07.653] [jointLog] [info] Index contained 182608 targets. processed 19000000 fragments; hits: 65897209; hits per frag: 3.47349. [2016-12-13 22:40:22.572] [jointLog] [info] Computed 137534 rich equivalence classes for further processing; [2016-12-13 22:40:22.572] [jointLog] [info] Counted 16265961 total reads in the equivalence classes; [2016-12-13 22:40:22.618] [jointLog] [info] Mapping rate = 83.509%. [2016-12-13 22:40:22.618] [jointLog] [info] finished quantifyLibrary(); [2016-12-13 22:40:22.619] [jointLog] [info] Starting optimizer; [2016-12-13 22:40:22.904] [jointLog] [info] Marked 0 weighted equivalence classes as degenerate; [2016-12-13 22:40:22.911] [jointLog] [info] iteration = 0 | max rel diff. = 299.976; [2016-12-13 22:40:23.620] [jointLog] [info] iteration = 100 | max rel diff. = 0.121769; [2016-12-13 22:40:24.367] [jointLog] [,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-266934878:1908,load,loading,1908,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-266934878,1,['load'],['loading']
Performance, ] => { Salmon_index_hg38.analysisSet_knownGene }; ### [ unmatedReads ] => { SRR2454059.fq.gz }; ### [ libType ] => { ISF }; ### [ useVBOpt ] => { }; ### [ output ] => { test_quant }; ### [ numGibbsSamples ] => { 100 }; ### [ threads ] => { 16 }; Logs will be written to test_quant/logs; [2016-12-13 22:44:07.409] [jointLog] [info] parsing read library format; [2016-12-13 22:44:07.409] [jointLog] [info] There is 1 library.; [2016-12-13 22:44:09.318] [jointLog] [info] Loading Quasi index; [2016-12-13 22:44:09.318] [jointLog] [info] Loading 32-bit quasi index; [2016-12-13 22:44:09.318] [stderrLog] [info] Loading Suffix Array; [2016-12-13 22:44:15.002] [stderrLog] [info] Loading Transcript Info; [2016-12-13 22:44:16.278] [stderrLog] [info] Loading Rank-Select Bit Array; [2016-12-13 22:44:16.625] [stderrLog] [info] There were 182608 set bits in the bit array; [2016-12-13 22:44:16.680] [stderrLog] [info] Computing transcript lengths; [2016-12-13 22:44:16.681] [stderrLog] [info] Waiting to finish loading hash; [2016-12-13 22:44:20.485] [stderrLog] [info] Done loading index; [2016-12-13 22:44:20.485] [jointLog] [info] done; [2016-12-13 22:44:20.485] [jointLog] [info] Index contained 182608 targets. processed 19000001 fragments; hits: 65897764; hits per frag: 3.48152. [2016-12-13 22:45:33.192] [jointLog] [info] Computed 137534 rich equivalence classes for further processing; [2016-12-13 22:45:33.192] [jointLog] [info] Counted 16265961 total reads in the equivalence classes; [2016-12-13 22:45:33.233] [jointLog] [info] Mapping rate = 83.509%. [2016-12-13 22:45:33.233] [jointLog] [info] finished quantifyLibrary(); [2016-12-13 22:45:33.234] [jointLog] [info] Starting optimizer; [2016-12-13 22:45:33.516] [jointLog] [info] Marked 0 weighted equivalence classes as degenerate; [2016-12-13 22:45:33.523] [jointLog] [info] iteration = 0 | max rel diff. = 299.95; [2016-12-13 22:45:34.217] [jointLog] [info] iteration = 100 | max rel diff. = 0.122252; [2016-12-13 22:45:34.912] [jointLog] [i,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-266935584:1781,load,loading,1781,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-266935584,1,['load'],['loading']
Performance, ] => { }; ### [ geneMap ] => { /home/ryan/references/hg38/Salmon_index_hg38.analysisSet_knownGene/genemap.txt }; ### [ output ] => { salmon_temp/REF/SRR2454069 }; ### [ auxDir ] => { aux_info }; ### [ numGibbsSamples ] => { 10 }; Logs will be written to salmon_temp/REF/SRR2454069/logs; [2016-12-15 15:58:50.157] [jointLog] [info] parsing read library format; [2016-12-15 15:58:50.157] [jointLog] [info] There is 1 library.; [2016-12-15 15:58:50.189] [jointLog] [info] Loading Quasi index; [2016-12-15 15:58:50.189] [jointLog] [info] Loading 32-bit quasi index; [2016-12-15 15:58:50.189] [stderrLog] [info] Loading Suffix Array; [2016-12-15 15:58:50.513] [stderrLog] [info] Loading Transcript Info; [2016-12-15 15:58:50.599] [stderrLog] [info] Loading Rank-Select Bit Array; [2016-12-15 15:58:50.661] [stderrLog] [info] There were 182608 set bits in the bit array; [2016-12-15 15:58:50.677] [stderrLog] [info] Computing transcript lengths; [2016-12-15 15:58:50.677] [stderrLog] [info] Waiting to finish loading hash; [2016-12-15 15:58:50.677] [stderrLog] [info] Done loading index; [2016-12-15 15:58:50.677] [jointLog] [info] done; [2016-12-15 15:58:50.677] [jointLog] [info] Index contained 182608 targets; [2016-12-15 15:58:51.587] [jointLog] [warning] Fragment GC bias correction is currently *experimental* in single-end libraries. Please use this option with caution. processed 16500000 fragments; hits: 44017772; hits per frag: 2.67057. [2016-12-15 16:01:44.937] [jointLog] [info] Computed 119318 rich equivalence classes for further processing; [2016-12-15 16:01:44.937] [jointLog] [info] Counted 12227080 total reads in the equivalence classes; [2016-12-15 16:01:44.948] [jointLog] [info] Mapping rate = 72.5194%. [2016-12-15 16:01:44.948] [jointLog] [info] finished quantifyLibrary(); [2016-12-15 16:01:44.949] [jointLog] [info] Starting optimizer; [2016-12-15 16:01:45.059] [jointLog] [info] Marked 0 weighted equivalence classes as degenerate; [2016-12-15 16:01:45.075] [jointLog] [info] i,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267489196:1554,load,loading,1554,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267489196,1,['load'],['loading']
Performance," decoys or the organism's genome as a decoy whenever possible. . 4) Related to @k3yavi's response and my elaboration above: we have dropped quasi-mapping from 1.0.0 (though something akin to it may return in the future if there is sufficient demand and if the shortcomings described in the manuscript can be overcome). However, as I mention in part 3 above, this doesn't mean it's not possible to use v1.0.0 without an explicit decoy sequence. The `--decoy` flag of the indexing command is optional, not required. We will update this in the documentation making it more explicit. However, as @k3yavi points out, it is true that if you wish to use quasi-mapping and selective-alignment against the full genome on the same machine, you will need both versions, as quasi-mapping is supported only in the [RapMap](https://github.com/COMBINE-lab/RapMap/tree/develop-salmon), while indexing something on the scale of the genome when not using the [pufferfish-based](https://github.com/COMBINE-lab/pufferfish/tree/develop) index has tremendous memory requirements (as is not recommended ). 5 & 6) To re-iterate @k3yavi's answer --- the extra flags used in the pre-print were only for the purpose of holding as many variables fixed as possible when comparing different approaches. It continues to be recommended to use the VBEM over the EM; it seems to perform better with respect to the ways in which we can measure and such improvements have also been documented in [other work](https://www.ncbi.nlm.nih.gov/pubmed/23821651). The _main_ effect of `--mimicBT2` is to discard orphan alignments for the purposes of quantification. This is a more strict requirement than the default behavior of allowing orphans if there is no satisfactory alignment of both ends of a fragment. However, there is no obvious reason why it is better behavior than accounting for these orphan fragments (when appropriately adjusting the conditional probability given their distance from the transcript boundaries, as salmon does).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/442#issuecomment-549195390:2739,perform,perform,2739,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/442#issuecomment-549195390,1,['perform'],['perform']
Performance," even seem to be trying to load the index! I obviously don't have the same set of reads you do, but here is what I get when using this pre-compiled binary on the 64-bit index (this is a small read set from single-cell data, which is why the total # of reads is so small). ```; rob@feynman:/mnt/scratch3/rob/JoshTest$ ~/SoftwareStaging/salmon/scripts/SalmonBeta-0.6.5-pre_CentOS5/bin/salmon quant -p 15 -i salmon_index -l IU -1 ../strange_peak/19232_1_1.fastq -2 ../strange_peak/19232_1_2.fastq -o quant_binary; Version Info: This is the most recent version of Salmon.; # salmon (mapping-based) v0.6.0; # [ program ] => salmon; # [ command ] => quant; # [ threads ] => { 15 }; # [ index ] => { salmon_index }; # [ libType ] => { IU }; # [ mates1 ] => { ../strange_peak/19232_1_1.fastq }; # [ mates2 ] => { ../strange_peak/19232_1_2.fastq }; # [ output ] => { quant_binary }; Logs will be written to quant_binary/logs; there is 1[2016-03-31 14:05:14.184] [jointLog] [info] parsing read library format; lib; Loading 64-bit quasi index[2016-03-31 14:05:14.266] [stderrLog] [info] Loading Suffix Array; [2016-03-31 14:05:14.266] [jointLog] [info] Loading Quasi index. [2016-03-31 14:07:58.647] [stderrLog] [info] Loading Transcript Info; [2016-03-31 14:08:59.703] [stderrLog] [info] Loading Rank-Select Bit Array; [2016-03-31 14:09:06.744] [stderrLog] [info] There were 2027284 set bits in the bit array; [2016-03-31 14:09:08.123] [stderrLog] [info] Computing transcript lengths; [2016-03-31 14:09:08.240] [stderrLog] [info] Waiting to finish loading hash; Index contained 2027284 targets; [2016-03-31 14:09:15.789] [jointLog] [info] done; [2016-03-31 14:09:15.786] [stderrLog] [info] Successfully loaded position hash; [2016-03-31 14:09:15.789] [stderrLog] [info] Done loading index. [2016-03-31 14:09:36.623] [jointLog] [info] Computed 8083 rich equivalence classes for further processing; [2016-03-31 14:09:36.623] [jointLog] [info] Counted 159824 total reads in the equivalence classes. [2016-03-31 14",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/54#issuecomment-204066023:1043,Load,Loading,1043,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/54#issuecomment-204066023,1,['Load'],['Loading']
Performance," first column will be the per CB level mapping rate i.e. `#mapped reads/#raw reads`. If you wan't absolute values for per-CB reads and mapped reads, it should be in the file `filtered_cb_frequency.txt` and `mappedUMI.txt` respectively.; * `re: cellranger subsampling:` Correct me if I am wrong, when you say cellranger subsampling, do you mean the `cellranger aggregate` pipeline? It's possible you are talking about some other step which I am not aware of but if it's `aggregate` then I think it happens downstream of all the quantification. Indeed coverage bias correction is an important part of the aggregation step but in general it's not the only one and that's why we recommend using the `Seurat` package downstream of the Alevin quantified matrices. We will be more than happy to write a tutorial on, ""how to perform batch correction downstream of Alevin"" but in summary the following steps would be the gist of the process.; - Use Alevin w/o any modification to the `fastq` on both of your sample to generate the gene count matrices. (We have made a major upgrade to the Alevin. We'd recommend using [v0.12.0-alpha](https://github.com/COMBINE-lab/salmon/tree/v0.12.0-alpha) for now, we are planning to make an official release before the end of this week, currently you can use pre-release. Unfortunately, not available on conda yet).; - Import Alevin count matrices into R using [this](https://combine-lab.github.io/alevin-tutorial/2018/alevin-seurat/) tutorial .; - Use [this](https://satijalab.org/seurat/immune_alignment.html) to perform the batch correction. ; We do realize it's currently complicated to use things downstream of Alevin and are working constantly on improving the overall pipeline to make the analyses as smooth as possible. If you happen to write a tutorial of your own on doing the analyses, we'd be happy to include that in Alevin tutorial page. However, if you get stuck with any of the above steps do let us know, we'd be more than happy to help in that front too.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/305#issuecomment-433169468:2673,perform,perform,2673,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/305#issuecomment-433169468,1,['perform'],['perform']
Performance," noticed that when the jobs fail due to memory (the actual issue in this thread) they fail after the `There is 1 library` message as shown below for one test:. ```; [2017-04-05 14:28:09.021] [jointLog] [info] parsing read library format; [2017-04-05 14:28:09.035] [jointLog] [info] There is 1 library.; terminate called without an active exception; /cm/local/apps/sge/var/spool/compute-064/job_scripts/420662: line 31: 28651 Aborted (core dumped) /dcl01/lieber/ajaffe/Emily/RNAseq-pipelin; e/Software/Salmon-0.8.2_linux_x86_64/bin/salmon quant -i /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode; .v25.transcripts -p 1 -l ISR -1 ${FILE1} -2 ${FILE2} -o /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test7/${ID}; ```. Files that work well, keep on going:. ```; [2017-04-05 14:30:23.757] [jointLog] [info] parsing read library format; [2017-04-05 14:30:23.767] [jointLog] [info] There is 1 library.; [2017-04-05 14:30:24.378] [jointLog] [info] Loading Quasi index; ```. I don't know if that hint makes you suspect anything in `Salmon`. . Now, for some tests only task 2 runs and it turns out that task 2 has a smaller fastq file than the other 2:. ```bash; $ ls -lh merged_fastq/R1000[1-3]*; -rw-r--r-- 1 lcollado lieber_jaffe 6.2G Feb 20 12:39 merged_fastq/R10001_D2B1WACXX.fastq.gz; -rw-r--r-- 1 lcollado lieber_jaffe 6.3G Feb 20 12:40 merged_fastq/R10001_D2B1WACXX_read2.fastq.gz; -rw-r--r-- 1 lcollado lieber_jaffe 4.6G Feb 20 12:42 merged_fastq/R10002_C29P7ACXX.fastq.gz; -rw-r--r-- 1 lcollado lieber_jaffe 4.7G Feb 20 12:44 merged_fastq/R10002_C29P7ACXX_read2.fastq.gz; -rw-r--r-- 1 lcollado lieber_jaffe 7.1G Feb 20 12:47 merged_fastq/R10003_D19KGACXX.fastq.gz; -rw-r--r-- 1 lcollado lieber_jaffe 7.1G Feb 20 12:50 merged_fastq/R10003_D19KGACXX_read2.fastq.gz; ```. where R10001* is task 1, R10002* is task 2, R10003* is task 3. So it looks like at some point Salmon is asking for some memory based on the input data. ## Strace test with ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:1180,Load,Loading,1180,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,1,['Load'],['Loading']
Performance," salmon (mapping-based) v0.8.2; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts }; ### [ threads ] => { 1 }; ### [ libType ] => { ISR }; ### [ mates1 ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/merged_fastq/R10001_D2B1WACXX.fastq.gz }; ### [ mates2 ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/merged_fastq/R10001_D2B1WACXX_read2.fastq.gz }; ### [ output ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test5/R10001_D2B1WACXX }; Logs will be written to /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test5/R10001_D2B1WACXX/logs; [1m[2017-03-29 23:59:18.699] [jointLog] [info] parsing read library format; [00m[1m[2017-03-29 23:59:18.721] [jointLog] [info] There is 1 library.; [00m[1m[2017-03-30 00:43:17.278] [stderrLog] [info] Loading Suffix Array ; [00m[1m[2017-03-30 00:43:17.237] [jointLog] [info] Loading Quasi index; [00m[1m[2017-03-30 00:43:17.273] [jointLog] [info] Loading 32-bit quasi index; [00m[1m[2017-03-30 02:37:54.437] [stderrLog] [info] Loading Transcript Info ; [00m[1m[2017-03-30 03:48:21.310] [stderrLog] [info] Loading Rank-Select Bit Array; [00m[1m[2017-03-30 04:20:16.735] [stderrLog] [info] There were 198093 set bits in the bit array; [00m[1m[2017-03-30 04:54:34.486] [stderrLog] [info] Computing transcript lengths; [00m[1m[2017-03-30 04:54:34.487] [stderrLog] [info] Waiting to finish loading hash; [00m[1m[2017-03-30 05:09:36.706] [stderrLog] [info] Done loading index; [00m[1m[2017-03-30 05:09:36.706] [jointLog] [info] done; [00m[1m[2017-03-30 05:09:36.790] [jointLog] [info] Index contained 198093 targets; [00m. [A. [32mprocessed[31m 500000 [32mfragments[0m; hits: 699833, hits per frag: 1.4138[A. [32mprocessed[31m 1000000 [32mfragments[0m; hits: 1395659, hits per frag: 1.40267[A. [32mprocessed[31m 1500000 [32mfragments[0m; hits: 2097294, hits per",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-290516965:9927,Load,Loading,9927,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-290516965,1,['Load'],['Loading']
Performance," see that the most striking difference is `MSAD_157177.t1` in Run B. The number of estimated reads isn't quite as high as with eXpress, but a considerable number of reads map to `MSAD_157177.t1` (and the posterior variance is still rather large). Given that the behavior you observe using default settings in Salmon is similar to what you observe in RSEM, my guess is that the allocation for `MSAD_157177.t1` in Run B from both of these methods is a result of the strong tendency of the EM algorithm toward sparsity. Though eXpress uses a variant of the EM algorithm, it's actually an *online* EM algorithm, and makes use of a small prior, both of which regularize the estimates it produces. In an offline algorithm (or the offline phase of a dual-algorithm method like Salmon), the same thing can be achieved by using a ""more Bayesian"" inference algorithm than the EM (in this case, using the VBEM algorithm). Most of the time, there is very strong agreement between the estimates produced by different optimization algorithms, but sometimes, as in this case, they can differ considerably. It's still an open area of research and analysis to determine if one such method is ""better"" than another. However, if you have strong external information telling you that `MSAD_157177.t1` should actually be expressed at a non-trivial level in Run B, it looks like the VBEM is giving you a better estimate here. Coming back to the suggestion in your original post, there is no good way, in the optimization procedure to ""switch off the re-assignment between similar genes"", since that is the entire point of the algorithm, and heuristically disabling certain reassignments would destroy any statistical guarantees of the procedure. However, regularizing the estimates is an alternative way of balancing the likelihood based assignment of the EM algorithm with some prior belief (and the strength of this prior belief can be tweaked, in Salmon, by modifying the `--vbPrior` argument when the `--useVBOpt` flag",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/107#issuecomment-263793798:3456,optimiz,optimization,3456,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/107#issuecomment-263793798,1,['optimiz'],['optimization']
Performance," strandedness:unstranded }; [2020-04-21 10:11:42.553] [jointLog] [info] setting maxHashResizeThreads to 8; [2020-04-21 10:11:42.553] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2020-04-21 10:11:42.553] [jointLog] [info] numQuantThreads = 4; parseThreads = 4; Checking that provided alignment files have consistent headers . . . done; Populating targets from aln = ""sample_alignments.sam"", fasta = ""../sample_data/transcripts.fasta"" . . .done; [2020-04-21 10:11:43.180] [jointLog] [info] replaced 0 non-ACGT nucleotides with random nucleotides. processed 0 reads in current round; killing thread 3 . . . done. Freeing memory used by read queue . . . 00; Joined parsing thread . . . ""sample_alignments.sam""; Closed all files . . .; Emptied frag queue. . . [2020-04-21 10:11:43.477] [jointLog] [info]. Completed first pass through the alignment file.; Total # of mapped reads : 10000; # of uniquely mapped reads : 6913; # ambiguously mapped reads : 3087. [2020-04-21 10:11:43.489] [jointLog] [info] Computed 27 rich equivalence classes for further processing; [2020-04-21 10:11:43.489] [jointLog] [info] Counted 10,000 total reads in the equivalence classes; [2020-04-21 10:11:43.490] [jointLog] [warning] Only 10000 fragments were mapped, but the number of burn-in fragments was set to 5000000.; The effective lengths have been computed using the observed mappings. [2020-04-21 10:11:43.492] [jointLog] [info] starting optimizer; [2020-04-21 10:11:43.493] [jointLog] [info] Marked 0 weighted equivalence classes as degenerate; [2020-04-21 10:11:43.493] [jointLog] [info] iteration = 0 | max rel diff. = 14.87; [2020-04-21 10:11:43.495] [jointLog] [info] iteration = 100 | max rel diff. = 9.59592e-05; [2020-04-21 10:11:43.495] [jointLog] [info] finished optimizer; [2020-04-21 10:11:43.495] [jointLog] [info] writing output. Emptied Alignemnt Group Pool. .; Emptied Alignment Group Queue. . . done; ```. Let me know if this works for you.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/511#issuecomment-617206094:2710,optimiz,optimizer,2710,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/511#issuecomment-617206094,3,"['Queue', 'optimiz']","['Queue', 'optimizer']"
Performance," subsetting from Biostrings, but in the premature case the strand information is used. Of course, this problem is out of the scope of this forum so it will be okay to close this issue. I will reach out to the developers of GenomicRanges and Biostrings to point out this potential problem and seek their guidance. Thank you again for all your help. Rached. ```; # setwd('wd'). options(scipen = 9999). libraries <- lapply(; X = c('data.table', 'magrittr', 'rtracklayer', 'Biostrings', 'reshape2', 'ggplot2'),; FUN = library, character.only = TRUE; ). ### Inputs ####; anot.gtf <- '../../shared_data/annotations/Ensembl/Homo_sapiens.GRCh38.101.gtf.gz' # Ensembl GTF; genome.fasta <- '../../shared_data/annotations/Ensembl/Homo_sapiens.GRCh38.dna.primary_assembly.fa.gz' # Genome fasta from Ensembl; gencode.tx.fasta <- '../../shared_data/annotations/Gencode/gencode.v35.transcripts.fa.gz' # Gencode transcript FASTA. dotPlot.fname <- '../ouput/dotPlots.pdf'. ### Read exon annotations ####; message('Loading Ensembl exon annotation (1-22, X, Y, MT)...'). chromosomes <- c(1:22, 'X', 'Y', 'MT'). anot <- import(anot.gtf, feature = 'exon') %>% sort; anot <- anot[seqnames(anot) %in% chromosomes, ]. # append gene and transcript version numbers to IDs; anot$gene_id <- paste(anot$gene_id, anot$gene_version, sep = '.'); anot$transcript_id <- paste(anot$transcript_id, anot$transcript_version, sep = '.'). ### Create premature transcript annotations ####; message('Creating premature transcript annotation...'). anot.pre <- split(anot, anot$transcript_id); anot.pre <- anot.pre[lengths(anot.pre) > 1] %>% range %>% unlist %>% sort # only consider transcripts with > 1 exon. anot.pre$transcript_range <- as.character(anot.pre); anot.pre$gene_id <- anot[match(names(anot.pre), anot$transcript_id), ]$gene_id. # collapse replicate pre-mature transcripts per gene...; names(anot.pre) <- anot.pre$premature_group <- sapply(; split(; names(anot.pre),; paste(anot.pre$gene_id, anot.pre$transcript_range, sep = '_');",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/655#issuecomment-826035191:4285,Load,Loading,4285,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/655#issuecomment-826035191,1,['Load'],['Loading']
Performance," the GDB manual and other documentation resources online at:; <http://www.gnu.org/software/gdb/documentation/>.; For help, type ""help"".; Type ""apropos word"" to search for commands related to ""word""...; Reading symbols from /u/user/local/bin/salmon...done.; (gdb) run alevin -l ISR --chromium -p 4 -o BM_1/alevin -1 ./BM_1/run1/bm_S10_L001_R1_001.fastq.gz -2 ./BM_1/run1/bm_S10_L001_R2_001.fastq.gz --maxHashResizeThreads 2 -i /u/user/ref/cellranger/salmon/transcripts_index --tgMap tx2gene.txt; Starting program: /u/user/local/bin/salmon alevin -l ISR --chromium -p 4 -o BM_1/alevin -1 ./BM_1/run1/bm_S10_L001_R1_001.fastq.gz -2 ./BM_1/run1/bm_S10_L001_R2_001.fastq.gz --maxHashResizeThreads 2 -i /u/user/ref/cellranger/salmon/transcripts_index --tgMap tx2gene.txt; [Thread debugging using libthread_db enabled]; Using host libthread_db library ""/lib/x86_64-linux-gnu/libthread_db.so.1"".; warning: File ""/u/user/local/lib64/libstdc++.so.6.0.21-gdb.py"" auto-loading has been declined by your `auto-load safe; -path' set to ""$debugdir:$datadir/auto-load"".; To enable execution of this file add; add-auto-load-safe-path /u/user/local/lib64/libstdc++.so.6.0.21-gdb.py; line to your configuration file ""/u/user/.gdbinit"".; To completely disable this security protection add; set auto-load safe-path /; line to your configuration file ""/u/user/.gdbinit"".; For more information about this security protection see the; ""Auto-loading safe path"" section in the GDB manual. E.g., run from the shell:; info ""(gdb)Auto-loading safe path""; [New Thread 0x7fff7dbff700 (LWP 21437)]; [Thread 0x7fff7dbff700 (LWP 21437) exited]; Version Info: Could not resolve upgrade information in the alotted time.; Check for upgrades manually at https://combine-lab.github.io/salmon; [New Thread 0x7ffefcfff700 (LWP 21653)]; Logs will be written to BM_1/alevin/logs; [New Thread 0x7ffe7cffe700 (LWP 21654)]; [New Thread 0x7ffdfcffd700 (LWP 21655)]; [New Thread 0x7ffd7cffc700 (LWP 21656)]; ### salmon (single-cell-based) v0.10.3; #",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-396078627:1718,load,loading,1718,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-396078627,3,['load'],"['load', 'loading']"
Performance," the extent permitted by law. Type ""show copying""; and ""show warranty"" for details.; This GDB was configured as ""x86_64-linux-gnu"".; Type ""show configuration"" for configuration details.; For bug reporting instructions, please see:; <http://www.gnu.org/software/gdb/bugs/>.; Find the GDB manual and other documentation resources online at:; <http://www.gnu.org/software/gdb/documentation/>.; For help, type ""help"".; Type ""apropos word"" to search for commands related to ""word"".; Attaching to process 29332; [New LWP 29334]; [New LWP 29335]; [New LWP 29336]; [New LWP 21224]; [New LWP 21225]; [New LWP 21226]; [New LWP 21227]; [New LWP 21228]; [New LWP 21229]; [New LWP 21230]; [Thread debugging using libthread_db enabled]; Using host libthread_db library ""/lib/x86_64-linux-gnu/libthread_db.so.1"".; 0x00007fcb8cf73789 in __ieee754_log_avx (x=<optimized out>) at ../sysdeps/ieee754/dbl-64/e_log.c:193; 193	../sysdeps/ieee754/dbl-64/e_log.c: No such file or directory.; #0 0x00007fcb8cf73789 in __ieee754_log_avx (x=<optimized out>) at ../sysdeps/ieee754/dbl-64/e_log.c:193; #1 0x0000000000637ccc in double std::gamma_distribution<double>::operator()<pcg_detail::engine<unsigned int, unsigned long, pcg_detail::xsh_rr_mixin<unsigned int, unsigned long>, true, pcg_detail::unique_stream<unsigned long>, pcg_detail::default_multiplier<unsigned long> > >(pcg_detail::engine<unsigned int, unsigned long, pcg_detail::xsh_rr_mixin<unsigned int, unsigned long>, true, pcg_detail::unique_stream<unsigned long>, pcg_detail::default_multiplier<unsigned long> >&, std::gamma_distribution<double>::param_type const&) (); #2 0x0000000000634b8d in tbb::interface9::internal::start_for<tbb::blocked_range<unsigned long>, sampleRoundNonCollapsedMultithreaded_(std::vector<std::pair<TranscriptGroup const, TGValue>, std::allocator<std::pair<TranscriptGroup const, TGValue> > >&, std::vector<bool, std::allocator<bool> >&, std::vector<unsigned long, std::allocator<unsigned long> >&, std::vector<double, std::allocator<do",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267488748:1374,optimiz,optimized,1374,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267488748,1,['optimiz'],['optimized']
Performance," time to validate Salmon's functionality. Indeed, Salmon is not the problem here. After taking a closer look at my transcript fasta, I noticed a problem with it, as you suggested. Long story short, half the premature transcripts had the wrong orientation and complementarity. Long story:. Oddly, the mature sequences were fine even though I used an identical approach to subset premature and mature transcripts from the genome reference!. Briefly my approach relied on three R packages rtracklayer, GenomicRanges, and Biostrings. 1. I used rtracklayer to load a gtf formatted exon annotations acquired from Ensembl. The file is loaded as a GenomicRanges object which essentially describes the locus of each exon (the transcribed strand [+ or -], chromosome, start and end positions relative to the reference strand) and its associated gene and transcript. 2. I used the GRanges object to generate pre-RNA coordinates that span all exons of a transcript. 3. I loaded the reference genome fasta acquired from Ensembl using the Biostrings package. GRanges and Biostrings are tightly integrated, allowing me to subset sequences from a Biostrings object using the GRanges object. **I believe the problem lies here.** It appears that when subsetting the mature exonic sequences from Biostrings using GRanges, the strand field in the GRanges object **was not** utilized. I.e., I needed to get the reverse complement of the extracted sequences for transcripts on the minus strand. I had done that and assumed that this behaviour would be consistent. However, for reasons I have not been able to pinpoint (potentially a bug), the strand information **was accounted for** when I used GRanges to subset the premature sequences. I **did not** need to get the reverse complement of the premature sequences on the minus strand as I had to do for the mature sequences. Yet, I did that anyway. I initially did test my protocol to ensure it produced identical transcript sequences to Gencode, but I only did this for ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/655#issuecomment-826035191:1393,load,loaded,1393,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/655#issuecomment-826035191,1,['load'],['loaded']
Performance,"""apropos word"" to search for commands related to ""word""...; Reading symbols from salmon...done.; (gdb) r; Starting program: /home/common/modules/el8/x86_64/software/salmon/1.2.1-CentOS-vanilla/bin/salmon index -t transcripts.fasta -i sample_salmon_fmd_index --type fmd; Missing separate debuginfos, use: yum debuginfo-install glibc-2.28-72.el8_1.1.x86_64; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; [Thread debugging using libthread_db enabled]; Using host libthread_db library ""/lib64/libthread_db.so.1"".; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641594410:2954,Load,Loadable,2954,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641594410,1,['Load'],['Loadable']
Performance,"# Create premature transcript annotations ####; message('Creating premature transcript annotation...'). anot.pre <- split(anot, anot$transcript_id); anot.pre <- anot.pre[lengths(anot.pre) > 1] %>% range %>% unlist %>% sort # only consider transcripts with > 1 exon. anot.pre$transcript_range <- as.character(anot.pre); anot.pre$gene_id <- anot[match(names(anot.pre), anot$transcript_id), ]$gene_id. # collapse replicate pre-mature transcripts per gene...; names(anot.pre) <- anot.pre$premature_group <- sapply(; split(; names(anot.pre),; paste(anot.pre$gene_id, anot.pre$transcript_range, sep = '_'); ),; paste, collapse = ';'; )[; paste(anot.pre$gene_id, anot.pre$transcript_range, sep = '_'); ]. # ... need to convert GR to data.table before unique because unique method for GR class ignores metadata and rownames; anot.pre <- as.data.table(anot.pre) %>% unique %>% makeGRangesFromDataFrame(., keep.extra.columns = T); names(anot.pre) <- anot.pre$premature_group. ### Read human genome sequence ####; message('Loading genome sequence...'). dna <- readDNAStringSet(filepath = genome.fasta). # simplify chromosome names; names(dna) <- sapply(strsplit(names(dna), ' '), '[', 1). dna <- dna[chromosomes] # subset chrom 1-22, X, Y, MT. ### Read Gencode transcript sequences ####; gencode <- readDNAStringSet(gencode.tx.fasta); names(gencode) <- gsub(; pattern = '\\|.*', replacement = '',; x = names(gencode); ). ### Sample transcripts on + and - strand (and avoid premature transcripts with multiple mature counterparts for simplicity); anot.pre <- anot.pre[order(width(anot.pre), decreasing = F), ]. chosenOnesP <- anot.pre[; strand(anot.pre) == '+' & !grepl(';', anot.pre$premature_group) & anot.pre$premature_group %in% names(gencode) & !duplicated(anot.pre$premature_group) &; anot.pre$premature_group %in% anot[anot$transcript_source == 'ensembl_havana']$transcript_id; ]$premature_group[1]. chosenOnesM <- anot.pre[; strand(anot.pre) == '-' & !grepl(';', anot.pre$premature_group) & anot.pre$prema",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/655#issuecomment-826035191:5701,Load,Loading,5701,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/655#issuecomment-826035191,1,['Load'],['Loading']
Performance,"## salmon (mapping-based) v0.11.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { /data2/csijcs/hg38/hg38.transcriptome.index }; ### [ libType ] => { A }; ### [ mates1 ] => { /data2/csijcs/AML/RNA_seq/AML_total_MNC/total_MNCs/Fresh_samples/RHM5942/RHM5942_R1_001.fastq.gz }; ### [ mates2 ] => { /data2/csijcs/AML/RNA_seq/AML_total_MNC/total_MNCs/Fresh_samples/RHM5942/RHM5942_R2_001.fastq.gz }; ### [ threads ] => { 32 }; ### [ output ] => { /data2/csijcs/AML/RNA_seq/AML_total_MNC/total_MNCs/Fresh_samples/salmon_quants/RHM5942 }; Logs will be written to /data2/csijcs/AML/RNA_seq/AML_total_MNC/total_MNCs/Fresh_samples/salmon_quants/RHM5942/logs; [2018-07-27 16:24:55.658] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2018-07-27 16:24:55.658] [jointLog] [info] parsing read library format; [2018-07-27 16:24:55.658] [jointLog] [info] There is 1 library.; [2018-07-27 16:25:01.242] [jointLog] [info] Loading Quasi index; [2018-07-27 16:25:01.242] [jointLog] [info] Loading 32-bit quasi index; [2018-07-27 16:25:01.243] [stderrLog] [info] Loading Suffix Array ; [2018-07-27 16:25:42.630] [stderrLog] [info] Loading Transcript Info ; [2018-07-27 16:25:45.683] [stderrLog] [info] Loading Rank-Select Bit Array; [2018-07-27 16:25:47.834] [stderrLog] [info] There were 203027 set bits in the bit array; [2018-07-27 16:25:48.128] [stderrLog] [info] Computing transcript lengths; [2018-07-27 16:25:48.200] [stderrLog] [info] Waiting to finish loading hash; [2018-07-27 16:25:48.331] [stderrLog] [info] Done loading index; [2018-07-27 16:25:48.331] [jointLog] [info] done; [2018-07-27 16:25:48.331] [jointLog] [info] Index contained 203027 targets. processed 239500000 fragmentsintLog] [info] Automatically detected most likely library type as ISR; hits: 651420499, hits per frag: 2.72282[2018-07-27 16:51:47.947] [jointLog] [info] Thread saw mini-batch with a maximum of 1.70% zero probability fragments; [2018-07-27 ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/261#issuecomment-409427898:1254,Load,Loading,1254,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/261#issuecomment-409427898,1,['Load'],['Loading']
Performance,### [ index ] => { /home/ryan/references/hg38/Salmon_index_hg38.analysisSet_knownGene }; ### [ libType ] => { SR }; ### [ unmatedReads ] => { fastq_files/SRR2454069.fq.gz }; ### [ threads ] => { 8 }; ### [ seqBias ] => { }; ### [ gcBias ] => { }; ### [ useVBOpt ] => { }; ### [ dumpEq ] => { }; ### [ dumpEqWeights ] => { }; ### [ geneMap ] => { /home/ryan/references/hg38/Salmon_index_hg38.analysisSet_knownGene/genemap.txt }; ### [ output ] => { salmon_temp/REF/SRR2454069 }; ### [ auxDir ] => { aux_info }; ### [ numGibbsSamples ] => { 10 }; Logs will be written to salmon_temp/REF/SRR2454069/logs; [2016-12-15 15:58:50.157] [jointLog] [info] parsing read library format; [2016-12-15 15:58:50.157] [jointLog] [info] There is 1 library.; [2016-12-15 15:58:50.189] [jointLog] [info] Loading Quasi index; [2016-12-15 15:58:50.189] [jointLog] [info] Loading 32-bit quasi index; [2016-12-15 15:58:50.189] [stderrLog] [info] Loading Suffix Array; [2016-12-15 15:58:50.513] [stderrLog] [info] Loading Transcript Info; [2016-12-15 15:58:50.599] [stderrLog] [info] Loading Rank-Select Bit Array; [2016-12-15 15:58:50.661] [stderrLog] [info] There were 182608 set bits in the bit array; [2016-12-15 15:58:50.677] [stderrLog] [info] Computing transcript lengths; [2016-12-15 15:58:50.677] [stderrLog] [info] Waiting to finish loading hash; [2016-12-15 15:58:50.677] [stderrLog] [info] Done loading index; [2016-12-15 15:58:50.677] [jointLog] [info] done; [2016-12-15 15:58:50.677] [jointLog] [info] Index contained 182608 targets; [2016-12-15 15:58:51.587] [jointLog] [warning] Fragment GC bias correction is currently *experimental* in single-end libraries. Please use this option with caution. processed 16500000 fragments; hits: 44017772; hits per frag: 2.67057. [2016-12-15 16:01:44.937] [jointLog] [info] Computed 119318 rich equivalence classes for further processing; [2016-12-15 16:01:44.937] [jointLog] [info] Counted 12227080 total reads in the equivalence classes; [2016-12-15 16:01:44.948] [joint,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267489196:1225,Load,Loading,1225,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267489196,1,['Load'],['Loading']
Performance,"+1. Trying to quantify ~2000 Smart-Seq2 samples. Currently takes about 5 days on a single node doing 1 cell at a time. Perhaps an easier way to implement this would be to provide a batch mode such that you load the index once and then serially quantify a batch of N samples within the same process. This would save the significant overhead of having to load the index for each sample (~50-75% of the total per-sample processing time). As a bonus, the batch mode could spit out a single transcript x sample matrix so you wouldn't have to run `quantmerge` separately.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/335#issuecomment-1416422342:206,load,load,206,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/335#issuecomment-1416422342,2,['load'],['load']
Performance,", without segfault. ```; [vale@ebi-003 salmon-problem]$ bash run_salmon.sh; Version Info: This is the most recent version of Salmon.; # salmon (mapping-based) v0.6.0; # [ program ] => salmon; # [ command ] => quant; # [ index ] => { mouse_cdna_38.p3.78_repbase_ercc.fa }; # [ libType ] => { IU }; # [ mates1 ] => { SRP057125_SRS936134_1.fastq }; # [ mates2 ] => { SRP057125_SRS936134_2.fastq }; # [ output ] => { SRP057125_SRS936134_salmon_out }; # [ biasCorrect ] => { }; # [ useFSPD ] => { }; Logs will be written to SRP057125_SRS936134_salmon_out/logs; [2016-01-02 20:16:39.349] [jointLog] [info] parsing read library format; there is 1 lib; Loading 32-bit quasi index[2016-01-02 20:16:39.895] [stderrLog] [info] Loading Suffix Array; [2016-01-02 20:16:39.895] [stderrLog] [info] Loading Position Hash; [2016-01-02 20:16:39.894] [jointLog] [info] Loading Quasi index; [2016-01-02 20:16:42.565] [stderrLog] [info] Loading Transcript Info; [2016-01-02 20:16:43.654] [stderrLog] [info] Loading Rank-Select Bit Array; [2016-01-02 20:16:44.075] [stderrLog] [info] There were 104534 set bits in the bit array; [2016-01-02 20:16:44.448] [stderrLog] [info] Computing transcript lengths; [2016-01-02 20:16:44.448] [stderrLog] [info] Waiting to finish loading hash; Index contained 104534 targets; [2016-01-02 20:16:57.606] [stderrLog] [info] Done loading index; [2016-01-02 20:16:57.606] [jointLog] [info] done. processed 12000000 fragments; hits: 24367197, hits per frag: 2.06194+06. [2016-01-02 20:17:29.841] [jointLog] [info] Computed 102251 rich equivalence classes for further processing; [2016-01-02 20:17:29.841] [jointLog] [info] Counted 10033689 total reads in the equivalence classes; [2016-01-02 20:17:29.867] [jointLog] [info] Mapping rate = 83.0244%. [2016-01-02 20:17:29.867] [jointLog] [info] finished quantifyLibrary(); [2016-01-02 20:17:29.867] [jointLog] [info] Starting optimizer; [2016-01-02 20:17:30.130] [jointLog] [info] Marked 0 weighted equivalence classes as degenerate; [2016-01-",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/34#issuecomment-168426741:2040,Load,Loading,2040,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/34#issuecomment-168426741,1,['Load'],['Loading']
Performance,"------------------- ; Reallocating bifurcations time: 0 ; True marks count: 14610695 ; Edges construction time: 9 -------------------------------------------------------------------------------- ; Distinct junctions = 1307919 allowedIn: 18 ; Max Junction ID: 1458039 ; seen.size():11664321 kmerInfo.size():1458040 approximateContigTotalLength: 96596288 ; counters for complex kmers: ; (prec>1 & succ>1)=163493 | (succ>1 & isStart)=1600 | (prec>1 & isEnd)=1705 | (isStart & isEnd)=136 contig count: 2046804 element count: 189087548 complex nodes: 166934 ; number of ones in rank vector: 2046803 ; [2022-04-16 11:19:37.060] [puff::index::jointLog] [info] Starting the Pufferfish indexing by reading the GFA binary file. [2022-04-16 11:19:37.060] [puff::index::jointLog] [info] Setting the index/BinaryGfa directory salmon_index_23 ; size = 189087548 ; ----------------------------------------- ; | Loading contigs | Time = 43.37 ms ----------------------------------------- ; size = 189087548 ; ----------------------------------------- ; | Loading contig boundaries | Time = 19.565 ms ----------------------------------------- ; Number of ones: 2046803 ; Number of ones per inventory item: 512 ; Inventory entries filled: 3998 ; 2046803 ; [2022-04-16 11:19:37.638] [puff::index::jointLog] [info] Done wrapping the rank vector with a rank9sel structure. [2022-04-16 11:19:37.687] [puff::index::jointLog] [info] contig count for validation: 2,046,803 ; [2022-04-16 11:19:38.556] [puff::index::jointLog] [info] Total # of Contigs : 2,046,803 ; [2022-04-16 11:19:38.556] [puff::index::jointLog] [info] Total # of numerical Contigs : 2,046,803 ; [2022-04-16 11:19:38.774] [puff::index::jointLog] [info] Total # of contig vec entries: 15,036,896 ; [2022-04-16 11:19:38.774] [puff::index::jointLog] [info] bits per offset entry 24 ; [2022-04-16 11:19:39.637] [puff::index::jointLog] [info] Done constructing the contig vector. 2046804 [2022-04-16 11:19:40.720] [puff::index::jointLog] [info] # segments = 2,04",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/768#issuecomment-1100734317:11812,Load,Loading,11812,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/768#issuecomment-1100734317,1,['Load'],['Loading']
Performance,"-----------------------------------------; | Loading sequence | Time = 1.983 s; -----------------------------------------; size = 572818984; -----------------------------------------; | Loading positions | Time = 14.658 s; -----------------------------------------; size = 942318702; -----------------------------------------; | Loading reference sequence | Time = 1.4932 s; -----------------------------------------; -----------------------------------------; | Loading reference accumulative lengths | Time = 10.959 ms; -----------------------------------------; Error: invalid feature coordinates (end<start!) at line:; NC_029855.1	RefSeq	gene	406748	107842	.	+	.	gene_id ""A5N79_gp28""; db_xref ""GeneID:27215502""; exception ""trans-splicing""; gbkey ""Gene""; gene ""nad2""; gene_biotype ""protein_coding""; locus_tag ""A5N79_gp28""; ; --- . After I remove the erroneous entry, there is no more complaint:. ---; Version Info: This is the most recent version of salmon.; -----------------------------------------; | Loading contig table | Time = 14.648 s; -----------------------------------------; size = 16145665; -----------------------------------------; | Loading contig offsets | Time = 336.77 ms; -----------------------------------------; -----------------------------------------; | Loading reference lengths | Time = 10.195 ms; -----------------------------------------; -----------------------------------------; | Loading mphf table | Time = 2.3113 s; -----------------------------------------; size = 1057188904; Number of ones: 16145664; Number of ones per inventory item: 512; Inventory entries filled: 31535; -----------------------------------------; | Loading contig boundaries | Time = 4.881 s; -----------------------------------------; size = 1057188904; -----------------------------------------; | Loading sequence | Time = 1.7554 s; -----------------------------------------; size = 572818984; -----------------------------------------; | Loading positions | Time = 13.626 s; ---------",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/569#issuecomment-709699746:1956,Load,Loading,1956,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/569#issuecomment-709699746,1,['Load'],['Loading']
Performance,"---------------------------------------; | Loading reference accumulative lengths | Time = 10.959 ms; -----------------------------------------; Error: invalid feature coordinates (end<start!) at line:; NC_029855.1	RefSeq	gene	406748	107842	.	+	.	gene_id ""A5N79_gp28""; db_xref ""GeneID:27215502""; exception ""trans-splicing""; gbkey ""Gene""; gene ""nad2""; gene_biotype ""protein_coding""; locus_tag ""A5N79_gp28""; ; --- . After I remove the erroneous entry, there is no more complaint:. ---; Version Info: This is the most recent version of salmon.; -----------------------------------------; | Loading contig table | Time = 14.648 s; -----------------------------------------; size = 16145665; -----------------------------------------; | Loading contig offsets | Time = 336.77 ms; -----------------------------------------; -----------------------------------------; | Loading reference lengths | Time = 10.195 ms; -----------------------------------------; -----------------------------------------; | Loading mphf table | Time = 2.3113 s; -----------------------------------------; size = 1057188904; Number of ones: 16145664; Number of ones per inventory item: 512; Inventory entries filled: 31535; -----------------------------------------; | Loading contig boundaries | Time = 4.881 s; -----------------------------------------; size = 1057188904; -----------------------------------------; | Loading sequence | Time = 1.7554 s; -----------------------------------------; size = 572818984; -----------------------------------------; | Loading positions | Time = 13.626 s; -----------------------------------------; size = 942318702; -----------------------------------------; | Loading reference sequence | Time = 1.5082 s; -----------------------------------------; -----------------------------------------; | Loading reference accumulative lengths | Time = 12.272 ms; -----------------------------------------; ---. However, the *.sf files are the same as previous ones, i.e. no gene level results.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/569#issuecomment-709699746:2610,Load,Loading,2610,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/569#issuecomment-709699746,5,['Load'],['Loading']
Performance,"--------------------------------; -----------------------------------------; | Loading reference accumulative lengths | Time = 10.959 ms; -----------------------------------------; Error: invalid feature coordinates (end<start!) at line:; NC_029855.1	RefSeq	gene	406748	107842	.	+	.	gene_id ""A5N79_gp28""; db_xref ""GeneID:27215502""; exception ""trans-splicing""; gbkey ""Gene""; gene ""nad2""; gene_biotype ""protein_coding""; locus_tag ""A5N79_gp28""; ; --- . After I remove the erroneous entry, there is no more complaint:. ---; Version Info: This is the most recent version of salmon.; -----------------------------------------; | Loading contig table | Time = 14.648 s; -----------------------------------------; size = 16145665; -----------------------------------------; | Loading contig offsets | Time = 336.77 ms; -----------------------------------------; -----------------------------------------; | Loading reference lengths | Time = 10.195 ms; -----------------------------------------; -----------------------------------------; | Loading mphf table | Time = 2.3113 s; -----------------------------------------; size = 1057188904; Number of ones: 16145664; Number of ones per inventory item: 512; Inventory entries filled: 31535; -----------------------------------------; | Loading contig boundaries | Time = 4.881 s; -----------------------------------------; size = 1057188904; -----------------------------------------; | Loading sequence | Time = 1.7554 s; -----------------------------------------; size = 572818984; -----------------------------------------; | Loading positions | Time = 13.626 s; -----------------------------------------; size = 942318702; -----------------------------------------; | Loading reference sequence | Time = 1.5082 s; -----------------------------------------; -----------------------------------------; | Loading reference accumulative lengths | Time = 12.272 ms; -----------------------------------------; ---. However, the *.sf files are the same as previo",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/569#issuecomment-709699746:2366,Load,Loading,2366,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/569#issuecomment-709699746,1,['Load'],['Loading']
Performance,"------------------------------; size = 16145665; -----------------------------------------; | Loading contig offsets | Time = 382.03 ms; -----------------------------------------; -----------------------------------------; | Loading reference lengths | Time = 9.4861 ms; -----------------------------------------; -----------------------------------------; | Loading mphf table | Time = 2.4236 s; -----------------------------------------; size = 1057188904; Number of ones: 16145664; Number of ones per inventory item: 512; Inventory entries filled: 31535; -----------------------------------------; | Loading contig boundaries | Time = 4.031 s; -----------------------------------------; size = 1057188904; -----------------------------------------; | Loading sequence | Time = 1.983 s; -----------------------------------------; size = 572818984; -----------------------------------------; | Loading positions | Time = 14.658 s; -----------------------------------------; size = 942318702; -----------------------------------------; | Loading reference sequence | Time = 1.4932 s; -----------------------------------------; -----------------------------------------; | Loading reference accumulative lengths | Time = 10.959 ms; -----------------------------------------; Error: invalid feature coordinates (end<start!) at line:; NC_029855.1	RefSeq	gene	406748	107842	.	+	.	gene_id ""A5N79_gp28""; db_xref ""GeneID:27215502""; exception ""trans-splicing""; gbkey ""Gene""; gene ""nad2""; gene_biotype ""protein_coding""; locus_tag ""A5N79_gp28""; ; --- . After I remove the erroneous entry, there is no more complaint:. ---; Version Info: This is the most recent version of salmon.; -----------------------------------------; | Loading contig table | Time = 14.648 s; -----------------------------------------; size = 16145665; -----------------------------------------; | Loading contig offsets | Time = 336.77 ms; -----------------------------------------; -----------------------------------------; | Loading r",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/569#issuecomment-709699746:1278,Load,Loading,1278,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/569#issuecomment-709699746,1,['Load'],['Loading']
Performance,"-----------------------------; -----------------------------------------; | Loading reference lengths | Time = 9.4861 ms; -----------------------------------------; -----------------------------------------; | Loading mphf table | Time = 2.4236 s; -----------------------------------------; size = 1057188904; Number of ones: 16145664; Number of ones per inventory item: 512; Inventory entries filled: 31535; -----------------------------------------; | Loading contig boundaries | Time = 4.031 s; -----------------------------------------; size = 1057188904; -----------------------------------------; | Loading sequence | Time = 1.983 s; -----------------------------------------; size = 572818984; -----------------------------------------; | Loading positions | Time = 14.658 s; -----------------------------------------; size = 942318702; -----------------------------------------; | Loading reference sequence | Time = 1.4932 s; -----------------------------------------; -----------------------------------------; | Loading reference accumulative lengths | Time = 10.959 ms; -----------------------------------------; Error: invalid feature coordinates (end<start!) at line:; NC_029855.1	RefSeq	gene	406748	107842	.	+	.	gene_id ""A5N79_gp28""; db_xref ""GeneID:27215502""; exception ""trans-splicing""; gbkey ""Gene""; gene ""nad2""; gene_biotype ""protein_coding""; locus_tag ""A5N79_gp28""; ; --- . After I remove the erroneous entry, there is no more complaint:. ---; Version Info: This is the most recent version of salmon.; -----------------------------------------; | Loading contig table | Time = 14.648 s; -----------------------------------------; size = 16145665; -----------------------------------------; | Loading contig offsets | Time = 336.77 ms; -----------------------------------------; -----------------------------------------; | Loading reference lengths | Time = 10.195 ms; -----------------------------------------; -----------------------------------------; | Loading mphf table | Tim",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/569#issuecomment-709699746:1412,Load,Loading,1412,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/569#issuecomment-709699746,1,['Load'],['Loading']
Performance,"----------; size = 942318702; -----------------------------------------; | Loading reference sequence | Time = 1.4932 s; -----------------------------------------; -----------------------------------------; | Loading reference accumulative lengths | Time = 10.959 ms; -----------------------------------------; Error: invalid feature coordinates (end<start!) at line:; NC_029855.1	RefSeq	gene	406748	107842	.	+	.	gene_id ""A5N79_gp28""; db_xref ""GeneID:27215502""; exception ""trans-splicing""; gbkey ""Gene""; gene ""nad2""; gene_biotype ""protein_coding""; locus_tag ""A5N79_gp28""; ; --- . After I remove the erroneous entry, there is no more complaint:. ---; Version Info: This is the most recent version of salmon.; -----------------------------------------; | Loading contig table | Time = 14.648 s; -----------------------------------------; size = 16145665; -----------------------------------------; | Loading contig offsets | Time = 336.77 ms; -----------------------------------------; -----------------------------------------; | Loading reference lengths | Time = 10.195 ms; -----------------------------------------; -----------------------------------------; | Loading mphf table | Time = 2.3113 s; -----------------------------------------; size = 1057188904; Number of ones: 16145664; Number of ones per inventory item: 512; Inventory entries filled: 31535; -----------------------------------------; | Loading contig boundaries | Time = 4.881 s; -----------------------------------------; size = 1057188904; -----------------------------------------; | Loading sequence | Time = 1.7554 s; -----------------------------------------; size = 572818984; -----------------------------------------; | Loading positions | Time = 13.626 s; -----------------------------------------; size = 942318702; -----------------------------------------; | Loading reference sequence | Time = 1.5082 s; -----------------------------------------; -----------------------------------------; | Loading reference accumu",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/569#issuecomment-709699746:2232,Load,Loading,2232,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/569#issuecomment-709699746,1,['Load'],['Loading']
Performance,"-------; size = 572818984; -----------------------------------------; | Loading positions | Time = 14.658 s; -----------------------------------------; size = 942318702; -----------------------------------------; | Loading reference sequence | Time = 1.4932 s; -----------------------------------------; -----------------------------------------; | Loading reference accumulative lengths | Time = 10.959 ms; -----------------------------------------; Error: invalid feature coordinates (end<start!) at line:; NC_029855.1	RefSeq	gene	406748	107842	.	+	.	gene_id ""A5N79_gp28""; db_xref ""GeneID:27215502""; exception ""trans-splicing""; gbkey ""Gene""; gene ""nad2""; gene_biotype ""protein_coding""; locus_tag ""A5N79_gp28""; ; --- . After I remove the erroneous entry, there is no more complaint:. ---; Version Info: This is the most recent version of salmon.; -----------------------------------------; | Loading contig table | Time = 14.648 s; -----------------------------------------; size = 16145665; -----------------------------------------; | Loading contig offsets | Time = 336.77 ms; -----------------------------------------; -----------------------------------------; | Loading reference lengths | Time = 10.195 ms; -----------------------------------------; -----------------------------------------; | Loading mphf table | Time = 2.3113 s; -----------------------------------------; size = 1057188904; Number of ones: 16145664; Number of ones per inventory item: 512; Inventory entries filled: 31535; -----------------------------------------; | Loading contig boundaries | Time = 4.881 s; -----------------------------------------; size = 1057188904; -----------------------------------------; | Loading sequence | Time = 1.7554 s; -----------------------------------------; size = 572818984; -----------------------------------------; | Loading positions | Time = 13.626 s; -----------------------------------------; size = 942318702; -----------------------------------------; | Loading reference",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/569#issuecomment-709699746:2101,Load,Loading,2101,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/569#issuecomment-709699746,1,['Load'],['Loading']
Performance,"-0.7.12.3/bwamem.c; bwa-0.7.12.3/bwamem.h; bwa-0.7.12.3/bwamem_extra.c; bwa-0.7.12.3/bwamem_pair.c; bwa-0.7.12.3/bwape.c; bwa-0.7.12.3/bwase.c; bwa-0.7.12.3/bwase.h; bwa-0.7.12.3/bwaseqio.c; bwa-0.7.12.3/bwashm.c; bwa-0.7.12.3/bwt.c; bwa-0.7.12.3/bwt.h; bwa-0.7.12.3/bwt_gen.c; bwa-0.7.12.3/bwt_lite.c; bwa-0.7.12.3/bwt_lite.h; bwa-0.7.12.3/bwtaln.c; bwa-0.7.12.3/bwtaln.h; bwa-0.7.12.3/bwtgap.c; bwa-0.7.12.3/bwtgap.h; bwa-0.7.12.3/bwtindex.c; bwa-0.7.12.3/bwtsw2.h; bwa-0.7.12.3/bwtsw2_aux.c; bwa-0.7.12.3/bwtsw2_chain.c; bwa-0.7.12.3/bwtsw2_core.c; bwa-0.7.12.3/bwtsw2_main.c; bwa-0.7.12.3/bwtsw2_pair.c; bwa-0.7.12.3/example.c; bwa-0.7.12.3/fastmap.c; bwa-0.7.12.3/is.c; bwa-0.7.12.3/kbtree.h; bwa-0.7.12.3/khash.h; bwa-0.7.12.3/kopen.c; bwa-0.7.12.3/kseq.h; bwa-0.7.12.3/ksort.h; bwa-0.7.12.3/kstring.c; bwa-0.7.12.3/kstring.h; bwa-0.7.12.3/ksw.c; bwa-0.7.12.3/ksw.h; bwa-0.7.12.3/kthread.c; bwa-0.7.12.3/kvec.h; bwa-0.7.12.3/main.c; bwa-0.7.12.3/malloc_wrap.c; bwa-0.7.12.3/malloc_wrap.h; bwa-0.7.12.3/maxk.c; bwa-0.7.12.3/pemerge.c; bwa-0.7.12.3/qualfa2fq.pl; bwa-0.7.12.3/utils.c; bwa-0.7.12.3/utils.h; bwa-0.7.12.3/xa2multi.pl; [ 50%] No patch step for 'libbwa'; [ 50%] No update step for 'libbwa'; [ 51%] No configure step for 'libbwa'; [ 51%] Performing build step for 'libbwa'; /bin/ld: cannot find -lz; collect2: error: ld returned 1 exit status; make[3]: *** [bwa] Error 1; make[2]: *** [libbwa-prefix/src/libbwa-stamp/libbwa-build] Error 2; make[1]: *** [CMakeFiles/libbwa.dir/all] Error 2; make: *** [all] Error 2. So as you said I'd say its having issued finding the zlibs library. Similar to how I used 'DZLIB_LIBRARY=/users/work/jake/bin/zlib-1.2.11/zlib.h' to specify the zlib library for 'cmake', is there a way to do it for the 'make' command? I've tried using the following but haven't had success:; make -I /users/work/jake/bin/zlib-1.2.11/zlib.h; make --include-dir=/users/work/jake/bin/zlib-1.2.11/zlib.h. Sorry for the very basic questions.... I'm kind of learning as I go.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/141#issuecomment-314451873:3409,Perform,Performing,3409,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/141#issuecomment-314451873,1,['Perform'],['Performing']
Performance,"-06 11:16:56.218] [jointLog] [info] There are 2 libraries.; [2018-12-06 11:16:56.292] [jointLog] [info] Loading Quasi index; [2018-12-06 11:16:56.294] [jointLog] [info] Loading 32-bit quasi index; [2018-12-06 11:16:56.205] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify. [2018-12-06 11:16:56.218] [alevinLog] [info] parsing read library format; [2018-12-06 11:16:56.296] [stderrLog] [info] Loading Suffix Array ; [2018-12-06 11:16:56.846] [stderrLog] [info] Loading Transcript Info ; [2018-12-06 11:16:57.009] [stderrLog] [info] Loading Rank-Select Bit Array; [2018-12-06 11:16:57.046] [stderrLog] [info] There were 167,268 set bits in the bit array; [2018-12-06 11:16:57.063] [stderrLog] [info] Computing transcript lengths; [2018-12-06 11:16:57.064] [stderrLog] [info] Waiting to finish loading hash; [2018-12-06 11:17:00.929] [jointLog] [info] done; [2018-12-06 11:17:00.929] [jointLog] [info] Index contained 167,268 targets. processed 267 Million fragmentsrrLog] [info] Done loading index; hits: 844899161, hits per frag: 3.15864^[[D. [2018-12-06 11:45:12.188] [jointLog] [info] Computed 118,295 rich equivalence classes for further processing; [2018-12-06 11:45:12.188] [jointLog] [info] Counted 154,595,094 total reads in the equivalence classes ; [2018-12-06 11:45:12.188] [jointLog] [warning] Found 115077 reads with `N` in the UMI sequence and ignored the reads.; Please report on github if this number is too large; [2018-12-06 11:45:12.188] [jointLog] [info] Mapping rate = 57.7821%. [2018-12-06 11:45:12.188] [jointLog] [info] finished quantifyLibrary(); [2018-12-06 11:45:13.385] [alevinLog] [info] Starting optimizer. Analyzed 5344 cells (100% of all).; [2018-12-06 11:49:42.634] [alevinLog] [info] Total 4845644.00 UMI after deduplicating.; [2018-12-06 11:49:42.722] [alevinLog] [info] Clearing EqMap; Might take some time.; [2018-12-06 11:49:47.400] [alevinLog] [info] Starting Import of the gene count matrix of size 5344x167268.; Exception : [std::bad_alloc]; ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/328#issuecomment-445008548:6944,load,loading,6944,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/328#issuecomment-445008548,1,['load'],['loading']
Performance,"-12 15:08:51.141] [alevinLog] [info] Done importing white-list Barcodes; [2018-12-12 15:08:51.141] [alevinLog] [warning] Skipping 1 Barcodes with 0 reads; Assuming this is the required behavior.; [2018-12-12 15:08:51.141] [alevinLog] [info] Total 95 white-listed Barcodes; [2018-12-12 15:08:51.144] [alevinLog] [info] Done populating Z matrix; [2018-12-12 15:08:51.146] [alevinLog] [info] Done indexing Barcodes; [2018-12-12 15:08:51.146] [alevinLog] [info] Total Unique barcodes found: 4096; [2018-12-12 15:08:51.146] [alevinLog] [info] Used Barcodes except Whitelist: 1864; [2018-12-12 15:08:51.272] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify. [2018-12-12 15:08:51.272] [alevinLog] [info] parsing read library format; [2018-12-12 15:08:51.375] [stderrLog] [info] Loading Suffix Array ; [2018-12-12 15:08:51.272] [jointLog] [info] There is 1 library.; [2018-12-12 15:08:51.375] [jointLog] [info] Loading Quasi index; [2018-12-12 15:08:51.375] [jointLog] [info] Loading 32-bit quasi index; [2018-12-12 15:09:10.216] [stderrLog] [info] Loading Transcript Info ; [2018-12-12 15:09:15.719] [stderrLog] [info] Loading Rank-Select Bit Array; [2018-12-12 15:09:16.330] [stderrLog] [info] There were 205,870 set bits in the bit array; [2018-12-12 15:09:16.343] [stderrLog] [info] Computing transcript lengths; [2018-12-12 15:09:16.343] [stderrLog] [info] Waiting to finish loading hash; [2018-12-12 15:09:21.460] [stderrLog] [info] Done loading index; [2018-12-12 15:09:21.460] [jointLog] [info] done; [2018-12-12 15:09:21.460] [jointLog] [info] Index contained 205,870 targets. processed 0 Million fragments; processed 1 Million fragments; processed 1 Million fragments; ..............; processed 74 Million fragments; hits: 111594303, hits per frag: 1.50848[2018-12-12 15:12:07.666] [jointLog] [info] Thread saw mini-batch with a maximum of 5.34% zero probability fragments; [2018-12-12 15:12:07.677] [jointLog] [info] Thread saw mini-batch with a maximum of 5.48% zero probabilit",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/329#issuecomment-446668422:4386,Load,Loading,4386,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/329#issuecomment-446668422,1,['Load'],['Loading']
Performance,-based) v0.7.3; ### [ program ] => salmon; ### [ command ] => quant; ### [ index ] => { /home/ryan/references/hg38/Salmon_index_hg38.analysisSet_knownGene }; ### [ libType ] => { SR }; ### [ unmatedReads ] => { fastq_files/SRR2454069.fq.gz }; ### [ threads ] => { 8 }; ### [ seqBias ] => { }; ### [ gcBias ] => { }; ### [ useVBOpt ] => { }; ### [ dumpEq ] => { }; ### [ dumpEqWeights ] => { }; ### [ geneMap ] => { /home/ryan/references/hg38/Salmon_index_hg38.analysisSet_knownGene/genemap.txt }; ### [ output ] => { salmon_temp/REF/SRR2454069 }; ### [ auxDir ] => { aux_info }; ### [ numGibbsSamples ] => { 10 }; Logs will be written to salmon_temp/REF/SRR2454069/logs; [2016-12-15 15:58:50.157] [jointLog] [info] parsing read library format; [2016-12-15 15:58:50.157] [jointLog] [info] There is 1 library.; [2016-12-15 15:58:50.189] [jointLog] [info] Loading Quasi index; [2016-12-15 15:58:50.189] [jointLog] [info] Loading 32-bit quasi index; [2016-12-15 15:58:50.189] [stderrLog] [info] Loading Suffix Array; [2016-12-15 15:58:50.513] [stderrLog] [info] Loading Transcript Info; [2016-12-15 15:58:50.599] [stderrLog] [info] Loading Rank-Select Bit Array; [2016-12-15 15:58:50.661] [stderrLog] [info] There were 182608 set bits in the bit array; [2016-12-15 15:58:50.677] [stderrLog] [info] Computing transcript lengths; [2016-12-15 15:58:50.677] [stderrLog] [info] Waiting to finish loading hash; [2016-12-15 15:58:50.677] [stderrLog] [info] Done loading index; [2016-12-15 15:58:50.677] [jointLog] [info] done; [2016-12-15 15:58:50.677] [jointLog] [info] Index contained 182608 targets; [2016-12-15 15:58:51.587] [jointLog] [warning] Fragment GC bias correction is currently *experimental* in single-end libraries. Please use this option with caution. processed 16500000 fragments; hits: 44017772; hits per frag: 2.67057. [2016-12-15 16:01:44.937] [jointLog] [info] Computed 119318 rich equivalence classes for further processing; [2016-12-15 16:01:44.937] [jointLog] [info] Counted 12227080 tota,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267489196:1158,Load,Loading,1158,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267489196,1,['Load'],['Loading']
Performance,-us; eVBOpt --output test_quant --numGibbsSamples 100 --threads 16; Version Info: This is the most recent **development version** of Salmon.; ### salmon (mapping-based) v0.7.3; ### [ program ] => salmon; ### [ command ] => quant; ### [ index ] => { Salmon_index_hg38.analysisSet_knownGene }; ### [ unmatedReads ] => { SRR2454059.fq.gz }; ### [ libType ] => { ISF }; ### [ useVBOpt ] => { }; ### [ output ] => { test_quant }; ### [ numGibbsSamples ] => { 100 }; ### [ threads ] => { 16 }; Logs will be written to test_quant/logs; [2016-12-13 22:44:07.409] [jointLog] [info] parsing read library format; [2016-12-13 22:44:07.409] [jointLog] [info] There is 1 library.; [2016-12-13 22:44:09.318] [jointLog] [info] Loading Quasi index; [2016-12-13 22:44:09.318] [jointLog] [info] Loading 32-bit quasi index; [2016-12-13 22:44:09.318] [stderrLog] [info] Loading Suffix Array; [2016-12-13 22:44:15.002] [stderrLog] [info] Loading Transcript Info; [2016-12-13 22:44:16.278] [stderrLog] [info] Loading Rank-Select Bit Array; [2016-12-13 22:44:16.625] [stderrLog] [info] There were 182608 set bits in the bit array; [2016-12-13 22:44:16.680] [stderrLog] [info] Computing transcript lengths; [2016-12-13 22:44:16.681] [stderrLog] [info] Waiting to finish loading hash; [2016-12-13 22:44:20.485] [stderrLog] [info] Done loading index; [2016-12-13 22:44:20.485] [jointLog] [info] done; [2016-12-13 22:44:20.485] [jointLog] [info] Index contained 182608 targets. processed 19000001 fragments; hits: 65897764; hits per frag: 3.48152. [2016-12-13 22:45:33.192] [jointLog] [info] Computed 137534 rich equivalence classes for further processing; [2016-12-13 22:45:33.192] [jointLog] [info] Counted 16265961 total reads in the equivalence classes; [2016-12-13 22:45:33.233] [jointLog] [info] Mapping rate = 83.509%. [2016-12-13 22:45:33.233] [jointLog] [info] finished quantifyLibrary(); [2016-12-13 22:45:33.234] [jointLog] [info] Starting optimizer; [2016-12-13 22:45:33.516] [jointLog] [info] Marked 0 weighted equi,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-266935584:1522,Load,Loading,1522,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-266935584,1,['Load'],['Loading']
Performance,-useVBOpt --output test_quant --; numGibbsSamples 100 --threads 16; Version Info: This is the most recent **development version** of Salmon.; ### salmon (mapping-based) v0.7.3; ### [ program ] => salmon; ### [ command ] => quant; ### [ index ] => { Salmon_index_hg38.analysisSet_knownGene }; ### [ unmatedReads ] => { SRR2454059.fq.gz }; ### [ libType ] => { ISF }; ### [ useVBOpt ] => { }; ### [ output ] => { test_quant }; ### [ numGibbsSamples ] => { 100 }; ### [ threads ] => { 16 }; Logs will be written to test_quant/logs; [2016-12-13 22:38:54.413] [jointLog] [info] parsing read library format; [2016-12-13 22:38:54.413] [jointLog] [info] There is 1 library.; [2016-12-13 22:38:56.240] [stderrLog] [info] Loading Suffix Array; [2016-12-13 22:38:56.240] [jointLog] [info] Loading Quasi index; [2016-12-13 22:38:56.240] [jointLog] [info] Loading 32-bit quasi index; [2016-12-13 22:39:01.268] [stderrLog] [info] Loading Transcript Info; [2016-12-13 22:39:02.630] [stderrLog] [info] Loading Rank-Select Bit Array; [2016-12-13 22:39:03.041] [stderrLog] [info] There were 182608 set bits in the bit array; [2016-12-13 22:39:03.159] [stderrLog] [info] Computing transcript lengths; [2016-12-13 22:39:03.160] [stderrLog] [info] Waiting to finish loading hash; [2016-12-13 22:39:07.653] [stderrLog] [info] Done loading index; [2016-12-13 22:39:07.653] [jointLog] [info] done; [2016-12-13 22:39:07.653] [jointLog] [info] Index contained 182608 targets. processed 19000000 fragments; hits: 65897209; hits per frag: 3.47349. [2016-12-13 22:40:22.572] [jointLog] [info] Computed 137534 rich equivalence classes for further processing; [2016-12-13 22:40:22.572] [jointLog] [info] Counted 16265961 total reads in the equivalence classes; [2016-12-13 22:40:22.618] [jointLog] [info] Mapping rate = 83.509%. [2016-12-13 22:40:22.618] [jointLog] [info] finished quantifyLibrary(); [2016-12-13 22:40:22.619] [jointLog] [info] Starting optimizer; [2016-12-13 22:40:22.904] [jointLog] [info] Marked 0 weighted equi,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-266934878:1649,Load,Loading,1649,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-266934878,1,['Load'],['Loading']
Performance,". I processed the data above using the latest salmon from the develop branch; (the release candidate for 1.3.0), and I got the following time (used 8; threads, so timing is not directly comparable). ```; 4604.57user 43.64system 9:24.15elapsed 823%CPU; ```. The whole log is. ```; [2020-06-15 23:51:54.747] [jointLog] [info] setting maxHashResizeThreads to; 8; [2020-06-15 23:51:54.747] [jointLog] [info] Fragment incompatibility prior; below threshold. Incompatible fragments will be ignored.; [2020-06-15 23:51:54.747] [jointLog] [info] Usage of --validateMappings; implies use of minScoreFraction. Since not explicitly specified, it is; being set to 0.65; [2020-06-15 23:51:54.747] [jointLog] [info] Usage of --validateMappings; implies a default consensus slack of 0.2. Setting consensusSlack to 0.35.; [2020-06-15 23:51:54.747] [jointLog] [info] parsing read library format; [2020-06-15 23:51:54.747] [jointLog] [info] There is 1 library.; [2020-06-15 23:51:54.814] [jointLog] [info] Loading pufferfish index; [2020-06-15 23:51:54.814] [jointLog] [info] Loading dense pufferfish index.; [2020-06-15 23:51:55.555] [jointLog] [info] done; [2020-06-15 23:51:55.555] [jointLog] [info] Index contained 116,248 targets; [2020-06-15 23:51:55.588] [jointLog] [info] Number of decoys : 0; [2020-06-16 00:00:59.666] [jointLog] [info] Computed 344,764 rich; equivalence classes for further processing; [2020-06-16 00:00:59.666] [jointLog] [info] Counted 12,956,134 total reads; in the equivalence classes; [2020-06-16 00:00:59.673] [jointLog] [warning] 0.0736383% of fragments were; shorter than the k used to build the index.; If this fraction is too large, consider re-building the index with a; smaller k.; The minimum read size found was 1. [2020-06-16 00:00:59.673] [jointLog] [info] Number of mappings discarded; because of alignment score : 134,091,887; [2020-06-16 00:00:59.673] [jointLog] [info] Number of fragments entirely; discarded because of alignment score : 2,429,390; [2020-06-16 00:00:59.6",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/537#issuecomment-644527727:1742,Load,Loading,1742,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/537#issuecomment-644527727,1,['Load'],['Loading']
Performance,".1 boost/1.70.0-gcc libiconv/1.16; export CC=`which gcc`; export CXX=`which c++`. cd $MODULE_HOME; mkdir -p source/$PACKAGE_NAME/$VERSION; INSTALL_DIR=$MODULE_HOME/modules/$PACKAGE_NAME/$VERSION; mkdir -p $INSTALL_DIR; mkdir -p modfiles/$PACKAGE_NAME. cd source/$PACKAGE_NAME/$VERSION; wget $LATEST_RELEASE -O - | tar -xz --strip-components 1; cmake -DBOOST_ROOT=/global/software/sl-7.x86_64/modules/gcc/7.4.0/boost/1.70.0-gcc -DCMAKE_INSTALL_PREFIX=$INSTALL_DIR; make; ```; And the tail of the output from make:. ```; creating: /clusterfs/vector/home/groups/software/sl-7.x86_64/source/salmon/1.5.1/scripts/../external/pufferfish-salmon-v1.5.1/tests/compile_tests/; inflating: /clusterfs/vector/home/groups/software/sl-7.x86_64/source/salmon/1.5.1/scripts/../external/pufferfish-salmon-v1.5.1/tests/compile_tests/int128_numeric_limits.cpp ; -- fetch PUFFERFISH exit code 0; -- Found ZLIB: /usr/lib64/libz.so (found version ""1.2.11"") ; -- Performing Test Iconv_IS_BUILT_IN; -- Performing Test Iconv_IS_BUILT_IN - Failed; CMake Error at /global/home/groups/consultsw/sl-7.x86_64/modules/cmake/3.15.1/share/cmake-3.15/Modules/FindPackageHandleStandardArgs.cmake:137 (message):; Could NOT find Iconv (missing: Iconv_LIBRARY); Call Stack (most recent call first):; /global/home/groups/consultsw/sl-7.x86_64/modules/cmake/3.15.1/share/cmake-3.15/Modules/FindPackageHandleStandardArgs.cmake:378 (_FPHSA_FAILURE_MESSAGE); /global/home/groups/consultsw/sl-7.x86_64/modules/cmake/3.15.1/share/cmake-3.15/Modules/FindIconv.cmake:120 (find_package_handle_standard_args); CMakeLists.txt:362 (find_package). -- Configuring incomplete, errors occurred!; See also ""/clusterfs/vector/home/groups/software/sl-7.x86_64/source/salmon/1.5.1/CMakeFiles/CMakeOutput.log"".; See also ""/clusterfs/vector/home/groups/software/sl-7.x86_64/source/salmon/1.5.1/CMakeFiles/CMakeError.log"".; ```; I'm also attaching the full CMake logs. This is right at the edge of my knowledge, so I'm not 100% sure I got libiconv installed corre",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/453#issuecomment-862737315:1768,Perform,Performing,1768,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/453#issuecomment-862737315,2,['Perform'],['Performing']
Performance,"/alevin -1 ./BM_1/run1/bm_S10_L001_R1_001.fastq.gz -2 ./BM_1/run1/bm_S10_L001_R2_001.fastq.gz --maxHashResizeThreads 2 -i /u/user/ref/cellranger/salmon/transcripts_index --tgMap tx2gene.txt; [Thread debugging using libthread_db enabled]; Using host libthread_db library ""/lib/x86_64-linux-gnu/libthread_db.so.1"".; warning: File ""/u/user/local/lib64/libstdc++.so.6.0.21-gdb.py"" auto-loading has been declined by your `auto-load safe; -path' set to ""$debugdir:$datadir/auto-load"".; To enable execution of this file add; add-auto-load-safe-path /u/user/local/lib64/libstdc++.so.6.0.21-gdb.py; line to your configuration file ""/u/user/.gdbinit"".; To completely disable this security protection add; set auto-load safe-path /; line to your configuration file ""/u/user/.gdbinit"".; For more information about this security protection see the; ""Auto-loading safe path"" section in the GDB manual. E.g., run from the shell:; info ""(gdb)Auto-loading safe path""; [New Thread 0x7fff7dbff700 (LWP 21437)]; [Thread 0x7fff7dbff700 (LWP 21437) exited]; Version Info: Could not resolve upgrade information in the alotted time.; Check for upgrades manually at https://combine-lab.github.io/salmon; [New Thread 0x7ffefcfff700 (LWP 21653)]; Logs will be written to BM_1/alevin/logs; [New Thread 0x7ffe7cffe700 (LWP 21654)]; [New Thread 0x7ffdfcffd700 (LWP 21655)]; [New Thread 0x7ffd7cffc700 (LWP 21656)]; ### salmon (single-cell-based) v0.10.3; ### [ program ] => salmon; ### [ command ] => alevin; ### [ libType ] => { ISR }; ### [ chromium ] => { }; ### [ threads ] => { 4 }; ### [ output ] => { BM_1/alevin }; ### [ mates1 ] => { ./BM_1/run1/bm_S10_L001_R1_001.fastq.gz }; ### [ mates2 ] => { ./BM_1/run1/bm_S10_L001_R2_001.fastq.gz }; ### [ maxHashResizeThreads ] => { 2 }; ### [ index ] => { /u/user/ref/cellranger/salmon/transcripts_index }; ### [ tgMap ] => { tx2gene.txt }. [2018-06-10 16:07:09.798] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [New ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-396078627:2267,load,loading,2267,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-396078627,1,['load'],['loading']
Performance,"/csijcs/AML/RNA_seq/AML_total_MNC/total_MNCs/Fresh_samples/RHM5942/RHM5942_R1_001.fastq.gz }; ### [ mates2 ] => { /data2/csijcs/AML/RNA_seq/AML_total_MNC/total_MNCs/Fresh_samples/RHM5942/RHM5942_R2_001.fastq.gz }; ### [ threads ] => { 32 }; ### [ output ] => { /data2/csijcs/AML/RNA_seq/AML_total_MNC/total_MNCs/Fresh_samples/salmon_quants/RHM5942 }; Logs will be written to /data2/csijcs/AML/RNA_seq/AML_total_MNC/total_MNCs/Fresh_samples/salmon_quants/RHM5942/logs; [2018-07-27 16:24:55.658] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2018-07-27 16:24:55.658] [jointLog] [info] parsing read library format; [2018-07-27 16:24:55.658] [jointLog] [info] There is 1 library.; [2018-07-27 16:25:01.242] [jointLog] [info] Loading Quasi index; [2018-07-27 16:25:01.242] [jointLog] [info] Loading 32-bit quasi index; [2018-07-27 16:25:01.243] [stderrLog] [info] Loading Suffix Array ; [2018-07-27 16:25:42.630] [stderrLog] [info] Loading Transcript Info ; [2018-07-27 16:25:45.683] [stderrLog] [info] Loading Rank-Select Bit Array; [2018-07-27 16:25:47.834] [stderrLog] [info] There were 203027 set bits in the bit array; [2018-07-27 16:25:48.128] [stderrLog] [info] Computing transcript lengths; [2018-07-27 16:25:48.200] [stderrLog] [info] Waiting to finish loading hash; [2018-07-27 16:25:48.331] [stderrLog] [info] Done loading index; [2018-07-27 16:25:48.331] [jointLog] [info] done; [2018-07-27 16:25:48.331] [jointLog] [info] Index contained 203027 targets. processed 239500000 fragmentsintLog] [info] Automatically detected most likely library type as ISR; hits: 651420499, hits per frag: 2.72282[2018-07-27 16:51:47.947] [jointLog] [info] Thread saw mini-batch with a maximum of 1.70% zero probability fragments; [2018-07-27 16:51:47.947] [jointLog] [info] Thread saw mini-batch with a maximum of 1.68% zero probability fragments; [2018-07-27 16:51:47.947] [jointLog] [info] Thread saw mini-batch with a maximum of 1.68% zero probabi",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/261#issuecomment-409427898:1460,Load,Loading,1460,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/261#issuecomment-409427898,1,['Load'],['Loading']
Performance,"/el8/x86_64/software/salmon/1.2.1-CentOS-vanilla/bin/salmon index -t transcripts.fasta -i sample_salmon_fmd_index --type fmd; Missing separate debuginfos, use: yum debuginfo-install glibc-2.28-72.el8_1.1.x86_64; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; [Thread debugging using libthread_db enabled]; Using host libthread_db library ""/lib64/libthread_db.so.1"".; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641594410:3098,Load,Loadable,3098,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641594410,1,['Load'],['Loadable']
Performance,"/www.gnu.org/software/gdb/documentation/>. For help, type ""help"".; Type ""apropos word"" to search for commands related to ""word""...; Reading symbols from salmon...done.; (gdb) r; Starting program: /home/common/modules/el8/x86_64/software/salmon/1.2.1-CentOS-vanilla/bin/salmon index -t transcripts.fasta -i sample_salmon_fmd_index --type fmd; Missing separate debuginfos, use: yum debuginfo-install glibc-2.28-72.el8_1.1.x86_64; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; [Thread debugging using libthread_db enabled]; Using host libthread_db library ""/lib64/libthread_db.so.1"".; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641594410:2882,Load,Loadable,2882,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641594410,1,['Load'],['Loadable']
Performance,"0.4 1524 1524.000 0.000000 0.000; LOC_Os01g01040.1 2508 2508.000 0.000000 0.000; LOC_Os01g01040.2 2482 2482.000 0.000000 0.000; LOC_Os01g01040.3 2583 2583.000 0.000000 0.000; LOC_Os01g01050.1 2039 2039.000 0.000000 0.000. [2019-03-04 01:24:12.788] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2019-03-04 01:24:12.788] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2019-03-04 01:24:12.788] [jointLog] [info] Usage of --validateMappings implies use of range factorization. rangeFactorizationBins is being set to 4; [2019-03-04 01:24:12.788] [jointLog] [info] Usage of --validateMappings implies a default consensus slack of 1. Setting consensusSlack to 1.; [2019-03-04 01:24:12.788] [jointLog] [info] parsing read library format; [2019-03-04 01:24:12.788] [jointLog] [info] There is 1 library.; [2019-03-04 01:24:12.852] [jointLog] [info] Loading Quasi index; [2019-03-04 01:24:12.852] [jointLog] [info] Loading 32-bit quasi index; [2019-03-04 01:24:19.703] [jointLog] [info] done; [2019-03-04 01:24:19.704] [jointLog] [info] Index contained 66,004 targets; [2019-03-04 01:25:14.064] [jointLog] [info] Thread saw mini-batch with a maximum of 91.10% zero probability fragments; [2019-03-04 01:25:14.075] [jointLog] [info] Thread saw mini-batch with a maximum of 90.58% zero probability fragments; [2019-03-04 01:25:14.085] [jointLog] [info] Thread saw mini-batch with a maximum of 90.64% zero probability fragments; [2019-03-04 01:25:14.089] [jointLog] [info] Thread saw mini-batch with a maximum of 91.08% zero probability fragments; [2019-03-04 01:25:14.091] [jointLog] [info] Thread saw mini-batch with a maximum of 90.72% zero probability fragments; [2019-03-04 01:25:14.093] [jointLog] [info] Thread saw mini-batch with a maximum of 90.78% zero probability fragments; [2019-03-04 01:25:14.102] [jointLog] [info] Thread saw mini-batch with a maxi",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/346#issuecomment-469215256:4218,Load,Loading,4218,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/346#issuecomment-469215256,1,['Load'],['Loading']
Performance,"0/20741299/60f84c1a-b697-11e6-9f83-1554ff471e94.png). So, as you can see, there is a substantial amount of uncertainty in RunA, especially for `MSAD_200218.t1`. This can explain how you see this transcript obtaining different numbers of reads over different executions for Run A. Specifically, the inferential uncertainty for this transcript is high, and though the mean of the posterior is close to the value you report above, the range is quite large (200 - 1200) reads (potentially even larger with more bootstraps, but 100 gives us a reasonable window on posterior variance). On the other hand, the EM algorithm *really* wants to assign ~0.8 reads to `MSAD_157177.t1` in Run B. To test how much this might be the result of the tendency of the EM algorithm toward sparsity, I tried processing both samples with Salmon's `--useVBOpt` flag --- causing it to use the variational bayesian optimization algorithm, which yields considerably more *regularized* estimates. The posterior distributions obtained using the VB optimizer are:. ### Run A (VB Opt). ![image](https://cloud.githubusercontent.com/assets/361470/20741629/916b3446-b699-11e6-9f92-b8b6d3519981.png). ![image](https://cloud.githubusercontent.com/assets/361470/20741636/98510f06-b699-11e6-8d9f-34f1c353c3e6.png). ### Run B (VB Opt). ![image](https://cloud.githubusercontent.com/assets/361470/20741642/a1341686-b699-11e6-9a87-8a30f87cd49c.png). ![image](https://cloud.githubusercontent.com/assets/361470/20741645/a7340d5c-b699-11e6-90dd-55f9795bac8f.png). So, while there are some small differences for Run A and transcript `MSAD_200218.t1` in Run B, you can see that the most striking difference is `MSAD_157177.t1` in Run B. The number of estimated reads isn't quite as high as with eXpress, but a considerable number of reads map to `MSAD_157177.t1` (and the posterior variance is still rather large). Given that the behavior you observe using default settings in Salmon is similar to what you observe in RSEM, my guess is that the all",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/107#issuecomment-263793798:1850,optimiz,optimizer,1850,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/107#issuecomment-263793798,1,['optimiz'],['optimizer']
Performance,"0000 0.000; LOC_Os01g01040.2 2482 2482.000 0.000000 0.000; LOC_Os01g01040.3 2583 2583.000 0.000000 0.000; LOC_Os01g01050.1 2039 2039.000 0.000000 0.000. [2019-03-04 01:24:12.788] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2019-03-04 01:24:12.788] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2019-03-04 01:24:12.788] [jointLog] [info] Usage of --validateMappings implies use of range factorization. rangeFactorizationBins is being set to 4; [2019-03-04 01:24:12.788] [jointLog] [info] Usage of --validateMappings implies a default consensus slack of 1. Setting consensusSlack to 1.; [2019-03-04 01:24:12.788] [jointLog] [info] parsing read library format; [2019-03-04 01:24:12.788] [jointLog] [info] There is 1 library.; [2019-03-04 01:24:12.852] [jointLog] [info] Loading Quasi index; [2019-03-04 01:24:12.852] [jointLog] [info] Loading 32-bit quasi index; [2019-03-04 01:24:19.703] [jointLog] [info] done; [2019-03-04 01:24:19.704] [jointLog] [info] Index contained 66,004 targets; [2019-03-04 01:25:14.064] [jointLog] [info] Thread saw mini-batch with a maximum of 91.10% zero probability fragments; [2019-03-04 01:25:14.075] [jointLog] [info] Thread saw mini-batch with a maximum of 90.58% zero probability fragments; [2019-03-04 01:25:14.085] [jointLog] [info] Thread saw mini-batch with a maximum of 90.64% zero probability fragments; [2019-03-04 01:25:14.089] [jointLog] [info] Thread saw mini-batch with a maximum of 91.08% zero probability fragments; [2019-03-04 01:25:14.091] [jointLog] [info] Thread saw mini-batch with a maximum of 90.72% zero probability fragments; [2019-03-04 01:25:14.093] [jointLog] [info] Thread saw mini-batch with a maximum of 90.78% zero probability fragments; [2019-03-04 01:25:14.102] [jointLog] [info] Thread saw mini-batch with a maximum of 90.60% zero probability fragments; [2019-03-04 01:25:14.102] ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/346#issuecomment-469215256:4283,Load,Loading,4283,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/346#issuecomment-469215256,1,['Load'],['Loading']
Performance,"02 20:23:03.751] [stderrLog] [info] Loading Transcript Info; [2016-01-02 20:23:04.776] [stderrLog] [info] Loading Rank-Select Bit Array; [2016-01-02 20:23:05.009] [stderrLog] [info] There were 104534 set bits in the bit array; [2016-01-02 20:23:05.325] [stderrLog] [info] Computing transcript lengths; [2016-01-02 20:23:05.325] [stderrLog] [info] Waiting to finish loading hash; Index contained 104534 targets; [2016-01-02 20:23:16.571] [stderrLog] [info] Done loading index; [2016-01-02 20:23:16.571] [jointLog] [info] done. processed 12000001 fragments; hits: 24367128, hits per frag: 2.04044. [2016-01-02 20:23:49.850] [jointLog] [info] Computed 102251 rich equivalence classes for further processing; [2016-01-02 20:23:49.850] [jointLog] [info] Counted 10033689 total reads in the equivalence classes; [2016-01-02 20:23:49.875] [jointLog] [info] Mapping rate = 83.0244%. [2016-01-02 20:23:49.875] [jointLog] [info] finished quantifyLibrary(); [2016-01-02 20:23:49.875] [jointLog] [info] Starting optimizer; [2016-01-02 20:23:50.378] [jointLog] [info] Marked 0 weighted equivalence classes as degenerate; [2016-01-02 20:23:50.382] [jointLog] [info] iteration = 0 | max rel diff. = 64.9993; [2016-01-02 20:23:50.584] [jointLog] [info] iteration 50, recomputing effective lengths; [2016-01-02 20:23:53.386] [jointLog] [info] iteration = 100 | max rel diff. = 0.263028; [2016-01-02 20:23:53.777] [jointLog] [info] iteration = 200 | max rel diff. = 0.13921; [2016-01-02 20:23:54.171] [jointLog] [info] iteration = 300 | max rel diff. = 0.0536404; [2016-01-02 20:23:54.564] [jointLog] [info] iteration = 400 | max rel diff. = 0.063039; [2016-01-02 20:23:54.954] [jointLog] [info] iteration 500, recomputing effective lengths; [2016-01-02 20:23:57.205] [jointLog] [info] iteration = 500 | max rel diff. = 0.748653; [2016-01-02 20:23:57.662] [jointLog] [info] iteration = 600 | max rel diff. = 0.0535482; [2016-01-02 20:23:58.058] [jointLog] [info] iteration = 700 | max rel diff. = 0.0180352; [2016-01-0",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/34#issuecomment-168426741:8839,optimiz,optimizer,8839,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/34#issuecomment-168426741,1,['optimiz'],['optimizer']
Performance,"029] [alevinLog] [info] # Barcodes Used: 2695632 / 2712324.; [2019-01-29 09:56:52.900] [alevinLog] [info] Knee found left boundary at 692 ; [2019-01-29 09:56:53.219] [alevinLog] [info] Gauss Corrected Boundary at 100 ; [2019-01-29 09:56:53.219] [alevinLog] [info] Learned InvCov: 114.414 normfactor: 148.807; [2019-01-29 09:56:53.219] [alevinLog] [info] Total 293(has 193 low confidence) barcodes; [2019-01-29 09:56:53.224] [alevinLog] [info] Done True Barcode Sampling; [2019-01-29 09:56:53.254] [alevinLog] [info] Done populating Z matrix; [2019-01-29 09:56:53.255] [alevinLog] [info] Done indexing Barcodes; [2019-01-29 09:56:53.255] [alevinLog] [info] Total Unique barcodes found: 125401; [2019-01-29 09:56:53.255] [alevinLog] [info] Used Barcodes except Whitelist: 1256; [2019-01-29 09:56:53.281] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify. [2019-01-29 09:56:53.281] [alevinLog] [info] parsing read library format; [2019-01-29 09:56:53.412] [stderrLog] [info] Loading Suffix Array ; [2019-01-29 09:56:53.281] [jointLog] [info] There is 1 library.; [2019-01-29 09:56:53.410] [jointLog] [info] Loading Quasi index; [2019-01-29 09:56:53.411] [jointLog] [info] Loading 32-bit quasi index; [2019-01-29 09:56:54.551] [stderrLog] [info] Loading Transcript Info ; [2019-01-29 09:56:54.826] [stderrLog] [info] Loading Rank-Select Bit Array; [2019-01-29 09:56:54.883] [stderrLog] [info] There were 80,511 set bits in the bit array; [2019-01-29 09:56:54.908] [stderrLog] [info] Computing transcript lengths; [2019-01-29 09:56:54.908] [stderrLog] [info] Waiting to finish loading hash; [2019-01-29 09:57:09.336] [stderrLog] [info] Done loading index; [2019-01-29 09:57:09.336] [jointLog] [info] done; [2019-01-29 09:57:09.336] [jointLog] [info] Index contained 80,511 targets. processed 2 Million fragments; hits: 812181, hits per frag: 0.326777. [2019-01-29 09:57:36.647] [alevinLog] [info] Starting optimizer; [2019-01-29 09:57:36.587] [jointLog] [info] Computed 12,933 rich equiv",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/337#issuecomment-458481722:8146,Load,Loading,8146,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/337#issuecomment-458481722,1,['Load'],['Loading']
Performance,"05,870 targets. processed 0 Million fragments; processed 1 Million fragments; processed 1 Million fragments; ..............; processed 74 Million fragments; hits: 111594303, hits per frag: 1.50848[2018-12-12 15:12:07.666] [jointLog] [info] Thread saw mini-batch with a maximum of 5.34% zero probability fragments; [2018-12-12 15:12:07.677] [jointLog] [info] Thread saw mini-batch with a maximum of 5.48% zero probability fragments. [2018-12-12 15:12:07.721] [jointLog] [info] Computed 173,365 rich equivalence classes for further processing; [2018-12-12 15:12:07.721] [jointLog] [info] Counted 27,831,508 total reads in the equivalence classes ; [2018-12-12 15:12:07.721] [jointLog] [warning] Found 31347 reads with `N` in the UMI sequence and ignored the reads.; Please report on github if this number is too large; [2018-12-12 15:12:07.721] [jointLog] [info] Mapping rate = 37.4197%. [2018-12-12 15:12:07.721] [jointLog] [info] finished quantifyLibrary(); [2018-12-12 15:12:07.904] [alevinLog] [info] Starting optimizer. Analyzed 7 cells (7% of all).; Analyzed 8 cells (8% of all).; Analyzed 9 cells (9% of all).; Analyzed 10 cells (11% of all).; Analyzed 11 cells (12% of all).; Analyzed 12 cells (13% of all).; Analyzed 13 cells (14% of all).; Analyzed 14 cells (15% of all).; Analyzed 15 cells (16% of all).; Analyzed 16 cells (17% of all).; Analyzed 17 cells (18% of all).; Analyzed 18 cells (19% of all).; Analyzed 19 cells (20% of all).; Analyzed 20 cells (21% of all).; Analyzed 21 cells (22% of all).; Analyzed 22 cells (23% of all).; Analyzed 23 cells (24% of all).; Analyzed 24 cells (25% of all).; Analyzed 25 cells (26% of all).; Analyzed 26 cells (27% of all).; Analyzed 27 cells (28% of all).; Analyzed 28 cells (29% of all).; Analyzed 29 cells (31% of all).; Analyzed 30 cells (32% of all).; Analyzed 31 cells (33% of all).; Analyzed 32 cells (34% of all).; Analyzed 33 cells (35% of all).; Analyzed 34 cells (36% of all).; Analyzed 35 cells (37% of all).; Analyzed 36 cells (38% of a",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/329#issuecomment-446668422:5992,optimiz,optimizer,5992,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/329#issuecomment-446668422,1,['optimiz'],['optimizer']
Performance,"06 19:24:55.716] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify. [2019-06-06 19:24:55.716] [alevinLog] [info] parsing read library format; [2019-06-06 19:24:55.716] [jointLog] [info] There is 1 library.; [2019-06-06 19:24:55.889] [jointLog] [info] Loading Quasi index; [2019-06-06 19:24:55.889] [jointLog] [info] Loading 32-bit quasi index; [2019-06-06 19:24:55.890] [stderrLog] [info] Loading Suffix Array ; [2019-06-06 19:24:56.791] [stderrLog] [info] Loading Transcript Info ; [2019-06-06 19:24:57.025] [stderrLog] [info] Loading Rank-Select Bit Array; [2019-06-06 19:24:57.061] [stderrLog] [info] There were 136,011 set bits in the bit array; [2019-06-06 19:24:57.084] [stderrLog] [info] Computing transcript lengths; [2019-06-06 19:24:57.084] [stderrLog] [info] Waiting to finish loading hash; [2019-06-06 19:25:06.552] [jointLog] [info] done; [2019-06-06 19:25:06.552] [jointLog] [info] Index contained 136,011 targets; [2019-06-06 19:25:06.552] [stderrLog] [info] Done loading index; [2019-06-06 19:25:06.728] [alevinLog] [error] Barcode not found in frequency table; ```. Salmon Quant log is this. ```; [2019-06-06 19:23:29.519] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2019-06-06 19:23:29.519] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2019-06-06 19:23:29.520] [jointLog] [info] Usage of --validateMappings, without --hardFilter implies use of range factorization. rangeFactorizationBins is being set to 4; [2019-06-06 19:23:29.520] [jointLog] [info] Usage of --validateMappings implies a default consensus slack of 0.2. Setting consensusSlack to 0.2.; [2019-06-06 19:23:29.520] [jointLog] [info] Using default value of 0.87 for minScoreFraction in Alevin; Using default value of 0.6 for consensusSlack in Alevin; [2019-06-06 19:24:55.716] [jointLog] [info] There is 1 library.; [2019-06-06 19:24:55.889] [joi",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/369#issuecomment-499592790:2028,load,loading,2028,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/369#issuecomment-499592790,1,['load'],['loading']
Performance,"07f8599d1d000); /lib64/ld-linux-x86-64.so.2 (0x00007f859b286000); libdl.so.2 => /lib/x86_64-linux-gnu/libdl.so.2 (0x00007f8599b19000); libstdc++.so.6 => /u/user/local/lib64/libstdc++.so.6 (0x00007f859979f000); ```. The linux version and g++ version are listed below:; ```; cat /proc/version; Linux version 4.9.0-0.bpo.6-amd64 (debian-kernel@lists.debian.org) (gcc version 4.9.2 (Debian 4.9.2-10+deb8u1) ) #1 SMP Debian 4.9.82-1+deb9u3~bpo8+1 (2018-03-22). ~/data/PCSI/PC10X/paper/pbmc$ g++ -v; Using built-in specs.; COLLECT_GCC=g++; COLLECT_LTO_WRAPPER=/u/user/local/libexec/gcc/x86_64-unknown-linux-gnu/5.4.0/lto-wrapper; Target: x86_64-unknown-linux-gnu; Configured with: ./configure --prefix=/u/user/local; Thread model: posix; gcc version 5.4.0 (GCC); ```. ```; [Thread debugging using libthread_db enabled]; Using host libthread_db library ""/lib/x86_64-linux-gnu/libthread_db.so.1"".; warning: File ""/u/user/local/lib64/libstdc++.so.6.0.21-gdb.py"" auto-loading has been declined by your `auto-load safe-path' set to ""$debugdir:$datadir/auto-load"".; To enable execution of this file add; add-auto-load-safe-path /u/user/local/lib64/libstdc++.so.6.0.21-gdb.py; line to your configuration file ""/u/user/.gdbinit"".; To completely disable this security protection add; set auto-load safe-path /; line to your configuration file ""/u/user/.gdbinit"".; For more information about this security protection see the; ""Auto-loading safe path"" section in the GDB manual. E.g., run from the shell:; info ""(gdb)Auto-loading safe path""; [New Thread 0x7fff7e0f4700 (LWP 14274)]; Version Info: ### A newer version of Salmon is available. ####; [Thread 0x7fff7e0f4700 (LWP 14274) exited]; ###; The newest version, available at https://github.com/COMBINE-lab/salmon/releases; contains new features, improvements, and bug fixes; please upgrade at your; earliest convenience.; ###; [New Thread 0x7fff7d273700 (LWP 14275)]; Logs will be written to pbmc4k/alevin/logs; [New Thread 0x7ffefc3f1700 (LWP 14276)]; [New Thread",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-395836214:2151,load,loading,2151,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-395836214,3,['load'],"['load', 'loading']"
Performance,"1/3 loss in performance seems significant, given that presumably the code does something else than just parsing UMIs. I am looking at Boost own comparison and benchmarks, and on long inputs (20MB) it is competitive with PCRE2. But with short inputs (20-30 characters) PCRE2 is consistently faster (by about 30% :thinking: ). And if PCRE2 is feature full, not sure it is the fastest either, especially for simple regexp.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/734#issuecomment-1023320721:12,perform,performance,12,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/734#issuecomment-1023320721,1,['perform'],['performance']
Performance,"18-07-19 22:55:37.303] [alevinLog] [info] Total 5238 white-listed Barcodes; [2018-07-19 22:55:37.675] [alevinLog] [info] Done populating Z matrix; [2018-07-19 22:55:37.683] [alevinLog] [info] Done indexing Barcodes; [2018-07-19 22:55:37.683] [alevinLog] [info] Total Unique barcodes found: 978816; [2018-07-19 22:55:37.683] [alevinLog] [info] Used Barcodes except Whitelist: 20705; [2018-07-19 22:55:38.386] [jointLog] [info] There is 1 library.; [2018-07-19 22:55:38.493] [jointLog] [info] Loading Quasi index; [2018-07-19 22:55:38.494] [jointLog] [info] Loading 32-bit quasi index; [2018-07-19 22:55:38.549] [jointLog] [info] done; [2018-07-19 22:55:38.549] [jointLog] [info] Index contained 179 targets. [2018-07-19 22:55:38.385] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify. [2018-07-19 22:55:38.385] [alevinLog] [info] parsing read library format; [2018-07-19 22:55:38.495] [stderrLog] [info] Loading Suffix Array ; [2018-07-19 22:55:38.498] [stderrLog] [info] Loading Transcript Info ; [2018-07-19 22:55:38.499] [stderrLog] [info] Loading Rank-Select Bit Array; [2018-07-19 22:55:38.500] [stderrLog] [info] There were 179 set bits in the bit array; [2018-07-19 22:55:38.501] [stderrLog] [info] Computing transcript lengths; [2018-07-19 22:55:38.501] [stderrLog] [info] Waiting to finish loading hash; processed 87 Million fragmentserrLog] [info] Done loading index; hits: 468892, hits per frag: 0.00535907. [2018-07-19 23:03:35.740] [jointLog] [info] Computed 150 rich equivalence classes for further processing; [2018-07-19 23:03:35.740] [jointLog] [info] Counted 412868 total reads in the equivalence classes ; [2018-07-19 23:03:35.741] [jointLog] [warning] Only 412868 fragments were mapped, but the number of burn-in fragments was set to 5000000.; The effective lengths have been computed using the observed mappings. [2018-07-19 23:03:35.741] [jointLog] [info] Mapping rate = 0.469385%. [2018-07-19 23:03:35.741] [jointLog] [info] finished quantifyLibrary(); [2018-07",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/253#issuecomment-406597243:2904,Load,Loading,2904,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/253#issuecomment-406597243,1,['Load'],['Loading']
Performance,"19-06-06 19:24:55.688] [alevinLog] [info] Total 247(has 200 low confidence) barcodes; [2019-06-06 19:24:55.688] [alevinLog] [info] Done True Barcode Sampling; [2019-06-06 19:24:55.690] [alevinLog] [info] Total 0% reads will be thrown away because of noisy Cellular barcodes.; [2019-06-06 19:24:55.692] [alevinLog] [info] Done populating Z matrix; [2019-06-06 19:24:55.692] [alevinLog] [info] Done indexing Barcodes; [2019-06-06 19:24:55.692] [alevinLog] [info] Total Unique barcodes found: 50; [2019-06-06 19:24:55.692] [alevinLog] [info] Used Barcodes except Whitelist: 0; [2019-06-06 19:24:55.716] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify. [2019-06-06 19:24:55.716] [alevinLog] [info] parsing read library format; [2019-06-06 19:24:55.716] [jointLog] [info] There is 1 library.; [2019-06-06 19:24:55.889] [jointLog] [info] Loading Quasi index; [2019-06-06 19:24:55.889] [jointLog] [info] Loading 32-bit quasi index; [2019-06-06 19:24:55.890] [stderrLog] [info] Loading Suffix Array ; [2019-06-06 19:24:56.791] [stderrLog] [info] Loading Transcript Info ; [2019-06-06 19:24:57.025] [stderrLog] [info] Loading Rank-Select Bit Array; [2019-06-06 19:24:57.061] [stderrLog] [info] There were 136,011 set bits in the bit array; [2019-06-06 19:24:57.084] [stderrLog] [info] Computing transcript lengths; [2019-06-06 19:24:57.084] [stderrLog] [info] Waiting to finish loading hash; [2019-06-06 19:25:06.552] [jointLog] [info] done; [2019-06-06 19:25:06.552] [jointLog] [info] Index contained 136,011 targets; [2019-06-06 19:25:06.552] [stderrLog] [info] Done loading index; [2019-06-06 19:25:06.728] [alevinLog] [error] Barcode not found in frequency table; ```. Salmon Quant log is this. ```; [2019-06-06 19:23:29.519] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2019-06-06 19:23:29.519] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/369#issuecomment-499592790:1438,Load,Loading,1438,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/369#issuecomment-499592790,1,['Load'],['Loading']
Performance,"1; read(4, ""THUMT00000097991.1|AGRN-002|AGRN""..., 8191) = 8191; read(4, ""HUMG00000001412.6|OTTHUMT0000000""..., 8191) = 8191; read(4, ""F3L-007|CPSF3L|1868|protein_codi""..., 8191) = 8191; read(4, ""01413.3|OTTHUMT00000004082.2|AUR""..., 8191) = 8191; read(4, ""UMT00000001363.3|ATAD3A-001|ATAD""..., 8191) = 8191; read(4, ""DK11B-202|CDK11B|2490|protein_co""..., 8191) = 8191; read(4, ""00002763.1|GNB1-002|GNB1|1512|re""..., 8191) = 8191; read(4, ""20-006|FAAP20|569|protein_coding""..., 8191) = 8191; read(4, ""212.1|ENSG00000157881.13|OTTHUMG""..., 8191) = 8191; read(4, ""0563.3|OTTHUMT00000099318.1|LINC""..., 8191) = 8191; read(4, ""-AS1|2875|processed_transcript|\177""..., 8191) = 8191; read(4, ""MG00000041729.1|OTTHUMT000000997""..., 8191) = 8191; read(4, ""1|LINC00337-001|LINC00337|1302|l""..., 8191) = 8191; read(4, ""\0\0\0\0ENST00000377728.7|ENSG000001""..., 8191) = 8191; read(4, ""|z\0\0\0\0\0\0\0ENST00000470648.5|ENSG0""..., 8191) = 8191; read(4, [1m[2017-04-05 16:40:33.297] [stderrLog] [info] Loading Transcript Info ; [00mread(4, ""35271.1|ENSG00000234546.3|OTTHUM""..., 8191) = 8191; read(4, ""00005018.1|UBE4B-003|UBE4B|2299|""..., 8191) = 8191; read(4, ""ding|x\0\0\0\0\0\0\0ENST00000468348.1|E""..., 8191) = 8191; read(4, ""005558.1|MTOR-001|MTOR|8677|prot""..., 8191) = 8191; read(4, ""rotein_coding|x\0\0\0\0\0\0\0ENST000004""..., 8191) = 8191; read(4, ""|\177\0\0\0\0\0\0\0ENST00000439324.2|ENSG0""..., 8191) = 8191; read(4, ""36.1|OTTHUMG00000009500.2|OTTHUM""..., 8191) = 8191; read(4, ""G00000175147.11|OTTHUMG000000020""..., 8191) = 8191; read(4, ""rotein_coding|}\0\0\0\0\0\0\0ENST000004""..., 8191) = 8191; read(4, ""ed_transcript|z\0\0\0\0\0\0\0ENST000004""..., 8191) = 8191; read(4, ""1|549|processed_transcript|{\0\0\0\0""..., 8191) = 8191; read(4, ""0006250.3|CROCC-002|CROCC|3931|p""..., 8191) = 8191; read(4, ""nscript|y\0\0\0\0\0\0\0ENST00000466151.""..., 8191) = 8191; read(4, ""R4|536|processed_transcript|q\0\0\0""..., 8191) = 8191; read(4, "".13|OTTHUMG00000002712.2|OTTHUMT""..., 8191) = 8191; read(4, ""0375",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:168957,Load,Loading,168957,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,1,['Load'],['Loading']
Performance,"1WACXX }; Logs will be written to /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test5/R10001_D2B1WACXX/logs; [1m[2017-03-29 23:59:18.699] [jointLog] [info] parsing read library format; [00m[1m[2017-03-29 23:59:18.721] [jointLog] [info] There is 1 library.; [00m[1m[2017-03-30 00:43:17.278] [stderrLog] [info] Loading Suffix Array ; [00m[1m[2017-03-30 00:43:17.237] [jointLog] [info] Loading Quasi index; [00m[1m[2017-03-30 00:43:17.273] [jointLog] [info] Loading 32-bit quasi index; [00m[1m[2017-03-30 02:37:54.437] [stderrLog] [info] Loading Transcript Info ; [00m[1m[2017-03-30 03:48:21.310] [stderrLog] [info] Loading Rank-Select Bit Array; [00m[1m[2017-03-30 04:20:16.735] [stderrLog] [info] There were 198093 set bits in the bit array; [00m[1m[2017-03-30 04:54:34.486] [stderrLog] [info] Computing transcript lengths; [00m[1m[2017-03-30 04:54:34.487] [stderrLog] [info] Waiting to finish loading hash; [00m[1m[2017-03-30 05:09:36.706] [stderrLog] [info] Done loading index; [00m[1m[2017-03-30 05:09:36.706] [jointLog] [info] done; [00m[1m[2017-03-30 05:09:36.790] [jointLog] [info] Index contained 198093 targets; [00m. [A. [32mprocessed[31m 500000 [32mfragments[0m; hits: 699833, hits per frag: 1.4138[A. [32mprocessed[31m 1000000 [32mfragments[0m; hits: 1395659, hits per frag: 1.40267[A. [32mprocessed[31m 1500000 [32mfragments[0m; hits: 2097294, hits per frag: 1.40287[A. [32mprocessed[31m 2000000 [32mfragments[0m; hits: 2794766, hits per frag: 1.40089[A. [32mprocessed[31m 2500000 [32mfragments[0m; hits: 3489235, hits per frag: 1.39849[A. [32mprocessed[31m 3000000 [32mfragments[0m; hits: 4183913, hits per frag: 1.39697[A. [32mprocessed[31m 3500000 [32mfragments[0m; hits: 4884560, hits per frag: 1.39759[A. [32mprocessed[31m 4000000 [32mfragments[0m; hits: 5584692, hits per frag: 1.39792[A. [32mprocessed[31m 4500000 [32mfragments[0m; hits: 6282640, hits per frag: 1.3977[A. [32mprocessed[31m 5000000 [3",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-290516965:10522,load,loading,10522,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-290516965,1,['load'],['loading']
Performance,200250[0m / [31m52200250[0m.; > [2020-06-04 12:42:01.300] [alevinLog] [info] Forcing to use 200000 cells; > [2020-06-04 12:42:02.037] [alevinLog] [info] Throwing 0 barcodes with < 1 reads; > [2020-06-04 12:42:02.738] [alevinLog] [info] Total [32m197328[0m(has [32m101[0m low confidence) barcodes; > [2020-06-04 12:42:03.656] [alevinLog] [info] Done True Barcode Sampling; > [2020-06-04 12:42:03.830] [alevinLog] [info] Total 0.780192% reads will be thrown away because of noisy Cellular barcodes.; > [2020-06-04 12:42:13.353] [alevinLog] [info] Done populating Z matrix; > [2020-06-04 12:42:13.353] [alevinLog] [info] Total 0 CB got sequence corrected; > [2020-06-04 12:42:13.353] [alevinLog] [info] Done indexing Barcodes; > [2020-06-04 12:42:13.353] [alevinLog] [info] Total Unique barcodes found: 604589; > [2020-06-04 12:42:13.353] [alevinLog] [info] Used Barcodes except Whitelist: 0; > [2020-06-04 12:42:13.555] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify; > ; > [2020-06-04 12:42:13.556] [alevinLog] [info] parsing read library format; > [2020-06-04 12:43:22.789] [alevinLog] [info] Starting optimizer; > ; > [2020-06-04 12:43:23.499] [alevinLog] [warning] mrna file not provided; using is 1 less feature for whitelisting; > [2020-06-04 12:43:23.499] [alevinLog] [warning] rrna file not provided; using is 1 less feature for whitelisting; > [2020-06-04 12:43:23.835] [alevinLog] [info] Total 24009.00 UMI after deduplicating.; > [2020-06-04 12:43:23.835] [alevinLog] [info] Total 89 BiDirected Edges.; > [2020-06-04 12:43:23.835] [alevinLog] [info] Total 82 UniDirected Edges.; > [2020-06-04 12:43:23.835] [alevinLog] [warning] Skipped 184123 barcodes due to No mapped read; > [2020-06-04 12:43:23.840] [alevinLog] [info] Clearing EqMap; Might take some time.; > [2020-06-04 12:43:23.846] [alevinLog] [warning] Num Low confidence barcodes too less 1 < 100.Can't performing whitelisting; Skipping; > [2020-06-04 12:43:23.846] [alevinLog] [info] Finished optimizer,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-638991199:6012,optimiz,optimizer,6012,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-638991199,3,"['optimiz', 'perform']","['optimizer', 'performing']"
Performance,"2018 Free Software Foundation, Inc.; License GPLv3+: GNU GPL version 3 or later <http://gnu.org/licenses/gpl.html>; This is free software: you are free to change and redistribute it.; There is NO WARRANTY, to the extent permitted by law.; Type ""show copying"" and ""show warranty"" for details.; This GDB was configured as ""x86_64-redhat-linux-gnu"".; Type ""show configuration"" for configuration details.; For bug reporting instructions, please see:; <http://www.gnu.org/software/gdb/bugs/>.; Find the GDB manual and other documentation resources online at:; <http://www.gnu.org/software/gdb/documentation/>. For help, type ""help"".; Type ""apropos word"" to search for commands related to ""word""...; Reading symbols from salmon...done.; (gdb) r; Starting program: /home/common/modules/el8/x86_64/software/salmon/1.2.1-CentOS-vanilla/bin/salmon index -t transcripts.fasta -i sample_salmon_fmd_index --type fmd; Missing separate debuginfos, use: yum debuginfo-install glibc-2.28-72.el8_1.1.x86_64; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; [T",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641594410:2306,Load,Loadable,2306,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641594410,1,['Load'],['Loadable']
Performance,"2019-07-09 09:17:07.572] [alevinLog] [info] Gauss Corrected Boundary at [32m 795 [0m; [2019-07-09 09:17:07.572] [alevinLog] [info] Learned InvCov: 173.265 normfactor: 1097.45; [2019-07-09 09:17:07.597] [alevinLog] [info] Total 41.2673% reads will be thrown away because of noisy Cellular barcodes.; [2019-07-09 09:17:07.597] [alevinLog] [info] Total [32m1192[0m(has [32m397[0m low confidence) barcodes; [2019-07-09 09:17:07.765] [alevinLog] [info] Done True Barcode Sampling; [2019-07-09 09:17:08.039] [alevinLog] [info] Done populating Z matrix; [2019-07-09 09:17:08.067] [alevinLog] [info] Done indexing Barcodes; [2019-07-09 09:17:08.067] [alevinLog] [info] Total Unique barcodes found: 7881525; [2019-07-09 09:17:08.067] [alevinLog] [info] Used Barcodes except Whitelist: 84951; [2019-07-09 09:17:08.128] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify. [2019-07-09 09:17:08.128] [alevinLog] [info] parsing read library format; [2019-07-09 10:02:26.992] [alevinLog] [info] Starting optimizer. [2019-07-09 10:13:56.661] [alevinLog] [info] Total 99488568.00 UMI after deduplicating.; [2019-07-09 10:13:56.701] [alevinLog] [info] Clearing EqMap; Might take some time.; [2019-07-09 10:14:11.020] [alevinLog] [info] Starting Import of the gene count matrix of size 1192x60053.; [2019-07-09 10:14:11.286] [alevinLog] [info] Done initializing the empty matrix.; [2019-07-09 10:14:13.421] [alevinLog] [info] Done Importing gene count matrix for dimension 1192x60053; [2019-07-09 10:14:13.622] [alevinLog] [info] Starting white listing; [2019-07-09 10:14:13.627] [alevinLog] [info] Done importing order of barcodes ""quants_mat_rows.txt"" file.; [2019-07-09 10:14:13.627] [alevinLog] [info] Total 1192 barcodes found; [2019-07-09 10:14:13.627] [alevinLog] [warning] mrna file not provided; using is 1 less feature for whitelisting; [2019-07-09 10:14:13.627] [alevinLog] [warning] rrna file not provided; using is 1 less feature for whitelisting; [2019-07-09 10:14:13.627] [alevinLog",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/396#issuecomment-510547693:1402,optimiz,optimizer,1402,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/396#issuecomment-510547693,1,['optimiz'],['optimizer']
Performance,"20:08 SRP057125_SRS936134_2.fastq -> /nfs/research2/teichmann/valentine/detection-comparison/salmon0.4.2-comparison/mouse/SRP057125_SRS936134_2.fastq; drwxrwxr-x 5 vale rst_pub 4.0K Jan 2 20:20 SRP057125_SRS936134_salmon_out; ```. But when I run the script there, it succeeds, without segfault. ```; [vale@ebi-003 salmon-problem]$ bash run_salmon.sh; Version Info: This is the most recent version of Salmon.; # salmon (mapping-based) v0.6.0; # [ program ] => salmon; # [ command ] => quant; # [ index ] => { mouse_cdna_38.p3.78_repbase_ercc.fa }; # [ libType ] => { IU }; # [ mates1 ] => { SRP057125_SRS936134_1.fastq }; # [ mates2 ] => { SRP057125_SRS936134_2.fastq }; # [ output ] => { SRP057125_SRS936134_salmon_out }; # [ biasCorrect ] => { }; # [ useFSPD ] => { }; Logs will be written to SRP057125_SRS936134_salmon_out/logs; [2016-01-02 20:16:39.349] [jointLog] [info] parsing read library format; there is 1 lib; Loading 32-bit quasi index[2016-01-02 20:16:39.895] [stderrLog] [info] Loading Suffix Array; [2016-01-02 20:16:39.895] [stderrLog] [info] Loading Position Hash; [2016-01-02 20:16:39.894] [jointLog] [info] Loading Quasi index; [2016-01-02 20:16:42.565] [stderrLog] [info] Loading Transcript Info; [2016-01-02 20:16:43.654] [stderrLog] [info] Loading Rank-Select Bit Array; [2016-01-02 20:16:44.075] [stderrLog] [info] There were 104534 set bits in the bit array; [2016-01-02 20:16:44.448] [stderrLog] [info] Computing transcript lengths; [2016-01-02 20:16:44.448] [stderrLog] [info] Waiting to finish loading hash; Index contained 104534 targets; [2016-01-02 20:16:57.606] [stderrLog] [info] Done loading index; [2016-01-02 20:16:57.606] [jointLog] [info] done. processed 12000000 fragments; hits: 24367197, hits per frag: 2.06194+06. [2016-01-02 20:17:29.841] [jointLog] [info] Computed 102251 rich equivalence classes for further processing; [2016-01-02 20:17:29.841] [jointLog] [info] Counted 10033689 total reads in the equivalence classes; [2016-01-02 20:17:29.867] [jointLog] ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/34#issuecomment-168426741:1770,Load,Loading,1770,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/34#issuecomment-168426741,1,['Load'],['Loading']
Performance,"20:16:42.565] [stderrLog] [info] Loading Transcript Info; [2016-01-02 20:16:43.654] [stderrLog] [info] Loading Rank-Select Bit Array; [2016-01-02 20:16:44.075] [stderrLog] [info] There were 104534 set bits in the bit array; [2016-01-02 20:16:44.448] [stderrLog] [info] Computing transcript lengths; [2016-01-02 20:16:44.448] [stderrLog] [info] Waiting to finish loading hash; Index contained 104534 targets; [2016-01-02 20:16:57.606] [stderrLog] [info] Done loading index; [2016-01-02 20:16:57.606] [jointLog] [info] done. processed 12000000 fragments; hits: 24367197, hits per frag: 2.06194+06. [2016-01-02 20:17:29.841] [jointLog] [info] Computed 102251 rich equivalence classes for further processing; [2016-01-02 20:17:29.841] [jointLog] [info] Counted 10033689 total reads in the equivalence classes; [2016-01-02 20:17:29.867] [jointLog] [info] Mapping rate = 83.0244%. [2016-01-02 20:17:29.867] [jointLog] [info] finished quantifyLibrary(); [2016-01-02 20:17:29.867] [jointLog] [info] Starting optimizer; [2016-01-02 20:17:30.130] [jointLog] [info] Marked 0 weighted equivalence classes as degenerate; [2016-01-02 20:17:30.136] [jointLog] [info] iteration = 0 | max rel diff. = 65.1271; [2016-01-02 20:17:30.315] [jointLog] [info] iteration 50, recomputing effective lengths; [2016-01-02 20:17:32.978] [jointLog] [info] iteration = 100 | max rel diff. = 0.259134; [2016-01-02 20:17:33.312] [jointLog] [info] iteration = 200 | max rel diff. = 0.136762; [2016-01-02 20:17:33.659] [jointLog] [info] iteration = 300 | max rel diff. = 0.0544656; [2016-01-02 20:17:33.979] [jointLog] [info] iteration = 400 | max rel diff. = 0.0635573; [2016-01-02 20:17:34.298] [jointLog] [info] iteration 500, recomputing effective lengths; [2016-01-02 20:17:36.486] [jointLog] [info] iteration = 500 | max rel diff. = 0.747925; [2016-01-02 20:17:36.865] [jointLog] [info] iteration = 600 | max rel diff. = 0.0480446; [2016-01-02 20:17:37.236] [jointLog] [info] iteration = 700 | max rel diff. = 0.0231505; [2016-01",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/34#issuecomment-168426741:2937,optimiz,optimizer,2937,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/34#issuecomment-168426741,1,['optimiz'],['optimizer']
Performance,"258 rich equivalence classes for further processing; [2020-04-23 00:10:07.647] [jointLog] [info] Counted 11,112,281 total reads in the equivalence classes ; [2020-04-23 00:10:07.660] [jointLog] [info] Number of mappings discarded because of alignment score : 26,561,460; [2020-04-23 00:10:07.660] [jointLog] [info] Number of fragments entirely discarded because of alignment score : 2,134,945; [2020-04-23 00:10:07.660] [jointLog] [info] Number of fragments discarded because they are best-mapped to decoys : 1,953,200; [2020-04-23 00:10:07.660] [jointLog] [info] Number of fragments discarded because they have only dovetail (discordant) mappings to valid targets : 33,267; [2020-04-23 00:10:07.660] [jointLog] [info] Mapping rate = 55.9852%. [2020-04-23 00:10:07.670] [jointLog] [info] finished quantifyLibrary(); [2020-04-23 00:10:07.648] [fileLog] [info] ; At end of round 0; Observed 19848610 total fragments (19848610 in most recent round). [2020-04-23 00:10:11.274] [jointLog] [info] Starting optimizer; [2020-04-23 00:10:57.432] [jointLog] [info] Marked 0 weighted equivalence classes as degenerate; [2020-04-23 00:10:57.563] [jointLog] [info] iteration = 0 | max rel diff. = 3769.01; [2020-04-23 00:10:57.705] [jointLog] [info] iteration 11, adjusting effective lengths to account for biases; [2020-04-23 00:13:04.343] [jointLog] [info] Computed expected counts (for bias correction); [2020-04-23 00:13:04.582] [jointLog] [info] processed bias for 0.0% of the transcripts; [2020-04-23 00:13:06.971] [jointLog] [info] processed bias for 10.0% of the transcripts; [2020-04-23 00:13:09.342] [jointLog] [info] processed bias for 20.0% of the transcripts; [2020-04-23 00:13:11.459] [jointLog] [info] processed bias for 30.0% of the transcripts; [2020-04-23 00:13:13.690] [jointLog] [info] processed bias for 40.0% of the transcripts; [2020-04-23 00:13:15.869] [jointLog] [info] processed bias for 50.0% of the transcripts; [2020-04-23 00:13:18.159] [jointLog] [info] processed bias for 60.0% of t",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/516#issuecomment-621872756:3228,optimiz,optimizer,3228,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/516#issuecomment-621872756,1,['optimiz'],['optimizer']
Performance,"2] [puff::index::jointLog] [info] writing index components ; [2022-04-16 11:19:55.117] [puff::index::jointLog] [info] finished writing dense pufferfish index ; [2022-04-16 11:19:55.401] [jLog] [info] done building index. and the log for quantification:. > [2022-04-16 11:23:51.572] [jointLog] [info] setting maxHashResizeThreads to 48 ; [2022-04-16 11:23:51.572] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored. ; [2022-04-16 11:23:51.572] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65 ; [2022-04-16 11:23:51.572] [jointLog] [info] Setting consensusSlack to selective-alignment default of 0.35. [2022-04-16 11:23:51.572] [jointLog] [info] parsing read library format ; [2022-04-16 11:23:51.572] [jointLog] [info] There is 1 library. ; [2022-04-16 11:23:51.694] [jointLog] [info] Loading pufferfish index ; [2022-04-16 11:23:51.695] [jointLog] [info] Loading dense pufferfish index. ; [2022-04-16 11:23:53.681] [jointLog] [info] done ; [2022-04-16 11:23:53.681] [jointLog] [info] Index contained 245,261 targets ; [2022-04-16 11:23:53.776] [jointLog] [info] Number of decoys : 0 ; [2022-04-16 11:24:42.358] [jointLog] [info] Computed 960,194 rich equivalence classes for further processing [2022-04-16 11:24:42.358] [jointLog] [info] Counted 23,784,776 total reads in the equivalence classes [2022-04-16 11:24:42.426] [jointLog] [info] Number of mappings discarded because of alignment score : 3,206,484 [2022-04-16 11:24:42.426] [jointLog] [info] Number of fragments entirely discarded because of alignment score : 170,372 [2022-04-16 11:24:42.426] [jointLog] [info] Number of fragments discarded because they are best-mapped to decoys : 0 [2022-04-16 11:24:42.426] [jointLog] [info] Number of fragments discarded because they have only dovetail (discordant) mappings to valid targets : 154,144 ; [2022-04-16 11:24:42.426] [jointLog] [info] Mapping rate ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/768#issuecomment-1100734317:16052,Load,Loading,16052,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/768#issuecomment-1100734317,1,['Load'],['Loading']
Performance,31m52200250[0m.; > [2020-06-05 13:09:43.576] [alevinLog] [info] Forcing to use 100000 cells; > [2020-06-05 13:09:43.653] [alevinLog] [info] Throwing 0 barcodes with < 1 reads; > [2020-06-05 13:09:43.673] [alevinLog] [info] Total [32m95377[0m(has [32m11[0m low confidence) barcodes; > [2020-06-05 13:09:43.875] [alevinLog] [info] Done True Barcode Sampling; > [2020-06-05 13:09:44.027] [alevinLog] [info] Total 1.2299% reads will be thrown away because of noisy Cellular barcodes.; > [2020-06-05 13:09:48.338] [alevinLog] [info] Done populating Z matrix; > [2020-06-05 13:09:48.376] [alevinLog] [info] Total 118774 CB got sequence corrected; > [2020-06-05 13:09:48.389] [alevinLog] [info] Done indexing Barcodes; > [2020-06-05 13:09:48.389] [alevinLog] [info] Total Unique barcodes found: 604589; > [2020-06-05 13:09:48.389] [alevinLog] [info] Used Barcodes except Whitelist: 88156; > [2020-06-05 13:09:49.130] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify; > ; > [2020-06-05 13:09:49.132] [alevinLog] [info] parsing read library format; > [2020-06-05 13:11:01.670] [alevinLog] [info] Starting optimizer; > ; > ; > [2020-06-05 13:11:02.377] [alevinLog] [warning] mrna file not provided; using is 1 less feature for whitelisting; > [2020-06-05 13:11:02.377] [alevinLog] [warning] rrna file not provided; using is 1 less feature for whitelisting; > [2020-06-05 13:11:04.408] [alevinLog] [info] Total 322945.00 UMI after deduplicating.; > [2020-06-05 13:11:04.408] [alevinLog] [info] Total 15972 BiDirected Edges.; > [2020-06-05 13:11:04.408] [alevinLog] [info] Total 176951 UniDirected Edges.; > [2020-06-05 13:11:04.408] [alevinLog] [warning] Skipped 12046 barcodes due to No mapped read; > [2020-06-05 13:11:04.415] [alevinLog] [info] Clearing EqMap; Might take some time.; > [2020-06-05 13:11:04.455] [alevinLog] [warning] Num Low confidence barcodes too less 8 < 10.Can't performing whitelisting; Skipping; > [2020-06-05 13:11:04.455] [alevinLog] [info] Finished optimizer,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-639642373:1820,optimiz,optimizer,1820,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-639642373,3,"['optimiz', 'perform']","['optimizer', 'performing']"
Performance,31m52200250[0m.; > [2020-06-05 13:39:18.623] [alevinLog] [info] Forcing to use 100000 cells; > [2020-06-05 13:39:19.364] [alevinLog] [info] Throwing 49909 barcodes with < 10 reads; > [2020-06-05 13:39:20.065] [alevinLog] [info] Total [32m50092[0m(has [32m201[0m low confidence) barcodes; > [2020-06-05 13:39:20.928] [alevinLog] [info] Done True Barcode Sampling; > [2020-06-05 13:39:21.057] [alevinLog] [info] Total 1.70493% reads will be thrown away because of noisy Cellular barcodes.; > [2020-06-05 13:39:23.175] [alevinLog] [info] Done populating Z matrix; > [2020-06-05 13:39:23.175] [alevinLog] [info] Total 0 CB got sequence corrected; > [2020-06-05 13:39:23.175] [alevinLog] [info] Done indexing Barcodes; > [2020-06-05 13:39:23.175] [alevinLog] [info] Total Unique barcodes found: 604589; > [2020-06-05 13:39:23.175] [alevinLog] [info] Used Barcodes except Whitelist: 0; > [2020-06-05 13:39:23.278] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify; > ; > [2020-06-05 13:39:23.278] [alevinLog] [info] parsing read library format; > [2020-06-05 13:40:35.769] [alevinLog] [info] Starting optimizer; > ; > ; > [2020-06-05 13:40:36.476] [alevinLog] [warning] mrna file not provided; using is 1 less feature for whitelisting; > [2020-06-05 13:40:36.476] [alevinLog] [warning] rrna file not provided; using is 1 less feature for whitelisting; > [2020-06-05 13:40:37.933] [alevinLog] [info] Total 227279.00 UMI after deduplicating.; > [2020-06-05 13:40:37.933] [alevinLog] [info] Total 14712 BiDirected Edges.; > [2020-06-05 13:40:37.933] [alevinLog] [info] Total 173086 UniDirected Edges.; > [2020-06-05 13:40:37.933] [alevinLog] [warning] Skipped 5326 barcodes due to No mapped read; > [2020-06-05 13:40:37.936] [alevinLog] [info] Clearing EqMap; Might take some time.; > [2020-06-05 13:40:37.962] [alevinLog] [warning] Num Low confidence barcodes too less 165 < 200.Can't performing whitelisting; Skipping; > [2020-06-05 13:40:37.962] [alevinLog] [info] Finished optimizer,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-639663002:1935,optimiz,optimizer,1935,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-639663002,3,"['optimiz', 'perform']","['optimizer', 'performing']"
Performance,"32.992] [jointLog] [info] Index contained 153,995 targets; [2020-09-23 10:09:33.190] [jointLog] [info] Number of decoys : 0; [2020-09-23 10:09:40.178] [jointLog] [info] Automatically detected most likely library type as ISR; [2020-09-23 10:31:17.407] [jointLog] [info] Thread saw mini-batch with a maximum of 1.68% zero probability fragments; [2020-09-23 10:31:17.467] [jointLog] [info] Thread saw mini-batch with a maximum of 1.64% zero probability fragments; [2020-09-23 10:31:17.563] [jointLog] [info] Thread saw mini-batch with a maximum of 1.66% zero probability fragments; [2020-09-23 10:31:17.573] [jointLog] [info] Thread saw mini-batch with a maximum of 1.72% zero probability fragments; [2020-09-23 10:31:18.005] [jointLog] [info] Computed 329,858 rich equivalence classes for further processing; [2020-09-23 10:31:18.005] [jointLog] [info] Counted 37,348,440 total reads in the equivalence classes ; [2020-09-23 10:31:18.009] [jointLog] [info] Number of mappings discarded because of alignment score : 120,261,413; [2020-09-23 10:31:18.009] [jointLog] [info] Number of fragments entirely discarded because of alignment score : 4,196,417; [2020-09-23 10:31:18.009] [jointLog] [info] Number of fragments discarded because they are best-mapped to decoys : 0; [2020-09-23 10:31:18.009] [jointLog] [info] Number of fragments discarded because they have only dovetail (discordant) mappings to valid targets : 569,393; [2020-09-23 10:31:18.009] [jointLog] [info] Mapping rate = 65.3931%. [2020-09-23 10:31:18.010] [jointLog] [info] finished quantifyLibrary(); [2020-09-23 10:31:18.097] [jointLog] [info] Starting optimizer; [2020-09-23 10:31:18.006] [fileLog] [info] . ""num_bootstraps"": 0,; ""num_processed"": 57113760,; ""num_mapped"": 37348440,; ""num_decoy_fragments"": 0,; ""num_dovetail_fragments"": 569393,; ""num_fragments_filtered_vm"": 4196417,; ""num_alignments_below_threshold_for_mapped_fragments_vm"": 120261413,; ""percent_mapped"": 65.39306815030214,; ""call"": ""quant"",; ```. Best,; Zheng Zhuqing",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/533#issuecomment-697107525:2152,optimiz,optimizer,2152,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/533#issuecomment-697107525,1,['optimiz'],['optimizer']
Performance,"493] [jointLog] [info] Loading Quasi index; [2018-07-19 22:55:38.494] [jointLog] [info] Loading 32-bit quasi index; [2018-07-19 22:55:38.549] [jointLog] [info] done; [2018-07-19 22:55:38.549] [jointLog] [info] Index contained 179 targets. [2018-07-19 22:55:38.385] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify. [2018-07-19 22:55:38.385] [alevinLog] [info] parsing read library format; [2018-07-19 22:55:38.495] [stderrLog] [info] Loading Suffix Array ; [2018-07-19 22:55:38.498] [stderrLog] [info] Loading Transcript Info ; [2018-07-19 22:55:38.499] [stderrLog] [info] Loading Rank-Select Bit Array; [2018-07-19 22:55:38.500] [stderrLog] [info] There were 179 set bits in the bit array; [2018-07-19 22:55:38.501] [stderrLog] [info] Computing transcript lengths; [2018-07-19 22:55:38.501] [stderrLog] [info] Waiting to finish loading hash; processed 87 Million fragmentserrLog] [info] Done loading index; hits: 468892, hits per frag: 0.00535907. [2018-07-19 23:03:35.740] [jointLog] [info] Computed 150 rich equivalence classes for further processing; [2018-07-19 23:03:35.740] [jointLog] [info] Counted 412868 total reads in the equivalence classes ; [2018-07-19 23:03:35.741] [jointLog] [warning] Only 412868 fragments were mapped, but the number of burn-in fragments was set to 5000000.; The effective lengths have been computed using the observed mappings. [2018-07-19 23:03:35.741] [jointLog] [info] Mapping rate = 0.469385%. [2018-07-19 23:03:35.741] [jointLog] [info] finished quantifyLibrary(); [2018-07-19 23:03:35.755] [alevinLog] [info] Starting optimizer. Analyzed 5238 cells (100% of all).; Skipped Barcodes are from High Confidence Region; `$ls -ltrha alevin_output/alevin/`; total 256K; drwxrwx--- 6 zare G-816158 4.0K Jul 19 22:36 ..; -rw-rw---- 1 zare G-816158 960 Jul 19 23:03 alevin.log; drwxrwx--- 2 zare G-816158 4.0K Jul 19 23:03 .; -rw-rw---- 1 zare G-816158 81K Jul 19 23:03 quants_mat_rows.txt; -rw-rw---- 1 zare G-816158 160K Jul 19 23:03 quants_mat.gz",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/253#issuecomment-406597243:3962,optimiz,optimizer,3962,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/253#issuecomment-406597243,1,['optimiz'],['optimizer']
Performance,"4:59.693] [alevinLog] [info] # Barcodes Used: 902561 / 912145.; [2019-01-29 09:55:04.490] [alevinLog] [info] Knee found left boundary at 391 ; [2019-01-29 09:55:04.817] [alevinLog] [info] Gauss Corrected Boundary at 99 ; [2019-01-29 09:55:04.817] [alevinLog] [info] Learned InvCov: 114.535 normfactor: 147.323; [2019-01-29 09:55:04.817] [alevinLog] [info] Total 289(has 190 low confidence) barcodes; [2019-01-29 09:55:04.822] [alevinLog] [info] Done True Barcode Sampling; [2019-01-29 09:55:04.855] [alevinLog] [info] Done populating Z matrix; [2019-01-29 09:55:04.855] [alevinLog] [info] Done indexing Barcodes; [2019-01-29 09:55:04.855] [alevinLog] [info] Total Unique barcodes found: 70316; [2019-01-29 09:55:04.855] [alevinLog] [info] Used Barcodes except Whitelist: 184; [2019-01-29 09:55:04.882] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify. [2019-01-29 09:55:04.882] [alevinLog] [info] parsing read library format; [2019-01-29 09:55:05.014] [stderrLog] [info] Loading Suffix Array ; [2019-01-29 09:55:04.882] [jointLog] [info] There is 1 library.; [2019-01-29 09:55:05.012] [jointLog] [info] Loading Quasi index; [2019-01-29 09:55:05.013] [jointLog] [info] Loading 32-bit quasi index; [2019-01-29 09:55:06.105] [stderrLog] [info] Loading Transcript Info ; [2019-01-29 09:55:09.968] [stderrLog] [info] Loading Rank-Select Bit Array; [2019-01-29 09:55:16.908] [stderrLog] [info] There were 80,511 set bits in the bit array; [2019-01-29 09:55:19.931] [stderrLog] [info] Computing transcript lengths; [2019-01-29 09:55:19.931] [stderrLog] [info] Waiting to finish loading hash; [2019-01-29 09:55:41.122] [jointLog] [info] done; [2019-01-29 09:55:41.122] [jointLog] [info] Index contained 80,511 targets; [2019-01-29 09:55:41.122] [stderrLog] [info] Done loading index. processed 0 Million fragments; hits: 161433, hits per frag: 0.32698. [2019-01-29 09:55:54.788] [alevinLog] [info] Starting optimizer; [2019-01-29 09:55:54.742] [jointLog] [info] Computed 6,346 rich equival",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/337#issuecomment-458481722:2747,Load,Loading,2747,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/337#issuecomment-458481722,1,['Load'],['Loading']
Performance,"4_2.fastq }; # [ output ] => { SRP057125_SRS936134_salmon_out }; # [ geneMap ] => { /nfs/research2/teichmann/reference/mus-musculus/salmon/mouse_cdna38.78_repbase_ercc_index_gene_map.txt }; # [ biasCorrect ] => { }; # [ useFSPD ] => { }; Logs will be written to SRP057125_SRS936134_salmon_out/logs; [2016-01-02 20:22:59.800] [jointLog] [info] parsing read library format; there is 1 lib; Loading 32-bit quasi index[2016-01-02 20:23:00.830] [stderrLog] [info] Loading Suffix Array; [2016-01-02 20:23:00.830] [stderrLog] [info] Loading Position Hash; [2016-01-02 20:23:00.829] [jointLog] [info] Loading Quasi index; [2016-01-02 20:23:03.751] [stderrLog] [info] Loading Transcript Info; [2016-01-02 20:23:04.776] [stderrLog] [info] Loading Rank-Select Bit Array; [2016-01-02 20:23:05.009] [stderrLog] [info] There were 104534 set bits in the bit array; [2016-01-02 20:23:05.325] [stderrLog] [info] Computing transcript lengths; [2016-01-02 20:23:05.325] [stderrLog] [info] Waiting to finish loading hash; Index contained 104534 targets; [2016-01-02 20:23:16.571] [stderrLog] [info] Done loading index; [2016-01-02 20:23:16.571] [jointLog] [info] done. processed 12000001 fragments; hits: 24367128, hits per frag: 2.04044. [2016-01-02 20:23:49.850] [jointLog] [info] Computed 102251 rich equivalence classes for further processing; [2016-01-02 20:23:49.850] [jointLog] [info] Counted 10033689 total reads in the equivalence classes; [2016-01-02 20:23:49.875] [jointLog] [info] Mapping rate = 83.0244%. [2016-01-02 20:23:49.875] [jointLog] [info] finished quantifyLibrary(); [2016-01-02 20:23:49.875] [jointLog] [info] Starting optimizer; [2016-01-02 20:23:50.378] [jointLog] [info] Marked 0 weighted equivalence classes as degenerate; [2016-01-02 20:23:50.382] [jointLog] [info] iteration = 0 | max rel diff. = 64.9993; [2016-01-02 20:23:50.584] [jointLog] [info] iteration 50, recomputing effective lengths; [2016-01-02 20:23:53.386] [jointLog] [info] iteration = 100 | max rel diff. = 0.263028; [2016-01",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/34#issuecomment-168426741:8204,load,loading,8204,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/34#issuecomment-168426741,1,['load'],['loading']
Performance,"537; [00m[1m[2017-03-30 11:35:12.190] [jointLog] [info] iteration = 1107 | max rel diff. = 0.00948523; [00m[1m[2017-03-30 11:35:12.199] [jointLog] [info] Finished optimizer; [00m[1m[2017-03-30 11:35:12.199] [jointLog] [info] writing output . [00m[33m[1m[2017-03-30 11:38:26.886] [jointLog] [warning] NOTE: Read Lib [( /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/merged_fastq/R10001_D2B1WACXX.fastq.gz, /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/merged_fastq/R10001_D2B1WACXX_read2.fastq.gz )] :. Greater than 5% of the fragments disagreed with the provided library type; check the file: /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test5/R10001_D2B1WACXX/lib_format_counts.json for details. [00m**** Job ends ****; Thu Mar 30 11:38:30 EDT 2017; ```. ### SGE email example info. ```; Job-array task 110632.1 (step6-salmon_test5.gsk_phaseII) Complete; User = lcollado; Queue = shared.q@compute-066.cm.cluster; Host = compute-066.cm.cluster; Start Time = 03/29/2017 23:27:10; End Time = 03/30/2017 11:38:30; User Time = 06:08:32; System Time = 12:46:46; Wallclock Time = 12:11:20; CPU = 18:55:18; Max vmem = 6.961G; Exit Status = 0; ```. For some reason, sample 1 took quite a bit of time. Samples 2 and 3 were actually much faster:. sample 2:. ```; Job-array task 110632.2 (step6-salmon_test5.gsk_phaseII) Complete; User = lcollado; Queue = shared.q@compute-051.cm.cluster; Host = compute-051.cm.cluster; Start Time = 03/30/2017 00:22:20; End Time = 03/30/2017 03:33:24; User Time = 02:37:02; System Time = 02:55:26; Wallclock Time = 03:11:04; CPU = 05:32:28; Max vmem = 6.941G; Exit Status = 0; ```. sample 3:. ```; Job-array task 110632.3 (step6-salmon_test5.gsk_phaseII) Complete; User = lcollado; Queue = shared.q@compute-051.cm.cluster; Host = compute-051.cm.cluster; Start Time = 03/30/2017 03:33:38; End Time = 03/30/2017 05:58:33; User Time = 03:45:43; System Time = 00:37:55; Wallclock Time = 02:24:55; CPU = 04:23:38; Max vmem = 6.947G; Exit Status = 0; ```. Best,; Leo",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-290516965:26323,Queue,Queue,26323,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-290516965,2,['Queue'],['Queue']
Performance,"55:37.303] [alevinLog] [info] Done importing white-list Barcodes; [2018-07-19 22:55:37.303] [alevinLog] [info] Total 5238 white-listed Barcodes; [2018-07-19 22:55:37.675] [alevinLog] [info] Done populating Z matrix; [2018-07-19 22:55:37.683] [alevinLog] [info] Done indexing Barcodes; [2018-07-19 22:55:37.683] [alevinLog] [info] Total Unique barcodes found: 978816; [2018-07-19 22:55:37.683] [alevinLog] [info] Used Barcodes except Whitelist: 20705; [2018-07-19 22:55:38.386] [jointLog] [info] There is 1 library.; [2018-07-19 22:55:38.493] [jointLog] [info] Loading Quasi index; [2018-07-19 22:55:38.494] [jointLog] [info] Loading 32-bit quasi index; [2018-07-19 22:55:38.549] [jointLog] [info] done; [2018-07-19 22:55:38.549] [jointLog] [info] Index contained 179 targets. [2018-07-19 22:55:38.385] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify. [2018-07-19 22:55:38.385] [alevinLog] [info] parsing read library format; [2018-07-19 22:55:38.495] [stderrLog] [info] Loading Suffix Array ; [2018-07-19 22:55:38.498] [stderrLog] [info] Loading Transcript Info ; [2018-07-19 22:55:38.499] [stderrLog] [info] Loading Rank-Select Bit Array; [2018-07-19 22:55:38.500] [stderrLog] [info] There were 179 set bits in the bit array; [2018-07-19 22:55:38.501] [stderrLog] [info] Computing transcript lengths; [2018-07-19 22:55:38.501] [stderrLog] [info] Waiting to finish loading hash; processed 87 Million fragmentserrLog] [info] Done loading index; hits: 468892, hits per frag: 0.00535907. [2018-07-19 23:03:35.740] [jointLog] [info] Computed 150 rich equivalence classes for further processing; [2018-07-19 23:03:35.740] [jointLog] [info] Counted 412868 total reads in the equivalence classes ; [2018-07-19 23:03:35.741] [jointLog] [warning] Only 412868 fragments were mapped, but the number of burn-in fragments was set to 5000000.; The effective lengths have been computed using the observed mappings. [2018-07-19 23:03:35.741] [jointLog] [info] Mapping rate = 0.469385%. [2018-07-1",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/253#issuecomment-406597243:2836,Load,Loading,2836,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/253#issuecomment-406597243,1,['Load'],['Loading']
Performance,"56,134 total reads; in the equivalence classes; [2020-06-16 00:00:59.673] [jointLog] [warning] 0.0736383% of fragments were; shorter than the k used to build the index.; If this fraction is too large, consider re-building the index with a; smaller k.; The minimum read size found was 1. [2020-06-16 00:00:59.673] [jointLog] [info] Number of mappings discarded; because of alignment score : 134,091,887; [2020-06-16 00:00:59.673] [jointLog] [info] Number of fragments entirely; discarded because of alignment score : 2,429,390; [2020-06-16 00:00:59.673] [jointLog] [info] Number of fragments discarded; because they are best-mapped to decoys : 0; [2020-06-16 00:00:59.673] [jointLog] [info] Number of fragments discarded; because they have only dovetail (discordant) mappings to valid targets :; 1,360,397; [2020-06-16 00:00:59.673] [jointLog] [info] Mapping rate = 45.4405%. [2020-06-16 00:00:59.673] [jointLog] [info] finished quantifyLibrary(); [2020-06-16 00:00:59.673] [jointLog] [info] Starting optimizer; [2020-06-16 00:00:59.792] [jointLog] [info] Marked 0 weighted equivalence; classes as degenerate; [2020-06-16 00:00:59.819] [jointLog] [info] iteration = 0 | max rel diff. =; 8250.92; [2020-06-16 00:00:59.667] [fileLog] [info]; At end of round 0; ==================; Observed 28512328 total fragments (28512328 in most recent round). [2020-06-16 00:01:01.745] [jointLog] [info] iteration = 100 | max rel diff.; = 19.507; [2020-06-16 00:01:03.495] [jointLog] [info] iteration = 200 | max rel diff.; = 2.45489; [2020-06-16 00:01:05.225] [jointLog] [info] iteration = 300 | max rel diff.; = 3.459; [2020-06-16 00:01:06.968] [jointLog] [info] iteration = 400 | max rel diff.; = 4.38485; [2020-06-16 00:01:08.693] [jointLog] [info] iteration = 500 | max rel diff.; = 0.229724; [2020-06-16 00:01:10.426] [jointLog] [info] iteration = 600 | max rel diff.; = 0.242741; [2020-06-16 00:01:12.163] [jointLog] [info] iteration = 700 | max rel diff.; = 0.196958; [2020-06-16 00:01:14.015] [jointLog] [i",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/537#issuecomment-644520228:2449,optimiz,optimizer,2449,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/537#issuecomment-644520228,2,['optimiz'],['optimizer']
Performance,"5] [alevinLog] [info] # Barcodes Used: 74376522 / 74376522.; [2018-12-12 15:08:51.141] [alevinLog] [info] Done importing white-list Barcodes; [2018-12-12 15:08:51.141] [alevinLog] [warning] Skipping 1 Barcodes with 0 reads; Assuming this is the required behavior.; [2018-12-12 15:08:51.141] [alevinLog] [info] Total 95 white-listed Barcodes; [2018-12-12 15:08:51.144] [alevinLog] [info] Done populating Z matrix; [2018-12-12 15:08:51.146] [alevinLog] [info] Done indexing Barcodes; [2018-12-12 15:08:51.146] [alevinLog] [info] Total Unique barcodes found: 4096; [2018-12-12 15:08:51.146] [alevinLog] [info] Used Barcodes except Whitelist: 1864; [2018-12-12 15:08:51.272] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify. [2018-12-12 15:08:51.272] [alevinLog] [info] parsing read library format; [2018-12-12 15:08:51.375] [stderrLog] [info] Loading Suffix Array ; [2018-12-12 15:08:51.272] [jointLog] [info] There is 1 library.; [2018-12-12 15:08:51.375] [jointLog] [info] Loading Quasi index; [2018-12-12 15:08:51.375] [jointLog] [info] Loading 32-bit quasi index; [2018-12-12 15:09:10.216] [stderrLog] [info] Loading Transcript Info ; [2018-12-12 15:09:15.719] [stderrLog] [info] Loading Rank-Select Bit Array; [2018-12-12 15:09:16.330] [stderrLog] [info] There were 205,870 set bits in the bit array; [2018-12-12 15:09:16.343] [stderrLog] [info] Computing transcript lengths; [2018-12-12 15:09:16.343] [stderrLog] [info] Waiting to finish loading hash; [2018-12-12 15:09:21.460] [stderrLog] [info] Done loading index; [2018-12-12 15:09:21.460] [jointLog] [info] done; [2018-12-12 15:09:21.460] [jointLog] [info] Index contained 205,870 targets. processed 0 Million fragments; processed 1 Million fragments; processed 1 Million fragments; ..............; processed 74 Million fragments; hits: 111594303, hits per frag: 1.50848[2018-12-12 15:12:07.666] [jointLog] [info] Thread saw mini-batch with a maximum of 5.34% zero probability fragments; [2018-12-12 15:12:07.677] [jointLog] ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/329#issuecomment-446668422:4321,Load,Loading,4321,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/329#issuecomment-446668422,1,['Load'],['Loading']
Performance,"5] [alevinLog] [info] Total 31.0106% reads will be thrown away because of noisy Cellular barcodes.; [2018-12-06 11:16:54.985] [alevinLog] [info] Total 5344(has 999 low confidence) barcodes; [2018-12-06 11:16:55.059] [alevinLog] [info] Done True Barcode Sampling; [2018-12-06 11:16:55.395] [alevinLog] [info] Done populating Z matrix; [2018-12-06 11:16:55.453] [alevinLog] [info] Done indexing Barcodes; [2018-12-06 11:16:55.453] [alevinLog] [info] Total Unique barcodes found: 4180559; [2018-12-06 11:16:55.453] [alevinLog] [info] Used Barcodes except Whitelist: 134856; [2018-12-06 11:16:56.218] [jointLog] [info] There are 2 libraries.; [2018-12-06 11:16:56.292] [jointLog] [info] Loading Quasi index; [2018-12-06 11:16:56.294] [jointLog] [info] Loading 32-bit quasi index; [2018-12-06 11:16:56.205] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify. [2018-12-06 11:16:56.218] [alevinLog] [info] parsing read library format; [2018-12-06 11:16:56.296] [stderrLog] [info] Loading Suffix Array ; [2018-12-06 11:16:56.846] [stderrLog] [info] Loading Transcript Info ; [2018-12-06 11:16:57.009] [stderrLog] [info] Loading Rank-Select Bit Array; [2018-12-06 11:16:57.046] [stderrLog] [info] There were 167,268 set bits in the bit array; [2018-12-06 11:16:57.063] [stderrLog] [info] Computing transcript lengths; [2018-12-06 11:16:57.064] [stderrLog] [info] Waiting to finish loading hash; [2018-12-06 11:17:00.929] [jointLog] [info] done; [2018-12-06 11:17:00.929] [jointLog] [info] Index contained 167,268 targets. processed 267 Million fragmentsrrLog] [info] Done loading index; hits: 844899161, hits per frag: 3.15864^[[D. [2018-12-06 11:45:12.188] [jointLog] [info] Computed 118,295 rich equivalence classes for further processing; [2018-12-06 11:45:12.188] [jointLog] [info] Counted 154,595,094 total reads in the equivalence classes ; [2018-12-06 11:45:12.188] [jointLog] [warning] Found 115077 reads with `N` in the UMI sequence and ignored the reads.; Please report on github if",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/328#issuecomment-445008548:6354,Load,Loading,6354,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/328#issuecomment-445008548,1,['Load'],['Loading']
Performance,"5_SRS936134_salmon_out; ```. But when I run the script there, it succeeds, without segfault. ```; [vale@ebi-003 salmon-problem]$ bash run_salmon.sh; Version Info: This is the most recent version of Salmon.; # salmon (mapping-based) v0.6.0; # [ program ] => salmon; # [ command ] => quant; # [ index ] => { mouse_cdna_38.p3.78_repbase_ercc.fa }; # [ libType ] => { IU }; # [ mates1 ] => { SRP057125_SRS936134_1.fastq }; # [ mates2 ] => { SRP057125_SRS936134_2.fastq }; # [ output ] => { SRP057125_SRS936134_salmon_out }; # [ biasCorrect ] => { }; # [ useFSPD ] => { }; Logs will be written to SRP057125_SRS936134_salmon_out/logs; [2016-01-02 20:16:39.349] [jointLog] [info] parsing read library format; there is 1 lib; Loading 32-bit quasi index[2016-01-02 20:16:39.895] [stderrLog] [info] Loading Suffix Array; [2016-01-02 20:16:39.895] [stderrLog] [info] Loading Position Hash; [2016-01-02 20:16:39.894] [jointLog] [info] Loading Quasi index; [2016-01-02 20:16:42.565] [stderrLog] [info] Loading Transcript Info; [2016-01-02 20:16:43.654] [stderrLog] [info] Loading Rank-Select Bit Array; [2016-01-02 20:16:44.075] [stderrLog] [info] There were 104534 set bits in the bit array; [2016-01-02 20:16:44.448] [stderrLog] [info] Computing transcript lengths; [2016-01-02 20:16:44.448] [stderrLog] [info] Waiting to finish loading hash; Index contained 104534 targets; [2016-01-02 20:16:57.606] [stderrLog] [info] Done loading index; [2016-01-02 20:16:57.606] [jointLog] [info] done. processed 12000000 fragments; hits: 24367197, hits per frag: 2.06194+06. [2016-01-02 20:17:29.841] [jointLog] [info] Computed 102251 rich equivalence classes for further processing; [2016-01-02 20:17:29.841] [jointLog] [info] Counted 10033689 total reads in the equivalence classes; [2016-01-02 20:17:29.867] [jointLog] [info] Mapping rate = 83.0244%. [2016-01-02 20:17:29.867] [jointLog] [info] finished quantifyLibrary(); [2016-01-02 20:17:29.867] [jointLog] [info] Starting optimizer; [2016-01-02 20:17:30.130] [jointL",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/34#issuecomment-168426741:1970,Load,Loading,1970,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/34#issuecomment-168426741,1,['Load'],['Loading']
Performance,"6665; [2021-01-25 16:27:07.414] [alevinLog] [info] Used Barcodes except Whitelist: 3667; [2021-01-25 16:27:07.498] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify; [2021-01-25 16:27:07.498] [alevinLog] [info] parsing read library format; [2021-01-25 16:30:54.542] [alevinLog] [info] Starting optimizer; [2021-01-25 16:30:54.782] [alevinLog] [warning] mrna file not provided; using is 1 less feature for whitelisting; [2021-01-25 16:30:54.782] [alevinLog] [warning] rrna file not provided; using is 1 less feature for whitelisting; [2021-01-25 16:30:55.950] [alevinLog] [info] Total 1350278.00 UMI after deduplicating.; [2021-01-25 16:30:55.950] [alevinLog] [info] Total 30909 BiDirected Edges.; [2021-01-25 16:30:55.950] [alevinLog] [info] Total 8817 UniDirected Edges.; [2021-01-25 16:30:55.969] [alevinLog] [info] Clearing EqMap; Might take some time.; [2021-01-25 16:30:56.294] [alevinLog] [warning] Num High confidence barcodes too less 20 < 90.Can't performing whitelisting; Skipping; [2021-01-25 16:30:56.297] [alevinLog] [info] Finished optimizer. ## with `--exceptCells 7000`; > [2021-01-21 09:24:45.891] [alevinLog] [info] Found 43030 transcripts(+0 decoys, +0 short and +0 duplicate names in the index); [2021-01-21 09:24:45.942] [alevinLog] [info] Filled with 43030 txp to gene entries; [2021-01-21 09:24:45.947] [alevinLog] [info] Found all transcripts to gene mappings; [2021-01-21 09:24:45.967] [alevinLog] [info] Processing barcodes files (if Present); [2021-01-21 09:33:35.885] [alevinLog] [info] Done barcode density calculation.; [2021-01-21 09:33:35.885] [alevinLog] [info] # Barcodes Used: 188934609 / 188934609.; [2021-01-21 09:33:37.337] [alevinLog] [info] Total 10016(has 1000 low confidence) barcodes; [2021-01-21 09:33:38.202] [alevinLog] [info] Done True Barcode Sampling; [2021-01-21 09:33:39.137] [alevinLog] [warning] Total **52.0343% reads will be thrown away** because of noisy Cellular barcodes.; [2021-01-21 09:33:39.960] [alevinLog] [info] Done p",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/340#issuecomment-766311567:4055,perform,performing,4055,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/340#issuecomment-766311567,1,['perform'],['performing']
Performance,"66; Task id: ; Version Info: This is the most recent version of Salmon.; ### salmon (mapping-based) v0.8.2; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts }; ### [ threads ] => { 1 }; ### [ libType ] => { ISR }; ### [ mates1 ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/merged_fastq/R10001_D2B1WACXX.fastq.gz }; ### [ mates2 ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/merged_fastq/R10001_D2B1WACXX_read2.fastq.gz }; ### [ output ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test5/R10001_D2B1WACXX }; Logs will be written to /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test5/R10001_D2B1WACXX/logs; [1m[2017-03-29 23:59:18.699] [jointLog] [info] parsing read library format; [00m[1m[2017-03-29 23:59:18.721] [jointLog] [info] There is 1 library.; [00m[1m[2017-03-30 00:43:17.278] [stderrLog] [info] Loading Suffix Array ; [00m[1m[2017-03-30 00:43:17.237] [jointLog] [info] Loading Quasi index; [00m[1m[2017-03-30 00:43:17.273] [jointLog] [info] Loading 32-bit quasi index; [00m[1m[2017-03-30 02:37:54.437] [stderrLog] [info] Loading Transcript Info ; [00m[1m[2017-03-30 03:48:21.310] [stderrLog] [info] Loading Rank-Select Bit Array; [00m[1m[2017-03-30 04:20:16.735] [stderrLog] [info] There were 198093 set bits in the bit array; [00m[1m[2017-03-30 04:54:34.486] [stderrLog] [info] Computing transcript lengths; [00m[1m[2017-03-30 04:54:34.487] [stderrLog] [info] Waiting to finish loading hash; [00m[1m[2017-03-30 05:09:36.706] [stderrLog] [info] Done loading index; [00m[1m[2017-03-30 05:09:36.706] [jointLog] [info] done; [00m[1m[2017-03-30 05:09:36.790] [jointLog] [info] Index contained 198093 targets; [00m. [A. [32mprocessed[31m 500000 [32mfragments[0m; hits: 699833, hits per frag: 1.4138[A. [32mprocessed[31m 1000000 [32mfragments[0m; hits: 1395659, hits per frag: 1.40267",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-290516965:9851,Load,Loading,9851,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-290516965,1,['Load'],['Loading']
Performance,77869[0m.; [2022-03-27 05:34:04.367] [alevinLog] [info] Throwing 0 barcodes with < 10 reads; [2022-03-27 05:34:05.069] [alevinLog] [info] Total [32m4000[0m(has [32m999[0m low confidence) barcodes; [2022-03-27 05:34:07.956] [alevinLog] [info] Done True Barcode Sampling; [2022-03-27 05:34:25.703] [alevinLog] [warning] Total 91.5531% reads will be thrown away because of noisy Cellular barcodes.; [2022-03-27 05:34:26.221] [alevinLog] [info] Done populating Z matrix; [2022-03-27 05:34:26.232] [alevinLog] [info] Total 60208 CB got sequence corrected; [2022-03-27 05:34:26.234] [alevinLog] [info] Done indexing Barcodes; [2022-03-27 05:34:26.234] [alevinLog] [info] Total Unique barcodes found: 127233006; [2022-03-27 05:34:26.234] [alevinLog] [info] Used Barcodes except Whitelist: 50131; [2022-03-27 05:34:26.966] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify. [2022-03-27 05:34:26.966] [alevinLog] [info] parsing read library format; [2022-03-27 05:46:41.876] [alevinLog] [info] Starting optimizer. [2022-03-27 05:46:42.064] [alevinLog] [warning] mrna file not provided; using is 1 less feature for whitelisting; [2022-03-27 05:46:42.064] [alevinLog] [warning] rrna file not provided; using is 1 less feature for whitelisting; [2022-03-27 05:49:49.761] [alevinLog] [info] Total 535438.00 UMI after deduplicating.; [2022-03-27 05:49:49.761] [alevinLog] [info] Total 2317116 BiDirected Edges.; [2022-03-27 05:49:49.761] [alevinLog] [info] Total 867878 UniDirected Edges.; [2022-03-27 05:49:49.761] [alevinLog] [warning] Skipped 955 barcodes due to No mapped read; [2022-03-27 05:49:49.766] [alevinLog] [info] Clearing EqMap; Might take some time.; [2022-03-27 05:49:50.011] [alevinLog] [info] Starting white listing of 3044 cells; [2022-03-27 05:49:50.011] [alevinLog] [info] Starting to make feature Matrix; [2022-03-27 05:49:50.014] [alevinLog] [info] Done making feature Matrix; [2022-03-27 05:49:50.717] [alevinLog] [info] Finished white listing; [2022-03-27 05:49:51.422] [a,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/763#issuecomment-1082597942:3082,optimiz,optimizer,3082,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/763#issuecomment-1082597942,1,['optimiz'],['optimizer']
Performance,"84; [2019-01-29 09:55:04.882] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify. [2019-01-29 09:55:04.882] [alevinLog] [info] parsing read library format; [2019-01-29 09:55:05.014] [stderrLog] [info] Loading Suffix Array ; [2019-01-29 09:55:04.882] [jointLog] [info] There is 1 library.; [2019-01-29 09:55:05.012] [jointLog] [info] Loading Quasi index; [2019-01-29 09:55:05.013] [jointLog] [info] Loading 32-bit quasi index; [2019-01-29 09:55:06.105] [stderrLog] [info] Loading Transcript Info ; [2019-01-29 09:55:09.968] [stderrLog] [info] Loading Rank-Select Bit Array; [2019-01-29 09:55:16.908] [stderrLog] [info] There were 80,511 set bits in the bit array; [2019-01-29 09:55:19.931] [stderrLog] [info] Computing transcript lengths; [2019-01-29 09:55:19.931] [stderrLog] [info] Waiting to finish loading hash; [2019-01-29 09:55:41.122] [jointLog] [info] done; [2019-01-29 09:55:41.122] [jointLog] [info] Index contained 80,511 targets; [2019-01-29 09:55:41.122] [stderrLog] [info] Done loading index. processed 0 Million fragments; hits: 161433, hits per frag: 0.32698. [2019-01-29 09:55:54.788] [alevinLog] [info] Starting optimizer; [2019-01-29 09:55:54.742] [jointLog] [info] Computed 6,346 rich equivalence classes for further processing; [2019-01-29 09:55:54.742] [jointLog] [info] Counted 80,300 total reads in the equivalence classes ; [2019-01-29 09:55:54.754] [jointLog] [warning] Only 80300 fragments were mapped, but the number of burn-in fragments was set to 5000000.; The effective lengths have been computed using the observed mappings. [2019-01-29 09:55:54.754] [jointLog] [info] Mapping rate = 8.80342%. [2019-01-29 09:55:54.754] [jointLog] [info] finished quantifyLibrary(). Analyzed 289 cells (100% of all).; [2019-01-29 09:55:56.858] [alevinLog] [info] Total 72037 UMI after deduplicating.; [2019-01-29 09:55:56.858] [alevinLog] [warning] Skipped 151 barcodes due to No mapped read; [2019-01-29 09:55:56.876] [alevinLog] [info] Clearing EqMap; Might take some ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/337#issuecomment-458481722:3537,load,loading,3537,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/337#issuecomment-458481722,1,['load'],['loading']
Performance,":55.681] [alevinLog] [info] # Barcodes Used: 31478936 / 31478936.; [2019-06-06 19:24:55.688] [alevinLog] [info] Total 247(has 200 low confidence) barcodes; [2019-06-06 19:24:55.688] [alevinLog] [info] Done True Barcode Sampling; [2019-06-06 19:24:55.690] [alevinLog] [info] Total 0% reads will be thrown away because of noisy Cellular barcodes.; [2019-06-06 19:24:55.692] [alevinLog] [info] Done populating Z matrix; [2019-06-06 19:24:55.692] [alevinLog] [info] Done indexing Barcodes; [2019-06-06 19:24:55.692] [alevinLog] [info] Total Unique barcodes found: 50; [2019-06-06 19:24:55.692] [alevinLog] [info] Used Barcodes except Whitelist: 0; [2019-06-06 19:24:55.716] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify. [2019-06-06 19:24:55.716] [alevinLog] [info] parsing read library format; [2019-06-06 19:24:55.716] [jointLog] [info] There is 1 library.; [2019-06-06 19:24:55.889] [jointLog] [info] Loading Quasi index; [2019-06-06 19:24:55.889] [jointLog] [info] Loading 32-bit quasi index; [2019-06-06 19:24:55.890] [stderrLog] [info] Loading Suffix Array ; [2019-06-06 19:24:56.791] [stderrLog] [info] Loading Transcript Info ; [2019-06-06 19:24:57.025] [stderrLog] [info] Loading Rank-Select Bit Array; [2019-06-06 19:24:57.061] [stderrLog] [info] There were 136,011 set bits in the bit array; [2019-06-06 19:24:57.084] [stderrLog] [info] Computing transcript lengths; [2019-06-06 19:24:57.084] [stderrLog] [info] Waiting to finish loading hash; [2019-06-06 19:25:06.552] [jointLog] [info] done; [2019-06-06 19:25:06.552] [jointLog] [info] Index contained 136,011 targets; [2019-06-06 19:25:06.552] [stderrLog] [info] Done loading index; [2019-06-06 19:25:06.728] [alevinLog] [error] Barcode not found in frequency table; ```. Salmon Quant log is this. ```; [2019-06-06 19:23:29.519] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2019-06-06 19:23:29.519] [jointLog] [info] Usage of --validateMappings implies us",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/369#issuecomment-499592790:1365,Load,Loading,1365,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/369#issuecomment-499592790,1,['Load'],['Loading']
Performance,":jointLog] [info] Filter size not provided; estimating from number of distinct k-mers; [2021-12-31 11:26:38.852] [puff::index::jointLog] [info] ntHll estimated 239287090 distinct k-mers, setting filter size to 2^32; allowedIn: 21; Max Junction ID: 1394611; seen.size():11156897 kmerInfo.size():1394612; approximateContigTotalLength: 132160289; counters for complex kmers:; (prec>1 & succ>1)=181344 | (succ>1 & isStart)=714 | (prec>1 & isEnd)=800 | (isStart & isEnd)=42; contig count: 2077595 element count: 297242564 complex nodes: 182900; # of ones in rank vector: 2077594; [2021-12-31 11:28:32.554] [puff::index::jointLog] [info] Starting the Pufferfish indexing by reading the GFA binary file.; [2021-12-31 11:28:32.554] [puff::index::jointLog] [info] Setting the index/BinaryGfa directory /no_backup/indexes/salmon/mm10_gencode; size = 297242564; -----------------------------------------; | Loading contigs | Time = 135.18 ms; -----------------------------------------; size = 297242564; -----------------------------------------; | Loading contig boundaries | Time = 61.18 ms; -----------------------------------------; Number of ones: 2077594; Number of ones per inventory item: 512; Inventory entries filled: 4058; 2077594; [2021-12-31 11:28:33.532] [puff::index::jointLog] [info] Done wrapping the rank vector with a rank9sel structure.; [2021-12-31 11:28:33.566] [puff::index::jointLog] [info] contig count for validation: 2,077,594; [2021-12-31 11:28:34.693] [puff::index::jointLog] [info] Total # of Contigs : 2,077,594; [2021-12-31 11:28:34.693] [puff::index::jointLog] [info] Total # of numerical Contigs : 2,077,594; [2021-12-31 11:28:34.787] [puff::index::jointLog] [info] Total # of contig vec entries: 13,003,859; [2021-12-31 11:28:34.787] [puff::index::jointLog] [info] bits per offset entry 24; [2021-12-31 11:28:35.409] [puff::index::jointLog] [info] Done constructing the contig vector. 2077595; [2021-12-31 11:28:36.870] [puff::index::jointLog] [info] # segments = 2,077,594; [2",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/731#issuecomment-1003342883:2584,Load,Loading,2584,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/731#issuecomment-1003342883,1,['Load'],['Loading']
Performance,"; # [ mates1 ] => { /nfs/research2/teichmann/valentine/detection-comparison/salmon0.4.2-comparison/mouse/SRP057125_SRS936134_1.fastq }; # [ mates2 ] => { /nfs/research2/teichmann/valentine/detection-comparison/salmon0.4.2-comparison/mouse/SRP057125_SRS936134_2.fastq }; # [ output ] => { SRP057125_SRS936134_salmon_out }; # [ geneMap ] => { /nfs/research2/teichmann/reference/mus-musculus/salmon/mouse_cdna38.78_repbase_ercc_index_gene_map.txt }; # [ biasCorrect ] => { }; # [ useFSPD ] => { }; Logs will be written to SRP057125_SRS936134_salmon_out/logs; [2016-01-02 20:22:59.800] [jointLog] [info] parsing read library format; there is 1 lib; Loading 32-bit quasi index[2016-01-02 20:23:00.830] [stderrLog] [info] Loading Suffix Array; [2016-01-02 20:23:00.830] [stderrLog] [info] Loading Position Hash; [2016-01-02 20:23:00.829] [jointLog] [info] Loading Quasi index; [2016-01-02 20:23:03.751] [stderrLog] [info] Loading Transcript Info; [2016-01-02 20:23:04.776] [stderrLog] [info] Loading Rank-Select Bit Array; [2016-01-02 20:23:05.009] [stderrLog] [info] There were 104534 set bits in the bit array; [2016-01-02 20:23:05.325] [stderrLog] [info] Computing transcript lengths; [2016-01-02 20:23:05.325] [stderrLog] [info] Waiting to finish loading hash; Index contained 104534 targets; [2016-01-02 20:23:16.571] [stderrLog] [info] Done loading index; [2016-01-02 20:23:16.571] [jointLog] [info] done. processed 12000001 fragments; hits: 24367128, hits per frag: 2.04044. [2016-01-02 20:23:49.850] [jointLog] [info] Computed 102251 rich equivalence classes for further processing; [2016-01-02 20:23:49.850] [jointLog] [info] Counted 10033689 total reads in the equivalence classes; [2016-01-02 20:23:49.875] [jointLog] [info] Mapping rate = 83.0244%. [2016-01-02 20:23:49.875] [jointLog] [info] finished quantifyLibrary(); [2016-01-02 20:23:49.875] [jointLog] [info] Starting optimizer; [2016-01-02 20:23:50.378] [jointLog] [info] Marked 0 weighted equivalence classes as degenerate; [2016-01-02 ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/34#issuecomment-168426741:7945,Load,Loading,7945,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/34#issuecomment-168426741,1,['Load'],['Loading']
Performance,"; # [ mates2 ] => { SRP057125_SRS936134_2.fastq }; # [ output ] => { SRP057125_SRS936134_salmon_out }; # [ biasCorrect ] => { }; # [ useFSPD ] => { }; Logs will be written to SRP057125_SRS936134_salmon_out/logs; [2016-01-02 20:16:39.349] [jointLog] [info] parsing read library format; there is 1 lib; Loading 32-bit quasi index[2016-01-02 20:16:39.895] [stderrLog] [info] Loading Suffix Array; [2016-01-02 20:16:39.895] [stderrLog] [info] Loading Position Hash; [2016-01-02 20:16:39.894] [jointLog] [info] Loading Quasi index; [2016-01-02 20:16:42.565] [stderrLog] [info] Loading Transcript Info; [2016-01-02 20:16:43.654] [stderrLog] [info] Loading Rank-Select Bit Array; [2016-01-02 20:16:44.075] [stderrLog] [info] There were 104534 set bits in the bit array; [2016-01-02 20:16:44.448] [stderrLog] [info] Computing transcript lengths; [2016-01-02 20:16:44.448] [stderrLog] [info] Waiting to finish loading hash; Index contained 104534 targets; [2016-01-02 20:16:57.606] [stderrLog] [info] Done loading index; [2016-01-02 20:16:57.606] [jointLog] [info] done. processed 12000000 fragments; hits: 24367197, hits per frag: 2.06194+06. [2016-01-02 20:17:29.841] [jointLog] [info] Computed 102251 rich equivalence classes for further processing; [2016-01-02 20:17:29.841] [jointLog] [info] Counted 10033689 total reads in the equivalence classes; [2016-01-02 20:17:29.867] [jointLog] [info] Mapping rate = 83.0244%. [2016-01-02 20:17:29.867] [jointLog] [info] finished quantifyLibrary(); [2016-01-02 20:17:29.867] [jointLog] [info] Starting optimizer; [2016-01-02 20:17:30.130] [jointLog] [info] Marked 0 weighted equivalence classes as degenerate; [2016-01-02 20:17:30.136] [jointLog] [info] iteration = 0 | max rel diff. = 65.1271; [2016-01-02 20:17:30.315] [jointLog] [info] iteration 50, recomputing effective lengths; [2016-01-02 20:17:32.978] [jointLog] [info] iteration = 100 | max rel diff. = 0.259134; [2016-01-02 20:17:33.312] [jointLog] [info] iteration = 200 | max rel diff. = 0.136762; [201",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/34#issuecomment-168426741:2395,load,loading,2395,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/34#issuecomment-168426741,1,['load'],['loading']
Performance,"; Type ""show configuration"" for configuration details.; For bug reporting instructions, please see:; <http://www.gnu.org/software/gdb/bugs/>.; Find the GDB manual and other documentation resources online at:; <http://www.gnu.org/software/gdb/documentation/>. For help, type ""help"".; Type ""apropos word"" to search for commands related to ""word""...; Reading symbols from salmon...done.; (gdb) r; Starting program: /home/common/modules/el8/x86_64/software/salmon/1.2.1-CentOS-vanilla/bin/salmon index -t transcripts.fasta -i sample_salmon_fmd_index --type fmd; Missing separate debuginfos, use: yum debuginfo-install glibc-2.28-72.el8_1.1.x86_64; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; [Thread debugging using libthread_db enabled]; Using host libthread_db library ""/lib64/libthread_db.so.1"".; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641594410:2666,Load,Loadable,2666,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641594410,1,['Load'],['Loadable']
Performance,"; [2018-07-19 22:55:37.675] [alevinLog] [info] Done populating Z matrix; [2018-07-19 22:55:37.683] [alevinLog] [info] Done indexing Barcodes; [2018-07-19 22:55:37.683] [alevinLog] [info] Total Unique barcodes found: 978816; [2018-07-19 22:55:37.683] [alevinLog] [info] Used Barcodes except Whitelist: 20705; [2018-07-19 22:55:38.386] [jointLog] [info] There is 1 library.; [2018-07-19 22:55:38.493] [jointLog] [info] Loading Quasi index; [2018-07-19 22:55:38.494] [jointLog] [info] Loading 32-bit quasi index; [2018-07-19 22:55:38.549] [jointLog] [info] done; [2018-07-19 22:55:38.549] [jointLog] [info] Index contained 179 targets. [2018-07-19 22:55:38.385] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify. [2018-07-19 22:55:38.385] [alevinLog] [info] parsing read library format; [2018-07-19 22:55:38.495] [stderrLog] [info] Loading Suffix Array ; [2018-07-19 22:55:38.498] [stderrLog] [info] Loading Transcript Info ; [2018-07-19 22:55:38.499] [stderrLog] [info] Loading Rank-Select Bit Array; [2018-07-19 22:55:38.500] [stderrLog] [info] There were 179 set bits in the bit array; [2018-07-19 22:55:38.501] [stderrLog] [info] Computing transcript lengths; [2018-07-19 22:55:38.501] [stderrLog] [info] Waiting to finish loading hash; processed 87 Million fragmentserrLog] [info] Done loading index; hits: 468892, hits per frag: 0.00535907. [2018-07-19 23:03:35.740] [jointLog] [info] Computed 150 rich equivalence classes for further processing; [2018-07-19 23:03:35.740] [jointLog] [info] Counted 412868 total reads in the equivalence classes ; [2018-07-19 23:03:35.741] [jointLog] [warning] Only 412868 fragments were mapped, but the number of burn-in fragments was set to 5000000.; The effective lengths have been computed using the observed mappings. [2018-07-19 23:03:35.741] [jointLog] [info] Mapping rate = 0.469385%. [2018-07-19 23:03:35.741] [jointLog] [info] finished quantifyLibrary(); [2018-07-19 23:03:35.755] [alevinLog] [info] Starting optimizer. Analyzed 5238 ce",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/253#issuecomment-406597243:2975,Load,Loading,2975,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/253#issuecomment-406597243,1,['Load'],['Loading']
Performance,"; [2018-12-12 15:08:51.141] [alevinLog] [warning] Skipping 1 Barcodes with 0 reads; Assuming this is the required behavior.; [2018-12-12 15:08:51.141] [alevinLog] [info] Total 95 white-listed Barcodes; [2018-12-12 15:08:51.144] [alevinLog] [info] Done populating Z matrix; [2018-12-12 15:08:51.146] [alevinLog] [info] Done indexing Barcodes; [2018-12-12 15:08:51.146] [alevinLog] [info] Total Unique barcodes found: 4096; [2018-12-12 15:08:51.146] [alevinLog] [info] Used Barcodes except Whitelist: 1864; [2018-12-12 15:08:51.272] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify. [2018-12-12 15:08:51.272] [alevinLog] [info] parsing read library format; [2018-12-12 15:08:51.375] [stderrLog] [info] Loading Suffix Array ; [2018-12-12 15:08:51.272] [jointLog] [info] There is 1 library.; [2018-12-12 15:08:51.375] [jointLog] [info] Loading Quasi index; [2018-12-12 15:08:51.375] [jointLog] [info] Loading 32-bit quasi index; [2018-12-12 15:09:10.216] [stderrLog] [info] Loading Transcript Info ; [2018-12-12 15:09:15.719] [stderrLog] [info] Loading Rank-Select Bit Array; [2018-12-12 15:09:16.330] [stderrLog] [info] There were 205,870 set bits in the bit array; [2018-12-12 15:09:16.343] [stderrLog] [info] Computing transcript lengths; [2018-12-12 15:09:16.343] [stderrLog] [info] Waiting to finish loading hash; [2018-12-12 15:09:21.460] [stderrLog] [info] Done loading index; [2018-12-12 15:09:21.460] [jointLog] [info] done; [2018-12-12 15:09:21.460] [jointLog] [info] Index contained 205,870 targets. processed 0 Million fragments; processed 1 Million fragments; processed 1 Million fragments; ..............; processed 74 Million fragments; hits: 111594303, hits per frag: 1.50848[2018-12-12 15:12:07.666] [jointLog] [info] Thread saw mini-batch with a maximum of 5.34% zero probability fragments; [2018-12-12 15:12:07.677] [jointLog] [info] Thread saw mini-batch with a maximum of 5.48% zero probability fragments. [2018-12-12 15:12:07.721] [jointLog] [info] Computed 173,36",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/329#issuecomment-446668422:4459,Load,Loading,4459,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/329#issuecomment-446668422,1,['Load'],['Loading']
Performance,"=> { 1 }; ### [ libType ] => { ISR }; ### [ mates1 ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/merged_fastq/R10001_D2B1WACXX.fastq.gz }; ### [ mates2 ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/merged_fastq/R10001_D2B1WACXX_read2.fastq.gz }; ### [ output ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test5/R10001_D2B1WACXX }; Logs will be written to /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test5/R10001_D2B1WACXX/logs; [1m[2017-03-29 23:59:18.699] [jointLog] [info] parsing read library format; [00m[1m[2017-03-29 23:59:18.721] [jointLog] [info] There is 1 library.; [00m[1m[2017-03-30 00:43:17.278] [stderrLog] [info] Loading Suffix Array ; [00m[1m[2017-03-30 00:43:17.237] [jointLog] [info] Loading Quasi index; [00m[1m[2017-03-30 00:43:17.273] [jointLog] [info] Loading 32-bit quasi index; [00m[1m[2017-03-30 02:37:54.437] [stderrLog] [info] Loading Transcript Info ; [00m[1m[2017-03-30 03:48:21.310] [stderrLog] [info] Loading Rank-Select Bit Array; [00m[1m[2017-03-30 04:20:16.735] [stderrLog] [info] There were 198093 set bits in the bit array; [00m[1m[2017-03-30 04:54:34.486] [stderrLog] [info] Computing transcript lengths; [00m[1m[2017-03-30 04:54:34.487] [stderrLog] [info] Waiting to finish loading hash; [00m[1m[2017-03-30 05:09:36.706] [stderrLog] [info] Done loading index; [00m[1m[2017-03-30 05:09:36.706] [jointLog] [info] done; [00m[1m[2017-03-30 05:09:36.790] [jointLog] [info] Index contained 198093 targets; [00m. [A. [32mprocessed[31m 500000 [32mfragments[0m; hits: 699833, hits per frag: 1.4138[A. [32mprocessed[31m 1000000 [32mfragments[0m; hits: 1395659, hits per frag: 1.40267[A. [32mprocessed[31m 1500000 [32mfragments[0m; hits: 2097294, hits per frag: 1.40287[A. [32mprocessed[31m 2000000 [32mfragments[0m; hits: 2794766, hits per frag: 1.40089[A. [32mprocessed[31m 2500000 [32mfragments[0m; hits: 3489235, hits per frag: 1.39849[A. [32mprocessed[31m 3000000 [32mfragments",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-290516965:10163,Load,Loading,10163,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-290516965,1,['Load'],['Loading']
Performance,"> And for us, who have blocked download on a computational cluster `cmake` silently continues even when `scripts/fetchRapMap.sh` failed (see error code `403` below). Dists downloading their own dependencies is also forbidden in package managers such as FreeBSD ports and pkgsrc (which is cross-platform and I personally use on Mac, NetBSD, and RHEL). Trusting upstream scripts to pull stuff off the Internet is a security risk, so the package managers perform and validate (via checksum) all downloads in a separate stage. It would be nice not to have to hack out the download code from a build system in order to create and maintain a package.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/19#issuecomment-989326040:452,perform,perform,452,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/19#issuecomment-989326040,1,['perform'],['perform']
Performance,"> Hi @austin-abbvie,; > ; > Thanks for the report. Would you be able to share the offending BAM file and reference? I'm also tagging @gmarcais for input / ideas.; > ; > Thanks,; > Rob. I'll have to check with my manager to see if this is something I'm allowed to do. I also just attempted to use the --noErrorModel instead of --ont, but now I'm getting a `segmentation fault (core dumped)` after about 2M reads. These BAMs have been through a lot so I'm going to check to make sure they haven't been corrupted in some way. Here's an output from Picard's ValidateSamFile; ```; WARNING 2021-07-01 08:12:30 ValidateSamFile NM validation cannot be performed without the reference. All other validations will still occur.; INFO 2021-07-01 08:12:48 SamFileValidator Seen many non-increasing record positions. Printing Read-names as well. ## HISTOGRAM java.lang.String; Error Type Count; ERROR:MISSING_READ_GROUP 1; WARNING:RECORD_MISSING_READ_GROUP 1085776; ```. After adding a dummy read group to one of my bam files using Picard's AddOrReplaceReadGroups, I was able to successfully quantify my file using the --ont error model. I'll repeat this for the lot to see if this solves the problem!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/289#issuecomment-872314305:644,perform,performed,644,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/289#issuecomment-872314305,1,['perform'],['performed']
Performance,> I have the same issue. None of the conda version works on my Linux Centos.; > Is there any library to add in the conda recipe to fix the issue ?. Similar issue here too with salmon 1.4.0 installed via conda in a clean environment; `salmon: error while loading shared libraries: libtbb.so.2: cannot open shared object file: No such file or directory`. Edit: apparently solved by downgrading `tbb` as suggested in https://www.biostars.org/p/494922/,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/565#issuecomment-802737580:254,load,loading,254,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/565#issuecomment-802737580,1,['load'],['loading']
Performance,"> Thanks again @alexvpickering, just pushed a fix. Confirm that .mtx.gz file is loading properly now. Thanks again!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/380#issuecomment-503787604:80,load,loading,80,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/380#issuecomment-503787604,1,['load'],['loading']
Performance,"> Yes that's one aspect. But also, Salmon uses CIGAR to evaluate alignment probability in alignment quantification mode no?. Indeed. > And with just RapMap output you would lose other information that Salmon uses to determine likely fragment assignment?. You would lose information (in the format of a CIGAR string) that Salmon uses in alignment mode, but not any information, I think, that Salmon uses in quasi-mapping-based mode (though one would incur a non-trivial performance hit for filtering the quasi-mappings through file / disk rather than dealing with them directly in memory as Salmon normally does). > With UMI's you can deduplicate fragments before inferring where they were likely to come from. Ideally you would deduplicate the reads directly based on UMI, then you wouldn't have to think about PCR duplication in the quantification. But of course keeping a hash of all reads in a FASTQ and accounting for dequencing errors wouldn't be really tractable.. I guess this is the real question I have. Specifically, what is the true computational burden to detect and eliminate duplicates using UMIs? In theory, the reads must (1) map to the same location and (2) have the same UMI tag. How often would one expect the UMI tag to be modified / corrupted / etc.? Would you have to search all 1 or 2 hamming distance neighbors to detect duplicates reliably? Is an equivalence class a sufficient proxy for ""mapping to the same location"", or do we also care that e.g. the position of the fragment within each transcript is a duplicate as well? These are the main questions that are preventing me from implementing the ""obvious solution"".",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/108#issuecomment-269001682:469,perform,performance,469,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/108#issuecomment-269001682,1,['perform'],['performance']
Performance,"> You mean like cloud services to perform the DE analysis? It’s always possible to round the non-integer counts to the nearest integer. However, reliable abundance estimation tools (e.g. RSEM) have been around long enough now that it’s worth pushing any cloud service you might be using to properly deal with these types of inputs. We do differential analysis quite commonly with DESeq2, and salmon -> tximport -> DESeq2 is a quite low-friction solution. I noticed that now salmon can export the quant.gene.sf file if I add the parameters""-g xx.gtf"". What's difference between this file and the result of tximport? Can I use the result to replace tximport?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/437#issuecomment-1535046180:34,perform,perform,34,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/437#issuecomment-1535046180,1,['perform'],['perform']
Performance,"> quant ; ### [ index ] => { /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts }; ### [ threads ] => { 1 }; ### [ libType ] => { ISR }; ### [ mates1 ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/merged_fastq/R10001_D2B1WACXX.fastq.gz }; ### [ mates2 ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/merged_fastq/R10001_D2B1WACXX_read2.fastq.gz }; ### [ output ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test5/R10001_D2B1WACXX }; Logs will be written to /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test5/R10001_D2B1WACXX/logs; [1m[2017-03-29 23:59:18.699] [jointLog] [info] parsing read library format; [00m[1m[2017-03-29 23:59:18.721] [jointLog] [info] There is 1 library.; [00m[1m[2017-03-30 00:43:17.278] [stderrLog] [info] Loading Suffix Array ; [00m[1m[2017-03-30 00:43:17.237] [jointLog] [info] Loading Quasi index; [00m[1m[2017-03-30 00:43:17.273] [jointLog] [info] Loading 32-bit quasi index; [00m[1m[2017-03-30 02:37:54.437] [stderrLog] [info] Loading Transcript Info ; [00m[1m[2017-03-30 03:48:21.310] [stderrLog] [info] Loading Rank-Select Bit Array; [00m[1m[2017-03-30 04:20:16.735] [stderrLog] [info] There were 198093 set bits in the bit array; [00m[1m[2017-03-30 04:54:34.486] [stderrLog] [info] Computing transcript lengths; [00m[1m[2017-03-30 04:54:34.487] [stderrLog] [info] Waiting to finish loading hash; [00m[1m[2017-03-30 05:09:36.706] [stderrLog] [info] Done loading index; [00m[1m[2017-03-30 05:09:36.706] [jointLog] [info] done; [00m[1m[2017-03-30 05:09:36.790] [jointLog] [info] Index contained 198093 targets; [00m. [A. [32mprocessed[31m 500000 [32mfragments[0m; hits: 699833, hits per frag: 1.4138[A. [32mprocessed[31m 1000000 [32mfragments[0m; hits: 1395659, hits per frag: 1.40267[A. [32mprocessed[31m 1500000 [32mfragments[0m; hits: 2097294, hits per frag: 1.40287[A. [32mprocessed[31m 2000000 [32mfragments[0m; hits: 27947",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-290516965:10001,Load,Loading,10001,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-290516965,1,['Load'],['Loading']
Performance,">>>>>>>>>>>>>>>>; Reference = [reference.masked.genome.fa]; Query = [/nfs/no_backup/transcriptome_seqs/Mus_musculus_GENCODE_v25_GRCm38.fa]; Kmer size = 16; Window size = 5; Segment length = 500 (read split allowed); Alphabet = DNA; Percentage identity threshold = 80%; Mapping output file = mashmap.out; Filter mode = 1 (1 = map, 2 = one-to-one, 3 = none); Execution threads = 8; >>>>>>>>>>>>>>>>>>; INFO, skch::Sketch::build, minimizers picked from reference = 843543544; INFO, skch::Sketch::index, unique minimizers = 276648625; INFO, skch::Sketch::computeFreqHist, Frequency histogram of minimizers = (1, 141685574) ... (2606547, 1); INFO, skch::Sketch::computeFreqHist, With threshold 0.001%, ignore minimizers occurring >= 7361 times during lookup.; INFO, skch::main, Time spent computing the reference index: 549.706 sec; INFO, skch::Map::mapQuery, [count of mapped reads, reads qualified for mapping, total input reads] = [111965, 112131, 142604]; INFO, skch::main, Time spent mapping the query : 17487.5 sec; INFO, skch::main, mapping results saved in : mashmap.out; [4/10] Extracting intervals from mashmap alignments; [5/10] Merging the intervals; [6/10] Extracting sequences from the genome; [7/10] Concatenating to get decoy sequences; [8/10] Making gentrome; [9/10] Extracting decoy sequence ids; [10/10] Removing temporary files; ```. Check the decoys:; ```; head /no_backup/indexes/salmon/gencode_mm10_unzip/decoys.txt ; GL456210.1; GL456367.1; chrX; chrY; GL456221.1; JH584304.1; GL456378.1; GL456211.1; JH584296.1; JH584300.1; ```. Check that the decoys are there in the `gentrome.fa`; ```; zgrep "">GL456210.1"" /no_backup/indexes/salmon/gencode_mm10_unzip/gentrome.fa ; >GL456210.1; ```. and then index with :; ```; salmon index -t /no_backup/indexes/salmon/gencode_mm10_unzip/gentrome.fa \; -i /no_backup/indexes/salmon/mm10_gencode \; -d /no_backup/indexes/salmon/gencode_mm10_unzip/decoys.txt \; -k 29 --threads 8 --gencode; ```; the job is in the queue now, I'll keep you posted.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/731#issuecomment-1003335885:2494,queue,queue,2494,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/731#issuecomment-1003335885,1,['queue'],['queue']
Performance,"@SFonsecaCosta,. Yes, the file is called `duplicate_clusters.tsv` and it is in the directory where the salmon *index* resides. The reason this is created is that when transcripts are sequence identical to each other, they cannot be independently quantified — that is, they are inferentially indistinguishable. So, the default strategy is to keep one representative from each indistinguishable cluster and to record the rest in the `duplicate_clusters` file. If you want to force salmon to quantify the duplicates (they should all just get equal abundance of 1 / D where D is the number of duplicates), you can pass `--keepDuplicates` when building the salmon index. When you quantify with alignments performed by STAR, no such duplicate removal is done by STAR upstream, and so all of the sequence identical transcripts are retained.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/803#issuecomment-1263826925:700,perform,performed,700,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/803#issuecomment-1263826925,1,['perform'],['performed']
Performance,"@ctb — One thing that would be required for this (apart from some engineering of the command-line parsing / validation code) is a trustworthy, efficient, _multithreaded_ `FAST(A/Q)` parser for interleaved format reads. Right now, Salmon (& Sailfish, &RapMap, & most of the other HTS-centric methods we're developing) use the Jellyfish 2 read parser. I've made this choice since it's fairly simple to use, yet provides nice parallel performance and, most importantly, is fairly well-tested and trust-worthy. Can you suggest a reliable, well-tested, concurrency-enabled library for parsing reads in interleaved format?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/29#issuecomment-152827801:432,perform,performance,432,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/29#issuecomment-152827801,2,"['concurren', 'perform']","['concurrency-enabled', 'performance']"
Performance,"@k3yavi That seems to have fixed it, but I did get a warning at the end:. ```; [2018-09-18 15:18:46.675] [alevinLog] [info] Finished optimizer; [2018-09-18 15:18:46.697] [jointLog] [warning] NOTE: Read Lib [./read-I1_si-AGGGACTG_lane-001-chunk-001.fastq.gz, ./read-I1_si-AGGGACTG_lane-002-chunk-000.fastq.gz, ./read-I1_si-AGGGACTG_lane-003-chunk-003.fastq.gz, ./read-I1_si-AGGGACTG_lane-004-chunk-002.fastq.gz, ./read-I1_si-CCTCTAAC_lane-001-chunk-001.fastq.gz, ./read-I1_si-CCTCTAAC_lane-002-chunk-000.fastq.gz, ./read-I1_si-CCTCTAAC_lane-003-chunk-003.fastq.gz, ./read-I1_si-CCTCTAAC_lane-004-chunk-002.fastq.gz, ./read-I1_si-GACAGGCT_lane-001-chunk-001.fastq.gz, ./read-I1_si-GACAGGCT_lane-002-chunk-000.fastq.gz, ./read-I1_si-GACAGGCT_lane-003-chunk-003.fastq.gz, ./read-I1_si-GACAGGCT_lane-004-chunk-002.fastq.gz, ./read-I1_si-TTATCTGA_lane-001-chunk-001.fastq.gz, ./read-I1_si-TTATCTGA_lane-002-chunk-000.fastq.gz, ./read-I1_si-TTATCTGA_lane-003-chunk-003.fastq.gz, ./read-I1_si-TTATCTGA_lane-004-chunk-002.fastq.gz] :. Greater than 5% of the fragments disagreed with the provided library type; check the file: ../../alevin_15_pc/lib_format_counts.json for details; ```; Is this ok to ignore?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/294#issuecomment-422564822:133,optimiz,optimizer,133,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/294#issuecomment-422564822,1,['optimiz'],['optimizer']
Performance,"@macmanes — Heng's code is very well-tested, but afaik, completely serialized. Of course, that's nothing that we couldn't handle internally by throwing the reported reads into our concurrent queue. Actually, I think that the Jellyfish 2 parser (for a single `FAST(A/Q)` file) would be easy to make work in this context. The trick is to require that the read ""batches"" always end on an even-indexed boundary, so that we never have an (interleaved) read pair spit across batch boundaries. I'm not sure how easy or difficult that is to enforce. I might just ask Guillaume about the best way to enforce this.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/29#issuecomment-152828484:180,concurren,concurrent,180,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/29#issuecomment-152828484,2,"['concurren', 'queue']","['concurrent', 'queue']"
Performance,"@rob-p - How much effort would it be to run a DP with tracing of the alignment? I remember reading that Brian Bushnell managed to fit everything into the CPU cache for BBMap's alignment algorithm, at least for regular read lengths, so the performance impact should be acceptable if done right. Not sure about licenses, but I think there was an optional native C implementation for it in his code base. This would be great to have so the SAM can be used for e.g. basic genotyping for QC purposes. Alternatively, maybe add a line to the docs of --writeMappings to make sure everyone understands the read alignments will have a score and position, but lack actual alignment and appear as if they were perfect matches.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/491#issuecomment-1204244129:158,cache,cache,158,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/491#issuecomment-1204244129,2,"['cache', 'perform']","['cache', 'performance']"
Performance,"@roryk I don't think an R package is the right answer :) . My real motivation is to load into Degust: http://www.vicbioinformatics.com/degust/. It can be done with simple Unix cut/paste or with a python script too. But I don't want to depend on R for the pipeline, or even littler. @vals I'll take a look at your script, but still be better if part of Salmon.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/77#issuecomment-240556885:84,load,load,84,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/77#issuecomment-240556885,1,['load'],['load']
Performance,"@vals, it shouldn't be a coverage issue, at least as compared to previous versions of Salmon. Hopefully we'll have a chance to look at this soon and see if we can figure out what might be causing the performance ""regression"" when `--useVBOpt` is enabled. As @dcjones suggests, we haven't really seen any performance degradation with the VB option in our other testing, so I suspect something characteristic of this dataset. @dcjones; it's great to see you drop by! I'm actually looking for a reasonable collection of datasets to do (automated) regression testing on new releases of salmon --- something to replace my fairly simple and manual existing regression tests. I'd greatly appreciate any suggestions or advice you may have about this! Such tests will become even more useful as we're experimenting with a few inference approaches and it would be great to have a reasonable spread of data to see the effects of different strategies.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/6#issuecomment-112224408:200,perform,performance,200,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/6#issuecomment-112224408,2,['perform'],['performance']
Performance,"A bit delayed, but this relates to the questions I've been asking on the salmon gitter. . First, it's worth pointing out that the new 10x (v2) sequencing is a lot more like other bead methods, where (i) index reads (i7/i5) are for labelling biological samples (ii) read1 contains the combined cell and molecular/UMI barcodes (ii) read2 is the transcript 3' read. So it seems there is now some data format convergence. Either way, I'd guess that ongoing iterations of the high throughput platforms will keep one read for the transcript 3', reserving the other 2 or 3 reads for some combination of the sample, cell and molecular barcodes. . Before thinking about how to best collapse UMIs, there's also the issue of how best to QC the barcodes and beads. Jim Namesh has [some functions](http://mccarrolllab.com/wp-content/uploads/2016/03/Drop-seqAlignmentCookbookv1.2Jan2016.pdf); as does [Vasilis Ntranos](https://github.com/pachterlab/scRNA-Seq-TCC-prep/blob/master/README.md). Arguably this has nothing to do with salmon/kallisto though I think the kallisto guys were smart to include it. It's a good filter even if only for speeding things up. Then it's really what might be the most appropriate demultiplexing of fastqs to allow compatibility between tecnhiques, I guess. I quite like how the kallisto workflow ends up with a fastq per cell together with a matching UMI file. Then at the very least one can ignore the UMIs (perhaps going with what @vals suggests). Not sure if that's helpful. But thought to chime in as somebody we would love to see salmon working on the high throughput single-cell platforms that have sample, cell and molecular barcodes. Even if only to test how worthwhile UMIs genuinely are for most applications. This may be a controversial comment, but I suspect for me UMIs will largely end up the same way as spike-ins: useful for quantifying endogenous RNA recovered per cell but perhaps not all that useful beyond that for low read depth single-cell signature profiling.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/93#issuecomment-265619589:1606,throughput,throughput,1606,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/93#issuecomment-265619589,1,['throughput'],['throughput']
Performance,"APSa16_1P.fq.gz }; ### [ mates2 ] => { /media/usr/trimmed_fastq_files/PAIRED_trimmed_fastq_files/APSa16_2P.fq.gz }; ### [ threads ] => { 7 }; ### [ output ] => { /media/usr/quantification/APSa16.fq.gz_quant }; Logs will be written to /media/usr/quantification/APSa16.fq.gz_quant/logs; [2020-05-05 09:19:06.171] [jointLog] [info] setting maxHashResizeThreads to 7; [2020-05-05 09:19:06.171] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2020-05-05 09:19:06.171] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2020-05-05 09:19:06.171] [jointLog] [info] Usage of --validateMappings implies a default consensus slack of 0.2. Setting consensusSlack to 0.35.; [2020-05-05 09:19:06.171] [jointLog] [info] parsing read library format; [2020-05-05 09:19:06.171] [jointLog] [info] There is 1 library.; [2020-05-05 09:19:06.278] [jointLog] [info] Loading pufferfish index; [2020-05-05 09:19:06.278] [jointLog] [warning] The index did not record if the `--keepDuplicates` flag was used. Please consider re-indexing with a newer version of salmon that will propagate this information.; [2020-05-05 09:19:06.278] [jointLog] [info] Loading dense pufferfish index.; -----------------------------------------; | Loading contig table | Time = 30.609 s; -----------------------------------------; size = 36981178; -----------------------------------------; | Loading contig offsets | Time = 1.3312 s; -----------------------------------------; -----------------------------------------; | Loading reference lengths | Time = 5.6842 ms; -----------------------------------------; -----------------------------------------; | Loading mphf table | Time = 20.002 s; -----------------------------------------; size = 3784352032; Number of ones: 36981177; Number of ones per inventory item: 512; Inventory entries filled: 72229; -----------------------------------------; | ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/518#issuecomment-623910021:1429,Load,Loading,1429,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/518#issuecomment-623910021,1,['Load'],['Loading']
Performance,"ARTID, parent_tidptr=0x7ffebe5e89d0, tls=0x7ffebe5e8700, child_tidptr=0x7ffebe5e89d0) = 14677; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts/sa.bin"", O_RDONLY) = 4; clock_gettime(CLOCK_REALTIME, {1491424830, 149197282}) = 0; read(4, ""l\n\221\21\0\0\0\0k\n\221\21\373\25\343\20\17\254\r\1\36\27\227\n\37\371\270\4\250\210\307\f""..., 8191) = 8191; mmap(NULL, 1342177280, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_NORESERVE, -1, 0) = 0x7ffe2e5e8000; munmap(0x7ffe2e5e8000, 1342177280) = 0; mmap(NULL, 1344270336, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_NORESERVE, -1, 0) = 0x7ffe2e3e9000; munmap(0x7ffe2e3e9000, 94208) = 0; munmap(0x7ffe7e400000, 1998848) = 0; [1m[2017-04-05 16:40:30.149] [stderrLog] [info] Loading Suffix Array ; [00m[1m[2017-04-05 16:40:30.069] [jointLog] [info] Loading Quasi index; [00m[1m[2017-04-05 16:40:30.139] [jointLog] [info] Loading 32-bit quasi index; [00mread(4, ""\16'w=\r\320m\306\0\35\26\306\0\224\23\270\10\205]D\0|\3!\4c_-\7\310O\2""..., 1178864057) = 1178864057; close(4) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts/txpInfo.bin"", O_RDONLY) = 4; clock_gettime(CLOCK_REALTIME, {1491424833, 297142816}) = 0; read(4, ""\315\5\3\0\0\0\0\0|\0\0\0\0\0\0\0ENST00000456328.""..., 8191) = 8191; read(4, ""RP4-669L17.8-001|RP4-669L17.8|12""..., 8191) = 8191; read(4, "".2|LINC01128-004|LINC01128|874|l""..., 8191) = 8191; read(4, ""THUMT00000097991.1|AGRN-002|AGRN""..., 8191) = 8191; read(4, ""HUMG00000001412.6|OTTHUMT0000000""..., 8191) = 8191; read(4, ""F3L-007|CPSF3L|1868|protein_codi""..., 8191) = 8191; read(4, ""01413.3|OTTHUMT00000004082.2|AUR""..., 8191) = 8191; read(4, ""UMT00000001363.3|ATAD3A-001|ATAD""..., 8191) = 8191; read(4, ""DK11B-202|CDK11B|2490|protein_co""..., 8191) = 8191; read(4, ""00002763.1|GNB1-002|GNB1|1512|re""..., 8191) = 8191; read(4, ""20-006|FAAP20|569|protein_coding""..., 819",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:167402,Load,Loading,167402,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,1,['Load'],['Loading']
Performance,Ah so what's happening is alevin is keeping around 500 low confidence CB for performing downstream whitelisting.; `[2021-12-10 15:28:09.434] [alevinLog] [info] Total 1501(has 500 low confidence) barcodes`,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/739#issuecomment-1022395566:77,perform,performing,77,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/739#issuecomment-1022395566,1,['perform'],['performing']
Performance,Awesome! Thank you so much for the detailed report and for finding this data that exposed this strange (but interesting) performance case. We'll fold these improvements into the next release as well.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/527#issuecomment-637601951:121,perform,performance,121,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/527#issuecomment-637601951,1,['perform'],['performance']
Performance,"B_INCLUDE_DIRS-ADVANCED:INTERNAL=1; //ADVANCED property for variable: TBB_LIBRARY; TBB_LIBRARY-ADVANCED:INTERNAL=1; //ADVANCED property for variable: TBB_LIBRARY_DEBUG; TBB_LIBRARY_DEBUG-ADVANCED:INTERNAL=1; //ADVANCED property for variable: TBB_LIBRARY_DIRS; TBB_LIBRARY_DIRS-ADVANCED:INTERNAL=1; //ADVANCED property for variable: TBB_MALLOC_LIBRARY; TBB_MALLOC_LIBRARY-ADVANCED:INTERNAL=1; //ADVANCED property for variable: TBB_MALLOC_LIBRARY_DEBUG; TBB_MALLOC_LIBRARY_DEBUG-ADVANCED:INTERNAL=1; ```. Also, here's the output of every hardware/OS reporting command I can think of:. ```; $ cat /proc/cpuinfo; processor : 0; vendor_id : GenuineIntel; cpu family : 6; model : 63; model name : Intel(R) Xeon(R) CPU E5-2623 v3 @ 3.00GHz; stepping : 2; microcode : 0x36; cpu MHz : 3300.000; cache size : 10240 KB; physical id : 0; siblings : 8; core id : 0; cpu cores : 4; apicid : 0; initial apicid : 0; fpu : yes; fpu_exception : yes; cpuid level : 15; wp : yes; flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36; clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc; arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqd; q dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid dca sse4_1 sse4; _2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm epb tpr_sh; adow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid cqm x; saveopt cqm_llc cqm_occup_llc dtherm ida arat pln pts; bugs :; bogomips : 5985.57; clflush size : 64; cache_alignment : 64; address sizes : 46 bits physical, 48 bits virtual; power management:; ...; [And 7 more cores]; $ uname -a; Linux salomon24 4.4.0-51-generic #72-Ubuntu SMP Thu Nov 24 18:29:54 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux; $ lsb_release -d; Description: Ubuntu 16.04.1 LTS; ```. lshw output: [salomon24-lshw.txt](https://github.com/COMBINE-lab/salmon/files/650904/salomon24-lshw.txt)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-266953657:1819,cache,cache,1819,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-266953657,1,['cache'],['cache']
Performance,"CMake caches some information during the build in `CMakeCache.txt` (I think) so you probably have to delete that, or your build directory, and then start again.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/42#issuecomment-186697657:6,cache,caches,6,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/42#issuecomment-186697657,1,['cache'],['caches']
Performance,"Confirmed with v0.6.0:. ```; Version Info: Could not resolve upgrade information in the alotted time.; Check for upgrades manually at https://combine-lab.github.io/salmon; # salmon (mapping-based) v0.6.0; # [ program ] => salmon; # [ command ] => quant; # [ index ] => { ... }; # [ libType ] => { IU }; # [ mates1 ] => { ... }; # [ mates2 ] => { ... }; # [ output ] => {... }; # [ threads ] => { 16 }; Logs will be written to ...; there is 1 lib; [2016-01-22 17:59:17.894] [jointLog] [info] parsing read library format; Loading 32-bit quasi index[2016-01-22 17:59:18.735] [stderrLog] [info] Loading Suffix Array; [2016-01-22 17:59:18.736] [stderrLog] [info] Loading Position Hash; [2016-01-22 17:59:18.731] [jointLog] [info] Loading Quasi index; [2016-01-22 18:00:59.879] [stderrLog] [info] Loading Transcript Info; [2016-01-22 18:01:25.157] [stderrLog] [info] Loading Rank-Select Bit Array; [2016-01-22 18:01:30.642] [stderrLog] [info] There were 552702 set bits in the bit a; [2016-01-22 18:01:31.487] [stderrLog] [info] Computing transcript lengths; [2016-01-22 18:01:31.491] [stderrLog] [info] Waiting to finish loading hash; Index contained 552702 targets; [2016-01-22 18:04:43.717] [jointLog] [info] done; [2016-01-22 18:04:43.717] [stderrLog] [info] Done loading index; ```. I'll check the index creation logs, but didn't notice anything out of the ordinary...",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/37#issuecomment-174082911:520,Load,Loading,520,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/37#issuecomment-174082911,8,"['Load', 'load']","['Loading', 'loading']"
Performance,"Damn. There are random numbers, but even setting the seed, the multi-threaded nature of almost all steps leads to non-deterministic behavior. The behavior you describe sounds like some sort of race condition that gets triggered depending on when threads get to different parts of the code. I couldn't get the hanging with the other dataset over multiple (~10) runs. So even if it's completely non-deterministic you seem to be getting it with higher frequency in your system. Is it always in the Gibbs phase? One question / thought, did salmon fetch and build the Intel TBB dependency, or are you using a system version?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-266951967:63,multi-thread,multi-threaded,63,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-266951967,2,"['multi-thread', 'race condition']","['multi-threaded', 'race condition']"
Performance,"Dear @callumparr,. Thank you for bringing this up. So you are correct that the `--noLengthCorrection` flag should be passed to salmon when quantifying data that does not have a ""fragmentation effect"", that is, where the number of fragments we expect to draw from a transcript is not dependent upon the length of that transcript. In the ONT protocols, it is usually the case that we get 1 read -> 1 transcript, even if we don't read the whole thing. We have tested the effect of this in ONT data with spike ins, and have verified that using `--noLengthCorrection` does generally lead to improved accuracy with respect to quantification estimates. We have informed ONT of this, and I would guess they may optimize the flags that are used soon (we have also developed an error model that works correctly for these long reads, and that should make it into the next release of salmon). Regarding the effect this has on the `NumReads` values reported by salmon, it's not as simple as with the `TPM` estimates. The length affects the assigned reads through the probabilistic model on which inference is done. With the length effect we have that P(f | t_i) ∝ P( position | f, t_i ) * P( alignment | f, t_i) --- forgetting the alignment term for the time being, we have that with length correction P( position | f, t_i ) ∝ 1 / l_i and without length correction the l_i term goes away. In other words, the probability of allocating reads has a term that depends on the effective length when the `--noLengthCorrection` flag is not passed, but that term goes away when it is passed. This is not quite as drastic as with TPM where the normalization includes the length directly in the normalization (note, however, that when the `--noLengthCorrection` flag is passed, this adjusts the TPM as well). Further, the `NumReads` is still better than TPM in this regard because it still encodes the effect size (i.e. `NumReads` will sum to the total number of aligned reads). Anyway TLDR: Passing the `--noLengthCorrectio",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/651#issuecomment-821995147:703,optimiz,optimize,703,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/651#issuecomment-821995147,1,['optimiz'],['optimize']
Performance,"Dear Peter,. I am also trying salmon for miRNA quant and was searching for tips and experience from other users/developers on this scenario. How did salmon perform for you in this use case? . Gonçalo",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/826#issuecomment-2228388816:156,perform,perform,156,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/826#issuecomment-2228388816,1,['perform'],['perform']
Performance,"EQVecT means we are in the function with `template <typename EQVecT>`; i is the index of the loop that generates alphaSum; If I printf ""Round"" line 257, I get:; [2018-05-31 22:27:34.996] [jointLog] [info] Starting optimizer; Round; [2018-05-31 22:27:35.226] [jointLog] [info] Marked 1 weighted equivalence classes as degenerate; Round; [2018-05-31 22:27:35.257] [jointLog] [info] iteration = 0 | max rel diff. = 127.379; Exception : [Error in function boost::math::digamma<double>(double): numeric overflow]",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/229#issuecomment-393669382:214,optimiz,optimizer,214,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/229#issuecomment-393669382,1,['optimiz'],['optimizer']
Performance,"E_FS|CLONE_FILES|CLONE_SIGHAND|CLONE_THREAD|CLONE_SYSVSEM|CLONE_SETTLS|CLONE_PARENT_SETTID|CLONE_CHILD_CLEARTID, parent_tidptr=0x7ffebe5e89d0, tls=0x7ffebe5e8700, child_tidptr=0x7ffebe5e89d0) = 14677; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts/sa.bin"", O_RDONLY) = 4; clock_gettime(CLOCK_REALTIME, {1491424830, 149197282}) = 0; read(4, ""l\n\221\21\0\0\0\0k\n\221\21\373\25\343\20\17\254\r\1\36\27\227\n\37\371\270\4\250\210\307\f""..., 8191) = 8191; mmap(NULL, 1342177280, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_NORESERVE, -1, 0) = 0x7ffe2e5e8000; munmap(0x7ffe2e5e8000, 1342177280) = 0; mmap(NULL, 1344270336, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_NORESERVE, -1, 0) = 0x7ffe2e3e9000; munmap(0x7ffe2e3e9000, 94208) = 0; munmap(0x7ffe7e400000, 1998848) = 0; [1m[2017-04-05 16:40:30.149] [stderrLog] [info] Loading Suffix Array ; [00m[1m[2017-04-05 16:40:30.069] [jointLog] [info] Loading Quasi index; [00m[1m[2017-04-05 16:40:30.139] [jointLog] [info] Loading 32-bit quasi index; [00mread(4, ""\16'w=\r\320m\306\0\35\26\306\0\224\23\270\10\205]D\0|\3!\4c_-\7\310O\2""..., 1178864057) = 1178864057; close(4) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts/txpInfo.bin"", O_RDONLY) = 4; clock_gettime(CLOCK_REALTIME, {1491424833, 297142816}) = 0; read(4, ""\315\5\3\0\0\0\0\0|\0\0\0\0\0\0\0ENST00000456328.""..., 8191) = 8191; read(4, ""RP4-669L17.8-001|RP4-669L17.8|12""..., 8191) = 8191; read(4, "".2|LINC01128-004|LINC01128|874|l""..., 8191) = 8191; read(4, ""THUMT00000097991.1|AGRN-002|AGRN""..., 8191) = 8191; read(4, ""HUMG00000001412.6|OTTHUMT0000000""..., 8191) = 8191; read(4, ""F3L-007|CPSF3L|1868|protein_codi""..., 8191) = 8191; read(4, ""01413.3|OTTHUMT00000004082.2|AUR""..., 8191) = 8191; read(4, ""UMT00000001363.3|ATAD3A-001|ATAD""..., 8191) = 8191; read(4, ""DK11B-202|CDK11B|2490|protein_co""..., 8191) = 8191; read(",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:167328,Load,Loading,167328,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,1,['Load'],['Loading']
Performance,"Excellent! Now we should do some internal testing to see if this has any negative performance impact on machines that _do_ have SSE4. Then we can determine if we can just make this the default, or if it's worth cutting a release under 2 configurations.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/500#issuecomment-610602162:82,perform,performance,82,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/500#issuecomment-610602162,1,['perform'],['performance']
Performance,"FYI, miniconda works fine on FreeBSD. It's not too difficult to configure manually, but to make it even easier:. As root:. ```; pkg install auto-admin linux-miniconda-installer; auto-install-linux_base; ```; As a non-root user:. ```; miniconda-installer; conda-shell; conda config --add channels conda-forge; conda config --add channels bioconda; conda create -n salmon salmon; ```; Note: Just running `conda install salmon` instead of `conda create -n salmon salmon` will install a very old version rather than the latest. This utilizes the Linux compatibility module, which simply adds Linux system calls to the FreeBSD kernel. Unlike a virtual machine, there's no performance penalty and memory overhead is trivial. In fact, Linux binaries sometimes run slightly faster on FreeBSD than they do on Linux. Average speed is about the same. I'd only use conda as a stop-gap, though. There's a large and growing selection of bioinformatics software in FreeBSD ports that can be more easily installed and used, e.g. 'pkg install samtools bwa'. Also I'm working on a native FreeBSD port for salmon:. https://github.com/COMBINE-lab/salmon/issues/162. Best,. Jason",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/419#issuecomment-917648051:667,perform,performance,667,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/419#issuecomment-917648051,1,['perform'],['performance']
Performance,"Fraction. Since not explicitly specified, it is being set to 0.65; [2019-08-25 11:40:44.518] [jointLog] [info] Usage of --validateMappings, without --hardFilter implies use of range factorization. rangeFactorizationBins is being set to 4; [2019-08-25 11:40:44.518] [jointLog] [info] Usage of --validateMappings implies a default consensus slack of 0.2. Setting consensusSlack to 0.2.; [2019-08-25 11:40:44.518] [jointLog] [info] parsing read library format; [2019-08-25 11:40:44.518] [jointLog] [info] There is 1 library.; Exception : [Error: The index version file salmonIndexDecoyMouse/versionInfo.json doesn't seem to exist. Please try re-building the salmon index.]; salmon quant was invoked improperly.; For usage information, try salmon quant --help; Exiting.; (salmon) wayne@Ubuntu19:~/rnaseq$ ls -R *.json; ls: cannot access '*.json': No such file or directory. Try 2.; Instead of referring to my directory decoys/ , I moved to the directory decoys/ ; and ran salmon index again, using your command exactly:; salmon index -t gentrome.fa -d decoys.txt -i combined_index. This time a few .json files were produced in the directory combined_index/ [your name this time]; [contents of decoys= combined_index gentrome.fa mus_musculus.tar.gz Salmontranscripts_quant; decoys.txt links.txt salmonQuantDecoy22.sh]. then [sh salmonQuantDecoy22.sh]; salmon quant -p 3 -i combined_index -l A -1 ../SRR1818187_2.fastq.gz -2 ../SRR1818187_1.fastq.gz --validateMappings -o Salmontranscripts_quant. Now no Segmentation Fault crash. ; The program finishes with; [2019-08-25 12:37:39.056] [jointLog] [info] Finished optimizer; [2019-08-25 12:37:39.056] [jointLog] [info] writing output . Now I am going to look for the mRNA counts. I think a major secret is to have mus_musculus.tar.gz in the same directory.; If my description is accurate [I did not repeat everything] you should have -mRNA [path to transcriptome.gz] on your command line, or instruct users to have the transcriptome.gz in the same directory.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/419#issuecomment-524651435:3026,optimiz,optimizer,3026,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/419#issuecomment-524651435,1,['optimiz'],['optimizer']
Performance,"Fraction. Since not explicitly specified, it is being set to 0.65; [2020-05-05 09:19:06.171] [jointLog] [info] Usage of --validateMappings implies a default consensus slack of 0.2. Setting consensusSlack to 0.35.; [2020-05-05 09:19:06.171] [jointLog] [info] parsing read library format; [2020-05-05 09:19:06.171] [jointLog] [info] There is 1 library.; [2020-05-05 09:19:06.278] [jointLog] [info] Loading pufferfish index; [2020-05-05 09:19:06.278] [jointLog] [warning] The index did not record if the `--keepDuplicates` flag was used. Please consider re-indexing with a newer version of salmon that will propagate this information.; [2020-05-05 09:19:06.278] [jointLog] [info] Loading dense pufferfish index.; -----------------------------------------; | Loading contig table | Time = 30.609 s; -----------------------------------------; size = 36981178; -----------------------------------------; | Loading contig offsets | Time = 1.3312 s; -----------------------------------------; -----------------------------------------; | Loading reference lengths | Time = 5.6842 ms; -----------------------------------------; -----------------------------------------; | Loading mphf table | Time = 20.002 s; -----------------------------------------; size = 3784352032; Number of ones: 36981177; Number of ones per inventory item: 512; Inventory entries filled: 72229; -----------------------------------------; | Loading contig boundaries | Time = 11.467 s; -----------------------------------------; size = 3784352032; -----------------------------------------; | Loading sequence | Time = 9.5665 s; -----------------------------------------; size = 2674916722; -----------------------------------------; | Loading positions | Time = 4.3912 ms; -----------------------------------------; Exception : [std::bad_alloc]; salmon quant was invoked improperly.; For usage information, try salmon quant --help; Exiting. Not sure why it happens... memory doesn't reach the max. ![Screenshot at 2020-05-05 09-45-37",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/518#issuecomment-623910021:2063,Load,Loading,2063,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/518#issuecomment-623910021,1,['Load'],['Loading']
Performance,"Great. I'm not sure why the old index was problematic, but I'm glad this one seems to load successfully etc. Also, I'm glad the read set is rather large, because this is one of those cases where the index loading time might otherwise trump the time related to map the reads on a smaller dataset! I have some work to do in speeding up the loading of large indices.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/54#issuecomment-204084502:86,load,load,86,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/54#issuecomment-204084502,3,['load'],"['load', 'loading']"
Performance,"HashResizeThreads to 7; [2020-05-05 09:19:06.171] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2020-05-05 09:19:06.171] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2020-05-05 09:19:06.171] [jointLog] [info] Usage of --validateMappings implies a default consensus slack of 0.2. Setting consensusSlack to 0.35.; [2020-05-05 09:19:06.171] [jointLog] [info] parsing read library format; [2020-05-05 09:19:06.171] [jointLog] [info] There is 1 library.; [2020-05-05 09:19:06.278] [jointLog] [info] Loading pufferfish index; [2020-05-05 09:19:06.278] [jointLog] [warning] The index did not record if the `--keepDuplicates` flag was used. Please consider re-indexing with a newer version of salmon that will propagate this information.; [2020-05-05 09:19:06.278] [jointLog] [info] Loading dense pufferfish index.; -----------------------------------------; | Loading contig table | Time = 30.609 s; -----------------------------------------; size = 36981178; -----------------------------------------; | Loading contig offsets | Time = 1.3312 s; -----------------------------------------; -----------------------------------------; | Loading reference lengths | Time = 5.6842 ms; -----------------------------------------; -----------------------------------------; | Loading mphf table | Time = 20.002 s; -----------------------------------------; size = 3784352032; Number of ones: 36981177; Number of ones per inventory item: 512; Inventory entries filled: 72229; -----------------------------------------; | Loading contig boundaries | Time = 11.467 s; -----------------------------------------; size = 3784352032; -----------------------------------------; | Loading sequence | Time = 9.5665 s; -----------------------------------------; size = 2674916722; -----------------------------------------; | Loading positions | Time = 4.3912 ms; -------",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/518#issuecomment-623910021:1788,Load,Loading,1788,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/518#issuecomment-623910021,1,['Load'],['Loading']
Performance,"Hey Avi, thanks for the quick reply!; Here is the salmon_quant_log file:; ```; [2019-07-09 09:07:39.153] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2019-07-09 09:07:39.153] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2019-07-09 09:07:39.153] [jointLog] [info] Usage of --validateMappings implies use of range factorization. rangeFactorizationBins is being set to 4; [2019-07-09 09:07:39.153] [jointLog] [info] Usage of --validateMappings implies a default consensus slack of 1. Setting consensusSlack to 1.; [2019-07-09 09:07:39.153] [jointLog] [info] Using default value of 0.8 for minScoreFraction in Alevin; [2019-07-09 09:17:08.128] [jointLog] [info] There is 1 library.; [2019-07-09 09:17:08.180] [jointLog] [info] Loading Quasi index; [2019-07-09 09:17:08.180] [jointLog] [info] Loading 32-bit quasi index; [2019-07-09 09:17:14.970] [jointLog] [info] done; [2019-07-09 09:17:14.970] [jointLog] [info] Index contained 197,787 targets; [2019-07-09 10:02:20.484] [jointLog] [info] Computed 251,090 rich equivalence classes for further processing; [2019-07-09 10:02:20.484] [jointLog] [info] Counted 348,673,166 total reads in the equivalence classes ; [2019-07-09 10:02:20.485] [jointLog] [warning] Found 1893 reads with `N` in the UMI sequence and ignored the reads.; Please report on github if this number is too large; [2019-07-09 10:02:20.485] [jointLog] [info] Mapping rate = 39.7151%. [2019-07-09 10:02:20.485] [jointLog] [info] finished quantifyLibrary(); ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/396#issuecomment-510544611:878,Load,Loading,878,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/396#issuecomment-510544611,2,['Load'],['Loading']
Performance,"Hey Avi,. I have ran alevin with addition of `--expectCells 8000` flag, the new output of cells detected: ; `3655, 5604, 4374` w/ `13%, 30%, 15.7%` reads thrown away. It is better than the first trial `1192, 4947, 3414` but nevertheless fewer than the cell ranger output `5150, 7618, 6404`. . Wonder ; 1. if I should set higher `--expectCells`, but which would result in more unconfident calls?; 2. From 1, if I just try to get more cells subjectively, will the expression matrix (and further analysis) be inaccurate/affected? (given downstream filtering of cells of low quality based on # of feature detected etc. would be performed anyway. ) ; 3. what could be the reason that these two algorithms output such different total cell numbers (precision in calling?) . Thanks!; Chelsea",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/396#issuecomment-510603746:624,perform,performed,624,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/396#issuecomment-510603746,1,['perform'],['performed']
Performance,"Hey Rob,. I did manage to test v1.3 this evening. Ran much faster. The same sample that took about 6 hours ran in 45mins. Still not great, but I think it might be intrinsic to some of these samples, also I was running it off my laptop and was running Linux off a; flash drive so not an ideal setup. Either way much more reasonable. Do you want me to attach any logs or anything?. Best,. Ryan . Sent from my iPhone. On Jun 16, 2020, at 10:20 AM, Rob Patro <notifications@github.com> wrote:. ﻿. Hi ; @shalercr,; I agree that if each sample runs as quickly as you see here, it's not a big deal to just re-run them all. Note that, while my avoids ~116 times more (eventually-discarded) alignments than did yours, the difference in the number of discarded; fragments (i.e. fragments that had no mapping) is very small — ~7,000, or 0.023% of the fragments. Thus, despite the huge speed-up, I wouldn't expect many differences in the quantifications. However, I couldn't argue against re-quantifying everything; with the new version just for good measure :). When you have a chance, please do let me know if you see this same performance difference using the pre-compiled (linux) binary. here. Of course, once we finalize this release (soon), we will push to bioconda so we will also have OSX binaries available. However, I just want to make sure this fixes things on your end as well before the release.; —; You are receiving this because you were mentioned.; Reply to this email directly, ; view it on GitHub, or ; unsubscribe.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/537#issuecomment-645119801:1118,perform,performance,1118,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/537#issuecomment-645119801,1,['perform'],['performance']
Performance,"Hi @Acribbs ,. Thanks for your kind words.; Basically, modularity is very important part of the whole salmon framework. Alignment and quantification are two separate module and they are all interconnected, so the optimizations in one is automatically propagated to another. As a result, the optimizations of SA done in the alignment stage got propagated to both alevin (single-cell) and salmon (bulk) RNA-seq quantification. As a summary, from 0.14.0 onwards alevin can automatically utilize the benefits of SA if the reference is indexed following the scripts we shared in the SalmonTools repo. Hope it answers your question.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/370#issuecomment-503643808:213,optimiz,optimizations,213,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/370#issuecomment-503643808,2,['optimiz'],['optimizations']
Performance,"Hi @AndrewSkelton,. There is currently no easy way to keep the index in RAM as STAR/Bowtie2 do. This is a feature we've been interested in for a _long_ time, but it's a feature that is very hard to justify spending a PhD student's time on since it's not going to contribute directly to any paper. But, this is a feature we'd like to add and maybe we can swing it with some of the CZI round-3 funding we just got. Nonetheless, the capability currently doesn't exist. Salmon can take multiple fastq files as input, but then it assumes they all derive from the same library, so you get one ""aggregate"" quant.sf, which isn't what you want here. So, I think the only approach currently would be to schedule a number of small jobs. I get why this isn't ideal. One small saving grace is that recent versions of salmon (>= 1.0.0) adopt the pufferfish index which is _much_ smaller than the previous RapMap index. Thus, the index loading time is quite small for a typical transcriptome. Also, this often allows operating system cache to keep the index around, even if it's not explicitly stored in shared memory. Thanks for both of the suggestions, and I'll be sure to keep you in the loop if we acquire either of the capabilities you mention above!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/589#issuecomment-733215735:921,load,loading,921,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/589#issuecomment-733215735,2,"['cache', 'load']","['cache', 'loading']"
Performance,"Hi @AngryMaciek,. You can get either Gibbs samples from the posterior, or bootstrap estimates. To get the former, you pass `--numGibbsSamples <nsamp>` to salmon, and to get the latter, you pass `--numBootstraps <nsamp>`. Either way, samples will be written to a binary, gzipped file in `aux_dir/bootstrap/ bootstraps.gz` (we decided to keep a uniform file name regardless of the sampling type, however the type of sampling performed can be derived from `aux_dir/meta_info.json`). Two things to point out here. First, the binary file format can be converted to TSV if you prefer using [this script](https://github.com/COMBINE-lab/salmon/blob/master/scripts/ConvertBootstrapsToTSV.py). Second, these are samples over the number of reads assigned to the transcripts (not the TPMs directly). However, you could easily convert samples over the number of reads to samples over the TPMs by applying the TPM formula (i.e. TPM_i = 10^6 * (num_reads_i / effective_length_i) / (sum_j (num_reads_j / effective_length_j))).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/246#issuecomment-401834462:423,perform,performed,423,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/246#issuecomment-401834462,1,['perform'],['performed']
Performance,"Hi @BenLangmead!. Thanks for the formal feature request. This is, indeed, a great idea, and something I've been interested in for quite a while. As far as I can tell, the main impediment to this is the hash table (https://github.com/greg7mdp/sparsepp) used in the index. The suffix array used by the mapping algorithm (by virtue of simply being a flat array of either 32 or 64-bit integers) is trivial to load via shared memory, as is the flat representation of the concatenated text itself. The bitvector and rank data structure that separate individual transcript sequences might be a bit trickier, but is also small enough to exist per-process. However, it's unclear to me if there is an easy or straightforward way to have the hash table reside in shared memory, and this is usually the single largest element of the index. As I mentioned, this is a feature that I've thought would be very useful for quite a while, and I'm interested in seeing it implemented. If you have any suggestions on what might be the best approach, I'm all 👂s.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/335#issuecomment-455905666:405,load,load,405,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/335#issuecomment-455905666,1,['load'],['load']
Performance,"Hi @BenjaminDEMAILLE,. I think brew is a bit behind bioconda on this front, and, indeed, the M1 being a completely new architecture complicates things. I have an M1 Max and so there are plans to get a native compile going soon. For the time being, the recommended way to get `salmon` on an M1 (or M2) Mac is as suggested [here](https://github.com/COMBINE-lab/salmon/issues/724#issuecomment-1137183671). Basically, you create an x86 conda environment (running under rosetta2) and install the latest version of salmon there. Rosetta2 is pretty amazing, and everything seems to run without a hitch, with nary a performance hit for the x86 -> ARM translation. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/787#issuecomment-1170723368:608,perform,performance,608,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/787#issuecomment-1170723368,1,['perform'],['performance']
Performance,"Hi @FlorianRNA ! As stated in the [usage docs](https://nf-co.re/rnaseq/3.8.1/usage#quantification-options) for the nf-core/rnaseq pipeline:. ""Since v3.0 of the pipeline, featureCounts is no longer used to perform gene/transcript quantification, however it is still used to generate QC metrics based on [biotype](http://www.ensembl.org/info/genome/genebuild/biotypes.html) information available within GFF/GTF genome annotation files. This decision was made primarily because of the limitations of featureCounts to appropriately quantify gene expression data. Please see [Zhao et al., 2015](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0141910#pone-0141910-t001) and [Soneson et al., 2015](https://f1000research.com/articles/4-1521/v1)."". This is a common cause of confusion and I have tried to be as explicit about this in the docs. featureCounts is used to quantify features in the annotation by `gene_biotype` and not the actual gene / transcript features themselves. This may explain why you are seeing these discrepancies. However, I am still a little puzzled how you are able to directly compare the counts generated by featureCounts and Salmon (in either mode) because the core features that are being quantified should be different. Where did you get the plant reference genome from? If it's not from Ensembl then it probably isn't worth running the biotype quantification with featureCounts anyway because the GTF annotation files may not contain that information. There are some docs for this [here](https://nf-co.re/rnaseq/3.8.1/usage#prokaryotic-genome-annotations). Hope that helps and if you think we can improve the pipeline in any way please feel free to create an issue on the nf-core/rnaseq repo.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/798#issuecomment-1237865190:205,perform,perform,205,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/798#issuecomment-1237865190,1,['perform'],['perform']
Performance,"Hi @GWW ,. Ok, we figured out where the threads are coming from. Deep inside the concurrent hash map we are using, there is a [function that grows the hash map](https://github.com/COMBINE-lab/salmon/blob/master/include/cuckoohash_map.hh#L1558). This function uses a function called [`parallel_exec`](https://github.com/COMBINE-lab/salmon/blob/master/include/cuckoohash_map.hh#L1751) to move the items from the old table to the new one. Here, they greedily use as many threads as available for that process. We can't see this behavior on our end by monitoring top/htop, because the hash table doubling happens so fast it's below the monitoring resolution. There are a couple ways to address this, one of which is hacking inside the hashmap library to modify this behavior. However, it would be nice if there was a way to do this without modifying the code (e.g. by limiting the number of threads the process was allowed to spawn concurrently from outside of the process itself). We are looking to see if this is doable using e.g. cgroups or some such.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-395890018:81,concurren,concurrent,81,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-395890018,2,['concurren'],"['concurrent', 'concurrently']"
Performance,"Hi @JSSaini,. The most common use case would be taxonomic abundance estimation in a DNA-seq library where the references are whole genomes of the potential taxa. The references indexed would be the gnomes (and / or contigs) of the potential organisms in the sample, and the output would be the estimated number of fragments arising from each contig / genome. If a given organism is split across multiple contigs, one would aggregate them post quantification in the same way one aggregates transcript abundance estimates to the gene level (i.e. the natural way to do this would be to create a contig to organism mapping and to load up the quantification results using tximport). Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/834#issuecomment-1450283495:626,load,load,626,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/834#issuecomment-1450283495,1,['load'],['load']
Performance,"Hi @Jensen416,. Thank you for reporting this. Certain versions of the GCC compiler are not capable of performing full program link time optimization (`lto`) for this codebase. This is a known issue — and there are other programs that exhibit this same behavior. This is something that GCC must fix upstream — an internal compiler error is something that really shouldn't happen. Luckily, the solution is simple; just don't use whole program inter procedural optimization. Try using this `cmake` invocation (after clearing out your build directory):. ```; cmake -DNO_IPO=TRUE -DFETCH_BOOST=TRUE -DTBB_INSTALL_DIR= ~/anaconda3/pkgs/tbb-2021.5.0-hd09550d_0/ -DCMAKE_INSTALL_PREFIX= ~/salmon/; ```. The `-DNO_IPO` tells `cmake` to invoke the compiler without inter procedural optimization (i.e. `lto`). Let me know if this works for you. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/778#issuecomment-1134776478:102,perform,performing,102,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/778#issuecomment-1134776478,4,"['optimiz', 'perform']","['optimization', 'performing']"
Performance,"Hi @Kisekya,. So BWA-MEM and BWA-MEM2 are somewhat of a problem to begin with because they perform local alignment, which isn't really ideal for aligning RNA-seq reads to the transcriptome. If you really wish to use an aligner, we've had good experiences with Bowtie2 (when used in the appropriate end-to-end alignment mode) and with STAR (using the alignments projected to the transcriptome with `--quantMode TranscriptomeSAM` flag to output the alignments in transcriptomic coordinates as required by salmon). Apart from the local alignment issue, sorting the BAM file is _absolutely_ a problem for salmon, and is likely why you get the strange library type. When run in alignment mode, just like RSEM, salmon requires the alignments for the the mates of a read pair to appear subsequently in the file, and for all alignments for a given read to appear contiguously in the file. This allows parsing the reads without having to require potentially unbounded memory (holding the record for one end of a fragment in memory while waiting for the record for the other end). In fact, given that you've sorted the alignments here, I'm surprised you're not getting the ""suspicious pair"" warnings in your logs. The ISR library with 40% mapping is likely a more reliable number. The obvious question here is why might the mapping rate be this low? There are a few reasons you might see something like this. One, for example, is poor ribosomal depletion, paired with not having all of the rRNA sequences in your index. In this case, you have many fewer reads coming from the rest of the transcriptome and you get depleted mapping rates like this. . Could you say a bit more about the experimental setup? Is this in a well-annotated organism like human / mouse etc.? Is this a polyA selection or ribosomal depletion prep? Anything else that might be relevant to sample quality?. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/676#issuecomment-873519594:91,perform,perform,91,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/676#issuecomment-873519594,1,['perform'],['perform']
Performance,"Hi @Lordlitong,. The name of a FASTA record is whatever appears up to the first white space character in its header line. This is why you get these long names in the index as a sequence name. If you pass the `—gencode` flag when building the salmon index, it will treat `|` as an additional separator, and your names will just be e.g. `ENST00000456328.2`. That is the easiest way to avoid this issue going forward. If you don’t want to rebuild the index and re-process the data (if you’ve already processed a ton of samples), then you would have to write some code to strip the sequence names before loading them.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/513#issuecomment-619584519:600,load,loading,600,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/513#issuecomment-619584519,1,['load'],['loading']
Performance,"Hi @Miserlou,. I'm not necessarily opposed to this. What exactly would the dry-run do? For example, would it simply check if the input files exist, try to load the index, etc.? This seems like it could be useful functionality, though, in my experience `--dry-run` commands usually aren't effectful (i.e. they usually don't create directories or output files). --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/189#issuecomment-362155044:155,load,load,155,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/189#issuecomment-362155044,1,['load'],['load']
Performance,"Hi @Miserlou,. It looks like the index was not written completely / successfully. Do you have a (binary) copy of the index being loaded? . --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/321#issuecomment-442529011:129,load,loaded,129,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/321#issuecomment-442529011,1,['load'],['loaded']
Performance,"Hi @Munfred ,. Apologies for the delayed response.; Thanks for your very important question. We are aware of the problem and are extensively working on improving the downstream processing of the alevin output. Unfortunately, in current form there is no other direct way of loading alevin output matrix. We are thinking of alternative options like using `loompy` but it's a work in progress. We will definitely inform here once we have a simpler working version.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/354#issuecomment-490091075:273,load,loading,273,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/354#issuecomment-490091075,1,['load'],['loading']
Performance,"Hi @PlantDr430,. Thanks for the context! As always, we'd be interested in learning anything interesting you find about the general behavior of salmon in different contexts and with different parameter settings etc. Out of curiosity, when you mention that genes perform ""better"" with one or another `--scoreExp`, is it the case that this is data where you have some sort of ground truth expectation for the abundance of the primary vs. spliced forms? If so, super interesting!. One other thought I had about this. While it is true, as I mentioned in my original post, that the conditioning on the transcripts is _fundamental_ in the case of salmon and other transcript expression tools that don't, themselves, try to assemble new transcripts, it's not necessarily true that there is no evidence in the quantifications that something my be awry. Specifically, I noticed that you are using posterior confidence estimation (bootstrapping). We actually have a [recent paper](https://www.biorxiv.org/content/10.1101/2020.04.07.029967v1.full) that discusses how to use the uncertainty estimates from salmon (though we rely on the Gibbs sampler rather than bootstrapping) to group together transcripts whose abundances cannot be individually estimated with confidence (with evidenced provided by the posterior samples). It might be useful to identify such cases in your analysis. Let me know if there's any other way I can help!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/523#issuecomment-633091638:261,perform,perform,261,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/523#issuecomment-633091638,1,['perform'],['perform']
Performance,"Hi @RoebideBruijn,. If you've already run `cmake ..`, you must `rm CMakeCache.txt` and `rm -fr CMakeFiles` before running `cmake -DFETCH_BOOST=TRUE`. This is because CMake will cache variables between runs, and it won't properly interpret the flag to fetch boost. Also, can you show the entire sequence of steps you're executing to build? It looks like the camke file can't be found. Are you running cmake from within a build directory, or are you running it from the top-level directory?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/139#issuecomment-449035144:177,cache,cache,177,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/139#issuecomment-449035144,1,['cache'],['cache']
Performance,"Hi @SSaleem94,. As the message suggests, your command is missing the required `--output` argument. Of course, it seems your command includes `-o`. The rest of the errors suggest that the command line is not being properly parsed. It looks like the part after the first line break is not being interpreted as a continuation of the same line. I think this is because the line extension character in the shell is not `/`, but is `\`. Maybe try the following:; ; ```; F=$(cat file_names.txt); for i in ${F}; do; F1=../processed_fastq/${i}_R1_001_val_1.fastq.gz; F2=../processed_fastq/${i}_R2_001_val_2.fastq.gz; echo ""performing salmon quant on ${i}""; salmon quant -i gencode_v43_index -l A -1 ${F1} -2 ${F2} -p 64 \; --validateMappings --writeUnmappedNames -o ${i}; echo ""finish quantifying ${i}""; done; ```. **Also**, as is suggested by the `salmon` message itself, you may want to consider upgrading to the latest version of `salmon`. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/854#issuecomment-1599169394:614,perform,performing,614,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/854#issuecomment-1599169394,1,['perform'],['performing']
Performance,"Hi @alexg9010,. Thanks for the info. I grabbed this transcriptome and indexed it, and then I grabbed the gtf file and executed this `quant` command with the same parameters (except, of course, for the read set). Unfortunately, I was unable to trigger the same behavior. On my machine (Ubuntu 16.10 x86-64) the index loaded successfully and quantification completed. Can you provide some more details about the system on which you are running? Would you be able to share the actual index file that you created? In relation to [issue 209](https://github.com/COMBINE-lab/salmon/issues/209), is the index being used on the same machine where it was created (from what you've posted, however, I believe it is)?. Thanks,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/210#issuecomment-376380132:316,load,loaded,316,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/210#issuecomment-376380132,1,['load'],['loaded']
Performance,"Hi @alexvpickering ,. Thanks for raising the issue. It seems #377 and #379 are connected .; Alevin is in fact suppose to output whitelist.txt file when provided with the flags you provided.; I think what's happening in your case is since `--keepCBFraction 1`, alevin is using all the CB for quantification and it couldn't find (any or very low) CB from the low confidence region needed for the whitelisting. ; Basically in the above screenshot, alevin never finished. It should have failed more gracefully, I'll make sure of that in the next release. In the meantime you can use the exit code 0 or ""Finished Optimizer"" log for successful finish. Also, try playing with the lower values for the `keepCBFracion` may be around (0.4 / 0.5) and `--freqThreshold` for changing the minimum frequency of a CB to consider, currently set to 10. You can also follow https://github.com/COMBINE-lab/salmon/issues/362 for more details.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/379#issuecomment-502818453:608,Optimiz,Optimizer,608,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/379#issuecomment-502818453,1,['Optimiz'],['Optimizer']
Performance,"Hi @amaer,. The warning suggests that the gff parser cannot even find a transcript with the given name (in the example you provided `ENST00000619185.1`). Does such a transcript exist? Can you grep for it. The string must match exactly (version number and all). The gff-based parser to do the transcript to gene mapping is quite picky, as gff & gtf files are often quite ill-formed. My top suggestion would be to do transcript -> gene abundance aggregation using [tximport](https://bioconductor.org/packages/release/bioc/html/tximport.html). The other option is to provide Salmon with a TSV mapping the transcripts to genes, as this eliminates all of the parsing problems (at the cost of pawning them off on the user, who must parse the questionable gtf file). However, tximport is the recommended strategy, since it can perform average gene length normalization across multiple samples (rather than just per-sample), which is useful for downstream DE.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/198#issuecomment-365950366:820,perform,perform,820,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/198#issuecomment-365950366,1,['perform'],['perform']
Performance,"Hi @annajbott ,. Thanks for your question.; It's an expected behavior. The idea is to dump some low confidence CB as well for certain kind of downstream processing. You'd see a file `whitelist.txt` as well in the output alevin folder which should contain whitelisted CB names (4340 in your case). You might have to filter those matrix out after loading the full matrix to get cells only passes the whitelisting filter. Please checkout [tximport](https://github.com/mikelove/tximport) to import the matrix in R, it's very efficient to load. In case you need some stats regarding the resource usage check [EDS](https://github.com/COMBINE-lab/EDS).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/428#issuecomment-530430735:345,load,loading,345,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/428#issuecomment-530430735,2,['load'],"['load', 'loading']"
Performance,"Hi @apredeus,. In short, what you explain in the first paragraph is right and is the expected behavior. However, to simplify the parsing algorithm (i.e. to ensure that BAM input can be parsed in bounded memory), both `salmon` and `RSEM` require that all of the alignments for a given read are adjacent within the input BAM file. If this is violated, they will be treated as different reads. In other words, if you have something like:. ```; read1:aln1; read1:aln2; read1:aln3; read2:aln1; read2:aln2; read2:aln3; ```. then in total, 2 ""reads"" worth of mass will be assigned (probabilistically across the targets). However, if you have. ```; read1:aln1; read1:aln2; read2:aln1; read1:aln3; read2:aln2; read2:aln3; ```. Then there will be *4* total reads assigned. Each time the query name (read name modulo 1/2 of a paired-end read) changes in the BAM stream, it is assumed to be a new read, and its alignments are dealt with separately. Both Bowtie2 and STAR (when projecting genomic alignments to the transcriptome) will follow this convention by default, but I'm not certain the same is true for other aligners. Again, this restriction is present in both `RSEM` and `salmon`, and it's an optimization that is made because otherwise there can be unbounded distance in the worst case between the different alignments for a read and so the parser would either have to hold all alignments in memory (which is very bad), or make many passes over the input BAM (which is also very bad) to perform quantification. Let me know if you think this may be the issue in your case. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/844#issuecomment-1518485720:1190,optimiz,optimization,1190,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/844#issuecomment-1518485720,2,"['optimiz', 'perform']","['optimization', 'perform']"
Performance,"Hi @cfischer1991,. Thanks for the report. There have certainly been _a lot_ of improvements and changes to salmon between v0.8.1 and v1.3.0. The built-in mapping functionality has been largely overhauled. However, I can see that you're not using that here (you're quantifying from alignments). There have been a number of improvements in the alignment-based codepath as well. However, I'd guess that one of the biggest differences in the results you're seeing is due to a changes in the variational Bayes prior that happened between these versions. Specifically, the prior was adjusted to be smaller, and the default was changed from a `per-nucleotide` prior to a `per-transcript` prior. You can try and achieve the newer functionality in 0.8.1 by setting `--perTranscriptPrior` and `--vbPrior 0.01` and seeing, under those settings, how differently things look between 0.8.1 and 1.3.0. *Also*, another important change is in the handling of _incompatible_ alignments — alignments that do not match the prescribed library type. The incompatibility prior used to be set to a small but non-zero value by default `9.9999999999999995e-21`, but has since been changed to `0` by default. Both of these changes in the default have been results of a lot of internal testing suggesting these settings improve quantification results _in general_ (of course, given the complexity in of the quantification problem, there is likely no universal set of parameters that are optimal with respect to every experiment). I'd suggest trying to set these parameters to be the same between versions and to see how much of the variance is controlled by these changes in default values. Then you can determine which settings you believe make more sense in your context, with the understanding that the newer settings have been chosen, in general, to optimize quantification accuracy. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/562#issuecomment-674855490:1826,optimiz,optimize,1826,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/562#issuecomment-674855490,1,['optimiz'],['optimize']
Performance,"Hi @charlesfoster,. Thanks for opening the issue. The second run looks like it ends before there is any information about mapped reads. Have mappings started to be reported at that point? I wonder if there is some issue related to the loading of the index. I have a few suggestions that may be worthwhile to try:. 1) Do you observe the same problem if you index only the transcriptome (i.e. if you don't also include the genome as a decoy)?. 2) If you are using nfcore/rnaseq you can also consider using the STAR => salmon path. Of course, I'm interested in addressing whatever the underlying issue here is anyway, but it's worth noting that this may be a viable alternative to allow you to process all of these samples using the nfcore pipeline in the meantime. This will align the reads to the genome using STAR (which gives the benefit of having a full decoy), project them to the transcriptome, and then quantify them. Also, if you can share a set of problematic reads (or even a subset of them that will reproduce the extreme slowness problem) privately, that would be very helpful in debugging. In addition to trying to debug what's going on here, I'd probably also try running them through [piscem](https://github.com/COMBINE-lab/piscem). While this isn't yet an actual substitute for salmon, it will help isolate if the problem is directly related to the index or something else. Thanks!; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/830#issuecomment-1441139338:235,load,loading,235,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/830#issuecomment-1441139338,1,['load'],['loading']
Performance,"Hi @cljacobs,. Thank you again for the detailed info! Just to verify, what you are indexing here is the transcriptome ([this](ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_mouse/release_M24/gencode.vM24.transcripts.fa.gz) file), using the genome ([this](ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_mouse/release_M24/GRCm38.primary_assembly.genome.fa.gz) file) as decoy? Both the memory requirement and _definitely_ the time requirement are something that I've not been able to reproduce. I wonder if you could say something about the disk where the index is being written and where the program is being run. If this is all being done on NFS partitions, would it be possible to write the index to a local scratch on the node to see if disk access times have anything to do with the performance? I am scratching my head a bit about the memory though, because I don't have a good explanation for the discrepancy on those numbers.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/476#issuecomment-590565684:791,perform,performance,791,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/476#issuecomment-590565684,1,['perform'],['performance']
Performance,"Hi @cljacobs,. There was at least one unnecessarily large allocation within our pufferfish code, and now Ilia has also massively optimized the intermediate disk space usage behavior of TwoPaCo. An updated binary that incorporates these changes can be obtained [here](https://drive.google.com/open?id=1QHYCT3Vs9bRD7UmJY6JJKjlzmmUE4wRl). If you have a chance, it would be fantastic if you could test this out and see how the resource requirements change for you.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/476#issuecomment-587082126:129,optimiz,optimized,129,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/476#issuecomment-587082126,1,['optimiz'],['optimized']
Performance,"Hi @come-raczy,. Thanks for reporting this, it is addressed now in commit efe26b1ca2ced305256357e3b2e95f0e51e3376d. While the function that returns this value is called in two places `normalizeAlphas()` and `writeAbundances()`, the latter of these is actually deprecated and so is not used (we should clean up that code). So, while this value should clearly be initialized, the only potential effect here is through `normalizeAlphas()`, is called before the optimization, and which modifies the alphas that will be used for setting the _initial conditions_ of the VBEM. Therefore, the effect is likely to be limited since, even if the value of `totalCount_` was incorrectly initialized, it should only affect the initialization condition of the optimization. Thank you again for the detailed bug report, and the patch! This is now fixed in develop and will be in the next release.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/355#issuecomment-480004146:458,optimiz,optimization,458,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/355#issuecomment-480004146,2,['optimiz'],['optimization']
Performance,"Hi @dritoshi ,. Thanks for your request. I'd be happy to add the support for Quartz-seq2 into alevin but it'd be great if you can answer a few questions for us. Is it possible to share some reads/fastq file on which we can test alevin ? Also, please excuse my ignorance, what type of PCR amplification is performed in `Quartz-seq2` protocol, is it CelSeq type IVT (linear) amplification or Drop-Seq type template switching PCR amplification ?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/416#issuecomment-521747003:305,perform,performed,305,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/416#issuecomment-521747003,1,['perform'],['performed']
Performance,"Hi @ebecht ,. Thanks for raising the issue. In the latest release we have significantly modified alevin to perform online feature creation and whitelisting. We hope that this might fix the memory related issue which you were observing on the clusters. Do let us know how it worked out for you. PS: Nice work on your recent [preprint](https://www.biorxiv.org/content/10.1101/648733v1), it raises very important questions. On the similar note, we also released a preprint today, can be found [here](https://www.biorxiv.org/content/10.1101/657874v1). Do let us know your thoughts !",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/328#issuecomment-498322884:107,perform,perform,107,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/328#issuecomment-498322884,1,['perform'],['perform']
Performance,"Hi @farshadf,. What exactly is the difference here (i.e. where are those reads going in salmon)? STAR doesn't perform stranded alignment. You can trying using the `-l U` library flag for salmon to see if it's a strandedness issue. In general, I'd always recommend using the latest version of salmon, which currently is 1.8.0 (though I doubt there would be a difference related to handling of stranded reads here). Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/218#issuecomment-1145469445:110,perform,perform,110,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/218#issuecomment-1145469445,1,['perform'],['perform']
Performance,"Hi @gamabunta313,. When you say `mapping-mode`, do you mean that you are passing a SAM file _into_ salmon rather than passing the FASTQ file and letting it perform the mapping itself? Because salmon makes use of a statistical inference procedure to determine the ultimate allocations of reads to transcripts, you cannot just count up the reads ""mapped"" to a transcript to obtain the count you see in the `quant.sf` file. Rather, when you see a read mapped to a transcript in the SAM/BAM file, you should interpret this as the read _could_ be assigned (most likely proportionally) to the transcript. The `--writeMappings` option is primarily intended for the mode where `salmon` performs the mapping itself, rather than the mode where aligned reads are provided as input. What does your alignment pipeline look like upstream of salmon?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/799#issuecomment-1245687786:156,perform,perform,156,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/799#issuecomment-1245687786,2,['perform'],"['perform', 'performs']"
Performance,"Hi @izaakm,. This segfault is unlikely related to the issue here, since that happened in ""mapping mode"" (salmon performing mapping itself), and yours is happening in alignment-based mode (you're feeding SAM files to salmon). Does it fail to occur when you provide _either_ of the SAM files to salmon? That is, does it run to completion with both `data/processed/bwa-mem/SRR10571655.sam` and `data/processed/bwa-mem/SRR10571656.sam` individually? Also, what if you combine them via a pipe (i.e. something like):. ```; ./src/salmon-latest_linux_x86_64/bin/salmon quant --threads $(nproc) --libType U -t GRCh38_latest_rna.fa -a <(cat data/processed/bwa-mem/SRR10571655.sam <(samtools view data/processed/bwa-mem/SRR10571656.sam)) -o _tmp/ ; ```. the double redirect is just to make sure the header isn't included in the second sam file. Also, is the reference that you are passing to the `-t` option identical to the one with which bwa-mem was run? If the problem persists, we might need the sam/bam files to track it down further, since I imagine it may be data-dependent. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/271#issuecomment-707338358:112,perform,performing,112,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/271#issuecomment-707338358,1,['perform'],['performing']
Performance,"Hi @jashapiro,. So there are definitely a few things going on here. The first is that you correctly diagnosed the missing cmd_info.json information when `alevin` is run in RAD mode. That was simply an oversight, and there is no reason that file shouldn't have been written. Second, there is also useful information that belongs in `meta_info.json` in the `aux_info` directory (like the SHA hash of the reference sequences); that was also missing but has now been added.; ; In addition to salmon's `alevin` command, each step of `alevin-fry` also writes some useful metadata when it executes. For example, there is a json file written by the `generate-permit-list` step, one written by the `collate` step, and one written by the `quant` step. We've never run into the problem of the output of `alevin-fry` overwriting the output of `alevin` because we use a directory structure where the output quantifications reside in a separate directory from the input RAD file. However, I can now see that if you're writing the quants in the same place as the input, then there will be a conflict in the file names, and the existing files will be overwritten with the new ones. I agree that both tools output useful information. I'm a *bit* ambivalent about assuming the salmon-generated files exist, and merging them into one output file, as I think there might be cases where those files aren't present and `alevin-fry` should still run properly since it doesn't require them to perform it's processing. One option would be to rename the `alevin-fry` output files to prefix/postfix them so they don't collide with the salmon files even if they live in the same directory. Then, one could (now or later) write a small command to merge the relevant json files into a unified output if that would be more convenient downstream. Let me know your thoughts. Thanks!; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/688#issuecomment-883497669:1469,perform,perform,1469,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/688#issuecomment-883497669,1,['perform'],['perform']
Performance,"Hi @jblachly,. Thanks for pointing this out. The underlying parser we use should also support gff (&gff3), so I should probably just expand the extension set. I'll ping back here once the relevant changes have been made on the develop branch. I'll also note that, generally, we now recommend [tximport](https://bioconductor.org/packages/release/bioc/html/tximport.html) as the way to aggregate transcript-level abundance estimates to the gene level, since it provides some nice multi-sample functionality and also allows the user to choose from a few different ways in which the aggregation can be performed. If you're doing any of your downstream analysis in R, it's worth a look. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/114#issuecomment-272709627:598,perform,performed,598,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/114#issuecomment-272709627,1,['perform'],['performed']
Performance,"Hi @jeremymsimon,. I've discussed the support for SPLiT-seq/ParseBio with @Gaura in some depth. Honestly, I think the cleanest solution right now is just to have a more streamlined (and streaming) way to match / replace the random hexamers upstream of alevin-fry. By my understanding, if we can simply replace barcode 1 appropriately (as your Perl script currently does), everything should work downstream in alevin/alevin-fry.; ; To that end, I've thrown together a small rust program based on your Perl script. Currently that lives [here](https://github.com/COMBINE-lab/splitp). It reads the same basic parameters as the Perl script, and writes its output to stdout so that it can be used with named pipes. For example, something like:; ; ```; <normal salmon command> -1 read_file_1.fq -2 <(splitp --read-file read_file_2.fq --bc-map bcSharing_example.txt --start 79 --end 86 --one-hamming); ```. which will transform the second fastq file and stream the transformed reads out which can then be read by alevin-fry. One important thing to note is that while *alevin* requires the input reads to be a real file (i.e. you can't stream reads in because it does 2 passes), if you are mapping these reads for processing with *alevin-fry* you can use the process substitution trick above. As you hinted, this program works considerably faster than the Perl script. For example, for the first 10,000,000 reads in `SRR6750042`, the Perl script took 2m 48s to transform the reads and `splitp` took ~6s (if the output wasn't being written to a file on disk it took <4s). This should generally be fast enough to not be a speed bottleneck. So, perhaps the next step is to try to help you walk through this approach with a test dataset (and ideally using alevin-fry) to see if things are turning out as expected?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-961598108:1617,bottleneck,bottleneck,1617,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-961598108,1,['bottleneck'],['bottleneck']
Performance,"Hi @juugii ,; Thanks for the very important and interesting discussion.; You are right, for the calculation of sequence saturation one *might* not need the exact deduplicated UMI count **but** I had to bring that part into the discussion as it was mentioned that you wanted to compare different deduplication strategies. I think your suggestion makes sense and mostly aligns with the definition being used by 10x [here](https://kb.10xgenomics.com/hc/en-us/articles/115003646912-How-is-sequencing-saturation-calculated-). Although note they have changed the definition with the new version of the software. Anyhow, the *short answer* to the question of how can we generate that in Alevin environment is -- by post processing the dumpFeatures output of the Alevin run. _long answer_: The difference lies in the term deduplication and the strategy used to perform it. Basically the fundamental unit for deduplication in 10x as mentioned in the link above is a tuple of `(valid cell-barcode, valid UMI, gene) `, while that's not exactly true for us. We can certainly generate it but it does not aligns with the theory of Alevin's deduplication Algorithm. Having said that, I also like your idea of using:; > the gene quantifications from (de)duplicated UMIs, gene quantifications from unique UMIs, using them to have an idea of the amount/ratio of redundant information. However, the above definition reflect more of the duplication rate (at least in terms of the definition defined in *Alevin* manuscript [here](https://www.biorxiv.org/content/early/2018/06/01/335000)) than sequence saturation. **NOTE** the quoted definition was actually the 10x definition of sequence saturation too before it was changed, at least in my understanding. If you need the deduplication rate of each cell you can get that by using `--dumpFeature` flag in the Alevin run and look for file `featureDump.txt`. There will be a dump of multiple features w/ each CB but the second (starting from 0) column of the file gives you ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/267#issuecomment-414784626:853,perform,perform,853,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/267#issuecomment-414784626,1,['perform'],['perform']
Performance,"Hi @k3yavi ,; Thanks for the info!. We are working on an optimized version of SCRBseq and one of the problems we had with the original protocol is the minimum distance between the cell barcodes being too low. So we increased the number of bases. The original protocol was 6 bc and 10 umi. We just switched the 7 position from umi to barcode. We use a known whitelist of barcodes since it's a well plate based protocol. We know that any other barcode are not cells. Is there an option for max distance allowed between BC or UMI?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/247#issuecomment-402440401:57,optimiz,optimized,57,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/247#issuecomment-402440401,1,['optimiz'],['optimized']
Performance,"Hi @k3yavi,; Many thanks for you prompt answer, once again. >When you say you try subsampling the Fastq, did you sample randomly across the full Fastq or chose the top X reads. Yes, I did perform a random subsampling, ie. taking a read with a p probability while reading the fastq files, p being the subsampling coefficient I did mention (pE[0;1]). An implementation of this approach as an option during the transcript quantification would be great. I can provide you with the simple python script I use for the subsampling, but I am not sure if it is the proper way to subsample during alevin quantification. >when you say cellranger subsampling, do you mean the cellranger aggregate pipeline?. Yes, sorry for not clearly stating it. I did use the cellranger aggregate function indeed, which by default subsample the expression matrices with high sequencing depth depending on amount of mapped reads, if I understand well. >Use Alevin w/o any modification to the fastq on both of your sample to generate the gene count matrices. I already did that, in downstream analyses I have a batch effect issue related to the sequencing depth. >that's why we recommend using the Seurat package downstream of the Alevin quantified matrices. I have some experience with downstream analyses with Seurat, Pagoda, Scater, scanpy and a few other tools, and I am aware of batch correction methods like CCA or MNN. But that is not what I am looking for here. I did both CCA and MNN but I loose some important information in the resulting eigenspaces or corrected matrix. I believe the proper way to correct my batch effect is to simply fix the difference between my two libraries, ie. the sequencing depth in this case. As I explained in my first message, cellranger aggregate (subsampling based on the amount of mapped reads) works very well in my case, correct the effect without any loss or modification of important genes in our scientific question. Not CCA or MNN. I would like to be able to do the same from the a",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/305#issuecomment-433319913:188,perform,perform,188,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/305#issuecomment-433319913,1,['perform'],['perform']
Performance,"Hi @kai2june,. Thank you for the _detailed_ report! It's interesting because (a) those functions aren't doing anything too exotic and (b) CentOS is the OS we use on our continuous integration. We'll try and get a better handle of what is going on here. In the mean time, could you tell us if you see the same behavior with the [pre-compiled binary](https://github.com/COMBINE-lab/salmon/releases/download/v1.4.0/salmon-1.4.0_linux_x86_64.tar.gz) available from the downloads page?. P.S. One other thing worth trying. We've noticed that compiler support for interprocedural optimization isn't terrific. You can try building salmon without this option by passing `-DNO_IPO=TRUE` as an additional cmake flag.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/609#issuecomment-751366046:573,optimiz,optimization,573,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/609#issuecomment-751366046,1,['optimiz'],['optimization']
Performance,"Hi @kaukrise ,. Thanks for the very interesting question. I don't think there is any theoretical limit wrt the alevin's method, however, it would be interesting to check how does alevin performs when we increase the CB length wrt the running time. The 20 length bound was just for sanity checking and can be increased, like you already did.; I'd be very interested, if possible, in hearing back about your experience with alevin using longer length CB both wrt running time and gene expression estimates generated. Also if I may ask what's the reason behind using this long CB ? Are you expecting tons of real cells, if there is we can think about improving alevin even more, in my experience, we have generally seen individual 10x experiment with ~20k cells max. Even the 1.3M dataset is 164 separate experiments.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/445#issuecomment-550391177:186,perform,performs,186,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/445#issuecomment-550391177,1,['perform'],['performs']
Performance,"Hi @kvittingseerup,. No need to apologize, I think it was I who was not clear. What I am saying is that this is *already* the way that Salmon handles such a case. That is, if you have a paired-end read, and one of the reads maps but the other doesn't (due to e.g., adapter contamination or just very low quality), then Salmon will consider the remaining (mapping) end of the read as representative of an entire fragment, and will resolve the fragment origin accordingly during optimization. Generally, not having both ends of a paired-end read leads to increased ambiguity, but this isn't a particularly big problem if it only happens to a generally small fraction of the reads. Further, since you cannot reliably infer the implied fragment length on a transcript from only a single-end read, such mappings will not contribute to the bias model. Again, however, as long as this doesn't happen to the vast majority of fragments, it should have only a negligible effect on quantification and bias correction. Please let me know if this description makes sense. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/150#issuecomment-355881997:477,optimiz,optimization,477,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/150#issuecomment-355881997,1,['optimiz'],['optimization']
Performance,"Hi @litongda007,. Thanks for providing the data; it's very useful. I will continue to poke here a bit, but in a first pass, I loaded up all of the bootstrap samples and did `frame.isna().sum().sum()` for all 8 samples and got 0 on each. So, at least loading the bootstraps this ways, I can't see any NaNs.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/529#issuecomment-638254418:126,load,loaded,126,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/529#issuecomment-638254418,2,['load'],"['loaded', 'loading']"
Performance,"Hi @lubios,. This suggests that the machine was not able to allocate enough memory to perform the requested operation. I would try the following things in order to see if they fix the issue. First, try quantifying without the decoy-aware index. This doesn't provide the benefits of the decoy sequence, but it will ensure that this is, in fact, the problem you are having. If that works, try building the decoy-aware index with the `--sparse` parameter. This will build the sparse index instead of the dense index, which is a bit smaller and may therefore fit in RAM on the machine where you are doing quantification. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/717#issuecomment-962058307:86,perform,perform,86,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/717#issuecomment-962058307,1,['perform'],['perform']
Performance,"Hi @mathog,. > Is it really the case that Salmon cannot use 1.57.0?. It may be able to. We set the minimum required version to the lowest boost version we use in any of our testing machines where we run regression tests. Currently, this is 1.59.0. If you change the relevant `CMakeLists.txt` line, you *really* need to make sure you clear out the CMake cache. You can do this by removing `CMakeCache.txt` in your build directory, as well as the directory `CMakeFiles`. However, it might be easiest just to remove and remake the entire `build` directory. You may also try passing `-DBoost_NO_SYSTEM_PATHS=Bool:ON` to your cmake command. Finally, note that the build system is probably looking for the static libraries --- you can elide that preference by modifying [this line](https://github.com/COMBINE-lab/salmon/blob/master/CMakeLists.txt#L222). Finally, since salmon uses C++11, it's important that whatever boost you link against exposes a C++11 compatible ABI. Unfortunately, `FindBoost.cmake` is the most finicky of the module finding packages I know about 😦. If you use `-DFETCH_BOOST=TRUE`, then CMake will fetch a recent boost and build the libraries it needs and link them statically. I realize you want to avoid this, so hopefully one of the ideas above will help.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/236#issuecomment-396781869:353,cache,cache,353,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/236#issuecomment-396781869,1,['cache'],['cache']
Performance,"Hi @mishaprochazka and @jdidion,. Thanks @jdidion for pinging me on this. Somehow, Gmail has decided that all GitHub notifications (except those that explicitly tag me, but somehow I missed this one) should go to SPAM. So, I've been missing some of the newer issues here. The short answer is that the documentation needs to be updated. When salmon was originally published, we made use of [RapMap](https://github.com/COMBINE-lab/RapMap) as the underlying mapper, which performed quasi-mapping against an index that consisted of a suffix array and a hash over k-mers pointing to prefixes in the suffix array (similar to the strategy used by STAR, but using much longer k-mers to improve lookup speed). We referred to this index as the quasi-index. As the software evolved and we continued to improve the mapping methodology, we eventually transitioned over to an index based on [our pufferfish data structure](https://github.com/COMBINE-lab/pufferfish). In addition to the new data structure, this coincided with our move over to selective-alignment as the mapping algorithm, and all of this happened at the 1.0.0 release (this is why, for example, indices built before 1.0.0 are not compatible with salmon > 1.0.0; a topic on which there have been a few GitHub issues). However, given the fact that the documentation and software are linked only through manual human intervention (we haven't leveled up to e.g. having salmon be a [literate program](https://en.wikipedia.org/wiki/Literate_programming) yet), these two sometimes get out of sync. This is an instance of that. We have maintained the functionality of the `--writeMappings` feature, and in fact, even augmented it. However, we have not replaced the antiquated `quasi-index` terminology in the documentation. The TLDR is that you can use `--writeMappings` with the index you built with the `salmon index` command, and it should work fine. If you are mapping against an index without decoy sequences, then the output format will be basically ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/727#issuecomment-996192524:469,perform,performed,469,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/727#issuecomment-996192524,1,['perform'],['performed']
Performance,"Hi @mugpeng,. This is because it is covered by the custom geometry specification (as laid out in the docs). I agree it's nice to have a specific flag for each geometry, rather than to have to e.g. specify the custom geometry each time. We are working on good solutions to that at a higher level (e.g. in our `simpleaf` tool where users can register their own custom geometry specifications and refer to them by name). However, in `salmon`/`alevin` right now, the named geometries are hard-coded, and so to have a specific `--indropV2` flag, that would have to be added to the argument parser and then mapped to the specific underlying geometry in the code. This isn't hard, but as the number of different chemistries proliferates, it's not ultimately a scalable solution. So, the current recommendation would be to use the custom geometry flags as specified in the documentation, or adopt a wrapper like `simpleaf` and add `indropV2` to your custom geometry specification library. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/878#issuecomment-1758171139:753,scalab,scalable,753,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/878#issuecomment-1758171139,1,['scalab'],['scalable']
Performance,"Hi @nh13,. This is not something for which we currently have support or something that we currently plan. I'd be open to it, but I'm honestly not sure how to cleanly do it in the current architecture, and doing so would certainly incur a performance hit. Salmon runs 2 phases of inference; and online phase and an offline phase. The online phase has access to _fragment-level_ information that is then summarized away during the offline phase (like the specific locations of each read, the length of each observed fragment, etc.). That information goes away when the reads are summarized into range-factorized equivalence classes. Moreover, some of the model parameters learned during the online phase will depend (in their details) on the order in which observations are made. Ostensibly, observing the same data in the same order **and issuing updates to shared model parameters from worker threads in the same order** should result in identical values, however this has never been tested and was never a design goal. The reason for this is that differences between runs are within the bounds of the inherent inferential uncertainty of the estimated parameters anyway. That is, if one is relying on a specific value at a level of precision such that a different run of salmon would produce a value different enough to change a downstream analysis, then one is imparting more precision on the estimates than they can provide. Other methods that produce identical results between runs for these values may produce the same output, but the accuracy of the output at that level shouldn't be trusted in this case. The uncertainty of the parameter estimates can be evaluated based on the Gibb samples (or bootstrap replicates) that salmon computes. Of course, the small differences between runs rarely lead to differences in downstream analysis (almost certainly at the gene level and also at the transcript level if you use a differential testing method that is aware of inferential uncertainty). On the ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/102#issuecomment-2159300538:238,perform,performance,238,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/102#issuecomment-2159300538,1,['perform'],['performance']
Performance,"Hi @pdellorusso,. This is because the `--gencode` flag is only relevant during indexing. That is, you should pass the `--gencode` flag to Salmon when building the index, but not when subsequently performing quantification.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/200#issuecomment-368350374:196,perform,performing,196,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/200#issuecomment-368350374,1,['perform'],['performing']
Performance,"Hi @pinin4fjords ,. We have release a new version `v0.14.0`. In the latest version we have added different error codes based on what stage the pipeline fails. The error codes are as follows:. ```; 1: Error while mapping reads and/or generic errors.; 64: Error in knee estimation / Cellular Barcode sequence correction.; 74: Error while deduplicating UMI and/or EM optimization.; 84: Error while intelligent whitelisting.; ```. As we have discussed earlier, you can control the expected behavior by tweaking the following two flags.; ```; --keepCBfraction: A value in (0, 1] i..e what fraction of CB to keep for quantification.; --freqThreshold: default 10, Minimum frequency required to quantify the CB.; ```. Just a heads up, alevin with the current release will by default dump the `dumpFeatures.txt` which contains the per CB level features. Please check the release notes for more details. Closing this issue for now, but feel free to reopen if you face any issue or have question.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/362#issuecomment-498040072:364,optimiz,optimization,364,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/362#issuecomment-498040072,1,['optimiz'],['optimization']
Performance,"Hi @ramezrawas,. Can you say precisely what you mean by reproducible? Do you mean that the values in the .sf file are not identical? If so, this is expected behavior. It exists for a number of reasons. The big one is that the initial phase of salmon uses an online inference algorithm so that specific details of the solution are dependent on the order in which the reads are processed (which is random given that multiple threads parse reads and update estimates asynchronously). However, the more important point here is that the inference estimates returned by Salmon (and, for that matter, every other transcript-level expression tool) are the result of a statistical optimization procedure that cannot guarantee a unique global optimal solution (and, in fact, even if a global optimum could be guaranteed, there may be multiple different optima). Thus, there is uncertainty inherent in the statistical problem being solved. Of course, if one ordered updates in the same way and set up the initial conditions precisely the same, there would be convergence to the same result, but any sense of confidence there is illusory. However, Salmon does provide a way to quantify, statistically, confidence in the result. The `--numBootstraps` option will do bootstrap sampling, or the `--numGibbsSamples` option will perform posterior Gibbs sampling. Both of these techniques will provide samples from the posterior distribution, and the variance of these samples will give you some information about the variance in the results that are due purely to the inherent statistical uncertainty in the problem. In the `scripts` folder there is a python script `ConvertBootstrapsToTSV.py` that will convert either the bootstrap or gibbs samples to a easily readable tsv format. These samples represent the estimated number of reads coming from each transcript when sampling from the posterior. These can be used to empirically estimate that statistical uncertainty in the abundance estimates of the different tran",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/102#issuecomment-259464248:672,optimiz,optimization,672,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/102#issuecomment-259464248,1,['optimiz'],['optimization']
Performance,"Hi @red-plant,. So, I have some update from our end. @mohsenzakeri dug into the data a bit (specifically `SRR7985407`). What he found is that there are a considerable number of reads (~13%) have long stretches of polyA or polyT that are matching in a hyper-repetitive manner internally within a certain set of transcripts (i.e. these are not matching polyA tails, because those are already trimmed). These matches are, obviously, minimally informative, but we had not special-cased ignoring them yet. Specifically, what seems to be prevalent in these reads are read pairs where one read has polyA, the other has polyT, and the keep matching to the same positions. However, the rest of the reads don't match the transcript, so a bunch of time is wasted on validating (and discarding) these mappings. To test this hypothesis, we made a small change to the mapping algorithm to special case and ignore k-mers that are purely homopolymers. I'll note that in this data, this has no effect on the mapping rate. I get the following performance profile running the trimmed version of this data (having trimmed with `fastp`) using 4 threads, and _without_ the additional `--hitFilterPolicy BOTH` flag. ```; 1306.86user 4.79system 4:42.54elapsed 464%CPU (0avgtext+0avgdata 592704maxresident)k; ```. I was wondering if you might test this altered version out and see if it has a similarly beneficial effect for you as well. Probably, the time will be different, since the processors themselves are, and since I elided all non-essential flags here, but I would hope this version is faster than the current (even with the altered `hitFilterPolicy`). You can find a tarball with the pre-compiled binary [here](https://drive.google.com/file/d/1tPyOPW3Y8l86RS0-zBRLh0wCt3VTpkNw/view?usp=sharing). It should work on any relatively recent linux system.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/527#issuecomment-637568013:1025,perform,performance,1025,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/527#issuecomment-637568013,1,['perform'],['performance']
Performance,"Hi @red-plant,. Thank you for providing the follow-up here. This behavior is very strange! However, I am not sure what is stranger; that 1.2.1 takes ~5x longer for you, or that 1.0.0 is taking > 5H in the first place! I can confirm that I am getting really strange (i.e. slow) behavior on this sample under both versions. It's unexpected because I've never seen a sample take this long before. We are looking into it, and will report back. However, since digging into the data to figure out precisely what is going on may take a little bit, I wanted to ask if you can try something. I think the issue may be resulting from some highly-expressed, ""pathologically"" repetitive sequence. Could you run salmon with the extra command line option `--hitFilterPolicy BOTH`, and let me know if / how the performance profile changes for you?. Thanks!; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/527#issuecomment-636605261:795,perform,performance,795,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/527#issuecomment-636605261,1,['perform'],['performance']
Performance,"Hi @reganhayward,. Thank you for the detailed report. It's interesting that this happens when running with STAR but not when running with selective alignment. However, salmon will attempt to solve the optimization problem with the alignments it is given, regardless of if those come from STAR or from it's built-in selective alignment. While I would generally expect these to be similar, the alignment algorithms are different; see [e.g. the differences between SA/SAF & STAR here](https://genomebiology.biomedcentral.com/articles/10.1186/s13059-020-02151-8). Nonetheless, it is possible that for a small subset of transcripts, the probabilistic allocations are _so_ ambiguous, that you get large swings in the resulting quantification estimates based on tiny variations in where the optimization starts (which is, itself, stochastic due to the asynchronous nature of salmon's online inference phase). One way we can test this hypothesis is as follows. You can run salmon with `--numGibbsSamples 100` and `-d`. This will tell salmon to perform posterior Gibbs sampling (`--numGibbsSamples 100`) and to dump the range-factorized equivalence classes used for offline quantification (`-d`). The Gibbs sampling files will contain the traces for the transcripts in question over the various iterations of the sampling procedure. Transcripts where there is a tremendous amount of ambiguity will tend to have highly anti-correlated posterior samples, and similarly, if you were to consider the abundance output of these transcripts as a *group*, there would be a large reduction in inferential relative variance. In fact, we [wrote a whole paper on this topic](https://academic.oup.com/bioinformatics/article/36/Supplement_1/i102/5870485). Consider this example from that paper:. ![image](https://user-images.githubusercontent.com/361470/101438021-706d3600-38df-11eb-9ada-a54ea9092d2d.png). The x-axis is samples from the Gibbs chains, and the y-values denote the estimated number of reads assigned to both t",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/600#issuecomment-740363115:201,optimiz,optimization,201,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/600#issuecomment-740363115,2,['optimiz'],['optimization']
Performance,"Hi @rekado,. The order is determined based on how work is pulled from a queue. Specifically, the way quantification works in the first phase is that independent threads pull reads to be processed from a lock-free concurrent queue [e.g. here for paired-end reads](https://github.com/COMBINE-lab/salmon/blob/master/src/SalmonQuantify.cpp#L981). This queue is filled in by parsing threads (e.g. [here](https://github.com/COMBINE-lab/salmon/blob/master/src/FastxParser.cpp#L151)). This is the major source of stochasticity. One other source is that once reads are pulled from the queue, they are mapped and then their contribution to the quantifications is processed in [this function](https://github.com/COMBINE-lab/salmon/blob/master/src/SalmonQuantify.cpp#L165) which, itself, calls update functions to a few classes that are potentially being updated by many threads. I'd be thrilled, of course, if you were able to find a good way to make this process deterministic. To me, however, this seems like a tall task. Best,; Rob. P.S. None of your questions are silly; I'm happy to answer them!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/185#issuecomment-392962209:72,queue,queue,72,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/185#issuecomment-392962209,5,"['concurren', 'queue']","['concurrent', 'queue']"
Performance,"Hi @rhlampe,. Currently, there is no way to prevent the salmon indexer from using more memory if it is needed ot build the index. However, if there is a limit placed by the cluster, it will likely just result in a `bad_alloc` exception from the indexer. The number of sequences alone can tell you a bit about scaling, but the total number of nuclotides being indexed is actually a better predictor of resource usage. How many nucleotides, total, are the references you're considering? While we are working on ways to make the indexing scheme highly scalable, it's worth noting that, to achieve some of it's speed, salmon pre-computes a lot of information it its index (so that the index can become fairly large). One thing I might suggest, if you want to attempt to index and quantify on a very large reference, is to use the `--perfectHash` index in the newest development version of Salmon (pre-release tarball attached below). The latest version (for which the official version should appear soon) represents a number of improvements to index construction. The default indexer has reduced memory usage by ~40%, and the new `--perfectHash` indexer, while somewhat slower, reduces the memory usage even more (by an additional 40-50%). With a fixed memory budget, then, it should allow you to index ever larger references. --Rob. [Salmon-v0.7.3-pre_linux_x86_64.tar.gz](https://github.com/COMBINE-lab/salmon/files/512019/Salmon-v0.7.3-pre_linux_x86_64.tar.gz)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/97#issuecomment-251759242:549,scalab,scalable,549,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/97#issuecomment-251759242,1,['scalab'],['scalable']
Performance,"Hi @rmurray2,. Thanks again for the detailed question (I answered them in reverse order, so that's why I'm saying ""again"" here). There are a few things going on that could be leading to differences. They are, in the order I think they will have an effect on the result:. * You are using RSEM in a mode that is mapping the reads to the entire genome (using STAR) and then projecting the resulting alignments to the transcriptome. You are using salmon in a way that is performing selective alignment against the transcriptome only. We have recently published [a paper](https://genomebiology.biomedcentral.com/articles/10.1186/s13059-020-02151-8) discussing in detail the effect that some of these choices can have on transcript and gene-level abundance estimation. In general, if you don't include the genome as a mapping target, depending on your sample, there may be certain reads that are assigned to the transcriptome even though they have a better alignment to some other genomic location. This is independent of e.g. salmon and RSEM, and you'd observe the same thing if you ran RSEM using e.g. Bowtie2 as the aligner aligning against the transcriptome. Luckily, you can control this source of variation. Salmon, like RSEM, can accept alignments to the transcriptome produced by STAR. If you want to see how big of an effect this is having in your sample, you can align reads to the genome using STAR (and project them to the transcriptome) to produce a BAM file that salmon can quantify. You can check RSEM's script to see exactly how it invokes STAR, but the parameters are something like `--outFilterType BySJout --alignSJoverhangMin 8 --outFilterMultimapNmax 20 --alignSJDBoverhangMin 1 --outFilterMismatchNmax 999 --outFilterMismatchNoverReadLmax 0.04 --alignIntronMin 20 --alignIntronMax 1000000 --alignMatesGapMax 1000000 --eadFilesCommand zcat --outSAMtype BAM Unsorted --quantMode TranscriptomeSAM --outSAMattributes NH HI AS NM MD --quantTranscriptomeBan IndelSoftclipSingleend`; note tha",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/612#issuecomment-758004590:467,perform,performing,467,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/612#issuecomment-758004590,1,['perform'],['performing']
Performance,"Hi @rob-p . Thanks for getting back. I know there are lots of such instances in the literature which have wordings like ```50% homology``` etc - that's why I shared the book chapter from Eugene Koonin's book and the other references/quotes from Walter Fitch. We both cannot change what has already been published, however, when we write something ourselves, we can change the paradigm and represent things correctly. Also, the preprint paper has similar wordings that you might want to reconsider changing:. ```To obtain homologous sequences within a reference, we map the spliced transcript sequences against a version of the genome where all exon segments are hard-masked (i.e. replaced with N). We perform this mapping using MashMap 20, with segment size 500 and homology 80%. ```. Probably, change the first instance of ```homologous``` to '_identical_' and ```homology 80%``` to' _identity 80%_'. And I do not want to digress from the main issue or **take the sheen away from the great work from your group on the paper**.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/365#issuecomment-499542660:701,perform,perform,701,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/365#issuecomment-499542660,1,['perform'],['perform']
Performance,"Hi @rob-p and @davismcc . A bit delayed, but this relates to the questions I've been asking on the salmon gitter. . First, it's worth pointing out that the new 10x (v2) sequencing is a lot more like other bead methods, where (i) index reads (i7/i5) are for labelling biological samples (ii) read1 contains the combined cell and molecular/UMI barcodes (ii) read2 is the transcript 3' read. So it seems there is now some data format convergence. Either way, I'd guess that ongoing iterations of the high throughput platforms will keep one read for the transcript 3', reserving the other 2 or 3 reads for some combination of the sample, cell and molecular barcodes. . Before thinking about how to best collapse UMIs, there's also the issue of how best to QC the barcodes and beads. Jim Namesh has [some functions](http://mccarrolllab.com/wp-content/uploads/2016/03/Drop-seqAlignmentCookbookv1.2Jan2016.pdf); as does [Vasilis Ntranos](https://github.com/pachterlab/scRNA-Seq-TCC-prep/blob/master/README.md). Arguably this has nothing to do with salmon/kallisto though I think the kallisto guys were smart to include it. It's a good filter even if only for speeding things up. Then it's really what might be the most appropriate demultiplexing of fastqs to allow compatibility between tecnhiques, I guess. I quite like how the kallisto workflow ends up with a fastq per cell together with a matching UMI file. Then at the very least one can ignore the UMIs (perhaps going with what @vals suggests). Not sure if that's helpful. But thought to chime in as somebody we would love to see salmon working on the high throughput single-cell platforms that have sample, cell and molecular barcodes. Even if only to test how worthwhile UMIs genuinely are for most applications. This may be a controversial comment, but I suspect for me UMIs will largely end up the same way as spike-ins: useful for quantifying endogenous RNA recovered per cell but perhaps not all that useful beyond that for low read depth single-",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/93#issuecomment-265619589:502,throughput,throughput,502,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/93#issuecomment-265619589,1,['throughput'],['throughput']
Performance,"Hi @rob-p,. Thanks for your prompt and detailed reply as usual. I was mostly concerned for seeing it happening only once when there are many more transcripts with no gene associated. Since reporting a warning for each transcript with no gene associated could be too noisy, maybe reporting a warning with the total number of transcripts without annotation would be enough. (And not placing any transcript in the ""quant.gene.sf"" file). Btw, thanks for the possibility to generate a .sam file introduced in version 0.7.2. That's very useful for some of the analyses I'll have to perform with my data. I appreciate that.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/98#issuecomment-252642473:576,perform,perform,576,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/98#issuecomment-252642473,1,['perform'],['perform']
Performance,"Hi @rob-p,. We ran the tests you requested and the main problem remains. The memory load is lower than before, but for some reason `Salmon` (0.8.2) only works in the SGE cluster we have access to when we increase the memory limits (just like 0.7.2). (Edit: we used 0.8.2 to build a new index). I'll ask the cluster admins as they might have a clue on how to proceed. ## Low memory test. ### bash script. ```bash; #!/bin/bash; #$ -cwd; #$ -l mem_free=14G,h_vmem=15G,h_fsize=100G; #$ -N step6-salmon_test3.gsk_phaseII; #$ -pe local 1; #$ -o ./logs/salmon_test3.$TASK_ID.txt; #$ -e ./logs/salmon_test3.$TASK_ID.txt; #$ -t 1-3; #$ -hold_jid pipeline_setup,step4-featCounts-alzheimer.gsk_phaseII; #$ -m e; echo ""**** Job starts ****""; date. echo ""**** JHPCE info ****""; echo ""User: ${USER}""; echo ""Job id: ${JOB_ID}""; echo ""Job name: ${JOB_NAME}""; echo ""Hostname: ${HOSTNAME}""; echo ""Task id: ${TASK_ID}"". FILE1=$(awk 'BEGIN {FS=""\t""} {print $1}' /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk ""NR==${SGE_TASK_ID}""); if [ TRUE == ""TRUE"" ] ; then; FILE2=$(awk 'BEGIN {FS=""\t""} {print $3}' /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk ""NR==${SGE_TASK_ID}""); fi; ID=$(cat /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk '{print $NF}' | awk ""NR==${SGE_TASK_ID}""). mkdir -p /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test3/${ID}. /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon quant 	-i /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts -p 1 -l ISR 	-1 ${FILE1} -2 ${FILE2} 	-o /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test3/${ID}. echo ""**** Job ends ****""; date; ```. ### Example log file. ```; **** Job starts ****; Wed Mar 29 14:51:10 EDT 2017; **** JHPCE info ****; User: lcollado; Job id: 110315; Job name: step6-salmon_test3.gsk_phaseII; Hostname: compute-061; Task id: ; Version Info: This is the most recen",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-290516965:84,load,load,84,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-290516965,1,['load'],['load']
Performance,"Hi @roryk,. Salmon doesn't currently have the ability to output a pseudobam, but that is definitely possible (and not too difficult). We have a related feature planned; perhaps you could tell me if it suits your use case. However, first, I should mention that if you'd simply like a pseudobam for _all_ the mapping locations of the reads, you can use [RapMap](https://github.com/COMBINE-lab/RapMap). RapMap implements the quasi-mapping algorithm upon which Salmon and Sailfish are based (and RapMap is used as a library in the Salmon and Sailfish codebases). Given an index and set of reads, RapMap will report all of the multi-mapping locations that Salmon and Sailfish would consider during quantification. The other feature we have in the works is to have Salmon optionally output a `.bam` file (with actual alignments) post-quantification. It turns out that, given the quasi-mapping information and the quantification results, taking the extra step from quasi-mapping to an actual _alignment_ can be done fairly efficiently. In this mode, Salmon would make one more pass over the reads and, considering the estimated abundances, sample a single alignment for each multi-mapping read proportional to the relative abundance of the different multi-mapping targets (i.e. it would perform a sampling over the multi-mapping locations that would, in expectation, give the same abundances as the _soft_ assignments computed by the optimization algorithm). This feature will be very useful for [transrate](https://github.com/Blahah/transrate). However, given that your goal is to use outside information to perform the filtering yourself, this option may not be ideal for you.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/38#issuecomment-175092553:1280,perform,perform,1280,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/38#issuecomment-175092553,3,"['optimiz', 'perform']","['optimization', 'perform']"
Performance,"Hi @ryanpe13002,. The bootstrap has no effect on the main `quant.sf` file (that is always the result of the main maximum likelihood estimate). All bootstrap samples are written to the `bootstraps.gz` file. If you load your data with the `fishpond` package in `R`, you can request to load the bootstraps to investigate them. Otherwise, if you use an uncertainty aware tool like [`swish`](https://bioconductor.org/packages/release/bioc/vignettes/fishpond/inst/doc/swish.html) for differential testing, it will make use of the bootstraps automatically to account for inferential uncertainty when performing differential testing. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/818#issuecomment-1354070141:213,load,load,213,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/818#issuecomment-1354070141,3,"['load', 'perform']","['load', 'performing']"
Performance,"Hi @s1corley . As @rob-p mentions, your paper could help assess different methodologies for quantification and also help optimize salmon further for QuantSeq. I would still like you to check if you have used salmon quant command line correctly for QuantSeq data analysis. Your paper briefly alludes to QuantSeq Forward in the Introduction section of the paper; >The QuantSeq Forward kit has an oligo (dT) primer which contains the Illumina-specific Read 2 linker ... but the Methods section of your paper does not specify if you have used QuantSeq FWD or REV. Page 14 of the PDF from the [Lexogen Website data analysis pipeline for QuantSeq FWD](https://www.bluebee.com/wp-content/uploads/2018/11/015UG108V0201-QuantSeq-Data-Analysis-Pipeline_2018-10-18.pdf) recommends using the below htseq command line. ```; htseq-count -m intersection-nonempty -s yes -f bam -r pos $bam; $resource_dir/annotation.gtf > $bam_dir/read_counts.txt; ```; > QuantSeq is a stranded protocol. For the QuantSeq FWD pipeline the argument -s yes indicates; > stranded in the sense orientation. For the QuantSeq REV pipeline -s reverse is used. Similar to the above htseq command line arguments, I think if you are using QuantSeq FWD, the` libType argument from salmon quant should have been SF` . One way I checked these with my datasets was to run the salmon quant command 3 times - once with `libType A`, once with` libType SF` and once with `libType SR` -- with QuantSeq FWD the estimated counts will be almost same with libType A and libType SF. I echo what @rob-p says - Congratulations once again on the paper.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-565653150:121,optimiz,optimize,121,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-565653150,1,['optimiz'],['optimize']
Performance,"Hi @s1corley,. Congratulations on your publication! The `--noLengthCorrection` flag has been around for a long time (e.g. where it is suggested in the post to which @tamuanand [links](https://groups.google.com/forum/#!msg/sailfish-users/VIfqBwgF6xQ/fw-rgC_kAwAJ)). However, given our limited access to QuantSeq and our limited (student) bandwidth to do extensive testing on alternative tech, we have kept this flag marked as experimental. As I mention above, it was introduced since, _conceptually_, the QuantSeq protocol should not exhibit a length effect and so the one may not wish to account for the length when determining assignment probabilities during the variational Bayesian optimization. However, the empirical testing of this has been limited. Now that your paper is published, and contains what look to be some _very through_ assessment methodologies, we may be able to look into this and determine if there is anything we can do to, perhaps, optimize salmon even more for accurate quantification from the QuantSeq protocol. We would welcome any suggestions or feedback you may have. Congratulations again on the paper!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-565474848:685,optimiz,optimization,685,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-565474848,2,['optimiz'],"['optimization', 'optimize']"
Performance,"Hi @sagnikbanerjee15,. > We are using Salmon to quantify gene counts for samples in RNA-Seq experiment. We will be using the weights of the equivalence class to perform a calculation for which we require the effective length of the equivalence classes. I checked in the eq_class.txt file under the aux_info directory but I was unable to find it. We are using alignment-based method where we supply a bamfile to salmon. Could you please help us to obtain the effective length of the equivalence classes?. An equivalence class is not an object that has a notion of a length or effective length. Specifically, an equivalence class represents a set of transcripts to which a set of fragments map or align. If you are using the range-factorized equivalence classes (which is what salmon uses by default internally), these represent a set of transcripts to which a set of fragments map or align with very similar conditional probability vectors. Since the equivalence class represents mappings or alignments to a collection of transcripts — where each transcript may have an arbitrarily different length — there is no such thing as the notion of the ""effective length"" of an equivalence class. Note that the sequence that induces an equivalence class need not even be a contiguous region of the underlying reference (see answer below), and thus the notion of an effective length (or a length in general) is not applicable here. > I have another question. Salmon operates in both lightweight alignment mode and in alignment mode. For the lightweight mode, one needs to first create an index (which is the colored De Bruijn graph). I understand that this index (along with all the equivalence class) remains the same even when gene counts of different RNA-Seq samples are estimated. But I am a bit confused about the alignment-based method. In this case, salmon does not require an index since it has the actual alignments. If we have multiple samples, which are mapped to the same transcriptome will Salmon r",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/579#issuecomment-717279405:161,perform,perform,161,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/579#issuecomment-717279405,1,['perform'],['perform']
Performance,"Hi @satta,. Thanks for bringing this to my attention. I am of two minds on this proposal. On one hand, I agree that it is cleaner, in theory, to have a RapMap shared library to which Salmon could simply link. Currently, Salmon pulls in the relevant portions of the RapMap code to call what is essentially an ill-defined public API for mapping. On the other hand, I have two concerns about separating the code at this point, one is major the other minor. The major concern is that both Salmon and RapMap are still very much under active development, core code and even the interfaces are undergoing reasonably rapid changes (thus the versioning < 1.0). This allows me to easily add features that may potentially benefit Salmon to the RapMap codebase, and then to synchronize Salmon releases with particular commits (tags) in the RapMap codebase. The current build system makes it very easy to pull in the appropriately versioned RapMap code. On the other hand, I have very little experience in properly versioning shared libraries so I would have to understand that better and how this could be done without complicating the build process. My _minor_ concern is that I don't know what effect, if any, separating the code into a separate shared library might have on compiler optimizations. Right now, since the relevant RapMap code is compiled alongside Salmon and they are linked together into the same module, certain optimizations may be possible that would not be so when linking to a shared library. My educated guess is that the effect of such optimizations would be negligible, but it's something that may be worth some exploration first. Overall, I'm very open to this idea, but I think I need to do some homework on it before we can commit and undertake the change.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/87#issuecomment-246027704:1274,optimiz,optimizations,1274,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/87#issuecomment-246027704,3,['optimiz'],['optimizations']
Performance,"Hi @shalercr,. I agree that if each sample runs as quickly as you see here, it's not a big deal to just re-run them all. Note that, while my avoids ~116 times more (eventually-discarded) alignments than did yours, the difference in the number of discarded _fragments_ (i.e. fragments that had no mapping) is very small — ~7,000, or 0.023% of the fragments. Thus, despite the huge speed-up, I wouldn't expect many differences in the quantifications. However, I couldn't argue against re-quantifying everything with the new version just for good measure :). When you have a chance, please do let me know if you see this same performance difference using the pre-compiled (linux) binary [here](https://drive.google.com/file/d/1tPyOPW3Y8l86RS0-zBRLh0wCt3VTpkNw/view?usp=sharing). Of course, once we finalize this release (soon), we will push to bioconda so we will also have OSX binaries available. However, I just want to make sure this fixes things on your end as well before the release.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/537#issuecomment-644796608:623,perform,performance,623,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/537#issuecomment-644796608,1,['perform'],['performance']
Performance,"Hi @silvanopiazza,. I'm glad Docker is working for you. If you compile from source, you should make sure to include `-DNO_IPO=TRUE` in your `cmake` command if you are compiling on GCC. This is because GCC support for inter-procedural optimization is rather broken currently.. I agree that it's strange to encounter such an illegal instruction. Especially since the machine doing the compiling is an older Xeon (circa 2017). I wonder if there's an easy way to figure out what the instruction is. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/783#issuecomment-1144002615:234,optimiz,optimization,234,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/783#issuecomment-1144002615,1,['optimiz'],['optimization']
Performance,"Hi @sjackman , Thanks for you question. It is indeed a good observation to use salmon for combining separate CB and read-sequence fastq files.; Having said that, we have designed alevin to work with, and tested it on 10x-chromium `cellranger` pipeline which itself has a feature similar to mentioned above by you (enabled by flag `--dumpfq`). This feature takes in two separate files: one with CB+UMI and another with read-sequence, and performs initial whitelisting (knee based , more intelligent whitelisting happens downstream and needs deduplicated UMI counts or one can just optionally provide external whitelist), error corrects the CB, attaches it to the header (although not with tag `BX:Z`) of the read-sequence in the second file, and dumps it to the standard out. I might have to read a bit about `longranger` and its `FASTQ` format, but if you are familiar with the `longranger` pipeline and are sure that it uses 16+10 (CB+UMI) in one file and read-sequence in the second file, then I think you are good to try alevin with `--dumpfq` flag. Let us know how it goes and if you face any problem. . Note: Just put an extra flag `--noQuant` so that alevin knows to stop after dumping the fastq otherwise it will start performing downstream tasks.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/233#issuecomment-395174284:437,perform,performs,437,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/233#issuecomment-395174284,2,['perform'],"['performing', 'performs']"
Performance,"Hi @sjaenick,. This is a bug in the compiler which GCC has not yet fixed related to inter-procedural optimization. To compile successfully, please add `-DNO_IPO=TRUE` to the CMake flags. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/664#issuecomment-847978707:101,optimiz,optimization,101,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/664#issuecomment-847978707,1,['optimiz'],['optimization']
Performance,"Hi @tamuanand ,. I think these are very important question and thanks for raising the issue.; As you mention, In the preprint we put out two different modes of Selective Alignment:; A) SA: The mashmap and bedtools based pipeline which follows old [SalmonTools](https://github.com/COMBINE-lab/SalmonTools/blob/master/README.md) based pipeline.; B) SAF: Inbuilt salmon pipeline to consume genome and follows [this](https://combine-lab.github.io/alevin-tutorial/2019/selective-alignment/) pipeline. The distinction between the two comes from how the decoy sequence are actually generated. To answer your question point wise.; 1.) That's correct SAF based pipeline follows the tutorial as mentioned in B above and uses the full genome as decoys.; 2.) That's correct, if a user wan't to run SA method, then they should follow mashmap based tutorial A. This might be useful for situation where the index is too big to fit into the machine's memory.; 3.) That's also correct, yes if you don't provide decoys `-d` you can still run salmon on the transcriptome. We have just enabled the validateMapping option by default, which is also used in transcriptome only mode, currently there is no option to _disable_ it.; 4) That's also correct, we have dropped the quasi-mapping based support from the latest version, If you need to run quasi we have released `0.15` just as a last version into the archive.; 5 & 6) Very good question, short answer is your default pipeline of VBEM is the recommended way. We have to use additional flags `--mimicBT2 and --useEM` while comparing the methods in the preprint. RSEM can only do EM and as we were comparing against Bowtie2 we have to mimic it with more stricter requirements for fair comparison. We expect the performance to be better with VB based optimization and not using `mimcBT2` . @rob-p Feel free to add if I missed something.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/442#issuecomment-549187035:1742,perform,performance,1742,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/442#issuecomment-549187035,2,"['optimiz', 'perform']","['optimization', 'performance']"
Performance,"Hi @tamuanand,. Thanks again for your detailed questions and thoughts on this issue. Just to follow-up / expand a bit on what @k3yavi has said (and to answer your other question): Yes, one would imagine that, given the details of the QuantSeq protocol, turning off length correction would make the most sense. The main reason this flag is listed as _experimental_, is simply that it was designed based on the expected characteristics of the protocol. Conceptually, the protocol is performing tagged-end sequencing, and so there should be little-to-no length effect. However, since we haven't done extensive internal validation on QuantSeq data, we have left this flag as experimental until it is further tested by ourselves or others. > Also @rob-p , weren't you referring to the RSEM caveat with QuantSeq data analysis wherein one cannot ask RSEM to disable lengthCorrection and hence the count statistics might be misleading?. Correct; as far as we are aware, there is no way to disable the built-in length-dependent assumptions of RSEM. One could use the `--estimate-rspd` flag to allow learning of a non-uniform read distribution (the equivalent of `--posBias` in salmon), though it's unclear / unlikely if this would be as effective as fully disabling the length correction for this type of tagged-end data. If you have any good empirical assessment mechanism for QuantSeq data, and a chance to test out these different salmon options, we'd be happy to get feedback and discuss details further!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-565285540:481,perform,performing,481,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-565285540,1,['perform'],['performing']
Performance,"Hi @tomsing1 ,; Apologies for the slow response, I was out of country for a while. Thanks for your kind words and starting a very interesting suggestion.; It’s fascinating to see, how methods being used in single-cell RNA-seq is coming full circle back to the bulk RNA-seq experiments. We have to do some more digging to say clearly about the caveats of using Alevin with the mentioned 3’ bulk RNA-seq experiments but given the understanding from the picture of the shared image we don’t see any obvious show stoppers; although below mentioned concerns should be kept in mind while using Alevin for bulk data deduplication:. Alevin solves the problem pretty well for protocols where fragmentation of the cDNA molecule happens post PCR amplification. There might be some concerns about over-deduplication of the UMI if fragmenation happens before amplification. Although in current form, Illumina sample index can be given as an external whitelist to Alevin but user should be aware that Alevin performs a sequence correction step before starting any optimizations.; Alevin is designed for droplets based protocols, where one end of Paired end read is just the CB/UMI (i.e. no read sequence) and therefore Alevin can’t optimally use the full paired end information of the bulk 3' protocol if its both end has read-sequence for example the ambiguous mapping resolution based on a previously/empirically known approximate fragment length. We would be more than happy to help/discuss, how does the results look in bulk 3’ tagged protocols or if you have particular suggestions about what improvements can be done in Alevin.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/306#issuecomment-439530193:994,perform,performs,994,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/306#issuecomment-439530193,2,"['optimiz', 'perform']","['optimizations', 'performs']"
Performance,"Hi @ulin27,. This isn't a `salmon`-related issue. The script is trying to run an instance of R, and within R to load the `edgeR` package to perform some normalization. It looks like the location you are running this doesn't have `edgeR` installed. I would check in with the people who installed `trinity` on your computer or, if that was you, ask upstream in the `trinity` user group. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/855#issuecomment-1604792956:112,load,load,112,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/855#issuecomment-1604792956,2,"['load', 'perform']","['load', 'perform']"
Performance,"Hi @vals,. This is very interesting, as we've been doing quite a bit of testing and (to the contrary) have found v0.4.0 to perform substantially _better_ than v0.3.x. Out of curiosity, could you check how v0.4.0 performs _without_ `--useVBOpt`? Obviously, if you continue to see this regression, I'll be happy to try and dig down deeper, but I might need you to provide some testing data. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/6#issuecomment-111538228:123,perform,perform,123,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/6#issuecomment-111538228,2,['perform'],"['perform', 'performs']"
Performance,"Hi @wmegchel ,. Thanks for the raising the issue.; If I understand correctly, your question is Number of mapped reads != Number of deduplicated reads ? Basically, the quant matrix (and the csv matrix) represents the number of _deduplicated_ reads, which indeed should be less than number of mapped reads. Alevin consumes the reads which are mapped, performs UMI level deduplication and reports them in the `quant_mat.gz`. I am unsure about the 10x part of your question i.e.; > I was able to run the 10x PBMC4k example and there, the sum of the count matrix entries indeed fitted the reported UMI counts and mapping rate. If this is true then something is wrong, as the number of mapped reads should be much greater than (based on the number of PCR cycles) number of deduplicated reads. Hope this answer your question ?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/361#issuecomment-490081966:349,perform,performs,349,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/361#issuecomment-490081966,1,['perform'],['performs']
Performance,"Hi Avi, thanks for your detailed explanation!. From my understanding: a pre-selection of high-quality cells based on 1) CB frequency - finding the knee point (in the initial whitelisting) and 2) other features (in finalized/intelligent) whitelisting is performed in alevin, while [cell ranger count](https://support.10xgenomics.com/single-cell-gene-expression/software/pipelines/latest/algorithms/overview#cell_calling) does step 1) related to the `--expectCells` number and used an alternative method w/o knee point estimation. . Based on above, the newly included cells w/ increased number of `--expectCells` are also more likely to be filtered out in later steps using criteria such as `min of number of features/reads` detected per sample. But such filtering may not be expected if interests are also on cells with small transcriptomes such as TILs. I will try some downstream filtering to see how many good cells I can get. . Yeah it helps - thanks!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/396#issuecomment-510639440:253,perform,performed,253,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/396#issuecomment-510639440,1,['perform'],['performed']
Performance,"Hi John,. Thanks for reporting this. Indeed this is an oversight. The gencode option is applied in quasi-mapping mode during index construction, but there is no indexing step in alignment mode. So, this transformation should be applied when the reference sequences are loaded in alignment-based mode. I'll add this option to alignment-based quant for v0.7.3, which should be coming soon. Thanks again for reporting this. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/95#issuecomment-250509570:269,load,loaded,269,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/95#issuecomment-250509570,1,['load'],['loaded']
Performance,"Hi Kivanc,. Thanks for the kind words, and thank you for the _extremely detailed_ report. Reports like this are a model of what every developer wishes a user did before filing an issue :). First, let me clear up what seems like might be a small source of confusion. Since both of the salmon runs are from v1.1.0, _neither_ of these are making use of quasi-mapping. Specifically, newer versions of salmon _only_ perform selective alignment (and this makes the `--validateMappings` command line argument redundant in newer versions, though we keep it so as to maximize backward compatibility with command line parameters people may be using). So, the main difference between your two salmon runs is inclusion of the decoy set. This almost certainly means that the reads that map in your second set of salmon runs but not your first are being assigned to decoys in the first case. To try and get a better handle on this, could you upload a `meta_info.json` file from both runs? This file lives in the `aux_info` directory, and it will provide information about e.g. how many reads were best mapped to decoys and were discarded for this reason. The guarantee you get from the selective alignment is that, if the fragment is discarded by decoy mapping, it maps _strictly better_ to the decoy than to the non-decoy sequence. There are many reasons this could happen. One is rRNA contamination, another could be that reads are coming from processed pseudogenes that are not properly in your annotation, yet a third is that your sample has a considerable fraction of reads spanning exon-intron junctions (in this case, the read will map better to the corresponding location on the genome, and worse to the annotate transcript where the intronic sequence is not present). Now, figuring out exactly which of these cases you are in is a bit more difficult, but one approach would be to pick one of the samples with the biggest differences and map to the reads to the genome with e.g. STAR or HISAT2 to see what y",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/479#issuecomment-578848875:411,perform,perform,411,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/479#issuecomment-578848875,1,['perform'],['perform']
Performance,"Hi Nick,. No problem at all; sorry for not providing a better explanation (I'm planning on writing one up for when this feature is listed in the next official release). In terms of strategy, my recommendation would be to use the default (the `dense hash`) unless indexing memory becomes a problem. The main differences are the following:; - The perfect hash uses an external memory algorithm to construct the hash function, and so requires less memory.; - Because the perfect hash function is built in external memory, **construction** of the hash using this data structure is sower. I don't have longitudinal benchmarks, but it is somewhere between 2 and 5x slower to populate the perfect hash than the dense hash.; - Once constructed, the perfect hash is _considerably_ smaller, and so quantification on an index built using a perfect hash will require only ~50% of the memory that is required when using a dense hash. Obviously if you're quantifying on the same machine that was able to build the index, this isn't a problem. However, if you're shipping the index to smaller memory computers, then this is something to consider.; - The performance difference in terms of mapping speed is very minimal; the minimum perfect hash can be 5-10% slower than the dense hash, but this difference is usually only a matter of seconds. Also, the total runtime difference can be even less since the smaller perfect hash can be read more quickly from disk than the larger dense hash. So, the standard recommendation would be use the default unless you run into memory problems building the index; in that case, try enabling the `--perfectHash` flag.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/53#issuecomment-204069238:1139,perform,performance,1139,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/53#issuecomment-204069238,1,['perform'],['performance']
Performance,"Hi Rob, . Thanks for the quick reply. I'm looking into it and will try this with an updated install of GCC >= 5.2.; The system default gcc is 4.8.5 but I set it to use a different install using environment modules to load gcc-4.9.2 but some environment variables may not have been set correctly, hence why the build file switches to a lower-version GCC but it isn't clear why it looks for 4.8.2 despite that.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/296#issuecomment-422891645:217,load,load,217,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/296#issuecomment-422891645,1,['load'],['load']
Performance,"Hi Rob,. Appreciate the response. . The link for the data should be in here:; https://drive.google.com/open?id=1SDqMrHLx-cbfvD4HDmpxcHitqO3B1ZLR; [https://drive.google.com/open?id=1SDqMrHLx-cbfvD4HDmpxcHitqO3B1ZLR](url); https://drive.google.com/drive/folders/1SDqMrHLx-cbfvD4HDmpxcHitqO3B1ZLR?usp=sharing. I've tried forcing the library type for both version 0.8 and 0.12 as follows:. **For version 0.8 with raw reads**; #!/bin/bash; #SBATCH -N 1; #SBATCH -c 8; #SBATCH --mem=10G; #SBATCH --mail-use=tarun2@illinois.edu; #SBATCH -J Salmon; #SBATCH -a 1-24. module load Salmon/0.8.2-IGB-gcc-4.9.4-Python-2.7.13. line=$(sed -n -e ""$SLURM_ARRAY_TASK_ID p"" ~/source/BLBnew.txt). salmon quant -i ~/data/genome/MSU7_transcript.index -l IU \; -1 ~/data/raw-data/BLB/${line}1.fastq.gz \; -2 ~/data/raw-data/BLB/${line}2.fastq.gz --numBootstraps=30 \; -p 12 -o ~/results/salmon_quant_Sheng_IU_old/${line} --seqBias --gcBias. The EffectiveLength is again the same (250) for all genes across all samples:; Name Length EffectiveLength TPM NumReads; LOC_Os01g01010.1 3017 250 28.8836 527.392; LOC_Os01g01010.2 2218 250 1.84062 33.6083; LOC_Os01g01019.1 1127 250 0.0547668 1; LOC_Os01g01030.1 2464 250 4.43611 81; LOC_Os01g01040.4 1524 250 0.941635 17.1935; LOC_Os01g01040.1 2508 250 11.5632 211.135; LOC_Os01g01040.2 2482 250 8.02082 146.454; LOC_Os01g01040.3 2583 250 8.55554 156.218; LOC_Os01g01050.1 2039 250 17.2333 314.667. The mapping rate is again similar for all samples:; [2019-03-04 04:42:18.872] [jointLog] [info] parsing read library format; [2019-03-04 04:42:18.872] [jointLog] [info] There is 1 library.; [2019-03-04 04:42:18.928] [jointLog] [info] Loading Quasi index; [2019-03-04 04:42:18.929] [jointLog] [info] Loading 32-bit quasi index; [2019-03-04 04:42:28.958] [jointLog] [info] done; [2019-03-04 04:42:28.958] [jointLog] [info] Index contained 66153 targets; [2019-03-04 04:44:08.443] [fileLog] [info]; At end of round 0; ==================; Observed 18861231 total fragments (18861231 in mo",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/346#issuecomment-469215256:565,load,load,565,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/346#issuecomment-469215256,1,['load'],['load']
Performance,"Hi Rob,; The cluster behavior/load might explain the indexing behaviour. ; Will keep you posted as I redo with vM25. Thank you again.; Hari",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/561#issuecomment-674870074:30,load,load,30,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/561#issuecomment-674870074,1,['load'],['load']
Performance,"Hi Ryan,; I was looking at the output matrix. It seems the count values are in scientific notations like e-7. Not sure how that happened and it's not happening at my end. I'll check what can be done. Thanks again for reporting this. Regarding the binary file parsing, we recently optimize the output format for Alevin and have updated the python parser. We are still working on updating R parser, will update here once stable.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/380#issuecomment-502788751:280,optimiz,optimize,280,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/380#issuecomment-502788751,1,['optimiz'],['optimize']
Performance,"Hi Shaun!. This is strange! One thing that's strange about it is that this seems to be trying to pull down v0.8.2 rather than v0.9.1 --- is that correct? The stranger thing though is that it seem the ""fetchRapMap.sh"" script isn't being run, which means the following from the CMakeLists.txt is not being executed:. ```; if(NOT FETCHED_RAPMAP); exec_program(${CMAKE_CURRENT_SOURCE_DIR}/scripts/fetchRapMap.sh); set(FETCHED_RAPMAP TRUE CACHE BOOL ""Has RapMap been fetched?"" FORCE); endif(); ```. Any idea why this might be happening? Does the CI environment prohibit this for some reason?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/181#issuecomment-367729441:434,CACHE,CACHE,434,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/181#issuecomment-367729441,1,['CACHE'],['CACHE']
Performance,"Hi Stephen,. So, the variation you see when you re-run salmon multiple times is _expected_ to be different (and _much_ smaller) than the variance you see when bootstrapping. Why is this? When you re-run salmon, the only variance you are seeing is due to small differences in the order of observations / updates from the streaming collapsed variational Bayes phase of the algorithm. This, in turn can have a _slight_ effect on the initialization conditions of the offline phase of the algorithm, and some of the parameters learned for the auxiliary parameters. However, in each run, you are observing _exactly_ the same set of reads and salmon is producing _exactly_ the same set of alignments; only the order and therefore some of the streaming updates change. So, we expect the final estimated abundances to be _very_ similar to each other. However, when salmon performs bootstrapping, it is actually resampling _with replacement_, from the counts of the range-factorized equivalence classes. Roughly, we expect this resampling to be similar to if we re-sampled _with replacement_ from the original set of input reads. That is, we are re-sampling from our population sample — the observed set of reads — to estimate the variance due to inference. So, for the bootstrap re-samplings, we expect significantly more variance than between subsequent runs of salmon, because the observations from which we are making the inference are actually changing. It is possible e.g. that some uniquely mapped reads may not be chosen in some bootstrap sample (since we are re-sampling the observed read count, but doing so _with replacement_), and so the estimates of sets of related isoforms will change in those samples. Thus, since the observations themselves are changing, we expect the estimates to display greater variance. In fact, this is the main goal of performing the bootstrapping (or Gibbs sampling) — to estimate the uncertainty due to inference if we had observed many reads coming from the same under",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/466#issuecomment-568828362:863,perform,performs,863,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/466#issuecomment-568828362,1,['perform'],['performs']
Performance,"Hi Victor,. Is it the case that `/n/data1/cores/bcbio/ej_rnaseq/tCells_KO/work/spikein/Flox5YFP0_B07_R/index` is an index of only your genes of interest? If so, that would explain what you're seeing. Salmon assumes that some non-zero fraction of reads map in your sample. In this case, I'd presume that if you have some samples where no reads map to any transcript of your gene of interest, then salmon will complain in exactly the manner mentioned above. Now that I think about it, there are actually two different scenarios that can cause the above. The first is if something goes wrong in the optimization (there should be no way for this to happen, and so it would be the result of a bug if it did). The second is actually if there are no mappable reads. That's not the result of a bug, or even an ""error"" per-se, but just very unexpected input (since, in a typical scenario, this would imply the reads are unmatched with the reference). It might make sense to handle this case separately. However, this is certainly what is causing the output in your case, and you can safely assume that here, were it not for this specific check, Salmon would return an estimated count of 0 for all transcripts in the index.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/119#issuecomment-278743839:596,optimiz,optimization,596,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/119#issuecomment-278743839,1,['optimiz'],['optimization']
Performance,"Hi rob. Ignore my last email. I did it again using this script. #!/bin/bash; #SBATCH -p shared; #SBATCH -c 100; #SBATCH --mem=200G; #SBATCH --gres=tmp:300G; #SBATCH -t 36:00:00. module purge; module load bioinformatics; module load salmon/1.10.1. cd /nobackup/qkdf72/Trinity/Reads/All-H.m-reads/Trimmed/. # Set the path to the Salmon index; salmon_index=""/nobackup/qkdf72/Trinity/Reads/All-H.m-reads/Trimmed/salmon_index"". # Set the path to the directory containing all the FASTQ files; fastq_dir=""/nobackup/qkdf72/Trinity/Reads/All-H.m-reads/Trimmed"". # Create an array of left and right read files; left_files=(; P1_H.m_1_221020_L002_R1.fastq.gz P1_H.m_21-29_221020_L002_R1.fastq.gz P2-4-10_221020_L002_R1.fastq.gz P2-6-12_221020_L002_R1.fastq.gz P3_40-48_221020_L002_R1.fastq.gz; P1_H.m_15-23_221020_L002_R1.fastq.gz P1_H.m_24-32_221020_L002_R1.fastq.gz P2-44-51_221020_L002_R1.fastq.gz P3_36-44_221020_L002_R1.fastq.gz P3_41-49_221020_L002_R1.fastq.gz; P1_H.m_16-24_221020_L002_R1.fastq.gz P1_H.m_26-34_221020_L002_R1.fastq.gz P2-45-54_221020_L002_R1.fastq.gz P3_37-46_221020_L002_R1.fastq.gz P3_42-50_221020_L002_R1.fastq.gz; P1_H.m_18-26_221020_L002_R1.fastq.gz P2-10-17_221020_L002_R1.fastq.gz P2-46-53_221020_L002_R1.fastq.gz P3_38-45_221020_L002_R1.fastq.gz P3_43-52_221020_L002_R1.fastq.gz; P1_H.m_19-27_221020_L002_R1.fastq.gz P2-11-18_221020_L002_R1.fastq.gz P2-5-11_221020_L002_R1.fastq.gz P3_39-47_221020_L002_R1.fastq.gz; ). right_files=(; P1_H.m_1_221020_L002_R2.fastq.gz P1_H.m_21-29_221020_L002_R2.fastq.gz P2-4-10_221020_L002_R2.fastq.gz P2-6-12_221020_L002_R2.fastq.gz P3_40-48_221020_L002_R2.fastq.gz; P1_H.m_15-23_221020_L002_R2.fastq.gz P1_H.m_24-32_221020_L002_R2.fastq.gz P2-44-51_221020_L002_R2.fastq.gz P3_36-44_221020_L002_R2.fastq.gz P3_41-49_221020_L002_R2.fastq.gz; P1_H.m_16-24_221020_L002_R2.fastq.gz P1_H.m_26-34_221020_L002_R2.fastq.gz P2-45-54_221020_L002_R2.fastq.gz P3_37-46_221020_L002_R2.fastq.gz P3_42-50_221020_L002_R2.fastq.gz; P1_H.m_18-26_221020_L002_R2.fa",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/870#issuecomment-1695989396:199,load,load,199,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/870#issuecomment-1695989396,2,['load'],['load']
Performance,"Hi rob... Yep, I found it with a binary search of the fasta reference file. On Friday, October 9, 2015, Rob Patro notifications@github.com wrote:. > Thanks for reporting this. Certainly, failure should be more apparent. Out; > of curiosity, is the failure in building the index? It looks like loading; > the index didn't work, so was the space character that caused the problem; > in your reference file?; > ; > --Rob; > ; > —; > Reply to this email directly or view it on GitHub; > https://github.com/COMBINE-lab/salmon/issues/22#issuecomment-146996488.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/22#issuecomment-147008848:293,load,loading,293,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/22#issuecomment-147008848,1,['load'],['loading']
Performance,"Hi vals,; I don't know the correlation between Salmon and featureCounts pipelines. However, I've just done similar counting with htseq-count (-m union) . The result of gene number is similar (just slightly higher) to featureCounts (w/o multimapped reads). ; https://flic.kr/p/RXy39z; As far as I can tell, count-based methods performs similarly. The number of detected gene is within expectation.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/120#issuecomment-279985466:326,perform,performs,326,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/120#issuecomment-279985466,1,['perform'],['performs']
Performance,"Hi! I'm really sorry for taking so long to get back to you; things have been quite hectic this semester. The reason it's not being show is because it's been placed in a parameter group that is not made visible by default; the `--posBias` option itself is still available. It's definitely still experimental in that it has not been tested nearly as thoroughly as the other bias models. However, it is useable. Once we have performed more testing, it will migrate into the normal options and be better documented. If you gather any useful data while using this flag, we'd love some feedback!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/191#issuecomment-367448963:422,perform,performed,422,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/191#issuecomment-367448963,1,['perform'],['performed']
Performance,"Hi, ; I am writing here, because I think this issue is relevant to both @rob-p and @kvittingseerup. I ran my salmon analysis twice with the most recent gencode annotation [https://www.gencodegenes.org/releases/current.html](url) -> PRI. Once with the `--keepDuplicates` option in the indexing and once without (bec I read this post late..). ; When loadind the data into IsoformSwithcAnalyzer the first time (w/o `--keepDuplicates`), I received the following warning message, ""The annotation (count matrix and isoform annotation) contain differences in which isoforms are analyzed... 875 more isoforms than the count matrix..."". Following the run with `--keepDuplicates`, I now receive ""67 more isoforms than the count matrix"". If I am using the `--keepDuplicates` option, what exactly are there 67 isforms?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/214#issuecomment-410512481:348,load,loadind,348,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/214#issuecomment-410512481,1,['load'],['loadind']
Performance,"Hi, I have some kind the same error. I download the prebuild index from refgenie and I got exactly the same error message. . refgenie pull hg38/salmon_sa_index <- I downloaded the 16Gb of the index files. [2020-05-04 21:30:58.648] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2020-05-04 21:30:58.648] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2020-05-04 21:30:58.648] [jointLog] [info] Usage of --validateMappings, without --hardFilter implies use of range factorization. rangeFactorizationBins is being set to 4; [2020-05-04 21:30:58.648] [jointLog] [info] Usage of --validateMappings implies a default consensus slack of 0.2. Setting consensusSlack to 0.2.; [2020-05-04 21:30:58.648] [jointLog] [info] parsing read library format; [2020-05-04 21:30:58.648] [jointLog] [info] There is 1 library.; [2020-05-04 21:30:58.701] [jointLog] [info] Loading Quasi index; Exception : [rapidjson internal assertion failure: IsObject()]; salmon quant was invoked improperly.; For usage information, try salmon quant --help; Exiting. The son files of the index show this;; ls -lrth *json; -rwxrwxrwx 1 usr usr 1007 dic 14 00:41 info.json; -rwxrwxrwx 1 usr usr 96 dic 14 00:44 versionInfo.json. Any idea would be really appreciated,. Kind regards, ; Fer",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/251#issuecomment-623664770:1000,Load,Loading,1000,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/251#issuecomment-623664770,1,['Load'],['Loading']
Performance,"Hi, Rob, thanks for the quick reply! By the way, great job on salmon!. Using ./ did fix the issue. About the stdout issue, I'm running:. ~/programs/Salmon-0.7.2_linux_x86_64/bin/salmon quant -i /data/reference/salmon/gencode.grch37.v19/ -r test.fastq --seqBias --gcBias --posBias -p 12 --geneMap /data/reference/salmon/gencode.grch37.v19/geneMap.txt --libType U -o x --writeMappings > out.sam. and not all messages are output to stderr (I'm not using 2> ). The ones starting with ### do, but others end up in out.sam. out.sam starts with:. ESC[1m[2016-09-14 11:37:38.908] [jointLog] [info] parsing read library format; ESC[00mESC[1m[2016-09-14 11:37:38.908] [jointLog] [info] There is 1 library.; ESC[00mESC[1m[2016-09-14 11:37:43.996] [jointLog] [info] Loading Quasi index; ESC[00mESC[1m[2016-09-14 11:37:43.996] [jointLog] [info] Loading 32-bit quasi index; ESC[00mESC[1m[2016-09-14 11:37:43.996] [stderrLog] [info] Loading Suffix Array ; ESC[00mESC[1m[2016-09-14 11:38:06.669] [stderrLog] [info] Loading Transcript Info ; ESC[00mESC[1m[2016-09-14 11:38:12.374] [stderrLog] [info] Loading Rank-Select Bit Array; ESC[00mESC[1m[2016-09-14 11:38:12.444] [stderrLog] [info] There were 95309 set bits in the bit array; ESC[00mESC[1m[2016-09-14 11:38:12.700] [stderrLog] [info] Computing transcript lengths; ESC[00mESC[1m[2016-09-14 11:38:12.700] [stderrLog] [info] Waiting to finish loading hash; ESC[00mESC[1m[2016-09-14 11:39:49.792] [stderrLog] [info] Successfully loaded position hash; ESC[00mESC[1m[2016-09-14 11:39:49.792] [stderrLog] [info] Done loading index; ESC[00mESC[1m[2016-09-14 11:39:49.792] [jointLog] [info] done; ESC[00mESC[1m[2016-09-14 11:39:49.792] [jointLog] [info] Index contained 95309 targets; ESC[00mESC[33mESC[1m[2016-09-14 11:40:18.128] [jointLog] [warning] Fragment GC bias correction is currently only implemented for paired-end libraries. Disabling fragment GC bias correction for this run; ESC[00m@HD VN:1.0 SO:unknown",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/90#issuecomment-247078586:754,Load,Loading,754,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/90#issuecomment-247078586,8,"['Load', 'load']","['Loading', 'loaded', 'loading']"
Performance,"Hi,. I'm working on a GNU/Linux operating system ""4.19.10-200.fc28.x86_64"". Herewith the detailed information on CPU:; Architecture: x86_64; CPU op-mode(s): 32-bit, 64-bit; Byte Order: Little Endian; CPU(s): 48; On-line CPU(s) list: 0-47; Thread(s) per core: 1; Core(s) per socket: 12; Socket(s): 4; NUMA node(s): 8; Vendor ID: AuthenticAMD; CPU family: 16; Model: 9; Model name: AMD Opteron(tm) Processor 6176; Stepping: 1; CPU MHz: 2300.000; CPU max MHz: 2300.0000; CPU min MHz: 800.0000; BogoMIPS: 4600.38; Virtualization: AMD-V; L1d cache: 64K; L1i cache: 64K; L2 cache: 512K; L3 cache: 5118K; NUMA node0 CPU(s): 0-5; NUMA node1 CPU(s): 6-11; NUMA node2 CPU(s): 12-17; NUMA node3 CPU(s): 18-23; NUMA node4 CPU(s): 24-29; NUMA node5 CPU(s): 30-35; NUMA node6 CPU(s): 36-41; NUMA node7 CPU(s): 42-47. Best regards,; Jamal.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/458#issuecomment-562069760:537,cache,cache,537,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/458#issuecomment-562069760,4,['cache'],['cache']
Performance,"Hi,; Basically Alevin performs CB sequence correction within 1 distance hamming ball, the intuition being the set of real CB should ideally be more than 1 edit distance away.; Here I think the x axis gives you the count of reads for a CB before sequence correction and on y axis post sequence correction. Hope it helps",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/488#issuecomment-591733839:22,perform,performs,22,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/488#issuecomment-591733839,1,['perform'],['performs']
Performance,Hi. I'm having a similar issue. When I run the Salmon exec I get:. `MacBook-Pro-31:~ alex$ /Users/alex/Desktop/Code/Salmon-v0.8.0_macOS_10.12/bin/salmon ; exit;; dyld: Library not loaded: /usr/local/opt/tbb/lib/libtbbmalloc_proxy.dylib; Referenced from: /Users/alex/Desktop/Code/Salmon-v0.8.0_macOS_10.12/bin/salmon; Reason: image not found; Abort trap: 6; logout; `. I'm running Sierra 10.12.2. Can you advise? What do I specifically need to do to get Salmon to work?. Thanks.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/117#issuecomment-279257362:180,load,loaded,180,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/117#issuecomment-279257362,1,['load'],['loaded']
Performance,"Hrmm, I seem to be able to load and map against that index (though I'm testing with the latest develop version). Is there anything specific about the machines / vms where this is failing versus succeeding?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/321#issuecomment-442557809:27,load,load,27,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/321#issuecomment-442557809,1,['load'],['load']
Performance,"I agree – I wasn’t aware of that one. I’ve tested that and it has the same effect as the other flag, performance looks good.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/966#issuecomment-2416748677:101,perform,performance,101,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/966#issuecomment-2416748677,1,['perform'],['performance']
Performance,"I also tried on the `testing` image. For more detail, here are the steps performed (perhaps taking a look at the installed packages will highlight a difference, as I did this from a clean testing Docker image, so my environment had nothing else in it). ### Attempt to reproduce segfault on Debian:testing. ```{bash}; $ docker pull debian:testing. $ docker run -it debian:testing. $ apt-get update. $ apt-get install build-essential git libboost-all-dev liblzma-dev libbz2-dev cmake zlib1g-dev curl unzip wget libcurl4-openssl-dev. $ git clone https://github.com/COMBINE-lab/salmon.git; $ cd salmon; $ mkdir build && cd build; $ cmake -DNO_IPO=TRUE .. # GCC still doesn't handle LTO robustly; $ make -j8; $ make install; $ make test; ```. which leads to the output. ```; root@fd877e359439:/salmon/build# make install; [ 7%] Built target libcereal; [ 13%] Built target libtbb; [ 16%] Built target ntcard; [ 19%] Built target graphdump; [ 27%] Built target twopaco; [ 29%] Built target ksw2pp_sse2; [ 32%] Built target ksw2pp_sse4; [ 37%] Built target ksw2pp_basic; [ 38%] Built target ksw2pp; [ 59%] Built target puffer; [ 73%] Built target salmon_core; [ 76%] Built target alevin_core; [ 77%] Built target UnitTestsMain; [ 81%] Built target unitTests; [100%] Built target salmon; Install the project...; -- Install configuration: ""Release""; -- Installing: /salmon/lib/libntcard.a; -- Installing: /salmon/lib/ntcard/ntcard-targets.cmake; -- Installing: /salmon/lib/ntcard/ntcard-targets-release.cmake; -- Installing: /salmon/lib/libgraphdump.a; -- Installing: /salmon/lib/graphdump/graphdump-targets.cmake; -- Installing: /salmon/lib/graphdump/graphdump-targets-release.cmake; -- Installing: /salmon/lib/libtwopaco.a; -- Installing: /salmon/lib/twopaco/twopaco-targets.cmake; -- Installing: /salmon/lib/twopaco/twopaco-targets-release.cmake; -- Installing: /salmon/lib/libtbb.so; -- Installing: /salmon/lib/libtbb.so.12; -- Installing: /salmon/lib/libtbb.so.12.5; -- Installing: /salmon/lib/libtbbmalloc",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463312554:73,perform,performed,73,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463312554,1,['perform'],['performed']
Performance,"I am also confused about it. It seems that peudosam can not be converted into bam because of lacking of location. If I just use the. ```bash; samtools sort -O bam -@ 30 -o sort.bam Mapping.sam . samtools index sort.bam; ```. I can not load the sort.bam into IGV. But I did find the two issue: #475 and #38 , which mentioned bam file.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/528#issuecomment-638026422:235,load,load,235,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/528#issuecomment-638026422,1,['load'],['load']
Performance,"I am assuming what you are looking for is the ""effective lengths"" of the transcripts i.e. not just the original transcript lengths but instead corrected based on the quantification model. I think it's going to be tricky to generate that because of two major reasons: (1) salmon model does not perform length correction in single-cell mode mainly due to 3' single-end sequencing of the read it's hard to reliably estimate the fragment lengths (2) salmon in single-cell mode performs quantification at gene-level which makes it harder to predict effective length of the transcripts.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/693#issuecomment-916889943:293,perform,perform,293,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/693#issuecomment-916889943,2,['perform'],"['perform', 'performs']"
Performance,I am getting the same error on the latest binary distro. I am running CentOS Linux 7 (Core).; Does this affect the performance?,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/277#issuecomment-440346529:115,perform,performance,115,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/277#issuecomment-440346529,1,['perform'],['performance']
Performance,"I don't completely disagree, and don't speak for this project as anything other than a user, but `until 'salmon [args]' 2>1 | grep -m 1 ""Starting optimizer""; do : ; done` seems pretty unix-y to me.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/189#issuecomment-361748694:146,optimiz,optimizer,146,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/189#issuecomment-361748694,1,['optimiz'],['optimizer']
Performance,"I don't mind what you do, but currently it says `cite` is a <COMMAND>, but it isn't?. ```; Commands:; cite Show salmon citation information; index Create a salmon index; quant Quantify a sample; swim Perform super-secret operation; ```. ie. `salmon cite` does *not* `Show salmon citation information` - that's all :)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/149#issuecomment-325164357:200,Perform,Perform,200,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/149#issuecomment-325164357,1,['Perform'],['Perform']
Performance,"I explicitly preallocate the output array/vector for pcre and re2. Boost regex doesn't seem to offer that (at least, I don't know). Regarding xpressive: yeah, what a disappointment. And I don't actually save the capture with xpressive. I thought the automaton was entirely generated and optimize at compile time. Apparently creating an automaton with C++ template system must be really hard because the generated code is garbage. Or I am using it wrong. In any case, xpressive as I use it is entirely static (I haven't tested the dynamic version). So it is not useful in our case. I was just curious if it could match hand crafted code. What was I thinking!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/734#issuecomment-1024206420:287,optimiz,optimize,287,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/734#issuecomment-1024206420,1,['optimiz'],['optimize']
Performance,"I faced the same problem and found a simple solution. The trick is at line 585 of the cMakeList.txt. ""if (${TBB_VERSION} VERSION_GREATER_EQUAL 2018.0)"". It checks if you have tbb version 2018 or above. If you install tbb BEFORE running cmake, it will fulfill the requirement and bypass installing tbb in the make command, hence bypass the error. The solution:; 1. Delete the salmon folder and download a fresh one from github; 2. sudo apt update (this step is very important, to update the packages to be above version 2018) ; 3. sudo apt-get install libtbb-dev; 4. (Optional) apt-cache policy libtbb-dev (check the version of libtbb, it should be 2019 or above); 5. Then follows the standard installation (cmake, make etc.) The error should disappear and compile successfully. Thanks!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/497#issuecomment-610977958:581,cache,cache,581,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/497#issuecomment-610977958,1,['cache'],['cache']
Performance,"I give .fastq directly to salmon to perform the alignment and I use the --writemapping option to have the bam on which performing other operations. I am focused on flags and mapq (field 3 and 5, respectively). I compared flags (field 3) between salmon and star (alignment performed on genome) and reads flagged as non-primary are comparable. I thought that salmon would assign counts to transcripts based on ""primary alignments"", but, filtering out secondary alignments I cannot reproduce counts in quant.sf. My question is: quant.sf is generated considering the output of --writemapping ? Thanks again for your quick response",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/799#issuecomment-1245700129:36,perform,perform,36,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/799#issuecomment-1245700129,3,['perform'],"['perform', 'performed', 'performing']"
Performance,"I just redownloaded and extracted and tried again, and unfortunately the problem persists =/. ```; ...; [2016-01-02 17:47:51.342] [jointLog] [info] iteration = 1600 | max rel diff. = 0.0133376; [2016-01-02 17:47:51.443] [jointLog] [info] iteration = 1630 | max rel diff. = 0.00771098; [2016-01-02 17:47:51.447] [jointLog] [info] Finished optimizer; [2016-01-02 17:47:51.448] [jointLog] [info] writing output. Computing gene-level abundance estimates; [2016-01-02 17:47:51.678] [jointLog] [warning] NOTE: Read Lib [( /nfs/research2/teichmann/valentine/detection-comparison/salmon0.4.2-comparison/mouse/SRP057125_SRS936134_1.fastq, /nfs/research2/teichmann/valentine/detection-comparison/salmon0.4.2-comparison/mouse/SRP057125_SRS936134_2.fastq )] :. Greater than 5% of the alignments (but not, necessarily reads) disagreed with the provided library type; check the file: SRP057125_SRS936134_salmon_out/libFormatCounts.txt for details. There were 104534 transcripts mapping to 44034 genes; Parsed 104000 expression lines; done; Aggregating expressions to gene level . . . done; Segmentation fault (core dumped); ```. If you want I can upload index and a couple of fastq files somewhere so you can try?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/34#issuecomment-168412271:338,optimiz,optimizer,338,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/34#issuecomment-168412271,1,['optimiz'],['optimizer']
Performance,"I just tried it on a fresh docker image of ubuntu 16.04 and am unable to install salmon. After `apt-get install build-essential cmake g++ gcc curl autoconfig libdevsufsort-dev`, `cmake -DFETCH_BOOST=TRUE` passes, but `make install` fails with following output:; ```; [ 6%] Built target liblzma; [ 12%] Built target libbz2; [ 18%] Built target libjemalloc; [ 19%] Performing download step (verify and extract) for 'libdivsufsort'; -- verifying file...; file='/home/salmon-0.10.2/external/libdivsufsort.zip'; -- verifying file... warning: did not verify file - no URL_HASH specified?; -- extracting...; src='/home/salmon-0.10.2/external/libdivsufsort.zip'; dst='/home/salmon-0.10.2/external/libdivsufsort-master'; CMake Error at /home/salmon-0.10.2/libdivsufsort-prefix/src/libdivsufsort-stamp/extract-libdivsufsort.cmake:11 (message):; error: file to extract does not exist:; '/home/salmon-0.10.2/external/libdivsufsort.zip'. CMakeFiles/libdivsufsort.dir/build.make:90: recipe for target 'libdivsufsort-prefix/src/libdivsufsort-stamp/libdivsufsort-download' failed; make[2]: *** [libdivsufsort-prefix/src/libdivsufsort-stamp/libdivsufsort-download] Error 1; CMakeFiles/Makefile2:137: recipe for target 'CMakeFiles/libdivsufsort.dir/all' failed; make[1]: *** [CMakeFiles/libdivsufsort.dir/all] Error 2; Makefile:160: recipe for target 'all' failed; make: *** [all] Error 2; ```; It confuses me, as the error seems to be in the libdevsufsort, which should be installed.; (sorry for all the mess, really)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/250#issuecomment-404455397:363,Perform,Performing,363,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/250#issuecomment-404455397,1,['Perform'],['Performing']
Performance,"I just tried the /dev/fd/0 approach. First I ran. ```; salmon quant -i /nfs/research2/teichmann/reference/mus-musculus/salmon/quasi/mouse_cdna_38.p3.78_repbase_ercc.fa -l IU -1 reads_1.fastq -2 reads_2.fastq -o normal_salmon_out; ```. In this case the following is the content of the `salmon_quant.log`. ```; [2016-01-03 00:33:37.001] [jointLog] [info] parsing read library format; [2016-01-03 00:33:37.510] [jointLog] [info] Loading Quasi index; [2016-01-03 00:33:53.646] [jointLog] [info] done; [2016-01-03 00:34:14.501] [jointLog] [info] Computed 13742 rich equivalence classes for further processing; [2016-01-03 00:34:14.501] [jointLog] [info] Counted 335230 total reads in the equivalence classes; [2016-01-03 00:34:14.501] [fileLog] [info]; At end of round 0; ==================; Observed 3835342 total fragments (3835342 in most recent round). [2016-01-03 00:34:20.992] [jointLog] [warning] Only 335230 fragments were mapped, but the number of burn-in fragments was set to 5000000.; The effective lengths have been computed using the observed mappings. [2016-01-03 00:34:20.992] [jointLog] [info] Mapping rate = 8.74055%. [2016-01-03 00:34:20.992] [jointLog] [info] finished quantifyLibrary(); [2016-01-03 00:34:20.992] [jointLog] [info] Starting optimizer; [2016-01-03 00:34:21.028] [jointLog] [info] Marked 0 weighted equivalence classes as degenerate; [2016-01-03 00:34:21.030] [jointLog] [info] iteration = 0 | max rel diff. = 23.4889; [2016-01-03 00:34:21.167] [jointLog] [info] iteration = 100 | max rel diff. = 0.150549; [2016-01-03 00:34:21.304] [jointLog] [info] iteration = 200 | max rel diff. = 0.0517672; [2016-01-03 00:34:21.447] [jointLog] [info] iteration = 300 | max rel diff. = 0.0368208; [2016-01-03 00:34:21.578] [jointLog] [info] iteration = 400 | max rel diff. = 0.0237254; [2016-01-03 00:34:21.705] [jointLog] [info] iteration = 500 | max rel diff. = 0.0147784; [2016-01-03 00:34:21.834] [jointLog] [info] iteration = 600 | max rel diff. = 0.0131134; [2016-01-03 00:34:21",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/29#issuecomment-168447784:426,Load,Loading,426,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/29#issuecomment-168447784,1,['Load'],['Loading']
Performance,"I managed to figure out what I assume is the up-to-date way of doing things. I will post the code that works for me here in case anyone else comes across this issue:; ```; suppressPackageStartupMessages({; library(fishpond); library(tximport); library(devtools); library(ggplot2); library(patchwork); # Just install Seurat like normal. Tutorial's allusion to a ""spatial"" branch appears to be outdated.; library(Seurat); }). # navigate to data directory; wkdir <- ""path/to/alevin_data/""; setwd(wkdir). # load in alevin output; files <- file.path(""alevin_out/alevin/quants_mat.gz""); file.exists(files). # set prefix for output files; prefix = ""alevin"". # tximport loads the alevin data into R; txi <- tximport(files = files, type = ""alevin""). # Creating a Seurat object with spatial assay; assay <- ""Spatial""; brain <- CreateSeuratObject(counts = txi$counts, project = ""SPATIAL"", assay = assay); brain. # loading the 10x image data; seqdir <- ""path/to/10x_imaging_data/""; image.data <- Read10X_Image(paste0(seqdir,""spatial/"")). # Since the names of alevin cb is different from 10x; # we rename the cells and filter the image data; # to have the metadata for only quantified cells; image.data@boundaries$centroids@cells <- gsub(""-1"", """", image.data@boundaries$centroids@cells); common.cells <- intersect(Cells(x = brain), image.data@boundaries$centroids@cells). # Subset the centroids object; centroids <- image.data@boundaries$centroids. # Find indices of common cells; common_indices <- which(centroids@cells %in% common.cells). # Subset the cells and coords slots; centroids@cells <- centroids@cells[common_indices]; centroids@coords <- centroids@coords[common_indices, ]. # Update the image.data object with the subsetted centroids; image.data@boundaries$centroids <- centroids. # Update the brain object accordingly; brain <- subset(brain, cells = common.cells). # adding image data to Seurat object; DefaultAssay(object = image.data) <- ""Spatial""; brain@images[['slice']] <- image.data; ```; The re",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/942#issuecomment-2204802696:503,load,load,503,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/942#issuecomment-2204802696,3,['load'],"['load', 'loading', 'loads']"
Performance,"I processed the data above using the latest salmon from the develop branch; (the release candidate for 1.3.0), and I got the following time (used 8; threads, so timing is not directly comparable). ```; 4604.57user 43.64system 9:24.15elapsed 823%CPU; ```. The whole log is. ```; [2020-06-15 23:51:54.747] [jointLog] [info] setting maxHashResizeThreads to; 8; [2020-06-15 23:51:54.747] [jointLog] [info] Fragment incompatibility prior; below threshold. Incompatible fragments will be ignored.; [2020-06-15 23:51:54.747] [jointLog] [info] Usage of --validateMappings; implies use of minScoreFraction. Since not explicitly specified, it is; being set to 0.65; [2020-06-15 23:51:54.747] [jointLog] [info] Usage of --validateMappings; implies a default consensus slack of 0.2. Setting consensusSlack to 0.35.; [2020-06-15 23:51:54.747] [jointLog] [info] parsing read library format; [2020-06-15 23:51:54.747] [jointLog] [info] There is 1 library.; [2020-06-15 23:51:54.814] [jointLog] [info] Loading pufferfish index; [2020-06-15 23:51:54.814] [jointLog] [info] Loading dense pufferfish index.; [2020-06-15 23:51:55.555] [jointLog] [info] done; [2020-06-15 23:51:55.555] [jointLog] [info] Index contained 116,248 targets; [2020-06-15 23:51:55.588] [jointLog] [info] Number of decoys : 0; [2020-06-16 00:00:59.666] [jointLog] [info] Computed 344,764 rich; equivalence classes for further processing; [2020-06-16 00:00:59.666] [jointLog] [info] Counted 12,956,134 total reads; in the equivalence classes; [2020-06-16 00:00:59.673] [jointLog] [warning] 0.0736383% of fragments were; shorter than the k used to build the index.; If this fraction is too large, consider re-building the index with a; smaller k.; The minimum read size found was 1. [2020-06-16 00:00:59.673] [jointLog] [info] Number of mappings discarded; because of alignment score : 134,091,887; [2020-06-16 00:00:59.673] [jointLog] [info] Number of fragments entirely; discarded because of alignment score : 2,429,390; [2020-06-16 00:00:59.673]",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/537#issuecomment-644520228:986,Load,Loading,986,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/537#issuecomment-644520228,1,['Load'],['Loading']
Performance,"I realize my mistake, I was confused by the error message.; Pseudoaligment seems to work now. [...]; [2018-08-03 20:13:23.083] [jointLog] [info] Computed 312565 rich; equivalence classes for further processing; [2018-08-03 20:13:23.083] [jointLog] [info] Counted 120065952 total; reads in the equivalence classes; [2018-08-03 20:13:23.084] [jointLog] [warning] Found 9775 reads with `N`; in the UMI sequence and ignored the reads.; Please report on github if this number is too large; [2018-08-03 20:13:23.084] [jointLog] [info] Mapping rate = 63.2442%. [2018-08-03 20:13:23.084] [jointLog] [info] finished quantifyLibrary(); [2018-08-03 20:13:26.208] [alevinLog] [info] Starting optimizer. ERROR: Txp to Gene Map not found for 203027 transcripts. Exiting(salmon). I just have a problem with my tx2gene file. Here is the head of my file:. ENST00000013125	MAP4K5; ENST00000215368	EFNA2; ENST00000200453	PPP1R15A; ENST00000202028	EPB41L1; ENST00000204679	GNPTG; ENST00000175506	ASNS; ENST00000215574	CDC34; ENST00000167106	VASH1; ENST00000074304	INPP4A; ENST00000055077	RFC2. The transcript ID is probably not consistent with the one from the; alevin output. However, I used to perform some pseudo-alignments using; salmon on bulk RNAseq with the same transcriptome references and the; same tx2gene file that I used here (postprocessed using R) and it work.; What could be wrong here? Could you provide me with an example of the; tx2gene file needed?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/264#issuecomment-410337209:680,optimiz,optimizer,680,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/264#issuecomment-410337209,2,"['optimiz', 'perform']","['optimizer', 'perform']"
Performance,"I saw no performance regressions, so 1.2.0 is built without the offending flag. Thanks for the heads up.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/500#issuecomment-612273525:9,perform,performance,9,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/500#issuecomment-612273525,1,['perform'],['performance']
Performance,"I see, we might have to tweak a bit based on the use case for `longranger basic`.; In `v0.10`, alevin should still be able to do CB correction, and attach the corrected CBs to the header of the second file, although the remaining template sequence (128 bases) from the first file might get loss, since `cellranger` was using template sequencing in only one file. Like @rob-p was saying we can work on making this step more generalized, once we confirm that the error-correction model for `cellranger` and `longranger` can be used interchangeably. In theory we can still concatenate the remaining 128 bases into an interleaved format since alevin has hidden options to provide the lengths explicitly but we have not tested this feature extensively. We will keep this at the top of our feature-request list and would inform you as soon as we have a stable version with this feature. Thanks again for the interest !!. re: *interleaved format* -- indeed an interleave format does makes sense and should be the default dumping format, but I believe since the default mode of 10x's `mkfastq` is to dump separate `FASTQ`, we should not use resources to create an interim interleaved format and then consume it downstream (since`FASTQ` itself is not very efficient), instead, in alevin we just consume the two separate `FASTQ` into our own interim data-structure to perform the downstream analysis.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/233#issuecomment-395195411:1358,perform,perform,1358,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/233#issuecomment-395195411,1,['perform'],['perform']
Performance,"I see. TopHat actually aligns the reads to the genome (using Bowtie and a strategy to perform split-read mapping). The results of TopHat, then, are meant to be used with tools like Cufflinks, which expects reads to be mapped directly to the genome rather than to the transcriptome. Salmon, on the other hand, works like tools such as RSEM / eXpress, which expect alignments to the transcriptome directly. This can be accomplished by either mapping the reads directly to the transcript sequences (using e.g. Bowtie2 / BWA-MEM) or by mapping the reads to the genome using a tool such as STAR, and telling it to project the alignments onto genomic coordinates. However, I should mention that the easiest thing to do is to simply have Salmon build and index on your transcript set and then pass it the raw (compressed) FASTQ files directly. Since Salmon provides an accurate and lightweight alignment proxy, it can accurately assess transcript abundance estimates directly from the raw (unaligned) sequenced reads. If you have questions about using either of these modes, please take a look at [the documentation](https://salmon.readthedocs.io/en/latest/). I'd also be happy to answer any other questions you might have.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/131#issuecomment-293273710:86,perform,perform,86,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/131#issuecomment-293273710,1,['perform'],['perform']
Performance,"I see. Well, this is definitely what is leading to the error. The JSON files shouldn't be empty. Can you report the output of `salmon quant` when you were building the index? It seems that the JSON files were not written correctly, which prevents proper loading of the index (and which may be indicative of other parts of the index not being properly written).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/251#issuecomment-404959801:254,load,loading,254,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/251#issuecomment-404959801,1,['load'],['loading']
Performance,"I think I figured it out! This behavior is triggered in `gamma_distribution` when the alpha parameter is nan. The issue (i.e. the reason this is going unnoticed elsewhere) is because salmon is compiled with `-Ofast` which turns on `finite-math-only` (the compiler need not handle infinite / nan values properly). So, it looks like the fix should be to insert some nan & inf checks and change the default optimization flags to O3. I should have a fix for you to try soon.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267866312:404,optimiz,optimization,404,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267866312,1,['optimiz'],['optimization']
Performance,"I think the idea of using memory-mapped IO might be useful, similar to bowtie2's `--mm` option. However, are you sure it's the index loading that's the issue? You may want to look into staging the salmon index on some local scratch space on your compute nodes as the bandwidth will be much greater than your network storage. Additionally, I tend to see IO saturation over our NFS pool from just streaming the FASTQ data to salmon, so you might still be screwed even if you take care of the index IO contribution. Your machines should likely be caching the index in RAM (if you have enough of it) after one access, but you can use a tool to force caching of the index file if you really want (https://serverfault.com/questions/43383/caching-preloading-files-on-linux-into-ram).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/319#issuecomment-442180390:133,load,loading,133,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/319#issuecomment-442180390,1,['load'],['loading']
Performance,"I think you're right wrt conda. I was able to install 1.10.2 with mamba fairly easily. We've been moving away from conda (towards mamba) but this didn't cross my mind when I was playing in my sandbox. Might be some cluster latency issues combined with conda's snail's pace causing the problem on our end. Thx for the quick replies!. Adam H. Freedman, PhD; Data Scientist; Faculty of Arts & Sciences Informatics Group; Harvard University; 38 Oxford St; Cambridge, MA 02138; phone: +001 310 415 7145; ________________________________; From: Rob Patro ***@***.***>; Sent: Sunday, October 29, 2023 11:01 AM; To: COMBINE-lab/salmon ***@***.***>; Cc: Freedman, Adam ***@***.***>; Mention ***@***.***>; Subject: Re: [COMBINE-lab/salmon] anaconda version of salmon outdated, missing decoys option (Issue #895). Hi @adamfreedman<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_adamfreedman&d=DwMCaQ&c=WO-RGvefibhHBZq3fL85hQ&r=MITI_LEJgyr1a24IMFAlSaZIPxMpOUT21T7L3fg4CjA&m=40O3raH84f_BIZ3HF7nqTYSO2FehGrGHL9b7sqT7LIpWZjFmA3BLxNDTHoz420jp&s=kxY9gCLGWZJp-dp7l31S6M5u2RuUTeWXVrKmaydpo5o&e=>,. I think this is just conda being very very very slow (and potentially broken). The following works fine for me (and finishes in ~1 minute):. mamba create -n salmon -c conda-forge -c bioconda salmon=1.10.2. Can you use the mamba resolver in your environment? Conda has become hardly usable over the years, but mamba works quite well as a fast replacement. I'll also note that I swapped the order of conda-forge and bioconda as the docs specify that bioconda should preferably come last in the list of channels. --Rob. —; Reply to this email directly, view it on GitHub<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_COMBINE-2Dlab_salmon_issues_895-23issuecomment-2D1784137337&d=DwMCaQ&c=WO-RGvefibhHBZq3fL85hQ&r=MITI_LEJgyr1a24IMFAlSaZIPxMpOUT21T7L3fg4CjA&m=40O3raH84f_BIZ3HF7nqTYSO2FehGrGHL9b7sqT7LIpWZjFmA3BLxNDTHoz420jp&s=GNiCXqUbJLM16QBJ5PNAqv-rsgDdpCpcvezPXO_riWk&e=>, or unsubscribe<",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/895#issuecomment-1784196835:223,latency,latency,223,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/895#issuecomment-1784196835,1,['latency'],['latency']
Performance,"I tried this again today with salmon 1.2.1 on CentOS 8 (with cmake 3.17.1). This time it could find libtbb but it still could not find Staden IO_LIB and libgff. In addition for it to use Boost169 it was necessary to modify the CmakeLists.txt file like so. ```; --- CMakeLists.txt.dist 2020-04-21 22:31:07.000000000 -0700; +++ CMakeLists.txt 2020-06-08 17:13:23.295499154 -0700; @@ -419,6 +419,8 @@; find_package(Boost 1.59.0 COMPONENTS iostreams filesystem system timer chrono program_options); message(""BOOST_INCLUDEDIR = ${BOOST_INCLUDEDIR}""); message(""BOOST_LIBRARYDIR = ${BOOST_LIBRARYDIR}""); +message(""Forcing Boost_FOUND to TRUE""); +set(Boost_FOUND TRUE); message(""Boost_FOUND = ${Boost_FOUND}""); endif(); ; ```. and to invoke cmake with:. ```; module load cmake; module load io_lib; module load libgff; module load libtbb; mkdir build; cd build; cmake \; -DCMAKE_VERBOSE_MAKEFILE:BOOL=ON \; -DBOOST_LIBRARYDIR=/usr/lib64/boost169 \; -DBOOST_INCLUDEDIR=/usr/include/boost169 \; -DBoost_NO_SYSTEM_PATHS=ON \; .. 2>&1 | tee cmake_2020_06_08.log; ```; Inkscape was built using cmake a couple of weeks ago on the same system and the -D flags for Boost in the cmake invocation were sufficient, there was no need to modify its CMakeLists.txt. Perhaps you might to compare that CMakeLIsts.txt with salmon's to see why theirs works and salmon's does not. I reiterate my plea for salmon's cmake file to accept some form of ROOT_LIBGFF, ROOT_LIBSTADEN, and ROOT_LIBTBB. Those modules ; were all defined but cmake could only figure out TBB this time, and for all I know it won't next time around (since it failed to do so for no apparent reason on CentOS 7). Salmon is a useful program but it has so far failed to build using existing libraries on this OS (unless extraordinary measures were applied) for CO 6, 7, and now 8! This is the information it had to work with:. ```; echo $PATH; /usr/common/modules/el8/x86_64/software/libgff/1.2-CentOS-vanilla/bin:/usr/common/modules/el8/x86_64/software/io_lib/1",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-640962684:758,load,load,758,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-640962684,4,['load'],['load']
Performance,"I'm also at a loss for exactly what could bre going on here. Specifically, this bit confused me:. > It looks like the log points to a sample that completed successfully at 19:45:18.487 before the sample at the top of the post started 19:51:56.392. So, unless the clock is messed up, it seems the successful completion (which, obviously required loading the complete index for alignment) happens *before* the exception. Further, the output you printed around the exception happens at the start of program execution, so I don't understand the timeline of events here for a single run / execution.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/512#issuecomment-618093803:345,load,loading,345,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/512#issuecomment-618093803,1,['load'],['loading']
Performance,"I've run into this (or a similar) issue attempting to install Salmon on the UC Berkeley HPC cluster. Iconv was present within one of our Python installs, but that didn't seem to have the header files, so I installed libiconv/1.16 thinking this was a dependency issue. Unfortunately this didn't seem to help. Any guidance would be greatly appreciated. Here is my build script to the point of failure:; ```sh; #!/bin/sh ; MODULE_HOME=/clusterfs/vector/home/groups/software/sl-7.x86_64; PACKAGE_NAME=salmon; GITHUB_URL=https://api.github.com/repos/COMBINE-lab/salmon/releases/latest; VERSION=$(curl -s $GITHUB_URL | \; grep '""tag_name"":' | \; cut -d : -f 2,3 | \; tr -d \"",v | \; xargs); LATEST_RELEASE=$(curl -s $GITHUB_URL | \; grep '""tarball_url""' | \; cut -d : -f 2,3 | \; tr -d \"", | \; xargs); module load gcc/7.4.0 cmake/3.15.1 boost/1.70.0-gcc libiconv/1.16; export CC=`which gcc`; export CXX=`which c++`. cd $MODULE_HOME; mkdir -p source/$PACKAGE_NAME/$VERSION; INSTALL_DIR=$MODULE_HOME/modules/$PACKAGE_NAME/$VERSION; mkdir -p $INSTALL_DIR; mkdir -p modfiles/$PACKAGE_NAME. cd source/$PACKAGE_NAME/$VERSION; wget $LATEST_RELEASE -O - | tar -xz --strip-components 1; cmake -DBOOST_ROOT=/global/software/sl-7.x86_64/modules/gcc/7.4.0/boost/1.70.0-gcc -DCMAKE_INSTALL_PREFIX=$INSTALL_DIR; make; ```; And the tail of the output from make:. ```; creating: /clusterfs/vector/home/groups/software/sl-7.x86_64/source/salmon/1.5.1/scripts/../external/pufferfish-salmon-v1.5.1/tests/compile_tests/; inflating: /clusterfs/vector/home/groups/software/sl-7.x86_64/source/salmon/1.5.1/scripts/../external/pufferfish-salmon-v1.5.1/tests/compile_tests/int128_numeric_limits.cpp ; -- fetch PUFFERFISH exit code 0; -- Found ZLIB: /usr/lib64/libz.so (found version ""1.2.11"") ; -- Performing Test Iconv_IS_BUILT_IN; -- Performing Test Iconv_IS_BUILT_IN - Failed; CMake Error at /global/home/groups/consultsw/sl-7.x86_64/modules/cmake/3.15.1/share/cmake-3.15/Modules/FindPackageHandleStandardArgs.cmake:137 (message",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/453#issuecomment-862737315:804,load,load,804,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/453#issuecomment-862737315,1,['load'],['load']
Performance,"I, too, would like to see the relative performance of the two libraries. The only challenge is in making the comparison apples-to-apples (i.e. enabling multi-threaded parsing in seqtk with minimal overhead — a concurrent queue is cheap, but not free).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/29#issuecomment-152828910:39,perform,performance,39,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/29#issuecomment-152828910,4,"['concurren', 'multi-thread', 'perform', 'queue']","['concurrent', 'multi-threaded', 'performance', 'queue']"
Performance,"ISR --chromium -p 4 -o BM_1/alevin -1 ./BM_1/run1/bm_S10_L001_R1_001.fastq.gz -2 ./BM_1/run1/bm_S10_L001_R2_001.fastq.gz --maxHashResizeThreads 2 -i /u/user/ref/cellranger/salmon/transcripts_index --tgMap tx2gene.txt; Starting program: /u/user/local/bin/salmon alevin -l ISR --chromium -p 4 -o BM_1/alevin -1 ./BM_1/run1/bm_S10_L001_R1_001.fastq.gz -2 ./BM_1/run1/bm_S10_L001_R2_001.fastq.gz --maxHashResizeThreads 2 -i /u/user/ref/cellranger/salmon/transcripts_index --tgMap tx2gene.txt; [Thread debugging using libthread_db enabled]; Using host libthread_db library ""/lib/x86_64-linux-gnu/libthread_db.so.1"".; warning: File ""/u/user/local/lib64/libstdc++.so.6.0.21-gdb.py"" auto-loading has been declined by your `auto-load safe; -path' set to ""$debugdir:$datadir/auto-load"".; To enable execution of this file add; add-auto-load-safe-path /u/user/local/lib64/libstdc++.so.6.0.21-gdb.py; line to your configuration file ""/u/user/.gdbinit"".; To completely disable this security protection add; set auto-load safe-path /; line to your configuration file ""/u/user/.gdbinit"".; For more information about this security protection see the; ""Auto-loading safe path"" section in the GDB manual. E.g., run from the shell:; info ""(gdb)Auto-loading safe path""; [New Thread 0x7fff7dbff700 (LWP 21437)]; [Thread 0x7fff7dbff700 (LWP 21437) exited]; Version Info: Could not resolve upgrade information in the alotted time.; Check for upgrades manually at https://combine-lab.github.io/salmon; [New Thread 0x7ffefcfff700 (LWP 21653)]; Logs will be written to BM_1/alevin/logs; [New Thread 0x7ffe7cffe700 (LWP 21654)]; [New Thread 0x7ffdfcffd700 (LWP 21655)]; [New Thread 0x7ffd7cffc700 (LWP 21656)]; ### salmon (single-cell-based) v0.10.3; ### [ program ] => salmon; ### [ command ] => alevin; ### [ libType ] => { ISR }; ### [ chromium ] => { }; ### [ threads ] => { 4 }; ### [ output ] => { BM_1/alevin }; ### [ mates1 ] => { ./BM_1/run1/bm_S10_L001_R1_001.fastq.gz }; ### [ mates2 ] => { ./BM_1/run1/bm_S10_L001_R2_",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-396078627:2040,load,load,2040,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-396078627,1,['load'],['load']
Performance,"If i use the smaller set of barcodes, then I progress further. However, I still receive an error message (and there no **quants_mat_rows.txt** file):. ```; [2021-07-13 13:59:07.109] [alevinLog] [info] Total 0.00 UMI after deduplicating.; [2021-07-13 13:59:07.109] [alevinLog] [info] Total 0 BiDirected Edges.; [2021-07-13 13:59:07.109] [alevinLog] [info] Total 0 UniDirected Edges.; [2021-07-13 13:59:07.134] [alevinLog] [info] Finished optimizer; /var/spool/slurmd/job3050767/slurm_script: line 23: 10494 Floating point exception../../Ref_Generation/salmon-1.5.1_linux_x86_64/bin/salmon alevin -l ISF --chromium -1 $R1 -2 $R2 -i $REF -p 4 -o $ID --tgMap $MAP --whitelist $CBWL. ```. If the barcode is on the opposite read, then I am not sure if I should really be using the reverse or reverse complement (possibly even for the full barcode list)?. However, for the sake of this discussion, I will now test not providing any white list. If that works, then I will close the ticket again. **Update (7/14/2021)**: I have added the full log file here: [cluster_log.log](https://github.com/COMBINE-lab/salmon/files/6819402/cluster_log.log)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/682#issuecomment-879497561:437,optimiz,optimizer,437,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/682#issuecomment-879497561,1,['optimiz'],['optimizer']
Performance,"In terms of an intermediate update:. **Setting 1**:. _Command 1_:; `/path/to/salmon alevin -l ISF --chromium -1 $R1 -2 $R2 -i $REF -p 4 -o $ID --tgMap $MAP`; _End of Log 1_:; ```; [2021-07-13 20:12:34.651] [alevinLog] [info] Starting white listing of 814 cells; [2021-07-13 20:12:34.651] [alevinLog] [info] Starting to make feature Matrix; [2021-07-13 20:12:34.654] [alevinLog] [info] Done making feature Matrix; [2021-07-13 20:12:35.447] [alevinLog] [info] Finished white listing; [2021-07-13 20:12:36.158] [alevinLog] [info] Finished optimizer; 0.0408521	8.9925e-05	0.000114595	636780	18682.9	; 0.0290163	6.61624e-05	0.000111685	230922	8010.3	; ```; _Size of quants_mat_rows.txt 1_: 814 lines/barcodes. **Setting 2:**:; _Command 1_:; `/path/to/salmon alevin -l ISR --chromium -1 $R1 -2 $R2 -i $REF -p 4 -o $ID --tgMap $MAP`; _End of Log 1_:; ```; [2021-07-14 09:51:38.564] [alevinLog] [info] Starting white listing of 814 cells; [2021-07-14 09:51:38.564] [alevinLog] [info] Starting to make feature Matrix; [2021-07-14 09:51:38.566] [alevinLog] [info] Done making feature Matrix; [2021-07-14 09:51:39.347] [alevinLog] [info] Finished white listing; [2021-07-14 09:51:39.541] [alevinLog] [info] Finished optimizer; [2021-07-14 09:51:39.564] [jointLog] [warning] NOTE: Read Lib [[ ../Reads/5309-CT-2_S01_L005_R1_001.fastq.gz, ../Reads/5309-CT-2_S01_L005_R2_001.fastq.gz]] :. Greater than 5% of the fragments disagreed with the provided library type; check the file: 5309-CT-2/lib_format_counts.json for details. 0.0408521	8.9925e-05	0.000114595	636780	18682.9	; 0.0290163	6.61624e-05	0.000111685	230922	8010.3	; ```; _Size of quants_mat_rows.txt 1_: 814 lines/barcodes. Technically, this means that the program ran without generating an error message, but this seems strange to me. So, I think I would prefer to keep the issue open a little bit longer.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/682#issuecomment-880273749:536,optimiz,optimizer,536,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/682#issuecomment-880273749,2,['optimiz'],['optimizer']
Performance,Interesting. It got past the index loading step for me in under 10 seconds at least. I could time it more properly if you like after this run has completed.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/54#issuecomment-204085138:35,load,loading,35,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/54#issuecomment-204085138,1,['load'],['loading']
Performance,"Is there a different binary somewhere perhaps? . I a downloading: . https://github.com/COMBINE-lab/salmon/releases/download/v0.8.2/Salmon-0.8.2_macOS_10.12.tar.gz. And get this: . Salmon-0.8.2_macOS_10.12.tar.gz; 100%[=====================================================>] 2.64M ; 326KB/s in 6.6s . 2017-04-18 09:43:33 (409 KB/s) - 'Salmon-0.8.2_macOS_10.12.tar.gz' saved; [2766997/2766997] . MacBook-Air:salmon jjv5$ tar zxf Salmon-0.8.2_macOS_10.12.tar.gz . MacBook-Air:salmon jjv5$ cd Salmon-0.8.2_macOX_10.12/bin/ . MacBook-Air:bin jjv5$ ./salmon -h . salmon(43548,0x7fffdc0c23c0) malloc: *** malloc_zone_unregister() failed; for 0x7fffdc0b8000 . Salmon v0.8.2 . Usage: salmon -h|--help or . salmon -v|--version or . salmon -c|--cite or . salmon [--no-version-check] <COMMAND> [-h | options] . Commands: . cite Show salmon citation information . index Create a salmon index . quant Quantify a sample . swim Perform super-secret operation . MacBook-Air:bin jjv5$ sw_vers . ProductName: Mac OS X . ProductVersion: 10.12.4 . BuildVersion: 16E195. On 2017-04-18 09:33, Rob Patro wrote:. > Hi @jjv5 [1], ; > ; > This error should be fixed. The binary works for me without error (or that strange jemalloc warning) on OS X 10.12.4. The relevant library should be statically linked in, so I doubt it's a path problem. You could also try the conda build [2] to see if that works for you. ; > ; > --; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub [3], or mute the thread [4].; . Links:; ------; [1] https://github.com/jjv5; [2] https://anaconda.org/bioconda/salmon; [3]; https://github.com/COMBINE-lab/salmon/issues/103#issuecomment-294845429; [4]; https://github.com/notifications/unsubscribe-auth/AA45u06Kawg81nafcz0GBVcZICdu85iqks5rxLuSgaJpZM4Ktuq4",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/103#issuecomment-294849229:912,Perform,Perform,912,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/103#issuecomment-294849229,1,['Perform'],['Perform']
Performance,"It looks like the first several runs crashed with:. ```; ...; [2016-12-18 12:10:47.956] [jointLog] [info] iteration = 519 | max rel diff. = 0.00832947; [2016-12-18 12:10:47.962] [jointLog] [info] Finished optimizer; [2016-12-18 12:10:47.962] [jointLog] [info] writing output. salmon: /usr/include/boost/random/gamma_distribution.hpp:117: boost::random::gamma_distribution<RealType>::gamma_distribution(const result_type&, const result_type&) [with RealType; = double; boost::random::gamma_distribution<RealType>::result_type = double]: Assertion `_alpha > result_type(0)' failed.; ```. And then a run finally hung with:. ```; [2016-12-18 13:31:06.283] [jointLog] [info] iteration = 517 | max rel diff. = 0.00871129; [2016-12-18 13:31:06.289] [jointLog] [info] Finished optimizer; [2016-12-18 13:31:06.289] [jointLog] [info] writing output. [2016-12-18 13:31:06.703] [jointLog] [info] Starting Gibbs Sampler; 0% [> ] ETA > 1 week; ```. Here's another batch of 100 backtraces: [salmon-gdb-bt.zip](https://github.com/COMBINE-lab/salmon/files/659757/salmon-gdb-bt.zip)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267855087:205,optimiz,optimizer,205,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267855087,2,['optimiz'],['optimizer']
Performance,"It looks like you are issuing . `$cmake .` . rather than . `$cmake ..`. when trying to perform the cmake step. If you could build from source, that would be great. However, I was suggesting you try downloading [this](; https://github.com/COMBINE-lab/salmon/releases/download/v0.11.1/salmon-0.11.1-linux_x86_64.tar.gz) pre-compiled linux binary and running that.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/261#issuecomment-409436938:87,perform,perform,87,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/261#issuecomment-409436938,1,['perform'],['perform']
Performance,"It took ~1.5H for V1.2.1 with ```--hitFilterPolicy BOTH```. Attaching log and fastp report, which shows normal tetramer over-representation. By the insert size determined by fastp I suspect there's quite a bit of dovetailing, I did had extremely slow performance with dovetailed libraries (for example SRR7945268, which is insert size 100, and its a PE 150 [not my data]) even allowing dovetails, to the point I ended up mapping them as single end and not using one of the pairs. Even then it took its time. Edit: allowing dovetails only increased the mapping rate by 0.0277%. As an additional note, not ```--minAlnProb 0.1``` nor ```--hardFilter``` help. . [fastp.pdf](https://github.com/COMBINE-lab/salmon/files/4711278/fastp.pdf); [salmon_quant.log](https://github.com/COMBINE-lab/salmon/files/4711259/salmon_quant.log)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/527#issuecomment-636837126:251,perform,performance,251,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/527#issuecomment-636837126,1,['perform'],['performance']
Performance,"It's possible this is [related to the other issue](https://github.com/COMBINE-lab/salmon/issues/321), since I'm also seeing:. ```; 2018-11-28 18:01:19,745 i-05ef169a0611966c7 data_refinery_workers.processors.utils ERROR [pipeline_applied: SALMON] [failure_reason: Shell call to salmon failed because: ### salmon (; ### [ program ] => salmon; ### [ command ] => quant; ### [ libType ] => { A }; ### [ biasSpeedSamp ] => { 5 }; ### [ index ] => { /home/user/data_store/TRANSCRIPTOME_INDEX/HOMO_SAPIENS/long }; ### [ mates1 ] => { /home/user/data_store/processor_job_405995/SRR2963482_1.fastq }; ### [ mates2 ] => { /home/user/data_store/processor_job_405995/SRR2963482_2.fastq }; ### [ threads ] => { 16 }; ### [ output ] => { /home/user/data_store/processor_job_405995/SRR2963482_output/ }; ### [ seqBias ] => { }; ### [ gcBias ] => { }; ### [ dumpEq ] => { }; ### [ writeUnmappedNames ] => { }; Logs will be written to /home/user/data_store/processor_job_405995/SRR2963482_output/logs; [2018-11-28 18:01:15.711] [jointLog] [info] parsing read library format; [2018-11-28 18:01:15.711] [jointLog] [info] There is 1 library.; [2018-11-28 18:01:15.761] [stderrLog] [info] Loading Suffix Array; [2018-11-28 18:01:15.761] [jointLog] [info] Loading Quasi index; [2018-11-28 18:01:15.761] [jointLog] [info] Loading 32-bit quasi index; Exception : [Failed to read 1176099240 bytes from input stream! Read 872415224]; ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/322#issuecomment-442548280:1169,Load,Loading,1169,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/322#issuecomment-442548280,3,['Load'],['Loading']
Performance,"Jumping on this thread. I received similar Seg faults with conda install on OSX. I tried the binary you posted, but receive this error when I try to execute. dyld: Library not loaded: @rpath/libtbbmalloc_proxy.dylib; Referenced from: /Users/dnb14/Documents/salmon_0.11.4-pre_OSX/./bin/salmon; Reason: image not found; Trace/BPT trap: 5",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/295#issuecomment-421407796:176,load,loaded,176,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/295#issuecomment-421407796,1,['load'],['loaded']
Performance,"No worries. The ""cache"" is one of the most annoying parts of CMake as a build system ;P.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/254#issuecomment-407465114:17,cache,cache,17,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/254#issuecomment-407465114,1,['cache'],['cache']
Performance,"O_WRAPPER=/u/user/local/libexec/gcc/x86_64-unknown-linux-gnu/5.4.0/lto-wrapper; Target: x86_64-unknown-linux-gnu; Configured with: ./configure --prefix=/u/user/local; Thread model: posix; gcc version 5.4.0 (GCC); ```. ```; [Thread debugging using libthread_db enabled]; Using host libthread_db library ""/lib/x86_64-linux-gnu/libthread_db.so.1"".; warning: File ""/u/user/local/lib64/libstdc++.so.6.0.21-gdb.py"" auto-loading has been declined by your `auto-load safe-path' set to ""$debugdir:$datadir/auto-load"".; To enable execution of this file add; add-auto-load-safe-path /u/user/local/lib64/libstdc++.so.6.0.21-gdb.py; line to your configuration file ""/u/user/.gdbinit"".; To completely disable this security protection add; set auto-load safe-path /; line to your configuration file ""/u/user/.gdbinit"".; For more information about this security protection see the; ""Auto-loading safe path"" section in the GDB manual. E.g., run from the shell:; info ""(gdb)Auto-loading safe path""; [New Thread 0x7fff7e0f4700 (LWP 14274)]; Version Info: ### A newer version of Salmon is available. ####; [Thread 0x7fff7e0f4700 (LWP 14274) exited]; ###; The newest version, available at https://github.com/COMBINE-lab/salmon/releases; contains new features, improvements, and bug fixes; please upgrade at your; earliest convenience.; ###; [New Thread 0x7fff7d273700 (LWP 14275)]; Logs will be written to pbmc4k/alevin/logs; [New Thread 0x7ffefc3f1700 (LWP 14276)]; [New Thread 0x7ffe7b56f700 (LWP 14277)]; [New Thread 0x7ffdfa6ed700 (LWP 14278)]; ### salmon (single-cell-based) v0.10.1; ### [ program ] => salmon; ### [ command ] => alevin; ### [ libType ] => { ISR }; ### [ chromium ] => { }; ### [ threads ] => { 8 }; ### [ output ] => { pbmc4k/alevin }; ### [ mates1 ] => { /dev/fd/63 }; ### [ mates2 ] => { /dev/fd/62 }; ### [ index ] => { /u/user/ref/cellranger/salmon/transcripts_index }; ### [ tgMap ] => { tx2gene.txt }. [2018-06-08 13:37:41.409] [jointLog] [info] Fragment incompatibility prior below threshold.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-395836214:2698,load,loading,2698,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-395836214,1,['load'],['loading']
Performance,"Oh, so multiple things can go wrong based on how you sampled the read like CB frequency not being aligning with the expected experiment. I'd say if you have to try a small experiment, may be sample all the reads from say ~10 Cellular barcode and specify them to alevin using `--whitelist` flag. I just tested the data it seems to work with the following log.; ```; [2021-04-16 15:57:26.183] [jointLog] [info] Mapping rate = 48.8769%. [2021-04-16 15:57:26.183] [jointLog] [info] finished quantifyLibrary(); [2021-04-16 15:57:26.360] [alevinLog] [info] Starting optimizer; ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/647#issuecomment-821529523:560,optimiz,optimizer,560,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/647#issuecomment-821529523,1,['optimiz'],['optimizer']
Performance,"Ok @DarwinAwardWinner, I think it's fixed for real this time. The issue was stemming from an uninitialized prior value in the Gibbs sampler under VBOpt mode (the initialization code was updated on the develop branch, which is where the bug was introduced). This, in turn, was leading to `nan` being passed as the alpha parameter of `std::gamma_distribution`. With the `-Ofast` optimization flags, at least, this leads `std::gamma_distribution()` to hang forever in an infinite loop. Clearly, `nan` should not be passed to `std::gamma_distribution()`, but I'd argue the behavior of looping forever here is not great. Anyway, I fixed the initialization bug, so that this nan should never pop up. Just to be safe, I also changed the default optimization flag to `-O3` so that at least `nan` and `inf` can be properly tested. Since the TBB code and the parallel sampling weren't causing the issue, I've added them back in. Could you please test the latest push (40584e62859fb65463188b50d132c1eb622b21f0) and verify that this resolves the issue for you (*hopefully*!)?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267877253:377,optimiz,optimization,377,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267877253,2,['optimiz'],['optimization']
Performance,"Ok all; another update. The issue I raise above still exists (differences between calls to `ksw_extz` and `ksw_extz2sse`). *However*, I think that what is happening in this case is actually explained more simply. That is, the positions being reported by salmon are _correct_ given the optimal alignment. Specifically, salmon is performing an end-to-end alignment of the read, and the optimal alignment here includes an indel of length 3 in the initial portion of the read. If we were outputting the CIGAR string along with the position, then the bases would line up because the ""off by 3"" issue that happens above for the reads would be addressed when walking the CIGAR. However, we don't (currently) output the CIGAR — rather, we output a decoy CIGAR that does not represent the optimal alignment as computed by ksw2. So, if we assume all matches / mismatches (an indel-free prefix for this read), then we see the position shift noted in the initial bug report. I think the easiest solution, for the time being at least, is to report the position as if the prefix before the first MEM is indel free under the optimal alignment (even if it is not and the optimal score reflects that). However, if there are other suggestions for the best way to address this, I'm open to those as well.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/475#issuecomment-574719940:328,perform,performing,328,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/475#issuecomment-574719940,1,['perform'],['performing']
Performance,"Ok, so even v0.9.1, on my machine at least, is not seeing this issue for your index. Can you tell me something about the host OS (VM) on the systems where it is failing?. To answer your other questions, by ""size of the types"" I mean e.g. if you are switching to a 32-bit processor or alternative architecture (very unlikely). One other thought is to try it ""interactively"" on a similar instance. Could it be some sort of issue where the file is being accessed before it has been completely loaded / moved to the target machine? Can you run some sort of checksum validation on the machine before attempting to load the index?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/321#issuecomment-442681478:490,load,loaded,490,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/321#issuecomment-442681478,2,['load'],"['load', 'loaded']"
Performance,"Ok, thank you very much.; The problem I had was RAM availability. I enlarged it for 48 and it works.; However, to quantify I had another problem.; I use this command line and I increase to 56 RAM. srun ./salmon-1.5.2_linux_x86_64/bin/salmon quant -i salmon_index \; -l A \; -1 ERR3537668_1.fastq.gz \; -2 ERR3537668_2.fastq.gz \; -o transcripts_DecoyQuant \; --validateMappings \; --numBootstraps 100 \; --gcBias \; --seqBias\; -p 12. And I got this error message:; [2021-11-08 14:35:28.348] [jointLog] [info] Finished Bootstrapping; ERROR: Could not create the directory [""transcripts_quant""]. Please check; that. But actually, it was created.; I really don't understand the message error. Best wishes,; Luciana. On Fri, Nov 5, 2021 at 5:56 PM Rob Patro ***@***.***> wrote:. > Hi @lubios <https://github.com/lubios>,; >; > This suggests that the machine was not able to allocate enough memory to; > perform the requested operation. I would try the following things in order; > to see if they fix the issue. First, try quantifying without the; > decoy-aware index. This doesn't provide the benefits of the decoy sequence,; > but it will ensure that this is, in fact, the problem you are having. If; > that works, try building the decoy-aware index with the --sparse; > parameter. This will build the sparse index instead of the dense index,; > which is a bit smaller and may therefore fit in RAM on the machine where; > you are doing quantification.; >; > Best,; > Rob; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/COMBINE-lab/salmon/issues/717#issuecomment-962058307>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/ADRT5CUYGXBSY3UOX24RTYDUKQLETANCNFSM5HOIMSQQ>; > .; > Triage notifications on the go with GitHub Mobile for iOS; > <https://apps.apple.com/app/apple-store/id1477376905?ct=notification-email&mt=8&pt=524675>; > or Android; > <https://play.google.com/store/apps/details?id",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/717#issuecomment-963995631:900,perform,perform,900,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/717#issuecomment-963995631,1,['perform'],['perform']
Performance,"Ok, the worst possible thing happened: I ran it a second time and it worked just fine. Does Salmon use any random number generation, and if so, is there an option to set the seed to get a deterministic run? Or is it potentially non-deterministic due to multi-threading?. One additional threading-related tidbit: I believe that when it does get stuck, a single CPU core is at 100% and the others are all unused.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-266950738:253,multi-thread,multi-threading,253,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-266950738,1,['multi-thread'],['multi-threading']
Performance,"Okay, so I've made some progress. After deleting the Cache.txt file I tried to build again at which point I noticed the following:; **WARNING: Target ""salmon"" requests linking to directory ""/users/work/jake/bin/zlib-1.2.11/"". Targets may link only to libraries. CMake is dropping the item.**; **WARNING: Target ""unitTests"" requests linking to directory ""/users/work/jake/bin/zlib-1.2.11/"". Targets may link only to libraries. CMake is dropping the item.**. So I actually went back a step and check my initial cmake command in the ../salmon-0.8.2/build/ directory. It also had the same issue and therefore wasn't building correctly. I started the install again from ../salmon-0.8.2/build/ using the following: . cmake -DBOOST_ROOT=/users/work/jake/bin/boost_1_64_0/ -DZLIB_LIBRARY=/users/work/jake/bin/zlib-1.2.11/zlib.h .. . It seemed to work nicely and I got all the build files to propagate into the ../salmon-0.8.2/build/ directory. From here I ran 'make' which did a whole bunch of things I hadn't seen it do yet, so assumably it was working as intended. This is until it got to the following stage:. Scanning dependencies of target libbwa; [ 48%] Creating directories for 'libbwa'; [ 49%] Performing download step for 'libbwa'; % Total % Received % Xferd Average Speed Time Time Time Current; Dload Upload Total Spent Left Speed; 100 125 0 125 0 0 167 0 --:--:-- --:--:-- --:--:-- 167; 0 0 0 219k 0 0 123k 0 --:--:-- 0:00:01 --:--:-- 326k; bwa-master.tar.gz: OK; bwa-0.7.12.3/.gitignore; bwa-0.7.12.3/.travis.yml; bwa-0.7.12.3/COPYING; bwa-0.7.12.3/ChangeLog; bwa-0.7.12.3/Makefile; bwa-0.7.12.3/NEWS.md; bwa-0.7.12.3/QSufSort.c; bwa-0.7.12.3/QSufSort.h; bwa-0.7.12.3/README-alt.md; bwa-0.7.12.3/README.md; bwa-0.7.12.3/bamlite.c; bwa-0.7.12.3/bamlite.h; bwa-0.7.12.3/bntseq.c; bwa-0.7.12.3/bntseq.h; bwa-0.7.12.3/bwa.1; bwa-0.7.12.3/bwa.c; bwa-0.7.12.3/bwa.h; bwa-0.7.12.3/bwakit/; bwa-0.7.12.3/bwakit/README.md; bwa-0.7.12.3/bwakit/bwa-postalt.js; bwa-0.7.12.3/bwakit/run-HLA; bwa-0.7.12.3/bwak",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/141#issuecomment-314451873:53,Cache,Cache,53,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/141#issuecomment-314451873,1,['Cache'],['Cache']
Performance,"Oki, so I have updated a couple of things in the latest commit on the develop branch, which should make the things more streamlined. . * `maxNumBarcodes`: As you have initially used `maxNumBarcodes` which is by default set to 100k it means. by default alevin quantifies 100k CBs which includes both the low and high confidence CB count. You can change this number accordingly to set the universe of the top CB to quantify.; * `KeepCBFraction` : It defines what fraction of `maxNumBarcodes` to be used as the high confidence barcodes and should definitely generate the quants for. If set to 1 then everything is high confidence and the whitelisting cannot be performed. Thanks to this issue, alevin will not fail without error when there is no low confidence CB is found instead it checks if the number of low confidence CB is less than `lowRegionMinBarcodes` (default to 200), alevin will warn and not perform the whitelisting.; * `freqThreshold`: This is used to filter out most obvious cases to filter out CB with frequency less than set by the parameter (default to 10). Hope this help ! I am also testing on my end for any other potential bug. Please let me know if you get a chance to check the develop branch .",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/379#issuecomment-503396823:658,perform,performed,658,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/379#issuecomment-503396823,2,['perform'],"['perform', 'performed']"
Performance,"On 11/04/2020 01:04, Rob Patro wrote:; > I saw no performance regressions, so 1.2.0 is built without the ; > offending flag. Thanks for the heads up. Hi, Rob. Thanks for fixing the problem so quickly!. Tony. -- ; Minke Informatics Limited, Registered in Scotland - Company No. SC419028; Registered Office: 3 Donview, Bridge of Alford, AB33 8QJ, Scotland (UK); tel. +44(0)19755 63548 http://minke-informatics.co.uk; mob. +44(0)7985 078324 mailto:tony.travis@minke-informatics.co.uk",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/500#issuecomment-612423808:50,perform,performance,50,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/500#issuecomment-612423808,1,['perform'],['performance']
Performance,"On Sun, Nov 01, 2015 at 06:15:19AM -0800, Rob Patro wrote:. > I, too, would like to see the relative performance of the two libraries. The only challenge is in making the comparison apples-to-apples (i.e. enabling multi-threaded parsing in seqtk with minimal overhead ??? a concurrent queue is cheap, but not free). . Other points worth considering:; - there's a runtime overhead to constantly changing sequencing formats. Some; programs want split, others want interleaved. We've settled on interleaved; because it enables streaming, which is a major win (2-4x performance); and; also because having one file is better than having 2 or 4.; - the management overhead to keeping track of many files is less for experts,; but is pretty significant for beginners. Enabling multiple input formats ++. So I think it'd be great to have the basic functionality, identify where; there are performance problems, and then simply note them for future ;). I would like to enable -1 and -2 in khmer scripts, but for our usual use cases; (multiple sequencing files being normalized and/or partitioned and/or error; trimmed) the command line syntax is too confusing ATM.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/29#issuecomment-152829225:101,perform,performance,101,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/29#issuecomment-152829225,6,"['concurren', 'multi-thread', 'perform', 'queue']","['concurrent', 'multi-threaded', 'performance', 'queue']"
Performance,"One thought might be that on OSX, I think docker sets a very low default RAM limit (2G?). That's insufficient for loading the entire human txome index. You could try [setting this](https://docs.docker.com/docker-for-mac/#advanced) to a larger value (e.g. 6 or 8G should suffice).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/243#issuecomment-400721687:114,load,loading,114,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/243#issuecomment-400721687,1,['load'],['loading']
Performance,"PL version 3 or later <http://gnu.org/licenses/gpl.html>; This is free software: you are free to change and redistribute it.; There is NO WARRANTY, to the extent permitted by law.; Type ""show copying"" and ""show warranty"" for details.; This GDB was configured as ""x86_64-redhat-linux-gnu"".; Type ""show configuration"" for configuration details.; For bug reporting instructions, please see:; <http://www.gnu.org/software/gdb/bugs/>.; Find the GDB manual and other documentation resources online at:; <http://www.gnu.org/software/gdb/documentation/>. For help, type ""help"".; Type ""apropos word"" to search for commands related to ""word""...; Reading symbols from salmon...done.; (gdb) r; Starting program: /home/common/modules/el8/x86_64/software/salmon/1.2.1-CentOS-vanilla/bin/salmon index -t transcripts.fasta -i sample_salmon_fmd_index --type fmd; Missing separate debuginfos, use: yum debuginfo-install glibc-2.28-72.el8_1.1.x86_64; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; [Thread debugging using libthread_db enabled]; Using host lib",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641594410:2378,Load,Loadable,2378,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641594410,1,['Load'],['Loadable']
Performance,"R library. flag As you can see the percentage of mapped reads is high and not consistent with incorrect strand mapping in my view. I did the salmon quantification both with and without using seq_bias and gc_bias corrections and got the same result. Info for both included. I was advised that a FWD library was used - this is a bit confusing given the success of running the SR option. I suggest you continue exploring with your own data in the current environment, which does differ from May 2018. ________________________________; From: tamuanand <notifications@github.com>; Sent: Saturday, 14 December 2019 10:53 AM; To: COMBINE-lab/salmon <salmon@noreply.github.com>; Cc: Susan Corley <s.corley@unsw.edu.au>; Mention <mention@noreply.github.com>; Subject: Re: [COMBINE-lab/salmon] Salmon SAF method - Read mapping issue with Lexogen/QuantSeq data?? (#449). Hi @s1corley<https://github.com/s1corley>. As @rob-p<https://github.com/rob-p> mentions, your paper could help assess different methodologies for quantification and also help optimize salmon further for QuantSeq. I would still like you to check if you have used salmon quant command line correctly for QuantSeq data analysis. Your paper briefly alludes to QuantSeq Forward in the Introduction section of the paper. The QuantSeq Forward kit has an oligo (dT) primer which contains the Illumina-specific Read 2 linker ... but the Methods section of your paper does not specify if you have used QuantSeq FWD or REV. Page 14 of the PDF from the Lexogen Website data analysis pipeline for QuantSeq FWD<https://www.bluebee.com/wp-content/uploads/2018/11/015UG108V0201-QuantSeq-Data-Analysis-Pipeline_2018-10-18.pdf> recommends using the below htseq command line. htseq-count -m intersection-nonempty -s yes -f bam -r pos $bam; $resource_dir/annotation.gtf > $bam_dir/read_counts.txt. QuantSeq is a stranded protocol. For the QuantSeq FWD pipeline the argument -s yes indicates; stranded in the sense orientation. For the QuantSeq REV pipeline -s ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-565684552:1124,optimiz,optimize,1124,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-565684552,1,['optimiz'],['optimize']
Performance,"Right, in short `salmon index -t txome_fasta -i txome_index` should work and both the versions of salmon (v0.15 and v1.0) is available on bioconda, check [here](https://bioconda.github.io/recipes/salmon/README.html), you may wanna try [force](https://docs.conda.io/projects/conda/en/latest/commands/update.html) update of conda. I think the confusion is you are thinking of the concept of Selective Alignment as the same as aligning to transcriptome w/ decoys (can be genome or mashmap based). Although they are related methods but the concept of Selective Alignment predates the idea of decoy based alignment, checkout [this](https://dl.acm.org/citation.cfm?id=3233589) paper from our lab where we discuss how Selectively Aligning difficult reads to just the transcriptome itself can result in improved quantification estimates compared to quasi or pseduo alignment. To summarize: ; In version 1.0; A) SA: The mashmap and bedtools based pipeline which follows old SalmonTools based pipeline.; B) SAF: Inbuilt salmon pipeline to consume genome and follows this pipeline.; C) If you don't provide any decoys, salmon will do Selective Alignment just on the transcriptome. The Release notes you quoted just means you cannot disable this feature i.e. you cannot fall back to quasi-mapping (in quasi mapping there is no alignment of the reads at all). In version 0.15.0; You cannot provide decoys and the transcriptome based mapping performed in this version would be quasi-mapping i.e. no Alignment of reads. Hope it helps .",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/442#issuecomment-549195321:1428,perform,performed,1428,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/442#issuecomment-549195321,1,['perform'],['performed']
Performance,"Right, the issue seems to be that the right binary is not getting created. My (re)compilation using the same script you shared above seems to be giving different help.; ```; alevin-specific Options:; -v [ --version ] print version string; -h [ --help ] produce help message; -o [ --output ] arg Output quantification directory.; -p [ --threads ] arg (=1) The number of threads to use; concurrently.; --tgMap arg transcript to gene map tsv file; --dropseq Use DropSeq Single Cell protocol for; the library; --chromiumV3 Use 10x chromium v3 Single Cell; protocol for the library.; --chromium Use 10x chromium v2 Single Cell; protocol for the library.; --gemcode Use 10x gemcode v1 Single Cell protocol; for the library.; --celseq Use CEL-Seq Single Cell protocol for; the library.; --celseq2 Use CEL-Seq2 Single Cell protocol for; the library.; ```. May I suggest removing the `CMakeCache.txt` file from the build folder of salmon and running `make -j 4 install` again. After recompilation using the `salmon` binary inside the `bin` folder should ideally give you the above updated help. However, If it doesn't resolve after that, I am compiling a linux binary and will share it to you to be used directly.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/325#issuecomment-443518366:385,concurren,concurrently,385,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/325#issuecomment-443518366,1,['concurren'],['concurrently']
Performance,"Rob,. Brilliant - I forgot that I built the boost libraries from whatever version of gcc was on the standard distribution. I have included -DFETCH_BOOST=TRUE, do you know why I am receiving the following error regarding a missing when executing make?. [ 5%] Performing configure step for 'libboost'; Building Boost.Build engine with toolset gcc... tools/build/src/engine/bin.linuxx86_64/b2; Detecting Python version... 2.7; Detecting Python root... /usr; Unicode/ICU support for Boost.Regex?... not found.; Generating Boost.Build configuration in project-config.jam... Bootstrapping is done. To build, run:. ./b2. To adjust configuration, edit 'project-config.jam'.; Further information:. - Command line help:; ./b2 --help. - Getting started guide:; http://www.boost.org/more/getting_started/unix-variants.html. - Boost.Build documentation:; http://www.boost.org/build/doc/html/index.html. using gcc : : /opt/gcc-8.2.0/bin/g++ ); [ 6%] Performing build step for 'libboost'; opt.jam: No such file or directory; /opt/salmon/external/boost_1_66_0/tools/build/src/build/toolset.jam:43: in toolset.using; ERROR: rule ""opt.init"" unknown in module ""toolset"".; /opt/salmon/external/boost_1_66_0/tools/build/src/build-system.jam:461: in process-explicit-toolset-requests; /opt/salmon/external/boost_1_66_0/tools/build/src/build-system.jam:527: in load; /opt/salmon/external/boost_1_66_0/tools/build/src/kernel/modules.jam:295: in import; /opt/salmon/external/boost_1_66_0/tools/build/src/kernel/bootstrap.jam:139: in boost-build; /opt/salmon/external/boost_1_66_0/boost-build.jam:17: in module scope; make[2]: *** [libboost-prefix/src/libboost-stamp/libboost-build] Error 1; make[1]: *** [CMakeFiles/libboost.dir/all] Error 2; make: *** [all] Error 2. Thanks for all your help!. Nate",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/309#issuecomment-436834099:258,Perform,Performing,258,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/309#issuecomment-436834099,3,"['Perform', 'load']","['Performing', 'load']"
Performance,"S936134_2.fastq; drwxrwxr-x 5 vale rst_pub 4.0K Jan 2 20:20 SRP057125_SRS936134_salmon_out; ```. But when I run the script there, it succeeds, without segfault. ```; [vale@ebi-003 salmon-problem]$ bash run_salmon.sh; Version Info: This is the most recent version of Salmon.; # salmon (mapping-based) v0.6.0; # [ program ] => salmon; # [ command ] => quant; # [ index ] => { mouse_cdna_38.p3.78_repbase_ercc.fa }; # [ libType ] => { IU }; # [ mates1 ] => { SRP057125_SRS936134_1.fastq }; # [ mates2 ] => { SRP057125_SRS936134_2.fastq }; # [ output ] => { SRP057125_SRS936134_salmon_out }; # [ biasCorrect ] => { }; # [ useFSPD ] => { }; Logs will be written to SRP057125_SRS936134_salmon_out/logs; [2016-01-02 20:16:39.349] [jointLog] [info] parsing read library format; there is 1 lib; Loading 32-bit quasi index[2016-01-02 20:16:39.895] [stderrLog] [info] Loading Suffix Array; [2016-01-02 20:16:39.895] [stderrLog] [info] Loading Position Hash; [2016-01-02 20:16:39.894] [jointLog] [info] Loading Quasi index; [2016-01-02 20:16:42.565] [stderrLog] [info] Loading Transcript Info; [2016-01-02 20:16:43.654] [stderrLog] [info] Loading Rank-Select Bit Array; [2016-01-02 20:16:44.075] [stderrLog] [info] There were 104534 set bits in the bit array; [2016-01-02 20:16:44.448] [stderrLog] [info] Computing transcript lengths; [2016-01-02 20:16:44.448] [stderrLog] [info] Waiting to finish loading hash; Index contained 104534 targets; [2016-01-02 20:16:57.606] [stderrLog] [info] Done loading index; [2016-01-02 20:16:57.606] [jointLog] [info] done. processed 12000000 fragments; hits: 24367197, hits per frag: 2.06194+06. [2016-01-02 20:17:29.841] [jointLog] [info] Computed 102251 rich equivalence classes for further processing; [2016-01-02 20:17:29.841] [jointLog] [info] Counted 10033689 total reads in the equivalence classes; [2016-01-02 20:17:29.867] [jointLog] [info] Mapping rate = 83.0244%. [2016-01-02 20:17:29.867] [jointLog] [info] finished quantifyLibrary(); [2016-01-02 20:17:29.867] [joi",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/34#issuecomment-168426741:1904,Load,Loading,1904,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/34#issuecomment-168426741,1,['Load'],['Loading']
Performance,"Salmon has two modes; alignment-based and quasi-mapping based. When you are using the alignment-based mode (i.e. feeding it a BAM file of aligned reads), you don't need to provide it with the raw reads. This is because all of the relevant information is already contained within the BAM file. . On the other hand, in quasi-mapping mode, you index the set of reference transcripts (using `salmon index`) and then provide salmon with the location of the index and the raw reads (i.e. the FASTQ file). In this case, it performs quasi-mapping (a lightweight stand in for alignment), and so it is not necessary to provide the BAM file. Please refer to quasi-mapping based mode and alignment-based mode in [the documentation](http://salmon.readthedocs.io/en/latest/salmon.html#quasi-mapping-based-mode-including-lightweight-alignment) for more details.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/113#issuecomment-270007599:516,perform,performs,516,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/113#issuecomment-270007599,1,['perform'],['performs']
Performance,"Salmon is version 0.9.1. This is happening for lots of samples, the error message is always `Exception : [Failed to read 879238456 bytes from input stream! Read 851443704]` regardless of the fastq files that are provided. . Nothing else too special is going on. It doesn't seem to have this problem with other indexes. Can you try to load and map again with 0.9.1?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/321#issuecomment-442569984:334,load,load,334,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/321#issuecomment-442569984,1,['load'],['load']
Performance,"So, I am still very surprised by the 45G number, but one big difference here is that the refgenomes indices are with the default value of k (`k=31`). As you can see, the dominant element of the index here is the `ctable.bin`, which stores where unitigs of the dBG start within each reference. As the k-met size gets smaller, unitigs get shorter, and they appear more places. Further, the increase here is not linear as `k` decreases. I’d suspect most of the size difference is due to that. There is also an optimization for the `ctable.bin` that we have been working on that wastes fewer bits, and will make this part of the index somewhat smaller in such cases. However, I am fairly certain that is not the dominant factor here. You could see what this is with the default `k`; I’d expect that to be closer to the refgenomes number (but perhaps a bit different due to version differences and the `—keepDuplicates` flag).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/505#issuecomment-613226163:507,optimiz,optimization,507,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/505#issuecomment-613226163,1,['optimiz'],['optimization']
Performance,"Some progress. Found a src rpm for cereal, rebuilt that into an RPM and installed. Then this (ROOT_* env variables come from the respective module load commands):. ```; cmake \; -DCMAKE_INSTALL_PREFIX=$TOPDIR \; -DSTADEN_ROOT=$ROOT_IO_LIB \; -DGFF_ROOT=$ROOT_LIBGFF \; -DTBB_ROOT=$ROOT_LIBTBB \; -DCMAKE_VERBOSE_MAKEFILE:BOOL=ON \; -DBOOST_LIBRARYDIR=/usr/lib64/boost169 \; -DBOOST_INCLUDEDIR=/usr/include/boost169 \; -DBoost_NO_SYSTEM_PATHS=ON \; .. 2>&1 | tee cmake_2020_06_09.log; ```; found everything. The ""make"" went along pretty well until here:; ```; [100%] Linking CXX executable salmon; cd /usr/common/src/salmon-1.2.1/build/src && /usr/common/src/cmake-3.17.1/bin/cmake -E cmake_link_script CMakeFiles/salmon.dir/link.txt --verbose=1; /usr/lib64/ccache/c++ -O3 -DNDEBUG -flto -fno-fat-lto-objects CMakeFiles/salmon.dir/EMUtils.cpp.o CMakeFiles/salmon.dir/CollapsedEMOptimizer.cpp.o CMakeFiles/salmon.dir/CollapsedCellOptimizer.cpp.o CMakeFiles/salmon.dir/CollapsedGibbsSampler.cpp.o CMakeFiles/salmon.dir/Salmon.cpp.o CMakeFiles/salmon.dir/BuildSalmonIndex.cpp.o CMakeFiles/salmon.dir/Graph.cpp.o CMakeFiles/salmon.dir/DedupUMI.cpp.o CMakeFiles/salmon.dir/Alevin.cpp.o CMakeFiles/salmon.dir/AlevinHash.cpp.o CMakeFiles/salmon.dir/SalmonAlevin.cpp.o CMakeFiles/salmon.dir/WhiteList.cpp.o CMakeFiles/salmon.dir/SalmonQuantify.cpp.o CMakeFiles/salmon.dir/FragmentLengthDistribution.cpp.o CMakeFiles/salmon.dir/FragmentStartPositionDistribution.cpp.o CMakeFiles/salmon.dir/GZipWriter.cpp.o CMakeFiles/salmon.dir/SalmonQuantMerge.cpp.o CMakeFiles/salmon.dir/ProgramOptionsGenerator.cpp.o CMakeFiles/salmon.dir/FASTAParser.cpp.o CMakeFiles/salmon.dir/AlignmentModel.cpp.o CMakeFiles/salmon.dir/SalmonQuantifyAlignments.cpp.o CMakeFiles/salmon.dir/BAMUtils.cpp.o -o salmon -L/usr/common/src/salmon-1.2.1/lib -L/usr/common/src/salmon-1.2.1/external/install/lib -Wl,-rpath,""\$ORIGIN/../lib:\$ORIGIN/../../lib:\$ORIGIN/:\$ORIGIN/../../external/install/lib"" ../external/pufferfish/src/libpuffer.a libs",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641531162:147,load,load,147,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641531162,1,['load'],['load']
Performance,"Sorry for the late response. According to the developer, the --meta flag is well-suited to metagenomics. Unlike handling RNA data, the use of this flag changes the initialization conditions of the EM algorithm and turns off Salmon's rich equivalence classes so as to better optimize Salmon for handling metagenomic (DNA) data. You can read more here- https://gitter.im/COMBINE-lab/salmon?at=589f11106b2d8dd5522e0ff1",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/330#issuecomment-874634736:274,optimiz,optimize,274,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/330#issuecomment-874634736,1,['optimiz'],['optimize']
Performance,"Sorry if I wasn't clear. Also, maybe I am trying to bluntly transpose a; metric that comes from alignment-based quantification. Yes, sequencing; saturation relies on UMI, using the transcript reads associated to the UMIs. I am not sure to understand the difference between resolving ambiguity; or collision at the transcript level, with the evaluation of sequencing; saturation in mind. To be more precise, I am not sure to see how it; could be a problem in this computation. But I am probably missing an; important point?. The idea of quasi-mapping as I understand is identifying the transcripts; from which the reads could have originated, generating a quantification.; For the sequencing saturation, we don't really need to know where the; read align on the transcript sequence, we just want to know that the; read comes from one single transcript, a unique UMI. So if I am right,; it is possible to summarize this quantification at the level of UMIs,; and have an idea of the duplication level of the transcripts that have; been tagged with UMIs. From what I understand, this is where alevin; perform the deduplication computation to have a correct idea of the; transcript amount when UMI are added, prior amplifications resulting; from the RT/PCR steps. So I was imagining it could be possible to take the gene quantifications; from (de)duplicated UMIs, gene quantifications from unique UMIs, using; them to have an idea of the amount/ratio of redundant information in the; sequencing data, producing a metric very similar to the seq sat from the; 10x definition.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/267#issuecomment-414331344:1097,perform,perform,1097,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/267#issuecomment-414331344,1,['perform'],['perform']
Performance,"Sure --- since, at this point, I don't seem able to reproduce the issue any more. Just for a sanity check, can you md5sum the binary you have? I have `fc39599b6c027eb97bb2f4c7bdd361f3`. Previously, I was getting the same segfault as you, but now it finishes cleanly:. ```; [2016-01-02 13:13:10.643] [jointLog] [info] iteration = 4500 | max rel diff. = 0.0100814; [2016-01-02 13:13:10.703] [jointLog] [info] iteration = 4508 | max rel diff. = 0.00999839; [2016-01-02 13:13:10.714] [jointLog] [info] Finished optimizer; [2016-01-02 13:13:10.714] [jointLog] [info] writing output. [2016-01-02 13:13:10.871] [jointLog] [warning] NOTE: Read Lib [( /dev/fd/63, /dev/fd/62 )] :. Detected a strand bias > 1% in an unstranded protocol check the file: salmon_flux_quant_nofspd/libFormatCounts.txt for details. [2016-01-02 13:13:10.871] [jointLog] [warning] NOTE: Read Lib [( /dev/fd/63, /dev/fd/62 )] :. Greater than 5% of the alignments (but not, necessarily reads) disagreed with the provided library type; check the file: salmon_flux_quant_nofspd/libFormatCounts.txt for details. rob@feynman:~/SoftwareStaging/salmon/build/tmp; ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/34#issuecomment-168413403:507,optimiz,optimizer,507,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/34#issuecomment-168413403,1,['optimiz'],['optimizer']
Performance,"TY, to the extent permitted by law.; Type ""show copying"" and ""show warranty"" for details.; This GDB was configured as ""x86_64-redhat-linux-gnu"".; Type ""show configuration"" for configuration details.; For bug reporting instructions, please see:; <http://www.gnu.org/software/gdb/bugs/>.; Find the GDB manual and other documentation resources online at:; <http://www.gnu.org/software/gdb/documentation/>. For help, type ""help"".; Type ""apropos word"" to search for commands related to ""word""...; Reading symbols from salmon...done.; (gdb) r; Starting program: /home/common/modules/el8/x86_64/software/salmon/1.2.1-CentOS-vanilla/bin/salmon index -t transcripts.fasta -i sample_salmon_fmd_index --type fmd; Missing separate debuginfos, use: yum debuginfo-install glibc-2.28-72.el8_1.1.x86_64; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; [Thread debugging using libthread_db enabled]; Using host libthread_db library ""/lib64/libthread_db.so.1"".; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641594410:2522,Load,Loadable,2522,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641594410,1,['Load'],['Loadable']
Performance,"Thank you for the swift answer!. We are working with [BD Rhapsody](https://www.bdbiosciences.com/en-us/instruments/research-instruments/single-cell-multiomics/single-cell-analysis-system), which uses a complex barcode structure (you can read about this in their [bioinformatics handbook](https://www.bd.com/documents/guides/user-guides/GMX_BD-Rhapsody-genomics-informatics_UG_EN.pdf) on page 14). The extracted, combined CB is 27bp long, which is why the default sanity check was too low for our purposes. In terms of cell numbers, BD Rhapsody appears to generate a lot of ""false-positive cells"", actually (we are seeing up to 90% of false positives). This is expected, and also mentioned in their bioinformatics handbook (pages 23-25), but appears to be an issue for the alevin cell detection: with standard settings this is approximately two orders of magnitude lower than expected, `--expectCells` improves matters drastically, however. We have opted for removing the false positives in post-processing ourselves - the low count depth population is very easily identifiable. In terms of performance, a complete alevin run on 150M reads (25k expected cells) takes around 1.5 hours using 10 threads, which is perfectly reasonable for us.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/445#issuecomment-551083490:1090,perform,performance,1090,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/445#issuecomment-551083490,1,['perform'],['performance']
Performance,"Thanks ! ; When you release the apple silocon version. Is it possible to upload to brew ? Do you want to take in account the gpu with metal or the neural engine ? . > Le 30 juin 2022 à 05:58, Rob Patro ***@***.***> a écrit :; > ; > ﻿; > Hi @BenjaminDEMAILLE,; > ; > I think brew is a bit behind bioconda on this front, and, indeed, the M1 being a completely new architecture complicates things. I have an M1 Max and so there are plans to get a native compile going soon.; > ; > For the time being, the recommended way to get salmon on an M1 (or M2) Mac is as suggested here. Basically, you create an x86 conda environment (running under rosetta2) and install the latest version of salmon there. Rosetta2 is pretty amazing, and everything seems to run without a hitch, with nary a performance hit for the x86 -> ARM translation.; > ; > Best,; > Rob; > ; > —; > Reply to this email directly, view it on GitHub, or unsubscribe.; > You are receiving this because you were mentioned.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/787#issuecomment-1170808558:780,perform,performance,780,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/787#issuecomment-1170808558,1,['perform'],['performance']
Performance,"Thanks @k3yavi , --keepCBfraction isn't in the docs, so I missed it. Unless it leads to completely unfeasible run times, --keepCBfraction 1 combined with downstream filtering may be the most robust way to handle things in my high throughput situation (as alluded to by @roryk ). Is there a way of combining this with a minimum UMI count per CB to remove just the most obvious junk and hopefully somewhat limit the impact on runtimes?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/362#issuecomment-490843243:230,throughput,throughput,230,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/362#issuecomment-490843243,1,['throughput'],['throughput']
Performance,"Thanks @reganhayward. I'm pinging @hiraksarkar here as well as he can help us dig into this. I do think it will be really useful to have the bootstrap (in this case Gibbs) folders for the runs, so we can load that data up and see what the posterior traces look like for these transcripts. If you can throw that up somewhere, then we can grab it as well.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/600#issuecomment-756948080:204,load,load,204,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/600#issuecomment-756948080,1,['load'],['load']
Performance,"Thanks @rob-p,. Your explanations are helpful, and I think it may my concern may just be more associated with your general thought as I've tested this with multiple parameters. The one I represented here was just an example, but I also can see how the parameters can be affecting these results. It was just strange to see such a huge shift with the addition/removal of one gene, which makes me think it more associated with how the inference of the variables are conditioned. . As for providing the meta_info.json files, I currently have thousands of them as I am running triplicates of ~150 parameter combinations for multiple tissue types and stages. In the end I don't think it will be necessary as we will likely be changing our approach a bit, which should be fine with the system I have in place. . Also, as for `--scoreExp` our main goal is to try and use Salmon to get quantification of individual genes (primary versus spliced forms). From my analysis, it appears that some genes perform better with scores > 0, however, some genes do perform better with a `--scoreExp` of 0. Although, this could be a factor in running Salmon with such a narrow view (i.e. two transcripts and some housekeeping genes) and might not be the case as more genes are added to the run.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/523#issuecomment-633062608:989,perform,perform,989,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/523#issuecomment-633062608,2,['perform'],['perform']
Performance,"Thanks @roryk and @k3yavi . The issue we have is that we're trying to run a pipeline in a fairly high-throughput manner to get a sensible 'enough' matrix without too much manual intervention. So I'm trying to avoid anything that requires an eyeballing step, accepting that the matrix we get will be less optimal than one you'd get from manual optimisation. Where possible, our curators are extracting the expected cell numbers from publications, so sometimes I have at least a general idea of where to look for an elbow/ feature. @roryk - have you used your alternate view on the data to automatically derive cutoffs? Does it work well?. @k3yavi:. As I say, first point is that this is for cases where I have a rough idea of the target cell number- we're generally working with pre-published data (though cell numbers per run are not always available). . From https://github.com/COMBINE-lab/salmon/issues/340 I'd inferred that --expectCells gives Alevin ballpark to look for a knee within, while --forceCells is a strict cuttoff. Is that correct? . That being the case, my thought was to try --expectCells first, and failing that --forceCells. The problem is that I need to parse the STDOUT/ERR to detect the boundary error from --expectCells, which is not a very robust way of doing things. If you returned informative error codes (anything but 1) on this and other errors, I could detect the error and implement the logic I describe.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/362#issuecomment-490157428:102,throughput,throughput,102,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/362#issuecomment-490157428,1,['throughput'],['throughput']
Performance,"Thanks Dr Patro,; Updating now, In my simulations weighted assignments perform quite better than 'best mappings' for ASE, so will stick with that. ; Best.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/347#issuecomment-469752257:71,perform,perform,71,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/347#issuecomment-469752257,1,['perform'],['perform']
Performance,"Thanks for reporting back (with the nice plots!). This is interesting, because, at least in our other testing, the VB seems to be performing slightly _better_ than the EM. One guess I have is that the VB Opt tends to produce slightly sparser solutions than the EM opt. Usually, this is a ""good thing"". However, if you're dealing with such small datasets (n ~50), then dropping a few points could make a significant difference. Since you can reproduce the previous behavior when dropping the VB option, there's no rush. However, if you are able to share some of the data at some point, I'd be interested in digging in and figuring out exactly what's happening here. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/6#issuecomment-111604379:130,perform,performing,130,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/6#issuecomment-111604379,1,['perform'],['performing']
Performance,"Thanks for reporting this. Certainly, failure should be more apparent. Out of curiosity, is the failure in building the index? It looks like loading the index didn't work, so was the space character that caused the problem in your reference file?. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/22#issuecomment-146996488:141,load,loading,141,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/22#issuecomment-146996488,1,['load'],['loading']
Performance,"Thanks for the details @cljacobs. We'll see if we can get a Docker image up to reproduce this under RH7. Our development machine is ubuntu based, and our CI is CentOS. It also builds on the environment used by bioconda. So it looks like we'll need a RH image to reproduce this. Out of curiosity, does anything happen differently if you pass `-DNO_IPO=TRUE` during the `cmake` configure step? That disables interprocedural optimization (whole program link-time optimization).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/455#issuecomment-558716670:422,optimiz,optimization,422,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/455#issuecomment-558716670,2,['optimiz'],['optimization']
Performance,"Thanks for the quick answer!; Here is the log file:. [2020-04-22 12:53:21.437] [jointLog] [info] setting maxHashResizeThreads to 8; [2020-04-22 12:53:21.437] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2020-04-22 12:53:21.437] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2020-04-22 12:53:21.437] [jointLog] [info] Usage of --validateMappings implies a default consensus slack of 0.2. Setting consensusSlack to 0.35.; [2020-04-22 12:53:21.437] [jointLog] [info] parsing read library format; [2020-04-22 12:53:21.437] [jointLog] [info] There is 1 library.; [2020-04-22 12:53:21.501] [jointLog] [info] Loading pufferfish index; [2020-04-22 12:53:21.503] [jointLog] [info] Loading dense pufferfish index.; [2020-04-22 12:54:13.540] [jointLog] [info] done; [2020-04-22 12:54:13.713] [jointLog] [info] Index contained 228,799 targets; [2020-04-22 12:54:29.422] [jointLog] [info] Number of decoys : 84; [2020-04-22 12:54:29.466] [jointLog] [info] First decoy index : 228,673 ; [2020-04-22 13:00:24.946] [jointLog] [info] Automatically detected most likely library type as ISR; [2020-04-23 00:06:31.287] [jointLog] [info] Thread saw mini-batch with a maximum of 1.06% zero probability fragments; [2020-04-23 00:06:41.198] [jointLog] [info] Thread saw mini-batch with a maximum of 1.08% zero probability fragments; [2020-04-23 00:06:50.741] [jointLog] [info] Thread saw mini-batch with a maximum of 1.02% zero probability fragments; [2020-04-23 00:06:56.260] [jointLog] [info] Thread saw mini-batch with a maximum of 1.08% zero probability fragments; [2020-04-23 00:06:56.781] [jointLog] [info] Thread saw mini-batch with a maximum of 1.04% zero probability fragments; [2020-04-23 00:07:03.636] [jointLog] [info] Thread saw mini-batch with a maximum of 1.04% zero probability fragments; [2020-04-23 00:07:03.759] [jointLog] [info] Thread saw mini-batch ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/516#issuecomment-621872756:756,Load,Loading,756,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/516#issuecomment-621872756,2,['Load'],['Loading']
Performance,"Thanks for the quick response. I see the confusion. **In general, it is not possible to determine which reads are assigned to which transcripts given just the information in the SAM file written by `--writeMappings`**. This is because allocation of reads to transcripts is performed using a probabilistic model that takes into account many factors, so it's not as if salmon is just applying some filter to the mappings and then summing up some alignments. One way you could potentially get more insight is to use the [`postmaster`](https://github.com/COMBINE-lab/postmaster) tool. It takes as input the SAM file generated by the `--writeMappings` flag of `salmon`, and produces another SAM file annotating each alignment record with a `ZW` field, which records the posterior probability that this read is assigned to the corresponding transcript. This will give the right abundances in expectation (if you sum up the `ZW` field for each alignment, you should get something similar to the `quant.sf` results), but it is not guaranteed to be exactly the same assignment that salmon makes for each alignment itself.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/799#issuecomment-1245730911:273,perform,performed,273,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/799#issuecomment-1245730911,1,['perform'],['performed']
Performance,"Thanks for the response. . The transcriptional variants I've been interested often are quite similar (e.g. only differ for a small part of one exon). Therefore, many of the reads (especially when they map to parts of the genes that don't differ) show up as pseudoaligned to multiple variants, as you'd expect. In that case, do you suggest only looking at the uniquely mapped reads, or only looking at primary alignments for each read, or still looking at all reads (perhaps with a certain `AS` score) for a given transcript? I'm mostly interested in performing sanity checks that transcriptional variants identified by Salmon/Swish are differentially used across conditions. Or would it be better to use a tool like DEXSeq to asks these questions directly? . Also, when filtering by the `AS`, I found some reads with `AS:i:-2147483648`, which I assume is an overflow error.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/528#issuecomment-639153957:550,perform,performing,550,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/528#issuecomment-639153957,1,['perform'],['performing']
Performance,"Thanks for the thorough suggestions. Actually, we fall into the easier case since Salmon does not support mixing single and paired-end reads in a single BAM file. When performing quantification on a single sample, the reads for that sample must follow a uniform library type. For paired-end reads, the BAM file can contain paired-end and single-end alignments (i.e. orphans), but the reads must all have been paired _in sequencing_. Mixing different library types in the BAM file makes it difficult to assess the compatibility of a fragment with the expected library type, especially if fragments from the different library types are expected to exist in a specific ratio in the input. Anyway, my main motivation for having the separate `AS` and `AP` types was to prevent the need to ""peek"" in the file, since, currently, there is not an easy way to peek the first read without opening the first file twice. However, I've decided that the benefit of having the same uniform (and simpler) interface of `A` always representing automatic library type detection is probably worth it, so I've pushed this implementation (commit 6116b2a). So, when the user provides the `A` library type, Salmon will peek into the first record in the BAM file to determine if the fragment was paired in sequencing or not, and will then set the single / paired-end status on that basis. The only corollary to this is that, in alignment-based mode, the `A` flag is not compatible with an input stream (i.e. the input must be a regular file). I will be sure to document this when I update the docs for the version bump.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/79#issuecomment-242399463:168,perform,performing,168,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/79#issuecomment-242399463,1,['perform'],['performing']
Performance,"Thanks, @k3yavi! ; I'll be sure to share my experience and any comparisons I perform.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/269#issuecomment-418863611:77,perform,perform,77,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/269#issuecomment-418863611,1,['perform'],['perform']
Performance,"That is . . . strange! Salmon _literally_ uses the RapMap index (and the RapMap functions) directly to obtain the quasi-mappings. One thing I noticed is that you seem to be using `pseudoindex` which is our independent re-implementation of pseudo-alignment. However, Salmon (and Sailfish) use quasi-mapping (RapMap's `quasiindex` and `quasimap` commands, as [we found this to be more accurate](http://biorxiv.org/content/biorxiv/early/2016/01/16/029652.full.pdf)). I presume that if you used the quasi-mapping functionality, you might observe the bug. If you don't (i.e. if RapMap performs quasi-mapping properly), then this is a real thinker (and I'd be happy to take a look myself if you can share the file). P.S. The same caveat I mentioned above may apply. That is, it is possible that a polyA transcript that is completely removed from the input could cause a problem unless we check for it in the quasi-index, but may not affect the pseudo-index. This is because the quasi-index relies on a packed representation of the transcriptome and an associated sparse bit-vector to perform the mapping, and it assumes that all of the transcripts will have a non-zero length (if this is the culprit, it is, of course, easy to fix with an explicit check). You could also test this hypothesis by generating the quasi-index with the `--noClip` option, which will disable poly-A clipping when building the index.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/37#issuecomment-175088841:580,perform,performs,580,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/37#issuecomment-175088841,2,['perform'],"['perform', 'performs']"
Performance,"That's very strange in that it doesn't even seem to be trying to load the index! I obviously don't have the same set of reads you do, but here is what I get when using this pre-compiled binary on the 64-bit index (this is a small read set from single-cell data, which is why the total # of reads is so small). ```; rob@feynman:/mnt/scratch3/rob/JoshTest$ ~/SoftwareStaging/salmon/scripts/SalmonBeta-0.6.5-pre_CentOS5/bin/salmon quant -p 15 -i salmon_index -l IU -1 ../strange_peak/19232_1_1.fastq -2 ../strange_peak/19232_1_2.fastq -o quant_binary; Version Info: This is the most recent version of Salmon.; # salmon (mapping-based) v0.6.0; # [ program ] => salmon; # [ command ] => quant; # [ threads ] => { 15 }; # [ index ] => { salmon_index }; # [ libType ] => { IU }; # [ mates1 ] => { ../strange_peak/19232_1_1.fastq }; # [ mates2 ] => { ../strange_peak/19232_1_2.fastq }; # [ output ] => { quant_binary }; Logs will be written to quant_binary/logs; there is 1[2016-03-31 14:05:14.184] [jointLog] [info] parsing read library format; lib; Loading 64-bit quasi index[2016-03-31 14:05:14.266] [stderrLog] [info] Loading Suffix Array; [2016-03-31 14:05:14.266] [jointLog] [info] Loading Quasi index. [2016-03-31 14:07:58.647] [stderrLog] [info] Loading Transcript Info; [2016-03-31 14:08:59.703] [stderrLog] [info] Loading Rank-Select Bit Array; [2016-03-31 14:09:06.744] [stderrLog] [info] There were 2027284 set bits in the bit array; [2016-03-31 14:09:08.123] [stderrLog] [info] Computing transcript lengths; [2016-03-31 14:09:08.240] [stderrLog] [info] Waiting to finish loading hash; Index contained 2027284 targets; [2016-03-31 14:09:15.789] [jointLog] [info] done; [2016-03-31 14:09:15.786] [stderrLog] [info] Successfully loaded position hash; [2016-03-31 14:09:15.789] [stderrLog] [info] Done loading index. [2016-03-31 14:09:36.623] [jointLog] [info] Computed 8083 rich equivalence classes for further processing; [2016-03-31 14:09:36.623] [jointLog] [info] Counted 159824 total reads in th",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/54#issuecomment-204066023:65,load,load,65,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/54#issuecomment-204066023,1,['load'],['load']
Performance,The cache and find_package system have both given me more headaches than they have saved I think.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/254#issuecomment-407465438:4,cache,cache,4,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/254#issuecomment-407465438,1,['cache'],['cache']
Performance,"The reason I bring this up is this line:. ```; [2020-05-04 21:30:58.701] [jointLog] [info] Loading Quasi index; ```. suggests salmon is trying to load the wrong type of index (the `quasi` index), since the new versions only support pufferfish-based indexes (and the 16G index to which you refer is a pufferfish-based index).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/518#issuecomment-623679572:91,Load,Loading,91,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/518#issuecomment-623679572,2,"['Load', 'load']","['Loading', 'load']"
Performance,The single-cell mode of salmon performs CB correction and knee based thresholding before mapping and quantification. That's why some of the reads from CB with very low frequency would never map.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/702#issuecomment-916883967:31,perform,performs,31,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/702#issuecomment-916883967,1,['perform'],['performs']
Performance,"There should be easy ways to handle reading line-buffered input from two file descriptors, where both file descriptors could be identical, and then passing these streams internally to buffers to be chunked for multithreaded processing. This would give you one code path for ingesting data, and the command line interface could remain the same as it is currently, with the possible addition of mapping the `-` symbol to `/dev/fd/0`. Is there really much to be gained from buffering all input in byte chunks up front? Remembering that unix pipes are buffered somewhat by default anyway? There has to be an acceptable way to handle line-based input in a more flexible way. In Python I would do:. ``` python; import argparse. example_parser = argparse.ArgumentParser(); example_parser.add_argument('-fq1', type=argparse.FileType('r')); example_parser.add_argument('-fq2', type=argparse.FileType('r')); args = parser.parse_args(). for line1, line2 in zip(args.fq1, args.fq2):; do_stuff_with_lines(); ```. You could then call the program flexibly:. ``` bash; $ example -fq1 file1.fq -fq2 file2.fq; $ example -fq1 <(gzip -dc file1.fq.gz) -fq2 <(gzip -dc file2.fq.gz); $ other_interleaved_process | example -fq1 - -fq2 -; ```. The caveat for the code above is that you would want to replace `argparse.FileType` with some class that reads 4 lines at a time - I'm sure there's no shortage of Python FASTQ readers that do that. And I know that you're looking for C++ libraries that perform well for your purposes, and my Python example is just a toy, but I think designing the option parser to at least **accept** streams and file-like objects and handle them using the same code path would be a worthy reason to refactor a bit.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/29#issuecomment-168545456:1471,perform,perform,1471,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/29#issuecomment-168545456,1,['perform'],['perform']
Performance,"This is a _good idea_. There's a little bit of trickiness, in that the multi-threaded read parser need not provide reads in the same order as in the input file. However, I think we could have a heuristic that checks for ordering according to the reference _within_ each parallel-processed bucket. It probably also makes sense to provide a flag to override it if the user is **sure** that the reads are not ordered.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/13#issuecomment-142744935:71,multi-thread,multi-threaded,71,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/13#issuecomment-142744935,1,['multi-thread'],['multi-threaded']
Performance,"This is failing on our local drone CI during runtime. The log output is :. ```; + echo ""[Testing quant]""; [Testing quant]; + ./.drone/test_quant.sh; Holy build box activated; Prefix: /hbb_exe; CFLAGS: -g -O2 -fvisibility=hidden -I/hbb_exe/include ; LDFLAGS: -L/hbb_exe/lib -static-libstdc++; STATICLIB_CFLAGS: -g -O2 -fvisibility=hidden -I/hbb_exe/include ; SHLIB_CFLAGS: -g -O2 -fvisibility=hidden -I/hbb_exe/include ; SHLIB_LDFLAGS: -L/hbb_exe/lib -static-libstdc++; [Drone test] current path : /drone/src/github.com/COMBINE-lab/salmon; [Drone test] making quant test directory; [Drone test] run nextflow pipeline; N E X T F L O W ~ version 0.29.1; Launching `tests/test_quant.nf` [curious_gilbert] - revision: 4f25b30301; [warm up] executor > local; [91/922fac] Submitted process > buildIndex; ERROR ~ Error executing process > 'buildIndex'; Caused by:; Process `buildIndex` terminated with an error exit status (127); Command executed:; /drone/src/github.com/COMBINE-lab/salmon/bin/salmon index -t Homo_sapiens.GRCh37.75.cdna.pc.fa -i nfindex; Command exit status:; 127; Command output:; (empty); Command error:; /drone/src/github.com/COMBINE-lab/salmon/bin/salmon: error while loading shared libraries: libjemalloc.so.2: cannot open shared object file: No such file or directory; Work dir:; /drone/src/github.com/COMBINE-lab/salmon/work/91/922facec25da43edd4a2ce82f2289d; Tip: when you have fixed the problem you can continue the execution appending to the nextflow command line the option `-resume`; -- Check '.nextflow.log' file for detail; ```. So, it seems to be due to failure to find the dynamic shared library for jemalloc. Any idea why that might be?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/348#issuecomment-472495264:1182,load,loading,1182,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/348#issuecomment-472495264,1,['load'],['loading']
Performance,"This is the initial output log, where it reports an inccorrect gene annotation:. ---; Version Info: This is the most recent version of salmon.; -----------------------------------------; | Loading contig table | Time = 13.512 s; -----------------------------------------; size = 16145665; -----------------------------------------; | Loading contig offsets | Time = 382.03 ms; -----------------------------------------; -----------------------------------------; | Loading reference lengths | Time = 9.4861 ms; -----------------------------------------; -----------------------------------------; | Loading mphf table | Time = 2.4236 s; -----------------------------------------; size = 1057188904; Number of ones: 16145664; Number of ones per inventory item: 512; Inventory entries filled: 31535; -----------------------------------------; | Loading contig boundaries | Time = 4.031 s; -----------------------------------------; size = 1057188904; -----------------------------------------; | Loading sequence | Time = 1.983 s; -----------------------------------------; size = 572818984; -----------------------------------------; | Loading positions | Time = 14.658 s; -----------------------------------------; size = 942318702; -----------------------------------------; | Loading reference sequence | Time = 1.4932 s; -----------------------------------------; -----------------------------------------; | Loading reference accumulative lengths | Time = 10.959 ms; -----------------------------------------; Error: invalid feature coordinates (end<start!) at line:; NC_029855.1	RefSeq	gene	406748	107842	.	+	.	gene_id ""A5N79_gp28""; db_xref ""GeneID:27215502""; exception ""trans-splicing""; gbkey ""Gene""; gene ""nad2""; gene_biotype ""protein_coding""; locus_tag ""A5N79_gp28""; ; --- . After I remove the erroneous entry, there is no more complaint:. ---; Version Info: This is the most recent version of salmon.; -----------------------------------------; | Loading contig table | Time = 14.648 s; -----",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/569#issuecomment-709699746:189,Load,Loading,189,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/569#issuecomment-709699746,6,['Load'],['Loading']
Performance,"Total Unique barcodes found: 4096; [2018-12-12 15:08:51.146] [alevinLog] [info] Used Barcodes except Whitelist: 1864; [2018-12-12 15:08:51.272] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify. [2018-12-12 15:08:51.272] [alevinLog] [info] parsing read library format; [2018-12-12 15:08:51.375] [stderrLog] [info] Loading Suffix Array ; [2018-12-12 15:08:51.272] [jointLog] [info] There is 1 library.; [2018-12-12 15:08:51.375] [jointLog] [info] Loading Quasi index; [2018-12-12 15:08:51.375] [jointLog] [info] Loading 32-bit quasi index; [2018-12-12 15:09:10.216] [stderrLog] [info] Loading Transcript Info ; [2018-12-12 15:09:15.719] [stderrLog] [info] Loading Rank-Select Bit Array; [2018-12-12 15:09:16.330] [stderrLog] [info] There were 205,870 set bits in the bit array; [2018-12-12 15:09:16.343] [stderrLog] [info] Computing transcript lengths; [2018-12-12 15:09:16.343] [stderrLog] [info] Waiting to finish loading hash; [2018-12-12 15:09:21.460] [stderrLog] [info] Done loading index; [2018-12-12 15:09:21.460] [jointLog] [info] done; [2018-12-12 15:09:21.460] [jointLog] [info] Index contained 205,870 targets. processed 0 Million fragments; processed 1 Million fragments; processed 1 Million fragments; ..............; processed 74 Million fragments; hits: 111594303, hits per frag: 1.50848[2018-12-12 15:12:07.666] [jointLog] [info] Thread saw mini-batch with a maximum of 5.34% zero probability fragments; [2018-12-12 15:12:07.677] [jointLog] [info] Thread saw mini-batch with a maximum of 5.48% zero probability fragments. [2018-12-12 15:12:07.721] [jointLog] [info] Computed 173,365 rich equivalence classes for further processing; [2018-12-12 15:12:07.721] [jointLog] [info] Counted 27,831,508 total reads in the equivalence classes ; [2018-12-12 15:12:07.721] [jointLog] [warning] Found 31347 reads with `N` in the UMI sequence and ignored the reads.; Please report on github if this number is too large; [2018-12-12 15:12:07.721] [jointLog] [info] Mapping rate = 37",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/329#issuecomment-446668422:4854,load,loading,4854,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/329#issuecomment-446668422,1,['load'],['loading']
Performance,"Ugh, salmon built, but it crashes. ```; module load salmon; cd /tmp; gunzip -c $ROOT_SALMON/sample_data.tgz | tar -xf -; cd sample_data; salmon index -t transcripts.fasta -i sample_salmon_fmd_index --type fmd; Segmentation fault (core dumped); ```; I wonder if this is related to the segfault seen when Pufferfish was built on the same platfrom from the git repository (today also.)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641545954:47,load,load,47,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641545954,1,['load'],['load']
Performance,"Uh, why then does ""make test"" fail if the root directory name is changed? That was using the binary/libraries in $WHEREVER, after bin and lib below the root directory were removed. Typically that sort of operation doesn't care what the top level is named. For some future release, perhaps the run time dynamic loading of libraries could look up the path to libtbb.so.2 and try that first, before falling back to LD_LIBRARY_PATH? On my system ldd of salmon shows a link to libtbb.so.2, no LD_LIBRARY_PATH needed. ldd does not show any links to libtbb.malloc*. The program will do at least ""salmon --help' that way without any errors or warnings. That isn't sufficient to pass ""make test"" though (even when the directory has not been renamed). It seems that libtbb.malloc* libraries are used during that test, and that use requires LD_LIBRARY_PATH. Only when they are found that way does ""make test"" work.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/236#issuecomment-397063656:310,load,loading,310,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/236#issuecomment-397063656,1,['load'],['loading']
Performance,"We seem to get the same mapping rate etc., so I'm assuming something different is happening between the end of the normal optimization and the Gibbs sampling between your run and my run.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-266935953:122,optimiz,optimization,122,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-266935953,1,['optimiz'],['optimization']
Performance,"Well, I figured out how to run Salmon under Docker, but how do I feed it data?. `[rancher@rancher ~]$ docker run combinelab/salmon salmon; Salmon v0.8.2. Usage: salmon -h|--help or; salmon -v|--version or; salmon -c|--cite or; salmon [--no-version-check] <COMMAND> [-h | options]. Commands:; cite Show salmon citation information; index Create a salmon index; quant Quantify a sample; swim Perform super-secret operation; [rancher@rancher ~]$ ls rna.fa.gz; rna.fa.gz; [rancher@rancher ~]$ docker run combinelab/salmon salmon index -t rna.fa.gz -i mus.rna.index; Version Info: This is the most recent version of Salmon.; The file [rna.fa.gz] provided for the transcriptome does not appear to exist.[rancher@rancher ~]$`",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/164#issuecomment-338276821:390,Perform,Perform,390,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/164#issuecomment-338276821,1,['Perform'],['Perform']
Performance,"Well, one can certainly use a tool (like gffread or rsem-prepare-reference) to take a genome and a (possibly custom/augmented) GTF to extract a set of target transcripts. Above, it looks like you were only processing between 90 and 100k transcripts. Given the overall size of the overall reference — ~2.4 billion nucleotides — my guess would be that some of these transcripts may be exceedingly long (and perhaps extracted incorrectly from the underlying tool). I should note that an index can be built on large references (which is why we support 64-bit index construction), but it's a very rare use-case as most transcriptomes (even large _de novo_ transcriptomes) rarely cross the 2^31 barrier, and I would expect it to consume quite a bit of memory. The default `quasi` indexer of Salmon is optimized to be very fast for typical sized transcriptomes (usually a few hundred mega-bases) at the cost of using more memory. The alternative `fmd` index can be made more memory efficient, by setting a larger sampling factor, but the resulting mapping will be slower (though still much faster than standard alignment). I would first check to see if the transcripts.fa file contains what you were expecting (i.e. the normal transcriptome + the auxiliary transcripts you were interested in quantifying), and that you actually have close to 2.4Gb of non-redundant transcriptome sequence that you want to quantify. If this is the case, the options are to try and build the quasi-index on a large memory machine (building the index requires more memory than mapping with the constructed index), or using the fmd-index with a large sampling factor. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/39#issuecomment-176802594:795,optimiz,optimized,795,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/39#issuecomment-176802594,1,['optimiz'],['optimized']
Performance,"Why am I seeing much higher values for this gene with FeatureCounts?. I have now run FeatureCounts several times with different overlaps (minOverlap =25, minOverlap =50, minOverlap =75min Overlap =100) and indeed the counts have decreased (again the psbI example: 8685 , 6011, 4237, 1805 accordingly). Again, this is a good argument for the hypothesis put forward. >Why does running Salmon outside nf-core lead to much higher values?. Hopefully, after I run Decoy mode, this problem is solved. I also tried mapping mode with the --softclipOverhangs option. That increased the counts (psbI : 4696 counts); playing around with the --minScoreFraction flag in addition to the --softclipOverhangs flag also increased the numbers ( minScoreFraction= 0 ->psbI = 8496; minScoreFraction= 0.5 ->psbI = 5633; minScoreFraction= 0.7 ->psbI =3627 ). . So, in summary, your explanation seems to be completely correct. ; In the case that decoy mode resolves the difference between the pipeline and the run outside the pipeline, I would not give this to the nf-core people. But I will if there are still large discrepancies after the run. I'm still not sure what the best parameters are for my analysis, but the --softclipOverhangs flag seems to be the best option for me now.; So thanks again!. @drpatelh. Thank you very much for your quick reply as well. ; I was a bit inaccurate when I said I used the FeatureCounts from the pipeline. I actually wasn't able to use the resulting .txt files. Instead, I used the resulting bam file from the pipeline to perform a FeatureCounts analysis on R. I hope this information answers the question of how I can compare the two results?; My genome and gtf file are from [EnsemblPlants](https://plants.ensembl.org/Arabidopsis_thaliana/Info/Index), so they should be fine. In the MultiQC file, the vast majority of reads align to protein coding regions according to FeatureCounts, so I hope my primary files are fine. . Thanks again for your help and time!. All the best ; Florian",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/798#issuecomment-1238043213:2491,perform,perform,2491,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/798#issuecomment-1238043213,1,['perform'],['perform']
Performance,"Yes; precisely. In the alignment-based case, Salmon will infer the library type from the alignments. In the case you mention above (someone performs stranded alignment using an unstranded library), Salmon would incorrectly infer a stranded type, though it would actually be a byproduct of passing incorrect options to the aligner. In the read-based mode, since we have control over both the mapping and quantification steps, we can avoid such an issue. However, it seems to me _ok_ to incorrectly infer a library type if we were passed incorrect alignments in the first place, right?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/79#issuecomment-241813836:140,perform,performs,140,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/79#issuecomment-241813836,1,['perform'],['performs']
Performance,"You mean like cloud services to perform the DE analysis? It’s always possible to round the non-integer counts to the nearest integer. However, reliable abundance estimation tools (e.g. RSEM) have been around long enough now that it’s worth pushing any cloud service you might be using to properly deal with these types of inputs. We do differential analysis quite commonly with DESeq2, and salmon -> tximport -> DESeq2 is a quite low-friction solution.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/437#issuecomment-751195284:32,perform,perform,32,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/437#issuecomment-751195284,1,['perform'],['perform']
Performance,"[alevinLog] [info] Done with Barcode Processing; Moving to Quantify; > ; > [2020-06-04 12:26:11.113] [alevinLog] [info] parsing read library format; > [2020-06-04 12:27:21.373] [alevinLog] [info] Starting optimizer; > ; > [2020-06-04 12:27:22.086] [alevinLog] [warning] mrna file not provided; using is 1 less feature for whitelisting; > [2020-06-04 12:27:22.086] [alevinLog] [warning] rrna file not provided; using is 1 less feature for whitelisting; > [2020-06-04 12:27:22.409] [alevinLog] [info] Total 23937.00 UMI after deduplicating.; > [2020-06-04 12:27:22.409] [alevinLog] [info] Total 91 BiDirected Edges.; > [2020-06-04 12:27:22.409] [alevinLog] [info] Total 82 UniDirected Edges.; > [2020-06-04 12:27:22.409] [alevinLog] [warning] Skipped 82268 barcodes due to No mapped read; > [2020-06-04 12:27:22.412] [alevinLog] [info] Clearing EqMap; Might take some time.; > [2020-06-04 12:27:22.418] [alevinLog] [warning] Num Low confidence barcodes too less 1 < 100.Can't performing whitelisting; Skipping; > [2020-06-04 12:27:22.418] [alevinLog] [info] Finished optimizer. Run 2: `salmon alevin -l ISR --citeseq --barcodeLength 16 --umiLength 10 --end 5 --featureStart 19 --featureLength 21 --maxNumBarcodes 200000 --freqThreshold 1 --lowRegionMinNumBarcodes 100`. > [2020-06-04 12:40:45.455] [alevinLog] [info] set CITE-seq minScoreFraction parameter to : 0.797619; > [2020-06-04 12:40:45.456] [alevinLog] [info] Found 64 transcripts(+0 decoys, +0 short and +0 duplicate names in the index); > [2020-06-04 12:40:45.456] [alevinLog] [info] Filled with 64 txp to gene entries ; > [2020-06-04 12:40:45.456] [alevinLog] [info] Found all transcripts to gene mappings; > [2020-06-04 12:40:45.461] [alevinLog] [info] Processing barcodes files (if Present) ; > ; > [2020-06-04 12:42:01.202] [alevinLog] [info] Done barcode density calculation.; > [2020-06-04 12:42:01.202] [alevinLog] [info] # Barcodes Used: [32m52200250[0m / [31m52200250[0m.; > [2020-06-04 12:42:01.300] [alevinLog] [info] Forcing ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-638991199:3944,perform,performing,3944,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-638991199,1,['perform'],['performing']
Performance,"[info] Done indexing Barcodes; [2019-06-06 19:24:55.692] [alevinLog] [info] Total Unique barcodes found: 50; [2019-06-06 19:24:55.692] [alevinLog] [info] Used Barcodes except Whitelist: 0; [2019-06-06 19:24:55.716] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify. [2019-06-06 19:24:55.716] [alevinLog] [info] parsing read library format; [2019-06-06 19:24:55.716] [jointLog] [info] There is 1 library.; [2019-06-06 19:24:55.889] [jointLog] [info] Loading Quasi index; [2019-06-06 19:24:55.889] [jointLog] [info] Loading 32-bit quasi index; [2019-06-06 19:24:55.890] [stderrLog] [info] Loading Suffix Array ; [2019-06-06 19:24:56.791] [stderrLog] [info] Loading Transcript Info ; [2019-06-06 19:24:57.025] [stderrLog] [info] Loading Rank-Select Bit Array; [2019-06-06 19:24:57.061] [stderrLog] [info] There were 136,011 set bits in the bit array; [2019-06-06 19:24:57.084] [stderrLog] [info] Computing transcript lengths; [2019-06-06 19:24:57.084] [stderrLog] [info] Waiting to finish loading hash; [2019-06-06 19:25:06.552] [jointLog] [info] done; [2019-06-06 19:25:06.552] [jointLog] [info] Index contained 136,011 targets; [2019-06-06 19:25:06.552] [stderrLog] [info] Done loading index; [2019-06-06 19:25:06.728] [alevinLog] [error] Barcode not found in frequency table; ```. Salmon Quant log is this. ```; [2019-06-06 19:23:29.519] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2019-06-06 19:23:29.519] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2019-06-06 19:23:29.520] [jointLog] [info] Usage of --validateMappings, without --hardFilter implies use of range factorization. rangeFactorizationBins is being set to 4; [2019-06-06 19:23:29.520] [jointLog] [info] Usage of --validateMappings implies a default consensus slack of 0.2. Setting consensusSlack to 0.2.; [2019-06-06 19:23:29.520] [jointLog] [info] Using default ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/369#issuecomment-499592790:1837,load,loading,1837,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/369#issuecomment-499592790,1,['load'],['loading']
Performance,"[info] finished populating pos vector ; [2022-04-16 11:19:53.442] [puff::index::jointLog] [info] writing index components ; [2022-04-16 11:19:55.117] [puff::index::jointLog] [info] finished writing dense pufferfish index ; [2022-04-16 11:19:55.401] [jLog] [info] done building index. and the log for quantification:. > [2022-04-16 11:23:51.572] [jointLog] [info] setting maxHashResizeThreads to 48 ; [2022-04-16 11:23:51.572] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored. ; [2022-04-16 11:23:51.572] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65 ; [2022-04-16 11:23:51.572] [jointLog] [info] Setting consensusSlack to selective-alignment default of 0.35. [2022-04-16 11:23:51.572] [jointLog] [info] parsing read library format ; [2022-04-16 11:23:51.572] [jointLog] [info] There is 1 library. ; [2022-04-16 11:23:51.694] [jointLog] [info] Loading pufferfish index ; [2022-04-16 11:23:51.695] [jointLog] [info] Loading dense pufferfish index. ; [2022-04-16 11:23:53.681] [jointLog] [info] done ; [2022-04-16 11:23:53.681] [jointLog] [info] Index contained 245,261 targets ; [2022-04-16 11:23:53.776] [jointLog] [info] Number of decoys : 0 ; [2022-04-16 11:24:42.358] [jointLog] [info] Computed 960,194 rich equivalence classes for further processing [2022-04-16 11:24:42.358] [jointLog] [info] Counted 23,784,776 total reads in the equivalence classes [2022-04-16 11:24:42.426] [jointLog] [info] Number of mappings discarded because of alignment score : 3,206,484 [2022-04-16 11:24:42.426] [jointLog] [info] Number of fragments entirely discarded because of alignment score : 170,372 [2022-04-16 11:24:42.426] [jointLog] [info] Number of fragments discarded because they are best-mapped to decoys : 0 [2022-04-16 11:24:42.426] [jointLog] [info] Number of fragments discarded because they have only dovetail (discordant) mappings to valid targets : 154,1",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/768#issuecomment-1100734317:15981,Load,Loading,15981,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/768#issuecomment-1100734317,1,['Load'],['Loading']
Performance,"[jointLog] [info] iteration = 700 | max rel diff. = 0.0130094; [2016-01-03 00:34:22.092] [jointLog] [info] iteration = 800 | max rel diff. = 0.0100546; [2016-01-03 00:34:22.196] [jointLog] [info] iteration = 882 | max rel diff. = 0.00861472; [2016-01-03 00:34:22.205] [jointLog] [info] Finished optimizer; [2016-01-03 00:34:22.205] [jointLog] [info] writing output. [2016-01-03 00:34:22.433] [jointLog] [warning] NOTE: Read Lib [( reads_1.fastq, reads_2.fastq )] :. Greater than 5% of the alignments (but not, necessarily reads) disagreed with the provided library type; check the file: normal_salmon_out/libFormatCounts.txt for details; ```. Then I ran. ```; cat all_reads.fastq | salmon quant -i /nfs/research2/teichmann/reference/mus-musculus/salmon/quasi/mouse_cdna_38.p3.78_repbase_ercc.fa -l IU -1 /dev/fd/0 -2 /dev/fd/0 -o interlaced_salmon_out; ```. Now I get. ```; [2016-01-03 00:36:48.844] [jointLog] [info] parsing read library format; [2016-01-03 00:36:49.995] [jointLog] [info] Loading Quasi index; [2016-01-03 00:37:08.293] [jointLog] [info] done; [2016-01-03 00:37:25.106] [jointLog] [info] Computed 23484 rich equivalence classes for further processing; [2016-01-03 00:37:25.106] [jointLog] [info] Counted 667333 total reads in the equivalence classes; [2016-01-03 00:37:25.106] [fileLog] [info]; At end of round 0; ==================; Observed 3060000 total fragments (3060000 in most recent round). [2016-01-03 00:37:31.905] [jointLog] [warning] Only 667333 fragments were mapped, but the number of burn-in fragments was set to 5000000.; The effective lengths have been computed using the observed mappings. [2016-01-03 00:37:31.905] [jointLog] [info] Mapping rate = 21.8083%. [2016-01-03 00:37:31.905] [jointLog] [info] finished quantifyLibrary(); [2016-01-03 00:37:31.905] [jointLog] [info] Starting optimizer; [2016-01-03 00:37:33.275] [jointLog] [info] Marked 0 weighted equivalence classes as degenerate; [2016-01-03 00:37:33.279] [jointLog] [info] iteration = 0 | max rel diff.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/29#issuecomment-168447784:2998,Load,Loading,2998,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/29#issuecomment-168447784,1,['Load'],['Loading']
Performance,"] Done indexing Barcodes; [2018-12-12 15:08:51.146] [alevinLog] [info] Total Unique barcodes found: 4096; [2018-12-12 15:08:51.146] [alevinLog] [info] Used Barcodes except Whitelist: 1864; [2018-12-12 15:08:51.272] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify. [2018-12-12 15:08:51.272] [alevinLog] [info] parsing read library format; [2018-12-12 15:08:51.375] [stderrLog] [info] Loading Suffix Array ; [2018-12-12 15:08:51.272] [jointLog] [info] There is 1 library.; [2018-12-12 15:08:51.375] [jointLog] [info] Loading Quasi index; [2018-12-12 15:08:51.375] [jointLog] [info] Loading 32-bit quasi index; [2018-12-12 15:09:10.216] [stderrLog] [info] Loading Transcript Info ; [2018-12-12 15:09:15.719] [stderrLog] [info] Loading Rank-Select Bit Array; [2018-12-12 15:09:16.330] [stderrLog] [info] There were 205,870 set bits in the bit array; [2018-12-12 15:09:16.343] [stderrLog] [info] Computing transcript lengths; [2018-12-12 15:09:16.343] [stderrLog] [info] Waiting to finish loading hash; [2018-12-12 15:09:21.460] [stderrLog] [info] Done loading index; [2018-12-12 15:09:21.460] [jointLog] [info] done; [2018-12-12 15:09:21.460] [jointLog] [info] Index contained 205,870 targets. processed 0 Million fragments; processed 1 Million fragments; processed 1 Million fragments; ..............; processed 74 Million fragments; hits: 111594303, hits per frag: 1.50848[2018-12-12 15:12:07.666] [jointLog] [info] Thread saw mini-batch with a maximum of 5.34% zero probability fragments; [2018-12-12 15:12:07.677] [jointLog] [info] Thread saw mini-batch with a maximum of 5.48% zero probability fragments. [2018-12-12 15:12:07.721] [jointLog] [info] Computed 173,365 rich equivalence classes for further processing; [2018-12-12 15:12:07.721] [jointLog] [info] Counted 27,831,508 total reads in the equivalence classes ; [2018-12-12 15:12:07.721] [jointLog] [warning] Found 31347 reads with `N` in the UMI sequence and ignored the reads.; Please report on github if this number is t",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/329#issuecomment-446668422:4790,load,loading,4790,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/329#issuecomment-446668422,1,['load'],['loading']
Performance,"] Total 5344(has 999 low confidence) barcodes; [2018-12-06 11:16:55.059] [alevinLog] [info] Done True Barcode Sampling; [2018-12-06 11:16:55.395] [alevinLog] [info] Done populating Z matrix; [2018-12-06 11:16:55.453] [alevinLog] [info] Done indexing Barcodes; [2018-12-06 11:16:55.453] [alevinLog] [info] Total Unique barcodes found: 4180559; [2018-12-06 11:16:55.453] [alevinLog] [info] Used Barcodes except Whitelist: 134856; [2018-12-06 11:16:56.218] [jointLog] [info] There are 2 libraries.; [2018-12-06 11:16:56.292] [jointLog] [info] Loading Quasi index; [2018-12-06 11:16:56.294] [jointLog] [info] Loading 32-bit quasi index; [2018-12-06 11:16:56.205] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify. [2018-12-06 11:16:56.218] [alevinLog] [info] parsing read library format; [2018-12-06 11:16:56.296] [stderrLog] [info] Loading Suffix Array ; [2018-12-06 11:16:56.846] [stderrLog] [info] Loading Transcript Info ; [2018-12-06 11:16:57.009] [stderrLog] [info] Loading Rank-Select Bit Array; [2018-12-06 11:16:57.046] [stderrLog] [info] There were 167,268 set bits in the bit array; [2018-12-06 11:16:57.063] [stderrLog] [info] Computing transcript lengths; [2018-12-06 11:16:57.064] [stderrLog] [info] Waiting to finish loading hash; [2018-12-06 11:17:00.929] [jointLog] [info] done; [2018-12-06 11:17:00.929] [jointLog] [info] Index contained 167,268 targets. processed 267 Million fragmentsrrLog] [info] Done loading index; hits: 844899161, hits per frag: 3.15864^[[D. [2018-12-06 11:45:12.188] [jointLog] [info] Computed 118,295 rich equivalence classes for further processing; [2018-12-06 11:45:12.188] [jointLog] [info] Counted 154,595,094 total reads in the equivalence classes ; [2018-12-06 11:45:12.188] [jointLog] [warning] Found 115077 reads with `N` in the UMI sequence and ignored the reads.; Please report on github if this number is too large; [2018-12-06 11:45:12.188] [jointLog] [info] Mapping rate = 57.7821%. [2018-12-06 11:45:12.188] [jointLog] [info] fin",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/328#issuecomment-445008548:6493,Load,Loading,6493,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/328#issuecomment-445008548,1,['Load'],['Loading']
Performance,"] [info] Total 293(has 193 low confidence) barcodes; [2019-01-29 09:56:53.224] [alevinLog] [info] Done True Barcode Sampling; [2019-01-29 09:56:53.254] [alevinLog] [info] Done populating Z matrix; [2019-01-29 09:56:53.255] [alevinLog] [info] Done indexing Barcodes; [2019-01-29 09:56:53.255] [alevinLog] [info] Total Unique barcodes found: 125401; [2019-01-29 09:56:53.255] [alevinLog] [info] Used Barcodes except Whitelist: 1256; [2019-01-29 09:56:53.281] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify. [2019-01-29 09:56:53.281] [alevinLog] [info] parsing read library format; [2019-01-29 09:56:53.412] [stderrLog] [info] Loading Suffix Array ; [2019-01-29 09:56:53.281] [jointLog] [info] There is 1 library.; [2019-01-29 09:56:53.410] [jointLog] [info] Loading Quasi index; [2019-01-29 09:56:53.411] [jointLog] [info] Loading 32-bit quasi index; [2019-01-29 09:56:54.551] [stderrLog] [info] Loading Transcript Info ; [2019-01-29 09:56:54.826] [stderrLog] [info] Loading Rank-Select Bit Array; [2019-01-29 09:56:54.883] [stderrLog] [info] There were 80,511 set bits in the bit array; [2019-01-29 09:56:54.908] [stderrLog] [info] Computing transcript lengths; [2019-01-29 09:56:54.908] [stderrLog] [info] Waiting to finish loading hash; [2019-01-29 09:57:09.336] [stderrLog] [info] Done loading index; [2019-01-29 09:57:09.336] [jointLog] [info] done; [2019-01-29 09:57:09.336] [jointLog] [info] Index contained 80,511 targets. processed 2 Million fragments; hits: 812181, hits per frag: 0.326777. [2019-01-29 09:57:36.647] [alevinLog] [info] Starting optimizer; [2019-01-29 09:57:36.587] [jointLog] [info] Computed 12,933 rich equivalence classes for further processing; [2019-01-29 09:57:36.587] [jointLog] [info] Counted 242,520 total reads in the equivalence classes ; [2019-01-29 09:57:36.601] [jointLog] [warning] Only 242520 fragments were mapped, but the number of burn-in fragments was set to 5000000.; The effective lengths have been computed using the observed mappin",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/337#issuecomment-458481722:8487,Load,Loading,8487,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/337#issuecomment-458481722,1,['Load'],['Loading']
Performance,"] [jointLog] [info] iteration = 400 | max rel diff. = 2.20112 ; [2022-04-16 11:25:15.019] [jointLog] [info] iteration = 500 | max rel diff. = 8.9451 ; [2022-04-16 11:25:20.936] [jointLog] [info] iteration = 600 | max rel diff. = 8.80249 ; [2022-04-16 11:25:26.808] [jointLog] [info] iteration = 700 | max rel diff. = 0.955605 ; [2022-04-16 11:25:32.739] [jointLog] [info] iteration = 800 | max rel diff. = 0.783506 ; [2022-04-16 11:25:38.614] [jointLog] [info] iteration = 900 | max rel diff. = 0.315252 ; [2022-04-16 11:25:44.475] [jointLog] [info] iteration = 1,000 | max rel diff. = 0.345064 ; [2022-04-16 11:25:50.254] [jointLog] [info] iteration = 1,100 | max rel diff. = 0.277546 ; [2022-04-16 11:25:56.156] [jointLog] [info] iteration = 1,200 | max rel diff. = 0.350471 ; [2022-04-16 11:26:02.062] [jointLog] [info] iteration = 1,300 | max rel diff. = 0.0385924 ; [2022-04-16 11:26:08.103] [jointLog] [info] iteration = 1,400 | max rel diff. = 10.4871 ; [2022-04-16 11:26:14.033] [jointLog] [info] iteration = 1,500 | max rel diff. = 0.0571527 ; [2022-04-16 11:26:20.066] [jointLog] [info] iteration = 1,600 | max rel diff. = 0.260293 ; [2022-04-16 11:26:26.129] [jointLog] [info] iteration = 1,700 | max rel diff. = 0.0360025 ; [2022-04-16 11:26:32.099] [jointLog] [info] iteration = 1,800 | max rel diff. = 0.0550004 ; [2022-04-16 11:26:38.060] [jointLog] [info] iteration = 1,900 | max rel diff. = 1.52554 ; [2022-04-16 11:26:45.086] [jointLog] [info] iteration = 2,000 | max rel diff. = 0.0264604 ; [2022-04-16 11:26:54.108] [jointLog] [info] iteration = 2,100 | max rel diff. = 0.0825479 ; [2022-04-16 11:27:03.466] [jointLog] [info] iteration = 2,200 | max rel diff. = 0.0842979 ; [2022-04-16 11:27:12.895] [jointLog] [info] iteration = 2,300 | max rel diff. = 0.441117 ; [2022-04-16 11:27:21.476] [jointLog] [info] iteration = 2,389 | max rel diff. = 0.0091923 ; [2022-04-16 11:27:21.658] [jointLog] [info] Finished optimizer ; [2022-04-16 11:27:21.658] [jointLog] [info] writing output",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/768#issuecomment-1100734317:19756,optimiz,optimizer,19756,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/768#issuecomment-1100734317,1,['optimiz'],['optimizer']
Performance,"] iteration = 1000 | max rel diff. = 0.0146819; [2016-01-02 20:17:40.968] [jointLog] [info] iteration = 1100 | max rel diff. = 0.021278; [2016-01-02 20:17:41.343] [jointLog] [info] iteration = 1200 | max rel diff. = 0.0188351; [2016-01-02 20:17:41.695] [jointLog] [info] iteration = 1300 | max rel diff. = 0.0115257; [2016-01-02 20:17:42.020] [jointLog] [info] iteration = 1400 | max rel diff. = 0.019727; [2016-01-02 20:17:42.346] [jointLog] [info] iteration = 1500 | max rel diff. = 0.0290858; [2016-01-02 20:17:42.679] [jointLog] [info] iteration = 1600 | max rel diff. = 0.0100559; [2016-01-02 20:17:42.993] [jointLog] [info] iteration = 1700 | max rel diff. = 0.0101365; [2016-01-02 20:17:43.314] [jointLog] [info] iteration = 1800 | max rel diff. = 0.0100707; [2016-01-02 20:17:43.650] [jointLog] [info] iteration = 1900 | max rel diff. = 0.0100722; [2016-01-02 20:17:43.933] [jointLog] [info] iteration = 1990 | max rel diff. = 0.00542674; [2016-01-02 20:17:43.937] [jointLog] [info] Finished optimizer; [2016-01-02 20:17:43.937] [jointLog] [info] writing output. [2016-01-02 20:17:44.160] [jointLog] [warning] NOTE: Read Lib [( SRP057125_SRS936134_1.fastq, SRP057125_SRS936134_2.fastq )] :. Greater than 5% of the alignments (but not, necessarily reads) disagreed with the provided library type; check the file: SRP057125_SRS936134_salmon_out/libFormatCoun ts.txt for details. [vale@ebi-003 salmon-problem]$; ```. The command run being:. ```; salmon quant \; -i mouse_cdna_38.p3.78_repbase_ercc.fa \; -l IU \; -1 SRP057125_SRS936134_1.fastq \; -2 SRP057125_SRS936134_2.fastq \; -o SRP057125_SRS936134_salmon_out \; -g /nfs/research2/teichmann/reference/mus-musculus/salmon/mouse_cdna38.78_repbase_ercc_index_gene_map.txt \; --biasCorrect \; --useFSPD; ```. But if I instead run salmon in the NFS directory where I want to run it, the core dumps... ```; [vale@ebi-003 mouse]$ salmon quant \; > -i /nfs/research2/teichmann/reference/mus-musculus/salmon/quasi/mouse_cdna_38.p3.78_repbase_ercc.fa",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/34#issuecomment-168426741:5240,optimiz,optimizer,5240,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/34#issuecomment-168426741,1,['optimiz'],['optimizer']
Performance,"_R1_001.fastq.gz }; ### [ mates2 ] => { /data2/csijcs/AML/RNA_seq/AML_total_MNC/total_MNCs/Fresh_samples/RHM5942/RHM5942_R2_001.fastq.gz }; ### [ threads ] => { 32 }; ### [ output ] => { /data2/csijcs/AML/RNA_seq/AML_total_MNC/total_MNCs/Fresh_samples/salmon_quants/RHM5942 }; Logs will be written to /data2/csijcs/AML/RNA_seq/AML_total_MNC/total_MNCs/Fresh_samples/salmon_quants/RHM5942/logs; [2018-07-27 16:24:55.658] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2018-07-27 16:24:55.658] [jointLog] [info] parsing read library format; [2018-07-27 16:24:55.658] [jointLog] [info] There is 1 library.; [2018-07-27 16:25:01.242] [jointLog] [info] Loading Quasi index; [2018-07-27 16:25:01.242] [jointLog] [info] Loading 32-bit quasi index; [2018-07-27 16:25:01.243] [stderrLog] [info] Loading Suffix Array ; [2018-07-27 16:25:42.630] [stderrLog] [info] Loading Transcript Info ; [2018-07-27 16:25:45.683] [stderrLog] [info] Loading Rank-Select Bit Array; [2018-07-27 16:25:47.834] [stderrLog] [info] There were 203027 set bits in the bit array; [2018-07-27 16:25:48.128] [stderrLog] [info] Computing transcript lengths; [2018-07-27 16:25:48.200] [stderrLog] [info] Waiting to finish loading hash; [2018-07-27 16:25:48.331] [stderrLog] [info] Done loading index; [2018-07-27 16:25:48.331] [jointLog] [info] done; [2018-07-27 16:25:48.331] [jointLog] [info] Index contained 203027 targets. processed 239500000 fragmentsintLog] [info] Automatically detected most likely library type as ISR; hits: 651420499, hits per frag: 2.72282[2018-07-27 16:51:47.947] [jointLog] [info] Thread saw mini-batch with a maximum of 1.70% zero probability fragments; [2018-07-27 16:51:47.947] [jointLog] [info] Thread saw mini-batch with a maximum of 1.68% zero probability fragments; [2018-07-27 16:51:47.947] [jointLog] [info] Thread saw mini-batch with a maximum of 1.68% zero probability fragments; [2018-07-27 16:51:47.947] [jointLog] [info] Thread saw mi",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/261#issuecomment-409427898:1531,Load,Loading,1531,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/261#issuecomment-409427898,1,['Load'],['Loading']
Performance,"_blank() # element_rect(fill = 'grey'); ) +; facet_wrap(paste('tx strand:', tx_strand) ~ paste('tx ID:', tx_id) + paste('myFasta seq type:', myFastaSeqType), ncol = 3, scales = 'free'). print(ggp). # dev.off(). ```. R session info:; ```; R version 4.0.2 (2020-06-22); Platform: x86_64-pc-linux-gnu (64-bit); Running under: CentOS Linux 7 (Core). Matrix products: default; BLAS/LAPACK: [hidden]/easybuild/software/2017/Core/imkl/2018.3.222/compilers_and_libraries_2018.3.222/linux/mkl/lib/intel64_lin/libmkl_gf_lp64.so. locale:; [1] LC_CTYPE=en_CA.UTF-8 LC_NUMERIC=C LC_TIME=en_CA.UTF-8 LC_COLLATE=en_CA.UTF-8 ; [5] LC_MONETARY=en_CA.UTF-8 LC_MESSAGES=en_CA.UTF-8 LC_PAPER=en_CA.UTF-8 LC_NAME=C ; [9] LC_ADDRESS=C LC_TELEPHONE=C LC_MEASUREMENT=en_CA.UTF-8 LC_IDENTIFICATION=C . attached base packages:; [1] parallel stats4 stats graphics grDevices utils datasets methods base . other attached packages:; [1] ggplot2_3.3.3 reshape2_1.4.4 Biostrings_2.58.0 XVector_0.30.0 rtracklayer_1.50.0 ; [6] GenomicRanges_1.42.0 GenomeInfoDb_1.26.7 IRanges_2.24.1 S4Vectors_0.28.1 BiocGenerics_0.36.1 ; [11] magrittr_2.0.1 data.table_1.14.0 . loaded via a namespace (and not attached):; [1] SummarizedExperiment_1.20.0 tidyselect_1.1.0 purrr_0.3.4 lattice_0.20-41 ; [5] colorspace_2.0-0 vctrs_0.3.7 generics_0.1.0 yaml_2.2.1 ; [9] utf8_1.2.1 XML_3.99-0.6 rlang_0.4.10 pillar_1.6.0 ; [13] glue_1.4.2 withr_2.4.1 DBI_1.1.1 BiocParallel_1.24.1 ; [17] matrixStats_0.58.0 GenomeInfoDbData_1.2.4 lifecycle_1.0.0 plyr_1.8.6 ; [21] stringr_1.4.0 zlibbioc_1.36.0 MatrixGenerics_1.2.1 munsell_0.5.0 ; [25] gtable_0.3.0 labeling_0.4.2 Biobase_2.50.0 fansi_0.4.2 ; [29] Rcpp_1.0.6 scales_1.1.1 DelayedArray_0.16.3 farver_2.1.0 ; [33] Rsamtools_2.6.0 digest_0.6.27 stringi_1.5.3 dplyr_1.0.5 ; [37] grid_4.0.2 tools_4.0.2 bitops_1.0-6 RCurl_1.98-1.3 ; [41] tibble_3.1.0 crayon_1.4.1 pkgconfig_2.0.3 ellipsis_0.3.1 ; [45] Matrix_1.2-18 assertthat_0.2.1 rstudioapi_0.13 R6_2.5.0 ; [49] GenomicAlignments_1.26.0 compiler_4.0.2; ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/655#issuecomment-826035191:11816,load,loaded,11816,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/655#issuecomment-826035191,1,['load'],['loaded']
Performance,_hg38.analysisSet_knownGene/genemap.txt }; ### [ output ] => { salmon_temp/REF/SRR2454069 }; ### [ auxDir ] => { aux_info }; ### [ numGibbsSamples ] => { 10 }; Logs will be written to salmon_temp/REF/SRR2454069/logs; [2016-12-15 15:58:50.157] [jointLog] [info] parsing read library format; [2016-12-15 15:58:50.157] [jointLog] [info] There is 1 library.; [2016-12-15 15:58:50.189] [jointLog] [info] Loading Quasi index; [2016-12-15 15:58:50.189] [jointLog] [info] Loading 32-bit quasi index; [2016-12-15 15:58:50.189] [stderrLog] [info] Loading Suffix Array; [2016-12-15 15:58:50.513] [stderrLog] [info] Loading Transcript Info; [2016-12-15 15:58:50.599] [stderrLog] [info] Loading Rank-Select Bit Array; [2016-12-15 15:58:50.661] [stderrLog] [info] There were 182608 set bits in the bit array; [2016-12-15 15:58:50.677] [stderrLog] [info] Computing transcript lengths; [2016-12-15 15:58:50.677] [stderrLog] [info] Waiting to finish loading hash; [2016-12-15 15:58:50.677] [stderrLog] [info] Done loading index; [2016-12-15 15:58:50.677] [jointLog] [info] done; [2016-12-15 15:58:50.677] [jointLog] [info] Index contained 182608 targets; [2016-12-15 15:58:51.587] [jointLog] [warning] Fragment GC bias correction is currently *experimental* in single-end libraries. Please use this option with caution. processed 16500000 fragments; hits: 44017772; hits per frag: 2.67057. [2016-12-15 16:01:44.937] [jointLog] [info] Computed 119318 rich equivalence classes for further processing; [2016-12-15 16:01:44.937] [jointLog] [info] Counted 12227080 total reads in the equivalence classes; [2016-12-15 16:01:44.948] [jointLog] [info] Mapping rate = 72.5194%. [2016-12-15 16:01:44.948] [jointLog] [info] finished quantifyLibrary(); [2016-12-15 16:01:44.949] [jointLog] [info] Starting optimizer; [2016-12-15 16:01:45.059] [jointLog] [info] Marked 0 weighted equivalence classes as degenerate; [2016-12-15 16:01:45.075] [jointLog] [info] iteration = 0 | max rel diff. = 261.892; [2016-12-15 16:01:45.248] [join,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267489196:1618,load,loading,1618,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267489196,1,['load'],['loading']
Performance,"abriel/Projects/salmon-0.13.1/build/CMakeFiles/libcereal.dir/DependInfo.cmake --color=; /Applications/Xcode.app/Contents/Developer/usr/bin/make -f CMakeFiles/libcereal.dir/build.make CMakeFiles/libcereal.dir/build; make[2]: Nothing to be done for `CMakeFiles/libcereal.dir/build'.; [ 8%] Built target libcereal; /Applications/Xcode.app/Contents/Developer/usr/bin/make -f CMakeFiles/libstadenio.dir/build.make CMakeFiles/libstadenio.dir/depend; cd /Users/gabriel/Projects/salmon-0.13.1/build && /usr/local/Cellar/cmake/3.13.4/bin/cmake -E cmake_depends ""Unix Makefiles"" /Users/gabriel/Projects/salmon-0.13.1 /Users/gabriel/Projects/salmon-0.13.1 /Users/gabriel/Projects/salmon-0.13.1/build /Users/gabriel/Projects/salmon-0.13.1/build /Users/gabriel/Projects/salmon-0.13.1/build/CMakeFiles/libstadenio.dir/DependInfo.cmake --color=; /Applications/Xcode.app/Contents/Developer/usr/bin/make -f CMakeFiles/libstadenio.dir/build.make CMakeFiles/libstadenio.dir/build; [ 9%] Performing configure step for 'libstadenio'; cd /Users/gabriel/Projects/salmon-0.13.1/external/staden-io_lib && ./configure --enable-shared=no --without-libcurl --prefix=/Users/gabriel/Projects/salmon-0.13.1/external/install LDFLAGS= CFLAGS= CC=/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/cc CXX=/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/c++; checking for a BSD-compatible install... /usr/local/bin/ginstall -c; checking whether build environment is sane... yes; checking for a thread-safe mkdir -p... /usr/local/bin/gmkdir -p; checking for gawk... gawk; checking whether make sets $(MAKE)... yes; checking whether make supports nested variables... yes; checking whether to enable maintainer-specific portions of Makefiles... no; checking for gcc... /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/cc; checking whether the C compiler works... yes; checking for C compiler default output file name... a.out",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/348#issuecomment-472500713:1942,Perform,Performing,1942,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/348#issuecomment-472500713,1,['Perform'],['Performing']
Performance,"al `1,099,008` are being discarded because they have only dovetail mappings. . We discard dovetail mappings by default, but you can admit them with `--allowDovetail`. The other `2,776,678` fragments are discarded because, though there are seeds for mapping that match, they do not have sufficiently high alignment score to be allowed for mapping. This default behavior, too, can be modified. The main flags that affect the behavior here are `--minScoreFraction`, where a lower number allows lower-quality alignments through and also the `--softclipOverhangs` flag which will decrease the penalty on alignments that overhang the end of an annotated transcript. However, it's worth noting that this is up to `3,875,686` more reads that might be mappable. This number is non-trivial, but quite far from the 90% rate of STAR. The rest of the reads, however, simply don't have support for alignment against the annotated transcriptome. **This suggests to me that STAR is probably aligning a lot of reads outside of annotated genes**. If you build the salmon index [using a full decoy of the genome](https://combine-lab.github.io/alevin-tutorial/2019/selective-alignment/), then you might be able to evaluate intergenic mapping in the output in terms of `Number of fragments discarded because they are best-mapped to decoys`. However, in that case, these reads still won't contribute to transcript expression, as they do not align to annotated transcripts. Finally, if you suspect these reads might be coming from genes expressed in your sample but not present in the annotation, you might consider performing a transcript assembly on your data, using a tool like [scallop2](https://github.com/Shao-Group/scallop2) or [stringtie](https://github.com/gpertea/stringtie). Best,; Rob. P.S. I'm closing the thread, since I think the above answers your direct question, but please feel free to continue commenting here (for discussion) or to open up another issue if there are follow-ups that are salmon-related.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/775#issuecomment-1126361719:1778,perform,performing,1778,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/775#issuecomment-1126361719,1,['perform'],['performing']
Performance,alevinLog] [info] Throwing 0 barcodes with < 1 reads; > [2020-06-04 12:26:05.872] [alevinLog] [info] Total [32m95377[0m(has [32m101[0m low confidence) barcodes; > [2020-06-04 12:26:06.746] [alevinLog] [info] Done True Barcode Sampling; > [2020-06-04 12:26:06.880] [alevinLog] [info] Total 1.2299% reads will be thrown away because of noisy Cellular barcodes.; > [2020-06-04 12:26:10.886] [alevinLog] [info] Done populating Z matrix; > [2020-06-04 12:26:10.924] [alevinLog] [info] Total 118774 CB got sequence corrected; > [2020-06-04 12:26:10.936] [alevinLog] [info] Done indexing Barcodes; > [2020-06-04 12:26:10.936] [alevinLog] [info] Total Unique barcodes found: 604589; > [2020-06-04 12:26:10.936] [alevinLog] [info] Used Barcodes except Whitelist: 88156; > [2020-06-04 12:26:11.113] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify; > ; > [2020-06-04 12:26:11.113] [alevinLog] [info] parsing read library format; > [2020-06-04 12:27:21.373] [alevinLog] [info] Starting optimizer; > ; > [2020-06-04 12:27:22.086] [alevinLog] [warning] mrna file not provided; using is 1 less feature for whitelisting; > [2020-06-04 12:27:22.086] [alevinLog] [warning] rrna file not provided; using is 1 less feature for whitelisting; > [2020-06-04 12:27:22.409] [alevinLog] [info] Total 23937.00 UMI after deduplicating.; > [2020-06-04 12:27:22.409] [alevinLog] [info] Total 91 BiDirected Edges.; > [2020-06-04 12:27:22.409] [alevinLog] [info] Total 82 UniDirected Edges.; > [2020-06-04 12:27:22.409] [alevinLog] [warning] Skipped 82268 barcodes due to No mapped read; > [2020-06-04 12:27:22.412] [alevinLog] [info] Clearing EqMap; Might take some time.; > [2020-06-04 12:27:22.418] [alevinLog] [warning] Num Low confidence barcodes too less 1 < 100.Can't performing whitelisting; Skipping; > [2020-06-04 12:27:22.418] [alevinLog] [info] Finished optimizer. Run 2: `salmon alevin -l ISR --citeseq --barcodeLength 16 --umiLength 10 --end 5 --featureStart 19 --featureLength 21 --maxNumBarcod,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-638991199:3175,optimiz,optimizer,3175,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-638991199,1,['optimiz'],['optimizer']
Performance,"appings implies a default consensus slack of 0.2. Setting consensusSlack to 0.35.; [2020-05-05 09:19:06.171] [jointLog] [info] parsing read library format; [2020-05-05 09:19:06.171] [jointLog] [info] There is 1 library.; [2020-05-05 09:19:06.278] [jointLog] [info] Loading pufferfish index; [2020-05-05 09:19:06.278] [jointLog] [warning] The index did not record if the `--keepDuplicates` flag was used. Please consider re-indexing with a newer version of salmon that will propagate this information.; [2020-05-05 09:19:06.278] [jointLog] [info] Loading dense pufferfish index.; -----------------------------------------; | Loading contig table | Time = 30.609 s; -----------------------------------------; size = 36981178; -----------------------------------------; | Loading contig offsets | Time = 1.3312 s; -----------------------------------------; -----------------------------------------; | Loading reference lengths | Time = 5.6842 ms; -----------------------------------------; -----------------------------------------; | Loading mphf table | Time = 20.002 s; -----------------------------------------; size = 3784352032; Number of ones: 36981177; Number of ones per inventory item: 512; Inventory entries filled: 72229; -----------------------------------------; | Loading contig boundaries | Time = 11.467 s; -----------------------------------------; size = 3784352032; -----------------------------------------; | Loading sequence | Time = 9.5665 s; -----------------------------------------; size = 2674916722; -----------------------------------------; | Loading positions | Time = 4.3912 ms; -----------------------------------------; Exception : [std::bad_alloc]; salmon quant was invoked improperly.; For usage information, try salmon quant --help; Exiting. Not sure why it happens... memory doesn't reach the max. ![Screenshot at 2020-05-05 09-45-37](https://user-images.githubusercontent.com/61701461/81045096-d14e0f00-8eb5-11ea-97ed-b4f4454ba042.png). Than you so much in advan",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/518#issuecomment-623910021:2197,Load,Loading,2197,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/518#issuecomment-623910021,1,['Load'],['Loading']
Performance,"arsing read library format; [2019-01-29 09:55:05.014] [stderrLog] [info] Loading Suffix Array ; [2019-01-29 09:55:04.882] [jointLog] [info] There is 1 library.; [2019-01-29 09:55:05.012] [jointLog] [info] Loading Quasi index; [2019-01-29 09:55:05.013] [jointLog] [info] Loading 32-bit quasi index; [2019-01-29 09:55:06.105] [stderrLog] [info] Loading Transcript Info ; [2019-01-29 09:55:09.968] [stderrLog] [info] Loading Rank-Select Bit Array; [2019-01-29 09:55:16.908] [stderrLog] [info] There were 80,511 set bits in the bit array; [2019-01-29 09:55:19.931] [stderrLog] [info] Computing transcript lengths; [2019-01-29 09:55:19.931] [stderrLog] [info] Waiting to finish loading hash; [2019-01-29 09:55:41.122] [jointLog] [info] done; [2019-01-29 09:55:41.122] [jointLog] [info] Index contained 80,511 targets; [2019-01-29 09:55:41.122] [stderrLog] [info] Done loading index. processed 0 Million fragments; hits: 161433, hits per frag: 0.32698. [2019-01-29 09:55:54.788] [alevinLog] [info] Starting optimizer; [2019-01-29 09:55:54.742] [jointLog] [info] Computed 6,346 rich equivalence classes for further processing; [2019-01-29 09:55:54.742] [jointLog] [info] Counted 80,300 total reads in the equivalence classes ; [2019-01-29 09:55:54.754] [jointLog] [warning] Only 80300 fragments were mapped, but the number of burn-in fragments was set to 5000000.; The effective lengths have been computed using the observed mappings. [2019-01-29 09:55:54.754] [jointLog] [info] Mapping rate = 8.80342%. [2019-01-29 09:55:54.754] [jointLog] [info] finished quantifyLibrary(). Analyzed 289 cells (100% of all).; [2019-01-29 09:55:56.858] [alevinLog] [info] Total 72037 UMI after deduplicating.; [2019-01-29 09:55:56.858] [alevinLog] [warning] Skipped 151 barcodes due to No mapped read; [2019-01-29 09:55:56.876] [alevinLog] [info] Clearing EqMap; Might take some time.; [2019-01-29 09:55:56.917] [alevinLog] [info] Starting Import of the gene count matrix.; [2019-01-29 09:55:57.130] [alevinLog] [info] Done ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/337#issuecomment-458481722:3675,optimiz,optimizer,3675,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/337#issuecomment-458481722,1,['optimiz'],['optimizer']
Performance,"ase_ercc.fa }; # [ libType ] => { IU }; # [ mates1 ] => { SRP057125_SRS936134_1.fastq }; # [ mates2 ] => { SRP057125_SRS936134_2.fastq }; # [ output ] => { SRP057125_SRS936134_salmon_out }; # [ biasCorrect ] => { }; # [ useFSPD ] => { }; Logs will be written to SRP057125_SRS936134_salmon_out/logs; [2016-01-02 20:16:39.349] [jointLog] [info] parsing read library format; there is 1 lib; Loading 32-bit quasi index[2016-01-02 20:16:39.895] [stderrLog] [info] Loading Suffix Array; [2016-01-02 20:16:39.895] [stderrLog] [info] Loading Position Hash; [2016-01-02 20:16:39.894] [jointLog] [info] Loading Quasi index; [2016-01-02 20:16:42.565] [stderrLog] [info] Loading Transcript Info; [2016-01-02 20:16:43.654] [stderrLog] [info] Loading Rank-Select Bit Array; [2016-01-02 20:16:44.075] [stderrLog] [info] There were 104534 set bits in the bit array; [2016-01-02 20:16:44.448] [stderrLog] [info] Computing transcript lengths; [2016-01-02 20:16:44.448] [stderrLog] [info] Waiting to finish loading hash; Index contained 104534 targets; [2016-01-02 20:16:57.606] [stderrLog] [info] Done loading index; [2016-01-02 20:16:57.606] [jointLog] [info] done. processed 12000000 fragments; hits: 24367197, hits per frag: 2.06194+06. [2016-01-02 20:17:29.841] [jointLog] [info] Computed 102251 rich equivalence classes for further processing; [2016-01-02 20:17:29.841] [jointLog] [info] Counted 10033689 total reads in the equivalence classes; [2016-01-02 20:17:29.867] [jointLog] [info] Mapping rate = 83.0244%. [2016-01-02 20:17:29.867] [jointLog] [info] finished quantifyLibrary(); [2016-01-02 20:17:29.867] [jointLog] [info] Starting optimizer; [2016-01-02 20:17:30.130] [jointLog] [info] Marked 0 weighted equivalence classes as degenerate; [2016-01-02 20:17:30.136] [jointLog] [info] iteration = 0 | max rel diff. = 65.1271; [2016-01-02 20:17:30.315] [jointLog] [info] iteration 50, recomputing effective lengths; [2016-01-02 20:17:32.978] [jointLog] [info] iteration = 100 | max rel diff. = 0.259134; [2016",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/34#issuecomment-168426741:2299,load,loading,2299,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/34#issuecomment-168426741,1,['load'],['loading']
Performance,"at 692 ; [2019-01-29 09:56:53.219] [alevinLog] [info] Gauss Corrected Boundary at 100 ; [2019-01-29 09:56:53.219] [alevinLog] [info] Learned InvCov: 114.414 normfactor: 148.807; [2019-01-29 09:56:53.219] [alevinLog] [info] Total 293(has 193 low confidence) barcodes; [2019-01-29 09:56:53.224] [alevinLog] [info] Done True Barcode Sampling; [2019-01-29 09:56:53.254] [alevinLog] [info] Done populating Z matrix; [2019-01-29 09:56:53.255] [alevinLog] [info] Done indexing Barcodes; [2019-01-29 09:56:53.255] [alevinLog] [info] Total Unique barcodes found: 125401; [2019-01-29 09:56:53.255] [alevinLog] [info] Used Barcodes except Whitelist: 1256; [2019-01-29 09:56:53.281] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify. [2019-01-29 09:56:53.281] [alevinLog] [info] parsing read library format; [2019-01-29 09:56:53.412] [stderrLog] [info] Loading Suffix Array ; [2019-01-29 09:56:53.281] [jointLog] [info] There is 1 library.; [2019-01-29 09:56:53.410] [jointLog] [info] Loading Quasi index; [2019-01-29 09:56:53.411] [jointLog] [info] Loading 32-bit quasi index; [2019-01-29 09:56:54.551] [stderrLog] [info] Loading Transcript Info ; [2019-01-29 09:56:54.826] [stderrLog] [info] Loading Rank-Select Bit Array; [2019-01-29 09:56:54.883] [stderrLog] [info] There were 80,511 set bits in the bit array; [2019-01-29 09:56:54.908] [stderrLog] [info] Computing transcript lengths; [2019-01-29 09:56:54.908] [stderrLog] [info] Waiting to finish loading hash; [2019-01-29 09:57:09.336] [stderrLog] [info] Done loading index; [2019-01-29 09:57:09.336] [jointLog] [info] done; [2019-01-29 09:57:09.336] [jointLog] [info] Index contained 80,511 targets. processed 2 Million fragments; hits: 812181, hits per frag: 0.326777. [2019-01-29 09:57:36.647] [alevinLog] [info] Starting optimizer; [2019-01-29 09:57:36.587] [jointLog] [info] Computed 12,933 rich equivalence classes for further processing; [2019-01-29 09:57:36.587] [jointLog] [info] Counted 242,520 total reads in the equivalence cl",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/337#issuecomment-458481722:8278,Load,Loading,8278,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/337#issuecomment-458481722,1,['Load'],['Loading']
Performance,"ata, which is why the total # of reads is so small). ```; rob@feynman:/mnt/scratch3/rob/JoshTest$ ~/SoftwareStaging/salmon/scripts/SalmonBeta-0.6.5-pre_CentOS5/bin/salmon quant -p 15 -i salmon_index -l IU -1 ../strange_peak/19232_1_1.fastq -2 ../strange_peak/19232_1_2.fastq -o quant_binary; Version Info: This is the most recent version of Salmon.; # salmon (mapping-based) v0.6.0; # [ program ] => salmon; # [ command ] => quant; # [ threads ] => { 15 }; # [ index ] => { salmon_index }; # [ libType ] => { IU }; # [ mates1 ] => { ../strange_peak/19232_1_1.fastq }; # [ mates2 ] => { ../strange_peak/19232_1_2.fastq }; # [ output ] => { quant_binary }; Logs will be written to quant_binary/logs; there is 1[2016-03-31 14:05:14.184] [jointLog] [info] parsing read library format; lib; Loading 64-bit quasi index[2016-03-31 14:05:14.266] [stderrLog] [info] Loading Suffix Array; [2016-03-31 14:05:14.266] [jointLog] [info] Loading Quasi index. [2016-03-31 14:07:58.647] [stderrLog] [info] Loading Transcript Info; [2016-03-31 14:08:59.703] [stderrLog] [info] Loading Rank-Select Bit Array; [2016-03-31 14:09:06.744] [stderrLog] [info] There were 2027284 set bits in the bit array; [2016-03-31 14:09:08.123] [stderrLog] [info] Computing transcript lengths; [2016-03-31 14:09:08.240] [stderrLog] [info] Waiting to finish loading hash; Index contained 2027284 targets; [2016-03-31 14:09:15.789] [jointLog] [info] done; [2016-03-31 14:09:15.786] [stderrLog] [info] Successfully loaded position hash; [2016-03-31 14:09:15.789] [stderrLog] [info] Done loading index. [2016-03-31 14:09:36.623] [jointLog] [info] Computed 8083 rich equivalence classes for further processing; [2016-03-31 14:09:36.623] [jointLog] [info] Counted 159824 total reads in the equivalence classes. [2016-03-31 14:13:24.480] [jointLog] [warning] Only 159824 fragments were mapped, but the number of burn-in fragments was set to 5000000.; The effective lengths have been computed using the observed mappings. [2016-03-31 14:13:24.480",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/54#issuecomment-204066023:1246,Load,Loading,1246,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/54#issuecomment-204066023,1,['Load'],['Loading']
Performance,"bbs error. I just ran using the binary you compiled with the following command, and got this output:. ```; $LD_LIBRARY_PATH=~/SoftwareStaging/salmon/lib:$LD_LIBRARY_PATH ./salmon quant --index Salmon_index_hg38.analysisSet_knownGene --unmatedReads SRR2454059.fq.gz --libType ISF --us; eVBOpt --output test_quant --numGibbsSamples 100 --threads 16; Version Info: This is the most recent **development version** of Salmon.; ### salmon (mapping-based) v0.7.3; ### [ program ] => salmon; ### [ command ] => quant; ### [ index ] => { Salmon_index_hg38.analysisSet_knownGene }; ### [ unmatedReads ] => { SRR2454059.fq.gz }; ### [ libType ] => { ISF }; ### [ useVBOpt ] => { }; ### [ output ] => { test_quant }; ### [ numGibbsSamples ] => { 100 }; ### [ threads ] => { 16 }; Logs will be written to test_quant/logs; [2016-12-13 22:44:07.409] [jointLog] [info] parsing read library format; [2016-12-13 22:44:07.409] [jointLog] [info] There is 1 library.; [2016-12-13 22:44:09.318] [jointLog] [info] Loading Quasi index; [2016-12-13 22:44:09.318] [jointLog] [info] Loading 32-bit quasi index; [2016-12-13 22:44:09.318] [stderrLog] [info] Loading Suffix Array; [2016-12-13 22:44:15.002] [stderrLog] [info] Loading Transcript Info; [2016-12-13 22:44:16.278] [stderrLog] [info] Loading Rank-Select Bit Array; [2016-12-13 22:44:16.625] [stderrLog] [info] There were 182608 set bits in the bit array; [2016-12-13 22:44:16.680] [stderrLog] [info] Computing transcript lengths; [2016-12-13 22:44:16.681] [stderrLog] [info] Waiting to finish loading hash; [2016-12-13 22:44:20.485] [stderrLog] [info] Done loading index; [2016-12-13 22:44:20.485] [jointLog] [info] done; [2016-12-13 22:44:20.485] [jointLog] [info] Index contained 182608 targets. processed 19000001 fragments; hits: 65897764; hits per frag: 3.48152. [2016-12-13 22:45:33.192] [jointLog] [info] Computed 137534 rich equivalence classes for further processing; [2016-12-13 22:45:33.192] [jointLog] [info] Counted 16265961 total reads in the equivalence ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-266935584:1247,Load,Loading,1247,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-266935584,1,['Load'],['Loading']
Performance,"be ignored.; [2022-03-27 05:24:09.395] [jointLog] [info] The --mimicBT2, --mimicStrictBT2 and --hardFilter flags imply mapping validation (--validateMappings). Enabling mapping validation.; [2022-03-27 05:24:09.395] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2022-03-27 05:24:09.395] [jointLog] [info] The use of range-factorized equivalence classes does not make sense in conjunction with --hardFilter. Disabling range-factorized equivalence classes. ; [2022-03-27 05:24:09.395] [jointLog] [info] Setting consensusSlack to selective-alignment default of 0.35.; [2022-03-27 05:24:09.395] [jointLog] [info] Using default value of 0.87 for minScoreFraction in Alevin; Using default value of 0.6 for consensusSlack in Alevin; [2022-03-27 05:34:26.966] [jointLog] [info] There is 1 library.; [2022-03-27 05:34:26.967] [jointLog] [info] Loading pufferfish index; [2022-03-27 05:34:26.967] [jointLog] [info] Loading dense pufferfish index.; [2022-03-27 05:34:27.433] [jointLog] [info] done; [2022-03-27 05:34:27.504] [jointLog] [info] Index contained 116,755 targets; [2022-03-27 05:34:27.540] [jointLog] [info] Number of decoys : 0; [2022-03-27 05:46:41.460] [jointLog] [info] Thread saw mini-batch with a maximum of 10.50% zero probability fragments; [2022-03-27 05:46:41.460] [jointLog] [info] Thread saw mini-batch with a maximum of 7.74% zero probability fragments; [2022-03-27 05:46:41.460] [jointLog] [info] Thread saw mini-batch with a maximum of 23.62% zero probability fragments; [2022-03-27 05:46:41.460] [jointLog] [info] Thread saw mini-batch with a maximum of 9.60% zero probability fragments; [2022-03-27 05:46:41.460] [jointLog] [info] Thread saw mini-batch with a maximum of 15.40% zero probability fragments; [2022-03-27 05:46:41.460] [jointLog] [info] Thread saw mini-batch with a maximum of 25.48% zero probability fragments; [2022-03-27 05:46:41.460] [jointLog] [info] Thread saw mini-batch ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/763#issuecomment-1082597942:5355,Load,Loading,5355,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/763#issuecomment-1082597942,1,['Load'],['Loading']
Performance,"bit array; [2016-03-31 14:09:08.123] [stderrLog] [info] Computing transcript lengths; [2016-03-31 14:09:08.240] [stderrLog] [info] Waiting to finish loading hash; Index contained 2027284 targets; [2016-03-31 14:09:15.789] [jointLog] [info] done; [2016-03-31 14:09:15.786] [stderrLog] [info] Successfully loaded position hash; [2016-03-31 14:09:15.789] [stderrLog] [info] Done loading index. [2016-03-31 14:09:36.623] [jointLog] [info] Computed 8083 rich equivalence classes for further processing; [2016-03-31 14:09:36.623] [jointLog] [info] Counted 159824 total reads in the equivalence classes. [2016-03-31 14:13:24.480] [jointLog] [warning] Only 159824 fragments were mapped, but the number of burn-in fragments was set to 5000000.; The effective lengths have been computed using the observed mappings. [2016-03-31 14:13:24.480] [jointLog] [info] Mapping rate = 36.3942%. [2016-03-31 14:13:24.480] [jointLog] [info] finished quantifyLibrary(); [2016-03-31 14:13:24.480] [jointLog] [info] Starting optimizer; [2016-03-31 14:13:25.441] [jointLog] [info] Marked 0 weighted equivalence classes as degenerate; [2016-03-31 14:13:25.660] [jointLog] [info] iteration = 0 | max rel diff. = 13.7627; [2016-03-31 14:13:26.460] [jointLog] [info] iteration = 100 | max rel diff. = 0.100799; [2016-03-31 14:13:27.252] [jointLog] [info] iteration = 200 | max rel diff. = 0.0452885; [2016-03-31 14:13:28.046] [jointLog] [info] iteration = 300 | max rel diff. = 0.0323517; [2016-03-31 14:13:29.037] [jointLog] [info] iteration = 400 | max rel diff. = 0.0173087; [2016-03-31 14:13:29.842] [jointLog] [info] iteration = 500 | max rel diff. = 0.0173241; [2016-03-31 14:13:30.837] [jointLog] [info] iteration = 600 | max rel diff. = 0.0131171; [2016-03-31 14:13:31.633] [jointLog] [info] iteration = 700 | max rel diff. = 0.0117939; [2016-03-31 14:13:32.631] [jointLog] [info] iteration = 800 | max rel diff. = 0.0102536; [2016-03-31 14:13:32.724] [jointLog] [info] iteration = 813 | max rel diff. = 0.00845215; [2016-",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/54#issuecomment-204066023:2427,optimiz,optimizer,2427,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/54#issuecomment-204066023,1,['optimiz'],['optimizer']
Performance,"bit on a few of @k3yavi's answers. 1&2) Yes; if you want to use SAF, you no longer need mashmap, as what you are essentially doing is treating the entire genome as a ""decoy"". As @k3yavi alludes, SA is still useful when you need to run in a very memory-constrained environment. After adopting the new [pufferfish-based](https://github.com/COMBINE-lab/pufferfish/tree/develop) index, the size of the transcriptome plush mashmap 2 decoys becomes considerably smaller than the previous size of the transcriptome in earlier versions of salmon (<= 0.15.0). However, depending on the organism, indexing the entire genome as decoy, even though it yields the best accuracy, does require a bit more memory, as specified in the release notes for the 0.99 betas and 1.0.0. 3) Yes; it is still possible to use `salmon index` without any decoy sequence. In this case, one can expect results similar to if you had aligned to the target transcriptome using Bowtie2. In this case, you perform indexing by simply not providing any `--decoy` flag to the `index` command. In that case, all of the records in the target fasta will be treated as valid and quantifiable targets. Of course, for reasons detailed in the pre-print --- the high _sensitivity_ of both Bowtie2 and selective-alignment --- we recommend including either mashmap-derived decoys or the organism's genome as a decoy whenever possible. . 4) Related to @k3yavi's response and my elaboration above: we have dropped quasi-mapping from 1.0.0 (though something akin to it may return in the future if there is sufficient demand and if the shortcomings described in the manuscript can be overcome). However, as I mention in part 3 above, this doesn't mean it's not possible to use v1.0.0 without an explicit decoy sequence. The `--decoy` flag of the indexing command is optional, not required. We will update this in the documentation making it more explicit. However, as @k3yavi points out, it is true that if you wish to use quasi-mapping and selective-alig",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/442#issuecomment-549195390:1041,perform,perform,1041,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/442#issuecomment-549195390,1,['perform'],['perform']
Performance,"bled]; Using host libthread_db library ""/lib64/libthread_db.so.1"".; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; [New Thread 0x7ffff0987700 (LWP 17537)]. Thread 2 ""salmon"" received signal SIGSEGV, Segmentation fault.; [Switching to Thread 0x7ffff0987700 (LWP 17537)]; 0x00007ffff68202ab in je_tcache_bin_flush_small () from /lib64/libjemalloc.so.2; Missing separate debuginfos, use: yum debuginfo-install boost169-filesystem-1.69.0-4.el8.x86_64 boost169-iostreams-1.69.0-4.el8.x86_64 boost169-program-options-1.69.0-4.el8.x86_64 boost169-system-1.69.0-4.el8.x86_64 brotli-1.0.6-1.el8.x86_64 bzip2-libs-1.0.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641594410:4358,Load,Loadable,4358,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641594410,1,['Load'],['Loadable']
Performance,"cal/Caskroom/miniforge/base/lib/python3.9/concurrent/futures/_base.py"", line 609, in result_iterator; yield fs.pop().result(); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/concurrent/futures/_base.py"", line 446, in result; return self.__get_result(); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/concurrent/futures/_base.py"", line 391, in __get_result; raise self._exception; File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/concurrent/futures/thread.py"", line 58, in run; result = self.fn(*self.args, **self.kwargs); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/conda/core/subdir_data.py"", line 132, in <lambda>; subdir_query = lambda url: tuple(SubdirData(Channel(url), repodata_fn=repodata_fn).query(; File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/conda/core/subdir_data.py"", line 145, in query; self.load(); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/conda/core/subdir_data.py"", line 210, in load; _internal_state = self._load(); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/conda/core/subdir_data.py"", line 375, in _load; raw_repodata_str = fetch_repodata_remote_request(; File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/conda/core/subdir_data.py"", line 701, in fetch_repodata_remote_request; resp = session.get(join_url(url, filename), headers=headers, proxies=session.proxies,; File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/requests/sessions.py"", line 542, in get; return self.request('GET', url, **kwargs); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/requests/sessions.py"", line 529, in request; resp = self.send(prep, **send_kwargs); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/requests/sessions.py"", line 645, in send; r = adapter.send(request, **kwargs); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/requests/adapters.py"", line 413, in send; conn = ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/724#issuecomment-1171208515:3556,load,load,3556,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/724#issuecomment-1171208515,1,['load'],['load']
Performance,"ce/BLBnew.txt). salmon quant -i ~/data/genome/MSU7_transcript.index -l IU \; -1 ~/data/raw-data/BLB/${line}1.fastq.gz \; -2 ~/data/raw-data/BLB/${line}2.fastq.gz --numBootstraps=30 \; -p 12 -o ~/results/salmon_quant_Sheng_IU_old/${line} --seqBias --gcBias. The EffectiveLength is again the same (250) for all genes across all samples:; Name Length EffectiveLength TPM NumReads; LOC_Os01g01010.1 3017 250 28.8836 527.392; LOC_Os01g01010.2 2218 250 1.84062 33.6083; LOC_Os01g01019.1 1127 250 0.0547668 1; LOC_Os01g01030.1 2464 250 4.43611 81; LOC_Os01g01040.4 1524 250 0.941635 17.1935; LOC_Os01g01040.1 2508 250 11.5632 211.135; LOC_Os01g01040.2 2482 250 8.02082 146.454; LOC_Os01g01040.3 2583 250 8.55554 156.218; LOC_Os01g01050.1 2039 250 17.2333 314.667. The mapping rate is again similar for all samples:; [2019-03-04 04:42:18.872] [jointLog] [info] parsing read library format; [2019-03-04 04:42:18.872] [jointLog] [info] There is 1 library.; [2019-03-04 04:42:18.928] [jointLog] [info] Loading Quasi index; [2019-03-04 04:42:18.929] [jointLog] [info] Loading 32-bit quasi index; [2019-03-04 04:42:28.958] [jointLog] [info] done; [2019-03-04 04:42:28.958] [jointLog] [info] Index contained 66153 targets; [2019-03-04 04:44:08.443] [fileLog] [info]; At end of round 0; ==================; Observed 18861231 total fragments (18861231 in most recent round). [2019-03-04 04:44:08.442] [jointLog] [info] Computed 48502 rich equivalence classes for further processing; [2019-03-04 04:44:08.442] [jointLog] [info] Counted 17308442 total reads in the equivalence classes; [2019-03-04 04:44:08.450] [jointLog] [info] Mapping rate = 91.7673%. [2019-03-04 04:44:08.450] [jointLog] [info] finished quantifyLibrary(). **For version 0.12**; #!/bin/bash; #SBATCH -N 1; #SBATCH -c 8; #SBATCH --mem=10G; #SBATCH --mail-use=tarun2@illinois.edu; #SBATCH -J Salmon; #SBATCH -a 1-24. module load Salmon/0.12.0-IGB-gcc-8.2.0. line=$(sed -n -e ""$SLURM_ARRAY_TASK_ID p"" ~/source/BLBnew.txt). salmon quant -i ~/data/genome",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/346#issuecomment-469215256:1651,Load,Loading,1651,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/346#issuecomment-469215256,1,['Load'],['Loading']
Performance,"cessed 74 Million barcodes. [2018-12-12 15:08:51.135] [alevinLog] [info] Done barcode density calculation.; [2018-12-12 15:08:51.135] [alevinLog] [info] # Barcodes Used: 74376522 / 74376522.; [2018-12-12 15:08:51.141] [alevinLog] [info] Done importing white-list Barcodes; [2018-12-12 15:08:51.141] [alevinLog] [warning] Skipping 1 Barcodes with 0 reads; Assuming this is the required behavior.; [2018-12-12 15:08:51.141] [alevinLog] [info] Total 95 white-listed Barcodes; [2018-12-12 15:08:51.144] [alevinLog] [info] Done populating Z matrix; [2018-12-12 15:08:51.146] [alevinLog] [info] Done indexing Barcodes; [2018-12-12 15:08:51.146] [alevinLog] [info] Total Unique barcodes found: 4096; [2018-12-12 15:08:51.146] [alevinLog] [info] Used Barcodes except Whitelist: 1864; [2018-12-12 15:08:51.272] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify. [2018-12-12 15:08:51.272] [alevinLog] [info] parsing read library format; [2018-12-12 15:08:51.375] [stderrLog] [info] Loading Suffix Array ; [2018-12-12 15:08:51.272] [jointLog] [info] There is 1 library.; [2018-12-12 15:08:51.375] [jointLog] [info] Loading Quasi index; [2018-12-12 15:08:51.375] [jointLog] [info] Loading 32-bit quasi index; [2018-12-12 15:09:10.216] [stderrLog] [info] Loading Transcript Info ; [2018-12-12 15:09:15.719] [stderrLog] [info] Loading Rank-Select Bit Array; [2018-12-12 15:09:16.330] [stderrLog] [info] There were 205,870 set bits in the bit array; [2018-12-12 15:09:16.343] [stderrLog] [info] Computing transcript lengths; [2018-12-12 15:09:16.343] [stderrLog] [info] Waiting to finish loading hash; [2018-12-12 15:09:21.460] [stderrLog] [info] Done loading index; [2018-12-12 15:09:21.460] [jointLog] [info] done; [2018-12-12 15:09:21.460] [jointLog] [info] Index contained 205,870 targets. processed 0 Million fragments; processed 1 Million fragments; processed 1 Million fragments; ..............; processed 74 Million fragments; hits: 111594303, hits per frag: 1.50848[2018-12-12 15:12:07.66",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/329#issuecomment-446668422:4189,Load,Loading,4189,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/329#issuecomment-446668422,1,['Load'],['Loading']
Performance,"command ] => quant ; ### [ index ] => { /data2/csijcs/hg38/hg38.transcriptome.index }; ### [ libType ] => { A }; ### [ mates1 ] => { /data2/csijcs/AML/RNA_seq/AML_total_MNC/total_MNCs/Fresh_samples/RHM5942/RHM5942_R1_001.fastq.gz }; ### [ mates2 ] => { /data2/csijcs/AML/RNA_seq/AML_total_MNC/total_MNCs/Fresh_samples/RHM5942/RHM5942_R2_001.fastq.gz }; ### [ threads ] => { 32 }; ### [ output ] => { /data2/csijcs/AML/RNA_seq/AML_total_MNC/total_MNCs/Fresh_samples/salmon_quants/RHM5942 }; Logs will be written to /data2/csijcs/AML/RNA_seq/AML_total_MNC/total_MNCs/Fresh_samples/salmon_quants/RHM5942/logs; [2018-07-27 16:24:55.658] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2018-07-27 16:24:55.658] [jointLog] [info] parsing read library format; [2018-07-27 16:24:55.658] [jointLog] [info] There is 1 library.; [2018-07-27 16:25:01.242] [jointLog] [info] Loading Quasi index; [2018-07-27 16:25:01.242] [jointLog] [info] Loading 32-bit quasi index; [2018-07-27 16:25:01.243] [stderrLog] [info] Loading Suffix Array ; [2018-07-27 16:25:42.630] [stderrLog] [info] Loading Transcript Info ; [2018-07-27 16:25:45.683] [stderrLog] [info] Loading Rank-Select Bit Array; [2018-07-27 16:25:47.834] [stderrLog] [info] There were 203027 set bits in the bit array; [2018-07-27 16:25:48.128] [stderrLog] [info] Computing transcript lengths; [2018-07-27 16:25:48.200] [stderrLog] [info] Waiting to finish loading hash; [2018-07-27 16:25:48.331] [stderrLog] [info] Done loading index; [2018-07-27 16:25:48.331] [jointLog] [info] done; [2018-07-27 16:25:48.331] [jointLog] [info] Index contained 203027 targets. processed 239500000 fragmentsintLog] [info] Automatically detected most likely library type as ISR; hits: 651420499, hits per frag: 2.72282[2018-07-27 16:51:47.947] [jointLog] [info] Thread saw mini-batch with a maximum of 1.70% zero probability fragments; [2018-07-27 16:51:47.947] [jointLog] [info] Thread saw mini-batch with a maximum",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/261#issuecomment-409427898:1319,Load,Loading,1319,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/261#issuecomment-409427898,1,['Load'],['Loading']
Performance,"core/solve.py"", line 463, in _collect_all_metadata; index, r = self._prepare(prepared_specs); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/conda/core/solve.py"", line 1058, in _prepare; reduced_index = get_reduced_index(self.prefix, self.channels,; File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/conda/core/index.py"", line 288, in get_reduced_index; new_records = SubdirData.query_all(spec, channels=channels, subdirs=subdirs,; File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/conda/core/subdir_data.py"", line 140, in query_all; result = tuple(concat(executor.map(subdir_query, channel_urls))); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/concurrent/futures/_base.py"", line 609, in result_iterator; yield fs.pop().result(); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/concurrent/futures/_base.py"", line 446, in result; return self.__get_result(); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/concurrent/futures/_base.py"", line 391, in __get_result; raise self._exception; File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/concurrent/futures/thread.py"", line 58, in run; result = self.fn(*self.args, **self.kwargs); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/conda/core/subdir_data.py"", line 132, in <lambda>; subdir_query = lambda url: tuple(SubdirData(Channel(url), repodata_fn=repodata_fn).query(; File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/conda/core/subdir_data.py"", line 145, in query; self.load(); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/conda/core/subdir_data.py"", line 210, in load; _internal_state = self._load(); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/conda/core/subdir_data.py"", line 375, in _load; raw_repodata_str = fetch_repodata_remote_request(; File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/conda/core/subdir_data.py"", line 701, in fetch_repodata_re",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/724#issuecomment-1171208515:2877,concurren,concurrent,2877,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/724#issuecomment-1171208515,1,['concurren'],['concurrent']
Performance,"cs/AML/RNA_seq/AML_total_MNC/total_MNCs/Fresh_samples/salmon_quants/RHM5942/logs; [2018-07-27 16:24:55.658] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2018-07-27 16:24:55.658] [jointLog] [info] parsing read library format; [2018-07-27 16:24:55.658] [jointLog] [info] There is 1 library.; [2018-07-27 16:25:01.242] [jointLog] [info] Loading Quasi index; [2018-07-27 16:25:01.242] [jointLog] [info] Loading 32-bit quasi index; [2018-07-27 16:25:01.243] [stderrLog] [info] Loading Suffix Array ; [2018-07-27 16:25:42.630] [stderrLog] [info] Loading Transcript Info ; [2018-07-27 16:25:45.683] [stderrLog] [info] Loading Rank-Select Bit Array; [2018-07-27 16:25:47.834] [stderrLog] [info] There were 203027 set bits in the bit array; [2018-07-27 16:25:48.128] [stderrLog] [info] Computing transcript lengths; [2018-07-27 16:25:48.200] [stderrLog] [info] Waiting to finish loading hash; [2018-07-27 16:25:48.331] [stderrLog] [info] Done loading index; [2018-07-27 16:25:48.331] [jointLog] [info] done; [2018-07-27 16:25:48.331] [jointLog] [info] Index contained 203027 targets. processed 239500000 fragmentsintLog] [info] Automatically detected most likely library type as ISR; hits: 651420499, hits per frag: 2.72282[2018-07-27 16:51:47.947] [jointLog] [info] Thread saw mini-batch with a maximum of 1.70% zero probability fragments; [2018-07-27 16:51:47.947] [jointLog] [info] Thread saw mini-batch with a maximum of 1.68% zero probability fragments; [2018-07-27 16:51:47.947] [jointLog] [info] Thread saw mini-batch with a maximum of 1.68% zero probability fragments; [2018-07-27 16:51:47.947] [jointLog] [info] Thread saw mini-batch with a maximum of 1.74% zero probability fragments; [2018-07-27 16:51:47.947] [jointLog] [info] Thread saw mini-batch with a maximum of 1.76% zero probability fragments; [2018-07-27 16:51:47.947] [jointLog] [info] Thread saw mini-batch with a maximum of 1.72% zero probability fragments; [2018-07-27 16:5",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/261#issuecomment-409427898:1854,load,loading,1854,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/261#issuecomment-409427898,1,['load'],['loading']
Performance,"d in the log) that there was a mapping bias (i.e. that the data look stranded). Specifically, here is what I get when I run (a close approximation of) your command. ```; $salmon quant --index Salmon_index_hg38.analysisSet_knownGene --unmatedReads SRR2454059.fq.gz --libType ISF --useVBOpt --output test_quant --; numGibbsSamples 100 --threads 16; Version Info: This is the most recent **development version** of Salmon.; ### salmon (mapping-based) v0.7.3; ### [ program ] => salmon; ### [ command ] => quant; ### [ index ] => { Salmon_index_hg38.analysisSet_knownGene }; ### [ unmatedReads ] => { SRR2454059.fq.gz }; ### [ libType ] => { ISF }; ### [ useVBOpt ] => { }; ### [ output ] => { test_quant }; ### [ numGibbsSamples ] => { 100 }; ### [ threads ] => { 16 }; Logs will be written to test_quant/logs; [2016-12-13 22:38:54.413] [jointLog] [info] parsing read library format; [2016-12-13 22:38:54.413] [jointLog] [info] There is 1 library.; [2016-12-13 22:38:56.240] [stderrLog] [info] Loading Suffix Array; [2016-12-13 22:38:56.240] [jointLog] [info] Loading Quasi index; [2016-12-13 22:38:56.240] [jointLog] [info] Loading 32-bit quasi index; [2016-12-13 22:39:01.268] [stderrLog] [info] Loading Transcript Info; [2016-12-13 22:39:02.630] [stderrLog] [info] Loading Rank-Select Bit Array; [2016-12-13 22:39:03.041] [stderrLog] [info] There were 182608 set bits in the bit array; [2016-12-13 22:39:03.159] [stderrLog] [info] Computing transcript lengths; [2016-12-13 22:39:03.160] [stderrLog] [info] Waiting to finish loading hash; [2016-12-13 22:39:07.653] [stderrLog] [info] Done loading index; [2016-12-13 22:39:07.653] [jointLog] [info] done; [2016-12-13 22:39:07.653] [jointLog] [info] Index contained 182608 targets. processed 19000000 fragments; hits: 65897209; hits per frag: 3.47349. [2016-12-13 22:40:22.572] [jointLog] [info] Computed 137534 rich equivalence classes for further processing; [2016-12-13 22:40:22.572] [jointLog] [info] Counted 16265961 total reads in the equivalence c",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-266934878:1375,Load,Loading,1375,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-266934878,1,['Load'],['Loading']
Performance,"d sequences do not retain the names of the GRanges used to subset them therefore my code could not identify minus strand transcripts and get their reverse complements. Apologies for any confusion!; ---; Thank you very much for the prompt response and for taking the time to validate Salmon's functionality. Indeed, Salmon is not the problem here. After taking a closer look at my transcript fasta, I noticed a problem with it, as you suggested. Long story short, half the premature transcripts had the wrong orientation and complementarity. Long story:. Oddly, the mature sequences were fine even though I used an identical approach to subset premature and mature transcripts from the genome reference!. Briefly my approach relied on three R packages rtracklayer, GenomicRanges, and Biostrings. 1. I used rtracklayer to load a gtf formatted exon annotations acquired from Ensembl. The file is loaded as a GenomicRanges object which essentially describes the locus of each exon (the transcribed strand [+ or -], chromosome, start and end positions relative to the reference strand) and its associated gene and transcript. 2. I used the GRanges object to generate pre-RNA coordinates that span all exons of a transcript. 3. I loaded the reference genome fasta acquired from Ensembl using the Biostrings package. GRanges and Biostrings are tightly integrated, allowing me to subset sequences from a Biostrings object using the GRanges object. **I believe the problem lies here.** It appears that when subsetting the mature exonic sequences from Biostrings using GRanges, the strand field in the GRanges object **was not** utilized. I.e., I needed to get the reverse complement of the extracted sequences for transcripts on the minus strand. I had done that and assumed that this behaviour would be consistent. However, for reasons I have not been able to pinpoint (potentially a bug), the strand information **was accounted for** when I used GRanges to subset the premature sequences. I **did not** need",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/655#issuecomment-826035191:1062,load,loaded,1062,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/655#issuecomment-826035191,1,['load'],['loaded']
Performance,"d. Incompatible fragments will be ignored.; [2020-05-05 09:19:06.171] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2020-05-05 09:19:06.171] [jointLog] [info] Usage of --validateMappings implies a default consensus slack of 0.2. Setting consensusSlack to 0.35.; [2020-05-05 09:19:06.171] [jointLog] [info] parsing read library format; [2020-05-05 09:19:06.171] [jointLog] [info] There is 1 library.; [2020-05-05 09:19:06.278] [jointLog] [info] Loading pufferfish index; [2020-05-05 09:19:06.278] [jointLog] [warning] The index did not record if the `--keepDuplicates` flag was used. Please consider re-indexing with a newer version of salmon that will propagate this information.; [2020-05-05 09:19:06.278] [jointLog] [info] Loading dense pufferfish index.; -----------------------------------------; | Loading contig table | Time = 30.609 s; -----------------------------------------; size = 36981178; -----------------------------------------; | Loading contig offsets | Time = 1.3312 s; -----------------------------------------; -----------------------------------------; | Loading reference lengths | Time = 5.6842 ms; -----------------------------------------; -----------------------------------------; | Loading mphf table | Time = 20.002 s; -----------------------------------------; size = 3784352032; Number of ones: 36981177; Number of ones per inventory item: 512; Inventory entries filled: 72229; -----------------------------------------; | Loading contig boundaries | Time = 11.467 s; -----------------------------------------; size = 3784352032; -----------------------------------------; | Loading sequence | Time = 9.5665 s; -----------------------------------------; size = 2674916722; -----------------------------------------; | Loading positions | Time = 4.3912 ms; -----------------------------------------; Exception : [std::bad_alloc]; salmon quant was invoked improperly.; For usage",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/518#issuecomment-623910021:1933,Load,Loading,1933,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/518#issuecomment-623910021,1,['Load'],['Loading']
Performance,"dence) barcodes; [2019-06-06 19:24:55.688] [alevinLog] [info] Done True Barcode Sampling; [2019-06-06 19:24:55.690] [alevinLog] [info] Total 0% reads will be thrown away because of noisy Cellular barcodes.; [2019-06-06 19:24:55.692] [alevinLog] [info] Done populating Z matrix; [2019-06-06 19:24:55.692] [alevinLog] [info] Done indexing Barcodes; [2019-06-06 19:24:55.692] [alevinLog] [info] Total Unique barcodes found: 50; [2019-06-06 19:24:55.692] [alevinLog] [info] Used Barcodes except Whitelist: 0; [2019-06-06 19:24:55.716] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify. [2019-06-06 19:24:55.716] [alevinLog] [info] parsing read library format; [2019-06-06 19:24:55.716] [jointLog] [info] There is 1 library.; [2019-06-06 19:24:55.889] [jointLog] [info] Loading Quasi index; [2019-06-06 19:24:55.889] [jointLog] [info] Loading 32-bit quasi index; [2019-06-06 19:24:55.890] [stderrLog] [info] Loading Suffix Array ; [2019-06-06 19:24:56.791] [stderrLog] [info] Loading Transcript Info ; [2019-06-06 19:24:57.025] [stderrLog] [info] Loading Rank-Select Bit Array; [2019-06-06 19:24:57.061] [stderrLog] [info] There were 136,011 set bits in the bit array; [2019-06-06 19:24:57.084] [stderrLog] [info] Computing transcript lengths; [2019-06-06 19:24:57.084] [stderrLog] [info] Waiting to finish loading hash; [2019-06-06 19:25:06.552] [jointLog] [info] done; [2019-06-06 19:25:06.552] [jointLog] [info] Index contained 136,011 targets; [2019-06-06 19:25:06.552] [stderrLog] [info] Done loading index; [2019-06-06 19:25:06.728] [alevinLog] [error] Barcode not found in frequency table; ```. Salmon Quant log is this. ```; [2019-06-06 19:23:29.519] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2019-06-06 19:23:29.519] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2019-06-06 19:23:29.520] [jointLog] [info] Usage of --valid",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/369#issuecomment-499592790:1506,Load,Loading,1506,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/369#issuecomment-499592790,1,['Load'],['Loading']
Performance,"des Used: 267451749 / 267548197.; [2018-12-06 11:16:52.732] [alevinLog] [info] Knee found left boundary at 11955 ; [2018-12-06 11:16:54.977] [alevinLog] [info] Gauss Corrected Boundary at 4345 ; [2018-12-06 11:16:54.977] [alevinLog] [info] Learned InvCov: 713.683 normfactor: 1183.93; [2018-12-06 11:16:54.985] [alevinLog] [info] Total 31.0106% reads will be thrown away because of noisy Cellular barcodes.; [2018-12-06 11:16:54.985] [alevinLog] [info] Total 5344(has 999 low confidence) barcodes; [2018-12-06 11:16:55.059] [alevinLog] [info] Done True Barcode Sampling; [2018-12-06 11:16:55.395] [alevinLog] [info] Done populating Z matrix; [2018-12-06 11:16:55.453] [alevinLog] [info] Done indexing Barcodes; [2018-12-06 11:16:55.453] [alevinLog] [info] Total Unique barcodes found: 4180559; [2018-12-06 11:16:55.453] [alevinLog] [info] Used Barcodes except Whitelist: 134856; [2018-12-06 11:16:56.218] [jointLog] [info] There are 2 libraries.; [2018-12-06 11:16:56.292] [jointLog] [info] Loading Quasi index; [2018-12-06 11:16:56.294] [jointLog] [info] Loading 32-bit quasi index; [2018-12-06 11:16:56.205] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify. [2018-12-06 11:16:56.218] [alevinLog] [info] parsing read library format; [2018-12-06 11:16:56.296] [stderrLog] [info] Loading Suffix Array ; [2018-12-06 11:16:56.846] [stderrLog] [info] Loading Transcript Info ; [2018-12-06 11:16:57.009] [stderrLog] [info] Loading Rank-Select Bit Array; [2018-12-06 11:16:57.046] [stderrLog] [info] There were 167,268 set bits in the bit array; [2018-12-06 11:16:57.063] [stderrLog] [info] Computing transcript lengths; [2018-12-06 11:16:57.064] [stderrLog] [info] Waiting to finish loading hash; [2018-12-06 11:17:00.929] [jointLog] [info] done; [2018-12-06 11:17:00.929] [jointLog] [info] Index contained 167,268 targets. processed 267 Million fragmentsrrLog] [info] Done loading index; hits: 844899161, hits per frag: 3.15864^[[D. [2018-12-06 11:45:12.188] [jointLog] [info] Computed ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/328#issuecomment-445008548:6047,Load,Loading,6047,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/328#issuecomment-445008548,1,['Load'],['Loading']
Performance,"develop branch; (the release candidate for 1.3.0), and I got the following time (used 8; threads, so timing is not directly comparable). ```; 4604.57user 43.64system 9:24.15elapsed 823%CPU; ```. The whole log is. ```; [2020-06-15 23:51:54.747] [jointLog] [info] setting maxHashResizeThreads to; 8; [2020-06-15 23:51:54.747] [jointLog] [info] Fragment incompatibility prior; below threshold. Incompatible fragments will be ignored.; [2020-06-15 23:51:54.747] [jointLog] [info] Usage of --validateMappings; implies use of minScoreFraction. Since not explicitly specified, it is; being set to 0.65; [2020-06-15 23:51:54.747] [jointLog] [info] Usage of --validateMappings; implies a default consensus slack of 0.2. Setting consensusSlack to 0.35.; [2020-06-15 23:51:54.747] [jointLog] [info] parsing read library format; [2020-06-15 23:51:54.747] [jointLog] [info] There is 1 library.; [2020-06-15 23:51:54.814] [jointLog] [info] Loading pufferfish index; [2020-06-15 23:51:54.814] [jointLog] [info] Loading dense pufferfish index.; [2020-06-15 23:51:55.555] [jointLog] [info] done; [2020-06-15 23:51:55.555] [jointLog] [info] Index contained 116,248 targets; [2020-06-15 23:51:55.588] [jointLog] [info] Number of decoys : 0; [2020-06-16 00:00:59.666] [jointLog] [info] Computed 344,764 rich; equivalence classes for further processing; [2020-06-16 00:00:59.666] [jointLog] [info] Counted 12,956,134 total reads; in the equivalence classes; [2020-06-16 00:00:59.673] [jointLog] [warning] 0.0736383% of fragments were; shorter than the k used to build the index.; If this fraction is too large, consider re-building the index with a; smaller k.; The minimum read size found was 1. [2020-06-16 00:00:59.673] [jointLog] [info] Number of mappings discarded; because of alignment score : 134,091,887; [2020-06-16 00:00:59.673] [jointLog] [info] Number of fragments entirely; discarded because of alignment score : 2,429,390; [2020-06-16 00:00:59.673] [jointLog] [info] Number of fragments discarded; because t",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/537#issuecomment-644520228:1056,Load,Loading,1056,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/537#issuecomment-644520228,2,['Load'],['Loading']
Performance,"ds you do, but here is what I get when using this pre-compiled binary on the 64-bit index (this is a small read set from single-cell data, which is why the total # of reads is so small). ```; rob@feynman:/mnt/scratch3/rob/JoshTest$ ~/SoftwareStaging/salmon/scripts/SalmonBeta-0.6.5-pre_CentOS5/bin/salmon quant -p 15 -i salmon_index -l IU -1 ../strange_peak/19232_1_1.fastq -2 ../strange_peak/19232_1_2.fastq -o quant_binary; Version Info: This is the most recent version of Salmon.; # salmon (mapping-based) v0.6.0; # [ program ] => salmon; # [ command ] => quant; # [ threads ] => { 15 }; # [ index ] => { salmon_index }; # [ libType ] => { IU }; # [ mates1 ] => { ../strange_peak/19232_1_1.fastq }; # [ mates2 ] => { ../strange_peak/19232_1_2.fastq }; # [ output ] => { quant_binary }; Logs will be written to quant_binary/logs; there is 1[2016-03-31 14:05:14.184] [jointLog] [info] parsing read library format; lib; Loading 64-bit quasi index[2016-03-31 14:05:14.266] [stderrLog] [info] Loading Suffix Array; [2016-03-31 14:05:14.266] [jointLog] [info] Loading Quasi index. [2016-03-31 14:07:58.647] [stderrLog] [info] Loading Transcript Info; [2016-03-31 14:08:59.703] [stderrLog] [info] Loading Rank-Select Bit Array; [2016-03-31 14:09:06.744] [stderrLog] [info] There were 2027284 set bits in the bit array; [2016-03-31 14:09:08.123] [stderrLog] [info] Computing transcript lengths; [2016-03-31 14:09:08.240] [stderrLog] [info] Waiting to finish loading hash; Index contained 2027284 targets; [2016-03-31 14:09:15.789] [jointLog] [info] done; [2016-03-31 14:09:15.786] [stderrLog] [info] Successfully loaded position hash; [2016-03-31 14:09:15.789] [stderrLog] [info] Done loading index. [2016-03-31 14:09:36.623] [jointLog] [info] Computed 8083 rich equivalence classes for further processing; [2016-03-31 14:09:36.623] [jointLog] [info] Counted 159824 total reads in the equivalence classes. [2016-03-31 14:13:24.480] [jointLog] [warning] Only 159824 fragments were mapped, but the number of ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/54#issuecomment-204066023:1114,Load,Loading,1114,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/54#issuecomment-204066023,1,['Load'],['Loading']
Performance,e most recent **development version** of Salmon.; ### salmon (mapping-based) v0.7.3; ### [ program ] => salmon; ### [ command ] => quant; ### [ index ] => { /home/ryan/references/hg38/Salmon_index_hg38.analysisSet_knownGene }; ### [ libType ] => { SR }; ### [ unmatedReads ] => { fastq_files/SRR2454069.fq.gz }; ### [ threads ] => { 8 }; ### [ seqBias ] => { }; ### [ gcBias ] => { }; ### [ useVBOpt ] => { }; ### [ dumpEq ] => { }; ### [ dumpEqWeights ] => { }; ### [ geneMap ] => { /home/ryan/references/hg38/Salmon_index_hg38.analysisSet_knownGene/genemap.txt }; ### [ output ] => { salmon_temp/REF/SRR2454069 }; ### [ auxDir ] => { aux_info }; ### [ numGibbsSamples ] => { 10 }; Logs will be written to salmon_temp/REF/SRR2454069/logs; [2016-12-15 15:58:50.157] [jointLog] [info] parsing read library format; [2016-12-15 15:58:50.157] [jointLog] [info] There is 1 library.; [2016-12-15 15:58:50.189] [jointLog] [info] Loading Quasi index; [2016-12-15 15:58:50.189] [jointLog] [info] Loading 32-bit quasi index; [2016-12-15 15:58:50.189] [stderrLog] [info] Loading Suffix Array; [2016-12-15 15:58:50.513] [stderrLog] [info] Loading Transcript Info; [2016-12-15 15:58:50.599] [stderrLog] [info] Loading Rank-Select Bit Array; [2016-12-15 15:58:50.661] [stderrLog] [info] There were 182608 set bits in the bit array; [2016-12-15 15:58:50.677] [stderrLog] [info] Computing transcript lengths; [2016-12-15 15:58:50.677] [stderrLog] [info] Waiting to finish loading hash; [2016-12-15 15:58:50.677] [stderrLog] [info] Done loading index; [2016-12-15 15:58:50.677] [jointLog] [info] done; [2016-12-15 15:58:50.677] [jointLog] [info] Index contained 182608 targets; [2016-12-15 15:58:51.587] [jointLog] [warning] Fragment GC bias correction is currently *experimental* in single-end libraries. Please use this option with caution. processed 16500000 fragments; hits: 44017772; hits per frag: 2.67057. [2016-12-15 16:01:44.937] [jointLog] [info] Computed 119318 rich equivalence classes for further process,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267489196:1085,Load,Loading,1085,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267489196,1,['Load'],['Loading']
Performance,"e next, even on the same data file. . I appreciate any help you can offer and I apologize in advance if there's something obvious I should have read or known about. (it seems like the lines below that are preceded by ### are coming out in fold face. They are not meant to.). (salmon) MacBook-Pro-2:salmon-tutorial brent$ bash quant_tut_samples.sh; Processing sample DRR016125; Version Info: Could not resolve upgrade information in the alotted time.; Check for upgrades manually at https://combine-lab.github.io/salmon; ### salmon (mapping-based) v0.11.3; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { athal_index }; ### [ libType ] => { A }; ### [ mates1 ] => { data/DRR016125/DRR016125_1.fastq.gz }; ### [ mates2 ] => { data/DRR016125/DRR016125_2.fastq.gz }; ### [ threads ] => { 8 }; ### [ output ] => { quants/DRR016125_quant }; Logs will be written to quants/DRR016125_quant/logs; [2018-11-24 15:08:09.785] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2018-11-24 15:08:09.785] [jointLog] [info] parsing read library format; [2018-11-24 15:08:09.785] [jointLog] [info] There is 1 library.; [2018-11-24 15:08:09.877] [jointLog] [info] Loading Quasi index; [2018-11-24 15:08:09.877] [jointLog] [info] Loading 32-bit quasi index; [2018-11-24 15:08:09.877] [stderrLog] [info] Loading Suffix Array ; [2018-11-24 15:08:10.319] [stderrLog] [info] Loading Transcript Info ; [2018-11-24 15:08:10.423] [stderrLog] [info] Loading Rank-Select Bit Array; [2018-11-24 15:08:10.432] [stderrLog] [info] There were 40,812 set bits in the bit array; [2018-11-24 15:08:10.435] [stderrLog] [info] Computing transcript lengths; [2018-11-24 15:08:10.435] [stderrLog] [info] Waiting to finish loading hash. quant_tut_samples.sh: line 2: 914 Segmentation fault: 11 salmon quant -i athal_index -l A -1 ${fn}/${samp}_1.fastq.gz -2 ${fn}/${samp}_2.fastq.gz -p 8 -o quants/${samp}_quant; (salmon) MacBook-Pro-2:salmon-tutorial brent$",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/317#issuecomment-441396828:1671,Load,Loading,1671,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/317#issuecomment-441396828,6,"['Load', 'load']","['Loading', 'loading']"
Performance,"e of noisy Cellular barcodes.; [2018-12-06 11:16:54.985] [alevinLog] [info] Total 5344(has 999 low confidence) barcodes; [2018-12-06 11:16:55.059] [alevinLog] [info] Done True Barcode Sampling; [2018-12-06 11:16:55.395] [alevinLog] [info] Done populating Z matrix; [2018-12-06 11:16:55.453] [alevinLog] [info] Done indexing Barcodes; [2018-12-06 11:16:55.453] [alevinLog] [info] Total Unique barcodes found: 4180559; [2018-12-06 11:16:55.453] [alevinLog] [info] Used Barcodes except Whitelist: 134856; [2018-12-06 11:16:56.218] [jointLog] [info] There are 2 libraries.; [2018-12-06 11:16:56.292] [jointLog] [info] Loading Quasi index; [2018-12-06 11:16:56.294] [jointLog] [info] Loading 32-bit quasi index; [2018-12-06 11:16:56.205] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify. [2018-12-06 11:16:56.218] [alevinLog] [info] parsing read library format; [2018-12-06 11:16:56.296] [stderrLog] [info] Loading Suffix Array ; [2018-12-06 11:16:56.846] [stderrLog] [info] Loading Transcript Info ; [2018-12-06 11:16:57.009] [stderrLog] [info] Loading Rank-Select Bit Array; [2018-12-06 11:16:57.046] [stderrLog] [info] There were 167,268 set bits in the bit array; [2018-12-06 11:16:57.063] [stderrLog] [info] Computing transcript lengths; [2018-12-06 11:16:57.064] [stderrLog] [info] Waiting to finish loading hash; [2018-12-06 11:17:00.929] [jointLog] [info] done; [2018-12-06 11:17:00.929] [jointLog] [info] Index contained 167,268 targets. processed 267 Million fragmentsrrLog] [info] Done loading index; hits: 844899161, hits per frag: 3.15864^[[D. [2018-12-06 11:45:12.188] [jointLog] [info] Computed 118,295 rich equivalence classes for further processing; [2018-12-06 11:45:12.188] [jointLog] [info] Counted 154,595,094 total reads in the equivalence classes ; [2018-12-06 11:45:12.188] [jointLog] [warning] Found 115077 reads with `N` in the UMI sequence and ignored the reads.; Please report on github if this number is too large; [2018-12-06 11:45:12.188] [jointLog] [info]",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/328#issuecomment-445008548:6422,Load,Loading,6422,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/328#issuecomment-445008548,1,['Load'],['Loading']
Performance,"ead2.fastq.gz }; ### [ output ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test4/R10001_D2B1WACXX }; Logs will be written to /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test4/R10001_D2B1WACXX/logs; [1m[2017-03-29 14:56:39.675] [jointLog] [info] parsing read library format; [00m[1m[2017-03-29 14:56:39.733] [jointLog] [info] There is 1 library.; [00mterminate called without an active exception; /cm/local/apps/sge/var/spool/compute-067/job_scripts/110316: line 31: 64339 Aborted (core dumped) /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon quant -i /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts -p 16 -l ISR -1 ${FILE1} -2 ${FILE2} -o /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test4/${ID}; **** Job ends ****; Wed Mar 29 14:58:05 EDT 2017. ```. ### SGE email example info. ```; Job-array task 110316.1 (step6-salmon_test4.gsk_phaseII) Complete; User = lcollado; Queue = shared.q@compute-067.cm.cluster; Host = compute-067.cm.cluster; Start Time = 03/29/2017 14:53:42; End Time = 03/29/2017 14:58:05; User Time = 00:00:00; System Time = 00:05:39; Wallclock Time = 00:04:23; CPU = 00:05:39; Max vmem = 24.202G; Exit Status = 0; ```. Note that in this case, it didn't read the maximum memory requested (16 * 3 = 48 GB). ## Large memory, p 1. ### Bash. ```bash; #!/bin/bash; #$ -cwd; #$ -l mem_free=80G,h_vmem=90G,h_fsize=100G; #$ -N step6-salmon_test5.gsk_phaseII; #$ -pe local 1; #$ -o ./logs/salmon_test5.$TASK_ID.txt; #$ -e ./logs/salmon_test5.$TASK_ID.txt; #$ -t 1-3; #$ -hold_jid pipeline_setup,step4-featCounts-alzheimer.gsk_phaseII; #$ -m e; echo ""**** Job starts ****""; date. echo ""**** JHPCE info ****""; echo ""User: ${USER}""; echo ""Job id: ${JOB_ID}""; echo ""Job name: ${JOB_NAME}""; echo ""Hostname: ${HOSTNAME}""; echo ""Task id: ${TASK_ID}"". FILE1=$(awk 'BEGIN {FS=""\t""} {print $1}' /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-290516965:6932,Queue,Queue,6932,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-290516965,1,['Queue'],['Queue']
Performance,"ebuginfos, use: yum debuginfo-install glibc-2.28-72.el8_1.1.x86_64; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; [Thread debugging using libthread_db enabled]; Using host libthread_db library ""/lib64/libthread_db.so.1"".; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641594410:3242,Load,Loadable,3242,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641594410,1,['Load'],['Loadable']
Performance,"ed InvCov: 114.535 normfactor: 147.323; [2019-01-29 09:55:04.817] [alevinLog] [info] Total 289(has 190 low confidence) barcodes; [2019-01-29 09:55:04.822] [alevinLog] [info] Done True Barcode Sampling; [2019-01-29 09:55:04.855] [alevinLog] [info] Done populating Z matrix; [2019-01-29 09:55:04.855] [alevinLog] [info] Done indexing Barcodes; [2019-01-29 09:55:04.855] [alevinLog] [info] Total Unique barcodes found: 70316; [2019-01-29 09:55:04.855] [alevinLog] [info] Used Barcodes except Whitelist: 184; [2019-01-29 09:55:04.882] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify. [2019-01-29 09:55:04.882] [alevinLog] [info] parsing read library format; [2019-01-29 09:55:05.014] [stderrLog] [info] Loading Suffix Array ; [2019-01-29 09:55:04.882] [jointLog] [info] There is 1 library.; [2019-01-29 09:55:05.012] [jointLog] [info] Loading Quasi index; [2019-01-29 09:55:05.013] [jointLog] [info] Loading 32-bit quasi index; [2019-01-29 09:55:06.105] [stderrLog] [info] Loading Transcript Info ; [2019-01-29 09:55:09.968] [stderrLog] [info] Loading Rank-Select Bit Array; [2019-01-29 09:55:16.908] [stderrLog] [info] There were 80,511 set bits in the bit array; [2019-01-29 09:55:19.931] [stderrLog] [info] Computing transcript lengths; [2019-01-29 09:55:19.931] [stderrLog] [info] Waiting to finish loading hash; [2019-01-29 09:55:41.122] [jointLog] [info] done; [2019-01-29 09:55:41.122] [jointLog] [info] Index contained 80,511 targets; [2019-01-29 09:55:41.122] [stderrLog] [info] Done loading index. processed 0 Million fragments; hits: 161433, hits per frag: 0.32698. [2019-01-29 09:55:54.788] [alevinLog] [info] Starting optimizer; [2019-01-29 09:55:54.742] [jointLog] [info] Computed 6,346 rich equivalence classes for further processing; [2019-01-29 09:55:54.742] [jointLog] [info] Counted 80,300 total reads in the equivalence classes ; [2019-01-29 09:55:54.754] [jointLog] [warning] Only 80300 fragments were mapped, but the number of burn-in fragments was set to 5000000",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/337#issuecomment-458481722:3017,Load,Loading,3017,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/337#issuecomment-458481722,1,['Load'],['Loading']
Performance,"efore used for quantification by default. Specifically, starting with 0.14, ""dovetail"" alignments [(as described in the Bowtie2 manual)](http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-dovetail) are considered discordant. This is the same default behavior imposed by Bowtie2. If you look in the `meta_info.json` file for some of these samples (which is in the `aux_info` subdirectory of the quantification directory for a sample), you can see how many mappings are being discarded by virtue of being dovetail mappings. It is possible to allow such alignments (consider them as concordant) by passing the `--allowDovetail` flag. It is not the case that such alignments are always ""bad"", its simply that one would not expect many fragments to align in such a way, and if these constitute the overwhelming majority of the mappings, one might be suspicious about the underlying data. * Selective alignment actually _aligns_ the reads to the transcriptome. For this purpose, it performs end-to-end alignment. This means that if you suspect that the sample may contain adapters or very low-quality read ends, the reads should be trimmed prior to quantification. It is, therefore, worth checking how the mapping rate changes for some of these samples if the reads are trimmed first. * Selective alignment is more robust than quasi-mapping to the chosen value of `-k`, the minimum match length used when searching for alignments. I noticed that some of the samples contain relatively short reads, so you might see if the mapping rate changes if you adopt a smaller value of `-k` in the index (e.g. we use `23` in the [pre-print](https://www.biorxiv.org/content/10.1101/657874v2.full.pdf)). * You mention that this index doesn't contain any decoy sequence. This of course, should not affect the mapping rate. However, I'd be quite curious to see if you index the reference using the _whole genome_ as decoy (i.e. the SAF method from the pre-print), how many reads are discarded because ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/482#issuecomment-582734798:2690,perform,performs,2690,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/482#issuecomment-582734798,1,['perform'],['performs']
Performance,"elective alignment, we could compare and contrast the two. At that point, there are a few options depending on how deeply you want to dive. You could try to see how STAR and selective alignment are mapping differently to these transcripts. One potential difference is that STAR is _a lot_ more happy to softclip reads, which selective alignment won't do by default (you can test the effect with the `--softclipOverhangs` to allow selective alignment to softclip reads that hang off the transcript end or `--softclip` to allow softclips anywhere). Note that selective alignment may _still_ be a bit more conservative than STAR about softclips simply because of the nature of the scoring function it uses. This might give you a sense if one of these alignment methodologies is more consistent with your expectations in this case. Another option is to consider doing a grouping with `terminus`. This will reduce the set of ""genes"" that you can call as DE, because it will be happy to group together transcripts from different genes. However, it should help considerably in eliminating DE from highly-uncertain point estimates. Finally, you might consider performing DE with swish (cc @mikelove as he might have some input here) rather than DESeq2 (though we've typically been using swish at the transcript level rather than the gene level). Unlike DESeq2, swish will explicitly take into account the inferential uncertainty in the abundance estimates, using the Gibbs samples produced by salmon. This will allow it to avoid spurious DE calls that might otherwise occur when you have highly uncertain transcripts that, by chance, end up being assigned very different abundances in different samples / over different runs. Sorry for the information dump, but I wanted to lay out what might be going on, how to assess it, and what some potential solutions might be. If you dive in to start investigating this, feel free to reach out in this issue along the way if you get stuck or have follow-up questions.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/600#issuecomment-740363115:4377,perform,performing,4377,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/600#issuecomment-740363115,1,['perform'],['performing']
Performance,"en I build this index on one of our machines. Perhaps we could see if these match: . ```; $:salmon_index [j1] (develop ?) $ sha256sum *; 306e9d98b3460859f579059bf876aa3b6e264c8f38c04cde332b03632edc6dfb complete_ref_lens.bin; 28519aac34b84b4d0570c97340815e719511c204e04a240dd43e365d2872eed3 ctable.bin; 1c7501deaa4524f4700152713228cb03949775dce481384eac67bb45458508be ctg_offsets.bin; dbc575fed0d589b4671c26bd8cbcb4b3d52ef41c299a90de978ab940abb751fc duplicate_clusters.tsv; 987050914456cf247a24136429d8faaa293cf5617bfd57166c64976b2778d95b info.json; 0b7e8cb4ebed78513900831c047f0d66589068921c33bb15c49b3567c84e2edc mphf.bin; 117369928fde1bff4ca278246c331e079cc0860c3b415e34cd4b08f588063abc pos.bin; 297492e67d274b2ff8f026d2fbc8045f96e17793a58dd74c19b5ab1b7156df8a pre_indexing.log; 8e665e5fdee5af6fcedabc69fd04eda6e66055ef811ebde6de6f86a66521198a rank.bin; 793c79f5fd6046dfea07bbc9587d2835088e54c78197d652d1b1f205c6b16983 refAccumLengths.bin; 92acf575c90c6954ff75be1ea791f822eee05e486c6e86c52943d8bc1a0849ca ref_indexing.log; b580b9c6257254a018a9ae22291a64892c1a3715c69272637f5c504fc5545a70 reflengths.bin; 89679603ac0b28042275e5ff04b222bad3fd431cab573f0c2b61e7455aec43e7 refseq.bin; 94cb79a2f4acd811d2164f2926c96869a8103b9118170d0688f57b46e695cd5c seq.bin; 89d56bb135f32c7b5fa337bc3c45814b80c2886a3cccc31ff0533c6324ca11fd versionInfo.json; ```. I'm also including a link [here](https://drive.google.com/file/d/1uxGUy8gaQ20dpEi7-D3ookFF4JYawsIR/view?usp=sharing) to a tarball containing the index I built. Could you see if you can perform quantification with this index? Finally, it might be worth checking that nothing strange / unexpected is going on with how libraries are being resolved in the linker path when you are running salmon. Could you share the output of running `ldd salmon`? If none of those point at anything obvious, I might also suggest seeing if it runs as expected inside a Docker container. You can grab a dockerfile for salmon [here](https://hub.docker.com/r/combinelab/salmon).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/561#issuecomment-674454751:1855,perform,perform,1855,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/561#issuecomment-674454751,1,['perform'],['perform']
Performance,"entation/>.; For help, type ""help"".; Type ""apropos word"" to search for commands related to ""word""...; Reading symbols from /u/user/local/bin/salmon...done.; (gdb) run alevin -l ISR --chromium -p 4 -o BM_1/alevin -1 ./BM_1/run1/bm_S10_L001_R1_001.fastq.gz -2 ./BM_1/run1/bm_S10_L001_R2_001.fastq.gz --maxHashResizeThreads 2 -i /u/user/ref/cellranger/salmon/transcripts_index --tgMap tx2gene.txt; Starting program: /u/user/local/bin/salmon alevin -l ISR --chromium -p 4 -o BM_1/alevin -1 ./BM_1/run1/bm_S10_L001_R1_001.fastq.gz -2 ./BM_1/run1/bm_S10_L001_R2_001.fastq.gz --maxHashResizeThreads 2 -i /u/user/ref/cellranger/salmon/transcripts_index --tgMap tx2gene.txt; [Thread debugging using libthread_db enabled]; Using host libthread_db library ""/lib/x86_64-linux-gnu/libthread_db.so.1"".; warning: File ""/u/user/local/lib64/libstdc++.so.6.0.21-gdb.py"" auto-loading has been declined by your `auto-load safe; -path' set to ""$debugdir:$datadir/auto-load"".; To enable execution of this file add; add-auto-load-safe-path /u/user/local/lib64/libstdc++.so.6.0.21-gdb.py; line to your configuration file ""/u/user/.gdbinit"".; To completely disable this security protection add; set auto-load safe-path /; line to your configuration file ""/u/user/.gdbinit"".; For more information about this security protection see the; ""Auto-loading safe path"" section in the GDB manual. E.g., run from the shell:; info ""(gdb)Auto-loading safe path""; [New Thread 0x7fff7dbff700 (LWP 21437)]; [Thread 0x7fff7dbff700 (LWP 21437) exited]; Version Info: Could not resolve upgrade information in the alotted time.; Check for upgrades manually at https://combine-lab.github.io/salmon; [New Thread 0x7ffefcfff700 (LWP 21653)]; Logs will be written to BM_1/alevin/logs; [New Thread 0x7ffe7cffe700 (LWP 21654)]; [New Thread 0x7ffdfcffd700 (LWP 21655)]; [New Thread 0x7ffd7cffc700 (LWP 21656)]; ### salmon (single-cell-based) v0.10.3; ### [ program ] => salmon; ### [ command ] => alevin; ### [ libType ] => { ISR }; ### [ chromium ] =",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-396078627:1863,load,load-safe-path,1863,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-396078627,1,['load'],['load-safe-path']
Performance,es in the index); > [2020-06-09 12:31:05.494] [alevinLog] [info] Filled with 64 txp to gene entries ; > [2020-06-09 12:31:05.494] [alevinLog] [info] Found all transcripts to gene mappings; > [2020-06-09 12:31:05.499] [alevinLog] [info] Processing barcodes files (if Present) ; > ; > ; > [2020-06-09 12:32:20.000] [alevinLog] [info] Done barcode density calculation.; > [2020-06-09 12:32:20.000] [alevinLog] [info] # Barcodes Used: [32m52200250[0m / [31m52200250[0m.; > [2020-06-09 12:32:20.285] [alevinLog] [info] Done importing white-list Barcodes; > [2020-06-09 12:32:20.423] [alevinLog] [warning] Skipping 672237 Barcodes as no read was mapped; > [2020-06-09 12:32:20.578] [alevinLog] [info] Total 65042 white-listed Barcodes; > [2020-06-09 12:32:20.578] [alevinLog] [info] Sorting and dumping raw barcodes; > [2020-06-09 12:32:21.060] [alevinLog] [info] Total 5.06742% reads will be thrown away because of noisy Cellular barcodes.; > [2020-06-09 12:32:23.856] [alevinLog] [info] Done populating Z matrix; > [2020-06-09 12:32:23.882] [alevinLog] [info] Total 79207 CB got sequence corrected. > [2020-06-09 12:32:23.893] [alevinLog] [info] Done indexing Barcodes; > [2020-06-09 12:32:23.893] [alevinLog] [info] Total Unique barcodes found: 604589; > [2020-06-09 12:32:23.893] [alevinLog] [info] Used Barcodes except Whitelist: 71340; > [2020-06-09 12:32:24.004] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify; > ; > [2020-06-09 12:32:24.004] [alevinLog] [info] parsing read library format; > [2020-06-09 12:33:33.719] [alevinLog] [info] Starting optimizer; > ; > ; > [2020-06-09 12:33:35.712] [alevinLog] [info] Total 161852.00 UMI after deduplicating.; > [2020-06-09 12:33:35.712] [alevinLog] [info] Total 14936 BiDirected Edges.; > [2020-06-09 12:33:35.712] [alevinLog] [info] Total 177402 UniDirected Edges.; > [2020-06-09 12:33:35.712] [alevinLog] [warning] Skipped 12422 barcodes due to No mapped read; > [2020-06-09 12:33:35.719] [alevinLog] [info] Finished optimizer,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-641426690:1990,optimiz,optimizer,1990,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-641426690,2,['optimiz'],['optimizer']
Performance,"es. Those jobs are still running (it's only been about 4hrs as of this writing, I'll update my post if/when they complete). Current logs are showing that they quickly consume all the available memory, but have not yet crashed. I've also got versions with 128-512GB of memory requested (by powers of 2) for comparison. Some random notes: both the 31-mer index experienced about twice as many soft page reclaims with the new/faster version and experienced a few hard page faults (the previous version saw none of the latter). The 17-mer version experienced fewer page reclaims than any of the 31-mer indices and far fewer than with the prior version. Again, a few page faults crept in, but relatively few by percentage and likely not contributing any significant amount of time overall. [index-qacct-17mer.log](https://github.com/COMBINE-lab/salmon/files/4246516/index-qacct-17mer.log); [index-qacct-31mer.log](https://github.com/COMBINE-lab/salmon/files/4246517/index-qacct-31mer.log). **UPDATE**; The 16GB version finished running. It actually only took a little over 4 hours to run, as well. The troubling thing about this job seems to be that, despite having successfully completed, according to the accounting log it used over 20GB of memory... which should be impossible to do. Our resident experts suspect there's a race condition occurring at the tail end of the job and that all of that extra memory is being allocated before the scheduler can kill it for exceeding the limit. Whatever the case, though, this throws into question some of those numbers that I've been grabbing from the accounting logs --- it's either being misreported, or the memory gobbling is happening so rapidly that it may not, in fact, be being properly recorded. I tested the index anyway. It *appears* to be working just fine. Nothing faulted or crashed when I attempted to quantify some reads against it. [index-qacct-17mer-16gigs.log](https://github.com/COMBINE-lab/salmon/files/4247214/index-qacct-17mer-16gigs.log)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/476#issuecomment-590516702:2130,race condition,race condition,2130,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/476#issuecomment-590516702,1,['race condition'],['race condition']
Performance,et_knownGene }; ### [ libType ] => { SR }; ### [ unmatedReads ] => { fastq_files/SRR2454069.fq.gz }; ### [ threads ] => { 8 }; ### [ seqBias ] => { }; ### [ gcBias ] => { }; ### [ useVBOpt ] => { }; ### [ dumpEq ] => { }; ### [ dumpEqWeights ] => { }; ### [ geneMap ] => { /home/ryan/references/hg38/Salmon_index_hg38.analysisSet_knownGene/genemap.txt }; ### [ output ] => { salmon_temp/REF/SRR2454069 }; ### [ auxDir ] => { aux_info }; ### [ numGibbsSamples ] => { 10 }; Logs will be written to salmon_temp/REF/SRR2454069/logs; [2016-12-15 15:58:50.157] [jointLog] [info] parsing read library format; [2016-12-15 15:58:50.157] [jointLog] [info] There is 1 library.; [2016-12-15 15:58:50.189] [jointLog] [info] Loading Quasi index; [2016-12-15 15:58:50.189] [jointLog] [info] Loading 32-bit quasi index; [2016-12-15 15:58:50.189] [stderrLog] [info] Loading Suffix Array; [2016-12-15 15:58:50.513] [stderrLog] [info] Loading Transcript Info; [2016-12-15 15:58:50.599] [stderrLog] [info] Loading Rank-Select Bit Array; [2016-12-15 15:58:50.661] [stderrLog] [info] There were 182608 set bits in the bit array; [2016-12-15 15:58:50.677] [stderrLog] [info] Computing transcript lengths; [2016-12-15 15:58:50.677] [stderrLog] [info] Waiting to finish loading hash; [2016-12-15 15:58:50.677] [stderrLog] [info] Done loading index; [2016-12-15 15:58:50.677] [jointLog] [info] done; [2016-12-15 15:58:50.677] [jointLog] [info] Index contained 182608 targets; [2016-12-15 15:58:51.587] [jointLog] [warning] Fragment GC bias correction is currently *experimental* in single-end libraries. Please use this option with caution. processed 16500000 fragments; hits: 44017772; hits per frag: 2.67057. [2016-12-15 16:01:44.937] [jointLog] [info] Computed 119318 rich equivalence classes for further processing; [2016-12-15 16:01:44.937] [jointLog] [info] Counted 12227080 total reads in the equivalence classes; [2016-12-15 16:01:44.948] [jointLog] [info] Mapping rate = 72.5194%. [2016-12-15 16:01:44.948] [jointLog],MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267489196:1295,Load,Loading,1295,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267489196,1,['Load'],['Loading']
Performance,"evinLog] [info] Done with Barcode Processing; Moving to Quantify; > ; > [2020-06-04 17:56:30.294] [alevinLog] [info] parsing read library format; > [2020-06-04 17:57:36.339] [alevinLog] [info] Starting optimizer; > ; > ; > [2020-06-04 17:57:37.051] [alevinLog] [warning] mrna file not provided; using is 1 less feature for whitelisting; > [2020-06-04 17:57:37.051] [alevinLog] [warning] rrna file not provided; using is 1 less feature for whitelisting; > [2020-06-04 17:57:37.338] [alevinLog] [info] Total 23937.00 UMI after deduplicating.; > [2020-06-04 17:57:37.338] [alevinLog] [info] Total 91 BiDirected Edges.; > [2020-06-04 17:57:37.338] [alevinLog] [info] Total 82 UniDirected Edges.; > [2020-06-04 17:57:37.338] [alevinLog] [warning] Skipped 82268 barcodes due to No mapped read; > [2020-06-04 17:57:37.341] [alevinLog] [info] Clearing EqMap; Might take some time.; > [2020-06-04 17:57:37.348] [alevinLog] [warning] Num Low confidence barcodes too less 1 < 10.Can't performing whitelisting; Skipping; > [2020-06-04 17:57:37.348] [alevinLog] [info] Finished optimizer; > ; > . salmon_quant.log. > [2020-06-04 17:55:11.700] [jointLog] [info] setting maxHashResizeThreads to 7; > [2020-06-04 17:55:11.700] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; > [2020-06-04 17:55:11.700] [jointLog] [info] The --mimicBT2, --mimicStrictBT2 and --hardFilter flags imply mapping validation (--validateMappings). Enabling mapping validation.; > [2020-06-04 17:55:11.700] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; > [2020-06-04 17:55:11.700] [jointLog] [info] The use of range-factorized equivalence classes does not make sense in conjunction with --hardFilter. Disabling range-factorized equivalence classes. ; > [2020-06-04 17:55:11.700] [jointLog] [info] Usage of --validateMappings implies a default consensus slack of 0.2. Setting consensusSlack to",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-639196415:2568,perform,performing,2568,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-639196415,1,['perform'],['performing']
Performance,"ff67cfee700 (LWP 21670) exited]; [New Thread 0x7ff57cfec700 (LWP 21672)]; [Thread 0x7ff5fcfed700 (LWP 21671) exited]; [New Thread 0x7ff4fcfeb700 (LWP 21673)]; [Thread 0x7ff57cfec700 (LWP 21672) exited]; [New Thread 0x7ff47cfea700 (LWP 21674)]; [Thread 0x7ff4fcfeb700 (LWP 21673) exited]; [New Thread 0x7ff3fcfe9700 (LWP 21675)]; terminate called without an active exception; [Thread 0x7ff47cfea700 (LWP 21674) exited]; [Thread 0x7ff3fcfe9700 (LWP 21675) exited]. Program received signal SIGABRT, Aborted.; 0x00007fff7e8a7067 in __GI_raise (sig=sig@entry=6) at ../nptl/sysdeps/unix/sysv/linux/raise.c:56; 56 ../nptl/sysdeps/unix/sysv/linux/raise.c: No such file or directory.; (gdb) bt; #0 0x00007fff7e8a7067 in __GI_raise (sig=sig@entry=6) at ../nptl/sysdeps/unix/sysv/linux/raise.c:56; #1 0x00007fff7e8a8448 in __GI_abort () at abort.c:89; #2 0x0000000000c3b76d in __gnu_cxx::__verbose_terminate_handler (); at ../../.././libstdc++-v3/libsupc++/vterminate.cc:95; #3 0x0000000000baf9b6 in __cxxabiv1::__terminate (handler=<optimized out>); at ../../.././libstdc++-v3/libsupc++/eh_terminate.cc:47; #4 0x0000000000bafa01 in std::terminate () at ../../.././libstdc++-v3/libsupc++/eh_terminate.cc:57; #5 0x0000000000715f1b in std::vector<std::thread, std::allocator<std::thread> >::~vector() (); #6 0x00000000007bee90 in void cuckoohash_map<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, unsigned int, BarcodeGroupStringHasher, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, unsigned int> >, 4ul>::parallel_exec<cuckoohash_map<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, unsigned int, BarcodeGroupStringHasher, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<std::__cxx11::basic_string<char, std::c",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-396078627:5551,optimiz,optimized,5551,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-396078627,1,['optimiz'],['optimized']
Performance,"finished quantifyLibrary(); [2016-03-31 14:13:24.480] [jointLog] [info] Starting optimizer; [2016-03-31 14:13:25.441] [jointLog] [info] Marked 0 weighted equivalence classes as degenerate; [2016-03-31 14:13:25.660] [jointLog] [info] iteration = 0 | max rel diff. = 13.7627; [2016-03-31 14:13:26.460] [jointLog] [info] iteration = 100 | max rel diff. = 0.100799; [2016-03-31 14:13:27.252] [jointLog] [info] iteration = 200 | max rel diff. = 0.0452885; [2016-03-31 14:13:28.046] [jointLog] [info] iteration = 300 | max rel diff. = 0.0323517; [2016-03-31 14:13:29.037] [jointLog] [info] iteration = 400 | max rel diff. = 0.0173087; [2016-03-31 14:13:29.842] [jointLog] [info] iteration = 500 | max rel diff. = 0.0173241; [2016-03-31 14:13:30.837] [jointLog] [info] iteration = 600 | max rel diff. = 0.0131171; [2016-03-31 14:13:31.633] [jointLog] [info] iteration = 700 | max rel diff. = 0.0117939; [2016-03-31 14:13:32.631] [jointLog] [info] iteration = 800 | max rel diff. = 0.0102536; [2016-03-31 14:13:32.724] [jointLog] [info] iteration = 813 | max rel diff. = 0.00845215; [2016-03-31 14:13:32.998] [jointLog] [info] Finished optimizer; [2016-03-31 14:13:32.998] [jointLog] [info] writing output. [2016-03-31 14:13:36.554] [jointLog] [warning] NOTE: Read Lib [( ../strange_peak/19232_1_1.fastq, ../strange_peak/19232_1_2.fastq )] :. Greater than 5% of the alignments (but not, necessarily reads) disagreed with the provided library type; check the file: quant_binary/libFormatCounts.txt for details; ```. of course, it takes a stupid amount of time to load the giant index the first time around, but it seems able to do this successfully on my end (using the data you shared). Do you have any idea why it may have quit? What if you try running it with `gdb`; e.g.?. ```; $ gdb /home/jorvis/salmon/bin/salmon; (gbd) r quant -p 24 -i transcripts_index -l IU -1 R1.trimmed.PE.fastq -2 R2.trimmed.PE.fastq -o transcripts_quan; ```. does that give any more info into why it's not even loading the index?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/54#issuecomment-204066023:3474,optimiz,optimizer,3474,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/54#issuecomment-204066023,3,"['load', 'optimiz']","['load', 'loading', 'optimizer']"
Performance,"fo] Number of fragments discarded because they are best-mapped to decoys : 3,572,798; [2022-05-14 00:49:06.636] [jointLog] [info] Number of fragments discarded because they have only dovetail (discordant) mappings to valid targets : 54,775; [2022-05-14 00:49:06.636] [jointLog] [info] Mapping rate = 62.2613%. [2022-05-14 00:49:06.636] [jointLog] [info] finished quantifyLibrary(); [2022-05-14 00:49:06.643] [jointLog] [info] Starting optimizer; [2022-05-14 00:49:06.706] [jointLog] [info] Marked 0 weighted equivalence classes as degenerate; [2022-05-14 00:49:06.713] [jointLog] [info] iteration = 0 | max rel diff. = 8788.91; [2022-05-14 00:49:07.363] [jointLog] [info] iteration = 100 | max rel diff. = 12.9125; [2022-05-14 00:49:08.016] [jointLog] [info] iteration = 200 | max rel diff. = 10.1452; [2022-05-14 00:49:08.665] [jointLog] [info] iteration = 300 | max rel diff. = 10.5557; [2022-05-14 00:49:09.322] [jointLog] [info] iteration = 400 | max rel diff. = 5.35911; [2022-05-14 00:49:09.990] [jointLog] [info] iteration = 500 | max rel diff. = 0.278805; [2022-05-14 00:49:10.647] [jointLog] [info] iteration = 600 | max rel diff. = 4.69875; [2022-05-14 00:49:11.295] [jointLog] [info] iteration = 700 | max rel diff. = 0.696517; [2022-05-14 00:49:11.994] [jointLog] [info] iteration = 800 | max rel diff. = 3.63395; [2022-05-14 00:49:12.648] [jointLog] [info] iteration = 900 | max rel diff. = 0.0421211; [2022-05-14 00:49:13.295] [jointLog] [info] iteration = 1,000 | max rel diff. = 0.150166; [2022-05-14 00:49:13.608] [jointLog] [info] iteration = 1,047 | max rel diff. = 0.00869236; [2022-05-14 00:49:13.620] [jointLog] [info] Finished optimizer; [2022-05-14 00:49:13.620] [jointLog] [info] writing output . I thought that the difference between the 84% from STAR and 57% from Salmon will be due mapping to introns or intergenic region (non-coding part) which I will get if I run salmon with the full decoy index but I got only 62% mapping.; Am I missing something here, please?; Thanks",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/775#issuecomment-1126593943:5717,optimiz,optimizer,5717,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/775#issuecomment-1126593943,1,['optimiz'],['optimizer']
Performance,"g command, and got this output:. ```; $LD_LIBRARY_PATH=~/SoftwareStaging/salmon/lib:$LD_LIBRARY_PATH ./salmon quant --index Salmon_index_hg38.analysisSet_knownGene --unmatedReads SRR2454059.fq.gz --libType ISF --us; eVBOpt --output test_quant --numGibbsSamples 100 --threads 16; Version Info: This is the most recent **development version** of Salmon.; ### salmon (mapping-based) v0.7.3; ### [ program ] => salmon; ### [ command ] => quant; ### [ index ] => { Salmon_index_hg38.analysisSet_knownGene }; ### [ unmatedReads ] => { SRR2454059.fq.gz }; ### [ libType ] => { ISF }; ### [ useVBOpt ] => { }; ### [ output ] => { test_quant }; ### [ numGibbsSamples ] => { 100 }; ### [ threads ] => { 16 }; Logs will be written to test_quant/logs; [2016-12-13 22:44:07.409] [jointLog] [info] parsing read library format; [2016-12-13 22:44:07.409] [jointLog] [info] There is 1 library.; [2016-12-13 22:44:09.318] [jointLog] [info] Loading Quasi index; [2016-12-13 22:44:09.318] [jointLog] [info] Loading 32-bit quasi index; [2016-12-13 22:44:09.318] [stderrLog] [info] Loading Suffix Array; [2016-12-13 22:44:15.002] [stderrLog] [info] Loading Transcript Info; [2016-12-13 22:44:16.278] [stderrLog] [info] Loading Rank-Select Bit Array; [2016-12-13 22:44:16.625] [stderrLog] [info] There were 182608 set bits in the bit array; [2016-12-13 22:44:16.680] [stderrLog] [info] Computing transcript lengths; [2016-12-13 22:44:16.681] [stderrLog] [info] Waiting to finish loading hash; [2016-12-13 22:44:20.485] [stderrLog] [info] Done loading index; [2016-12-13 22:44:20.485] [jointLog] [info] done; [2016-12-13 22:44:20.485] [jointLog] [info] Index contained 182608 targets. processed 19000001 fragments; hits: 65897764; hits per frag: 3.48152. [2016-12-13 22:45:33.192] [jointLog] [info] Computed 137534 rich equivalence classes for further processing; [2016-12-13 22:45:33.192] [jointLog] [info] Counted 16265961 total reads in the equivalence classes; [2016-12-13 22:45:33.233] [jointLog] [info] Mapping rate = ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-266935584:1312,Load,Loading,1312,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-266935584,1,['Load'],['Loading']
Performance,"g instructions, please see:; <http://www.gnu.org/software/gdb/bugs/>.; Find the GDB manual and other documentation resources online at:; <http://www.gnu.org/software/gdb/documentation/>. For help, type ""help"".; Type ""apropos word"" to search for commands related to ""word""...; Reading symbols from salmon...done.; (gdb) r; Starting program: /home/common/modules/el8/x86_64/software/salmon/1.2.1-CentOS-vanilla/bin/salmon index -t transcripts.fasta -i sample_salmon_fmd_index --type fmd; Missing separate debuginfos, use: yum debuginfo-install glibc-2.28-72.el8_1.1.x86_64; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; [Thread debugging using libthread_db enabled]; Using host libthread_db library ""/lib64/libthread_db.so.1"".; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641594410:2738,Load,Loadable,2738,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641594410,1,['Load'],['Loadable']
Performance,g38.analysisSet_knownGene --unmatedReads SRR2454059.fq.gz --libType ISF --us; eVBOpt --output test_quant --numGibbsSamples 100 --threads 16; Version Info: This is the most recent **development version** of Salmon.; ### salmon (mapping-based) v0.7.3; ### [ program ] => salmon; ### [ command ] => quant; ### [ index ] => { Salmon_index_hg38.analysisSet_knownGene }; ### [ unmatedReads ] => { SRR2454059.fq.gz }; ### [ libType ] => { ISF }; ### [ useVBOpt ] => { }; ### [ output ] => { test_quant }; ### [ numGibbsSamples ] => { 100 }; ### [ threads ] => { 16 }; Logs will be written to test_quant/logs; [2016-12-13 22:44:07.409] [jointLog] [info] parsing read library format; [2016-12-13 22:44:07.409] [jointLog] [info] There is 1 library.; [2016-12-13 22:44:09.318] [jointLog] [info] Loading Quasi index; [2016-12-13 22:44:09.318] [jointLog] [info] Loading 32-bit quasi index; [2016-12-13 22:44:09.318] [stderrLog] [info] Loading Suffix Array; [2016-12-13 22:44:15.002] [stderrLog] [info] Loading Transcript Info; [2016-12-13 22:44:16.278] [stderrLog] [info] Loading Rank-Select Bit Array; [2016-12-13 22:44:16.625] [stderrLog] [info] There were 182608 set bits in the bit array; [2016-12-13 22:44:16.680] [stderrLog] [info] Computing transcript lengths; [2016-12-13 22:44:16.681] [stderrLog] [info] Waiting to finish loading hash; [2016-12-13 22:44:20.485] [stderrLog] [info] Done loading index; [2016-12-13 22:44:20.485] [jointLog] [info] done; [2016-12-13 22:44:20.485] [jointLog] [info] Index contained 182608 targets. processed 19000001 fragments; hits: 65897764; hits per frag: 3.48152. [2016-12-13 22:45:33.192] [jointLog] [info] Computed 137534 rich equivalence classes for further processing; [2016-12-13 22:45:33.192] [jointLog] [info] Counted 16265961 total reads in the equivalence classes; [2016-12-13 22:45:33.233] [jointLog] [info] Mapping rate = 83.509%. [2016-12-13 22:45:33.233] [jointLog] [info] finished quantifyLibrary(); [2016-12-13 22:45:33.234] [jointLog] [info] Starting opti,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-266935584:1452,Load,Loading,1452,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-266935584,1,['Load'],['Loading']
Performance,g38.analysisSet_knownGene --unmatedReads SRR2454059.fq.gz --libType ISF --useVBOpt --output test_quant --; numGibbsSamples 100 --threads 16; Version Info: This is the most recent **development version** of Salmon.; ### salmon (mapping-based) v0.7.3; ### [ program ] => salmon; ### [ command ] => quant; ### [ index ] => { Salmon_index_hg38.analysisSet_knownGene }; ### [ unmatedReads ] => { SRR2454059.fq.gz }; ### [ libType ] => { ISF }; ### [ useVBOpt ] => { }; ### [ output ] => { test_quant }; ### [ numGibbsSamples ] => { 100 }; ### [ threads ] => { 16 }; Logs will be written to test_quant/logs; [2016-12-13 22:38:54.413] [jointLog] [info] parsing read library format; [2016-12-13 22:38:54.413] [jointLog] [info] There is 1 library.; [2016-12-13 22:38:56.240] [stderrLog] [info] Loading Suffix Array; [2016-12-13 22:38:56.240] [jointLog] [info] Loading Quasi index; [2016-12-13 22:38:56.240] [jointLog] [info] Loading 32-bit quasi index; [2016-12-13 22:39:01.268] [stderrLog] [info] Loading Transcript Info; [2016-12-13 22:39:02.630] [stderrLog] [info] Loading Rank-Select Bit Array; [2016-12-13 22:39:03.041] [stderrLog] [info] There were 182608 set bits in the bit array; [2016-12-13 22:39:03.159] [stderrLog] [info] Computing transcript lengths; [2016-12-13 22:39:03.160] [stderrLog] [info] Waiting to finish loading hash; [2016-12-13 22:39:07.653] [stderrLog] [info] Done loading index; [2016-12-13 22:39:07.653] [jointLog] [info] done; [2016-12-13 22:39:07.653] [jointLog] [info] Index contained 182608 targets. processed 19000000 fragments; hits: 65897209; hits per frag: 3.47349. [2016-12-13 22:40:22.572] [jointLog] [info] Computed 137534 rich equivalence classes for further processing; [2016-12-13 22:40:22.572] [jointLog] [info] Counted 16265961 total reads in the equivalence classes; [2016-12-13 22:40:22.618] [jointLog] [info] Mapping rate = 83.509%. [2016-12-13 22:40:22.618] [jointLog] [info] finished quantifyLibrary(); [2016-12-13 22:40:22.619] [jointLog] [info] Starting opti,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-266934878:1579,Load,Loading,1579,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-266934878,1,['Load'],['Loading']
Performance,"g] [info] Knee found left boundary at 11955 ; [2018-12-06 11:16:54.977] [alevinLog] [info] Gauss Corrected Boundary at 4345 ; [2018-12-06 11:16:54.977] [alevinLog] [info] Learned InvCov: 713.683 normfactor: 1183.93; [2018-12-06 11:16:54.985] [alevinLog] [info] Total 31.0106% reads will be thrown away because of noisy Cellular barcodes.; [2018-12-06 11:16:54.985] [alevinLog] [info] Total 5344(has 999 low confidence) barcodes; [2018-12-06 11:16:55.059] [alevinLog] [info] Done True Barcode Sampling; [2018-12-06 11:16:55.395] [alevinLog] [info] Done populating Z matrix; [2018-12-06 11:16:55.453] [alevinLog] [info] Done indexing Barcodes; [2018-12-06 11:16:55.453] [alevinLog] [info] Total Unique barcodes found: 4180559; [2018-12-06 11:16:55.453] [alevinLog] [info] Used Barcodes except Whitelist: 134856; [2018-12-06 11:16:56.218] [jointLog] [info] There are 2 libraries.; [2018-12-06 11:16:56.292] [jointLog] [info] Loading Quasi index; [2018-12-06 11:16:56.294] [jointLog] [info] Loading 32-bit quasi index; [2018-12-06 11:16:56.205] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify. [2018-12-06 11:16:56.218] [alevinLog] [info] parsing read library format; [2018-12-06 11:16:56.296] [stderrLog] [info] Loading Suffix Array ; [2018-12-06 11:16:56.846] [stderrLog] [info] Loading Transcript Info ; [2018-12-06 11:16:57.009] [stderrLog] [info] Loading Rank-Select Bit Array; [2018-12-06 11:16:57.046] [stderrLog] [info] There were 167,268 set bits in the bit array; [2018-12-06 11:16:57.063] [stderrLog] [info] Computing transcript lengths; [2018-12-06 11:16:57.064] [stderrLog] [info] Waiting to finish loading hash; [2018-12-06 11:17:00.929] [jointLog] [info] done; [2018-12-06 11:17:00.929] [jointLog] [info] Index contained 167,268 targets. processed 267 Million fragmentsrrLog] [info] Done loading index; hits: 844899161, hits per frag: 3.15864^[[D. [2018-12-06 11:45:12.188] [jointLog] [info] Computed 118,295 rich equivalence classes for further processing; [2018-12-06",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/328#issuecomment-445008548:6112,Load,Loading,6112,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/328#issuecomment-445008548,1,['Load'],['Loading']
Performance,"gene counts in csv format; 0.00215799	7.4911e-08	0.000194712	11697.8	; 0.00705206	1.19109e-07	30039.7	29692.8	; [2019-01-29 09:55:59.105] [alevinLog] [info] Finished dumping csv counts; [2019-01-29 09:55:59.106] [alevinLog] [info] Starting white listing; [2019-01-29 09:55:59.107] [alevinLog] [info] Done importing order of barcodes ""quants_mat_rows.txt"" file.; [2019-01-29 09:55:59.107] [alevinLog] [info] Total 138 barcodes found; [2019-01-29 09:55:59.107] [alevinLog] [warning] mrna file not provided; using is 1 less feature for whitelisting; [2019-01-29 09:55:59.107] [alevinLog] [warning] rrna file not provided; using is 1 less feature for whitelisting; [2019-01-29 09:55:59.107] [alevinLog] [info] Starting to make feature Matrix; [2019-01-29 09:55:59.115] [alevinLog] [info] Done making regular featues; [2019-01-29 09:55:59.115] [alevinLog] [info] Done making feature Matrix; [2019-01-29 09:55:59.123] [alevinLog] [info] Finished white listing; [2019-01-29 09:55:59.126] [alevinLog] [info] Finished optimizer; ``` . Concat fastq:; ```; salmon alevin -l ISR -1 big.fastq.1.gz -2 big.fastq.2.gz --chromium -i geneset.dir/geneset_coding_exons.salmon.index/ -o salmon.dir/ --tgMap transcript2geneMap.tsv --dumpCsvCounts; Version Info: ### PLEASE UPGRADE SALMON ###; ### A newer version of Salmon with important bug fixes and improvements is available. ####; ###; The newest version, available at https://github.com/COMBINE-lab/salmon/releases; contains new features, improvements, and bug fixes; please upgrade at your; earliest convenience.; ###; Logs will be written to salmon.dir/logs; ### alevin (dscRNA-seq quantification) v0.11.3; ### [ program ] => salmon ; ### [ command ] => alevin ; ### [ libType ] => { ISR }; ### [ mates1 ] => { big.fastq.1.gz }; ### [ mates2 ] => { big.fastq.2.gz }; ### [ chromium ] => { }; ### [ index ] => { geneset.dir/geneset_coding_exons.salmon.index/ }; ### [ output ] => { salmon.dir/ }; ### [ tgMap ] => { transcript2geneMap.tsv }; ### [ dumpCsvCounts ] =>",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/337#issuecomment-458481722:5806,optimiz,optimizer,5806,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/337#issuecomment-458481722,1,['optimiz'],['optimizer']
Performance,"hello! have you by any chance figured it out? I have quite similiar problem. . I am running salmon v.1.1.0 on my ubuntu machine with 128GB of RAM. I set the limit for vitrual memory at ~75GB to not overload the system:. ```bash; ○ → ulimit -a; core file size (blocks, -c) 0; data seg size (kbytes, -d) unlimited; scheduling priority (-e) 0; file size (blocks, -f) unlimited; pending signals (-i) 514510; max locked memory (kbytes, -l) 65536; max memory size (kbytes, -m) unlimited; open files (-n) 1024; pipe size (512 bytes, -p) 8; POSIX message queues (bytes, -q) 819200; real-time priority (-r) 0; stack size (kbytes, -s) 8192; cpu time (seconds, -t) unlimited; max user processes (-u) 514510; virtual memory (kbytes, -v) 75331648; file locks (-x) unlimited; ```. I am building the index with the following command:. ```bash; salmon index \; -t /mnt/rescomp/ref/hg38/gentrome.fa.gz \; -i /mnt/rescomp/ref/hg38/salmon_index -k 31 \; --decoys /mnt/rescomp/ref/hg38/decoys.txt \; --threads 16 \; --gencode |& tee logs/salmon_index.log; ```. gentrome is created based on the gencode transcriptome (v33) and genome primary algnment sequence (GRCh38.p13). [salmon_index.log](https://github.com/COMBINE-lab/salmon/files/4392725/salmon_index.log). The output directory:; ```; ○ → ll /mnt/rescomp/ref/hg38/salmon_index; total 7.9G; drwxr-sr-x 1 37304 723 4.0K Mar 27 01:36 ./; drwxr-sr-x 1 37304 723 4.0K Mar 26 22:13 ../; -rw-r--r-- 1 37304 723 888K Mar 27 00:32 complete_ref_lens.bin; -rw-r--r-- 1 37304 723 31K Mar 27 00:27 duplicate_clusters.tsv; -rw-r--r-- 1 37304 723 674M Mar 27 01:46 path.bin; -rw-r--r-- 1 37304 723 55 Mar 27 01:46 pre_indexing.log; -rw-r--r-- 1 37304 723 40K Mar 27 01:46 ref_indexing.log; -rw-r--r-- 1 37304 723 3.3G Mar 27 00:32 ref_k31_fixed.fa; -rw-r--r-- 1 37304 723 703 Mar 27 00:32 ref_sigs.json; -rw-r--r-- 1 37304 723 4.1G Mar 27 01:36 tmp_dbg.bin; ```; I know for a fact that the memory usage did not go over 16GB. Any hints how to proceed?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/441#issuecomment-604919589:547,queue,queues,547,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/441#issuecomment-604919589,1,['queue'],['queues']
Performance,"ib/python3.9/site-packages/conda/core/solve.py"", line 1058, in _prepare; reduced_index = get_reduced_index(self.prefix, self.channels,; File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/conda/core/index.py"", line 288, in get_reduced_index; new_records = SubdirData.query_all(spec, channels=channels, subdirs=subdirs,; File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/conda/core/subdir_data.py"", line 140, in query_all; result = tuple(concat(executor.map(subdir_query, channel_urls))); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/concurrent/futures/_base.py"", line 609, in result_iterator; yield fs.pop().result(); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/concurrent/futures/_base.py"", line 446, in result; return self.__get_result(); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/concurrent/futures/_base.py"", line 391, in __get_result; raise self._exception; File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/concurrent/futures/thread.py"", line 58, in run; result = self.fn(*self.args, **self.kwargs); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/conda/core/subdir_data.py"", line 132, in <lambda>; subdir_query = lambda url: tuple(SubdirData(Channel(url), repodata_fn=repodata_fn).query(; File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/conda/core/subdir_data.py"", line 145, in query; self.load(); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/conda/core/subdir_data.py"", line 210, in load; _internal_state = self._load(); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/conda/core/subdir_data.py"", line 375, in _load; raw_repodata_str = fetch_repodata_remote_request(; File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/conda/core/subdir_data.py"", line 701, in fetch_repodata_remote_request; resp = session.get(join_url(url, filename), headers=headers, proxies=session.proxies,; File ""/usr/local/Caskroom/miniforg",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/724#issuecomment-1171208515:3012,concurren,concurrent,3012,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/724#issuecomment-1171208515,1,['concurren'],['concurrent']
Performance,"icense GPLv3+: GNU GPL version 3 or later <http://gnu.org/licenses/gpl.html>; This is free software: you are free to change and redistribute it.; There is NO WARRANTY, to the extent permitted by law. Type ""show copying""; and ""show warranty"" for details.; This GDB was configured as ""x86_64-linux-gnu"".; Type ""show configuration"" for configuration details.; For bug reporting instructions, please see:; <http://www.gnu.org/software/gdb/bugs/>.; Find the GDB manual and other documentation resources online at:; <http://www.gnu.org/software/gdb/documentation/>.; For help, type ""help"".; Type ""apropos word"" to search for commands related to ""word"".; Attaching to process 29332; [New LWP 29334]; [New LWP 29335]; [New LWP 29336]; [New LWP 21224]; [New LWP 21225]; [New LWP 21226]; [New LWP 21227]; [New LWP 21228]; [New LWP 21229]; [New LWP 21230]; [Thread debugging using libthread_db enabled]; Using host libthread_db library ""/lib/x86_64-linux-gnu/libthread_db.so.1"".; 0x00007fcb8cf73789 in __ieee754_log_avx (x=<optimized out>) at ../sysdeps/ieee754/dbl-64/e_log.c:193; 193	../sysdeps/ieee754/dbl-64/e_log.c: No such file or directory.; #0 0x00007fcb8cf73789 in __ieee754_log_avx (x=<optimized out>) at ../sysdeps/ieee754/dbl-64/e_log.c:193; #1 0x0000000000637ccc in double std::gamma_distribution<double>::operator()<pcg_detail::engine<unsigned int, unsigned long, pcg_detail::xsh_rr_mixin<unsigned int, unsigned long>, true, pcg_detail::unique_stream<unsigned long>, pcg_detail::default_multiplier<unsigned long> > >(pcg_detail::engine<unsigned int, unsigned long, pcg_detail::xsh_rr_mixin<unsigned int, unsigned long>, true, pcg_detail::unique_stream<unsigned long>, pcg_detail::default_multiplier<unsigned long> >&, std::gamma_distribution<double>::param_type const&) (); #2 0x0000000000634b8d in tbb::interface9::internal::start_for<tbb::blocked_range<unsigned long>, sampleRoundNonCollapsedMultithreaded_(std::vector<std::pair<TranscriptGroup const, TGValue>, std::allocator<std::pair<Transcri",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267488748:1202,optimiz,optimized,1202,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267488748,1,['optimiz'],['optimized']
Performance,"ides; [2021-12-31 11:26:33.218] [puff::index::jointLog] [info] Clipped poly-A tails from 758 transcripts; wrote 141009 cleaned references; [2021-12-31 11:26:34.700] [puff::index::jointLog] [info] Filter size not provided; estimating from number of distinct k-mers; [2021-12-31 11:26:38.852] [puff::index::jointLog] [info] ntHll estimated 239287090 distinct k-mers, setting filter size to 2^32; allowedIn: 21; Max Junction ID: 1394611; seen.size():11156897 kmerInfo.size():1394612; approximateContigTotalLength: 132160289; counters for complex kmers:; (prec>1 & succ>1)=181344 | (succ>1 & isStart)=714 | (prec>1 & isEnd)=800 | (isStart & isEnd)=42; contig count: 2077595 element count: 297242564 complex nodes: 182900; # of ones in rank vector: 2077594; [2021-12-31 11:28:32.554] [puff::index::jointLog] [info] Starting the Pufferfish indexing by reading the GFA binary file.; [2021-12-31 11:28:32.554] [puff::index::jointLog] [info] Setting the index/BinaryGfa directory /no_backup/indexes/salmon/mm10_gencode; size = 297242564; -----------------------------------------; | Loading contigs | Time = 135.18 ms; -----------------------------------------; size = 297242564; -----------------------------------------; | Loading contig boundaries | Time = 61.18 ms; -----------------------------------------; Number of ones: 2077594; Number of ones per inventory item: 512; Inventory entries filled: 4058; 2077594; [2021-12-31 11:28:33.532] [puff::index::jointLog] [info] Done wrapping the rank vector with a rank9sel structure.; [2021-12-31 11:28:33.566] [puff::index::jointLog] [info] contig count for validation: 2,077,594; [2021-12-31 11:28:34.693] [puff::index::jointLog] [info] Total # of Contigs : 2,077,594; [2021-12-31 11:28:34.693] [puff::index::jointLog] [info] Total # of numerical Contigs : 2,077,594; [2021-12-31 11:28:34.787] [puff::index::jointLog] [info] Total # of contig vec entries: 13,003,859; [2021-12-31 11:28:34.787] [puff::index::jointLog] [info] bits per offset entry 24; [2021-1",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/731#issuecomment-1003342883:2442,Load,Loading,2442,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/731#issuecomment-1003342883,1,['Load'],['Loading']
Performance,"imapNmax 20 --alignSJDBoverhangMin 1 --outFilterMismatchNmax 999 --outFilterMismatchNoverReadLmax 0.04 --alignIntronMin 20 --alignIntronMax 1000000 --alignMatesGapMax 1000000 --eadFilesCommand zcat --outSAMtype BAM Unsorted --quantMode TranscriptomeSAM --outSAMattributes NH HI AS NM MD --quantTranscriptomeBan IndelSoftclipSingleend`; note that last parameter that I will come back to later. Also, the paper referenced above also describes a new capability present in recent versions of salmon that allow it to index the entire genome (as well as the transcriptome) to have the former act as a decoy. This allows avoiding what might otherwise be spurious mappings that result when one considers only the transcriptome as a source of mapping. There are a number of ways to proceed on this front, but this is a good place to first check for discrepancy (and the paper gives a good overview of the relative tradeoffs and merits of different alignment approaches). * Salmon and RSEM use related but distinct optimization algorithms by default. RSEM uses the EM algorithm, and salmon uses the variational Bayesian EM algorithm. The latter tends to induce more sparse solutions. This is simply because they are optimizing slightly different objectives. It is very difficult to say in general if one is ""better"" than the other in a blanket way, but [there is previous literature to support that the VBEM may be more accurate](https://academic.oup.com/bioinformatics/article/29/18/2292/239795). However, while RSEM only implements the EM algorithm, salmon actually implements and provides a switch to use either. So, if you want to test the effect of this difference, you can run salmon with the `--useEM` algorithm. This will tell salmon to use the ""classic"" EM algorithm and will eliminate this source of variation. * As with the other question you asked, there may be a _small_ discrepancy depending on when enforcement of a stranded library kicks in under salmon's `A` library type. You can eliminate tha",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/612#issuecomment-758004590:2662,optimiz,optimization,2662,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/612#issuecomment-758004590,1,['optimiz'],['optimization']
Performance,"imizer; [2021-01-21 09:48:12.160] [alevinLog] [warning] mrna file not provided; using is 1 less feature for whitelisting; [2021-01-21 09:48:12.160] [alevinLog] [warning] rrna file not provided; using is 1 less feature for whitelisting; [2021-01-21 09:48:36.288] [alevinLog] [info] Total 19031525.00 UMI after deduplicating.; [2021-01-21 09:48:36.288] [alevinLog] [info] Total 454402 BiDirected Edges.; [2021-01-21 09:48:36.288] [alevinLog] [info] Total 113688 UniDirected Edges.; [2021-01-21 09:48:36.288] [alevinLog] [warning] Skipped 44 barcodes due to No mapped read; [2021-01-21 09:48:36.307] [alevinLog] [info] Clearing EqMap; Might take some time.; [2021-01-21 09:48:41.314] [alevinLog] [info] Starting white listing of 9971 cells; [2021-01-21 09:48:41.314] [alevinLog] [info] Starting to make feature Matrix; [2021-01-21 09:48:41.337] [alevinLog] [info] Done making feature Matrix; [2021-01-21 09:48:41.557] [alevinLog] [info] Finished white listing; [2021-01-21 09:48:41.580] [alevinLog] [info] Finished optimizer. > {; ""total_reads"": 188934609,; ""reads_with_N"": 0,; ""noisy_cb_reads"": 98310747,; ""noisy_umi_reads"": 16600,; ""used_reads"": 90607262,; ""mapping_rate"": 18.89108045842464,; ""reads_in_eqclasses"": 35691789,; ""total_cbs"": 3896665,; ""used_cbs"": 44518,; ""initial_whitelist"": 9015,; ""low_conf_cbs"": 1000,; ""num_features"": 5,; ""no_read_mapping_cbs"": 44,; ""final_num_cbs"": 6765,; ""deduplicated_umis"": 19031525,; ""mean_umis_per_cell"": 2813,; ""mean_genes_per_cell"": 1315; }. ## My best result with `--exceptCells 30000`; > ...; [2021-01-23 11:07:52.910] [alevinLog] [info] Done barcode density calculation.; [2021-01-23 11:07:52.910] [alevinLog] [info] # Barcodes Used: 188934609 / 188934609.; [2021-01-23 11:07:54.387] [alevinLog] [info] Total 12507(has 995 low confidence) barcodes; [2021-01-23 11:07:55.251] [alevinLog] [info] Done True Barcode Sampling; [2021-01-23 11:07:56.200] [alevinLog] [info] Total **49.0191% reads will be thrown away** because of noisy Cellular barcodes.; [2021-0",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/340#issuecomment-766311567:6658,optimiz,optimizer,6658,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/340#issuecomment-766311567,1,['optimiz'],['optimizer']
Performance,"implies a default consensus slack of 0.2. Setting consensusSlack to 0.35.; [2020-05-05 09:19:06.171] [jointLog] [info] parsing read library format; [2020-05-05 09:19:06.171] [jointLog] [info] There is 1 library.; [2020-05-05 09:19:06.278] [jointLog] [info] Loading pufferfish index; [2020-05-05 09:19:06.278] [jointLog] [warning] The index did not record if the `--keepDuplicates` flag was used. Please consider re-indexing with a newer version of salmon that will propagate this information.; [2020-05-05 09:19:06.278] [jointLog] [info] Loading dense pufferfish index.; -----------------------------------------; | Loading contig table | Time = 30.609 s; -----------------------------------------; size = 36981178; -----------------------------------------; | Loading contig offsets | Time = 1.3312 s; -----------------------------------------; -----------------------------------------; | Loading reference lengths | Time = 5.6842 ms; -----------------------------------------; -----------------------------------------; | Loading mphf table | Time = 20.002 s; -----------------------------------------; size = 3784352032; Number of ones: 36981177; Number of ones per inventory item: 512; Inventory entries filled: 72229; -----------------------------------------; | Loading contig boundaries | Time = 11.467 s; -----------------------------------------; size = 3784352032; -----------------------------------------; | Loading sequence | Time = 9.5665 s; -----------------------------------------; size = 2674916722; -----------------------------------------; | Loading positions | Time = 4.3912 ms; -----------------------------------------; Exception : [std::bad_alloc]; salmon quant was invoked improperly.; For usage information, try salmon quant --help; Exiting. Not sure why it happens... memory doesn't reach the max. ![Screenshot at 2020-05-05 09-45-37](https://user-images.githubusercontent.com/61701461/81045096-d14e0f00-8eb5-11ea-97ed-b4f4454ba042.png). Than you so much in advance!; Fer",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/518#issuecomment-623910021:2441,Load,Loading,2441,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/518#issuecomment-623910021,3,['Load'],['Loading']
Performance,"in query_all; result = tuple(concat(executor.map(subdir_query, channel_urls))); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/concurrent/futures/_base.py"", line 609, in result_iterator; yield fs.pop().result(); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/concurrent/futures/_base.py"", line 446, in result; return self.__get_result(); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/concurrent/futures/_base.py"", line 391, in __get_result; raise self._exception; File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/concurrent/futures/thread.py"", line 58, in run; result = self.fn(*self.args, **self.kwargs); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/conda/core/subdir_data.py"", line 132, in <lambda>; subdir_query = lambda url: tuple(SubdirData(Channel(url), repodata_fn=repodata_fn).query(; File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/conda/core/subdir_data.py"", line 145, in query; self.load(); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/conda/core/subdir_data.py"", line 210, in load; _internal_state = self._load(); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/conda/core/subdir_data.py"", line 375, in _load; raw_repodata_str = fetch_repodata_remote_request(; File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/conda/core/subdir_data.py"", line 701, in fetch_repodata_remote_request; resp = session.get(join_url(url, filename), headers=headers, proxies=session.proxies,; File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/requests/sessions.py"", line 542, in get; return self.request('GET', url, **kwargs); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/requests/sessions.py"", line 529, in request; resp = self.send(prep, **send_kwargs); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/requests/sessions.py"", line 645, in send; r = adapter.send(request, **kwargs); File ""/usr/local/Caskroom",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/724#issuecomment-1171208515:3438,load,load,3438,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/724#issuecomment-1171208515,1,['load'],['load']
Performance,"in solve_final_state; ssc = self._collect_all_metadata(ssc); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/conda/common/io.py"", line 88, in decorated; return f(*args, **kwds); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/conda/core/solve.py"", line 463, in _collect_all_metadata; index, r = self._prepare(prepared_specs); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/conda/core/solve.py"", line 1058, in _prepare; reduced_index = get_reduced_index(self.prefix, self.channels,; File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/conda/core/index.py"", line 288, in get_reduced_index; new_records = SubdirData.query_all(spec, channels=channels, subdirs=subdirs,; File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/conda/core/subdir_data.py"", line 140, in query_all; result = tuple(concat(executor.map(subdir_query, channel_urls))); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/concurrent/futures/_base.py"", line 609, in result_iterator; yield fs.pop().result(); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/concurrent/futures/_base.py"", line 446, in result; return self.__get_result(); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/concurrent/futures/_base.py"", line 391, in __get_result; raise self._exception; File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/concurrent/futures/thread.py"", line 58, in run; result = self.fn(*self.args, **self.kwargs); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/conda/core/subdir_data.py"", line 132, in <lambda>; subdir_query = lambda url: tuple(SubdirData(Channel(url), repodata_fn=repodata_fn).query(; File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/conda/core/subdir_data.py"", line 145, in query; self.load(); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/conda/core/subdir_data.py"", line 210, in load; _internal_state = self._load(); File ""/usr/local/Cask",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/724#issuecomment-1171208515:2603,concurren,concurrent,2603,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/724#issuecomment-1171208515,1,['concurren'],['concurrent']
Performance,"in the bit array; [2016-12-15 15:58:50.677] [stderrLog] [info] Computing transcript lengths; [2016-12-15 15:58:50.677] [stderrLog] [info] Waiting to finish loading hash; [2016-12-15 15:58:50.677] [stderrLog] [info] Done loading index; [2016-12-15 15:58:50.677] [jointLog] [info] done; [2016-12-15 15:58:50.677] [jointLog] [info] Index contained 182608 targets; [2016-12-15 15:58:51.587] [jointLog] [warning] Fragment GC bias correction is currently *experimental* in single-end libraries. Please use this option with caution. processed 16500000 fragments; hits: 44017772; hits per frag: 2.67057. [2016-12-15 16:01:44.937] [jointLog] [info] Computed 119318 rich equivalence classes for further processing; [2016-12-15 16:01:44.937] [jointLog] [info] Counted 12227080 total reads in the equivalence classes; [2016-12-15 16:01:44.948] [jointLog] [info] Mapping rate = 72.5194%. [2016-12-15 16:01:44.948] [jointLog] [info] finished quantifyLibrary(); [2016-12-15 16:01:44.949] [jointLog] [info] Starting optimizer; [2016-12-15 16:01:45.059] [jointLog] [info] Marked 0 weighted equivalence classes as degenerate; [2016-12-15 16:01:45.075] [jointLog] [info] iteration = 0 | max rel diff. = 261.892; [2016-12-15 16:01:45.248] [jointLog] [info] iteration 11, adjusting effective lengths to account for biases; [2016-12-15 16:11:15.738] [jointLog] [info] Computed expected counts (for bias correction); [2016-12-15 16:11:15.739] [jointLog] [info] processed bias for 0.0% of the transcripts; [2016-12-15 16:13:07.074] [jointLog] [info] processed bias for 10.0% of the transcripts; [2016-12-15 16:14:57.019] [jointLog] [info] processed bias for 20.0% of the transcripts; [2016-12-15 16:16:40.365] [jointLog] [info] processed bias for 30.0% of the transcripts; [2016-12-15 16:18:25.798] [jointLog] [info] processed bias for 40.0% of the transcripts; [2016-12-15 16:20:13.944] [jointLog] [info] processed bias for 50.0% of the transcripts; [2016-12-15 16:21:52.350] [jointLog] [info] processed bias for 100.0% of ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267489196:2398,optimiz,optimizer,2398,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267489196,1,['optimiz'],['optimizer']
Performance,"ind the GDB manual and other documentation resources online at:; <http://www.gnu.org/software/gdb/documentation/>. For help, type ""help"".; Type ""apropos word"" to search for commands related to ""word""...; Reading symbols from salmon...done.; (gdb) r; Starting program: /home/common/modules/el8/x86_64/software/salmon/1.2.1-CentOS-vanilla/bin/salmon index -t transcripts.fasta -i sample_salmon_fmd_index --type fmd; Missing separate debuginfos, use: yum debuginfo-install glibc-2.28-72.el8_1.1.x86_64; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; [Thread debugging using libthread_db enabled]; Using host libthread_db library ""/lib64/libthread_db.so.1"".; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641594410:2810,Load,Loadable,2810,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641594410,1,['Load'],['Loadable']
Performance,"ine/detection-comparison/salmon0.4.2-comparison/mouse/SRP057125_SRS936134_2.fastq; drwxrwxr-x 5 vale rst_pub 4.0K Jan 2 20:20 SRP057125_SRS936134_salmon_out; ```. But when I run the script there, it succeeds, without segfault. ```; [vale@ebi-003 salmon-problem]$ bash run_salmon.sh; Version Info: This is the most recent version of Salmon.; # salmon (mapping-based) v0.6.0; # [ program ] => salmon; # [ command ] => quant; # [ index ] => { mouse_cdna_38.p3.78_repbase_ercc.fa }; # [ libType ] => { IU }; # [ mates1 ] => { SRP057125_SRS936134_1.fastq }; # [ mates2 ] => { SRP057125_SRS936134_2.fastq }; # [ output ] => { SRP057125_SRS936134_salmon_out }; # [ biasCorrect ] => { }; # [ useFSPD ] => { }; Logs will be written to SRP057125_SRS936134_salmon_out/logs; [2016-01-02 20:16:39.349] [jointLog] [info] parsing read library format; there is 1 lib; Loading 32-bit quasi index[2016-01-02 20:16:39.895] [stderrLog] [info] Loading Suffix Array; [2016-01-02 20:16:39.895] [stderrLog] [info] Loading Position Hash; [2016-01-02 20:16:39.894] [jointLog] [info] Loading Quasi index; [2016-01-02 20:16:42.565] [stderrLog] [info] Loading Transcript Info; [2016-01-02 20:16:43.654] [stderrLog] [info] Loading Rank-Select Bit Array; [2016-01-02 20:16:44.075] [stderrLog] [info] There were 104534 set bits in the bit array; [2016-01-02 20:16:44.448] [stderrLog] [info] Computing transcript lengths; [2016-01-02 20:16:44.448] [stderrLog] [info] Waiting to finish loading hash; Index contained 104534 targets; [2016-01-02 20:16:57.606] [stderrLog] [info] Done loading index; [2016-01-02 20:16:57.606] [jointLog] [info] done. processed 12000000 fragments; hits: 24367197, hits per frag: 2.06194+06. [2016-01-02 20:17:29.841] [jointLog] [info] Computed 102251 rich equivalence classes for further processing; [2016-01-02 20:17:29.841] [jointLog] [info] Counted 10033689 total reads in the equivalence classes; [2016-01-02 20:17:29.867] [jointLog] [info] Mapping rate = 83.0244%. [2016-01-02 20:17:29.867] [jointLog",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/34#issuecomment-168426741:1837,Load,Loading,1837,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/34#issuecomment-168426741,1,['Load'],['Loading']
Performance,"ing with STAR but not when running with selective alignment. However, salmon will attempt to solve the optimization problem with the alignments it is given, regardless of if those come from STAR or from it's built-in selective alignment. While I would generally expect these to be similar, the alignment algorithms are different; see [e.g. the differences between SA/SAF & STAR here](https://genomebiology.biomedcentral.com/articles/10.1186/s13059-020-02151-8). Nonetheless, it is possible that for a small subset of transcripts, the probabilistic allocations are _so_ ambiguous, that you get large swings in the resulting quantification estimates based on tiny variations in where the optimization starts (which is, itself, stochastic due to the asynchronous nature of salmon's online inference phase). One way we can test this hypothesis is as follows. You can run salmon with `--numGibbsSamples 100` and `-d`. This will tell salmon to perform posterior Gibbs sampling (`--numGibbsSamples 100`) and to dump the range-factorized equivalence classes used for offline quantification (`-d`). The Gibbs sampling files will contain the traces for the transcripts in question over the various iterations of the sampling procedure. Transcripts where there is a tremendous amount of ambiguity will tend to have highly anti-correlated posterior samples, and similarly, if you were to consider the abundance output of these transcripts as a *group*, there would be a large reduction in inferential relative variance. In fact, we [wrote a whole paper on this topic](https://academic.oup.com/bioinformatics/article/36/Supplement_1/i102/5870485). Consider this example from that paper:. ![image](https://user-images.githubusercontent.com/361470/101438021-706d3600-38df-11eb-9ada-a54ea9092d2d.png). The x-axis is samples from the Gibbs chains, and the y-values denote the estimated number of reads assigned to both transcripts in each sample. The green line at the top is what you get if you sum the abundances of ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/600#issuecomment-740363115:1036,perform,perform,1036,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/600#issuecomment-740363115,1,['perform'],['perform']
Performance,ing/salmon/lib:$LD_LIBRARY_PATH ./salmon quant --index Salmon_index_hg38.analysisSet_knownGene --unmatedReads SRR2454059.fq.gz --libType ISF --us; eVBOpt --output test_quant --numGibbsSamples 100 --threads 16; Version Info: This is the most recent **development version** of Salmon.; ### salmon (mapping-based) v0.7.3; ### [ program ] => salmon; ### [ command ] => quant; ### [ index ] => { Salmon_index_hg38.analysisSet_knownGene }; ### [ unmatedReads ] => { SRR2454059.fq.gz }; ### [ libType ] => { ISF }; ### [ useVBOpt ] => { }; ### [ output ] => { test_quant }; ### [ numGibbsSamples ] => { 100 }; ### [ threads ] => { 16 }; Logs will be written to test_quant/logs; [2016-12-13 22:44:07.409] [jointLog] [info] parsing read library format; [2016-12-13 22:44:07.409] [jointLog] [info] There is 1 library.; [2016-12-13 22:44:09.318] [jointLog] [info] Loading Quasi index; [2016-12-13 22:44:09.318] [jointLog] [info] Loading 32-bit quasi index; [2016-12-13 22:44:09.318] [stderrLog] [info] Loading Suffix Array; [2016-12-13 22:44:15.002] [stderrLog] [info] Loading Transcript Info; [2016-12-13 22:44:16.278] [stderrLog] [info] Loading Rank-Select Bit Array; [2016-12-13 22:44:16.625] [stderrLog] [info] There were 182608 set bits in the bit array; [2016-12-13 22:44:16.680] [stderrLog] [info] Computing transcript lengths; [2016-12-13 22:44:16.681] [stderrLog] [info] Waiting to finish loading hash; [2016-12-13 22:44:20.485] [stderrLog] [info] Done loading index; [2016-12-13 22:44:20.485] [jointLog] [info] done; [2016-12-13 22:44:20.485] [jointLog] [info] Index contained 182608 targets. processed 19000001 fragments; hits: 65897764; hits per frag: 3.48152. [2016-12-13 22:45:33.192] [jointLog] [info] Computed 137534 rich equivalence classes for further processing; [2016-12-13 22:45:33.192] [jointLog] [info] Counted 16265961 total reads in the equivalence classes; [2016-12-13 22:45:33.233] [jointLog] [info] Mapping rate = 83.509%. [2016-12-13 22:45:33.233] [jointLog] [info] finished quantify,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-266935584:1385,Load,Loading,1385,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-266935584,1,['Load'],['Loading']
Performance,"ing: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; [New Thread 0x7ffff0987700 (LWP 17537)]. Thread 2 ""salmon"" received signal SIGSEGV, Segmentation fault.; [Switching to Thread 0x7ffff0987700 (LWP 17537)]; 0x00007ffff68202ab in je_tcache_bin_flush_small () from /lib64/libjemalloc.so.2; Missing separate debuginfos, use: yum debuginfo-install boost169-filesystem-1.69.0-4.el8.x86_64 boost169-iostreams-1.69.0-4.el8.x86_64 boost169-program-options-1.69.0-4.el8.x86_64 boost169-system-1.69.0-4.el8.x86_64 brotli-1.0.6-1.el8.x86_64 bzip2-libs-1.0.6-26.el8.x86_64 cyrus-sasl-lib-2.1.27-1.el8.x86_64 jemalloc-5.2.1-2.el8.x86_64 keyutils-libs-1.5.10-6.el8.x86_64 krb5-libs-1.17-9.el8.x86_64 libcom_err-1.44.6-3.el8.x86_64 libcurl-7.61.1-11.el8.x86_64 libgcc-8.3.1-4.5.el8.x86_64 libgomp-8.3.1-4.5.el8.x86_64 libidn2-2.2.0-1.el8.x86_64 libnghttp2-1.33.0-1.el8_0.1.x86_64 libpsl-0.20.2-5.el8.x86_64 libselinux-2.9-2.1.el8.x86_64 libssh-0.9.0-4.el8.x86_64 libstdc++-8.3.1-4.5.el8.x86_6",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641594410:4790,Load,Loadable,4790,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641594410,1,['Load'],['Loadable']
Performance,"ing: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; [New Thread 0x7ffff0987700 (LWP 17537)]. Thread 2 ""salmon"" received signal SIGSEGV, Segmentation fault.; [Switching to Thread 0x7ffff0987700 (LWP 17537)]; 0x00007ffff68202ab in je_tcache_bin_flush_small () from /lib64/libjemalloc.so.2; Missing separate debuginfos, use: yum debuginfo-install boost169-filesystem-1.69.0-4.el8.x86_64 boost169-iostreams-1.69.0-4.el8.x86_64 boost169-program-options-1.69.0-4.el8.x86_64 boost169-system-1.69.0-4.el8.x86_64 brotli-1.0.6-1.el8.x86_64 bzip2-libs-1.0.6-26.el8.x86_64 cyrus-sasl-lib-2.1.27-1.el8.x86_64 jemalloc-5.2.1-2.el8.x86_64 keyutils-libs-1.5.10-6.el8.x86_64 krb5-libs-1.17-9.el8.x86_64 libcom_err-1.44.6-3.el8.x86_64 libcurl-7.61.1-11.el8.x86_64 libgcc-8.3.1-4.5.el8.x86_64 libgomp-8.3.1-4.5.el8.x86_64 libidn2-2.2.0-1.el8.x86_64 libnghttp2-1.33.0-1.el8_0.1.x86_64 libpsl-0.20.2-5.el8.x86_64 libselinux-2.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641594410:4718,Load,Loadable,4718,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641594410,1,['Load'],['Loadable']
Performance,"ing: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; [New Thread 0x7ffff0987700 (LWP 17537)]. Thread 2 ""salmon"" received signal SIGSEGV, Segmentation fault.; [Switching to Thread 0x7ffff0987700 (LWP 17537)]; 0x00007ffff68202ab in je_tcache_bin_flush_small () from /lib64/libjemalloc.so.2; Missing separate debuginfos, use: yum debuginfo-install boost169-filesystem-1.69.0-4.el8.x86_64 boost169-iostreams-1.69.0-4.el8.x86_64 boost169-program-options-1.69.0-4.el8.x86_64 boost169-system-1.69.0-4.el8.x86_64 brotli-1.0.6-1.el8.x86_64 bzip2-libs-1.0.6-26.el8.x86_64 cyrus-sasl-lib-2.1.27-1.el8.x86_64 jemalloc-5.2.1-2.el8.x86_64 keyutils-libs-1.5.10-6.el8.x86_64 krb5-libs-1.17-9.el8.x86_64 libcom_err-1.44.6-3.el8.x86_64 libcurl-7.61.1-11.el8.x86_64 libgcc-8.3.1-4.5.el8.x86_64 libgomp-8.3.1-4.5.el8.x86_64 libidn2-2.2.0-1.el8.x86_64 lib",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641594410:4646,Load,Loadable,4646,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641594410,1,['Load'],['Loadable']
Performance,"ing: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; [New Thread 0x7ffff0987700 (LWP 17537)]. Thread 2 ""salmon"" received signal SIGSEGV, Segmentation fault.; [Switching to Thread 0x7ffff0987700 (LWP 17537)]; 0x00007ffff68202ab in je_tcache_bin_flush_small () from /lib64/libjemalloc.so.2; Missing separate debuginfos, use: yum debuginfo-install boost169-filesystem-1.69.0-4.el8.x86_64 boost169-iostreams-1.69.0-4.el8.x86_64 boost169-program-options-1.69.0-4.el8.x86_64 boost169-system-1.69.0-4.el8.x86_64 brotli-1.0.6-1.el8.x86_64 bzip2-libs-1.0.6-26.el8.x86_64 cyrus-sasl-lib-2.1.27-1.el8.x86_64 jemalloc-5.2.1-2.el8.x86_64 keyutils-libs-1.5.10-6.el8.x86_64 krb5-libs-1.17-9.el8.x86_64 libcom_err-1.44.6-3.el8.x86_64 libcurl-7.61.1-11.el8.x86_64 libgcc-8.3.1-4.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641594410:4574,Load,Loadable,4574,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641594410,1,['Load'],['Loadable']
Performance,"ing: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; [New Thread 0x7ffff0987700 (LWP 17537)]. Thread 2 ""salmon"" received signal SIGSEGV, Segmentation fault.; [Switching to Thread 0x7ffff0987700 (LWP 17537)]; 0x00007ffff68202ab in je_tcache_bin_flush_small () from /lib64/libjemalloc.so.2; Missing separate debuginfos, use: yum debuginfo-install boost169-filesystem-1.69.0-4.el8.x86_64 boost169-iostreams-1.69.0-4.el8.x86_64 boost169-program-options-1.69.0-4.el8.x86_64 boost169-system-1.69.0-4.el8.x86_64 brotli-1.0.6-1.el8.x86_64 bzip2-libs-1.0.6-26.el8.x86_64 cyrus-sasl-lib-2.1.27-1.el8.x86_64 jemalloc-5.2.1-2.el8.x86_64 keyutils-libs-1.5.10-6.el8.x86_64 krb5-libs-1.17-9.el8.x86_64 lib",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641594410:4502,Load,Loadable,4502,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641594410,1,['Load'],['Loadable']
Performance,"ing: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; [New Thread 0x7ffff0987700 (LWP 17537)]. Thread 2 ""salmon"" received signal SIGSEGV, Segmentation fault.; [Switching to Thread 0x7ffff0987700 (LWP 17537)]; 0x00007ffff68202ab in je_tcache_bin_flush_small () from /lib64/libjemalloc.so.2; Missing separate debuginfos, use: yum debuginfo-install boost169-filesystem-1.69.0-4.el8.x86_64 boost169-iostreams-1.69.0-4.el8.x86_64 boost169-program-options-1.69.0-4.el8.x86_64 boost169-system-1.69.0-4.el8.x86_64 brotli-1.0.6-1.el8.x86_64 bzip2-libs-1.0.6-26.el8.x86_64 cyrus-sasl-lib-2.1.27-1.el8.x86_64 jemalloc-5.2.1-2.el8.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641594410:4430,Load,Loadable,4430,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641594410,1,['Load'],['Loadable']
Performance,"inly does seem very low. To answer your specific questions first:; 1) I'm not sure --- let's try tor find out; 2) I don't think so (if they are part of your index, they should be aligned against); 3) If there are many transcripts / targets you expect to be sequenced but which aren't present in this set, that can affect the mapping rate, but not likely to take it down to 6%. Here are the things I'd investigate --- roughly in order: . 1) In addition to the fraction of reads STAR mapped (which you report above), what fraction of the reads are assigned to features by featureCounts? In some cases, when there is a failure of rRNA depletion of polyA selection, you can end up with an experiment where most of the sequenced RNA comes from rRNA not present in the reference transcriptome. In this case, STAR will be able to align the reads to the genome, but you won't see these reads mapping to annotated features (and you also won't see them showing up in your transcript level quantifications). So, it may be worth to take a look at the count of reads assigned to the feature set of genes by featureCounts. 2) Above, it looks like a considerable number of fragments were discarded due to no alignment reaching the required alignment score (`11,448,458` fragments discarded because of this). Have you tried to adapter / quality trim the data? Does this have any effect on the mapping rate?. 3) If the above don't reveal any clues, I'd be happy to try to take a look at the data if you can share it. I'd be quite surprised if STAR is aligning a lot of reads *to transcriptome features* that are being missed by salmon. Nonetheless, if you pass the proper flags to STAR (including `--quantMode TranscriptomeSAM`), then you can use the SAM/BAM file generated by STAR to perform quantification with salmon (i.e. use STAR's alignments to do _transcript-level_ quantification). I'd be happy to help dig further on any of these, so please feel free to reach out if you find anything interesting. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/661#issuecomment-846251054:1838,perform,perform,1838,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/661#issuecomment-846251054,1,['perform'],['perform']
Performance,ion.; [2021-01-21 09:33:35.885] [alevinLog] [info] # Barcodes Used: 188934609 / 188934609.; [2021-01-21 09:33:37.337] [alevinLog] [info] Total 10016(has 1000 low confidence) barcodes; [2021-01-21 09:33:38.202] [alevinLog] [info] Done True Barcode Sampling; [2021-01-21 09:33:39.137] [alevinLog] [warning] Total **52.0343% reads will be thrown away** because of noisy Cellular barcodes.; [2021-01-21 09:33:39.960] [alevinLog] [info] Done populating Z matrix; [2021-01-21 09:33:39.989] [alevinLog] [info] Total 34923 CB got sequence corrected; [2021-01-21 09:33:39.994] [alevinLog] [info] Done indexing Barcodes; [2021-01-21 09:33:39.994] [alevinLog] [info] Total Unique barcodes found: 3896665; [2021-01-21 09:33:39.994] [alevinLog] [info] Used Barcodes except Whitelist: 34503; [2021-01-21 09:33:40.718] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify; [2021-01-21 09:33:40.718] [alevinLog] [info] parsing read library format; [2021-01-21 09:48:11.430] [alevinLog] [info] Starting optimizer; [2021-01-21 09:48:12.160] [alevinLog] [warning] mrna file not provided; using is 1 less feature for whitelisting; [2021-01-21 09:48:12.160] [alevinLog] [warning] rrna file not provided; using is 1 less feature for whitelisting; [2021-01-21 09:48:36.288] [alevinLog] [info] Total 19031525.00 UMI after deduplicating.; [2021-01-21 09:48:36.288] [alevinLog] [info] Total 454402 BiDirected Edges.; [2021-01-21 09:48:36.288] [alevinLog] [info] Total 113688 UniDirected Edges.; [2021-01-21 09:48:36.288] [alevinLog] [warning] Skipped 44 barcodes due to No mapped read; [2021-01-21 09:48:36.307] [alevinLog] [info] Clearing EqMap; Might take some time.; [2021-01-21 09:48:41.314] [alevinLog] [info] Starting white listing of 9971 cells; [2021-01-21 09:48:41.314] [alevinLog] [info] Starting to make feature Matrix; [2021-01-21 09:48:41.337] [alevinLog] [info] Done making feature Matrix; [2021-01-21 09:48:41.557] [alevinLog] [info] Finished white listing; [2021-01-21 09:48:41.580] [alevinLog] [,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/340#issuecomment-766311567:5643,optimiz,optimizer,5643,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/340#issuecomment-766311567,1,['optimiz'],['optimizer']
Performance,itNum: 0; itNum: 1; [2018-05-31 22:48:54.566] [jointLog] [info] Computed 583973 rich equivalence classes for further processing; [2018-05-31 22:48:54.566] [jointLog] [info] Counted 59985214 total reads in the equivalence classes; [2018-05-31 22:48:54.609] [jointLog] [info] Mapping rate = 88.2723%. [2018-05-31 22:48:54.609] [jointLog] [info] finished quantifyLibrary(); [2018-05-31 22:48:54.610] [jointLog] [info] Starting optimizer; [2018-05-31 22:48:54.829] [jointLog] [info] Marked 1 weighted equivalence classes as degenerate; [2018-05-31 22:48:54.859] [jointLog] [info] iteration = 0 | max rel diff. = 127.38; Exception : [Error in function boost::math::digamma<double>(double): numeric overflow]; salmon quant was invoked improperly.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/229#issuecomment-393675075:424,optimiz,optimizer,424,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/229#issuecomment-393675075,1,['optimiz'],['optimizer']
Performance,"ithm so that specific details of the solution are dependent on the order in which the reads are processed (which is random given that multiple threads parse reads and update estimates asynchronously). However, the more important point here is that the inference estimates returned by Salmon (and, for that matter, every other transcript-level expression tool) are the result of a statistical optimization procedure that cannot guarantee a unique global optimal solution (and, in fact, even if a global optimum could be guaranteed, there may be multiple different optima). Thus, there is uncertainty inherent in the statistical problem being solved. Of course, if one ordered updates in the same way and set up the initial conditions precisely the same, there would be convergence to the same result, but any sense of confidence there is illusory. However, Salmon does provide a way to quantify, statistically, confidence in the result. The `--numBootstraps` option will do bootstrap sampling, or the `--numGibbsSamples` option will perform posterior Gibbs sampling. Both of these techniques will provide samples from the posterior distribution, and the variance of these samples will give you some information about the variance in the results that are due purely to the inherent statistical uncertainty in the problem. In the `scripts` folder there is a python script `ConvertBootstrapsToTSV.py` that will convert either the bootstrap or gibbs samples to a easily readable tsv format. These samples represent the estimated number of reads coming from each transcript when sampling from the posterior. These can be used to empirically estimate that statistical uncertainty in the abundance estimates of the different transcripts. Finally, I'll note that while, for the reasons described above, the output is not purely deterministic. The difference between subsequent runs of salmon (with differences changing depending on the order in which reads are parsed and processed) is typically small (and mu",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/102#issuecomment-259464248:1312,perform,perform,1312,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/102#issuecomment-259464248,1,['perform'],['perform']
Performance,"jointLog] [info] Loading Quasi index; [2018-12-06 11:16:56.294] [jointLog] [info] Loading 32-bit quasi index; [2018-12-06 11:16:56.205] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify. [2018-12-06 11:16:56.218] [alevinLog] [info] parsing read library format; [2018-12-06 11:16:56.296] [stderrLog] [info] Loading Suffix Array ; [2018-12-06 11:16:56.846] [stderrLog] [info] Loading Transcript Info ; [2018-12-06 11:16:57.009] [stderrLog] [info] Loading Rank-Select Bit Array; [2018-12-06 11:16:57.046] [stderrLog] [info] There were 167,268 set bits in the bit array; [2018-12-06 11:16:57.063] [stderrLog] [info] Computing transcript lengths; [2018-12-06 11:16:57.064] [stderrLog] [info] Waiting to finish loading hash; [2018-12-06 11:17:00.929] [jointLog] [info] done; [2018-12-06 11:17:00.929] [jointLog] [info] Index contained 167,268 targets. processed 267 Million fragmentsrrLog] [info] Done loading index; hits: 844899161, hits per frag: 3.15864^[[D. [2018-12-06 11:45:12.188] [jointLog] [info] Computed 118,295 rich equivalence classes for further processing; [2018-12-06 11:45:12.188] [jointLog] [info] Counted 154,595,094 total reads in the equivalence classes ; [2018-12-06 11:45:12.188] [jointLog] [warning] Found 115077 reads with `N` in the UMI sequence and ignored the reads.; Please report on github if this number is too large; [2018-12-06 11:45:12.188] [jointLog] [info] Mapping rate = 57.7821%. [2018-12-06 11:45:12.188] [jointLog] [info] finished quantifyLibrary(); [2018-12-06 11:45:13.385] [alevinLog] [info] Starting optimizer. Analyzed 5344 cells (100% of all).; [2018-12-06 11:49:42.634] [alevinLog] [info] Total 4845644.00 UMI after deduplicating.; [2018-12-06 11:49:42.722] [alevinLog] [info] Clearing EqMap; Might take some time.; [2018-12-06 11:49:47.400] [alevinLog] [info] Starting Import of the gene count matrix of size 5344x167268.; Exception : [std::bad_alloc]; alevin was invoked improperly.; For usage information, try alevin --help; Exiting.; ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/328#issuecomment-445008548:7586,optimiz,optimizer,7586,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/328#issuecomment-445008548,1,['optimiz'],['optimizer']
Performance,"l IU \; -1 ~/data/raw-data/BLB/${line}1.fastq.gz \; -2 ~/data/raw-data/BLB/${line}2.fastq.gz --numBootstraps=30 \; -p 12 -o ~/results/salmon_quant_Sheng_IU_old/${line} --seqBias --gcBias. The EffectiveLength is again the same (250) for all genes across all samples:; Name Length EffectiveLength TPM NumReads; LOC_Os01g01010.1 3017 250 28.8836 527.392; LOC_Os01g01010.2 2218 250 1.84062 33.6083; LOC_Os01g01019.1 1127 250 0.0547668 1; LOC_Os01g01030.1 2464 250 4.43611 81; LOC_Os01g01040.4 1524 250 0.941635 17.1935; LOC_Os01g01040.1 2508 250 11.5632 211.135; LOC_Os01g01040.2 2482 250 8.02082 146.454; LOC_Os01g01040.3 2583 250 8.55554 156.218; LOC_Os01g01050.1 2039 250 17.2333 314.667. The mapping rate is again similar for all samples:; [2019-03-04 04:42:18.872] [jointLog] [info] parsing read library format; [2019-03-04 04:42:18.872] [jointLog] [info] There is 1 library.; [2019-03-04 04:42:18.928] [jointLog] [info] Loading Quasi index; [2019-03-04 04:42:18.929] [jointLog] [info] Loading 32-bit quasi index; [2019-03-04 04:42:28.958] [jointLog] [info] done; [2019-03-04 04:42:28.958] [jointLog] [info] Index contained 66153 targets; [2019-03-04 04:44:08.443] [fileLog] [info]; At end of round 0; ==================; Observed 18861231 total fragments (18861231 in most recent round). [2019-03-04 04:44:08.442] [jointLog] [info] Computed 48502 rich equivalence classes for further processing; [2019-03-04 04:44:08.442] [jointLog] [info] Counted 17308442 total reads in the equivalence classes; [2019-03-04 04:44:08.450] [jointLog] [info] Mapping rate = 91.7673%. [2019-03-04 04:44:08.450] [jointLog] [info] finished quantifyLibrary(). **For version 0.12**; #!/bin/bash; #SBATCH -N 1; #SBATCH -c 8; #SBATCH --mem=10G; #SBATCH --mail-use=tarun2@illinois.edu; #SBATCH -J Salmon; #SBATCH -a 1-24. module load Salmon/0.12.0-IGB-gcc-8.2.0. line=$(sed -n -e ""$SLURM_ARRAY_TASK_ID p"" ~/source/BLBnew.txt). salmon quant -i ~/data/genome/MSU7new_transcript.index -l IU \; -1 ~/results/trimmingSheng/${line",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/346#issuecomment-469215256:1716,Load,Loading,1716,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/346#issuecomment-469215256,1,['Load'],['Loading']
Performance,ld is just the GNU linker.; I still think it's not able to find the zlib **library** file since the error at `-lz` where `-l` gives the namespace of the library.; If you are confident about the inclusion of the `Zlib` then can you try clearing the cmake cache (i.e. remove the file CMakeCache.txt) and build again?,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/141#issuecomment-314430634:254,cache,cache,254,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/141#issuecomment-314430634,1,['cache'],['cache']
Performance,"lengths; [2019-06-06 19:24:57.084] [stderrLog] [info] Waiting to finish loading hash; [2019-06-06 19:25:06.552] [jointLog] [info] done; [2019-06-06 19:25:06.552] [jointLog] [info] Index contained 136,011 targets; [2019-06-06 19:25:06.552] [stderrLog] [info] Done loading index; [2019-06-06 19:25:06.728] [alevinLog] [error] Barcode not found in frequency table; ```. Salmon Quant log is this. ```; [2019-06-06 19:23:29.519] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2019-06-06 19:23:29.519] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2019-06-06 19:23:29.520] [jointLog] [info] Usage of --validateMappings, without --hardFilter implies use of range factorization. rangeFactorizationBins is being set to 4; [2019-06-06 19:23:29.520] [jointLog] [info] Usage of --validateMappings implies a default consensus slack of 0.2. Setting consensusSlack to 0.2.; [2019-06-06 19:23:29.520] [jointLog] [info] Using default value of 0.87 for minScoreFraction in Alevin; Using default value of 0.6 for consensusSlack in Alevin; [2019-06-06 19:24:55.716] [jointLog] [info] There is 1 library.; [2019-06-06 19:24:55.889] [jointLog] [info] Loading Quasi index; [2019-06-06 19:24:55.889] [jointLog] [info] Loading 32-bit quasi index; [2019-06-06 19:25:06.552] [jointLog] [info] done; [2019-06-06 19:25:06.552] [jointLog] [info] Index contained 136,011 targets; ```. It is interesting because the barcodes are recognized during the processing, but they don't appear in the frequency table? I don0t get that part. > Can you clarify a bit more about what you meant with: The FASTQ file of the reads is not paired-end. I mean that each of the files has all the unique reads, that is, it is not a paired-end sample where one fastq is forward and the other one is reverse. I just mentioned it in case it was necessary for the `--end 5`parameter. Thanks for the help!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/369#issuecomment-499592790:3046,Load,Loading,3046,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/369#issuecomment-499592790,2,['Load'],['Loading']
Performance,"levinLog] [info] Done barcode density calculation.; [2019-06-06 19:24:55.681] [alevinLog] [info] # Barcodes Used: 31478936 / 31478936.; [2019-06-06 19:24:55.688] [alevinLog] [info] Total 247(has 200 low confidence) barcodes; [2019-06-06 19:24:55.688] [alevinLog] [info] Done True Barcode Sampling; [2019-06-06 19:24:55.690] [alevinLog] [info] Total 0% reads will be thrown away because of noisy Cellular barcodes.; [2019-06-06 19:24:55.692] [alevinLog] [info] Done populating Z matrix; [2019-06-06 19:24:55.692] [alevinLog] [info] Done indexing Barcodes; [2019-06-06 19:24:55.692] [alevinLog] [info] Total Unique barcodes found: 50; [2019-06-06 19:24:55.692] [alevinLog] [info] Used Barcodes except Whitelist: 0; [2019-06-06 19:24:55.716] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify. [2019-06-06 19:24:55.716] [alevinLog] [info] parsing read library format; [2019-06-06 19:24:55.716] [jointLog] [info] There is 1 library.; [2019-06-06 19:24:55.889] [jointLog] [info] Loading Quasi index; [2019-06-06 19:24:55.889] [jointLog] [info] Loading 32-bit quasi index; [2019-06-06 19:24:55.890] [stderrLog] [info] Loading Suffix Array ; [2019-06-06 19:24:56.791] [stderrLog] [info] Loading Transcript Info ; [2019-06-06 19:24:57.025] [stderrLog] [info] Loading Rank-Select Bit Array; [2019-06-06 19:24:57.061] [stderrLog] [info] There were 136,011 set bits in the bit array; [2019-06-06 19:24:57.084] [stderrLog] [info] Computing transcript lengths; [2019-06-06 19:24:57.084] [stderrLog] [info] Waiting to finish loading hash; [2019-06-06 19:25:06.552] [jointLog] [info] done; [2019-06-06 19:25:06.552] [jointLog] [info] Index contained 136,011 targets; [2019-06-06 19:25:06.552] [stderrLog] [info] Done loading index; [2019-06-06 19:25:06.728] [alevinLog] [error] Barcode not found in frequency table; ```. Salmon Quant log is this. ```; [2019-06-06 19:23:29.519] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2019-06-06 19",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/369#issuecomment-499592790:1300,Load,Loading,1300,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/369#issuecomment-499592790,1,['Load'],['Loading']
Performance,levinLog] [info] Throwing 0 barcodes with < 1 reads; > [2020-06-04 17:56:25.388] [alevinLog] [info] Total [32m95377[0m(has [32m11[0m low confidence) barcodes; > [2020-06-04 17:56:25.577] [alevinLog] [info] Done True Barcode Sampling; > [2020-06-04 17:56:25.698] [alevinLog] [info] Total 1.2299% reads will be thrown away because of noisy Cellular barcodes.; > [2020-06-04 17:56:29.508] [alevinLog] [info] Done populating Z matrix; > [2020-06-04 17:56:29.545] [alevinLog] [info] Total 118774 CB got sequence corrected; > [2020-06-04 17:56:29.557] [alevinLog] [info] Done indexing Barcodes; > [2020-06-04 17:56:29.557] [alevinLog] [info] Total Unique barcodes found: 604589; > [2020-06-04 17:56:29.557] [alevinLog] [info] Used Barcodes except Whitelist: 88156; > [2020-06-04 17:56:30.294] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify; > ; > [2020-06-04 17:56:30.294] [alevinLog] [info] parsing read library format; > [2020-06-04 17:57:36.339] [alevinLog] [info] Starting optimizer; > ; > ; > [2020-06-04 17:57:37.051] [alevinLog] [warning] mrna file not provided; using is 1 less feature for whitelisting; > [2020-06-04 17:57:37.051] [alevinLog] [warning] rrna file not provided; using is 1 less feature for whitelisting; > [2020-06-04 17:57:37.338] [alevinLog] [info] Total 23937.00 UMI after deduplicating.; > [2020-06-04 17:57:37.338] [alevinLog] [info] Total 91 BiDirected Edges.; > [2020-06-04 17:57:37.338] [alevinLog] [info] Total 82 UniDirected Edges.; > [2020-06-04 17:57:37.338] [alevinLog] [warning] Skipped 82268 barcodes due to No mapped read; > [2020-06-04 17:57:37.341] [alevinLog] [info] Clearing EqMap; Might take some time.; > [2020-06-04 17:57:37.348] [alevinLog] [warning] Num Low confidence barcodes too less 1 < 10.Can't performing whitelisting; Skipping; > [2020-06-04 17:57:37.348] [alevinLog] [info] Finished optimizer; > ; > . salmon_quant.log. > [2020-06-04 17:55:11.700] [jointLog] [info] setting maxHashResizeThreads to 7; > [2020-06-04 17:55:11.7,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-639196415:1796,optimiz,optimizer,1796,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-639196415,1,['optimiz'],['optimizer']
Performance,"list ] => { barcode_seq_5K.txt }; ### [ dumpCsvCounts ] => { }. [2018-07-19 22:53:27.714] [alevinLog] [info] Processing barcodes files (if Present) . ; processed 87 Million barcodes. [2018-07-19 22:55:37.299] [alevinLog] [info] Done barcode density calculation.; [2018-07-19 22:55:37.299] [alevinLog] [info] # Barcodes Used: 86885223 / 87959276.; [2018-07-19 22:55:37.303] [alevinLog] [info] Done importing white-list Barcodes; [2018-07-19 22:55:37.303] [alevinLog] [info] Total 5238 white-listed Barcodes; [2018-07-19 22:55:37.675] [alevinLog] [info] Done populating Z matrix; [2018-07-19 22:55:37.683] [alevinLog] [info] Done indexing Barcodes; [2018-07-19 22:55:37.683] [alevinLog] [info] Total Unique barcodes found: 978816; [2018-07-19 22:55:37.683] [alevinLog] [info] Used Barcodes except Whitelist: 20705; [2018-07-19 22:55:38.386] [jointLog] [info] There is 1 library.; [2018-07-19 22:55:38.493] [jointLog] [info] Loading Quasi index; [2018-07-19 22:55:38.494] [jointLog] [info] Loading 32-bit quasi index; [2018-07-19 22:55:38.549] [jointLog] [info] done; [2018-07-19 22:55:38.549] [jointLog] [info] Index contained 179 targets. [2018-07-19 22:55:38.385] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify. [2018-07-19 22:55:38.385] [alevinLog] [info] parsing read library format; [2018-07-19 22:55:38.495] [stderrLog] [info] Loading Suffix Array ; [2018-07-19 22:55:38.498] [stderrLog] [info] Loading Transcript Info ; [2018-07-19 22:55:38.499] [stderrLog] [info] Loading Rank-Select Bit Array; [2018-07-19 22:55:38.500] [stderrLog] [info] There were 179 set bits in the bit array; [2018-07-19 22:55:38.501] [stderrLog] [info] Computing transcript lengths; [2018-07-19 22:55:38.501] [stderrLog] [info] Waiting to finish loading hash; processed 87 Million fragmentserrLog] [info] Done loading index; hits: 468892, hits per frag: 0.00535907. [2018-07-19 23:03:35.740] [jointLog] [info] Computed 150 rich equivalence classes for further processing; [2018-07-19 23:03:35.740] [",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/253#issuecomment-406597243:2471,Load,Loading,2471,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/253#issuecomment-406597243,1,['Load'],['Loading']
Performance,"lmon/quasi/mouse_cdna_38.p3.78_repbase_ercc.fa }; # [ libType ] => { IU }; # [ mates1 ] => { /nfs/research2/teichmann/valentine/detection-comparison/salmon0.4.2-comparison/mouse/SRP057125_SRS936134_1.fastq }; # [ mates2 ] => { /nfs/research2/teichmann/valentine/detection-comparison/salmon0.4.2-comparison/mouse/SRP057125_SRS936134_2.fastq }; # [ output ] => { SRP057125_SRS936134_salmon_out }; # [ geneMap ] => { /nfs/research2/teichmann/reference/mus-musculus/salmon/mouse_cdna38.78_repbase_ercc_index_gene_map.txt }; # [ biasCorrect ] => { }; # [ useFSPD ] => { }; Logs will be written to SRP057125_SRS936134_salmon_out/logs; [2016-01-02 20:22:59.800] [jointLog] [info] parsing read library format; there is 1 lib; Loading 32-bit quasi index[2016-01-02 20:23:00.830] [stderrLog] [info] Loading Suffix Array; [2016-01-02 20:23:00.830] [stderrLog] [info] Loading Position Hash; [2016-01-02 20:23:00.829] [jointLog] [info] Loading Quasi index; [2016-01-02 20:23:03.751] [stderrLog] [info] Loading Transcript Info; [2016-01-02 20:23:04.776] [stderrLog] [info] Loading Rank-Select Bit Array; [2016-01-02 20:23:05.009] [stderrLog] [info] There were 104534 set bits in the bit array; [2016-01-02 20:23:05.325] [stderrLog] [info] Computing transcript lengths; [2016-01-02 20:23:05.325] [stderrLog] [info] Waiting to finish loading hash; Index contained 104534 targets; [2016-01-02 20:23:16.571] [stderrLog] [info] Done loading index; [2016-01-02 20:23:16.571] [jointLog] [info] done. processed 12000001 fragments; hits: 24367128, hits per frag: 2.04044. [2016-01-02 20:23:49.850] [jointLog] [info] Computed 102251 rich equivalence classes for further processing; [2016-01-02 20:23:49.850] [jointLog] [info] Counted 10033689 total reads in the equivalence classes; [2016-01-02 20:23:49.875] [jointLog] [info] Mapping rate = 83.0244%. [2016-01-02 20:23:49.875] [jointLog] [info] finished quantifyLibrary(); [2016-01-02 20:23:49.875] [jointLog] [info] Starting optimizer; [2016-01-02 20:23:50.378] [jointLog]",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/34#issuecomment-168426741:7875,Load,Loading,7875,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/34#issuecomment-168426741,1,['Load'],['Loading']
Performance,"lowing is the content of the `salmon_quant.log`. ```; [2016-01-03 00:33:37.001] [jointLog] [info] parsing read library format; [2016-01-03 00:33:37.510] [jointLog] [info] Loading Quasi index; [2016-01-03 00:33:53.646] [jointLog] [info] done; [2016-01-03 00:34:14.501] [jointLog] [info] Computed 13742 rich equivalence classes for further processing; [2016-01-03 00:34:14.501] [jointLog] [info] Counted 335230 total reads in the equivalence classes; [2016-01-03 00:34:14.501] [fileLog] [info]; At end of round 0; ==================; Observed 3835342 total fragments (3835342 in most recent round). [2016-01-03 00:34:20.992] [jointLog] [warning] Only 335230 fragments were mapped, but the number of burn-in fragments was set to 5000000.; The effective lengths have been computed using the observed mappings. [2016-01-03 00:34:20.992] [jointLog] [info] Mapping rate = 8.74055%. [2016-01-03 00:34:20.992] [jointLog] [info] finished quantifyLibrary(); [2016-01-03 00:34:20.992] [jointLog] [info] Starting optimizer; [2016-01-03 00:34:21.028] [jointLog] [info] Marked 0 weighted equivalence classes as degenerate; [2016-01-03 00:34:21.030] [jointLog] [info] iteration = 0 | max rel diff. = 23.4889; [2016-01-03 00:34:21.167] [jointLog] [info] iteration = 100 | max rel diff. = 0.150549; [2016-01-03 00:34:21.304] [jointLog] [info] iteration = 200 | max rel diff. = 0.0517672; [2016-01-03 00:34:21.447] [jointLog] [info] iteration = 300 | max rel diff. = 0.0368208; [2016-01-03 00:34:21.578] [jointLog] [info] iteration = 400 | max rel diff. = 0.0237254; [2016-01-03 00:34:21.705] [jointLog] [info] iteration = 500 | max rel diff. = 0.0147784; [2016-01-03 00:34:21.834] [jointLog] [info] iteration = 600 | max rel diff. = 0.0131134; [2016-01-03 00:34:21.961] [jointLog] [info] iteration = 700 | max rel diff. = 0.0130094; [2016-01-03 00:34:22.092] [jointLog] [info] iteration = 800 | max rel diff. = 0.0100546; [2016-01-03 00:34:22.196] [jointLog] [info] iteration = 882 | max rel diff. = 0.00861472; [2016-",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/29#issuecomment-168447784:1255,optimiz,optimizer,1255,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/29#issuecomment-168447784,1,['optimiz'],['optimizer']
Performance,"lt still segfaults. It still needed an edit of the CMakeLists.txt file. Still, for future reference:. ```; pversion=1.2.1; package=salmon; TOPDIR=/usr/common/modules/el8/x86_64/software/${package}/${pversion}-CentOS-vanilla; wget https://github.com/COMBINE-lab/salmon/archive/v1.2.1.tar.gz; gunzip -c v1.2.1.tar.gz | tar -xf -; /bin/rm v1.2.1.tar.gz; cd ${package}-${pversion}; mv CMakeLists.txt CMakeLists.txt.dist; cat >mypatch <<'EOD'; --- CMakeLists.txt.dist	2020-04-21 22:31:07.000000000 -0700; +++ CMakeLists.txt	2020-06-09 14:55:02.733885772 -0700; @@ -419,6 +419,10 @@; find_package(Boost 1.59.0 COMPONENTS iostreams filesystem system timer chrono program_options); message(""BOOST_INCLUDEDIR = ${BOOST_INCLUDEDIR}""); message(""BOOST_LIBRARYDIR = ${BOOST_LIBRARYDIR}""); +message(""Forcing Boost_FOUND to TRUE""); +set(Boost_FOUND TRUE); +set(Boost_LIBRARY_DIRS ""/usr/lib64/boost169""); +set(Boost_LIBRARIES -lboost_iostreams -lboost_filesystem -lboost_system -lboost_timer -lboost_chrono -lboost_program_options); message(""Boost_FOUND = ${Boost_FOUND}""); endif(); ; EOD; patch -p0 <mypatch; module load cmake; module load io_lib; module load libgff; module load libtbb; mkdir build; cd build; export CFLAGS=""-g -O0""; export CXXFLAGS=""-g -O0""; cmake \; -DCMAKE_INSTALL_PREFIX=$TOPDIR \; -DSTADEN_ROOT=$ROOT_IO_LIB \; -DGFF_ROOT=$ROOT_LIBGFF \; -DTBB_ROOT=$ROOT_LIBTBB \; -DCMAKE_VERBOSE_MAKEFILE:BOOL=ON \; -DBOOST_LIBRARYDIR=/usr/lib64/boost169 \; -DBOOST_INCLUDEDIR=/usr/include/boost169 \; -DBoost_NO_SYSTEM_PATHS=ON \; .. 2>&1 | tee cmake_2020_06_09.log; make -j 4 2>&1 | tee build_2020_06_09.log. ```. Since it was compiled ""-g -O0"" this time it was easier to step through it. Well, somewhat. In Salmon.cpp line 195 is the last place a break point works. If one is set for 197 it segfaults before reaching it. Line 195 is:. `	 po::store(parsed, vm);; `; I tried briefly to trace inward from there but couldn't make heads or tails of the path it was taking through an endless series of headers.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641612831:1149,load,load,1149,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641612831,4,['load'],['load']
Performance,"lt_multiplier<unsigned long> >&, std::gamma_distribution<double>::param_type const&) (); #2 0x0000000000634b8d in tbb::interface9::internal::start_for<tbb::blocked_range<unsigned long>, sampleRoundNonCollapsedMultithreaded_(std::vector<std::pair<TranscriptGroup const, TGValue>, std::allocator<std::pair<TranscriptGroup const, TGValue> > >&, std::vector<bool, std::allocator<bool> >&, std::vector<unsigned long, std::allocator<unsigned long> >&, std::vector<double, std::allocator<double> >&, std::vector<double, std::allocator<double> >&, Eigen::Matrix<double, -1, 1, 0, -1, 1>&, std::vector<double, std::allocator<double> > const&, std::vector<double, std::allocator<double> >&, std::vector<unsigned int, std::allocator<unsigned int> >&)::{lambda(tbb::blocked_range<unsigned long> const&)#2}, tbb::auto_partitioner const>::execute() (); #3 0x00007f20171ca492 in tbb::internal::custom_scheduler<tbb::internal::IntelSchedulerTraits>::local_wait_for_all (this=0x7f1fd8dc0c00, parent=..., child=<optimized out>); at ../../src/tbb/custom_scheduler.h:469; #4 0x00007f20171c85a0 in tbb::internal::generic_scheduler::local_spawn_root_and_wait (this=0x7f1fd8dc0c00, first=..., next=@0x7f1fd8db7d38: 0x7f1fd8db7340); at ../../src/tbb/scheduler.cpp:649; #5 0x0000000000632eba in sampleRoundNonCollapsedMultithreaded_(std::vector<std::pair<TranscriptGroup const, TGValue>, std::allocator<std::pair<TranscriptGroup const, TGValue> > >&, std::vector<bool, std::allocator<bool> >&, std::vector<unsigned long, std::allocator<unsigned long> >&, std::vector<double, std::allocator<double> >&, std::vector<double, std::allocator<double> >&, Eigen::Matrix<double, -1, 1, 0, -1, 1>&, std::vector<double, std::allocator<double> > const&, std::vector<double, std::allocator<double> >&, std::vector<unsigned int, std::allocator<unsigned int> >&) (); #6 0x000000000063936f in bool CollapsedGibbsSampler::sample<ReadExperiment>(ReadExperiment&, SalmonOpts&, std::function<bool (std::vector<double, std::allocator<double> > c",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267534520:2867,optimiz,optimized,2867,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267534520,1,['optimiz'],['optimized']
Performance,"mat; [2019-03-04 04:42:18.872] [jointLog] [info] There is 1 library.; [2019-03-04 04:42:18.928] [jointLog] [info] Loading Quasi index; [2019-03-04 04:42:18.929] [jointLog] [info] Loading 32-bit quasi index; [2019-03-04 04:42:28.958] [jointLog] [info] done; [2019-03-04 04:42:28.958] [jointLog] [info] Index contained 66153 targets; [2019-03-04 04:44:08.443] [fileLog] [info]; At end of round 0; ==================; Observed 18861231 total fragments (18861231 in most recent round). [2019-03-04 04:44:08.442] [jointLog] [info] Computed 48502 rich equivalence classes for further processing; [2019-03-04 04:44:08.442] [jointLog] [info] Counted 17308442 total reads in the equivalence classes; [2019-03-04 04:44:08.450] [jointLog] [info] Mapping rate = 91.7673%. [2019-03-04 04:44:08.450] [jointLog] [info] finished quantifyLibrary(). **For version 0.12**; #!/bin/bash; #SBATCH -N 1; #SBATCH -c 8; #SBATCH --mem=10G; #SBATCH --mail-use=tarun2@illinois.edu; #SBATCH -J Salmon; #SBATCH -a 1-24. module load Salmon/0.12.0-IGB-gcc-8.2.0. line=$(sed -n -e ""$SLURM_ARRAY_TASK_ID p"" ~/source/BLBnew.txt). salmon quant -i ~/data/genome/MSU7new_transcript.index -l IU \; -1 ~/results/trimmingSheng/${line}1.paired.fastq \; -2 ~/results/trimmingSheng/${line}2.paired.fastq --numBootstraps=30 \; -p 12 -o ~/results/salmon_quant_Sheng_IU/${line} --seqBias --gcBias --validateMappings. There are no estimate and reads generated when invokin the library type IU:; Name Length EffectiveLength TPM NumReads; LOC_Os01g01010.1 3017 3017.000 0.000000 0.000; LOC_Os01g01010.2 2218 2218.000 0.000000 0.000; LOC_Os01g01019.1 1127 1127.000 0.000000 0.000; LOC_Os01g01030.1 2464 2464.000 0.000000 0.000; LOC_Os01g01040.4 1524 1524.000 0.000000 0.000; LOC_Os01g01040.1 2508 2508.000 0.000000 0.000; LOC_Os01g01040.2 2482 2482.000 0.000000 0.000; LOC_Os01g01040.3 2583 2583.000 0.000000 0.000; LOC_Os01g01050.1 2039 2039.000 0.000000 0.000. [2019-03-04 01:24:12.788] [jointLog] [info] Fragment incompatibility prior below thresho",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/346#issuecomment-469215256:2534,load,load,2534,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/346#issuecomment-469215256,1,['load'],['load']
Performance,"me sample with salmon index generated as discussed above and got this report ; [2022-05-14 01:26:06.437] [jointLog] [info] Computed 380,631 rich equivalence classes for further processing; [2022-05-14 01:26:06.437] [jointLog] [info] Counted 22,462,069 total reads in the equivalence classes ; [2022-05-14 01:26:06.454] [jointLog] [info] Number of mappings discarded because of alignment score : 236,393,072; [2022-05-14 01:26:06.454] [jointLog] [info] Number of fragments entirely discarded because of alignment score : 3,028,418; [2022-05-14 01:26:06.454] [jointLog] [info] Number of fragments discarded because they are best-mapped to decoys : 0; [2022-05-14 01:26:06.454] [jointLog] [info] Number of fragments discarded because they have only dovetail (discordant) mappings to valid targets : 1,137,227; [2022-05-14 01:26:06.454] [jointLog] [info] Mapping rate = 57.216%. [2022-05-14 01:26:06.455] [jointLog] [info] finished quantifyLibrary(); [2022-05-14 01:26:06.485] [jointLog] [info] Starting optimizer; [2022-05-14 01:26:06.581] [jointLog] [info] Marked 0 weighted equivalence classes as degenerate; [2022-05-14 01:26:06.593] [jointLog] [info] iteration = 0 | max rel diff. = 10507; [2022-05-14 01:26:07.966] [jointLog] [info] iteration = 100 | max rel diff. = 17.2222; [2022-05-14 01:26:09.253] [jointLog] [info] iteration = 200 | max rel diff. = 12.5822; [2022-05-14 01:26:10.641] [jointLog] [info] iteration = 300 | max rel diff. = 12.6466; [2022-05-14 01:26:11.976] [jointLog] [info] iteration = 400 | max rel diff. = 4.95752; [2022-05-14 01:26:13.272] [jointLog] [info] iteration = 500 | max rel diff. = 0.754259; [2022-05-14 01:26:14.546] [jointLog] [info] iteration = 600 | max rel diff. = 0.148902; [2022-05-14 01:26:15.788] [jointLog] [info] iteration = 700 | max rel diff. = 0.117727; [2022-05-14 01:26:17.074] [jointLog] [info] iteration = 800 | max rel diff. = 0.166671; [2022-05-14 01:26:18.385] [jointLog] [info] iteration = 900 | max rel diff. = 0.068019; [2022-05-14 01:26:19.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/775#issuecomment-1126593943:2311,optimiz,optimizer,2311,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/775#issuecomment-1126593943,1,['optimiz'],['optimizer']
Performance,"mon for mapping and quantification, there is a separate background thread that simply consumes reads from file and puts them in memory for quantification, and while e.g. pairing information between files is guaranteed to be preserved, exact read order is not. This can lead to differences in the order in which reads are processed and, as a result, differences in the initialization conditions of the optimization. The ultimate result is that for transcripts that have large inferential uncertainty, different numbers of reads can be assigned between runs. We have thought *a lot* about this behavior, what it means, and how the `NumRead` values should best be communicated to users. At the end of the day, the `NumReads` constitute the expected value of latent variables inferred in a _very_ high-dimensional space (# of parameters is at least the number of transcripts). Therefore, there are certain transcripts, whose estimated number of reads simply have _tremendous_ inferential uncertainty — and small perturbations in the initial conditions of the optimization will lead to different estimated values for their abundances. For those transcripts where you observe such fluctuations between runs, this is simply evidence that the precision that can be confidently placed on those estimates is below the degree of variation you observe. Treating these transcripts in downstream analysis as more certain can easily lead to spurious inferences regarding things like differential transcript expression or usage. . One can make an argument for trying to provide a way to enforce removal of this variation (which, granted, would be a challenge). However, the reason we decided against even attempting this is because it doesn't properly address any issue with respect to an actual biological analysis. That is, even if you could fix, precisely, the update order and initialization conditions for a specific sample to eliminate any variation between runs, almost all experiments consist of multiple samp",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/613#issuecomment-757989858:1861,optimiz,optimization,1861,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/613#issuecomment-757989858,1,['optimiz'],['optimization']
Performance,mon run that I got the backtrace from:. ```; Version Info: This is the most recent **development version** of Salmon.; ### salmon (mapping-based) v0.7.3; ### [ program ] => salmon; ### [ command ] => quant; ### [ index ] => { /home/ryan/references/hg38/Salmon_index_hg38.analysisSet_knownGene }; ### [ libType ] => { SR }; ### [ unmatedReads ] => { fastq_files/SRR2454069.fq.gz }; ### [ threads ] => { 8 }; ### [ seqBias ] => { }; ### [ gcBias ] => { }; ### [ useVBOpt ] => { }; ### [ dumpEq ] => { }; ### [ dumpEqWeights ] => { }; ### [ geneMap ] => { /home/ryan/references/hg38/Salmon_index_hg38.analysisSet_knownGene/genemap.txt }; ### [ output ] => { salmon_temp/REF/SRR2454069 }; ### [ auxDir ] => { aux_info }; ### [ numGibbsSamples ] => { 10 }; Logs will be written to salmon_temp/REF/SRR2454069/logs; [2016-12-15 15:58:50.157] [jointLog] [info] parsing read library format; [2016-12-15 15:58:50.157] [jointLog] [info] There is 1 library.; [2016-12-15 15:58:50.189] [jointLog] [info] Loading Quasi index; [2016-12-15 15:58:50.189] [jointLog] [info] Loading 32-bit quasi index; [2016-12-15 15:58:50.189] [stderrLog] [info] Loading Suffix Array; [2016-12-15 15:58:50.513] [stderrLog] [info] Loading Transcript Info; [2016-12-15 15:58:50.599] [stderrLog] [info] Loading Rank-Select Bit Array; [2016-12-15 15:58:50.661] [stderrLog] [info] There were 182608 set bits in the bit array; [2016-12-15 15:58:50.677] [stderrLog] [info] Computing transcript lengths; [2016-12-15 15:58:50.677] [stderrLog] [info] Waiting to finish loading hash; [2016-12-15 15:58:50.677] [stderrLog] [info] Done loading index; [2016-12-15 15:58:50.677] [jointLog] [info] done; [2016-12-15 15:58:50.677] [jointLog] [info] Index contained 182608 targets; [2016-12-15 15:58:51.587] [jointLog] [warning] Fragment GC bias correction is currently *experimental* in single-end libraries. Please use this option with caution. processed 16500000 fragments; hits: 44017772; hits per frag: 2.67057. [2016-12-15 16:01:44.937] [jointLog],MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267489196:1020,Load,Loading,1020,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267489196,1,['Load'],['Loading']
Performance,"mon0.4.2-comparison/mouse/SRP057125_SRS936134_1.fastq; lrwxrwxrwx 1 vale rst_pub 112 Jan 2 20:08 SRP057125_SRS936134_2.fastq -> /nfs/research2/teichmann/valentine/detection-comparison/salmon0.4.2-comparison/mouse/SRP057125_SRS936134_2.fastq; drwxrwxr-x 5 vale rst_pub 4.0K Jan 2 20:20 SRP057125_SRS936134_salmon_out; ```. But when I run the script there, it succeeds, without segfault. ```; [vale@ebi-003 salmon-problem]$ bash run_salmon.sh; Version Info: This is the most recent version of Salmon.; # salmon (mapping-based) v0.6.0; # [ program ] => salmon; # [ command ] => quant; # [ index ] => { mouse_cdna_38.p3.78_repbase_ercc.fa }; # [ libType ] => { IU }; # [ mates1 ] => { SRP057125_SRS936134_1.fastq }; # [ mates2 ] => { SRP057125_SRS936134_2.fastq }; # [ output ] => { SRP057125_SRS936134_salmon_out }; # [ biasCorrect ] => { }; # [ useFSPD ] => { }; Logs will be written to SRP057125_SRS936134_salmon_out/logs; [2016-01-02 20:16:39.349] [jointLog] [info] parsing read library format; there is 1 lib; Loading 32-bit quasi index[2016-01-02 20:16:39.895] [stderrLog] [info] Loading Suffix Array; [2016-01-02 20:16:39.895] [stderrLog] [info] Loading Position Hash; [2016-01-02 20:16:39.894] [jointLog] [info] Loading Quasi index; [2016-01-02 20:16:42.565] [stderrLog] [info] Loading Transcript Info; [2016-01-02 20:16:43.654] [stderrLog] [info] Loading Rank-Select Bit Array; [2016-01-02 20:16:44.075] [stderrLog] [info] There were 104534 set bits in the bit array; [2016-01-02 20:16:44.448] [stderrLog] [info] Computing transcript lengths; [2016-01-02 20:16:44.448] [stderrLog] [info] Waiting to finish loading hash; Index contained 104534 targets; [2016-01-02 20:16:57.606] [stderrLog] [info] Done loading index; [2016-01-02 20:16:57.606] [jointLog] [info] done. processed 12000000 fragments; hits: 24367197, hits per frag: 2.06194+06. [2016-01-02 20:17:29.841] [jointLog] [info] Computed 102251 rich equivalence classes for further processing; [2016-01-02 20:17:29.841] [jointLog] [info] Cou",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/34#issuecomment-168426741:1699,Load,Loading,1699,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/34#issuecomment-168426741,1,['Load'],['Loading']
Performance,"mon_index }; # [ libType ] => { IU }; # [ mates1 ] => { ../strange_peak/19232_1_1.fastq }; # [ mates2 ] => { ../strange_peak/19232_1_2.fastq }; # [ output ] => { quant_binary }; Logs will be written to quant_binary/logs; there is 1[2016-03-31 14:05:14.184] [jointLog] [info] parsing read library format; lib; Loading 64-bit quasi index[2016-03-31 14:05:14.266] [stderrLog] [info] Loading Suffix Array; [2016-03-31 14:05:14.266] [jointLog] [info] Loading Quasi index. [2016-03-31 14:07:58.647] [stderrLog] [info] Loading Transcript Info; [2016-03-31 14:08:59.703] [stderrLog] [info] Loading Rank-Select Bit Array; [2016-03-31 14:09:06.744] [stderrLog] [info] There were 2027284 set bits in the bit array; [2016-03-31 14:09:08.123] [stderrLog] [info] Computing transcript lengths; [2016-03-31 14:09:08.240] [stderrLog] [info] Waiting to finish loading hash; Index contained 2027284 targets; [2016-03-31 14:09:15.789] [jointLog] [info] done; [2016-03-31 14:09:15.786] [stderrLog] [info] Successfully loaded position hash; [2016-03-31 14:09:15.789] [stderrLog] [info] Done loading index. [2016-03-31 14:09:36.623] [jointLog] [info] Computed 8083 rich equivalence classes for further processing; [2016-03-31 14:09:36.623] [jointLog] [info] Counted 159824 total reads in the equivalence classes. [2016-03-31 14:13:24.480] [jointLog] [warning] Only 159824 fragments were mapped, but the number of burn-in fragments was set to 5000000.; The effective lengths have been computed using the observed mappings. [2016-03-31 14:13:24.480] [jointLog] [info] Mapping rate = 36.3942%. [2016-03-31 14:13:24.480] [jointLog] [info] finished quantifyLibrary(); [2016-03-31 14:13:24.480] [jointLog] [info] Starting optimizer; [2016-03-31 14:13:25.441] [jointLog] [info] Marked 0 weighted equivalence classes as degenerate; [2016-03-31 14:13:25.660] [jointLog] [info] iteration = 0 | max rel diff. = 13.7627; [2016-03-31 14:13:26.460] [jointLog] [info] iteration = 100 | max rel diff. = 0.100799; [2016-03-31 14:13:27.252] ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/54#issuecomment-204066023:1731,load,loaded,1731,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/54#issuecomment-204066023,1,['load'],['loaded']
