quality_attribute,sentence,source,author,repo,version,id,keyword,matched_word,match_idx,wiki,url,total_similar,target_keywords,target_matched_words
Performance,"mp3,. Thanks for raising this issue. So, I _am_ surprised at these particular differences that you found, but the behavior you are observing is consistent with how automatic library type detection works. Let me explain what it's doing, and then I'm open to discussing if we should focus on changing that behavior going forward. The standard library type detection works by looking at the total number of compatible mappings in both possible orientations for the first x=10,000 aligned reads. These 10,000 reads are themselves mapped with an `IU` orientation in paired data and a `U` orientation in unpaired data. Once the 10,000 data points have been processed, a heuristic chooses the most likely library type and applies it (and salmon issues a warning if, at the end of quantification,, there are too many reads that disagree). So, the explanation of what could be happening here is that the reads that are different between your runs are coming within the first set of 10,000 aligned reads (note, this may not be the first 10k reads of the file, because concurrent processing means that reads from different threads are being aligned in an essentially random order ... but of course maintaining pairing information). The argument for why this should usually not cause a considerable difference is because (1) the reads are assumed to arrive in a random order (2) this is only a very small fraction of the total data and (3) if the unoriented reads map to a target in the ""wrong"" direction, they will also align to the proper target in the ""right"" direction and, once the orientation filter is applied for future reads, the weight of evidence should turn the probability of assignment of these unoriented reads toward the proper target. However, I'm guessing there is an edge case you're seeing here where the conditions don't induce this behavior. So, there are 2 immediate solutions to the problem. First, if you know the library type explicitly, you can use that. Second (and some other folks h",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/489#issuecomment-738830213:1076,concurren,concurrent,1076,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/489#issuecomment-738830213,1,['concurren'],['concurrent']
Performance,"n/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts }; ### [ threads ] => { 1 }; ### [ libType ] => { ISR }; ### [ mates1 ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/merged_fastq/R10001_D2B1WACXX.fastq.gz }; ### [ mates2 ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/merged_fastq/R10001_D2B1WACXX_read2.fastq.gz }; ### [ output ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test5/R10001_D2B1WACXX }; Logs will be written to /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test5/R10001_D2B1WACXX/logs; [1m[2017-03-29 23:59:18.699] [jointLog] [info] parsing read library format; [00m[1m[2017-03-29 23:59:18.721] [jointLog] [info] There is 1 library.; [00m[1m[2017-03-30 00:43:17.278] [stderrLog] [info] Loading Suffix Array ; [00m[1m[2017-03-30 00:43:17.237] [jointLog] [info] Loading Quasi index; [00m[1m[2017-03-30 00:43:17.273] [jointLog] [info] Loading 32-bit quasi index; [00m[1m[2017-03-30 02:37:54.437] [stderrLog] [info] Loading Transcript Info ; [00m[1m[2017-03-30 03:48:21.310] [stderrLog] [info] Loading Rank-Select Bit Array; [00m[1m[2017-03-30 04:20:16.735] [stderrLog] [info] There were 198093 set bits in the bit array; [00m[1m[2017-03-30 04:54:34.486] [stderrLog] [info] Computing transcript lengths; [00m[1m[2017-03-30 04:54:34.487] [stderrLog] [info] Waiting to finish loading hash; [00m[1m[2017-03-30 05:09:36.706] [stderrLog] [info] Done loading index; [00m[1m[2017-03-30 05:09:36.706] [jointLog] [info] done; [00m[1m[2017-03-30 05:09:36.790] [jointLog] [info] Index contained 198093 targets; [00m. [A. [32mprocessed[31m 500000 [32mfragments[0m; hits: 699833, hits per frag: 1.4138[A. [32mprocessed[31m 1000000 [32mfragments[0m; hits: 1395659, hits per frag: 1.40267[A. [32mprocessed[31m 1500000 [32mfragments[0m; hits: 2097294, hits per frag: 1.40287[A. [32mprocessed[31m 2000000 [32mfragments[0m; hits: 2794766, hits per frag: 1.40089[A. [32mprocessed[31m 2500000 [32mfragments[0m; h",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-290516965:10083,Load,Loading,10083,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-290516965,1,['Load'],['Loading']
Performance,"ndexing Barcodes; [2018-12-06 11:16:55.453] [alevinLog] [info] Total Unique barcodes found: 4180559; [2018-12-06 11:16:55.453] [alevinLog] [info] Used Barcodes except Whitelist: 134856; [2018-12-06 11:16:56.218] [jointLog] [info] There are 2 libraries.; [2018-12-06 11:16:56.292] [jointLog] [info] Loading Quasi index; [2018-12-06 11:16:56.294] [jointLog] [info] Loading 32-bit quasi index; [2018-12-06 11:16:56.205] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify. [2018-12-06 11:16:56.218] [alevinLog] [info] parsing read library format; [2018-12-06 11:16:56.296] [stderrLog] [info] Loading Suffix Array ; [2018-12-06 11:16:56.846] [stderrLog] [info] Loading Transcript Info ; [2018-12-06 11:16:57.009] [stderrLog] [info] Loading Rank-Select Bit Array; [2018-12-06 11:16:57.046] [stderrLog] [info] There were 167,268 set bits in the bit array; [2018-12-06 11:16:57.063] [stderrLog] [info] Computing transcript lengths; [2018-12-06 11:16:57.064] [stderrLog] [info] Waiting to finish loading hash; [2018-12-06 11:17:00.929] [jointLog] [info] done; [2018-12-06 11:17:00.929] [jointLog] [info] Index contained 167,268 targets. processed 267 Million fragmentsrrLog] [info] Done loading index; hits: 844899161, hits per frag: 3.15864^[[D. [2018-12-06 11:45:12.188] [jointLog] [info] Computed 118,295 rich equivalence classes for further processing; [2018-12-06 11:45:12.188] [jointLog] [info] Counted 154,595,094 total reads in the equivalence classes ; [2018-12-06 11:45:12.188] [jointLog] [warning] Found 115077 reads with `N` in the UMI sequence and ignored the reads.; Please report on github if this number is too large; [2018-12-06 11:45:12.188] [jointLog] [info] Mapping rate = 57.7821%. [2018-12-06 11:45:12.188] [jointLog] [info] finished quantifyLibrary(); [2018-12-06 11:45:13.385] [alevinLog] [info] Starting optimizer. Analyzed 5344 cells (100% of all).; [2018-12-06 11:49:42.634] [alevinLog] [info] Total 4845644.00 UMI after deduplicating.; [2018-12-06 11:49:42.722] [al",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/328#issuecomment-445008548:6753,load,loading,6753,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/328#issuecomment-445008548,1,['load'],['loading']
Performance,"ned 245,261 targets ; [2022-04-16 11:23:53.776] [jointLog] [info] Number of decoys : 0 ; [2022-04-16 11:24:42.358] [jointLog] [info] Computed 960,194 rich equivalence classes for further processing [2022-04-16 11:24:42.358] [jointLog] [info] Counted 23,784,776 total reads in the equivalence classes [2022-04-16 11:24:42.426] [jointLog] [info] Number of mappings discarded because of alignment score : 3,206,484 [2022-04-16 11:24:42.426] [jointLog] [info] Number of fragments entirely discarded because of alignment score : 170,372 [2022-04-16 11:24:42.426] [jointLog] [info] Number of fragments discarded because they are best-mapped to decoys : 0 [2022-04-16 11:24:42.426] [jointLog] [info] Number of fragments discarded because they have only dovetail (discordant) mappings to valid targets : 154,144 ; [2022-04-16 11:24:42.426] [jointLog] [info] Mapping rate = 95.4075% [2022-04-16 11:24:42.426] [jointLog] [info] finished quantifyLibrary() ; [2022-04-16 11:24:42.494] [jointLog] [info] Starting optimizer ; [2022-04-16 11:24:42.359] [fileLog] [info] ; At end of round 0 ; ================== ; Observed 24929662 total fragments (24929662 in most recent round) [2022-04-16 11:24:43.294] [jointLog] [info] Marked 0 weighted equivalence classes as degenerate [2022-04-16 11:24:43.366] [jointLog] [info] iteration = 0 | max rel diff. = 5078.09 ; [2022-04-16 11:24:50.352] [jointLog] [info] iteration = 100 | max rel diff. = 20.8492 ; [2022-04-16 11:24:57.458] [jointLog] [info] iteration = 200 | max rel diff. = 18.848 ; [2022-04-16 11:25:04.256] [jointLog] [info] iteration = 300 | max rel diff. = 4.55549 ; [2022-04-16 11:25:09.015] [jointLog] [info] iteration = 400 | max rel diff. = 2.20112 ; [2022-04-16 11:25:15.019] [jointLog] [info] iteration = 500 | max rel diff. = 8.9451 ; [2022-04-16 11:25:20.936] [jointLog] [info] iteration = 600 | max rel diff. = 8.80249 ; [2022-04-16 11:25:26.808] [jointLog] [info] iteration = 700 | max rel diff. = 0.955605 ; [2022-04-16 11:25:32.739] [jointLog] [in",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/768#issuecomment-1100734317:17193,optimiz,optimizer,17193,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/768#issuecomment-1100734317,1,['optimiz'],['optimizer']
Performance,"ng it; [2021-01-25 16:27:05.707] [alevinLog] [info] Learned InvCov: 556.394 normfactor: 9159.58; [2021-01-25 16:27:05.707] [alevinLog] [info] Total 222(has 201 low confidence) barcodes; [2021-01-25 16:27:06.573] [alevinLog] [info] Done True Barcode Sampling; [2021-01-25 16:27:07.383] [alevinLog] [warning] Total **96.7029% reads will be thrown away** because of noisy Cellular barcodes.; [2021-01-25 16:27:07.412] [alevinLog] [info] Done populating Z matrix; [2021-01-25 16:27:07.414] [alevinLog] [info] Total 3667 CB got sequence corrected; [2021-01-25 16:27:07.414] [alevinLog] [info] Done indexing Barcodes; [2021-01-25 16:27:07.414] [alevinLog] [info] Total Unique barcodes found: 3896665; [2021-01-25 16:27:07.414] [alevinLog] [info] Used Barcodes except Whitelist: 3667; [2021-01-25 16:27:07.498] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify; [2021-01-25 16:27:07.498] [alevinLog] [info] parsing read library format; [2021-01-25 16:30:54.542] [alevinLog] [info] Starting optimizer; [2021-01-25 16:30:54.782] [alevinLog] [warning] mrna file not provided; using is 1 less feature for whitelisting; [2021-01-25 16:30:54.782] [alevinLog] [warning] rrna file not provided; using is 1 less feature for whitelisting; [2021-01-25 16:30:55.950] [alevinLog] [info] Total 1350278.00 UMI after deduplicating.; [2021-01-25 16:30:55.950] [alevinLog] [info] Total 30909 BiDirected Edges.; [2021-01-25 16:30:55.950] [alevinLog] [info] Total 8817 UniDirected Edges.; [2021-01-25 16:30:55.969] [alevinLog] [info] Clearing EqMap; Might take some time.; [2021-01-25 16:30:56.294] [alevinLog] [warning] Num High confidence barcodes too less 20 < 90.Can't performing whitelisting; Skipping; [2021-01-25 16:30:56.297] [alevinLog] [info] Finished optimizer. ## with `--exceptCells 7000`; > [2021-01-21 09:24:45.891] [alevinLog] [info] Found 43030 transcripts(+0 decoys, +0 short and +0 duplicate names in the index); [2021-01-21 09:24:45.942] [alevinLog] [info] Filled with 43030 txp to gene ent",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/340#issuecomment-766311567:3392,optimiz,optimizer,3392,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/340#issuecomment-766311567,1,['optimiz'],['optimizer']
Performance,"ng of these considerations. It’s good to think about how data processing choices may affect your results and you are being thoughtful here. I wouldn’t say that, generally, alignment-free tools are more accurate than alignment-based ones. For example, you might look at our recent paper on how [alignment and mapping methodology can influence abundance estimation even when holding the quantification approach fixed](https://genomebiology.biomedcentral.com/articles/10.1186/s13059-020-02151-8), or [this paper on the corner cases of alignment-free methodology](https://bmcgenomics.biomedcentral.com/articles/10.1186/s12864-018-4869-5) (note the second paper pre-dates the first, and the new selective-alignment methodology in salmon should largely address the issues raised in that paper). However, the bigger and more meaningful distinction is between methods that attempt to properly quantify abundance (generally using a generative statistical model) — including methods like RSEM, BitSeq, salmon, etc., and those that try to simply count aligned reads — including methods like HTSeq and featureCounts. Generally, the former type of methods are more accurate than the latter at both the gene level and the former can also offer transcript-level estimates if desired (counting based methods generally cannot). Finally, to your question more directly, I don’t believe that model misspecification that may result due to not knowing the fragment length distribution will generally have enough of a deleterious effect on the probabilistic quantification methods to degrade their performance to the level of counting based methods. I would still argue to prefer probabilistic quantification (i.e. salmon) to read counting, even if you don’t know the fragment length distribution. As I mentioned above, it may change the maximum likelihood estimates a bit, but should do so across all samples, hopefully minimizing the downstream effects on differential analysis. Good luck with your analysis!. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/127#issuecomment-750943952:1629,perform,performance,1629,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/127#issuecomment-750943952,2,['perform'],['performance']
Performance,"ng to Quantify; > ; > [2020-06-04 12:26:11.113] [alevinLog] [info] parsing read library format; > [2020-06-04 12:27:21.373] [alevinLog] [info] Starting optimizer; > ; > [2020-06-04 12:27:22.086] [alevinLog] [warning] mrna file not provided; using is 1 less feature for whitelisting; > [2020-06-04 12:27:22.086] [alevinLog] [warning] rrna file not provided; using is 1 less feature for whitelisting; > [2020-06-04 12:27:22.409] [alevinLog] [info] Total 23937.00 UMI after deduplicating.; > [2020-06-04 12:27:22.409] [alevinLog] [info] Total 91 BiDirected Edges.; > [2020-06-04 12:27:22.409] [alevinLog] [info] Total 82 UniDirected Edges.; > [2020-06-04 12:27:22.409] [alevinLog] [warning] Skipped 82268 barcodes due to No mapped read; > [2020-06-04 12:27:22.412] [alevinLog] [info] Clearing EqMap; Might take some time.; > [2020-06-04 12:27:22.418] [alevinLog] [warning] Num Low confidence barcodes too less 1 < 100.Can't performing whitelisting; Skipping; > [2020-06-04 12:27:22.418] [alevinLog] [info] Finished optimizer. Run 2: `salmon alevin -l ISR --citeseq --barcodeLength 16 --umiLength 10 --end 5 --featureStart 19 --featureLength 21 --maxNumBarcodes 200000 --freqThreshold 1 --lowRegionMinNumBarcodes 100`. > [2020-06-04 12:40:45.455] [alevinLog] [info] set CITE-seq minScoreFraction parameter to : 0.797619; > [2020-06-04 12:40:45.456] [alevinLog] [info] Found 64 transcripts(+0 decoys, +0 short and +0 duplicate names in the index); > [2020-06-04 12:40:45.456] [alevinLog] [info] Filled with 64 txp to gene entries ; > [2020-06-04 12:40:45.456] [alevinLog] [info] Found all transcripts to gene mappings; > [2020-06-04 12:40:45.461] [alevinLog] [info] Processing barcodes files (if Present) ; > ; > [2020-06-04 12:42:01.202] [alevinLog] [info] Done barcode density calculation.; > [2020-06-04 12:42:01.202] [alevinLog] [info] # Barcodes Used: [32m52200250[0m / [31m52200250[0m.; > [2020-06-04 12:42:01.300] [alevinLog] [info] Forcing to use 200000 cells; > [2020-06-04 12:42:02.037] [alev",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-638991199:4035,optimiz,optimizer,4035,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-638991199,2,['optimiz'],['optimizer']
Performance,"ng-based) v0.6.0; # [ program ] => salmon; # [ command ] => quant; # [ index ] => { /nfs/research2/teichmann/reference/mus-musculus/salmon/quasi/mouse_cdna_38.p3.78_repbase_ercc.fa }; # [ libType ] => { IU }; # [ mates1 ] => { /nfs/research2/teichmann/valentine/detection-comparison/salmon0.4.2-comparison/mouse/SRP057125_SRS936134_1.fastq }; # [ mates2 ] => { /nfs/research2/teichmann/valentine/detection-comparison/salmon0.4.2-comparison/mouse/SRP057125_SRS936134_2.fastq }; # [ output ] => { SRP057125_SRS936134_salmon_out }; # [ geneMap ] => { /nfs/research2/teichmann/reference/mus-musculus/salmon/mouse_cdna38.78_repbase_ercc_index_gene_map.txt }; # [ biasCorrect ] => { }; # [ useFSPD ] => { }; Logs will be written to SRP057125_SRS936134_salmon_out/logs; [2016-01-02 20:22:59.800] [jointLog] [info] parsing read library format; there is 1 lib; Loading 32-bit quasi index[2016-01-02 20:23:00.830] [stderrLog] [info] Loading Suffix Array; [2016-01-02 20:23:00.830] [stderrLog] [info] Loading Position Hash; [2016-01-02 20:23:00.829] [jointLog] [info] Loading Quasi index; [2016-01-02 20:23:03.751] [stderrLog] [info] Loading Transcript Info; [2016-01-02 20:23:04.776] [stderrLog] [info] Loading Rank-Select Bit Array; [2016-01-02 20:23:05.009] [stderrLog] [info] There were 104534 set bits in the bit array; [2016-01-02 20:23:05.325] [stderrLog] [info] Computing transcript lengths; [2016-01-02 20:23:05.325] [stderrLog] [info] Waiting to finish loading hash; Index contained 104534 targets; [2016-01-02 20:23:16.571] [stderrLog] [info] Done loading index; [2016-01-02 20:23:16.571] [jointLog] [info] done. processed 12000001 fragments; hits: 24367128, hits per frag: 2.04044. [2016-01-02 20:23:49.850] [jointLog] [info] Computed 102251 rich equivalence classes for further processing; [2016-01-02 20:23:49.850] [jointLog] [info] Counted 10033689 total reads in the equivalence classes; [2016-01-02 20:23:49.875] [jointLog] [info] Mapping rate = 83.0244%. [2016-01-02 20:23:49.875] [jointLog] [",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/34#issuecomment-168426741:7742,Load,Loading,7742,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/34#issuecomment-168426741,1,['Load'],['Loading']
Performance,"nscripts.fasta -i sample_salmon_fmd_index --type fmd; Missing separate debuginfos, use: yum debuginfo-install glibc-2.28-72.el8_1.1.x86_64; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; [Thread debugging using libthread_db enabled]; Using host libthread_db library ""/lib64/libthread_db.so.1"".; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641594410:3170,Load,Loadable,3170,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641594410,1,['Load'],['Loadable']
Performance,"nt algorithms like Bowtie2 and BWA-MEM with respect to both sensitivity and specificity. Here, you are likely seeing a manifestation of the former. Specifically, greedy behavior can lead to spurious matches. Many of these spurious matches are filtered out when applying a consensus mechanism to the series of matches produced by a read; however, this can result in the read going unmapped. We have noticed this behavior where spurious matches can ""mask"" better overall mappings, and we have developed an algorithm to overcome these limitations (called selective-alignment). This is currently implemented in [this branch](https://github.com/COMBINE-lab/salmon/tree/rescue-orphan) of the Salmon repo (if you want to test it out and have trouble building, we can build you a linux executable). This algorithm explores more potential mappings and then applies a fast algorithm for filtering potentially poor ones. In our benchmarks, it exhibits sensitivity and specificity very close to Bowtie2 (which is among the best of the alignment-based methods we considered). Also, I will note that, though the speed and statistical optimization procedures used in fast transcript abundance estimation tools make them a potentially desirable choice for microbiomic / metagenomic abundance estimation, their indices are typically optimized for speed and not size. For small numbers of bacterial species this can be okay, but if one wishes to index large collections of species, the memory usage can become a problem. To this end, we have developed a new indexing scheme (software [here](https://github.com/COMBINE-lab/pufferfish), slightly out-of-date pre-print [here](https://www.biorxiv.org/content/early/2017/09/21/191874)). That code already implements a tool for taxonomic read assignment (a la the excellent [Kraken](https://github.com/DerrickWood/kraken)), but not yet abundance estimation (that is coming soon). So, depending on how much you want to scale up, you might want to keep an eye on that as well.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/196#issuecomment-365337297:1447,optimiz,optimization,1447,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/196#issuecomment-365337297,2,['optimiz'],"['optimization', 'optimized']"
Performance,"nty"" for details.; This GDB was configured as ""x86_64-redhat-linux-gnu"".; Type ""show configuration"" for configuration details.; For bug reporting instructions, please see:; <http://www.gnu.org/software/gdb/bugs/>.; Find the GDB manual and other documentation resources online at:; <http://www.gnu.org/software/gdb/documentation/>. For help, type ""help"".; Type ""apropos word"" to search for commands related to ""word""...; Reading symbols from salmon...done.; (gdb) r; Starting program: /home/common/modules/el8/x86_64/software/salmon/1.2.1-CentOS-vanilla/bin/salmon index -t transcripts.fasta -i sample_salmon_fmd_index --type fmd; Missing separate debuginfos, use: yum debuginfo-install glibc-2.28-72.el8_1.1.x86_64; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; [Thread debugging using libthread_db enabled]; Using host libthread_db library ""/lib64/libthread_db.so.1"".; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641594410:2594,Load,Loadable,2594,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641594410,1,['Load'],['Loadable']
Performance,"nu/libdl.so.2 (0x00007f8599b19000); libstdc++.so.6 => /u/user/local/lib64/libstdc++.so.6 (0x00007f859979f000); ```. The linux version and g++ version are listed below:; ```; cat /proc/version; Linux version 4.9.0-0.bpo.6-amd64 (debian-kernel@lists.debian.org) (gcc version 4.9.2 (Debian 4.9.2-10+deb8u1) ) #1 SMP Debian 4.9.82-1+deb9u3~bpo8+1 (2018-03-22). ~/data/PCSI/PC10X/paper/pbmc$ g++ -v; Using built-in specs.; COLLECT_GCC=g++; COLLECT_LTO_WRAPPER=/u/user/local/libexec/gcc/x86_64-unknown-linux-gnu/5.4.0/lto-wrapper; Target: x86_64-unknown-linux-gnu; Configured with: ./configure --prefix=/u/user/local; Thread model: posix; gcc version 5.4.0 (GCC); ```. ```; [Thread debugging using libthread_db enabled]; Using host libthread_db library ""/lib/x86_64-linux-gnu/libthread_db.so.1"".; warning: File ""/u/user/local/lib64/libstdc++.so.6.0.21-gdb.py"" auto-loading has been declined by your `auto-load safe-path' set to ""$debugdir:$datadir/auto-load"".; To enable execution of this file add; add-auto-load-safe-path /u/user/local/lib64/libstdc++.so.6.0.21-gdb.py; line to your configuration file ""/u/user/.gdbinit"".; To completely disable this security protection add; set auto-load safe-path /; line to your configuration file ""/u/user/.gdbinit"".; For more information about this security protection see the; ""Auto-loading safe path"" section in the GDB manual. E.g., run from the shell:; info ""(gdb)Auto-loading safe path""; [New Thread 0x7fff7e0f4700 (LWP 14274)]; Version Info: ### A newer version of Salmon is available. ####; [Thread 0x7fff7e0f4700 (LWP 14274) exited]; ###; The newest version, available at https://github.com/COMBINE-lab/salmon/releases; contains new features, improvements, and bug fixes; please upgrade at your; earliest convenience.; ###; [New Thread 0x7fff7d273700 (LWP 14275)]; Logs will be written to pbmc4k/alevin/logs; [New Thread 0x7ffefc3f1700 (LWP 14276)]; [New Thread 0x7ffe7b56f700 (LWP 14277)]; [New Thread 0x7ffdfa6ed700 (LWP 14278)]; ### salmon (single-cell-bas",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-395836214:2294,load,load-safe-path,2294,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-395836214,1,['load'],['load-safe-path']
Performance,"o] Done indexing Barcodes; [2019-01-29 09:55:04.855] [alevinLog] [info] Total Unique barcodes found: 70316; [2019-01-29 09:55:04.855] [alevinLog] [info] Used Barcodes except Whitelist: 184; [2019-01-29 09:55:04.882] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify. [2019-01-29 09:55:04.882] [alevinLog] [info] parsing read library format; [2019-01-29 09:55:05.014] [stderrLog] [info] Loading Suffix Array ; [2019-01-29 09:55:04.882] [jointLog] [info] There is 1 library.; [2019-01-29 09:55:05.012] [jointLog] [info] Loading Quasi index; [2019-01-29 09:55:05.013] [jointLog] [info] Loading 32-bit quasi index; [2019-01-29 09:55:06.105] [stderrLog] [info] Loading Transcript Info ; [2019-01-29 09:55:09.968] [stderrLog] [info] Loading Rank-Select Bit Array; [2019-01-29 09:55:16.908] [stderrLog] [info] There were 80,511 set bits in the bit array; [2019-01-29 09:55:19.931] [stderrLog] [info] Computing transcript lengths; [2019-01-29 09:55:19.931] [stderrLog] [info] Waiting to finish loading hash; [2019-01-29 09:55:41.122] [jointLog] [info] done; [2019-01-29 09:55:41.122] [jointLog] [info] Index contained 80,511 targets; [2019-01-29 09:55:41.122] [stderrLog] [info] Done loading index. processed 0 Million fragments; hits: 161433, hits per frag: 0.32698. [2019-01-29 09:55:54.788] [alevinLog] [info] Starting optimizer; [2019-01-29 09:55:54.742] [jointLog] [info] Computed 6,346 rich equivalence classes for further processing; [2019-01-29 09:55:54.742] [jointLog] [info] Counted 80,300 total reads in the equivalence classes ; [2019-01-29 09:55:54.754] [jointLog] [warning] Only 80300 fragments were mapped, but the number of burn-in fragments was set to 5000000.; The effective lengths have been computed using the observed mappings. [2019-01-29 09:55:54.754] [jointLog] [info] Mapping rate = 8.80342%. [2019-01-29 09:55:54.754] [jointLog] [info] finished quantifyLibrary(). Analyzed 289 cells (100% of all).; [2019-01-29 09:55:56.858] [alevinLog] [info] Total 72037 UMI after",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/337#issuecomment-458481722:3347,load,loading,3347,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/337#issuecomment-458481722,1,['load'],['loading']
Performance,"o] iteration = 300 | max rel diff. = 0.0375335; [00m[1m[2017-03-30 11:33:16.917] [jointLog] [info] iteration = 400 | max rel diff. = 0.0281626; [00m[1m[2017-03-30 11:33:32.635] [jointLog] [info] iteration = 500 | max rel diff. = 0.0213515; [00m[1m[2017-03-30 11:33:48.229] [jointLog] [info] iteration = 600 | max rel diff. = 0.0163419; [00m[1m[2017-03-30 11:34:05.482] [jointLog] [info] iteration = 700 | max rel diff. = 0.0161512; [00m[1m[2017-03-30 11:34:22.202] [jointLog] [info] iteration = 800 | max rel diff. = 0.0161512; [00m[1m[2017-03-30 11:34:38.380] [jointLog] [info] iteration = 900 | max rel diff. = 0.0124406; [00m[1m[2017-03-30 11:34:54.979] [jointLog] [info] iteration = 1000 | max rel diff. = 0.0116537; [00m[1m[2017-03-30 11:35:11.215] [jointLog] [info] iteration = 1100 | max rel diff. = 0.0116537; [00m[1m[2017-03-30 11:35:12.190] [jointLog] [info] iteration = 1107 | max rel diff. = 0.00948523; [00m[1m[2017-03-30 11:35:12.199] [jointLog] [info] Finished optimizer; [00m[1m[2017-03-30 11:35:12.199] [jointLog] [info] writing output . [00m[33m[1m[2017-03-30 11:38:26.886] [jointLog] [warning] NOTE: Read Lib [( /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/merged_fastq/R10001_D2B1WACXX.fastq.gz, /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/merged_fastq/R10001_D2B1WACXX_read2.fastq.gz )] :. Greater than 5% of the fragments disagreed with the provided library type; check the file: /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test5/R10001_D2B1WACXX/lib_format_counts.json for details. [00m**** Job ends ****; Thu Mar 30 11:38:30 EDT 2017; ```. ### SGE email example info. ```; Job-array task 110632.1 (step6-salmon_test5.gsk_phaseII) Complete; User = lcollado; Queue = shared.q@compute-066.cm.cluster; Host = compute-066.cm.cluster; Start Time = 03/29/2017 23:27:10; End Time = 03/30/2017 11:38:30; User Time = 06:08:32; System Time = 12:46:46; Wallclock Time = 12:11:20; CPU = 18:55:18; Max vmem = 6.961G; Exit Status = 0; ```. For some reaso",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-290516965:25136,optimiz,optimizer,25136,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-290516965,1,['optimiz'],['optimizer']
Performance,"ob-p ,. Edit: I have resolved the problem. It is not a problem with Biostrings or GRanges. It turns out that when subsetting the premature sequences, the subsetted sequences do not retain the names of the GRanges used to subset them therefore my code could not identify minus strand transcripts and get their reverse complements. Apologies for any confusion!; ---; Thank you very much for the prompt response and for taking the time to validate Salmon's functionality. Indeed, Salmon is not the problem here. After taking a closer look at my transcript fasta, I noticed a problem with it, as you suggested. Long story short, half the premature transcripts had the wrong orientation and complementarity. Long story:. Oddly, the mature sequences were fine even though I used an identical approach to subset premature and mature transcripts from the genome reference!. Briefly my approach relied on three R packages rtracklayer, GenomicRanges, and Biostrings. 1. I used rtracklayer to load a gtf formatted exon annotations acquired from Ensembl. The file is loaded as a GenomicRanges object which essentially describes the locus of each exon (the transcribed strand [+ or -], chromosome, start and end positions relative to the reference strand) and its associated gene and transcript. 2. I used the GRanges object to generate pre-RNA coordinates that span all exons of a transcript. 3. I loaded the reference genome fasta acquired from Ensembl using the Biostrings package. GRanges and Biostrings are tightly integrated, allowing me to subset sequences from a Biostrings object using the GRanges object. **I believe the problem lies here.** It appears that when subsetting the mature exonic sequences from Biostrings using GRanges, the strand field in the GRanges object **was not** utilized. I.e., I needed to get the reverse complement of the extracted sequences for transcripts on the minus strand. I had done that and assumed that this behaviour would be consistent. However, for reasons I have not ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/655#issuecomment-826035191:989,load,load,989,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/655#issuecomment-826035191,2,['load'],['load']
Performance,"oftware: you are free to change and redistribute it.; There is NO WARRANTY, to the extent permitted by law.; Type ""show copying"" and ""show warranty"" for details.; This GDB was configured as ""x86_64-redhat-linux-gnu"".; Type ""show configuration"" for configuration details.; For bug reporting instructions, please see:; <http://www.gnu.org/software/gdb/bugs/>.; Find the GDB manual and other documentation resources online at:; <http://www.gnu.org/software/gdb/documentation/>. For help, type ""help"".; Type ""apropos word"" to search for commands related to ""word""...; Reading symbols from salmon...done.; (gdb) r; Starting program: /home/common/modules/el8/x86_64/software/salmon/1.2.1-CentOS-vanilla/bin/salmon index -t transcripts.fasta -i sample_salmon_fmd_index --type fmd; Missing separate debuginfos, use: yum debuginfo-install glibc-2.28-72.el8_1.1.x86_64; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; [Thread debugging using libthread_db enabled]; Using host libthread_db library ""/lib64/libthread_db.so.1"".; warning: Loadable section",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641594410:2450,Load,Loadable,2450,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641594410,1,['Load'],['Loadable']
Performance,"og] [info] Total 289(has 190 low confidence) barcodes; [2019-01-29 09:55:04.822] [alevinLog] [info] Done True Barcode Sampling; [2019-01-29 09:55:04.855] [alevinLog] [info] Done populating Z matrix; [2019-01-29 09:55:04.855] [alevinLog] [info] Done indexing Barcodes; [2019-01-29 09:55:04.855] [alevinLog] [info] Total Unique barcodes found: 70316; [2019-01-29 09:55:04.855] [alevinLog] [info] Used Barcodes except Whitelist: 184; [2019-01-29 09:55:04.882] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify. [2019-01-29 09:55:04.882] [alevinLog] [info] parsing read library format; [2019-01-29 09:55:05.014] [stderrLog] [info] Loading Suffix Array ; [2019-01-29 09:55:04.882] [jointLog] [info] There is 1 library.; [2019-01-29 09:55:05.012] [jointLog] [info] Loading Quasi index; [2019-01-29 09:55:05.013] [jointLog] [info] Loading 32-bit quasi index; [2019-01-29 09:55:06.105] [stderrLog] [info] Loading Transcript Info ; [2019-01-29 09:55:09.968] [stderrLog] [info] Loading Rank-Select Bit Array; [2019-01-29 09:55:16.908] [stderrLog] [info] There were 80,511 set bits in the bit array; [2019-01-29 09:55:19.931] [stderrLog] [info] Computing transcript lengths; [2019-01-29 09:55:19.931] [stderrLog] [info] Waiting to finish loading hash; [2019-01-29 09:55:41.122] [jointLog] [info] done; [2019-01-29 09:55:41.122] [jointLog] [info] Index contained 80,511 targets; [2019-01-29 09:55:41.122] [stderrLog] [info] Done loading index. processed 0 Million fragments; hits: 161433, hits per frag: 0.32698. [2019-01-29 09:55:54.788] [alevinLog] [info] Starting optimizer; [2019-01-29 09:55:54.742] [jointLog] [info] Computed 6,346 rich equivalence classes for further processing; [2019-01-29 09:55:54.742] [jointLog] [info] Counted 80,300 total reads in the equivalence classes ; [2019-01-29 09:55:54.754] [jointLog] [warning] Only 80300 fragments were mapped, but the number of burn-in fragments was set to 5000000.; The effective lengths have been computed using the observed mappings. ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/337#issuecomment-458481722:3088,Load,Loading,3088,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/337#issuecomment-458481722,1,['Load'],['Loading']
Performance,"ointLog] [info] Finished optimizer; [2022-05-14 01:26:19.655] [jointLog] [info] writing output . Then I generated another index similar to [using a full decoy of the genome](https://combine-lab.github.io/alevin-tutorial/2019/selective-alignment/) as suggested above but I got this report. [2022-05-14 00:49:06.636] [jointLog] [info] Number of mappings discarded because of alignment score : 7,179,799; [2022-05-14 00:49:06.636] [jointLog] [info] Number of fragments entirely discarded because of alignment score : 3,986,275; [2022-05-14 00:49:06.636] [jointLog] [info] Number of fragments discarded because they are best-mapped to decoys : 3,572,798; [2022-05-14 00:49:06.636] [jointLog] [info] Number of fragments discarded because they have only dovetail (discordant) mappings to valid targets : 54,775; [2022-05-14 00:49:06.636] [jointLog] [info] Mapping rate = 62.2613%. [2022-05-14 00:49:06.636] [jointLog] [info] finished quantifyLibrary(); [2022-05-14 00:49:06.643] [jointLog] [info] Starting optimizer; [2022-05-14 00:49:06.706] [jointLog] [info] Marked 0 weighted equivalence classes as degenerate; [2022-05-14 00:49:06.713] [jointLog] [info] iteration = 0 | max rel diff. = 8788.91; [2022-05-14 00:49:07.363] [jointLog] [info] iteration = 100 | max rel diff. = 12.9125; [2022-05-14 00:49:08.016] [jointLog] [info] iteration = 200 | max rel diff. = 10.1452; [2022-05-14 00:49:08.665] [jointLog] [info] iteration = 300 | max rel diff. = 10.5557; [2022-05-14 00:49:09.322] [jointLog] [info] iteration = 400 | max rel diff. = 5.35911; [2022-05-14 00:49:09.990] [jointLog] [info] iteration = 500 | max rel diff. = 0.278805; [2022-05-14 00:49:10.647] [jointLog] [info] iteration = 600 | max rel diff. = 4.69875; [2022-05-14 00:49:11.295] [jointLog] [info] iteration = 700 | max rel diff. = 0.696517; [2022-05-14 00:49:11.994] [jointLog] [info] iteration = 800 | max rel diff. = 3.63395; [2022-05-14 00:49:12.648] [jointLog] [info] iteration = 900 | max rel diff. = 0.0421211; [2022-05-14 00:49:13",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/775#issuecomment-1126593943:4502,optimiz,optimizer,4502,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/775#issuecomment-1126593943,1,['optimiz'],['optimizer']
Performance,"ok stranded). Specifically, here is what I get when I run (a close approximation of) your command. ```; $salmon quant --index Salmon_index_hg38.analysisSet_knownGene --unmatedReads SRR2454059.fq.gz --libType ISF --useVBOpt --output test_quant --; numGibbsSamples 100 --threads 16; Version Info: This is the most recent **development version** of Salmon.; ### salmon (mapping-based) v0.7.3; ### [ program ] => salmon; ### [ command ] => quant; ### [ index ] => { Salmon_index_hg38.analysisSet_knownGene }; ### [ unmatedReads ] => { SRR2454059.fq.gz }; ### [ libType ] => { ISF }; ### [ useVBOpt ] => { }; ### [ output ] => { test_quant }; ### [ numGibbsSamples ] => { 100 }; ### [ threads ] => { 16 }; Logs will be written to test_quant/logs; [2016-12-13 22:38:54.413] [jointLog] [info] parsing read library format; [2016-12-13 22:38:54.413] [jointLog] [info] There is 1 library.; [2016-12-13 22:38:56.240] [stderrLog] [info] Loading Suffix Array; [2016-12-13 22:38:56.240] [jointLog] [info] Loading Quasi index; [2016-12-13 22:38:56.240] [jointLog] [info] Loading 32-bit quasi index; [2016-12-13 22:39:01.268] [stderrLog] [info] Loading Transcript Info; [2016-12-13 22:39:02.630] [stderrLog] [info] Loading Rank-Select Bit Array; [2016-12-13 22:39:03.041] [stderrLog] [info] There were 182608 set bits in the bit array; [2016-12-13 22:39:03.159] [stderrLog] [info] Computing transcript lengths; [2016-12-13 22:39:03.160] [stderrLog] [info] Waiting to finish loading hash; [2016-12-13 22:39:07.653] [stderrLog] [info] Done loading index; [2016-12-13 22:39:07.653] [jointLog] [info] done; [2016-12-13 22:39:07.653] [jointLog] [info] Index contained 182608 targets. processed 19000000 fragments; hits: 65897209; hits per frag: 3.47349. [2016-12-13 22:40:22.572] [jointLog] [info] Computed 137534 rich equivalence classes for further processing; [2016-12-13 22:40:22.572] [jointLog] [info] Counted 16265961 total reads in the equivalence classes; [2016-12-13 22:40:22.618] [jointLog] [info] Mapping rate =",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-266934878:1441,Load,Loading,1441,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-266934878,1,['Load'],['Loading']
Performance,"ols from salmon...done.; (gdb) r; Starting program: /home/common/modules/el8/x86_64/software/salmon/1.2.1-CentOS-vanilla/bin/salmon index -t transcripts.fasta -i sample_salmon_fmd_index --type fmd; Missing separate debuginfos, use: yum debuginfo-install glibc-2.28-72.el8_1.1.x86_64; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; [Thread debugging using libthread_db enabled]; Using host libthread_db library ""/lib64/libthread_db.so.1"".; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641594410:3026,Load,Loadable,3026,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641594410,1,['Load'],['Loadable']
Performance,"ompatibility prior below threshold. Incompatible fragments will be ignored.; > [2020-06-04 17:55:11.700] [jointLog] [info] The --mimicBT2, --mimicStrictBT2 and --hardFilter flags imply mapping validation (--validateMappings). Enabling mapping validation.; > [2020-06-04 17:55:11.700] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; > [2020-06-04 17:55:11.700] [jointLog] [info] The use of range-factorized equivalence classes does not make sense in conjunction with --hardFilter. Disabling range-factorized equivalence classes. ; > [2020-06-04 17:55:11.700] [jointLog] [info] Usage of --validateMappings implies a default consensus slack of 0.2. Setting consensusSlack to 0.35.; > [2020-06-04 17:55:11.700] [jointLog] [info] Using default value of 0.797619 for minScoreFraction in Alevin; > Using default value of 0.6 for consensusSlack in Alevin; > [2020-06-04 17:56:30.294] [jointLog] [info] There is 1 library.; > [2020-06-04 17:56:30.355] [jointLog] [info] Loading pufferfish index; > [2020-06-04 17:56:30.355] [jointLog] [info] Loading dense pufferfish index.; > [2020-06-04 17:56:30.355] [jointLog] [info] done; > [2020-06-04 17:56:30.355] [jointLog] [info] Index contained 64 targets; > [2020-06-04 17:56:30.355] [jointLog] [info] Number of decoys : 0; > [2020-06-04 17:57:36.305] [jointLog] [info] Computed 64 rich equivalence classes for further processing; > [2020-06-04 17:57:36.305] [jointLog] [info] Counted 39,818 total reads in the equivalence classes ; > [2020-06-04 17:57:36.305] [jointLog] [info] Number of fragments discarded because they are best-mapped to decoys : 0; > [2020-06-04 17:57:36.305] [jointLog] [warning] Found 1354 reads with `N` in the UMI sequence and ignored the reads.; > Please report on github if this number is too large; > [2020-06-04 17:57:36.305] [jointLog] [info] Mapping rate = 0.0762793%; > ; > [2020-06-04 17:57:36.305] [jointLog] [info] finished quantifyLibrary()",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-639196415:3884,Load,Loading,3884,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-639196415,2,['Load'],['Loading']
Performance,"ompiled binary on the 64-bit index (this is a small read set from single-cell data, which is why the total # of reads is so small). ```; rob@feynman:/mnt/scratch3/rob/JoshTest$ ~/SoftwareStaging/salmon/scripts/SalmonBeta-0.6.5-pre_CentOS5/bin/salmon quant -p 15 -i salmon_index -l IU -1 ../strange_peak/19232_1_1.fastq -2 ../strange_peak/19232_1_2.fastq -o quant_binary; Version Info: This is the most recent version of Salmon.; # salmon (mapping-based) v0.6.0; # [ program ] => salmon; # [ command ] => quant; # [ threads ] => { 15 }; # [ index ] => { salmon_index }; # [ libType ] => { IU }; # [ mates1 ] => { ../strange_peak/19232_1_1.fastq }; # [ mates2 ] => { ../strange_peak/19232_1_2.fastq }; # [ output ] => { quant_binary }; Logs will be written to quant_binary/logs; there is 1[2016-03-31 14:05:14.184] [jointLog] [info] parsing read library format; lib; Loading 64-bit quasi index[2016-03-31 14:05:14.266] [stderrLog] [info] Loading Suffix Array; [2016-03-31 14:05:14.266] [jointLog] [info] Loading Quasi index. [2016-03-31 14:07:58.647] [stderrLog] [info] Loading Transcript Info; [2016-03-31 14:08:59.703] [stderrLog] [info] Loading Rank-Select Bit Array; [2016-03-31 14:09:06.744] [stderrLog] [info] There were 2027284 set bits in the bit array; [2016-03-31 14:09:08.123] [stderrLog] [info] Computing transcript lengths; [2016-03-31 14:09:08.240] [stderrLog] [info] Waiting to finish loading hash; Index contained 2027284 targets; [2016-03-31 14:09:15.789] [jointLog] [info] done; [2016-03-31 14:09:15.786] [stderrLog] [info] Successfully loaded position hash; [2016-03-31 14:09:15.789] [stderrLog] [info] Done loading index. [2016-03-31 14:09:36.623] [jointLog] [info] Computed 8083 rich equivalence classes for further processing; [2016-03-31 14:09:36.623] [jointLog] [info] Counted 159824 total reads in the equivalence classes. [2016-03-31 14:13:24.480] [jointLog] [warning] Only 159824 fragments were mapped, but the number of burn-in fragments was set to 5000000.; The effective le",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/54#issuecomment-204066023:1180,Load,Loading,1180,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/54#issuecomment-204066023,1,['Load'],['Loading']
Performance,"on = 900 | max rel diff. = 0.0146915; [2016-01-02 20:23:59.212] [jointLog] [info] iteration 1000, recomputing effective lengths; [2016-01-02 20:24:01.395] [jointLog] [info] iteration = 1000 | max rel diff. = 0.0147088; [2016-01-02 20:24:01.837] [jointLog] [info] iteration = 1100 | max rel diff. = 0.021175; [2016-01-02 20:24:02.193] [jointLog] [info] iteration = 1200 | max rel diff. = 0.01904; [2016-01-02 20:24:02.572] [jointLog] [info] iteration = 1300 | max rel diff. = 0.0187047; [2016-01-02 20:24:02.972] [jointLog] [info] iteration = 1400 | max rel diff. = 0.0213549; [2016-01-02 20:24:03.360] [jointLog] [info] iteration = 1500 | max rel diff. = 0.0311727; [2016-01-02 20:24:03.745] [jointLog] [info] iteration = 1600 | max rel diff. = 0.0100658; [2016-01-02 20:24:04.141] [jointLog] [info] iteration = 1700 | max rel diff. = 0.0100679; [2016-01-02 20:24:04.536] [jointLog] [info] iteration = 1800 | max rel diff. = 0.0100686; [2016-01-02 20:24:04.642] [jointLog] [info] iteration = 1827 | max rel diff. = 0.00921912; [2016-01-02 20:24:04.646] [jointLog] [info] Finished optimizer; [2016-01-02 20:24:04.646] [jointLog] [info] writing output. Computing gene-level abundance estimates; [2016-01-02 20:24:04.882] [jointLog] [warning] NOTE: Read Lib [( /nfs/research2/teichmann/valentine/detection-comparison/salmon0.4.2-comparison/mouse/SRP057125_SRS936134_1.fastq, /nfs/research2/teichmann/valentine/detection-comparison/salmon0.4.2-comparison/mouse/SRP057125_SRS936134_2.fastq )] :. Greater than 5% of the alignments (but not, necessarily reads) disagreed with the provided library type; check the file: SRP057125_SRS936134_salmon_out/libFormatCounts.txt for details. There were 104534 transcripts mapping to 44034 genes; Parsed 104000 expression lines; done; Aggregating expressions to gene level . . . done; Segmentation fault (core dumped); [vale@ebi-003 mouse]$; ```. (I also tried the command in the NSF directory to write to /tmp/SRP057125_SRS936134_salmon_out, but that also segfaults)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/34#issuecomment-168426741:11049,optimiz,optimizer,11049,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/34#issuecomment-168426741,1,['optimiz'],['optimizer']
Performance,"on Info: This is the most recent version of Salmon.; # salmon (mapping-based) v0.6.0; # [ program ] => salmon; # [ command ] => quant; # [ index ] => { /nfs/research2/teichmann/reference/mus-musculus/salmon/quasi/mouse_cdna_38.p3.78_repbase_ercc.fa }; # [ libType ] => { IU }; # [ mates1 ] => { /nfs/research2/teichmann/valentine/detection-comparison/salmon0.4.2-comparison/mouse/SRP057125_SRS936134_1.fastq }; # [ mates2 ] => { /nfs/research2/teichmann/valentine/detection-comparison/salmon0.4.2-comparison/mouse/SRP057125_SRS936134_2.fastq }; # [ output ] => { SRP057125_SRS936134_salmon_out }; # [ geneMap ] => { /nfs/research2/teichmann/reference/mus-musculus/salmon/mouse_cdna38.78_repbase_ercc_index_gene_map.txt }; # [ biasCorrect ] => { }; # [ useFSPD ] => { }; Logs will be written to SRP057125_SRS936134_salmon_out/logs; [2016-01-02 20:22:59.800] [jointLog] [info] parsing read library format; there is 1 lib; Loading 32-bit quasi index[2016-01-02 20:23:00.830] [stderrLog] [info] Loading Suffix Array; [2016-01-02 20:23:00.830] [stderrLog] [info] Loading Position Hash; [2016-01-02 20:23:00.829] [jointLog] [info] Loading Quasi index; [2016-01-02 20:23:03.751] [stderrLog] [info] Loading Transcript Info; [2016-01-02 20:23:04.776] [stderrLog] [info] Loading Rank-Select Bit Array; [2016-01-02 20:23:05.009] [stderrLog] [info] There were 104534 set bits in the bit array; [2016-01-02 20:23:05.325] [stderrLog] [info] Computing transcript lengths; [2016-01-02 20:23:05.325] [stderrLog] [info] Waiting to finish loading hash; Index contained 104534 targets; [2016-01-02 20:23:16.571] [stderrLog] [info] Done loading index; [2016-01-02 20:23:16.571] [jointLog] [info] done. processed 12000001 fragments; hits: 24367128, hits per frag: 2.04044. [2016-01-02 20:23:49.850] [jointLog] [info] Computed 102251 rich equivalence classes for further processing; [2016-01-02 20:23:49.850] [jointLog] [info] Counted 10033689 total reads in the equivalence classes; [2016-01-02 20:23:49.875] [jointLog] [in",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/34#issuecomment-168426741:7675,Load,Loading,7675,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/34#issuecomment-168426741,1,['Load'],['Loading']
Performance,"on/io.py"", line 88, in decorated; return f(*args, **kwds); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/conda/core/solve.py"", line 463, in _collect_all_metadata; index, r = self._prepare(prepared_specs); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/conda/core/solve.py"", line 1058, in _prepare; reduced_index = get_reduced_index(self.prefix, self.channels,; File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/conda/core/index.py"", line 288, in get_reduced_index; new_records = SubdirData.query_all(spec, channels=channels, subdirs=subdirs,; File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/conda/core/subdir_data.py"", line 140, in query_all; result = tuple(concat(executor.map(subdir_query, channel_urls))); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/concurrent/futures/_base.py"", line 609, in result_iterator; yield fs.pop().result(); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/concurrent/futures/_base.py"", line 446, in result; return self.__get_result(); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/concurrent/futures/_base.py"", line 391, in __get_result; raise self._exception; File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/concurrent/futures/thread.py"", line 58, in run; result = self.fn(*self.args, **self.kwargs); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/conda/core/subdir_data.py"", line 132, in <lambda>; subdir_query = lambda url: tuple(SubdirData(Channel(url), repodata_fn=repodata_fn).query(; File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/conda/core/subdir_data.py"", line 145, in query; self.load(); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/conda/core/subdir_data.py"", line 210, in load; _internal_state = self._load(); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/conda/core/subdir_data.py"", line 375, in _load; raw_repodata_str = fetch_repodata_remote_req",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/724#issuecomment-1171208515:2743,concurren,concurrent,2743,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/724#issuecomment-1171208515,1,['concurren'],['concurrent']
Performance,"on/mouse_cdna38.78_repbase_ercc_index_gene_map.txt \; > --biasCorrect \; > --useFSPD; Version Info: This is the most recent version of Salmon.; # salmon (mapping-based) v0.6.0; # [ program ] => salmon; # [ command ] => quant; # [ index ] => { /nfs/research2/teichmann/reference/mus-musculus/salmon/quasi/mouse_cdna_38.p3.78_repbase_ercc.fa }; # [ libType ] => { IU }; # [ mates1 ] => { /nfs/research2/teichmann/valentine/detection-comparison/salmon0.4.2-comparison/mouse/SRP057125_SRS936134_1.fastq }; # [ mates2 ] => { /nfs/research2/teichmann/valentine/detection-comparison/salmon0.4.2-comparison/mouse/SRP057125_SRS936134_2.fastq }; # [ output ] => { SRP057125_SRS936134_salmon_out }; # [ geneMap ] => { /nfs/research2/teichmann/reference/mus-musculus/salmon/mouse_cdna38.78_repbase_ercc_index_gene_map.txt }; # [ biasCorrect ] => { }; # [ useFSPD ] => { }; Logs will be written to SRP057125_SRS936134_salmon_out/logs; [2016-01-02 20:22:59.800] [jointLog] [info] parsing read library format; there is 1 lib; Loading 32-bit quasi index[2016-01-02 20:23:00.830] [stderrLog] [info] Loading Suffix Array; [2016-01-02 20:23:00.830] [stderrLog] [info] Loading Position Hash; [2016-01-02 20:23:00.829] [jointLog] [info] Loading Quasi index; [2016-01-02 20:23:03.751] [stderrLog] [info] Loading Transcript Info; [2016-01-02 20:23:04.776] [stderrLog] [info] Loading Rank-Select Bit Array; [2016-01-02 20:23:05.009] [stderrLog] [info] There were 104534 set bits in the bit array; [2016-01-02 20:23:05.325] [stderrLog] [info] Computing transcript lengths; [2016-01-02 20:23:05.325] [stderrLog] [info] Waiting to finish loading hash; Index contained 104534 targets; [2016-01-02 20:23:16.571] [stderrLog] [info] Done loading index; [2016-01-02 20:23:16.571] [jointLog] [info] done. processed 12000001 fragments; hits: 24367128, hits per frag: 2.04044. [2016-01-02 20:23:49.850] [jointLog] [info] Computed 102251 rich equivalence classes for further processing; [2016-01-02 20:23:49.850] [jointLog] [info] Counte",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/34#issuecomment-168426741:7604,Load,Loading,7604,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/34#issuecomment-168426741,1,['Load'],['Loading']
Performance,"otal Unique barcodes found: 125401; [2019-01-29 09:56:53.255] [alevinLog] [info] Used Barcodes except Whitelist: 1256; [2019-01-29 09:56:53.281] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify. [2019-01-29 09:56:53.281] [alevinLog] [info] parsing read library format; [2019-01-29 09:56:53.412] [stderrLog] [info] Loading Suffix Array ; [2019-01-29 09:56:53.281] [jointLog] [info] There is 1 library.; [2019-01-29 09:56:53.410] [jointLog] [info] Loading Quasi index; [2019-01-29 09:56:53.411] [jointLog] [info] Loading 32-bit quasi index; [2019-01-29 09:56:54.551] [stderrLog] [info] Loading Transcript Info ; [2019-01-29 09:56:54.826] [stderrLog] [info] Loading Rank-Select Bit Array; [2019-01-29 09:56:54.883] [stderrLog] [info] There were 80,511 set bits in the bit array; [2019-01-29 09:56:54.908] [stderrLog] [info] Computing transcript lengths; [2019-01-29 09:56:54.908] [stderrLog] [info] Waiting to finish loading hash; [2019-01-29 09:57:09.336] [stderrLog] [info] Done loading index; [2019-01-29 09:57:09.336] [jointLog] [info] done; [2019-01-29 09:57:09.336] [jointLog] [info] Index contained 80,511 targets. processed 2 Million fragments; hits: 812181, hits per frag: 0.326777. [2019-01-29 09:57:36.647] [alevinLog] [info] Starting optimizer; [2019-01-29 09:57:36.587] [jointLog] [info] Computed 12,933 rich equivalence classes for further processing; [2019-01-29 09:57:36.587] [jointLog] [info] Counted 242,520 total reads in the equivalence classes ; [2019-01-29 09:57:36.601] [jointLog] [warning] Only 242520 fragments were mapped, but the number of burn-in fragments was set to 5000000.; The effective lengths have been computed using the observed mappings. [2019-01-29 09:57:36.601] [jointLog] [info] Mapping rate = 8.94141%. [2019-01-29 09:57:36.601] [jointLog] [info] finished quantifyLibrary(). Analyzed 293 cells (100% of all).; [2019-01-29 09:57:40.090] [alevinLog] [info] Total 206902 UMI after deduplicating.; [2019-01-29 09:57:40.091] [alevinLog] [warning] S",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/337#issuecomment-458481722:8810,load,loading,8810,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/337#issuecomment-458481722,1,['load'],['loading']
Performance,"ounted 12227080 total reads in the equivalence classes; [2016-12-15 16:01:44.948] [jointLog] [info] Mapping rate = 72.5194%. [2016-12-15 16:01:44.948] [jointLog] [info] finished quantifyLibrary(); [2016-12-15 16:01:44.949] [jointLog] [info] Starting optimizer; [2016-12-15 16:01:45.059] [jointLog] [info] Marked 0 weighted equivalence classes as degenerate; [2016-12-15 16:01:45.075] [jointLog] [info] iteration = 0 | max rel diff. = 261.892; [2016-12-15 16:01:45.248] [jointLog] [info] iteration 11, adjusting effective lengths to account for biases; [2016-12-15 16:11:15.738] [jointLog] [info] Computed expected counts (for bias correction); [2016-12-15 16:11:15.739] [jointLog] [info] processed bias for 0.0% of the transcripts; [2016-12-15 16:13:07.074] [jointLog] [info] processed bias for 10.0% of the transcripts; [2016-12-15 16:14:57.019] [jointLog] [info] processed bias for 20.0% of the transcripts; [2016-12-15 16:16:40.365] [jointLog] [info] processed bias for 30.0% of the transcripts; [2016-12-15 16:18:25.798] [jointLog] [info] processed bias for 40.0% of the transcripts; [2016-12-15 16:20:13.944] [jointLog] [info] processed bias for 50.0% of the transcripts; [2016-12-15 16:21:52.350] [jointLog] [info] processed bias for 100.0% of the transcripts; [2016-12-15 16:21:53.854] [jointLog] [info] iteration = 100 | max rel diff. = 0.250674; [2016-12-15 16:22:12.498] [jointLog] [info] iteration = 200 | max rel diff. = 0.251947; [2016-12-15 16:22:14.261] [jointLog] [info] iteration = 300 | max rel diff. = 0.377281; [2016-12-15 16:22:15.769] [jointLog] [info] iteration = 400 | max rel diff. = 0.121203; [2016-12-15 16:22:17.427] [jointLog] [info] iteration = 500 | max rel diff. = 0.0203027; [2016-12-15 16:22:18.761] [jointLog] [info] iteration = 583 | max rel diff. = 0.00813273; [2016-12-15 16:22:18.773] [jointLog] [info] Finished optimizer; [2016-12-15 16:22:18.773] [jointLog] [info] writing output. [2016-12-15 16:22:19.744] [jointLog] [info] Starting Gibbs Sampler 1 week; ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267489196:3999,optimiz,optimizer,3999,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267489196,1,['optimiz'],['optimizer']
Performance,"patibility prior below threshold. Incompatible fragments will be ignored.; [2022-03-27 05:24:09.395] [jointLog] [info] The --mimicBT2, --mimicStrictBT2 and --hardFilter flags imply mapping validation (--validateMappings). Enabling mapping validation.; [2022-03-27 05:24:09.395] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2022-03-27 05:24:09.395] [jointLog] [info] The use of range-factorized equivalence classes does not make sense in conjunction with --hardFilter. Disabling range-factorized equivalence classes. ; [2022-03-27 05:24:09.395] [jointLog] [info] Setting consensusSlack to selective-alignment default of 0.35.; [2022-03-27 05:24:09.395] [jointLog] [info] Using default value of 0.87 for minScoreFraction in Alevin; Using default value of 0.6 for consensusSlack in Alevin; [2022-03-27 05:34:26.966] [jointLog] [info] There is 1 library.; [2022-03-27 05:34:26.967] [jointLog] [info] Loading pufferfish index; [2022-03-27 05:34:26.967] [jointLog] [info] Loading dense pufferfish index.; [2022-03-27 05:34:27.433] [jointLog] [info] done; [2022-03-27 05:34:27.504] [jointLog] [info] Index contained 116,755 targets; [2022-03-27 05:34:27.540] [jointLog] [info] Number of decoys : 0; [2022-03-27 05:46:41.460] [jointLog] [info] Thread saw mini-batch with a maximum of 10.50% zero probability fragments; [2022-03-27 05:46:41.460] [jointLog] [info] Thread saw mini-batch with a maximum of 7.74% zero probability fragments; [2022-03-27 05:46:41.460] [jointLog] [info] Thread saw mini-batch with a maximum of 23.62% zero probability fragments; [2022-03-27 05:46:41.460] [jointLog] [info] Thread saw mini-batch with a maximum of 9.60% zero probability fragments; [2022-03-27 05:46:41.460] [jointLog] [info] Thread saw mini-batch with a maximum of 15.40% zero probability fragments; [2022-03-27 05:46:41.460] [jointLog] [info] Thread saw mini-batch with a maximum of 25.48% zero probability fragments; [202",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/763#issuecomment-1082597942:5285,Load,Loading,5285,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/763#issuecomment-1082597942,1,['Load'],['Loading']
Performance,"pdate order and initialization conditions for a specific sample to eliminate any variation between runs, almost all experiments consist of multiple samples. In other samples, the same transcript fractions could give rise to a slightly different set of observed fragments that induce exactly the same type of variation under uncertainty; and since that uncertainty is baked into the sample, it cannot and should not be removed. Having exact replication of a sample at a numerical threshold below the inferential uncertainty for a transcript conveys false confidence in the precision of the estimate. This is why, for transcript-level analysis, we highly recommend having salmon produce posterior gibbs samples (with the `--numGibbsSamples` flag). This will draw samples from the posterior distribution over the abundance estimates and allow determination of what inferences can be made robustly and what cannot. We have spent a good deal of time thinking about how to properly perform statistical inference on these uncertain quantities, and so I'd point you at [swish](https://bioconductor.org/packages/release/bioc/vignettes/fishpond/inst/doc/swish.html), which is a tool for differential analysis at the transcript level that makes uses of a non-parametric test over the inferential replicates (Gibbs samples) to incorporate uncertainty into the differential analysis. We also developed a tool [terminus](https://academic.oup.com/bioinformatics/article/36/Supplement_1/i102/5870485) that makes use of the Gibbs samples and point estimates of salmon to group together transcripts whose individual abundances cannot be reliably inferred given the fragments in the sample. While the best way to properly assess, propagate and handle uncertainty in transcript-level inference is still, in my opinion, an active area of research in the field, these are some solutions we've come up with to address this challenge so far. And while, as a computer scientist myself, I _certainly_ appreciate the desire to ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/613#issuecomment-757989858:3631,perform,perform,3631,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/613#issuecomment-757989858,2,['perform'],['perform']
Performance,"perty"" outside of ELF segments; [Thread debugging using libthread_db enabled]; Using host libthread_db library ""/lib64/libthread_db.so.1"".; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; [New Thread 0x7ffff0987700 (LWP 17537)]. Thread 2 ""salmon"" received signal SIGSEGV, Segmentation fault.; [Switching to Thread 0x7ffff0987700 (LWP 17537)]; 0x00007ffff68202ab in je_tcache_bin_flush_small () from /lib64/libjemalloc.so.2; Missing separate debuginfos, use: yum debuginfo-install boost169-filesystem-1.69.0-4.el8.x86_64 boost169-iostreams-1.69.0-4.el8.x86_64 boost169-program-options-1.69.0-4.el8.x86_64 boost",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641594410:4286,Load,Loadable,4286,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641594410,1,['Load'],['Loadable']
Performance,"perty"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; [Thread debugging using libthread_db enabled]; Using host libthread_db library ""/lib64/libthread_db.so.1"".; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; [New Thread 0x7ffff0987700 (LWP 17537)]. Thread 2 ""salmon"" received signal SIGSEGV, Segmentation fault.; [Switching to Thread 0x7ffff0987700 (LWP 17537)]; 0x00007ffff68202ab in je_tcache_bin_flush_small () from /lib64/libjemalloc.so.2; Missing separate debuginfos, use: yum debuginfo-install boost169-filesystem-1.69.0-4.el8.x86_64 boost169-iostream",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641594410:4214,Load,Loadable,4214,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641594410,1,['Load'],['Loadable']
Performance,"perty"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; [Thread debugging using libthread_db enabled]; Using host libthread_db library ""/lib64/libthread_db.so.1"".; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; [New Thread 0x7ffff0987700 (LWP 17537)]. Thread 2 ""salmon"" received signal SIGSEGV, Segmentation fault.; [Switching to Thread 0x7ffff0987700 (LWP 17537)]; 0x00007ffff68202ab in je_tcache_bin_flush_small () from /lib64/libjemalloc.so.2; Missing separate debuginfos, use: yum deb",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641594410:4142,Load,Loadable,4142,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641594410,1,['Load'],['Loadable']
Performance,"perty"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; [Thread debugging using libthread_db enabled]; Using host libthread_db library ""/lib64/libthread_db.so.1"".; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; [New Thread 0x7ffff0987700 (LWP 17537)]. Thread 2 ""salmon"" received signal SIGSEGV, Segmentation fault.; [Switching to Thread 0x7ffff0987700 (LWP 17537)]; 0x00007ffff68202ab in je_tcache_bin_flush_small ()",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641594410:4070,Load,Loadable,4070,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641594410,1,['Load'],['Loadable']
Performance,"perty"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; [Thread debugging using libthread_db enabled]; Using host libthread_db library ""/lib64/libthread_db.so.1"".; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; [New Thread 0x7ffff0987700 (LWP 17537)]. Thread 2 ""salmon"" received signal SIGSEGV, Segmentation fault.; [Switching to Thread 0x7ffff",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641594410:3998,Load,Loadable,3998,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641594410,1,['Load'],['Loadable']
Performance,"perty"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; [Thread debugging using libthread_db enabled]; Using host libthread_db library ""/lib64/libthread_db.so.1"".; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; [New Thread 0x7ffff0987700 (LWP 17537)]. Thread 2 ""salmon"" re",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641594410:3926,Load,Loadable,3926,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641594410,1,['Load'],['Loadable']
Performance,"perty"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; [Thread debugging using libthread_db enabled]; Using host libthread_db library ""/lib64/libthread_db.so.1"".; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641594410:3854,Load,Loadable,3854,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641594410,1,['Load'],['Loadable']
Performance,"perty"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; [Thread debugging using libthread_db enabled]; Using host libthread_db library ""/lib64/libthread_db.so.1"".; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641594410:3782,Load,Loadable,3782,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641594410,1,['Load'],['Loadable']
Performance,"perty"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; [Thread debugging using libthread_db enabled]; Using host libthread_db library ""/lib64/libthread_db.so.1"".; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641594410:3710,Load,Loadable,3710,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641594410,1,['Load'],['Loadable']
Performance,"perty"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; [Thread debugging using libthread_db enabled]; Using host libthread_db library ""/lib64/libthread_db.so.1"".; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641594410:3638,Load,Loadable,3638,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641594410,1,['Load'],['Loadable']
Performance,"perty"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; [Thread debugging using libthread_db enabled]; Using host libthread_db library ""/lib64/libthread_db.so.1"".; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641594410:3566,Load,Loadable,3566,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641594410,1,['Load'],['Loadable']
Performance,"perty"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; [Thread debugging using libthread_db enabled]; Using host libthread_db library ""/lib64/libthread_db.so.1"".; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641594410:3494,Load,Loadable,3494,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641594410,1,['Load'],['Loadable']
Performance,proximation of) your command. ```; $salmon quant --index Salmon_index_hg38.analysisSet_knownGene --unmatedReads SRR2454059.fq.gz --libType ISF --useVBOpt --output test_quant --; numGibbsSamples 100 --threads 16; Version Info: This is the most recent **development version** of Salmon.; ### salmon (mapping-based) v0.7.3; ### [ program ] => salmon; ### [ command ] => quant; ### [ index ] => { Salmon_index_hg38.analysisSet_knownGene }; ### [ unmatedReads ] => { SRR2454059.fq.gz }; ### [ libType ] => { ISF }; ### [ useVBOpt ] => { }; ### [ output ] => { test_quant }; ### [ numGibbsSamples ] => { 100 }; ### [ threads ] => { 16 }; Logs will be written to test_quant/logs; [2016-12-13 22:38:54.413] [jointLog] [info] parsing read library format; [2016-12-13 22:38:54.413] [jointLog] [info] There is 1 library.; [2016-12-13 22:38:56.240] [stderrLog] [info] Loading Suffix Array; [2016-12-13 22:38:56.240] [jointLog] [info] Loading Quasi index; [2016-12-13 22:38:56.240] [jointLog] [info] Loading 32-bit quasi index; [2016-12-13 22:39:01.268] [stderrLog] [info] Loading Transcript Info; [2016-12-13 22:39:02.630] [stderrLog] [info] Loading Rank-Select Bit Array; [2016-12-13 22:39:03.041] [stderrLog] [info] There were 182608 set bits in the bit array; [2016-12-13 22:39:03.159] [stderrLog] [info] Computing transcript lengths; [2016-12-13 22:39:03.160] [stderrLog] [info] Waiting to finish loading hash; [2016-12-13 22:39:07.653] [stderrLog] [info] Done loading index; [2016-12-13 22:39:07.653] [jointLog] [info] done; [2016-12-13 22:39:07.653] [jointLog] [info] Index contained 182608 targets. processed 19000000 fragments; hits: 65897209; hits per frag: 3.47349. [2016-12-13 22:40:22.572] [jointLog] [info] Computed 137534 rich equivalence classes for further processing; [2016-12-13 22:40:22.572] [jointLog] [info] Counted 16265961 total reads in the equivalence classes; [2016-12-13 22:40:22.618] [jointLog] [info] Mapping rate = 83.509%. [2016-12-13 22:40:22.618] [jointLog] [info] finished quant,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-266934878:1506,Load,Loading,1506,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-266934878,1,['Load'],['Loading']
Performance,"put ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test5/R10001_D2B1WACXX }; Logs will be written to /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test5/R10001_D2B1WACXX/logs; [1m[2017-03-29 23:59:18.699] [jointLog] [info] parsing read library format; [00m[1m[2017-03-29 23:59:18.721] [jointLog] [info] There is 1 library.; [00m[1m[2017-03-30 00:43:17.278] [stderrLog] [info] Loading Suffix Array ; [00m[1m[2017-03-30 00:43:17.237] [jointLog] [info] Loading Quasi index; [00m[1m[2017-03-30 00:43:17.273] [jointLog] [info] Loading 32-bit quasi index; [00m[1m[2017-03-30 02:37:54.437] [stderrLog] [info] Loading Transcript Info ; [00m[1m[2017-03-30 03:48:21.310] [stderrLog] [info] Loading Rank-Select Bit Array; [00m[1m[2017-03-30 04:20:16.735] [stderrLog] [info] There were 198093 set bits in the bit array; [00m[1m[2017-03-30 04:54:34.486] [stderrLog] [info] Computing transcript lengths; [00m[1m[2017-03-30 04:54:34.487] [stderrLog] [info] Waiting to finish loading hash; [00m[1m[2017-03-30 05:09:36.706] [stderrLog] [info] Done loading index; [00m[1m[2017-03-30 05:09:36.706] [jointLog] [info] done; [00m[1m[2017-03-30 05:09:36.790] [jointLog] [info] Index contained 198093 targets; [00m. [A. [32mprocessed[31m 500000 [32mfragments[0m; hits: 699833, hits per frag: 1.4138[A. [32mprocessed[31m 1000000 [32mfragments[0m; hits: 1395659, hits per frag: 1.40267[A. [32mprocessed[31m 1500000 [32mfragments[0m; hits: 2097294, hits per frag: 1.40287[A. [32mprocessed[31m 2000000 [32mfragments[0m; hits: 2794766, hits per frag: 1.40089[A. [32mprocessed[31m 2500000 [32mfragments[0m; hits: 3489235, hits per frag: 1.39849[A. [32mprocessed[31m 3000000 [32mfragments[0m; hits: 4183913, hits per frag: 1.39697[A. [32mprocessed[31m 3500000 [32mfragments[0m; hits: 4884560, hits per frag: 1.39759[A. [32mprocessed[31m 4000000 [32mfragments[0m; hits: 5584692, hits per frag: 1.39792[A. [32mprocessed[31m 4500000 [32mfragmen",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-290516965:10449,load,loading,10449,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-290516965,1,['load'],['loading']
Performance,"quant/logs; [2020-05-05 09:19:06.171] [jointLog] [info] setting maxHashResizeThreads to 7; [2020-05-05 09:19:06.171] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2020-05-05 09:19:06.171] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2020-05-05 09:19:06.171] [jointLog] [info] Usage of --validateMappings implies a default consensus slack of 0.2. Setting consensusSlack to 0.35.; [2020-05-05 09:19:06.171] [jointLog] [info] parsing read library format; [2020-05-05 09:19:06.171] [jointLog] [info] There is 1 library.; [2020-05-05 09:19:06.278] [jointLog] [info] Loading pufferfish index; [2020-05-05 09:19:06.278] [jointLog] [warning] The index did not record if the `--keepDuplicates` flag was used. Please consider re-indexing with a newer version of salmon that will propagate this information.; [2020-05-05 09:19:06.278] [jointLog] [info] Loading dense pufferfish index.; -----------------------------------------; | Loading contig table | Time = 30.609 s; -----------------------------------------; size = 36981178; -----------------------------------------; | Loading contig offsets | Time = 1.3312 s; -----------------------------------------; -----------------------------------------; | Loading reference lengths | Time = 5.6842 ms; -----------------------------------------; -----------------------------------------; | Loading mphf table | Time = 20.002 s; -----------------------------------------; size = 3784352032; Number of ones: 36981177; Number of ones per inventory item: 512; Inventory entries filled: 72229; -----------------------------------------; | Loading contig boundaries | Time = 11.467 s; -----------------------------------------; size = 3784352032; -----------------------------------------; | Loading sequence | Time = 9.5665 s; -----------------------------------------; size = 2674916722; -----------------------",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/518#issuecomment-623910021:1710,Load,Loading,1710,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/518#issuecomment-623910021,1,['Load'],['Loading']
Performance,"r. That is, there was a v0.14.x and a (released in source only v0.15.0), and then the versions moved to 1.0.0 and beyond. However, this behavior certainly isn't related to that. There are 2 things going on that can lead to this effect. The first one, which is relatively easy to test, is that there may be small changes in when the inferred library type starts to be enforced (if it is not `IU`) when auto type detection is used (see [this issue and comments therein](https://github.com/COMBINE-lab/salmon/issues/489)). The second and more fundamental thing going on is that the observed behavior is intended. Even with a single thread of execution provided to salmon for mapping and quantification, there is a separate background thread that simply consumes reads from file and puts them in memory for quantification, and while e.g. pairing information between files is guaranteed to be preserved, exact read order is not. This can lead to differences in the order in which reads are processed and, as a result, differences in the initialization conditions of the optimization. The ultimate result is that for transcripts that have large inferential uncertainty, different numbers of reads can be assigned between runs. We have thought *a lot* about this behavior, what it means, and how the `NumRead` values should best be communicated to users. At the end of the day, the `NumReads` constitute the expected value of latent variables inferred in a _very_ high-dimensional space (# of parameters is at least the number of transcripts). Therefore, there are certain transcripts, whose estimated number of reads simply have _tremendous_ inferential uncertainty — and small perturbations in the initial conditions of the optimization will lead to different estimated values for their abundances. For those transcripts where you observe such fluctuations between runs, this is simply evidence that the precision that can be confidently placed on those estimates is below the degree of variation you obser",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/613#issuecomment-757989858:1207,optimiz,optimization,1207,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/613#issuecomment-757989858,2,['optimiz'],['optimization']
Performance,"range_peak/19232_1_1.fastq }; # [ mates2 ] => { ../strange_peak/19232_1_2.fastq }; # [ output ] => { quant_binary }; Logs will be written to quant_binary/logs; there is 1[2016-03-31 14:05:14.184] [jointLog] [info] parsing read library format; lib; Loading 64-bit quasi index[2016-03-31 14:05:14.266] [stderrLog] [info] Loading Suffix Array; [2016-03-31 14:05:14.266] [jointLog] [info] Loading Quasi index. [2016-03-31 14:07:58.647] [stderrLog] [info] Loading Transcript Info; [2016-03-31 14:08:59.703] [stderrLog] [info] Loading Rank-Select Bit Array; [2016-03-31 14:09:06.744] [stderrLog] [info] There were 2027284 set bits in the bit array; [2016-03-31 14:09:08.123] [stderrLog] [info] Computing transcript lengths; [2016-03-31 14:09:08.240] [stderrLog] [info] Waiting to finish loading hash; Index contained 2027284 targets; [2016-03-31 14:09:15.789] [jointLog] [info] done; [2016-03-31 14:09:15.786] [stderrLog] [info] Successfully loaded position hash; [2016-03-31 14:09:15.789] [stderrLog] [info] Done loading index. [2016-03-31 14:09:36.623] [jointLog] [info] Computed 8083 rich equivalence classes for further processing; [2016-03-31 14:09:36.623] [jointLog] [info] Counted 159824 total reads in the equivalence classes. [2016-03-31 14:13:24.480] [jointLog] [warning] Only 159824 fragments were mapped, but the number of burn-in fragments was set to 5000000.; The effective lengths have been computed using the observed mappings. [2016-03-31 14:13:24.480] [jointLog] [info] Mapping rate = 36.3942%. [2016-03-31 14:13:24.480] [jointLog] [info] finished quantifyLibrary(); [2016-03-31 14:13:24.480] [jointLog] [info] Starting optimizer; [2016-03-31 14:13:25.441] [jointLog] [info] Marked 0 weighted equivalence classes as degenerate; [2016-03-31 14:13:25.660] [jointLog] [info] iteration = 0 | max rel diff. = 13.7627; [2016-03-31 14:13:26.460] [jointLog] [info] iteration = 100 | max rel diff. = 0.100799; [2016-03-31 14:13:27.252] [jointLog] [info] iteration = 200 | max rel diff. = 0.0452885;",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/54#issuecomment-204066023:1803,load,loading,1803,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/54#issuecomment-204066023,1,['load'],['loading']
Performance,"rcode Sampling; [2019-06-06 19:24:55.690] [alevinLog] [info] Total 0% reads will be thrown away because of noisy Cellular barcodes.; [2019-06-06 19:24:55.692] [alevinLog] [info] Done populating Z matrix; [2019-06-06 19:24:55.692] [alevinLog] [info] Done indexing Barcodes; [2019-06-06 19:24:55.692] [alevinLog] [info] Total Unique barcodes found: 50; [2019-06-06 19:24:55.692] [alevinLog] [info] Used Barcodes except Whitelist: 0; [2019-06-06 19:24:55.716] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify. [2019-06-06 19:24:55.716] [alevinLog] [info] parsing read library format; [2019-06-06 19:24:55.716] [jointLog] [info] There is 1 library.; [2019-06-06 19:24:55.889] [jointLog] [info] Loading Quasi index; [2019-06-06 19:24:55.889] [jointLog] [info] Loading 32-bit quasi index; [2019-06-06 19:24:55.890] [stderrLog] [info] Loading Suffix Array ; [2019-06-06 19:24:56.791] [stderrLog] [info] Loading Transcript Info ; [2019-06-06 19:24:57.025] [stderrLog] [info] Loading Rank-Select Bit Array; [2019-06-06 19:24:57.061] [stderrLog] [info] There were 136,011 set bits in the bit array; [2019-06-06 19:24:57.084] [stderrLog] [info] Computing transcript lengths; [2019-06-06 19:24:57.084] [stderrLog] [info] Waiting to finish loading hash; [2019-06-06 19:25:06.552] [jointLog] [info] done; [2019-06-06 19:25:06.552] [jointLog] [info] Index contained 136,011 targets; [2019-06-06 19:25:06.552] [stderrLog] [info] Done loading index; [2019-06-06 19:25:06.728] [alevinLog] [error] Barcode not found in frequency table; ```. Salmon Quant log is this. ```; [2019-06-06 19:23:29.519] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2019-06-06 19:23:29.519] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2019-06-06 19:23:29.520] [jointLog] [info] Usage of --validateMappings, without --hardFilter implies use of range factorization. ran",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/369#issuecomment-499592790:1577,Load,Loading,1577,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/369#issuecomment-499592790,1,['Load'],['Loading']
Performance,"rcodes except Whitelist: 20705; [2018-07-19 22:55:38.386] [jointLog] [info] There is 1 library.; [2018-07-19 22:55:38.493] [jointLog] [info] Loading Quasi index; [2018-07-19 22:55:38.494] [jointLog] [info] Loading 32-bit quasi index; [2018-07-19 22:55:38.549] [jointLog] [info] done; [2018-07-19 22:55:38.549] [jointLog] [info] Index contained 179 targets. [2018-07-19 22:55:38.385] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify. [2018-07-19 22:55:38.385] [alevinLog] [info] parsing read library format; [2018-07-19 22:55:38.495] [stderrLog] [info] Loading Suffix Array ; [2018-07-19 22:55:38.498] [stderrLog] [info] Loading Transcript Info ; [2018-07-19 22:55:38.499] [stderrLog] [info] Loading Rank-Select Bit Array; [2018-07-19 22:55:38.500] [stderrLog] [info] There were 179 set bits in the bit array; [2018-07-19 22:55:38.501] [stderrLog] [info] Computing transcript lengths; [2018-07-19 22:55:38.501] [stderrLog] [info] Waiting to finish loading hash; processed 87 Million fragmentserrLog] [info] Done loading index; hits: 468892, hits per frag: 0.00535907. [2018-07-19 23:03:35.740] [jointLog] [info] Computed 150 rich equivalence classes for further processing; [2018-07-19 23:03:35.740] [jointLog] [info] Counted 412868 total reads in the equivalence classes ; [2018-07-19 23:03:35.741] [jointLog] [warning] Only 412868 fragments were mapped, but the number of burn-in fragments was set to 5000000.; The effective lengths have been computed using the observed mappings. [2018-07-19 23:03:35.741] [jointLog] [info] Mapping rate = 0.469385%. [2018-07-19 23:03:35.741] [jointLog] [info] finished quantifyLibrary(); [2018-07-19 23:03:35.755] [alevinLog] [info] Starting optimizer. Analyzed 5238 cells (100% of all).; Skipped Barcodes are from High Confidence Region; `$ls -ltrha alevin_output/alevin/`; total 256K; drwxrwx--- 6 zare G-816158 4.0K Jul 19 22:36 ..; -rw-rw---- 1 zare G-816158 960 Jul 19 23:03 alevin.log; drwxrwx--- 2 zare G-816158 4.0K Jul 19 23:03 .; -rw-r",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/253#issuecomment-406597243:3231,load,loading,3231,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/253#issuecomment-406597243,2,['load'],['loading']
Performance,"read2.fastq.gz }; ### [ output ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test3/R10001_D2B1WACXX }; Logs will be written to /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test3/R10001_D2B1WACXX/logs; [1m[2017-03-29 14:51:11.533] [jointLog] [info] parsing read library format; [00m[1m[2017-03-29 14:51:11.545] [jointLog] [info] There is 1 library.; [00mterminate called without an active exception; /cm/local/apps/sge/var/spool/compute-061/job_scripts/110315: line 31: 54922 Aborted (core dumped) /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon quant -i /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts -p 1 -l ISR -1 ${FILE1} -2 ${FILE2} -o /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test3/${ID}; **** Job ends ****; Wed Mar 29 14:51:13 EDT 2017; ```. ### SGE email info example. ```; Job-array task 110315.1 (step6-salmon_test3.gsk_phaseII) Complete; User = lcollado; Queue = shared.q@compute-061.cm.cluster; Host = compute-061.cm.cluster; Start Time = 03/29/2017 14:51:09; End Time = 03/29/2017 14:51:13; User Time = 00:00:00; System Time = 00:00:02; Wallclock Time = 00:00:04; CPU = 00:00:02; Max vmem = 14.820G; Exit Status = 0; ```. ## 16 cores. ### Bash. ```bash; #!/bin/bash; #$ -cwd; #$ -l mem_free=2G,h_vmem=3G,h_fsize=100G; #$ -N step6-salmon_test4.gsk_phaseII; #$ -pe local 16; #$ -o ./logs/salmon_test4.$TASK_ID.txt; #$ -e ./logs/salmon_test4.$TASK_ID.txt; #$ -t 1-3; #$ -hold_jid pipeline_setup,step4-featCounts-alzheimer.gsk_phaseII; #$ -m e; echo ""**** Job starts ****""; date. echo ""**** JHPCE info ****""; echo ""User: ${USER}""; echo ""Job id: ${JOB_ID}""; echo ""Job name: ${JOB_NAME}""; echo ""Hostname: ${HOSTNAME}""; echo ""Task id: ${TASK_ID}"". FILE1=$(awk 'BEGIN {FS=""\t""} {print $1}' /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk ""NR==${SGE_TASK_ID}""); if [ TRUE == ""TRUE"" ] ; then; FILE2=$(awk 'BEGIN {FS=""\t""} {print $",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-290516965:3521,Queue,Queue,3521,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-290516965,1,['Queue'],['Queue']
Performance,"rge/base/lib/python3.9/site-packages/requests/adapters.py"", line 308, in get_connection; raise InvalidProxyURL(""Please check proxy URL. It is malformed""; requests.exceptions.InvalidProxyURL: Please check proxy URL. It is malformed and could be missing the host. `$ /usr/local/bin/conda install salmon`. environment variables:; CIO_TEST=<not set>; CONDA_ROOT=/usr/local/Caskroom/miniforge/base; CURL_CA_BUNDLE=<not set>; INFOPATH=/opt/homebrew/share/info:; MANPATH=/opt/homebrew/share/man::; PATH=/opt/homebrew/bin:/opt/homebrew/sbin:/usr/local/bin:/usr/bin:/bin:/usr; /sbin:/sbin; REQUESTS_CA_BUNDLE=<not set>; SSL_CERT_FILE=<not set>; all_proxy=<set>. active environment : None; user config file : /Users/Benjamin/.condarc; populated config files : /usr/local/Caskroom/miniforge/base/.condarc; conda version : 4.12.0; conda-build version : not installed; python version : 3.9.13.final.0; virtual packages : __osx=12.4=0; __unix=0=0; __archspec=1=arm64; base environment : /usr/local/Caskroom/miniforge/base (writable); conda av data dir : /usr/local/Caskroom/miniforge/base/etc/conda; conda av metadata url : None; channel URLs : https://conda.anaconda.org/conda-forge/osx-arm64; https://conda.anaconda.org/conda-forge/noarch; package cache : /usr/local/Caskroom/miniforge/base/pkgs; /Users/Benjamin/.conda/pkgs; envs directories : /usr/local/Caskroom/miniforge/base/envs; /Users/Benjamin/.conda/envs; platform : osx-arm64; user-agent : conda/4.12.0 requests/2.27.1 CPython/3.9.13 Darwin/21.5.0 OSX/12.4; UID:GID : 501:20; netrc file : None; offline mode : False. An unexpected error has occurred. Conda has prepared the above report. If submitted, this report will be used by core maintainers to improve; future releases of conda.; Would you like conda to send this report to the core maintainers?. [y/N]: y; Upload did not complete. Thank you for helping to improve conda.; Opt-in to always sending reports (and not see this message again); by running. $ conda config --set report_errors true; ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/724#issuecomment-1171208515:5873,cache,cache,5873,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/724#issuecomment-1171208515,1,['cache'],['cache']
Performance,"riptome.index }; ### [ libType ] => { A }; ### [ mates1 ] => { /data2/csijcs/AML/RNA_seq/AML_total_MNC/total_MNCs/Fresh_samples/RHM5942/RHM5942_R1_001.fastq.gz }; ### [ mates2 ] => { /data2/csijcs/AML/RNA_seq/AML_total_MNC/total_MNCs/Fresh_samples/RHM5942/RHM5942_R2_001.fastq.gz }; ### [ threads ] => { 32 }; ### [ output ] => { /data2/csijcs/AML/RNA_seq/AML_total_MNC/total_MNCs/Fresh_samples/salmon_quants/RHM5942 }; Logs will be written to /data2/csijcs/AML/RNA_seq/AML_total_MNC/total_MNCs/Fresh_samples/salmon_quants/RHM5942/logs; [2018-07-27 16:24:55.658] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2018-07-27 16:24:55.658] [jointLog] [info] parsing read library format; [2018-07-27 16:24:55.658] [jointLog] [info] There is 1 library.; [2018-07-27 16:25:01.242] [jointLog] [info] Loading Quasi index; [2018-07-27 16:25:01.242] [jointLog] [info] Loading 32-bit quasi index; [2018-07-27 16:25:01.243] [stderrLog] [info] Loading Suffix Array ; [2018-07-27 16:25:42.630] [stderrLog] [info] Loading Transcript Info ; [2018-07-27 16:25:45.683] [stderrLog] [info] Loading Rank-Select Bit Array; [2018-07-27 16:25:47.834] [stderrLog] [info] There were 203027 set bits in the bit array; [2018-07-27 16:25:48.128] [stderrLog] [info] Computing transcript lengths; [2018-07-27 16:25:48.200] [stderrLog] [info] Waiting to finish loading hash; [2018-07-27 16:25:48.331] [stderrLog] [info] Done loading index; [2018-07-27 16:25:48.331] [jointLog] [info] done; [2018-07-27 16:25:48.331] [jointLog] [info] Index contained 203027 targets. processed 239500000 fragmentsintLog] [info] Automatically detected most likely library type as ISR; hits: 651420499, hits per frag: 2.72282[2018-07-27 16:51:47.947] [jointLog] [info] Thread saw mini-batch with a maximum of 1.70% zero probability fragments; [2018-07-27 16:51:47.947] [jointLog] [info] Thread saw mini-batch with a maximum of 1.68% zero probability fragments; [2018-07-27 16:51:47.947] [joint",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/261#issuecomment-409427898:1392,Load,Loading,1392,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/261#issuecomment-409427898,1,['Load'],['Loading']
Performance,"rsing read library format; [2019-01-29 09:56:53.412] [stderrLog] [info] Loading Suffix Array ; [2019-01-29 09:56:53.281] [jointLog] [info] There is 1 library.; [2019-01-29 09:56:53.410] [jointLog] [info] Loading Quasi index; [2019-01-29 09:56:53.411] [jointLog] [info] Loading 32-bit quasi index; [2019-01-29 09:56:54.551] [stderrLog] [info] Loading Transcript Info ; [2019-01-29 09:56:54.826] [stderrLog] [info] Loading Rank-Select Bit Array; [2019-01-29 09:56:54.883] [stderrLog] [info] There were 80,511 set bits in the bit array; [2019-01-29 09:56:54.908] [stderrLog] [info] Computing transcript lengths; [2019-01-29 09:56:54.908] [stderrLog] [info] Waiting to finish loading hash; [2019-01-29 09:57:09.336] [stderrLog] [info] Done loading index; [2019-01-29 09:57:09.336] [jointLog] [info] done; [2019-01-29 09:57:09.336] [jointLog] [info] Index contained 80,511 targets. processed 2 Million fragments; hits: 812181, hits per frag: 0.326777. [2019-01-29 09:57:36.647] [alevinLog] [info] Starting optimizer; [2019-01-29 09:57:36.587] [jointLog] [info] Computed 12,933 rich equivalence classes for further processing; [2019-01-29 09:57:36.587] [jointLog] [info] Counted 242,520 total reads in the equivalence classes ; [2019-01-29 09:57:36.601] [jointLog] [warning] Only 242520 fragments were mapped, but the number of burn-in fragments was set to 5000000.; The effective lengths have been computed using the observed mappings. [2019-01-29 09:57:36.601] [jointLog] [info] Mapping rate = 8.94141%. [2019-01-29 09:57:36.601] [jointLog] [info] finished quantifyLibrary(). Analyzed 293 cells (100% of all).; [2019-01-29 09:57:40.090] [alevinLog] [info] Total 206902 UMI after deduplicating.; [2019-01-29 09:57:40.091] [alevinLog] [warning] Skipped 71 barcodes due to No mapped read; [2019-01-29 09:57:40.110] [alevinLog] [info] Clearing EqMap; Might take some time.; [2019-01-29 09:57:40.176] [alevinLog] [info] Starting Import of the gene count matrix.; [2019-01-29 09:57:41.168] [alevinLog] [info] Do",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/337#issuecomment-458481722:9075,optimiz,optimizer,9075,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/337#issuecomment-458481722,1,['optimiz'],['optimizer']
Performance,"rsion of Salmon.; # salmon (mapping-based) v0.6.0; # [ program ] => salmon; # [ command ] => quant; # [ threads ] => { 15 }; # [ index ] => { salmon_index }; # [ libType ] => { IU }; # [ mates1 ] => { ../strange_peak/19232_1_1.fastq }; # [ mates2 ] => { ../strange_peak/19232_1_2.fastq }; # [ output ] => { quant_binary }; Logs will be written to quant_binary/logs; there is 1[2016-03-31 14:05:14.184] [jointLog] [info] parsing read library format; lib; Loading 64-bit quasi index[2016-03-31 14:05:14.266] [stderrLog] [info] Loading Suffix Array; [2016-03-31 14:05:14.266] [jointLog] [info] Loading Quasi index. [2016-03-31 14:07:58.647] [stderrLog] [info] Loading Transcript Info; [2016-03-31 14:08:59.703] [stderrLog] [info] Loading Rank-Select Bit Array; [2016-03-31 14:09:06.744] [stderrLog] [info] There were 2027284 set bits in the bit array; [2016-03-31 14:09:08.123] [stderrLog] [info] Computing transcript lengths; [2016-03-31 14:09:08.240] [stderrLog] [info] Waiting to finish loading hash; Index contained 2027284 targets; [2016-03-31 14:09:15.789] [jointLog] [info] done; [2016-03-31 14:09:15.786] [stderrLog] [info] Successfully loaded position hash; [2016-03-31 14:09:15.789] [stderrLog] [info] Done loading index. [2016-03-31 14:09:36.623] [jointLog] [info] Computed 8083 rich equivalence classes for further processing; [2016-03-31 14:09:36.623] [jointLog] [info] Counted 159824 total reads in the equivalence classes. [2016-03-31 14:13:24.480] [jointLog] [warning] Only 159824 fragments were mapped, but the number of burn-in fragments was set to 5000000.; The effective lengths have been computed using the observed mappings. [2016-03-31 14:13:24.480] [jointLog] [info] Mapping rate = 36.3942%. [2016-03-31 14:13:24.480] [jointLog] [info] finished quantifyLibrary(); [2016-03-31 14:13:24.480] [jointLog] [info] Starting optimizer; [2016-03-31 14:13:25.441] [jointLog] [info] Marked 0 weighted equivalence classes as degenerate; [2016-03-31 14:13:25.660] [jointLog] [info] iteration ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/54#issuecomment-204066023:1576,load,loading,1576,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/54#issuecomment-204066023,1,['load'],['loading']
Performance,"ry at 391 ; [2019-01-29 09:55:04.817] [alevinLog] [info] Gauss Corrected Boundary at 99 ; [2019-01-29 09:55:04.817] [alevinLog] [info] Learned InvCov: 114.535 normfactor: 147.323; [2019-01-29 09:55:04.817] [alevinLog] [info] Total 289(has 190 low confidence) barcodes; [2019-01-29 09:55:04.822] [alevinLog] [info] Done True Barcode Sampling; [2019-01-29 09:55:04.855] [alevinLog] [info] Done populating Z matrix; [2019-01-29 09:55:04.855] [alevinLog] [info] Done indexing Barcodes; [2019-01-29 09:55:04.855] [alevinLog] [info] Total Unique barcodes found: 70316; [2019-01-29 09:55:04.855] [alevinLog] [info] Used Barcodes except Whitelist: 184; [2019-01-29 09:55:04.882] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify. [2019-01-29 09:55:04.882] [alevinLog] [info] parsing read library format; [2019-01-29 09:55:05.014] [stderrLog] [info] Loading Suffix Array ; [2019-01-29 09:55:04.882] [jointLog] [info] There is 1 library.; [2019-01-29 09:55:05.012] [jointLog] [info] Loading Quasi index; [2019-01-29 09:55:05.013] [jointLog] [info] Loading 32-bit quasi index; [2019-01-29 09:55:06.105] [stderrLog] [info] Loading Transcript Info ; [2019-01-29 09:55:09.968] [stderrLog] [info] Loading Rank-Select Bit Array; [2019-01-29 09:55:16.908] [stderrLog] [info] There were 80,511 set bits in the bit array; [2019-01-29 09:55:19.931] [stderrLog] [info] Computing transcript lengths; [2019-01-29 09:55:19.931] [stderrLog] [info] Waiting to finish loading hash; [2019-01-29 09:55:41.122] [jointLog] [info] done; [2019-01-29 09:55:41.122] [jointLog] [info] Index contained 80,511 targets; [2019-01-29 09:55:41.122] [stderrLog] [info] Done loading index. processed 0 Million fragments; hits: 161433, hits per frag: 0.32698. [2019-01-29 09:55:54.788] [alevinLog] [info] Starting optimizer; [2019-01-29 09:55:54.742] [jointLog] [info] Computed 6,346 rich equivalence classes for further processing; [2019-01-29 09:55:54.742] [jointLog] [info] Counted 80,300 total reads in the equivalence class",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/337#issuecomment-458481722:2879,Load,Loading,2879,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/337#issuecomment-458481722,1,['Load'],['Loading']
Performance,"s/research2/teichmann/reference/mus-musculus/salmon/mouse_cdna38.78_repbase_ercc_index_gene_map.txt }; # [ biasCorrect ] => { }; # [ useFSPD ] => { }; Logs will be written to SRP057125_SRS936134_salmon_out/logs; [2016-01-02 20:22:59.800] [jointLog] [info] parsing read library format; there is 1 lib; Loading 32-bit quasi index[2016-01-02 20:23:00.830] [stderrLog] [info] Loading Suffix Array; [2016-01-02 20:23:00.830] [stderrLog] [info] Loading Position Hash; [2016-01-02 20:23:00.829] [jointLog] [info] Loading Quasi index; [2016-01-02 20:23:03.751] [stderrLog] [info] Loading Transcript Info; [2016-01-02 20:23:04.776] [stderrLog] [info] Loading Rank-Select Bit Array; [2016-01-02 20:23:05.009] [stderrLog] [info] There were 104534 set bits in the bit array; [2016-01-02 20:23:05.325] [stderrLog] [info] Computing transcript lengths; [2016-01-02 20:23:05.325] [stderrLog] [info] Waiting to finish loading hash; Index contained 104534 targets; [2016-01-02 20:23:16.571] [stderrLog] [info] Done loading index; [2016-01-02 20:23:16.571] [jointLog] [info] done. processed 12000001 fragments; hits: 24367128, hits per frag: 2.04044. [2016-01-02 20:23:49.850] [jointLog] [info] Computed 102251 rich equivalence classes for further processing; [2016-01-02 20:23:49.850] [jointLog] [info] Counted 10033689 total reads in the equivalence classes; [2016-01-02 20:23:49.875] [jointLog] [info] Mapping rate = 83.0244%. [2016-01-02 20:23:49.875] [jointLog] [info] finished quantifyLibrary(); [2016-01-02 20:23:49.875] [jointLog] [info] Starting optimizer; [2016-01-02 20:23:50.378] [jointLog] [info] Marked 0 weighted equivalence classes as degenerate; [2016-01-02 20:23:50.382] [jointLog] [info] iteration = 0 | max rel diff. = 64.9993; [2016-01-02 20:23:50.584] [jointLog] [info] iteration 50, recomputing effective lengths; [2016-01-02 20:23:53.386] [jointLog] [info] iteration = 100 | max rel diff. = 0.263028; [2016-01-02 20:23:53.777] [jointLog] [info] iteration = 200 | max rel diff. = 0.13921; [2016-01",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/34#issuecomment-168426741:8300,load,loading,8300,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/34#issuecomment-168426741,1,['load'],['loading']
Performance,"sam-xlate is actually the only tool that I'm aware of to perform this operation on an existing BAM file. I've heard of people using it with success. Of course, I'd also think of doing an analysis with the original reads to validate concordance. Note: if you don't have the original reads, you can do a BAM -> FASTQ conversion to recover the read sequences and then feed them to Salmon.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/131#issuecomment-293316682:57,perform,perform,57,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/131#issuecomment-293316682,1,['perform'],['perform']
Performance,"sed Barcodes except Whitelist: 3667; [2021-01-25 16:27:07.498] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify; [2021-01-25 16:27:07.498] [alevinLog] [info] parsing read library format; [2021-01-25 16:30:54.542] [alevinLog] [info] Starting optimizer; [2021-01-25 16:30:54.782] [alevinLog] [warning] mrna file not provided; using is 1 less feature for whitelisting; [2021-01-25 16:30:54.782] [alevinLog] [warning] rrna file not provided; using is 1 less feature for whitelisting; [2021-01-25 16:30:55.950] [alevinLog] [info] Total 1350278.00 UMI after deduplicating.; [2021-01-25 16:30:55.950] [alevinLog] [info] Total 30909 BiDirected Edges.; [2021-01-25 16:30:55.950] [alevinLog] [info] Total 8817 UniDirected Edges.; [2021-01-25 16:30:55.969] [alevinLog] [info] Clearing EqMap; Might take some time.; [2021-01-25 16:30:56.294] [alevinLog] [warning] Num High confidence barcodes too less 20 < 90.Can't performing whitelisting; Skipping; [2021-01-25 16:30:56.297] [alevinLog] [info] Finished optimizer. ## with `--exceptCells 7000`; > [2021-01-21 09:24:45.891] [alevinLog] [info] Found 43030 transcripts(+0 decoys, +0 short and +0 duplicate names in the index); [2021-01-21 09:24:45.942] [alevinLog] [info] Filled with 43030 txp to gene entries; [2021-01-21 09:24:45.947] [alevinLog] [info] Found all transcripts to gene mappings; [2021-01-21 09:24:45.967] [alevinLog] [info] Processing barcodes files (if Present); [2021-01-21 09:33:35.885] [alevinLog] [info] Done barcode density calculation.; [2021-01-21 09:33:35.885] [alevinLog] [info] # Barcodes Used: 188934609 / 188934609.; [2021-01-21 09:33:37.337] [alevinLog] [info] Total 10016(has 1000 low confidence) barcodes; [2021-01-21 09:33:38.202] [alevinLog] [info] Done True Barcode Sampling; [2021-01-21 09:33:39.137] [alevinLog] [warning] Total **52.0343% reads will be thrown away** because of noisy Cellular barcodes.; [2021-01-21 09:33:39.960] [alevinLog] [info] Done populating Z matrix; [2021-01-21 09:33:39.989] [alevin",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/340#issuecomment-766311567:4144,optimiz,optimizer,4144,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/340#issuecomment-766311567,1,['optimiz'],['optimizer']
Performance,"shResizeThreads 2 -i /u/user/ref/cellranger/salmon/transcripts_index --tgMap tx2gene.txt; Starting program: /u/user/local/bin/salmon alevin -l ISR --chromium -p 4 -o BM_1/alevin -1 ./BM_1/run1/bm_S10_L001_R1_001.fastq.gz -2 ./BM_1/run1/bm_S10_L001_R2_001.fastq.gz --maxHashResizeThreads 2 -i /u/user/ref/cellranger/salmon/transcripts_index --tgMap tx2gene.txt; [Thread debugging using libthread_db enabled]; Using host libthread_db library ""/lib/x86_64-linux-gnu/libthread_db.so.1"".; warning: File ""/u/user/local/lib64/libstdc++.so.6.0.21-gdb.py"" auto-loading has been declined by your `auto-load safe; -path' set to ""$debugdir:$datadir/auto-load"".; To enable execution of this file add; add-auto-load-safe-path /u/user/local/lib64/libstdc++.so.6.0.21-gdb.py; line to your configuration file ""/u/user/.gdbinit"".; To completely disable this security protection add; set auto-load safe-path /; line to your configuration file ""/u/user/.gdbinit"".; For more information about this security protection see the; ""Auto-loading safe path"" section in the GDB manual. E.g., run from the shell:; info ""(gdb)Auto-loading safe path""; [New Thread 0x7fff7dbff700 (LWP 21437)]; [Thread 0x7fff7dbff700 (LWP 21437) exited]; Version Info: Could not resolve upgrade information in the alotted time.; Check for upgrades manually at https://combine-lab.github.io/salmon; [New Thread 0x7ffefcfff700 (LWP 21653)]; Logs will be written to BM_1/alevin/logs; [New Thread 0x7ffe7cffe700 (LWP 21654)]; [New Thread 0x7ffdfcffd700 (LWP 21655)]; [New Thread 0x7ffd7cffc700 (LWP 21656)]; ### salmon (single-cell-based) v0.10.3; ### [ program ] => salmon; ### [ command ] => alevin; ### [ libType ] => { ISR }; ### [ chromium ] => { }; ### [ threads ] => { 4 }; ### [ output ] => { BM_1/alevin }; ### [ mates1 ] => { ./BM_1/run1/bm_S10_L001_R1_001.fastq.gz }; ### [ mates2 ] => { ./BM_1/run1/bm_S10_L001_R2_001.fastq.gz }; ### [ maxHashResizeThreads ] => { 2 }; ### [ index ] => { /u/user/ref/cellranger/salmon/transcripts_index }; ##",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-396078627:2178,load,loading,2178,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-396078627,1,['load'],['loading']
Performance,"sh_samples/salmon_quants/RHM5942 }; Logs will be written to /data2/csijcs/AML/RNA_seq/AML_total_MNC/total_MNCs/Fresh_samples/salmon_quants/RHM5942/logs; [2018-07-27 16:24:55.658] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2018-07-27 16:24:55.658] [jointLog] [info] parsing read library format; [2018-07-27 16:24:55.658] [jointLog] [info] There is 1 library.; [2018-07-27 16:25:01.242] [jointLog] [info] Loading Quasi index; [2018-07-27 16:25:01.242] [jointLog] [info] Loading 32-bit quasi index; [2018-07-27 16:25:01.243] [stderrLog] [info] Loading Suffix Array ; [2018-07-27 16:25:42.630] [stderrLog] [info] Loading Transcript Info ; [2018-07-27 16:25:45.683] [stderrLog] [info] Loading Rank-Select Bit Array; [2018-07-27 16:25:47.834] [stderrLog] [info] There were 203027 set bits in the bit array; [2018-07-27 16:25:48.128] [stderrLog] [info] Computing transcript lengths; [2018-07-27 16:25:48.200] [stderrLog] [info] Waiting to finish loading hash; [2018-07-27 16:25:48.331] [stderrLog] [info] Done loading index; [2018-07-27 16:25:48.331] [jointLog] [info] done; [2018-07-27 16:25:48.331] [jointLog] [info] Index contained 203027 targets. processed 239500000 fragmentsintLog] [info] Automatically detected most likely library type as ISR; hits: 651420499, hits per frag: 2.72282[2018-07-27 16:51:47.947] [jointLog] [info] Thread saw mini-batch with a maximum of 1.70% zero probability fragments; [2018-07-27 16:51:47.947] [jointLog] [info] Thread saw mini-batch with a maximum of 1.68% zero probability fragments; [2018-07-27 16:51:47.947] [jointLog] [info] Thread saw mini-batch with a maximum of 1.68% zero probability fragments; [2018-07-27 16:51:47.947] [jointLog] [info] Thread saw mini-batch with a maximum of 1.74% zero probability fragments; [2018-07-27 16:51:47.947] [jointLog] [info] Thread saw mini-batch with a maximum of 1.76% zero probability fragments; [2018-07-27 16:51:47.947] [jointLog] [info] Thread saw mini-bat",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/261#issuecomment-409427898:1790,load,loading,1790,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/261#issuecomment-409427898,1,['load'],['loading']
Performance,"size=7, ...}) = 0; open(""/cm/shared/apps/sge/current/lib/linux-x64/tls/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/cm/shared/apps/sge/current/lib/linux-x64/tls/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/cm/shared/apps/sge/current/lib/linux-x64/tls/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/cm/shared/apps/sge/current/lib/linux-x64/tls"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/cm/shared/apps/sge/current/lib/linux-x64/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/cm/shared/apps/sge/current/lib/linux-x64/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/cm/shared/apps/sge/current/lib/linux-x64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/cm/shared/apps/sge/current/lib/linux-x64"", {st_mode=S_IFDIR|0755, st_size=7, ...}) = 0; open(""/etc/ld.so.cache"", O_RDONLY) = 3; fstat(3, {st_mode=S_IFREG|0644, st_size=100319, ...}) = 0; mmap(NULL, 100319, PROT_READ, MAP_PRIVATE, 3, 0) = 0x7fffbffe4000; close(3) = 0; open(""/lib64/libpthread.so.0"", O_RDONLY) = 3; read(3, ""\177ELF\2\1\1\0\0\0\0\0\0\0\0\0\3\0>\0\1\0\0\0\340]@\3427\0\0\0""..., 832) = 832; fstat(3, {st_mode=S_IFREG|0755, st_size=145896, ...}) = 0; mmap(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7fffbffe3000; mmap(0x37e2400000, 2212848, PROT_READ|PROT_EXEC, MAP_PRIVATE|MAP_DENYWRITE, 3, 0) = 0x37e2400000; mprotect(0x37e2417000, 2097152, PROT_NONE) = 0; mmap(0x37e2617000, 8192, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_DENYWRITE, 3, 0x17000) = 0x37e2617000; mmap(0x37e2619000, 13296, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_ANONYMOUS, -1, 0) = 0x37e2619000; close(3) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/liblzma.so.0"", O_RDONLY) = 3; read(3, ""\177ELF\2\1\1\0\0\0\0\0\0\0\0\0\3\0>\0\1\0\0\0 %\0\0\0\0\0\0""..., 832) = ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:91081,cache,cache,91081,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,1,['cache'],['cache']
Performance,"size=7, ...}) = 0; open(""/cm/shared/apps/sge/current/lib/linux-x64/tls/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/cm/shared/apps/sge/current/lib/linux-x64/tls/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/cm/shared/apps/sge/current/lib/linux-x64/tls/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/cm/shared/apps/sge/current/lib/linux-x64/tls"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/cm/shared/apps/sge/current/lib/linux-x64/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/cm/shared/apps/sge/current/lib/linux-x64/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/cm/shared/apps/sge/current/lib/linux-x64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/cm/shared/apps/sge/current/lib/linux-x64"", {st_mode=S_IFDIR|0755, st_size=7, ...}) = 0; open(""/etc/ld.so.cache"", O_RDONLY) = 3; fstat(3, {st_mode=S_IFREG|0644, st_size=100319, ...}) = 0; mmap(NULL, 100319, PROT_READ, MAP_PRIVATE, 3, 0) = 0x7fffbffe4000; close(3) = 0; open(""/lib64/libpthread.so.0"", O_RDONLY) = 3; read(3, ""\177ELF\2\1\1\0\0\0\0\0\0\0\0\0\3\0>\0\1\0\0\0\340]\300\r5\0\0\0""..., 832) = 832; fstat(3, {st_mode=S_IFREG|0755, st_size=145896, ...}) = 0; mmap(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7fffbffe3000; mmap(0x350dc00000, 2212848, PROT_READ|PROT_EXEC, MAP_PRIVATE|MAP_DENYWRITE, 3, 0) = 0x350dc00000; mprotect(0x350dc17000, 2097152, PROT_NONE) = 0; mmap(0x350de17000, 8192, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_DENYWRITE, 3, 0x17000) = 0x350de17000; mmap(0x350de19000, 13296, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_ANONYMOUS, -1, 0) = 0x350de19000; close(3) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/liblzma.so.0"", O_RDONLY) = 3; read(3, ""\177ELF\2\1\1\0\0\0\0\0\0\0\0\0\3\0>\0\1\0\0\0 %\0\0\0\0\0\0""..., 832) =",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:15748,cache,cache,15748,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,1,['cache'],['cache']
Performance,"size=7, ...}) = 0; open(""/cm/shared/apps/sge/current/lib/linux-x64/tls/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/cm/shared/apps/sge/current/lib/linux-x64/tls/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/cm/shared/apps/sge/current/lib/linux-x64/tls/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/cm/shared/apps/sge/current/lib/linux-x64/tls"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/cm/shared/apps/sge/current/lib/linux-x64/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/cm/shared/apps/sge/current/lib/linux-x64/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/cm/shared/apps/sge/current/lib/linux-x64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/cm/shared/apps/sge/current/lib/linux-x64"", {st_mode=S_IFDIR|0755, st_size=7, ...}) = 0; open(""/etc/ld.so.cache"", O_RDONLY) = 3; fstat(3, {st_mode=S_IFREG|0644, st_size=101124, ...}) = 0; mmap(NULL, 101124, PROT_READ, MAP_PRIVATE, 3, 0) = 0x7fffbffe4000; close(3) = 0; open(""/lib64/libpthread.so.0"", O_RDONLY) = 3; read(3, ""\177ELF\2\1\1\0\0\0\0\0\0\0\0\0\3\0>\0\1\0\0\0\340]\200\316;\0\0\0""..., 832) = 832; fstat(3, {st_mode=S_IFREG|0755, st_size=145896, ...}) = 0; mmap(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7fffbffe3000; mmap(0x3bce800000, 2212848, PROT_READ|PROT_EXEC, MAP_PRIVATE|MAP_DENYWRITE, 3, 0) = 0x3bce800000; mprotect(0x3bce817000, 2097152, PROT_NONE) = 0; mmap(0x3bcea17000, 8192, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_DENYWRITE, 3, 0x17000) = 0x3bcea17000; mmap(0x3bcea19000, 13296, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_ANONYMOUS, -1, 0) = 0x3bcea19000; close(3) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/liblzma.so.0"", O_RDONLY) = 3; read(3, ""\177ELF\2\1\1\0\0\0\0\0\0\0\0\0\3\0>\0\1\0\0\0 %\0\0\0\0\0\0""..., 832)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:52618,cache,cache,52618,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,2,['cache'],['cache']
Performance,"t = 1307919 ; False junctions count = 233850 ; Hash table size = 1541769 ; Candidate marks count = 14841235 -------------------------------------------------------------------------------- ; Reallocating bifurcations time: 0 ; True marks count: 14610695 ; Edges construction time: 9 -------------------------------------------------------------------------------- ; Distinct junctions = 1307919 allowedIn: 18 ; Max Junction ID: 1458039 ; seen.size():11664321 kmerInfo.size():1458040 approximateContigTotalLength: 96596288 ; counters for complex kmers: ; (prec>1 & succ>1)=163493 | (succ>1 & isStart)=1600 | (prec>1 & isEnd)=1705 | (isStart & isEnd)=136 contig count: 2046804 element count: 189087548 complex nodes: 166934 ; number of ones in rank vector: 2046803 ; [2022-04-16 11:19:37.060] [puff::index::jointLog] [info] Starting the Pufferfish indexing by reading the GFA binary file. [2022-04-16 11:19:37.060] [puff::index::jointLog] [info] Setting the index/BinaryGfa directory salmon_index_23 ; size = 189087548 ; ----------------------------------------- ; | Loading contigs | Time = 43.37 ms ----------------------------------------- ; size = 189087548 ; ----------------------------------------- ; | Loading contig boundaries | Time = 19.565 ms ----------------------------------------- ; Number of ones: 2046803 ; Number of ones per inventory item: 512 ; Inventory entries filled: 3998 ; 2046803 ; [2022-04-16 11:19:37.638] [puff::index::jointLog] [info] Done wrapping the rank vector with a rank9sel structure. [2022-04-16 11:19:37.687] [puff::index::jointLog] [info] contig count for validation: 2,046,803 ; [2022-04-16 11:19:38.556] [puff::index::jointLog] [info] Total # of Contigs : 2,046,803 ; [2022-04-16 11:19:38.556] [puff::index::jointLog] [info] Total # of numerical Contigs : 2,046,803 ; [2022-04-16 11:19:38.774] [puff::index::jointLog] [info] Total # of contig vec entries: 15,036,896 ; [2022-04-16 11:19:38.774] [puff::index::jointLog] [info] bits per offset entry 24 ; [2022-0",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/768#issuecomment-1100734317:11669,Load,Loading,11669,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/768#issuecomment-1100734317,1,['Load'],['Loading']
Performance,"t to generate, do let us know how it looks in your case.; If you run Alevin with `--dumpFeatures` flag, alevin will generate a file `featureDump.txt`, whose first column will be the per CB level mapping rate i.e. `#mapped reads/#raw reads`. If you wan't absolute values for per-CB reads and mapped reads, it should be in the file `filtered_cb_frequency.txt` and `mappedUMI.txt` respectively.; * `re: cellranger subsampling:` Correct me if I am wrong, when you say cellranger subsampling, do you mean the `cellranger aggregate` pipeline? It's possible you are talking about some other step which I am not aware of but if it's `aggregate` then I think it happens downstream of all the quantification. Indeed coverage bias correction is an important part of the aggregation step but in general it's not the only one and that's why we recommend using the `Seurat` package downstream of the Alevin quantified matrices. We will be more than happy to write a tutorial on, ""how to perform batch correction downstream of Alevin"" but in summary the following steps would be the gist of the process.; - Use Alevin w/o any modification to the `fastq` on both of your sample to generate the gene count matrices. (We have made a major upgrade to the Alevin. We'd recommend using [v0.12.0-alpha](https://github.com/COMBINE-lab/salmon/tree/v0.12.0-alpha) for now, we are planning to make an official release before the end of this week, currently you can use pre-release. Unfortunately, not available on conda yet).; - Import Alevin count matrices into R using [this](https://combine-lab.github.io/alevin-tutorial/2018/alevin-seurat/) tutorial .; - Use [this](https://satijalab.org/seurat/immune_alignment.html) to perform the batch correction. ; We do realize it's currently complicated to use things downstream of Alevin and are working constantly on improving the overall pipeline to make the analyses as smooth as possible. If you happen to write a tutorial of your own on doing the analyses, we'd be happy to inc",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/305#issuecomment-433169468:1947,perform,perform,1947,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/305#issuecomment-433169468,2,['perform'],['perform']
Performance,"t }; ### [ tgMap ] => { transposon_sequence_set.fa.tsv }; ### [ whitelist ] => { barcode_seq_5K.txt }; ### [ dumpCsvCounts ] => { }. [2018-07-19 22:53:27.714] [alevinLog] [info] Processing barcodes files (if Present) . ; processed 87 Million barcodes. [2018-07-19 22:55:37.299] [alevinLog] [info] Done barcode density calculation.; [2018-07-19 22:55:37.299] [alevinLog] [info] # Barcodes Used: 86885223 / 87959276.; [2018-07-19 22:55:37.303] [alevinLog] [info] Done importing white-list Barcodes; [2018-07-19 22:55:37.303] [alevinLog] [info] Total 5238 white-listed Barcodes; [2018-07-19 22:55:37.675] [alevinLog] [info] Done populating Z matrix; [2018-07-19 22:55:37.683] [alevinLog] [info] Done indexing Barcodes; [2018-07-19 22:55:37.683] [alevinLog] [info] Total Unique barcodes found: 978816; [2018-07-19 22:55:37.683] [alevinLog] [info] Used Barcodes except Whitelist: 20705; [2018-07-19 22:55:38.386] [jointLog] [info] There is 1 library.; [2018-07-19 22:55:38.493] [jointLog] [info] Loading Quasi index; [2018-07-19 22:55:38.494] [jointLog] [info] Loading 32-bit quasi index; [2018-07-19 22:55:38.549] [jointLog] [info] done; [2018-07-19 22:55:38.549] [jointLog] [info] Index contained 179 targets. [2018-07-19 22:55:38.385] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify. [2018-07-19 22:55:38.385] [alevinLog] [info] parsing read library format; [2018-07-19 22:55:38.495] [stderrLog] [info] Loading Suffix Array ; [2018-07-19 22:55:38.498] [stderrLog] [info] Loading Transcript Info ; [2018-07-19 22:55:38.499] [stderrLog] [info] Loading Rank-Select Bit Array; [2018-07-19 22:55:38.500] [stderrLog] [info] There were 179 set bits in the bit array; [2018-07-19 22:55:38.501] [stderrLog] [info] Computing transcript lengths; [2018-07-19 22:55:38.501] [stderrLog] [info] Waiting to finish loading hash; processed 87 Million fragmentserrLog] [info] Done loading index; hits: 468892, hits per frag: 0.00535907. [2018-07-19 23:03:35.740] [jointLog] [info] Computed 150 rich equ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/253#issuecomment-406597243:2406,Load,Loading,2406,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/253#issuecomment-406597243,1,['Load'],['Loading']
Performance,"t/scratch3/rob/JoshTest$ ~/SoftwareStaging/salmon/scripts/SalmonBeta-0.6.5-pre_CentOS5/bin/salmon quant -p 15 -i salmon_index -l IU -1 ../strange_peak/19232_1_1.fastq -2 ../strange_peak/19232_1_2.fastq -o quant_binary; Version Info: This is the most recent version of Salmon.; # salmon (mapping-based) v0.6.0; # [ program ] => salmon; # [ command ] => quant; # [ threads ] => { 15 }; # [ index ] => { salmon_index }; # [ libType ] => { IU }; # [ mates1 ] => { ../strange_peak/19232_1_1.fastq }; # [ mates2 ] => { ../strange_peak/19232_1_2.fastq }; # [ output ] => { quant_binary }; Logs will be written to quant_binary/logs; there is 1[2016-03-31 14:05:14.184] [jointLog] [info] parsing read library format; lib; Loading 64-bit quasi index[2016-03-31 14:05:14.266] [stderrLog] [info] Loading Suffix Array; [2016-03-31 14:05:14.266] [jointLog] [info] Loading Quasi index. [2016-03-31 14:07:58.647] [stderrLog] [info] Loading Transcript Info; [2016-03-31 14:08:59.703] [stderrLog] [info] Loading Rank-Select Bit Array; [2016-03-31 14:09:06.744] [stderrLog] [info] There were 2027284 set bits in the bit array; [2016-03-31 14:09:08.123] [stderrLog] [info] Computing transcript lengths; [2016-03-31 14:09:08.240] [stderrLog] [info] Waiting to finish loading hash; Index contained 2027284 targets; [2016-03-31 14:09:15.789] [jointLog] [info] done; [2016-03-31 14:09:15.786] [stderrLog] [info] Successfully loaded position hash; [2016-03-31 14:09:15.789] [stderrLog] [info] Done loading index. [2016-03-31 14:09:36.623] [jointLog] [info] Computed 8083 rich equivalence classes for further processing; [2016-03-31 14:09:36.623] [jointLog] [info] Counted 159824 total reads in the equivalence classes. [2016-03-31 14:13:24.480] [jointLog] [warning] Only 159824 fragments were mapped, but the number of burn-in fragments was set to 5000000.; The effective lengths have been computed using the observed mappings. [2016-03-31 14:13:24.480] [jointLog] [info] Mapping rate = 36.3942%. [2016-03-31 14:13:24.480] [j",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/54#issuecomment-204066023:1316,Load,Loading,1316,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/54#issuecomment-204066023,1,['Load'],['Loading']
Performance,tLog] [info] done; [2016-12-13 22:44:20.485] [jointLog] [info] Index contained 182608 targets. processed 19000001 fragments; hits: 65897764; hits per frag: 3.48152. [2016-12-13 22:45:33.192] [jointLog] [info] Computed 137534 rich equivalence classes for further processing; [2016-12-13 22:45:33.192] [jointLog] [info] Counted 16265961 total reads in the equivalence classes; [2016-12-13 22:45:33.233] [jointLog] [info] Mapping rate = 83.509%. [2016-12-13 22:45:33.233] [jointLog] [info] finished quantifyLibrary(); [2016-12-13 22:45:33.234] [jointLog] [info] Starting optimizer; [2016-12-13 22:45:33.516] [jointLog] [info] Marked 0 weighted equivalence classes as degenerate; [2016-12-13 22:45:33.523] [jointLog] [info] iteration = 0 | max rel diff. = 299.95; [2016-12-13 22:45:34.217] [jointLog] [info] iteration = 100 | max rel diff. = 0.122252; [2016-12-13 22:45:34.912] [jointLog] [info] iteration = 200 | max rel diff. = 0.102915; [2016-12-13 22:45:35.612] [jointLog] [info] iteration = 300 | max rel diff. = 0.145792; [2016-12-13 22:45:36.357] [jointLog] [info] iteration = 400 | max rel diff. = 0.217489; [2016-12-13 22:45:37.055] [jointLog] [info] iteration = 500 | max rel diff. = 0.0159298; [2016-12-13 22:45:37.628] [jointLog] [info] iteration = 569 | max rel diff. = 0.00958049; [2016-12-13 22:45:37.653] [jointLog] [info] Finished optimizer; [2016-12-13 22:45:37.653] [jointLog] [info] writing output. [2016-12-13 22:45:38.213] [jointLog] [info] Starting Gibbs Sampler; 100% [=====================================================] in 31s; [2016-12-13 22:46:10.451] [jointLog] [info] Finished Gibbs Sampler; [2016-12-13 22:46:10.451] [jointLog] [warning] NOTE: Read Lib [SRR2454059.fq.gz] :. Detected a *potential* strand bias > 1% in an unstranded protocol check the file: test_quant/lib_format_counts.json for details; ```. i.e. I don't seem to get the complaints from the Gibbs sampler and all output files look to be created properly. I'm trying to figure out what could be different.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-266935584:3235,optimiz,optimizer,3235,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-266935584,1,['optimiz'],['optimizer']
Performance,"targets ] => { ../sample_data/transcripts.fasta }; # [ output ] => { sample_aln_quant }; Logs will be written to sample_aln_quant/logs; Library format { type:paired end, relative orientation:inward, strandedness:unstranded }; [2020-04-21 10:11:42.553] [jointLog] [info] setting maxHashResizeThreads to 8; [2020-04-21 10:11:42.553] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2020-04-21 10:11:42.553] [jointLog] [info] numQuantThreads = 4; parseThreads = 4; Checking that provided alignment files have consistent headers . . . done; Populating targets from aln = ""sample_alignments.sam"", fasta = ""../sample_data/transcripts.fasta"" . . .done; [2020-04-21 10:11:43.180] [jointLog] [info] replaced 0 non-ACGT nucleotides with random nucleotides. processed 0 reads in current round; killing thread 3 . . . done. Freeing memory used by read queue . . . 00; Joined parsing thread . . . ""sample_alignments.sam""; Closed all files . . .; Emptied frag queue. . . [2020-04-21 10:11:43.477] [jointLog] [info]. Completed first pass through the alignment file.; Total # of mapped reads : 10000; # of uniquely mapped reads : 6913; # ambiguously mapped reads : 3087. [2020-04-21 10:11:43.489] [jointLog] [info] Computed 27 rich equivalence classes for further processing; [2020-04-21 10:11:43.489] [jointLog] [info] Counted 10,000 total reads in the equivalence classes; [2020-04-21 10:11:43.490] [jointLog] [warning] Only 10000 fragments were mapped, but the number of burn-in fragments was set to 5000000.; The effective lengths have been computed using the observed mappings. [2020-04-21 10:11:43.492] [jointLog] [info] starting optimizer; [2020-04-21 10:11:43.493] [jointLog] [info] Marked 0 weighted equivalence classes as degenerate; [2020-04-21 10:11:43.493] [jointLog] [info] iteration = 0 | max rel diff. = 14.87; [2020-04-21 10:11:43.495] [jointLog] [info] iteration = 100 | max rel diff. = 9.59592e-05; [2020-04-21 10:11:43.495] [jointLog] [in",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/511#issuecomment-617206094:2036,queue,queue,2036,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/511#issuecomment-617206094,1,['queue'],['queue']
Performance,"ted Boundary at 99 ; [2019-01-29 09:55:04.817] [alevinLog] [info] Learned InvCov: 114.535 normfactor: 147.323; [2019-01-29 09:55:04.817] [alevinLog] [info] Total 289(has 190 low confidence) barcodes; [2019-01-29 09:55:04.822] [alevinLog] [info] Done True Barcode Sampling; [2019-01-29 09:55:04.855] [alevinLog] [info] Done populating Z matrix; [2019-01-29 09:55:04.855] [alevinLog] [info] Done indexing Barcodes; [2019-01-29 09:55:04.855] [alevinLog] [info] Total Unique barcodes found: 70316; [2019-01-29 09:55:04.855] [alevinLog] [info] Used Barcodes except Whitelist: 184; [2019-01-29 09:55:04.882] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify. [2019-01-29 09:55:04.882] [alevinLog] [info] parsing read library format; [2019-01-29 09:55:05.014] [stderrLog] [info] Loading Suffix Array ; [2019-01-29 09:55:04.882] [jointLog] [info] There is 1 library.; [2019-01-29 09:55:05.012] [jointLog] [info] Loading Quasi index; [2019-01-29 09:55:05.013] [jointLog] [info] Loading 32-bit quasi index; [2019-01-29 09:55:06.105] [stderrLog] [info] Loading Transcript Info ; [2019-01-29 09:55:09.968] [stderrLog] [info] Loading Rank-Select Bit Array; [2019-01-29 09:55:16.908] [stderrLog] [info] There were 80,511 set bits in the bit array; [2019-01-29 09:55:19.931] [stderrLog] [info] Computing transcript lengths; [2019-01-29 09:55:19.931] [stderrLog] [info] Waiting to finish loading hash; [2019-01-29 09:55:41.122] [jointLog] [info] done; [2019-01-29 09:55:41.122] [jointLog] [info] Index contained 80,511 targets; [2019-01-29 09:55:41.122] [stderrLog] [info] Done loading index. processed 0 Million fragments; hits: 161433, hits per frag: 0.32698. [2019-01-29 09:55:54.788] [alevinLog] [info] Starting optimizer; [2019-01-29 09:55:54.742] [jointLog] [info] Computed 6,346 rich equivalence classes for further processing; [2019-01-29 09:55:54.742] [jointLog] [info] Counted 80,300 total reads in the equivalence classes ; [2019-01-29 09:55:54.754] [jointLog] [warning] Only 80300 fragm",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/337#issuecomment-458481722:2944,Load,Loading,2944,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/337#issuecomment-458481722,1,['Load'],['Loading']
Performance,"the item.**; **WARNING: Target ""unitTests"" requests linking to directory ""/users/work/jake/bin/zlib-1.2.11/"". Targets may link only to libraries. CMake is dropping the item.**. So I actually went back a step and check my initial cmake command in the ../salmon-0.8.2/build/ directory. It also had the same issue and therefore wasn't building correctly. I started the install again from ../salmon-0.8.2/build/ using the following: . cmake -DBOOST_ROOT=/users/work/jake/bin/boost_1_64_0/ -DZLIB_LIBRARY=/users/work/jake/bin/zlib-1.2.11/zlib.h .. . It seemed to work nicely and I got all the build files to propagate into the ../salmon-0.8.2/build/ directory. From here I ran 'make' which did a whole bunch of things I hadn't seen it do yet, so assumably it was working as intended. This is until it got to the following stage:. Scanning dependencies of target libbwa; [ 48%] Creating directories for 'libbwa'; [ 49%] Performing download step for 'libbwa'; % Total % Received % Xferd Average Speed Time Time Time Current; Dload Upload Total Spent Left Speed; 100 125 0 125 0 0 167 0 --:--:-- --:--:-- --:--:-- 167; 0 0 0 219k 0 0 123k 0 --:--:-- 0:00:01 --:--:-- 326k; bwa-master.tar.gz: OK; bwa-0.7.12.3/.gitignore; bwa-0.7.12.3/.travis.yml; bwa-0.7.12.3/COPYING; bwa-0.7.12.3/ChangeLog; bwa-0.7.12.3/Makefile; bwa-0.7.12.3/NEWS.md; bwa-0.7.12.3/QSufSort.c; bwa-0.7.12.3/QSufSort.h; bwa-0.7.12.3/README-alt.md; bwa-0.7.12.3/README.md; bwa-0.7.12.3/bamlite.c; bwa-0.7.12.3/bamlite.h; bwa-0.7.12.3/bntseq.c; bwa-0.7.12.3/bntseq.h; bwa-0.7.12.3/bwa.1; bwa-0.7.12.3/bwa.c; bwa-0.7.12.3/bwa.h; bwa-0.7.12.3/bwakit/; bwa-0.7.12.3/bwakit/README.md; bwa-0.7.12.3/bwakit/bwa-postalt.js; bwa-0.7.12.3/bwakit/run-HLA; bwa-0.7.12.3/bwakit/run-bwamem; bwa-0.7.12.3/bwakit/run-gen-ref; bwa-0.7.12.3/bwakit/typeHLA-selctg.js; bwa-0.7.12.3/bwakit/typeHLA.js; bwa-0.7.12.3/bwakit/typeHLA.sh; bwa-0.7.12.3/bwamem.c; bwa-0.7.12.3/bwamem.h; bwa-0.7.12.3/bwamem_extra.c; bwa-0.7.12.3/bwamem_pair.c; bwa-0.7.12.3/bwape.c; bwa",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/141#issuecomment-314451873:1194,Perform,Performing,1194,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/141#issuecomment-314451873,1,['Perform'],['Performing']
Performance,"thm, it's actually an *online* EM algorithm, and makes use of a small prior, both of which regularize the estimates it produces. In an offline algorithm (or the offline phase of a dual-algorithm method like Salmon), the same thing can be achieved by using a ""more Bayesian"" inference algorithm than the EM (in this case, using the VBEM algorithm). Most of the time, there is very strong agreement between the estimates produced by different optimization algorithms, but sometimes, as in this case, they can differ considerably. It's still an open area of research and analysis to determine if one such method is ""better"" than another. However, if you have strong external information telling you that `MSAD_157177.t1` should actually be expressed at a non-trivial level in Run B, it looks like the VBEM is giving you a better estimate here. Coming back to the suggestion in your original post, there is no good way, in the optimization procedure to ""switch off the re-assignment between similar genes"", since that is the entire point of the algorithm, and heuristically disabling certain reassignments would destroy any statistical guarantees of the procedure. However, regularizing the estimates is an alternative way of balancing the likelihood based assignment of the EM algorithm with some prior belief (and the strength of this prior belief can be tweaked, in Salmon, by modifying the `--vbPrior` argument when the `--useVBOpt` flag is passed; a larger prior leads to more regularization). I hate to leave my analysis with a less than decisive answer, but I'm afraid this is the current state of the research here, and so this is about the best analysis I can currently offer. However, I will mention another project we're working on that relates to this by means of regularization across samples. That tool is [shoal](https://github.com/COMBINE-lab/shoal), and it's a method that takes the output of Salmon, and explicitly borrows information across all of the samples in an experiment to try a",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/107#issuecomment-263793798:3938,optimiz,optimization,3938,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/107#issuecomment-263793798,1,['optimiz'],['optimization']
Performance,"trimmed and become too short to be recognized as adapter sequence. When you run BBDuk with both quality-trimming and adapter-trimming in the same run, it will do adapter-trimming first, then quality-trimming. 2. I very well know that the advantage of using fastp is that it can do adapter trimming, etc in a automatic fashion - no need to provide external sequences (example adapter sequences). Yes, I know one can also provide a fasta file of adapters and fatsp will work off it. There are many fatsp issues in GH about adapter detection:. - fail to detect adpaters automatically - (https://github.com/OpenGene/fastp/issues/222 and https://github.com/OpenGene/fastp/issues/205). - [incorrect automatic adapter detection](https://github.com/OpenGene/fastp/issues/240). - [inconsistent behavior with different runs](https://github.com/OpenGene/fastp/issues/231). 3. When I see the above, I am bit skeptical using fastp for qc/adapter trimming. . After lot of trials with bbduk and fastp, I have decided to use bbduk and bbmap for my high throughput analysis. Below, I explain my reasoning behind those choices: . **_```Note - edited this on 02-Apr-2020 to have the correct order of operations ```_** . 1. **_STEP 1 - run bbmap.sh on raw fatsq file to remove contaminants as appropriate (rRNA, mitochondrial, chloroplast)_**; - You have alluded to the importance of removing contaminants [in this post](https://github.com/COMBINE-lab/salmon/issues/160#issuecomment-334762498); >However, the other thing to try is simply to align one of these samples to the genome with a tool like STAR or HISAT2 and look at their mapping rate to known features. If it's similar, then the other reads could be accounted for by e.g. intron retention or even contamination. Finally, [@vals has an excellent series of blog posts on investigating and addressing low mapping rates](http://www.nxn.se/valent/2017/9/18/low-mapping-rate-5-human-dna-contamination); - bbmap Command ([based of this biostars post](https://www.bios",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-597393209:1917,throughput,throughput,1917,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-597393209,2,['throughput'],['throughput']
Performance,"true, write: false }; 2021-12-06 15:37:20 INFO paired : false, ref_count : 226,030, num_chunks : 6,923; 2021-12-06 15:37:21 INFO tg-map contained 60,603 genes mapping to 226,030 transcripts.; 2021-12-06 15:37:21 INFO read 2 file-level tags; 2021-12-06 15:37:21 INFO read 2 read-level tags; 2021-12-06 15:37:21 INFO read 1 alignemnt-level tags; 2021-12-06 15:37:21 INFO File-level tag values FileTags { bclen: 24, umilen: 10 }; ⠓ [00:00:00] [╢╢▌╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟] ⠐ [00:00:00] [╢╢╢╢╢▌╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟] ⠁ [00:00:00] [╢╢╢╢╢╢╢╢▌╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟] ⠴ [00:00:01] [╢╢╢╢╢╢╢╢╢╢╢▌╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟] ⠤ [00:00:01] [╢╢╢╢╢╢╢╢╢╢╢╢╢╢▌╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟] ⠁ [00:00:01] [╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢▌╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟] ⠤ [00:00:01] [╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢▌╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟] ⠠ [00:00:02] [╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢░╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟╟] ⠐ [00:00:03] [╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢░╟╟╟╟╟╟╟╟╟╟╟╟╟] ⠋ [00:00:03] [╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢░╟╟╟╟╟╟╟╟╟╟] ⠄ [00:00:04] [╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢░╟╟╟╟╟╟╟] ⠈ [00:00:04] [╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢▌╟╟╟╟╟] ⠙ [00:00:04] [╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢▌╟╟] 6551/6923 ; 2021-12-06 15:37:26 WARN ; found connected component with 30679 vertices, resolved into 18 UMIs over 10 genes with trivial resolution.; [00:00:07] [╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢] 6923/6923 finished quantifying 6,923 cells.2021-12-06 15:37:28 INFO processed 26,250,078 total read records; ```. - Found that 6913 out of 6923 (>99%) barcodes are present in the submitted data.; - Finally ran a correlation b/w the alevin-fry output (located in `res/alevin`) and submitted data. Here are the results:. ![image](https://user-images.githubusercontent.com/12998572/144936078-b4e0ab3e-de1e-4b5d-8000-8c71109f27ae.png). ```; Min. 1st Qu. Median Mean 3rd Qu. Max. ; 0.03701 0.74469 0.88377 0.83131 0.94898 1.00000 ; ```. This demonstrates that alevin performs well with split-seq protocol. Let me know what you think, @jeremymsimon.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-987334414:6618,perform,performs,6618,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-987334414,1,['perform'],['performs']
Performance,"ts; [2020-04-23 00:13:24.793] [jointLog] [info] processed bias for 90.0% of the transcripts; [2020-04-23 00:13:26.996] [jointLog] [info] processed bias for 100.0% of the transcripts; [2020-04-23 00:13:28.195] [jointLog] [info] iteration = 100 | max rel diff. = 18.2995; [2020-04-23 00:13:29.515] [jointLog] [info] iteration = 200 | max rel diff. = 9.0865; [2020-04-23 00:13:30.800] [jointLog] [info] iteration = 300 | max rel diff. = 4.01818; [2020-04-23 00:13:32.083] [jointLog] [info] iteration = 400 | max rel diff. = 4.55608; [2020-04-23 00:13:33.364] [jointLog] [info] iteration = 500 | max rel diff. = 0.520451; [2020-04-23 00:13:34.643] [jointLog] [info] iteration = 600 | max rel diff. = 2.54118; [2020-04-23 00:13:35.923] [jointLog] [info] iteration = 700 | max rel diff. = 3.03814; [2020-04-23 00:13:37.202] [jointLog] [info] iteration = 800 | max rel diff. = 1.03192; [2020-04-23 00:13:38.483] [jointLog] [info] iteration = 900 | max rel diff. = 0.0895496; [2020-04-23 00:13:39.763] [jointLog] [info] iteration = 1,000 | max rel diff. = 0.114555; [2020-04-23 00:13:41.046] [jointLog] [info] iteration = 1,100 | max rel diff. = 0.0141693; [2020-04-23 00:13:42.326] [jointLog] [info] iteration = 1,200 | max rel diff. = 0.0828263; [2020-04-23 00:13:43.604] [jointLog] [info] iteration = 1,300 | max rel diff. = 0.0393046; [2020-04-23 00:13:44.883] [jointLog] [info] iteration = 1,400 | max rel diff. = 0.0200319; [2020-04-23 00:13:46.163] [jointLog] [info] iteration = 1,500 | max rel diff. = 0.0299069; [2020-04-23 00:13:47.443] [jointLog] [info] iteration = 1,600 | max rel diff. = 0.0153416; [2020-04-23 00:13:48.723] [jointLog] [info] iteration = 1,700 | max rel diff. = 0.0219194; [2020-04-23 00:13:50.003] [jointLog] [info] iteration = 1,800 | max rel diff. = 0.0886396; [2020-04-23 00:13:50.706] [jointLog] [info] iteration = 1,856 | max rel diff. = 0.00570505; [2020-04-23 00:13:50.714] [jointLog] [info] Finished optimizer; [2020-04-23 00:13:50.714] [jointLog] [info] writing output",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/516#issuecomment-621872756:6349,optimiz,optimizer,6349,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/516#issuecomment-621872756,1,['optimiz'],['optimizer']
Performance,"tstrap re-samplings, we expect significantly more variance than between subsequent runs of salmon, because the observations from which we are making the inference are actually changing. It is possible e.g. that some uniquely mapped reads may not be chosen in some bootstrap sample (since we are re-sampling the observed read count, but doing so _with replacement_), and so the estimates of sets of related isoforms will change in those samples. Thus, since the observations themselves are changing, we expect the estimates to display greater variance. In fact, this is the main goal of performing the bootstrapping (or Gibbs sampling) — to estimate the uncertainty due to inference if we had observed many reads coming from the same underlying ""population"" as the ones we have in our specific sample, but subject to the random sampling effect induced by sequencing and all of the subsequent downstream effects it has on our estimator (i.e. salmon's computational procedure for estimating transcript abundance via the variational Bayesian optimization algorithm). From the practical perspective, one would not necessarily expect taking the average of the bootstrap estimates to produce a more accurate point estimate than taking the normal point estimate produced by salmon. The main purpose of performing the Gibbs sampling or bootstrapping is to allow accurate assessment of the _posterior variance_ of the point estimates (to build things like credible intervals). The mean of the bootstrap estimates should be highly-correlated with the normal point estimates, but I wouldn't expect it to be identical. Also, you might try seeing what you get with a different summary statistic, like the median. However, the main point of producing this information is to allow you to assess the posterior variance, and also to pass these samples to uncertainty-aware differential analysis tools, like [swish](https://academic.oup.com/nar/article/47/18/e105/5542870), downstream of salmon. . Anyway, thanks again f",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/466#issuecomment-568828362:2301,optimiz,optimization,2301,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/466#issuecomment-568828362,2,['optimiz'],['optimization']
Performance,"uantify; > ; > [2020-06-04 17:56:30.294] [alevinLog] [info] parsing read library format; > [2020-06-04 17:57:36.339] [alevinLog] [info] Starting optimizer; > ; > ; > [2020-06-04 17:57:37.051] [alevinLog] [warning] mrna file not provided; using is 1 less feature for whitelisting; > [2020-06-04 17:57:37.051] [alevinLog] [warning] rrna file not provided; using is 1 less feature for whitelisting; > [2020-06-04 17:57:37.338] [alevinLog] [info] Total 23937.00 UMI after deduplicating.; > [2020-06-04 17:57:37.338] [alevinLog] [info] Total 91 BiDirected Edges.; > [2020-06-04 17:57:37.338] [alevinLog] [info] Total 82 UniDirected Edges.; > [2020-06-04 17:57:37.338] [alevinLog] [warning] Skipped 82268 barcodes due to No mapped read; > [2020-06-04 17:57:37.341] [alevinLog] [info] Clearing EqMap; Might take some time.; > [2020-06-04 17:57:37.348] [alevinLog] [warning] Num Low confidence barcodes too less 1 < 10.Can't performing whitelisting; Skipping; > [2020-06-04 17:57:37.348] [alevinLog] [info] Finished optimizer; > ; > . salmon_quant.log. > [2020-06-04 17:55:11.700] [jointLog] [info] setting maxHashResizeThreads to 7; > [2020-06-04 17:55:11.700] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; > [2020-06-04 17:55:11.700] [jointLog] [info] The --mimicBT2, --mimicStrictBT2 and --hardFilter flags imply mapping validation (--validateMappings). Enabling mapping validation.; > [2020-06-04 17:55:11.700] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; > [2020-06-04 17:55:11.700] [jointLog] [info] The use of range-factorized equivalence classes does not make sense in conjunction with --hardFilter. Disabling range-factorized equivalence classes. ; > [2020-06-04 17:55:11.700] [jointLog] [info] Usage of --validateMappings implies a default consensus slack of 0.2. Setting consensusSlack to 0.35.; > [2020-06-04 17:55:11.700] [jointLog] [info] Usin",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-639196415:2659,optimiz,optimizer,2659,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-639196415,1,['optimiz'],['optimizer']
Performance,"v/fd/0 -o interlaced_salmon_out; ```. Now I get. ```; [2016-01-03 00:36:48.844] [jointLog] [info] parsing read library format; [2016-01-03 00:36:49.995] [jointLog] [info] Loading Quasi index; [2016-01-03 00:37:08.293] [jointLog] [info] done; [2016-01-03 00:37:25.106] [jointLog] [info] Computed 23484 rich equivalence classes for further processing; [2016-01-03 00:37:25.106] [jointLog] [info] Counted 667333 total reads in the equivalence classes; [2016-01-03 00:37:25.106] [fileLog] [info]; At end of round 0; ==================; Observed 3060000 total fragments (3060000 in most recent round). [2016-01-03 00:37:31.905] [jointLog] [warning] Only 667333 fragments were mapped, but the number of burn-in fragments was set to 5000000.; The effective lengths have been computed using the observed mappings. [2016-01-03 00:37:31.905] [jointLog] [info] Mapping rate = 21.8083%. [2016-01-03 00:37:31.905] [jointLog] [info] finished quantifyLibrary(); [2016-01-03 00:37:31.905] [jointLog] [info] Starting optimizer; [2016-01-03 00:37:33.275] [jointLog] [info] Marked 0 weighted equivalence classes as degenerate; [2016-01-03 00:37:33.279] [jointLog] [info] iteration = 0 | max rel diff. = 35.6186; [2016-01-03 00:37:33.533] [jointLog] [info] iteration = 100 | max rel diff. = 0.12044; [2016-01-03 00:37:33.755] [jointLog] [info] iteration = 200 | max rel diff. = 0.0493504; [2016-01-03 00:37:33.970] [jointLog] [info] iteration = 300 | max rel diff. = 0.0275491; [2016-01-03 00:37:34.194] [jointLog] [info] iteration = 400 | max rel diff. = 0.0216294; [2016-01-03 00:37:34.418] [jointLog] [info] iteration = 500 | max rel diff. = 0.0214024; [2016-01-03 00:37:34.640] [jointLog] [info] iteration = 600 | max rel diff. = 0.0132335; [2016-01-03 00:37:34.850] [jointLog] [info] iteration = 700 | max rel diff. = 0.0132363; [2016-01-03 00:37:35.066] [jointLog] [info] iteration = 800 | max rel diff. = 0.0122673; [2016-01-03 00:37:35.287] [jointLog] [info] iteration = 900 | max rel diff. = 0.012951; [2016-01-",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/29#issuecomment-168447784:3827,optimiz,optimizer,3827,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/29#issuecomment-168447784,1,['optimiz'],['optimizer']
Performance,"ved 28512328 total fragments (28512328 in most recent round). [2020-06-16 00:01:01.745] [jointLog] [info] iteration = 100 | max rel diff.; = 19.507; [2020-06-16 00:01:03.495] [jointLog] [info] iteration = 200 | max rel diff.; = 2.45489; [2020-06-16 00:01:05.225] [jointLog] [info] iteration = 300 | max rel diff.; = 3.459; [2020-06-16 00:01:06.968] [jointLog] [info] iteration = 400 | max rel diff.; = 4.38485; [2020-06-16 00:01:08.693] [jointLog] [info] iteration = 500 | max rel diff.; = 0.229724; [2020-06-16 00:01:10.426] [jointLog] [info] iteration = 600 | max rel diff.; = 0.242741; [2020-06-16 00:01:12.163] [jointLog] [info] iteration = 700 | max rel diff.; = 0.196958; [2020-06-16 00:01:14.015] [jointLog] [info] iteration = 800 | max rel diff.; = 0.239461; [2020-06-16 00:01:15.803] [jointLog] [info] iteration = 900 | max rel diff.; = 0.197651; [2020-06-16 00:01:17.095] [jointLog] [info] iteration = 969 | max rel diff.; = 0.00714824; [2020-06-16 00:01:17.131] [jointLog] [info] Finished optimizer; [2020-06-16 00:01:17.131] [jointLog] [info] writing output. ```. So, you can note that the number of mappings discarded because of alignment; score is still quite big (134M) and, indeed, this took longer than I would; normally expect for; a sample with ~30M reads. However, it is _massively_ smaller (~116 times); than the 15.6B in your run. Thus, it may have been the same issue as in; the other GitHub issue. You can try the pre-compiled linux binary I linked; there if you have access to a linux machine to test on. By the way, the; issue there was a bunch of reads plagued by super-repetitive homopolymer; segments, I haven't looked at these reads yet for evidence of that though. On Mon, Jun 15, 2020 at 11:09 PM shalercr <notifications@github.com> wrote:. >; >; >; >; >; > Hi Rob,; >; >; > Thanks for the quick response. The other computer was OSX, should I try a; > linux machine?; >; >; > Here are some dropbox links to two of the files. I believe this is the set; > for the logs I",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/537#issuecomment-644527727:4488,optimiz,optimizer,4488,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/537#issuecomment-644527727,1,['optimiz'],['optimizer']
Performance,"ved 28512328 total fragments (28512328 in most recent round). [2020-06-16 00:01:01.745] [jointLog] [info] iteration = 100 | max rel diff.; = 19.507; [2020-06-16 00:01:03.495] [jointLog] [info] iteration = 200 | max rel diff.; = 2.45489; [2020-06-16 00:01:05.225] [jointLog] [info] iteration = 300 | max rel diff.; = 3.459; [2020-06-16 00:01:06.968] [jointLog] [info] iteration = 400 | max rel diff.; = 4.38485; [2020-06-16 00:01:08.693] [jointLog] [info] iteration = 500 | max rel diff.; = 0.229724; [2020-06-16 00:01:10.426] [jointLog] [info] iteration = 600 | max rel diff.; = 0.242741; [2020-06-16 00:01:12.163] [jointLog] [info] iteration = 700 | max rel diff.; = 0.196958; [2020-06-16 00:01:14.015] [jointLog] [info] iteration = 800 | max rel diff.; = 0.239461; [2020-06-16 00:01:15.803] [jointLog] [info] iteration = 900 | max rel diff.; = 0.197651; [2020-06-16 00:01:17.095] [jointLog] [info] iteration = 969 | max rel diff.; = 0.00714824; [2020-06-16 00:01:17.131] [jointLog] [info] Finished optimizer; [2020-06-16 00:01:17.131] [jointLog] [info] writing output; ```. So, you can note that the number of mappings discarded because of alignment; score is still quite big (134M) and, indeed, this took longer than I would; normally expect for; a sample with ~30M reads. However, it is _massively_ smaller (~116 times); than the 15.6B in your run. Thus, it may have been the same issue as in; the other GitHub issue. You can try the pre-compiled linux binary I linked; there if you have access to a linux machine to test on. By the way, the; issue there was a bunch of reads plagued by super-repetitive homopolymer; segments, I haven't looked at these reads yet for evidence of that though. On Mon, Jun 15, 2020 at 11:09 PM shalercr <notifications@github.com> wrote:. >; >; >; >; >; > Hi Rob,; >; >; > Thanks for the quick response. The other computer was OSX, should I try a; > linux machine?; >; >; > Here are some dropbox links to two of the files. I believe this is the set; > for the logs I",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/537#issuecomment-644520228:3732,optimiz,optimizer,3732,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/537#issuecomment-644520228,1,['optimiz'],['optimizer']
Performance,"which we are making the inference are actually changing. It is possible e.g. that some uniquely mapped reads may not be chosen in some bootstrap sample (since we are re-sampling the observed read count, but doing so _with replacement_), and so the estimates of sets of related isoforms will change in those samples. Thus, since the observations themselves are changing, we expect the estimates to display greater variance. In fact, this is the main goal of performing the bootstrapping (or Gibbs sampling) — to estimate the uncertainty due to inference if we had observed many reads coming from the same underlying ""population"" as the ones we have in our specific sample, but subject to the random sampling effect induced by sequencing and all of the subsequent downstream effects it has on our estimator (i.e. salmon's computational procedure for estimating transcript abundance via the variational Bayesian optimization algorithm). From the practical perspective, one would not necessarily expect taking the average of the bootstrap estimates to produce a more accurate point estimate than taking the normal point estimate produced by salmon. The main purpose of performing the Gibbs sampling or bootstrapping is to allow accurate assessment of the _posterior variance_ of the point estimates (to build things like credible intervals). The mean of the bootstrap estimates should be highly-correlated with the normal point estimates, but I wouldn't expect it to be identical. Also, you might try seeing what you get with a different summary statistic, like the median. However, the main point of producing this information is to allow you to assess the posterior variance, and also to pass these samples to uncertainty-aware differential analysis tools, like [swish](https://academic.oup.com/nar/article/47/18/e105/5542870), downstream of salmon. . Anyway, thanks again for the detailed report! We'll look into the logging issue, and please let me know if my description above answers your question.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/466#issuecomment-568828362:2557,perform,performing,2557,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/466#issuecomment-568828362,2,['perform'],['performing']
Performance,"with only the -l A and --useVBOpt options, it processes all the reads but fails later on:. processed 67500000 fragmentsointLog] [info] Automatically detected most likely library type as IU; hits: 230221778, hits per frag: 3.41111. [2018-05-30 19:12:47.976] [jointLog] [info] Thread saw mini-batch with a maximum of 1.48% zero probability fragments; [2018-05-30 19:12:47.985] [jointLog] [info] Thread saw mini-batch with a maximum of 1.48% zero probability fragments; [2018-05-30 19:12:48.029] [jointLog] [info] Thread saw mini-batch with a maximum of 1.46% zero probability fragments; [2018-05-30 19:12:48.068] [jointLog] [info] Thread saw mini-batch with a maximum of 1.44% zero probability fragments; [2018-05-30 19:12:48.396] [jointLog] [info] Computed 425882 rich equivalence classes for further processing; [2018-05-30 19:12:48.396] [jointLog] [info] Counted 61485857 total reads in the equivalence classes; [2018-05-30 19:12:48.399] [jointLog] [info] Mapping rate = 90.4806%. [2018-05-30 19:12:48.399] [jointLog] [info] finished quantifyLibrary(); [2018-05-30 19:12:48.402] [jointLog] [info] Starting optimizer; [2018-05-30 19:12:48.586] [jointLog] [info] Marked 1 weighted equivalence classes as degenerate; [2018-05-30 19:12:48.608] [jointLog] [info] iteration = 0 | max rel diff. = 63.2619; Exception : [Error in function boost::math::digamma<double>(double): numeric overflow]; salmon quant was invoked improperly.; For usage information, try salmon quant --help; Exiting. Sorry but I won't be able to look into this more today...",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/228#issuecomment-393243827:1107,optimiz,optimizer,1107,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/228#issuecomment-393243827,1,['optimiz'],['optimizer']
Performance,"x (which is the colored De Bruijn graph). I understand that this index (along with all the equivalence class) remains the same even when gene counts of different RNA-Seq samples are estimated. But I am a bit confused about the alignment-based method. In this case, salmon does not require an index since it has the actual alignments. If we have multiple samples, which are mapped to the same transcriptome will Salmon return the same set of equivalence classes? Since the samples are different the weights will change and so will the reads mapped to each equivalence class but will the set of eq. classes change?. The index remains the same when different samples are processed, just as with a traditional alignment tool like STAR or HISAT2. However, the set of equivalence classes are _not_ fixed between samples. The equivalence classes are induced by the specific set of aligned or mapped reads. Further, salmon adopts a notion of [range-factorized equivalence classes](https://academic.oup.com/bioinformatics/article/33/14/i142/3953977) in which the equivalence relation depends not only on the transcripts to which a read aligns or maps, but also on the conditional probabilities of the fragment being generated from these transcripts, which itself depends on experiment-specific parameters like the fragment length distribution. Thus, it is not the case under either its own builtin lightweight (selective) alignment, nor when operating with an external BAM file, that the set of equivalence classes produced by salmon will be the same across samples. The equivalence classes are _based_ on the underlying reference sequence, but are sample specific and induced both by the specific patterns of multimapping as well as by the sample-specific parameters (like the fragment length distribution). Thus, if you wish to perform some type of equivalence-class type analysis over multiple samples, you'll need to take the union over the equivalence classes observed in each of them. I hope this helps!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/579#issuecomment-717279405:3403,perform,perform,3403,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/579#issuecomment-717279405,1,['perform'],['perform']
Performance,"xpect this resampling to be similar to if we re-sampled _with replacement_ from the original set of input reads. That is, we are re-sampling from our population sample — the observed set of reads — to estimate the variance due to inference. So, for the bootstrap re-samplings, we expect significantly more variance than between subsequent runs of salmon, because the observations from which we are making the inference are actually changing. It is possible e.g. that some uniquely mapped reads may not be chosen in some bootstrap sample (since we are re-sampling the observed read count, but doing so _with replacement_), and so the estimates of sets of related isoforms will change in those samples. Thus, since the observations themselves are changing, we expect the estimates to display greater variance. In fact, this is the main goal of performing the bootstrapping (or Gibbs sampling) — to estimate the uncertainty due to inference if we had observed many reads coming from the same underlying ""population"" as the ones we have in our specific sample, but subject to the random sampling effect induced by sequencing and all of the subsequent downstream effects it has on our estimator (i.e. salmon's computational procedure for estimating transcript abundance via the variational Bayesian optimization algorithm). From the practical perspective, one would not necessarily expect taking the average of the bootstrap estimates to produce a more accurate point estimate than taking the normal point estimate produced by salmon. The main purpose of performing the Gibbs sampling or bootstrapping is to allow accurate assessment of the _posterior variance_ of the point estimates (to build things like credible intervals). The mean of the bootstrap estimates should be highly-correlated with the normal point estimates, but I wouldn't expect it to be identical. Also, you might try seeing what you get with a different summary statistic, like the median. However, the main point of producing this inf",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/466#issuecomment-568828362:1849,perform,performing,1849,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/466#issuecomment-568828362,2,['perform'],['performing']
Performance,y fragments; [2018-07-27 16:51:47.948] [jointLog] [info] Thread saw mini-batch with a maximum of 1.80% zero probability fragments; [2018-07-27 16:51:47.948] [jointLog] [info] Thread saw mini-batch with a maximum of 1.72% zero probability fragments; [2018-07-27 16:51:47.948] [jointLog] [info] Thread saw mini-batch with a maximum of 1.64% zero probability fragments; [2018-07-27 16:51:47.948] [jointLog] [info] Thread saw mini-batch with a maximum of 1.84% zero probability fragments; [2018-07-27 16:51:47.948] [jointLog] [info] Thread saw mini-batch with a maximum of 1.68% zero probability fragments; [2018-07-27 16:51:47.967] [jointLog] [info] Thread saw mini-batch with a maximum of 1.70% zero probability fragments; [2018-07-27 16:51:47.978] [jointLog] [info] Thread saw mini-batch with a maximum of 1.76% zero probability fragments; [2018-07-27 16:51:48.009] [jointLog] [info] Thread saw mini-batch with a maximum of 1.64% zero probability fragments; [2018-07-27 16:51:48.042] [jointLog] [info] Thread saw mini-batch with a maximum of 1.66% zero probability fragments; [2018-07-27 16:51:48.047] [jointLog] [info] Thread saw mini-batch with a maximum of 1.86% zero probability fragments; [2018-07-27 16:51:48.088] [jointLog] [info] Thread saw mini-batch with a maximum of 1.74% zero probability fragments; [2018-07-27 16:51:48.089] [jointLog] [info] Thread saw mini-batch with a maximum of 1.84% zero probability fragments; [2018-07-27 16:51:48.118] [jointLog] [info] Thread saw mini-batch with a maximum of 1.90% zero probability fragments. [2018-07-27 16:51:48.473] [jointLog] [info] Computed 457276 rich equivalence classes for further processing; [2018-07-27 16:51:48.473] [jointLog] [info] Counted 179109410 total reads in the equivalence classes . [2018-07-27 16:51:48.491] [jointLog] [info] Mapping rate = 74.748%. [2018-07-27 16:51:48.491] [jointLog] [info] finished quantifyLibrary(); [2018-07-27 16:51:48.507] [jointLog] [info] Starting optimizer; Segmentation fault (core dumped). ```,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/261#issuecomment-409427898:6315,optimiz,optimizer,6315,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/261#issuecomment-409427898,1,['optimiz'],['optimizer']
Performance,"zer. [2022-03-27 05:46:42.064] [alevinLog] [warning] mrna file not provided; using is 1 less feature for whitelisting; [2022-03-27 05:46:42.064] [alevinLog] [warning] rrna file not provided; using is 1 less feature for whitelisting; [2022-03-27 05:49:49.761] [alevinLog] [info] Total 535438.00 UMI after deduplicating.; [2022-03-27 05:49:49.761] [alevinLog] [info] Total 2317116 BiDirected Edges.; [2022-03-27 05:49:49.761] [alevinLog] [info] Total 867878 UniDirected Edges.; [2022-03-27 05:49:49.761] [alevinLog] [warning] Skipped 955 barcodes due to No mapped read; [2022-03-27 05:49:49.766] [alevinLog] [info] Clearing EqMap; Might take some time.; [2022-03-27 05:49:50.011] [alevinLog] [info] Starting white listing of 3044 cells; [2022-03-27 05:49:50.011] [alevinLog] [info] Starting to make feature Matrix; [2022-03-27 05:49:50.014] [alevinLog] [info] Done making feature Matrix; [2022-03-27 05:49:50.717] [alevinLog] [info] Finished white listing; [2022-03-27 05:49:51.422] [alevinLog] [info] Finished optimizer; ````. and the `salmon_quant.log` looks like:; ```; [2022-03-27 05:24:09.395] [jointLog] [info] setting maxHashResizeThreads to 32; [2022-03-27 05:24:09.395] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2022-03-27 05:24:09.395] [jointLog] [info] The --mimicBT2, --mimicStrictBT2 and --hardFilter flags imply mapping validation (--validateMappings). Enabling mapping validation.; [2022-03-27 05:24:09.395] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2022-03-27 05:24:09.395] [jointLog] [info] The use of range-factorized equivalence classes does not make sense in conjunction with --hardFilter. Disabling range-factorized equivalence classes. ; [2022-03-27 05:24:09.395] [jointLog] [info] Setting consensusSlack to selective-alignment default of 0.35.; [2022-03-27 05:24:09.395] [jointLog] [info] Using default value of 0.87 fo",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/763#issuecomment-1082597942:4097,optimiz,optimizer,4097,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/763#issuecomment-1082597942,1,['optimiz'],['optimizer']
Performance,"| max rel diff. = 0.0116537; [00m[1m[2017-03-30 11:35:11.215] [jointLog] [info] iteration = 1100 | max rel diff. = 0.0116537; [00m[1m[2017-03-30 11:35:12.190] [jointLog] [info] iteration = 1107 | max rel diff. = 0.00948523; [00m[1m[2017-03-30 11:35:12.199] [jointLog] [info] Finished optimizer; [00m[1m[2017-03-30 11:35:12.199] [jointLog] [info] writing output . [00m[33m[1m[2017-03-30 11:38:26.886] [jointLog] [warning] NOTE: Read Lib [( /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/merged_fastq/R10001_D2B1WACXX.fastq.gz, /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/merged_fastq/R10001_D2B1WACXX_read2.fastq.gz )] :. Greater than 5% of the fragments disagreed with the provided library type; check the file: /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test5/R10001_D2B1WACXX/lib_format_counts.json for details. [00m**** Job ends ****; Thu Mar 30 11:38:30 EDT 2017; ```. ### SGE email example info. ```; Job-array task 110632.1 (step6-salmon_test5.gsk_phaseII) Complete; User = lcollado; Queue = shared.q@compute-066.cm.cluster; Host = compute-066.cm.cluster; Start Time = 03/29/2017 23:27:10; End Time = 03/30/2017 11:38:30; User Time = 06:08:32; System Time = 12:46:46; Wallclock Time = 12:11:20; CPU = 18:55:18; Max vmem = 6.961G; Exit Status = 0; ```. For some reason, sample 1 took quite a bit of time. Samples 2 and 3 were actually much faster:. sample 2:. ```; Job-array task 110632.2 (step6-salmon_test5.gsk_phaseII) Complete; User = lcollado; Queue = shared.q@compute-051.cm.cluster; Host = compute-051.cm.cluster; Start Time = 03/30/2017 00:22:20; End Time = 03/30/2017 03:33:24; User Time = 02:37:02; System Time = 02:55:26; Wallclock Time = 03:11:04; CPU = 05:32:28; Max vmem = 6.941G; Exit Status = 0; ```. sample 3:. ```; Job-array task 110632.3 (step6-salmon_test5.gsk_phaseII) Complete; User = lcollado; Queue = shared.q@compute-051.cm.cluster; Host = compute-051.cm.cluster; Start Time = 03/30/2017 03:33:38; End Time = 03/30/2017 05:58:33; User Time = 03:45:",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-290516965:25859,Queue,Queue,25859,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-290516965,1,['Queue'],['Queue']
Safety," #1 SMP Debian 4.9.82-1+deb9u3~bpo8+1 (2018-03-22). ~/data/PCSI/PC10X/paper/pbmc$ g++ -v; Using built-in specs.; COLLECT_GCC=g++; COLLECT_LTO_WRAPPER=/u/user/local/libexec/gcc/x86_64-unknown-linux-gnu/5.4.0/lto-wrapper; Target: x86_64-unknown-linux-gnu; Configured with: ./configure --prefix=/u/user/local; Thread model: posix; gcc version 5.4.0 (GCC); ```. ```; [Thread debugging using libthread_db enabled]; Using host libthread_db library ""/lib/x86_64-linux-gnu/libthread_db.so.1"".; warning: File ""/u/user/local/lib64/libstdc++.so.6.0.21-gdb.py"" auto-loading has been declined by your `auto-load safe-path' set to ""$debugdir:$datadir/auto-load"".; To enable execution of this file add; add-auto-load-safe-path /u/user/local/lib64/libstdc++.so.6.0.21-gdb.py; line to your configuration file ""/u/user/.gdbinit"".; To completely disable this security protection add; set auto-load safe-path /; line to your configuration file ""/u/user/.gdbinit"".; For more information about this security protection see the; ""Auto-loading safe path"" section in the GDB manual. E.g., run from the shell:; info ""(gdb)Auto-loading safe path""; [New Thread 0x7fff7e0f4700 (LWP 14274)]; Version Info: ### A newer version of Salmon is available. ####; [Thread 0x7fff7e0f4700 (LWP 14274) exited]; ###; The newest version, available at https://github.com/COMBINE-lab/salmon/releases; contains new features, improvements, and bug fixes; please upgrade at your; earliest convenience.; ###; [New Thread 0x7fff7d273700 (LWP 14275)]; Logs will be written to pbmc4k/alevin/logs; [New Thread 0x7ffefc3f1700 (LWP 14276)]; [New Thread 0x7ffe7b56f700 (LWP 14277)]; [New Thread 0x7ffdfa6ed700 (LWP 14278)]; ### salmon (single-cell-based) v0.10.1; ### [ program ] => salmon; ### [ command ] => alevin; ### [ libType ] => { ISR }; ### [ chromium ] => { }; ### [ threads ] => { 8 }; ### [ output ] => { pbmc4k/alevin }; ### [ mates1 ] => { /dev/fd/63 }; ### [ mates2 ] => { /dev/fd/62 }; ### [ index ] => { /u/user/ref/cellranger/salmon/trans",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-395836214:2617,safe,safe,2617,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-395836214,1,['safe'],['safe']
Safety," /proc/version; Linux version 4.9.0-0.bpo.6-amd64 (debian-kernel@lists.debian.org) (gcc version 4.9.2 (Debian 4.9.2-10+deb8u1) ) #1 SMP Debian 4.9.82-1+deb9u3~bpo8+1 (2018-03-22). ~/data/PCSI/PC10X/paper/pbmc$ g++ -v; Using built-in specs.; COLLECT_GCC=g++; COLLECT_LTO_WRAPPER=/u/user/local/libexec/gcc/x86_64-unknown-linux-gnu/5.4.0/lto-wrapper; Target: x86_64-unknown-linux-gnu; Configured with: ./configure --prefix=/u/user/local; Thread model: posix; gcc version 5.4.0 (GCC); ```. ```; [Thread debugging using libthread_db enabled]; Using host libthread_db library ""/lib/x86_64-linux-gnu/libthread_db.so.1"".; warning: File ""/u/user/local/lib64/libstdc++.so.6.0.21-gdb.py"" auto-loading has been declined by your `auto-load safe-path' set to ""$debugdir:$datadir/auto-load"".; To enable execution of this file add; add-auto-load-safe-path /u/user/local/lib64/libstdc++.so.6.0.21-gdb.py; line to your configuration file ""/u/user/.gdbinit"".; To completely disable this security protection add; set auto-load safe-path /; line to your configuration file ""/u/user/.gdbinit"".; For more information about this security protection see the; ""Auto-loading safe path"" section in the GDB manual. E.g., run from the shell:; info ""(gdb)Auto-loading safe path""; [New Thread 0x7fff7e0f4700 (LWP 14274)]; Version Info: ### A newer version of Salmon is available. ####; [Thread 0x7fff7e0f4700 (LWP 14274) exited]; ###; The newest version, available at https://github.com/COMBINE-lab/salmon/releases; contains new features, improvements, and bug fixes; please upgrade at your; earliest convenience.; ###; [New Thread 0x7fff7d273700 (LWP 14275)]; Logs will be written to pbmc4k/alevin/logs; [New Thread 0x7ffefc3f1700 (LWP 14276)]; [New Thread 0x7ffe7b56f700 (LWP 14277)]; [New Thread 0x7ffdfa6ed700 (LWP 14278)]; ### salmon (single-cell-based) v0.10.1; ### [ program ] => salmon; ### [ command ] => alevin; ### [ libType ] => { ISR }; ### [ chromium ] => { }; ### [ threads ] => { 8 }; ### [ output ] => { pbmc4k/alevi",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-395836214:2476,safe,safe-path,2476,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-395836214,1,['safe'],['safe-path']
Safety," = 14; > parseThreads = 6; > Checking that provided alignment files have consistent headers . . . done; > Populating targets from aln = ""SRR3212847.Aligned.Shuffled.bam"", fasta = ""mRNA.fasta"" . . .done; > ; > processed 0 reads in current roundSegmentation fault (core dumped); > ```; > ; > ### 2. Shuffling a headless bam file with `samtools collate`; > (I think I saw something about the bam's header in another thread dealing with this issue); > ; > ```; > samtools view \; > -b \; > -@ 40 \; > -o SRR3212847.Aligned.SortedByCoord.NoHeader.bam \; > SRR3212847.Aligned.SortedByCoord.bam; > ; > samtools collate \; > -@ 40 \; > -o SRR3212847.Aligned.Shuffled.NoHeader.bam \; > SRR3212847.Aligned.SortedByCoord.NoHeader.bam; > ; > salmon quant \; > -t mRNA.fasta \; > -p 20 \; > -l A \; > -a SRR3212847.Aligned.Shuffled.NoHeader.bam \; > -o SRR3212847.Aligned.Shuffled.NoHeader; > ```; > ; > ```; > ; > ....; > ; > ; > [2021-01-08 12:42:10.700] [jointLog] [warning] ; > ; > WARNING: Detected suspicious pair --- ; > The names are different:; > read1 : SRR3212847.24133171; > read2 : SRR3212847.33911054; > The proper-pair statuses are inconsistent:; > read1 [SRR3212847.24133171] : no proper-pair; not mapped; matenot mapped; > ; > read2 : [SRR3212847.24133171] : proper-pair; mapped; matemapped; > ; > [2021-01-08 12:42:10.700] [jointLog] [warning] ; > ; > WARNING: Detected suspicious pair --- ; > The names are different:; > read1 : SRR3212847.33911054; > read2 : SRR3212847.30781941; > ; > Segmentation fault (core dumped); > ```; > ; > ### 3. Sorting with `samtools sort -n`; > ```; > samtools sort \; > -@ 40 \; > -n \; > -o SRR3212847.Aligned.SortedByName.bam \; > SRR3212847.Aligned.SortedByCoord.bam; > ; > salmon quant \; > -t mRNA.fasta \; > -p 20 \; > -l A \; > -a SRR3212847.Aligned.SortedByName.bam \; > -o SRR3212847.Aligned.SortedByName; > ```; > ; > ```; > Version Info: This is the most recent version of salmon.; > # salmon (alignment-based) v1.4.0; > # [ program ] => salmon ; > # [",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/582#issuecomment-1343749456:2562,Detect,Detected,2562,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/582#issuecomment-1343749456,1,['Detect'],['Detected']
Safety, [info] Index contained 182608 targets. processed 19000000 fragments; hits: 65897209; hits per frag: 3.47349. [2016-12-13 22:40:22.572] [jointLog] [info] Computed 137534 rich equivalence classes for further processing; [2016-12-13 22:40:22.572] [jointLog] [info] Counted 16265961 total reads in the equivalence classes; [2016-12-13 22:40:22.618] [jointLog] [info] Mapping rate = 83.509%. [2016-12-13 22:40:22.618] [jointLog] [info] finished quantifyLibrary(); [2016-12-13 22:40:22.619] [jointLog] [info] Starting optimizer; [2016-12-13 22:40:22.904] [jointLog] [info] Marked 0 weighted equivalence classes as degenerate; [2016-12-13 22:40:22.911] [jointLog] [info] iteration = 0 | max rel diff. = 299.976; [2016-12-13 22:40:23.620] [jointLog] [info] iteration = 100 | max rel diff. = 0.121769; [2016-12-13 22:40:24.367] [jointLog] [info] iteration = 200 | max rel diff. = 0.103587; [2016-12-13 22:40:25.102] [jointLog] [info] iteration = 300 | max rel diff. = 0.144748; [2016-12-13 22:40:25.815] [jointLog] [info] iteration = 400 | max rel diff. = 0.231057; [2016-12-13 22:40:26.505] [jointLog] [info] iteration = 500 | max rel diff. = 0.0156154; [2016-12-13 22:40:27.020] [jointLog] [info] iteration = 570 | max rel diff. = 0.00955966; [2016-12-13 22:40:27.052] [jointLog] [info] Finished optimizer; [2016-12-13 22:40:27.052] [jointLog] [info] writing output. [2016-12-13 22:40:27.523] [jointLog] [info] Starting Gibbs Sampler 1 week; 100% [=====================================================] in 44s; [2016-12-13 22:41:12.189] [jointLog] [info] Finished Gibbs Sampler; [2016-12-13 22:41:12.190] [jointLog] [warning] NOTE: Read Lib [SRR2454059.fq.gz] :. Detected a *potential* strand bias > 1% in an unstranded protocol check the file: test_quant/lib_format_counts.json for details; ```. edit: One note is that I was using my build of the same commit number. I'm running the executable you compiled now (since I had to put the appropriate libraries in the `LD_LIBRARY_PATH` to get it to be happy).,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-266934878:3730,Detect,Detected,3730,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-266934878,1,['Detect'],['Detected']
Safety," [warning] Entry with header [ENST00000604838.1|ENSG00000270185.1|OTTHUMG00000184585.2|OTTHUMT00000468915.2|RP11-1360M22.4-001|IGHD1OR15-1B|17|IG_D_gene|], had length less than the k-mer length of 31 (perhaps after poly-A clipping); counted k-mers for 150000 transcripts[2018-08-02 16:23:32.097] [jointLog] [warning] Entry with header [ENST00000579054.1|ENSG00000266416.1|OTTHUMG00000179204.1|OTTHUMT00000445280.1|RP1-66C13.2-001|RP1-66C13.2|28|processed_pseudogene|], had length less than the k-mer length of 31 (perhaps after poly-A clipping); counted k-mers for 170000 transcripts[2018-08-02 16:23:32.554] [jointLog] [warning] Entry with header [ENST00000634174.1|ENSG00000282732.1|OTTHUMG00000191398.1|OTTHUMT00000487783.1|RP11-157B13.10-001|RP11-157B13.10|28|unprocessed_pseudogene|], had length less than the k-mer length of 31 (perhaps after poly-A clipping); counted k-mers for 200000 transcriptsElapsed time: 5.76935s. [2018-08-02 16:23:33.248] [jointLog] [warning] There were 808 transcripts that would need to be removed to avoid duplicates.; Replaced 4 non-ATCG nucleotides; Clipped poly-A tails from 1586 transcripts; Building rank-select dictionary and saving to disk done; Elapsed time: 0.0169059s; Writing sequence data to file . . . done; Elapsed time: 0.13359s; [info] Building 32-bit suffix array (length of generalized text is 309778559); Building suffix array . . . success; saving to disk . . . done; Elapsed time: 6.96499s; done; Elapsed time: 33.5821s; processed 309000000 positions; khash had 130317526 keys; saving hash to disk . . . done; Elapsed time: 34.8185s; [2018-08-02 16:26:58.153] [jLog] [info] done building index; ```; I reproduced the warnings from the initial run w/o the `--keepDuplicates` argument. ; ```; [Step 1 of 4] : counting k-mers; [2018-08-06 09:29:02.061] [jointLog] [warning] Entry with header [ENST00000473810.1|ENSG00000239255.1|OTTHUMG00000157482.1|OTTHUMT00000348942.1|RP11-145M9.2-001|RP11-145M9.2|25|processed_pseudogene|], had length less than",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/214#issuecomment-410601245:10114,avoid,avoid,10114,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/214#issuecomment-410601245,1,['avoid'],['avoid']
Safety," anot.pre$premature_group <- sapply(; split(; names(anot.pre),; paste(anot.pre$gene_id, anot.pre$transcript_range, sep = '_'); ),; paste, collapse = ';'; )[; paste(anot.pre$gene_id, anot.pre$transcript_range, sep = '_'); ]. # ... need to convert GR to data.table before unique because unique method for GR class ignores metadata and rownames; anot.pre <- as.data.table(anot.pre) %>% unique %>% makeGRangesFromDataFrame(., keep.extra.columns = T); names(anot.pre) <- anot.pre$premature_group. ### Read human genome sequence ####; message('Loading genome sequence...'). dna <- readDNAStringSet(filepath = genome.fasta). # simplify chromosome names; names(dna) <- sapply(strsplit(names(dna), ' '), '[', 1). dna <- dna[chromosomes] # subset chrom 1-22, X, Y, MT. ### Read Gencode transcript sequences ####; gencode <- readDNAStringSet(gencode.tx.fasta); names(gencode) <- gsub(; pattern = '\\|.*', replacement = '',; x = names(gencode); ). ### Sample transcripts on + and - strand (and avoid premature transcripts with multiple mature counterparts for simplicity); anot.pre <- anot.pre[order(width(anot.pre), decreasing = F), ]. chosenOnesP <- anot.pre[; strand(anot.pre) == '+' & !grepl(';', anot.pre$premature_group) & anot.pre$premature_group %in% names(gencode) & !duplicated(anot.pre$premature_group) &; anot.pre$premature_group %in% anot[anot$transcript_source == 'ensembl_havana']$transcript_id; ]$premature_group[1]. chosenOnesM <- anot.pre[; strand(anot.pre) == '-' & !grepl(';', anot.pre$premature_group) & anot.pre$premature_group %in% names(gencode) & !duplicated(anot.pre$premature_group) &; anot.pre$premature_group %in% anot[anot$transcript_source == 'ensembl_havana']$transcript_id; ]$premature_group[1]. chosenOnes <- c(chosenOnesP, chosenOnesM). # subset chosed ones; anot.ori <- anot; anot.pre.ori <- anot.pre. anot <- anot[anot$transcript_id %in% chosenOnes, ]; anot.pre <- anot.pre[anot.pre$premature_group %in% chosenOnes, ]. # sanity check (make sure strand information is the same ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/655#issuecomment-826035191:6145,avoid,avoid,6145,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/655#issuecomment-826035191,2,['avoid'],['avoid']
Safety," here with alevin, so it would mis-detect cells like the shifted ones you pasted above. For SPLiT-seq, we do know exactly which barcodes go into the wells, however, so it is technically possible to restrict based on all possible known combinations of barcodes instead and be more positionally flexible. But deciding how many indel bases are allowable, and presumably doing multiple passes through the data to establish an include-list could be time-consuming. Further, the zUMIs developer rightly mentions [in this thread](https://github.com/sdparekh/zUMIs/issues/63) that there are likely going to be _many_ unused barcode combinations this way, so lots of time could be spent looking for ""cells"" that don't actually exist in the data. The authors of the paper from which our test dataset was derived describe in their methods using a Drop-seq computational framework, so I'm not sure which approach theirs is more similar to. . The simplest approach here is certainly the automatic detection, but it will come at the cost of losing meaningful reads to frameshift errors. . My guess is this falls well out of the scope of alevin, but if you're interested in improving on that, there may be a middle ground between the two approaches above, one that I'm not sure if your group or others have attempted for other methods: we could essentially do a 2-pass barcode detection. The first pass would restrict based on positions like we're already doing, and establish an include-list of possible barcodes seen in the data. Then we could pass through the barcode sequences a second time, looking only for those sequence combinations, but allowing 1-2bp flexibility in the positions they occur, potentially rescuing some of the ones missed during the first pass. This would get around the issue of searching for thousands (or more) barcodes that never exist. . However, for your above sequences in red, we would still need to somehow collapse the barcodes `GATAGACA`, `ATAGACAT`, and `ATAGACAG`, but perhaps t",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-985554883:1226,detect,detection,1226,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-985554883,2,['detect'],['detection']
Safety," ignored.; [2018-07-27 16:24:55.658] [jointLog] [info] parsing read library format; [2018-07-27 16:24:55.658] [jointLog] [info] There is 1 library.; [2018-07-27 16:25:01.242] [jointLog] [info] Loading Quasi index; [2018-07-27 16:25:01.242] [jointLog] [info] Loading 32-bit quasi index; [2018-07-27 16:25:01.243] [stderrLog] [info] Loading Suffix Array ; [2018-07-27 16:25:42.630] [stderrLog] [info] Loading Transcript Info ; [2018-07-27 16:25:45.683] [stderrLog] [info] Loading Rank-Select Bit Array; [2018-07-27 16:25:47.834] [stderrLog] [info] There were 203027 set bits in the bit array; [2018-07-27 16:25:48.128] [stderrLog] [info] Computing transcript lengths; [2018-07-27 16:25:48.200] [stderrLog] [info] Waiting to finish loading hash; [2018-07-27 16:25:48.331] [stderrLog] [info] Done loading index; [2018-07-27 16:25:48.331] [jointLog] [info] done; [2018-07-27 16:25:48.331] [jointLog] [info] Index contained 203027 targets. processed 239500000 fragmentsintLog] [info] Automatically detected most likely library type as ISR; hits: 651420499, hits per frag: 2.72282[2018-07-27 16:51:47.947] [jointLog] [info] Thread saw mini-batch with a maximum of 1.70% zero probability fragments; [2018-07-27 16:51:47.947] [jointLog] [info] Thread saw mini-batch with a maximum of 1.68% zero probability fragments; [2018-07-27 16:51:47.947] [jointLog] [info] Thread saw mini-batch with a maximum of 1.68% zero probability fragments; [2018-07-27 16:51:47.947] [jointLog] [info] Thread saw mini-batch with a maximum of 1.74% zero probability fragments; [2018-07-27 16:51:47.947] [jointLog] [info] Thread saw mini-batch with a maximum of 1.76% zero probability fragments; [2018-07-27 16:51:47.947] [jointLog] [info] Thread saw mini-batch with a maximum of 1.72% zero probability fragments; [2018-07-27 16:51:47.947] [jointLog] [info] Thread saw mini-batch with a maximum of 1.74% zero probability fragments; [2018-07-27 16:51:47.947] [jointLog] [info] Thread saw mini-batch with a maximum of 1.68% zero probabi",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/261#issuecomment-409427898:2053,detect,detected,2053,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/261#issuecomment-409427898,1,['detect'],['detected']
Safety," library type. When I change the ""A"" to ""ISR"" or ""IU"", the % mapped changes a lot. That does seem strange, but I honestly don't know much about `Evigene` or what it's doing in combining these assemblies. When you specify ""IU"", the mappings will generally be _more_ lenient (i.e. you'd expect to get more mappings) than when you specify ""ISR"". The ""A"" flag just looks at how the first 10,000 reads map and guesses the library type based on that. On thing to make sure of is that your reads aren't ""ordered"" in any way, such that you'd expect the first 10,000 to deviate in any meaningful way from the statistics of the reads of the reads. > Is it better to build assemblies with strand-aware flags? If so, does it usually make a large difference to quantification results, or a minor one? I don't know what protocol the sequencing facility used, but I am sure I could ask them. I gather from my recent reading that the extra information gained by using a stranded protocol is worthwhile, so I would expect that the sequencing facility used one, but why doesn't Trinity or MEGAHIT detect the sequecing protocol that was used? . So there are really 2 questions here. *If* the data are stranded, then yes, it's worthwhile to use stranded flags in both assembly and quantification. This is because stranded protocols will allow you to better disambiguate (a) overlapping genes and (b) reads that are ambiguous between sequence-similar genes that happen to reside on different strands. The *second* question is why Trinity or MEGAHIT wouldn't detect this. The main reason for this is that these are assembly tools. Without access to a reference genome, there is no principled way for these tools to know what the orientation of a read is _a priori_, so they generally rely on the user to specify if the reads are stranded or unstranded. > Or, if you have to specify it, why do none of the example Trinity commands I've come across include this option? It doesn't strike me as a commonly used specification i",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/840#issuecomment-1493034427:1263,detect,detect,1263,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/840#issuecomment-1493034427,1,['detect'],['detect']
Safety," not used downstream. . Well, yes and no. We make extensive use of the position when estimate the implied fragment length (distance between paired end reads) and then model the conditional probability of this fragment based on the global fragment length distribution. This is just as much as is done by e.g. RSEM. However, you are right that there is no notion of using the coverage profile in estimation (more on this below)!. > Also, my intuition for these transcripts is not really a coverage ""bias"" . My intuition agrees with yours here completely. First, this isn't really a coverage bias as we use the normal definition of the term. Second, the positional bias modeling in salmon is not on a per-transcript level (since that would be an astronomical number of different parameters to learn, and any procedure would almost certainly overfit). Instead, it groups transcripts into length bins, and learns a distinct coverage bias model per-bin. > It would be neat if Salmon could detect these kinds of dramatic dropoffs and add a warning or something... even if not incorporating the information into the quants... it could even be a good QC step to identify large deletions/insertions over a gene body. As far as I know, there are NO rnaseq quant programs that would handle this, because even something like a STAR -> RSEM pipeline just projects read counts to the transcriptome and doesn't incorporate the coverage information. These are **great** points! A couple of thoughts. First, you are right that salmon, RSEM, etc. don't use coverage information in the way you describe here. One piece of software you might look into is [Salmon Anomaly Detection](https://github.com/Kingsford-Group/sad) (paper [here](https://www.cell.com/cell-systems/pdf/S2405-4712(19)30381-3.pdf)). This is sort of akin to what you are suggesting, and post-processes salmon output by looking for anomalous coverage profiles. It can both flag ""suspicious"" transcripts, and can also sometimes move reads around to mitiga",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-623047035:1657,detect,detect,1657,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-623047035,2,['detect'],['detect']
Safety," term. Second, the positional bias modeling in salmon is not on a per-transcript level (since that would be an astronomical number of different parameters to learn, and any procedure would almost certainly overfit). Instead, it groups transcripts into length bins, and learns a distinct coverage bias model per-bin. > It would be neat if Salmon could detect these kinds of dramatic dropoffs and add a warning or something... even if not incorporating the information into the quants... it could even be a good QC step to identify large deletions/insertions over a gene body. As far as I know, there are NO rnaseq quant programs that would handle this, because even something like a STAR -> RSEM pipeline just projects read counts to the transcriptome and doesn't incorporate the coverage information. These are **great** points! A couple of thoughts. First, you are right that salmon, RSEM, etc. don't use coverage information in the way you describe here. One piece of software you might look into is [Salmon Anomaly Detection](https://github.com/Kingsford-Group/sad) (paper [here](https://www.cell.com/cell-systems/pdf/S2405-4712(19)30381-3.pdf)). This is sort of akin to what you are suggesting, and post-processes salmon output by looking for anomalous coverage profiles. It can both flag ""suspicious"" transcripts, and can also sometimes move reads around to mitigate anomalous coverage. Another tool / metric you might consider is the junction coverage compatibility (paper [here](https://www.life-science-alliance.org/content/2/1/e201800175)). While both of these approaches get at some of the core intuitions you raise in your response, they are both rather ""heavyweight"", and neither, of course, is built into salmon. So, I **completely agree** that a lightweight version of something like SAD would be great to have built _into_ salmon. Specifically, it makes a lot of sense to have some component of the likelihood account for the coverage profile of transcripts. While I don't know of any ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-623047035:2324,Detect,Detection,2324,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-623047035,1,['Detect'],['Detection']
Safety," the GDB manual and other documentation resources online at:; <http://www.gnu.org/software/gdb/documentation/>.; For help, type ""help"".; Type ""apropos word"" to search for commands related to ""word""...; Reading symbols from /u/user/local/bin/salmon...done.; (gdb) run alevin -l ISR --chromium -p 4 -o BM_1/alevin -1 ./BM_1/run1/bm_S10_L001_R1_001.fastq.gz -2 ./BM_1/run1/bm_S10_L001_R2_001.fastq.gz --maxHashResizeThreads 2 -i /u/user/ref/cellranger/salmon/transcripts_index --tgMap tx2gene.txt; Starting program: /u/user/local/bin/salmon alevin -l ISR --chromium -p 4 -o BM_1/alevin -1 ./BM_1/run1/bm_S10_L001_R1_001.fastq.gz -2 ./BM_1/run1/bm_S10_L001_R2_001.fastq.gz --maxHashResizeThreads 2 -i /u/user/ref/cellranger/salmon/transcripts_index --tgMap tx2gene.txt; [Thread debugging using libthread_db enabled]; Using host libthread_db library ""/lib/x86_64-linux-gnu/libthread_db.so.1"".; warning: File ""/u/user/local/lib64/libstdc++.so.6.0.21-gdb.py"" auto-loading has been declined by your `auto-load safe; -path' set to ""$debugdir:$datadir/auto-load"".; To enable execution of this file add; add-auto-load-safe-path /u/user/local/lib64/libstdc++.so.6.0.21-gdb.py; line to your configuration file ""/u/user/.gdbinit"".; To completely disable this security protection add; set auto-load safe-path /; line to your configuration file ""/u/user/.gdbinit"".; For more information about this security protection see the; ""Auto-loading safe path"" section in the GDB manual. E.g., run from the shell:; info ""(gdb)Auto-loading safe path""; [New Thread 0x7fff7dbff700 (LWP 21437)]; [Thread 0x7fff7dbff700 (LWP 21437) exited]; Version Info: Could not resolve upgrade information in the alotted time.; Check for upgrades manually at https://combine-lab.github.io/salmon; [New Thread 0x7ffefcfff700 (LWP 21653)]; Logs will be written to BM_1/alevin/logs; [New Thread 0x7ffe7cffe700 (LWP 21654)]; [New Thread 0x7ffdfcffd700 (LWP 21655)]; [New Thread 0x7ffd7cffc700 (LWP 21656)]; ### salmon (single-cell-based) v0.10.3; #",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-396078627:1763,safe,safe,1763,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-396078627,1,['safe'],['safe']
Safety, the bam's header in another thread dealing with this issue); > ; > ```; > samtools view \; > -b \; > -@ 40 \; > -o SRR3212847.Aligned.SortedByCoord.NoHeader.bam \; > SRR3212847.Aligned.SortedByCoord.bam; > ; > samtools collate \; > -@ 40 \; > -o SRR3212847.Aligned.Shuffled.NoHeader.bam \; > SRR3212847.Aligned.SortedByCoord.NoHeader.bam; > ; > salmon quant \; > -t mRNA.fasta \; > -p 20 \; > -l A \; > -a SRR3212847.Aligned.Shuffled.NoHeader.bam \; > -o SRR3212847.Aligned.Shuffled.NoHeader; > ```; > ; > ```; > ; > ....; > ; > ; > [2021-01-08 12:42:10.700] [jointLog] [warning] ; > ; > WARNING: Detected suspicious pair --- ; > The names are different:; > read1 : SRR3212847.24133171; > read2 : SRR3212847.33911054; > The proper-pair statuses are inconsistent:; > read1 [SRR3212847.24133171] : no proper-pair; not mapped; matenot mapped; > ; > read2 : [SRR3212847.24133171] : proper-pair; mapped; matemapped; > ; > [2021-01-08 12:42:10.700] [jointLog] [warning] ; > ; > WARNING: Detected suspicious pair --- ; > The names are different:; > read1 : SRR3212847.33911054; > read2 : SRR3212847.30781941; > ; > Segmentation fault (core dumped); > ```; > ; > ### 3. Sorting with `samtools sort -n`; > ```; > samtools sort \; > -@ 40 \; > -n \; > -o SRR3212847.Aligned.SortedByName.bam \; > SRR3212847.Aligned.SortedByCoord.bam; > ; > salmon quant \; > -t mRNA.fasta \; > -p 20 \; > -l A \; > -a SRR3212847.Aligned.SortedByName.bam \; > -o SRR3212847.Aligned.SortedByName; > ```; > ; > ```; > Version Info: This is the most recent version of salmon.; > # salmon (alignment-based) v1.4.0; > # [ program ] => salmon ; > # [ command ] => quant ; > # [ targets ] => { mRNA.fasta }; > # [ threads ] => { 20 }; > # [ libType ] => { A }; > # [ alignments ] => { SRR3212847.Aligned.SortedByName.bam }; > # [ output ] => { SRR3212847.Aligned.SortedByName }; > Logs will be written to SRR3212847.Aligned.SortedByName/logs; > [2021-01-08 13:02:04.845] [jointLog] [info] setting maxHashResizeThreads to 20; > [2021-01,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/582#issuecomment-1343749456:2946,Detect,Detected,2946,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/582#issuecomment-1343749456,1,['Detect'],['Detected']
Safety," the most recent version of Salmon.; ### salmon (mapping-based) v0.8.2; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts }; ### [ threads ] => { 1 }; ### [ libType ] => { ISR }; ### [ mates1 ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/merged_fastq/R10001_D2B1WACXX.fastq.gz }; ### [ mates2 ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/merged_fastq/R10001_D2B1WACXX_read2.fastq.gz }; ### [ output ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test3/R10001_D2B1WACXX }; Logs will be written to /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test3/R10001_D2B1WACXX/logs; [1m[2017-03-29 14:51:11.533] [jointLog] [info] parsing read library format; [00m[1m[2017-03-29 14:51:11.545] [jointLog] [info] There is 1 library.; [00mterminate called without an active exception; /cm/local/apps/sge/var/spool/compute-061/job_scripts/110315: line 31: 54922 Aborted (core dumped) /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon quant -i /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts -p 1 -l ISR -1 ${FILE1} -2 ${FILE2} -o /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test3/${ID}; **** Job ends ****; Wed Mar 29 14:51:13 EDT 2017; ```. ### SGE email info example. ```; Job-array task 110315.1 (step6-salmon_test3.gsk_phaseII) Complete; User = lcollado; Queue = shared.q@compute-061.cm.cluster; Host = compute-061.cm.cluster; Start Time = 03/29/2017 14:51:09; End Time = 03/29/2017 14:51:13; User Time = 00:00:00; System Time = 00:00:02; Wallclock Time = 00:00:04; CPU = 00:00:02; Max vmem = 14.820G; Exit Status = 0; ```. ## 16 cores. ### Bash. ```bash; #!/bin/bash; #$ -cwd; #$ -l mem_free=2G,h_vmem=3G,h_fsize=100G; #$ -N step6-salmon_test4.gsk_phaseII; #$ -pe local 16; #$ -o ./logs/salmon_test4.$TASK_ID.txt; #$ -e",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-290516965:3009,Abort,Aborted,3009,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-290516965,1,['Abort'],['Aborted']
Safety,"**_I could be wrong here with my next line_** - [Based on Figure 1 of this paper, it looks to me as though quality trimming is done before adapter trimming](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6129281/figure/bty560-F1/). - [To quote Brian Bushnell (author of BBTools)]( http://seqanswers.com/forums/showpost.php?p=140819&postcount=5), . > It's best to do adapter-trimming first, then quality-trimming, because if you do quality-trimming first, sometimes adapters will be partially trimmed and become too short to be recognized as adapter sequence. When you run BBDuk with both quality-trimming and adapter-trimming in the same run, it will do adapter-trimming first, then quality-trimming. 2. I very well know that the advantage of using fastp is that it can do adapter trimming, etc in a automatic fashion - no need to provide external sequences (example adapter sequences). Yes, I know one can also provide a fasta file of adapters and fatsp will work off it. There are many fatsp issues in GH about adapter detection:. - fail to detect adpaters automatically - (https://github.com/OpenGene/fastp/issues/222 and https://github.com/OpenGene/fastp/issues/205). - [incorrect automatic adapter detection](https://github.com/OpenGene/fastp/issues/240). - [inconsistent behavior with different runs](https://github.com/OpenGene/fastp/issues/231). 3. When I see the above, I am bit skeptical using fastp for qc/adapter trimming. . After lot of trials with bbduk and fastp, I have decided to use bbduk and bbmap for my high throughput analysis. Below, I explain my reasoning behind those choices: . **_```Note - edited this on 02-Apr-2020 to have the correct order of operations ```_** . 1. **_STEP 1 - run bbmap.sh on raw fatsq file to remove contaminants as appropriate (rRNA, mitochondrial, chloroplast)_**; - You have alluded to the importance of removing contaminants [in this post](https://github.com/COMBINE-lab/salmon/issues/160#issuecomment-334762498); >However, the other thing to try is",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-597393209:1409,detect,detection,1409,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-597393209,2,['detect'],['detection']
Safety,". Here is the logs. ## Default setting ; `salmon alevin -l ISR -1 ../clean/sample_S1_L001_R1_001.fastq -2 ../clean/sample_S1_L001_R2_001.fastq --chromiumV3 -i ../../dna/00.ref_genome/sample/salmon_index_allmRNA -p 40 -o test_alevin_allmRNA --tgMap ../../dna/00.ref_genome/sample/alltxp2gene.tsv`. > [2021-01-25 16:22:09.565] [alevinLog] [info] Found 43030 transcripts(+0 decoys, +0 short and +0 duplicate names in the index); [2021-01-25 16:22:09.615] [alevinLog] [info] Filled with 43030 txp to gene entries; [2021-01-25 16:22:09.620] [alevinLog] [info] Found all transcripts to gene mappings; [2021-01-25 16:22:09.631] [alevinLog] [info] Processing barcodes files (if Present); [2021-01-25 16:26:35.067] [alevinLog] [info] Done barcode density calculation.; [2021-01-25 16:26:35.067] [alevinLog] [info] # Barcodes Used: 188934609 / 188934609.; [2021-01-25 16:26:42.979] [alevinLog] [info] Knee found left boundary at 21; [2021-01-25 16:27:05.707] [alevinLog] [warning] Gauss Prediction 4969 Too far from knee prediction skipping it; [2021-01-25 16:27:05.707] [alevinLog] [info] Learned InvCov: 556.394 normfactor: 9159.58; [2021-01-25 16:27:05.707] [alevinLog] [info] Total 222(has 201 low confidence) barcodes; [2021-01-25 16:27:06.573] [alevinLog] [info] Done True Barcode Sampling; [2021-01-25 16:27:07.383] [alevinLog] [warning] Total **96.7029% reads will be thrown away** because of noisy Cellular barcodes.; [2021-01-25 16:27:07.412] [alevinLog] [info] Done populating Z matrix; [2021-01-25 16:27:07.414] [alevinLog] [info] Total 3667 CB got sequence corrected; [2021-01-25 16:27:07.414] [alevinLog] [info] Done indexing Barcodes; [2021-01-25 16:27:07.414] [alevinLog] [info] Total Unique barcodes found: 3896665; [2021-01-25 16:27:07.414] [alevinLog] [info] Used Barcodes except Whitelist: 3667; [2021-01-25 16:27:07.498] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify; [2021-01-25 16:27:07.498] [alevinLog] [info] parsing read library format; [2021-01-25 16:30:54.542]",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/340#issuecomment-766311567:2340,Predict,Prediction,2340,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/340#issuecomment-766311567,2,"['Predict', 'predict']","['Prediction', 'prediction']"
Safety,"/PMC6129281/figure/bty560-F1/). - [To quote Brian Bushnell (author of BBTools)]( http://seqanswers.com/forums/showpost.php?p=140819&postcount=5), . > It's best to do adapter-trimming first, then quality-trimming, because if you do quality-trimming first, sometimes adapters will be partially trimmed and become too short to be recognized as adapter sequence. When you run BBDuk with both quality-trimming and adapter-trimming in the same run, it will do adapter-trimming first, then quality-trimming. 2. I very well know that the advantage of using fastp is that it can do adapter trimming, etc in a automatic fashion - no need to provide external sequences (example adapter sequences). Yes, I know one can also provide a fasta file of adapters and fatsp will work off it. There are many fatsp issues in GH about adapter detection:. - fail to detect adpaters automatically - (https://github.com/OpenGene/fastp/issues/222 and https://github.com/OpenGene/fastp/issues/205). - [incorrect automatic adapter detection](https://github.com/OpenGene/fastp/issues/240). - [inconsistent behavior with different runs](https://github.com/OpenGene/fastp/issues/231). 3. When I see the above, I am bit skeptical using fastp for qc/adapter trimming. . After lot of trials with bbduk and fastp, I have decided to use bbduk and bbmap for my high throughput analysis. Below, I explain my reasoning behind those choices: . **_```Note - edited this on 02-Apr-2020 to have the correct order of operations ```_** . 1. **_STEP 1 - run bbmap.sh on raw fatsq file to remove contaminants as appropriate (rRNA, mitochondrial, chloroplast)_**; - You have alluded to the importance of removing contaminants [in this post](https://github.com/COMBINE-lab/salmon/issues/160#issuecomment-334762498); >However, the other thing to try is simply to align one of these samples to the genome with a tool like STAR or HISAT2 and look at their mapping rate to known features. If it's similar, then the other reads could be accounted for by ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-597393209:1591,detect,detection,1591,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-597393209,2,['detect'],['detection']
Safety,"/alevin -1 ./BM_1/run1/bm_S10_L001_R1_001.fastq.gz -2 ./BM_1/run1/bm_S10_L001_R2_001.fastq.gz --maxHashResizeThreads 2 -i /u/user/ref/cellranger/salmon/transcripts_index --tgMap tx2gene.txt; [Thread debugging using libthread_db enabled]; Using host libthread_db library ""/lib/x86_64-linux-gnu/libthread_db.so.1"".; warning: File ""/u/user/local/lib64/libstdc++.so.6.0.21-gdb.py"" auto-loading has been declined by your `auto-load safe; -path' set to ""$debugdir:$datadir/auto-load"".; To enable execution of this file add; add-auto-load-safe-path /u/user/local/lib64/libstdc++.so.6.0.21-gdb.py; line to your configuration file ""/u/user/.gdbinit"".; To completely disable this security protection add; set auto-load safe-path /; line to your configuration file ""/u/user/.gdbinit"".; For more information about this security protection see the; ""Auto-loading safe path"" section in the GDB manual. E.g., run from the shell:; info ""(gdb)Auto-loading safe path""; [New Thread 0x7fff7dbff700 (LWP 21437)]; [Thread 0x7fff7dbff700 (LWP 21437) exited]; Version Info: Could not resolve upgrade information in the alotted time.; Check for upgrades manually at https://combine-lab.github.io/salmon; [New Thread 0x7ffefcfff700 (LWP 21653)]; Logs will be written to BM_1/alevin/logs; [New Thread 0x7ffe7cffe700 (LWP 21654)]; [New Thread 0x7ffdfcffd700 (LWP 21655)]; [New Thread 0x7ffd7cffc700 (LWP 21656)]; ### salmon (single-cell-based) v0.10.3; ### [ program ] => salmon; ### [ command ] => alevin; ### [ libType ] => { ISR }; ### [ chromium ] => { }; ### [ threads ] => { 4 }; ### [ output ] => { BM_1/alevin }; ### [ mates1 ] => { ./BM_1/run1/bm_S10_L001_R1_001.fastq.gz }; ### [ mates2 ] => { ./BM_1/run1/bm_S10_L001_R2_001.fastq.gz }; ### [ maxHashResizeThreads ] => { 2 }; ### [ index ] => { /u/user/ref/cellranger/salmon/transcripts_index }; ### [ tgMap ] => { tx2gene.txt }. [2018-06-10 16:07:09.798] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [New ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-396078627:2275,safe,safe,2275,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-396078627,1,['safe'],['safe']
Safety,"07f8599d1d000); /lib64/ld-linux-x86-64.so.2 (0x00007f859b286000); libdl.so.2 => /lib/x86_64-linux-gnu/libdl.so.2 (0x00007f8599b19000); libstdc++.so.6 => /u/user/local/lib64/libstdc++.so.6 (0x00007f859979f000); ```. The linux version and g++ version are listed below:; ```; cat /proc/version; Linux version 4.9.0-0.bpo.6-amd64 (debian-kernel@lists.debian.org) (gcc version 4.9.2 (Debian 4.9.2-10+deb8u1) ) #1 SMP Debian 4.9.82-1+deb9u3~bpo8+1 (2018-03-22). ~/data/PCSI/PC10X/paper/pbmc$ g++ -v; Using built-in specs.; COLLECT_GCC=g++; COLLECT_LTO_WRAPPER=/u/user/local/libexec/gcc/x86_64-unknown-linux-gnu/5.4.0/lto-wrapper; Target: x86_64-unknown-linux-gnu; Configured with: ./configure --prefix=/u/user/local; Thread model: posix; gcc version 5.4.0 (GCC); ```. ```; [Thread debugging using libthread_db enabled]; Using host libthread_db library ""/lib/x86_64-linux-gnu/libthread_db.so.1"".; warning: File ""/u/user/local/lib64/libstdc++.so.6.0.21-gdb.py"" auto-loading has been declined by your `auto-load safe-path' set to ""$debugdir:$datadir/auto-load"".; To enable execution of this file add; add-auto-load-safe-path /u/user/local/lib64/libstdc++.so.6.0.21-gdb.py; line to your configuration file ""/u/user/.gdbinit"".; To completely disable this security protection add; set auto-load safe-path /; line to your configuration file ""/u/user/.gdbinit"".; For more information about this security protection see the; ""Auto-loading safe path"" section in the GDB manual. E.g., run from the shell:; info ""(gdb)Auto-loading safe path""; [New Thread 0x7fff7e0f4700 (LWP 14274)]; Version Info: ### A newer version of Salmon is available. ####; [Thread 0x7fff7e0f4700 (LWP 14274) exited]; ###; The newest version, available at https://github.com/COMBINE-lab/salmon/releases; contains new features, improvements, and bug fixes; please upgrade at your; earliest convenience.; ###; [New Thread 0x7fff7d273700 (LWP 14275)]; Logs will be written to pbmc4k/alevin/logs; [New Thread 0x7ffefc3f1700 (LWP 14276)]; [New Thread",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-395836214:2196,safe,safe-path,2196,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-395836214,1,['safe'],['safe-path']
Safety,2. Shuffling a headless bam file with `samtools collate`; (I think I saw something about the bam's header in another thread dealing with this issue); ```; samtools view \; -b \; -@ 40 \; -o SRR3212847.Aligned.SortedByCoord.NoHeader.bam \; SRR3212847.Aligned.SortedByCoord.bam. samtools collate \; -@ 40 \; -o SRR3212847.Aligned.Shuffled.NoHeader.bam \; SRR3212847.Aligned.SortedByCoord.NoHeader.bam. salmon quant \; -t mRNA.fasta \; -p 20 \; -l A \; -a SRR3212847.Aligned.Shuffled.NoHeader.bam \; -o SRR3212847.Aligned.Shuffled.NoHeader; ```. ```. .... [2021-01-08 12:42:10.700] [jointLog] [warning] . WARNING: Detected suspicious pair --- ; The names are different:; read1 : SRR3212847.24133171; read2 : SRR3212847.33911054; The proper-pair statuses are inconsistent:; read1 [SRR3212847.24133171] : no proper-pair; not mapped; matenot mapped. read2 : [SRR3212847.24133171] : proper-pair; mapped; matemapped. [2021-01-08 12:42:10.700] [jointLog] [warning] . WARNING: Detected suspicious pair --- ; The names are different:; read1 : SRR3212847.33911054; read2 : SRR3212847.30781941. Segmentation fault (core dumped); ```. ### 3. Sorting with `samtools sort -n`; ```; samtools sort \; -@ 40 \; -n \; -o SRR3212847.Aligned.SortedByName.bam \; SRR3212847.Aligned.SortedByCoord.bam. salmon quant \; -t mRNA.fasta \; -p 20 \; -l A \; -a SRR3212847.Aligned.SortedByName.bam \; -o SRR3212847.Aligned.SortedByName; ```. ```; Version Info: This is the most recent version of salmon.; # salmon (alignment-based) v1.4.0; # [ program ] => salmon ; # [ command ] => quant ; # [ targets ] => { mRNA.fasta }; # [ threads ] => { 20 }; # [ libType ] => { A }; # [ alignments ] => { SRR3212847.Aligned.SortedByName.bam }; # [ output ] => { SRR3212847.Aligned.SortedByName }; Logs will be written to SRR3212847.Aligned.SortedByName/logs; [2021-01-08 13:02:04.845] [jointLog] [info] setting maxHashResizeThreads to 20; [2021-01-08 13:02:04.845] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatib,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/582#issuecomment-756727212:2731,Detect,Detected,2731,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/582#issuecomment-756727212,1,['Detect'],['Detected']
Safety,"5.251] [alevinLog] [info] Done True Barcode Sampling; [2021-01-23 11:07:56.200] [alevinLog] [info] Total **49.0191% reads will be thrown away** because of noisy Cellular barcodes.; [2021-01-23 11:07:57.144] [alevinLog] [info] Done populating Z matrix; [2021-01-23 11:07:57.172] [alevinLog] [info] Total 35787 CB got sequence corrected; [2021-01-23 11:07:57.177] [alevinLog] [info] Done indexing Barcodes; [2021-01-23 11:07:57.177] [alevinLog] [info] Total Unique barcodes found: 3896665; [2021-01-23 11:07:57.177] [alevinLog] [info] Used Barcodes except Whitelist: 35219; [2021-01-23 11:07:57.360] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify; .... > {; ""total_reads"": 188934609,; ""reads_with_N"": 0,; ""noisy_cb_reads"": 92614076,; ""noisy_umi_reads"": 17028,; ""used_reads"": 96303505,; ""mapping_rate"": 19.451325087824434,; ""reads_in_eqclasses"": 36750285,; ""total_cbs"": 3896665,; ""used_cbs"": 47725,; ""initial_whitelist"": 11511,; ""low_conf_cbs"": 995,; ""num_features"": 5,; ""no_read_mapping_cbs"": 70,; ""final_num_cbs"": 8324,; ""deduplicated_umis"": 19613485,; ""mean_umis_per_cell"": 2356,; ""mean_genes_per_cell"": 1120; }. ## I'm wondering that ; 1. how can I use as much reads as possible and improve the mapping rate.; 2. will the 150bp reads R1 affect the pipeline, and if it will, how can I make it to 28bp. By the way, the cellranger result shows that reads map to Transcriptome is low, but reads mapped to Genome is 85%. Reads Mapped to Genome | 85.2%; -- | --; Reads Mapped Confidently to Genome | 45.8%; Reads Mapped Confidently to Intergenic Regions | 11.0%; Reads Mapped Confidently to Intronic Regions | 4.2%; Reads Mapped Confidently to Exonic Regions | 30.6%; Reads Mapped Confidently to Transcriptome | 25.3%; Reads Mapped Antisense to Gene | 0.9%. Estimated Number of Cells | 7,938; -- | --; Fraction Reads in Cells | 73.1%; Mean Reads per Cell | 23,801; Median Genes per Cell | 1,076; Total Genes Detected | 17,492; Median UMI Counts per Cell | 2,155. Best wishes,; Matthew",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/340#issuecomment-766311567:9383,Detect,Detected,9383,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/340#issuecomment-766311567,1,['Detect'],['Detected']
Safety,"7-29 15:58:39.034] [jointLog] [info] Usage of --validateMappings,; > without --hardFilter implies use of range factorization.; > rangeFactorizationBins is being set to 4; > [2019-07-29 15:58:39.034] [jointLog] [info] Usage of --validateMappings; > implies a default consensus slack of 0.2. Setting consensusSlack to 0.2.; > [2019-07-29 15:58:39.034] [jointLog] [info] parsing read library format; > [2019-07-29 15:58:39.034] [jointLog] [error] Failed to successfully parse; > any complete read libraries. Please make sure you provided arguments; > properly to -1, -2 (for paired-end libraries) or -r (for single-end; > libraries), and that the library format option (-l) *comes before* the read; > libraries.; >; > On Mon, Jul 29, 2019 at 4:06 PM Avi Srivastava <notifications@github.com>; > wrote:; >; >> Oh Sorry about that what I meant was the salmon.log file or the the; >> meta-info.json file created by salmon in the output directory. You can; >> check what files salmon is detecting it seems there are 12 files in the; >> mate1 and 13 files in the mate2. Can you confirm there are 13 pairs of file; >> in that directory and their regex is same as you are using ? Can you also; >> try putting the names of the file instead * as regex ?; >>; >> —; >> You are receiving this because you were mentioned.; >> Reply to this email directly, view it on GitHub; >> <https://github.com/COMBINE-lab/salmon/issues/408?email_source=notifications&email_token=AEHDXAA5DHKAZKVCZY5N7ULQB5ZXXA5CNFSM4IGU4ZTKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOD3CIG3I#issuecomment-516195181>,; >> or mute the thread; >> <https://github.com/notifications/unsubscribe-auth/AEHDXAHE56TJTIQFQDFDGMDQB5ZXXANCNFSM4IGU4ZTA>; >> .; >>; >; >; > --; > Sara E. Boles, MS; > PhD Candidate | Whitehead Lab; > Pharmacology and Toxicology Graduate Group; > Department of Environmental Toxicology; > University of California, Davis, CA 95616; > http://whiteheadresearch.wordpress.com/; > https://sites.google.com/a/ucdavi",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/408#issuecomment-516521791:3519,detect,detecting,3519,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/408#issuecomment-516521791,1,['detect'],['detecting']
Safety,"> And for us, who have blocked download on a computational cluster `cmake` silently continues even when `scripts/fetchRapMap.sh` failed (see error code `403` below). Dists downloading their own dependencies is also forbidden in package managers such as FreeBSD ports and pkgsrc (which is cross-platform and I personally use on Mac, NetBSD, and RHEL). Trusting upstream scripts to pull stuff off the Internet is a security risk, so the package managers perform and validate (via checksum) all downloads in a separate stage. It would be nice not to have to hack out the download code from a build system in order to create and maintain a package.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/19#issuecomment-989326040:422,risk,risk,422,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/19#issuecomment-989326040,1,['risk'],['risk']
Safety,"> Hi @citron96,; > ; > This is what is covered in #496. This is because an upstream package changed the SHA of their _tagged_ releases (which is really not ideal). Are you pulling from the master branch? If you pull from develop, everything should build. I can pull the changes that fix this into master. Unfortunately, to avoid changing the signatures of _our_ tagged releases, I can't push this change back to older releases.; > ; > I think @nadyawilliams may also have a patch for the CMakeLists.txt file, which, perhaps, can be shared?. thank you so much.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/497#issuecomment-604461264:323,avoid,avoid,323,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/497#issuecomment-604461264,1,['avoid'],['avoid']
Safety,"> In STAR there is an option to use stranded alignment (--readStrand, which can take ""Unstranded"", ""Forward"", or ""Reverse""). For the pipeline I'm building it would be ideal if I didn't have to specify the strandedness of the library as I'm not the one preparing the samples and it's not always easy to get that information from the scientist in the lab. As such, it would be great if I can use the default strandedness argument to STAR (""Unstranded"") and let salmon ""do the right thing"" by letting it choose the libType for me. With that in mind, if I let salmon choose for me (-l A) am I risking throwing out any data?. Right, so in this case, STAR should produce all highest-scoring valid alignments regardless of orientation. Then, when running salmon with `-l A` it will detect the strandedness and only discard alignments compatible with the appropriate strand type (which may be unstranded if that is the protocol). Salmon is pretty conservative about reporting when there is any ambiguity. By default, if the strand bias is stronger than a few percent. In a stranded protocol, it will report and if it infers more than a few percent of fragments no having a valid alignment. So you can always double-check samples where the strandedness is at all ambiguous. > In addition, if a transcript was aligned in a unstranded manner and ended up aligning to the wrong location due to ambiguity between the positive orientation of one transcript and the negative orientation of another, can salmon correct this by reassigning it to the right transcript based on the joint probability of all the other alignments (if you can't tell I'm at the edge of my BS zone)?. If there is not an alignment to the correct location _in addition to_ the wrong location, then no. If you run salmon in alignment mode, it will assign each fragment probabilistically to the set of transcripts to which it aligns. There is, by definition, a probability of 0 for a fragment being assigned to a location where it doesn't align.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/590#issuecomment-733417813:589,risk,risking,589,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/590#issuecomment-733417813,2,"['detect', 'risk']","['detect', 'risking']"
Safety,"> Thanks!! Looking into it, replied. Hi,. I am having a similar issue when running salmon 1.4 on stranded single end data. Transcript count is over 4,000 for certain genes when analyzed by STAR, but salmon does not detect the transcript. Is there any newer version of this branch or suggested configuration that I can use to test my data? Thank you.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/218#issuecomment-1145373488:215,detect,detect,215,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/218#issuecomment-1145373488,1,['detect'],['detect']
Safety,"> Yes that's one aspect. But also, Salmon uses CIGAR to evaluate alignment probability in alignment quantification mode no?. Indeed. > And with just RapMap output you would lose other information that Salmon uses to determine likely fragment assignment?. You would lose information (in the format of a CIGAR string) that Salmon uses in alignment mode, but not any information, I think, that Salmon uses in quasi-mapping-based mode (though one would incur a non-trivial performance hit for filtering the quasi-mappings through file / disk rather than dealing with them directly in memory as Salmon normally does). > With UMI's you can deduplicate fragments before inferring where they were likely to come from. Ideally you would deduplicate the reads directly based on UMI, then you wouldn't have to think about PCR duplication in the quantification. But of course keeping a hash of all reads in a FASTQ and accounting for dequencing errors wouldn't be really tractable.. I guess this is the real question I have. Specifically, what is the true computational burden to detect and eliminate duplicates using UMIs? In theory, the reads must (1) map to the same location and (2) have the same UMI tag. How often would one expect the UMI tag to be modified / corrupted / etc.? Would you have to search all 1 or 2 hamming distance neighbors to detect duplicates reliably? Is an equivalence class a sufficient proxy for ""mapping to the same location"", or do we also care that e.g. the position of the fragment within each transcript is a duplicate as well? These are the main questions that are preventing me from implementing the ""obvious solution"".",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/108#issuecomment-269001682:1068,detect,detect,1068,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/108#issuecomment-269001682,2,['detect'],['detect']
Safety,"@Gaura that definitely seems promising! A few questions:. -Is quantification via alevin-fry (rather than alevin itself) mandatory here? I ask since your run seems successful whereas my full alevin run had a very poor BC detection and mapping rate. -I see you specified `-l A` - can you comment on what the detected/correct library type was here?. -I assume all of this will also work in conjunction with `--expectCells` or `--keepCBFraction` if those parameters were needed? Your ~7k cells detected is very close to the published number _post-filtering_, but no similar filtering has been done here yet. My guess is that the proportion of cells that pass these filters will be higher for alevin, but we may still be under-estimating the number of real cells by a little bit here. . -Is there any prospect of dealing with frameshift errors in the barcode detection step? Or is that out of scope?. Thanks!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-987910445:220,detect,detection,220,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-987910445,4,['detect'],"['detected', 'detection']"
Safety,"@Gaura this sort of frameshift in the barcodes is a known issue, and can be computationally challenging (at least for existing methods). zUMIs, for example, does an automatic barcode detection based on fixed barcode positions like we're doing here with alevin, so it would mis-detect cells like the shifted ones you pasted above. For SPLiT-seq, we do know exactly which barcodes go into the wells, however, so it is technically possible to restrict based on all possible known combinations of barcodes instead and be more positionally flexible. But deciding how many indel bases are allowable, and presumably doing multiple passes through the data to establish an include-list could be time-consuming. Further, the zUMIs developer rightly mentions [in this thread](https://github.com/sdparekh/zUMIs/issues/63) that there are likely going to be _many_ unused barcode combinations this way, so lots of time could be spent looking for ""cells"" that don't actually exist in the data. The authors of the paper from which our test dataset was derived describe in their methods using a Drop-seq computational framework, so I'm not sure which approach theirs is more similar to. . The simplest approach here is certainly the automatic detection, but it will come at the cost of losing meaningful reads to frameshift errors. . My guess is this falls well out of the scope of alevin, but if you're interested in improving on that, there may be a middle ground between the two approaches above, one that I'm not sure if your group or others have attempted for other methods: we could essentially do a 2-pass barcode detection. The first pass would restrict based on positions like we're already doing, and establish an include-list of possible barcodes seen in the data. Then we could pass through the barcode sequences a second time, looking only for those sequence combinations, but allowing 1-2bp flexibility in the positions they occur, potentially rescuing some of the ones missed during the first pass. This",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-985554883:183,detect,detection,183,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-985554883,4,['detect'],"['detect', 'detection']"
Safety,"@deevdevil88,. As an update to this, you can now use the alevin -> [alevin-fry](https://alevin-fry.readthedocs.io/en/latest/) pipeline to quantify with different strategies for filtering. If you're using a technology with an external permit list (like 10x chromium), you can recover and quantify unfiltered cells as well as of version 0.2.0 using the `--unfiltered-pl` flag. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/538#issuecomment-825059035:275,recover,recover,275,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/538#issuecomment-825059035,1,['recover'],['recover']
Safety,"@rbenel,. If you are using a version prior to 0.14.0, you will also have to pass `--no-version-check` to avoid contamination of stdout by the versioning message.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/38#issuecomment-507241631:105,avoid,avoid,105,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/38#issuecomment-507241631,1,['avoid'],['avoid']
Safety,"@rob-p @mdshw5 ; Thanks for the quick response! For this specific run I am running an older version.; However, even with the `--no-version-check` flag I can't seem to pipe `writeMappings` to samtools (same command as above). ```; (mapping-based mode) Exception : [unrecognised option '-b'].; Please be sure you are passing correct options, and that you are running in the intended mode.; alignment-based mode is detected and enabled via the '-a' flag. Exiting.; ```. On the other hand, `--writeMappings=output.sam` works fine. I would just like to save the hassle of converting all of the .sam files to .bam files following the run ...",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/38#issuecomment-507271061:412,detect,detected,412,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/38#issuecomment-507271061,1,['detect'],['detected']
Safety,"@rob-p can you elaborate on this a bit more: . > The effect of --minScoreFraction depends, to some extent, on how you set the match/mismatch/gap parameters. With the default parameters, 0.9 is actually higher than 90% sequence identity, because the default mismatch penalty is twice the match score. If you assume only matches and mismatches, then the --minScoreFraction you want to set is the one such that x * (match_score * read_length) <= (match_score * read_length) - (m * read_length * match_score) + (m * read_length * mismatch_penalty), where m is the mismatch fraction (0.1 in your case). So, for example, if the match_score is 2 and mismatch penalty is -4, and the read length is 100, you want to set it so that: x * 200 = 200 - (0.1 * 100 * 2) + (0.1 * 100 * -4) = 200 - 20 - 40 = 140 so, the appropriate x would be ~0.7. Of course, if you want to make the calculation simple, you can set the match score to 1 and mismatch penalty to 0, and then the interpretation (modulo gaps) is straightforward (and 0.9 means what you want). Would the two parameter sets mentioned above have the same effect assuming read length 100?. Also, it says Alevin has a default minScoreFraction of 0.87. Would it be safe to assume differentiating between isoforms with Alevin is a similar problem to differentiating between orthologous genes in metagenomics/transcriptomics?. Which parameters would be relevant to control for this?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/330#issuecomment-2249029869:1206,safe,safe,1206,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/330#issuecomment-2249029869,2,['safe'],['safe']
Safety,"A BAM file can contain both paired and single-end reads. I haven't been using Salmon long enough to know whether it supports a mixture of paired and single reads. If it doesn't, then there's no issue, because you know immediately after reading the first mapped read whether it is paired. If Salmon does support a mixture of paired and single reads, then you have a problem, because you could have, for example, a BAM file with 10 million single-end reads and then one paired set of 2 reads. In other words, you can't conclude a BAM file is single-end only except by checking every read in the file. I think this means that in the worst case, `--libtype A` would require 2 passes through the BAM file, once to check for paired reads and then again to actually run the quantification. Here's a strategy that might work without 2 passes, possibly at the cost of increased peak memory usage. The release notes say that `--libType A` uses the first 50k reads to infer the lib type. So, read from the BAM file until enough read pairs (25k pairs?) have been read, and then infer the paired library type from those. However, if the first 100k reads don't yield 25k pairs, then just infer the orientation of the unpaired/first mate reads. In this case, now feed the input into 3 separate runs of the quantification at once, one for each possible paired library type. For example, if the first-read orientation is inferred as `SF`, then the 3 possible paired library types are `ISF`, `MSF`, and `OSF`. Run the entire file through each of these 3 quantifaction runs, and then decide afterward which one turned out to be correct (probably whichever one counted the most concordantly paired mates?). Then kill the other 2 runs and finish running the chosen one through the rest of the algorithm. That should avoid having to make multiple passes through the input, but you will triple some component of the memory usage up to the point where the two wrong runs are killed.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/79#issuecomment-241900687:1795,avoid,avoid,1795,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/79#issuecomment-241900687,1,['avoid'],['avoid']
Safety,"A bit delayed, but this relates to the questions I've been asking on the salmon gitter. . First, it's worth pointing out that the new 10x (v2) sequencing is a lot more like other bead methods, where (i) index reads (i7/i5) are for labelling biological samples (ii) read1 contains the combined cell and molecular/UMI barcodes (ii) read2 is the transcript 3' read. So it seems there is now some data format convergence. Either way, I'd guess that ongoing iterations of the high throughput platforms will keep one read for the transcript 3', reserving the other 2 or 3 reads for some combination of the sample, cell and molecular barcodes. . Before thinking about how to best collapse UMIs, there's also the issue of how best to QC the barcodes and beads. Jim Namesh has [some functions](http://mccarrolllab.com/wp-content/uploads/2016/03/Drop-seqAlignmentCookbookv1.2Jan2016.pdf); as does [Vasilis Ntranos](https://github.com/pachterlab/scRNA-Seq-TCC-prep/blob/master/README.md). Arguably this has nothing to do with salmon/kallisto though I think the kallisto guys were smart to include it. It's a good filter even if only for speeding things up. Then it's really what might be the most appropriate demultiplexing of fastqs to allow compatibility between tecnhiques, I guess. I quite like how the kallisto workflow ends up with a fastq per cell together with a matching UMI file. Then at the very least one can ignore the UMIs (perhaps going with what @vals suggests). Not sure if that's helpful. But thought to chime in as somebody we would love to see salmon working on the high throughput single-cell platforms that have sample, cell and molecular barcodes. Even if only to test how worthwhile UMIs genuinely are for most applications. This may be a controversial comment, but I suspect for me UMIs will largely end up the same way as spike-ins: useful for quantifying endogenous RNA recovered per cell but perhaps not all that useful beyond that for low read depth single-cell signature profiling.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/93#issuecomment-265619589:1912,recover,recovered,1912,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/93#issuecomment-265619589,1,['recover'],['recovered']
Safety,"Also getting segmentation fault. Any progress on this? This is salmon v1.3.0, installed with conda or using the binary, running in slurm. I do not get a segmentation fault if I pass only a single file, but I do if I pass two files. ```; $ ./src/salmon-latest_linux_x86_64/bin/salmon quant --threads $(nproc) --libType U -t GRCh38_latest_rna.fa -a data/processed/bwa-mem/SRR10571655.sam data/processed/bwa-mem/SRR10571656.sam -o _tmp/ ; Version Info Exception: server did not respond before timeout; # salmon (alignment-based) v1.3.0; # [ program ] => salmon ; # [ command ] => quant ; # [ threads ] => { 32 }; # [ libType ] => { U }; # [ targets ] => { GRCh38_latest_rna.fa }; # [ alignments ] => { data/processed/bwa-mem/SRR10571655.sam data/processed/bwa-mem/SRR10571656.sam }; # [ output ] => { _tmp/ }; Logs will be written to _tmp/logs; [2020-10-12 16:13:21.969] [jointLog] [info] setting maxHashResizeThreads to 32; [2020-10-12 16:13:21.969] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; Library format { type:single end, relative orientation:none, strandedness:unstranded }; [2020-10-12 16:13:21.969] [jointLog] [info] numQuantThreads = 26; parseThreads = 6; Checking that provided alignment files have consistent headers . . . done; Populating targets from aln = ""data/processed/bwa-mem/SRR10571655.sam"", fasta = ""GRCh38_latest_rna.fa"" . . .done; [2020-10-12 16:13:26.979] [jointLog] [info] replaced 5 non-ACGT nucleotides with random nucleotides. processed 103000000 reads in current round[1] 1994 segmentation fault (core dumped) ./src/salmon-latest_linux_x86_64/bin/salmon quant --threads $(nproc) --libTyp; ```. Always at 103000000 reads.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/271#issuecomment-707334655:490,timeout,timeout,490,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/271#issuecomment-707334655,1,['timeout'],['timeout']
Safety,"And for us, who have blocked download on a computational cluster `cmake` silently continues even when `scripts/fetchRapMap.sh` failed (see error code `403` below). That is bad. Please propagate the error back to `cmake` so it dies immediately. Actually, remove the download altogether. Improve Requirements documentation and put a link to it there instead. ```; $blah/salmon-0.10.2 $ cmake -DCMAKE_VERBOSE_MAKEFILE:BOOL=ON -DBoost_NO_BOOST_CMAKE=BOOL:ON -DFETCH_BOOST=TRUE CMakeLists.txt; -- The C compiler identification is GNU 7.3.0; -- The CXX compiler identification is GNU 7.3.0; -- Check for working C compiler: /apps/gentoo/usr/bin/cc; -- Check for working C compiler: /apps/gentoo/usr/bin/cc -- works; -- Detecting C compiler ABI info; -- Detecting C compiler ABI info - done; -- Detecting C compile features; -- Detecting C compile features - done; -- Check for working CXX compiler: /apps/gentoo/usr/bin/c++; -- Check for working CXX compiler: /apps/gentoo/usr/bin/c++ -- works; -- Detecting CXX compiler ABI info; -- Detecting CXX compiler ABI info - done; -- Detecting CXX compile features; -- Detecting CXX compile features - done; Making Release build; running $blah/salmon-0.10.2/scripts/fetchRapMap.sh 2>&1; % Total % Received % Xferd Average Speed Time Time Time Current; Dload Upload Total Spent Left Speed; 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0; curl: (56) Received HTTP code 403 from proxy after CONNECT; -- Found ZLIB: /apps/gentoo/usr/lib/libz.a (found version ""1.2.11""); -- Looking for lzma_auto_decoder in /apps/gentoo/usr/lib/liblzma.a; -- Looking for lzma_auto_decoder in /apps/gentoo/usr/lib/liblzma.a - found; -- Looking for lzma_easy_encoder in /apps/gentoo/usr/lib/liblzma.a; -- Looking for lzma_easy_encoder in /apps/gentoo/usr/lib/liblzma.a - found; -- Looking for lzma_lzma_preset in /apps/gentoo/usr/lib/liblzma.a; -- Looking for lzma_lzma_preset in /apps/gentoo/usr/lib/liblzma.a - found; -- Found LibLZMA: /apps/gentoo/usr/include (found version ""5.2.3""); Fo",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/19#issuecomment-399775387:713,Detect,Detecting,713,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/19#issuecomment-399775387,8,['Detect'],['Detecting']
Safety,"As an alternative, documenting the *geometry* format for specifying custom barcodes would be helpful. This seems to avoid the barcode length issue. From what I can tell, the format is `<readNum>[start-end]`, i.e. for my case:. --umi-geometry '1[28-35]' --bc-geometry '1[1-27]' --read-geometry '2[1-end]'",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/445#issuecomment-777881915:116,avoid,avoid,116,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/445#issuecomment-777881915,1,['avoid'],['avoid']
Safety,"Cool, glad to hear that the above binary works for you. The binary on the release page was for linux that's why you were getting that error. As we progress, I'll keep updating the version for Macosx here, until the conda build is fixed for Osx. Also I've update the name of the file above just to avoid the confusion, thanks for the tip .",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/260#issuecomment-412663036:297,avoid,avoid,297,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/260#issuecomment-412663036,1,['avoid'],['avoid']
Safety,"Dear @juugii,. Thanks for reporting these. Regarding . (1) : Yes, it is possible to skip the version check. Simply place `--no-version-check` before any command. For example:. ```; salmon --no-version-check index <... parameters for indexing>; ```. and . ```; salmon --no-version-check quant <... parameters for quantification>; ```; This will let you avoid the network timeout. Regarding issue (2), it's difficult to say what's happening without seeing the data. I'm looping in @k3yavi to help take a look into this.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/264#issuecomment-410255823:352,avoid,avoid,352,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/264#issuecomment-410255823,2,"['avoid', 'timeout']","['avoid', 'timeout']"
Safety,"Dear @rob-p, . Hope you are well. . Thank you so much for the time and effort that you put in for helping me. . I finally built full decoy index with more RAM allocation to 35Gb (found this in the previous posts) and successfully ran salmon quant on the samples with full decoy index. . The mapped rate of these samples with decoy sequence included, and the mapping rate dropped slightly than salmon without decoy sequence. I think this is expected, as this is to avoid spurious alignments to annotated transcripts (more conservative approach?). ![image](https://user-images.githubusercontent.com/50330051/102348292-95297380-3f99-11eb-9e7a-13b292bf0b35.png); ![image](https://user-images.githubusercontent.com/50330051/102348333-abcfca80-3f99-11eb-8b1a-079463d9af06.png); ![image](https://user-images.githubusercontent.com/50330051/102348400-c4d87b80-3f99-11eb-8859-b8fe0fbe6350.png). The explanations and reasons that you proposed are very useful and helpful. The fact that two methods of quantification suggest the same result is promising to believe that there will be more digging for the truth to be revealed. But I am a bit out of my depth on assembling novel transcripts, or extracting unmapped reads and aligning them with STAR and inspecting the BAM files. But I will give a try. Best Wishes, . David",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/603#issuecomment-746227004:464,avoid,avoid,464,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/603#issuecomment-746227004,1,['avoid'],['avoid']
Safety,"Dear all. Thank you for your prompt reply. ; @mikelove yes, the CPM is only cross-sample normalisation, but not cross genes. TPM is both cross-sample and cross-gene normalisation. Thus, in my mind, TPM is more suitable for downstream RNA-seq analysis, including clustering analysis, differential expression testing using Wilcoxon rank-sum test. Also, for accurately detecting differentially expressed genes, is it reasonable to overlap the results from different methods, such as edgeR+Wilcoxon rank-sum test?. Best regards,; Zheng zhuqing",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/812#issuecomment-1324468833:366,detect,detecting,366,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/812#issuecomment-1324468833,1,['detect'],['detecting']
Safety,"Depending on what environment you install in (other conda software), the default resolver in conda is messed up. You should just explicitly ask for 1.10.2 with “ conda install salmon=1.10.2”. You can also try installing it in a clean conda env which is how I install most of my conda software anyway. Best,; Rob. note: these resolver issues are a conda problem, and there’s nothin we as the salmon devs can do. So if you’d like to be able to avoid specifying the version, even when you put it in an env with arbitrary other software, I suggest making aMWE and opening an issue upstream in conda/bioconda.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/895#issuecomment-1784085120:442,avoid,avoid,442,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/895#issuecomment-1784085120,1,['avoid'],['avoid']
Safety,"Does anyone have an answer to this, are those error models 'safe' to ignore?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/701#issuecomment-1419784692:60,safe,safe,60,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/701#issuecomment-1419784692,1,['safe'],['safe']
Safety,"Especially since the files in both cases actually are in the same location... I could imagine it being an issue with something going write with the communication over the NFS. But in the working case it's just links to the same NFS location. Here is the tail of the gdb output:. ```; Computing gene-level abundance estimates; [2016-01-02 21:56:43.793] [jointLog] [warning] NOTE: Read Lib [( /nfs/research2/teichmann/valentine/detection-comparison/salmon0.4.2-comparison/mouse/SRP057125_SRS936134_1.fastq, /nfs/research2/teichmann/valentine/detection-comparison/salmon0.4.2-comparison/mouse/SRP057125_SRS936134_2.fastq )] :. Greater than 5% of the alignments (but not, necessarily reads) disagreed with the provided library type; check the file: SRP057125_SRS936134_salmon_out/libFormatCounts.txt for details. There were 104534 transcripts mapping to 44034 genes; Parsed 104000 expression lines; done; Aggregating expressions to gene level . . . done. Program received signal SIGSEGV, Segmentation fault.; 0x000000320dc093a0 in pthread_mutex_lock () from /lib64/libpthread.so.0; Missing separate debuginfos, use: debuginfo-install glibc-2.12-1.149.el6_6.5.x86_64; (gdb) bt; #0 0x000000320dc093a0 in pthread_mutex_lock () from /lib64/libpthread.so.0; #1 0x0000000000806370 in je_tcache_bin_flush_small () at include/jemalloc/internal/mutex.h:85; #2 0x0000000000806c60 in je_tcache_event_hard () at src/tcache.c:44; #3 0x00000000005915fc in std::vector<Transcript, std::allocator<Transcript> >::~vector() (); #4 0x00000000005941c6 in ReadExperiment::~ReadExperiment() (); #5 0x00000000005872ce in salmonQuantify(int, char**) (); #6 0x0000000000514472 in main (); (gdb); ```. It does indeed seem to be inside JeMalloc.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/34#issuecomment-168431900:426,detect,detection-comparison,426,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/34#issuecomment-168431900,2,['detect'],['detection-comparison']
Safety,"Excellent, I was hoping streaming input would 'just work'. Thanks, Rob!. On Wed., 7 Sep. 2016, 4:45 pm Rob Patro, notifications@github.com wrote:. > Hi Pete,; > ; > Yup, this would be my recommended way to handle it. Since salmon accepts; > streaming input, you could do something like:; > ; > salmon quant -i index -l A -1 <(gzcat rep1_muliplex1_1.fq.gz rep1_mutliplex2_1.fq.gz) -2 <(gzcat rep1_multiplex1_2.fq.gz rep1_multiplex2_2.fq.gz) [other options etc.]; > ; > to avoid creating the intermediate concatenated files on disk. This will; > treat all the multiplexed samples from the same replicate as one giant; > input read stream (conceptually representing a single replicate). As far as; > merging / combining Salmon output, if you're doing the downstream analysis; > in R, the tximport package is nice. Otherwise, @vals; > https://github.com/vals has a python tool readquant; > https://github.com/Teichlab/readquant that can also do some merging.; > ; > Best,; > Rob; > ; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub; > https://github.com/COMBINE-lab/salmon/issues/88#issuecomment-245412770,; > or mute the thread; > https://github.com/notifications/unsubscribe-auth/ABAEjUsIBA5yK5R7MPW38jiuH0xx_IRCks5qnyJJgaJpZM4J3L2E; > .",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/88#issuecomment-245413908:471,avoid,avoid,471,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/88#issuecomment-245413908,1,['avoid'],['avoid']
Safety,"Given the alternatives, I think this is currently the best approach for implementing automatic library type detection in alignment-based mode. I'll add an appropriate note to the documentation to specify that streaming input cannot be used with automatic library type detection when using the `A` library type --- otherwise it should work as in the read-based mode.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/79#issuecomment-243438079:108,detect,detection,108,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/79#issuecomment-243438079,2,['detect'],['detection']
Safety,"Great idea! Hopefully, this is something that could be done on e.g. the first 10k reads just like the automatic library type detection, as a sanity check.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/151#issuecomment-326430054:125,detect,detection,125,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/151#issuecomment-326430054,2,"['detect', 'sanity check']","['detection', 'sanity check']"
Safety,"HI @pinin4fjords ,. Thanks for reporting the this. There was bug associated with binary format to mtx format conversion we fixed in the upcoming release. The problem was associated with the last index of the matrix which can be off by max 8 indices because we were using `uint_8` for storing the bit vectors. ; My apologies for the trouble, there are two ways to solve this issue:; 1.) Rerun the pipeline with the latest beta release of [0.99](https://github.com/COMBINE-lab/salmon/releases/tag/v0.99.0-beta2), unfortunately this is not in conda yet, but we plan to release it soon with awesome new updates like consuming both genome and transcriptome for read mapping.; 2.) If you wan't to avoid rerunning the full pipeline, try this. Try cloning [this](https://github.com/COMBINE-lab/EDS) repo and do a `cargo install --release` for the code in `src-rs` folder. Note: You might have to install [Rust](https://www.rust-lang.org/tools/install) for this, it's just one liner install. Once compiled the EDS code, you can just do the following to generate the correct mtx file.; ```; ./target/release/eds convert -i <Path to output/alevin/quants_mat.gz> --mtx -c <num_cells> -f <num_genes>; ```. Please let me know if it works out for you.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/431#issuecomment-537069929:691,avoid,avoid,691,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/431#issuecomment-537069929,1,['avoid'],['avoid']
Safety,Hello @rob-p! I was wondering if there have been any updates on the fusion/detection of spanning reads problem. I'm about to embark on a project to process many bacterial transcriptomes from many different genomes/species and plan to use salmon. I would love to be able to detect polycistronic transcripts through the identification of spanning reads.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/52#issuecomment-1017768886:75,detect,detection,75,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/52#issuecomment-1017768886,2,['detect'],"['detect', 'detection']"
Safety,"Hello @rob-p, may I ask whether there are any news concerning gene fusion detection in Salmon?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/52#issuecomment-255103667:74,detect,detection,74,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/52#issuecomment-255103667,1,['detect'],['detection']
Safety,"Hello Rob,. Thank you for your quick reply to my question. My MEGAHIT and Trinity assemblies were not built with strand-aware flags. I made decoy-aware transcriptomes using a MEGAHIT assembly, a Trinity Assembly, and a published transcriptome from the same species, and when I ran my read files through salmon using ""A"" as the library type and each of the three indexes, all three were detected as ""most likely library type IU"". It's strange that once all three have been compiled into a single assembly using Evigene, salmon detects the ISR library type. When I change the ""A"" to ""ISR"" or ""IU"", the % mapped changes a lot. ; Is it better to build assemblies with strand-aware flags? If so, does it usually make a large difference to quantification results, or a minor one? I don't know what protocol the sequencing facility used, but I am sure I could ask them. I gather from my recent reading that the extra information gained by using a stranded protocol _is_ worthwhile, so I would expect that the sequencing facility used one, but why doesn't Trinity or MEGAHIT detect the sequecing protocol that was used? Or, if you have to specify it, why do none of the example Trinity commands I've come across include this option? It doesn't strike me as a commonly used specification in making assemblies. Thanks for answering my noobie questions. Holly",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/840#issuecomment-1492849365:386,detect,detected,386,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/840#issuecomment-1492849365,3,['detect'],"['detect', 'detected', 'detects']"
Safety,"Hello,. I've actually been thinking of a different method that would require very stringent mapping. By providing transcripts of only exon 1 & 2, exon 2 & 3, and exon 1 & 3 I could get a better idea of the number of reads that skip exon 2 all together. Also, by averaging the read counts that map to the junctions of exon 1 & 2 and exon 2 & 3, I can help eliminate polyA tail bias that is heavily positioned towards exon 1 and would also allow me to get a more accurate prediction of the two gene versions since 1 read mapped to exon 1 & 2 and 1 read mapped to exon 2 & 3 would essentially tell me twice that the gene is there while a read mapped to exon 1 & 3 would only tell me once that the gene is there. However, doing so would force me to bring ```AuxSampleNumber``` down to very low numbers such as 10 - 100 as using stringent coverage parameters drastically reduces my reads mapped. . I do wonder though how these low AUX numbers might affect your model development and algorithm. Any input into the aspect of low AUX numbers?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/401#issuecomment-512905804:470,predict,prediction,470,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/401#issuecomment-512905804,1,['predict'],['prediction']
Safety,"Hey @Gaura and @rob-p - just as a point of comparison, I ran zUMIs on the same exact files. With nominal filtering I get 12,942 cells recovered, of which 10,386 (80%) were also contained in the published matrix (exact sequence matches). . Happy to provide any of those files if that's useful. But it does seem to argue something is funky when it comes to alevin's detection of these barcodes, right?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-987136859:134,recover,recovered,134,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-987136859,2,"['detect', 'recover']","['detection', 'recovered']"
Safety,"Hey @rob-p and @Gaura - thanks for this! My understanding is that your `splitp` will replace my slow perl script, which is great, and then alevin-fry should work pretty much like any other run, yes? If so, can you comment on the low alignment rate and other oddities I encountered running regular alevin following editing of my R2 FASTQ in this way (documented above), and whether there's something inherently different about alevin-fry that should address those issues? Because I currently detect only a tiny fraction of the cells expected. . I'm more than happy/eager to give splitp+alevin-fry a try, but I suspect there's some secondary issue at hand that we'll need to address downstream",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-978168267:491,detect,detect,491,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-978168267,1,['detect'],['detect']
Safety,"Hey Avi,. I have ran alevin with addition of `--expectCells 8000` flag, the new output of cells detected: ; `3655, 5604, 4374` w/ `13%, 30%, 15.7%` reads thrown away. It is better than the first trial `1192, 4947, 3414` but nevertheless fewer than the cell ranger output `5150, 7618, 6404`. . Wonder ; 1. if I should set higher `--expectCells`, but which would result in more unconfident calls?; 2. From 1, if I just try to get more cells subjectively, will the expression matrix (and further analysis) be inaccurate/affected? (given downstream filtering of cells of low quality based on # of feature detected etc. would be performed anyway. ) ; 3. what could be the reason that these two algorithms output such different total cell numbers (precision in calling?) . Thanks!; Chelsea",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/396#issuecomment-510603746:96,detect,detected,96,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/396#issuecomment-510603746,2,['detect'],['detected']
Safety,"Hey Matt,. First, thanks for the detailed analysis! Second, phewww --- I looked for a while in the indexer and didn't see anything that could have caused lost transcripts, so I'm glad that's not the case. It sounds like you had to go down a bit of a rabbit hole to figure this out. Anyway, I'll take a look at where Salmon might be producing an EOF marker on stderr anyway (I'd like to avoid that behavior if I'm indeed doing that). Thanks again for reporting back on this! I'll close the issue for now since it seems resolved.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/132#issuecomment-303739707:386,avoid,avoid,386,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/132#issuecomment-303739707,1,['avoid'],['avoid']
Safety,"Hey Rob,. I did manage to test v1.3 this evening. Ran much faster. The same sample that took about 6 hours ran in 45mins. Still not great, but I think it might be intrinsic to some of these samples, also I was running it off my laptop and was running Linux off a; flash drive so not an ideal setup. Either way much more reasonable. Do you want me to attach any logs or anything?. Best,. Ryan . Sent from my iPhone. On Jun 16, 2020, at 10:20 AM, Rob Patro <notifications@github.com> wrote:. ﻿. Hi ; @shalercr,; I agree that if each sample runs as quickly as you see here, it's not a big deal to just re-run them all. Note that, while my avoids ~116 times more (eventually-discarded) alignments than did yours, the difference in the number of discarded; fragments (i.e. fragments that had no mapping) is very small — ~7,000, or 0.023% of the fragments. Thus, despite the huge speed-up, I wouldn't expect many differences in the quantifications. However, I couldn't argue against re-quantifying everything; with the new version just for good measure :). When you have a chance, please do let me know if you see this same performance difference using the pre-compiled (linux) binary. here. Of course, once we finalize this release (soon), we will push to bioconda so we will also have OSX binaries available. However, I just want to make sure this fixes things on your end as well before the release.; —; You are receiving this because you were mentioned.; Reply to this email directly, ; view it on GitHub, or ; unsubscribe.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/537#issuecomment-645119801:636,avoid,avoids,636,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/537#issuecomment-645119801,1,['avoid'],['avoids']
Safety,"Hi @Anto007,. Sounds like an interesting experiment! A couple of questions: (1) are you quantifying the meta-transcriptome or the metagenomes? What I mean is, are your target sequences the specific genes from the microbes, or the entire microbial genomes? Is the sequencing data RNA-seq from sequencing the mixture of expressed gene transcripts, or DNA-seq of the microbes? This will have an effect on how you expect reads to be generated. The effect of `--minScoreFraction` depends, to some extent, on how you set the match/mismatch/gap parameters. With the default parameters, `0.9` is actually higher than 90% sequence identity, because the default mismatch penalty is twice the match score. If you assume only matches and mismatches, then the `--minScoreFraction` you want to set is the one such that ; x * (match_score * read_length) <= (match_score * read_length) - (m * read_length * match_score) + (m * read_length * mismatch_penalty), where m is the mismatch fraction (0.1 in your case). So, for example, if the match_score is 2 and mismatch penalty is -4, and the read length is 100, you want to set it so that:. x * 200 = 200 - (0.1 * 100 * 2) + (0.1 * 100 * -4) = 200 - 20 - 40 = 140 . so, the appropriate x would be ~0.7. Of course, if you want to make the calculation simple, you can set the match score to 1 and mismatch penalty to 0, and then the interpretation (modulo gaps) is straightforward (and 0.9 means what you want). Finally, I'd typically avoid using `--mimicStrictBT2`, since those are pretty harsh parameters. Of course, you could try mapping both with and without that flag and see how it affects your mapping rate.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/330#issuecomment-447589060:1465,avoid,avoid,1465,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/330#issuecomment-447589060,2,['avoid'],['avoid']
Safety,"Hi @ChelseaCHENX ,. Thanks for confirming the counts of the number of predicted cells.; As much as I'd love to give you an exact answers, but in realty w/ current settings it requires a little more exploratory analysis. Whitelisting traditionally is done by making some greedy choices and generally can results in different number of predicted cells, and having an exact answer is difficult to have. For example, if you run alevin with `--dumpFeatures` and plot the frequency of CB, as dumped in the `raw_cb_frequency.txt`, you will observe a monotonically non-increasing function. Different tools try to get the ""knee"" in the distribution, so as alevin, as the first round of whitelisting. For cellranger, at least in my understanding, they try to take the top X% (I think it's 10) of the value suggested through `expectCells` command as high confidence and use all the CB which has the frequency greater than the lowest frequency of the high confidence barcodes for quantification. To counter the greediness of the CB calling, we in our suggested method for alevin, proposed a naive bayes based approach by learning features from not only CB frequency but various other features. There had been other methods like ""emptyDrops"" which you can try for more fine-grained whitelisting post quantification using alevin quants. Having said that, if you use expectCells with bigger value, alevin will start to include more and more cells. However as the frequency of the new CB which gets included as high confidence with each new iteration drops exponentially, and even though the new CB gets merged to a high confidence barcode its chance of affecting the quantification also drops. In summary, if you are sure about your experiment to have more cells then it's ideal to increase the value otherwise, I think, with the increased expectCells value the quants can potentially be effected but most probably not by a lot. Hope it helps !",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/396#issuecomment-510628771:70,predict,predicted,70,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/396#issuecomment-510628771,4,['predict'],['predicted']
Safety,"Hi @ChelseaCHENX ,. Thanks for raising the issue.; I think if you can share the alevin log (say for 1192 cells ?) we can comment much more about the details. However, if you ask me to guess then I believe the initial whitelisting of alevin seems to be predicting a lot less cells, if you check the alevin log, it would say what % of CB are thrown due to noisy cellular barcodes. If the number is `>20%`, then the chances are indeed ""knee"" estimates are shooting up. The way to get better estimates from there would be to help alevin with a ballpark number of cells (as you are giving to cellranger with --expect-cell 8000, you can provide alevin with --expectCells 8000). Even after that if you get a lot of noisy CB prediction then you can force alevin to use certain number of cells with `--forceCells` option. https://github.com/COMBINE-lab/salmon/issues/362 this issue might help you understand more the details of the pipeline.; Hope it helps !",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/396#issuecomment-510540540:252,predict,predicting,252,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/396#issuecomment-510540540,2,['predict'],"['predicting', 'prediction']"
Safety,"Hi @Lordlitong,. The name of a FASTA record is whatever appears up to the first white space character in its header line. This is why you get these long names in the index as a sequence name. If you pass the `—gencode` flag when building the salmon index, it will treat `|` as an additional separator, and your names will just be e.g. `ENST00000456328.2`. That is the easiest way to avoid this issue going forward. If you don’t want to rebuild the index and re-process the data (if you’ve already processed a ton of samples), then you would have to write some code to strip the sequence names before loading them.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/513#issuecomment-619584519:383,avoid,avoid,383,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/513#issuecomment-619584519,1,['avoid'],['avoid']
Safety,"Hi @Munfred , ; Thanks again for testing Alevin with your dataset. Extrapolating from the log, It indeed looks like a challenging dataset. In default settings Alevin pipeline starts with finding a knee in the curve (which itself is a non-trivial problem) and then use KDE w/ gaussian correction to adjust for the right probability. In your case it looks like knee is overshooting (if true number of CB is 300 ) but more troubling part for me is gaussian correction is coming out 0. Now based on your motivation for using Alevin, I can propose two solutions:. 1. If the motivation is to get gene-level count without worrying about the whitelisted CB prediction then the easiest way is to use external whitelist. Alevin can use external whitelist using flag `--whitelist` and would generate gene level counts for specified list of CB.; 2. If you need full end-to-end run of Alevin, then I propose using command line flag `--dumpFeatures` along with Alevin default. This flag tells Alevin to dump various features, the important one here would be a file named `frequency.txt`, what this file basically tells you is the frequency of all the observed CB in a order. From there we can manually select a knee in the frequency curve and use that as a whitelist. In terms of improving the task for improving the knee selection in Alevin, if you can share the `frequency.txt` file then I can look into what's causing the issue for gaussian correction or the knee selection itself. Thanks again for your interest !",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/245#issuecomment-402547744:649,predict,prediction,649,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/245#issuecomment-402547744,1,['predict'],['prediction']
Safety,"Hi @OnlyHigh,. Indeed, the _default_ behavior of salmon is to de-duplicate transcripts (to avoid that behavior and allow salmon to index duplicate transcripts, you need to pass the `--keepDuplicates` flag to the indexer). When it does this, it will log the duplicate transcripts in the index. If you look in the directory containing the salmon index, you will find a file called `duplicate_clusters.tsv`. This is a 2 column TSV file with a row for each transcript that was collapsed during indexing. The first column says which retained transcript was identical to the collapsed transcript. We do not write down the specific sequence of these transcripts, but with the original fasta file on which the index was built, you can easily extract this. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/299#issuecomment-428612513:91,avoid,avoid,91,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/299#issuecomment-428612513,1,['avoid'],['avoid']
Safety,"Hi @Sa753 . Yes, there are some other considerations. In this second dataset salon maps > 3M reads to the decoy. Further, since salmon only uses the decoy to avoid spurious alignment, it will only report reads as decoy if they map contiguously to the genome, not if they are spliced (but not mapping to an annotated transcript). Anyway, those reads will not be counted toward the mapping rate. While star reports all the reads mapped, salmon's mapping rate only counts reads that will actually be used for quantification. The numbers these different tools report as the mapping rate are just not comparable in terms of their meaning. If you want a more direct comparison, try something like running the STAR reads through feature counts and see how many are assigned to annotated genes. Alternatively, you can run STAR with --quantMode transcriptomeSAM, and pass the resulting BAM file as input to salmon (since it can also do transcript quantification with a transcript-coordinate BAM file) and see how many reads make it into that quantification. When situations like this arise, they almost always result from reads arising outside of the annotation. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/775#issuecomment-1126604296:158,avoid,avoid,158,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/775#issuecomment-1126604296,1,['avoid'],['avoid']
Safety,"Hi @ShenTTT,. First, thank you for the detailed analysis (and for doing the work of looking up this issue in past posts). If the (trimmed) reads are of high quality and there aren't signs of contamination, my initial hunch would be that there are a considerable number of reads coming from outside of the annotated transcriptome (that is, I would suspect `2` to be the most likely culprit here). I don't think this is because of DNA `contamination` necessarily, but rather because of novel transcripts that don't appear in your annotation. Obviously, salmon can only quantify what it knows about in terms of annotated transcripts. If you are concerned about these mapping rates, one thing you might try is to do transcript assembly in these samples (using e.g. scallop or StringTie2) and then re-quantify using salmon under the expanded annotation. Also, while you are losing ~5M reads to low mapping scores (suggesting they are not a good match for the underlying annotated transcripts), this doesn't seem to be what is driving your overall mapping rate (i.e. this is only ~15% of fragments, so the rest of the difference between 85% and 56% comes from reads that don't fall into this category). Finally, while you may be able to ""recover"" more reads by lowering the mapping threshold `--minScoreFraction` from its default value of 0.65, that default is actually pretty liberal (especially for trimmed reads). So this would be letting in quite low-quality alignments. Note that, if you have unannotated isoforms that share sequence (exons) with annotated isoforms, this could partly describe what you are seeing with some of these reads, where part of the read aligns but part does not (because it comes from an unannotated splice form).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/533#issuecomment-638929976:1232,recover,recover,1232,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/533#issuecomment-638929976,1,['recover'],['recover']
Safety,"Hi @Tima-Ze,. This should not cause any trouble with downstream analysis. The indexing procedure is simply informing you that these transcripts (about which you are being warned) are shorter than the seed length used for alignment. This means that it simply won't be possible for fragments to align to these transcripts, and so they will always have a 0 abundance in the resulting `quant.sf` files. This isn't a problem, as these transcripts are too short to be measured via RNA-seq anyway. The indexing messages just let you know this in advance. You can safely ignore these warnings for your downstream analysis.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/214#issuecomment-751366278:556,safe,safely,556,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/214#issuecomment-751366278,2,['safe'],['safely']
Safety,"Hi @alexmascension ,. Thanks for confirming. I'll paste my response, I sent you earlier, here too. In case it's helpful to some other user. > Hi Alex,. >Thanks again for forwarding the data. I think I have the solution for the problems you are facing in alevin. >Your first question was related to alevin quantifying very less number of reads. To answer that,; if you look at the log, at the first few lines, alevin warns about ~91% of the reads being thrown away because; of the noisy CBs. The problem is alevin’s first “knee"" estimation is overshooting in predicting the first boundary. You will find https://github.com/COMBINE-lab/salmon/issues/362 issue to be; very useful in understanding that. As a summary if you look at the plot I attached it has bi-modalities,; which is generally not the case and alevin is greedily finding the threshold at the first ~100 cells. If this; happens the general direction is to help alevin by proving a upper bound, in case of your data; would be ~14000 cells. You can tell alevin with `—expectCells 14000` and alevin start to work; normally and logs ~12% of the data is noisy. >You second question was a little complicated to answer. Seemingly, your salmon index has transcript with; same exact name `ENST00000399966.9`, occurring twice with different sequences. Just by looking at the index,; I am unsure it’s actually present in the reference or its salmon indexing messing up. If I Assume it was actually; present two times in the reference, alevin should report it instead of exiting abruptly in the middle of quantification.; Although, alevin does warns:; ```; [2019-07-04 14:12:32.519] [alevinLog] [warning] Found 1 transcripts with duplicate names; ```; >However, the bug i.e. not being able to distinguish duplicate names of the transcript, has been ; fixed and pushed in the develop branch of salmon. Alevin was reporting the error at the stage of quantification too, ; if you dump the logs in a file, but it was invisible in the console as it was ove",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/386#issuecomment-508754845:558,predict,predicting,558,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/386#issuecomment-508754845,2,['predict'],['predicting']
Safety,"Hi @asher1234,. Thanks for the detailed bug report. The detection of the library type as `MU` certainly does raise some flags as that is not something that would be expected. Moreover, in the v0.12.0 log you posted, we see messages like:. ```; Thread saw mini-batch with a maximum of 90.16% zero probability fragments; ```. Which means that e.g. ~90% of the fragments, even though they map, are being assigned a 0 probability under the model (because of e.g. incompatibility with the library type). Would you be able to share one of these samples and the reference transcriptome against which you are quantifying? Also, do things look any different if you force the library type to be something more common (e.g. `-l IU`)?. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/346#issuecomment-469108517:56,detect,detection,56,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/346#issuecomment-469108517,1,['detect'],['detection']
Safety,"Hi @bounlu ,. This warning is harmless, and comes from the fact that the parsing code improved but the rapmap code being called to build the index is forgetting to call a particular method. So, the destructor detects this and calls it instead. This isn't a problem, and won't affect the results. However, I'll push a patch release that eliminates this issue (either today or tomorrow sometime). Until then, you can go ahead using this index, it should work fine.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/176#issuecomment-347524898:209,detect,detects,209,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/176#issuecomment-347524898,1,['detect'],['detects']
Safety,"Hi @bumproo and @mmp3,. Thanks for raising this issue. So, I _am_ surprised at these particular differences that you found, but the behavior you are observing is consistent with how automatic library type detection works. Let me explain what it's doing, and then I'm open to discussing if we should focus on changing that behavior going forward. The standard library type detection works by looking at the total number of compatible mappings in both possible orientations for the first x=10,000 aligned reads. These 10,000 reads are themselves mapped with an `IU` orientation in paired data and a `U` orientation in unpaired data. Once the 10,000 data points have been processed, a heuristic chooses the most likely library type and applies it (and salmon issues a warning if, at the end of quantification,, there are too many reads that disagree). So, the explanation of what could be happening here is that the reads that are different between your runs are coming within the first set of 10,000 aligned reads (note, this may not be the first 10k reads of the file, because concurrent processing means that reads from different threads are being aligned in an essentially random order ... but of course maintaining pairing information). The argument for why this should usually not cause a considerable difference is because (1) the reads are assumed to arrive in a random order (2) this is only a very small fraction of the total data and (3) if the unoriented reads map to a target in the ""wrong"" direction, they will also align to the proper target in the ""right"" direction and, once the orientation filter is applied for future reads, the weight of evidence should turn the probability of assignment of these unoriented reads toward the proper target. However, I'm guessing there is an edge case you're seeing here where the conditions don't induce this behavior. So, there are 2 immediate solutions to the problem. First, if you know the library type explicitly, you can use that. Second (and s",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/489#issuecomment-738830213:205,detect,detection,205,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/489#issuecomment-738830213,2,['detect'],['detection']
Safety,"Hi @cihanerkut,. First, thanks for reporting this, and going through the trouble to give the `strace` information. Second, salmon won't auto-update anyway. That would be quite slick, but there's not a good and reliable way to do that with natively-compiled programs that I know of. However, the most surprising thing is that you are finding the call to the version check ip to be hanging for any significant amount of time. The timeout should be pretty quick. How long does it hang when you do `salmon index --help`? I'll look into it on our end as well.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/486#issuecomment-592203836:428,timeout,timeout,428,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/486#issuecomment-592203836,1,['timeout'],['timeout']
Safety,"Hi @citron96,. This is what is covered in https://github.com/COMBINE-lab/salmon/issues/496. This is because an upstream package changed the SHA of their *tagged* releases (which is really not ideal). Are you pulling from the master branch? If you pull from develop, everything should build. I can pull the changes that fix this into master. Unfortunately, to avoid changing the signatures of _our_ tagged releases, I can't push this change back to older releases. I think @nadyawilliams may also have a patch for the CMakeLists.txt file, which, perhaps, can be shared?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/497#issuecomment-603902738:359,avoid,avoid,359,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/497#issuecomment-603902738,1,['avoid'],['avoid']
Safety,"Hi @crazyhottommy ,. Reading a bit in https://github.com/COMBINE-lab/salmon/issues/245 and https://github.com/COMBINE-lab/salmon/issues/284 would definitely help understand more about the pipeline. _summary:_ it's possible the 50% mapping read is due to alevin throwing away CB. In this case, we normally suggest to try running alevin in the following order:; 1.) `--expectCells X`: alevin will look for local knee threshold near to top X barcodes. Alevin can still here based on the CB frequency distribution.; 2.) `--forceCells X`: run alevin with `--noQuant --dumpFeature` mode and extract the frequency histogram of the CBs present in the histogram. Try to manually found knee in the descending sorted CB frequency histogram and figure out X. alevin will use top X barcodes as specified by the user.; 3.) If there is other tools like `cellranger` already been run on the data, then alevin can directly consume their predicted CB sequence using `--whitelist` option. This is different file, not the 727k file from 10x, and is different for each experiment .",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/340#issuecomment-458793327:920,predict,predicted,920,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/340#issuecomment-458793327,1,['predict'],['predicted']
Safety,"Hi @deevdevil88,. The challenges I faced with this issue made me switch over to `kallisto` which has some nice advantages as far as speed. I didn't see any obvious affects on quality for my samples although I did have to re-implement some of the auto-detection that `alevin` and `salmon` do for you. . I personally observed some strange behaviour with Soupx - visually apparent differences in gene expression between samples that at the time I felt were artefactual of the adjustment by Soupx. I eventually rolled-my-own strategy where I omitted ambient outlier genes from differential expression. Ambient outliers were defined by taking droplets with UMI counts <10 with using a boxplot in R to define outliers. The osca.bioconductor.org [recommendations](https://osca.bioconductor.org/multi-sample-comparisons.html#ambient-problems) ended up being very similar. They also describe some of the pitfalls of adjusting counts. Best of luck! Always appreciative of all the great work and responsiveness of @k3yavi and the team!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/538#issuecomment-646058370:251,detect,detection,251,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/538#issuecomment-646058370,2,['detect'],['detection']
Safety,"Hi @demis001,. What I mean is that the _standard_ Ensemble format of `transcript_name.transcript_version`, separates the name from the version using a `.`. This is, in no way, a standard or universal rule. For example, what if the gtf file is coming from another source (Gencode, RefSeq, UCSC, something else)? We can't safely assume that one can universally just remove the portion of the identifier after the last `.` to get the un-versioned name. In this case, the question is, what is the right way to handle this, since users are employing all manner of different sources for their reference transcriptomes and not just Ensembl. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/122#issuecomment-282341182:320,safe,safely,320,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/122#issuecomment-282341182,1,['safe'],['safely']
Safety,"Hi @dritoshi ,. As per your request I've added the support for Quartz-seq2 data in the alevin framework with https://github.com/COMBINE-lab/salmon/commit/f6905b1d1dc6cf6bc4597927ad3be637ba615c9a and should be available with next salmon release. Currently the develop branch has to be compile from source to use the following command line argument.; ![image](https://user-images.githubusercontent.com/8772521/63282768-8df73600-c27d-11e9-832d-f4a1232f17f6.png). Currently I just have on flag i.e. quartzseq2 which assumes 15 length CB and 8 length UMI. Unfortunately adding multiple versioned is gonna be little complicated as I might have to discuss with the alevin team and that might take some time. As you can check through the new code through the commit (linked above) adding just the Rule of new protocol is not enough and we might have to add some helper code with each new protocol which increases the redundancy in the code. Currently we are in the process of figuring out a better way to handle new protocols.; Having said that it should not stop users from using alevin with previous version of quartzseq2, you can use the following command line triplet as `--end 5 --barcodeLength 14 --umiLength 8` along with you other alevin flag and it's gonna behave just like `QuartzSeq2v31` you specified above. If possible, It'd be great if you can share some of the results you get while comparing Quartz-seq2 pipeline with alevin. Hope this helps !",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/416#issuecomment-522658541:909,redund,redundancy,909,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/416#issuecomment-522658541,1,['redund'],['redundancy']
Safety,"Hi @gresteban,. Thanks for reporting this. Did this happen when running with the automatic library type detection or with `-l SF`? It is _not_ intended, but knowing what code path was executed will help me narrow down the source of the bug.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/82#issuecomment-243602381:104,detect,detection,104,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/82#issuecomment-243602381,1,['detect'],['detection']
Safety,"Hi @gtollefson,. To understand the output here a little bit better, it is necessary to understand what salmon is doing during indexing. My understanding is that you provided salmon with a transcriptome and (small) decoy reference genome, and asked it to build an index with k-mer size `k=31`. When you do this, salmon will do a few things. First, it will go over your input gentrome file, replace ambiguous characters (e.g. `N`) with pseudo-random nucleotides. It will also report any transcripts smaller than the chosen k-mer size, and it will detect and remove (unless `--keepDuplicates` is passed) any identical / duplicate sequences. After all of this, it will begin constructing the index in earnest. This is done by running a modified version of [TwoPaCo](https://github.com/medvedevgroup/TwoPaCo) to construct the compacted colored de Bruijn graph on the gentrome, which is then indexed using our [pufferfish index](https://github.com/COMBINE-lab/pufferfish). The TwoPaCo algorithm that generates the compacted colored de Bruijn graph from the input sequence is based on a very elegant algorithm that couples a Bloom filter with an exact hash table, and makes two (or more) passes over the input to identify all of the junctions in the reference (which directly implies all unitigs). To make the algorithm work efficiently, one needs to have an estimate for the number of distinct k-mers that will be encountered in the reference sequence. If the estimate is too big, one wastes memory. If the estimate is too small, the Bloom filter is not big enough, it doesn't filter efficiently, and the algorithm ends up putting way too much data in the exact hash table. In order to determine how to set the Bloom filter size appropriately, we take the following approach. If the Bloom filter size isn't provided directly (_note_: this is _not_ the same as the k-mer size, this is an estimate of the total number of distinct k-mers in the entire input data), then we make a call to a function defined in ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/510#issuecomment-616713186:545,detect,detect,545,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/510#issuecomment-616713186,1,['detect'],['detect']
Safety,"Hi @jasonvrogers,. First of all thank you so much for sharing this thorough analysis with us, it was very clear and helpful for understanding the details of the problem you are referring to. Secondly, I apologize for the long time it took me to get back at you. I would like you to know that we have been and are still working on possible solutions for addressing this problem, and here I would like to share some updates with you. . About the success cases, it was nice to know that the current model of Salmon with length correction works pretty well in recovering the right estimates for those ""easier"" cases where one transcript is fully contained in another one. Turning off the length correction, tells the Salmon model not to consider the effective length of each transcript for computing the conditional probabilities of originating a fragment from a transcript. So, for the RNA-seq data there is no reason to turn off this term of the model, and we highly recommend not to use that flag for the bulk RNA-seq abundance estimation with Salmon. Looking more carefully at the 2nd case you have posted as the failure case, it is interesting to see that there is a very nice visual evidence on the super transcript that the long transcript might not be expressed at all. I am referring to the zero coverage regions on the Super Transcript between the regions corresponding to the smaller transcripts, e. g., between POF1 and EMC1. So, we tried a solution that inspects the coverage profile of all transcripts and calculates the probability of observing a zero coverage region on each transcript. If this probability is too low, this would be counted as an evidence for a transcript not being expressed at all. This approach seems to be working fine on this example that you have shared here. however, one problem was that there were considerable number of reads in the sample that were uniquely mapping only to the Super Transcript and turning of the expression of that transcript would result in t",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-666512703:556,recover,recovering,556,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-666512703,2,['recover'],['recovering']
Safety,"Hi @jeremymsimon and @Gaura,. After redoing the analysis with the correct barcode geometry (still with --sketch-mode), using knee filtering with alevin-fry leads to the following:. ```; robp@ocean1:/data007/users/rob/SRR10174292$ ~/alevin-fry/target/release/alevin-fry generate-permit-list -k -i SRR10174292_map -o SRR10174292_quant -d both; 2021-12-03 09:49:37 INFO paired : false, ref_count : 228,754, num_chunks : 11,194; 2021-12-03 09:49:37 INFO read 2 file-level tags; 2021-12-03 09:49:37 INFO read 2 read-level tags; 2021-12-03 09:49:37 INFO read 1 alignemnt-level tags; 2021-12-03 09:49:37 INFO File-level tag values FileTags { bclen: 24, umilen: 10 }; 2021-12-03 09:49:50 INFO observed 55,952,280 reads in 11,194 chunks --- max ambiguity read occurs in 2,330 refs; 2021-12-03 09:49:50 INFO max_idx = 268803; 2021-12-03 09:49:50 INFO max_idx = 86532; 2021-12-03 09:49:50 INFO max_idx = 30016; 2021-12-03 09:49:50 INFO max_idx = 12061; 2021-12-03 09:49:50 INFO max_idx = 8292; 2021-12-03 09:49:50 INFO max_idx = 7396; 2021-12-03 09:49:50 INFO max_idx = 7112; 2021-12-03 09:49:50 INFO max_idx = 7012; 2021-12-03 09:49:50 INFO max_idx = 6969; 2021-12-03 09:49:50 INFO max_idx = 6952; 2021-12-03 09:49:50 INFO knee-finding iter = 10; 2021-12-03 09:49:50 INFO max_idx = 6944; 2021-12-03 09:49:50 INFO max_idx = 6938; 2021-12-03 09:49:50 INFO max_idx = 6937; 2021-12-03 09:49:50 INFO knee distance method resulted in the selection of 6938 permitted barcodes.; 2021-12-03 09:49:52 INFO total number of distinct corrected barcodes : 391,939; ````. so 6938 detected cells seems about right. Of course, since I'm not using the external unfiltered permit list here, they are likely not the same barcodes as in the deposited data due to the issue that @Gaura mentioned.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-985583153:1555,detect,detected,1555,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-985583153,1,['detect'],['detected']
Safety,"Hi @jeremymsimon — @Gaura is going to take a look at unfiltered permit listing and will share those results here later. Regarding frameshift errors, I think that's certainly out of scope for the alevin -> fry phase, but that type of thing *could* be in scope for `splitp`. Basically, my logic / reasoning is this: I'd like to avoid further complicating the already immense salmon/alevin codebase with special implementations handling problems outside of their core function (e.g. mapping reads to the reference efficiently and quantifying UMIs/barcode). Since most protocols (and the most common) have quite simple barcode geometry, it makes sense for this code to live there. I'm fully supportive of enabling support for more complex barcode geometries and preprocessing requirements if there are folks whom it would help, but it feels like that essential complexity belongs upstream of alevin / fry, so that by the time the reads get to alevin, it can assume a straightforward geometry. So TLDR : I think we'd be willing to investigate what is required to address potential frameshift errors, and how much of a difference that makes, but I think that analysis and eventual implementation (if we decide it's worth it), belongs in `splitp`.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-988030837:326,avoid,avoid,326,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-988030837,2,['avoid'],['avoid']
Safety,"Hi @jeremymsimon, to answer your last question:. > As for the barcode detection - my usual approach with alevin at least is to let it try to estimate a ""real"" cell number, but if it's way off from our experimental expectations, to inject --expectCells ncells and let that serve as a starting point (with subsequent filtering). That has worked reasonably well in the past for me , and seems to be an option for alevin-fry as well. I don't know whether that is poor practice in the long run...it came from a place of seeing far too many weak knee plots early in the droplet scRNA-seq days. Are you generally more trusting of these estimates these days?. So one of the nice aspects of the alevin to alevin-fry pipeline is that it's relatively easy to try different filtering approaches since the initial mapping process only has to happen once. In general, the knee detection method is pretty good, and often gives a reasonable cell count. However, this isn't always the case. What we find in the alevin-fry pre-print is that it tends to be slightly more conservative than if you did e.g. unfiltered quantification followed by filtering with something like `DropletUtils` (but usually only slightly). The knee method is basically the iterative knee finding procedure from UMI-tools, with some slight tweaks to the parameters. However, unlike alevin, alevin-fry also supports unfiltered quantification. In this case, you provide an `unfiltered-permitlist`, which is a set of acceptable barcodes (not necessarily all expected to be present), and alevin-fry will correct against this. This will tend to produce a _lot_ of quantified cells, since we quantify any barcode matching 10 or more reads (by default, this value is modifiable on the command line). So, such unfiltered matrices definitely need to be filtered after quantification. However, for protocols with an external permit list, or those where you can reasonably derive a list of potential expected barcodes, it's less stringent and therefore po",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-988967759:70,detect,detection,70,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-988967759,2,['detect'],['detection']
Safety,"Hi @jeremymsimon,. A few quick thoughts on this.; ; > -Is quantification via alevin-fry (rather than alevin itself) mandatory here? I ask since your run seems successful whereas my full alevin run had a very poor BC detection and mapping rate.; ; I don't think we've been able to successfully obtain the same concordance with alevin yet (as opposed to alevin-fry). There is more sophisticated _internal_ barcode logic going on there, and we may need to pull @k3yavi in to see what is happening outside of the RAD -> fry pipeline.; ; > -I see you specified -l A - can you comment on what the detected/correct library type was here?; ; Unlike `alevin`, when you run with in `--rad` or `--sketch` mode, the library type isn't really relevant. All mappings are passed through to the rad file. Subsequently, in `alevin-fry` there is a `-d` (direction) flag that is used to filter mappings that don't concord with the expected orientation. I'm not sure what @Gaura used in the run above — the default is to keep reads from either orientation.; ; > -I assume all of this will also work in conjunction with --expectCells or --keepCBFraction if those parameters were needed? Your ~7k cells detected is very close to the published number post-filtering, but no similar filtering has been done here yet. My guess is that the proportion of cells that pass these filters will be higher for alevin, but we may still be under-estimating the number of real cells by a little bit here.; ; According to the commands listed, @Gaura used `alevin-fry`'s built-in knee-like filtering. This tries to use a knee on the cumulative read count histogram to determine a good cutoff for ""reliable"" cells versus poor quality cells. Alternatively, one can provide an external permit list with `-u` (unfiltered permit list) to quantify all cells that match any known barcode. This will generally result in *many* more quantified cells, which you will then want to filter post-quantification.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-988011633:216,detect,detection,216,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-988011633,3,['detect'],"['detected', 'detection']"
Safety,"Hi @jeremymsimon,. So I'm trying to think about what issues _could_ be reasonably dealt with here. . 1) If the length of the sequence in the BAM header and the sequence provided in the FASTA file are different, this seems like a very difficult error to recover from since records can then contain alignments to bases about which we don't know. 2) If the same transcript appears multiple times in the input BAM header, but with different lengths, this also seems a difficult situation to allow. Exact duplicates are one thing, but I'm not sure if sequences ever appear with the same name but different lengths. If so, I'm thinking this would be a hard error. So, I think at least one situation we could reasonably deal with is that the input FASTA file contains multiple entries with the same name (and same length / sequence). In this case, we could retain only one of them, and document / log the fact that multiple identical entries were present in the input. Of course, there would still be an issue if we had a mismatch as with your example STAR input, where STAR concatenated all 3 occurences of an identical transcript. Are there other cases you can think of where it would make sense to somehow deal with the issue in salmon and continue with processing (perhaps with some extra warnings / log info)?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/282#issuecomment-418412904:253,recover,recover,253,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/282#issuecomment-418412904,1,['recover'],['recover']
Safety,"Hi @k3yavi,. Thanks for the reply!. Let's take the PBMC 4K as example. Looking at the summary sheet from 10x: ; http://cf.10xgenomics.com/samples/cell-exp/2.1.0/pbmc4k/pbmc4k_web_summary.html. They detected 4,340 cells with a median UMI count of 3,866 per cell. That means ~17M UMIs in the count matrix, which is in the same order what I find with Alevin. I am not sure if/where Alevin reports the number of mapped reads (maybe it is the number of hits?), but this is not of much importance. Indeed, the total UMI count is **much** lower than the number of sequenced/mapped/barcoded reads (~190M), which is expected. However, using the `--dumpUmiGraph` option provides a file ""MappedUMI.txt"" which I assume are the number of deduplicated UMIs mapped per cell/barcode (summed over all genes). The sum of over all the barcodes = 17M in this case and the sum per barcode = the sum in the quant_mat. This does not hold for the adapted cel-seq2 protocol. sum mapped UMI != summed quant_mat.gz. I am making a mistake, or is there something wrong?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/361#issuecomment-490098177:198,detect,detected,198,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/361#issuecomment-490098177,1,['detect'],['detected']
Safety,"Hi @kaukrise ,. Thanks for the very interesting question. I don't think there is any theoretical limit wrt the alevin's method, however, it would be interesting to check how does alevin performs when we increase the CB length wrt the running time. The 20 length bound was just for sanity checking and can be increased, like you already did.; I'd be very interested, if possible, in hearing back about your experience with alevin using longer length CB both wrt running time and gene expression estimates generated. Also if I may ask what's the reason behind using this long CB ? Are you expecting tons of real cells, if there is we can think about improving alevin even more, in my experience, we have generally seen individual 10x experiment with ~20k cells max. Even the 1.3M dataset is 164 separate experiments.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/445#issuecomment-550391177:281,sanity check,sanity checking,281,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/445#issuecomment-550391177,1,['sanity check'],['sanity checking']
Safety,"Hi @kzkedzierska,. I'm not sure why the virtual memory usage here is so high, and am also not aware of a great way to predict it. One thing I might ask is if you could test this executable on your system ( [salmon-1.2.0-beta](https://drive.google.com/open?id=1QHYCT3Vs9bRD7UmJY6JJKjlzmmUE4wRl)). This is the near-final beta version of 1.2.0 whose release is imminent. One of the big changes in this version is a considerably more memory-efficient construction. We have been measuring this in terms of resident memory, but it may also apply to virtual memory. Would you mind giving it a try if you have a chance?. Thanks!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/441#issuecomment-605106040:118,predict,predict,118,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/441#issuecomment-605106040,1,['predict'],['predict']
Safety,"Hi @mathog,. > Is it really the case that Salmon cannot use 1.57.0?. It may be able to. We set the minimum required version to the lowest boost version we use in any of our testing machines where we run regression tests. Currently, this is 1.59.0. If you change the relevant `CMakeLists.txt` line, you *really* need to make sure you clear out the CMake cache. You can do this by removing `CMakeCache.txt` in your build directory, as well as the directory `CMakeFiles`. However, it might be easiest just to remove and remake the entire `build` directory. You may also try passing `-DBoost_NO_SYSTEM_PATHS=Bool:ON` to your cmake command. Finally, note that the build system is probably looking for the static libraries --- you can elide that preference by modifying [this line](https://github.com/COMBINE-lab/salmon/blob/master/CMakeLists.txt#L222). Finally, since salmon uses C++11, it's important that whatever boost you link against exposes a C++11 compatible ABI. Unfortunately, `FindBoost.cmake` is the most finicky of the module finding packages I know about 😦. If you use `-DFETCH_BOOST=TRUE`, then CMake will fetch a recent boost and build the libraries it needs and link them statically. I realize you want to avoid this, so hopefully one of the ideas above will help.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/236#issuecomment-396781869:1217,avoid,avoid,1217,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/236#issuecomment-396781869,2,['avoid'],['avoid']
Safety,"Hi @mej54,. First, thanks for using salmon and for providing detailed feedback! There are two main points I'd like to make in response to the points you raise. . First, v0.9.1 is _very_ old, and there have been a large number of bug fixes and substantial improvements to salmon since that version (though it's much better than people who are still using 0.8.2 from, like, 3 years ago!). Specifically, I'd highly recommend upgrading to the latest version (1.1.0, with 1.2.0 coming out shortly). We've added (and made standard) selective-alignment, which is a procedure that provides alignment scoring for the assigned reads to avoid spurious mappings that arise with fast lightweight mapping procedures. Second, the observation of mismatching bases at the provided alignment location is the expected behavior with the mappings written by salmon with the `--writeMappings` option. Specifically, while newer versions of salmon (0.15.0 and greater) will do alignment scoring and removal of low score alignments by default, salmon still does not compute or write out a full CIGAR string for its alignments. Instead, it uses a _score-only_ dynamic program to compute the optimal alignment score at the given location, but it ""spoofs"" the CIGAR string. Thus, if there is e.g. a small indel in the read, this will show up in an IGV visualization as a large number of mismatches after that indeed location. I'm not sure that is what is happening in the screenshot you show above, and, in fact, may of these mappings may disappear with selective-alignment. However, it will definitely still be possible to see a cigar string showing full matches, where there are mismatches in IGV. This is intended behavior due to score-only alignment. However, it's also true that newer versions of salmon will report the alignment score in an `AS` tag, so that you can see how high the alignment quality was at the particular location.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/491#issuecomment-597349699:626,avoid,avoid,626,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/491#issuecomment-597349699,2,['avoid'],['avoid']
Safety,"Hi @mooreann,. So, as you can see the strand mapping bias is calculated as `0.5172763911708863`, so ~51.7%. A *perfectly* unbiased ratio would be 50%. However, there are many reasons you might see small deviations from this in your sample. Salmon is *super* conservative in reporting a _potential_ bias (anything > 1% deviation from 50/50), since raising the warning doesn't cost anything (we compute these statistics anyway), and it's better that someone who could be expecting such a thing is a aware of it than that someone notice the warning and decide it's not a problem. In this case, your sample is 0.7% above the detection threshold, and so the warning is raised. Unless you're noticing anything else that looks strange with the results, I would suggest that this probably isn't anything you need to worry about. As I mentioned, one might expect some natural variation from a ""perfect"" 50% split between reads arising in each orientation, and the bias in this data looks pretty slight; it's just that salmon is very conservative in reporting the issue. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/659#issuecomment-841483705:621,detect,detection,621,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/659#issuecomment-841483705,1,['detect'],['detection']
Safety,"Hi @moschmi ,. Thanks for sharing the file.; You are right the transcript id `PB.40054.21` is indeed present & has the gene mapping in the file you forwarded. Unfortunately, the specific error message was not useful here but the issue is the following: ; ![image](https://user-images.githubusercontent.com/8772521/85436584-45706f00-b557-11ea-9ba2-95ebf4e43bc4.png). If you check the file you forwarded from line number 12,133 - 12,137, it seems a bunch of transcript ids are blank and has no assigned gene-ids. In this case the file parser was not intelligent enough to ignore such empty mappings and end up using the next line (before) tab as the wrong mapped gene-mappings. Later, when alevin sanity checks for the mappings of all transcripts, alevin complaints about not being able to find it for a random transcript much lower in the order. In short, I know you used the bioawk script for making the transcript to gene mapping file, but the script was written with the gencode generated GTF in mind, it seems the one you have has some small difference which is creating the issue. Currently, the easiest fix is to parse the GFF file again and generate the mappings for all the transcript in the proper format. In the future, we will add a sanity check for these type of corner cases, thanks for reporting this.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/540#issuecomment-648319730:695,sanity check,sanity checks,695,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/540#issuecomment-648319730,2,['sanity check'],"['sanity check', 'sanity checks']"
Safety,"Hi @rbenel,. This message is just salmon letting you know a newer version is available. The installed version should function perfectly fine. If you really want to avoid the message, you can pass `--no-version-check` *before* the salmon command; e.g.:. ` salmon --no-version-check index ...`. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/262#issuecomment-409903345:164,avoid,avoid,164,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/262#issuecomment-409903345,1,['avoid'],['avoid']
Safety,"Hi @rfarouni ,. Please use [this](https://drive.google.com/file/d/11lav7dOQkn5VuSNZwC2CZUgx_eeXpBmx/view?usp=sharing) link to download a linux compatible binary, the fix will be available by default with the next release . > Also, does Alevin use 10x cell barcode whitelist internally to correct barcodes?. In our experiments, we find that, in expectation, the 10x generated experiments are clean enough that we don't need the 10x whitelisted barcode to be explicitly specified or used. > And do you recommend using the `--naiveEqclass` only 64 guide sequences as features ?. That's a very good question. Basically the answer lies in how complicated the UMI graph network is. Experiment with the antibody derived barcodes (ADT) with 20 protein panel, generally, doesn't need the `--naiveEqclass` mode UMI deduplication, unless the experiment is super deeply sequenced. However, for super low diversity like 4-8 barcodes e.g. for HTO like sample barcodes, the graphical network becomes exponentially hard to solve and significantly increases the running time for alevin. . In general, I'd recommend if you expect very low diversity in the number of barcodes in your experiment, use `--naiveEqclass` otherwise prefer avoiding it. Generally, the experiment with low diversity barcodes results in such a highly dense count matrix that a few error in UMI deduplication won't matter and you can tradeoff extra long running time with reasonable under/over UMI deduplicated counts. . _In short_, 64 guide sequences are relatively high diversity and I'd advise skipping `--naiveEqclass` in your command line argument. Hope it helps !",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-638576983:1215,avoid,avoiding,1215,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-638576983,2,['avoid'],['avoiding']
Safety,"Hi @rfarouni ,. Thanks a lot for raising the issue.; It looks like a corner case with the custom barcode length and I'd have to push a hot-fix for it. Basically, it's failing in the initial sanity check stage where it assumes we can provide only one single-cell protocol type. Give me like half an hour to make the changes and I'll push the fix to the develop. If you can compile salmon from source that's great, otherwise I can also forward a linux portable binary.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-638385340:190,sanity check,sanity check,190,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-638385340,1,['sanity check'],['sanity check']
Safety,"Hi @rhlampe,. Currently, there is no way to prevent the salmon indexer from using more memory if it is needed ot build the index. However, if there is a limit placed by the cluster, it will likely just result in a `bad_alloc` exception from the indexer. The number of sequences alone can tell you a bit about scaling, but the total number of nuclotides being indexed is actually a better predictor of resource usage. How many nucleotides, total, are the references you're considering? While we are working on ways to make the indexing scheme highly scalable, it's worth noting that, to achieve some of it's speed, salmon pre-computes a lot of information it its index (so that the index can become fairly large). One thing I might suggest, if you want to attempt to index and quantify on a very large reference, is to use the `--perfectHash` index in the newest development version of Salmon (pre-release tarball attached below). The latest version (for which the official version should appear soon) represents a number of improvements to index construction. The default indexer has reduced memory usage by ~40%, and the new `--perfectHash` indexer, while somewhat slower, reduces the memory usage even more (by an additional 40-50%). With a fixed memory budget, then, it should allow you to index ever larger references. --Rob. [Salmon-v0.7.3-pre_linux_x86_64.tar.gz](https://github.com/COMBINE-lab/salmon/files/512019/Salmon-v0.7.3-pre_linux_x86_64.tar.gz)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/97#issuecomment-251759242:388,predict,predictor,388,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/97#issuecomment-251759242,1,['predict'],['predictor']
Safety,"Hi @rmurray2,. Thank you for the report. First, I just want to mention that I don't believe v0.99.0 to be an officially released version number. That is, there was a v0.14.x and a (released in source only v0.15.0), and then the versions moved to 1.0.0 and beyond. However, this behavior certainly isn't related to that. There are 2 things going on that can lead to this effect. The first one, which is relatively easy to test, is that there may be small changes in when the inferred library type starts to be enforced (if it is not `IU`) when auto type detection is used (see [this issue and comments therein](https://github.com/COMBINE-lab/salmon/issues/489)). The second and more fundamental thing going on is that the observed behavior is intended. Even with a single thread of execution provided to salmon for mapping and quantification, there is a separate background thread that simply consumes reads from file and puts them in memory for quantification, and while e.g. pairing information between files is guaranteed to be preserved, exact read order is not. This can lead to differences in the order in which reads are processed and, as a result, differences in the initialization conditions of the optimization. The ultimate result is that for transcripts that have large inferential uncertainty, different numbers of reads can be assigned between runs. We have thought *a lot* about this behavior, what it means, and how the `NumRead` values should best be communicated to users. At the end of the day, the `NumReads` constitute the expected value of latent variables inferred in a _very_ high-dimensional space (# of parameters is at least the number of transcripts). Therefore, there are certain transcripts, whose estimated number of reads simply have _tremendous_ inferential uncertainty — and small perturbations in the initial conditions of the optimization will lead to different estimated values for their abundances. For those transcripts where you observe such fluctuations between",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/613#issuecomment-757989858:553,detect,detection,553,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/613#issuecomment-757989858,2,['detect'],['detection']
Safety,"Hi @rob-p , @mdshw5 , . I did a local run, it crashed again, but now at least with some more information and a core dump. ; So the process failed with this error:; ```; /bin/bash: line 1: 31345 Aborted (core dumped) /home/agosdsc/pigx/pigx_rnaseq/.guix-profile/bin/salmon quant -i /scratch/AG_Akalin/agosdsc/projects/mrg1_rnaseq/analysis_v2/salmon_index -l A -p 8 -1 /scratch/AG_Akalin/agosdsc/projects/mrg1_rnaseq/analysis_v2/trimmed_reads/N2_1_R1.fastq.gz -2 /scratch/AG_Akalin/agosdsc/projects/mrg1_rnaseq/analysis_v2/trimmed_reads/N2_1_R2.fastq.gz -o /scratch/AG_Akalin/agosdsc/projects/mrg1_rnaseq/analysis_v2/salmon_output/N2_1 --seqBias --gcBias -g /data/akalin/Base/Annotation/ce11/ENSEMBL91/Caenorhabditis_elegans.WBcel235.91.gtf >> /scratch/AG_Akalin/agosdsc/projects/mrg1_rnaseq/analysis_v2/logs/salmon_quant_N2_1.log 2>&1; ```; I uploaded the files and the dump, such that you can try to debug this: ; https://1drv.ms/f/s!AqRdeUKlw8lFjDV7eDqqQbN7cQPa",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/210#issuecomment-377190490:194,Abort,Aborted,194,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/210#issuecomment-377190490,1,['Abort'],['Aborted']
Safety,"Hi @rob-p . I had a similar problem, however, I reassemblied the new isoforms using the Hisat2+Stringtie pipeline. The mapping rate from Hisat is 96.49% but it is 65.39% in Salmon. I also noticed a high number of mappings discarded because of alignment score. I also wonder why the number of mappings discarded can be larger than num of processed (57113760, the reads number in 1_1.fq.gz). Thanks. ```; Command: salmon-latest_linux_x86_64/bin/salmon quant -i transcript -l A -1 1_1.fq.gz -2 1_2.fq.gz -p 4 -o ${out}. [2020-09-23 10:09:32.992] [jointLog] [info] Index contained 153,995 targets; [2020-09-23 10:09:33.190] [jointLog] [info] Number of decoys : 0; [2020-09-23 10:09:40.178] [jointLog] [info] Automatically detected most likely library type as ISR; [2020-09-23 10:31:17.407] [jointLog] [info] Thread saw mini-batch with a maximum of 1.68% zero probability fragments; [2020-09-23 10:31:17.467] [jointLog] [info] Thread saw mini-batch with a maximum of 1.64% zero probability fragments; [2020-09-23 10:31:17.563] [jointLog] [info] Thread saw mini-batch with a maximum of 1.66% zero probability fragments; [2020-09-23 10:31:17.573] [jointLog] [info] Thread saw mini-batch with a maximum of 1.72% zero probability fragments; [2020-09-23 10:31:18.005] [jointLog] [info] Computed 329,858 rich equivalence classes for further processing; [2020-09-23 10:31:18.005] [jointLog] [info] Counted 37,348,440 total reads in the equivalence classes ; [2020-09-23 10:31:18.009] [jointLog] [info] Number of mappings discarded because of alignment score : 120,261,413; [2020-09-23 10:31:18.009] [jointLog] [info] Number of fragments entirely discarded because of alignment score : 4,196,417; [2020-09-23 10:31:18.009] [jointLog] [info] Number of fragments discarded because they are best-mapped to decoys : 0; [2020-09-23 10:31:18.009] [jointLog] [info] Number of fragments discarded because they have only dovetail (discordant) mappings to valid targets : 569,393; [2020-09-23 10:31:18.009] [jointLog] [info]",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/533#issuecomment-697107525:718,detect,detected,718,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/533#issuecomment-697107525,1,['detect'],['detected']
Safety,"Hi @rob-p, thanks for you response! I think this answers my question, but let me ask a couple follow up questions just to be sure:. In `STAR` there is an option to use stranded alignment (`--readStrand`, which can take ""Unstranded"", ""Forward"", or ""Reverse""). For the pipeline I'm building it would be ideal if I didn't have to specify the strandedness of the library as I'm not the one preparing the samples and it's not always easy to get that information from the scientist in the lab. As such, it would be great if I can use the default strandedness argument to `STAR` (""Unstranded"") and let `salmon` ""do the right thing"" by letting it choose the `libType` for me. With that in mind, if I let `salmon` choose for me (`-l A`) am I risking throwing out any data?. In addition, if a transcript was aligned in a unstranded manner and ended up aligning to the wrong location due to ambiguity between the positive orientation of one transcript and the negative orientation of another, can `salmon` correct this by reassigning it to the right transcript based on the joint probability of all the other alignments (if you can't tell I'm at the edge of my BS zone)?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/590#issuecomment-733278723:733,risk,risking,733,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/590#issuecomment-733278723,1,['risk'],['risking']
Safety,"Hi @rob-p,. As for our main goal, we are looking at the precision of Salmon versus biological PCR expectations of abundances. However, it is on a small number of genes as there have been some initial challenges with using ""accurate"" transcripts versus ""computational predicted transcripts"". Anyway, we hope to have this paper ready this year, but again I think we need to look at it from a different angle. While this project is a bit of a side project, my hope it that it will accomplish our initial goal and to provide the community with the general behavior of Salmon with different spliced types (i.e. Exon skipping, IR, AA, AD, etc). Again, it'll be on a small set of genes, but still should be interesting and hopeful can improve the future use of Salmon. I'll make sure to let you know when it is available.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/523#issuecomment-633099524:267,predict,predicted,267,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/523#issuecomment-633099524,1,['predict'],['predicted']
Safety,"Hi @rob-p,. I am also seeking guidance on the use of Salmon for metatranscriptomes. Similar to this issue and issue #350 I am using the predicted genes from a metagenome assembly as the 'reference transcriptome' and would like to quantify gene expression from the corresponding metatranscriptome data. My metaT data is unstranded. What flags are most appropriate for this purpose? `--meta`? Something else? Are there any assumptions within Salmon that make it unsuitable for metagenomic/metatranscriptomic data (for example, the probability of observing a fragment when organisms are present at different abudances)?. Rachael",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/195#issuecomment-598522020:136,predict,predicted,136,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/195#issuecomment-598522020,2,['predict'],['predicted']
Safety,"Hi @schelhorn,. Yes; we are _actively_ looking at fusion prediction based on quasi-mapping. The initial results are promising, but we're still working on improving and refining the method. I'll be sure to let you know when we have something that is ready to test :). Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/52#issuecomment-202593692:57,predict,prediction,57,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/52#issuecomment-202593692,1,['predict'],['prediction']
Safety,"Hi @seanken,. Thank you for reporting this. I agree this error message should always show up. My guess is that this is related to the fact that the error is reported through the asynchronous logger, which is notoriously picky about how it must be torn down to avoid dropping messages on atypical (non-zero) program exit. I'll see if I can make this one show up reliably. By the way, do you have a small pair of FASTQ files that will trigger this error?. Thanks,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/736#issuecomment-1018119606:260,avoid,avoid,260,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/736#issuecomment-1018119606,1,['avoid'],['avoid']
Safety,"Hi @shalercr,. I agree that if each sample runs as quickly as you see here, it's not a big deal to just re-run them all. Note that, while my avoids ~116 times more (eventually-discarded) alignments than did yours, the difference in the number of discarded _fragments_ (i.e. fragments that had no mapping) is very small — ~7,000, or 0.023% of the fragments. Thus, despite the huge speed-up, I wouldn't expect many differences in the quantifications. However, I couldn't argue against re-quantifying everything with the new version just for good measure :). When you have a chance, please do let me know if you see this same performance difference using the pre-compiled (linux) binary [here](https://drive.google.com/file/d/1tPyOPW3Y8l86RS0-zBRLh0wCt3VTpkNw/view?usp=sharing). Of course, once we finalize this release (soon), we will push to bioconda so we will also have OSX binaries available. However, I just want to make sure this fixes things on your end as well before the release.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/537#issuecomment-644796608:141,avoid,avoids,141,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/537#issuecomment-644796608,1,['avoid'],['avoids']
Safety,"Hi @shilpagarg, did you find a solution for the warning below?. `WARNING: Detected suspicious pair ---; The names are different:; read1 : SRR764782.282; read2 : SRR764782.283`",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/131#issuecomment-1219488397:74,Detect,Detected,74,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/131#issuecomment-1219488397,1,['Detect'],['Detected']
Safety,"Hi @silvernano,. Though alignment stringency parameters can have an effect here, the problem of comparing the abundance of a specific transcript within the context of different annotations is more fundamental. That is, apart from the transcript of interest, the ""background"" of related transcripts may be different. Consider the following case:. You have an annotation with 2 transcripts annotated for your gene:. ```; [A, B, C]; [A,C]; ```. Where `A`, `B`, and `C` are exons and the `[A,B,C]` notation means the transcript is exon `A`, followed by `B`, followed by `C`. Now, imagine that in annotation 2, you just have:. ```; [A,C]; ```. That is, the other isoform `[A, B, C]` is missing from annotation 2. Now, imagine that, in reality, `[A,B,C]` is highly expressed in your sample and `[A,C]` is lowly expressed. Under annotation 1, you get (correct) high expression for `[A,B,C]` and low expression for `[A,C]`. However, in annotation 2, since you still have to describe the `A` reads and the `C` reads, you get high expression for `[A,C]` since the reads contained within `A` and within `C` still map well there — the reads that map to `B` and to the `A-B` and `B-C` junction will likely just go un-mapped (which explains a difference in mapping rate). Now if you compare `[A,C]` across databases ... you will see big differences. This is not really related to the alignments that are observed, but rather how the data (reads) must be explained conditioned on the transcriptome (annotation) you have available. In other words, in loci with substantial unannotated transcription, the annotation used can definitely have a considerable effect on the quantification results. How to best assess, detect, and mitigate these effects is an active area of research, but I can point you at papers like [this](https://www.life-science-alliance.org/content/2/1/e201800175) and [this](https://www.cell.com/cell-systems/pdfExtended/S2405-4712(19)30381-3).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/525#issuecomment-639057440:1697,detect,detect,1697,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/525#issuecomment-639057440,1,['detect'],['detect']
Safety,"Hi @tamuanand & @k3yavi,. Actually, I think the `makefasta` bedtools command we use accepts a gff file directly (https://bedtools.readthedocs.io/en/latest/content/tools/maskfasta.html). So, it might make sense to have a flag (or automatically detect, but that can be error prone), and only run the line Avi links above if we have a GTF. If we have a BED or GFF file, we can just pass it directly to bedtools.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/384#issuecomment-503627124:243,detect,detect,243,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/384#issuecomment-503627124,1,['detect'],['detect']
Safety,"Hi @tobi-te ,; Salmon is a two-phase algorithm i.e. online and offline. The first phase i.e. online-phase learns various parameters before starting the offline-phase (order doesn't matter). Like most online learning algorithm Salmon also expects the input to be randomized enough to avoid bias or in the case of Salmon *possibly* nudge the offline-phase towards a local-minima, which can vary according to the data (not always). I think in your case even though the learnt online parameters are biased (because of non-random order) the estimated abundances at the end are corrected by the offline-phase pretty well and you are observing the similar results.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/155#issuecomment-331262951:283,avoid,avoid,283,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/155#issuecomment-331262951,2,['avoid'],['avoid']
Safety,"Hi @uniqueg,. Yes, it would. However, it's worth noting that `--skipQuant` does not usually shave that much time off of the run. Specifically, it only eliminates the quantification step, but not the alignment of all of the reads. On the other hand, library type detection chooses a library type after the first ~10,000 mapped reads. If you would like to use this flag for library type detection, I'd recommend something like the following. Feed your input to salmon using the `--skipQuant` option, but only fix it a small prefix of the read set (maybe the first 100,000 reads or so). This way, it will run quickly, not attempt to do quantification, and still provide you with an inferred library type. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/138#issuecomment-585812231:262,detect,detection,262,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/138#issuecomment-585812231,2,['detect'],['detection']
Safety,"Hi @yeodynasty,. This is because of the unfortunate conventions regarding the parsing of command line options in the presence of a flag that has an _implicit_ option. Specifically, the `--writeMappings` flag has an implicit option. Therefore, to provide an explicit option to the long-form argument flag, you must use the syntax `--writeMappings=<outputdir>`. So, your command would look something like:. ```; /gpfsdata/apps/salmon-latest_linux_x86_64/bin/salmon quant; -i /gpfshome/hockchuan/SALMON/GCF_900626175.2_cs10_index; -l ISR; -1 /gpfsdata/JangiLab/hockchuan/170302/2.Trimmomatic_output/clean_HEADBANDSTEM_1.fastq.gz; -2 /gpfsdata/JangiLab/hockchuan/170302/2.Trimmomatic_output/clean_HEADBANDSTEM_2.fastq.gz; --seqBias; --gcBias; --posBias; --incompatPrior 0.0; --geneMap /gpfsdata/JangiLab/hockchuan/cs10_reference_genome/GCF_900626175.2_cs10_genomic.gtf; --recoverOrphans; --allowDovetail; --threads $NSLOTS; --dumpEq; --minScoreFraction 0.65; --writeMappings=/gpfshome/hockchuan/SALMON/MAP/HEADBANDSTEM; --fldMean 250; --fldSD 25; --writeOrphanLinks; --writeUnmappedNames; --quiet; -o /gpfshome/hockchuan/SALMON/HEADBANDSTEM_quant; ```. let me know if this resolves your issue. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/573#issuecomment-709323564:868,recover,recoverOrphans,868,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/573#issuecomment-709323564,1,['recover'],['recoverOrphans']
Safety,"Hi Avi, thanks for your detailed explanation!. From my understanding: a pre-selection of high-quality cells based on 1) CB frequency - finding the knee point (in the initial whitelisting) and 2) other features (in finalized/intelligent) whitelisting is performed in alevin, while [cell ranger count](https://support.10xgenomics.com/single-cell-gene-expression/software/pipelines/latest/algorithms/overview#cell_calling) does step 1) related to the `--expectCells` number and used an alternative method w/o knee point estimation. . Based on above, the newly included cells w/ increased number of `--expectCells` are also more likely to be filtered out in later steps using criteria such as `min of number of features/reads` detected per sample. But such filtering may not be expected if interests are also on cells with small transcriptomes such as TILs. I will try some downstream filtering to see how many good cells I can get. . Yeah it helps - thanks!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/396#issuecomment-510639440:723,detect,detected,723,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/396#issuecomment-510639440,1,['detect'],['detected']
Safety,"Hi Bill,. You probably shouldn't be including the transcript version number (the; trailing . 2) when using grep, to be safe. It's possible that you could; have a different transcript version so there isn't any profit in being so; exact. Jim. On Fri, Oct 12, 2018, 9:03 PM wedelma <notifications@github.com> wrote:. > Hi Rob,; >; > Thanks to both you and Jim for helping with this, since I'm the one who; > actually need some help. I've tried indexed using v0.11.0 then the latest; > version. Both, with the same transcriptome you tried doesn't result in; > duplicates when I grep ""ENST00000617214.2"". Telling me I'm getting a; > different result from your grep. I don't know why. I will be downloading; > the latest version of the human transcriptome and using latest salmon to; > index, and I should see these duplicate transcripts in the duplicate; > clusters file, like you did, likely resolving my issue. We had older data; > which is why I used an older version of the human transcriptome, which I; > will not be doing anymore. I'll keep you posted and thanks for the help!; >; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/COMBINE-lab/salmon/issues/301#issuecomment-429498684>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AFqmvIVbfG6l9DaQQiKnkYPO1UGGQQ90ks5ukTvAgaJpZM4XaDfK>; > .; >",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/301#issuecomment-429499670:119,safe,safe,119,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/301#issuecomment-429499670,1,['safe'],['safe']
Safety,"Hi Holley,. Thanks for the response: Here are some followup thoughts . >It's strange that once all three have been compiled into a single assembly using Evigene, salmon detects the ISR library type. When I change the ""A"" to ""ISR"" or ""IU"", the % mapped changes a lot. That does seem strange, but I honestly don't know much about `Evigene` or what it's doing in combining these assemblies. When you specify ""IU"", the mappings will generally be _more_ lenient (i.e. you'd expect to get more mappings) than when you specify ""ISR"". The ""A"" flag just looks at how the first 10,000 reads map and guesses the library type based on that. On thing to make sure of is that your reads aren't ""ordered"" in any way, such that you'd expect the first 10,000 to deviate in any meaningful way from the statistics of the reads of the reads. > Is it better to build assemblies with strand-aware flags? If so, does it usually make a large difference to quantification results, or a minor one? I don't know what protocol the sequencing facility used, but I am sure I could ask them. I gather from my recent reading that the extra information gained by using a stranded protocol is worthwhile, so I would expect that the sequencing facility used one, but why doesn't Trinity or MEGAHIT detect the sequecing protocol that was used? . So there are really 2 questions here. *If* the data are stranded, then yes, it's worthwhile to use stranded flags in both assembly and quantification. This is because stranded protocols will allow you to better disambiguate (a) overlapping genes and (b) reads that are ambiguous between sequence-similar genes that happen to reside on different strands. The *second* question is why Trinity or MEGAHIT wouldn't detect this. The main reason for this is that these are assembly tools. Without access to a reference genome, there is no principled way for these tools to know what the orientation of a read is _a priori_, so they generally rely on the user to specify if the reads are stranded o",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/840#issuecomment-1493034427:169,detect,detects,169,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/840#issuecomment-1493034427,1,['detect'],['detects']
Safety,"Hi Kivanc,. Thanks for the kind words, and thank you for the _extremely detailed_ report. Reports like this are a model of what every developer wishes a user did before filing an issue :). First, let me clear up what seems like might be a small source of confusion. Since both of the salmon runs are from v1.1.0, _neither_ of these are making use of quasi-mapping. Specifically, newer versions of salmon _only_ perform selective alignment (and this makes the `--validateMappings` command line argument redundant in newer versions, though we keep it so as to maximize backward compatibility with command line parameters people may be using). So, the main difference between your two salmon runs is inclusion of the decoy set. This almost certainly means that the reads that map in your second set of salmon runs but not your first are being assigned to decoys in the first case. To try and get a better handle on this, could you upload a `meta_info.json` file from both runs? This file lives in the `aux_info` directory, and it will provide information about e.g. how many reads were best mapped to decoys and were discarded for this reason. The guarantee you get from the selective alignment is that, if the fragment is discarded by decoy mapping, it maps _strictly better_ to the decoy than to the non-decoy sequence. There are many reasons this could happen. One is rRNA contamination, another could be that reads are coming from processed pseudogenes that are not properly in your annotation, yet a third is that your sample has a considerable fraction of reads spanning exon-intron junctions (in this case, the read will map better to the corresponding location on the genome, and worse to the annotate transcript where the intronic sequence is not present). Now, figuring out exactly which of these cases you are in is a bit more difficult, but one approach would be to pick one of the samples with the biggest differences and map to the reads to the genome with e.g. STAR or HISAT2 to see what y",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/479#issuecomment-578848875:502,redund,redundant,502,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/479#issuecomment-578848875,2,['redund'],['redundant']
Safety,"Hi Kristoffer,. The duplicate transcript issue is a frustrating one. It came to our attention when we noticed that ensembl often annotated transcripts on patch / haplotype contigs that were identical and unlikely to be different from more ""canonical"" transcripts in any way. Further, these transcripts are indistinguishable from the quantification perspective. That being said, the removal of sequence duplicate transcripts is optional in Salmon. If you pass `--keepDuplicates` to the indexer, it wont remove them. Also, Salmon does record, in the index directory, the ""collapsing map"". Specifically, there is a tsv file that record, for every collapsed transcript, the transcript that was sequence identical and retained in the index. You can use this map to recover the abundances for the collapsed transcripts, since they are all sequence identical, they should all have an abundance of x / num duplicates (where x is the abundance of the retained transcript). I hope this info helps. Let me know if there is anything else i can clarify or help with. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/214#issuecomment-381580235:760,recover,recover,760,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/214#issuecomment-381580235,1,['recover'],['recover']
Safety,"Hi Pete,. Yup, this would be my recommended way to handle it. Since salmon accepts streaming input, you could do something like:. ```; salmon quant -i index -l A -1 <(gzcat rep1_muliplex1_1.fq.gz rep1_mutliplex2_1.fq.gz) -2 <(gzcat rep1_multiplex1_2.fq.gz rep1_multiplex2_2.fq.gz) [other options etc.]; ```. to avoid creating the intermediate concatenated files on disk. This will treat all the multiplexed samples from the same replicate as one giant input read stream (conceptually representing a single replicate). As far as merging / combining Salmon output, if you're doing the downstream analysis in R, the tximport package is nice. Otherwise, @vals has a python tool [readquant](https://github.com/Teichlab/readquant) that can also do some merging. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/88#issuecomment-245412770:311,avoid,avoid,311,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/88#issuecomment-245412770,1,['avoid'],['avoid']
Safety,"Hi Rob and val,; I re-compare the number of detected gene of a new data set (PE100, 96 cells, N.Wilson 2015 Cell Stem Cell) with featureCounts, Salmon and Kallisto. All the three has similar gene detected number in which k-mer based methods produce a slight higher gene number. I guess it's mainly due to the the fact that whether multimapping reads are taken into account. Anyway, it confirms my guess about the the issue described above may just because quasi-mapping is not so friendly with short single end reads, which may introduce a huge ambiguity in the quantitation process. Since my own data set won't be short and single-end, I suppose I will keep using salmon to analyze my data in the future. Thanks for your contribution and help to this issue.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/120#issuecomment-282327027:44,detect,detected,44,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/120#issuecomment-282327027,2,['detect'],['detected']
Safety,"Hi Rob,. I don't have git (don't have root access on the red hat server im on). I downloaded the salmon-master.zip, and then tried running the following:. ```; [bernsteinnj@lngnode1 salmon-master]$ cmake . . -- The C compiler identification is GNU 4.4.7; -- The CXX compiler identification is GNU 4.4.7; -- Check for working C compiler: /usr/bin/cc; -- Check for working C compiler: /usr/bin/cc -- works; -- Detecting C compiler ABI info; -- Detecting C compiler ABI info - done; -- Check for working CXX compiler: /usr/bin/c++; -- Check for working CXX compiler: /usr/bin/c++ -- works; -- Detecting CXX compiler ABI info; -- Detecting CXX compiler ABI info - done; CMake Error at CMakeLists.txt:69 (message):; Salmon requires g++ 4.7 or greater.; ```. I'm trying now with -k 27 with the original build I had. Keep you updated. Best",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/53#issuecomment-203018082:408,Detect,Detecting,408,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/53#issuecomment-203018082,4,['Detect'],['Detecting']
Safety,"Hi Rob,. Thanks for being so interested in this! I'm blown away by your support. And thank you for preemptively fixing the bug before I could even post an example!. > One piece of software you might look into is [Salmon Anomaly Detection](https://github.com/Kingsford-Group/sad) (paper [here](https://www.cell.com/cell-systems/pdf/S2405-4712(19)30381-3.pdf)). This is sort of akin to what you are suggesting, and post-processes salmon output by looking for anomalous coverage profiles. It can both flag ""suspicious"" transcripts, and can also sometimes move reads around to mitigate anomalous coverage. Another tool / metric you might consider is the junction coverage compatibility (paper [here](https://www.life-science-alliance.org/content/2/1/e201800175)). Excellent papers! Definitely going to give those tools a try on my data. > So, I **completely agree** that a lightweight version of something like SAD would be great to have built _into_ salmon. Specifically, it makes a lot of sense to have some component of the likelihood account for the coverage profile of transcripts. Yes! I've been analyzing a large dataset and my real motivating problem was not really the example I posted above, but distinguishing between pre-processed and fully-processed non-coding RNA transcripts. I'm attaching an image showing an example ncRNA; the two tracks are the same data, but the lower one shows abundance on a log scale. In this particular sample, it's easy to estimate that ~5-10% of the transcripts are pre-processed (the transcripts still have neighboring genomic DNA). I wanted to see how this ratio changes between samples (for example, in a snoRNA processing-defective mutant strain), but quickly realized this is not easily done in salmon or any other quant tools because the processed transcript is entirely a subset of the sequence of the pre-processed transcript. The only way to accurately quantify it is to use the coverage information, which as you agreed is not really taken into account ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-623963851:228,Detect,Detection,228,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-623963851,1,['Detect'],['Detection']
Safety,"Hi Rob,. The joint distribution of the read and UMI counts can contain important information. The majority of observations (CB + guide combination) lie along a well defined experiment-specific mean trend whose slope is given by the coverage ( ratio of reads to UMIs). Also the same regularity can be observed when aggregating across the cell barcodes. See figure below. The points below the black horizontal line are cells with less than 100 reads. ![image](https://user-images.githubusercontent.com/9895004/83791774-30937080-a668-11ea-9b44-937ba8f69b34.png). At the guide level, it would look like this . ![image](https://user-images.githubusercontent.com/9895004/83792096-941d9e00-a668-11ea-9b26-976332f639fe.png). In general, I often find myself needing to work with read counts. For example, the read counts can be used to estimate the hopping rate and detect hopped reads in multiplexed scRNAseq data as we show in this recent paper https://www.nature.com/articles/s41467-020-16522-z . Rick,",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-639005220:857,detect,detect,857,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-639005220,2,['detect'],['detect']
Safety,"Hi Rob,; Thanks for your help and advice. No, I built the index on my office machine. I will return home this weekend to give salmon a try on my office computer. In the meantime, I will try rebuilding the index on my laptop to see if that makes things work. I will get back to you when I have some answers just to let you know what happened.; All the best,; Grant. Grant R. Cramer; Professor; Department of Biochemistry and Molecular Biology, Howard Building Room 205, Mail Stop 330; University of Nevada, Reno; Reno, NV 89557; (775) 784-4204; cramer@unr.edu<mailto:cramer@unr.edu>; http://www.ag.unr.edu/cramer/. On Mar 22, 2018, at 6:21 PM, Rob Patro <notifications@github.com<mailto:notifications@github.com>> wrote:. Hi @grantcramer<https://na01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Fgrantcramer&data=01%7C01%7Ccramer%40unr.edu%7C54d34feceb114e30a61b08d5905c7a7b%7C523b4bfc0ebd4c03b2b96f6a17fd31d8%7C1&sdata=w1ED%2B5ZBUY6Z8fTiIs62IZJizv0HcvVzw8CtfEdK32E%3D&reserved=0>,. I was able to successfully index and map against the fasta file you link above (on linux). I was also able to index and map against the index on OSX, using the salmon from bioconda (v 0.9.1). So, I'm not yet able to reproduce this. It seems the file you uploaded for your pre-built index is no longer available, so I couldn't try that out. I'd be happy to give it a try if you can put it up on dropbox or some such. Otherwise, I wonder if there could be some sort of binary compatibility issue. Did you build the index on the same machine you're quantifying on? The OSX I tested on is 10.13.1. Best,; Rob. —; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://na01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2FCOMBINE-lab%2Fsalmon%2Fissues%2F209%23issuecomment-375509050&data=01%7C01%7Ccramer%40unr.edu%7C54d34feceb114e30a61b08d5905c7a7b%7C523b4bfc0ebd4c03b2b96f6a17fd31d8%7C1&sdata=5XDT2ix1q1Uz%2B3kTchI%2B5K9Hzu7UuGkyQAz",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/209#issuecomment-375513800:750,safe,safelinks,750,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/209#issuecomment-375513800,1,['safe'],['safelinks']
Safety,"Hi Rob,; That seemed to be the problem. I rebuilt the index on my laptop and salmon worked perfectly on my laptop!; Thanks,; Grant. On Mar 22, 2018, at 6:21 PM, Rob Patro <notifications@github.com<mailto:notifications@github.com>> wrote:. Hi @grantcramer<https://na01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Fgrantcramer&data=01%7C01%7Ccramer%40unr.edu%7C54d34feceb114e30a61b08d5905c7a7b%7C523b4bfc0ebd4c03b2b96f6a17fd31d8%7C1&sdata=w1ED%2B5ZBUY6Z8fTiIs62IZJizv0HcvVzw8CtfEdK32E%3D&reserved=0>,. I was able to successfully index and map against the fasta file you link above (on linux). I was also able to index and map against the index on OSX, using the salmon from bioconda (v 0.9.1). So, I'm not yet able to reproduce this. It seems the file you uploaded for your pre-built index is no longer available, so I couldn't try that out. I'd be happy to give it a try if you can put it up on dropbox or some such. Otherwise, I wonder if there could be some sort of binary compatibility issue. Did you build the index on the same machine you're quantifying on? The OSX I tested on is 10.13.1. Best,; Rob. —; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://na01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2FCOMBINE-lab%2Fsalmon%2Fissues%2F209%23issuecomment-375509050&data=01%7C01%7Ccramer%40unr.edu%7C54d34feceb114e30a61b08d5905c7a7b%7C523b4bfc0ebd4c03b2b96f6a17fd31d8%7C1&sdata=5XDT2ix1q1Uz%2B3kTchI%2B5K9Hzu7UuGkyQAz8KB9ko4o%3D&reserved=0>, or mute the thread<https://na01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Fnotifications%2Funsubscribe-auth%2FAj0RizznzcCphH-HJ9Q8uXvndQ4Lsg9Oks5thE43gaJpZM4Sw28q&data=01%7C01%7Ccramer%40unr.edu%7C54d34feceb114e30a61b08d5905c7a7b%7C523b4bfc0ebd4c03b2b96f6a17fd31d8%7C1&sdata=7DLxrFx74WqeN71%2Bs5cfSxEA1NRxj%2F7uqvp9SrGgjck%3D&reserved=0>.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/209#issuecomment-375683475:268,safe,safelinks,268,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/209#issuecomment-375683475,3,['safe'],['safelinks']
Safety,"Hi Victor,. Is it the case that `/n/data1/cores/bcbio/ej_rnaseq/tCells_KO/work/spikein/Flox5YFP0_B07_R/index` is an index of only your genes of interest? If so, that would explain what you're seeing. Salmon assumes that some non-zero fraction of reads map in your sample. In this case, I'd presume that if you have some samples where no reads map to any transcript of your gene of interest, then salmon will complain in exactly the manner mentioned above. Now that I think about it, there are actually two different scenarios that can cause the above. The first is if something goes wrong in the optimization (there should be no way for this to happen, and so it would be the result of a bug if it did). The second is actually if there are no mappable reads. That's not the result of a bug, or even an ""error"" per-se, but just very unexpected input (since, in a typical scenario, this would imply the reads are unmatched with the reference). It might make sense to handle this case separately. However, this is certainly what is causing the output in your case, and you can safely assume that here, were it not for this specific check, Salmon would return an estimated count of 0 for all transcripts in the index.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/119#issuecomment-278743839:1074,safe,safely,1074,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/119#issuecomment-278743839,1,['safe'],['safely']
Safety,"Hi again,. Together with Mark Miller (JHPCE's admin) we ran more tests. We verified that `Salmon` does indeed use at least 2 threads so now I'm always requesting 2 from SGE. We also noticed that when the jobs fail due to memory (the actual issue in this thread) they fail after the `There is 1 library` message as shown below for one test:. ```; [2017-04-05 14:28:09.021] [jointLog] [info] parsing read library format; [2017-04-05 14:28:09.035] [jointLog] [info] There is 1 library.; terminate called without an active exception; /cm/local/apps/sge/var/spool/compute-064/job_scripts/420662: line 31: 28651 Aborted (core dumped) /dcl01/lieber/ajaffe/Emily/RNAseq-pipelin; e/Software/Salmon-0.8.2_linux_x86_64/bin/salmon quant -i /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode; .v25.transcripts -p 1 -l ISR -1 ${FILE1} -2 ${FILE2} -o /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test7/${ID}; ```. Files that work well, keep on going:. ```; [2017-04-05 14:30:23.757] [jointLog] [info] parsing read library format; [2017-04-05 14:30:23.767] [jointLog] [info] There is 1 library.; [2017-04-05 14:30:24.378] [jointLog] [info] Loading Quasi index; ```. I don't know if that hint makes you suspect anything in `Salmon`. . Now, for some tests only task 2 runs and it turns out that task 2 has a smaller fastq file than the other 2:. ```bash; $ ls -lh merged_fastq/R1000[1-3]*; -rw-r--r-- 1 lcollado lieber_jaffe 6.2G Feb 20 12:39 merged_fastq/R10001_D2B1WACXX.fastq.gz; -rw-r--r-- 1 lcollado lieber_jaffe 6.3G Feb 20 12:40 merged_fastq/R10001_D2B1WACXX_read2.fastq.gz; -rw-r--r-- 1 lcollado lieber_jaffe 4.6G Feb 20 12:42 merged_fastq/R10002_C29P7ACXX.fastq.gz; -rw-r--r-- 1 lcollado lieber_jaffe 4.7G Feb 20 12:44 merged_fastq/R10002_C29P7ACXX_read2.fastq.gz; -rw-r--r-- 1 lcollado lieber_jaffe 7.1G Feb 20 12:47 merged_fastq/R10003_D19KGACXX.fastq.gz; -rw-r--r-- 1 lcollado lieber_jaffe 7.1G Feb 20 12:50 merged_fastq/R10003_D19KGACXX_read2.fastq.g",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:606,Abort,Aborted,606,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,1,['Abort'],['Aborted']
Safety,"Hi k3yavi, yes you are correct regarding 1,2 & 3. Howver, at step 2, I generated mapped files as two separate files, *.R1.paired.fastq, *.R2.paired.fastq and individual *.singletons.fastq file. Used Hisat2 using -1, -2 and -U parameters with the respective files and generated bam files - used these files in Salmon then and encountered the error.; I can run Hisat2 again without the -U option and see if Salmon works!!. In a separate run, I used transcriptome.fasta file in the 1st step and generated bam file using Hisat2. Then used bam file in Salmon using transcriptome.fasta in the -t flag. Error below:. WARNING: Detected suspicious pair --- ; 	The names are different:; 	read1 : HWI-7001326F:36:C7J2GANXX:4:1302:8789:95937; 	read2 : HWI-7001326F:36:C7J2GANXX:4:2204:6152:63667; 	The proper-pair statuses are inconsistent:; read1 [HWI-7001326F:36:C7J2GANXX:4:1302:8789:95937] : proper-pair; mapped; matemapped. read2 : [HWI-7001326F:36:C7J2GANXX:4:1302:8789:95937] : no proper-pair; mapped; matenot mapped. [2017-07-07 10:53:31.160] [jointLog] [warning] . Does the bam files need to be sorted before using Salmon? Thanks",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/140#issuecomment-313546915:619,Detect,Detected,619,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/140#issuecomment-313546915,1,['Detect'],['Detected']
Safety,"Hi vals,; Cutoffs for Salmon as well as STAR+featurecounts/RSEM are all >0, no matter it is normalized value (RPKM, TPM) or rawcount. To my knowledge, there shouldn't be a hugh difference between different pipeline in terms of number of detected genes. Somehow, I think Salmon is over-sensitive to some extent. It's good to know that there will be small >0 expression on most genes. That makes the thing clear~. Best!; Gary",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/120#issuecomment-279960488:237,detect,detected,237,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/120#issuecomment-279960488,2,['detect'],['detected']
Safety,"Hi vals,; I don't know the correlation between Salmon and featureCounts pipelines. However, I've just done similar counting with htseq-count (-m union) . The result of gene number is similar (just slightly higher) to featureCounts (w/o multimapped reads). ; https://flic.kr/p/RXy39z; As far as I can tell, count-based methods performs similarly. The number of detected gene is within expectation.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/120#issuecomment-279985466:360,detect,detected,360,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/120#issuecomment-279985466,1,['detect'],['detected']
Safety,"Hi vals,; Interestingly, I just did the gene number summary for both Salmon and featureCounts. Cutoffs are counts >=5. Still, Salmon gives a roughly 2-fold increment on detected gene number. See from links as follows,; Salmon:; https://flic.kr/p/QRZhVq; featureCounts:; https://flic.kr/p/RXw7FK; I was wondering if my Salmon code attached above was wrong. Best!; Gary",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/120#issuecomment-279978182:169,detect,detected,169,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/120#issuecomment-279978182,1,['detect'],['detected']
Safety,"Hi vals,; Yes, the data is single end 43bp. Which is very short! So I set the k=19 when doing Salmon indexing for quasi-mapping. My featureCounts script is as follow.; #!/bin/bash. GTF=/home1/garyhe/workingdir/ref/gencode/gencode.v25.primary_assembly.annotation.ercc.gtf. cd /home1/garyhe/workingdir/data/bjorklund2016ni/01_aligned. featureCounts *Aligned.sortedByCoord.out.bam -M -T 24 -a $GTF -o /home1/garyhe/workingdir/data/bjorklund2016ni/02_quant/ilc.unprocessed.matrix.txt. cd /home1/garyhe/workingdir/data/bjorklund2016ni/02_quant/. cat ilc.unprocessed.matrix.txt | cut -f1,7- | sed 1d > ilc.matrix.txt. Actually, multimapped reads were all taken into account with the -M option. . And as a matter of fact, a gene counting without multimapped reads was also done. The number of detected gene (cutoff=5) was even lower :(; https://flic.kr/p/S9sPp4",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/120#issuecomment-279981603:786,detect,detected,786,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/120#issuecomment-279981603,1,['detect'],['detected']
Safety,"Hi,; I'm having a similar issue with specification of library type. I'm quantifying a single-end library of type SF with salmon 1.3.0. ; The two commands being compared are:. auto detect:. salmon --no-version-check quant --writeMappings -i target --incompatPrior 0.0 --validateMappings -l A -r d218056_dedup.fastq -p 4 -o d218056_A.quant > d218056_A.sam. specify SF:. salmon --no-version-check quant --writeMappings -i target --incompatPrior 0.0 --validateMappings -l SF -r d218056_dedup.fastq -p 4 -o d218056_SF.quant > d218056_SF.sam. The log files indicate that salmon correctly identifies the library as SF in the auto case. I noticed the issue when examining a pair of genes with overlapping 3'UTRs. The forward strand gene (GQ67_03478) is expressed at a much lower level than the reverse strand gene (GQ67_03479). The sam files contain the same number of reads mapped to each transcript without regard to how the libtype is specified:. egrep -v '^@' d218056_A.sam|grep -c GQ67_03478 ; 382; egrep -v '^@' d218056_A.sam|grep -c GQ67_03479; 399; egrep -v '^@' d218056_SF.sam|grep -c GQ67_03478 ; 382; egrep -v '^@' d218056_SF.sam|grep -c GQ67_03479; 399. The quantitation is very different with 120 counts assigned to the forward strand gene in the A case and a much more accurate (based on examination of the sam file) 10 counts in the SF case:. grep GQ67_03478 d218056_A.quant/quant.sf ; GQ67_03478T0 2914 2664.000 202.831978 119.926. grep GQ67_03478 d218056_SF.quant/quant.sf ; GQ67_03478T0 2914 2664.000 17.066270 10.000. For the reverse strand gene, the auto case undercounts due to reads being assigned to the forward strand gene. grep GQ67_03479 d218056_A.quant/quant.sf ; GQ67_03479T0 1383 1133.000 1245.013842 313.074. grep GQ67_03479 d218056_SF.quant/quant.sf ; GQ67_03479T0 1383 1133.000 1589.051981 396.000. I've been using salmon with -l A thinking that if the software correctly recognizes the libtype, the results would be nearly identical to explicitly specifying the libtype but th",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/489#issuecomment-738804437:180,detect,detect,180,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/489#issuecomment-738804437,1,['detect'],['detect']
Safety,Hi. I'm having a similar issue. When I run the Salmon exec I get:. `MacBook-Pro-31:~ alex$ /Users/alex/Desktop/Code/Salmon-v0.8.0_macOS_10.12/bin/salmon ; exit;; dyld: Library not loaded: /usr/local/opt/tbb/lib/libtbbmalloc_proxy.dylib; Referenced from: /Users/alex/Desktop/Code/Salmon-v0.8.0_macOS_10.12/bin/salmon; Reason: image not found; Abort trap: 6; logout; `. I'm running Sierra 10.12.2. Can you advise? What do I specifically need to do to get Salmon to work?. Thanks.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/117#issuecomment-279257362:342,Abort,Abort,342,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/117#issuecomment-279257362,1,['Abort'],['Abort']
Safety,"I am also interested in this approach. I have paired-end bulk-RNAseq with UMIs in order to avoid duplicates. I have three fastq's per sample : 1 UMI, 2 and 3 paired-end FASTQ My aim is if I can use alevin in this way. salmon alevin -l ISR -1 UMI.fq.gz -2 Sample_read_1.fq.gz Sample_read_2.fq.gz. Thanks in advance",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/306#issuecomment-446171558:91,avoid,avoid,91,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/306#issuecomment-446171558,1,['avoid'],['avoid']
Safety,"I am assuming what you are looking for is the ""effective lengths"" of the transcripts i.e. not just the original transcript lengths but instead corrected based on the quantification model. I think it's going to be tricky to generate that because of two major reasons: (1) salmon model does not perform length correction in single-cell mode mainly due to 3' single-end sequencing of the read it's hard to reliably estimate the fragment lengths (2) salmon in single-cell mode performs quantification at gene-level which makes it harder to predict effective length of the transcripts.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/693#issuecomment-916889943:536,predict,predict,536,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/693#issuecomment-916889943,1,['predict'],['predict']
Safety,"I am unsure what qualifies as many but on an input of 20M reads and an unsorted BAM file, I get around 600 lines of error in the log file, some of the reads have many alignments so the errors are redundant to some extent. The no. of unique reads' alignments that cause an error is perhaps 300.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/701#issuecomment-1427049939:196,redund,redundant,196,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/701#issuecomment-1427049939,1,['redund'],['redundant']
Safety,"I am using the following commands:. ```; ./bin/salmon index -t ../Homo_sapiens.GRCh37.75.cdna.all.fa.gz -i transcripts_index --type quasi -k 31. ./bin/salmon quant -l A -i transcripts_index -r ../../rnaseq_data/SRR764785.fastq ../../rnaseq_data/SRR764786.fastq ../../rnaseq_data/SRR764787.fastq ../../rnaseq_data/SRR764788.fastq ../../rnaseq_data/SRR764789.fastq ../../rnaseq_data/SRR764790.fastq ../../rnaseq_data/SRR764791.fastq ../../rnaseq_data/SRR764792.fastq ../../rnaseq_data/SRR764793.fastq ../../rnaseq_data/SRR764794.fastq ../../rnaseq_data/SRR764795.fastq ../../rnaseq_data/SRR764796.fastq ../../rnaseq_data/SRR764797.fastq ../../rnaseq_data/SRR764802.fastq ../../rnaseq_data/SRR764803.fastq ../../rnaseq_data/SRR764804.fastq ../../rnaseq_data/SRR764805.fastq ../../rnaseq_data/SRR764806.fastq ../../rnaseq_data/SRR764807.fastq ../../rnaseq_data/SRR764808.fastq ../../rnaseq_data/SRR764809.fastq ../../rnaseq_data/SRR764810.fastq ../../rnaseq_data/SRR764811.fastq ../../rnaseq_data/SRR764812.fastq ../../rnaseq_data/SRR764813.fastq -1 ../../rnaseq_data/SRR764782_1.fastq ../../rnaseq_data/SRR764783_1.fastq ../../rnaseq_data/SRR764784_1.fastq -2 ../../rnaseq_data/SRR764782_2.fastq ../../rnaseq_data/SRR764783_2.fastq ../../rnaseq_data/SRR764784_2.fastq -o transcripts_quant; ```; and I get the following error and no .sf file in output:; ```; processed 783000000 fragmentsrag: 3.56267[2017-04-11 20:17:10.337] [jointLog] [info] Automatically detected most likely library type as IU; hits: 184962311, hits per frag: 0.236263couldn't dequeue read chunk; couldn't dequeue read chunk; couldn't dequeue read chunk; couldn't dequeue read chunk; ```. Am I using the commands wrong?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/131#issuecomment-293391845:1454,detect,detected,1454,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/131#issuecomment-293391845,1,['detect'],['detected']
Safety,I can confirm this avoids the problem. Thanks Rob. I used rsem-prepare-reference with the GTF and genome FASTA and used the transcripts.fa produced by rsem with salmon quant. No problems. One minor thing I noticed is that the `libParams` dir is empty with or without GC bias still. Is that expected with the alignment based quantification?,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/104#issuecomment-267608771:19,avoid,avoids,19,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/104#issuecomment-267608771,1,['avoid'],['avoids']
Safety,"I can't reproduce this using 0.11.2 on Galaxy (18.05, not that that should matter) with a slurm (17.02.9) cluster. I've tried using both 20 cores and 1 core (in case something weird is going on with the threading) and both run fine. I used our cluster default of 6GB per core, which is overkill for this job. My guess is that the same tbb version is getting used in each version of salmon you're trying and that it got corrupted at some point. Are you spinning up a new CloudMan instance for these runs or are you restarting a saved instance? If you're not starting a brand new instance then try that, then you can avoid using the same possibly corrupted tbb install.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/271#issuecomment-416383307:615,avoid,avoid,615,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/271#issuecomment-416383307,1,['avoid'],['avoid']
Safety,"I did not see any output. That's the reason why the test stopped with the timeout.; Ref: https://travis-ci.org/COMBINE-lab/salmon/builds/419012959. Here is my commit on this PR. You can do cherry-pick to check it.; https://github.com/junaruga/salmon/commits/hotfix/develop-unrecognized-cxx-std-14_3. If you add `--verbose` or `--debug` to the `ctest`, you might see something?. ```; /usr/local/cmake-3.9.2/bin/ctest --force-new-ctest-process --verbose --debug; ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/276#issuecomment-416155226:74,timeout,timeout,74,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/276#issuecomment-416155226,1,['timeout'],['timeout']
Safety,"I have a similar problem.; Attached are:; 1. gtf file, where clearly, the gene_ id and transcript_id are provided; 2. quant files are as followed for gene and transcripts; 3. my command as followed:; ---. /gpfsdata/apps/salmon-latest_linux_x86_64/bin/salmon quant \; -i /gpfshome/hockchuan/SALMON/GCF_900626175.2_cs10_index \; -l ISR \; -1 /gpfsdata/JangiLab/hockchuan/170302/2.Trimmomatic_output/clean_HEADBANDSTEM_1.fastq.gz \; -2 /gpfsdata/JangiLab/hockchuan/170302/2.Trimmomatic_output/clean_HEADBANDSTEM_2.fastq.gz \; --seqBias \; --gcBias \; --posBias \; --incompatPrior 0.0 \; --geneMap /gpfsdata/JangiLab/hockchuan/cs10_reference_genome/GCF_900626175.2_cs10_genomic.gtf \; --recoverOrphans \; --allowDovetail \; --threads $NSLOTS \; --dumpEq \; --minScoreFraction 0.65 \; --writeMappings /gpfshome/hockchuan/SALMON/MAP/HEADBANDSTEM \; --fldMean 250 \; --fldSD 25 \; --writeOrphanLinks \; --writeUnmappedNames \; --quiet \; -o /gpfshome/hockchuan/SALMON/HEADBANDSTEM_quant; ---. [fewLines.gtf.txt](https://github.com/COMBINE-lab/salmon/files/5383013/fewLines.gtf.txt); [quant.genes.txt](https://github.com/COMBINE-lab/salmon/files/5382998/quant.genes.txt); [quant.txt](https://github.com/COMBINE-lab/salmon/files/5382999/quant.txt)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/569#issuecomment-708949661:683,recover,recoverOrphans,683,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/569#issuecomment-708949661,2,['recover'],['recoverOrphans']
Safety,"I just redownloaded and extracted and tried again, and unfortunately the problem persists =/. ```; ...; [2016-01-02 17:47:51.342] [jointLog] [info] iteration = 1600 | max rel diff. = 0.0133376; [2016-01-02 17:47:51.443] [jointLog] [info] iteration = 1630 | max rel diff. = 0.00771098; [2016-01-02 17:47:51.447] [jointLog] [info] Finished optimizer; [2016-01-02 17:47:51.448] [jointLog] [info] writing output. Computing gene-level abundance estimates; [2016-01-02 17:47:51.678] [jointLog] [warning] NOTE: Read Lib [( /nfs/research2/teichmann/valentine/detection-comparison/salmon0.4.2-comparison/mouse/SRP057125_SRS936134_1.fastq, /nfs/research2/teichmann/valentine/detection-comparison/salmon0.4.2-comparison/mouse/SRP057125_SRS936134_2.fastq )] :. Greater than 5% of the alignments (but not, necessarily reads) disagreed with the provided library type; check the file: SRP057125_SRS936134_salmon_out/libFormatCounts.txt for details. There were 104534 transcripts mapping to 44034 genes; Parsed 104000 expression lines; done; Aggregating expressions to gene level . . . done; Segmentation fault (core dumped); ```. If you want I can upload index and a couple of fastq files somewhere so you can try?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/34#issuecomment-168412271:551,detect,detection-comparison,551,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/34#issuecomment-168412271,2,['detect'],['detection-comparison']
Safety,"I think if you want to automate these steps though the easiest and most robust thing you could do is require everyone to tell you how many cells they captured and sequenced, and relax that number a little bit and do whatever filtering you need to do downstream to get rid of the crap on the low end; usually other quality control metrics like mitochondrial content or genes detected or whatever will filter out the garbage that leaks into the count matrix from being permissive in initial cell demultiplexing + quantification steps.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/362#issuecomment-490161823:374,detect,detected,374,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/362#issuecomment-490161823,1,['detect'],['detected']
Safety,I usually get IU for auto-detected library type for TCGA samples.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/137#issuecomment-406356935:26,detect,detected,26,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/137#issuecomment-406356935,1,['detect'],['detected']
Safety,"I was trying to troubleshoot the contemplation period of salmon with monitoring utilities and just stumbled upon this issue upon submitting my own. The failed version check gets buried by the spew of warnings for too short/long transcripts for hg38 mrna.fna in my case. The current behaviour is particularly irritating as I assumed, that `salmon index -h` just runs into a loop accidentally. The check takes multiple minutes to timeout. I am behind a proxy. Please remove the version check by default, as this is not common behaviour of command line tools or anticipated by the user. Or at least please add a verbose message before checking ""Checking for upgrades online..."".",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/277#issuecomment-474388032:428,timeout,timeout,428,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/277#issuecomment-474388032,1,['timeout'],['timeout']
Safety,"I would argue that Kallisto is ""cheating"" a bit by looking at expression of the equivalence classes :p, avoiding the ambiguous assignment issue. Just offering an opinion as a Salmon fan, but to me it seems extremely hard to make the data generation model of coverage based sequencing compatible with umi-tags. I've been thinking a bit about this, and actually, if the PCR bias model in 0.7/Alpine is good, it might even make sense to _ignore_ the UMI and quantify the expression based the mRNA tags alone. In this case you would just need to change transcript length to be constant per transcript, and only update effectiveLength's based on the sequence biases. The reason you have UMI's in the first place, is that 3'/5'-tag libraries will have much lower complexity than full-length libraries, and due to that you can argue that PCR bias will be a larger problem. But if it is possible to accurately account for the PCR bias with GC content, maybe they are not so needed?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/93#issuecomment-249524891:104,avoid,avoiding,104,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/93#issuecomment-249524891,1,['avoid'],['avoiding']
Safety,"I'm wondering the same thing! Can Salmon be used for quantification with a reference set of predicted CDS? IMO this would also have advantages for quantification with de novo assembled transcriptomes, as this would alleviate problems with chimeric contigs...",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/350#issuecomment-824686957:92,predict,predicted,92,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/350#issuecomment-824686957,1,['predict'],['predicted']
Safety,"ISR --chromium -p 4 -o BM_1/alevin -1 ./BM_1/run1/bm_S10_L001_R1_001.fastq.gz -2 ./BM_1/run1/bm_S10_L001_R2_001.fastq.gz --maxHashResizeThreads 2 -i /u/user/ref/cellranger/salmon/transcripts_index --tgMap tx2gene.txt; Starting program: /u/user/local/bin/salmon alevin -l ISR --chromium -p 4 -o BM_1/alevin -1 ./BM_1/run1/bm_S10_L001_R1_001.fastq.gz -2 ./BM_1/run1/bm_S10_L001_R2_001.fastq.gz --maxHashResizeThreads 2 -i /u/user/ref/cellranger/salmon/transcripts_index --tgMap tx2gene.txt; [Thread debugging using libthread_db enabled]; Using host libthread_db library ""/lib/x86_64-linux-gnu/libthread_db.so.1"".; warning: File ""/u/user/local/lib64/libstdc++.so.6.0.21-gdb.py"" auto-loading has been declined by your `auto-load safe; -path' set to ""$debugdir:$datadir/auto-load"".; To enable execution of this file add; add-auto-load-safe-path /u/user/local/lib64/libstdc++.so.6.0.21-gdb.py; line to your configuration file ""/u/user/.gdbinit"".; To completely disable this security protection add; set auto-load safe-path /; line to your configuration file ""/u/user/.gdbinit"".; For more information about this security protection see the; ""Auto-loading safe path"" section in the GDB manual. E.g., run from the shell:; info ""(gdb)Auto-loading safe path""; [New Thread 0x7fff7dbff700 (LWP 21437)]; [Thread 0x7fff7dbff700 (LWP 21437) exited]; Version Info: Could not resolve upgrade information in the alotted time.; Check for upgrades manually at https://combine-lab.github.io/salmon; [New Thread 0x7ffefcfff700 (LWP 21653)]; Logs will be written to BM_1/alevin/logs; [New Thread 0x7ffe7cffe700 (LWP 21654)]; [New Thread 0x7ffdfcffd700 (LWP 21655)]; [New Thread 0x7ffd7cffc700 (LWP 21656)]; ### salmon (single-cell-based) v0.10.3; ### [ program ] => salmon; ### [ command ] => alevin; ### [ libType ] => { ISR }; ### [ chromium ] => { }; ### [ threads ] => { 4 }; ### [ output ] => { BM_1/alevin }; ### [ mates1 ] => { ./BM_1/run1/bm_S10_L001_R1_001.fastq.gz }; ### [ mates2 ] => { ./BM_1/run1/bm_S10_L001_R2_",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-396078627:2045,safe,safe-path,2045,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-396078627,1,['safe'],['safe-path']
Safety,"If you are getting a lot of reads mapping to the genome but not quantified with Salmon, a good thing to check for is genomic DNA contamination. If you count up read mapping to genes with featureCounts or something similar you can detect genomic DNA contamination by looking at the numbers that fall into intergenic regions.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/170#issuecomment-341744828:230,detect,detect,230,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/170#issuecomment-341744828,1,['detect'],['detect']
Safety,"Interesting... So you're concerned that; [https://github.com/jemalloc/jemalloc/archive/5.1.0.tar.gz](https://github.com/jemalloc/jemalloc/archive/5.1.0.tar.gz); could change at some point? I'm not an expert on Github internals, but I would assume there are some safeguards against changes to release distfiles.; Thanks,; Jason",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/288#issuecomment-420335374:262,safe,safeguards,262,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/288#issuecomment-420335374,1,['safe'],['safeguards']
Safety,"Is salmon suggesting this is stranded?. `Detected a *potential* strand bias > 1% in an unstranded protocol check the file: 142-salmon-quant/lib_format_counts.json for details`. . The libraries are generated using the [smart-seq2](http://www.nature.com/nmeth/journal/v10/n11/full/nmeth.2639.html) protocol which as far I know does not retain strand information. From the article . ""Currently, Smart-seq2 is limited to poly(A)+ RNAs and does not retain strand or molecule information, although it is compatible with partial-molecule counting.""",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/144#issuecomment-319669636:41,Detect,Detected,41,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/144#issuecomment-319669636,1,['Detect'],['Detected']
Safety,Is there any update on this? I am seeing the same warnings and I don't think I totally understand what they mean and whether they can be safely ignored... Thanks!,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/701#issuecomment-1328992610:137,safe,safely,137,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/701#issuecomment-1328992610,1,['safe'],['safely']
Safety,"It appears that you're trying to index the entire mm9 genome using salmon. Both salmon and rapmap are designed to work with a smaller sequence space such as what you would find in a transcriptome. Your log file shows that salmon processes 615,000,000 bases from the genome and then aborts. Depending on how many transcripts are in your feature file, a human transcriptome [might be 5-10X smaller](http://seqanswers.com/forums/showthread.php?t=5298).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/49#issuecomment-197862096:282,abort,aborts,282,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/49#issuecomment-197862096,1,['abort'],['aborts']
Safety,"It gets stranger... I prepared a public directory with the files I use and made a bash script to reproduce the run of salmon. This directory is in my home folder, and has symlinks to the actual NFS locations of the files: http://www.ebi.ac.uk/~vale/salmon-problem/. ```; [vale@ebi-003 salmon-problem]$ ls -lh; total 20K; lrwxrwxrwx 1 vale rst_pub 96 Jan 2 20:09 mouse_cdna_38.p3.78_repbase_ercc.fa -> /nfs/research2/teichmann/reference/mus-musculus/salmon/quasi/mouse_cdna_38.p3.78_repbase_ercc.fa; -rw-rw-r-- 1 vale rst_pub 301 Jan 2 20:19 run_salmon.sh; lrwxrwxrwx 1 vale rst_pub 112 Jan 2 20:08 SRP057125_SRS936134_1.fastq -> /nfs/research2/teichmann/valentine/detection-comparison/salmon0.4.2-comparison/mouse/SRP057125_SRS936134_1.fastq; lrwxrwxrwx 1 vale rst_pub 112 Jan 2 20:08 SRP057125_SRS936134_2.fastq -> /nfs/research2/teichmann/valentine/detection-comparison/salmon0.4.2-comparison/mouse/SRP057125_SRS936134_2.fastq; drwxrwxr-x 5 vale rst_pub 4.0K Jan 2 20:20 SRP057125_SRS936134_salmon_out; ```. But when I run the script there, it succeeds, without segfault. ```; [vale@ebi-003 salmon-problem]$ bash run_salmon.sh; Version Info: This is the most recent version of Salmon.; # salmon (mapping-based) v0.6.0; # [ program ] => salmon; # [ command ] => quant; # [ index ] => { mouse_cdna_38.p3.78_repbase_ercc.fa }; # [ libType ] => { IU }; # [ mates1 ] => { SRP057125_SRS936134_1.fastq }; # [ mates2 ] => { SRP057125_SRS936134_2.fastq }; # [ output ] => { SRP057125_SRS936134_salmon_out }; # [ biasCorrect ] => { }; # [ useFSPD ] => { }; Logs will be written to SRP057125_SRS936134_salmon_out/logs; [2016-01-02 20:16:39.349] [jointLog] [info] parsing read library format; there is 1 lib; Loading 32-bit quasi index[2016-01-02 20:16:39.895] [stderrLog] [info] Loading Suffix Array; [2016-01-02 20:16:39.895] [stderrLog] [info] Loading Position Hash; [2016-01-02 20:16:39.894] [jointLog] [info] Loading Quasi index; [2016-01-02 20:16:42.565] [stderrLog] [info] Loading Transcript Info; [2016-",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/34#issuecomment-168426741:664,detect,detection-comparison,664,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/34#issuecomment-168426741,2,['detect'],['detection-comparison']
Safety,"It looks like they're starting work on scRNA support: https://github.com/COMBINE-lab/salmon/blob/a41c6b4e38fb23e51b59dc4a0a450071dc92c180/src/CollapsedCellOptimizer.cpp. Seems like @k3yavi is doing most of the implementation so far. Our group would definitely be interested in this functionality, but I understand how difficult resourcing for new features can be. Thanks for all the hard work!. Edit: Barcode detection / preprocessor looks like it lives here: https://github.com/k3yavi/alevin",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/93#issuecomment-371817266:409,detect,detection,409,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/93#issuecomment-371817266,1,['detect'],['detection']
Safety,"It really doesn't seem like Salmon is treating them all as orphans. As an example, our forward file has 17385254 reads, reverse 17361911. Salmon says:. ```; At end of round 0; ==================; Observed 17361911 total fragments (17361911 in most recent round). [2022-04-11 23:11:53.713] [jointLog] [info] Computed 2,763,922 rich equivalence classes for further processing; [2022-04-11 23:11:53.731] [jointLog] [info] Counted 16,393,065 total reads in the equivalence classes ; ... [2022-04-11 23:11:53.743] [jointLog] [info] Number of mappings discarded because of alignment score : 680,083; [2022-04-11 23:11:53.743] [jointLog] [info] Number of fragments entirely discarded because of alignment score : 263,662; [2022-04-11 23:11:53.743] [jointLog] [info] Number of fragments discarded because they are best-mapped to decoys : 0; [2022-04-11 23:11:53.743] [jointLog] [info] Number of fragments discarded because they have only dovetail (discordant) mappings to valid targets : 2,335; [2022-04-11 23:11:53.744] [jointLog] [info] Mapping rate = 94.4197%; ```. Also, library is auto-detected as IU and mean fragment length is computed as 417.8. This looks to me like most of the reads are recognized as paired, which in fact they are.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/793#issuecomment-1220248939:1083,detect,detected,1083,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/793#issuecomment-1220248939,1,['detect'],['detected']
Safety,"Just following up on this, I figured out that the dataset was the problem. I had subset it from a larger scifi-RNA-seq dataset and was too aggressive. I had just over 1000 aligned reads per cell detected by alevin. I ran two 10X datasets using this procedure and both worked as expected. The 10X mixing experiment found about 50:50 mixture of human and mouse cells with a few collisions, and a 10X human PBMC dataset returned no mouse cells at all. . I'll go ahead and close this now. For future reference, using a concatenated reference along with the `--resolution trivial` flag allows alevin to handle species mixture data just fine.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/715#issuecomment-952521555:195,detect,detected,195,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/715#issuecomment-952521555,1,['detect'],['detected']
Safety,"Just in case it helps, I've written a script to splice out cell barcode linker sequences and shift them to before the polyA. In the process of doing this, it also does a 2-distance hamming correction of cell barcode and linker regions. All operations assume there are no INDELs:. https://gitlab.com/gringer/bioinfscripts/-/blob/master/synthSquish.pl. [usual disclaimers apply: I cannot guarantee that this works; use at your own risk]. This script could be used as a stop-gap measure to pre-process Rhapsody reads for use with Alevin via the undocumented custom length settings [--end 5, --barcodeLength 27, --umiLength 8]",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/628#issuecomment-776417938:429,risk,risk,429,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/628#issuecomment-776417938,2,['risk'],['risk']
Safety,"LONE_SETTLS|CLONE_PARENT_SETTID|CLONE_CHILD_CLEARTID, parent_tidptr=0x7ff8be5d09d0, tls=0x7ff8be5d0700, child_tidptr=0x7ff8be5d09d0) = 52025; mmap(NULL, 1073745920, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_STACK, -1, 0) = 0x7ff83e5cf000; mprotect(0x7ff83e5cf000, 4096, PROT_NONE) = 0; clone(child_stack=0x7ff87e5ceed0, flags=CLONE_VM|CLONE_FS|CLONE_FILES|CLONE_SIGHAND|CLONE_THREAD|CLONE_SYSVSEM|CLONE_SETTLS|CLONE_PARENT_SETTID|CLONE_CHILD_CLEARTID, parent_tidptr=0x7ff87e5cf9d0, tls=0x7ff87e5cf700, child_tidptr=0x7ff87e5cf9d0) = 52026; mmap(NULL, 1073745920, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_STACK, -1, 0) = -1 ENOMEM (Cannot allocate memory); futex(0x7fffbf4c3350, FUTEX_WAKE_PRIVATE, 2147483647) = 0; write(2, ""terminate called without an acti""..., 45terminate called without an active exception; ) = 45; rt_sigprocmask(SIG_UNBLOCK, [ABRT], NULL, 8) = 0; write(3, ""[2017-04-05 16:40:15.587] [joint""..., 136) = 136; tgkill(51996, 51996, SIGABRT) = 0; --- SIGABRT (Aborted) @ 0 (0) ---; +++ killed by SIGABRT (core dumped) +++; ```. and for task 2:. ```; execve(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon"", [""/dcl01/lieber/ajaffe/Emily/RNAse""..., ""quant"", ""-i"", ""/dcl01/lieber/ajaffe/Emily/RNAse""..., ""-p"", ""1"", ""-l"", ""ISR"", ""-1"", ""/dcl01/lieber/ajaffe/lab/libd_al""..., ""-2"", ""/dcl01/lieber/ajaffe/lab/libd_al""..., ""-o"", ""/dcl01/lieber/ajaffe/lab/libd_al""...], [/* 107 vars */]) = 0; brk(0) = 0xc2c000; mmap(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7fffbfffd000; readlink(""/proc/self/exe"", ""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon"", 4096) = 88; access(""/etc/ld.so.preload"", R_OK) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/tls/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipel",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:121587,Abort,Aborted,121587,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,1,['Abort'],['Aborted']
Safety,"LONE_SETTLS|CLONE_PARENT_SETTID|CLONE_CHILD_CLEARTID, parent_tidptr=0x7ffc3e5de9d0, tls=0x7ffc3e5de700, child_tidptr=0x7ffc3e5de9d0) = 10753; mmap(NULL, 1073745920, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_STACK, -1, 0) = 0x7ffbbe5dd000; mprotect(0x7ffbbe5dd000, 4096, PROT_NONE) = 0; clone(child_stack=0x7ffbfe5dced0, flags=CLONE_VM|CLONE_FS|CLONE_FILES|CLONE_SIGHAND|CLONE_THREAD|CLONE_SYSVSEM|CLONE_SETTLS|CLONE_PARENT_SETTID|CLONE_CHILD_CLEARTID, parent_tidptr=0x7ffbfe5dd9d0, tls=0x7ffbfe5dd700, child_tidptr=0x7ffbfe5dd9d0) = 10754; mmap(NULL, 1073745920, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_STACK, -1, 0) = -1 ENOMEM (Cannot allocate memory); futex(0x7fffbf4c3350, FUTEX_WAKE_PRIVATE, 2147483647) = 0; write(2, ""terminate called without an acti""..., 45terminate called without an active exception; ) = 45; rt_sigprocmask(SIG_UNBLOCK, [ABRT], NULL, 8) = 0; write(3, ""[2017-04-05 16:24:38.504] [joint""..., 136) = 136; tgkill(10693, 10693, SIGABRT) = 0; --- SIGABRT (Aborted) @ 0 (0) ---; +++ killed by SIGABRT (core dumped) +++; ```. (371 lines for task 1, 368 for task 2). Basically, both fail at a point where `mmap()` cannot allocate memory. So it definitely looks like a memory issue and I don't know if these information gives you any hints. . ## Bumping memory. Bumping the memory request to 28/30GB. This is a scenario where task 2 seems to work ok but tasks 1 and 3 fail. ```bash; #!/bin/bash; #$ -cwd; #$ -pe local 2; #$ -l mem_free=14G,h_vmem=15G,h_fsize=100G; #$ -N step6-salmon_test12.gsk_phaseII; #$ -o ./logs/salmon_test12.$TASK_ID.txt; #$ -e ./logs/salmon_test12.$TASK_ID.txt; #$ -t 1-3; #$ -hold_jid pipeline_setup,step4-featCounts-alzheimer.gsk_phaseII; #$ -m e; echo ""**** Job starts ****""; date. echo ""**** JHPCE info ****""; echo ""User: ${USER}""; echo ""Job id: ${JOB_ID}""; echo ""Job name: ${JOB_NAME}""; echo ""Hostname: ${HOSTNAME}""; echo ""Task id: ${TASK_ID}"". FILE1=$(awk 'BEGIN {FS=""\t""} {print $1}' /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/sa",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:77293,Abort,Aborted,77293,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,1,['Abort'],['Aborted']
Safety,"LS|CLONE_PARENT_SETTID|CLONE_CHILD_CLEARTID, parent_tidptr=0x7ffc3e5de9d0, tls=0x7ffc3e5de700, child_tidptr=0x7ffc3e5de9d0) = 32696; mmap(NULL, 1073745920, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_STACK, -1, 0) = 0x7ffbbe5dd000; mprotect(0x7ffbbe5dd000, 4096, PROT_NONE) = 0; clone(child_stack=0x7ffbfe5dced0, flags=CLONE_VM|CLONE_FS|CLONE_FILES|CLONE_SIGHAND|CLONE_THREAD|CLONE_SYSVSEM|CLONE_SETTLS|CLONE_PARENT_SETTID|CLONE_CHILD_CLEARTID, parent_tidptr=0x7ffbfe5dd9d0, tls=0x7ffbfe5dd700, child_tidptr=0x7ffbfe5dd9d0) = 32697; mmap(NULL, 1073745920, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_STACK, -1, 0) = -1 ENOMEM (Cannot allocate memory); futex(0x7fffbf4c3350, FUTEX_WAKE_PRIVATE, 2147483647) = 0; write(2, ""terminate called without an acti""..., 45terminate called without an active exception; ) = 45; rt_sigprocmask(SIG_UNBLOCK, [ABRT], NULL, 8) = 0; write(3, ""[2017-04-05 16:24:37.940] [joint""..., 136) = 136; tgkill(32681, 32681, SIGABRT) = 0; --- SIGABRT (Aborted) @ 0 (0) ---; +++ killed by SIGABRT (core dumped) +++; ```; and for task 2:. ```; execve(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon"", [""/dcl01/lieber/ajaffe/Emily/RNAse""..., ""quant"", ""-i"", ""/dcl01/lieber/ajaffe/Emily/RNAse""..., ""-p"", ""1"", ""-l"", ""ISR"", ""-1"", ""/dcl01/lieber/ajaffe/lab/libd_al""..., ""-2"", ""/dcl01/lieber/ajaffe/lab/libd_al""..., ""-o"", ""/dcl01/lieber/ajaffe/lab/libd_al""...], [/* 107 vars */]) = 0; brk(0) = 0xc2c000; mmap(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7fffbfffd000; readlink(""/proc/self/exe"", ""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon"", 4096) = 88; access(""/etc/ld.so.preload"", R_OK) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/tls/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Soft",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:40624,Abort,Aborted,40624,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,1,['Abort'],['Aborted']
Safety,"Looks like --no-version-check does the job of avoiding this warning, however, make it is better to just make a command for version check instead of forcing users to do --no-version-check all the time to silence this error?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/277#issuecomment-415572366:46,avoid,avoiding,46,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/277#issuecomment-415572366,1,['avoid'],['avoiding']
Safety,"MI count **but** I had to bring that part into the discussion as it was mentioned that you wanted to compare different deduplication strategies. I think your suggestion makes sense and mostly aligns with the definition being used by 10x [here](https://kb.10xgenomics.com/hc/en-us/articles/115003646912-How-is-sequencing-saturation-calculated-). Although note they have changed the definition with the new version of the software. Anyhow, the *short answer* to the question of how can we generate that in Alevin environment is -- by post processing the dumpFeatures output of the Alevin run. _long answer_: The difference lies in the term deduplication and the strategy used to perform it. Basically the fundamental unit for deduplication in 10x as mentioned in the link above is a tuple of `(valid cell-barcode, valid UMI, gene) `, while that's not exactly true for us. We can certainly generate it but it does not aligns with the theory of Alevin's deduplication Algorithm. Having said that, I also like your idea of using:; > the gene quantifications from (de)duplicated UMIs, gene quantifications from unique UMIs, using them to have an idea of the amount/ratio of redundant information. However, the above definition reflect more of the duplication rate (at least in terms of the definition defined in *Alevin* manuscript [here](https://www.biorxiv.org/content/early/2018/06/01/335000)) than sequence saturation. **NOTE** the quoted definition was actually the 10x definition of sequence saturation too before it was changed, at least in my understanding. If you need the deduplication rate of each cell you can get that by using `--dumpFeature` flag in the Alevin run and look for file `featureDump.txt`. There will be a dump of multiple features w/ each CB but the second (starting from 0) column of the file gives you the duplication rate of each CB. Hope that helps, I totally understand your suggestion and would like to include @rob-p into this too if he has more comments/insights on this.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/267#issuecomment-414784626:1344,redund,redundant,1344,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/267#issuecomment-414784626,1,['redund'],['redundant']
Safety,"Next, I am using alignment mode for paired-end reads aligned to reference transcript using bwa and I get this warning:. ```; WARNING: Detected suspicious pair ---; The names are different:; read1 : SRR764782.282; read2 : SRR764782.283. [2017-04-12 10:30:00.202] [jointLog] [warning]. WARNING: Detected suspicious pair ---; The names are different:; read1 : SRR764782.283; read2 : SRR764782.284. ```. Shall I just ignore or salmon assumes paired end reads as different reads?. Next question: why non-alignment mode is better than alignment mode?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/131#issuecomment-293512406:134,Detect,Detected,134,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/131#issuecomment-293512406,2,['Detect'],['Detected']
Safety,"O_WRAPPER=/u/user/local/libexec/gcc/x86_64-unknown-linux-gnu/5.4.0/lto-wrapper; Target: x86_64-unknown-linux-gnu; Configured with: ./configure --prefix=/u/user/local; Thread model: posix; gcc version 5.4.0 (GCC); ```. ```; [Thread debugging using libthread_db enabled]; Using host libthread_db library ""/lib/x86_64-linux-gnu/libthread_db.so.1"".; warning: File ""/u/user/local/lib64/libstdc++.so.6.0.21-gdb.py"" auto-loading has been declined by your `auto-load safe-path' set to ""$debugdir:$datadir/auto-load"".; To enable execution of this file add; add-auto-load-safe-path /u/user/local/lib64/libstdc++.so.6.0.21-gdb.py; line to your configuration file ""/u/user/.gdbinit"".; To completely disable this security protection add; set auto-load safe-path /; line to your configuration file ""/u/user/.gdbinit"".; For more information about this security protection see the; ""Auto-loading safe path"" section in the GDB manual. E.g., run from the shell:; info ""(gdb)Auto-loading safe path""; [New Thread 0x7fff7e0f4700 (LWP 14274)]; Version Info: ### A newer version of Salmon is available. ####; [Thread 0x7fff7e0f4700 (LWP 14274) exited]; ###; The newest version, available at https://github.com/COMBINE-lab/salmon/releases; contains new features, improvements, and bug fixes; please upgrade at your; earliest convenience.; ###; [New Thread 0x7fff7d273700 (LWP 14275)]; Logs will be written to pbmc4k/alevin/logs; [New Thread 0x7ffefc3f1700 (LWP 14276)]; [New Thread 0x7ffe7b56f700 (LWP 14277)]; [New Thread 0x7ffdfa6ed700 (LWP 14278)]; ### salmon (single-cell-based) v0.10.1; ### [ program ] => salmon; ### [ command ] => alevin; ### [ libType ] => { ISR }; ### [ chromium ] => { }; ### [ threads ] => { 8 }; ### [ output ] => { pbmc4k/alevin }; ### [ mates1 ] => { /dev/fd/63 }; ### [ mates2 ] => { /dev/fd/62 }; ### [ index ] => { /u/user/ref/cellranger/salmon/transcripts_index }; ### [ tgMap ] => { tx2gene.txt }. [2018-06-08 13:37:41.409] [jointLog] [info] Fragment incompatibility prior below threshold.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-395836214:2706,safe,safe,2706,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-395836214,1,['safe'],['safe']
Safety,Oh Sorry about that what I meant was the salmon.log file or the the meta-info.json file created by salmon in the output directory. You can check what files salmon is detecting it seems there are 12 files in the mate1 and 13 files in the mate2. Can you confirm there are 13 pairs of file in that directory and their regex is same as you are using ? Can you also try putting the names of the file instead `*` as regex ?,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/408#issuecomment-516195181:166,detect,detecting,166,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/408#issuecomment-516195181,1,['detect'],['detecting']
Safety,"Oh man, too many sanity checks over the years, can you just remove one cellular barcode from the full list and try again?. Basically, many people have confused this flag by providing the full 10x whitelist without knowing the consequences, that's why the warning. Here our use case is specific and it should not matter.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-641296035:17,sanity check,sanity checks,17,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-641296035,1,['sanity check'],['sanity checks']
Safety,"Ok @DarwinAwardWinner, I think it's fixed for real this time. The issue was stemming from an uninitialized prior value in the Gibbs sampler under VBOpt mode (the initialization code was updated on the develop branch, which is where the bug was introduced). This, in turn, was leading to `nan` being passed as the alpha parameter of `std::gamma_distribution`. With the `-Ofast` optimization flags, at least, this leads `std::gamma_distribution()` to hang forever in an infinite loop. Clearly, `nan` should not be passed to `std::gamma_distribution()`, but I'd argue the behavior of looping forever here is not great. Anyway, I fixed the initialization bug, so that this nan should never pop up. Just to be safe, I also changed the default optimization flag to `-O3` so that at least `nan` and `inf` can be properly tested. Since the TBB code and the parallel sampling weren't causing the issue, I've added them back in. Could you please test the latest push (40584e62859fb65463188b50d132c1eb622b21f0) and verify that this resolves the issue for you (*hopefully*!)?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267877253:705,safe,safe,705,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267877253,1,['safe'],['safe']
Safety,Okay got it. And is there any prospect of dealing with frameshift errors in the barcode detection step? Or is that out of scope?,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-988023540:88,detect,detection,88,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-988023540,1,['detect'],['detection']
Safety,"Okay my alevin run finished, and I got a mapping rate of just 6.1% and 2254 cells detected. My `lib_format_counts.json` contains the following:. ```; {; ""read_files"": ""[ SRR10174292_2.fastq.gz, SRR10174292_1.fastq.gz]"",; ""expected_format"": ""ISR"",; ""compatible_fragment_ratio"": 1.0,; ""num_compatible_fragments"": 15259749,; ""num_assigned_fragments"": 15259749,; ""num_frags_with_concordant_consistent_mappings"": 0,; ""num_frags_with_inconsistent_or_orphan_mappings"": 61866895,; ""strand_mapping_bias"": 0.0,; ""MSF"": 0,; ""OSF"": 0,; ""ISF"": 0,; ""MSR"": 0,; ""OSR"": 0,; ""ISR"": 0,; ""SF"": 0,; ""SR"": 0,; ""MU"": 0,; ""OU"": 0,; ""IU"": 0,; ""U"": 0; }; ```. so lots of fragments are discarded for one reason or another, and it's not clear whether the library type assignment is working properly, sort of like my initial example above. Separately, I'm running zUMIs on the same files and will report back with those data when the run is complete",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-985038970:82,detect,detected,82,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-985038970,2,['detect'],['detected']
Safety,"Okay, thanks @k3yavi. Just to be clear- you're saying I should derive the whitelist from the filtered_cb_frequency rather than the raw? This is a much smaller file in the case of the bad data above (more so than I'd expect from the cb correction, 984), so I was afraid it had already been subjected to knee detection. I also note that it's also not in fact sorted by default.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/362#issuecomment-490914214:307,detect,detection,307,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/362#issuecomment-490914214,2,['detect'],['detection']
Safety,"P 21669)]; [Thread 0x7ff77cff0700 (LWP 21668) exited]; [New Thread 0x7ff67cfee700 (LWP 21670)]; [Thread 0x7ff6fcfef700 (LWP 21669) exited]; [New Thread 0x7ff5fcfed700 (LWP 21671)]; [Thread 0x7ff67cfee700 (LWP 21670) exited]; [New Thread 0x7ff57cfec700 (LWP 21672)]; [Thread 0x7ff5fcfed700 (LWP 21671) exited]; [New Thread 0x7ff4fcfeb700 (LWP 21673)]; [Thread 0x7ff57cfec700 (LWP 21672) exited]; [New Thread 0x7ff47cfea700 (LWP 21674)]; [Thread 0x7ff4fcfeb700 (LWP 21673) exited]; [New Thread 0x7ff3fcfe9700 (LWP 21675)]; terminate called without an active exception; [Thread 0x7ff47cfea700 (LWP 21674) exited]; [Thread 0x7ff3fcfe9700 (LWP 21675) exited]. Program received signal SIGABRT, Aborted.; 0x00007fff7e8a7067 in __GI_raise (sig=sig@entry=6) at ../nptl/sysdeps/unix/sysv/linux/raise.c:56; 56 ../nptl/sysdeps/unix/sysv/linux/raise.c: No such file or directory.; (gdb) bt; #0 0x00007fff7e8a7067 in __GI_raise (sig=sig@entry=6) at ../nptl/sysdeps/unix/sysv/linux/raise.c:56; #1 0x00007fff7e8a8448 in __GI_abort () at abort.c:89; #2 0x0000000000c3b76d in __gnu_cxx::__verbose_terminate_handler (); at ../../.././libstdc++-v3/libsupc++/vterminate.cc:95; #3 0x0000000000baf9b6 in __cxxabiv1::__terminate (handler=<optimized out>); at ../../.././libstdc++-v3/libsupc++/eh_terminate.cc:47; #4 0x0000000000bafa01 in std::terminate () at ../../.././libstdc++-v3/libsupc++/eh_terminate.cc:57; #5 0x0000000000715f1b in std::vector<std::thread, std::allocator<std::thread> >::~vector() (); #6 0x00000000007bee90 in void cuckoohash_map<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, unsigned int, BarcodeGroupStringHasher, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, unsigned int> >, 4ul>::parallel_exec<cuckoohash_map<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, unsigned",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-396078627:5357,abort,abort,5357,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-396078627,1,['abort'],['abort']
Safety,"RP057125_SRS936134_2.fastq )] :. Greater than 5% of the alignments (but not, necessarily reads) disagreed with the provided library type; check the file: SRP057125_SRS936134_salmon_out/libFormatCoun ts.txt for details. [vale@ebi-003 salmon-problem]$; ```. The command run being:. ```; salmon quant \; -i mouse_cdna_38.p3.78_repbase_ercc.fa \; -l IU \; -1 SRP057125_SRS936134_1.fastq \; -2 SRP057125_SRS936134_2.fastq \; -o SRP057125_SRS936134_salmon_out \; -g /nfs/research2/teichmann/reference/mus-musculus/salmon/mouse_cdna38.78_repbase_ercc_index_gene_map.txt \; --biasCorrect \; --useFSPD; ```. But if I instead run salmon in the NFS directory where I want to run it, the core dumps... ```; [vale@ebi-003 mouse]$ salmon quant \; > -i /nfs/research2/teichmann/reference/mus-musculus/salmon/quasi/mouse_cdna_38.p3.78_repbase_ercc.fa \; > -l IU \; > -1 /nfs/research2/teichmann/valentine/detection-comparison/salmon0.4.2-comparison/mouse/SRP057125_SRS936134_1.fastq \; > -2 /nfs/research2/teichmann/valentine/detection-comparison/salmon0.4.2-comparison/mouse/SRP057125_SRS936134_2.fastq \; > -o SRP057125_SRS936134_salmon_out \; > -g /nfs/research2/teichmann/reference/mus-musculus/salmon/mouse_cdna38.78_repbase_ercc_index_gene_map.txt \; > --biasCorrect \; > --useFSPD; Version Info: This is the most recent version of Salmon.; # salmon (mapping-based) v0.6.0; # [ program ] => salmon; # [ command ] => quant; # [ index ] => { /nfs/research2/teichmann/reference/mus-musculus/salmon/quasi/mouse_cdna_38.p3.78_repbase_ercc.fa }; # [ libType ] => { IU }; # [ mates1 ] => { /nfs/research2/teichmann/valentine/detection-comparison/salmon0.4.2-comparison/mouse/SRP057125_SRS936134_1.fastq }; # [ mates2 ] => { /nfs/research2/teichmann/valentine/detection-comparison/salmon0.4.2-comparison/mouse/SRP057125_SRS936134_2.fastq }; # [ output ] => { SRP057125_SRS936134_salmon_out }; # [ geneMap ] => { /nfs/research2/teichmann/reference/mus-musculus/salmon/mouse_cdna38.78_repbase_ercc_index_gene_map.txt }; ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/34#issuecomment-168426741:6416,detect,detection-comparison,6416,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/34#issuecomment-168426741,1,['detect'],['detection-comparison']
Safety,"Rob,. Brilliant - I forgot that I built the boost libraries from whatever version of gcc was on the standard distribution. I have included -DFETCH_BOOST=TRUE, do you know why I am receiving the following error regarding a missing when executing make?. [ 5%] Performing configure step for 'libboost'; Building Boost.Build engine with toolset gcc... tools/build/src/engine/bin.linuxx86_64/b2; Detecting Python version... 2.7; Detecting Python root... /usr; Unicode/ICU support for Boost.Regex?... not found.; Generating Boost.Build configuration in project-config.jam... Bootstrapping is done. To build, run:. ./b2. To adjust configuration, edit 'project-config.jam'.; Further information:. - Command line help:; ./b2 --help. - Getting started guide:; http://www.boost.org/more/getting_started/unix-variants.html. - Boost.Build documentation:; http://www.boost.org/build/doc/html/index.html. using gcc : : /opt/gcc-8.2.0/bin/g++ ); [ 6%] Performing build step for 'libboost'; opt.jam: No such file or directory; /opt/salmon/external/boost_1_66_0/tools/build/src/build/toolset.jam:43: in toolset.using; ERROR: rule ""opt.init"" unknown in module ""toolset"".; /opt/salmon/external/boost_1_66_0/tools/build/src/build-system.jam:461: in process-explicit-toolset-requests; /opt/salmon/external/boost_1_66_0/tools/build/src/build-system.jam:527: in load; /opt/salmon/external/boost_1_66_0/tools/build/src/kernel/modules.jam:295: in import; /opt/salmon/external/boost_1_66_0/tools/build/src/kernel/bootstrap.jam:139: in boost-build; /opt/salmon/external/boost_1_66_0/boost-build.jam:17: in module scope; make[2]: *** [libboost-prefix/src/libboost-stamp/libboost-build] Error 1; make[1]: *** [CMakeFiles/libboost.dir/all] Error 2; make: *** [all] Error 2. Thanks for all your help!. Nate",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/309#issuecomment-436834099:391,Detect,Detecting,391,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/309#issuecomment-436834099,2,['Detect'],['Detecting']
Safety,"Salmon detected suspicious pair, will it be quantified?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/131#issuecomment-1343751408:7,detect,detected,7,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/131#issuecomment-1343751408,1,['detect'],['detected']
Safety,"So which --chemistry flag in Cell Ranger does the change to -lISF correspond to? Is it `SC5P-R2` or `fiveprime`? https://support.10xgenomics.com/single-cell-gene-expression/software/pipelines/latest/using/count. Also since salmon/alevin can detect the library type automatically, would detect the correct library in the case of 5'-tagged scRNAseq 10X Feature barcode?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/439#issuecomment-622019385:241,detect,detect,241,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/439#issuecomment-622019385,2,['detect'],['detect']
Safety,"Sorry if I wasn't clear. Also, maybe I am trying to bluntly transpose a; metric that comes from alignment-based quantification. Yes, sequencing; saturation relies on UMI, using the transcript reads associated to the UMIs. I am not sure to understand the difference between resolving ambiguity; or collision at the transcript level, with the evaluation of sequencing; saturation in mind. To be more precise, I am not sure to see how it; could be a problem in this computation. But I am probably missing an; important point?. The idea of quasi-mapping as I understand is identifying the transcripts; from which the reads could have originated, generating a quantification.; For the sequencing saturation, we don't really need to know where the; read align on the transcript sequence, we just want to know that the; read comes from one single transcript, a unique UMI. So if I am right,; it is possible to summarize this quantification at the level of UMIs,; and have an idea of the duplication level of the transcripts that have; been tagged with UMIs. From what I understand, this is where alevin; perform the deduplication computation to have a correct idea of the; transcript amount when UMI are added, prior amplifications resulting; from the RT/PCR steps. So I was imagining it could be possible to take the gene quantifications; from (de)duplicated UMIs, gene quantifications from unique UMIs, using; them to have an idea of the amount/ratio of redundant information in the; sequencing data, producing a metric very similar to the seq sat from the; 10x definition.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/267#issuecomment-414331344:1449,redund,redundant,1449,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/267#issuecomment-414331344,2,['redund'],['redundant']
Safety,"Success!. ```; ==> Detecting if salmon-HEAD-bd7096e_2.el_capitan.bottle.tar.gz is relocatable...; ./salmon-HEAD-bd7096e_2.el_capitan.bottle.tar.gz; bottle do; cellar :any; sha256 ""467695cb8b24ef5806a2087bfe58cc77b924b82cb110391a23513a05d9aac34e"" => :el_capitan; end; ```. Tag 0.7.0 whenever you're ready. Will you submit the PR to bump the Homebrew Science Salmon formula?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/70#issuecomment-239634438:19,Detect,Detecting,19,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/70#issuecomment-239634438,1,['Detect'],['Detecting']
Safety,"Success!. ```; ❯❯❯ brew bottle salmon --json -v; ==> Detecting if salmon-0.6.0_1.el_capitan.bottle.1.tar.gz is relocatable...; ./salmon-0.6.0_1.el_capitan.bottle.1.tar.gz; bottle do; cellar :any; revision 1; sha256 ""8c646bf4e16567180377628fb99fce3a98eeec8b9a55e9140699e0d76b423810"" => :el_capitan; end; ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/70#issuecomment-239631182:53,Detect,Detecting,53,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/70#issuecomment-239631182,1,['Detect'],['Detecting']
Safety,"Sure --- since, at this point, I don't seem able to reproduce the issue any more. Just for a sanity check, can you md5sum the binary you have? I have `fc39599b6c027eb97bb2f4c7bdd361f3`. Previously, I was getting the same segfault as you, but now it finishes cleanly:. ```; [2016-01-02 13:13:10.643] [jointLog] [info] iteration = 4500 | max rel diff. = 0.0100814; [2016-01-02 13:13:10.703] [jointLog] [info] iteration = 4508 | max rel diff. = 0.00999839; [2016-01-02 13:13:10.714] [jointLog] [info] Finished optimizer; [2016-01-02 13:13:10.714] [jointLog] [info] writing output. [2016-01-02 13:13:10.871] [jointLog] [warning] NOTE: Read Lib [( /dev/fd/63, /dev/fd/62 )] :. Detected a strand bias > 1% in an unstranded protocol check the file: salmon_flux_quant_nofspd/libFormatCounts.txt for details. [2016-01-02 13:13:10.871] [jointLog] [warning] NOTE: Read Lib [( /dev/fd/63, /dev/fd/62 )] :. Greater than 5% of the alignments (but not, necessarily reads) disagreed with the provided library type; check the file: salmon_flux_quant_nofspd/libFormatCounts.txt for details. rob@feynman:~/SoftwareStaging/salmon/build/tmp; ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/34#issuecomment-168413403:93,sanity check,sanity check,93,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/34#issuecomment-168413403,2,"['Detect', 'sanity check']","['Detected', 'sanity check']"
Safety,"Thank *you* for providing this software to the community.; BTW, it seems you're making an effort to support externally installed dependencies, for which I'm grateful. I did have to patch around a few bundled deps (e.g. libgff), which are downloaded unconditionally. Many package managers (e.g. FreeBSD ports, Gentoo Portage, MacPorts, pkgsrc, ...) do not allow manual downloads by upstream build systems, for obvious security reasons. I'm hoping it will be possible to avoid all such downloads without patching in the future, by preinstalling and having them discovered by find_package(), as you're already doing for things like bzip2. This will make it easier to package salmon in many of the numerous package managers out there (and eliminate the need for you to install dependencies via cmake). Cheers!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/288#issuecomment-420352699:469,avoid,avoid,469,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/288#issuecomment-420352699,1,['avoid'],['avoid']
Safety,"Thank you for the clear and thorough explanation, @rob-p . Now I understand exactly why this is happening. I like your idea for the “throw-away” run for Salmon, and the short example command you sketched out is exactly what I had said in mind as I read your words. Reworking the core Salmon algorithm to do some gymnastics with re-processing the first 10,000 reads would not be elegant or worth your time. I think the workaround you proposed is a perfectly good solution. If in the long run many other people find this useful, perhaps an easier fix would be to make a new command in Salmon that just bails after the first 10k reads automatically and returns the detected library orientation upon termination of the command; e.g. in Bash:. `mylibtype=$(salmon quant —getLibType -r reads.fq.gz)`; `salmon quant —libType $mylibtype -r reads.fq.gz`. Thank you for the great software and for being so attentive to detail and our questions.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/489#issuecomment-738896890:662,detect,detected,662,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/489#issuecomment-738896890,2,['detect'],['detected']
Safety,"Thank you for the swift answer!. We are working with [BD Rhapsody](https://www.bdbiosciences.com/en-us/instruments/research-instruments/single-cell-multiomics/single-cell-analysis-system), which uses a complex barcode structure (you can read about this in their [bioinformatics handbook](https://www.bd.com/documents/guides/user-guides/GMX_BD-Rhapsody-genomics-informatics_UG_EN.pdf) on page 14). The extracted, combined CB is 27bp long, which is why the default sanity check was too low for our purposes. In terms of cell numbers, BD Rhapsody appears to generate a lot of ""false-positive cells"", actually (we are seeing up to 90% of false positives). This is expected, and also mentioned in their bioinformatics handbook (pages 23-25), but appears to be an issue for the alevin cell detection: with standard settings this is approximately two orders of magnitude lower than expected, `--expectCells` improves matters drastically, however. We have opted for removing the false positives in post-processing ourselves - the low count depth population is very easily identifiable. In terms of performance, a complete alevin run on 150M reads (25k expected cells) takes around 1.5 hours using 10 threads, which is perfectly reasonable for us.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/445#issuecomment-551083490:463,sanity check,sanity check,463,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/445#issuecomment-551083490,4,"['detect', 'sanity check']","['detection', 'sanity check']"
Safety,"Thanks @k3yavi - building the `develop` branch currently and will let you know if I encounter any issues. I thought of another approach to obtain at least a sample of 1-10UMI CBs:. - Run alevin with standard options, then parse `raw_cb_frequency.txt` for a sample of 1-10UMI CBs and using them as input to `--whitelist` option for additional run of alevin with `--freqThreshold 0 --maxNumBarcodes 4294967295`. `--whitelist`:. > This is an optional argument, where user can explicitly specify the whitelist CB to use for cell detection and CB sequence correction. If not given, alevin generates its own set of putative CBs. I did the above and everything completed fine. I took a sample of 50,000 1-10UMI CBs of which ~30,000 ended up in `quants_mat.mtx.gz` (I'm assuming the difference is because of CB equivalence relationships within the supplied whitelist). Of these, ~50% had counts <= 10 (I'm assuming those with more counts had CB equivalence relationships across all CBs for which they were assigned reads). Does the above approach seem reasonable?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/379#issuecomment-503620733:525,detect,detection,525,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/379#issuecomment-503620733,1,['detect'],['detection']
Safety,"Thanks @roryk and @k3yavi . The issue we have is that we're trying to run a pipeline in a fairly high-throughput manner to get a sensible 'enough' matrix without too much manual intervention. So I'm trying to avoid anything that requires an eyeballing step, accepting that the matrix we get will be less optimal than one you'd get from manual optimisation. Where possible, our curators are extracting the expected cell numbers from publications, so sometimes I have at least a general idea of where to look for an elbow/ feature. @roryk - have you used your alternate view on the data to automatically derive cutoffs? Does it work well?. @k3yavi:. As I say, first point is that this is for cases where I have a rough idea of the target cell number- we're generally working with pre-published data (though cell numbers per run are not always available). . From https://github.com/COMBINE-lab/salmon/issues/340 I'd inferred that --expectCells gives Alevin ballpark to look for a knee within, while --forceCells is a strict cuttoff. Is that correct? . That being the case, my thought was to try --expectCells first, and failing that --forceCells. The problem is that I need to parse the STDOUT/ERR to detect the boundary error from --expectCells, which is not a very robust way of doing things. If you returned informative error codes (anything but 1) on this and other errors, I could detect the error and implement the logic I describe.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/362#issuecomment-490157428:209,avoid,avoid,209,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/362#issuecomment-490157428,3,"['avoid', 'detect']","['avoid', 'detect']"
Safety,"Thanks for the quick response yourself :). Ok, so it looks like there is just an ungodly amount of time between this line:; ```; [2020-04-22 13:00:24.946] [jointLog] [info] Automatically detected most likely library type as ISR; ```. and this one. ```; [2020-04-23 00:06:31.287] [jointLog] [info] Thread saw mini-batch with a maximum of 1.06% zero probability fragments; ```. This is an absolutely outrageous amount of time spent on trying to align ~19M reads. Was there any other console output that is missing here? . However, even other parts of the run are outrageously slow. For example. ```; [2020-04-23 00:07:47.416] [jointLog] [info] Thread saw mini-batch with a maximum of 1.24% zero probability fragments; [2020-04-23 00:10:07.526] [jointLog] [info] Computed 414,258 rich equivalence classes for further processing; ```. literally minutes passed between these two lines but almost nothing is done in this time. This makes me think there is, perhaps, a resource problem. Is this a shared machine? Was someone else, perhaps, using all of the cores?. I assume the data can't be easily shared, right? I could see how long it takes to run on a different machine. Otherwise, do you have a different machine on which you could run?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/516#issuecomment-621987962:187,detect,detected,187,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/516#issuecomment-621987962,1,['detect'],['detected']
Safety,"Thanks for the response. . The transcriptional variants I've been interested often are quite similar (e.g. only differ for a small part of one exon). Therefore, many of the reads (especially when they map to parts of the genes that don't differ) show up as pseudoaligned to multiple variants, as you'd expect. In that case, do you suggest only looking at the uniquely mapped reads, or only looking at primary alignments for each read, or still looking at all reads (perhaps with a certain `AS` score) for a given transcript? I'm mostly interested in performing sanity checks that transcriptional variants identified by Salmon/Swish are differentially used across conditions. Or would it be better to use a tool like DEXSeq to asks these questions directly? . Also, when filtering by the `AS`, I found some reads with `AS:i:-2147483648`, which I assume is an overflow error.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/528#issuecomment-639153957:561,sanity check,sanity checks,561,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/528#issuecomment-639153957,1,['sanity check'],['sanity checks']
Safety,"Thanks for the thorough suggestions. Actually, we fall into the easier case since Salmon does not support mixing single and paired-end reads in a single BAM file. When performing quantification on a single sample, the reads for that sample must follow a uniform library type. For paired-end reads, the BAM file can contain paired-end and single-end alignments (i.e. orphans), but the reads must all have been paired _in sequencing_. Mixing different library types in the BAM file makes it difficult to assess the compatibility of a fragment with the expected library type, especially if fragments from the different library types are expected to exist in a specific ratio in the input. Anyway, my main motivation for having the separate `AS` and `AP` types was to prevent the need to ""peek"" in the file, since, currently, there is not an easy way to peek the first read without opening the first file twice. However, I've decided that the benefit of having the same uniform (and simpler) interface of `A` always representing automatic library type detection is probably worth it, so I've pushed this implementation (commit 6116b2a). So, when the user provides the `A` library type, Salmon will peek into the first record in the BAM file to determine if the fragment was paired in sequencing or not, and will then set the single / paired-end status on that basis. The only corollary to this is that, in alignment-based mode, the `A` flag is not compatible with an input stream (i.e. the input must be a regular file). I will be sure to document this when I update the docs for the version bump.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/79#issuecomment-242399463:1048,detect,detection,1048,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/79#issuecomment-242399463,2,['detect'],['detection']
Safety,"Thanks for your response! I focus on both transcript level and gene level.; I have another question: I got low mapping rate (less than 20%) of tot-RNA-seq and Nascent-seq. So, is it mean that Salmon is not suitable for pre-mRNA detection? How can I promote the mapping rate?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/32#issuecomment-208223403:228,detect,detection,228,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/32#issuecomment-208223403,1,['detect'],['detection']
Safety,"Thanks, I was good with linking against external jemalloc after your first reply. Mainly interested in knowing the details of your concern, so thanks for elaborating. We use pkgsrc for most of our CentOS installs, and now I feel safe using devel/jemalloc as a dependency. We also use FreeBSD, and in this case, I just patched out the dependency altogether, since jemalloc is FreeBSD's default allocator. Cheers!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/288#issuecomment-420343097:229,safe,safe,229,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/288#issuecomment-420343097,1,['safe'],['safe']
Safety,"Thanks- Jonathan. Yikes, that bad quality one looks like particularly bad quality, I have an example that looks like that in my failed examples. Were you able to recover usable data from it?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/362#issuecomment-490510234:162,recover,recover,162,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/362#issuecomment-490510234,2,['recover'],['recover']
Safety,"The following bash code will detect and parse either format of gtf into an appropriately versioned two column tx2gene file. test=$(zless -S $gtf | grep -v ""#"" | awk '$3==""transcript""' | head -n 1| cut -f9 | tr -s "";"" "" "" | awk '{print$3}' | sort | uniq | sed 's/\""//g'); if [[ $test == ""transcript_id"" ]]; then; zless -S $gtf | grep -v ""#"" | awk '$3==""transcript""' | cut -f9 | tr -s "";"" "" "" | awk '{print$4""\t""$2}' | sort | uniq | sed 's/\""//g' > txp2gene.tsv; elif [[ $test == ""gene_version"" ]]; then; echo ""Separate version field (ensembl, non-gencode transcriptome, eg. rat, etc)""; zless -S $gtf | grep -v ""#"" | awk '$3==""transcript""' | cut -f9 | tr -s "";"" "" "" | awk '{print$6 ""."" $8""\t""$2 ""."" $4}' | sort | uniq | sed 's/\""//g' > txp2gene.tsv; fi",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/598#issuecomment-737617544:29,detect,detect,29,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/598#issuecomment-737617544,1,['detect'],['detect']
Safety,"There is a long literature about why we use counts or CPM (in either case, optionally with an effective transcript length offset) instead of raw TPM for statistical modeling. Using TPM throws out information about the sampling variation. It can be recovered in large sample datasets, but in small sample datasets, it's too much information loss. With respect to Wilcoxon, again, it's good to incorporate the inherent sampling variation of counts into the test statistic even with nonparametric schemes. This occurs in SAMseq (2013). https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4605138/. ...and also in our method Swish (2019), which is based on SAMseq but designed specifically for output of methods like Salmon. https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6765120/. Note that Swish is both 1) nonparametric 2) takes into account the multinomial-based sampling nature of sequencing data 3) also takes into account inferential uncertainty from multimapping reads (across isoforms, alleles, or genes).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/812#issuecomment-1325134215:248,recover,recovered,248,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/812#issuecomment-1325134215,1,['recover'],['recovered']
Safety,"These messages have been removed in 0.9.0. Also, the read parser has had a considerable overhaul to avoid simply busy waiting in a situation like this where the processing is much slower than the disk. Let me know if this problem is resolved on your end.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/152#issuecomment-346981211:100,avoid,avoid,100,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/152#issuecomment-346981211,2,['avoid'],['avoid']
Safety,"Thinking more about the another problem can be the salmon index i.e. since it's gencode and if not already specified, you might wanna add `--gencode` as the command line flag while creating the index. The problem is the _full_ name in the reference fasta and the GTF does not align, only a prefix from the fasta does. Another thing I noticed in the logs you forwarded is that the number of CB detected by our knee heuristic seems to be undershooting. I might have to look into the data to tell more about it but the alternatives would be to explicitly specify the true/expected CB through a tsv file using flag `--whitelist` or you can force Alevin to use top X highly expressed CB with flag `--forceCells X`. Hope this helps.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/326#issuecomment-443715231:393,detect,detected,393,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/326#issuecomment-443715231,1,['detect'],['detected']
Safety,"This happens when there was no read in the same length bin during training period (the first so many reads are used for training) as the read under consideration. So Salmon can't assigned a valid log likelihood and an error is reported. The 3 errors are really the same one. The error log likelihood of 3 models are added (based on position of first mismatch/indel, length of clipping at each end of the read). If the length bin is empty for 1 model, it is likely empty for the other 2 models, and 3 warnings are printed when 1 would have been enough. This read gets a error likelihood of 1 and is mostly ignored by Salmon after that. Such reads should be rare by definition (unless the input BAM was not randomized, or there is bug) and this warning should be rare as well. So unless you see many such warnings, you can safely ignore it.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/701#issuecomment-1421264240:821,safe,safely,821,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/701#issuecomment-1421264240,1,['safe'],['safely']
Safety,"UPDATE: On @rob-p 's suggestion, I removed the `--recoverOrphans` option and then all 60 samples did finished without segfaulting. Perhaps there were too many orphans to handle - alignments rates were a dismal 0.5-23%. These were heavily degraded samples that the sequencing center recommended not to sequence but the PI wanted to try it anyway. If you want a pair of fastq files (full or cutdown to ~5 M reads) to test this weird edge case, I can see about getting them to you. Thanks!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/668#issuecomment-862525216:50,recover,recoverOrphans,50,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/668#issuecomment-862525216,1,['recover'],['recoverOrphans']
Safety,"Well, one can certainly use a tool (like gffread or rsem-prepare-reference) to take a genome and a (possibly custom/augmented) GTF to extract a set of target transcripts. Above, it looks like you were only processing between 90 and 100k transcripts. Given the overall size of the overall reference — ~2.4 billion nucleotides — my guess would be that some of these transcripts may be exceedingly long (and perhaps extracted incorrectly from the underlying tool). I should note that an index can be built on large references (which is why we support 64-bit index construction), but it's a very rare use-case as most transcriptomes (even large _de novo_ transcriptomes) rarely cross the 2^31 barrier, and I would expect it to consume quite a bit of memory. The default `quasi` indexer of Salmon is optimized to be very fast for typical sized transcriptomes (usually a few hundred mega-bases) at the cost of using more memory. The alternative `fmd` index can be made more memory efficient, by setting a larger sampling factor, but the resulting mapping will be slower (though still much faster than standard alignment). I would first check to see if the transcripts.fa file contains what you were expecting (i.e. the normal transcriptome + the auxiliary transcripts you were interested in quantifying), and that you actually have close to 2.4Gb of non-redundant transcriptome sequence that you want to quantify. If this is the case, the options are to try and build the quasi-index on a large memory machine (building the index requires more memory than mapping with the constructed index), or using the fmd-index with a large sampling factor. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/39#issuecomment-176802594:1348,redund,redundant,1348,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/39#issuecomment-176802594,1,['redund'],['redundant']
Safety,"While I definitely trust the jemalloc devs, I do know that such things are possible, as a release is simply associated with a tagged commit, which _can_ be changed via a forced update to the tags. I know because, in my early days using git + GitHub, I did such a foolish thing. So, while I'm sure that the jemalloc devs wouldn't change the file associated with a tag, and while there are safeguards (e.g. check that the file we get matches the SHA of what we expect), simply pulling from a fork is a convenient way to handle this ""generally"" (for packages not as production-quality as jemalloc, or where the developers might not have tagged a release corresponding to what we need). I completely understand that you don't want to link against a standard jemalloc if we compile some strange version with custom modifications. However, here, we simply want to use the vanilla jemalloc. In fact, when salmon is built under bioconda, this is exactly what we do (we link against the conda jemalloc >= 5.1.0).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/288#issuecomment-420339510:388,safe,safeguards,388,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/288#issuecomment-420339510,2,['safe'],['safeguards']
Safety,"Yea. Both are frustrating, which is why we spam warning messages to the console when we remove duplicates. Sorry if this default behavior caused you any trouble, but hopefully its easy to recover these quants without rerunning anything using the map of collapsed transcripts.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/214#issuecomment-381584892:188,recover,recover,188,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/214#issuecomment-381584892,1,['recover'],['recover']
Safety,"Yep that sounds reasonable to me.; In case you wan't to avoid multiple round of alevin runs, the idea in the develop branch is to use `--freqThreshold 0 --maxNumBarcodes 4294967295 --keepCBFraction 0.95` i.e. maxNumBarcodes is almost infinity which will force alevin to consider all CB for processing while keeping 95% of the CB as high confidence and hopefully the last 5% would be `>200` CBs which will make alevin run whitelisting. Thanks again for testing alevin and its features !",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/379#issuecomment-503624687:56,avoid,avoid,56,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/379#issuecomment-503624687,1,['avoid'],['avoid']
Safety,"Yes, that's a wrong file. You have to run alevin either w/o the whitelist or provide the CB as predicted by Cellranger in its output folder, usually inside `filtered_bc_matrix` folder. Please check the `--whitelist` section [here](https://salmon.readthedocs.io/en/latest/alevin.html) for more info.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/404#issuecomment-513495991:95,predict,predicted,95,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/404#issuecomment-513495991,1,['predict'],['predicted']
Safety,"Yes, this would be possible. My main concern would be how different upstream tools handle this. We know STAR sums the lengths of the repeats --- does HISAT / BBMap etc.? I would like to avoid having too many special cases that are tied in with certain tools. I'm not completely opposed to having a few special cases, so long as there are only a few ;P.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/282#issuecomment-418812548:186,avoid,avoid,186,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/282#issuecomment-418812548,1,['avoid'],['avoid']
Safety,"Yes; precisely. In the alignment-based case, Salmon will infer the library type from the alignments. In the case you mention above (someone performs stranded alignment using an unstranded library), Salmon would incorrectly infer a stranded type, though it would actually be a byproduct of passing incorrect options to the aligner. In the read-based mode, since we have control over both the mapping and quantification steps, we can avoid such an issue. However, it seems to me _ok_ to incorrectly infer a library type if we were passed incorrect alignments in the first place, right?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/79#issuecomment-241813836:432,avoid,avoid,432,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/79#issuecomment-241813836,1,['avoid'],['avoid']
Safety,"Yup, and the fact that this ended up as `MU` is strange, since the library type frequencies clearly suggest `IU` (since `ISF` and `ISR` counts seem to dominate). Could it be the result of having the FASTQ files generated by converting from BAM which some sort of bias in the beginning reads? The automatic detection uses the first 10,000 reads to decide --- if these are mapped in a biased way, that could be the cause.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/137#issuecomment-406366598:306,detect,detection,306,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/137#issuecomment-406366598,2,['detect'],['detection']
Safety,"[I confirmed with the developer of zUMIs](https://github.com/sdparekh/zUMIs/issues/298) that no frameshift detection/correction is happening in their approach for SPLiT-seq libraries, so the barcode discovery should be fairly consistent with what alevin is already doing (ie with fixed geometry positions). So, likely no need to incorporate this into `splitp` at the moment but if we/others determine that frameshifts are frequent enough and the data can improve in some noticeable way with correcting them, we can revisit later as you suggested. . As for the barcode detection - my usual approach with `alevin` at least is to let it try to estimate a ""real"" cell number, but if it's way off from our experimental expectations, to inject `--expectCells ncells` and let that serve as a starting point (with subsequent filtering). That has worked reasonably well in the past for me , and seems to be an option for `alevin-fry` as well. I don't know whether that is poor practice in the long run...it came from a place of seeing far too many weak knee plots early in the droplet scRNA-seq days. Are you generally more trusting of these estimates these days?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-988184912:107,detect,detection,107,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-988184912,2,['detect'],['detection']
Safety,"\; --useFSPD; ```. But if I instead run salmon in the NFS directory where I want to run it, the core dumps... ```; [vale@ebi-003 mouse]$ salmon quant \; > -i /nfs/research2/teichmann/reference/mus-musculus/salmon/quasi/mouse_cdna_38.p3.78_repbase_ercc.fa \; > -l IU \; > -1 /nfs/research2/teichmann/valentine/detection-comparison/salmon0.4.2-comparison/mouse/SRP057125_SRS936134_1.fastq \; > -2 /nfs/research2/teichmann/valentine/detection-comparison/salmon0.4.2-comparison/mouse/SRP057125_SRS936134_2.fastq \; > -o SRP057125_SRS936134_salmon_out \; > -g /nfs/research2/teichmann/reference/mus-musculus/salmon/mouse_cdna38.78_repbase_ercc_index_gene_map.txt \; > --biasCorrect \; > --useFSPD; Version Info: This is the most recent version of Salmon.; # salmon (mapping-based) v0.6.0; # [ program ] => salmon; # [ command ] => quant; # [ index ] => { /nfs/research2/teichmann/reference/mus-musculus/salmon/quasi/mouse_cdna_38.p3.78_repbase_ercc.fa }; # [ libType ] => { IU }; # [ mates1 ] => { /nfs/research2/teichmann/valentine/detection-comparison/salmon0.4.2-comparison/mouse/SRP057125_SRS936134_1.fastq }; # [ mates2 ] => { /nfs/research2/teichmann/valentine/detection-comparison/salmon0.4.2-comparison/mouse/SRP057125_SRS936134_2.fastq }; # [ output ] => { SRP057125_SRS936134_salmon_out }; # [ geneMap ] => { /nfs/research2/teichmann/reference/mus-musculus/salmon/mouse_cdna38.78_repbase_ercc_index_gene_map.txt }; # [ biasCorrect ] => { }; # [ useFSPD ] => { }; Logs will be written to SRP057125_SRS936134_salmon_out/logs; [2016-01-02 20:22:59.800] [jointLog] [info] parsing read library format; there is 1 lib; Loading 32-bit quasi index[2016-01-02 20:23:00.830] [stderrLog] [info] Loading Suffix Array; [2016-01-02 20:23:00.830] [stderrLog] [info] Loading Position Hash; [2016-01-02 20:23:00.829] [jointLog] [info] Loading Quasi index; [2016-01-02 20:23:03.751] [stderrLog] [info] Loading Transcript Info; [2016-01-02 20:23:04.776] [stderrLog] [info] Loading Rank-Select Bit Array; [2016-01-02",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/34#issuecomment-168426741:7014,detect,detection-comparison,7014,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/34#issuecomment-168426741,1,['detect'],['detection-comparison']
Safety,"almon-0.13.1/build && /usr/local/Cellar/cmake/3.13.4/bin/cmake -E cmake_depends ""Unix Makefiles"" /Users/gabriel/Projects/salmon-0.13.1 /Users/gabriel/Projects/salmon-0.13.1 /Users/gabriel/Projects/salmon-0.13.1/build /Users/gabriel/Projects/salmon-0.13.1/build /Users/gabriel/Projects/salmon-0.13.1/build/CMakeFiles/libstadenio.dir/DependInfo.cmake --color=; /Applications/Xcode.app/Contents/Developer/usr/bin/make -f CMakeFiles/libstadenio.dir/build.make CMakeFiles/libstadenio.dir/build; [ 9%] Performing configure step for 'libstadenio'; cd /Users/gabriel/Projects/salmon-0.13.1/external/staden-io_lib && ./configure --enable-shared=no --without-libcurl --prefix=/Users/gabriel/Projects/salmon-0.13.1/external/install LDFLAGS= CFLAGS= CC=/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/cc CXX=/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/c++; checking for a BSD-compatible install... /usr/local/bin/ginstall -c; checking whether build environment is sane... yes; checking for a thread-safe mkdir -p... /usr/local/bin/gmkdir -p; checking for gawk... gawk; checking whether make sets $(MAKE)... yes; checking whether make supports nested variables... yes; checking whether to enable maintainer-specific portions of Makefiles... no; checking for gcc... /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/cc; checking whether the C compiler works... yes; checking for C compiler default output file name... a.out; checking for suffix of executables...; checking whether we are cross compiling... configure: error: in `/Users/gabriel/Projects/salmon-0.13.1/external/staden-io_lib':; configure: error: cannot run C compiled programs.; If you meant to cross compile, use `--host'.; See `config.log' for more details; make[2]: *** [libstadenio-prefix/src/libstadenio-stamp/libstadenio-configure] Error 1; make[1]: *** [CMakeFiles/libstadenio.dir/all] Error 2; make: *** [all] Error 2; ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/348#issuecomment-472500713:2515,safe,safe,2515,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/348#issuecomment-472500713,1,['safe'],['safe']
Safety,"approach right. I believe, It takes time and understanding to develop a good model for data generated from any technology and that's what we have been trying to do with salmon for years, piece by piece. Having said that, we don't mean to discourage people from trying salmon, that's one of the way we learn how can we improve the model even further. Now, coming back to your original question about using QuantSeq with salmon and how the paper above approach to solve it. I have a couple of thoughts:; 1.) Like you said, from the reading of their command line argument they didn't use the `nolengthcorrection` and I am surprised about the results myself. Since you have experience with the technology, you are best person to explore the difference in using and not using the length correction with salmon, that's why I shared.; 2.) Salmon models the transcript lengths in its quantification model. The basic intuition being longer length transcripts have higher probability of a read being sampled from them and has to be corrected for when using relative count metrices (like TPM) to avoid length bias. The logic behind `noLengthCorrection` is to _not_ correct for length for 3' protocol since we expect all the reads from one end of the transcript and if we do length correction, I hypothesize, we might end up biasing the estimates on the opposite direction; however the effect size of this hypothesis is still an open question and seemingly from the results from the paper it has minor effect. On the flip side may be it does have effect but their baseline estimates were not great and any improvement is good, for that again since you have experience with the data it's good to know / test what's going on.; 3.) A little experimental thought, although `noLengthCorrection` flag can generate decent estimates, it's actually fully disabling the length effect, which in my opinion we can do better as you look at Figure 1B of the paper it shows some length based affect but again we don't know how ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-565256512:1990,avoid,avoid,1990,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-565256512,2,['avoid'],['avoid']
Safety,"ble difference is because (1) the reads are assumed to arrive in a random order (2) this is only a very small fraction of the total data and (3) if the unoriented reads map to a target in the ""wrong"" direction, they will also align to the proper target in the ""right"" direction and, once the orientation filter is applied for future reads, the weight of evidence should turn the probability of assignment of these unoriented reads toward the proper target. However, I'm guessing there is an edge case you're seeing here where the conditions don't induce this behavior. So, there are 2 immediate solutions to the problem. First, if you know the library type explicitly, you can use that. Second (and some other folks have discussed this here for other reasons), you can do a ""throw-away"" run of salmon on a small prefix of the read file (e.g. `salmon quant ... -lA --skipQuant -r <(gunzip -c reads.fq.gz | head -n 400000)`) to get the output of the automatic library type determination, and then run the full dataset with that library type. Finally, moving forward, I'm happy to consider working on modifying this default behavior. That is, we could (though it would be a little bit of work) modify the default behavior. The idea here is to basically run as we do now for the first 10,000 aligned reads to get the library type and then ""reset"" the whole quantification pipeline. The main challenge here is that salmon is designed to work with streaming FASTQ input, and we don't want to break that. So we can't do something as easy as ""reset the file pointer"". I think the best option is to make a copy of the first X reads in memory, detection the library type with them, and then start quantifying them and continue with the rest of the file. That complicates the logic a bit, because now the input source for reads changes dynamically during quantification --- but I think it could be done. Please let me know if you both have interest in this feature and it's worth putting on the list. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/489#issuecomment-738830213:2935,detect,detection,2935,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/489#issuecomment-738830213,1,['detect'],['detection']
Safety,"e index I used before. There were no issues when I built the index before. In fact everything went very smoothly. Super easy!; I am using a different computer (laptop) instead of my office computer. Here is a link to my index that I built:; https://nevada.box.com/s/b7wx8rnwae4dzak6m04u0lgxalv1kxh6. Here is a link to the transcriptome that was used in the build: Sorry my NevadaBox is very slow copying many files so I have copied the transcriptome again to the following Dropbox folder:. https://www.dropbox.com/s/3ux7lz84qrx5ybd/CS_clean.primary.corrected_loci.CDS.fasta?dl=0. Thanks for your help!. Grant. Grant R. Cramer; Professor; Department of Biochemistry and Molecular Biology, Howard Building Room 205, Mail Stop 330; University of Nevada, Reno; Reno, NV 89557; (775) 784-4204; cramer@unr.edu<mailto:cramer@unr.edu>; http://www.ag.unr.edu/cramer/. On Mar 19, 2018, at 1:43 PM, Rob Patro <notifications@github.com<mailto:notifications@github.com>> wrote:. Hi @grantcramer<https://na01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Fgrantcramer&data=01%7C01%7Ccramer%40unr.edu%7Cfa8af76ea22140f38e4008d58dda106b%7C523b4bfc0ebd4c03b2b96f6a17fd31d8%7C1&sdata=Rv5JuLm0kNlPPfQOshcc%2FUGmEC2g%2B0wIXVmdmIXnbCk%3D&reserved=0>,. Is this the same index you used before? Were there any issues with indexing? Could you provide a link to the transcriptome you are mapping against? We could see if we can reproduce the error on our end. --Rob. —; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://na01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2FCOMBINE-lab%2Fsalmon%2Fissues%2F209%23issuecomment-374368312&data=01%7C01%7Ccramer%40unr.edu%7Cfa8af76ea22140f38e4008d58dda106b%7C523b4bfc0ebd4c03b2b96f6a17fd31d8%7C1&sdata=5xxIgJXM4Fks3IGZkGjQ5%2FR7SAaqb%2F5TvMudf4jZTio%3D&reserved=0>, or mute the thread<https://na01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Fnotifications%2Funsubscrib",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/209#issuecomment-374383623:1025,safe,safelinks,1025,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/209#issuecomment-374383623,1,['safe'],['safelinks']
Safety,"ead 0x7ff97cff4700 (LWP 21664) exited]; [New Thread 0x7ff87cff2700 (LWP 21666)]; [Thread 0x7ff8fcff3700 (LWP 21665) exited]; [New Thread 0x7ff7fcff1700 (LWP 21667)]; [Thread 0x7ff87cff2700 (LWP 21666) exited]; [New Thread 0x7ff77cff0700 (LWP 21668)]; [Thread 0x7ff7fcff1700 (LWP 21667) exited]; [New Thread 0x7ff6fcfef700 (LWP 21669)]; [Thread 0x7ff77cff0700 (LWP 21668) exited]; [New Thread 0x7ff67cfee700 (LWP 21670)]; [Thread 0x7ff6fcfef700 (LWP 21669) exited]; [New Thread 0x7ff5fcfed700 (LWP 21671)]; [Thread 0x7ff67cfee700 (LWP 21670) exited]; [New Thread 0x7ff57cfec700 (LWP 21672)]; [Thread 0x7ff5fcfed700 (LWP 21671) exited]; [New Thread 0x7ff4fcfeb700 (LWP 21673)]; [Thread 0x7ff57cfec700 (LWP 21672) exited]; [New Thread 0x7ff47cfea700 (LWP 21674)]; [Thread 0x7ff4fcfeb700 (LWP 21673) exited]; [New Thread 0x7ff3fcfe9700 (LWP 21675)]; terminate called without an active exception; [Thread 0x7ff47cfea700 (LWP 21674) exited]; [Thread 0x7ff3fcfe9700 (LWP 21675) exited]. Program received signal SIGABRT, Aborted.; 0x00007fff7e8a7067 in __GI_raise (sig=sig@entry=6) at ../nptl/sysdeps/unix/sysv/linux/raise.c:56; 56 ../nptl/sysdeps/unix/sysv/linux/raise.c: No such file or directory.; (gdb) bt; #0 0x00007fff7e8a7067 in __GI_raise (sig=sig@entry=6) at ../nptl/sysdeps/unix/sysv/linux/raise.c:56; #1 0x00007fff7e8a8448 in __GI_abort () at abort.c:89; #2 0x0000000000c3b76d in __gnu_cxx::__verbose_terminate_handler (); at ../../.././libstdc++-v3/libsupc++/vterminate.cc:95; #3 0x0000000000baf9b6 in __cxxabiv1::__terminate (handler=<optimized out>); at ../../.././libstdc++-v3/libsupc++/eh_terminate.cc:47; #4 0x0000000000bafa01 in std::terminate () at ../../.././libstdc++-v3/libsupc++/eh_terminate.cc:57; #5 0x0000000000715f1b in std::vector<std::thread, std::allocator<std::thread> >::~vector() (); #6 0x00000000007bee90 in void cuckoohash_map<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, unsigned int, BarcodeGroupStringHasher, std::equal_to<std::__cxx1",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-396078627:5024,Abort,Aborted,5024,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-396078627,1,['Abort'],['Aborted']
Safety,"ection, tells the Salmon model not to consider the effective length of each transcript for computing the conditional probabilities of originating a fragment from a transcript. So, for the RNA-seq data there is no reason to turn off this term of the model, and we highly recommend not to use that flag for the bulk RNA-seq abundance estimation with Salmon. Looking more carefully at the 2nd case you have posted as the failure case, it is interesting to see that there is a very nice visual evidence on the super transcript that the long transcript might not be expressed at all. I am referring to the zero coverage regions on the Super Transcript between the regions corresponding to the smaller transcripts, e. g., between POF1 and EMC1. So, we tried a solution that inspects the coverage profile of all transcripts and calculates the probability of observing a zero coverage region on each transcript. If this probability is too low, this would be counted as an evidence for a transcript not being expressed at all. This approach seems to be working fine on this example that you have shared here. however, one problem was that there were considerable number of reads in the sample that were uniquely mapping only to the Super Transcript and turning of the expression of that transcript would result in treating those reads as un-mapped. Furthermore, this problem was more evident when we tried that approach on other larger samples, it seemed that could effect the expression of a lot transcripts very significantly. Specially, on the real samples where the coverage are often not uniform and detecting a zero coverage region on a transcript is more common due to un-annotated transcripts in the samples and etc. Currently, we are actively looking for more thorough solutions for this problem to deal with the coverage profile of transcripts. I'll try to update you more as we make more progress about this. Thank you again for the detailed explanation, hope to get back at you soon. Best,; Mohsen",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-666512703:2291,detect,detecting,2291,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-666512703,2,['detect'],['detecting']
Safety,"elective alignment, we could compare and contrast the two. At that point, there are a few options depending on how deeply you want to dive. You could try to see how STAR and selective alignment are mapping differently to these transcripts. One potential difference is that STAR is _a lot_ more happy to softclip reads, which selective alignment won't do by default (you can test the effect with the `--softclipOverhangs` to allow selective alignment to softclip reads that hang off the transcript end or `--softclip` to allow softclips anywhere). Note that selective alignment may _still_ be a bit more conservative than STAR about softclips simply because of the nature of the scoring function it uses. This might give you a sense if one of these alignment methodologies is more consistent with your expectations in this case. Another option is to consider doing a grouping with `terminus`. This will reduce the set of ""genes"" that you can call as DE, because it will be happy to group together transcripts from different genes. However, it should help considerably in eliminating DE from highly-uncertain point estimates. Finally, you might consider performing DE with swish (cc @mikelove as he might have some input here) rather than DESeq2 (though we've typically been using swish at the transcript level rather than the gene level). Unlike DESeq2, swish will explicitly take into account the inferential uncertainty in the abundance estimates, using the Gibbs samples produced by salmon. This will allow it to avoid spurious DE calls that might otherwise occur when you have highly uncertain transcripts that, by chance, end up being assigned very different abundances in different samples / over different runs. Sorry for the information dump, but I wanted to lay out what might be going on, how to assess it, and what some potential solutions might be. If you dive in to start investigating this, feel free to reach out in this issue along the way if you get stuck or have follow-up questions.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/600#issuecomment-740363115:4740,avoid,avoid,4740,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/600#issuecomment-740363115,2,['avoid'],['avoid']
Safety,"entation/>.; For help, type ""help"".; Type ""apropos word"" to search for commands related to ""word""...; Reading symbols from /u/user/local/bin/salmon...done.; (gdb) run alevin -l ISR --chromium -p 4 -o BM_1/alevin -1 ./BM_1/run1/bm_S10_L001_R1_001.fastq.gz -2 ./BM_1/run1/bm_S10_L001_R2_001.fastq.gz --maxHashResizeThreads 2 -i /u/user/ref/cellranger/salmon/transcripts_index --tgMap tx2gene.txt; Starting program: /u/user/local/bin/salmon alevin -l ISR --chromium -p 4 -o BM_1/alevin -1 ./BM_1/run1/bm_S10_L001_R1_001.fastq.gz -2 ./BM_1/run1/bm_S10_L001_R2_001.fastq.gz --maxHashResizeThreads 2 -i /u/user/ref/cellranger/salmon/transcripts_index --tgMap tx2gene.txt; [Thread debugging using libthread_db enabled]; Using host libthread_db library ""/lib/x86_64-linux-gnu/libthread_db.so.1"".; warning: File ""/u/user/local/lib64/libstdc++.so.6.0.21-gdb.py"" auto-loading has been declined by your `auto-load safe; -path' set to ""$debugdir:$datadir/auto-load"".; To enable execution of this file add; add-auto-load-safe-path /u/user/local/lib64/libstdc++.so.6.0.21-gdb.py; line to your configuration file ""/u/user/.gdbinit"".; To completely disable this security protection add; set auto-load safe-path /; line to your configuration file ""/u/user/.gdbinit"".; For more information about this security protection see the; ""Auto-loading safe path"" section in the GDB manual. E.g., run from the shell:; info ""(gdb)Auto-loading safe path""; [New Thread 0x7fff7dbff700 (LWP 21437)]; [Thread 0x7fff7dbff700 (LWP 21437) exited]; Version Info: Could not resolve upgrade information in the alotted time.; Check for upgrades manually at https://combine-lab.github.io/salmon; [New Thread 0x7ffefcfff700 (LWP 21653)]; Logs will be written to BM_1/alevin/logs; [New Thread 0x7ffe7cffe700 (LWP 21654)]; [New Thread 0x7ffdfcffd700 (LWP 21655)]; [New Thread 0x7ffd7cffc700 (LWP 21656)]; ### salmon (single-cell-based) v0.10.3; ### [ program ] => salmon; ### [ command ] => alevin; ### [ libType ] => { ISR }; ### [ chromium ] =",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-396078627:1868,safe,safe-path,1868,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-396078627,1,['safe'],['safe-path']
Safety,"ents, and bug fixes; please upgrade at your; earliest convenience.; ###; [New Thread 0x7fff7d273700 (LWP 14275)]; Logs will be written to pbmc4k/alevin/logs; [New Thread 0x7ffefc3f1700 (LWP 14276)]; [New Thread 0x7ffe7b56f700 (LWP 14277)]; [New Thread 0x7ffdfa6ed700 (LWP 14278)]; ### salmon (single-cell-based) v0.10.1; ### [ program ] => salmon; ### [ command ] => alevin; ### [ libType ] => { ISR }; ### [ chromium ] => { }; ### [ threads ] => { 8 }; ### [ output ] => { pbmc4k/alevin }; ### [ mates1 ] => { /dev/fd/63 }; ### [ mates2 ] => { /dev/fd/62 }; ### [ index ] => { /u/user/ref/cellranger/salmon/transcripts_index }; ### [ tgMap ] => { tx2gene.txt }. [2018-06-08 13:37:41.409] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [New Thread 0x7ffd795e7700 (LWP 14279)]; [New Thread 0x7ffcf95e6700 (LWP 14280)]; [New Thread 0x7ffc795e5700 (LWP 14281)]; [2018-06-08 13:37:41.419] [alevinLog] [info] Processing barcodes files (if Present). processed 6 Million barcodes[New Thread 0x7ffbf7063700 (LWP 14333)]; [New Thread 0x7ffb77062700 (LWP 14334)]; [New Thread 0x7ffaf7061700 (LWP 14335)]; [New Thread 0x7ffa77060700 (LWP 14336)]; [New Thread 0x7ff9f705f700 (LWP 14337)]; [New Thread 0x7ff97705e700 (LWP 14338)]; [New Thread 0x7ff8f705d700 (LWP 14340)]; [New Thread 0x7ff87705c700 (LWP 14341)]; [New Thread 0x7ff7f705b700 (LWP 14342)]; [New Thread 0x7ff77705a700 (LWP 14343)]; [New Thread 0x7ff6f7059700 (LWP 14344)]; [New Thread 0x7ff677058700 (LWP 14345)]; [New Thread 0x7ff5f7057700 (LWP 14346)]; [Thread 0x7ffbf7063700 (LWP 14333) exited]; [New Thread 0x7ff577056700 (LWP 14347)]; [Thread 0x7ffaf7061700 (LWP 14335) exited]; [New Thread 0x7ff4f7055700 (LWP 14348)]; [Thread 0x7ffa77060700 (LWP 14336) exited]; [New Thread 0x7ff477054700 (LWP 14349)]; terminate called without an active exception; [Thread 0x7ff9f705f700 (LWP 14337) exited]; [Thread 0x7ffb77062700 (LWP 14334) exited]. Program received signal SIGABRT, Aborted.; ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-395836214:4971,Abort,Aborted,4971,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-395836214,1,['Abort'],['Aborted']
Safety,"erparts for simplicity); anot.pre <- anot.pre[order(width(anot.pre), decreasing = F), ]. chosenOnesP <- anot.pre[; strand(anot.pre) == '+' & !grepl(';', anot.pre$premature_group) & anot.pre$premature_group %in% names(gencode) & !duplicated(anot.pre$premature_group) &; anot.pre$premature_group %in% anot[anot$transcript_source == 'ensembl_havana']$transcript_id; ]$premature_group[1]. chosenOnesM <- anot.pre[; strand(anot.pre) == '-' & !grepl(';', anot.pre$premature_group) & anot.pre$premature_group %in% names(gencode) & !duplicated(anot.pre$premature_group) &; anot.pre$premature_group %in% anot[anot$transcript_source == 'ensembl_havana']$transcript_id; ]$premature_group[1]. chosenOnes <- c(chosenOnesP, chosenOnesM). # subset chosed ones; anot.ori <- anot; anot.pre.ori <- anot.pre. anot <- anot[anot$transcript_id %in% chosenOnes, ]; anot.pre <- anot.pre[anot.pre$premature_group %in% chosenOnes, ]. # sanity check (make sure strand information is the same for pre and mature RNA counterparts); all(; sort(paste(strand(anot), anot$transcript_id) %>% unique) ==; sort(paste(strand(anot.pre), anot.pre$premature_group) %>% unique); ) %>% print. ### Mature transcript sequences ####; message('Creating mature transcript sequences...'). # subset pos sorted exons, split by tx ID, concatenate exon seq per transcript using unlist; mature.tx <- lapply(; X = split(dna[anot], anot$transcript_id),; FUN = unlist; ) %>% DNAStringSet. message('... now getting reverse complements of mature transcripts on the minus strand...'). mature.tx[names(mature.tx) %in% anot[strand(anot) == '-', ]$transcript_id] <- reverseComplement(; mature.tx[names(mature.tx) %in% anot[strand(anot) == '-', ]$transcript_id]; ). ### Premature transcript sequences ####; message('Creating premature transcript sequences...'). premature.tx <- dna[anot.pre]. message('... now getting reverse complements of premature transcripts on the minus strand...'). premature.tx[names(premature.tx) %in% anot.pre[strand(anot.pre) == '-', ]$",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/655#issuecomment-826035191:7109,sanity check,sanity check,7109,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/655#issuecomment-826035191,2,['sanity check'],['sanity check']
Safety,"essor; Department of Biochemistry and Molecular Biology, Howard Building Room 205, Mail Stop 330; University of Nevada, Reno; Reno, NV 89557; (775) 784-4204; cramer@unr.edu<mailto:cramer@unr.edu>; http://www.ag.unr.edu/cramer/. On Mar 22, 2018, at 6:21 PM, Rob Patro <notifications@github.com<mailto:notifications@github.com>> wrote:. Hi @grantcramer<https://na01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Fgrantcramer&data=01%7C01%7Ccramer%40unr.edu%7C54d34feceb114e30a61b08d5905c7a7b%7C523b4bfc0ebd4c03b2b96f6a17fd31d8%7C1&sdata=w1ED%2B5ZBUY6Z8fTiIs62IZJizv0HcvVzw8CtfEdK32E%3D&reserved=0>,. I was able to successfully index and map against the fasta file you link above (on linux). I was also able to index and map against the index on OSX, using the salmon from bioconda (v 0.9.1). So, I'm not yet able to reproduce this. It seems the file you uploaded for your pre-built index is no longer available, so I couldn't try that out. I'd be happy to give it a try if you can put it up on dropbox or some such. Otherwise, I wonder if there could be some sort of binary compatibility issue. Did you build the index on the same machine you're quantifying on? The OSX I tested on is 10.13.1. Best,; Rob. —; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://na01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2FCOMBINE-lab%2Fsalmon%2Fissues%2F209%23issuecomment-375509050&data=01%7C01%7Ccramer%40unr.edu%7C54d34feceb114e30a61b08d5905c7a7b%7C523b4bfc0ebd4c03b2b96f6a17fd31d8%7C1&sdata=5XDT2ix1q1Uz%2B3kTchI%2B5K9Hzu7UuGkyQAz8KB9ko4o%3D&reserved=0>, or mute the thread<https://na01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Fnotifications%2Funsubscribe-auth%2FAj0RizznzcCphH-HJ9Q8uXvndQ4Lsg9Oks5thE43gaJpZM4Sw28q&data=01%7C01%7Ccramer%40unr.edu%7C54d34feceb114e30a61b08d5905c7a7b%7C523b4bfc0ebd4c03b2b96f6a17fd31d8%7C1&sdata=7DLxrFx74WqeN71%2Bs5cfSxEA1NRxj%2F7uqvp9SrGgjck%3D&reserved=0>.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/209#issuecomment-375513800:1724,safe,safelinks,1724,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/209#issuecomment-375513800,2,['safe'],['safelinks']
Safety,"he lower one shows abundance on a log scale. In this particular sample, it's easy to estimate that ~5-10% of the transcripts are pre-processed (the transcripts still have neighboring genomic DNA). I wanted to see how this ratio changes between samples (for example, in a snoRNA processing-defective mutant strain), but quickly realized this is not easily done in salmon or any other quant tools because the processed transcript is entirely a subset of the sequence of the pre-processed transcript. The only way to accurately quantify it is to use the coverage information, which as you agreed is not really taken into account downstream. If Salmon could incorporate the coverage information to solve this class of problem, that would indeed be a **huge win**. I think the ncRNA example would be both a great biologically-interesting motivating problem, as well as a good technical benchmark for implementing any new methods. It could even be used as a secondary RNA velocity measure in scRNA seq data, provided the method used can detect these (non-polyadenylated) transcripts. > The big questions are (1) how do you fold this type of intuition formally into the probabilistic model and (2) is it possible to incorporate this information efficiently?. This is definitely your domain of expertise (and I know it's a rhetorical question but I'd love to throw some ideas out here)... I can think of a few mostly heuristical approaches.... . 1) when apportioning reads to transcripts, after the mapping phase, incorporate a notion of ""evenness"" into the EM step... reads that decrease the variance in coverage are favored over reads that increase the variance (so, define read depth per 10 bp window or something and calculate the variance across all windows for the transcript, then try to assign reads such that they minimize read depth variance per isoform). The problem here is actual coverage biases may then masquerade as alternative transcript isoforms... 2) Use the information from the unique seq",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-623963851:2406,detect,detect,2406,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-623963851,2,['detect'],['detect']
Safety,"hypothesis of what's going on. * Why are the salmon counts much lower for this gene when using alignment-mode and mapping mode under nf-core?. * Though the behavior you observe is similar, I think the cause is somewhat different. **In alignment mode**, STAR is used for alignment. The alignments are made against the genome and then _projected_ onto the annotated transcriptome. STAR has many internal rules for when an alignment can be successfully projected or not. In this case, STAR limits the number of soft clips it will permit in an alignment that it reports to be valid with respect to the annotated transcriptome. I am guessing that many alignments overhang the end of the annotated transcripts, and so STAR does not project them to the transcriptome and so salmon cannot count them. **In mapping mode**, the nf-core pipeline makes use of salmon's selective-alignment _with decoy sequences_. The main purpose of this is to avoid spurious mapping to transcriptomic sequences that may be similar to other unannotated sequences in the genome that are nonetheless a better match for the read (e.g. an unannotated possibly transcribed pseudogene). The way this works in practice is that both the transcript sequences themselves *and the full genome* are indexed. Any read that aligns _strictly better_ to the genome than the transcriptome is considered to map to a decoy, and is not used for the purposes of quantification. Consistent with the behavior I hypothesized above for STAR, if you have many softclipped bases at the end of the read that nonetheless match what is in the genome downstream of the end of the annotated transcript, you'll likely see these reads assigned as decoys. To check this, you can look at salmon's `meta_info.json` output file to see how many reads were mapped best to decoys. * Why do I see much higher counts for this gene with FeatureCounts?. * It depends on the specific behavior you invoke. However, my guess is that FeatureCounts is being run with flags such t",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/798#issuecomment-1237133883:1224,avoid,avoid,1224,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/798#issuecomment-1237133883,1,['avoid'],['avoid']
Safety,"igure 1 of this paper, it looks to me as though quality trimming is done before adapter trimming](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6129281/figure/bty560-F1/). - [To quote Brian Bushnell (author of BBTools)]( http://seqanswers.com/forums/showpost.php?p=140819&postcount=5), . > It's best to do adapter-trimming first, then quality-trimming, because if you do quality-trimming first, sometimes adapters will be partially trimmed and become too short to be recognized as adapter sequence. When you run BBDuk with both quality-trimming and adapter-trimming in the same run, it will do adapter-trimming first, then quality-trimming. 2. I very well know that the advantage of using fastp is that it can do adapter trimming, etc in a automatic fashion - no need to provide external sequences (example adapter sequences). Yes, I know one can also provide a fasta file of adapters and fatsp will work off it. There are many fatsp issues in GH about adapter detection:. - fail to detect adpaters automatically - (https://github.com/OpenGene/fastp/issues/222 and https://github.com/OpenGene/fastp/issues/205). - [incorrect automatic adapter detection](https://github.com/OpenGene/fastp/issues/240). - [inconsistent behavior with different runs](https://github.com/OpenGene/fastp/issues/231). 3. When I see the above, I am bit skeptical using fastp for qc/adapter trimming. . After lot of trials with bbduk and fastp, I have decided to use bbduk and bbmap for my high throughput analysis. Below, I explain my reasoning behind those choices: . **_```Note - edited this on 02-Apr-2020 to have the correct order of operations ```_** . 1. **_STEP 1 - run bbmap.sh on raw fatsq file to remove contaminants as appropriate (rRNA, mitochondrial, chloroplast)_**; - You have alluded to the importance of removing contaminants [in this post](https://github.com/COMBINE-lab/salmon/issues/160#issuecomment-334762498); >However, the other thing to try is simply to align one of these samples to the genome with a t",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-597393209:1431,detect,detect,1431,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-597393209,2,['detect'],['detect']
Safety,"led bug report! So, I have two initial responses / thoughts about your issue. First, you asked if the issue may be related to a memory allocation error wherein the index didn't build successfully. This is quite possible (and the error you see during quantification is consistent with that). The *full* decoy index is substantially larger than the index on just the transcriptome (after all, it is indexing the entire human genome in addition to the transcriptome). One thing you might try to test this hypothesis, other than requesting to build on a node with more RAM, is to compute a hash (e.g. md5 or sha256 sum) on all of the files in the index, and also record their sizes. Then we can build the index on the same version of the files on our end and compare. Second — and perhaps more importantly for your end goal — the main purpose of the decoy-aware index is to improve specificity rather than sensitivity. That is, the decoys are designed to help avoid _spurious_ mapping of reads to an annotated transcript when a better explanation for the read exists elsewhere in the genome. However, the reads that are mapped to decoys are not otherwise used for quantification. Thus, using the decoy aware transcriptome index is unlikely to improve your mapping rate. I agree that your mapping rate does seem rather low. There are a few potential culprits here, and some diagnostics we can look at to see what might be going wrong. First, you can take a look at the file `aux_info/meta_info.json` in the salmon quantification directories to get a few more details about why reads were not mapped. If you share one of those files here I can describe the relevant fields. Also, I have two more rather common things to consider that might affect the mapping rate. One is to add the sequence for the ribosomal RNAs to your transcriptome before indexing and then quantifying. If your mapping rate increases considerably, this is evidence of rather inefficient depletion prior to sequencing. The other thing t",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/603#issuecomment-744162850:1000,avoid,avoid,1000,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/603#issuecomment-744162850,1,['avoid'],['avoid']
Safety,"ly specified, it is; being set to 0.65; [2019-07-29 15:58:39.034] [jointLog] [info] Usage of --validateMappings,; without --hardFilter implies use of range factorization.; rangeFactorizationBins is being set to 4; [2019-07-29 15:58:39.034] [jointLog] [info] Usage of --validateMappings; implies a default consensus slack of 0.2. Setting consensusSlack to 0.2.; [2019-07-29 15:58:39.034] [jointLog] [info] parsing read library format; [2019-07-29 15:58:39.034] [jointLog] [error] Failed to successfully parse; any complete read libraries. Please make sure you provided arguments; properly to -1, -2 (for paired-end libraries) or -r (for single-end; libraries), and that the library format option (-l) *comes before* the read; libraries. On Mon, Jul 29, 2019 at 4:06 PM Avi Srivastava <notifications@github.com>; wrote:. > Oh Sorry about that what I meant was the salmon.log file or the the; > meta-info.json file created by salmon in the output directory. You can; > check what files salmon is detecting it seems there are 12 files in the; > mate1 and 13 files in the mate2. Can you confirm there are 13 pairs of file; > in that directory and their regex is same as you are using ? Can you also; > try putting the names of the file instead * as regex ?; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/COMBINE-lab/salmon/issues/408?email_source=notifications&email_token=AEHDXAA5DHKAZKVCZY5N7ULQB5ZXXA5CNFSM4IGU4ZTKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOD3CIG3I#issuecomment-516195181>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AEHDXAHE56TJTIQFQDFDGMDQB5ZXXANCNFSM4IGU4ZTA>; > .; >. -- ; Sara E. Boles, MS; PhD Candidate | Whitehead Lab; Pharmacology and Toxicology Graduate Group; Department of Environmental Toxicology; University of California, Davis, CA 95616; http://whiteheadresearch.wordpress.com/; https://sites.google.com/a/ucdavis.edu/sara-e-boles/",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/408#issuecomment-516514620:1527,detect,detecting,1527,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/408#issuecomment-516514620,1,['detect'],['detecting']
Safety,"ndedness:unstranded }; [2021-01-08 12:43:44.711] [jointLog] [info] numQuantThreads = 14; parseThreads = 6; Checking that provided alignment files have consistent headers . . . done; Populating targets from aln = ""SRR3212847.Aligned.Shuffled.bam"", fasta = ""mRNA.fasta"" . . .done. processed 0 reads in current roundSegmentation fault (core dumped); ```. ### 2. Shuffling a headless bam file with `samtools collate`; (I think I saw something about the bam's header in another thread dealing with this issue); ```; samtools view \; -b \; -@ 40 \; -o SRR3212847.Aligned.SortedByCoord.NoHeader.bam \; SRR3212847.Aligned.SortedByCoord.bam. samtools collate \; -@ 40 \; -o SRR3212847.Aligned.Shuffled.NoHeader.bam \; SRR3212847.Aligned.SortedByCoord.NoHeader.bam. salmon quant \; -t mRNA.fasta \; -p 20 \; -l A \; -a SRR3212847.Aligned.Shuffled.NoHeader.bam \; -o SRR3212847.Aligned.Shuffled.NoHeader; ```. ```. .... [2021-01-08 12:42:10.700] [jointLog] [warning] . WARNING: Detected suspicious pair --- ; The names are different:; read1 : SRR3212847.24133171; read2 : SRR3212847.33911054; The proper-pair statuses are inconsistent:; read1 [SRR3212847.24133171] : no proper-pair; not mapped; matenot mapped. read2 : [SRR3212847.24133171] : proper-pair; mapped; matemapped. [2021-01-08 12:42:10.700] [jointLog] [warning] . WARNING: Detected suspicious pair --- ; The names are different:; read1 : SRR3212847.33911054; read2 : SRR3212847.30781941. Segmentation fault (core dumped); ```. ### 3. Sorting with `samtools sort -n`; ```; samtools sort \; -@ 40 \; -n \; -o SRR3212847.Aligned.SortedByName.bam \; SRR3212847.Aligned.SortedByCoord.bam. salmon quant \; -t mRNA.fasta \; -p 20 \; -l A \; -a SRR3212847.Aligned.SortedByName.bam \; -o SRR3212847.Aligned.SortedByName; ```. ```; Version Info: This is the most recent version of salmon.; # salmon (alignment-based) v1.4.0; # [ program ] => salmon ; # [ command ] => quant ; # [ targets ] => { mRNA.fasta }; # [ threads ] => { 20 }; # [ libType ] => { A }; # ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/582#issuecomment-756727212:2375,Detect,Detected,2375,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/582#issuecomment-756727212,1,['Detect'],['Detected']
Safety,nm - I just re-read the above and realized @rob-p already suggested just that. Sorry for being redundant! PS I am very grateful for the existence of Salmon. Thanks to all contributors!,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/175#issuecomment-392179743:95,redund,redundant,95,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/175#issuecomment-392179743,1,['redund'],['redundant']
Safety,"ntLog] [info] writing output. [2016-01-02 20:17:44.160] [jointLog] [warning] NOTE: Read Lib [( SRP057125_SRS936134_1.fastq, SRP057125_SRS936134_2.fastq )] :. Greater than 5% of the alignments (but not, necessarily reads) disagreed with the provided library type; check the file: SRP057125_SRS936134_salmon_out/libFormatCoun ts.txt for details. [vale@ebi-003 salmon-problem]$; ```. The command run being:. ```; salmon quant \; -i mouse_cdna_38.p3.78_repbase_ercc.fa \; -l IU \; -1 SRP057125_SRS936134_1.fastq \; -2 SRP057125_SRS936134_2.fastq \; -o SRP057125_SRS936134_salmon_out \; -g /nfs/research2/teichmann/reference/mus-musculus/salmon/mouse_cdna38.78_repbase_ercc_index_gene_map.txt \; --biasCorrect \; --useFSPD; ```. But if I instead run salmon in the NFS directory where I want to run it, the core dumps... ```; [vale@ebi-003 mouse]$ salmon quant \; > -i /nfs/research2/teichmann/reference/mus-musculus/salmon/quasi/mouse_cdna_38.p3.78_repbase_ercc.fa \; > -l IU \; > -1 /nfs/research2/teichmann/valentine/detection-comparison/salmon0.4.2-comparison/mouse/SRP057125_SRS936134_1.fastq \; > -2 /nfs/research2/teichmann/valentine/detection-comparison/salmon0.4.2-comparison/mouse/SRP057125_SRS936134_2.fastq \; > -o SRP057125_SRS936134_salmon_out \; > -g /nfs/research2/teichmann/reference/mus-musculus/salmon/mouse_cdna38.78_repbase_ercc_index_gene_map.txt \; > --biasCorrect \; > --useFSPD; Version Info: This is the most recent version of Salmon.; # salmon (mapping-based) v0.6.0; # [ program ] => salmon; # [ command ] => quant; # [ index ] => { /nfs/research2/teichmann/reference/mus-musculus/salmon/quasi/mouse_cdna_38.p3.78_repbase_ercc.fa }; # [ libType ] => { IU }; # [ mates1 ] => { /nfs/research2/teichmann/valentine/detection-comparison/salmon0.4.2-comparison/mouse/SRP057125_SRS936134_1.fastq }; # [ mates2 ] => { /nfs/research2/teichmann/valentine/detection-comparison/salmon0.4.2-comparison/mouse/SRP057125_SRS936134_2.fastq }; # [ output ] => { SRP057125_SRS936134_salmon_out }; ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/34#issuecomment-168426741:6295,detect,detection-comparison,6295,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/34#issuecomment-168426741,1,['detect'],['detection-comparison']
Safety,"nu/libdl.so.2 (0x00007f8599b19000); libstdc++.so.6 => /u/user/local/lib64/libstdc++.so.6 (0x00007f859979f000); ```. The linux version and g++ version are listed below:; ```; cat /proc/version; Linux version 4.9.0-0.bpo.6-amd64 (debian-kernel@lists.debian.org) (gcc version 4.9.2 (Debian 4.9.2-10+deb8u1) ) #1 SMP Debian 4.9.82-1+deb9u3~bpo8+1 (2018-03-22). ~/data/PCSI/PC10X/paper/pbmc$ g++ -v; Using built-in specs.; COLLECT_GCC=g++; COLLECT_LTO_WRAPPER=/u/user/local/libexec/gcc/x86_64-unknown-linux-gnu/5.4.0/lto-wrapper; Target: x86_64-unknown-linux-gnu; Configured with: ./configure --prefix=/u/user/local; Thread model: posix; gcc version 5.4.0 (GCC); ```. ```; [Thread debugging using libthread_db enabled]; Using host libthread_db library ""/lib/x86_64-linux-gnu/libthread_db.so.1"".; warning: File ""/u/user/local/lib64/libstdc++.so.6.0.21-gdb.py"" auto-loading has been declined by your `auto-load safe-path' set to ""$debugdir:$datadir/auto-load"".; To enable execution of this file add; add-auto-load-safe-path /u/user/local/lib64/libstdc++.so.6.0.21-gdb.py; line to your configuration file ""/u/user/.gdbinit"".; To completely disable this security protection add; set auto-load safe-path /; line to your configuration file ""/u/user/.gdbinit"".; For more information about this security protection see the; ""Auto-loading safe path"" section in the GDB manual. E.g., run from the shell:; info ""(gdb)Auto-loading safe path""; [New Thread 0x7fff7e0f4700 (LWP 14274)]; Version Info: ### A newer version of Salmon is available. ####; [Thread 0x7fff7e0f4700 (LWP 14274) exited]; ###; The newest version, available at https://github.com/COMBINE-lab/salmon/releases; contains new features, improvements, and bug fixes; please upgrade at your; earliest convenience.; ###; [New Thread 0x7fff7d273700 (LWP 14275)]; Logs will be written to pbmc4k/alevin/logs; [New Thread 0x7ffefc3f1700 (LWP 14276)]; [New Thread 0x7ffe7b56f700 (LWP 14277)]; [New Thread 0x7ffdfa6ed700 (LWP 14278)]; ### salmon (single-cell-bas",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-395836214:2299,safe,safe-path,2299,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-395836214,1,['safe'],['safe-path']
Safety,"on = 900 | max rel diff. = 0.0146915; [2016-01-02 20:23:59.212] [jointLog] [info] iteration 1000, recomputing effective lengths; [2016-01-02 20:24:01.395] [jointLog] [info] iteration = 1000 | max rel diff. = 0.0147088; [2016-01-02 20:24:01.837] [jointLog] [info] iteration = 1100 | max rel diff. = 0.021175; [2016-01-02 20:24:02.193] [jointLog] [info] iteration = 1200 | max rel diff. = 0.01904; [2016-01-02 20:24:02.572] [jointLog] [info] iteration = 1300 | max rel diff. = 0.0187047; [2016-01-02 20:24:02.972] [jointLog] [info] iteration = 1400 | max rel diff. = 0.0213549; [2016-01-02 20:24:03.360] [jointLog] [info] iteration = 1500 | max rel diff. = 0.0311727; [2016-01-02 20:24:03.745] [jointLog] [info] iteration = 1600 | max rel diff. = 0.0100658; [2016-01-02 20:24:04.141] [jointLog] [info] iteration = 1700 | max rel diff. = 0.0100679; [2016-01-02 20:24:04.536] [jointLog] [info] iteration = 1800 | max rel diff. = 0.0100686; [2016-01-02 20:24:04.642] [jointLog] [info] iteration = 1827 | max rel diff. = 0.00921912; [2016-01-02 20:24:04.646] [jointLog] [info] Finished optimizer; [2016-01-02 20:24:04.646] [jointLog] [info] writing output. Computing gene-level abundance estimates; [2016-01-02 20:24:04.882] [jointLog] [warning] NOTE: Read Lib [( /nfs/research2/teichmann/valentine/detection-comparison/salmon0.4.2-comparison/mouse/SRP057125_SRS936134_1.fastq, /nfs/research2/teichmann/valentine/detection-comparison/salmon0.4.2-comparison/mouse/SRP057125_SRS936134_2.fastq )] :. Greater than 5% of the alignments (but not, necessarily reads) disagreed with the provided library type; check the file: SRP057125_SRS936134_salmon_out/libFormatCounts.txt for details. There were 104534 transcripts mapping to 44034 genes; Parsed 104000 expression lines; done; Aggregating expressions to gene level . . . done; Segmentation fault (core dumped); [vale@ebi-003 mouse]$; ```. (I also tried the command in the NSF directory to write to /tmp/SRP057125_SRS936134_salmon_out, but that also segfaults)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/34#issuecomment-168426741:11262,detect,detection-comparison,11262,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/34#issuecomment-168426741,2,['detect'],['detection-comparison']
Safety,"ou'd expect to get more mappings) than when you specify ""ISR"". The ""A"" flag just looks at how the first 10,000 reads map and guesses the library type based on that. On thing to make sure of is that your reads aren't ""ordered"" in any way, such that you'd expect the first 10,000 to deviate in any meaningful way from the statistics of the reads of the reads. > Is it better to build assemblies with strand-aware flags? If so, does it usually make a large difference to quantification results, or a minor one? I don't know what protocol the sequencing facility used, but I am sure I could ask them. I gather from my recent reading that the extra information gained by using a stranded protocol is worthwhile, so I would expect that the sequencing facility used one, but why doesn't Trinity or MEGAHIT detect the sequecing protocol that was used? . So there are really 2 questions here. *If* the data are stranded, then yes, it's worthwhile to use stranded flags in both assembly and quantification. This is because stranded protocols will allow you to better disambiguate (a) overlapping genes and (b) reads that are ambiguous between sequence-similar genes that happen to reside on different strands. The *second* question is why Trinity or MEGAHIT wouldn't detect this. The main reason for this is that these are assembly tools. Without access to a reference genome, there is no principled way for these tools to know what the orientation of a read is _a priori_, so they generally rely on the user to specify if the reads are stranded or unstranded. > Or, if you have to specify it, why do none of the example Trinity commands I've come across include this option? It doesn't strike me as a commonly used specification in making assemblies. The Trinity command to specify the strandedness is `--SS_lib_type` (see e.g. [here](https://scilifelab.github.io/courses/ngsintro/1604/labs/rnaseqDenovo)). By default, Trinity will assume unstranded reads (as that's the safest default assumption). Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/840#issuecomment-1493034427:1721,detect,detect,1721,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/840#issuecomment-1493034427,2,"['detect', 'safe']","['detect', 'safest']"
Safety,"sam-xlate is actually the only tool that I'm aware of to perform this operation on an existing BAM file. I've heard of people using it with success. Of course, I'd also think of doing an analysis with the original reads to validate concordance. Note: if you don't have the original reads, you can do a BAM -> FASTQ conversion to recover the read sequences and then feed them to Salmon.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/131#issuecomment-293316682:329,recover,recover,329,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/131#issuecomment-293316682,1,['recover'],['recover']
Safety,"shResizeThreads 2 -i /u/user/ref/cellranger/salmon/transcripts_index --tgMap tx2gene.txt; Starting program: /u/user/local/bin/salmon alevin -l ISR --chromium -p 4 -o BM_1/alevin -1 ./BM_1/run1/bm_S10_L001_R1_001.fastq.gz -2 ./BM_1/run1/bm_S10_L001_R2_001.fastq.gz --maxHashResizeThreads 2 -i /u/user/ref/cellranger/salmon/transcripts_index --tgMap tx2gene.txt; [Thread debugging using libthread_db enabled]; Using host libthread_db library ""/lib/x86_64-linux-gnu/libthread_db.so.1"".; warning: File ""/u/user/local/lib64/libstdc++.so.6.0.21-gdb.py"" auto-loading has been declined by your `auto-load safe; -path' set to ""$debugdir:$datadir/auto-load"".; To enable execution of this file add; add-auto-load-safe-path /u/user/local/lib64/libstdc++.so.6.0.21-gdb.py; line to your configuration file ""/u/user/.gdbinit"".; To completely disable this security protection add; set auto-load safe-path /; line to your configuration file ""/u/user/.gdbinit"".; For more information about this security protection see the; ""Auto-loading safe path"" section in the GDB manual. E.g., run from the shell:; info ""(gdb)Auto-loading safe path""; [New Thread 0x7fff7dbff700 (LWP 21437)]; [Thread 0x7fff7dbff700 (LWP 21437) exited]; Version Info: Could not resolve upgrade information in the alotted time.; Check for upgrades manually at https://combine-lab.github.io/salmon; [New Thread 0x7ffefcfff700 (LWP 21653)]; Logs will be written to BM_1/alevin/logs; [New Thread 0x7ffe7cffe700 (LWP 21654)]; [New Thread 0x7ffdfcffd700 (LWP 21655)]; [New Thread 0x7ffd7cffc700 (LWP 21656)]; ### salmon (single-cell-based) v0.10.3; ### [ program ] => salmon; ### [ command ] => alevin; ### [ libType ] => { ISR }; ### [ chromium ] => { }; ### [ threads ] => { 4 }; ### [ output ] => { BM_1/alevin }; ### [ mates1 ] => { ./BM_1/run1/bm_S10_L001_R1_001.fastq.gz }; ### [ mates2 ] => { ./BM_1/run1/bm_S10_L001_R2_001.fastq.gz }; ### [ maxHashResizeThreads ] => { 2 }; ### [ index ] => { /u/user/ref/cellranger/salmon/transcripts_index }; ##",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-396078627:2186,safe,safe,2186,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-396078627,1,['safe'],['safe']
Safety,"sible known combinations of barcodes instead and be more positionally flexible. But deciding how many indel bases are allowable, and presumably doing multiple passes through the data to establish an include-list could be time-consuming. Further, the zUMIs developer rightly mentions [in this thread](https://github.com/sdparekh/zUMIs/issues/63) that there are likely going to be _many_ unused barcode combinations this way, so lots of time could be spent looking for ""cells"" that don't actually exist in the data. The authors of the paper from which our test dataset was derived describe in their methods using a Drop-seq computational framework, so I'm not sure which approach theirs is more similar to. . The simplest approach here is certainly the automatic detection, but it will come at the cost of losing meaningful reads to frameshift errors. . My guess is this falls well out of the scope of alevin, but if you're interested in improving on that, there may be a middle ground between the two approaches above, one that I'm not sure if your group or others have attempted for other methods: we could essentially do a 2-pass barcode detection. The first pass would restrict based on positions like we're already doing, and establish an include-list of possible barcodes seen in the data. Then we could pass through the barcode sequences a second time, looking only for those sequence combinations, but allowing 1-2bp flexibility in the positions they occur, potentially rescuing some of the ones missed during the first pass. This would get around the issue of searching for thousands (or more) barcodes that never exist. . However, for your above sequences in red, we would still need to somehow collapse the barcodes `GATAGACA`, `ATAGACAT`, and `ATAGACAG`, but perhaps that can be achieved with some Levenshtein distance flexibility using the entire 24bp barcode sequence detected...? . Anyway sorry for the brainstorming dump, but the short answer is: we're probably stuck losing a bunch of ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-985554883:1604,detect,detection,1604,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-985554883,2,['detect'],['detection']
Safety,"t:; https://nevada.box.com/s/b7wx8rnwae4dzak6m04u0lgxalv1kxh6. Here is a link to the transcriptome that was used in the build: Sorry my NevadaBox is very slow copying many files so I have copied the transcriptome again to the following Dropbox folder:. https://www.dropbox.com/s/3ux7lz84qrx5ybd/CS_clean.primary.corrected_loci.CDS.fasta?dl=0. Thanks for your help!. Grant. Grant R. Cramer; Professor; Department of Biochemistry and Molecular Biology, Howard Building Room 205, Mail Stop 330; University of Nevada, Reno; Reno, NV 89557; (775) 784-4204; cramer@unr.edu<mailto:cramer@unr.edu>; http://www.ag.unr.edu/cramer/. On Mar 19, 2018, at 1:43 PM, Rob Patro <notifications@github.com<mailto:notifications@github.com>> wrote:. Hi @grantcramer<https://na01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Fgrantcramer&data=01%7C01%7Ccramer%40unr.edu%7Cfa8af76ea22140f38e4008d58dda106b%7C523b4bfc0ebd4c03b2b96f6a17fd31d8%7C1&sdata=Rv5JuLm0kNlPPfQOshcc%2FUGmEC2g%2B0wIXVmdmIXnbCk%3D&reserved=0>,. Is this the same index you used before? Were there any issues with indexing? Could you provide a link to the transcriptome you are mapping against? We could see if we can reproduce the error on our end. --Rob. —; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://na01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2FCOMBINE-lab%2Fsalmon%2Fissues%2F209%23issuecomment-374368312&data=01%7C01%7Ccramer%40unr.edu%7Cfa8af76ea22140f38e4008d58dda106b%7C523b4bfc0ebd4c03b2b96f6a17fd31d8%7C1&sdata=5xxIgJXM4Fks3IGZkGjQ5%2FR7SAaqb%2F5TvMudf4jZTio%3D&reserved=0>, or mute the thread<https://na01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Fnotifications%2Funsubscribe-auth%2FAj0RiwrvJNIRo4GQHosqdQGVHLIG-iFYks5tgBhsgaJpZM4Sw28q&data=01%7C01%7Ccramer%40unr.edu%7Cfa8af76ea22140f38e4008d58dda106b%7C523b4bfc0ebd4c03b2b96f6a17fd31d8%7C1&sdata=mTKTIF9dFJToq9zGkIBQF%2FaET1Hu42%2F3QHiFmxpakNc%3D&reserved=0>.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/209#issuecomment-374383623:1605,safe,safelinks,1605,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/209#issuecomment-374383623,2,['safe'],['safelinks']
Safety,tLog] [info] done; [2016-12-13 22:44:20.485] [jointLog] [info] Index contained 182608 targets. processed 19000001 fragments; hits: 65897764; hits per frag: 3.48152. [2016-12-13 22:45:33.192] [jointLog] [info] Computed 137534 rich equivalence classes for further processing; [2016-12-13 22:45:33.192] [jointLog] [info] Counted 16265961 total reads in the equivalence classes; [2016-12-13 22:45:33.233] [jointLog] [info] Mapping rate = 83.509%. [2016-12-13 22:45:33.233] [jointLog] [info] finished quantifyLibrary(); [2016-12-13 22:45:33.234] [jointLog] [info] Starting optimizer; [2016-12-13 22:45:33.516] [jointLog] [info] Marked 0 weighted equivalence classes as degenerate; [2016-12-13 22:45:33.523] [jointLog] [info] iteration = 0 | max rel diff. = 299.95; [2016-12-13 22:45:34.217] [jointLog] [info] iteration = 100 | max rel diff. = 0.122252; [2016-12-13 22:45:34.912] [jointLog] [info] iteration = 200 | max rel diff. = 0.102915; [2016-12-13 22:45:35.612] [jointLog] [info] iteration = 300 | max rel diff. = 0.145792; [2016-12-13 22:45:36.357] [jointLog] [info] iteration = 400 | max rel diff. = 0.217489; [2016-12-13 22:45:37.055] [jointLog] [info] iteration = 500 | max rel diff. = 0.0159298; [2016-12-13 22:45:37.628] [jointLog] [info] iteration = 569 | max rel diff. = 0.00958049; [2016-12-13 22:45:37.653] [jointLog] [info] Finished optimizer; [2016-12-13 22:45:37.653] [jointLog] [info] writing output. [2016-12-13 22:45:38.213] [jointLog] [info] Starting Gibbs Sampler; 100% [=====================================================] in 31s; [2016-12-13 22:46:10.451] [jointLog] [info] Finished Gibbs Sampler; [2016-12-13 22:46:10.451] [jointLog] [warning] NOTE: Read Lib [SRR2454059.fq.gz] :. Detected a *potential* strand bias > 1% in an unstranded protocol check the file: test_quant/lib_format_counts.json for details; ```. i.e. I don't seem to get the complaints from the Gibbs sampler and all output files look to be created properly. I'm trying to figure out what could be different.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-266935584:3595,Detect,Detected,3595,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-266935584,1,['Detect'],['Detected']
Safety,"tead and be more positionally flexible. But deciding how many indel bases are allowable, and presumably doing multiple passes through the data to establish an include-list could be time-consuming. Further, the zUMIs developer rightly mentions [in this thread](https://github.com/sdparekh/zUMIs/issues/63) that there are likely going to be _many_ unused barcode combinations this way, so lots of time could be spent looking for ""cells"" that don't actually exist in the data. The authors of the paper from which our test dataset was derived describe in their methods using a Drop-seq computational framework, so I'm not sure which approach theirs is more similar to. . The simplest approach here is certainly the automatic detection, but it will come at the cost of losing meaningful reads to frameshift errors. . My guess is this falls well out of the scope of alevin, but if you're interested in improving on that, there may be a middle ground between the two approaches above, one that I'm not sure if your group or others have attempted for other methods: we could essentially do a 2-pass barcode detection. The first pass would restrict based on positions like we're already doing, and establish an include-list of possible barcodes seen in the data. Then we could pass through the barcode sequences a second time, looking only for those sequence combinations, but allowing 1-2bp flexibility in the positions they occur, potentially rescuing some of the ones missed during the first pass. This would get around the issue of searching for thousands (or more) barcodes that never exist. . However, for your above sequences in red, we would still need to somehow collapse the barcodes `GATAGACA`, `ATAGACAT`, and `ATAGACAG`, but perhaps that can be achieved with some Levenshtein distance flexibility using the entire 24bp barcode sequence detected...? . Anyway sorry for the brainstorming dump, but the short answer is: we're probably stuck losing a bunch of reads due to positional errors like this",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-985554883:2345,detect,detected,2345,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-985554883,2,['detect'],['detected']
Safety,"the most recent version of Salmon.; ### salmon (mapping-based) v0.8.2; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts }; ### [ threads ] => { 16 }; ### [ libType ] => { ISR }; ### [ mates1 ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/merged_fastq/R10001_D2B1WACXX.fastq.gz }; ### [ mates2 ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/merged_fastq/R10001_D2B1WACXX_read2.fastq.gz }; ### [ output ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test4/R10001_D2B1WACXX }; Logs will be written to /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test4/R10001_D2B1WACXX/logs; [1m[2017-03-29 14:56:39.675] [jointLog] [info] parsing read library format; [00m[1m[2017-03-29 14:56:39.733] [jointLog] [info] There is 1 library.; [00mterminate called without an active exception; /cm/local/apps/sge/var/spool/compute-067/job_scripts/110316: line 31: 64339 Aborted (core dumped) /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon quant -i /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts -p 16 -l ISR -1 ${FILE1} -2 ${FILE2} -o /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test4/${ID}; **** Job ends ****; Wed Mar 29 14:58:05 EDT 2017. ```. ### SGE email example info. ```; Job-array task 110316.1 (step6-salmon_test4.gsk_phaseII) Complete; User = lcollado; Queue = shared.q@compute-067.cm.cluster; Host = compute-067.cm.cluster; Start Time = 03/29/2017 14:53:42; End Time = 03/29/2017 14:58:05; User Time = 00:00:00; System Time = 00:05:39; Wallclock Time = 00:04:23; CPU = 00:05:39; Max vmem = 24.202G; Exit Status = 0; ```. Note that in this case, it didn't read the maximum memory requested (16 * 3 = 48 GB). ## Large memory, p 1. ### Bash. ```bash; #!/bin/bash; #$ -cwd; #$ -l mem_free=80G,h_vmem=90G,h_fsize=100G; #$",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-290516965:6419,Abort,Aborted,6419,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-290516965,1,['Abort'],['Aborted']
Safety,"this is having in your sample, you can align reads to the genome using STAR (and project them to the transcriptome) to produce a BAM file that salmon can quantify. You can check RSEM's script to see exactly how it invokes STAR, but the parameters are something like `--outFilterType BySJout --alignSJoverhangMin 8 --outFilterMultimapNmax 20 --alignSJDBoverhangMin 1 --outFilterMismatchNmax 999 --outFilterMismatchNoverReadLmax 0.04 --alignIntronMin 20 --alignIntronMax 1000000 --alignMatesGapMax 1000000 --eadFilesCommand zcat --outSAMtype BAM Unsorted --quantMode TranscriptomeSAM --outSAMattributes NH HI AS NM MD --quantTranscriptomeBan IndelSoftclipSingleend`; note that last parameter that I will come back to later. Also, the paper referenced above also describes a new capability present in recent versions of salmon that allow it to index the entire genome (as well as the transcriptome) to have the former act as a decoy. This allows avoiding what might otherwise be spurious mappings that result when one considers only the transcriptome as a source of mapping. There are a number of ways to proceed on this front, but this is a good place to first check for discrepancy (and the paper gives a good overview of the relative tradeoffs and merits of different alignment approaches). * Salmon and RSEM use related but distinct optimization algorithms by default. RSEM uses the EM algorithm, and salmon uses the variational Bayesian EM algorithm. The latter tends to induce more sparse solutions. This is simply because they are optimizing slightly different objectives. It is very difficult to say in general if one is ""better"" than the other in a blanket way, but [there is previous literature to support that the VBEM may be more accurate](https://academic.oup.com/bioinformatics/article/29/18/2292/239795). However, while RSEM only implements the EM algorithm, salmon actually implements and provides a switch to use either. So, if you want to test the effect of this difference, you can run",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/612#issuecomment-758004590:2271,avoid,avoiding,2271,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/612#issuecomment-758004590,2,['avoid'],['avoiding']
Safety,"too many mismatches |	0; % of reads unmapped: too many mismatches |	0.00%; Number of reads unmapped: too short |	0; % of reads unmapped: too short |	0.00%; Number of reads unmapped: other |	4006; % of reads unmapped: other |	0.00%; CHIMERIC READS:; Number of chimeric reads |	0; % of chimeric reads |	0.00%; ```. It was really better but I am afraid that I have really low quality (I try the parameter 0.3 when I wrote these lines ), I filtered again with samtools -f 2 -F3840 and the salmon counts which is still very low : 24323720 counts. I used samtools flagstat to see what happens after the filter and we get this?; ```; 48983692 + 0 in total (QC-passed reads + QC-failed reads); 0 + 0 secondary; 0 + 0 supplementary; 0 + 0 duplicates; 48983692 + 0 mapped (100.00% : N/A); 48983692 + 0 paired in sequencing; 24491846 + 0 read1; 24491846 + 0 read2; 48983692 + 0 properly paired (100.00% : N/A); 48983692 + 0 with itself and mate mapped; 0 + 0 singletons (0.00% : N/A); 0 + 0 with mate mapped to a different chr; 0 + 0 with mate mapped to a different chr (mapQ>=5); ```. I don't understand why I'm losing so many counts, is it because I'm filtering? But still I have to filter to get the properly pairs... For the sorting it's totally my fault I read the doc wrong but even by not sorting I get very low results not usable less than 26%. The experimentation is done on oak, on 4 times 3 late samples and 3 early samples of dormancy were recovered and we made a TruSeq stranded illumina on these samples. I use a gene model built by my team with the 25808 genes that the oak has as reference. For this part ""Is this a polyA selection or ribosomal depletion prep"" I don't know, I'll find out. To be honest I am totally lost because I don't understand what's wrong in my analysis.... Thank you very much for your help once again . Kisekya. EDIT:. I discover that I have 59 millions of duplicates in my data...; I tried to delete it after filtering my proper pair I get bad records 38% of mapping ...",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/676#issuecomment-874540664:4832,recover,recovered,4832,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/676#issuecomment-874540664,2,['recover'],['recovered']
Safety,"tting the reads 50/50 or, with the default settings, giving nearly all the reads to the longer transcript. I realized that, as a human, the reason the short transcript is obviously the dominant one is how the reads pileup in the alignment. There are hundreds of reads mapping to both transcripts, but NO reads map to the 5' of the long transcript. As I understand the selective alignment, the alignment scores are passed to the quantification step, but the *position* of the reads is not used downstream. In order to pass my human intuition along here, the software would need to pay attention to the coverage bias of the reads mapping to the transcripts and assign a penalty when two otherwise identical transcripts have a different coverage variance across the transcript. This sounds like what the --posBias flag should incorporate into the effective lengths, but it doesn't have much effect on these transcripts for me (FYI, I am getting a segfault when I run only --posBias in the current salmon version, but if I run all the models together like --gcBias --seqBias --posBias, it completes fine). . Also, my intuition for these transcripts is not really a coverage ""bias"" as much as the read depth absolutely plummeting at the 5' end of the long transcript. It would be neat if Salmon could detect these kinds of dramatic dropoffs and add a warning or something... even if not incorporating the information into the quants... it could even be a good QC step to identify large deletions/insertions over a gene body. As far as I know, there are NO rnaseq quant programs that would handle this, because even something like a STAR -> RSEM pipeline just projects read counts to the transcriptome and doesn't incorporate the coverage information. So, for now my workaround is to just modify the transcripts so they are non-overlapping in the transcriptome fasta or to manually count reads after looking at the alignments, but I'd love to hear any more thoughts you have on this problem. Thanks,; Jason",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-623043651:1814,detect,detect,1814,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-623043651,2,['detect'],['detect']
Safety,"ty prior below threshold. Incompatible fragments will be ignored.; [2020-04-22 12:53:21.437] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2020-04-22 12:53:21.437] [jointLog] [info] Usage of --validateMappings implies a default consensus slack of 0.2. Setting consensusSlack to 0.35.; [2020-04-22 12:53:21.437] [jointLog] [info] parsing read library format; [2020-04-22 12:53:21.437] [jointLog] [info] There is 1 library.; [2020-04-22 12:53:21.501] [jointLog] [info] Loading pufferfish index; [2020-04-22 12:53:21.503] [jointLog] [info] Loading dense pufferfish index.; [2020-04-22 12:54:13.540] [jointLog] [info] done; [2020-04-22 12:54:13.713] [jointLog] [info] Index contained 228,799 targets; [2020-04-22 12:54:29.422] [jointLog] [info] Number of decoys : 84; [2020-04-22 12:54:29.466] [jointLog] [info] First decoy index : 228,673 ; [2020-04-22 13:00:24.946] [jointLog] [info] Automatically detected most likely library type as ISR; [2020-04-23 00:06:31.287] [jointLog] [info] Thread saw mini-batch with a maximum of 1.06% zero probability fragments; [2020-04-23 00:06:41.198] [jointLog] [info] Thread saw mini-batch with a maximum of 1.08% zero probability fragments; [2020-04-23 00:06:50.741] [jointLog] [info] Thread saw mini-batch with a maximum of 1.02% zero probability fragments; [2020-04-23 00:06:56.260] [jointLog] [info] Thread saw mini-batch with a maximum of 1.08% zero probability fragments; [2020-04-23 00:06:56.781] [jointLog] [info] Thread saw mini-batch with a maximum of 1.04% zero probability fragments; [2020-04-23 00:07:03.636] [jointLog] [info] Thread saw mini-batch with a maximum of 1.04% zero probability fragments; [2020-04-23 00:07:03.759] [jointLog] [info] Thread saw mini-batch with a maximum of 1.04% zero probability fragments; [2020-04-23 00:07:47.416] [jointLog] [info] Thread saw mini-batch with a maximum of 1.24% zero probability fragments; [2020-04-23 00:10:07.526] [",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/516#issuecomment-621872756:1185,detect,detected,1185,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/516#issuecomment-621872756,1,['detect'],['detected']
Safety,uant \; > -i /nfs/research2/teichmann/reference/mus-musculus/salmon/quasi/mouse_cdna_38.p3.78_repbase_ercc.fa \; > -l IU \; > -1 /nfs/research2/teichmann/valentine/detection-comparison/salmon0.4.2-comparison/mouse/SRP057125_SRS936134_1.fastq \; > -2 /nfs/research2/teichmann/valentine/detection-comparison/salmon0.4.2-comparison/mouse/SRP057125_SRS936134_2.fastq \; > -o SRP057125_SRS936134_salmon_out \; > -g /nfs/research2/teichmann/reference/mus-musculus/salmon/mouse_cdna38.78_repbase_ercc_index_gene_map.txt \; > --biasCorrect \; > --useFSPD; Version Info: This is the most recent version of Salmon.; # salmon (mapping-based) v0.6.0; # [ program ] => salmon; # [ command ] => quant; # [ index ] => { /nfs/research2/teichmann/reference/mus-musculus/salmon/quasi/mouse_cdna_38.p3.78_repbase_ercc.fa }; # [ libType ] => { IU }; # [ mates1 ] => { /nfs/research2/teichmann/valentine/detection-comparison/salmon0.4.2-comparison/mouse/SRP057125_SRS936134_1.fastq }; # [ mates2 ] => { /nfs/research2/teichmann/valentine/detection-comparison/salmon0.4.2-comparison/mouse/SRP057125_SRS936134_2.fastq }; # [ output ] => { SRP057125_SRS936134_salmon_out }; # [ geneMap ] => { /nfs/research2/teichmann/reference/mus-musculus/salmon/mouse_cdna38.78_repbase_ercc_index_gene_map.txt }; # [ biasCorrect ] => { }; # [ useFSPD ] => { }; Logs will be written to SRP057125_SRS936134_salmon_out/logs; [2016-01-02 20:22:59.800] [jointLog] [info] parsing read library format; there is 1 lib; Loading 32-bit quasi index[2016-01-02 20:23:00.830] [stderrLog] [info] Loading Suffix Array; [2016-01-02 20:23:00.830] [stderrLog] [info] Loading Position Hash; [2016-01-02 20:23:00.829] [jointLog] [info] Loading Quasi index; [2016-01-02 20:23:03.751] [stderrLog] [info] Loading Transcript Info; [2016-01-02 20:23:04.776] [stderrLog] [info] Loading Rank-Select Bit Array; [2016-01-02 20:23:05.009] [stderrLog] [info] There were 104534 set bits in the bit array; [2016-01-02 20:23:05.325] [stderrLog] [info] Computing transcript ,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/34#issuecomment-168426741:7148,detect,detection-comparison,7148,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/34#issuecomment-168426741,1,['detect'],['detection-comparison']
Safety,"with only the -l A and --useVBOpt options, it processes all the reads but fails later on:. processed 67500000 fragmentsointLog] [info] Automatically detected most likely library type as IU; hits: 230221778, hits per frag: 3.41111. [2018-05-30 19:12:47.976] [jointLog] [info] Thread saw mini-batch with a maximum of 1.48% zero probability fragments; [2018-05-30 19:12:47.985] [jointLog] [info] Thread saw mini-batch with a maximum of 1.48% zero probability fragments; [2018-05-30 19:12:48.029] [jointLog] [info] Thread saw mini-batch with a maximum of 1.46% zero probability fragments; [2018-05-30 19:12:48.068] [jointLog] [info] Thread saw mini-batch with a maximum of 1.44% zero probability fragments; [2018-05-30 19:12:48.396] [jointLog] [info] Computed 425882 rich equivalence classes for further processing; [2018-05-30 19:12:48.396] [jointLog] [info] Counted 61485857 total reads in the equivalence classes; [2018-05-30 19:12:48.399] [jointLog] [info] Mapping rate = 90.4806%. [2018-05-30 19:12:48.399] [jointLog] [info] finished quantifyLibrary(); [2018-05-30 19:12:48.402] [jointLog] [info] Starting optimizer; [2018-05-30 19:12:48.586] [jointLog] [info] Marked 1 weighted equivalence classes as degenerate; [2018-05-30 19:12:48.608] [jointLog] [info] iteration = 0 | max rel diff. = 63.2619; Exception : [Error in function boost::math::digamma<double>(double): numeric overflow]; salmon quant was invoked improperly.; For usage information, try salmon quant --help; Exiting. Sorry but I won't be able to look into this more today...",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/228#issuecomment-393243827:149,detect,detected,149,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/228#issuecomment-393243827,1,['detect'],['detected']
Security," #1 SMP Debian 4.9.82-1+deb9u3~bpo8+1 (2018-03-22). ~/data/PCSI/PC10X/paper/pbmc$ g++ -v; Using built-in specs.; COLLECT_GCC=g++; COLLECT_LTO_WRAPPER=/u/user/local/libexec/gcc/x86_64-unknown-linux-gnu/5.4.0/lto-wrapper; Target: x86_64-unknown-linux-gnu; Configured with: ./configure --prefix=/u/user/local; Thread model: posix; gcc version 5.4.0 (GCC); ```. ```; [Thread debugging using libthread_db enabled]; Using host libthread_db library ""/lib/x86_64-linux-gnu/libthread_db.so.1"".; warning: File ""/u/user/local/lib64/libstdc++.so.6.0.21-gdb.py"" auto-loading has been declined by your `auto-load safe-path' set to ""$debugdir:$datadir/auto-load"".; To enable execution of this file add; add-auto-load-safe-path /u/user/local/lib64/libstdc++.so.6.0.21-gdb.py; line to your configuration file ""/u/user/.gdbinit"".; To completely disable this security protection add; set auto-load safe-path /; line to your configuration file ""/u/user/.gdbinit"".; For more information about this security protection see the; ""Auto-loading safe path"" section in the GDB manual. E.g., run from the shell:; info ""(gdb)Auto-loading safe path""; [New Thread 0x7fff7e0f4700 (LWP 14274)]; Version Info: ### A newer version of Salmon is available. ####; [Thread 0x7fff7e0f4700 (LWP 14274) exited]; ###; The newest version, available at https://github.com/COMBINE-lab/salmon/releases; contains new features, improvements, and bug fixes; please upgrade at your; earliest convenience.; ###; [New Thread 0x7fff7d273700 (LWP 14275)]; Logs will be written to pbmc4k/alevin/logs; [New Thread 0x7ffefc3f1700 (LWP 14276)]; [New Thread 0x7ffe7b56f700 (LWP 14277)]; [New Thread 0x7ffdfa6ed700 (LWP 14278)]; ### salmon (single-cell-based) v0.10.1; ### [ program ] => salmon; ### [ command ] => alevin; ### [ libType ] => { ISR }; ### [ chromium ] => { }; ### [ threads ] => { 8 }; ### [ output ] => { pbmc4k/alevin }; ### [ mates1 ] => { /dev/fd/63 }; ### [ mates2 ] => { /dev/fd/62 }; ### [ index ] => { /u/user/ref/cellranger/salmon/trans",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-395836214:2574,secur,security,2574,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-395836214,1,['secur'],['security']
Security," (perhaps after poly-A clipping); counted k-mers for 170000 transcripts[2018-08-02 16:23:32.554] [jointLog] [warning] Entry with header [ENST00000634174.1|ENSG00000282732.1|OTTHUMG00000191398.1|OTTHUMT00000487783.1|RP11-157B13.10-001|RP11-157B13.10|28|unprocessed_pseudogene|], had length less than the k-mer length of 31 (perhaps after poly-A clipping); counted k-mers for 200000 transcriptsElapsed time: 5.76935s. [2018-08-02 16:23:33.248] [jointLog] [warning] There were 808 transcripts that would need to be removed to avoid duplicates.; Replaced 4 non-ATCG nucleotides; Clipped poly-A tails from 1586 transcripts; Building rank-select dictionary and saving to disk done; Elapsed time: 0.0169059s; Writing sequence data to file . . . done; Elapsed time: 0.13359s; [info] Building 32-bit suffix array (length of generalized text is 309778559); Building suffix array . . . success; saving to disk . . . done; Elapsed time: 6.96499s; done; Elapsed time: 33.5821s; processed 309000000 positions; khash had 130317526 keys; saving hash to disk . . . done; Elapsed time: 34.8185s; [2018-08-02 16:26:58.153] [jLog] [info] done building index; ```; I reproduced the warnings from the initial run w/o the `--keepDuplicates` argument. ; ```; [Step 1 of 4] : counting k-mers; [2018-08-06 09:29:02.061] [jointLog] [warning] Entry with header [ENST00000473810.1|ENSG00000239255.1|OTTHUMG00000157482.1|OTTHUMT00000348942.1|RP11-145M9.2-001|RP11-145M9.2|25|processed_pseudogene|], had length less than the k-mer length of 31 (perhaps after poly-A clipping); [2018-08-06 09:29:02.143] [jointLog] [warning] Entry with header [ENST00000603775.1|ENSG00000271544.1|OTTHUMG00000184300.1|OTTHUMT00000468575.1|AC006499.9-001|AC006499.9|23|processed_pseudogene|], had length less than the k-mer length of 31 (perhaps after poly-A clipping); [2018-08-06 09:29:03.084] [jointLog] [warning] Entry with header [ENST00000632684.1|ENSG00000282431.1|OTTHUMG00000190602.2|OTTHUMT00000485301.2|RP11-520H11.10-001|TRBD1|12|TR_D_gene",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/214#issuecomment-410601245:10620,hash,hash,10620,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/214#issuecomment-410601245,1,['hash'],['hash']
Security," -i ~/data/genome/MSU7new_transcript.index -l IU \; -1 ~/results/trimmingSheng/${line}1.paired.fastq \; -2 ~/results/trimmingSheng/${line}2.paired.fastq --numBootstraps=30 \; -p 12 -o ~/results/salmon_quant_Sheng_IU/${line} --seqBias --gcBias --validateMappings. There are no estimate and reads generated when invokin the library type IU:; Name Length EffectiveLength TPM NumReads; LOC_Os01g01010.1 3017 3017.000 0.000000 0.000; LOC_Os01g01010.2 2218 2218.000 0.000000 0.000; LOC_Os01g01019.1 1127 1127.000 0.000000 0.000; LOC_Os01g01030.1 2464 2464.000 0.000000 0.000; LOC_Os01g01040.4 1524 1524.000 0.000000 0.000; LOC_Os01g01040.1 2508 2508.000 0.000000 0.000; LOC_Os01g01040.2 2482 2482.000 0.000000 0.000; LOC_Os01g01040.3 2583 2583.000 0.000000 0.000; LOC_Os01g01050.1 2039 2039.000 0.000000 0.000. [2019-03-04 01:24:12.788] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2019-03-04 01:24:12.788] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2019-03-04 01:24:12.788] [jointLog] [info] Usage of --validateMappings implies use of range factorization. rangeFactorizationBins is being set to 4; [2019-03-04 01:24:12.788] [jointLog] [info] Usage of --validateMappings implies a default consensus slack of 1. Setting consensusSlack to 1.; [2019-03-04 01:24:12.788] [jointLog] [info] parsing read library format; [2019-03-04 01:24:12.788] [jointLog] [info] There is 1 library.; [2019-03-04 01:24:12.852] [jointLog] [info] Loading Quasi index; [2019-03-04 01:24:12.852] [jointLog] [info] Loading 32-bit quasi index; [2019-03-04 01:24:19.703] [jointLog] [info] done; [2019-03-04 01:24:19.704] [jointLog] [info] Index contained 66,004 targets; [2019-03-04 01:25:14.064] [jointLog] [info] Thread saw mini-batch with a maximum of 91.10% zero probability fragments; [2019-03-04 01:25:14.075] [jointLog] [info] Thread saw mini-batch with a maximum of 90.58",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/346#issuecomment-469215256:3637,validat,validateMappings,3637,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/346#issuecomment-469215256,1,['validat'],['validateMappings']
Security," /proc/version; Linux version 4.9.0-0.bpo.6-amd64 (debian-kernel@lists.debian.org) (gcc version 4.9.2 (Debian 4.9.2-10+deb8u1) ) #1 SMP Debian 4.9.82-1+deb9u3~bpo8+1 (2018-03-22). ~/data/PCSI/PC10X/paper/pbmc$ g++ -v; Using built-in specs.; COLLECT_GCC=g++; COLLECT_LTO_WRAPPER=/u/user/local/libexec/gcc/x86_64-unknown-linux-gnu/5.4.0/lto-wrapper; Target: x86_64-unknown-linux-gnu; Configured with: ./configure --prefix=/u/user/local; Thread model: posix; gcc version 5.4.0 (GCC); ```. ```; [Thread debugging using libthread_db enabled]; Using host libthread_db library ""/lib/x86_64-linux-gnu/libthread_db.so.1"".; warning: File ""/u/user/local/lib64/libstdc++.so.6.0.21-gdb.py"" auto-loading has been declined by your `auto-load safe-path' set to ""$debugdir:$datadir/auto-load"".; To enable execution of this file add; add-auto-load-safe-path /u/user/local/lib64/libstdc++.so.6.0.21-gdb.py; line to your configuration file ""/u/user/.gdbinit"".; To completely disable this security protection add; set auto-load safe-path /; line to your configuration file ""/u/user/.gdbinit"".; For more information about this security protection see the; ""Auto-loading safe path"" section in the GDB manual. E.g., run from the shell:; info ""(gdb)Auto-loading safe path""; [New Thread 0x7fff7e0f4700 (LWP 14274)]; Version Info: ### A newer version of Salmon is available. ####; [Thread 0x7fff7e0f4700 (LWP 14274) exited]; ###; The newest version, available at https://github.com/COMBINE-lab/salmon/releases; contains new features, improvements, and bug fixes; please upgrade at your; earliest convenience.; ###; [New Thread 0x7fff7d273700 (LWP 14275)]; Logs will be written to pbmc4k/alevin/logs; [New Thread 0x7ffefc3f1700 (LWP 14276)]; [New Thread 0x7ffe7b56f700 (LWP 14277)]; [New Thread 0x7ffdfa6ed700 (LWP 14278)]; ### salmon (single-cell-based) v0.10.1; ### [ program ] => salmon; ### [ command ] => alevin; ### [ libType ] => { ISR }; ### [ chromium ] => { }; ### [ threads ] => { 8 }; ### [ output ] => { pbmc4k/alevi",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-395836214:2437,secur,security,2437,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-395836214,1,['secur'],['security']
Security," Done indexing Barcodes; [2019-01-29 09:56:53.255] [alevinLog] [info] Total Unique barcodes found: 125401; [2019-01-29 09:56:53.255] [alevinLog] [info] Used Barcodes except Whitelist: 1256; [2019-01-29 09:56:53.281] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify. [2019-01-29 09:56:53.281] [alevinLog] [info] parsing read library format; [2019-01-29 09:56:53.412] [stderrLog] [info] Loading Suffix Array ; [2019-01-29 09:56:53.281] [jointLog] [info] There is 1 library.; [2019-01-29 09:56:53.410] [jointLog] [info] Loading Quasi index; [2019-01-29 09:56:53.411] [jointLog] [info] Loading 32-bit quasi index; [2019-01-29 09:56:54.551] [stderrLog] [info] Loading Transcript Info ; [2019-01-29 09:56:54.826] [stderrLog] [info] Loading Rank-Select Bit Array; [2019-01-29 09:56:54.883] [stderrLog] [info] There were 80,511 set bits in the bit array; [2019-01-29 09:56:54.908] [stderrLog] [info] Computing transcript lengths; [2019-01-29 09:56:54.908] [stderrLog] [info] Waiting to finish loading hash; [2019-01-29 09:57:09.336] [stderrLog] [info] Done loading index; [2019-01-29 09:57:09.336] [jointLog] [info] done; [2019-01-29 09:57:09.336] [jointLog] [info] Index contained 80,511 targets. processed 2 Million fragments; hits: 812181, hits per frag: 0.326777. [2019-01-29 09:57:36.647] [alevinLog] [info] Starting optimizer; [2019-01-29 09:57:36.587] [jointLog] [info] Computed 12,933 rich equivalence classes for further processing; [2019-01-29 09:57:36.587] [jointLog] [info] Counted 242,520 total reads in the equivalence classes ; [2019-01-29 09:57:36.601] [jointLog] [warning] Only 242520 fragments were mapped, but the number of burn-in fragments was set to 5000000.; The effective lengths have been computed using the observed mappings. [2019-01-29 09:57:36.601] [jointLog] [info] Mapping rate = 8.94141%. [2019-01-29 09:57:36.601] [jointLog] [info] finished quantifyLibrary(). Analyzed 293 cells (100% of all).; [2019-01-29 09:57:40.090] [alevinLog] [info] Total 206902 UMI ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/337#issuecomment-458481722:8754,hash,hash,8754,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/337#issuecomment-458481722,1,['hash'],['hash']
Security," Low confidence barcodes too less 1 < 10.Can't performing whitelisting; Skipping; > [2020-06-04 17:57:37.348] [alevinLog] [info] Finished optimizer; > ; > . salmon_quant.log. > [2020-06-04 17:55:11.700] [jointLog] [info] setting maxHashResizeThreads to 7; > [2020-06-04 17:55:11.700] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; > [2020-06-04 17:55:11.700] [jointLog] [info] The --mimicBT2, --mimicStrictBT2 and --hardFilter flags imply mapping validation (--validateMappings). Enabling mapping validation.; > [2020-06-04 17:55:11.700] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; > [2020-06-04 17:55:11.700] [jointLog] [info] The use of range-factorized equivalence classes does not make sense in conjunction with --hardFilter. Disabling range-factorized equivalence classes. ; > [2020-06-04 17:55:11.700] [jointLog] [info] Usage of --validateMappings implies a default consensus slack of 0.2. Setting consensusSlack to 0.35.; > [2020-06-04 17:55:11.700] [jointLog] [info] Using default value of 0.797619 for minScoreFraction in Alevin; > Using default value of 0.6 for consensusSlack in Alevin; > [2020-06-04 17:56:30.294] [jointLog] [info] There is 1 library.; > [2020-06-04 17:56:30.355] [jointLog] [info] Loading pufferfish index; > [2020-06-04 17:56:30.355] [jointLog] [info] Loading dense pufferfish index.; > [2020-06-04 17:56:30.355] [jointLog] [info] done; > [2020-06-04 17:56:30.355] [jointLog] [info] Index contained 64 targets; > [2020-06-04 17:56:30.355] [jointLog] [info] Number of decoys : 0; > [2020-06-04 17:57:36.305] [jointLog] [info] Computed 64 rich equivalence classes for further processing; > [2020-06-04 17:57:36.305] [jointLog] [info] Counted 39,818 total reads in the equivalence classes ; > [2020-06-04 17:57:36.305] [jointLog] [info] Number of fragments discarded because they are best-mapped to decoys : 0; > [2020-0",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-639196415:3510,validat,validateMappings,3510,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-639196415,1,['validat'],['validateMappings']
Security," Skipped 955 barcodes due to No mapped read; [2022-03-27 05:49:49.766] [alevinLog] [info] Clearing EqMap; Might take some time.; [2022-03-27 05:49:50.011] [alevinLog] [info] Starting white listing of 3044 cells; [2022-03-27 05:49:50.011] [alevinLog] [info] Starting to make feature Matrix; [2022-03-27 05:49:50.014] [alevinLog] [info] Done making feature Matrix; [2022-03-27 05:49:50.717] [alevinLog] [info] Finished white listing; [2022-03-27 05:49:51.422] [alevinLog] [info] Finished optimizer; ````. and the `salmon_quant.log` looks like:; ```; [2022-03-27 05:24:09.395] [jointLog] [info] setting maxHashResizeThreads to 32; [2022-03-27 05:24:09.395] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2022-03-27 05:24:09.395] [jointLog] [info] The --mimicBT2, --mimicStrictBT2 and --hardFilter flags imply mapping validation (--validateMappings). Enabling mapping validation.; [2022-03-27 05:24:09.395] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2022-03-27 05:24:09.395] [jointLog] [info] The use of range-factorized equivalence classes does not make sense in conjunction with --hardFilter. Disabling range-factorized equivalence classes. ; [2022-03-27 05:24:09.395] [jointLog] [info] Setting consensusSlack to selective-alignment default of 0.35.; [2022-03-27 05:24:09.395] [jointLog] [info] Using default value of 0.87 for minScoreFraction in Alevin; Using default value of 0.6 for consensusSlack in Alevin; [2022-03-27 05:34:26.966] [jointLog] [info] There is 1 library.; [2022-03-27 05:34:26.967] [jointLog] [info] Loading pufferfish index; [2022-03-27 05:34:26.967] [jointLog] [info] Loading dense pufferfish index.; [2022-03-27 05:34:27.433] [jointLog] [info] done; [2022-03-27 05:34:27.504] [jointLog] [info] Index contained 116,755 targets; [2022-03-27 05:34:27.540] [jointLog] [info] Number of decoys : 0; [2022-03-27 05:46:41.460] [join",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/763#issuecomment-1082597942:4604,validat,validateMappings,4604,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/763#issuecomment-1082597942,1,['validat'],['validateMappings']
Security," [alevinLog] [info] Total 23937.00 UMI after deduplicating.; > [2020-06-04 17:57:37.338] [alevinLog] [info] Total 91 BiDirected Edges.; > [2020-06-04 17:57:37.338] [alevinLog] [info] Total 82 UniDirected Edges.; > [2020-06-04 17:57:37.338] [alevinLog] [warning] Skipped 82268 barcodes due to No mapped read; > [2020-06-04 17:57:37.341] [alevinLog] [info] Clearing EqMap; Might take some time.; > [2020-06-04 17:57:37.348] [alevinLog] [warning] Num Low confidence barcodes too less 1 < 10.Can't performing whitelisting; Skipping; > [2020-06-04 17:57:37.348] [alevinLog] [info] Finished optimizer; > ; > . salmon_quant.log. > [2020-06-04 17:55:11.700] [jointLog] [info] setting maxHashResizeThreads to 7; > [2020-06-04 17:55:11.700] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; > [2020-06-04 17:55:11.700] [jointLog] [info] The --mimicBT2, --mimicStrictBT2 and --hardFilter flags imply mapping validation (--validateMappings). Enabling mapping validation.; > [2020-06-04 17:55:11.700] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; > [2020-06-04 17:55:11.700] [jointLog] [info] The use of range-factorized equivalence classes does not make sense in conjunction with --hardFilter. Disabling range-factorized equivalence classes. ; > [2020-06-04 17:55:11.700] [jointLog] [info] Usage of --validateMappings implies a default consensus slack of 0.2. Setting consensusSlack to 0.35.; > [2020-06-04 17:55:11.700] [jointLog] [info] Using default value of 0.797619 for minScoreFraction in Alevin; > Using default value of 0.6 for consensusSlack in Alevin; > [2020-06-04 17:56:30.294] [jointLog] [info] There is 1 library.; > [2020-06-04 17:56:30.355] [jointLog] [info] Loading pufferfish index; > [2020-06-04 17:56:30.355] [jointLog] [info] Loading dense pufferfish index.; > [2020-06-04 17:56:30.355] [jointLog] [info] done; > [2020-06-04 17:56:30.355] [joint",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-639196415:3078,validat,validation,3078,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-639196415,1,['validat'],['validation']
Security, ] => { Salmon_index_hg38.analysisSet_knownGene }; ### [ unmatedReads ] => { SRR2454059.fq.gz }; ### [ libType ] => { ISF }; ### [ useVBOpt ] => { }; ### [ output ] => { test_quant }; ### [ numGibbsSamples ] => { 100 }; ### [ threads ] => { 16 }; Logs will be written to test_quant/logs; [2016-12-13 22:38:54.413] [jointLog] [info] parsing read library format; [2016-12-13 22:38:54.413] [jointLog] [info] There is 1 library.; [2016-12-13 22:38:56.240] [stderrLog] [info] Loading Suffix Array; [2016-12-13 22:38:56.240] [jointLog] [info] Loading Quasi index; [2016-12-13 22:38:56.240] [jointLog] [info] Loading 32-bit quasi index; [2016-12-13 22:39:01.268] [stderrLog] [info] Loading Transcript Info; [2016-12-13 22:39:02.630] [stderrLog] [info] Loading Rank-Select Bit Array; [2016-12-13 22:39:03.041] [stderrLog] [info] There were 182608 set bits in the bit array; [2016-12-13 22:39:03.159] [stderrLog] [info] Computing transcript lengths; [2016-12-13 22:39:03.160] [stderrLog] [info] Waiting to finish loading hash; [2016-12-13 22:39:07.653] [stderrLog] [info] Done loading index; [2016-12-13 22:39:07.653] [jointLog] [info] done; [2016-12-13 22:39:07.653] [jointLog] [info] Index contained 182608 targets. processed 19000000 fragments; hits: 65897209; hits per frag: 3.47349. [2016-12-13 22:40:22.572] [jointLog] [info] Computed 137534 rich equivalence classes for further processing; [2016-12-13 22:40:22.572] [jointLog] [info] Counted 16265961 total reads in the equivalence classes; [2016-12-13 22:40:22.618] [jointLog] [info] Mapping rate = 83.509%. [2016-12-13 22:40:22.618] [jointLog] [info] finished quantifyLibrary(); [2016-12-13 22:40:22.619] [jointLog] [info] Starting optimizer; [2016-12-13 22:40:22.904] [jointLog] [info] Marked 0 weighted equivalence classes as degenerate; [2016-12-13 22:40:22.911] [jointLog] [info] iteration = 0 | max rel diff. = 299.976; [2016-12-13 22:40:23.620] [jointLog] [info] iteration = 100 | max rel diff. = 0.121769; [2016-12-13 22:40:24.367] [jointLog] [,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-266934878:1916,hash,hash,1916,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-266934878,2,['hash'],['hash']
Security, ] => { Salmon_index_hg38.analysisSet_knownGene }; ### [ unmatedReads ] => { SRR2454059.fq.gz }; ### [ libType ] => { ISF }; ### [ useVBOpt ] => { }; ### [ output ] => { test_quant }; ### [ numGibbsSamples ] => { 100 }; ### [ threads ] => { 16 }; Logs will be written to test_quant/logs; [2016-12-13 22:44:07.409] [jointLog] [info] parsing read library format; [2016-12-13 22:44:07.409] [jointLog] [info] There is 1 library.; [2016-12-13 22:44:09.318] [jointLog] [info] Loading Quasi index; [2016-12-13 22:44:09.318] [jointLog] [info] Loading 32-bit quasi index; [2016-12-13 22:44:09.318] [stderrLog] [info] Loading Suffix Array; [2016-12-13 22:44:15.002] [stderrLog] [info] Loading Transcript Info; [2016-12-13 22:44:16.278] [stderrLog] [info] Loading Rank-Select Bit Array; [2016-12-13 22:44:16.625] [stderrLog] [info] There were 182608 set bits in the bit array; [2016-12-13 22:44:16.680] [stderrLog] [info] Computing transcript lengths; [2016-12-13 22:44:16.681] [stderrLog] [info] Waiting to finish loading hash; [2016-12-13 22:44:20.485] [stderrLog] [info] Done loading index; [2016-12-13 22:44:20.485] [jointLog] [info] done; [2016-12-13 22:44:20.485] [jointLog] [info] Index contained 182608 targets. processed 19000001 fragments; hits: 65897764; hits per frag: 3.48152. [2016-12-13 22:45:33.192] [jointLog] [info] Computed 137534 rich equivalence classes for further processing; [2016-12-13 22:45:33.192] [jointLog] [info] Counted 16265961 total reads in the equivalence classes; [2016-12-13 22:45:33.233] [jointLog] [info] Mapping rate = 83.509%. [2016-12-13 22:45:33.233] [jointLog] [info] finished quantifyLibrary(); [2016-12-13 22:45:33.234] [jointLog] [info] Starting optimizer; [2016-12-13 22:45:33.516] [jointLog] [info] Marked 0 weighted equivalence classes as degenerate; [2016-12-13 22:45:33.523] [jointLog] [info] iteration = 0 | max rel diff. = 299.95; [2016-12-13 22:45:34.217] [jointLog] [info] iteration = 100 | max rel diff. = 0.122252; [2016-12-13 22:45:34.912] [jointLog] [i,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-266935584:1789,hash,hash,1789,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-266935584,1,['hash'],['hash']
Security, ] => { }; ### [ geneMap ] => { /home/ryan/references/hg38/Salmon_index_hg38.analysisSet_knownGene/genemap.txt }; ### [ output ] => { salmon_temp/REF/SRR2454069 }; ### [ auxDir ] => { aux_info }; ### [ numGibbsSamples ] => { 10 }; Logs will be written to salmon_temp/REF/SRR2454069/logs; [2016-12-15 15:58:50.157] [jointLog] [info] parsing read library format; [2016-12-15 15:58:50.157] [jointLog] [info] There is 1 library.; [2016-12-15 15:58:50.189] [jointLog] [info] Loading Quasi index; [2016-12-15 15:58:50.189] [jointLog] [info] Loading 32-bit quasi index; [2016-12-15 15:58:50.189] [stderrLog] [info] Loading Suffix Array; [2016-12-15 15:58:50.513] [stderrLog] [info] Loading Transcript Info; [2016-12-15 15:58:50.599] [stderrLog] [info] Loading Rank-Select Bit Array; [2016-12-15 15:58:50.661] [stderrLog] [info] There were 182608 set bits in the bit array; [2016-12-15 15:58:50.677] [stderrLog] [info] Computing transcript lengths; [2016-12-15 15:58:50.677] [stderrLog] [info] Waiting to finish loading hash; [2016-12-15 15:58:50.677] [stderrLog] [info] Done loading index; [2016-12-15 15:58:50.677] [jointLog] [info] done; [2016-12-15 15:58:50.677] [jointLog] [info] Index contained 182608 targets; [2016-12-15 15:58:51.587] [jointLog] [warning] Fragment GC bias correction is currently *experimental* in single-end libraries. Please use this option with caution. processed 16500000 fragments; hits: 44017772; hits per frag: 2.67057. [2016-12-15 16:01:44.937] [jointLog] [info] Computed 119318 rich equivalence classes for further processing; [2016-12-15 16:01:44.937] [jointLog] [info] Counted 12227080 total reads in the equivalence classes; [2016-12-15 16:01:44.948] [jointLog] [info] Mapping rate = 72.5194%. [2016-12-15 16:01:44.948] [jointLog] [info] finished quantifyLibrary(); [2016-12-15 16:01:44.949] [jointLog] [info] Starting optimizer; [2016-12-15 16:01:45.059] [jointLog] [info] Marked 0 weighted equivalence classes as degenerate; [2016-12-15 16:01:45.075] [jointLog] [info] i,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267489196:1562,hash,hash,1562,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267489196,1,['hash'],['hash']
Security," run on 1.3.1, would you recommend I redo the whole dataset alignment on 1.3.1? If it runs even close to what you saw it shouldn’t take too long; to rerun. . Thanks again,. Ryan. Sent from my iPhone. On Jun 16, 2020, at 12:13 AM, Rob Patro <notifications@github.com> wrote:. ﻿. I processed the data above using the latest salmon from the develop branch; (the release candidate for 1.3.0), and I got the following time (used 8; threads, so timing is not directly comparable). ```; 4604.57user 43.64system 9:24.15elapsed 823%CPU; ```. The whole log is. ```; [2020-06-15 23:51:54.747] [jointLog] [info] setting maxHashResizeThreads to; 8; [2020-06-15 23:51:54.747] [jointLog] [info] Fragment incompatibility prior; below threshold. Incompatible fragments will be ignored.; [2020-06-15 23:51:54.747] [jointLog] [info] Usage of --validateMappings; implies use of minScoreFraction. Since not explicitly specified, it is; being set to 0.65; [2020-06-15 23:51:54.747] [jointLog] [info] Usage of --validateMappings; implies a default consensus slack of 0.2. Setting consensusSlack to 0.35.; [2020-06-15 23:51:54.747] [jointLog] [info] parsing read library format; [2020-06-15 23:51:54.747] [jointLog] [info] There is 1 library.; [2020-06-15 23:51:54.814] [jointLog] [info] Loading pufferfish index; [2020-06-15 23:51:54.814] [jointLog] [info] Loading dense pufferfish index.; [2020-06-15 23:51:55.555] [jointLog] [info] done; [2020-06-15 23:51:55.555] [jointLog] [info] Index contained 116,248 targets; [2020-06-15 23:51:55.588] [jointLog] [info] Number of decoys : 0; [2020-06-16 00:00:59.666] [jointLog] [info] Computed 344,764 rich; equivalence classes for further processing; [2020-06-16 00:00:59.666] [jointLog] [info] Counted 12,956,134 total reads; in the equivalence classes; [2020-06-16 00:00:59.673] [jointLog] [warning] 0.0736383% of fragments were; shorter than the k used to build the index.; If this fraction is too large, consider re-building the index with a; smaller k.; The minimum read size ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/537#issuecomment-644527727:1467,validat,validateMappings,1467,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/537#issuecomment-644527727,1,['validat'],['validateMappings']
Security," to generally be similar to that of quasi-mapping, but there are some important exceptions. You can find some aggregate statistics in supplementary figure 1 of the [pre-print that introduces selective alignment](https://www.biorxiv.org/content/10.1101/657874v2.full.pdf); ; ![image](https://user-images.githubusercontent.com/361470/73905651-08d4fd00-486e-11ea-91f4-9f167f54f676.png). Here, ""orcale"" is a method that aligns the reads both to the transcriptome with Bowtie2 and the genome with STAR, and removes reads from the Bowtie2 `bam` that seem to be spuriously aligned to the transcriptome (they align to the genome outside of an annotated transcriptome with a better score than that assigned by Bowtie2 within the transcriptome). Here, you can see that in most cases most methods map a similar number of reads, but there are definitely samples where methods map more reads than the oracle, and sometimes quasi-mapping maps quite a few more. This is, to a large extent, because it doesn't validate those mappings and some of them may be spurious (i.e. the exact matches used to find the mapping in the given location would not support a high quality alignment at that location). (2) This is certainly possible that some samples get very little to no mapping. _However_, there are a few points worth noting about how the data are processed that is worth being aware of before you write such samples off. * There is a change in default behavior between salmon < 0.13 and >= 0.13 with which mappings are considered as ""concordant"" and therefore used for quantification by default. Specifically, starting with 0.14, ""dovetail"" alignments [(as described in the Bowtie2 manual)](http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-dovetail) are considered discordant. This is the same default behavior imposed by Bowtie2. If you look in the `meta_info.json` file for some of these samples (which is in the `aux_info` subdirectory of the quantification directory for a sample), you c",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/482#issuecomment-582734798:1147,validat,validate,1147,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/482#issuecomment-582734798,2,['validat'],['validate']
Security," to retain duplicate transcripts, please use the `--keepDuplicates` flag ; [2022-04-16 11:16:00.541] [puff::index::jointLog] [info] Replaced 4 non-ATCG nucleotides ; [2022-04-16 11:16:00.541] [puff::index::jointLog] [info] Clipped poly-A tails from 1,961 transcripts wrote 245236 cleaned references ; [2022-04-16 11:16:02.811] [puff::index::jointLog] [info] Filter size not provided; estimating from number of distinct k-mers [2022-04-16 11:16:07.979] [puff::index::jointLog] [info] ntHll estimated 143558277 distinct k-mers, setting filter size to 2^32 Threads = 12 ; Vertex length = 23 ; Hash functions = 5 ; Filter size = 4294967296 ; Capacity = 1 ; Files: ; salmon_index_23/ref_k23_fixed.fa -------------------------------------------------------------------------------- ; Round 0, 0:4294967296 ; Pass Filling Filtering ; 1 13 148 ; 2 9 0 ; True junctions count = 1307919 ; False junctions count = 233850 ; Hash table size = 1541769 ; Candidate marks count = 14841235 -------------------------------------------------------------------------------- ; Reallocating bifurcations time: 0 ; True marks count: 14610695 ; Edges construction time: 9 -------------------------------------------------------------------------------- ; Distinct junctions = 1307919 allowedIn: 18 ; Max Junction ID: 1458039 ; seen.size():11664321 kmerInfo.size():1458040 approximateContigTotalLength: 96596288 ; counters for complex kmers: ; (prec>1 & succ>1)=163493 | (succ>1 & isStart)=1600 | (prec>1 & isEnd)=1705 | (isStart & isEnd)=136 contig count: 2046804 element count: 189087548 complex nodes: 166934 ; number of ones in rank vector: 2046803 ; [2022-04-16 11:19:37.060] [puff::index::jointLog] [info] Starting the Pufferfish indexing by reading the GFA binary file. [2022-04-16 11:19:37.060] [puff::index::jointLog] [info] Setting the index/BinaryGfa directory salmon_index_23 ; size = 189087548 ; ----------------------------------------- ; | Loading contigs | Time = 43.37 ms ------------------------------------",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/768#issuecomment-1100734317:10651,Hash,Hash,10651,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/768#issuecomment-1100734317,1,['Hash'],['Hash']
Security," v0.8 and 1.2.1. The one that seems most relevant here is the introduction of selective-alignment to replace the quasi-mapping procedure that was originally used in salmon. Selective-alignment actually scores the mappings found to the transcriptome, and rejects alignments whose quality is below a (user-specified) threshold. Here, you can see that, in 1.2.1. * 39 fragments are mapped within the score threshold; * 216 fragments are discarded because no mapping location has an alignment score above the threshold. all together, this means that the total number of ""mapped"" fragments in 1.2.1 is very similar to 0.8 (1.2.1 maps 39+216 = 255, while 0.8 maps 254). However, 1.2.1 discards 216 of the fragments because no mapping is sufficiently good. The default for ""sufficiently good"", by the way, is to have an alignment score of at least 65% of the maximum possible for a read of the given length. For typical RNA-seq data, this is actually quite liberal / generous, and is similar to the type of noise in alignment that Bowtie2 allows with the sensitive flag. In general, the heuristics used in 1.2.1 (selective-alignment) tend to be more sensitive than those used in 0.8 (quasi-mapping), since the mappings are then validated using alignment scoring. However, this does mean that the quality of the alignment along the whole read matters. Thus, it is more important to do quality / adapter trimming in the newer version compared to the older one. There is also a flag in 1.2.1 (`--softclip`) that will allow mismatches / gaps at the ends of reads to not detract from the alignment score. So, these are the main differences. However, looking at the output logs you provided, a couple of basic questions did come to mind. Why are there so few reads to begin with? Even in 0.8, only 254 reads mapped, which is obviously a very small number of reads. Is there something non-typical about this sample? Is it a full RNA-seq sample? Are these reads something atypical (like long reads — ONT or PacBio)?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/542#issuecomment-651332239:1331,validat,validated,1331,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/542#issuecomment-651332239,1,['validat'],['validated']
Security," you probably want to disable the length bias modeling or at least consider how it would interact with coverage modeling. With that said, I'm sharing an example that illustrates each of the above points and a link to a toy dataset that you can use to recreate the examples or explore this further. If you'd like to dig deeper into this, free free to e-mail me at jason@calicolabs.com, I have tons more notes and data that I'm willing to share. Dataset is in google drive (you'll have to click the link and request access to view it) https://drive.google.com/drive/folders/1LcJNa4PHNoYqGsnkRx0YxvNXnNJCVyq9?usp=sharing. 1. **Success scenarios with default options:** . In the below IGV snapshots, I show the read alignments for one sample. The top GTF annotation is the default gene annotation, and the GTF at the bottom shows the new transcript isoforms I made and quantified on (this index is called ""extras""). For each example I ran salmon on the transcripts from the default or extra index, with standard options (only --validateMappings), with or without the --noLengthCorrection flag. **I'm showing only the number of reads** assigned to each transcript, not the TPM. I also tried this on more samples and transcript scenarios and saw the same trends. **Nested transcript isoforms:** ; ![AGP1_example](https://user-images.githubusercontent.com/10292386/86509506-45654000-bd9d-11ea-839f-6637620c3247.png). <img width=""430"" alt=""AGP1_table"" src=""https://user-images.githubusercontent.com/10292386/86509511-48f8c700-bd9d-11ea-8203-c37eeaf4820d.png"">. Looking first at the ""extras"" index + default options, almost all the reads are assigned to AGP1_long1, which indeed seems to be the best fit for the actual gene body + UTRs (the default AGP1 transcript is only protein coding ORF, no UTRs). Even though all of the reads from AGP1_long1 would also multimap to AGP1_long2, etc., AGP1_long1 is assigned all the reads because it has the highest reads per kb. Presumably the few reads assigned to AGP1_",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-653747847:2462,validat,validateMappings,2462,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-653747847,2,['validat'],['validateMappings']
Security,"--unmatedReads ] arg List of files containing unmated reads ; of (e.g. single-end reads); -1 [ --mates1 ] arg File containing the #1 mates; -2 [ --mates2 ] arg File containing the #2 mates. alevin-specific Options:; --noDedup Stops the pipeline after CB sequence ; correction and quasi-mapping reads.; --dropseq Use DropSeq Single Cell protocol for ; the library; --chromium Use 10x chromium v2 Single Cell ; protocol for the library.; --gemcode Use 10x gemcode v1 Single Cell protocol; for the library.; --whitelist arg File containing white-list barcodes; --noQuant Don't run downstream barcode-salmon ; model.; --naive Run Gene level naive deduplication; --noSoftMap Don't use soft-assignment for quant ; instead do hard-assignment.; --mrna arg path to a file containing mito-RNA ; gene, one per line; --rrna arg path to a file containing ribosomal ; RNA, one per line; --useCorrelation Use pair-wise pearson correlation with ; True barcodes as a feature for ; white-list creation.; --dumpfq Dump barcode modified fastq file for ; downstream analysis by using coin toss ; for multi-mapping.; --debug Enabling this mode mode will try to ; ignore segfaults based on no whitelist ; mapping or no whitelist deduplicated ; count; --dumpBfh dump the big hash with all the barcodes; and the UMI sequence.; --dumpFeatures Dump features for whitelist and ; downstream analysis.; --dumpCsvCounts Dump cell v transcripts count matrix in; csv format.; --lowRegionMinNumBarcodes arg (=200) Minimum Number of CB to use for ; learning Low confidence region ; (Default: 200).; --maxNumBarcodes arg (=100000) Maximum allowable limit to process the ; cell barcodes. (Default: 100000); --tgMap arg transcript to gene map tsv file; ```; 2) `salmon alevin -lISR -1 cells_CTTGTA_L001_R1_001.fastq.gz -2 cells_CTTGTA_L001_R2_001.fastq.gz --celseq2 -i AlevinIndex_develop/ -p 8 -o alevin_output --tgMap gencode.primary_assembly.tsv`. **The tsv I created myself (with tximport), but I don't think that is the issue here...",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/325#issuecomment-443517536:1602,hash,hash,1602,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/325#issuecomment-443517536,2,['hash'],['hash']
Security,"-000.fastq.gz ./fastq/fastqs/flowcell1/read-I1_si-CGAAGTTG_lane-003-chunk-003.fastq.gz ./fastq/fastqs/flowcell1/read-I1_si-CGAAGTTG_lane-004-chunk-002.fastq.gz ./fastq/fastqs/flowcell1/read-I1_si-GAGCACGC_lane-001-chunk-001.fastq.gz ./fastq/fastqs/flowcell1/read-I1_si-GAGCACGC_lane-002-chunk-000.fastq.gz ./fastq/fastqs/flowcell1/read-I1_si-GAGCACGC_lane-003-chunk-003.fastq.gz ./fastq/fastqs/flowcell1/read-I1_si-GAGCACGC_lane-004-chunk-002.fastq.gz ./fastq/fastqs/flowcell1/read-I1_si-TTCGTGAA_lane-001-chunk-001.fastq.gz ./fastq/fastqs/flowcell1/read-I1_si-TTCGTGAA_lane-002-chunk-000.fastq.gz ./fastq/fastqs/flowcell1/read-I1_si-TTCGTGAA_lane-003-chunk-003.fastq.gz ./fastq/fastqs/flowcell1/read-I1_si-TTCGTGAA_lane-004-chunk-002.fastq.gz }. [2018-12-06 11:14:56.533] [jointLog] [warning] You seem to have passed in both un-paired reads and paired-end reads. It is not currently possible to quantify hybrid library types in salmon.; [2018-12-06 11:14:56.533] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2018-12-06 11:14:56.533] [jointLog] [info] Usage of --validateMappings implies use of range factorization. rangeFactorizationBins is being set to 4; [2018-12-06 11:14:56.534] [jointLog] [info] Usage of --validateMappings implies a default consensus slack of 1. Setting consensusSlack to 1.; [2018-12-06 11:14:56.534] [jointLog] [info] Using default value of 0.8 for minScoreFraction in Alevin; [2018-12-06 11:14:56.540] [alevinLog] [info] Processing barcodes files (if Present) . ; processed 267 Million barcodes. [2018-12-06 11:16:47.491] [alevinLog] [info] Done barcode density calculation.; [2018-12-06 11:16:47.491] [alevinLog] [info] # Barcodes Used: 267451749 / 267548197.; [2018-12-06 11:16:52.732] [alevinLog] [info] Knee found left boundary at 11955 ; [2018-12-06 11:16:54.977] [alevinLog] [info] Gauss Corrected Boundary at 4345 ; [2018-12-06 11:16:54.977] [alevinLog] [info] Learned InvCov",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/328#issuecomment-445008548:4302,validat,validateMappings,4302,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/328#issuecomment-445008548,1,['validat'],['validateMappings']
Security,"-A clipping); [2018-07-13 21:27:54.013] [jointLog] [warning] Entry with header [ENST00000603693.1|ENSG00000270451.1|OTTHUMG00000184611.3|OTTHUMT00000468945.3|RP11-810K23.14-001|IGHD4OR15-4B|19|IG_D_gene|], had length less than the k-mer length of 31 (perhaps after poly-A clipping); [2018-07-13 21:27:54.013] [jointLog] [warning] Entry with header [ENST00000604838.1|ENSG00000270185.1|OTTHUMG00000184585.2|OTTHUMT00000468915.2|RP11-1360M22.4-001|IGHD1OR15-1B|17|IG_D_gene|], had length less than the k-mer length of 31 (perhaps after poly-A clipping); [2018-07-13 21:27:55.348] [jointLog] [warning] Entry with header [ENST00000579054.1|ENSG00000266416.1|OTTHUMG00000179204.1|OTTHUMT00000445280.1|RP1-66C13.2-001|RP1-66C13.2|28|processed_pseudogene|], had length less than the k-mer length of 31 (perhaps after poly-A clipping); [2018-07-13 21:27:56.453] [jointLog] [warning] Entry with header [ENST00000634174.1|ENSG00000282732.1|OTTHUMG00000191398.1|OTTHUMT00000487783.1|RP11-157B13.10-001|RP11-157B13.10|28|unprocessed_pseudogene|], had length less than the k-mer length of 31 (perhaps after poly-A clipping); Elapsed time: 20.6564s. [2018-07-13 21:27:58.139] [jointLog] [warning] Removed 808 transcripts that were sequence duplicates of indexed transcripts.; [2018-07-13 21:27:58.139] [jointLog] [warning] If you wish to retain duplicate transcripts, please use the `--keepDuplicates` flag; Replaced 4 non-ATCG nucleotides; Clipped poly-A tails from 1586 transcripts; Building rank-select dictionary and saving to disk done; Elapsed time: 0.0133569s; Writing sequence data to file . . . done; Elapsed time: 0.182628s; [info] Building 32-bit suffix array (length of generalized text is 308972089); Building suffix array . . . success; saving to disk . . . done; Elapsed time: 0.513756s; done; Elapsed time: 58.2945s; processed 308000000 positions; khash had 130317526 keys; saving hash to disk . . . done; Elapsed time: 9.6539s; [2018-07-13 21:32:25.842] [jLog] [info] done building index; (salmon)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/251#issuecomment-404960748:10744,hash,hash,10744,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/251#issuecomment-404960748,1,['hash'],['hash']
Security,".fastq.gz }; ### [ mates2 ] => { 12_CTTGTA_L001_R2_001.fastq.gz 12_CTTGTA_L001_R2_002.fastq.gz 12_CTTGTA_L001_R2_003.fastq.gz 12_CTTGTA_L001_R2_004.fastq.gz 12_CTTGTA_L001_R2_005.fastq.gz 12_CTTGTA_L001_R2_006.fastq.gz 12_CTTGTA_L001_R2_007.fastq.gz 12_CTTGTA_L001_R2_008.fastq.gz 12_CTTGTA_L001_R2_009.fastq.gz 12_CTTGTA_L001_R2_010.fastq.gz 12_CTTGTA_L002_R2_001.fastq.gz 12_CTTGTA_L002_R2_002.fastq.gz 12_CTTGTA_L002_R2_003.fastq.gz 12_CTTGTA_L002_R2_004.fastq.gz 12_CTTGTA_L002_R2_005.fastq.gz 12_CTTGTA_L002_R2_006.fastq.gz 12_CTTGTA_L002_R2_007.fastq.gz 12_CTTGTA_L002_R2_008.fastq.gz 12_CTTGTA_L002_R2_009.fastq.gz 12_CTTGTA_L002_R2_010.fastq.gz }; ### [ threads ] => { 8 }; ### [ celseq2 ] => { }; ### [ dumpCsvCounts ] => { }; ### [ output ] => { /path/to/alevin_outputSingleLibrary/quantSC }; ### [ tgMap ] => { /path/to/gencode_annot/gencode.primary_assembly.v29.tsv }; ### [ whitelist ] => { /path/to/salmon/my_barcode.tsv }. [2018-12-12 15:07:42.022] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2018-12-12 15:07:42.022] [jointLog] [info] Usage of --validateMappings implies use of range factorization. rangeFactorizationBins is being set to 4; [2018-12-12 15:07:42.022] [jointLog] [info] Usage of --validateMappings implies a default consensus slack of 1. Setting consensusSlack to 1.; [2018-12-12 15:07:42.022] [jointLog] [info] Using default value of 0.8 for minScoreFraction in Alevin; [2018-12-12 15:07:42.028] [alevinLog] [info] Processing barcodes files (if Present) . ; processed 74 Million barcodes. [2018-12-12 15:08:51.135] [alevinLog] [info] Done barcode density calculation.; [2018-12-12 15:08:51.135] [alevinLog] [info] # Barcodes Used: 74376522 / 74376522.; [2018-12-12 15:08:51.141] [alevinLog] [info] Done importing white-list Barcodes; [2018-12-12 15:08:51.141] [alevinLog] [warning] Skipping 1 Barcodes with 0 reads; Assuming this is the required behavior.; [2018-12-12 15:08:5",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/329#issuecomment-446668422:2606,validat,validateMappings,2606,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/329#issuecomment-446668422,1,['validat'],['validateMappings']
Security,"002_R2.fastq.gz; P1_H.m_15-23_221020_L002_R2.fastq.gz P1_H.m_24-32_221020_L002_R2.fastq.gz P2-44-51_221020_L002_R2.fastq.gz P3_36-44_221020_L002_R2.fastq.gz P3_41-49_221020_L002_R2.fastq.gz; P1_H.m_16-24_221020_L002_R2.fastq.gz P1_H.m_26-34_221020_L002_R2.fastq.gz P2-45-54_221020_L002_R2.fastq.gz P3_37-46_221020_L002_R2.fastq.gz P3_42-50_221020_L002_R2.fastq.gz; P1_H.m_18-26_221020_L002_R2.fastq.gz P2-10-17_221020_L002_R2.fastq.gz P2-46-53_221020_L002_R2.fastq.gz P3_38-45_221020_L002_R2.fastq.gz P3_43-52_221020_L002_R2.fastq.gz; P1_H.m_19-27_221020_L002_R2.fastq.gz P2-11-18_221020_L002_R2.fastq.gz P2-5-11_221020_L002_R2.fastq.gz P3_39-47_221020_L002_R2.fastq.gz. ). # Loop through the read files and run Salmon quant; for i in ""${!left_files[@]}""; do; left_file=""${left_files[i]}""; right_file=""${right_files[i]}"". # Extract the sample name; sample=$(basename ""$left_file"" ""_L002_R1.fastq.gz""). # Run Salmon quant with the current read files; salmon quant -i ""$salmon_index"" -l IU -1 ""$fastq_dir/$left_file"" -2 ""$fastq_dir/$right_file"" --validateMappings -o ""salmon_out/${sample}_quant""; done. and the results of the first 2 look like this. Name Length EffectiveLength TPM NumReads; TRINITY_DN1448606_c0_g1_i1 472 275.399 0.000000 0.000; TRINITY_DN1448584_c0_g1_i1 394 201.561 0.000000 0.000; TRINITY_DN1448585_c0_g1_i2 237 72.382 0.000000 0.000; TRINITY_DN1448598_c0_g1_i1 227 65.738 0.000000 0.000; TRINITY_DN1448598_c1_g1_i1 254 84.301 0.000000 0.000; TRINITY_DN1448554_c0_g1_i1 349 160.724 0.000000 0.000; TRINITY_DN1448554_c1_g1_i1 247 79.278 0.000000 0.000; TRINITY_DN1448554_c2_g1_i1 242 75.824 0.000000 0.000; TRINITY_DN1448616_c0_g1_i1 313 129.689 0.000000 0.000; [qkdf72@login2.ham8 P1_H.m_1_221020_quant]$ cd ..; [qkdf72@login2.ham8 salmon_out]$ cd P1_H.m_21-29_221020_quant/; [qkdf72@login2.ham8 P1_H.m_21-29_221020_quant]$ head quant.sf; Name Length EffectiveLength TPM NumReads; TRINITY_DN1448606_c0_g1_i1 472 298.999 0.000000 0.000; TRINITY_DN1448584_c0_g1_i1 394 222.370 0.00000",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/870#issuecomment-1695989396:2651,validat,validateMappings,2651,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/870#issuecomment-1695989396,1,['validat'],['validateMappings']
Security,019-07-01 12:33:02.020] [jointLog] [info] Replaced 3801867 non-ATCG nucleotides; [2019-07-01 12:33:02.020] [jointLog] [info] Clipped poly-A tails from 1630 transcripts; [2019-07-01 12:33:02.041] [jointLog] [info] Building rank-select dictionary and saving to disk; [2019-07-01 12:33:02.248] [jointLog] [info] done; Elapsed time: 0.20793s; [2019-07-01 12:33:02.252] [jointLog] [info] Writing sequence data to file . . . ; [2019-07-01 12:33:04.501] [jointLog] [info] done; Elapsed time: 2.24861s; [2019-07-01 12:33:04.572] [jointLog] [info] Building 32-bit suffix array (length of generalized text is 469043886); [2019-07-01 12:33:08.681] [jointLog] [info] Building suffix array . . . ; success; saving to disk . . . done; Elapsed time: 61.4932s; done; Elapsed time: 171.743s; processed 12000000 positionsKilled. I can send log files if required. The problem I have is that I cannot seem to run quant without the quant function. salmon quant --validateMappings ; -i /home/RnaSeq/transcriptome_gencode_v29/human_GENCODEv29/combined_index -l IU ; -1 /home/RnaSeq/fastq/DM_4a_H_1.fq.gz /home/RnaSeq/fastq/DM_4b_H_1.fq.gz /home/RnaSeq/fastq/DM_4c_H_1.fq.gz ; -2 /home/RnaSeq/fastq/DM_4a_H_2.fq.gz /home/RnaSeq/fastq/DM_4b_H_2.fq.gz /home/RnaSeq/fastq/DM_4c_H_2.fq.gz ; -o /home/RnaSeq/salmon_output_files/out/DM4h; Version Info: Could not resolve upgrade information in the alotted time.; Check for upgrades manually at https://combine-lab.github.io/salmon; ### salmon (mapping-based) v0.14.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { /home/RnaSeq/transcriptome_gencode_v29/human_GENCODEv29/combined_index }; ### [ libType ] => { IU }; ### [ mates1 ] => { /home/RnaSeq/fastq/DM_4a_H_1.fq.gz /home/RnaSeq/fastq/DM_4b_H_1.fq.gz /home/RnaSeq/fastq/DM_4c_H_1.fq.gz }; ### [ mates2 ] => { /home/RnaSeq/fastq/DM_4a_H_2.fq.gz /home/RnaSeq/fastq/DM_4b_H_2.fq.gz /home/RnaSeq/fastq/DM_4c_H_2.fq.gz }; ### [ validateMappings ] => { }; ### [ output ] => { /home/RnaSeq/salmon_output_fi,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/389#issuecomment-507253562:1870,validat,validateMappings,1870,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/389#issuecomment-507253562,1,['validat'],['validateMappings']
Security,"2019-06-06 19:24:57.025] [stderrLog] [info] Loading Rank-Select Bit Array; [2019-06-06 19:24:57.061] [stderrLog] [info] There were 136,011 set bits in the bit array; [2019-06-06 19:24:57.084] [stderrLog] [info] Computing transcript lengths; [2019-06-06 19:24:57.084] [stderrLog] [info] Waiting to finish loading hash; [2019-06-06 19:25:06.552] [jointLog] [info] done; [2019-06-06 19:25:06.552] [jointLog] [info] Index contained 136,011 targets; [2019-06-06 19:25:06.552] [stderrLog] [info] Done loading index; [2019-06-06 19:25:06.728] [alevinLog] [error] Barcode not found in frequency table; ```. Salmon Quant log is this. ```; [2019-06-06 19:23:29.519] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2019-06-06 19:23:29.519] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2019-06-06 19:23:29.520] [jointLog] [info] Usage of --validateMappings, without --hardFilter implies use of range factorization. rangeFactorizationBins is being set to 4; [2019-06-06 19:23:29.520] [jointLog] [info] Usage of --validateMappings implies a default consensus slack of 0.2. Setting consensusSlack to 0.2.; [2019-06-06 19:23:29.520] [jointLog] [info] Using default value of 0.87 for minScoreFraction in Alevin; Using default value of 0.6 for consensusSlack in Alevin; [2019-06-06 19:24:55.716] [jointLog] [info] There is 1 library.; [2019-06-06 19:24:55.889] [jointLog] [info] Loading Quasi index; [2019-06-06 19:24:55.889] [jointLog] [info] Loading 32-bit quasi index; [2019-06-06 19:25:06.552] [jointLog] [info] done; [2019-06-06 19:25:06.552] [jointLog] [info] Index contained 136,011 targets; ```. It is interesting because the barcodes are recognized during the processing, but they don't appear in the frequency table? I don0t get that part. > Can you clarify a bit more about what you meant with: The FASTQ file of the reads is not paired-end. I mean that e",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/369#issuecomment-499592790:2513,validat,validateMappings,2513,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/369#issuecomment-499592790,1,['validat'],['validateMappings']
Security,"3350, FUTEX_WAKE_PRIVATE, 2147483647) = 0; write(2, ""terminate called without an acti""..., 45terminate called without an active exception; ) = 45; rt_sigprocmask(SIG_UNBLOCK, [ABRT], NULL, 8) = 0; write(3, ""[2017-04-05 16:24:37.940] [joint""..., 136) = 136; tgkill(32681, 32681, SIGABRT) = 0; --- SIGABRT (Aborted) @ 0 (0) ---; +++ killed by SIGABRT (core dumped) +++; ```; and for task 2:. ```; execve(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon"", [""/dcl01/lieber/ajaffe/Emily/RNAse""..., ""quant"", ""-i"", ""/dcl01/lieber/ajaffe/Emily/RNAse""..., ""-p"", ""1"", ""-l"", ""ISR"", ""-1"", ""/dcl01/lieber/ajaffe/lab/libd_al""..., ""-2"", ""/dcl01/lieber/ajaffe/lab/libd_al""..., ""-o"", ""/dcl01/lieber/ajaffe/lab/libd_al""...], [/* 107 vars */]) = 0; brk(0) = 0xc2c000; mmap(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7fffbfffd000; readlink(""/proc/self/exe"", ""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon"", 4096) = 88; access(""/etc/ld.so.preload"", R_OK) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/tls/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/tls/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/tls/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/tls"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linu",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:41331,access,access,41331,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,1,['access'],['access']
Security,"3350, FUTEX_WAKE_PRIVATE, 2147483647) = 0; write(2, ""terminate called without an acti""..., 45terminate called without an active exception; ) = 45; rt_sigprocmask(SIG_UNBLOCK, [ABRT], NULL, 8) = 0; write(3, ""[2017-04-05 16:40:15.587] [joint""..., 136) = 136; tgkill(51996, 51996, SIGABRT) = 0; --- SIGABRT (Aborted) @ 0 (0) ---; +++ killed by SIGABRT (core dumped) +++; ```. and for task 2:. ```; execve(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon"", [""/dcl01/lieber/ajaffe/Emily/RNAse""..., ""quant"", ""-i"", ""/dcl01/lieber/ajaffe/Emily/RNAse""..., ""-p"", ""1"", ""-l"", ""ISR"", ""-1"", ""/dcl01/lieber/ajaffe/lab/libd_al""..., ""-2"", ""/dcl01/lieber/ajaffe/lab/libd_al""..., ""-o"", ""/dcl01/lieber/ajaffe/lab/libd_al""...], [/* 107 vars */]) = 0; brk(0) = 0xc2c000; mmap(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7fffbfffd000; readlink(""/proc/self/exe"", ""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon"", 4096) = 88; access(""/etc/ld.so.preload"", R_OK) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/tls/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/tls/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/tls/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/tls"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linu",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:122294,access,access,122294,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,1,['access'],['access']
Security,"37.338] [alevinLog] [info] Total 91 BiDirected Edges.; > [2020-06-04 17:57:37.338] [alevinLog] [info] Total 82 UniDirected Edges.; > [2020-06-04 17:57:37.338] [alevinLog] [warning] Skipped 82268 barcodes due to No mapped read; > [2020-06-04 17:57:37.341] [alevinLog] [info] Clearing EqMap; Might take some time.; > [2020-06-04 17:57:37.348] [alevinLog] [warning] Num Low confidence barcodes too less 1 < 10.Can't performing whitelisting; Skipping; > [2020-06-04 17:57:37.348] [alevinLog] [info] Finished optimizer; > ; > . salmon_quant.log. > [2020-06-04 17:55:11.700] [jointLog] [info] setting maxHashResizeThreads to 7; > [2020-06-04 17:55:11.700] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; > [2020-06-04 17:55:11.700] [jointLog] [info] The --mimicBT2, --mimicStrictBT2 and --hardFilter flags imply mapping validation (--validateMappings). Enabling mapping validation.; > [2020-06-04 17:55:11.700] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; > [2020-06-04 17:55:11.700] [jointLog] [info] The use of range-factorized equivalence classes does not make sense in conjunction with --hardFilter. Disabling range-factorized equivalence classes. ; > [2020-06-04 17:55:11.700] [jointLog] [info] Usage of --validateMappings implies a default consensus slack of 0.2. Setting consensusSlack to 0.35.; > [2020-06-04 17:55:11.700] [jointLog] [info] Using default value of 0.797619 for minScoreFraction in Alevin; > Using default value of 0.6 for consensusSlack in Alevin; > [2020-06-04 17:56:30.294] [jointLog] [info] There is 1 library.; > [2020-06-04 17:56:30.355] [jointLog] [info] Loading pufferfish index; > [2020-06-04 17:56:30.355] [jointLog] [info] Loading dense pufferfish index.; > [2020-06-04 17:56:30.355] [jointLog] [info] done; > [2020-06-04 17:56:30.355] [jointLog] [info] Index contained 64 targets; > [2020-06-04 17:56:30.355] [jointLog] [i",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-639196415:3148,validat,validateMappings,3148,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-639196415,1,['validat'],['validateMappings']
Security,"4 ; [2022-04-16 11:19:39.637] [puff::index::jointLog] [info] Done constructing the contig vector. 2046804 [2022-04-16 11:19:40.720] [puff::index::jointLog] [info] # segments = 2,046,803 ; [2022-04-16 11:19:40.720] [puff::index::jointLog] [info] total length = 189,087,548 ; [2022-04-16 11:19:40.878] [puff::index::jointLog] [info] Reading the reference files ... ; [2022-04-16 11:19:42.562] [puff::index::jointLog] [info] positional integer width = 28 ; [2022-04-16 11:19:42.562] [puff::index::jointLog] [info] seqSize = 189,087,548 ; [2022-04-16 11:19:42.562] [puff::index::jointLog] [info] rankSize = 189,087,548 ; [2022-04-16 11:19:42.562] [puff::index::jointLog] [info] edgeVecSize = 0 ; [2022-04-16 11:19:42.562] [puff::index::jointLog] [info] num keys = 144,057,882 ; for info, total work write each : 2.331 total work inram from level 3 : 4.322 total work raw : 25.000 ; [Building BooPHF] 100 % elapsed: 0 min 6 sec remaining: 0 min 0 sec ; Bitarray 754822720 bits (100.00 %) (array + ranks ) ; final hash 0 bits (0.00 %) (nb in final hash 0) ; [2022-04-16 11:19:48.362] [puff::index::jointLog] [info] mphf size = 89.9819 MB ; [2022-04-16 11:19:48.637] [puff::index::jointLog] [info] chunk size = 15,757,296 ; [2022-04-16 11:19:48.637] [puff::index::jointLog] [info] chunk 0 = [0, 15,757,296) ; [2022-04-16 11:19:48.637] [puff::index::jointLog] [info] chunk 1 = [15,757,296, 31,514,592) ; [2022-04-16 11:19:48.637] [puff::index::jointLog] [info] chunk 2 = [31,514,592, 47,271,888) ; [2022-04-16 11:19:48.637] [puff::index::jointLog] [info] chunk 3 = [47,271,888, 63,029,184) ; [2022-04-16 11:19:48.637] [puff::index::jointLog] [info] chunk 4 = [63,029,184, 78,786,480) ; [2022-04-16 11:19:48.637] [puff::index::jointLog] [info] chunk 5 = [78,786,480, 94,543,776) ; [2022-04-16 11:19:48.637] [puff::index::jointLog] [info] chunk 6 = [94,543,776, 110,301,072) ; [2022-04-16 11:19:48.638] [puff::index::jointLog] [info] chunk 7 = [110,301,072, 126,058,368) ; [2022-04-16 11:19:48.638] [puff::inde",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/768#issuecomment-1100734317:13602,hash,hash,13602,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/768#issuecomment-1100734317,1,['hash'],['hash']
Security,"485). Consider this example from that paper:. ![image](https://user-images.githubusercontent.com/361470/101438021-706d3600-38df-11eb-9ada-a54ea9092d2d.png). The x-axis is samples from the Gibbs chains, and the y-values denote the estimated number of reads assigned to both transcripts in each sample. The green line at the top is what you get if you sum the abundances of these two transcripts. The main point is that the inferential relative variance (adjusted ratio of the variance over the mean) is _much_ smaller for the sum of these transcripts than for either individually. This is strong evidence that they are _inherently_ uncertain given the read evidence and alignments used for quantification. The tool described in that paper, called [`terminus`](https://github.com/COMBINE-lab/terminus), is a tool for automatically finding such groups of transcripts. Anyway, once you have the Gibbs samples in hand, we can walk you though how to do some assessment of these transcripts (tagging @hiraksarkar here since he's most likely to have access to scripts that will let us look at the posterior samples from individual transcripts). Similarly, if you can provide the quantification directory, we can help examine this too. If this is the case, that the posterior distributions are highly anti-correlated, it is likely that the ambiguity you are seeing is simply inherent given the alignments salmon is being provided. If you have the quantification folder resulting from the same sample using selective alignment, we could compare and contrast the two. At that point, there are a few options depending on how deeply you want to dive. You could try to see how STAR and selective alignment are mapping differently to these transcripts. One potential difference is that STAR is _a lot_ more happy to softclip reads, which selective alignment won't do by default (you can test the effect with the `--softclipOverhangs` to allow selective alignment to softclip reads that hang off the transcript end o",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/600#issuecomment-740363115:2769,access,access,2769,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/600#issuecomment-740363115,2,['access'],['access']
Security,"4_2.fastq }; # [ output ] => { SRP057125_SRS936134_salmon_out }; # [ geneMap ] => { /nfs/research2/teichmann/reference/mus-musculus/salmon/mouse_cdna38.78_repbase_ercc_index_gene_map.txt }; # [ biasCorrect ] => { }; # [ useFSPD ] => { }; Logs will be written to SRP057125_SRS936134_salmon_out/logs; [2016-01-02 20:22:59.800] [jointLog] [info] parsing read library format; there is 1 lib; Loading 32-bit quasi index[2016-01-02 20:23:00.830] [stderrLog] [info] Loading Suffix Array; [2016-01-02 20:23:00.830] [stderrLog] [info] Loading Position Hash; [2016-01-02 20:23:00.829] [jointLog] [info] Loading Quasi index; [2016-01-02 20:23:03.751] [stderrLog] [info] Loading Transcript Info; [2016-01-02 20:23:04.776] [stderrLog] [info] Loading Rank-Select Bit Array; [2016-01-02 20:23:05.009] [stderrLog] [info] There were 104534 set bits in the bit array; [2016-01-02 20:23:05.325] [stderrLog] [info] Computing transcript lengths; [2016-01-02 20:23:05.325] [stderrLog] [info] Waiting to finish loading hash; Index contained 104534 targets; [2016-01-02 20:23:16.571] [stderrLog] [info] Done loading index; [2016-01-02 20:23:16.571] [jointLog] [info] done. processed 12000001 fragments; hits: 24367128, hits per frag: 2.04044. [2016-01-02 20:23:49.850] [jointLog] [info] Computed 102251 rich equivalence classes for further processing; [2016-01-02 20:23:49.850] [jointLog] [info] Counted 10033689 total reads in the equivalence classes; [2016-01-02 20:23:49.875] [jointLog] [info] Mapping rate = 83.0244%. [2016-01-02 20:23:49.875] [jointLog] [info] finished quantifyLibrary(); [2016-01-02 20:23:49.875] [jointLog] [info] Starting optimizer; [2016-01-02 20:23:50.378] [jointLog] [info] Marked 0 weighted equivalence classes as degenerate; [2016-01-02 20:23:50.382] [jointLog] [info] iteration = 0 | max rel diff. = 64.9993; [2016-01-02 20:23:50.584] [jointLog] [info] iteration 50, recomputing effective lengths; [2016-01-02 20:23:53.386] [jointLog] [info] iteration = 100 | max rel diff. = 0.263028; [2016-01",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/34#issuecomment-168426741:8212,hash,hash,8212,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/34#issuecomment-168426741,1,['hash'],['hash']
Security,"624] [jointLog] [error] You passed paired-end files to; salmon, but you passed 12 files to --mates1 and 13 files to --mates2. You; must pass the same number of files to both flags. Thank you in advance for any tips you may have for me. Sara. On Tue, Jul 30, 2019 at 10:30 AM Sara Boles <seboles@ucdavis.edu> wrote:. > Hi Avi,; >; > Here is the salmon log from one of my PE libraries. There are only 12; > libraries for each in the directory, which is why I got confused when it; > said 13. I will try putting in all of the file names and let you know how; > it goes. Thank you for all of your help.; >; > Sara; >; > [2019-07-29 15:58:39.034] [jointLog] [info] Fragment incompatibility prior; > below threshold. Incompatible fragments will be ignored.; > [2019-07-29 15:58:39.034] [jointLog] [info] Usage of --validateMappings; > implies use of minScoreFraction. Since not explicitly specified, it is; > being set to 0.65; > [2019-07-29 15:58:39.034] [jointLog] [info] Usage of --validateMappings,; > without --hardFilter implies use of range factorization.; > rangeFactorizationBins is being set to 4; > [2019-07-29 15:58:39.034] [jointLog] [info] Usage of --validateMappings; > implies a default consensus slack of 0.2. Setting consensusSlack to 0.2.; > [2019-07-29 15:58:39.034] [jointLog] [info] parsing read library format; > [2019-07-29 15:58:39.034] [jointLog] [error] Failed to successfully parse; > any complete read libraries. Please make sure you provided arguments; > properly to -1, -2 (for paired-end libraries) or -r (for single-end; > libraries), and that the library format option (-l) *comes before* the read; > libraries.; >; > On Mon, Jul 29, 2019 at 4:06 PM Avi Srivastava <notifications@github.com>; > wrote:; >; >> Oh Sorry about that what I meant was the salmon.log file or the the; >> meta-info.json file created by salmon in the output directory. You can; >> check what files salmon is detecting it seems there are 12 files in the; >> mate1 and 13 files in the mate2. Can you ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/408#issuecomment-516521791:2587,validat,validateMappings,2587,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/408#issuecomment-516521791,1,['validat'],['validateMappings']
Security,"634174.1|ENSG00000282732.1|OTTHUMG00000191398|OTTHUMT00000487783.1|AC073539.14-201|AC073539.14|28|unprocessed_pseudogene|], had length less than equal to the k-mer length of 31 (perhaps after poly-A clipping). [2020-12-26 10:49:06.436] [puff::index::jointLog] [warning] Removed 829 transcripts that were sequence duplicates of indexed transcripts.; [2020-12-26 10:49:06.436] [puff::index::jointLog] [warning] If you wish to retain duplicate transcripts, please use the `--keepDuplicates` flag; [2020-12-26 10:49:06.448] [puff::index::jointLog] [info] Replaced 151,122,967 non-ATCG nucleotides; [2020-12-26 10:49:06.448] [puff::index::jointLog] [info] Clipped poly-A tails from 1,829 transcripts; wrote 231443 cleaned references; [2020-12-26 10:49:09.969] [puff::index::jointLog] [info] Filter size not provided; estimating from number of distinct k-mers; [2020-12-26 10:49:40.159] [puff::index::jointLog] [info] ntHll estimated 2628436199 distinct k-mers, setting filter size to 2^36; Threads = 12; Vertex length = 31; Hash functions = 5; Filter size = 68719476736; Capacity = 2; Files:; salmon-decoy-sa-index/ref_k31_fixed.fa; --------------------------------------------. **So using gffread I created a transcripts.fa file:; gffread -w salmon_transcripts.fa -g GRCh38.primary_assembly.genome.fa gencode.v36.annotation.gtf. using this new transcripts.fa I run again the above mentioned salmon index with decoy command, but the warning message was shown up again:**. [Step 1 of 4] : counting k-mers; [2020-12-26 11:30:08.799] [puff::index::jointLog] [warning] Entry with header [ENST00000473810.1], had length less than equal to the k-mer length of 31 (perhaps after poly-A clipping); [2020-12-26 11:30:08.951] [puff::index::jointLog] [warning] Entry with header [ENST00000603775.1], had length less than equal to the k-mer length of 31 (perhaps after poly-A clipping); [2020-12-26 11:30:10.751] [puff::index::jointLog] [warning] Entry with header [ENST00000632684.1], had length less than equal to t",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/214#issuecomment-751354493:14554,Hash,Hash,14554,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/214#issuecomment-751354493,1,['Hash'],['Hash']
Security,"634174.1|ENSG00000282732.1|OTTHUMG00000191398|OTTHUMT00000487783.1|AC073539.14-201|AC073539.14|28|unprocessed_pseudogene|], had length less than equal to the k-mer length of 31 (perhaps after poly-A clipping); [2020-12-26 10:49:06.436] [puff::index::jointLog] [warning] Removed 829 transcripts that were sequence duplicates of indexed transcripts.; [2020-12-26 10:49:06.436] [puff::index::jointLog] [warning] If you wish to retain duplicate transcripts, please use the `--keepDuplicates` flag; [2020-12-26 10:49:06.448] [puff::index::jointLog] [info] Replaced 151,122,967 non-ATCG nucleotides; [2020-12-26 10:49:06.448] [puff::index::jointLog] [info] Clipped poly-A tails from 1,829 transcripts; wrote 231443 cleaned references; [2020-12-26 10:49:09.969] [puff::index::jointLog] [info] Filter size not provided; estimating from number of distinct k-mers; [2020-12-26 10:49:40.159] [puff::index::jointLog] [info] ntHll estimated 2628436199 distinct k-mers, setting filter size to 2^36; Threads = 12; Vertex length = 31; Hash functions = 5; Filter size = 68719476736; Capacity = 2; Files:; salmon-decoy-sa-index/ref_k31_fixed.fa. **So using gffread I created a transcripts.fa file:; gffread -w salmon_transcripts.fa -g GRCh38.primary_assembly.genome.fa gencode.v36.annotation.gtf. using this new transcripts.fa I run again the above mentioned salmon index with decoy command, but the warning message was shown up again:**. [Step 1 of 4] : counting k-mers; [2020-12-26 11:30:08.799] [puff::index::jointLog] [warning] Entry with header [ENST00000473810.1], had length less than equal to the k-mer length of 31 (perhaps after poly-A clipping); [2020-12-26 11:30:08.951] [puff::index::jointLog] [warning] Entry with header [ENST00000603775.1], had length less than equal to the k-mer length of 31 (perhaps after poly-A clipping); [2020-12-26 11:30:10.751] [puff::index::jointLog] [warning] Entry with header [ENST00000632684.1], had length less than equal to the k-mer length of 31 (perhaps after poly-A cl",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/214#issuecomment-751354991:14553,Hash,Hash,14553,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/214#issuecomment-751354991,1,['Hash'],['Hash']
Security,":index::jointLog] [info] chunk 8 = [126,058,368, 141,815,664) ; [2022-04-16 11:19:48.638] [puff::index::jointLog] [info] chunk 9 = [141,815,664, 157,572,960) ; [2022-04-16 11:19:48.638] [puff::index::jointLog] [info] chunk 10 = [157,572,960, 173,330,256) ; [2022-04-16 11:19:48.638] [puff::index::jointLog] [info] chunk 11 = [173,330,256, 189,087,526) ; [2022-04-16 11:19:53.442] [puff::index::jointLog] [info] finished populating pos vector ; [2022-04-16 11:19:53.442] [puff::index::jointLog] [info] writing index components ; [2022-04-16 11:19:55.117] [puff::index::jointLog] [info] finished writing dense pufferfish index ; [2022-04-16 11:19:55.401] [jLog] [info] done building index. and the log for quantification:. > [2022-04-16 11:23:51.572] [jointLog] [info] setting maxHashResizeThreads to 48 ; [2022-04-16 11:23:51.572] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored. ; [2022-04-16 11:23:51.572] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65 ; [2022-04-16 11:23:51.572] [jointLog] [info] Setting consensusSlack to selective-alignment default of 0.35. [2022-04-16 11:23:51.572] [jointLog] [info] parsing read library format ; [2022-04-16 11:23:51.572] [jointLog] [info] There is 1 library. ; [2022-04-16 11:23:51.694] [jointLog] [info] Loading pufferfish index ; [2022-04-16 11:23:51.695] [jointLog] [info] Loading dense pufferfish index. ; [2022-04-16 11:23:53.681] [jointLog] [info] done ; [2022-04-16 11:23:53.681] [jointLog] [info] Index contained 245,261 targets ; [2022-04-16 11:23:53.776] [jointLog] [info] Number of decoys : 0 ; [2022-04-16 11:24:42.358] [jointLog] [info] Computed 960,194 rich equivalence classes for further processing [2022-04-16 11:24:42.358] [jointLog] [info] Counted 23,784,776 total reads in the equivalence classes [2022-04-16 11:24:42.426] [jointLog] [info] Number of mappings discarded because of alignment sco",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/768#issuecomment-1100734317:15582,validat,validateMappings,15582,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/768#issuecomment-1100734317,1,['validat'],['validateMappings']
Security,"======; Please add /salmon/bin to your PATH; Please add /salmon/lib to your LD_LIBRARY_PATH; ==========================================================================; root@fd877e359439:/salmon/build# make test; Running tests...; Test project /salmon/build; Start 1: unit_tests; 1/2 Test #1: unit_tests ....................... Passed 0.37 sec; Start 2: salmon_read_test_quasi; 2/2 Test #2: salmon_read_test_quasi ........... Passed 1.80 sec. 100% tests passed, 0 tests failed out of 2. Total Test time (real) = 2.17 sec; ```. The `make test` command itself runs the test the builds the index and maps the reads against it. Either way, I can do that explicitly too (from within build):. ```; $ ./src/salmon index -t ../sample_data/transcripts.fasta -i sample_idx; ```. returns succesfully with a built index. ```; ...; [2023-03-10 05:51:33.748] [puff::index::jointLog] [info] Done wrapping the rank vector with a rank9sel structure.; [2023-03-10 05:51:33.748] [puff::index::jointLog] [info] contig count for validation: 23; [2023-03-10 05:51:33.748] [puff::index::jointLog] [info] Total # of Contigs : 23; [2023-03-10 05:51:33.748] [puff::index::jointLog] [info] Total # of numerical Contigs : 23; [2023-03-10 05:51:33.748] [puff::index::jointLog] [info] Total # of contig vec entries: 36; [2023-03-10 05:51:33.748] [puff::index::jointLog] [info] bits per offset entry 6; [2023-03-10 05:51:33.748] [puff::index::jointLog] [info] Done constructing the contig vector. 24; [2023-03-10 05:51:33.748] [puff::index::jointLog] [info] # segments = 23; [2023-03-10 05:51:33.748] [puff::index::jointLog] [info] total length = 19592; [2023-03-10 05:51:33.748] [puff::index::jointLog] [info] Reading the reference files ...; [2023-03-10 05:51:33.750] [puff::index::jointLog] [info] positional integer width = 15; [2023-03-10 05:51:33.750] [puff::index::jointLog] [info] seqSize = 19592; [2023-03-10 05:51:33.750] [puff::index::jointLog] [info] rankSize = 19592; [2023-03-10 05:51:33.750] [puff::index::jointLog] ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463312554:3488,validat,validation,3488,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463312554,1,['validat'],['validation']
Security,"=> quant ; ### [ index ] => { /media/usr/Hybrid_02/Unidad_Bioinf/FER_Scripts/Index/hg38/salmon_sa_index/default }; ### [ libType ] => { A }; ### [ gcBias ] => { }; ### [ validateMappings ] => { }; ### [ mates1 ] => { /media/usr/trimmed_fastq_files/PAIRED_trimmed_fastq_files/APSa16_1P.fq.gz }; ### [ mates2 ] => { /media/usr/trimmed_fastq_files/PAIRED_trimmed_fastq_files/APSa16_2P.fq.gz }; ### [ threads ] => { 7 }; ### [ output ] => { /media/usr/quantification/APSa16.fq.gz_quant }; Logs will be written to /media/usr/quantification/APSa16.fq.gz_quant/logs; [2020-05-05 09:19:06.171] [jointLog] [info] setting maxHashResizeThreads to 7; [2020-05-05 09:19:06.171] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2020-05-05 09:19:06.171] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2020-05-05 09:19:06.171] [jointLog] [info] Usage of --validateMappings implies a default consensus slack of 0.2. Setting consensusSlack to 0.35.; [2020-05-05 09:19:06.171] [jointLog] [info] parsing read library format; [2020-05-05 09:19:06.171] [jointLog] [info] There is 1 library.; [2020-05-05 09:19:06.278] [jointLog] [info] Loading pufferfish index; [2020-05-05 09:19:06.278] [jointLog] [warning] The index did not record if the `--keepDuplicates` flag was used. Please consider re-indexing with a newer version of salmon that will propagate this information.; [2020-05-05 09:19:06.278] [jointLog] [info] Loading dense pufferfish index.; -----------------------------------------; | Loading contig table | Time = 30.609 s; -----------------------------------------; size = 36981178; -----------------------------------------; | Loading contig offsets | Time = 1.3312 s; -----------------------------------------; -----------------------------------------; | Loading reference lengths | Time = 5.6842 ms; -----------------------------------------; --------------",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/518#issuecomment-623910021:1155,validat,validateMappings,1155,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/518#issuecomment-623910021,1,['validat'],['validateMappings']
Security,"> And for us, who have blocked download on a computational cluster `cmake` silently continues even when `scripts/fetchRapMap.sh` failed (see error code `403` below). Dists downloading their own dependencies is also forbidden in package managers such as FreeBSD ports and pkgsrc (which is cross-platform and I personally use on Mac, NetBSD, and RHEL). Trusting upstream scripts to pull stuff off the Internet is a security risk, so the package managers perform and validate (via checksum) all downloads in a separate stage. It would be nice not to have to hack out the download code from a build system in order to create and maintain a package.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/19#issuecomment-989326040:413,secur,security,413,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/19#issuecomment-989326040,3,"['checksum', 'secur', 'validat']","['checksum', 'security', 'validate']"
Security,"> Hi @amitpande74 ,; > ; > Please check the path of the files like `V300012057_L3_HK500HUMpybEAAKRAAPEI-530_2.fq` since you provided the full path of other files like `/media/amit/Amit/Usr/DNA12/fastq/V300012057_L3_HK500HUMpybEAAKRAAPEI-530_1.fq`. @k3yavi it should be like this ?. `./bin/salmon quant -i /media/amit/Amit/Usr/new_salmon_index/ -l IU -1 /media/amit/Amit/Usr/DNA12/fastq/V300012057_L3_HK500HUMpybEAAKRAAPEI-530_1.fq /media/amit/Amit/Usr/DNA12/fastq V300012057_L4_HK500HUMpybEAAKRAAPEI-530_1.fq -2 /media/amit/Amit/Usr/DNA12/fastq/V300012057_L3_HK500HUMpybEAAKRAAPEI-530_2.fq /media/amit/Amit/Usr/DNA12/fastq /V300012057_L4_HK500HUMpybEAAKRAAPEI-530_2.fq -p 8 --validateMappings -o /media/amit/Amit/Usr/DNA12/fastq/DNA12.quant`. Regards.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/737#issuecomment-1019983461:676,validat,validateMappings,676,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/737#issuecomment-1019983461,1,['validat'],['validateMappings']
Security,"> Hi @austin-abbvie,; > ; > Thanks for the report. Would you be able to share the offending BAM file and reference? I'm also tagging @gmarcais for input / ideas.; > ; > Thanks,; > Rob. I'll have to check with my manager to see if this is something I'm allowed to do. I also just attempted to use the --noErrorModel instead of --ont, but now I'm getting a `segmentation fault (core dumped)` after about 2M reads. These BAMs have been through a lot so I'm going to check to make sure they haven't been corrupted in some way. Here's an output from Picard's ValidateSamFile; ```; WARNING 2021-07-01 08:12:30 ValidateSamFile NM validation cannot be performed without the reference. All other validations will still occur.; INFO 2021-07-01 08:12:48 SamFileValidator Seen many non-increasing record positions. Printing Read-names as well. ## HISTOGRAM java.lang.String; Error Type Count; ERROR:MISSING_READ_GROUP 1; WARNING:RECORD_MISSING_READ_GROUP 1085776; ```. After adding a dummy read group to one of my bam files using Picard's AddOrReplaceReadGroups, I was able to successfully quantify my file using the --ont error model. I'll repeat this for the lot to see if this solves the problem!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/289#issuecomment-872314305:554,Validat,ValidateSamFile,554,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/289#issuecomment-872314305,4,"['Validat', 'validat']","['ValidateSamFile', 'validation', 'validations']"
Security,"> Hi Brian,; > ; > In general, I would argue that one should be cautious with removing PCR duplicates in RNA-seq data (unless you are dealing with reads with UMI tags). This is because reads that align to the same reference position can easily have come from alternative transcripts sharing the same underlying sequence. Hence, the normal tests used to infer PCR duplicates with e.g. DNA-seq reads can yield false-positives in RNA-seq. This is particularly true for highly abundant transcripts (or transcripts from highly-abundant genes).; > ; > We are currently working on the code that will do duplicate removal when UMI tags are present. That methodology can be extended to remove duplicates even without UMI tags --- though I'd generally caution against that for the reasons mentioned above. However, for the time being, if you have a strong need or desire to filter PCR duplicates, you could use alignment-based Salmon with a BAM file that has duplicates removed.; > ; > Finally, regarding the error you are getting during SAM validation; this sounds like a different issue. Would you mind providing a piece of that SAM file for me to take a look at? Specifically, I don't believe the quasi-mapping output file should even contain unmapped reads (unless you consider unmapped mates of orphaned reads).; > ; > --Rob. It is in the latest Salmon release?. Thanks",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/136#issuecomment-446191570:1032,validat,validation,1032,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/136#issuecomment-446191570,1,['validat'],['validation']
Security,"> Is this read set & reference txome available to try and reproduce this?. Unfortunately no, it's a generated fasta file (it used to work with 0.9.1 without ""validateMappings"" though). [info] Building 32-bit suffix array (length of generalized text is 462349554); processed 462000000 positions; khash had 208056876 keys. > Also, would it be possible to check if this occurs using the bioconda-packaged release?. Still a seg fault but I now have the following message:; WARNING: Could not associate known library type with read!; WARNING: PE compatibility function called with SE read!; expected: Library format { type:paired end, relative orientation:inward, strandedness:unstranded }, observed: Library format { type:, relative orientation:, strandedness: }; Segmentation fault: 11",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/228#issuecomment-393236903:158,validat,validateMappings,158,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/228#issuecomment-393236903,1,['validat'],['validateMappings']
Security,"> Yes that's one aspect. But also, Salmon uses CIGAR to evaluate alignment probability in alignment quantification mode no?. Indeed. > And with just RapMap output you would lose other information that Salmon uses to determine likely fragment assignment?. You would lose information (in the format of a CIGAR string) that Salmon uses in alignment mode, but not any information, I think, that Salmon uses in quasi-mapping-based mode (though one would incur a non-trivial performance hit for filtering the quasi-mappings through file / disk rather than dealing with them directly in memory as Salmon normally does). > With UMI's you can deduplicate fragments before inferring where they were likely to come from. Ideally you would deduplicate the reads directly based on UMI, then you wouldn't have to think about PCR duplication in the quantification. But of course keeping a hash of all reads in a FASTQ and accounting for dequencing errors wouldn't be really tractable.. I guess this is the real question I have. Specifically, what is the true computational burden to detect and eliminate duplicates using UMIs? In theory, the reads must (1) map to the same location and (2) have the same UMI tag. How often would one expect the UMI tag to be modified / corrupted / etc.? Would you have to search all 1 or 2 hamming distance neighbors to detect duplicates reliably? Is an equivalence class a sufficient proxy for ""mapping to the same location"", or do we also care that e.g. the position of the fragment within each transcript is a duplicate as well? These are the main questions that are preventing me from implementing the ""obvious solution"".",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/108#issuecomment-269001682:874,hash,hash,874,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/108#issuecomment-269001682,1,['hash'],['hash']
Security,"@EricDeveaud,. Does passing `--no-version-check` resolve the issue? This flag goes before any other command and disables this behavior. For example:. ```; salmon --no-version-check index -t <gentrome.fa> -d decoys.txt -i index; ```. or . ```; salmon --no-version-check quant -i index -la -1 reads_1.fq.gz -2 reads_2.fq.gz -o quant_dir; ```; There should be _no_ network access when using this flag.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/486#issuecomment-617286729:370,access,access,370,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/486#issuecomment-617286729,1,['access'],['access']
Security,"@cljacobs,. 256G and 7-10 hours; holy **expletive deleted**. This _certainly_ has to do with the creation of many small temporary files by TwoPaCo during the initial cdbg creation. Can you say something specific about the setup of the cluster on which you are running these jobs? When we build on the M23 transcriptome using the genome as decoys, it takes ~30 minutes and 16-18G of memory. What is the situation in terms of disk access on your cluster? Will the index be constructed on an written to a local disk, or to a networked file system? I imagine the latter could become _much_ (pathologically?) slower.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/476#issuecomment-583546762:429,access,access,429,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/476#issuecomment-583546762,1,['access'],['access']
Security,"@ctb — One thing that would be required for this (apart from some engineering of the command-line parsing / validation code) is a trustworthy, efficient, _multithreaded_ `FAST(A/Q)` parser for interleaved format reads. Right now, Salmon (& Sailfish, &RapMap, & most of the other HTS-centric methods we're developing) use the Jellyfish 2 read parser. I've made this choice since it's fairly simple to use, yet provides nice parallel performance and, most importantly, is fairly well-tested and trust-worthy. Can you suggest a reliable, well-tested, concurrency-enabled library for parsing reads in interleaved format?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/29#issuecomment-152827801:108,validat,validation,108,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/29#issuecomment-152827801,2,['validat'],['validation']
Security,"@demis001 Salmon's `--geneMap | -g` option does take a GTF file (although you're correct that it can also take a two-column text file, and I think accepting both types of files in the same option is a bit confusing). See some context in this [old issue](https://github.com/COMBINE-lab/salmon/issues/114). I believe the issue you're seeing is that Ensembl will update transcript (and gene I think) versions like so:. ```; !! this is not real data, just a toy example. ensembl v24; -------------; ENST0000001.1; ENST0000002.1. ensembl v25; -------------; ENST0000001.2; ENST0000002.2; ```; and the GTF file you used to build the salmon index is ""ensembl v24"", but now you only have ""ensembl v25"" available during the `salmon quant` run. . **The most correct thing** to do at this point would be to either rebuild the salmon index using ""ensembl v25"" and rerun `salmon quant -g ensembl_v25.gtf`, or get the ""ensembl v24"" GTF file (re-download from Ensembl website) and pass this to `salmon quant -g ensembl_v24.gtf`. . **The thing would probably be okay** is to allow passing GTF files that do not exactly match the transcript accessions, where ""ENST0000001"" is the ""accession"" and "".1"" is the ""version"" - hence ""accession.version"". This way you can just ignore the version part of the transcript/gene names in the GTF file for the purposes of constructing a tx<>gene map.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/122#issuecomment-282342092:1124,access,accessions,1124,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/122#issuecomment-282342092,3,['access'],"['accession', 'accessions']"
Security,"@demis001 salmon currently makes exact matches between the fasta headers and transcript annotations in the GTF, so no - it doesn't work. Since gene level summarization is pretty simple you could just use something like https://github.com/daler/gffutils to read your GTF, drop the version numbers from the GTF entries, then drop the version numbers from the salmon quant.sf file, and join the two yourself. The summarization from tx->gene is just summing each gene's transcripts' TPM values. @rob-p: I do think this is a common enough issue that salmon could handle dropping accession.version numbers with an extra option.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/122#issuecomment-282048231:574,access,accession,574,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/122#issuecomment-282048231,2,['access'],['accession']
Security,"@mikelove - was this question with reference to salmon quant on QuantSeq data?. > Just to check: do you have length bias in your data (are counts roughly proportional to effective transcript length)?. @rob-p Is there a way to get the answer to Mike's question from the meta_info.json files. Also, aren't the counts in quant.sf file provided after taking into account length bias and effective transcript length?. This is the salmon quant command line being used for RNA-Seq quantification - still not figured out the right command line combination for QuantSeq data. ```; salmon --no-version-check quant --threads 16 --seqBias --validateMappings --numBootstraps 100 .......; ```. The original question in the post is ""what are the correct steps with tximport for running DESEQ after salmon quant""",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/581#issuecomment-719721141:629,validat,validateMappings,629,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/581#issuecomment-719721141,1,['validat'],['validateMappings']
Security,"@rob-p ; I don't know what you mean by ""accession.version"", my initial question was, if you pass "" -g Homo_sapiens.GRCh38.87.chr.gtf"" to salmon to get a gene level count, it will fail to map Transcript to Gene Name. . Instead of asking the user to pass a two column annotation that map ""Transcript to Gene"", it would be nice to support standard format from Ensembl gtf file to generate a gene level count from a solmon CLI. . Am I missing something?. @demis001",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/122#issuecomment-282337316:40,access,accession,40,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/122#issuecomment-282337316,1,['access'],['accession']
Security,"@rob-p Could it be that I am not using the correct command line `salmon quant` options for Lexogen/QuantSeq _(this will be referred to as QS in the rest of the message(s))_ ?. `salmon quant --threads 16 --noLengthCorrection --validateMappings --numBootstraps 100 -l SF -i <path_to_SAF_Gentrome_Index> -r <SE_READ_1.fq> -o <salmon_SE_READ_1>`. I chose the above command line options (`especially --noLengthCorrection`) based on [Rob's message here](https://groups.google.com/d/msg/sailfish-users/VIfqBwgF6xQ/fw-rgC_kAwAJ) and a [thread here](https://github.com/COMBINE-lab/salmon/issues/108). Let me elaborate the big picture of my analyses and give more details about how I came up with the mapping numbers in my original post. Big Picture - DEG identification for samples sequenced by ILMN (whole transcript method) and QS (3' method) - [something similar to this paper](https://bmcgenomics.biomedcentral.com/articles/10.1186/s12864-018-5393-3). Bioinformatics Pipeline(s) for both ILMN and QS :. 1. HISAT Method : Adapter/Quality Trimming, Hisat2-HTSEQ, Get_Count_Table, DESeq; 2. STAR_RSEM Method: Adapter/Quality Trimming, STAR_RSEM, Get_Count_Table, DESeq; 3. SAF Method: Adapter/Quality Trimming, SAF_SALMON, Get_Count_Table, DESeq; 4. Quasi-Mapping or TXOME Method: Adapter/Quality Trimming, TXOME_SALMON, Get_Count_Table, DESeq. I used UpSetR plots for comparisons of sets of DEGs from each method just [as you have shown in your recent preprint](https://www.biorxiv.org/content/10.1101/657874v1.full). In the ILMN analyses, there is great concordance between the SAF method and HISAT/STAR_RSEM method. However, in the QS analyses, there is very limited concordance between SAF and the HISAT/STAR_RSEM method. For QS analyses, the TXOME method shows great concordance with HISAT/STAR_RSEM. This finding made me wonder if this has to be something with my salmon quant command line options for QS. Therefore, I wanted to check how the QS expected counts for SAF method show up for all samples in",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-554768195:226,validat,validateMappings,226,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-554768195,1,['validat'],['validateMappings']
Security,"@rob-p I think it's reasonable to support only ""accession.version"" since that seems common (it's used for ensemble at least), and allowing more user parameters means more work implementing, testing, fixing... I'm sure you don't need it, but I implemented something similar to allow a user to pass a custom ""key function"" in one of my python packages: https://github.com/mdshw5/pyfaidx#keyfn. I'm not sure how you would allow custom functions since you're using C++, and you might have to come up with an entire domain-specific language for this, but maybe something exists for this purpose...",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/122#issuecomment-282331518:48,access,accession,48,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/122#issuecomment-282331518,1,['access'],['accession']
Security,"@rob-p I tried SalmonBeta-0.6.5-pre_CentOS5.tar.gz but for some reason, it still make 32-bit index on my x86_64 machine. What do you think I am doing wrong?. ```; $ salmon index -t emase.pooled.transcripts.fa -i salmon; Version Info: This is the most recent version of Salmon.; [2016-05-19 16:06:55.048] [jLog] [info] building index; RapMap Indexer. [Step 1 of 4] : counting k-mers; counted k-mers for 920000 transcriptsElapsed time: 24.0224s. Replaced 12 non-ATCG nucleotides; Clipped poly-A tails from 4247 transcripts; Building rank-select dictionary and saving to disk done; Elapsed time: 0.0972664s; Writing sequence data to file . . . done; Elapsed time: 0.872786s; [info] Building 32-bit suffix array (length of generalized text is 1561273393); Building suffix array . . . success; saving to disk . . . done; Elapsed time: 3.65916s; done; Elapsed time: 265.19s; processed 1561000000 positions; khash had 135536906 keys; saving hash to disk . . . done; Elapsed time: 11.27s; [2016-05-19 16:19:10.357] [jLog] [info] done building index; ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/54#issuecomment-220450290:934,hash,hash,934,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/54#issuecomment-220450290,1,['hash'],['hash']
Security,"@rob-p More info - if you find it useful . The mapping stats as I calculated above for ILMN with SAF method - 91% to the transcripts and 9% to the decoys.. . To reiterate, this I what I did:. > expected counts for SAF method -- convert to final summarized table (after tximport). take colSum for all my samples and then checked the numbers for the transcripts and the decoys. For QS, I also used incompatPrior - the results are the same . ` salmon quant --threads 16 --noLengthCorrection --incompatPrior 0.0 --validateMappings --numBootstraps 100 -l SF -i <path_to_SAF_Gentrome_Index> -r <SE_READ_1.fq> -o <salmon_SE_READ_1>`",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-554822134:510,validat,validateMappings,510,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-554822134,1,['validat'],['validateMappings']
Security,"@rob-p That's a good point. I have been relying on Picard for validating the files and this was flagged as an error. Incorrectly so as you point out. Is there any validation for the CIGAR strings that are generated? In some cases with some of the shorter transcripts, the operator falls of the end of the reference. ENST00000424567 is 135 bp long. . ```; NB501336:15:H3KVTBGXY:1:13202:16266:9834 99 ENST00000424567 1 1 1S150M = 1 -135 GTAGTCGAAACTGAAGAAGACAGAGACGCAAGAGAAATTCGATAAGTCGAAACTGAAGAAGACAGAGACGCAAGAGAAAAATCCACTGCCCGAGATCGGAAGAGCACACGTCAGAACTCCAGTCACCGTAGAAGCTCGTATGCCGTCTTCG * NH:i:7; ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/94#issuecomment-250561171:62,validat,validating,62,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/94#issuecomment-250561171,2,['validat'],"['validating', 'validation']"
Security,"@tamuanand,. Right now, I added the code to dump the _salmon_ version into versionInfo.json. Which is a standard json file that goes in the index directory. Actually, that file already contains an index version key, which is simply a number that is incremented every time there is a change made that alters the binary representation of the index on disk. That is particularly useful because not every salmon version requires re-building the index. Regarding the feature I've added. It's fairly standard practice for us to put information that is meant to be read by both humans and machines (scripts, R packages downstream, etc.) into a JSON file. This makes it easy to access it simply from many languages, and to have _some_ (but not too much) structure to this data. There are even slick command line tools for pulling info out of JSON files (like [jq](https://stedolan.github.io/jq/)). If there is a strong reason that you need the _salmon_ version in its own text file, I'm willing to oblige and duplicate the information there. Just let me know.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/498#issuecomment-605694474:670,access,access,670,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/498#issuecomment-605694474,2,['access'],['access']
Security,Actually I meant the following command:; `cmake -DBOOST_ROOT=/users/work/jake/bin/boost_1_64_0/ -DZLIB_LIBRARY=/users/work/jake/bin/zlib-1.2.11/`.; Also you can try [linuxbrew](http://linuxbrew.sh/) for which you don't need root access.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/141#issuecomment-314460816:229,access,access,229,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/141#issuecomment-314460816,1,['access'],['access']
Security,"Also, this appears to be:; 1. A very old version of Salmon (0.4.2); 2. Using GCC 5.0, to which I have not yet moved (and which isn't installed on any machines where I have access). Is it easy to check if this pops up with 4.8.x or 4.9.x as well?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/46#issuecomment-193922543:172,access,access,172,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/46#issuecomment-193922543,1,['access'],['access']
Security,Awesome! Thank you so much for the detailed report and for finding this data that exposed this strange (but interesting) performance case. We'll fold these improvements into the next release as well.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/527#issuecomment-637601951:82,expose,exposed,82,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/527#issuecomment-637601951,1,['expose'],['exposed']
Security,"Certainly. Let me be more specific. The model itself is general, though we train it on a context that is of length 8. Specifically, the model that is used (the context) is defined here. https://github.com/COMBINE-lab/salmon/blob/1c3f6c014ce77ec593d5b37ee2bb0cf9feddf123/src/SBModel.cpp#L20. If you look further up in that file, you can see that it's reasonably easy to consider different contexts — it's just a matter of how the model is initialized. However, this isn't something that we currently expose as a runtime parameter. However, if you have a reason to believe that a different model topology would work better in your context, we'd be happy to help you try it out (and enable such a feature in a future release). Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/880#issuecomment-1757810371:499,expose,expose,499,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/880#issuecomment-1757810371,1,['expose'],['expose']
Security,"Confirmed with v0.6.0:. ```; Version Info: Could not resolve upgrade information in the alotted time.; Check for upgrades manually at https://combine-lab.github.io/salmon; # salmon (mapping-based) v0.6.0; # [ program ] => salmon; # [ command ] => quant; # [ index ] => { ... }; # [ libType ] => { IU }; # [ mates1 ] => { ... }; # [ mates2 ] => { ... }; # [ output ] => {... }; # [ threads ] => { 16 }; Logs will be written to ...; there is 1 lib; [2016-01-22 17:59:17.894] [jointLog] [info] parsing read library format; Loading 32-bit quasi index[2016-01-22 17:59:18.735] [stderrLog] [info] Loading Suffix Array; [2016-01-22 17:59:18.736] [stderrLog] [info] Loading Position Hash; [2016-01-22 17:59:18.731] [jointLog] [info] Loading Quasi index; [2016-01-22 18:00:59.879] [stderrLog] [info] Loading Transcript Info; [2016-01-22 18:01:25.157] [stderrLog] [info] Loading Rank-Select Bit Array; [2016-01-22 18:01:30.642] [stderrLog] [info] There were 552702 set bits in the bit a; [2016-01-22 18:01:31.487] [stderrLog] [info] Computing transcript lengths; [2016-01-22 18:01:31.491] [stderrLog] [info] Waiting to finish loading hash; Index contained 552702 targets; [2016-01-22 18:04:43.717] [jointLog] [info] done; [2016-01-22 18:04:43.717] [stderrLog] [info] Done loading index; ```. I'll check the index creation logs, but didn't notice anything out of the ordinary...",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/37#issuecomment-174082911:675,Hash,Hash,675,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/37#issuecomment-174082911,2,"['Hash', 'hash']","['Hash', 'hash']"
Security,"Dear @rob-p ,. Edit: I have resolved the problem. It is not a problem with Biostrings or GRanges. It turns out that when subsetting the premature sequences, the subsetted sequences do not retain the names of the GRanges used to subset them therefore my code could not identify minus strand transcripts and get their reverse complements. Apologies for any confusion!; ---; Thank you very much for the prompt response and for taking the time to validate Salmon's functionality. Indeed, Salmon is not the problem here. After taking a closer look at my transcript fasta, I noticed a problem with it, as you suggested. Long story short, half the premature transcripts had the wrong orientation and complementarity. Long story:. Oddly, the mature sequences were fine even though I used an identical approach to subset premature and mature transcripts from the genome reference!. Briefly my approach relied on three R packages rtracklayer, GenomicRanges, and Biostrings. 1. I used rtracklayer to load a gtf formatted exon annotations acquired from Ensembl. The file is loaded as a GenomicRanges object which essentially describes the locus of each exon (the transcribed strand [+ or -], chromosome, start and end positions relative to the reference strand) and its associated gene and transcript. 2. I used the GRanges object to generate pre-RNA coordinates that span all exons of a transcript. 3. I loaded the reference genome fasta acquired from Ensembl using the Biostrings package. GRanges and Biostrings are tightly integrated, allowing me to subset sequences from a Biostrings object using the GRanges object. **I believe the problem lies here.** It appears that when subsetting the mature exonic sequences from Biostrings using GRanges, the strand field in the GRanges object **was not** utilized. I.e., I needed to get the reverse complement of the extracted sequences for transcripts on the minus strand. I had done that and assumed that this behaviour would be consistent. However, for reasons I ha",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/655#issuecomment-826035191:443,validat,validate,443,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/655#issuecomment-826035191,2,['validat'],['validate']
Security,"Dear @rob-p,. Hope you are well, thank you so much for your response and input. . Following your suggestions, firstly I tried to compute a hash on all of the files in the index using this command:; find /scratch/scratch/skgtjzw/workspace/middle_aged_microglia/salmon_quantification_SAF/salmon_index -type f -exec md5sum {} \; | md5sum; c0959830010f005c7f2e041aac4829ef -. Secondly, I have attached the aux_info/meta_info.json on here ; ![SRR2557120](https://user-images.githubusercontent.com/50330051/102141871-71f7aa80-3e59-11eb-9d3f-5e824b7a1346.PNG); ![SRR2557121](https://user-images.githubusercontent.com/50330051/102141883-73c16e00-3e59-11eb-9c50-6cc61b8d34c1.PNG); ![SRR2557119](https://user-images.githubusercontent.com/50330051/102141894-76bc5e80-3e59-11eb-80e2-4cb86c4466b1.PNG). Thirdly, as I am quite new to the RNA-Seq analysis world and coding, I am not sure how can I add the sequence for the ribosomal RNA to my transcriptome. For example, where could I find such files with gencode? and with a file of ribosomal RNA, do I give both the gencode.v36.transcripts.fa.g and the ribosomal RNA together to the salmon index command? or there is certain parameter in the salmon index command that needs to be changed?. Finally, for these three data, it was from published paper, and I am trying to do re-analysis on them. And before salmon quantification, I have already ran fastp on them to do the trim and QC. . Hopefully, I am making sense here. Please let me know if there is anything incorrect here. Thank you for helping out in advance. . Best Wishes, . David",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/603#issuecomment-744750168:139,hash,hash,139,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/603#issuecomment-744750168,1,['hash'],['hash']
Security,"Excellent. May I point out that tools such as Oncofuse https://github.com/mikessh/oncofuse/ and Pegasus https://github.com/RabadanLab/Pegasus have a particular, additional value since they provide functional annotation of fusion events identified by other approaches? Also, these resources may prove helpful wrt validation data: https://github.com/chapmanb/bcbio-nextgen/issues/210 and http://m.genome.cshlp.org/content/early/2015/11/10/gr.186114.114 Adding @roryk here for highlighting this feature request in bcbio.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/52#issuecomment-202711490:312,validat,validation,312,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/52#issuecomment-202711490,1,['validat'],['validation']
Security,"Exp` is 0, then the model considers alignments (say to transcript 2) with 2 substitutions to be just as likely as alignments (say to transcript 1) that are perfect (with no substitutions). While you can play around with different values of `--scoreExp` to determine how differences from the optimal alignment should be weighted, I'd strongly suggest against setting `--scoreExp` equal to 0. * `--allowDovetail` and `--softclipOverhangs` may or may not have a significant effect based on the quality of your library and annotation. Ideally, you would have no dovetailed mappings and no reads overhanging annotated transcripts. However, if you have an incomplete assembly or a library of questionable quality, these can both occur in practice. The `meta_info.json` file in the `aux_info` directory will give you stats about the number of dovetailed reads, so you can see if this is likely to have an effect here or not. * `--consensusSlack` determines which reads pass through the mapping-based filtering based on their chaining score and are therefore subject to alignment validation. While the chaining score is a decent proxy for alignment score, it's not perfect (otherwise, we would not really waste compute cycles computing the optimal alignment). Setting the `--consensusSlack` to a large value allows many things to be subject to mapping validation, while setting it to a smaller value doesn't. If the value is too small, then you may see situations where the mapping that yields the optimal _alignment_ doesn't have a chance to be counted because its chain score is too low. Now, it _is_ true that the only reads used will be those surpassing `--minScoreFraction` in terms of their alignment score, so changing the `--consensusSlack` won't allow through poor alignments, but if you set it too conservatively, you might miss some mappings that could have yielded the optimal alignment to mappings that are sub-optimal (personally, though, I'd guess this flag is probably the least likely to be ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/523#issuecomment-632953613:2592,validat,validation,2592,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/523#issuecomment-632953613,1,['validat'],['validation']
Security,"FYI, I'm taking another crack at an official FreeBSD port, but still hitting some gnarly issues with 1.5.2, so it might be a while. https://github.com/outpaddling/freebsd-ports-wip/tree/master/salmon; https://github.com/outpaddling/freebsd-ports-wip/tree/master/pufferfish; https://github.com/COMBINE-lab/salmon/issues/502. 1. The cmake system still forces downloading pufferfish during configure, which is forbidden in the ports system (like many other package managers). All downloads must occur during fetch phase and be verified using locally stored checksums. This would be easy to work around using GH_TUPLE, which downloads additional distfiles during fetch phase, except that fetchPufferfish.sh doesn't just extract the pufferfish dist, but has a long list of ""cp"" commands to copy pieces of it to ${INSTALL_DIR}. That's not something I'm inclined to tamper with since it will likely change with new versions and hence be a headache to maintain over time. It would be ideal if salmon could work with a separately installed pufferfish as it does with many other dependencies. This would make the port much cleaner.; 2. The code is not compatible with onetbb 2021.3, which is the current FreeBSD ports version.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/162#issuecomment-917642392:554,checksum,checksums,554,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/162#issuecomment-917642392,1,['checksum'],['checksums']
Security,"Fraction. Since not explicitly specified, it is being set to 0.65; [2019-08-25 11:40:44.518] [jointLog] [info] Usage of --validateMappings, without --hardFilter implies use of range factorization. rangeFactorizationBins is being set to 4; [2019-08-25 11:40:44.518] [jointLog] [info] Usage of --validateMappings implies a default consensus slack of 0.2. Setting consensusSlack to 0.2.; [2019-08-25 11:40:44.518] [jointLog] [info] parsing read library format; [2019-08-25 11:40:44.518] [jointLog] [info] There is 1 library.; Exception : [Error: The index version file salmonIndexDecoyMouse/versionInfo.json doesn't seem to exist. Please try re-building the salmon index.]; salmon quant was invoked improperly.; For usage information, try salmon quant --help; Exiting.; (salmon) wayne@Ubuntu19:~/rnaseq$ ls -R *.json; ls: cannot access '*.json': No such file or directory. Try 2.; Instead of referring to my directory decoys/ , I moved to the directory decoys/ ; and ran salmon index again, using your command exactly:; salmon index -t gentrome.fa -d decoys.txt -i combined_index. This time a few .json files were produced in the directory combined_index/ [your name this time]; [contents of decoys= combined_index gentrome.fa mus_musculus.tar.gz Salmontranscripts_quant; decoys.txt links.txt salmonQuantDecoy22.sh]. then [sh salmonQuantDecoy22.sh]; salmon quant -p 3 -i combined_index -l A -1 ../SRR1818187_2.fastq.gz -2 ../SRR1818187_1.fastq.gz --validateMappings -o Salmontranscripts_quant. Now no Segmentation Fault crash. ; The program finishes with; [2019-08-25 12:37:39.056] [jointLog] [info] Finished optimizer; [2019-08-25 12:37:39.056] [jointLog] [info] writing output . Now I am going to look for the mRNA counts. I think a major secret is to have mus_musculus.tar.gz in the same directory.; If my description is accurate [I did not repeat everything] you should have -mRNA [path to transcriptome.gz] on your command line, or instruct users to have the transcriptome.gz in the same directory.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/419#issuecomment-524651435:2866,validat,validateMappings,2866,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/419#issuecomment-524651435,1,['validat'],['validateMappings']
Security,"Hello @rob-p . While I have the luxury of catching your attention, I am going to be sneaky :) and refer you back to my original question on this thread - would like to know your response. To summarize, these are my questions:. 1. what Salmon ```quant```command line options would you recommend for QuantSeq data -- I realize you introduced 'noLengthCorrection' specifically for QuantSeq as mentioned in [Issue108](https://github.com/COMBINE-lab/salmon/issues/108) and [Issue177](https://github.com/COMBINE-lab/salmon/issues/177). - I thought this would be good one: ```salmon quant -i {input.index} -l A -1 {input.R1} -2 {input.R2} -o {output} --noLengthCorrection --validateMappings --gcBias --seqBias --posBias```. 2. likewise, what would be the command line if I chose to take SA approach (build gentrome.fa with decoys). Suggestion: once the dust has settled after the printing of this new paper, you should include these command line suggestions for QuantSeq in your tutorial/readthedocs/README sections. Thanks in advance",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/365#issuecomment-499732849:667,validat,validateMappings,667,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/365#issuecomment-499732849,1,['validat'],['validateMappings']
Security,"Hello Avi,. Here is my out put log. Thank you in advance for an help you can provide. [2019-07-29 15:58:39.034] [jointLog] [info] Fragment incompatibility prior; below threshold. Incompatible fragments will be ignored.; [2019-07-29 15:58:39.034] [jointLog] [info] Usage of --validateMappings; implies use of minScoreFraction. Since not explicitly specified, it is; being set to 0.65; [2019-07-29 15:58:39.034] [jointLog] [info] Usage of --validateMappings,; without --hardFilter implies use of range factorization.; rangeFactorizationBins is being set to 4; [2019-07-29 15:58:39.034] [jointLog] [info] Usage of --validateMappings; implies a default consensus slack of 0.2. Setting consensusSlack to 0.2.; [2019-07-29 15:58:39.034] [jointLog] [info] parsing read library format; [2019-07-29 15:58:39.034] [jointLog] [error] Failed to successfully parse; any complete read libraries. Please make sure you provided arguments; properly to -1, -2 (for paired-end libraries) or -r (for single-end; libraries), and that the library format option (-l) *comes before* the read; libraries. Best,. Sara. On Mon, Jul 29, 2019 at 3:25 PM Avi Srivastava <notifications@github.com>; wrote:. > You passed paired-end files; > to salmon, but you passed 12 files to --mates1 and 13 files to --mates2.; > You must pass the same number of files to both flags; >; > Is this true ? Can you share the log ?; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/COMBINE-lab/salmon/issues/408?email_source=notifications&email_token=AEHDXAH7HQIR4ZVWMTE2KXLQB5U5LA5CNFSM4IGU4ZTKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOD3CF3JY#issuecomment-516185511>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AEHDXAG7WI3B7QBMJOSXTATQB5U5LANCNFSM4IGU4ZTA>; > .; >. -- ; Sara E. Boles, MS; PhD Candidate | Whitehead Lab; Pharmacology and Toxicology Graduate Group; Department of Environmental Toxicology; Univer",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/408#issuecomment-516194201:275,validat,validateMappings,275,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/408#issuecomment-516194201,3,['validat'],['validateMappings']
Security,"Hello again @rob-p . I was calling using the wrong code for quantification and calling sailfish .; The code that I just sent you is included in the tutorial and is saved as shell script . `quant_tut_samples.sh`. However this doesn't match with the code described immediately below in the tutorial. ; >#!/bin/bash; >for fn in data/DRR0161{25..40};; > do; > samp=`basename ${fn}`; > echo ""Processing sample ${samp}""; > salmon quant -i athal_index -l A \; > -1 ${fn}/${samp}_1.fastq.gz \; > -2 ${fn}/${samp}_2.fastq.gz \; > -p 8 --validateMappings -o quants/${samp}_quant; >done. This is something that should be corrected in the tutorial. Thank you so much. I apologize.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/508#issuecomment-614289282:528,validat,validateMappings,528,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/508#issuecomment-614289282,1,['validat'],['validateMappings']
Security,"Hello,. The checksums were correct. I now refined the problem. It does not happen when I set the number of threads to 4 with ""-p 4"", in which case the procedure goes until completion. ; With ""-p 12"" The ""invalid character"" is sometimes different, and found in different chromosomes.; It is likely that the number of threads exceeding the number of cores (8) causes the problem. NB: I used the procedure with or without ""-k 31"" to follow; https://salmon.readthedocs.io/en/latest/salmon.html#preparing-transcriptome-indices-mapping-based-mode; or; https://combine-lab.github.io/alevin-tutorial/2019/selective-alignment/ . Would you now advise to drop the ""-k 31""?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/521#issuecomment-627835939:12,checksum,checksums,12,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/521#issuecomment-627835939,1,['checksum'],['checksums']
Security,"Hey @Gaura - I have a test dataset for us to use. I'm about to set up an alevin run of my own, but wanted to pass it on to you in the meantime. I haven't yet done any testing or exploration of my own yet, though the data comes from a collaborator of ours. The raw (FASTQ) and processed data (UMI counts matrix) is accessible from GEO at [GSE137941](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE137941) and SRA (`fastq-dump --split-files SRR10174292`). These data were generated with the original SPLiT-seq method (your ""v1""). The caveat is that they did NOT combine the oligo-dT and random hexamer barcodes, meaning they are separate cells/columns in their processed data matrix. This means we should be able to run `alevin`/`alevin-fry` directly on these FASTQs, bypassing `splitp` for now, and get something that hopefully matches their processed data matrix. . According to the methods section [of their paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7366517/), they used GENCODE v28 annotations, and ultimately kept 6,888 nuclei after filtering. Their processed data matrix seems to have 25,000 columns, so I suppose this is pre-filtering. . Let me know what you think!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-984646381:314,access,accessible,314,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-984646381,1,['access'],['accessible']
Security,"Hey @rob-p @mdshw5 ,. First, thanks a lot for implementing salmon, it is super helpful. Has this been achieved? I would like to visualise the ```salmon quant```output in IGV. . I have generate the .bam file with ```salmon quant -lISR -r Parent_NGSC3_DI_HodgkinsLymphoma_S1_L002_R2_001.fastq.gz -i $SALMON_INDEX -p 26 -o alignment_file --validateMappings --no-version-check --writeMappings | samtools view -Sb - | samtools sort -T sort.tmp -o - > salmon.bam```. But if I explore the bam file with ```samtools view```what I see is:; ```; A00519:603:H7KMNDSXY:2:1307:5900:21699	16	ENST00000390436.2	204	255	91M	*	0	0	AAAAGACCTCAGCTTATTATAGACATTCGTTCAAATGTGGGCGAAAAGAAAGACCAACGAATTGCTGTTACATTGAACAAGACAGCCAAAC	*	NH:i:1	HI:i:1	XT:A:T	AS:i:176; A00519:603:H7KMNDSXY:2:1307:5801:2018	0	ENST00000535880.2	326	255	91M	*	0	0	GACGGTTTTCTGTGAAACACATTCTGACCCAGAAAGCCTTTCACTTGGTGATCTCTCCAGTAAGGACTGAAGACAGTGCCACTTACTACTG	*	NH:i:1	HI:i:1	XT:A:T	AS:i:182; ```. Where in the 3rd column I am seeing the transcript ID. I would like to have the chromosome coordinates of that read, like here:; ```; A00519:603:H7KMNDSXY:2:1401:1814:22357	0	chr1	11261	0	90M	*	0	0	CTATTGCTTAGACTGGTGGCCAGCGCCCCCTGCTGGCGCCGGGGCACTGCAGGGCCCTCTTGCTTACTGTATAGTGGTGGCACGCCGCCT	FF,FFFFFFFFF,FFFFFFFFFFFFF:FFFF,FFFFFFFFFFFF,FFFFFFF:,FFFFFFFFFFFF,:,:FFFFF,FFFF::F,F,F:FF	NH:i:5	HI:i:1	AS:i:84	nM:i:2	RG:Z:Parent_NGSC3_DI_HodgkinsLymphoma:0:1:H7KMNDSXY:2	RE:A:I	xf:i:0	CR:Z:GATTCGACAACGCATT	CY:Z:FFFFFFFFFF:F,F:F	CB:Z:GATTCGACAACGCATT-1	UR:Z:CGATCACGGAAC	UY:Z:FFFFFFF,:FFF	UB:Z:CGATCACGGAAC; A00519:603:H7KMNDSXY:2:1250:26503:19272	16	chr1	11570	1	90M	*	0	0	GATTACCATCAGAATTGTACTGTTCTGTATCCCACCAGCAATGTCTAGGAATGCCTGTTTCTCCACAAAGTGTTTACTTTTGGATTTTTG	FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF	NH:i:3	HI:i:1	AS:i:88	nM:i:0	RG:Z:Parent_NGSC3_DI_HodgkinsLymphoma:0:1:H7KMNDSXY:2	RE:A:I	xf:i:0	CR:Z:CCGGACAGTACAAACA	CY:Z:FFFFFFFFFFFFFFFF	CB:Z:CCGGACAGTACAAACA-1	UR:Z:AAGATTCACTAT	UY:Z:FFFFFFFFFFFF	UB:Z:AA",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/193#issuecomment-733126078:337,validat,validateMappings,337,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/193#issuecomment-733126078,1,['validat'],['validateMappings']
Security,"Hey Avi, thanks for the quick reply!; Here is the salmon_quant_log file:; ```; [2019-07-09 09:07:39.153] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2019-07-09 09:07:39.153] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2019-07-09 09:07:39.153] [jointLog] [info] Usage of --validateMappings implies use of range factorization. rangeFactorizationBins is being set to 4; [2019-07-09 09:07:39.153] [jointLog] [info] Usage of --validateMappings implies a default consensus slack of 1. Setting consensusSlack to 1.; [2019-07-09 09:07:39.153] [jointLog] [info] Using default value of 0.8 for minScoreFraction in Alevin; [2019-07-09 09:17:08.128] [jointLog] [info] There is 1 library.; [2019-07-09 09:17:08.180] [jointLog] [info] Loading Quasi index; [2019-07-09 09:17:08.180] [jointLog] [info] Loading 32-bit quasi index; [2019-07-09 09:17:14.970] [jointLog] [info] done; [2019-07-09 09:17:14.970] [jointLog] [info] Index contained 197,787 targets; [2019-07-09 10:02:20.484] [jointLog] [info] Computed 251,090 rich equivalence classes for further processing; [2019-07-09 10:02:20.484] [jointLog] [info] Counted 348,673,166 total reads in the equivalence classes ; [2019-07-09 10:02:20.485] [jointLog] [warning] Found 1893 reads with `N` in the UMI sequence and ignored the reads.; Please report on github if this number is too large; [2019-07-09 10:02:20.485] [jointLog] [info] Mapping rate = 39.7151%. [2019-07-09 10:02:20.485] [jointLog] [info] finished quantifyLibrary(); ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/396#issuecomment-510544611:267,validat,validateMappings,267,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/396#issuecomment-510544611,3,['validat'],['validateMappings']
Security,"Hi @ACastanza,. Thanks for reporting both of these. For the first, I think it is just the case that the message needs to be updated. In fact, the `--validateMappings` flag is now deprecated since selective-alignment is used by default (and can't be turned off, except in the single-cell mapping context, with the `--sketchMode` flag, which is currently only in the develop branch). We'll update that message.; Regarding the misplaced newline, the issue is that the other messages are written by the logger, which is asynchronous. So, sometimes it will get to the appropriate place and write a newline before the fragment counter starts, and sometimes it won't. I'll look into if there is a way to better clear the line, even if the update is asynchronous. Thanks!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/587#issuecomment-729044670:149,validat,validateMappings,149,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/587#issuecomment-729044670,2,['validat'],['validateMappings']
Security,"Hi @AnnaAMonaco ,. Thanks for reaching out and I agree it'd be super useful to have alevin working for both scRNA-seq and scATAC-seq multiome datasets. In short I'd say the framework is not ready yet and there are multiple challenges which we are still working-on to find the right solution. The Central issue is that the technologies to profile open-chromatin regions expects the read to align majorly to non-coding regions and salmon/alevin framework is designed to work (generally) with transcriptomic data. Having said that, one can potentially index the full genome using salmon indexing but we have not yet extensively validated the genomic alignment generated from alevin framework. Once settled, we can certainly figure out ways to run alevin without UMI, that's the easier part. What do I do now ? Basically since the scRNA-seq and scATAC-seq are two different library preps (along with the fastq), I'd still recommend using alevin for scRNA-seq, however, one might have to run other tools (like bwa-mem) to align scATAC-seq data. The are multiple reasons to recommend that, the significant power of alevin comes in with (1) multi-mapping reads but we generally expect low number of such reads with ATAC-seq data (2) UMI deduplication which is absent in the ATAC-seq data and the deduplication happens based on the aligned position. Again, I agree it's great to have a uniform workflow for the multiome data but we are thinking about the challenges in designing such workflow and how solve them. We'd let you know once we have a vignette / tutorial. -- Avi",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/611#issuecomment-758028858:625,validat,validated,625,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/611#issuecomment-758028858,1,['validat'],['validated']
Security,"Hi @BW15061999 , ; Yes, this is a known problem for single-cell data uploaded on NCBI. The idea is to download the BAM files of the data (yours should be [here](https://trace.ncbi.nlm.nih.gov/Traces/sra/?run=SRR8453531) under data access section) and then use tools like [these](https://github.com/10XGenomics/bamtofastq) to generate paired-end FASTQ files from the BAM file before running alevin. The one downloaded directly from NCBI/EBI doesn't has the CB/UMI components of the paired-reads. Hope it helps !",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/769#issuecomment-1107843131:231,access,access,231,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/769#issuecomment-1107843131,1,['access'],['access']
Security,"Hi @BenLangmead!. Thanks for the formal feature request. This is, indeed, a great idea, and something I've been interested in for quite a while. As far as I can tell, the main impediment to this is the hash table (https://github.com/greg7mdp/sparsepp) used in the index. The suffix array used by the mapping algorithm (by virtue of simply being a flat array of either 32 or 64-bit integers) is trivial to load via shared memory, as is the flat representation of the concatenated text itself. The bitvector and rank data structure that separate individual transcript sequences might be a bit trickier, but is also small enough to exist per-process. However, it's unclear to me if there is an easy or straightforward way to have the hash table reside in shared memory, and this is usually the single largest element of the index. As I mentioned, this is a feature that I've thought would be very useful for quite a while, and I'm interested in seeing it implemented. If you have any suggestions on what might be the best approach, I'm all 👂s.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/335#issuecomment-455905666:202,hash,hash,202,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/335#issuecomment-455905666,4,['hash'],['hash']
Security,"Hi @CloXD . The library is in the container in `/usr/local/lib`, but isn't being found by default for some reason. Can you try the following?. ```; singularity exec -e ""LD_LIBRARY_PATH=/usr/local/lib:$LD_LIBRARY_PATH"" docker://combinelab/salmon:latest salmon quant --validateMappings -l A -p ${threads} -o ./salmon_map -i ${salmon_index} -1 ${file_1} -2 ${file_2}; ```. and let me know if that works for you. I'll have to figure out how to make sure it's in the path by default.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/447#issuecomment-552987872:267,validat,validateMappings,267,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/447#issuecomment-552987872,1,['validat'],['validateMappings']
Security,"Hi @Cold7,. Thanks for the report. So, could you provide the full output that you get on the terminal when you run this? Your command line looks fine to me. Since version 1.0.0, `--validateMappings` has become the default behavior and so this flag technically has no effect (it is marked as ""deprecated""). However, the argument parser should _absolutely_ accept it, and it's not clear to me why it might be giving you this error. The full output from the terminal may help to diagnose this.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/563#issuecomment-680250718:181,validat,validateMappings,181,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/563#issuecomment-680250718,2,['validat'],['validateMappings']
Security,"Hi @Davidwei7,. Thank you for the very detailed bug report! So, I have two initial responses / thoughts about your issue. First, you asked if the issue may be related to a memory allocation error wherein the index didn't build successfully. This is quite possible (and the error you see during quantification is consistent with that). The *full* decoy index is substantially larger than the index on just the transcriptome (after all, it is indexing the entire human genome in addition to the transcriptome). One thing you might try to test this hypothesis, other than requesting to build on a node with more RAM, is to compute a hash (e.g. md5 or sha256 sum) on all of the files in the index, and also record their sizes. Then we can build the index on the same version of the files on our end and compare. Second — and perhaps more importantly for your end goal — the main purpose of the decoy-aware index is to improve specificity rather than sensitivity. That is, the decoys are designed to help avoid _spurious_ mapping of reads to an annotated transcript when a better explanation for the read exists elsewhere in the genome. However, the reads that are mapped to decoys are not otherwise used for quantification. Thus, using the decoy aware transcriptome index is unlikely to improve your mapping rate. I agree that your mapping rate does seem rather low. There are a few potential culprits here, and some diagnostics we can look at to see what might be going wrong. First, you can take a look at the file `aux_info/meta_info.json` in the salmon quantification directories to get a few more details about why reads were not mapped. If you share one of those files here I can describe the relevant fields. Also, I have two more rather common things to consider that might affect the mapping rate. One is to add the sequence for the ribosomal RNAs to your transcriptome before indexing and then quantifying. If your mapping rate increases considerably, this is evidence of rather inefficient depl",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/603#issuecomment-744162850:630,hash,hash,630,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/603#issuecomment-744162850,1,['hash'],['hash']
Security,"Hi @GWW ,. Ok, we figured out where the threads are coming from. Deep inside the concurrent hash map we are using, there is a [function that grows the hash map](https://github.com/COMBINE-lab/salmon/blob/master/include/cuckoohash_map.hh#L1558). This function uses a function called [`parallel_exec`](https://github.com/COMBINE-lab/salmon/blob/master/include/cuckoohash_map.hh#L1751) to move the items from the old table to the new one. Here, they greedily use as many threads as available for that process. We can't see this behavior on our end by monitoring top/htop, because the hash table doubling happens so fast it's below the monitoring resolution. There are a couple ways to address this, one of which is hacking inside the hashmap library to modify this behavior. However, it would be nice if there was a way to do this without modifying the code (e.g. by limiting the number of threads the process was allowed to spawn concurrently from outside of the process itself). We are looking to see if this is doable using e.g. cgroups or some such.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-395890018:92,hash,hash,92,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-395890018,4,['hash'],"['hash', 'hashmap']"
Security,"Hi @Hoohm ,; Thanks for the feature request.; Currently `Alevin` do have a hidden feature, where you can explicitly specify the CB and UMI length. Although we have not yet extensively tested these options but in your settings you might have to specify the following command line argument:; ```; --barcodeLength 7 --umiLength 9 --end 5; ```; Please let us know how it works out for you in these settings, it will help validate these options for `Alevin`. PS: Just a quick question for my understanding, is there a specific reason you chose to use the length of the UMI longer than CB in your experiment ?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/247#issuecomment-402349013:417,validat,validate,417,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/247#issuecomment-402349013,1,['validat'],['validate']
Security,"Hi @KAffoh,. Please let me know if this is resolved. If not, you can try running:. ```; salmon --no-version-check quant -i salmon_index -l A -1 $FW -2 $RV --validateMappings -o /Volumes/Ultra_Touch/malaria/Salmon/$FILEBASE/; ```. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/851#issuecomment-1563024409:157,validat,validateMappings,157,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/851#issuecomment-1563024409,1,['validat'],['validateMappings']
Security,"Hi @PeteCausey-Freeman ,. You can access the script and the requirements [here](https://github.com/COMBINE-lab/SalmonTools). Look for `generateDecoyTranscriptome`.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/373#issuecomment-501284160:34,access,access,34,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/373#issuecomment-501284160,1,['access'],['access']
Security,"Hi @SSaleem94,. As the message suggests, your command is missing the required `--output` argument. Of course, it seems your command includes `-o`. The rest of the errors suggest that the command line is not being properly parsed. It looks like the part after the first line break is not being interpreted as a continuation of the same line. I think this is because the line extension character in the shell is not `/`, but is `\`. Maybe try the following:; ; ```; F=$(cat file_names.txt); for i in ${F}; do; F1=../processed_fastq/${i}_R1_001_val_1.fastq.gz; F2=../processed_fastq/${i}_R2_001_val_2.fastq.gz; echo ""performing salmon quant on ${i}""; salmon quant -i gencode_v43_index -l A -1 ${F1} -2 ${F2} -p 64 \; --validateMappings --writeUnmappedNames -o ${i}; echo ""finish quantifying ${i}""; done; ```. **Also**, as is suggested by the `salmon` message itself, you may want to consider upgrading to the latest version of `salmon`. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/854#issuecomment-1599169394:716,validat,validateMappings,716,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/854#issuecomment-1599169394,1,['validat'],['validateMappings']
Security,"Hi @amitpande74,. Almost, but I think you are missing a `/` or so. Assuming uniform paths for the input, I think the command should look like:. ```{bash}. ./bin/salmon quant -i /media/amit/Amit/Usr/new_salmon_index/ -l IU -1 /media/amit/Amit/Usr/DNA12/fastq/V300012057_L3_HK500HUMpybEAAKRAAPEI-530_1.fq /media/amit/Amit/Usr/DNA12/fastq/V300012057_L4_HK500HUMpybEAAKRAAPEI-530_1.fq -2 /media/amit/Amit/Usr/DNA12/fastq/V300012057_L3_HK500HUMpybEAAKRAAPEI-530_2.fq /media/amit/Amit/Usr/DNA12/fastq/V300012057_L4_HK500HUMpybEAAKRAAPEI-530_2.fq -p 8 --validateMappings -o /media/amit/Amit/Usr/DNA12/fastq/DNA12.quant. ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/737#issuecomment-1021830675:547,validat,validateMappings,547,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/737#issuecomment-1021830675,1,['validat'],['validateMappings']
Security,"Hi @benadikt,. This indicates a system level problem with the underlying filesystem during the period that salmon calls out to TwoPaCo to create the compacted de Bruijn graph (or when attempting to clean up the intermediate files it makes after execution). Please make sure that the filesystem has sufficient free space, and that you have sufficient permissions for the salmon output directory. Finally, there have been intermittent issues in the past with the behavior of Twopaco on NFS mounted filesystems. If you are on a networkes filesystem, you should try building the index on a loc scratch partition, and then copying it over to a shared location if you need shared access to it. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/767#issuecomment-1094372240:674,access,access,674,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/767#issuecomment-1094372240,1,['access'],['access']
Security,"Hi @brianjohnhaas --- I know it's been a while (but I didn't gain access to an older OSX machine in that time). However, you should now be able to get the latest Salmon release on any OSX >= 10.8 via [its Bioconda release](https://bioconda.github.io/recipes/salmon/README.html). Let me know if this works for you. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/117#issuecomment-287753410:66,access,access,66,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/117#issuecomment-287753410,1,['access'],['access']
Security,"Hi @cljacobs,. Thank you again for the detailed info! Just to verify, what you are indexing here is the transcriptome ([this](ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_mouse/release_M24/gencode.vM24.transcripts.fa.gz) file), using the genome ([this](ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_mouse/release_M24/GRCm38.primary_assembly.genome.fa.gz) file) as decoy? Both the memory requirement and _definitely_ the time requirement are something that I've not been able to reproduce. I wonder if you could say something about the disk where the index is being written and where the program is being run. If this is all being done on NFS partitions, would it be possible to write the index to a local scratch on the node to see if disk access times have anything to do with the performance? I am scratching my head a bit about the memory though, because I don't have a good explanation for the discrepancy on those numbers.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/476#issuecomment-590565684:749,access,access,749,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/476#issuecomment-590565684,1,['access'],['access']
Security,"Hi @curtisd0886,. Indeed; thanks for sharing! @k3yavi -- I think we should take a look [here](https://github.com/COMBINE-lab/salmon/blob/develop/src/SalmonAlevin.cpp#L152) and at the resulting implications. We've thus far had limited access to data with barcode lengths > 16, so I think we should try to evaluate if there are any other places we make such assumptions.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/670#issuecomment-859016646:234,access,access,234,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/670#issuecomment-859016646,1,['access'],['access']
Security,"Hi @davidaknowles,. Indeed — the barcode extraction will happen either in `salmon alevin` or, if you are using the new `piscem` module for mapping prior to quantification (both are exposed in the `simpleaf` wrapper tool to simplify single-cell processing with `alevin-fry`), then it will happen there. We have a new very general and much more capable module in the works that will be able to handle all manners of single-cell geometry, but nothing about the Parse library seems beyond the capabilities of the current geometry processing code. If you share some reads, we can also try and take a look and figure out where the last BC resides. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/874#issuecomment-1733872331:181,expose,exposed,181,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/874#issuecomment-1733872331,2,['expose'],['exposed']
Security,Hi @egreen2 : It could have to do with the MacOS version. I don't have access to a 10.12 box. We can try and build a version on an older OSX and see if that works for you (generally MacOS apps are not backward compatible). @k3yavi --- what version of MacOS are you running?,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/318#issuecomment-442682181:71,access,access,71,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/318#issuecomment-442682181,1,['access'],['access']
Security,"Hi @ehiggs, You're right; there's no real reason we shouldn't be able to support ICC. The only issue is that we currently don't have access to a machine with icc, so this prevents us from testing the build ourselves. Is there a (free) resource (similar to Travis) that would allow us to test ICC builds? I'd be willing to add CMake support either way, but it would obviously be better if we could iron out the details ourself rather than wait for users to report issues building with icc.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/9#issuecomment-126348908:133,access,access,133,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/9#issuecomment-126348908,1,['access'],['access']
Security,"Hi @gpertea,. One thought about losing reads to the decoys in this case is that the default strategy is to assign as decoy any read that maps strictly better to the decoy than the target (transcriptome). So, even if e.g. the intron describes a single extra base, then the read gets assigned as decoy rather than transcriptomic. This is actually something that is easy to customize the behavior of (i.e. to add some ""slack"" so that reads have to map better to the decoy by some threshold before being assigned to the decoy). . Out of curiosity, what is salmon's mapping rate on this sample without the decoy? When you add the decoy, how many reads are assigned to the decoy sequence? Not that I necessarily suspect anything awry, but we'd be interested in taking a look at such samples anyway; what's the accession for the one you mention above?. Thanks!; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/779#issuecomment-1474336994:804,access,accession,804,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/779#issuecomment-1474336994,1,['access'],['accession']
Security,"Hi @jashapiro,. So there are definitely a few things going on here. The first is that you correctly diagnosed the missing cmd_info.json information when `alevin` is run in RAD mode. That was simply an oversight, and there is no reason that file shouldn't have been written. Second, there is also useful information that belongs in `meta_info.json` in the `aux_info` directory (like the SHA hash of the reference sequences); that was also missing but has now been added.; ; In addition to salmon's `alevin` command, each step of `alevin-fry` also writes some useful metadata when it executes. For example, there is a json file written by the `generate-permit-list` step, one written by the `collate` step, and one written by the `quant` step. We've never run into the problem of the output of `alevin-fry` overwriting the output of `alevin` because we use a directory structure where the output quantifications reside in a separate directory from the input RAD file. However, I can now see that if you're writing the quants in the same place as the input, then there will be a conflict in the file names, and the existing files will be overwritten with the new ones. I agree that both tools output useful information. I'm a *bit* ambivalent about assuming the salmon-generated files exist, and merging them into one output file, as I think there might be cases where those files aren't present and `alevin-fry` should still run properly since it doesn't require them to perform it's processing. One option would be to rename the `alevin-fry` output files to prefix/postfix them so they don't collide with the salmon files even if they live in the same directory. Then, one could (now or later) write a small command to merge the relevant json files into a unified output if that would be more convenient downstream. Let me know your thoughts. Thanks!; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/688#issuecomment-883497669:390,hash,hash,390,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/688#issuecomment-883497669,2,['hash'],['hash']
Security,"Hi @jckhearn,. The documentation could definitely be more clear, so let me try and clarify here and make a note to clean up the documentation more as well. I'll answer in reverse order:. > Given the above command should I go back to a non-decoy aware transcriptome?. No. What the statement in the documentation means to convey is that if you are using the basic quasi-mapping algorithm (not selective-alignment as enabled by `--validateMappings`, `--mimicBT2` or `--mimicStrictBT2`), then you should not be using a decoy-aware transcriptome. We have not tested the effect of decoys on the basic quasi-mapping approach, and though that may be supported in the future, it is not right now. However, if you are using any flavor of selective-alignment, then please _do_ use the decoy-aware transcriptome. . Regarding ""combining"" `--validateMappings`, `--mimicBT2` and `--mimicStrictBT2`, this is not possible. That is, you should view `--mimicBT2` and `--mimicStrictBT2` as ""meta-flags"" that enable selective-alignment and also set a few other options that are meant to mimic the BT2 behavior more closely. We generally do _not_ recommend `--mimicStrictBT2`, and so the main choice is between simply using `--validateMappings` vs. `--mimicBT2`. The main differences here are that `--mimicBT2` sets slightly more sensitive parameters to find alignments, but is also stricter in what it reports. The biggest differences is that `--validateMappings` will allow orphaned mappings (where one end of a paired-end fragment aligns but the mate doesn't), while `--mimicBT2` will not allow such mappings. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/399#issuecomment-511884297:428,validat,validateMappings,428,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/399#issuecomment-511884297,8,['validat'],['validateMappings']
Security,"Hi @jeremymsimon! In order to test and validate the implementation I would need a count matrix generated on samples. Do you have a sample and count matrix from that? The Rosenberg submission of the data has an unclear way of specifying barcodes and I have emailed him about it. If you have count matrix and matching fastqs that we can use to validate, we can wrap it up soon.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-982878463:39,validat,validate,39,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-982878463,2,['validat'],['validate']
Security,"Hi @jeremymsimon, to answer your last question:. > As for the barcode detection - my usual approach with alevin at least is to let it try to estimate a ""real"" cell number, but if it's way off from our experimental expectations, to inject --expectCells ncells and let that serve as a starting point (with subsequent filtering). That has worked reasonably well in the past for me , and seems to be an option for alevin-fry as well. I don't know whether that is poor practice in the long run...it came from a place of seeing far too many weak knee plots early in the droplet scRNA-seq days. Are you generally more trusting of these estimates these days?. So one of the nice aspects of the alevin to alevin-fry pipeline is that it's relatively easy to try different filtering approaches since the initial mapping process only has to happen once. In general, the knee detection method is pretty good, and often gives a reasonable cell count. However, this isn't always the case. What we find in the alevin-fry pre-print is that it tends to be slightly more conservative than if you did e.g. unfiltered quantification followed by filtering with something like `DropletUtils` (but usually only slightly). The knee method is basically the iterative knee finding procedure from UMI-tools, with some slight tweaks to the parameters. However, unlike alevin, alevin-fry also supports unfiltered quantification. In this case, you provide an `unfiltered-permitlist`, which is a set of acceptable barcodes (not necessarily all expected to be present), and alevin-fry will correct against this. This will tend to produce a _lot_ of quantified cells, since we quantify any barcode matching 10 or more reads (by default, this value is modifiable on the command line). So, such unfiltered matrices definitely need to be filtered after quantification. However, for protocols with an external permit list, or those where you can reasonably derive a list of potential expected barcodes, it's less stringent and therefore po",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-988967759:231,inject,inject,231,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-988967759,1,['inject'],['inject']
Security,"Hi @junaruga,. Sorry for the slow reply; I was on vacation the beginning of this week, so internet access has been touch-and-go. Anyway, the hanging of the `unit_tests` seems a problem to me. They should all complete very quickly, and the fact that it is hanging there suggests to me something else is going wrong.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/276#issuecomment-415634849:99,access,access,99,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/276#issuecomment-415634849,1,['access'],['access']
Security,"Hi @k3yavi,. Thank you for your reply!. > The Central issue is that the technologies to profile open-chromatin regions expects the read to align majorly to non-coding regions and salmon/alevin framework is designed to work (generally) with transcriptomic data. Having said that, one can potentially index the full genome using salmon indexing but we have not yet extensively validated the genomic alignment generated from alevin framework. Yes, this was the first issue I encountered and tried to work around. My attempt to a solution was - as both you and @rob-p suggested - to find a way of binning the reference so it would be treated similarly to transcripts. The underlying thought was that if for scRNA-seq the reference transcriptome acts as a collection of features that the reads are ""compared"" to, the equivalent for scATAC-seq would be known peaks of open chromatin in the given organism/developmental stage/tissue/etc. But please correct me if I'm wrong in this assumption, I am a wet lab-trained biologist trying to understand the analysis tools to my best capability. So at the moment I have a ""reference peak set"" for my scATAC-seq data. I generated this by combining MACS2-called peaks from bulk ATAC-seq I have for the same developmental time-point of both parental and hybrid lines (as I mentioned, I'm working with cross-species hybrids). I used the coordinates from this `mergedPeaks.bed` to extract a `mergedPeaks.fa` from the whole `referenceGenome.fa`, does this sound reasonable?. -Anna",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/611#issuecomment-758575486:375,validat,validated,375,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/611#issuecomment-758575486,1,['validat'],['validated']
Security,"Hi @knokknok,. Would it be possible to share a small subset of these reads that reproduce the issue? Basic thoughts : does it work without `--validateMappings`? Are the read files synchronized (i.e. are there the same number of left and right reads)?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/228#issuecomment-393240942:142,validat,validateMappings,142,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/228#issuecomment-393240942,1,['validat'],['validateMappings']
Security,"Hi @leagleag,. Thank you for your question. This is because with selective alignment (`--validateMappings`) salmon is making use of [range-factorized equivalence classes](https://academic.oup.com/bioinformatics/article/33/14/i142/3953977), which do not directly correspond to the ""standard"" notion of equivalence classes. In fact, as of the next release, it will _always_ make use of these equivalence classes by default. This leads to potentially confusing results when used in conjunction with `--dumpEq`. Specifically, the range-factorized equivalence relation group fragments not only by the transcripts to which they map, but also with respect to the conditional probabilities of having generated that fragment & alignment score given each transcript. Practically, what happens is that the space of conditional probabilities is quantized, and an equivalence relation is defined based on both the transcript set and the vector of conditional probability bins into which the mapping falls with respect to each transcript in the equivalence class. This means that range-factorized equivalence classes can have multiple classes of fragments that map to the same set of transcripts, but with different conditional probabilities. Additionally, for each bin, the average conditional probability of fragments arising from that bin is maintained. What you are seeing printed out are the transcript sets, followed by the conditional bin indexes. Starting in the next release (and currently in the develop branch), we've cleaned up the interaction of the range-factorized equivalence classes with the `--dumpEq` and `--dumpEqWeights` flags. If you run with the `--dumpEqWeights` flags, salmon will dump the transcript sets, followed by the conditional probability vector, followed by the fragment count. If you run with the `--dumpEq` flag, it will collapse all of the range-factorized equivalence classes into ""simple"" equivalence classes by combining classes with the same transcript set (but different co",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/402#issuecomment-517041654:89,validat,validateMappings,89,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/402#issuecomment-517041654,2,['validat'],['validateMappings']
Security,"Hi @mathog,. > Is it really the case that Salmon cannot use 1.57.0?. It may be able to. We set the minimum required version to the lowest boost version we use in any of our testing machines where we run regression tests. Currently, this is 1.59.0. If you change the relevant `CMakeLists.txt` line, you *really* need to make sure you clear out the CMake cache. You can do this by removing `CMakeCache.txt` in your build directory, as well as the directory `CMakeFiles`. However, it might be easiest just to remove and remake the entire `build` directory. You may also try passing `-DBoost_NO_SYSTEM_PATHS=Bool:ON` to your cmake command. Finally, note that the build system is probably looking for the static libraries --- you can elide that preference by modifying [this line](https://github.com/COMBINE-lab/salmon/blob/master/CMakeLists.txt#L222). Finally, since salmon uses C++11, it's important that whatever boost you link against exposes a C++11 compatible ABI. Unfortunately, `FindBoost.cmake` is the most finicky of the module finding packages I know about 😦. If you use `-DFETCH_BOOST=TRUE`, then CMake will fetch a recent boost and build the libraries it needs and link them statically. I realize you want to avoid this, so hopefully one of the ideas above will help.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/236#issuecomment-396781869:934,expose,exposes,934,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/236#issuecomment-396781869,2,['expose'],['exposes']
Security,"Hi @mishaprochazka and @jdidion,. Thanks @jdidion for pinging me on this. Somehow, Gmail has decided that all GitHub notifications (except those that explicitly tag me, but somehow I missed this one) should go to SPAM. So, I've been missing some of the newer issues here. The short answer is that the documentation needs to be updated. When salmon was originally published, we made use of [RapMap](https://github.com/COMBINE-lab/RapMap) as the underlying mapper, which performed quasi-mapping against an index that consisted of a suffix array and a hash over k-mers pointing to prefixes in the suffix array (similar to the strategy used by STAR, but using much longer k-mers to improve lookup speed). We referred to this index as the quasi-index. As the software evolved and we continued to improve the mapping methodology, we eventually transitioned over to an index based on [our pufferfish data structure](https://github.com/COMBINE-lab/pufferfish). In addition to the new data structure, this coincided with our move over to selective-alignment as the mapping algorithm, and all of this happened at the 1.0.0 release (this is why, for example, indices built before 1.0.0 are not compatible with salmon > 1.0.0; a topic on which there have been a few GitHub issues). However, given the fact that the documentation and software are linked only through manual human intervention (we haven't leveled up to e.g. having salmon be a [literate program](https://en.wikipedia.org/wiki/Literate_programming) yet), these two sometimes get out of sync. This is an instance of that. We have maintained the functionality of the `--writeMappings` feature, and in fact, even augmented it. However, we have not replaced the antiquated `quasi-index` terminology in the documentation. The TLDR is that you can use `--writeMappings` with the index you built with the `salmon index` command, and it should work fine. If you are mapping against an index without decoy sequences, then the output format will be basically ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/727#issuecomment-996192524:549,hash,hash,549,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/727#issuecomment-996192524,1,['hash'],['hash']
Security,"Hi @najibveto,. I do not have access to a windows machine, unfortunately, so I can not test this directly. It would seem that somehow the appropriate version of `libstdc++` is not available or is not being found? I would recommend to raise this issue over on the [`bioconda` repository](https://github.com/bioconda/bioconda-recipes/issues) or in their [gitter channel](https://app.gitter.im/#/room/#bioconda_Lobby:gitter.im). Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/864#issuecomment-1660467862:30,access,access,30,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/864#issuecomment-1660467862,1,['access'],['access']
Security,"Hi @nh13,. This is not something for which we currently have support or something that we currently plan. I'd be open to it, but I'm honestly not sure how to cleanly do it in the current architecture, and doing so would certainly incur a performance hit. Salmon runs 2 phases of inference; and online phase and an offline phase. The online phase has access to _fragment-level_ information that is then summarized away during the offline phase (like the specific locations of each read, the length of each observed fragment, etc.). That information goes away when the reads are summarized into range-factorized equivalence classes. Moreover, some of the model parameters learned during the online phase will depend (in their details) on the order in which observations are made. Ostensibly, observing the same data in the same order **and issuing updates to shared model parameters from worker threads in the same order** should result in identical values, however this has never been tested and was never a design goal. The reason for this is that differences between runs are within the bounds of the inherent inferential uncertainty of the estimated parameters anyway. That is, if one is relying on a specific value at a level of precision such that a different run of salmon would produce a value different enough to change a downstream analysis, then one is imparting more precision on the estimates than they can provide. Other methods that produce identical results between runs for these values may produce the same output, but the accuracy of the output at that level shouldn't be trusted in this case. The uncertainty of the parameter estimates can be evaluated based on the Gibb samples (or bootstrap replicates) that salmon computes. Of course, the small differences between runs rarely lead to differences in downstream analysis (almost certainly at the gene level and also at the transcript level if you use a differential testing method that is aware of inferential uncertainty). On the ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/102#issuecomment-2159300538:350,access,access,350,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/102#issuecomment-2159300538,2,['access'],['access']
Security,"Hi @phickner,. Any update on this? How does the BAM file look under ValidateSamFile or some such?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/323#issuecomment-450573944:68,Validat,ValidateSamFile,68,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/323#issuecomment-450573944,1,['Validat'],['ValidateSamFile']
Security,"Hi @phickner,. The error message seems to be coming from the library we use to parse the BAM file (https://github.com/jkbonfield/io_lib/blob/master/io_lib/bam.c#L329). Is it possible that somehow the BAM itself is ill-formed? Maybe as determined by [picard ValidateSamFile](https://broadinstitute.github.io/picard/command-line-overview.html#ValidateSamFile) or some such?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/323#issuecomment-442697747:257,Validat,ValidateSamFile,257,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/323#issuecomment-442697747,2,['Validat'],['ValidateSamFile']
Security,"Hi @qifei9,. Thanks for the question and for pointing out the need for update in the docs. Regarding your first question, both approaches (3) and (2) seem reasonable to me. I would *not* try approach (1) as this will eliminate the benefit of the stranded library for the targets where you do know the orientation. For approach (2) , I'd either use `--validateMappings` or at least set `--rangeFactorizationBins 4` (the former implies the latter). As for what value to set for `--incompatPrior`, the effect should be reasonably robust across a range of values, the question is how unlikely _a priori_ would you expect a mapping not in `ISR` orientation to be if you also observed a mapping in `ISR` ... probably very unlikely (you could try e.g. 1e-10 or some such). Approach 3 is also also reasonable, though what you might consider doing is looking at the abundances for these opposite strands of the same sequence post quantification --- you should generally see that one of the two has a non-zero expression, or at least one orientation should have a much higher expression than the other (for expressed transcripts, at least, this might give you evidence as to the true strand of origin). Regarding your second point, the changelog is correct. In recent versions of salmon, `--incompatPrior` is 0 by default. We'll update the documentation accordingly.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/332#issuecomment-450929631:351,validat,validateMappings,351,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/332#issuecomment-450929631,1,['validat'],['validateMappings']
Security,"Hi @rached-97,. First of all, thank you for the _incredibly-detailed_ report. All of the information you provided made it easy to pull down the data and to test what might be going on. I pulled down the first sample, consisting of `SRR9071838_1.fastq` and `SRR9071838_2.fastq`, which was recognized as `IU` for you. . However, since I didn't have access to the annotation you used or the specific scripts you used to extract the transcriptome reference, I instead quantified directly against [gencode v37](ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_37/gencode.v37.transcripts.fa.gz). When I did this, salmon calls the library format type as `ISR`, which is what we would expect. The `lib_format_count.json` is as such:. ```; {; ""read_files"": ""[ SRR9071838_1.fastq.gz, SRR9071838_2.fastq.gz]"",; ""expected_format"": ""ISR"",; ""compatible_fragment_ratio"": 1.0,; ""num_compatible_fragments"": 31944161,; ""num_assigned_fragments"": 31944161,; ""num_frags_with_concordant_consistent_mappings"": 29445487,; ""num_frags_with_inconsistent_or_orphan_mappings"": 2576421,; ""strand_mapping_bias"": 0.000022006283676957945,; ""MSF"": 0,; ""OSF"": 0,; ""ISF"": 648,; ""MSR"": 0,; ""OSR"": 0,; ""ISR"": 29445487,; ""SF"": 1098610,; ""SR"": 1477163,; ""MU"": 0,; ""OU"": 0,; ""IU"": 0,; ""U"": 0; }; ```. As you can see, the strand mapping bias reported is `0.000022006283676957945` (to an insanely higher level of precision than we actually need). This is, of course, drastically different from the value of `0.36810071818291797` that showed up in your table for this sample. While it is true that salmon is quite conservative about calling a library as stranded (i.e. it would rather make the mistake of calling stranded library as unstranded than vice-versa, as the latter would discard reads while the former would not), in this case it looks like the culprit is likely the transcriptome reference being used. When quantified under the standard gencode transcriptome, this sample is inferred as `ISR` with very high confidence ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/655#issuecomment-825393464:347,access,access,347,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/655#issuecomment-825393464,1,['access'],['access']
Security,"Hi @red-plant,. So, I have some update from our end. @mohsenzakeri dug into the data a bit (specifically `SRR7985407`). What he found is that there are a considerable number of reads (~13%) have long stretches of polyA or polyT that are matching in a hyper-repetitive manner internally within a certain set of transcripts (i.e. these are not matching polyA tails, because those are already trimmed). These matches are, obviously, minimally informative, but we had not special-cased ignoring them yet. Specifically, what seems to be prevalent in these reads are read pairs where one read has polyA, the other has polyT, and the keep matching to the same positions. However, the rest of the reads don't match the transcript, so a bunch of time is wasted on validating (and discarding) these mappings. To test this hypothesis, we made a small change to the mapping algorithm to special case and ignore k-mers that are purely homopolymers. I'll note that in this data, this has no effect on the mapping rate. I get the following performance profile running the trimmed version of this data (having trimmed with `fastp`) using 4 threads, and _without_ the additional `--hitFilterPolicy BOTH` flag. ```; 1306.86user 4.79system 4:42.54elapsed 464%CPU (0avgtext+0avgdata 592704maxresident)k; ```. I was wondering if you might test this altered version out and see if it has a similarly beneficial effect for you as well. Probably, the time will be different, since the processors themselves are, and since I elided all non-essential flags here, but I would hope this version is faster than the current (even with the altered `hitFilterPolicy`). You can find a tarball with the pre-compiled binary [here](https://drive.google.com/file/d/1tPyOPW3Y8l86RS0-zBRLh0wCt3VTpkNw/view?usp=sharing). It should work on any relatively recent linux system.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/527#issuecomment-637568013:755,validat,validating,755,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/527#issuecomment-637568013,1,['validat'],['validating']
Security,"Hi @red-plant,. This is actually an issue that is a result of the range-factorized equivalence classes that are induced by the validate mappings option. We noticed this side-effect of range-factorization in our own testing, and the issue causing it was fixed in 0.13.0. However, it is worth noting that `--validateMappings` will generally map reads in a much more sensitive way than the default quasi-mapping, and so it is likely that if a read maps to one allele, it will also map to the other but with a lower alignment score (which the algorithm accounts for during quantification). If you really only want to consider the best mappings for a read, and not weight read assignments by alignment score, then you can use the `--hardFilter` option that is also introduced in 0.13.0. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/347#issuecomment-469750859:127,validat,validate,127,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/347#issuecomment-469750859,2,['validat'],"['validate', 'validateMappings']"
Security,"Hi @rob-p ,. It works! Thank you so much!; I tried all of the k-mer values in your advice (19, 21, 23, 25) for building indices and set the `--minAssignedFrags` parameter rather small to 3 and got a pretty nice mapping rate. And among them `-k` of 19 seemed to have the highest mapping rate. . Please let me know if anything looks abnormal!. Here is the command I used for indexing (same for `-k` = 19, 21, 23, 25):. `salmon index -t gencode.v40.transcripts.fa.gz -k 19 -p 12 -i salmon_index_19 --gencode`. And here is my command for quantification:. `salmon quant -i ../ref/salmon_index_19 -l IU -1 SRR493372_1.fastq SRR493373_1.fastq SRR493374_1.fastq SRR493375_1.fastq SRR493376_1.fastq SRR493377_1.fastq -2 SRR493372_2.fastq SRR493373_2.fastq SRR493374_2.fastq SRR493375_2.fastq SRR493376_2.fastq SRR493377_2.fastq --validateMappings --minAssignedFrags 3 -o transcripts_quant_19`. And the log file for indexing:. > [2022-04-16 11:15:45.756] [jLog] [info] building index ; out : salmon_index_23 ; [2022-04-16 11:15:45.778] [puff::index::jointLog] [info] Running fixFasta [Step 1 of 4] : counting k-mers ; [2022-04-16 11:15:46.377] [puff::index::jointLog] [warning] Entry with header [ENST00000682202.1|ENSG00000243480.8|OTTHUMG00000011023.3|-|AMY2A-204|AMY2A|19|processed_transcript|], had length less than equal to the k-mer length of 23 (perhaps after poly-A clipping) [2022-04-16 11:15:49.574] [puff::index::jointLog] [warning] Entry with header [ENST00000603775.1|ENSG00000271544.1|OTTHUMG00000184300.1|OTTHUMT00000468575.1|ENST00000603775|ENSG00000271544|23|processed_pseudogene|], had length less than equal to the k-mer length of 23 (perhaps after poly-A clipping) [2022-04-16 11:15:52.071] [puff::index::jointLog] [warning] Entry with header [ENST00000632684.1|ENSG00000282431.1|OTTHUMG00000190602.2|OTTHUMT00000485301.2|TRBD1-202|TRBD1|12|TR_D_gene|], had length less than equal to the k-mer length of 23 (perhaps after poly-A clipping) [2022-04-16 11:15:55.682] [puff::index::jointLog] [w",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/768#issuecomment-1100734317:821,validat,validateMappings,821,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/768#issuecomment-1100734317,1,['validat'],['validateMappings']
Security,"Hi @rob-p ,. Yes that's one aspect. But also, Salmon uses CIGAR to evaluate alignment probability in alignment quantification mode no?. And with just RapMap output you would lose other information that Salmon uses to determine likely fragment assignment?. With UMI's you can deduplicate fragments _before_ inferring where they were likely to come from. Ideally you would deduplicate the reads directly based on UMI, then you wouldn't have to think about PCR duplication in the quantification. But of course keeping a hash of all reads in a FASTQ and accounting for dequencing errors wouldn't be really tractable..",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/108#issuecomment-268994712:517,hash,hash,517,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/108#issuecomment-268994712,1,['hash'],['hash']
Security,"Hi @rob-p ,; I used the latest version of salmon, and you were right, the difference between two database decreased a little bit, but still affect my downstream analysis. So I'm wondering should I change or add some options when run salmon quantification step to count for the different reads between two databases? Now I'm using the same script for both NCBI and ENSEMBL quantification except using related index file as below:. ./salmon-latest_linux_x86_64/bin/salmon quant -i index -l A -r SRR.fastq -p 8 --numBootstraps 100 --validateMappings --writeMappings=../mapinfo.sam -o pat1 . As you mentioned the NCBI find the best locus to assign reads and ENSEMBL match the reads better, so should I use different parameters when quantify reads for these two databases? Thank you.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/525#issuecomment-639000029:530,validat,validateMappings,530,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/525#issuecomment-639000029,1,['validat'],['validateMappings']
Security,"Hi @rob-p . Sorry, but we couldn't test again the index I used to report the issue. Instead, we used a smaller one with the following characteristics:. ```; counted k-mers for 16040000 transcripts; Elapsed time: 726.738s. Replaced 5730782 non-ATCG nucleotides; Clipped poly-A tails from 530 transcripts; Building rank-select dictionary and saving to disk done; Elapsed time: 13.1116s; Writing sequence data to file . . . done; Elapsed time: 118.505s; [info] Building 64-bit suffix array (length of generalized text is 12671064288 ); Building suffix array . . . success; saving to disk . . . done; Elapsed time: 877.586s; done; Elapsed time: 3607.17s; processed 12671000000 positions; khash had 5905993560 keys; saving hash to disk . . . done; Elapsed time: 1249.59s; [2017-03-22 06:39:06.131] [jLog] [info] done building index; ```. Using this new index and salmon v0.8.2 precompiled binaries we didn't have any problems. Hope this helps. Thanks!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/129#issuecomment-288675236:718,hash,hash,718,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/129#issuecomment-288675236,1,['hash'],['hash']
Security,"Hi @rob-p,. We ran the tests you requested and the main problem remains. The memory load is lower than before, but for some reason `Salmon` (0.8.2) only works in the SGE cluster we have access to when we increase the memory limits (just like 0.7.2). (Edit: we used 0.8.2 to build a new index). I'll ask the cluster admins as they might have a clue on how to proceed. ## Low memory test. ### bash script. ```bash; #!/bin/bash; #$ -cwd; #$ -l mem_free=14G,h_vmem=15G,h_fsize=100G; #$ -N step6-salmon_test3.gsk_phaseII; #$ -pe local 1; #$ -o ./logs/salmon_test3.$TASK_ID.txt; #$ -e ./logs/salmon_test3.$TASK_ID.txt; #$ -t 1-3; #$ -hold_jid pipeline_setup,step4-featCounts-alzheimer.gsk_phaseII; #$ -m e; echo ""**** Job starts ****""; date. echo ""**** JHPCE info ****""; echo ""User: ${USER}""; echo ""Job id: ${JOB_ID}""; echo ""Job name: ${JOB_NAME}""; echo ""Hostname: ${HOSTNAME}""; echo ""Task id: ${TASK_ID}"". FILE1=$(awk 'BEGIN {FS=""\t""} {print $1}' /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk ""NR==${SGE_TASK_ID}""); if [ TRUE == ""TRUE"" ] ; then; FILE2=$(awk 'BEGIN {FS=""\t""} {print $3}' /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk ""NR==${SGE_TASK_ID}""); fi; ID=$(cat /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk '{print $NF}' | awk ""NR==${SGE_TASK_ID}""). mkdir -p /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test3/${ID}. /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon quant 	-i /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts -p 1 -l ISR 	-1 ${FILE1} -2 ${FILE2} 	-o /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test3/${ID}. echo ""**** Job ends ****""; date; ```. ### Example log file. ```; **** Job starts ****; Wed Mar 29 14:51:10 EDT 2017; **** JHPCE info ****; User: lcollado; Job id: 110315; Job name: step6-salmon_test3.gsk_phaseII; Hostname: compute-061; Task id: ; Version Info: This is the most recen",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-290516965:186,access,access,186,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-290516965,1,['access'],['access']
Security,"Hi @rudondamba,. There are a few options. If it's less than ~10MB, then you can just drop the file into the text box in the GitHub web interface here, and it will upload it and provide a link. If it's a few hundred MB or so, as is typical of many transcriptomes, the best thing to do might be to put it up on Google Drive or Box or Dropbox (whatever you have access to) and share a link. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/683#issuecomment-879989898:359,access,access,359,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/683#issuecomment-879989898,1,['access'],['access']
Security,"Hi @s1corley,. Congratulations on your publication! The `--noLengthCorrection` flag has been around for a long time (e.g. where it is suggested in the post to which @tamuanand [links](https://groups.google.com/forum/#!msg/sailfish-users/VIfqBwgF6xQ/fw-rgC_kAwAJ)). However, given our limited access to QuantSeq and our limited (student) bandwidth to do extensive testing on alternative tech, we have kept this flag marked as experimental. As I mention above, it was introduced since, _conceptually_, the QuantSeq protocol should not exhibit a length effect and so the one may not wish to account for the length when determining assignment probabilities during the variational Bayesian optimization. However, the empirical testing of this has been limited. Now that your paper is published, and contains what look to be some _very through_ assessment methodologies, we may be able to look into this and determine if there is anything we can do to, perhaps, optimize salmon even more for accurate quantification from the QuantSeq protocol. We would welcome any suggestions or feedback you may have. Congratulations again on the paper!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-565474848:292,access,access,292,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-565474848,2,['access'],['access']
Security,"Hi @tamuanand ,. I think these are very important question and thanks for raising the issue.; As you mention, In the preprint we put out two different modes of Selective Alignment:; A) SA: The mashmap and bedtools based pipeline which follows old [SalmonTools](https://github.com/COMBINE-lab/SalmonTools/blob/master/README.md) based pipeline.; B) SAF: Inbuilt salmon pipeline to consume genome and follows [this](https://combine-lab.github.io/alevin-tutorial/2019/selective-alignment/) pipeline. The distinction between the two comes from how the decoy sequence are actually generated. To answer your question point wise.; 1.) That's correct SAF based pipeline follows the tutorial as mentioned in B above and uses the full genome as decoys.; 2.) That's correct, if a user wan't to run SA method, then they should follow mashmap based tutorial A. This might be useful for situation where the index is too big to fit into the machine's memory.; 3.) That's also correct, yes if you don't provide decoys `-d` you can still run salmon on the transcriptome. We have just enabled the validateMapping option by default, which is also used in transcriptome only mode, currently there is no option to _disable_ it.; 4) That's also correct, we have dropped the quasi-mapping based support from the latest version, If you need to run quasi we have released `0.15` just as a last version into the archive.; 5 & 6) Very good question, short answer is your default pipeline of VBEM is the recommended way. We have to use additional flags `--mimicBT2 and --useEM` while comparing the methods in the preprint. RSEM can only do EM and as we were comparing against Bowtie2 we have to mimic it with more stricter requirements for fair comparison. We expect the performance to be better with VB based optimization and not using `mimcBT2` . @rob-p Feel free to add if I missed something.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/442#issuecomment-549187035:1078,validat,validateMapping,1078,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/442#issuecomment-549187035,1,['validat'],['validateMapping']
Security,"Hi @tamuanand ,; Thanks for raising this doubt. SA is already integrated into the salmon environment i.e. you just have to re index salmon using the `generateDecoyTranscriptome.sh` script from [here](https://github.com/COMBINE-lab/SalmonTools) and run salmon quant as you usually do w/ the `--validateMappings` additional command line flag.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/365#issuecomment-499297622:293,validat,validateMappings,293,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/365#issuecomment-499297622,1,['validat'],['validateMappings']
Security,"Hi @tamuanand,. Nope; these values are right. The `indexVersion` is a global identifier with respect to previous versions of salmon. It is a global number that is incremented each time (a) a backward-incompatible change to the index is introduced or (b) a fundamentally new piece of information is contained in the index. This field took a value of `1` way back when we started versioning the salmon index a number of years ago, and version `1` was based on the RapMap index (rather than pufferfish like the current one). This is simply a global identifier that we can use internally to determine whether the version of salmon reading this index can be expected to make use of it. The other field `indexType` corresponds to the value from an internal enumeration used in the salmon code. Over the years (since it was first released in 2014), salmon has used a number of different data structures for its underlying index. First, it used a modified version of the FMD index that BWA is based upon, then, it used the RapMap index (based upon a sparse hash map and an uncompressed suffix array), and now it uses the pufferfish index. This `indexType` filed just records the type of this index. In modern (post 1.0.0) versions of salmon, the pufferfish index (`2`) is the only valid version. There's a lot of history to these values, but they all make sense internally within salmon, which is how the contents of this file are primarily used (i.e. to make sure there is compatibility between the version of salmon being run and the index we are trying to consume). Hopefully, this description clears things up a bit. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/504#issuecomment-613217080:1049,hash,hash,1049,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/504#issuecomment-613217080,2,['hash'],['hash']
Security,"Hi @tamuanand,. Thanks @k3yavi for pointing out the major idea. Just to fill in some more details. The implementation of SA is, as Avi mentions, part of the mainline salmon code now (in the develop and master branch). We link, in the README, to some pre-constructed decoy-aware transcriptomes, but you can build your own for any organism where you have the transcriptome, the genome, and an annotation, using the script Avi linked to. There are a few ways to enable selective alignment, and the details are listed with the relevant flags in the release notes (we will be updating the documentation shortly with more detailed examples as well). Specifically, you can pass salmon the `—validateMappings` flag, which turns on selective alignment with some reasonable default parameters. You can, instead, pass the flag `—mimicBT2`, which is a meta-flag that enables selective alignment, and turns on a few other things that make the alignments more similar to the Bowtie2 parameters we discuss in the paper (e.g. it disallows orphan alignments). Finally, there is the `—mimicStrictBT2` flag, which mimics Bowtie2 parameters that disallow indels; however, we generally don’t recommend this flag unless you have a particular reason for using it. For any of these, once you’ve built a decoy-aware index, you need not do anything else special during quantification. We’ll ping back here with more details once we have more examples in place etc.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/365#issuecomment-499303095:684,validat,validateMappings,684,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/365#issuecomment-499303095,1,['validat'],['validateMappings']
Security,"Hi @tamuanand,. Thanks again for your detailed questions and thoughts on this issue. Just to follow-up / expand a bit on what @k3yavi has said (and to answer your other question): Yes, one would imagine that, given the details of the QuantSeq protocol, turning off length correction would make the most sense. The main reason this flag is listed as _experimental_, is simply that it was designed based on the expected characteristics of the protocol. Conceptually, the protocol is performing tagged-end sequencing, and so there should be little-to-no length effect. However, since we haven't done extensive internal validation on QuantSeq data, we have left this flag as experimental until it is further tested by ourselves or others. > Also @rob-p , weren't you referring to the RSEM caveat with QuantSeq data analysis wherein one cannot ask RSEM to disable lengthCorrection and hence the count statistics might be misleading?. Correct; as far as we are aware, there is no way to disable the built-in length-dependent assumptions of RSEM. One could use the `--estimate-rspd` flag to allow learning of a non-uniform read distribution (the equivalent of `--posBias` in salmon), though it's unclear / unlikely if this would be as effective as fully disabling the length correction for this type of tagged-end data. If you have any good empirical assessment mechanism for QuantSeq data, and a chance to test out these different salmon options, we'd be happy to get feedback and discuss details further!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-565285540:616,validat,validation,616,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-565285540,2,['validat'],['validation']
Security,"Hi @teshomem ,. We are working on resolving this issue just waiting for few other things to resolve before making a new tagged release.; In the meantime you can resolve this issue by replace the hash in [this](https://github.com/COMBINE-lab/salmon/blob/master/CMakeLists.txt#L522) line by `00a8b2798c498507572e24c2db7bf4896f05b760a38ed9ba566ffd348a7c6cef `.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/153#issuecomment-331260342:195,hash,hash,195,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/153#issuecomment-331260342,1,['hash'],['hash']
Security,"Hi @vd4mmind,. Indeed, @mdshw5 is spot on. The issue you're seeing is a result of the hash table doubling failing to allocate sufficient memory when attempting to build a hash table for all 31-mers in the mouse genome. In addition to the memory requirements of building a quasi-index on the genome (which we're actually working to mitigate b/c we think it could be useful in another context), this won't be particularly useful for quantification. Salmon treats each entry in the multifasta file as a distinct transcriptional target. Thus, here, even if the index did build successfully, you'd be quantifying the abundance of different chromosomes & contigs, rather than the transcripts. What you should do (as pointed out by @mdshw5 above), is to grab a file that contains the mouse transcripts (or take your mm9 genome and an appropriate gtf file and use a tool like `gffread` to extract the transcript sequences).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/49#issuecomment-197873003:86,hash,hash,86,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/49#issuecomment-197873003,2,['hash'],['hash']
Security,"Hi Avi,. Here is the salmon log from one of my PE libraries. There are only 12; libraries for each in the directory, which is why I got confused when it; said 13. I will try putting in all of the file names and let you know how; it goes. Thank you for all of your help. Sara. [2019-07-29 15:58:39.034] [jointLog] [info] Fragment incompatibility prior; below threshold. Incompatible fragments will be ignored.; [2019-07-29 15:58:39.034] [jointLog] [info] Usage of --validateMappings; implies use of minScoreFraction. Since not explicitly specified, it is; being set to 0.65; [2019-07-29 15:58:39.034] [jointLog] [info] Usage of --validateMappings,; without --hardFilter implies use of range factorization.; rangeFactorizationBins is being set to 4; [2019-07-29 15:58:39.034] [jointLog] [info] Usage of --validateMappings; implies a default consensus slack of 0.2. Setting consensusSlack to 0.2.; [2019-07-29 15:58:39.034] [jointLog] [info] parsing read library format; [2019-07-29 15:58:39.034] [jointLog] [error] Failed to successfully parse; any complete read libraries. Please make sure you provided arguments; properly to -1, -2 (for paired-end libraries) or -r (for single-end; libraries), and that the library format option (-l) *comes before* the read; libraries. On Mon, Jul 29, 2019 at 4:06 PM Avi Srivastava <notifications@github.com>; wrote:. > Oh Sorry about that what I meant was the salmon.log file or the the; > meta-info.json file created by salmon in the output directory. You can; > check what files salmon is detecting it seems there are 12 files in the; > mate1 and 13 files in the mate2. Can you confirm there are 13 pairs of file; > in that directory and their regex is same as you are using ? Can you also; > try putting the names of the file instead * as regex ?; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/COMBINE-lab/salmon/issues/408?email_source=notifications&email_token=AEHDXAA5DH",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/408#issuecomment-516514620:465,validat,validateMappings,465,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/408#issuecomment-516514620,3,['validat'],['validateMappings']
Security,"Hi Brian,. In general, I would argue that one should be cautious with removing PCR duplicates in RNA-seq data (unless you are dealing with reads with UMI tags). This is because reads that align to the same reference position can easily have come from alternative transcripts sharing the same underlying sequence. Hence, the normal tests used to infer PCR duplicates with e.g. DNA-seq reads can yield false-positives in RNA-seq. This is particularly true for highly abundant transcripts (or transcripts from highly-abundant genes). We are currently working on the code that will do duplicate removal when UMI tags are present. That methodology can be extended to remove duplicates even without UMI tags --- though I'd generally caution against that for the reasons mentioned above. However, for the time being, if you have a strong need or desire to filter PCR duplicates, you could use alignment-based Salmon with a BAM file that has duplicates removed. Finally, regarding the error you are getting during SAM validation; this sounds like a different issue. Would you mind providing a piece of that SAM file for me to take a look at? Specifically, I don't believe the quasi-mapping output file should even contain unmapped reads (unless you consider unmapped mates of orphaned reads). --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/136#issuecomment-305317281:1010,validat,validation,1010,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/136#issuecomment-305317281,1,['validat'],['validation']
Security,"Hi Kadir,. So, the short answer is that on a _single sample_ the `-g` flag and `tximport` do something very similar. However, the real benefit of `tximport` is that it has access to _all_ of the samples when doing transcript to gene-level aggregation. . So, while Salmon with the `-g` flag will estimate the average expressed gene length in each sample, `tximport` will also have knowledge of how the average gene length varies across all samples. Also, `tximport` provides a few different options for how, exactly, you wish to aggregate. Generally, the `-g` option is completely reasonable, but `tximport` is the same in the simple case and better in the general case.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/169#issuecomment-341731522:172,access,access,172,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/169#issuecomment-341731522,2,['access'],['access']
Security,"Hi Kimon,. I was able to access the file with no problem. Unfortunately, I don't seem able to reproduce the issue! I grabbed the 0.7.1 release, in case there were any differences between that and the latest develop version that I usually use, and I tried to index your fasta. ```; ./salmon index -t ~/salmon/build/Homo_sapiens.GRCh37.transcripts.fa -i idx; Version Info: ### A newer version of Salmon is available. ####; ###; The newest version, available at https://github.com/COMBINE-lab/salmon/releases; contains some new features and minor bug fixes; please upgrade at your; earliest convenience.; ###; index [""idx""] did not previously exist . . . creating it; [2016-11-04 12:41:37.805] [jLog] [info] building index; RapMap Indexer. [Step 1 of 4] : counting k-mers; counted k-mers for 30000 transcripts[2016-11-04 12:41:39.312] [jointLog] [warning] Entry with header [ENST00000415118], had length less than the k-mer length of 31 (perhaps after poly-A clipping); [2016-11-04 12:41:39.312] [jointLog] [warning] Entry with header [ENST00000434970], had length less than the k-mer length of 31 (perhaps after poly-A clipping); [2016-11-04 12:41:39.312] [jointLog] [warning] Entry with header [ENST00000448914], had length less than the k-mer length of 31 (perhaps after poly-A clipping); [2016-11-04 12:41:39.380] [jointLog] [warning] Entry with header [ENST00000439842], had length less than the k-mer length of 31 (perhaps after poly-A clipping); [2016-11-04 12:41:39.380] [jointLog] [warning] Entry with header [ENST00000390567], had length less than the k-mer length of 31 (perhaps after poly-A clipping); [2016-11-04 12:41:39.380] [jointLog] [warning] Entry with header [ENST00000452198], had length less than the k-mer length of 31 (perhaps after poly-A clipping); [2016-11-04 12:41:39.380] [jointLog] [warning] Entry with header [ENST00000390569], had length less than the k-mer length of 31 (perhaps after poly-A clipping); [2016-11-04 12:41:39.380] [jointLog] [warning] Entry with header [EN",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/100#issuecomment-258484912:25,access,access,25,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/100#issuecomment-258484912,1,['access'],['access']
Security,"Hi Kivanc,. Thanks for the kind words, and thank you for the _extremely detailed_ report. Reports like this are a model of what every developer wishes a user did before filing an issue :). First, let me clear up what seems like might be a small source of confusion. Since both of the salmon runs are from v1.1.0, _neither_ of these are making use of quasi-mapping. Specifically, newer versions of salmon _only_ perform selective alignment (and this makes the `--validateMappings` command line argument redundant in newer versions, though we keep it so as to maximize backward compatibility with command line parameters people may be using). So, the main difference between your two salmon runs is inclusion of the decoy set. This almost certainly means that the reads that map in your second set of salmon runs but not your first are being assigned to decoys in the first case. To try and get a better handle on this, could you upload a `meta_info.json` file from both runs? This file lives in the `aux_info` directory, and it will provide information about e.g. how many reads were best mapped to decoys and were discarded for this reason. The guarantee you get from the selective alignment is that, if the fragment is discarded by decoy mapping, it maps _strictly better_ to the decoy than to the non-decoy sequence. There are many reasons this could happen. One is rRNA contamination, another could be that reads are coming from processed pseudogenes that are not properly in your annotation, yet a third is that your sample has a considerable fraction of reads spanning exon-intron junctions (in this case, the read will map better to the corresponding location on the genome, and worse to the annotate transcript where the intronic sequence is not present). Now, figuring out exactly which of these cases you are in is a bit more difficult, but one approach would be to pick one of the samples with the biggest differences and map to the reads to the genome with e.g. STAR or HISAT2 to see what y",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/479#issuecomment-578848875:462,validat,validateMappings,462,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/479#issuecomment-578848875,2,['validat'],['validateMappings']
Security,"Hi Nick,. If that doesn't work, you can use [this](https://github.com/COMBINE-lab/salmon/files/197982/SalmonBeta-0.6.5-pre_CentOS5.tar.gz) salmon executable to try the perfect hash indexing. If you pass the `--perfectHash` flag when indexing, it will use the minimum perfect hash rather than Google's dense hash. Also, please use this executable anyway when _quantifying_ your reads, as it fixes a potential bug with 64-bit indices in the older release.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/53#issuecomment-203994051:176,hash,hash,176,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/53#issuecomment-203994051,3,['hash'],['hash']
Security,"Hi Nick,. No problem at all; sorry for not providing a better explanation (I'm planning on writing one up for when this feature is listed in the next official release). In terms of strategy, my recommendation would be to use the default (the `dense hash`) unless indexing memory becomes a problem. The main differences are the following:; - The perfect hash uses an external memory algorithm to construct the hash function, and so requires less memory.; - Because the perfect hash function is built in external memory, **construction** of the hash using this data structure is sower. I don't have longitudinal benchmarks, but it is somewhere between 2 and 5x slower to populate the perfect hash than the dense hash.; - Once constructed, the perfect hash is _considerably_ smaller, and so quantification on an index built using a perfect hash will require only ~50% of the memory that is required when using a dense hash. Obviously if you're quantifying on the same machine that was able to build the index, this isn't a problem. However, if you're shipping the index to smaller memory computers, then this is something to consider.; - The performance difference in terms of mapping speed is very minimal; the minimum perfect hash can be 5-10% slower than the dense hash, but this difference is usually only a matter of seconds. Also, the total runtime difference can be even less since the smaller perfect hash can be read more quickly from disk than the larger dense hash. So, the standard recommendation would be use the default unless you run into memory problems building the index; in that case, try enabling the `--perfectHash` flag.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/53#issuecomment-204069238:249,hash,hash,249,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/53#issuecomment-204069238,14,['hash'],['hash']
Security,"Hi Rob, . For example, here is the log output when I try to index the GENCODE Human transcript set v36, using the below code;. salmon index --keepDuplicates -k 35 --gencode -t gencode.v36.transcripts.fa -i Human_v36_Index_k35. Here is where the phrase is found in the log, and is then repeated a lot until the end. Number of ones: 1309432; Number of ones per inventory item: 512; Inventory entries filled: 2558; 1309432; [2021-02-15 04:42:27.548] [puff::index::jointLog] [info] Done wrapping the rank vector with a rank9sel structure.; [2021-02-15 04:42:27.565] [puff::index::jointLog] [info] contig count for validation: 1,309,432; [2021-02-15 04:42:28.338] [puff::index::jointLog] [info] Total # of Contigs : 1,309,432; [2021-02-15 04:42:28.339] [puff::index::jointLog] [info] Total # of numerical Contigs : 1,309,432; [2021-02-15 04:42:28.404] [puff::index::jointLog] [info] Total # of contig vec entries: 7,119,643; [2021-02-15 04:42:28.404] [puff::index::jointLog] [info] bits per offset entry 23; [2021-02-15 04:42:28.590] [puff::index::jointLog] [info] Done constructing the contig vector. 1309433; [2021-02-15 04:42:29.459] [puff::index::jointLog] [info] # segments = 1,309,432; [2021-02-15 04:42:29.459] [puff::index::jointLog] [info] total length = 188,284,293; [2021-02-15 04:42:29.548] [puff::index::jointLog] [info] Reading the reference files ...; [2021-02-15 04:42:31.594] [puff::index::jointLog] [info] positional integer width = 28; [2021-02-15 04:42:31.594] [puff::index::jointLog] [info] seqSize = 188,284,293; [2021-02-15 04:42:31.595] [puff::index::jointLog] [info] rankSize = 188,284,293; [2021-02-15 04:42:31.595] [puff::index::jointLog] [info] edgeVecSize = 0; [2021-02-15 04:42:31.595] [puff::index::jointLog] [info] num keys = 143,763,605; len should not be greater than 64.; ...; ...; ...; len should not be greater than 64.; [2021-02-15 05:07:13.459] [puff::index::jointLog] [info] finished populating pos vector; [2021-02-15 05:07:13.460] [puff::index::jointLog] [info] wr",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/632#issuecomment-779416548:610,validat,validation,610,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/632#issuecomment-779416548,1,['validat'],['validation']
Security,"Hi Rob, thanks for the quick reply.; I tried what you suggested and I tried with adding the bioconda channel but still got the same error, however adding the conda-forge and bioconda channels to the conda config solved it. Maybe it needed access to conda-forge to find the boost and libcxx packages?. ```; $ conda config --add channels conda-forge; $ conda config --add channels bioconda; $ conda create -n salmon salmon=0.9.1; Solving environment: done. ## Package Plan ##. environment location: /Users/Jb_Macbook/miniconda3/envs/salmon. added / updated specs: ; - salmon=0.9.1. The following packages will be downloaded:. package | build; ---------------------------|-----------------; tk-8.6.7 | 0 3.0 MB conda-forge; mkl_random-1.0.1 | py36_0 371 KB conda-forge; boost-1.64.0 | py36_4 304 KB conda-forge; libiconv-1.15 | 0 1.3 MB conda-forge; clangdev-4.0.0 | default_0 62.8 MB conda-forge; bzip2-1.0.6 | 1 145 KB conda-forge; xz-5.2.3 | 0 304 KB conda-forge; certifi-2018.1.18 | py36_0 143 KB conda-forge; pip-9.0.3 | py36_0 1.7 MB conda-forge; tbb-2018_20171205 | 0 404 KB conda-forge; boost-cpp-1.64.0 | 1 16.2 MB conda-forge; ncurses-5.9 | 10 1.1 MB conda-forge; jemalloc-4.5.0 | 0 4.1 MB bioconda; salmon-0.9.1 | 1 2.6 MB bioconda; numpy-1.14.2 | py36ha9ae307_1 4.0 MB; sqlite-3.20.1 | 2 1.4 MB conda-forge; setuptools-39.0.1 | py36_0 552 KB conda-forge; llvmdev-4.0.0 | default_0 100.9 MB conda-forge; icu-58.2 | 0 22.7 MB conda-forge; readline-7.0 | 0 383 KB conda-forge; libcxx-4.0.0 | 1 1.1 MB conda-forge; zlib-1.2.11 | 0 95 KB conda-forge; libxml2-2.9.8 | 0 1.9 MB conda-forge; wheel-0.31.0 | py36_0 62 KB conda-forge; python-3.6.5 | 1 13.9 MB conda-forge; mkl_fft-1.0.1 | py36_1 146 KB conda-forge; ------------------------------------------------------------; Total: 241.7 MB; ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/192#issuecomment-379821279:239,access,access,239,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/192#issuecomment-379821279,1,['access'],['access']
Security,"Hi Rob,. All of the different single-cell library prep methods put the cellular barcodes and UMI in different places; what we've been doing is sticking that information in the read name so we have access to it post alignment. Valentine has this awesome repository: https://github.com/vals/umis that does that part via fastqtransform, and has example regexes for a bunch of the different commonly used chemistries:. https://github.com/vals/umis/tree/master/examples. It might be easiest to support the format that Vals is spitting out and assume the user has stuck that information in the read name as a first go rather than re-implement that stuff.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/108#issuecomment-269070288:197,access,access,197,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/108#issuecomment-269070288,1,['access'],['access']
Security,"Hi Rob,. I did some follow up using your suggestions, and I had indexed my; transcriptome incorrectly, but now it appears that I am having a separate; issue and was hoping that you might be able to point me in the right; direction? Here is my command:. ```#!/bin/bash -l; #SBATCH -J male_salmon_map; #SBATCH -t 150:00:00; #SBATCH -p high; #SBATCH --cpus-per-task=24; source ~/.bashrc; source activate salmon; cd /home/seboles/abaloneraw/salmon_quantification/SALMON_MALE/; for i in *.qc.fq.gz; do; salmon quant -i maleredabalone_index --libType IU -1 *R1_001.qc.fq.gz -2; *R2_001.qc.fq.gz ${i} -o ${i}_quant --seqBias --gcBias --validateMappings; done```. And here is the error message that I receive:. ```[2019-07-29 14:31:12.352] [jointLog] [error] You passed paired-end files; to salmon, but you passed 12 files to --mates1 and 13 files to --mates2.; You must pass the same number of files to both flags; Name : male_salmon_map; User : seboles; Partition : high; Nodes : c11-71; Cores : 24; GPUs : 0; State : FAILED; Submit : 2019-07-29T14:31:01; Start : 2019-07-29T14:31:02; End : 2019-07-29T14:31:13; Reserved walltime : 6-06:00:00; Used walltime : 00:00:11; Used CPU time : 00:00:09; % User (Computation): 54.66%; % System (I/O) : 45.33%; Mem reserved : 2000M/core; Max Mem used : 0.00 (c11-71); Max Disk Write : 0.00 (c11-71); Max Disk Read : 0.00 (c11-71)```. I have gone back and checked the directory containing the PE reads, and; they are all accounted for, so I am a little stumped at the moment. I; appreciate any advice you may have. Happy Monday,. Sara. On Wed, Jul 24, 2019 at 3:04 PM Rob Patro <notifications@github.com> wrote:. > Hi @seboles <https://github.com/seboles> ,; >; > My guess is that the issue is related to this (non-salmon) error appearing; > before each salmon output:; >; > basename: extra operand ‘lightreceptor-1_S114_L005_R1_001.qc.fq.gz’; >; > Try 'basename --help' for more information.; >; >; > it looks like there is an error in the way the paths to the files ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/408#issuecomment-516173395:629,validat,validateMappings,629,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/408#issuecomment-516173395,1,['validat'],['validateMappings']
Security,"Hi Rob,. I don't have git (don't have root access on the red hat server im on). I downloaded the salmon-master.zip, and then tried running the following:. ```; [bernsteinnj@lngnode1 salmon-master]$ cmake . . -- The C compiler identification is GNU 4.4.7; -- The CXX compiler identification is GNU 4.4.7; -- Check for working C compiler: /usr/bin/cc; -- Check for working C compiler: /usr/bin/cc -- works; -- Detecting C compiler ABI info; -- Detecting C compiler ABI info - done; -- Check for working CXX compiler: /usr/bin/c++; -- Check for working CXX compiler: /usr/bin/c++ -- works; -- Detecting CXX compiler ABI info; -- Detecting CXX compiler ABI info - done; CMake Error at CMakeLists.txt:69 (message):; Salmon requires g++ 4.7 or greater.; ```. I'm trying now with -k 27 with the original build I had. Keep you updated. Best",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/53#issuecomment-203018082:43,access,access,43,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/53#issuecomment-203018082,1,['access'],['access']
Security,"Hi Rob,. Thank you for really quick response. Also thanks for your comment on the report. Always trying to pay attention on documenting/reproducibility, and great to hear that it was helpful. . I was not so sure about writing ""quasi-mapping"". It sometimes gets confusing with all that terms so thank you for clarifying that. It's also good to know about `--validateMappings` argument and selective alignment. I will be keeping that in mind. Please find below meta_info.json files from both runs for two different samples:. _**From a sample with low mapping rate**_:; <details><summary>meta_info for salmon run with decoys</summary>; <p>. ```json; {; ""salmon_version"": ""1.1.0"",; ""samp_type"": ""bootstrap"",; ""opt_type"": ""vb"",; ""quant_errors"": [],; ""num_libraries"": 1,; ""library_types"": [; ""ISF""; ],; ""frag_dist_length"": 1001,; ""seq_bias_correct"": true,; ""gc_bias_correct"": true,; ""num_bias_bins"": 4096,; ""mapping_type"": ""mapping"",; ""num_valid_targets"": 82785,; ""num_decoy_targets"": 384,; ""num_eq_classes"": 14170,; ""serialized_eq_classes"": false,; ""eq_class_properties"": [; ""range_factorized""; ],; ""length_classes"": [; 657,; 1257,; 1868,; 2701,; 18586; ],; ""index_seq_hash"": ""4f69fdca155ff281a9051bf6f31831edd7e1f71ec8cf630564a59346d82a9791"",; ""index_name_hash"": ""7da07d00d0c1890fdedeb25e843c19981ff38fa5cdb3c2f1af25c0ff0b7aeb3e"",; ""index_seq_hash512"": ""f7410be132f10bc0aa56a9513037be738d843ec5c1326aee3eefc7af479d138630673b84705982fbbbd4783c66b40b6eccd83c4933a87220efd3ee5f3ff84d62"",; ""index_name_hash512"": ""6eb2d9569579e6fc9ecf832b8ce8b67482edaf6b6773afff0660644bda1f7ea27585ffbd53fcc50bf35495cad2a21ebde2b300e6954cdcf30be05d4b49538925"",; ""index_decoy_seq_hash"": ""b766133ec97b898f1cc1d25ec9240e9e8a54ae82cb5fa7494fe8347b6ea60b21"",; ""index_decoy_name_hash"": ""39a1e89e06638787f331ee368746cac8f09ab519442650f2bfdd6606dffa5e24"",; ""num_bootstraps"": 100,; ""num_processed"": 11225446,; ""num_mapped"": 3069202,; ""num_decoy_fragments"": 6809189,; ""num_dovetail_fragments"": 52039,; ""num_fragments_filtered_vm"": 68778",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/479#issuecomment-578980727:357,validat,validateMappings,357,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/479#issuecomment-578980727,1,['validat'],['validateMappings']
Security,"Hi again @GWW,. We have a hotfix for this that we are currently testing, but feel free to try it out if you have a chance. If you download the source from [here](https://github.com/COMBINE-lab/salmon/archive/hash-resize-hotfix.zip), or checkout the branch `hash-resize-hotfix`, you can pass alevin an extra hidden option `--maxHashResizeThreads` that allows you to limit the maximum number of threads used during the hash table resize. If you use `--maxHashResizeThreads 1`, at most one extra thread should be created during hash table resizing. Hopefully, this should fix the issue occurring in your execution environment. If so, please let us know so we can merge the fix back into develop (and then master).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-395907924:208,hash,hash-resize-hotfix,208,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-395907924,4,['hash'],"['hash', 'hash-resize-hotfix']"
Security,"Hi guys,. Which existing dependencies would you like to be able to use? There are some of these libraries that cannot be replaced by already installed variants. Specifically,; - BWA --- since the version that is pulled in and used actually requires we expose certain functionality for our lightweight alignment procedure (though this dependency may go away all together if we deprecate lightweight alignment in favor of quasi-mapping).; - Jellyfish --- here, we require the ability to use jellyfish as a library. Specifically, we rely on some headers that are not installed with the standard package. Perhaps here there could be some synergy with Guillaume on making all of the things Salmon uses part of the standard Jellyfish install, but, at least currently, this isn't the case. The CMake build system already looks for existing versions of the following before fetching them:; - Boost; - tbb; - jemalloc. So, the the remaining guys are `libgff` (which is just some small libraryification of a gff parser that I put together a while ago, I don't know that it's in any package manager --- is it? It doesn't even have an associated install script) and `staden IO lib`. For Staden, I'd be happy to have it look for an existing installation, but there is no FindStaden.cmake that I know of, and I don't really know how to write FindX.cmake files appropriately. However, I'd be happy to learn and / or accept pull requests.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/19#issuecomment-193559957:252,expose,expose,252,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/19#issuecomment-193559957,2,['expose'],['expose']
Security,"Hi rob-p,; `gcc -version ` tells me its version `6.3.0` of the GCC compiler. . ```; c+\+ -v; Using built-in specs.; COLLECT_GCC=c++; COLLECT_LTO_WRAPPER=/usr/libexec/gcc/x86_64-alpine-linux-musl/6.3.0/lto-wrapper; Target: x86_64-alpine-linux-musl; Configured with: /home/buildozer/aports/main/gcc/src/gcc-6.3.0/configure --prefix=/usr --mandir=/usr/share/man --infodir=/usr/share/info --build=x86_64-alpine-linux-musl --host=x86_64-alpine-linux-musl --target=x86_64-alpine-linux-musl --with-pkgversion='Alpine 6.3.0' --enable-checking=release --disable-fixed-point --disable-libstdcxx-pch --disable-multilib --disable-nls --disable-werror --disable-symvers --enable-__cxa_atexit --enable-default-pie --enable-cloog-backend --enable-languages=c,c++,objc,java,fortran,ada --disable-libssp --disable-libmpx --disable-libmudflap --disable-libsanitizer --enable-shared --enable-threads --enable-tls --with-system-zlib --with-linker-hash-style=gnu; Thread model: posix; gcc version 6.3.0 (Alpine 6.3.0); ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/162#issuecomment-343658308:927,hash,hash-style,927,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/162#issuecomment-343658308,1,['hash'],['hash-style']
Security,"Hi, I have some kind the same error. I download the prebuild index from refgenie and I got exactly the same error message. . refgenie pull hg38/salmon_sa_index <- I downloaded the 16Gb of the index files. [2020-05-04 21:30:58.648] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2020-05-04 21:30:58.648] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2020-05-04 21:30:58.648] [jointLog] [info] Usage of --validateMappings, without --hardFilter implies use of range factorization. rangeFactorizationBins is being set to 4; [2020-05-04 21:30:58.648] [jointLog] [info] Usage of --validateMappings implies a default consensus slack of 0.2. Setting consensusSlack to 0.2.; [2020-05-04 21:30:58.648] [jointLog] [info] parsing read library format; [2020-05-04 21:30:58.648] [jointLog] [info] There is 1 library.; [2020-05-04 21:30:58.701] [jointLog] [info] Loading Quasi index; Exception : [rapidjson internal assertion failure: IsObject()]; salmon quant was invoked improperly.; For usage information, try salmon quant --help; Exiting. The son files of the index show this;; ls -lrth *json; -rwxrwxrwx 1 usr usr 1007 dic 14 00:41 info.json; -rwxrwxrwx 1 usr usr 96 dic 14 00:44 versionInfo.json. Any idea would be really appreciated,. Kind regards, ; Fer",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/251#issuecomment-623664770:393,validat,validateMappings,393,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/251#issuecomment-623664770,3,['validat'],['validateMappings']
Security,"Hi, Rob, thanks for the quick reply! By the way, great job on salmon!. Using ./ did fix the issue. About the stdout issue, I'm running:. ~/programs/Salmon-0.7.2_linux_x86_64/bin/salmon quant -i /data/reference/salmon/gencode.grch37.v19/ -r test.fastq --seqBias --gcBias --posBias -p 12 --geneMap /data/reference/salmon/gencode.grch37.v19/geneMap.txt --libType U -o x --writeMappings > out.sam. and not all messages are output to stderr (I'm not using 2> ). The ones starting with ### do, but others end up in out.sam. out.sam starts with:. ESC[1m[2016-09-14 11:37:38.908] [jointLog] [info] parsing read library format; ESC[00mESC[1m[2016-09-14 11:37:38.908] [jointLog] [info] There is 1 library.; ESC[00mESC[1m[2016-09-14 11:37:43.996] [jointLog] [info] Loading Quasi index; ESC[00mESC[1m[2016-09-14 11:37:43.996] [jointLog] [info] Loading 32-bit quasi index; ESC[00mESC[1m[2016-09-14 11:37:43.996] [stderrLog] [info] Loading Suffix Array ; ESC[00mESC[1m[2016-09-14 11:38:06.669] [stderrLog] [info] Loading Transcript Info ; ESC[00mESC[1m[2016-09-14 11:38:12.374] [stderrLog] [info] Loading Rank-Select Bit Array; ESC[00mESC[1m[2016-09-14 11:38:12.444] [stderrLog] [info] There were 95309 set bits in the bit array; ESC[00mESC[1m[2016-09-14 11:38:12.700] [stderrLog] [info] Computing transcript lengths; ESC[00mESC[1m[2016-09-14 11:38:12.700] [stderrLog] [info] Waiting to finish loading hash; ESC[00mESC[1m[2016-09-14 11:39:49.792] [stderrLog] [info] Successfully loaded position hash; ESC[00mESC[1m[2016-09-14 11:39:49.792] [stderrLog] [info] Done loading index; ESC[00mESC[1m[2016-09-14 11:39:49.792] [jointLog] [info] done; ESC[00mESC[1m[2016-09-14 11:39:49.792] [jointLog] [info] Index contained 95309 targets; ESC[00mESC[33mESC[1m[2016-09-14 11:40:18.128] [jointLog] [warning] Fragment GC bias correction is currently only implemented for paired-end libraries. Disabling fragment GC bias correction for this run; ESC[00m@HD VN:1.0 SO:unknown",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/90#issuecomment-247078586:1388,hash,hash,1388,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/90#issuecomment-247078586,2,['hash'],['hash']
Security,"Hi,. I think keeping this all in one issue is best. First, i applaud your Herculean effort! I don't have access to a FreeBSD or OpenBSD box, which is partly why we hadn't seen these issues. I can look into this, but testing is hard b/c i don't have the target environment. In the meantime, if you are just trying to use the software, perhaps give the Docker image a try (as i hear Docket can be cajoled to work on FreeBSD).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/162#issuecomment-337396709:105,access,access,105,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/162#issuecomment-337396709,1,['access'],['access']
Security,"Hi,; I'm having a similar issue with specification of library type. I'm quantifying a single-end library of type SF with salmon 1.3.0. ; The two commands being compared are:. auto detect:. salmon --no-version-check quant --writeMappings -i target --incompatPrior 0.0 --validateMappings -l A -r d218056_dedup.fastq -p 4 -o d218056_A.quant > d218056_A.sam. specify SF:. salmon --no-version-check quant --writeMappings -i target --incompatPrior 0.0 --validateMappings -l SF -r d218056_dedup.fastq -p 4 -o d218056_SF.quant > d218056_SF.sam. The log files indicate that salmon correctly identifies the library as SF in the auto case. I noticed the issue when examining a pair of genes with overlapping 3'UTRs. The forward strand gene (GQ67_03478) is expressed at a much lower level than the reverse strand gene (GQ67_03479). The sam files contain the same number of reads mapped to each transcript without regard to how the libtype is specified:. egrep -v '^@' d218056_A.sam|grep -c GQ67_03478 ; 382; egrep -v '^@' d218056_A.sam|grep -c GQ67_03479; 399; egrep -v '^@' d218056_SF.sam|grep -c GQ67_03478 ; 382; egrep -v '^@' d218056_SF.sam|grep -c GQ67_03479; 399. The quantitation is very different with 120 counts assigned to the forward strand gene in the A case and a much more accurate (based on examination of the sam file) 10 counts in the SF case:. grep GQ67_03478 d218056_A.quant/quant.sf ; GQ67_03478T0 2914 2664.000 202.831978 119.926. grep GQ67_03478 d218056_SF.quant/quant.sf ; GQ67_03478T0 2914 2664.000 17.066270 10.000. For the reverse strand gene, the auto case undercounts due to reads being assigned to the forward strand gene. grep GQ67_03479 d218056_A.quant/quant.sf ; GQ67_03479T0 1383 1133.000 1245.013842 313.074. grep GQ67_03479 d218056_SF.quant/quant.sf ; GQ67_03479T0 1383 1133.000 1589.051981 396.000. I've been using salmon with -l A thinking that if the software correctly recognizes the libtype, the results would be nearly identical to explicitly specifying the libtype but th",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/489#issuecomment-738804437:269,validat,validateMappings,269,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/489#issuecomment-738804437,2,['validat'],['validateMappings']
Security,"Hm, that could be it. All accessions that are having this problem with `851443704` bytes are `/home/user/data_store/TRANSCRIPTOME_INDEX/MUS_MUSCULUS/short`. . Here's that TXI: https://s3.amazonaws.com/data-refinery-s3-transcriptome-index-circleci-prod/MUS_MUSCULUS_TRANSCRIPTOME_SHORT.tar.gz",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/321#issuecomment-442542353:26,access,accessions,26,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/321#issuecomment-442542353,1,['access'],['accessions']
Security,"Hm. I had to tweak a few bits in the cmake file for it to compile here due; to the firewall I'm behind (generally no ftp access) so it must have been a; side effect of that. I tried to make sure I was starting from a clean slate; to verify before posting, but guess I wasn't. Jason. On Tue, Jun 9, 2015 at 4:12 PM, Rob Patro notifications@github.com wrote:. > Strange! I should still be using Jellyfish 2.1.3 (; > https://github.com/COMBINE-lab/salmon/blob/master/CMakeLists.txt#L355).; > I'm not sure why it was fetching 2.2.0 for you. Anyway, I'm glad that this; > seems to resolve the error with the bias correction --- thanks for; > reporting back here. I'll probably roll this and a few other small changes; > into a v0.4.1 soon.; > ; > —; > Reply to this email directly or view it on GitHub; > https://github.com/COMBINE-lab/salmon/issues/5#issuecomment-110489862.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/5#issuecomment-110492510:83,firewall,firewall,83,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/5#issuecomment-110492510,2,"['access', 'firewall']","['access', 'firewall']"
Security,"I agree completely with that complaint. Originally, I started using TBB instead of OpenMP because OSX's clang compiler didn't have OpenMP support. It's possible I will revisit this decision in the future, as I think that is no longer the case. On the other hand, this bug looks not to be TBB's fault. I pushed a fix, but then I explicitly resized the hash *before* setting the max thread count. I just pushed an update to this branch --- can you see if that helps?. Thanks!; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-396093096:351,hash,hash,351,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-396093096,1,['hash'],['hash']
Security,"I have tried to dichotomise my transcript db. The 2nd transcript in the attached file, crashes with the 2x12 paired-end fastq I have tried (ISR or IU). index was generated with:; salmon index -t test.fa --gencode -k 31 -i index. quantification with:; salmon quant -i index -l A -1 /tmp/r1.fastq.gz -2 /tmp/r2.fastq.gz --validateMappings -o test",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/228#issuecomment-393482153:320,validat,validateMappings,320,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/228#issuecomment-393482153,1,['validat'],['validateMappings']
Security,I haven't found a desktop with enough memory to run it (the one I have access to has only 8Gb). I will try to reproduce there if I have the chance. Have you managed to make alevin work on the sets of FASTQ I linked?,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/328#issuecomment-449157274:71,access,access,71,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/328#issuecomment-449157274,1,['access'],['access']
Security,"I processed the data above using the latest salmon from the develop branch; (the release candidate for 1.3.0), and I got the following time (used 8; threads, so timing is not directly comparable). ```; 4604.57user 43.64system 9:24.15elapsed 823%CPU; ```. The whole log is. ```; [2020-06-15 23:51:54.747] [jointLog] [info] setting maxHashResizeThreads to; 8; [2020-06-15 23:51:54.747] [jointLog] [info] Fragment incompatibility prior; below threshold. Incompatible fragments will be ignored.; [2020-06-15 23:51:54.747] [jointLog] [info] Usage of --validateMappings; implies use of minScoreFraction. Since not explicitly specified, it is; being set to 0.65; [2020-06-15 23:51:54.747] [jointLog] [info] Usage of --validateMappings; implies a default consensus slack of 0.2. Setting consensusSlack to 0.35.; [2020-06-15 23:51:54.747] [jointLog] [info] parsing read library format; [2020-06-15 23:51:54.747] [jointLog] [info] There is 1 library.; [2020-06-15 23:51:54.814] [jointLog] [info] Loading pufferfish index; [2020-06-15 23:51:54.814] [jointLog] [info] Loading dense pufferfish index.; [2020-06-15 23:51:55.555] [jointLog] [info] done; [2020-06-15 23:51:55.555] [jointLog] [info] Index contained 116,248 targets; [2020-06-15 23:51:55.588] [jointLog] [info] Number of decoys : 0; [2020-06-16 00:00:59.666] [jointLog] [info] Computed 344,764 rich; equivalence classes for further processing; [2020-06-16 00:00:59.666] [jointLog] [info] Counted 12,956,134 total reads; in the equivalence classes; [2020-06-16 00:00:59.673] [jointLog] [warning] 0.0736383% of fragments were; shorter than the k used to build the index.; If this fraction is too large, consider re-building the index with a; smaller k.; The minimum read size found was 1. [2020-06-16 00:00:59.673] [jointLog] [info] Number of mappings discarded; because of alignment score : 134,091,887; [2020-06-16 00:00:59.673] [jointLog] [info] Number of fragments entirely; discarded because of alignment score : 2,429,390; [2020-06-16 00:00:59.673]",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/537#issuecomment-644520228:547,validat,validateMappings,547,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/537#issuecomment-644520228,2,['validat'],['validateMappings']
Security,"I ran salmon alevin with the additional ``--softclip`` flag as @rob-p suggested. The mapping rate was almost identical compared to results without that flag. . As I didn't include the ``--validateMappings`` flag, changing the ``--minScoreFraction`` wouldn't matter (if I understand the manual correctly). . If these mapping rates are what you have seen for similar data, that is fine for me.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/738#issuecomment-1027231550:188,validat,validateMappings,188,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/738#issuecomment-1027231550,1,['validat'],['validateMappings']
Security,"I think the idea of using memory-mapped IO might be useful, similar to bowtie2's `--mm` option. However, are you sure it's the index loading that's the issue? You may want to look into staging the salmon index on some local scratch space on your compute nodes as the bandwidth will be much greater than your network storage. Additionally, I tend to see IO saturation over our NFS pool from just streaming the FASTQ data to salmon, so you might still be screwed even if you take care of the index IO contribution. Your machines should likely be caching the index in RAM (if you have enough of it) after one access, but you can use a tool to force caching of the index file if you really want (https://serverfault.com/questions/43383/caching-preloading-files-on-linux-into-ram).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/319#issuecomment-442180390:606,access,access,606,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/319#issuecomment-442180390,1,['access'],['access']
Security,"I think this is resolved, right? Since Salmon builds properly in homebrew-science? The next release should solve the external package hashing requirement that they now want to enforce.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/45#issuecomment-285511495:134,hash,hashing,134,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/45#issuecomment-285511495,1,['hash'],['hashing']
Security,"I'm in touch with the people administrating the cluster as well and based on their guidance I ran alevin with exclusive access, however that did not help.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/328#issuecomment-447403587:120,access,access,120,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/328#issuecomment-447403587,2,['access'],['access']
Security,"I've encountered a very similar scenario - I've used STAR for alignment and next ran salmon quant with transcripts data.. I'm also getting the error:. `[2019-01-21 23:11:38.495] [jointLog] [critical] Please provide a reference FASTA file that includes all targets present in the BAM header; If you have access to the genome FASTA and GTF used for alignment`. But the correction suggested above using gttread does not solve my issue.. any suggestions?. Edit: apologies, it appears I forgot to use the `--quantMode TranscriptomeSAM` flag in STAR. now that I had the suggested fix works just fine.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/104#issuecomment-456201406:303,access,access,303,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/104#issuecomment-456201406,1,['access'],['access']
Security,"I've run into this as well, but's proving tricky to track down. I'm by no mean a expert on build chains (or a C/C++ for that matter), but as far as I can figure, this issue seems specific to RedHat systems. I get exactly the same linking error on RH6 and RH7 using any GCC compiler I have access to on those systems (4.8.5, 5.2.0, 7.2.0). Compiling on an Arch system with GCC 9.2.0 (glibc 2.30) sees no issue. Unfortunately I don't have easy access to the same compiler versions on both systems. I'm compiling GCC 5.2.0 (with glibc2.28) on the Arch system to test this now, but it's going to be a little while before I even know if I have a working toolchain that can use it.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/455#issuecomment-558714532:289,access,access,289,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/455#issuecomment-558714532,2,['access'],['access']
Security,"ISR --chromium -p 4 -o BM_1/alevin -1 ./BM_1/run1/bm_S10_L001_R1_001.fastq.gz -2 ./BM_1/run1/bm_S10_L001_R2_001.fastq.gz --maxHashResizeThreads 2 -i /u/user/ref/cellranger/salmon/transcripts_index --tgMap tx2gene.txt; Starting program: /u/user/local/bin/salmon alevin -l ISR --chromium -p 4 -o BM_1/alevin -1 ./BM_1/run1/bm_S10_L001_R1_001.fastq.gz -2 ./BM_1/run1/bm_S10_L001_R2_001.fastq.gz --maxHashResizeThreads 2 -i /u/user/ref/cellranger/salmon/transcripts_index --tgMap tx2gene.txt; [Thread debugging using libthread_db enabled]; Using host libthread_db library ""/lib/x86_64-linux-gnu/libthread_db.so.1"".; warning: File ""/u/user/local/lib64/libstdc++.so.6.0.21-gdb.py"" auto-loading has been declined by your `auto-load safe; -path' set to ""$debugdir:$datadir/auto-load"".; To enable execution of this file add; add-auto-load-safe-path /u/user/local/lib64/libstdc++.so.6.0.21-gdb.py; line to your configuration file ""/u/user/.gdbinit"".; To completely disable this security protection add; set auto-load safe-path /; line to your configuration file ""/u/user/.gdbinit"".; For more information about this security protection see the; ""Auto-loading safe path"" section in the GDB manual. E.g., run from the shell:; info ""(gdb)Auto-loading safe path""; [New Thread 0x7fff7dbff700 (LWP 21437)]; [Thread 0x7fff7dbff700 (LWP 21437) exited]; Version Info: Could not resolve upgrade information in the alotted time.; Check for upgrades manually at https://combine-lab.github.io/salmon; [New Thread 0x7ffefcfff700 (LWP 21653)]; Logs will be written to BM_1/alevin/logs; [New Thread 0x7ffe7cffe700 (LWP 21654)]; [New Thread 0x7ffdfcffd700 (LWP 21655)]; [New Thread 0x7ffd7cffc700 (LWP 21656)]; ### salmon (single-cell-based) v0.10.3; ### [ program ] => salmon; ### [ command ] => alevin; ### [ libType ] => { ISR }; ### [ chromium ] => { }; ### [ threads ] => { 4 }; ### [ output ] => { BM_1/alevin }; ### [ mates1 ] => { ./BM_1/run1/bm_S10_L001_R1_001.fastq.gz }; ### [ mates2 ] => { ./BM_1/run1/bm_S10_L001_R2_",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-396078627:2006,secur,security,2006,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-396078627,1,['secur'],['security']
Security,"In my experience it is normal to get a **much lower** transcriptome mapping rate for rRNA-depleted samples vs polyA-selected samples. . I'm getting ~21% mapping rate (using Gencode 41 transcripts) on human brain RNAseq samples sequenced several years ago using rRNA-depletion protocol (older Illumina Ribo Zero kits).; I was initially shocked (being used to seeing >90% mapping rates from HISAT2/STAR for these samples) but it turns out **this is normal** for this kind of samples, in this context.; HISAT2 reports 96% mapping rate on the same samples, but QC metrics (rnaseqc) for these HISAT2 alignments (using the same Gencode annotation) show a **65% intronic rate** and a **%23.5 exonic rate** (the rest being intergenic etc). So the _exonic rate_ is getting close to what Salmon is showing (and what it measures), thus I suppose it makes sense to see such a low mapping rate for Salmon on these samples.; (kallisto also reports ~21% pseudoaligned percentage on the same samples). I am only a bit disappointed that when I use `--validateMappings` with decoy sequences (whole genome) added, the mapping rate goes down to about **16.7%** -- as some reads map better to the decoys in that case (partially intronic reads etc.), but I also see a `higher number of fragments entirely discarded because of alignment score` (higher `num_fragments_filtered_vm` and much higher `num_alignments_below_threshold_for_mapped_fragments_vm`).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/779#issuecomment-1474291747:1034,validat,validateMappings,1034,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/779#issuecomment-1474291747,1,['validat'],['validateMappings']
Security,"Is there any way to access the CMakeLog info that was not written to stderr/stdout? This is all related to it not running the fetch script, but the stdout doesn't show anything about that.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/181#issuecomment-367755874:20,access,access,20,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/181#issuecomment-367755874,1,['access'],['access']
Security,"It's currently being developed here — https://github.com/COMBINE-lab/RapMap/tree/quasi-mph. Once we're convinced RapMap still behaves correctly when using the perfect hash index, then I have some (not too much) work to do to propagate the necessary changes to Sailfish & Salmon. The option is currently functional. If you grab this branch and build a quasi index using the `-p` option, it will use the emphf library to build the hash rather than a google dense hash (with a concordant decrease in memory usage).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/37#issuecomment-188294669:167,hash,hash,167,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/37#issuecomment-188294669,3,['hash'],['hash']
Security,"It's ignoring the environment variable `$CPPFLAGS` which has the search path for `zlib.h`. ```; $ env |grep CPPFLAGS; CPPFLAGS=-isystem/home/linuxbrew/.linuxbrew/include; ```. This workaround works, but doesn't work on a system without root access. ``` sh; sudo apt-get install libz-dev; ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/45#issuecomment-193960137:241,access,access,241,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/45#issuecomment-193960137,1,['access'],['access']
Security,"It's possible that `Caenorhabditis_elegans.WBcel235.cdna.all.fa.gz` was corrupted during your FTP download, since there's no error correction aside from TCP checksums. You might want to check your file just to make sure:. ```shell; $ md5 Caenorhabditis_elegans.WBcel235.cdna.all.fa.gz ; MD5 (Caenorhabditis_elegans.WBcel235.cdna.all.fa.gz) = 3979cd3a2d5fe408b6261ae5b1d0c4de; ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/210#issuecomment-376924236:157,checksum,checksums,157,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/210#issuecomment-376924236,1,['checksum'],['checksums']
Security,"Looks like I have some sort of conflict going on:. UnsatisfiableError: The following specifications were found to be in conflict:; - libboost -> libcxx >=4.0.1 -> clangdev ==5.0.0 -> llvmdev ==5.0.0; - libcxx 4.0.0* -> clangdev ==4.0.0 -> llvmdev ==4.0.0; Use ""conda info <package>"" to see the dependencies for each package. [https://sites.google.com/site/ummslogos/_/rsrc/1489610858836/home/apple-icon-76x76.png]. Javier E. Irazoqui, PhD; Associate Professor; Department of Microbiology and Physiological Systems; UMass Medical School. 368 Plantation Street; Albert Sherman Center; Room AS8.1053; Worcester, MA 01605. (774) 455-3797; Skype: javierirazoqui. Confidentiality Notice:; This e-mail message, including any attachments, is for the sole use of the intended recipient(s) and may contain confidential, proprietary and privileged information. Any unauthorized review, use, disclosure or distribution is prohibited. If you are not the intended recipient, please contact the sender immediately and destroy or permanently delete all copies of the original message. On Feb 11, 2018, at 11:01 PM, Rob Patro <notifications@github.com<mailto:notifications@github.com>> wrote:. I can't seem to reproduce this locally (OSX 10.13.1). However, what happens if you try:. > conda install salmon=0.9.1. do you see this version as available? Does it try to install it?. —; You are receiving this because you authored the thread.; Reply to this email directly, view it on GitHub<https://github.com/COMBINE-lab/salmon/issues/194#issuecomment-364824034>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AiohHaDPT6VtnW3toOd9kEKLLo2Zjvvcks5tT7e0gaJpZM4SAonB>.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/194#issuecomment-364941997:658,Confidential,Confidentiality,658,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/194#issuecomment-364941997,2,"['Confidential', 'confidential']","['Confidentiality', 'confidential']"
Security,"Man, I was afraid it would be hard to repro _inside_ of GDB. Sorry about that! The solution you found does seem generally useful though. Another possibility is to try to run it outside GDB, but to use `strace` (see the first answer [here](http://unix.stackexchange.com/questions/166541/how-to-know-where-a-program-is-stuck-in-linux)). This would let the program run outside of GDB (where you can repro the issue), but still get access to the stack at the point of the hanging.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267331282:428,access,access,428,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267331282,1,['access'],['access']
Security,"My issue was resolved. Thanks. On Sun, Dec 30, 2018 at 12:07 PM Rob Patro <notifications@github.com> wrote:. > Hi @phickner <https://github.com/phickner>,; >; > Any update on this? How does the BAM file look under ValidateSamFile or; > some such?; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/COMBINE-lab/salmon/issues/323#issuecomment-450573944>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/APvI3l_civHZCPEisrvMD2azctC_EEM1ks5u-PLngaJpZM4Y4K_L>; > .; >",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/323#issuecomment-450704257:214,Validat,ValidateSamFile,214,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/323#issuecomment-450704257,1,['Validat'],['ValidateSamFile']
Security,"NCODEv29/combined_index -l IU ; -1 /home/RnaSeq/fastq/DM_4a_H_1.fq.gz /home/RnaSeq/fastq/DM_4b_H_1.fq.gz /home/RnaSeq/fastq/DM_4c_H_1.fq.gz ; -2 /home/RnaSeq/fastq/DM_4a_H_2.fq.gz /home/RnaSeq/fastq/DM_4b_H_2.fq.gz /home/RnaSeq/fastq/DM_4c_H_2.fq.gz ; -o /home/RnaSeq/salmon_output_files/out/DM4h; Version Info: Could not resolve upgrade information in the alotted time.; Check for upgrades manually at https://combine-lab.github.io/salmon; ### salmon (mapping-based) v0.14.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { /home/RnaSeq/transcriptome_gencode_v29/human_GENCODEv29/combined_index }; ### [ libType ] => { IU }; ### [ mates1 ] => { /home/RnaSeq/fastq/DM_4a_H_1.fq.gz /home/RnaSeq/fastq/DM_4b_H_1.fq.gz /home/RnaSeq/fastq/DM_4c_H_1.fq.gz }; ### [ mates2 ] => { /home/RnaSeq/fastq/DM_4a_H_2.fq.gz /home/RnaSeq/fastq/DM_4b_H_2.fq.gz /home/RnaSeq/fastq/DM_4c_H_2.fq.gz }; ### [ validateMappings ] => { }; ### [ output ] => { /home/RnaSeq/salmon_output_files/out/DM4h }; Logs will be written to /home/RnaSeq/salmon_output_files/out/DM4h/logs; [2019-07-01 12:51:42.856] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2019-07-01 12:51:42.856] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2019-07-01 12:51:42.856] [jointLog] [info] Usage of --validateMappings, without --hardFilter implies use of range factorization. rangeFactorizationBins is being set to 4; [2019-07-01 12:51:42.856] [jointLog] [info] Usage of --validateMappings implies a default consensus slack of 0.2. Setting consensusSlack to 0.2.; [2019-07-01 12:51:42.856] [jointLog] [info] parsing read library format; [2019-07-01 12:51:42.856] [jointLog] [info] There is 1 library.; Exception : [Error: The index version file /home/RnaSeq/transcriptome_gencode_v29/human_GENCODEv29/combined_index/versionInfo.json doesn't seem to exist. Please try re-buil",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/389#issuecomment-507253562:2853,validat,validateMappings,2853,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/389#issuecomment-507253562,1,['validat'],['validateMappings']
Security,"No problem! We're actually working now on an optional use of a perfect hash in the quasi-index. It increases index construction times, but provides the same speed of lookup as the current hash. Also, it reduces the memory usage by a factor of ~2. We just have to figure out how to implement this cleanly in the code base.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/37#issuecomment-187748517:71,hash,hash,71,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/37#issuecomment-187748517,2,['hash'],['hash']
Security,"Oh wow; I had no idea about libgff :). Regarding Jellyfish, there's not a source ""change"" required upstream, rather the fact that I seem to require the `config.h` file that is not installed during the ""normal"" Jellyfish install process. I don't know if you have any idea how one might get around that. Regarding staden, thanks for brining this to my attention. It will probably take a bit for me to wrap my head around the right way to access this information in CMake, but I'll see what I can manage to cobble together on that front (I really wish there was something better, with a less horrendous ""language"" than CMake, but nothing I know of exists that works nearly as well ""out of the box"").",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/19#issuecomment-195436157:436,access,access,436,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/19#issuecomment-195436157,1,['access'],['access']
Security,"Ok, I have an strace file from a hung run. I couldn't attach with gdb because the default system security settings prohibit it. I'll change the settings and try to get a gdb backtrace, but in the meantime, here's the strace log. Note that it was hung for about 2 hours before I was able to collect the log. https://www.dropbox.com/s/zn7qzo55wtcrbyg/salmon-strace.log.gz?dl=0",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267413760:97,secur,security,97,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267413760,1,['secur'],['security']
Security,"Ok, more interesting information. I just pushed a fix for this that will put 0 instead of NAN and output a warning. But I ran this sample with `--validateMappings` introduced a few versions ago, and it seems *none* of the reads map there. This means the orphans that are mapping must be doing so poorly, and `--validateMappings` is taking care of this by getting rid of those reads. With that flag, _none_ of the reads map.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/279#issuecomment-415993406:146,validat,validateMappings,146,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/279#issuecomment-415993406,2,['validat'],['validateMappings']
Security,"Ok, so even v0.9.1, on my machine at least, is not seeing this issue for your index. Can you tell me something about the host OS (VM) on the systems where it is failing?. To answer your other questions, by ""size of the types"" I mean e.g. if you are switching to a 32-bit processor or alternative architecture (very unlikely). One other thought is to try it ""interactively"" on a similar instance. Could it be some sort of issue where the file is being accessed before it has been completely loaded / moved to the target machine? Can you run some sort of checksum validation on the machine before attempting to load the index?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/321#issuecomment-442681478:451,access,accessed,451,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/321#issuecomment-442681478,3,"['access', 'checksum', 'validat']","['accessed', 'checksum', 'validation']"
Security,"Ok, thank you very much.; The problem I had was RAM availability. I enlarged it for 48 and it works.; However, to quantify I had another problem.; I use this command line and I increase to 56 RAM. srun ./salmon-1.5.2_linux_x86_64/bin/salmon quant -i salmon_index \; -l A \; -1 ERR3537668_1.fastq.gz \; -2 ERR3537668_2.fastq.gz \; -o transcripts_DecoyQuant \; --validateMappings \; --numBootstraps 100 \; --gcBias \; --seqBias\; -p 12. And I got this error message:; [2021-11-08 14:35:28.348] [jointLog] [info] Finished Bootstrapping; ERROR: Could not create the directory [""transcripts_quant""]. Please check; that. But actually, it was created.; I really don't understand the message error. Best wishes,; Luciana. On Fri, Nov 5, 2021 at 5:56 PM Rob Patro ***@***.***> wrote:. > Hi @lubios <https://github.com/lubios>,; >; > This suggests that the machine was not able to allocate enough memory to; > perform the requested operation. I would try the following things in order; > to see if they fix the issue. First, try quantifying without the; > decoy-aware index. This doesn't provide the benefits of the decoy sequence,; > but it will ensure that this is, in fact, the problem you are having. If; > that works, try building the decoy-aware index with the --sparse; > parameter. This will build the sparse index instead of the dense index,; > which is a bit smaller and may therefore fit in RAM on the machine where; > you are doing quantification.; >; > Best,; > Rob; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/COMBINE-lab/salmon/issues/717#issuecomment-962058307>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/ADRT5CUYGXBSY3UOX24RTYDUKQLETANCNFSM5HOIMSQQ>; > .; > Triage notifications on the go with GitHub Mobile for iOS; > <https://apps.apple.com/app/apple-store/id1477376905?ct=notification-email&mt=8&pt=524675>; > or Android; > <https://play.google.com/store/apps/details?id",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/717#issuecomment-963995631:361,validat,validateMappings,361,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/717#issuecomment-963995631,1,['validat'],['validateMappings']
Security,"Ok, the assertion is useful. That argument shouldn't be 0. But it's also the case that if Boost validates the arguments appropriately, it shouldn't *hang*.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267856046:96,validat,validates,96,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267856046,1,['validat'],['validates']
Security,"Ok, the missing transcripts (from the reference FASTA) were definitely *the* problem. I created a transcript fasta using the genome FASTA and GTF file that were fed to STAR. Specifically, I used the command:. ```; $ ./gffread -w all_transcripts.fa -g Homo_sapiens.GRCh38.dna.primary_assembly.fa Homo_sapiens.GRCh38.87.gtf; ```. this produced transcript fasta that led to no warnings (fasta sequences not present in BAM) or errors (BAM sequences not present in fasta). This also allowed quantification (with bias correction) to run to completion. @mikelove, can you validate that this fixes things on your end? If so, perhaps @tomsing1 could also validate that this is the same root cause of the issue for him? In that case, I think that the right thing for me to do is to merge in the change that yells very loudly and bails if we find BAM header entries not present in the transcriptome FASTA.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/104#issuecomment-267507316:565,validat,validate,565,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/104#issuecomment-267507316,2,['validat'],['validate']
Security,"Okay, now I am on a physical Ubuntu 19.04. I am leaving out most travails. [Don't allow ubuntu gui to install conda.]. Salmon (in the conda evironment) is going differently ! Skip to Try 2. below for success; Try 1.; Index seemed to go the same as before, using the command [from a script]; salmon index -t decoys/gentrome.fa -d decoys/decoys.txt -i salmonIndexDecoyMouse; but then command; salmon quant -p 3 -i salmonIndexDecoyMouse -l A -1 SRR1818187_2.fastq.gz -2 SRR1818187_1.fastq.gz --validateMappings -o Salmontranscripts_quant; Fails as follows, saying it cannot find a .json file(s); ---------------------------------------------------------------------; (salmon) wayne@Ubuntu19:~/rnaseq$ sh salmonQuantDecoy.sh ; Version Info: This is the most recent version of salmon.; ### salmon (mapping-based) v0.14.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ threads ] => { 3 }; ### [ index ] => { salmonIndexDecoyMouse }; ### [ libType ] => { A }; ### [ mates1 ] => { SRR1818187_2.fastq.gz }; ### [ mates2 ] => { SRR1818187_1.fastq.gz }; ### [ validateMappings ] => { }; ### [ output ] => { Salmontranscripts_quant }; Logs will be written to Salmontranscripts_quant/logs; [2019-08-25 11:40:44.518] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2019-08-25 11:40:44.518] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2019-08-25 11:40:44.518] [jointLog] [info] Usage of --validateMappings, without --hardFilter implies use of range factorization. rangeFactorizationBins is being set to 4; [2019-08-25 11:40:44.518] [jointLog] [info] Usage of --validateMappings implies a default consensus slack of 0.2. Setting consensusSlack to 0.2.; [2019-08-25 11:40:44.518] [jointLog] [info] parsing read library format; [2019-08-25 11:40:44.518] [jointLog] [info] There is 1 library.; Exception : [Error: The index version file salmonIndexDeco",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/419#issuecomment-524651435:491,validat,validateMappings,491,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/419#issuecomment-524651435,1,['validat'],['validateMappings']
Security,"Ran with only --validateMappings and -p 4 options. Wow, it took less than 15 minutes! Thanks a lot to you and your team for looking into this.; Best,; Jose; [salmon_quant.log](https://github.com/COMBINE-lab/salmon/files/4717767/salmon_quant.log)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/527#issuecomment-637581730:16,validat,validateMappings,16,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/527#issuecomment-637581730,1,['validat'],['validateMappings']
Security,"Since I can't reproduce this in an environment I have access to, I'm going to close this for now. However, if it's still an issue that needs to be resolved, please feel free to comment and I'll re-open.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/51#issuecomment-285510844:54,access,access,54,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/51#issuecomment-285510844,1,['access'],['access']
Security,"Sorry :// Another issue... . Version Info: This is the most recent version of salmon.; ### salmon (mapping-based) v1.2.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { /media/usr/Hybrid_02/Unidad_Bioinf/FER_Scripts/Index/hg38/salmon_sa_index/default }; ### [ libType ] => { A }; ### [ gcBias ] => { }; ### [ validateMappings ] => { }; ### [ mates1 ] => { /media/usr/trimmed_fastq_files/PAIRED_trimmed_fastq_files/APSa16_1P.fq.gz }; ### [ mates2 ] => { /media/usr/trimmed_fastq_files/PAIRED_trimmed_fastq_files/APSa16_2P.fq.gz }; ### [ threads ] => { 7 }; ### [ output ] => { /media/usr/quantification/APSa16.fq.gz_quant }; Logs will be written to /media/usr/quantification/APSa16.fq.gz_quant/logs; [2020-05-05 09:19:06.171] [jointLog] [info] setting maxHashResizeThreads to 7; [2020-05-05 09:19:06.171] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2020-05-05 09:19:06.171] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2020-05-05 09:19:06.171] [jointLog] [info] Usage of --validateMappings implies a default consensus slack of 0.2. Setting consensusSlack to 0.35.; [2020-05-05 09:19:06.171] [jointLog] [info] parsing read library format; [2020-05-05 09:19:06.171] [jointLog] [info] There is 1 library.; [2020-05-05 09:19:06.278] [jointLog] [info] Loading pufferfish index; [2020-05-05 09:19:06.278] [jointLog] [warning] The index did not record if the `--keepDuplicates` flag was used. Please consider re-indexing with a newer version of salmon that will propagate this information.; [2020-05-05 09:19:06.278] [jointLog] [info] Loading dense pufferfish index.; -----------------------------------------; | Loading contig table | Time = 30.609 s; -----------------------------------------; size = 36981178; -----------------------------------------; | Loading contig offsets | Time = 1.3312 s; --------------------------",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/518#issuecomment-623910021:336,validat,validateMappings,336,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/518#issuecomment-623910021,2,['validat'],['validateMappings']
Security,"TA_L001_R2_005.fastq.gz 12_CTTGTA_L001_R2_006.fastq.gz 12_CTTGTA_L001_R2_007.fastq.gz 12_CTTGTA_L001_R2_008.fastq.gz 12_CTTGTA_L001_R2_009.fastq.gz 12_CTTGTA_L001_R2_010.fastq.gz 12_CTTGTA_L002_R2_001.fastq.gz 12_CTTGTA_L002_R2_002.fastq.gz 12_CTTGTA_L002_R2_003.fastq.gz 12_CTTGTA_L002_R2_004.fastq.gz 12_CTTGTA_L002_R2_005.fastq.gz 12_CTTGTA_L002_R2_006.fastq.gz 12_CTTGTA_L002_R2_007.fastq.gz 12_CTTGTA_L002_R2_008.fastq.gz 12_CTTGTA_L002_R2_009.fastq.gz 12_CTTGTA_L002_R2_010.fastq.gz }; ### [ threads ] => { 8 }; ### [ celseq2 ] => { }; ### [ dumpCsvCounts ] => { }; ### [ output ] => { /path/to/alevin_outputSingleLibrary/quantSC }; ### [ tgMap ] => { /path/to/gencode_annot/gencode.primary_assembly.v29.tsv }; ### [ whitelist ] => { /path/to/salmon/my_barcode.tsv }. [2018-12-12 15:07:42.022] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2018-12-12 15:07:42.022] [jointLog] [info] Usage of --validateMappings implies use of range factorization. rangeFactorizationBins is being set to 4; [2018-12-12 15:07:42.022] [jointLog] [info] Usage of --validateMappings implies a default consensus slack of 1. Setting consensusSlack to 1.; [2018-12-12 15:07:42.022] [jointLog] [info] Using default value of 0.8 for minScoreFraction in Alevin; [2018-12-12 15:07:42.028] [alevinLog] [info] Processing barcodes files (if Present) . ; processed 74 Million barcodes. [2018-12-12 15:08:51.135] [alevinLog] [info] Done barcode density calculation.; [2018-12-12 15:08:51.135] [alevinLog] [info] # Barcodes Used: 74376522 / 74376522.; [2018-12-12 15:08:51.141] [alevinLog] [info] Done importing white-list Barcodes; [2018-12-12 15:08:51.141] [alevinLog] [warning] Skipping 1 Barcodes with 0 reads; Assuming this is the required behavior.; [2018-12-12 15:08:51.141] [alevinLog] [info] Total 95 white-listed Barcodes; [2018-12-12 15:08:51.144] [alevinLog] [info] Done populating Z matrix; [2018-12-12 15:08:51.146] [alevinL",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/329#issuecomment-446668422:2768,validat,validateMappings,2768,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/329#issuecomment-446668422,1,['validat'],['validateMappings']
Security,"TTGTA_L001_R2_010.fastq.gz 12_CTTGTA_L002_R2_001.fastq.gz 12_CTTGTA_L002_R2_002.fastq.gz 12_CTTGTA_L002_R2_003.fastq.gz 12_CTTGTA_L002_R2_004.fastq.gz 12_CTTGTA_L002_R2_005.fastq.gz 12_CTTGTA_L002_R2_006.fastq.gz 12_CTTGTA_L002_R2_007.fastq.gz 12_CTTGTA_L002_R2_008.fastq.gz 12_CTTGTA_L002_R2_009.fastq.gz 12_CTTGTA_L002_R2_010.fastq.gz }; ### [ threads ] => { 8 }; ### [ celseq2 ] => { }; ### [ dumpCsvCounts ] => { }; ### [ output ] => { /path/to/alevin_outputSingleLibrary/quantSC }; ### [ tgMap ] => { /path/to/gencode_annot/gencode.primary_assembly.v29.tsv }; ### [ whitelist ] => { /path/to/salmon/my_barcode.tsv }. [2018-12-12 15:07:42.022] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2018-12-12 15:07:42.022] [jointLog] [info] Usage of --validateMappings implies use of range factorization. rangeFactorizationBins is being set to 4; [2018-12-12 15:07:42.022] [jointLog] [info] Usage of --validateMappings implies a default consensus slack of 1. Setting consensusSlack to 1.; [2018-12-12 15:07:42.022] [jointLog] [info] Using default value of 0.8 for minScoreFraction in Alevin; [2018-12-12 15:07:42.028] [alevinLog] [info] Processing barcodes files (if Present) . ; processed 74 Million barcodes. [2018-12-12 15:08:51.135] [alevinLog] [info] Done barcode density calculation.; [2018-12-12 15:08:51.135] [alevinLog] [info] # Barcodes Used: 74376522 / 74376522.; [2018-12-12 15:08:51.141] [alevinLog] [info] Done importing white-list Barcodes; [2018-12-12 15:08:51.141] [alevinLog] [warning] Skipping 1 Barcodes with 0 reads; Assuming this is the required behavior.; [2018-12-12 15:08:51.141] [alevinLog] [info] Total 95 white-listed Barcodes; [2018-12-12 15:08:51.144] [alevinLog] [info] Done populating Z matrix; [2018-12-12 15:08:51.146] [alevinLog] [info] Done indexing Barcodes; [2018-12-12 15:08:51.146] [alevinLog] [info] Total Unique barcodes found: 4096; [2018-12-12 15:08:51.146] [alevinLog]",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/329#issuecomment-446668422:2918,validat,validateMappings,2918,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/329#issuecomment-446668422,1,['validat'],['validateMappings']
Security,"Thank *you* for providing this software to the community.; BTW, it seems you're making an effort to support externally installed dependencies, for which I'm grateful. I did have to patch around a few bundled deps (e.g. libgff), which are downloaded unconditionally. Many package managers (e.g. FreeBSD ports, Gentoo Portage, MacPorts, pkgsrc, ...) do not allow manual downloads by upstream build systems, for obvious security reasons. I'm hoping it will be possible to avoid all such downloads without patching in the future, by preinstalling and having them discovered by find_package(), as you're already doing for things like bzip2. This will make it easier to package salmon in many of the numerous package managers out there (and eliminate the need for you to install dependencies via cmake). Cheers!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/288#issuecomment-420352699:417,secur,security,417,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/288#issuecomment-420352699,1,['secur'],['security']
Security,"Thank you @rob-p for commenting, I presumed that could be the case for reads from unspliced pre-mRNAs that are even extending a small fraction into the introns (hence better scoring on the decoys). The 2 FASTQ files for one of the samples I was describing above can be found as R4171*.fastq.gz at this globus link: http://research.libd.org/globus/jhpce_bsp2-dlpfc/index.html. I used just the main chromosomes with Gencode v41 annotation (slightly ""curated"" to remove read-through and ""retained intron"" annotated transcripts). I am attaching 3 `meta_info.json` outputs for the 3 ways I ran salmon on this sample:. - [tx_only.meta_info.json.gz](https://github.com/COMBINE-lab/salmon/files/11006627/tx_only.meta_info.json.gz) : no decoys, **without** `--validateMappings`; - [gentrome_full.meta_info.json.gz](https://github.com/COMBINE-lab/salmon/files/11006628/gentrome_full.meta_info.json.gz) : with `--validateMappings`, decoys are full chromosome sequences appended to the transcripts file, ; - [gentrome_mashed.meta_info.json.gz](https://github.com/COMBINE-lab/salmon/files/11006629/gentrome_mashed.meta_info.json.gz) : with `--validateMappings`, decoys prepared with mashmap as instructed [here](https://github.com/COMBINE-lab/SalmonTools/blob/master/README.md). It would be great to be able to use Salmon's ""wicked fast"" mapping engine to estimate intronic and intergenic reads at the same time, so I'm considering to make better use of the `writeMappings` output for that purpose, by preparing the decoys in a specific way (extracting intronic and intergenic sequences as distinctively labeled decoys and count the mappings to each label from Salmon's SAM output -- would that work?). I am wondering, due to pre-mRNAs found in rRNA-depletion (ribo-zero) samples, it might be better to artifically add the unspliced transcripts into the mix along with the ""reference"" annotation transcripts, so they also get quantified during the EM-guided probabilistic distribution of reads across this mix of p",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/779#issuecomment-1474451463:751,validat,validateMappings,751,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/779#issuecomment-1474451463,4,['validat'],['validateMappings']
Security,"Thanks @rob-p for a quick and complete reply. I got your point :) Actually, I downloaded fastq files from ENA so I do not have access to BioAnalyzer results. From literature review it could be concluded that Alignment-free tools like Salmon or kallisto yield more accurate quantifications, that's why I went to apply salmon on my data (my aim is differential gene expression at the end). Now, my main issue is: without an accurate estimation of fragment length for running salmon, would it end up with less accurate quantification result? If yes, then it is more rational to me to use traditional methods such as featureCounts. Do you have any idea that sheds more light on this ambiguity.; Best,; Tima",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/127#issuecomment-750925173:127,access,access,127,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/127#issuecomment-750925173,1,['access'],['access']
Security,"Thanks Nicolas,. I downloaded the files from this url and (unfortunately?) was unable to reproduce the segfault. I'd just like to check that we are working from the same source files and there wasn't e.g. a corruption during your download or some such. I have the following as the MD5 hash sums for the files input into the indexing. ```; $ md5sum GRCm38.primary_assembly.genome.fa.gz; 3bc591be24b77f710b6ba5d41022fc5a GRCm38.primary_assembly.genome.fa.gz; $ md5sum gencode.vM25.transcripts.fa.gz; a821c0dde39c48b9d2c4b48d36b0180c gencode.vM25.transcripts.fa.gz; $ md5sum decoys.txt; fdfb8e3ea371649a7ec2c39fcd8bb8f4 decoys.txt; $ md5sum gentrome.fa.gz; db7022ecc40483f105aedcdc4e113304 gentrome.fa.gz; ```. could you let me know if the signatures for your files are the same?. Thanks!; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/521#issuecomment-627671880:285,hash,hash,285,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/521#issuecomment-627671880,1,['hash'],['hash']
Security,"Thanks again @jdrnevich for sharing the data for debugging purposes. For anyone seeing similar behavior or following this issue, the resolution is as follows:. The mapping rate difference for between 100bp and 150bp reads (for both single-end and paired-end) becomes very small, and consistent with the ""high"" mapping rate of ~76-79% when using salmon v0.13.1 with `--validateMappings`. Thus, the recommendation here (and in general) is to process the data using the latest version of salmon and ensuring to use the `--validateMappings` option. Also, thanks to @jdrnevich for suggesting that the importance of this feature be highlighted in the documentation to the same extent it is in the release notes.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/349#issuecomment-472994215:368,validat,validateMappings,368,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/349#issuecomment-472994215,2,['validat'],['validateMappings']
Security,"Thanks for the detailed answer, Rick! . I just saw that paper pop up yesterday and it was on my reading list :). Internally, we have access to the number of occurrences of each UMI, gene pair within each barcode, so I do not think it would be too difficult to to provide read counts (optionally) along with deduplicated counts (though @k3yavi would be best equipped to say how easy or difficult this would be from the implementation perspective). Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-639020241:133,access,access,133,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-639020241,1,['access'],['access']
Security,"Thanks for the quick answer!; Here is the log file:. [2020-04-22 12:53:21.437] [jointLog] [info] setting maxHashResizeThreads to 8; [2020-04-22 12:53:21.437] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2020-04-22 12:53:21.437] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2020-04-22 12:53:21.437] [jointLog] [info] Usage of --validateMappings implies a default consensus slack of 0.2. Setting consensusSlack to 0.35.; [2020-04-22 12:53:21.437] [jointLog] [info] parsing read library format; [2020-04-22 12:53:21.437] [jointLog] [info] There is 1 library.; [2020-04-22 12:53:21.501] [jointLog] [info] Loading pufferfish index; [2020-04-22 12:53:21.503] [jointLog] [info] Loading dense pufferfish index.; [2020-04-22 12:54:13.540] [jointLog] [info] done; [2020-04-22 12:54:13.713] [jointLog] [info] Index contained 228,799 targets; [2020-04-22 12:54:29.422] [jointLog] [info] Number of decoys : 84; [2020-04-22 12:54:29.466] [jointLog] [info] First decoy index : 228,673 ; [2020-04-22 13:00:24.946] [jointLog] [info] Automatically detected most likely library type as ISR; [2020-04-23 00:06:31.287] [jointLog] [info] Thread saw mini-batch with a maximum of 1.06% zero probability fragments; [2020-04-23 00:06:41.198] [jointLog] [info] Thread saw mini-batch with a maximum of 1.08% zero probability fragments; [2020-04-23 00:06:50.741] [jointLog] [info] Thread saw mini-batch with a maximum of 1.02% zero probability fragments; [2020-04-23 00:06:56.260] [jointLog] [info] Thread saw mini-batch with a maximum of 1.08% zero probability fragments; [2020-04-23 00:06:56.781] [jointLog] [info] Thread saw mini-batch with a maximum of 1.04% zero probability fragments; [2020-04-23 00:07:03.636] [jointLog] [info] Thread saw mini-batch with a maximum of 1.04% zero probability fragments; [2020-04-23 00:07:03.759] [jointLog] [info] Thread saw mini-batch ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/516#issuecomment-621872756:320,validat,validateMappings,320,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/516#issuecomment-621872756,2,['validat'],['validateMappings']
Security,"Thanks for your quickly reply! It really worked @k3yavi; Then I run the command line ; `salmon alevin -l ISR /home/lailab/disk/gjw/Ascite-1_R1.fq.gz -2 /home/lailab/disk/gjw/Ascite-1_R2.fq.gz --chromium --index /home/lailab/disk/gjw/default/ -p 10 -o /home/lailab/disk/gjw/alevin_out --tgMap /home/lailab/disk/gjw/txp2gene.tsv`. ```; Version Server Response: Not Found; Logs will be written to /home/lailab/disk/gjw/alevin_out/logs; [2021-05-27 14:31:00.318] [jointLog] [info] setting maxHashResizeThreads to 10; [2021-05-27 14:31:00.318] [jointLog] [info] The --mimicBT2, --mimicStrictBT2 and --hardFilter flags imply mapping validation (--validateMappings). Enabling mapping validation.; [2021-05-27 14:31:00.318] [jointLog] [error] You passed paired-end files to salmon, but you passed 0 files to --mates1 and 1 files to --mates2. You must pass the same number of files to both flags; [2021-05-27 14:31:00.318] [jointLog] [info] Using default value of 0.87 for minScoreFraction in Alevin; Using default value of 0.6 for consensusSlack in Alevin; [2021-05-27 14:31:00.318] [alevinLog] [error] Could not properly process salmon-level options!; ```; Is it the problem with my data?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/663#issuecomment-850151665:627,validat,validation,627,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/663#issuecomment-850151665,3,['validat'],"['validateMappings', 'validation']"
Security,"Thanks, I usually do not trim reads. I am surprised to see such a difference from version 0.8.3. Do you have a recommendation for --minScoreFraction if I do not trim reads? Or maybe I should go back to NOT using --validateMappings?; For testing purposes, I will try trimming the reads for this sample. Will report back.; Oh, and this sample was prepared by ultra-low RNA input protocol, so the issues of adapter contamination could be present.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-586475673:214,validat,validateMappings,214,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-586475673,1,['validat'],['validateMappings']
Security,"Thanks, Rob! Much appreciated. ~brian. On Mon, Mar 20, 2017 at 9:06 AM, Rob Patro <notifications@github.com> wrote:. > Hi @brianjohnhaas <https://github.com/brianjohnhaas> --- I know it's been; > a while (but I didn't gain access to an older OSX machine in that time).; > However, you should now be able to get the latest Salmon release on any OSX; > >= 10.8 via its Bioconda release; > <https://bioconda.github.io/recipes/salmon/README.html>. Let me know if; > this works for you.; >; > Best,; > Rob; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/COMBINE-lab/salmon/issues/117#issuecomment-287753410>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AHMVX9ed1SrEG30OgxTLVaHzGtq20WI0ks5rnnnngaJpZM4L3UvG>; > .; >. -- ; --; Brian J. Haas; The Broad Institute; http://broadinstitute.org/~bhaas <http://broad.mit.edu/~bhaas>",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/117#issuecomment-287756041:223,access,access,223,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/117#issuecomment-287756041,1,['access'],['access']
Security,"The problem you're encountering here seems to be a result of a memory allocation error. Basically, building the index requires considerably more memory than actually storing it (and using it for quantification). One option would be to try and build the index with smaller k-mers, which should require less memory. It looks like you successfully indexed 3.8 / 4.1 billion nucleotides, so you're reasonably close to done. The other option will only work with the newest commits of Salmon (i.e. you'd have to clone the repository and build) --- however, they allow building a perfect hash index rather than using the google dense hash we use by default. The perfect hash construction uses an external memory algorithm, and it takes considerably less memory to build the index. A pre-compiled binary exposing this option should also be available later this week.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/53#issuecomment-202592429:581,hash,hash,581,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/53#issuecomment-202592429,3,['hash'],['hash']
Security,"We do no have access to BSD-based systems (apart from the extent to which OSX can be said to be BSD-based) on which to test during development. Bioconda works on many linux distributions; though I do not have a comprehensive list. For example, we regularly run on Ubuntu, CentOS, RedHat and Debian. If you have the facilities to use Docker on this machine, you can also pull down a docker image of the latest release from https://hub.docker.com/r/combinelab/salmon.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/419#issuecomment-522628674:14,access,access,14,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/419#issuecomment-522628674,1,['access'],['access']
Security,"Writing the targets to JSON is probably a good idea. My only remaining concern would be how to make it as easy as possible to compare these files against each other:. - Does target order matter? If so, JSON parsers will almost always make an unordered object during deserialization. ; - Will a user just be able to diff or hash these files against each other? If so I’d say that’s the best solution.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/469#issuecomment-569966210:323,hash,hash,323,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/469#issuecomment-569966210,1,['hash'],['hash']
Security,"Yeah, I haven't heard back yet. Any test case is fine where the data is publicly accessible. Thanks.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-983999718:81,access,accessible,81,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-983999718,1,['access'],['accessible']
Security,"Yes, the data is all public, so I have no problems sharing it, except finding a place to host it publically. I can't just link to the public source because there's some preprocessing steps. Both the FASTQ and the Salmon index are over 1.5 GB, so they're too big for my free Dropbox account, and my institute's network is tightly firewalled, so I can't just server if via a local server. Do you have any suggestions?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-266896459:329,firewall,firewalled,329,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-266896459,1,['firewall'],['firewalled']
Security,"Yes; that should definitely correctly be identified as 32-bit. The way the parser works is that it ""chops"" the header at the first whitepsace character. I can't think of anything that would cause failure during mapping (but bugs come from exactly the kind of thing you can't think of). Something that might cause an issue now that I think about it is a complete poly-A transcript. The indexer will attempt to clip poly-A tails (if a transcript ends with > 10 A's, then it will clip all of the trailing A's. If this causes the entire sequence to disappear, this might cause an issue. Also, I hadn't given deep consideration to what might happen if a transcript is shorter than the k-mer size (default 31) used for hashing --- so I might also check for very short transcripts.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/37#issuecomment-174578337:713,hash,hashing,713,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/37#issuecomment-174578337,1,['hash'],['hashing']
Security,"You are right on the spot. ; After trimming, every problem went away:; ""num_processed"": 102482661,; ""num_mapped"": 85812375,; ""num_decoy_fragments"": 760387,; ""num_dovetail_fragments"": 1265734,; ""num_fragments_filtered_vm"": 7722295,; ""num_alignments_below_threshold_for_mapped_fragments_vm"": 293676436,; ""percent_mapped"": 83.7335546937057,. I would really like to have the soft clipping feature though. With salmon being so fast, trimming step basically takes more time than the salmon quantification step. A lot of us are now turning to cloud platforms and are charged by the the computing time. Some other questions unrelated to this topic:; For snRNA-seq like 10X platform, do you recommend just trimming read2?; From what I read out of documentation, decoy enhanced index would only work with --validateMapping. Would Alevin only work with non-decoy index then?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-586530740:797,validat,validateMapping,797,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-586530740,1,['validat'],['validateMapping']
Security,"[I confirmed with the developer of zUMIs](https://github.com/sdparekh/zUMIs/issues/298) that no frameshift detection/correction is happening in their approach for SPLiT-seq libraries, so the barcode discovery should be fairly consistent with what alevin is already doing (ie with fixed geometry positions). So, likely no need to incorporate this into `splitp` at the moment but if we/others determine that frameshifts are frequent enough and the data can improve in some noticeable way with correcting them, we can revisit later as you suggested. . As for the barcode detection - my usual approach with `alevin` at least is to let it try to estimate a ""real"" cell number, but if it's way off from our experimental expectations, to inject `--expectCells ncells` and let that serve as a starting point (with subsequent filtering). That has worked reasonably well in the past for me , and seems to be an option for `alevin-fry` as well. I don't know whether that is poor practice in the long run...it came from a place of seeing far too many weak knee plots early in the droplet scRNA-seq days. Are you generally more trusting of these estimates these days?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-988184912:731,inject,inject,731,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-988184912,1,['inject'],['inject']
Security,"[info] Done indexing Barcodes; [2019-06-06 19:24:55.692] [alevinLog] [info] Total Unique barcodes found: 50; [2019-06-06 19:24:55.692] [alevinLog] [info] Used Barcodes except Whitelist: 0; [2019-06-06 19:24:55.716] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify. [2019-06-06 19:24:55.716] [alevinLog] [info] parsing read library format; [2019-06-06 19:24:55.716] [jointLog] [info] There is 1 library.; [2019-06-06 19:24:55.889] [jointLog] [info] Loading Quasi index; [2019-06-06 19:24:55.889] [jointLog] [info] Loading 32-bit quasi index; [2019-06-06 19:24:55.890] [stderrLog] [info] Loading Suffix Array ; [2019-06-06 19:24:56.791] [stderrLog] [info] Loading Transcript Info ; [2019-06-06 19:24:57.025] [stderrLog] [info] Loading Rank-Select Bit Array; [2019-06-06 19:24:57.061] [stderrLog] [info] There were 136,011 set bits in the bit array; [2019-06-06 19:24:57.084] [stderrLog] [info] Computing transcript lengths; [2019-06-06 19:24:57.084] [stderrLog] [info] Waiting to finish loading hash; [2019-06-06 19:25:06.552] [jointLog] [info] done; [2019-06-06 19:25:06.552] [jointLog] [info] Index contained 136,011 targets; [2019-06-06 19:25:06.552] [stderrLog] [info] Done loading index; [2019-06-06 19:25:06.728] [alevinLog] [error] Barcode not found in frequency table; ```. Salmon Quant log is this. ```; [2019-06-06 19:23:29.519] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2019-06-06 19:23:29.519] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2019-06-06 19:23:29.520] [jointLog] [info] Usage of --validateMappings, without --hardFilter implies use of range factorization. rangeFactorizationBins is being set to 4; [2019-06-06 19:23:29.520] [jointLog] [info] Usage of --validateMappings implies a default consensus slack of 0.2. Setting consensusSlack to 0.2.; [2019-06-06 19:23:29.520] [jointLog] [info] Using default ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/369#issuecomment-499592790:1845,hash,hash,1845,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/369#issuecomment-499592790,1,['hash'],['hash']
Security,"[info] Loading 32-bit quasi index; [2019-06-06 19:24:55.890] [stderrLog] [info] Loading Suffix Array ; [2019-06-06 19:24:56.791] [stderrLog] [info] Loading Transcript Info ; [2019-06-06 19:24:57.025] [stderrLog] [info] Loading Rank-Select Bit Array; [2019-06-06 19:24:57.061] [stderrLog] [info] There were 136,011 set bits in the bit array; [2019-06-06 19:24:57.084] [stderrLog] [info] Computing transcript lengths; [2019-06-06 19:24:57.084] [stderrLog] [info] Waiting to finish loading hash; [2019-06-06 19:25:06.552] [jointLog] [info] done; [2019-06-06 19:25:06.552] [jointLog] [info] Index contained 136,011 targets; [2019-06-06 19:25:06.552] [stderrLog] [info] Done loading index; [2019-06-06 19:25:06.728] [alevinLog] [error] Barcode not found in frequency table; ```. Salmon Quant log is this. ```; [2019-06-06 19:23:29.519] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2019-06-06 19:23:29.519] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2019-06-06 19:23:29.520] [jointLog] [info] Usage of --validateMappings, without --hardFilter implies use of range factorization. rangeFactorizationBins is being set to 4; [2019-06-06 19:23:29.520] [jointLog] [info] Usage of --validateMappings implies a default consensus slack of 0.2. Setting consensusSlack to 0.2.; [2019-06-06 19:23:29.520] [jointLog] [info] Using default value of 0.87 for minScoreFraction in Alevin; Using default value of 0.6 for consensusSlack in Alevin; [2019-06-06 19:24:55.716] [jointLog] [info] There is 1 library.; [2019-06-06 19:24:55.889] [jointLog] [info] Loading Quasi index; [2019-06-06 19:24:55.889] [jointLog] [info] Loading 32-bit quasi index; [2019-06-06 19:25:06.552] [jointLog] [info] done; [2019-06-06 19:25:06.552] [jointLog] [info] Index contained 136,011 targets; ```. It is interesting because the barcodes are recognized during the processing, but they do",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/369#issuecomment-499592790:2351,validat,validateMappings,2351,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/369#issuecomment-499592790,1,['validat'],['validateMappings']
Security,"[info] chunk 1 = [37,155,321, 74,310,642); [2021-12-31 11:28:47.220] [puff::index::jointLog] [info] chunk 2 = [74,310,642, 111,465,963); [2021-12-31 11:28:47.220] [puff::index::jointLog] [info] chunk 3 = [111,465,963, 148,621,284); [2021-12-31 11:28:47.220] [puff::index::jointLog] [info] chunk 4 = [148,621,284, 185,776,605); [2021-12-31 11:28:47.220] [puff::index::jointLog] [info] chunk 5 = [185,776,605, 222,931,953); [2021-12-31 11:28:47.220] [puff::index::jointLog] [info] chunk 6 = [222,931,953, 260,087,274); [2021-12-31 11:28:47.220] [puff::index::jointLog] [info] chunk 7 = [260,087,274, 297,242,536); [2021-12-31 11:28:57.275] [puff::index::jointLog] [info] finished populating pos vector; [2021-12-31 11:28:57.275] [puff::index::jointLog] [info] writing index components; [2021-12-31 11:28:59.670] [puff::index::jointLog] [info] finished writing dense pufferfish index; [2021-12-31 11:28:59.944] [jLog] [info] done building index; Threads = 8; Vertex length = 29; Hash functions = 5; Filter size = 4294967296; Capacity = 2; Files: ; /no_backup/indexes/salmon/mm10_gencode/ref_k29_fixed.fa; --------------------------------------------------------------------------------; Round 0, 0:4294967296; Pass	Filling	Filtering; 1	22	34	; 2	9	0; True junctions count = 1275494; False junctions count = 1606379; Hash table size = 2881873; Candidate marks count = 14783512; --------------------------------------------------------------------------------; Reallocating bifurcations time: 0; True marks count: 12564712; Edges construction time: 10; --------------------------------------------------------------------------------; Distinct junctions = 1275494. for info, total work write each : 2.331 total work inram from level 3 : 4.322 total work raw : 25.000 ; Bitarray 1252655360 bits (100.00 %) (array + ranks ); final hash 0 bits (0.00 %) (nb in final hash 0); ```. And these files are present in the index folder:; ```; ls -1 /no_backup/indexes/salmon/mm10_gencode; complete_ref_lens.bin; ctabl",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/731#issuecomment-1003342883:5466,Hash,Hash,5466,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/731#issuecomment-1003342883,1,['Hash'],['Hash']
Security,"] Done indexing Barcodes; [2018-12-12 15:08:51.146] [alevinLog] [info] Total Unique barcodes found: 4096; [2018-12-12 15:08:51.146] [alevinLog] [info] Used Barcodes except Whitelist: 1864; [2018-12-12 15:08:51.272] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify. [2018-12-12 15:08:51.272] [alevinLog] [info] parsing read library format; [2018-12-12 15:08:51.375] [stderrLog] [info] Loading Suffix Array ; [2018-12-12 15:08:51.272] [jointLog] [info] There is 1 library.; [2018-12-12 15:08:51.375] [jointLog] [info] Loading Quasi index; [2018-12-12 15:08:51.375] [jointLog] [info] Loading 32-bit quasi index; [2018-12-12 15:09:10.216] [stderrLog] [info] Loading Transcript Info ; [2018-12-12 15:09:15.719] [stderrLog] [info] Loading Rank-Select Bit Array; [2018-12-12 15:09:16.330] [stderrLog] [info] There were 205,870 set bits in the bit array; [2018-12-12 15:09:16.343] [stderrLog] [info] Computing transcript lengths; [2018-12-12 15:09:16.343] [stderrLog] [info] Waiting to finish loading hash; [2018-12-12 15:09:21.460] [stderrLog] [info] Done loading index; [2018-12-12 15:09:21.460] [jointLog] [info] done; [2018-12-12 15:09:21.460] [jointLog] [info] Index contained 205,870 targets. processed 0 Million fragments; processed 1 Million fragments; processed 1 Million fragments; ..............; processed 74 Million fragments; hits: 111594303, hits per frag: 1.50848[2018-12-12 15:12:07.666] [jointLog] [info] Thread saw mini-batch with a maximum of 5.34% zero probability fragments; [2018-12-12 15:12:07.677] [jointLog] [info] Thread saw mini-batch with a maximum of 5.48% zero probability fragments. [2018-12-12 15:12:07.721] [jointLog] [info] Computed 173,365 rich equivalence classes for further processing; [2018-12-12 15:12:07.721] [jointLog] [info] Counted 27,831,508 total reads in the equivalence classes ; [2018-12-12 15:12:07.721] [jointLog] [warning] Found 31347 reads with `N` in the UMI sequence and ignored the reads.; Please report on github if this number is t",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/329#issuecomment-446668422:4798,hash,hash,4798,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/329#issuecomment-446668422,1,['hash'],['hash']
Security,"```. Secondly, I created a new transcriptome-only salmon index (`singularity run -B /data $SALMON_SIMG salmon index -t genome.transcripts.fa -i salmon_index -k 31`), then ran `salmon quant` again (as above) but using the new transcriptome-only index. Note: 'genome.transcripts.fa' is the transcripts file created during the `nf-core/rnaseq` pipeline. Again, this analysis completed properly in a reasonable time. Seems like there is something very wrong with the 'gentrome.fa' file that's being created by `nf-core/rnaseq`! It's just so odd that _some_ samples would work and others wouldn't. 2. It's definitely worth noting that I originally opted against using `star_salmon` with the following command:. ```; nextflow run nf-core/rnaseq --max_memory 55.GB --fasta /data/reference_genomes/GRCh38/Homo_sapiens.GRCh38.dna_sm.primary_assembly.fa.gz --gtf /data/reference_genomes/GRCh38/Homo_sapiens.GRCh38.106.gtf.gz --skip_alignment --pseudo_aligner salmon --seq_center 'Ramaciotti Centre for Genomics' --input samplesheet.csv --outdir nf-core_results --save_merged_fastq true --skip_markduplicates true --extra_salmon_quant_args '--seqBias --gcBias --posBias' -profile singularity; ```. I'll re-run (a) using the refgenie salmon index specified; (b) with the `star_salmon` pathway to see if the decoy-aware index created that way is appropriate. 3. Other; I've installed `piscem` and can give it a go, although it does seem more like a salmon index issue with `nf-core/rnaseq` from the debugging above. Do you agree? If so, I'll raise an issue there. Considering this, would it still be useful to have access to the reads? I've got the green light to share them if need be. If so, what's a good contact address to share a OneDrive link?. Thanks!; Charles. p.s. something else odd that I can dig into further later if need be is that the singularity version of salmon created an index in about 5 minutes, yet the conda version has been creating the index for nearly 20 minutes so far with no change...",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/830#issuecomment-1441194948:2687,access,access,2687,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/830#issuecomment-1441194948,1,['access'],['access']
Security,"ained 66153 targets; [2019-03-04 04:44:08.443] [fileLog] [info]; At end of round 0; ==================; Observed 18861231 total fragments (18861231 in most recent round). [2019-03-04 04:44:08.442] [jointLog] [info] Computed 48502 rich equivalence classes for further processing; [2019-03-04 04:44:08.442] [jointLog] [info] Counted 17308442 total reads in the equivalence classes; [2019-03-04 04:44:08.450] [jointLog] [info] Mapping rate = 91.7673%. [2019-03-04 04:44:08.450] [jointLog] [info] finished quantifyLibrary(). **For version 0.12**; #!/bin/bash; #SBATCH -N 1; #SBATCH -c 8; #SBATCH --mem=10G; #SBATCH --mail-use=tarun2@illinois.edu; #SBATCH -J Salmon; #SBATCH -a 1-24. module load Salmon/0.12.0-IGB-gcc-8.2.0. line=$(sed -n -e ""$SLURM_ARRAY_TASK_ID p"" ~/source/BLBnew.txt). salmon quant -i ~/data/genome/MSU7new_transcript.index -l IU \; -1 ~/results/trimmingSheng/${line}1.paired.fastq \; -2 ~/results/trimmingSheng/${line}2.paired.fastq --numBootstraps=30 \; -p 12 -o ~/results/salmon_quant_Sheng_IU/${line} --seqBias --gcBias --validateMappings. There are no estimate and reads generated when invokin the library type IU:; Name Length EffectiveLength TPM NumReads; LOC_Os01g01010.1 3017 3017.000 0.000000 0.000; LOC_Os01g01010.2 2218 2218.000 0.000000 0.000; LOC_Os01g01019.1 1127 1127.000 0.000000 0.000; LOC_Os01g01030.1 2464 2464.000 0.000000 0.000; LOC_Os01g01040.4 1524 1524.000 0.000000 0.000; LOC_Os01g01040.1 2508 2508.000 0.000000 0.000; LOC_Os01g01040.2 2482 2482.000 0.000000 0.000; LOC_Os01g01040.3 2583 2583.000 0.000000 0.000; LOC_Os01g01050.1 2039 2039.000 0.000000 0.000. [2019-03-04 01:24:12.788] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2019-03-04 01:24:12.788] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2019-03-04 01:24:12.788] [jointLog] [info] Usage of --validateMappings implies use of range factorizatio",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/346#issuecomment-469215256:2889,validat,validateMappings,2889,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/346#issuecomment-469215256,1,['validat'],['validateMappings']
Security,"al # of Contigs : 23; [2023-03-10 05:51:33.748] [puff::index::jointLog] [info] Total # of numerical Contigs : 23; [2023-03-10 05:51:33.748] [puff::index::jointLog] [info] Total # of contig vec entries: 36; [2023-03-10 05:51:33.748] [puff::index::jointLog] [info] bits per offset entry 6; [2023-03-10 05:51:33.748] [puff::index::jointLog] [info] Done constructing the contig vector. 24; [2023-03-10 05:51:33.748] [puff::index::jointLog] [info] # segments = 23; [2023-03-10 05:51:33.748] [puff::index::jointLog] [info] total length = 19592; [2023-03-10 05:51:33.748] [puff::index::jointLog] [info] Reading the reference files ...; [2023-03-10 05:51:33.750] [puff::index::jointLog] [info] positional integer width = 15; [2023-03-10 05:51:33.750] [puff::index::jointLog] [info] seqSize = 19592; [2023-03-10 05:51:33.750] [puff::index::jointLog] [info] rankSize = 19592; [2023-03-10 05:51:33.750] [puff::index::jointLog] [info] edgeVecSize = 0; [2023-03-10 05:51:33.750] [puff::index::jointLog] [info] num keys = 18902; for info, total work write each : 2.331 total work inram from level 3 : 4.322 total work raw : 25.000; [Building BooPHF] 100 % elapsed: 0 min 0 sec remaining: 0 min 0 sec; Bitarray 105024 bits (100.00 %) (array + ranks ); final hash 0 bits (0.00 %) (nb in final hash 0); [2023-03-10 05:51:33.781] [puff::index::jointLog] [info] mphf size = 0.0125198 MB; [2023-03-10 05:51:33.781] [puff::index::jointLog] [info] chunk size = 9796; [2023-03-10 05:51:33.781] [puff::index::jointLog] [info] chunk 0 = [0, 9796); [2023-03-10 05:51:33.781] [puff::index::jointLog] [info] chunk 1 = [9796, 19562); [2023-03-10 05:51:33.784] [puff::index::jointLog] [info] finished populating pos vector; [2023-03-10 05:51:33.784] [puff::index::jointLog] [info] writing index components; [2023-03-10 05:51:33.784] [puff::index::jointLog] [info] finished writing dense pufferfish index; [2023-03-10 05:51:33.784] [jLog] [info] done building index; ```. So on `testing` at least, I can't yet reproduce this issue.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463312554:4807,hash,hash,4807,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463312554,2,['hash'],['hash']
Security,"almon-0.10.2/bin/salmon; -- Installing: /salmon-0.10.2/lib/libsalmon_core.a. Installation complete. Please ensure the following paths are set properly.; ==========================================================================; Please add /salmon-0.10.2/bin to your PATH; Please add /salmon-0.10.2/lib to your LD_LIBRARY_PATH; ==========================================================================; root@e08cc9670e4a:/salmon-0.10.2/build# make test; Running tests...; Test project /salmon-0.10.2/build; Start 1: unit_tests; 1/3 Test #1: unit_tests ....................... Passed 0.17 sec; Start 2: salmon_read_test_fmd; 2/3 Test #2: salmon_read_test_fmd ............. Passed 1.78 sec; Start 3: salmon_read_test_quasi; 3/3 Test #3: salmon_read_test_quasi ........... Passed 1.59 sec. 100% tests passed, 0 tests failed out of 3. Total Test time (real) = 3.54 sec; root@e08cc9670e4a:/salmon-0.10.2/build# lsb_release -a; LSB Version: core-9.20160110ubuntu0.2-amd64:core-9.20160110ubuntu0.2-noarch:security-9.20160110ubuntu0.2-amd64:security-9.20160110ubuntu0.2-noarch; Distributor ID: Ubuntu; Description: Ubuntu 16.04.4 LTS; Release: 16.04; Codename: xenial; ```. I built with:. `$ cmake -DFETCH_BOOST=TRUE .. && make install && make test`. I can also install the boost via apt and see if that makes a difference (though I expect not since it looked like TBB was the issue, and I let cmake install that). We can also check our compiler versions, perhaps. I have : . ```; root@e08cc9670e4a:/salmon-0.10.2/build# g++ --version; g++ (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609; Copyright (C) 2015 Free Software Foundation, Inc.; This is free software; see the source for copying conditions. There is NO; warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. root@e08cc9670e4a:/salmon-0.10.2/build# gcc --version; gcc (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609; Copyright (C) 2015 Free Software Foundation, Inc.; This is free software; see the source for copying conditi",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/250#issuecomment-404306268:2413,secur,security-,2413,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/250#issuecomment-404306268,1,['secur'],['security-']
Security,"ase_ercc.fa }; # [ libType ] => { IU }; # [ mates1 ] => { SRP057125_SRS936134_1.fastq }; # [ mates2 ] => { SRP057125_SRS936134_2.fastq }; # [ output ] => { SRP057125_SRS936134_salmon_out }; # [ biasCorrect ] => { }; # [ useFSPD ] => { }; Logs will be written to SRP057125_SRS936134_salmon_out/logs; [2016-01-02 20:16:39.349] [jointLog] [info] parsing read library format; there is 1 lib; Loading 32-bit quasi index[2016-01-02 20:16:39.895] [stderrLog] [info] Loading Suffix Array; [2016-01-02 20:16:39.895] [stderrLog] [info] Loading Position Hash; [2016-01-02 20:16:39.894] [jointLog] [info] Loading Quasi index; [2016-01-02 20:16:42.565] [stderrLog] [info] Loading Transcript Info; [2016-01-02 20:16:43.654] [stderrLog] [info] Loading Rank-Select Bit Array; [2016-01-02 20:16:44.075] [stderrLog] [info] There were 104534 set bits in the bit array; [2016-01-02 20:16:44.448] [stderrLog] [info] Computing transcript lengths; [2016-01-02 20:16:44.448] [stderrLog] [info] Waiting to finish loading hash; Index contained 104534 targets; [2016-01-02 20:16:57.606] [stderrLog] [info] Done loading index; [2016-01-02 20:16:57.606] [jointLog] [info] done. processed 12000000 fragments; hits: 24367197, hits per frag: 2.06194+06. [2016-01-02 20:17:29.841] [jointLog] [info] Computed 102251 rich equivalence classes for further processing; [2016-01-02 20:17:29.841] [jointLog] [info] Counted 10033689 total reads in the equivalence classes; [2016-01-02 20:17:29.867] [jointLog] [info] Mapping rate = 83.0244%. [2016-01-02 20:17:29.867] [jointLog] [info] finished quantifyLibrary(); [2016-01-02 20:17:29.867] [jointLog] [info] Starting optimizer; [2016-01-02 20:17:30.130] [jointLog] [info] Marked 0 weighted equivalence classes as degenerate; [2016-01-02 20:17:30.136] [jointLog] [info] iteration = 0 | max rel diff. = 65.1271; [2016-01-02 20:17:30.315] [jointLog] [info] iteration 50, recomputing effective lengths; [2016-01-02 20:17:32.978] [jointLog] [info] iteration = 100 | max rel diff. = 0.259134; [2016",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/34#issuecomment-168426741:2307,hash,hash,2307,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/34#issuecomment-168426741,1,['hash'],['hash']
Security,"cc : @k3yavi . Hi @xuesoso, I know that Avi (tagged above) has implemented a flag for this, but I'm not certain if it is exposed in the current release. I'm tagging him here to chime in.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/567#issuecomment-695004138:121,expose,exposed,121,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/567#issuecomment-695004138,1,['expose'],['exposed']
Security,"dexing. My understanding is that you provided salmon with a transcriptome and (small) decoy reference genome, and asked it to build an index with k-mer size `k=31`. When you do this, salmon will do a few things. First, it will go over your input gentrome file, replace ambiguous characters (e.g. `N`) with pseudo-random nucleotides. It will also report any transcripts smaller than the chosen k-mer size, and it will detect and remove (unless `--keepDuplicates` is passed) any identical / duplicate sequences. After all of this, it will begin constructing the index in earnest. This is done by running a modified version of [TwoPaCo](https://github.com/medvedevgroup/TwoPaCo) to construct the compacted colored de Bruijn graph on the gentrome, which is then indexed using our [pufferfish index](https://github.com/COMBINE-lab/pufferfish). The TwoPaCo algorithm that generates the compacted colored de Bruijn graph from the input sequence is based on a very elegant algorithm that couples a Bloom filter with an exact hash table, and makes two (or more) passes over the input to identify all of the junctions in the reference (which directly implies all unitigs). To make the algorithm work efficiently, one needs to have an estimate for the number of distinct k-mers that will be encountered in the reference sequence. If the estimate is too big, one wastes memory. If the estimate is too small, the Bloom filter is not big enough, it doesn't filter efficiently, and the algorithm ends up putting way too much data in the exact hash table. In order to determine how to set the Bloom filter size appropriately, we take the following approach. If the Bloom filter size isn't provided directly (_note_: this is _not_ the same as the k-mer size, this is an estimate of the total number of distinct k-mers in the entire input data), then we make a call to a function defined in the [ntCard](https://github.com/bcgsc/ntCard) library. This is a program designed specifically for cardinality estimation of k-",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/510#issuecomment-616713186:1145,hash,hash,1145,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/510#issuecomment-616713186,1,['hash'],['hash']
Security,"e conda evironment) is going differently ! Skip to Try 2. below for success; Try 1.; Index seemed to go the same as before, using the command [from a script]; salmon index -t decoys/gentrome.fa -d decoys/decoys.txt -i salmonIndexDecoyMouse; but then command; salmon quant -p 3 -i salmonIndexDecoyMouse -l A -1 SRR1818187_2.fastq.gz -2 SRR1818187_1.fastq.gz --validateMappings -o Salmontranscripts_quant; Fails as follows, saying it cannot find a .json file(s); ---------------------------------------------------------------------; (salmon) wayne@Ubuntu19:~/rnaseq$ sh salmonQuantDecoy.sh ; Version Info: This is the most recent version of salmon.; ### salmon (mapping-based) v0.14.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ threads ] => { 3 }; ### [ index ] => { salmonIndexDecoyMouse }; ### [ libType ] => { A }; ### [ mates1 ] => { SRR1818187_2.fastq.gz }; ### [ mates2 ] => { SRR1818187_1.fastq.gz }; ### [ validateMappings ] => { }; ### [ output ] => { Salmontranscripts_quant }; Logs will be written to Salmontranscripts_quant/logs; [2019-08-25 11:40:44.518] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2019-08-25 11:40:44.518] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2019-08-25 11:40:44.518] [jointLog] [info] Usage of --validateMappings, without --hardFilter implies use of range factorization. rangeFactorizationBins is being set to 4; [2019-08-25 11:40:44.518] [jointLog] [info] Usage of --validateMappings implies a default consensus slack of 0.2. Setting consensusSlack to 0.2.; [2019-08-25 11:40:44.518] [jointLog] [info] parsing read library format; [2019-08-25 11:40:44.518] [jointLog] [info] There is 1 library.; Exception : [Error: The index version file salmonIndexDecoyMouse/versionInfo.json doesn't seem to exist. Please try re-building the salmon index.]; salmon quant was invoked improperly.; For ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/419#issuecomment-524651435:1064,validat,validateMappings,1064,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/419#issuecomment-524651435,1,['validat'],['validateMappings']
Security,"e next, even on the same data file. . I appreciate any help you can offer and I apologize in advance if there's something obvious I should have read or known about. (it seems like the lines below that are preceded by ### are coming out in fold face. They are not meant to.). (salmon) MacBook-Pro-2:salmon-tutorial brent$ bash quant_tut_samples.sh; Processing sample DRR016125; Version Info: Could not resolve upgrade information in the alotted time.; Check for upgrades manually at https://combine-lab.github.io/salmon; ### salmon (mapping-based) v0.11.3; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { athal_index }; ### [ libType ] => { A }; ### [ mates1 ] => { data/DRR016125/DRR016125_1.fastq.gz }; ### [ mates2 ] => { data/DRR016125/DRR016125_2.fastq.gz }; ### [ threads ] => { 8 }; ### [ output ] => { quants/DRR016125_quant }; Logs will be written to quants/DRR016125_quant/logs; [2018-11-24 15:08:09.785] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2018-11-24 15:08:09.785] [jointLog] [info] parsing read library format; [2018-11-24 15:08:09.785] [jointLog] [info] There is 1 library.; [2018-11-24 15:08:09.877] [jointLog] [info] Loading Quasi index; [2018-11-24 15:08:09.877] [jointLog] [info] Loading 32-bit quasi index; [2018-11-24 15:08:09.877] [stderrLog] [info] Loading Suffix Array ; [2018-11-24 15:08:10.319] [stderrLog] [info] Loading Transcript Info ; [2018-11-24 15:08:10.423] [stderrLog] [info] Loading Rank-Select Bit Array; [2018-11-24 15:08:10.432] [stderrLog] [info] There were 40,812 set bits in the bit array; [2018-11-24 15:08:10.435] [stderrLog] [info] Computing transcript lengths; [2018-11-24 15:08:10.435] [stderrLog] [info] Waiting to finish loading hash. quant_tut_samples.sh: line 2: 914 Segmentation fault: 11 salmon quant -i athal_index -l A -1 ${fn}/${samp}_1.fastq.gz -2 ${fn}/${samp}_2.fastq.gz -p 8 -o quants/${samp}_quant; (salmon) MacBook-Pro-2:salmon-tutorial brent$",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/317#issuecomment-441396828:2215,hash,hash,2215,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/317#issuecomment-441396828,1,['hash'],['hash']
Security,"e/RnaSeq/fastq/DM_4c_H_1.fq.gz ; -2 /home/RnaSeq/fastq/DM_4a_H_2.fq.gz /home/RnaSeq/fastq/DM_4b_H_2.fq.gz /home/RnaSeq/fastq/DM_4c_H_2.fq.gz ; -o /home/RnaSeq/salmon_output_files/out/DM4h; Version Info: Could not resolve upgrade information in the alotted time.; Check for upgrades manually at https://combine-lab.github.io/salmon; ### salmon (mapping-based) v0.14.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { /home/RnaSeq/transcriptome_gencode_v29/human_GENCODEv29/combined_index }; ### [ libType ] => { IU }; ### [ mates1 ] => { /home/RnaSeq/fastq/DM_4a_H_1.fq.gz /home/RnaSeq/fastq/DM_4b_H_1.fq.gz /home/RnaSeq/fastq/DM_4c_H_1.fq.gz }; ### [ mates2 ] => { /home/RnaSeq/fastq/DM_4a_H_2.fq.gz /home/RnaSeq/fastq/DM_4b_H_2.fq.gz /home/RnaSeq/fastq/DM_4c_H_2.fq.gz }; ### [ validateMappings ] => { }; ### [ output ] => { /home/RnaSeq/salmon_output_files/out/DM4h }; Logs will be written to /home/RnaSeq/salmon_output_files/out/DM4h/logs; [2019-07-01 12:51:42.856] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2019-07-01 12:51:42.856] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2019-07-01 12:51:42.856] [jointLog] [info] Usage of --validateMappings, without --hardFilter implies use of range factorization. rangeFactorizationBins is being set to 4; [2019-07-01 12:51:42.856] [jointLog] [info] Usage of --validateMappings implies a default consensus slack of 0.2. Setting consensusSlack to 0.2.; [2019-07-01 12:51:42.856] [jointLog] [info] parsing read library format; [2019-07-01 12:51:42.856] [jointLog] [info] There is 1 library.; Exception : [Error: The index version file /home/RnaSeq/transcriptome_gencode_v29/human_GENCODEv29/combined_index/versionInfo.json doesn't seem to exist. Please try re-building the salmon index.]; salmon quant was invoked improperly. Any ideas what I'm doing wrong please?. Thanks",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/389#issuecomment-507253562:3205,validat,validateMappings,3205,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/389#issuecomment-507253562,3,['validat'],['validateMappings']
Security,"ed, I'd strongly suggest against setting `--scoreExp` equal to 0. * `--allowDovetail` and `--softclipOverhangs` may or may not have a significant effect based on the quality of your library and annotation. Ideally, you would have no dovetailed mappings and no reads overhanging annotated transcripts. However, if you have an incomplete assembly or a library of questionable quality, these can both occur in practice. The `meta_info.json` file in the `aux_info` directory will give you stats about the number of dovetailed reads, so you can see if this is likely to have an effect here or not. * `--consensusSlack` determines which reads pass through the mapping-based filtering based on their chaining score and are therefore subject to alignment validation. While the chaining score is a decent proxy for alignment score, it's not perfect (otherwise, we would not really waste compute cycles computing the optimal alignment). Setting the `--consensusSlack` to a large value allows many things to be subject to mapping validation, while setting it to a smaller value doesn't. If the value is too small, then you may see situations where the mapping that yields the optimal _alignment_ doesn't have a chance to be counted because its chain score is too low. Now, it _is_ true that the only reads used will be those surpassing `--minScoreFraction` in terms of their alignment score, so changing the `--consensusSlack` won't allow through poor alignments, but if you set it too conservatively, you might miss some mappings that could have yielded the optimal alignment to mappings that are sub-optimal (personally, though, I'd guess this flag is probably the least likely to be having an effect here). So, where to go from here? I'd try these flags 1-by-1, roughly in the order I listed them above, to see which ones are having the most drastic effect on your result. Also, if you'd be willing to share the `meta_info.json` files in each quantification directory, I'd be happy to look into them and see i",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/523#issuecomment-632953613:2864,validat,validation,2864,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/523#issuecomment-632953613,1,['validat'],['validation']
Security,g to disk . . . done; Elapsed time: 0.959095s; done; Elapsed time: 8.1189s; ^M^Mprocessed 0 positions^M^Mprocessed 1000000 positions^M^Mprocessed 2000000 positions^M^Mprocessed 3000000 positions^M^Mprocessed 4000000 positions^M^Mprocessed 5000000 positions^M^Mprocessed 6000000 positions^M^Mprocessed 7000000 positions^M^Mprocessed 8000000 positions^M^Mprocessed 9000000 positions^M^Mprocessed 10000000 positions^M^Mprocessed 11000000 positions^M^Mprocessed 12000000 positions^M^Mprocessed 13000000 positions^M^Mprocessed 14000000 positions^M^Mprocessed 15000000 positions^M^Mprocessed 16000000 positions^M^Mprocessed 17000000 positions^M^Mprocessed 18000000 positions^M^Mprocessed 19000000 positions^M^Mprocessed 20000000 positions^M^Mprocessed 21000000 positions^M^Mprocessed 22000000 positions^M^Mprocessed 23000000 positions^M^Mprocessed 24000000 positions^M^Mprocessed 25000000 positions^M^Mprocessed 26000000 positions^M^Mprocessed 27000000 positions^M^Mprocessed 28000000 positions^M^Mprocessed 29000000 positions^M^Mprocessed 30000000 positions^M^Mprocessed 31000000 positions^M^Mprocessed 32000000 positions^M^Mprocessed 33000000 positions^M^Mprocessed 34000000 positions^M^Mprocessed 35000000 positions^M^Mprocessed 36000000 positions^M^Mprocessed 37000000 positions^M^Mprocessed 38000000 positions^M^Mprocessed 39000000 positions^M^Mprocessed 40000000 positions^M^Mprocessed 41000000 positions^M^Mprocessed 42000000 positions^M^Mprocessed 43000000 positions^M^Mprocessed 44000000 positions^M^Mprocessed 45000000 positions^M^Mprocessed 46000000 positions^M^Mprocessed 47000000 positions^M^Mprocessed 48000000 positions^M^Mprocessed 49000000 positions^M^Mprocessed 50000000 positions^M^Mprocessed 51000000 positions^M^Mprocessed 52000000 positions^M^Mprocessed 53000000 positions^M^Mprocessed 54000000 positions^M^Mprocessed 55000000 positions^M^Mprocessed 56000000 positions; khash had 29386942 keys; saving hash to disk . . . done; Elapsed time: 75.4197s; [2018-03-20 17:43:53.055] [jLog] [,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/210#issuecomment-376093497:3284,hash,hash,3284,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/210#issuecomment-376093497,1,['hash'],['hash']
Security,"good suggestion. [https://sites.google.com/site/ummslogos/_/rsrc/1489610858836/home/apple-icon-76x76.png]. Javier E. Irazoqui, PhD; Associate Professor; Department of Microbiology and Physiological Systems; UMass Medical School. 368 Plantation Street; Albert Sherman Center; Room AS8.1053; Worcester, MA 01605. (774) 455-3797; Skype: javierirazoqui. Confidentiality Notice:; This e-mail message, including any attachments, is for the sole use of the intended recipient(s) and may contain confidential, proprietary and privileged information. Any unauthorized review, use, disclosure or distribution is prohibited. If you are not the intended recipient, please contact the sender immediately and destroy or permanently delete all copies of the original message. On Feb 12, 2018, at 12:21 PM, Marcel Bargull <notifications@github.com<mailto:notifications@github.com>> wrote:. Hi @jirazoqui<https://github.com/jirazoqui> and @pdellorusso<https://github.com/pdellorusso>,; beware that if you install via a .tar.gz file, you make conda ignore all dependencies. It's somewhat equivalent to conda install --no-deps ... and thus I wouldn't recommend doing something like that.; Until we fix the dependencies in Bioconda, can you, if possible, use a separate Conda environment for salmon with conda create -c bioconda -c conda-forge --name salmon salmon. In this new environment you wouldn't have any dependency version conflict. —; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://github.com/COMBINE-lab/salmon/issues/194#issuecomment-364996006>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AiohHe_b7YX4kqzddLHJT7ZK6s1PhJgoks5tUHM1gaJpZM4SAonB>.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/194#issuecomment-364996252:350,Confidential,Confidentiality,350,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/194#issuecomment-364996252,2,"['Confidential', 'confidential']","['Confidentiality', 'confidential']"
Security,"h header [ENST00000604838.1|ENSG00000270185.1|OTTHUMG00000184585.2|OTTHUMT00000468915.2|IGHD1OR15-1B-201|IGHD1OR15-1B|17|IG_D_gene|], had length less than equal to the k-mer length of 23 (perhaps after poly-A clipping) [2022-04-16 11:16:00.515] [puff::index::jointLog] [warning] Removed 1363 transcripts that were sequence duplicates of indexed transcripts. ; [2022-04-16 11:16:00.515] [puff::index::jointLog] [warning] If you wish to retain duplicate transcripts, please use the `--keepDuplicates` flag ; [2022-04-16 11:16:00.541] [puff::index::jointLog] [info] Replaced 4 non-ATCG nucleotides ; [2022-04-16 11:16:00.541] [puff::index::jointLog] [info] Clipped poly-A tails from 1,961 transcripts wrote 245236 cleaned references ; [2022-04-16 11:16:02.811] [puff::index::jointLog] [info] Filter size not provided; estimating from number of distinct k-mers [2022-04-16 11:16:07.979] [puff::index::jointLog] [info] ntHll estimated 143558277 distinct k-mers, setting filter size to 2^32 Threads = 12 ; Vertex length = 23 ; Hash functions = 5 ; Filter size = 4294967296 ; Capacity = 1 ; Files: ; salmon_index_23/ref_k23_fixed.fa -------------------------------------------------------------------------------- ; Round 0, 0:4294967296 ; Pass Filling Filtering ; 1 13 148 ; 2 9 0 ; True junctions count = 1307919 ; False junctions count = 233850 ; Hash table size = 1541769 ; Candidate marks count = 14841235 -------------------------------------------------------------------------------- ; Reallocating bifurcations time: 0 ; True marks count: 14610695 ; Edges construction time: 9 -------------------------------------------------------------------------------- ; Distinct junctions = 1307919 allowedIn: 18 ; Max Junction ID: 1458039 ; seen.size():11664321 kmerInfo.size():1458040 approximateContigTotalLength: 96596288 ; counters for complex kmers: ; (prec>1 & succ>1)=163493 | (succ>1 & isStart)=1600 | (prec>1 & isEnd)=1705 | (isStart & isEnd)=136 contig count: 2046804 element count: 189087548 compl",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/768#issuecomment-1100734317:10329,Hash,Hash,10329,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/768#issuecomment-1100734317,1,['Hash'],['Hash']
Security,"ine/detection-comparison/salmon0.4.2-comparison/mouse/SRP057125_SRS936134_2.fastq; drwxrwxr-x 5 vale rst_pub 4.0K Jan 2 20:20 SRP057125_SRS936134_salmon_out; ```. But when I run the script there, it succeeds, without segfault. ```; [vale@ebi-003 salmon-problem]$ bash run_salmon.sh; Version Info: This is the most recent version of Salmon.; # salmon (mapping-based) v0.6.0; # [ program ] => salmon; # [ command ] => quant; # [ index ] => { mouse_cdna_38.p3.78_repbase_ercc.fa }; # [ libType ] => { IU }; # [ mates1 ] => { SRP057125_SRS936134_1.fastq }; # [ mates2 ] => { SRP057125_SRS936134_2.fastq }; # [ output ] => { SRP057125_SRS936134_salmon_out }; # [ biasCorrect ] => { }; # [ useFSPD ] => { }; Logs will be written to SRP057125_SRS936134_salmon_out/logs; [2016-01-02 20:16:39.349] [jointLog] [info] parsing read library format; there is 1 lib; Loading 32-bit quasi index[2016-01-02 20:16:39.895] [stderrLog] [info] Loading Suffix Array; [2016-01-02 20:16:39.895] [stderrLog] [info] Loading Position Hash; [2016-01-02 20:16:39.894] [jointLog] [info] Loading Quasi index; [2016-01-02 20:16:42.565] [stderrLog] [info] Loading Transcript Info; [2016-01-02 20:16:43.654] [stderrLog] [info] Loading Rank-Select Bit Array; [2016-01-02 20:16:44.075] [stderrLog] [info] There were 104534 set bits in the bit array; [2016-01-02 20:16:44.448] [stderrLog] [info] Computing transcript lengths; [2016-01-02 20:16:44.448] [stderrLog] [info] Waiting to finish loading hash; Index contained 104534 targets; [2016-01-02 20:16:57.606] [stderrLog] [info] Done loading index; [2016-01-02 20:16:57.606] [jointLog] [info] done. processed 12000000 fragments; hits: 24367197, hits per frag: 2.06194+06. [2016-01-02 20:17:29.841] [jointLog] [info] Computed 102251 rich equivalence classes for further processing; [2016-01-02 20:17:29.841] [jointLog] [info] Counted 10033689 total reads in the equivalence classes; [2016-01-02 20:17:29.867] [jointLog] [info] Mapping rate = 83.0244%. [2016-01-02 20:17:29.867] [jointLog",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/34#issuecomment-168426741:1854,Hash,Hash,1854,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/34#issuecomment-168426741,1,['Hash'],['Hash']
Security,"ing: /salmon-0.10.2/lib/libsalmon_core.a. Installation complete. Please ensure the following paths are set properly.; ==========================================================================; Please add /salmon-0.10.2/bin to your PATH; Please add /salmon-0.10.2/lib to your LD_LIBRARY_PATH; ==========================================================================; root@e08cc9670e4a:/salmon-0.10.2/build# make test; Running tests...; Test project /salmon-0.10.2/build; Start 1: unit_tests; 1/3 Test #1: unit_tests ....................... Passed 0.17 sec; Start 2: salmon_read_test_fmd; 2/3 Test #2: salmon_read_test_fmd ............. Passed 1.78 sec; Start 3: salmon_read_test_quasi; 3/3 Test #3: salmon_read_test_quasi ........... Passed 1.59 sec. 100% tests passed, 0 tests failed out of 3. Total Test time (real) = 3.54 sec; root@e08cc9670e4a:/salmon-0.10.2/build# lsb_release -a; LSB Version: core-9.20160110ubuntu0.2-amd64:core-9.20160110ubuntu0.2-noarch:security-9.20160110ubuntu0.2-amd64:security-9.20160110ubuntu0.2-noarch; Distributor ID: Ubuntu; Description: Ubuntu 16.04.4 LTS; Release: 16.04; Codename: xenial; ```. I built with:. `$ cmake -DFETCH_BOOST=TRUE .. && make install && make test`. I can also install the boost via apt and see if that makes a difference (though I expect not since it looked like TBB was the issue, and I let cmake install that). We can also check our compiler versions, perhaps. I have : . ```; root@e08cc9670e4a:/salmon-0.10.2/build# g++ --version; g++ (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609; Copyright (C) 2015 Free Software Foundation, Inc.; This is free software; see the source for copying conditions. There is NO; warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. root@e08cc9670e4a:/salmon-0.10.2/build# gcc --version; gcc (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609; Copyright (C) 2015 Free Software Foundation, Inc.; This is free software; see the source for copying conditions. There is NO; warranty; not even",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/250#issuecomment-404306268:2448,secur,security-,2448,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/250#issuecomment-404306268,1,['secur'],['security-']
Security,"isStart)=1600 | (prec>1 & isEnd)=1705 | (isStart & isEnd)=136 contig count: 2046804 element count: 189087548 complex nodes: 166934 ; number of ones in rank vector: 2046803 ; [2022-04-16 11:19:37.060] [puff::index::jointLog] [info] Starting the Pufferfish indexing by reading the GFA binary file. [2022-04-16 11:19:37.060] [puff::index::jointLog] [info] Setting the index/BinaryGfa directory salmon_index_23 ; size = 189087548 ; ----------------------------------------- ; | Loading contigs | Time = 43.37 ms ----------------------------------------- ; size = 189087548 ; ----------------------------------------- ; | Loading contig boundaries | Time = 19.565 ms ----------------------------------------- ; Number of ones: 2046803 ; Number of ones per inventory item: 512 ; Inventory entries filled: 3998 ; 2046803 ; [2022-04-16 11:19:37.638] [puff::index::jointLog] [info] Done wrapping the rank vector with a rank9sel structure. [2022-04-16 11:19:37.687] [puff::index::jointLog] [info] contig count for validation: 2,046,803 ; [2022-04-16 11:19:38.556] [puff::index::jointLog] [info] Total # of Contigs : 2,046,803 ; [2022-04-16 11:19:38.556] [puff::index::jointLog] [info] Total # of numerical Contigs : 2,046,803 ; [2022-04-16 11:19:38.774] [puff::index::jointLog] [info] Total # of contig vec entries: 15,036,896 ; [2022-04-16 11:19:38.774] [puff::index::jointLog] [info] bits per offset entry 24 ; [2022-04-16 11:19:39.637] [puff::index::jointLog] [info] Done constructing the contig vector. 2046804 [2022-04-16 11:19:40.720] [puff::index::jointLog] [info] # segments = 2,046,803 ; [2022-04-16 11:19:40.720] [puff::index::jointLog] [info] total length = 189,087,548 ; [2022-04-16 11:19:40.878] [puff::index::jointLog] [info] Reading the reference files ... ; [2022-04-16 11:19:42.562] [puff::index::jointLog] [info] positional integer width = 28 ; [2022-04-16 11:19:42.562] [puff::index::jointLog] [info] seqSize = 189,087,548 ; [2022-04-16 11:19:42.562] [puff::index::jointLog] [info] rankSize ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/768#issuecomment-1100734317:12199,validat,validation,12199,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/768#issuecomment-1100734317,1,['validat'],['validation']
Security,"l depend (somewhat) on the `--fldMean` and `--fldSD` flags that are used. It's important to note that this is not a unique characteristic of salmon, and any transcript-level quantification tool using a probabilistic model (e.g. RSEM, eXpress, BitSeq, etc.) have the same requirement. That is, the fragment length distribution should be known so that _effective_ transcript lengths can be estimated, which have an effect on fragment assignment probabilities. If the wrong fragment length distribution is specified, then the _effective_ transcript lengths will be off and this can affect the assignment of some fragments. This is only a requirement with single-end reads, since with paired-end reads the fragment length distribution is learned from the data. Further, the inference procedure is somewhat robust to these choices (small changes in fld mean and sd don't generally lead to drastically different results). If you have access to the BioAnalyzer results for the sequencing run, those can give information about the fragment length distribution (even in a single end experiment). If not, you can proceed with the default values. Even if they don't exactly match the true distribution in the single-end sample, at least the same values will be applied in all samples and so, ideally, most results of misspecification will wash out in subsequent differential analysis. . Finally, it's worth noting that the same restriction holds in both alignment-based and mapping-based modes. This is because in neither mode do single-end fragments provide sufficient information to estimate the fragment length distribution from the data. We only know where one end of a fragment mapped and cannot infer where the other end would be. This is not an alignment versus mapping (versus selective-alignment) issue, but rather is fundamental to having only observed one side of the entire fragment generated during fragmentation and prior to sequencing. You cannot know the length of a fragment given only a read fr",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/127#issuecomment-750920243:1010,access,access,1010,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/127#issuecomment-750920243,2,['access'],['access']
Security,ls -l /work/yu_liu/resource/salmon_gencodev28_index/; total 2234181; -rw-r--r-- 1 yu_liu data-sci 179889 Jul 13 19:43 duplicate_clusters.tsv; -rw-r--r-- 1 yu_liu data-sci 673607680 Jul 13 19:47 hash.bin; -rw-r--r-- 1 yu_liu data-sci 0 Jul 13 19:47 header.json; -rw-r--r-- 1 yu_liu data-sci 0 Jul 13 19:47 indexing.log; -rw-r--r-- 1 yu_liu data-sci 8192 Jul 13 19:47 quasi_index.log; -rw-r--r-- 1 yu_liu data-sci 0 Jul 13 19:47 refInfo.json; -rw-r--r-- 1 yu_liu data-sci 38621520 Jul 13 19:43 rsd.bin; -rw-r--r-- 1 yu_liu data-sci 1235888364 Jul 13 19:44 sa.bin; -rw-r--r-- 1 yu_liu data-sci 336807483 Jul 13 19:43 txpInfo.bin; -rw-r--r-- 1 yu_liu data-sci 0 Jul 13 19:47 versionInfo.json,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/251#issuecomment-404957888:194,hash,hash,194,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/251#issuecomment-404957888,1,['hash'],['hash']
Security,"mon_index }; # [ libType ] => { IU }; # [ mates1 ] => { ../strange_peak/19232_1_1.fastq }; # [ mates2 ] => { ../strange_peak/19232_1_2.fastq }; # [ output ] => { quant_binary }; Logs will be written to quant_binary/logs; there is 1[2016-03-31 14:05:14.184] [jointLog] [info] parsing read library format; lib; Loading 64-bit quasi index[2016-03-31 14:05:14.266] [stderrLog] [info] Loading Suffix Array; [2016-03-31 14:05:14.266] [jointLog] [info] Loading Quasi index. [2016-03-31 14:07:58.647] [stderrLog] [info] Loading Transcript Info; [2016-03-31 14:08:59.703] [stderrLog] [info] Loading Rank-Select Bit Array; [2016-03-31 14:09:06.744] [stderrLog] [info] There were 2027284 set bits in the bit array; [2016-03-31 14:09:08.123] [stderrLog] [info] Computing transcript lengths; [2016-03-31 14:09:08.240] [stderrLog] [info] Waiting to finish loading hash; Index contained 2027284 targets; [2016-03-31 14:09:15.789] [jointLog] [info] done; [2016-03-31 14:09:15.786] [stderrLog] [info] Successfully loaded position hash; [2016-03-31 14:09:15.789] [stderrLog] [info] Done loading index. [2016-03-31 14:09:36.623] [jointLog] [info] Computed 8083 rich equivalence classes for further processing; [2016-03-31 14:09:36.623] [jointLog] [info] Counted 159824 total reads in the equivalence classes. [2016-03-31 14:13:24.480] [jointLog] [warning] Only 159824 fragments were mapped, but the number of burn-in fragments was set to 5000000.; The effective lengths have been computed using the observed mappings. [2016-03-31 14:13:24.480] [jointLog] [info] Mapping rate = 36.3942%. [2016-03-31 14:13:24.480] [jointLog] [info] finished quantifyLibrary(); [2016-03-31 14:13:24.480] [jointLog] [info] Starting optimizer; [2016-03-31 14:13:25.441] [jointLog] [info] Marked 0 weighted equivalence classes as degenerate; [2016-03-31 14:13:25.660] [jointLog] [info] iteration = 0 | max rel diff. = 13.7627; [2016-03-31 14:13:26.460] [jointLog] [info] iteration = 100 | max rel diff. = 0.100799; [2016-03-31 14:13:27.252] ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/54#issuecomment-204066023:1747,hash,hash,1747,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/54#issuecomment-204066023,1,['hash'],['hash']
Security,"my output from salmon.log. [2019-07-30 10:40:14.624] [jointLog] [info] Fragment incompatibility prior; below threshold. Incompatible fragments will be ignored.; [2019-07-30 10:40:14.624] [jointLog] [error] You passed paired-end files to; salmon, but you passed 12 files to --mates1 and 13 files to --mates2. You; must pass the same number of files to both flags. Thank you in advance for any tips you may have for me. Sara. On Tue, Jul 30, 2019 at 10:30 AM Sara Boles <seboles@ucdavis.edu> wrote:. > Hi Avi,; >; > Here is the salmon log from one of my PE libraries. There are only 12; > libraries for each in the directory, which is why I got confused when it; > said 13. I will try putting in all of the file names and let you know how; > it goes. Thank you for all of your help.; >; > Sara; >; > [2019-07-29 15:58:39.034] [jointLog] [info] Fragment incompatibility prior; > below threshold. Incompatible fragments will be ignored.; > [2019-07-29 15:58:39.034] [jointLog] [info] Usage of --validateMappings; > implies use of minScoreFraction. Since not explicitly specified, it is; > being set to 0.65; > [2019-07-29 15:58:39.034] [jointLog] [info] Usage of --validateMappings,; > without --hardFilter implies use of range factorization.; > rangeFactorizationBins is being set to 4; > [2019-07-29 15:58:39.034] [jointLog] [info] Usage of --validateMappings; > implies a default consensus slack of 0.2. Setting consensusSlack to 0.2.; > [2019-07-29 15:58:39.034] [jointLog] [info] parsing read library format; > [2019-07-29 15:58:39.034] [jointLog] [error] Failed to successfully parse; > any complete read libraries. Please make sure you provided arguments; > properly to -1, -2 (for paired-end libraries) or -r (for single-end; > libraries), and that the library format option (-l) *comes before* the read; > libraries.; >; > On Mon, Jul 29, 2019 at 4:06 PM Avi Srivastava <notifications@github.com>; > wrote:; >; >> Oh Sorry about that what I meant was the salmon.log file or the the; >> meta-info",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/408#issuecomment-516521791:2417,validat,validateMappings,2417,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/408#issuecomment-516521791,1,['validat'],['validateMappings']
Security,"n equal to the k-mer length of 31 (perhaps after poly-A clipping); [2020-12-26 11:30:13.489] [puff::index::jointLog] [warning] Entry with header [ENST00000603935.1], had length less than equal to the k-mer length of 31 (perhaps after poly-A clipping); [2020-12-26 11:30:13.489] [puff::index::jointLog] [warning] Entry with header [ENST00000604102.1], had length less than equal to the k-mer length of 31 (perhaps after poly-A clipping); [2020-12-26 11:30:13.489] [puff::index::jointLog] [warning] Entry with header [ENST00000604838.1], had length less than equal to the k-mer length of 31 (perhaps after poly-A clipping); [2020-12-26 11:30:14.411] [puff::index::jointLog] [warning] Entry with header [ENST00000579054.1], had length less than equal to the k-mer length of 31 (perhaps after poly-A clipping); [2020-12-26 11:30:15.280] [puff::index::jointLog] [warning] Entry with header [ENST00000634174.1], had length less than equal to the k-mer length of 31 (perhaps after poly-A clipping); [2020-12-26 11:31:24.590] [puff::index::jointLog] [warning] Removed 829 transcripts that were sequence duplicates of indexed transcripts.; [2020-12-26 11:31:24.590] [puff::index::jointLog] [warning] If you wish to retain duplicate transcripts, please use the `--keepDuplicates` flag; [2020-12-26 11:31:24.641] [puff::index::jointLog] [info] Replaced 151,122,967 non-ATCG nucleotides; [2020-12-26 11:31:24.641] [puff::index::jointLog] [info] Clipped poly-A tails from 1,829 transcripts; wrote 231443 cleaned references; [2020-12-26 11:31:28.118] [puff::index::jointLog] [info] Filter size not provided; estimating from number of distinct k-mers; [2020-12-26 11:31:58.286] [puff::index::jointLog] [info] ntHll estimated 2628436199 distinct k-mers, setting filter size to 2^36; Threads = 12; Vertex length = 31; Hash functions = 5; Filter size = 68719476736; Capacity = 2; Files:; salmon-decoy-sa-index/ref_k31_fixed.fa. **My concern is would it make problem for rest of downstream analysis?. Thanks,; Tima**; #",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/214#issuecomment-751354991:24307,Hash,Hash,24307,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/214#issuecomment-751354991,1,['Hash'],['Hash']
Security,"n the library type IU:; Name Length EffectiveLength TPM NumReads; LOC_Os01g01010.1 3017 3017.000 0.000000 0.000; LOC_Os01g01010.2 2218 2218.000 0.000000 0.000; LOC_Os01g01019.1 1127 1127.000 0.000000 0.000; LOC_Os01g01030.1 2464 2464.000 0.000000 0.000; LOC_Os01g01040.4 1524 1524.000 0.000000 0.000; LOC_Os01g01040.1 2508 2508.000 0.000000 0.000; LOC_Os01g01040.2 2482 2482.000 0.000000 0.000; LOC_Os01g01040.3 2583 2583.000 0.000000 0.000; LOC_Os01g01050.1 2039 2039.000 0.000000 0.000. [2019-03-04 01:24:12.788] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2019-03-04 01:24:12.788] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2019-03-04 01:24:12.788] [jointLog] [info] Usage of --validateMappings implies use of range factorization. rangeFactorizationBins is being set to 4; [2019-03-04 01:24:12.788] [jointLog] [info] Usage of --validateMappings implies a default consensus slack of 1. Setting consensusSlack to 1.; [2019-03-04 01:24:12.788] [jointLog] [info] parsing read library format; [2019-03-04 01:24:12.788] [jointLog] [info] There is 1 library.; [2019-03-04 01:24:12.852] [jointLog] [info] Loading Quasi index; [2019-03-04 01:24:12.852] [jointLog] [info] Loading 32-bit quasi index; [2019-03-04 01:24:19.703] [jointLog] [info] done; [2019-03-04 01:24:19.704] [jointLog] [info] Index contained 66,004 targets; [2019-03-04 01:25:14.064] [jointLog] [info] Thread saw mini-batch with a maximum of 91.10% zero probability fragments; [2019-03-04 01:25:14.075] [jointLog] [info] Thread saw mini-batch with a maximum of 90.58% zero probability fragments; [2019-03-04 01:25:14.085] [jointLog] [info] Thread saw mini-batch with a maximum of 90.64% zero probability fragments; [2019-03-04 01:25:14.089] [jointLog] [info] Thread saw mini-batch with a maximum of 91.08% zero probability fragments; [2019-03-04 01:25:14.091] [jointLog] [info] Thr",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/346#issuecomment-469215256:3949,validat,validateMappings,3949,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/346#issuecomment-469215256,1,['validat'],['validateMappings']
Security,"nd; salmon quant -p 3 -i salmonIndexDecoyMouse -l A -1 SRR1818187_2.fastq.gz -2 SRR1818187_1.fastq.gz --validateMappings -o Salmontranscripts_quant; Fails as follows, saying it cannot find a .json file(s); ---------------------------------------------------------------------; (salmon) wayne@Ubuntu19:~/rnaseq$ sh salmonQuantDecoy.sh ; Version Info: This is the most recent version of salmon.; ### salmon (mapping-based) v0.14.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ threads ] => { 3 }; ### [ index ] => { salmonIndexDecoyMouse }; ### [ libType ] => { A }; ### [ mates1 ] => { SRR1818187_2.fastq.gz }; ### [ mates2 ] => { SRR1818187_1.fastq.gz }; ### [ validateMappings ] => { }; ### [ output ] => { Salmontranscripts_quant }; Logs will be written to Salmontranscripts_quant/logs; [2019-08-25 11:40:44.518] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2019-08-25 11:40:44.518] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2019-08-25 11:40:44.518] [jointLog] [info] Usage of --validateMappings, without --hardFilter implies use of range factorization. rangeFactorizationBins is being set to 4; [2019-08-25 11:40:44.518] [jointLog] [info] Usage of --validateMappings implies a default consensus slack of 0.2. Setting consensusSlack to 0.2.; [2019-08-25 11:40:44.518] [jointLog] [info] parsing read library format; [2019-08-25 11:40:44.518] [jointLog] [info] There is 1 library.; Exception : [Error: The index version file salmonIndexDecoyMouse/versionInfo.json doesn't seem to exist. Please try re-building the salmon index.]; salmon quant was invoked improperly.; For usage information, try salmon quant --help; Exiting.; (salmon) wayne@Ubuntu19:~/rnaseq$ ls -R *.json; ls: cannot access '*.json': No such file or directory. Try 2.; Instead of referring to my directory decoys/ , I moved to the directory decoys/ ; and ran ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/419#issuecomment-524651435:1380,validat,validateMappings,1380,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/419#issuecomment-524651435,1,['validat'],['validateMappings']
Security,"ndex --libType IU -1; mgonad-2_S121_L006_R1_001.qc.fq.gz; lightreceptor-1_S114_L006_R1_001.qc.fq.gz; mgonad-1_S120_L006_R1_001.qc.fq.gz; lightreceptor-2_S115_L006_R1_001.qc.fq.gz; mgonad-2_S121_L005_R1_001.qc.fq.gz mgonad-1_S120_L005_R1_001.qc.fq.gz; lightreceptor-2_S115_L005_R1_001.qc.fq.gz; lightreceptor-1_S114_L005_R1_001.qc.fq.gz; mgonad-2_S121_L004_R1_001.qc.fq.gz mgonad-1_S120_L004_R1_001.qc.fq.gz; lightreceptor-2_S115_L004_R1_001.qc.fq.gz; lightreceptor-1_S114_L004_R1_001.qc.fq.gz -2; mgonad-2_S121_L006_R2_001.qc.fq.gz; lightreceptor-1_S114_L006_R2_001.qc.fq.gz; mgonad-1_S120_L006_R2_001.qc.fq.gz; lightreceptor-2_S115_L006_R2_001.qc.fq.gz; mgonad-2_S121_L005_R2_001.qc.fq.gz mgonad-1_S120_L005_R2_001.qc.fq.gz; lightreceptor-2_S115_L005_R2_001.qc.fq.gz; lightreceptor-1_S114_L005_R2_001.qc.fq.gz; mgonad-2_S121_L004_R2_001.qc.fq.gz mgonad-1_S120_L004_R2_001.qc.fq.gz; lightreceptor-2_S115_L004_R2_001.qc.fq.gz; lightreceptor-1_S114_L004_R2_001.qc.fq.gz ${i} -o ${i}_quant --seqBias; --gcBias --validateMappings; done```. And here is my output from salmon.log. [2019-07-30 10:40:14.624] [jointLog] [info] Fragment incompatibility prior; below threshold. Incompatible fragments will be ignored.; [2019-07-30 10:40:14.624] [jointLog] [error] You passed paired-end files to; salmon, but you passed 12 files to --mates1 and 13 files to --mates2. You; must pass the same number of files to both flags. Thank you in advance for any tips you may have for me. Sara. On Tue, Jul 30, 2019 at 10:30 AM Sara Boles <seboles@ucdavis.edu> wrote:. > Hi Avi,; >; > Here is the salmon log from one of my PE libraries. There are only 12; > libraries for each in the directory, which is why I got confused when it; > said 13. I will try putting in all of the file names and let you know how; > it goes. Thank you for all of your help.; >; > Sara; >; > [2019-07-29 15:58:39.034] [jointLog] [info] Fragment incompatibility prior; > below threshold. Incompatible fragments will be ignored.; > [2019-07-29 15:5",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/408#issuecomment-516521791:1387,validat,validateMappings,1387,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/408#issuecomment-516521791,1,['validat'],['validateMappings']
Security,"ndexing Barcodes; [2018-12-06 11:16:55.453] [alevinLog] [info] Total Unique barcodes found: 4180559; [2018-12-06 11:16:55.453] [alevinLog] [info] Used Barcodes except Whitelist: 134856; [2018-12-06 11:16:56.218] [jointLog] [info] There are 2 libraries.; [2018-12-06 11:16:56.292] [jointLog] [info] Loading Quasi index; [2018-12-06 11:16:56.294] [jointLog] [info] Loading 32-bit quasi index; [2018-12-06 11:16:56.205] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify. [2018-12-06 11:16:56.218] [alevinLog] [info] parsing read library format; [2018-12-06 11:16:56.296] [stderrLog] [info] Loading Suffix Array ; [2018-12-06 11:16:56.846] [stderrLog] [info] Loading Transcript Info ; [2018-12-06 11:16:57.009] [stderrLog] [info] Loading Rank-Select Bit Array; [2018-12-06 11:16:57.046] [stderrLog] [info] There were 167,268 set bits in the bit array; [2018-12-06 11:16:57.063] [stderrLog] [info] Computing transcript lengths; [2018-12-06 11:16:57.064] [stderrLog] [info] Waiting to finish loading hash; [2018-12-06 11:17:00.929] [jointLog] [info] done; [2018-12-06 11:17:00.929] [jointLog] [info] Index contained 167,268 targets. processed 267 Million fragmentsrrLog] [info] Done loading index; hits: 844899161, hits per frag: 3.15864^[[D. [2018-12-06 11:45:12.188] [jointLog] [info] Computed 118,295 rich equivalence classes for further processing; [2018-12-06 11:45:12.188] [jointLog] [info] Counted 154,595,094 total reads in the equivalence classes ; [2018-12-06 11:45:12.188] [jointLog] [warning] Found 115077 reads with `N` in the UMI sequence and ignored the reads.; Please report on github if this number is too large; [2018-12-06 11:45:12.188] [jointLog] [info] Mapping rate = 57.7821%. [2018-12-06 11:45:12.188] [jointLog] [info] finished quantifyLibrary(); [2018-12-06 11:45:13.385] [alevinLog] [info] Starting optimizer. Analyzed 5344 cells (100% of all).; [2018-12-06 11:49:42.634] [alevinLog] [info] Total 4845644.00 UMI after deduplicating.; [2018-12-06 11:49:42.722] [al",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/328#issuecomment-445008548:6761,hash,hash,6761,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/328#issuecomment-445008548,1,['hash'],['hash']
Security,"ng-based) v0.6.0; # [ program ] => salmon; # [ command ] => quant; # [ index ] => { /nfs/research2/teichmann/reference/mus-musculus/salmon/quasi/mouse_cdna_38.p3.78_repbase_ercc.fa }; # [ libType ] => { IU }; # [ mates1 ] => { /nfs/research2/teichmann/valentine/detection-comparison/salmon0.4.2-comparison/mouse/SRP057125_SRS936134_1.fastq }; # [ mates2 ] => { /nfs/research2/teichmann/valentine/detection-comparison/salmon0.4.2-comparison/mouse/SRP057125_SRS936134_2.fastq }; # [ output ] => { SRP057125_SRS936134_salmon_out }; # [ geneMap ] => { /nfs/research2/teichmann/reference/mus-musculus/salmon/mouse_cdna38.78_repbase_ercc_index_gene_map.txt }; # [ biasCorrect ] => { }; # [ useFSPD ] => { }; Logs will be written to SRP057125_SRS936134_salmon_out/logs; [2016-01-02 20:22:59.800] [jointLog] [info] parsing read library format; there is 1 lib; Loading 32-bit quasi index[2016-01-02 20:23:00.830] [stderrLog] [info] Loading Suffix Array; [2016-01-02 20:23:00.830] [stderrLog] [info] Loading Position Hash; [2016-01-02 20:23:00.829] [jointLog] [info] Loading Quasi index; [2016-01-02 20:23:03.751] [stderrLog] [info] Loading Transcript Info; [2016-01-02 20:23:04.776] [stderrLog] [info] Loading Rank-Select Bit Array; [2016-01-02 20:23:05.009] [stderrLog] [info] There were 104534 set bits in the bit array; [2016-01-02 20:23:05.325] [stderrLog] [info] Computing transcript lengths; [2016-01-02 20:23:05.325] [stderrLog] [info] Waiting to finish loading hash; Index contained 104534 targets; [2016-01-02 20:23:16.571] [stderrLog] [info] Done loading index; [2016-01-02 20:23:16.571] [jointLog] [info] done. processed 12000001 fragments; hits: 24367128, hits per frag: 2.04044. [2016-01-02 20:23:49.850] [jointLog] [info] Computed 102251 rich equivalence classes for further processing; [2016-01-02 20:23:49.850] [jointLog] [info] Counted 10033689 total reads in the equivalence classes; [2016-01-02 20:23:49.875] [jointLog] [info] Mapping rate = 83.0244%. [2016-01-02 20:23:49.875] [jointLog] [",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/34#issuecomment-168426741:7759,Hash,Hash,7759,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/34#issuecomment-168426741,1,['Hash'],['Hash']
Security,"ng] If you wish to retain duplicate transcripts, please use the `--keepDuplicates` flag; [2019-10-04 10:37:22.318] [ff::console] [info] Replaced 1,775,734,603 non-ATCG nucleotides; [2019-10-04 10:37:22.318] [ff::console] [info] Clipped poly-A tails from 422 transcripts; wrote 593292 cleaned references; seqHash 256 : bd425816a78195ed31cf17ce9df99c2bf56bff98f0df5ace1e958b263d805390; seqHash 512 : 845b625de6f8f018796e464f7c49f6596d2b31b28a58771d56ece24b3d9cad98b8189572ff43d6a3eb8ef24b5d3bc5ac0f89845a57e3682498a56a1bc920e7b7; nameHash 256 : 3bd11eac1e6b05e93689676ca056c165e7c26723c4b137fd284bb8b40ef5df62; nameHash 512 : e68449cfd99f5968182735275b00779b8a396e413a3629beef933e51bd18902c821c26e2a5461c687d023ef85168e58d76bacd5fe1f0a3111bfccc34af9c4035; [2019-10-04 10:37:37.931] [console] [info] Filter size not provided; estimating from number of distinct k-mers; [2019-10-04 10:38:33.012] [console] [info] ntHll estimated 2765935300 distinct k-mers, setting filter size to 2^36; Threads = 8; Vertex length = 31; Hash functions = 5; Filter size = 68719476736; Capacity = 2; Files:; test_pufferfish_index/ref_k31_fixed.fa; --------------------------------------------------------------------------------; Round 0, 0:68719476736; Pass Filling Filtering; 1 385 3124; 2 1258 2; True junctions count = 5437144; False junctions count = 4410615; Hash table size = 9847759; Candidate marks count = 26276463; --------------------------------------------------------------------------------; Reallocating bifurcations time: 6; True marks count: 20290262; Edges construction time: 5004; --------------------------------------------------------------------------------; Distinct junctions = 5437144. approximateContigTotalLength: 1543877663; counters:; 49076 936 921 40; Exception : [std::bad_alloc]; ./testing/src/novartis-pisces/pisces/redist/salmon/bin/salmon index was invoked improperly.; For usage information, try ./testing/src/novartis-pisces/pisces/redist/salmon/bin/salmon index --help; Exiting.; ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/432#issuecomment-538547108:1238,Hash,Hash,1238,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/432#issuecomment-538547108,2,['Hash'],['Hash']
Security,"notation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts -p 1 -l ISR 	-1 ${FILE1} -2 ${FILE2} 	-o /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/${ID} 2> logs/strace_${SGE_TASK_ID}.txt. echo ""**** Job ends ****""; date; ```. This requests SGE 2 cores with a total free memory of 2 * 7 = 14 GB and a maximum memory of 16 GB. This is the `strace` output for task 1:. ```; execve(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon"", [""/dcl01/lieber/ajaffe/Emily/RNAse""..., ""quant"", ""-i"", ""/dcl01/lieber/ajaffe/Emily/RNAse""..., ""-p"", ""1"", ""-l"", ""ISR"", ""-1"", ""/dcl01/lieber/ajaffe/lab/libd_al""..., ""-2"", ""/dcl01/lieber/ajaffe/lab/libd_al""..., ""-o"", ""/dcl01/lieber/ajaffe/lab/libd_al""...], [/* 107 vars */]) = 0; brk(0) = 0xc2c000; mmap(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7fffbfffd000; readlink(""/proc/self/exe"", ""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon"", 4096) = 88; access(""/etc/ld.so.preload"", R_OK) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/tls/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/tls/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/tls/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/tls"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linu",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:4461,access,access,4461,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,1,['access'],['access']
Security,"nt incompatibility prior below threshold. Incompatible fragments will be ignored.; [2019-08-25 11:40:44.518] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2019-08-25 11:40:44.518] [jointLog] [info] Usage of --validateMappings, without --hardFilter implies use of range factorization. rangeFactorizationBins is being set to 4; [2019-08-25 11:40:44.518] [jointLog] [info] Usage of --validateMappings implies a default consensus slack of 0.2. Setting consensusSlack to 0.2.; [2019-08-25 11:40:44.518] [jointLog] [info] parsing read library format; [2019-08-25 11:40:44.518] [jointLog] [info] There is 1 library.; Exception : [Error: The index version file salmonIndexDecoyMouse/versionInfo.json doesn't seem to exist. Please try re-building the salmon index.]; salmon quant was invoked improperly.; For usage information, try salmon quant --help; Exiting.; (salmon) wayne@Ubuntu19:~/rnaseq$ ls -R *.json; ls: cannot access '*.json': No such file or directory. Try 2.; Instead of referring to my directory decoys/ , I moved to the directory decoys/ ; and ran salmon index again, using your command exactly:; salmon index -t gentrome.fa -d decoys.txt -i combined_index. This time a few .json files were produced in the directory combined_index/ [your name this time]; [contents of decoys= combined_index gentrome.fa mus_musculus.tar.gz Salmontranscripts_quant; decoys.txt links.txt salmonQuantDecoy22.sh]. then [sh salmonQuantDecoy22.sh]; salmon quant -p 3 -i combined_index -l A -1 ../SRR1818187_2.fastq.gz -2 ../SRR1818187_1.fastq.gz --validateMappings -o Salmontranscripts_quant. Now no Segmentation Fault crash. ; The program finishes with; [2019-08-25 12:37:39.056] [jointLog] [info] Finished optimizer; [2019-08-25 12:37:39.056] [jointLog] [info] writing output . Now I am going to look for the mRNA counts. I think a major secret is to have mus_musculus.tar.gz in the same directory.; If my description is ac",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/419#issuecomment-524651435:2246,access,access,2246,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/419#issuecomment-524651435,1,['access'],['access']
Security,"o] Done indexing Barcodes; [2019-01-29 09:55:04.855] [alevinLog] [info] Total Unique barcodes found: 70316; [2019-01-29 09:55:04.855] [alevinLog] [info] Used Barcodes except Whitelist: 184; [2019-01-29 09:55:04.882] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify. [2019-01-29 09:55:04.882] [alevinLog] [info] parsing read library format; [2019-01-29 09:55:05.014] [stderrLog] [info] Loading Suffix Array ; [2019-01-29 09:55:04.882] [jointLog] [info] There is 1 library.; [2019-01-29 09:55:05.012] [jointLog] [info] Loading Quasi index; [2019-01-29 09:55:05.013] [jointLog] [info] Loading 32-bit quasi index; [2019-01-29 09:55:06.105] [stderrLog] [info] Loading Transcript Info ; [2019-01-29 09:55:09.968] [stderrLog] [info] Loading Rank-Select Bit Array; [2019-01-29 09:55:16.908] [stderrLog] [info] There were 80,511 set bits in the bit array; [2019-01-29 09:55:19.931] [stderrLog] [info] Computing transcript lengths; [2019-01-29 09:55:19.931] [stderrLog] [info] Waiting to finish loading hash; [2019-01-29 09:55:41.122] [jointLog] [info] done; [2019-01-29 09:55:41.122] [jointLog] [info] Index contained 80,511 targets; [2019-01-29 09:55:41.122] [stderrLog] [info] Done loading index. processed 0 Million fragments; hits: 161433, hits per frag: 0.32698. [2019-01-29 09:55:54.788] [alevinLog] [info] Starting optimizer; [2019-01-29 09:55:54.742] [jointLog] [info] Computed 6,346 rich equivalence classes for further processing; [2019-01-29 09:55:54.742] [jointLog] [info] Counted 80,300 total reads in the equivalence classes ; [2019-01-29 09:55:54.754] [jointLog] [warning] Only 80300 fragments were mapped, but the number of burn-in fragments was set to 5000000.; The effective lengths have been computed using the observed mappings. [2019-01-29 09:55:54.754] [jointLog] [info] Mapping rate = 8.80342%. [2019-01-29 09:55:54.754] [jointLog] [info] finished quantifyLibrary(). Analyzed 289 cells (100% of all).; [2019-01-29 09:55:56.858] [alevinLog] [info] Total 72037 UMI after",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/337#issuecomment-458481722:3355,hash,hash,3355,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/337#issuecomment-458481722,1,['hash'],['hash']
Security,"of 31 (perhaps after poly-A clipping); [2020-12-26 11:30:13.489] [puff::index::jointLog] [warning] Entry with header [ENST00000603935.1], had length less than equal to the k-mer length of 31 (perhaps after poly-A clipping); [2020-12-26 11:30:13.489] [puff::index::jointLog] [warning] Entry with header [ENST00000604102.1], had length less than equal to the k-mer length of 31 (perhaps after poly-A clipping); [2020-12-26 11:30:13.489] [puff::index::jointLog] [warning] Entry with header [ENST00000604838.1], had length less than equal to the k-mer length of 31 (perhaps after poly-A clipping); [2020-12-26 11:30:14.411] [puff::index::jointLog] [warning] Entry with header [ENST00000579054.1], had length less than equal to the k-mer length of 31 (perhaps after poly-A clipping); [2020-12-26 11:30:15.280] [puff::index::jointLog] [warning] Entry with header [ENST00000634174.1], had length less than equal to the k-mer length of 31 (perhaps after poly-A clipping). [2020-12-26 11:31:24.590] [puff::index::jointLog] [warning] Removed 829 transcripts that were sequence duplicates of indexed transcripts.; [2020-12-26 11:31:24.590] [puff::index::jointLog] [warning] If you wish to retain duplicate transcripts, please use the `--keepDuplicates` flag; [2020-12-26 11:31:24.641] [puff::index::jointLog] [info] Replaced 151,122,967 non-ATCG nucleotides; [2020-12-26 11:31:24.641] [puff::index::jointLog] [info] Clipped poly-A tails from 1,829 transcripts; wrote 231443 cleaned references; [2020-12-26 11:31:28.118] [puff::index::jointLog] [info] Filter size not provided; estimating from number of distinct k-mers; [2020-12-26 11:31:58.286] [puff::index::jointLog] [info] ntHll estimated 2628436199 distinct k-mers, setting filter size to 2^36; Threads = 12; Vertex length = 31; Hash functions = 5; Filter size = 68719476736; Capacity = 2; Files:; salmon-decoy-sa-index/ref_k31_fixed.fa; -----------------------------. **My concern is would it make problem for rest of downstream analysis?. Thanks,; Tima**",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/214#issuecomment-751354493:24354,Hash,Hash,24354,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/214#issuecomment-751354493,1,['Hash'],['Hash']
Security,"og] [info] chunk 5 = [185,776,605, 222,931,953); [2021-12-31 11:28:47.220] [puff::index::jointLog] [info] chunk 6 = [222,931,953, 260,087,274); [2021-12-31 11:28:47.220] [puff::index::jointLog] [info] chunk 7 = [260,087,274, 297,242,536); [2021-12-31 11:28:57.275] [puff::index::jointLog] [info] finished populating pos vector; [2021-12-31 11:28:57.275] [puff::index::jointLog] [info] writing index components; [2021-12-31 11:28:59.670] [puff::index::jointLog] [info] finished writing dense pufferfish index; [2021-12-31 11:28:59.944] [jLog] [info] done building index; Threads = 8; Vertex length = 29; Hash functions = 5; Filter size = 4294967296; Capacity = 2; Files: ; /no_backup/indexes/salmon/mm10_gencode/ref_k29_fixed.fa; --------------------------------------------------------------------------------; Round 0, 0:4294967296; Pass	Filling	Filtering; 1	22	34	; 2	9	0; True junctions count = 1275494; False junctions count = 1606379; Hash table size = 2881873; Candidate marks count = 14783512; --------------------------------------------------------------------------------; Reallocating bifurcations time: 0; True marks count: 12564712; Edges construction time: 10; --------------------------------------------------------------------------------; Distinct junctions = 1275494. for info, total work write each : 2.331 total work inram from level 3 : 4.322 total work raw : 25.000 ; Bitarray 1252655360 bits (100.00 %) (array + ranks ); final hash 0 bits (0.00 %) (nb in final hash 0); ```. And these files are present in the index folder:; ```; ls -1 /no_backup/indexes/salmon/mm10_gencode; complete_ref_lens.bin; ctable.bin; ctg_offsets.bin; duplicate_clusters.tsv; info.json; mphf.bin; pos.bin; pre_indexing.log; rank.bin; refAccumLengths.bin; ref_indexing.log; reflengths.bin; refseq.bin; seq.bin; versionInfo.json; ```. So the problem was that the transcript file I provided to the `generateDecoyTranscriptome.sh` was gzipped and failed with `cat`.... 🤦‍♂️. Thanks a lot the help!; Nicco",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/731#issuecomment-1003342883:5803,Hash,Hash,5803,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/731#issuecomment-1003342883,3,"['Hash', 'hash']","['Hash', 'hash']"
Security,"otal 867878 UniDirected Edges.; [2022-03-27 05:49:49.761] [alevinLog] [warning] Skipped 955 barcodes due to No mapped read; [2022-03-27 05:49:49.766] [alevinLog] [info] Clearing EqMap; Might take some time.; [2022-03-27 05:49:50.011] [alevinLog] [info] Starting white listing of 3044 cells; [2022-03-27 05:49:50.011] [alevinLog] [info] Starting to make feature Matrix; [2022-03-27 05:49:50.014] [alevinLog] [info] Done making feature Matrix; [2022-03-27 05:49:50.717] [alevinLog] [info] Finished white listing; [2022-03-27 05:49:51.422] [alevinLog] [info] Finished optimizer; ````. and the `salmon_quant.log` looks like:; ```; [2022-03-27 05:24:09.395] [jointLog] [info] setting maxHashResizeThreads to 32; [2022-03-27 05:24:09.395] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2022-03-27 05:24:09.395] [jointLog] [info] The --mimicBT2, --mimicStrictBT2 and --hardFilter flags imply mapping validation (--validateMappings). Enabling mapping validation.; [2022-03-27 05:24:09.395] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2022-03-27 05:24:09.395] [jointLog] [info] The use of range-factorized equivalence classes does not make sense in conjunction with --hardFilter. Disabling range-factorized equivalence classes. ; [2022-03-27 05:24:09.395] [jointLog] [info] Setting consensusSlack to selective-alignment default of 0.35.; [2022-03-27 05:24:09.395] [jointLog] [info] Using default value of 0.87 for minScoreFraction in Alevin; Using default value of 0.6 for consensusSlack in Alevin; [2022-03-27 05:34:26.966] [jointLog] [info] There is 1 library.; [2022-03-27 05:34:26.967] [jointLog] [info] Loading pufferfish index; [2022-03-27 05:34:26.967] [jointLog] [info] Loading dense pufferfish index.; [2022-03-27 05:34:27.433] [jointLog] [info] done; [2022-03-27 05:34:27.504] [jointLog] [info] Index contained 116,755 targets; [2022-03-27 05:34:",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/763#issuecomment-1082597942:4536,validat,validation,4536,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/763#issuecomment-1082597942,1,['validat'],['validation']
Security,"otally disabling this with the —noLengthCorrection flag** (NOT the —no**Effective**LengthCorrection flag) **actually *creates* the transcript within a transcript failure scenario that I mistakenly thought was the original issue.** That is, when length bias modeling is turned off, then longer transcripts will always get assigned *all* of the reads that multimap to shorter transcripts.; -Therefore... if you *did* want to tackle the transcript within a transcript scenario to build a coverage bias model, you probably want to disable the length bias modeling or at least consider how it would interact with coverage modeling. With that said, I'm sharing an example that illustrates each of the above points and a link to a toy dataset that you can use to recreate the examples or explore this further. If you'd like to dig deeper into this, free free to e-mail me at jason@calicolabs.com, I have tons more notes and data that I'm willing to share. Dataset is in google drive (you'll have to click the link and request access to view it) https://drive.google.com/drive/folders/1LcJNa4PHNoYqGsnkRx0YxvNXnNJCVyq9?usp=sharing. 1. **Success scenarios with default options:** . In the below IGV snapshots, I show the read alignments for one sample. The top GTF annotation is the default gene annotation, and the GTF at the bottom shows the new transcript isoforms I made and quantified on (this index is called ""extras""). For each example I ran salmon on the transcripts from the default or extra index, with standard options (only --validateMappings), with or without the --noLengthCorrection flag. **I'm showing only the number of reads** assigned to each transcript, not the TPM. I also tried this on more samples and transcript scenarios and saw the same trends. **Nested transcript isoforms:** ; ![AGP1_example](https://user-images.githubusercontent.com/10292386/86509506-45654000-bd9d-11ea-839f-6637620c3247.png). <img width=""430"" alt=""AGP1_table"" src=""https://user-images.githubusercontent.com/1029",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-653747847:1952,access,access,1952,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-653747847,2,['access'],['access']
Security,"ou'd expect to get more mappings) than when you specify ""ISR"". The ""A"" flag just looks at how the first 10,000 reads map and guesses the library type based on that. On thing to make sure of is that your reads aren't ""ordered"" in any way, such that you'd expect the first 10,000 to deviate in any meaningful way from the statistics of the reads of the reads. > Is it better to build assemblies with strand-aware flags? If so, does it usually make a large difference to quantification results, or a minor one? I don't know what protocol the sequencing facility used, but I am sure I could ask them. I gather from my recent reading that the extra information gained by using a stranded protocol is worthwhile, so I would expect that the sequencing facility used one, but why doesn't Trinity or MEGAHIT detect the sequecing protocol that was used? . So there are really 2 questions here. *If* the data are stranded, then yes, it's worthwhile to use stranded flags in both assembly and quantification. This is because stranded protocols will allow you to better disambiguate (a) overlapping genes and (b) reads that are ambiguous between sequence-similar genes that happen to reside on different strands. The *second* question is why Trinity or MEGAHIT wouldn't detect this. The main reason for this is that these are assembly tools. Without access to a reference genome, there is no principled way for these tools to know what the orientation of a read is _a priori_, so they generally rely on the user to specify if the reads are stranded or unstranded. > Or, if you have to specify it, why do none of the example Trinity commands I've come across include this option? It doesn't strike me as a commonly used specification in making assemblies. The Trinity command to specify the strandedness is `--SS_lib_type` (see e.g. [here](https://scilifelab.github.io/courses/ngsintro/1604/labs/rnaseqDenovo)). By default, Trinity will assume unstranded reads (as that's the safest default assumption). Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/840#issuecomment-1493034427:1801,access,access,1801,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/840#issuecomment-1493034427,1,['access'],['access']
Security,"ouse genome and one of the bacteria species of interest. . Given the several orders of magnitude difference in discarded alignments between mine on 1.2.1 and your test run on 1.3.1, would you recommend I redo the whole dataset alignment on 1.3.1? If it runs even close to what you saw it shouldn’t take too long; to rerun. . Thanks again,. Ryan. Sent from my iPhone. On Jun 16, 2020, at 12:13 AM, Rob Patro <notifications@github.com> wrote:. ﻿. I processed the data above using the latest salmon from the develop branch; (the release candidate for 1.3.0), and I got the following time (used 8; threads, so timing is not directly comparable). ```; 4604.57user 43.64system 9:24.15elapsed 823%CPU; ```. The whole log is. ```; [2020-06-15 23:51:54.747] [jointLog] [info] setting maxHashResizeThreads to; 8; [2020-06-15 23:51:54.747] [jointLog] [info] Fragment incompatibility prior; below threshold. Incompatible fragments will be ignored.; [2020-06-15 23:51:54.747] [jointLog] [info] Usage of --validateMappings; implies use of minScoreFraction. Since not explicitly specified, it is; being set to 0.65; [2020-06-15 23:51:54.747] [jointLog] [info] Usage of --validateMappings; implies a default consensus slack of 0.2. Setting consensusSlack to 0.35.; [2020-06-15 23:51:54.747] [jointLog] [info] parsing read library format; [2020-06-15 23:51:54.747] [jointLog] [info] There is 1 library.; [2020-06-15 23:51:54.814] [jointLog] [info] Loading pufferfish index; [2020-06-15 23:51:54.814] [jointLog] [info] Loading dense pufferfish index.; [2020-06-15 23:51:55.555] [jointLog] [info] done; [2020-06-15 23:51:55.555] [jointLog] [info] Index contained 116,248 targets; [2020-06-15 23:51:55.588] [jointLog] [info] Number of decoys : 0; [2020-06-16 00:00:59.666] [jointLog] [info] Computed 344,764 rich; equivalence classes for further processing; [2020-06-16 00:00:59.666] [jointLog] [info] Counted 12,956,134 total reads; in the equivalence classes; [2020-06-16 00:00:59.673] [jointLog] [warning] 0.0736383% ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/537#issuecomment-644527727:1303,validat,validateMappings,1303,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/537#issuecomment-644527727,1,['validat'],['validateMappings']
Security,"ovided; using is 1 less feature for whitelisting; > [2020-06-04 17:57:37.338] [alevinLog] [info] Total 23937.00 UMI after deduplicating.; > [2020-06-04 17:57:37.338] [alevinLog] [info] Total 91 BiDirected Edges.; > [2020-06-04 17:57:37.338] [alevinLog] [info] Total 82 UniDirected Edges.; > [2020-06-04 17:57:37.338] [alevinLog] [warning] Skipped 82268 barcodes due to No mapped read; > [2020-06-04 17:57:37.341] [alevinLog] [info] Clearing EqMap; Might take some time.; > [2020-06-04 17:57:37.348] [alevinLog] [warning] Num Low confidence barcodes too less 1 < 10.Can't performing whitelisting; Skipping; > [2020-06-04 17:57:37.348] [alevinLog] [info] Finished optimizer; > ; > . salmon_quant.log. > [2020-06-04 17:55:11.700] [jointLog] [info] setting maxHashResizeThreads to 7; > [2020-06-04 17:55:11.700] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; > [2020-06-04 17:55:11.700] [jointLog] [info] The --mimicBT2, --mimicStrictBT2 and --hardFilter flags imply mapping validation (--validateMappings). Enabling mapping validation.; > [2020-06-04 17:55:11.700] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; > [2020-06-04 17:55:11.700] [jointLog] [info] The use of range-factorized equivalence classes does not make sense in conjunction with --hardFilter. Disabling range-factorized equivalence classes. ; > [2020-06-04 17:55:11.700] [jointLog] [info] Usage of --validateMappings implies a default consensus slack of 0.2. Setting consensusSlack to 0.35.; > [2020-06-04 17:55:11.700] [jointLog] [info] Using default value of 0.797619 for minScoreFraction in Alevin; > Using default value of 0.6 for consensusSlack in Alevin; > [2020-06-04 17:56:30.294] [jointLog] [info] There is 1 library.; > [2020-06-04 17:56:30.355] [jointLog] [info] Loading pufferfish index; > [2020-06-04 17:56:30.355] [jointLog] [info] Loading dense pufferfish index.; > [2020-0",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-639196415:3028,validat,validation,3028,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-639196415,2,['validat'],"['validateMappings', 'validation']"
Security,"plicates` is passed) any identical / duplicate sequences. After all of this, it will begin constructing the index in earnest. This is done by running a modified version of [TwoPaCo](https://github.com/medvedevgroup/TwoPaCo) to construct the compacted colored de Bruijn graph on the gentrome, which is then indexed using our [pufferfish index](https://github.com/COMBINE-lab/pufferfish). The TwoPaCo algorithm that generates the compacted colored de Bruijn graph from the input sequence is based on a very elegant algorithm that couples a Bloom filter with an exact hash table, and makes two (or more) passes over the input to identify all of the junctions in the reference (which directly implies all unitigs). To make the algorithm work efficiently, one needs to have an estimate for the number of distinct k-mers that will be encountered in the reference sequence. If the estimate is too big, one wastes memory. If the estimate is too small, the Bloom filter is not big enough, it doesn't filter efficiently, and the algorithm ends up putting way too much data in the exact hash table. In order to determine how to set the Bloom filter size appropriately, we take the following approach. If the Bloom filter size isn't provided directly (_note_: this is _not_ the same as the k-mer size, this is an estimate of the total number of distinct k-mers in the entire input data), then we make a call to a function defined in the [ntCard](https://github.com/bcgsc/ntCard) library. This is a program designed specifically for cardinality estimation of k-mers in sequencing data. Based on the estimated number of distinct k-mers, we use the standard equations (derived from the theory behind Bloom filters) to set the Bloom filter to be of the smallest possible size that still achieves a relatively low, pre-specified, false positive rate. The message you are seeing is that the estimates suggest the Bloom filter should be of size 2^28 *bits*, which is ~ 33.55MB — pretty small, actually. This is because ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/510#issuecomment-616713186:1656,hash,hash,1656,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/510#issuecomment-616713186,1,['hash'],['hash']
Security,"put ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test5/R10001_D2B1WACXX }; Logs will be written to /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test5/R10001_D2B1WACXX/logs; [1m[2017-03-29 23:59:18.699] [jointLog] [info] parsing read library format; [00m[1m[2017-03-29 23:59:18.721] [jointLog] [info] There is 1 library.; [00m[1m[2017-03-30 00:43:17.278] [stderrLog] [info] Loading Suffix Array ; [00m[1m[2017-03-30 00:43:17.237] [jointLog] [info] Loading Quasi index; [00m[1m[2017-03-30 00:43:17.273] [jointLog] [info] Loading 32-bit quasi index; [00m[1m[2017-03-30 02:37:54.437] [stderrLog] [info] Loading Transcript Info ; [00m[1m[2017-03-30 03:48:21.310] [stderrLog] [info] Loading Rank-Select Bit Array; [00m[1m[2017-03-30 04:20:16.735] [stderrLog] [info] There were 198093 set bits in the bit array; [00m[1m[2017-03-30 04:54:34.486] [stderrLog] [info] Computing transcript lengths; [00m[1m[2017-03-30 04:54:34.487] [stderrLog] [info] Waiting to finish loading hash; [00m[1m[2017-03-30 05:09:36.706] [stderrLog] [info] Done loading index; [00m[1m[2017-03-30 05:09:36.706] [jointLog] [info] done; [00m[1m[2017-03-30 05:09:36.790] [jointLog] [info] Index contained 198093 targets; [00m. [A. [32mprocessed[31m 500000 [32mfragments[0m; hits: 699833, hits per frag: 1.4138[A. [32mprocessed[31m 1000000 [32mfragments[0m; hits: 1395659, hits per frag: 1.40267[A. [32mprocessed[31m 1500000 [32mfragments[0m; hits: 2097294, hits per frag: 1.40287[A. [32mprocessed[31m 2000000 [32mfragments[0m; hits: 2794766, hits per frag: 1.40089[A. [32mprocessed[31m 2500000 [32mfragments[0m; hits: 3489235, hits per frag: 1.39849[A. [32mprocessed[31m 3000000 [32mfragments[0m; hits: 4183913, hits per frag: 1.39697[A. [32mprocessed[31m 3500000 [32mfragments[0m; hits: 4884560, hits per frag: 1.39759[A. [32mprocessed[31m 4000000 [32mfragments[0m; hits: 5584692, hits per frag: 1.39792[A. [32mprocessed[31m 4500000 [32mfragmen",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-290516965:10457,hash,hash,10457,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-290516965,1,['hash'],['hash']
Security,"r poly-A clipping); [2018-08-06 09:29:04.752] [jointLog] [warning] Entry with header [ENST00000603693.1|ENSG00000270451.1|OTTHUMG00000184611.3|OTTHUMT00000468945.3|RP11-810K23.14-001|IGHD4OR15-4B|19|IG_D_gene|], had length less than the k-mer length of 31 (perhaps after poly-A clipping); [2018-08-06 09:29:04.752] [jointLog] [warning] Entry with header [ENST00000604838.1|ENSG00000270185.1|OTTHUMG00000184585.2|OTTHUMT00000468915.2|RP11-1360M22.4-001|IGHD1OR15-1B|17|IG_D_gene|], had length less than the k-mer length of 31 (perhaps after poly-A clipping); [2018-08-06 09:29:05.304] [jointLog] [warning] Entry with header [ENST00000579054.1|ENSG00000266416.1|OTTHUMG00000179204.1|OTTHUMT00000445280.1|RP1-66C13.2-001|RP1-66C13.2|28|processed_pseudogene|], had length less than the k-mer length of 31 (perhaps after poly-A clipping); [2018-08-06 09:29:05.761] [jointLog] [warning] Entry with header [ENST00000634174.1|ENSG00000282732.1|OTTHUMG00000191398.1|OTTHUMT00000487783.1|RP11-157B13.10-001|RP11-157B13.10|28|unprocessed_pseudogene|], had length less than the k-mer length of 31 (perhaps after poly-A clipping); Elapsed time: 5.65811s. [2018-08-06 09:29:06.451] [jointLog] [warning] Removed 808 transcripts that were sequence duplicates of indexed transcripts.; [2018-08-06 09:29:06.451] [jointLog] [warning] If you wish to retain duplicate transcripts, please use the `--keepDuplicates` flag; Replaced 4 non-ATCG nucleotides; Clipped poly-A tails from 1586 transcripts; Building rank-select dictionary and saving to disk done; Elapsed time: 0.0178594s; Writing sequence data to file . . . done; Elapsed time: 0.702003s; [info] Building 32-bit suffix array (length of generalized text is 308972089); Building suffix array . . . success; saving to disk . . . done; Elapsed time: 8.62493s; done; Elapsed time: 35.9517s; processed 308000000 positions; khash had 130317526 keys; saving hash to disk . . . done; Elapsed time: 29.414s; [2018-08-06 09:34:12.370] [jLog] [info] done building index; ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/214#issuecomment-410601245:21214,hash,hash,21214,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/214#issuecomment-410601245,1,['hash'],['hash']
Security,"raps=30 \; -p 12 -o ~/results/salmon_quant_Sheng_IU/${line} --seqBias --gcBias --validateMappings. There are no estimate and reads generated when invokin the library type IU:; Name Length EffectiveLength TPM NumReads; LOC_Os01g01010.1 3017 3017.000 0.000000 0.000; LOC_Os01g01010.2 2218 2218.000 0.000000 0.000; LOC_Os01g01019.1 1127 1127.000 0.000000 0.000; LOC_Os01g01030.1 2464 2464.000 0.000000 0.000; LOC_Os01g01040.4 1524 1524.000 0.000000 0.000; LOC_Os01g01040.1 2508 2508.000 0.000000 0.000; LOC_Os01g01040.2 2482 2482.000 0.000000 0.000; LOC_Os01g01040.3 2583 2583.000 0.000000 0.000; LOC_Os01g01050.1 2039 2039.000 0.000000 0.000. [2019-03-04 01:24:12.788] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2019-03-04 01:24:12.788] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2019-03-04 01:24:12.788] [jointLog] [info] Usage of --validateMappings implies use of range factorization. rangeFactorizationBins is being set to 4; [2019-03-04 01:24:12.788] [jointLog] [info] Usage of --validateMappings implies a default consensus slack of 1. Setting consensusSlack to 1.; [2019-03-04 01:24:12.788] [jointLog] [info] parsing read library format; [2019-03-04 01:24:12.788] [jointLog] [info] There is 1 library.; [2019-03-04 01:24:12.852] [jointLog] [info] Loading Quasi index; [2019-03-04 01:24:12.852] [jointLog] [info] Loading 32-bit quasi index; [2019-03-04 01:24:19.703] [jointLog] [info] done; [2019-03-04 01:24:19.704] [jointLog] [info] Index contained 66,004 targets; [2019-03-04 01:25:14.064] [jointLog] [info] Thread saw mini-batch with a maximum of 91.10% zero probability fragments; [2019-03-04 01:25:14.075] [jointLog] [info] Thread saw mini-batch with a maximum of 90.58% zero probability fragments; [2019-03-04 01:25:14.085] [jointLog] [info] Thread saw mini-batch with a maximum of 90.64% zero probability fragments; [2019-03-04 01",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/346#issuecomment-469215256:3799,validat,validateMappings,3799,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/346#issuecomment-469215256,1,['validat'],['validateMappings']
Security,"rcodes except Whitelist: 20705; [2018-07-19 22:55:38.386] [jointLog] [info] There is 1 library.; [2018-07-19 22:55:38.493] [jointLog] [info] Loading Quasi index; [2018-07-19 22:55:38.494] [jointLog] [info] Loading 32-bit quasi index; [2018-07-19 22:55:38.549] [jointLog] [info] done; [2018-07-19 22:55:38.549] [jointLog] [info] Index contained 179 targets. [2018-07-19 22:55:38.385] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify. [2018-07-19 22:55:38.385] [alevinLog] [info] parsing read library format; [2018-07-19 22:55:38.495] [stderrLog] [info] Loading Suffix Array ; [2018-07-19 22:55:38.498] [stderrLog] [info] Loading Transcript Info ; [2018-07-19 22:55:38.499] [stderrLog] [info] Loading Rank-Select Bit Array; [2018-07-19 22:55:38.500] [stderrLog] [info] There were 179 set bits in the bit array; [2018-07-19 22:55:38.501] [stderrLog] [info] Computing transcript lengths; [2018-07-19 22:55:38.501] [stderrLog] [info] Waiting to finish loading hash; processed 87 Million fragmentserrLog] [info] Done loading index; hits: 468892, hits per frag: 0.00535907. [2018-07-19 23:03:35.740] [jointLog] [info] Computed 150 rich equivalence classes for further processing; [2018-07-19 23:03:35.740] [jointLog] [info] Counted 412868 total reads in the equivalence classes ; [2018-07-19 23:03:35.741] [jointLog] [warning] Only 412868 fragments were mapped, but the number of burn-in fragments was set to 5000000.; The effective lengths have been computed using the observed mappings. [2018-07-19 23:03:35.741] [jointLog] [info] Mapping rate = 0.469385%. [2018-07-19 23:03:35.741] [jointLog] [info] finished quantifyLibrary(); [2018-07-19 23:03:35.755] [alevinLog] [info] Starting optimizer. Analyzed 5238 cells (100% of all).; Skipped Barcodes are from High Confidence Region; `$ls -ltrha alevin_output/alevin/`; total 256K; drwxrwx--- 6 zare G-816158 4.0K Jul 19 22:36 ..; -rw-rw---- 1 zare G-816158 960 Jul 19 23:03 alevin.log; drwxrwx--- 2 zare G-816158 4.0K Jul 19 23:03 .; -rw-r",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/253#issuecomment-406597243:3239,hash,hash,3239,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/253#issuecomment-406597243,1,['hash'],['hash']
Security,"rsion Info: This is the most recent version of salmon.; ### salmon (mapping-based) v0.14.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ threads ] => { 3 }; ### [ index ] => { salmonIndexDecoyMouse }; ### [ libType ] => { A }; ### [ mates1 ] => { SRR1818187_2.fastq.gz }; ### [ mates2 ] => { SRR1818187_1.fastq.gz }; ### [ validateMappings ] => { }; ### [ output ] => { Salmontranscripts_quant }; Logs will be written to Salmontranscripts_quant/logs; [2019-08-25 11:40:44.518] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2019-08-25 11:40:44.518] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2019-08-25 11:40:44.518] [jointLog] [info] Usage of --validateMappings, without --hardFilter implies use of range factorization. rangeFactorizationBins is being set to 4; [2019-08-25 11:40:44.518] [jointLog] [info] Usage of --validateMappings implies a default consensus slack of 0.2. Setting consensusSlack to 0.2.; [2019-08-25 11:40:44.518] [jointLog] [info] parsing read library format; [2019-08-25 11:40:44.518] [jointLog] [info] There is 1 library.; Exception : [Error: The index version file salmonIndexDecoyMouse/versionInfo.json doesn't seem to exist. Please try re-building the salmon index.]; salmon quant was invoked improperly.; For usage information, try salmon quant --help; Exiting.; (salmon) wayne@Ubuntu19:~/rnaseq$ ls -R *.json; ls: cannot access '*.json': No such file or directory. Try 2.; Instead of referring to my directory decoys/ , I moved to the directory decoys/ ; and ran salmon index again, using your command exactly:; salmon index -t gentrome.fa -d decoys.txt -i combined_index. This time a few .json files were produced in the directory combined_index/ [your name this time]; [contents of decoys= combined_index gentrome.fa mus_musculus.tar.gz Salmontranscripts_quant; decoys.txt links.txt salmonQuantDeco",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/419#issuecomment-524651435:1714,validat,validateMappings,1714,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/419#issuecomment-524651435,1,['validat'],['validateMappings']
Security,"rsion of Salmon.; # salmon (mapping-based) v0.6.0; # [ program ] => salmon; # [ command ] => quant; # [ threads ] => { 15 }; # [ index ] => { salmon_index }; # [ libType ] => { IU }; # [ mates1 ] => { ../strange_peak/19232_1_1.fastq }; # [ mates2 ] => { ../strange_peak/19232_1_2.fastq }; # [ output ] => { quant_binary }; Logs will be written to quant_binary/logs; there is 1[2016-03-31 14:05:14.184] [jointLog] [info] parsing read library format; lib; Loading 64-bit quasi index[2016-03-31 14:05:14.266] [stderrLog] [info] Loading Suffix Array; [2016-03-31 14:05:14.266] [jointLog] [info] Loading Quasi index. [2016-03-31 14:07:58.647] [stderrLog] [info] Loading Transcript Info; [2016-03-31 14:08:59.703] [stderrLog] [info] Loading Rank-Select Bit Array; [2016-03-31 14:09:06.744] [stderrLog] [info] There were 2027284 set bits in the bit array; [2016-03-31 14:09:08.123] [stderrLog] [info] Computing transcript lengths; [2016-03-31 14:09:08.240] [stderrLog] [info] Waiting to finish loading hash; Index contained 2027284 targets; [2016-03-31 14:09:15.789] [jointLog] [info] done; [2016-03-31 14:09:15.786] [stderrLog] [info] Successfully loaded position hash; [2016-03-31 14:09:15.789] [stderrLog] [info] Done loading index. [2016-03-31 14:09:36.623] [jointLog] [info] Computed 8083 rich equivalence classes for further processing; [2016-03-31 14:09:36.623] [jointLog] [info] Counted 159824 total reads in the equivalence classes. [2016-03-31 14:13:24.480] [jointLog] [warning] Only 159824 fragments were mapped, but the number of burn-in fragments was set to 5000000.; The effective lengths have been computed using the observed mappings. [2016-03-31 14:13:24.480] [jointLog] [info] Mapping rate = 36.3942%. [2016-03-31 14:13:24.480] [jointLog] [info] finished quantifyLibrary(); [2016-03-31 14:13:24.480] [jointLog] [info] Starting optimizer; [2016-03-31 14:13:25.441] [jointLog] [info] Marked 0 weighted equivalence classes as degenerate; [2016-03-31 14:13:25.660] [jointLog] [info] iteration ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/54#issuecomment-204066023:1584,hash,hash,1584,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/54#issuecomment-204066023,1,['hash'],['hash']
Security,"sam-xlate is actually the only tool that I'm aware of to perform this operation on an existing BAM file. I've heard of people using it with success. Of course, I'd also think of doing an analysis with the original reads to validate concordance. Note: if you don't have the original reads, you can do a BAM -> FASTQ conversion to recover the read sequences and then feed them to Salmon.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/131#issuecomment-293316682:223,validat,validate,223,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/131#issuecomment-293316682,1,['validat'],['validate']
Security,"shResizeThreads 2 -i /u/user/ref/cellranger/salmon/transcripts_index --tgMap tx2gene.txt; Starting program: /u/user/local/bin/salmon alevin -l ISR --chromium -p 4 -o BM_1/alevin -1 ./BM_1/run1/bm_S10_L001_R1_001.fastq.gz -2 ./BM_1/run1/bm_S10_L001_R2_001.fastq.gz --maxHashResizeThreads 2 -i /u/user/ref/cellranger/salmon/transcripts_index --tgMap tx2gene.txt; [Thread debugging using libthread_db enabled]; Using host libthread_db library ""/lib/x86_64-linux-gnu/libthread_db.so.1"".; warning: File ""/u/user/local/lib64/libstdc++.so.6.0.21-gdb.py"" auto-loading has been declined by your `auto-load safe; -path' set to ""$debugdir:$datadir/auto-load"".; To enable execution of this file add; add-auto-load-safe-path /u/user/local/lib64/libstdc++.so.6.0.21-gdb.py; line to your configuration file ""/u/user/.gdbinit"".; To completely disable this security protection add; set auto-load safe-path /; line to your configuration file ""/u/user/.gdbinit"".; For more information about this security protection see the; ""Auto-loading safe path"" section in the GDB manual. E.g., run from the shell:; info ""(gdb)Auto-loading safe path""; [New Thread 0x7fff7dbff700 (LWP 21437)]; [Thread 0x7fff7dbff700 (LWP 21437) exited]; Version Info: Could not resolve upgrade information in the alotted time.; Check for upgrades manually at https://combine-lab.github.io/salmon; [New Thread 0x7ffefcfff700 (LWP 21653)]; Logs will be written to BM_1/alevin/logs; [New Thread 0x7ffe7cffe700 (LWP 21654)]; [New Thread 0x7ffdfcffd700 (LWP 21655)]; [New Thread 0x7ffd7cffc700 (LWP 21656)]; ### salmon (single-cell-based) v0.10.3; ### [ program ] => salmon; ### [ command ] => alevin; ### [ libType ] => { ISR }; ### [ chromium ] => { }; ### [ threads ] => { 4 }; ### [ output ] => { BM_1/alevin }; ### [ mates1 ] => { ./BM_1/run1/bm_S10_L001_R1_001.fastq.gz }; ### [ mates2 ] => { ./BM_1/run1/bm_S10_L001_R2_001.fastq.gz }; ### [ maxHashResizeThreads ] => { 2 }; ### [ index ] => { /u/user/ref/cellranger/salmon/transcripts_index }; ##",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-396078627:2143,secur,security,2143,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-396078627,1,['secur'],['security']
Security,"sh_samples/salmon_quants/RHM5942 }; Logs will be written to /data2/csijcs/AML/RNA_seq/AML_total_MNC/total_MNCs/Fresh_samples/salmon_quants/RHM5942/logs; [2018-07-27 16:24:55.658] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2018-07-27 16:24:55.658] [jointLog] [info] parsing read library format; [2018-07-27 16:24:55.658] [jointLog] [info] There is 1 library.; [2018-07-27 16:25:01.242] [jointLog] [info] Loading Quasi index; [2018-07-27 16:25:01.242] [jointLog] [info] Loading 32-bit quasi index; [2018-07-27 16:25:01.243] [stderrLog] [info] Loading Suffix Array ; [2018-07-27 16:25:42.630] [stderrLog] [info] Loading Transcript Info ; [2018-07-27 16:25:45.683] [stderrLog] [info] Loading Rank-Select Bit Array; [2018-07-27 16:25:47.834] [stderrLog] [info] There were 203027 set bits in the bit array; [2018-07-27 16:25:48.128] [stderrLog] [info] Computing transcript lengths; [2018-07-27 16:25:48.200] [stderrLog] [info] Waiting to finish loading hash; [2018-07-27 16:25:48.331] [stderrLog] [info] Done loading index; [2018-07-27 16:25:48.331] [jointLog] [info] done; [2018-07-27 16:25:48.331] [jointLog] [info] Index contained 203027 targets. processed 239500000 fragmentsintLog] [info] Automatically detected most likely library type as ISR; hits: 651420499, hits per frag: 2.72282[2018-07-27 16:51:47.947] [jointLog] [info] Thread saw mini-batch with a maximum of 1.70% zero probability fragments; [2018-07-27 16:51:47.947] [jointLog] [info] Thread saw mini-batch with a maximum of 1.68% zero probability fragments; [2018-07-27 16:51:47.947] [jointLog] [info] Thread saw mini-batch with a maximum of 1.68% zero probability fragments; [2018-07-27 16:51:47.947] [jointLog] [info] Thread saw mini-batch with a maximum of 1.74% zero probability fragments; [2018-07-27 16:51:47.947] [jointLog] [info] Thread saw mini-batch with a maximum of 1.76% zero probability fragments; [2018-07-27 16:51:47.947] [jointLog] [info] Thread saw mini-bat",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/261#issuecomment-409427898:1798,hash,hash,1798,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/261#issuecomment-409427898,1,['hash'],['hash']
Security,"stq/fastqs/flowcell1/read-I1_si-GAGCACGC_lane-001-chunk-001.fastq.gz ./fastq/fastqs/flowcell1/read-I1_si-GAGCACGC_lane-002-chunk-000.fastq.gz ./fastq/fastqs/flowcell1/read-I1_si-GAGCACGC_lane-003-chunk-003.fastq.gz ./fastq/fastqs/flowcell1/read-I1_si-GAGCACGC_lane-004-chunk-002.fastq.gz ./fastq/fastqs/flowcell1/read-I1_si-TTCGTGAA_lane-001-chunk-001.fastq.gz ./fastq/fastqs/flowcell1/read-I1_si-TTCGTGAA_lane-002-chunk-000.fastq.gz ./fastq/fastqs/flowcell1/read-I1_si-TTCGTGAA_lane-003-chunk-003.fastq.gz ./fastq/fastqs/flowcell1/read-I1_si-TTCGTGAA_lane-004-chunk-002.fastq.gz }. [2018-12-06 11:14:56.533] [jointLog] [warning] You seem to have passed in both un-paired reads and paired-end reads. It is not currently possible to quantify hybrid library types in salmon.; [2018-12-06 11:14:56.533] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2018-12-06 11:14:56.533] [jointLog] [info] Usage of --validateMappings implies use of range factorization. rangeFactorizationBins is being set to 4; [2018-12-06 11:14:56.534] [jointLog] [info] Usage of --validateMappings implies a default consensus slack of 1. Setting consensusSlack to 1.; [2018-12-06 11:14:56.534] [jointLog] [info] Using default value of 0.8 for minScoreFraction in Alevin; [2018-12-06 11:14:56.540] [alevinLog] [info] Processing barcodes files (if Present) . ; processed 267 Million barcodes. [2018-12-06 11:16:47.491] [alevinLog] [info] Done barcode density calculation.; [2018-12-06 11:16:47.491] [alevinLog] [info] # Barcodes Used: 267451749 / 267548197.; [2018-12-06 11:16:52.732] [alevinLog] [info] Knee found left boundary at 11955 ; [2018-12-06 11:16:54.977] [alevinLog] [info] Gauss Corrected Boundary at 4345 ; [2018-12-06 11:16:54.977] [alevinLog] [info] Learned InvCov: 713.683 normfactor: 1183.93; [2018-12-06 11:16:54.985] [alevinLog] [info] Total 31.0106% reads will be thrown away because of noisy Cellular barcodes.; [2018-12-",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/328#issuecomment-445008548:4464,validat,validateMappings,4464,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/328#issuecomment-445008548,1,['validat'],['validateMappings']
Security,"stqs/flowcell1/read-I1_si-GAGCACGC_lane-003-chunk-003.fastq.gz ./fastq/fastqs/flowcell1/read-I1_si-GAGCACGC_lane-004-chunk-002.fastq.gz ./fastq/fastqs/flowcell1/read-I1_si-TTCGTGAA_lane-001-chunk-001.fastq.gz ./fastq/fastqs/flowcell1/read-I1_si-TTCGTGAA_lane-002-chunk-000.fastq.gz ./fastq/fastqs/flowcell1/read-I1_si-TTCGTGAA_lane-003-chunk-003.fastq.gz ./fastq/fastqs/flowcell1/read-I1_si-TTCGTGAA_lane-004-chunk-002.fastq.gz }. [2018-12-06 11:14:56.533] [jointLog] [warning] You seem to have passed in both un-paired reads and paired-end reads. It is not currently possible to quantify hybrid library types in salmon.; [2018-12-06 11:14:56.533] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2018-12-06 11:14:56.533] [jointLog] [info] Usage of --validateMappings implies use of range factorization. rangeFactorizationBins is being set to 4; [2018-12-06 11:14:56.534] [jointLog] [info] Usage of --validateMappings implies a default consensus slack of 1. Setting consensusSlack to 1.; [2018-12-06 11:14:56.534] [jointLog] [info] Using default value of 0.8 for minScoreFraction in Alevin; [2018-12-06 11:14:56.540] [alevinLog] [info] Processing barcodes files (if Present) . ; processed 267 Million barcodes. [2018-12-06 11:16:47.491] [alevinLog] [info] Done barcode density calculation.; [2018-12-06 11:16:47.491] [alevinLog] [info] # Barcodes Used: 267451749 / 267548197.; [2018-12-06 11:16:52.732] [alevinLog] [info] Knee found left boundary at 11955 ; [2018-12-06 11:16:54.977] [alevinLog] [info] Gauss Corrected Boundary at 4345 ; [2018-12-06 11:16:54.977] [alevinLog] [info] Learned InvCov: 713.683 normfactor: 1183.93; [2018-12-06 11:16:54.985] [alevinLog] [info] Total 31.0106% reads will be thrown away because of noisy Cellular barcodes.; [2018-12-06 11:16:54.985] [alevinLog] [info] Total 5344(has 999 low confidence) barcodes; [2018-12-06 11:16:55.059] [alevinLog] [info] Done True Barcode Sampling",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/328#issuecomment-445008548:4614,validat,validateMappings,4614,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/328#issuecomment-445008548,1,['validat'],['validateMappings']
Security,"t cannot find a .json file(s); ---------------------------------------------------------------------; (salmon) wayne@Ubuntu19:~/rnaseq$ sh salmonQuantDecoy.sh ; Version Info: This is the most recent version of salmon.; ### salmon (mapping-based) v0.14.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ threads ] => { 3 }; ### [ index ] => { salmonIndexDecoyMouse }; ### [ libType ] => { A }; ### [ mates1 ] => { SRR1818187_2.fastq.gz }; ### [ mates2 ] => { SRR1818187_1.fastq.gz }; ### [ validateMappings ] => { }; ### [ output ] => { Salmontranscripts_quant }; Logs will be written to Salmontranscripts_quant/logs; [2019-08-25 11:40:44.518] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2019-08-25 11:40:44.518] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2019-08-25 11:40:44.518] [jointLog] [info] Usage of --validateMappings, without --hardFilter implies use of range factorization. rangeFactorizationBins is being set to 4; [2019-08-25 11:40:44.518] [jointLog] [info] Usage of --validateMappings implies a default consensus slack of 0.2. Setting consensusSlack to 0.2.; [2019-08-25 11:40:44.518] [jointLog] [info] parsing read library format; [2019-08-25 11:40:44.518] [jointLog] [info] There is 1 library.; Exception : [Error: The index version file salmonIndexDecoyMouse/versionInfo.json doesn't seem to exist. Please try re-building the salmon index.]; salmon quant was invoked improperly.; For usage information, try salmon quant --help; Exiting.; (salmon) wayne@Ubuntu19:~/rnaseq$ ls -R *.json; ls: cannot access '*.json': No such file or directory. Try 2.; Instead of referring to my directory decoys/ , I moved to the directory decoys/ ; and ran salmon index again, using your command exactly:; salmon index -t gentrome.fa -d decoys.txt -i combined_index. This time a few .json files were produced in the directory combi",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/419#issuecomment-524651435:1542,validat,validateMappings,1542,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/419#issuecomment-524651435,1,['validat'],['validateMappings']
Security,"t)=714 | (prec>1 & isEnd)=800 | (isStart & isEnd)=42; contig count: 2077595 element count: 297242564 complex nodes: 182900; # of ones in rank vector: 2077594; [2021-12-31 11:28:32.554] [puff::index::jointLog] [info] Starting the Pufferfish indexing by reading the GFA binary file.; [2021-12-31 11:28:32.554] [puff::index::jointLog] [info] Setting the index/BinaryGfa directory /no_backup/indexes/salmon/mm10_gencode; size = 297242564; -----------------------------------------; | Loading contigs | Time = 135.18 ms; -----------------------------------------; size = 297242564; -----------------------------------------; | Loading contig boundaries | Time = 61.18 ms; -----------------------------------------; Number of ones: 2077594; Number of ones per inventory item: 512; Inventory entries filled: 4058; 2077594; [2021-12-31 11:28:33.532] [puff::index::jointLog] [info] Done wrapping the rank vector with a rank9sel structure.; [2021-12-31 11:28:33.566] [puff::index::jointLog] [info] contig count for validation: 2,077,594; [2021-12-31 11:28:34.693] [puff::index::jointLog] [info] Total # of Contigs : 2,077,594; [2021-12-31 11:28:34.693] [puff::index::jointLog] [info] Total # of numerical Contigs : 2,077,594; [2021-12-31 11:28:34.787] [puff::index::jointLog] [info] Total # of contig vec entries: 13,003,859; [2021-12-31 11:28:34.787] [puff::index::jointLog] [info] bits per offset entry 24; [2021-12-31 11:28:35.409] [puff::index::jointLog] [info] Done constructing the contig vector. 2077595; [2021-12-31 11:28:36.870] [puff::index::jointLog] [info] # segments = 2,077,594; [2021-12-31 11:28:36.870] [puff::index::jointLog] [info] total length = 297,242,564; [2021-12-31 11:28:36.999] [puff::index::jointLog] [info] Reading the reference files ...; [2021-12-31 11:28:38.719] [puff::index::jointLog] [info] positional integer width = 29; [2021-12-31 11:28:38.719] [puff::index::jointLog] [info] seqSize = 297,242,564; [2021-12-31 11:28:38.719] [puff::index::jointLog] [info] rankSize = 297,242",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/731#issuecomment-1003342883:2967,validat,validation,2967,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/731#issuecomment-1003342883,1,['validat'],['validation']
Security,"tLog] [info] Done constructing the contig vector. 2046804 [2022-04-16 11:19:40.720] [puff::index::jointLog] [info] # segments = 2,046,803 ; [2022-04-16 11:19:40.720] [puff::index::jointLog] [info] total length = 189,087,548 ; [2022-04-16 11:19:40.878] [puff::index::jointLog] [info] Reading the reference files ... ; [2022-04-16 11:19:42.562] [puff::index::jointLog] [info] positional integer width = 28 ; [2022-04-16 11:19:42.562] [puff::index::jointLog] [info] seqSize = 189,087,548 ; [2022-04-16 11:19:42.562] [puff::index::jointLog] [info] rankSize = 189,087,548 ; [2022-04-16 11:19:42.562] [puff::index::jointLog] [info] edgeVecSize = 0 ; [2022-04-16 11:19:42.562] [puff::index::jointLog] [info] num keys = 144,057,882 ; for info, total work write each : 2.331 total work inram from level 3 : 4.322 total work raw : 25.000 ; [Building BooPHF] 100 % elapsed: 0 min 6 sec remaining: 0 min 0 sec ; Bitarray 754822720 bits (100.00 %) (array + ranks ) ; final hash 0 bits (0.00 %) (nb in final hash 0) ; [2022-04-16 11:19:48.362] [puff::index::jointLog] [info] mphf size = 89.9819 MB ; [2022-04-16 11:19:48.637] [puff::index::jointLog] [info] chunk size = 15,757,296 ; [2022-04-16 11:19:48.637] [puff::index::jointLog] [info] chunk 0 = [0, 15,757,296) ; [2022-04-16 11:19:48.637] [puff::index::jointLog] [info] chunk 1 = [15,757,296, 31,514,592) ; [2022-04-16 11:19:48.637] [puff::index::jointLog] [info] chunk 2 = [31,514,592, 47,271,888) ; [2022-04-16 11:19:48.637] [puff::index::jointLog] [info] chunk 3 = [47,271,888, 63,029,184) ; [2022-04-16 11:19:48.637] [puff::index::jointLog] [info] chunk 4 = [63,029,184, 78,786,480) ; [2022-04-16 11:19:48.637] [puff::index::jointLog] [info] chunk 5 = [78,786,480, 94,543,776) ; [2022-04-16 11:19:48.637] [puff::index::jointLog] [info] chunk 6 = [94,543,776, 110,301,072) ; [2022-04-16 11:19:48.638] [puff::index::jointLog] [info] chunk 7 = [110,301,072, 126,058,368) ; [2022-04-16 11:19:48.638] [puff::index::jointLog] [info] chunk 8 = [126,058,368, 141,",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/768#issuecomment-1100734317:13636,hash,hash,13636,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/768#issuecomment-1100734317,1,['hash'],['hash']
Security,"tal 2317116 BiDirected Edges.; [2022-03-27 05:49:49.761] [alevinLog] [info] Total 867878 UniDirected Edges.; [2022-03-27 05:49:49.761] [alevinLog] [warning] Skipped 955 barcodes due to No mapped read; [2022-03-27 05:49:49.766] [alevinLog] [info] Clearing EqMap; Might take some time.; [2022-03-27 05:49:50.011] [alevinLog] [info] Starting white listing of 3044 cells; [2022-03-27 05:49:50.011] [alevinLog] [info] Starting to make feature Matrix; [2022-03-27 05:49:50.014] [alevinLog] [info] Done making feature Matrix; [2022-03-27 05:49:50.717] [alevinLog] [info] Finished white listing; [2022-03-27 05:49:51.422] [alevinLog] [info] Finished optimizer; ````. and the `salmon_quant.log` looks like:; ```; [2022-03-27 05:24:09.395] [jointLog] [info] setting maxHashResizeThreads to 32; [2022-03-27 05:24:09.395] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2022-03-27 05:24:09.395] [jointLog] [info] The --mimicBT2, --mimicStrictBT2 and --hardFilter flags imply mapping validation (--validateMappings). Enabling mapping validation.; [2022-03-27 05:24:09.395] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2022-03-27 05:24:09.395] [jointLog] [info] The use of range-factorized equivalence classes does not make sense in conjunction with --hardFilter. Disabling range-factorized equivalence classes. ; [2022-03-27 05:24:09.395] [jointLog] [info] Setting consensusSlack to selective-alignment default of 0.35.; [2022-03-27 05:24:09.395] [jointLog] [info] Using default value of 0.87 for minScoreFraction in Alevin; Using default value of 0.6 for consensusSlack in Alevin; [2022-03-27 05:34:26.966] [jointLog] [info] There is 1 library.; [2022-03-27 05:34:26.967] [jointLog] [info] Loading pufferfish index; [2022-03-27 05:34:26.967] [jointLog] [info] Loading dense pufferfish index.; [2022-03-27 05:34:27.433] [jointLog] [info] done; [2022-03-27 05:34:",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/763#issuecomment-1082597942:4486,validat,validation,4486,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/763#issuecomment-1082597942,2,['validat'],"['validateMappings', 'validation']"
Security,"ter poly-A clipping); counted k-mers for 80000 transcripts[2016-11-04 12:41:39.926] [jointLog] [warning] Entry with header [ENST00000436204], had length less than the k-mer length of 31 (perhaps after poly-A clipping); counted k-mers for 90000 transcripts[2016-11-04 12:41:40.016] [jointLog] [warning] Entry with header [ENST00000473810], had length less than the k-mer length of 31 (perhaps after poly-A clipping); counted k-mers for 140000 transcripts[2016-11-04 12:41:40.568] [jointLog] [warning] Entry with header [ENST00000437226], had length less than the k-mer length of 31 (perhaps after poly-A clipping); [2016-11-04 12:41:40.570] [jointLog] [warning] Entry with header [ENST00000428001], had length less than the k-mer length of 31 (perhaps after poly-A clipping); [2016-11-04 12:41:40.574] [jointLog] [warning] Entry with header [ENST00000445788], had length less than the k-mer length of 31 (perhaps after poly-A clipping); [2016-11-04 12:41:40.576] [jointLog] [warning] Entry with header [ENST00000489969], had length less than the k-mer length of 31 (perhaps after poly-A clipping); [2016-11-04 12:41:40.578] [jointLog] [warning] Entry with header [ENST00000411692], had length less than the k-mer length of 31 (perhaps after poly-A clipping); counted k-mers for 150000 transcriptsElapsed time: 2.85251s. Replaced 6009 non-ATCG nucleotides; Clipped poly-A tails from 1120 transcripts; Building rank-select dictionary and saving to disk done; Elapsed time: 0.0151688s; Writing sequence data to file . . . done; Elapsed time: 0.13411s; [info] Building 32-bit suffix array (length of generalized text is 258980005); ...; ...; [more messages here]; ...; ...; khash had 99651131 keys; saving hash to disk . . . done; Elapsed time: 4.98016s; [2016-11-04 12:45:45.948] [jLog] [info] done building index; ```. So the index builds successfully. The process took ~3 min on my local machine. I wonder what could be happening on your end. Is the process using any resources, or just hanging?. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/100#issuecomment-258484912:6188,hash,hash,6188,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/100#issuecomment-258484912,1,['hash'],['hash']
Security,"th flags. Thank you in advance for any tips you may have for me. Sara. On Tue, Jul 30, 2019 at 10:30 AM Sara Boles <seboles@ucdavis.edu> wrote:. > Hi Avi,; >; > Here is the salmon log from one of my PE libraries. There are only 12; > libraries for each in the directory, which is why I got confused when it; > said 13. I will try putting in all of the file names and let you know how; > it goes. Thank you for all of your help.; >; > Sara; >; > [2019-07-29 15:58:39.034] [jointLog] [info] Fragment incompatibility prior; > below threshold. Incompatible fragments will be ignored.; > [2019-07-29 15:58:39.034] [jointLog] [info] Usage of --validateMappings; > implies use of minScoreFraction. Since not explicitly specified, it is; > being set to 0.65; > [2019-07-29 15:58:39.034] [jointLog] [info] Usage of --validateMappings,; > without --hardFilter implies use of range factorization.; > rangeFactorizationBins is being set to 4; > [2019-07-29 15:58:39.034] [jointLog] [info] Usage of --validateMappings; > implies a default consensus slack of 0.2. Setting consensusSlack to 0.2.; > [2019-07-29 15:58:39.034] [jointLog] [info] parsing read library format; > [2019-07-29 15:58:39.034] [jointLog] [error] Failed to successfully parse; > any complete read libraries. Please make sure you provided arguments; > properly to -1, -2 (for paired-end libraries) or -r (for single-end; > libraries), and that the library format option (-l) *comes before* the read; > libraries.; >; > On Mon, Jul 29, 2019 at 4:06 PM Avi Srivastava <notifications@github.com>; > wrote:; >; >> Oh Sorry about that what I meant was the salmon.log file or the the; >> meta-info.json file created by salmon in the output directory. You can; >> check what files salmon is detecting it seems there are 12 files in the; >> mate1 and 13 files in the mate2. Can you confirm there are 13 pairs of file; >> in that directory and their regex is same as you are using ? Can you also; >> try putting the names of the file instead * as regex ?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/408#issuecomment-516521791:2767,validat,validateMappings,2767,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/408#issuecomment-516521791,1,['validat'],['validateMappings']
Security,"the case for reads from unspliced pre-mRNAs that are even extending a small fraction into the introns (hence better scoring on the decoys). The 2 FASTQ files for one of the samples I was describing above can be found as R4171*.fastq.gz at this globus link: http://research.libd.org/globus/jhpce_bsp2-dlpfc/index.html. I used just the main chromosomes with Gencode v41 annotation (slightly ""curated"" to remove read-through and ""retained intron"" annotated transcripts). I am attaching 3 `meta_info.json` outputs for the 3 ways I ran salmon on this sample:. - [tx_only.meta_info.json.gz](https://github.com/COMBINE-lab/salmon/files/11006627/tx_only.meta_info.json.gz) : no decoys, **without** `--validateMappings`; - [gentrome_full.meta_info.json.gz](https://github.com/COMBINE-lab/salmon/files/11006628/gentrome_full.meta_info.json.gz) : with `--validateMappings`, decoys are full chromosome sequences appended to the transcripts file, ; - [gentrome_mashed.meta_info.json.gz](https://github.com/COMBINE-lab/salmon/files/11006629/gentrome_mashed.meta_info.json.gz) : with `--validateMappings`, decoys prepared with mashmap as instructed [here](https://github.com/COMBINE-lab/SalmonTools/blob/master/README.md). It would be great to be able to use Salmon's ""wicked fast"" mapping engine to estimate intronic and intergenic reads at the same time, so I'm considering to make better use of the `writeMappings` output for that purpose, by preparing the decoys in a specific way (extracting intronic and intergenic sequences as distinctively labeled decoys and count the mappings to each label from Salmon's SAM output -- would that work?). I am wondering, due to pre-mRNAs found in rRNA-depletion (ribo-zero) samples, it might be better to artifically add the unspliced transcripts into the mix along with the ""reference"" annotation transcripts, so they also get quantified during the EM-guided probabilistic distribution of reads across this mix of pre-mRNAs + mature RNAs in each locus.. What do you think?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/779#issuecomment-1474451463:1130,validat,validateMappings,1130,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/779#issuecomment-1474451463,2,['validat'],['validateMappings']
Security,"x rel diff.; = 0.229724; [2020-06-16 00:01:10.426] [jointLog] [info] iteration = 600 | max rel diff.; = 0.242741; [2020-06-16 00:01:12.163] [jointLog] [info] iteration = 700 | max rel diff.; = 0.196958; [2020-06-16 00:01:14.015] [jointLog] [info] iteration = 800 | max rel diff.; = 0.239461; [2020-06-16 00:01:15.803] [jointLog] [info] iteration = 900 | max rel diff.; = 0.197651; [2020-06-16 00:01:17.095] [jointLog] [info] iteration = 969 | max rel diff.; = 0.00714824; [2020-06-16 00:01:17.131] [jointLog] [info] Finished optimizer; [2020-06-16 00:01:17.131] [jointLog] [info] writing output. ```. So, you can note that the number of mappings discarded because of alignment; score is still quite big (134M) and, indeed, this took longer than I would; normally expect for; a sample with ~30M reads. However, it is _massively_ smaller (~116 times); than the 15.6B in your run. Thus, it may have been the same issue as in; the other GitHub issue. You can try the pre-compiled linux binary I linked; there if you have access to a linux machine to test on. By the way, the; issue there was a bunch of reads plagued by super-repetitive homopolymer; segments, I haven't looked at these reads yet for evidence of that though. On Mon, Jun 15, 2020 at 11:09 PM shalercr <notifications@github.com> wrote:. >; >; >; >; >; > Hi Rob,; >; >; > Thanks for the quick response. The other computer was OSX, should I try a; > linux machine?; >; >; > Here are some dropbox links to two of the files. I believe this is the set; > for the logs I posted.; >; >; > https://www.dropbox.com/s/8c3p9hmgmadgj89/31_1.trimmed.fastq.gz?dl=0; >; >; > https://www.dropbox.com/s/2y9jfvaphe9h21x/31_2.trimmed.fastq.gz?dl=0; >; >; >; >; > Thanks,; >; >; > Ryan; >; >; >; >; >; > On Jun 15, 2020, at 9:32 PM, Rob Patro <notifications@github.com> wrote:; >; >; >; >; > Thank you for the report. Can you share one of the samples where you see; > this issue? Also, out of curiosity, was the other machine you tried on also; > OSX, or was ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/537#issuecomment-644527727:4980,access,access,4980,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/537#issuecomment-644527727,1,['access'],['access']
Security,"x rel diff.; = 0.229724; [2020-06-16 00:01:10.426] [jointLog] [info] iteration = 600 | max rel diff.; = 0.242741; [2020-06-16 00:01:12.163] [jointLog] [info] iteration = 700 | max rel diff.; = 0.196958; [2020-06-16 00:01:14.015] [jointLog] [info] iteration = 800 | max rel diff.; = 0.239461; [2020-06-16 00:01:15.803] [jointLog] [info] iteration = 900 | max rel diff.; = 0.197651; [2020-06-16 00:01:17.095] [jointLog] [info] iteration = 969 | max rel diff.; = 0.00714824; [2020-06-16 00:01:17.131] [jointLog] [info] Finished optimizer; [2020-06-16 00:01:17.131] [jointLog] [info] writing output; ```. So, you can note that the number of mappings discarded because of alignment; score is still quite big (134M) and, indeed, this took longer than I would; normally expect for; a sample with ~30M reads. However, it is _massively_ smaller (~116 times); than the 15.6B in your run. Thus, it may have been the same issue as in; the other GitHub issue. You can try the pre-compiled linux binary I linked; there if you have access to a linux machine to test on. By the way, the; issue there was a bunch of reads plagued by super-repetitive homopolymer; segments, I haven't looked at these reads yet for evidence of that though. On Mon, Jun 15, 2020 at 11:09 PM shalercr <notifications@github.com> wrote:. >; >; >; >; >; > Hi Rob,; >; >; > Thanks for the quick response. The other computer was OSX, should I try a; > linux machine?; >; >; > Here are some dropbox links to two of the files. I believe this is the set; > for the logs I posted.; >; >; > https://www.dropbox.com/s/8c3p9hmgmadgj89/31_1.trimmed.fastq.gz?dl=0; >; >; > https://www.dropbox.com/s/2y9jfvaphe9h21x/31_2.trimmed.fastq.gz?dl=0; >; >; >; >; > Thanks,; >; >; > Ryan; >; >; >; >; >; > On Jun 15, 2020, at 9:32 PM, Rob Patro <notifications@github.com> wrote:; >; >; >; >; > Thank you for the report. Can you share one of the samples where you see; > this issue? Also, out of curiosity, was the other machine you tried on also; > OSX, or was ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/537#issuecomment-644520228:4224,access,access,4224,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/537#issuecomment-644520228,1,['access'],['access']
Security,"x86_64/bin/salmon quant 	-i /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts -p 1 -l ISR 	-1 ${FILE1} -2 ${FILE2} 	-o /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/${ID} 2> logs/strace_test12_${SGE_TASK_ID}.txt. echo ""**** Job ends ****""; date; ```. Again, here is the `strace` output for task 1 (411 lines):. ```; execve(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon"", [""/dcl01/lieber/ajaffe/Emily/RNAse""..., ""quant"", ""-i"", ""/dcl01/lieber/ajaffe/Emily/RNAse""..., ""-p"", ""1"", ""-l"", ""ISR"", ""-1"", ""/dcl01/lieber/ajaffe/lab/libd_al""..., ""-2"", ""/dcl01/lieber/ajaffe/lab/libd_al""..., ""-o"", ""/dcl01/lieber/ajaffe/lab/libd_al""...], [/* 107 vars */]) = 0; brk(0) = 0xc2c000; mmap(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7fffbfffd000; readlink(""/proc/self/exe"", ""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon"", 4096) = 88; access(""/etc/ld.so.preload"", R_OK) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/tls/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/tls/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/tls/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/tls"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linu",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:79794,access,access,79794,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,1,['access'],['access']
Security,"y; [2019-06-06 19:24:57.084] [stderrLog] [info] Computing transcript lengths; [2019-06-06 19:24:57.084] [stderrLog] [info] Waiting to finish loading hash; [2019-06-06 19:25:06.552] [jointLog] [info] done; [2019-06-06 19:25:06.552] [jointLog] [info] Index contained 136,011 targets; [2019-06-06 19:25:06.552] [stderrLog] [info] Done loading index; [2019-06-06 19:25:06.728] [alevinLog] [error] Barcode not found in frequency table; ```. Salmon Quant log is this. ```; [2019-06-06 19:23:29.519] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2019-06-06 19:23:29.519] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2019-06-06 19:23:29.520] [jointLog] [info] Usage of --validateMappings, without --hardFilter implies use of range factorization. rangeFactorizationBins is being set to 4; [2019-06-06 19:23:29.520] [jointLog] [info] Usage of --validateMappings implies a default consensus slack of 0.2. Setting consensusSlack to 0.2.; [2019-06-06 19:23:29.520] [jointLog] [info] Using default value of 0.87 for minScoreFraction in Alevin; Using default value of 0.6 for consensusSlack in Alevin; [2019-06-06 19:24:55.716] [jointLog] [info] There is 1 library.; [2019-06-06 19:24:55.889] [jointLog] [info] Loading Quasi index; [2019-06-06 19:24:55.889] [jointLog] [info] Loading 32-bit quasi index; [2019-06-06 19:25:06.552] [jointLog] [info] done; [2019-06-06 19:25:06.552] [jointLog] [info] Index contained 136,011 targets; ```. It is interesting because the barcodes are recognized during the processing, but they don't appear in the frequency table? I don0t get that part. > Can you clarify a bit more about what you meant with: The FASTQ file of the reads is not paired-end. I mean that each of the files has all the unique reads, that is, it is not a paired-end sample where one fastq is forward and the other one is reverse. I just mentioned it in c",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/369#issuecomment-499592790:2685,validat,validateMappings,2685,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/369#issuecomment-499592790,1,['validat'],['validateMappings']
Testability," ${FILE2} 	-o /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test3/${ID}. echo ""**** Job ends ****""; date; ```. ### Example log file. ```; **** Job starts ****; Wed Mar 29 14:51:10 EDT 2017; **** JHPCE info ****; User: lcollado; Job id: 110315; Job name: step6-salmon_test3.gsk_phaseII; Hostname: compute-061; Task id: ; Version Info: This is the most recent version of Salmon.; ### salmon (mapping-based) v0.8.2; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts }; ### [ threads ] => { 1 }; ### [ libType ] => { ISR }; ### [ mates1 ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/merged_fastq/R10001_D2B1WACXX.fastq.gz }; ### [ mates2 ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/merged_fastq/R10001_D2B1WACXX_read2.fastq.gz }; ### [ output ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test3/R10001_D2B1WACXX }; Logs will be written to /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test3/R10001_D2B1WACXX/logs; [1m[2017-03-29 14:51:11.533] [jointLog] [info] parsing read library format; [00m[1m[2017-03-29 14:51:11.545] [jointLog] [info] There is 1 library.; [00mterminate called without an active exception; /cm/local/apps/sge/var/spool/compute-061/job_scripts/110315: line 31: 54922 Aborted (core dumped) /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon quant -i /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts -p 1 -l ISR -1 ${FILE1} -2 ${FILE2} -o /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test3/${ID}; **** Job ends ****; Wed Mar 29 14:51:13 EDT 2017; ```. ### SGE email info example. ```; Job-array task 110315.1 (step6-salmon_test3.gsk_phaseII) Complete; User = lcollado; Queue = shared.q@compute-061.cm.cluster; Host = compute-061.cm.cluster; Start Time = 03/29/2017 14:51:09; End Time = ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-290516965:2625,Log,Logs,2625,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-290516965,2,"['Log', 'log']","['Logs', 'logs']"
Testability," ${FILE2} 	-o /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test5/${ID}. echo ""**** Job ends ****""; date; ```. ### Example log file. ```; **** Job starts ****; Wed Mar 29 23:27:11 EDT 2017; **** JHPCE info ****; User: lcollado; Job id: 110632; Job name: step6-salmon_test5.gsk_phaseII; Hostname: compute-066; Task id: ; Version Info: This is the most recent version of Salmon.; ### salmon (mapping-based) v0.8.2; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts }; ### [ threads ] => { 1 }; ### [ libType ] => { ISR }; ### [ mates1 ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/merged_fastq/R10001_D2B1WACXX.fastq.gz }; ### [ mates2 ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/merged_fastq/R10001_D2B1WACXX_read2.fastq.gz }; ### [ output ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test5/R10001_D2B1WACXX }; Logs will be written to /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test5/R10001_D2B1WACXX/logs; [1m[2017-03-29 23:59:18.699] [jointLog] [info] parsing read library format; [00m[1m[2017-03-29 23:59:18.721] [jointLog] [info] There is 1 library.; [00m[1m[2017-03-30 00:43:17.278] [stderrLog] [info] Loading Suffix Array ; [00m[1m[2017-03-30 00:43:17.237] [jointLog] [info] Loading Quasi index; [00m[1m[2017-03-30 00:43:17.273] [jointLog] [info] Loading 32-bit quasi index; [00m[1m[2017-03-30 02:37:54.437] [stderrLog] [info] Loading Transcript Info ; [00m[1m[2017-03-30 03:48:21.310] [stderrLog] [info] Loading Rank-Select Bit Array; [00m[1m[2017-03-30 04:20:16.735] [stderrLog] [info] There were 198093 set bits in the bit array; [00m[1m[2017-03-30 04:54:34.486] [stderrLog] [info] Computing transcript lengths; [00m[1m[2017-03-30 04:54:34.487] [stderrLog] [info] Waiting to finish loading hash; [00m[1m[2017-03-30 05:09:36.706] [stderrLog] [info] Done loading index; [00m[1m[2017-0",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-290516965:9540,Log,Logs,9540,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-290516965,2,"['Log', 'log']","['Logs', 'logs']"
Testability," -- Installing: /salmon-0.10.2/lib/libtbbmalloc_proxy.so; -- Installing: /salmon-0.10.2/lib/libtbbmalloc.so.2; -- Installing: /salmon-0.10.2/lib/libtbb.so.2; -- Installing: /salmon-0.10.2/lib/pkgconfig; -- Installing: /salmon-0.10.2/lib/libtbbmalloc_proxy.so.2; -- Installing: /salmon-0.10.2/bin/salmon; -- Installing: /salmon-0.10.2/lib/libsalmon_core.a. Installation complete. Please ensure the following paths are set properly.; ==========================================================================; Please add /salmon-0.10.2/bin to your PATH; Please add /salmon-0.10.2/lib to your LD_LIBRARY_PATH; ==========================================================================; root@e08cc9670e4a:/salmon-0.10.2/build# make test; Running tests...; Test project /salmon-0.10.2/build; Start 1: unit_tests; 1/3 Test #1: unit_tests ....................... Passed 0.17 sec; Start 2: salmon_read_test_fmd; 2/3 Test #2: salmon_read_test_fmd ............. Passed 1.78 sec; Start 3: salmon_read_test_quasi; 3/3 Test #3: salmon_read_test_quasi ........... Passed 1.59 sec. 100% tests passed, 0 tests failed out of 3. Total Test time (real) = 3.54 sec; root@e08cc9670e4a:/salmon-0.10.2/build# lsb_release -a; LSB Version: core-9.20160110ubuntu0.2-amd64:core-9.20160110ubuntu0.2-noarch:security-9.20160110ubuntu0.2-amd64:security-9.20160110ubuntu0.2-noarch; Distributor ID: Ubuntu; Description: Ubuntu 16.04.4 LTS; Release: 16.04; Codename: xenial; ```. I built with:. `$ cmake -DFETCH_BOOST=TRUE .. && make install && make test`. I can also install the boost via apt and see if that makes a difference (though I expect not since it looked like TBB was the issue, and I let cmake install that). We can also check our compiler versions, perhaps. I have : . ```; root@e08cc9670e4a:/salmon-0.10.2/build# g++ --version; g++ (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609; Copyright (C) 2015 Free Software Foundation, Inc.; This is free software; see the source for copying conditions. There is NO; warranty; not",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/250#issuecomment-404306268:2141,Test,Test,2141,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/250#issuecomment-404306268,1,['Test'],['Test']
Testability," -d : -f 2,3 | \; tr -d \"",v | \; xargs); LATEST_RELEASE=$(curl -s $GITHUB_URL | \; grep '""tarball_url""' | \; cut -d : -f 2,3 | \; tr -d \"", | \; xargs); module load gcc/7.4.0 cmake/3.15.1 boost/1.70.0-gcc libiconv/1.16; export CC=`which gcc`; export CXX=`which c++`. cd $MODULE_HOME; mkdir -p source/$PACKAGE_NAME/$VERSION; INSTALL_DIR=$MODULE_HOME/modules/$PACKAGE_NAME/$VERSION; mkdir -p $INSTALL_DIR; mkdir -p modfiles/$PACKAGE_NAME. cd source/$PACKAGE_NAME/$VERSION; wget $LATEST_RELEASE -O - | tar -xz --strip-components 1; cmake -DBOOST_ROOT=/global/software/sl-7.x86_64/modules/gcc/7.4.0/boost/1.70.0-gcc -DCMAKE_INSTALL_PREFIX=$INSTALL_DIR; make; ```; And the tail of the output from make:. ```; creating: /clusterfs/vector/home/groups/software/sl-7.x86_64/source/salmon/1.5.1/scripts/../external/pufferfish-salmon-v1.5.1/tests/compile_tests/; inflating: /clusterfs/vector/home/groups/software/sl-7.x86_64/source/salmon/1.5.1/scripts/../external/pufferfish-salmon-v1.5.1/tests/compile_tests/int128_numeric_limits.cpp ; -- fetch PUFFERFISH exit code 0; -- Found ZLIB: /usr/lib64/libz.so (found version ""1.2.11"") ; -- Performing Test Iconv_IS_BUILT_IN; -- Performing Test Iconv_IS_BUILT_IN - Failed; CMake Error at /global/home/groups/consultsw/sl-7.x86_64/modules/cmake/3.15.1/share/cmake-3.15/Modules/FindPackageHandleStandardArgs.cmake:137 (message):; Could NOT find Iconv (missing: Iconv_LIBRARY); Call Stack (most recent call first):; /global/home/groups/consultsw/sl-7.x86_64/modules/cmake/3.15.1/share/cmake-3.15/Modules/FindPackageHandleStandardArgs.cmake:378 (_FPHSA_FAILURE_MESSAGE); /global/home/groups/consultsw/sl-7.x86_64/modules/cmake/3.15.1/share/cmake-3.15/Modules/FindIconv.cmake:120 (find_package_handle_standard_args); CMakeLists.txt:362 (find_package). -- Configuring incomplete, errors occurred!; See also ""/clusterfs/vector/home/groups/software/sl-7.x86_64/source/salmon/1.5.1/CMakeFiles/CMakeOutput.log"".; See also ""/clusterfs/vector/home/groups/software/sl-7.x86_64/so",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/453#issuecomment-862737315:1623,test,tests,1623,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/453#issuecomment-862737315,2,['test'],['tests']
Testability," . Now, for some tests only task 2 runs and it turns out that task 2 has a smaller fastq file than the other 2:. ```bash; $ ls -lh merged_fastq/R1000[1-3]*; -rw-r--r-- 1 lcollado lieber_jaffe 6.2G Feb 20 12:39 merged_fastq/R10001_D2B1WACXX.fastq.gz; -rw-r--r-- 1 lcollado lieber_jaffe 6.3G Feb 20 12:40 merged_fastq/R10001_D2B1WACXX_read2.fastq.gz; -rw-r--r-- 1 lcollado lieber_jaffe 4.6G Feb 20 12:42 merged_fastq/R10002_C29P7ACXX.fastq.gz; -rw-r--r-- 1 lcollado lieber_jaffe 4.7G Feb 20 12:44 merged_fastq/R10002_C29P7ACXX_read2.fastq.gz; -rw-r--r-- 1 lcollado lieber_jaffe 7.1G Feb 20 12:47 merged_fastq/R10003_D19KGACXX.fastq.gz; -rw-r--r-- 1 lcollado lieber_jaffe 7.1G Feb 20 12:50 merged_fastq/R10003_D19KGACXX_read2.fastq.gz; ```. where R10001* is task 1, R10002* is task 2, R10003* is task 3. So it looks like at some point Salmon is asking for some memory based on the input data. ## Strace test with low memory (but above reported usage when requesting 90GB). Mark taught me about `strace` and we ran the following test:. ```bash; #!/bin/bash; #$ -cwd; #$ -pe local 2; #$ -l mem_free=7G,h_vmem=8G,h_fsize=100G; #$ -N step6-salmon_test11.gsk_phaseII; #$ -o ./logs/salmon_test11.$TASK_ID.txt; #$ -e ./logs/salmon_test11.$TASK_ID.txt; #$ -t 1-3; #$ -hold_jid pipeline_setup,step4-featCounts-alzheimer.gsk_phaseII; #$ -m e; echo ""**** Job starts ****""; date. echo ""**** JHPCE info ****""; echo ""User: ${USER}""; echo ""Job id: ${JOB_ID}""; echo ""Job name: ${JOB_NAME}""; echo ""Hostname: ${HOSTNAME}""; echo ""Task id: ${TASK_ID}"". FILE1=$(awk 'BEGIN {FS=""\t""} {print $1}' /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk ""NR==${SGE_TASK_ID}""); if [ TRUE == ""TRUE"" ] ; then; FILE2=$(awk 'BEGIN {FS=""\t""} {print $3}' /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk ""NR==${SGE_TASK_ID}""); fi; ID=$(cat /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk '{print $NF}' | awk ""NR==${SGE_TASK_ID}""). mkdir -p /dcl01/lieber/ajaffe/lab/libd_alzheimers",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:2296,test,test,2296,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,1,['test'],['test']
Testability," > ; > [2021-01-08 12:42:10.700] [jointLog] [warning] ; > ; > WARNING: Detected suspicious pair --- ; > The names are different:; > read1 : SRR3212847.33911054; > read2 : SRR3212847.30781941; > ; > Segmentation fault (core dumped); > ```; > ; > ### 3. Sorting with `samtools sort -n`; > ```; > samtools sort \; > -@ 40 \; > -n \; > -o SRR3212847.Aligned.SortedByName.bam \; > SRR3212847.Aligned.SortedByCoord.bam; > ; > salmon quant \; > -t mRNA.fasta \; > -p 20 \; > -l A \; > -a SRR3212847.Aligned.SortedByName.bam \; > -o SRR3212847.Aligned.SortedByName; > ```; > ; > ```; > Version Info: This is the most recent version of salmon.; > # salmon (alignment-based) v1.4.0; > # [ program ] => salmon ; > # [ command ] => quant ; > # [ targets ] => { mRNA.fasta }; > # [ threads ] => { 20 }; > # [ libType ] => { A }; > # [ alignments ] => { SRR3212847.Aligned.SortedByName.bam }; > # [ output ] => { SRR3212847.Aligned.SortedByName }; > Logs will be written to SRR3212847.Aligned.SortedByName/logs; > [2021-01-08 13:02:04.845] [jointLog] [info] setting maxHashResizeThreads to 20; > [2021-01-08 13:02:04.845] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; > Library format { type:paired end, relative orientation:inward, strandedness:unstranded }; > [2021-01-08 13:02:04.878] [jointLog] [info] numQuantThreads = 14; > parseThreads = 6; > Checking that provided alignment files have consistent headers . . . done; > Populating targets from aln = ""SRR3212847.Aligned.SortedByName.bam"", fasta = ""mRNA.fasta"" . . .done; > ; > processed 0 reads in current roundSegmentation fault (core dumped); > ```; > ; > (Which is the same as the 1st error. Actually, each time I re-run those two errors switched.); > ; > I tried running Salmon on the sorted-by-coordinates bam, and it didn't fail:; > ; > ```; > nohup salmon quant \; > -t mRNA.fasta \; > -p 20 \; > -l A \; > -a SRR3212847.Aligned.SortedByCoord.bam \; > -o SRR3212847.Aligned.SortedByCoord \",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/582#issuecomment-1343749456:3867,log,logs,3867,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/582#issuecomment-1343749456,1,['log'],['logs']
Testability," Gibbs samples in hand, we can walk you though how to do some assessment of these transcripts (tagging @hiraksarkar here since he's most likely to have access to scripts that will let us look at the posterior samples from individual transcripts). Similarly, if you can provide the quantification directory, we can help examine this too. If this is the case, that the posterior distributions are highly anti-correlated, it is likely that the ambiguity you are seeing is simply inherent given the alignments salmon is being provided. If you have the quantification folder resulting from the same sample using selective alignment, we could compare and contrast the two. At that point, there are a few options depending on how deeply you want to dive. You could try to see how STAR and selective alignment are mapping differently to these transcripts. One potential difference is that STAR is _a lot_ more happy to softclip reads, which selective alignment won't do by default (you can test the effect with the `--softclipOverhangs` to allow selective alignment to softclip reads that hang off the transcript end or `--softclip` to allow softclips anywhere). Note that selective alignment may _still_ be a bit more conservative than STAR about softclips simply because of the nature of the scoring function it uses. This might give you a sense if one of these alignment methodologies is more consistent with your expectations in this case. Another option is to consider doing a grouping with `terminus`. This will reduce the set of ""genes"" that you can call as DE, because it will be happy to group together transcripts from different genes. However, it should help considerably in eliminating DE from highly-uncertain point estimates. Finally, you might consider performing DE with swish (cc @mikelove as he might have some input here) rather than DESeq2 (though we've typically been using swish at the transcript level rather than the gene level). Unlike DESeq2, swish will explicitly take into account ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/600#issuecomment-740363115:3599,test,test,3599,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/600#issuecomment-740363115,2,['test'],['test']
Testability," IO_LIB and libgff. In addition for it to use Boost169 it was necessary to modify the CmakeLists.txt file like so. ```; --- CMakeLists.txt.dist 2020-04-21 22:31:07.000000000 -0700; +++ CMakeLists.txt 2020-06-08 17:13:23.295499154 -0700; @@ -419,6 +419,8 @@; find_package(Boost 1.59.0 COMPONENTS iostreams filesystem system timer chrono program_options); message(""BOOST_INCLUDEDIR = ${BOOST_INCLUDEDIR}""); message(""BOOST_LIBRARYDIR = ${BOOST_LIBRARYDIR}""); +message(""Forcing Boost_FOUND to TRUE""); +set(Boost_FOUND TRUE); message(""Boost_FOUND = ${Boost_FOUND}""); endif(); ; ```. and to invoke cmake with:. ```; module load cmake; module load io_lib; module load libgff; module load libtbb; mkdir build; cd build; cmake \; -DCMAKE_VERBOSE_MAKEFILE:BOOL=ON \; -DBOOST_LIBRARYDIR=/usr/lib64/boost169 \; -DBOOST_INCLUDEDIR=/usr/include/boost169 \; -DBoost_NO_SYSTEM_PATHS=ON \; .. 2>&1 | tee cmake_2020_06_08.log; ```; Inkscape was built using cmake a couple of weeks ago on the same system and the -D flags for Boost in the cmake invocation were sufficient, there was no need to modify its CMakeLists.txt. Perhaps you might to compare that CMakeLIsts.txt with salmon's to see why theirs works and salmon's does not. I reiterate my plea for salmon's cmake file to accept some form of ROOT_LIBGFF, ROOT_LIBSTADEN, and ROOT_LIBTBB. Those modules ; were all defined but cmake could only figure out TBB this time, and for all I know it won't next time around (since it failed to do so for no apparent reason on CentOS 7). Salmon is a useful program but it has so far failed to build using existing libraries on this OS (unless extraordinary measures were applied) for CO 6, 7, and now 8! This is the information it had to work with:. ```; echo $PATH; /usr/common/modules/el8/x86_64/software/libgff/1.2-CentOS-vanilla/bin:/usr/common/modules/el8/x86_64/software/io_lib/1.14.9-CentOS-vanilla/bin:/usr/common/modules/el8/x86_64/software/cmake/3.17.1-CentOS-vanilla/bin:/usr/lib64/ccache:/usr/local/bin:/usr/bin:/u",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-640962684:1045,log,log,1045,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-640962684,1,['log'],['log']
Testability," Installing: /salmon/lib/libtbbmalloc.so.2.5; -- Installing: /salmon/lib/libtbbmalloc_proxy.so; -- Installing: /salmon/lib/libtbbmalloc_proxy.so.2; -- Installing: /salmon/lib/libtbbmalloc_proxy.so.2.5; -- Installing: /salmon/bin/salmon; -- Installing: /salmon/lib/libsalmon_core.a. Installation complete. Please ensure the following paths are set properly.; ==========================================================================; Please add /salmon/bin to your PATH; Please add /salmon/lib to your LD_LIBRARY_PATH; ==========================================================================; root@fd877e359439:/salmon/build# make test; Running tests...; Test project /salmon/build; Start 1: unit_tests; 1/2 Test #1: unit_tests ....................... Passed 0.37 sec; Start 2: salmon_read_test_quasi; 2/2 Test #2: salmon_read_test_quasi ........... Passed 1.80 sec. 100% tests passed, 0 tests failed out of 2. Total Test time (real) = 2.17 sec; ```. The `make test` command itself runs the test the builds the index and maps the reads against it. Either way, I can do that explicitly too (from within build):. ```; $ ./src/salmon index -t ../sample_data/transcripts.fasta -i sample_idx; ```. returns succesfully with a built index. ```; ...; [2023-03-10 05:51:33.748] [puff::index::jointLog] [info] Done wrapping the rank vector with a rank9sel structure.; [2023-03-10 05:51:33.748] [puff::index::jointLog] [info] contig count for validation: 23; [2023-03-10 05:51:33.748] [puff::index::jointLog] [info] Total # of Contigs : 23; [2023-03-10 05:51:33.748] [puff::index::jointLog] [info] Total # of numerical Contigs : 23; [2023-03-10 05:51:33.748] [puff::index::jointLog] [info] Total # of contig vec entries: 36; [2023-03-10 05:51:33.748] [puff::index::jointLog] [info] bits per offset entry 6; [2023-03-10 05:51:33.748] [puff::index::jointLog] [info] Done constructing the contig vector. 24; [2023-03-10 05:51:33.748] [puff::index::jointLog] [info] # segments = 23; [2023-03-10 05:51:33.748] [puff",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463312554:3017,test,test,3017,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463312554,2,['test'],['test']
Testability," Run B. ![image](https://cloud.githubusercontent.com/assets/361470/20741292/4f8243a0-b697-11e6-93ae-29d4b48327cd.png). ![image](https://cloud.githubusercontent.com/assets/361470/20741299/60f84c1a-b697-11e6-9f83-1554ff471e94.png). So, as you can see, there is a substantial amount of uncertainty in RunA, especially for `MSAD_200218.t1`. This can explain how you see this transcript obtaining different numbers of reads over different executions for Run A. Specifically, the inferential uncertainty for this transcript is high, and though the mean of the posterior is close to the value you report above, the range is quite large (200 - 1200) reads (potentially even larger with more bootstraps, but 100 gives us a reasonable window on posterior variance). On the other hand, the EM algorithm *really* wants to assign ~0.8 reads to `MSAD_157177.t1` in Run B. To test how much this might be the result of the tendency of the EM algorithm toward sparsity, I tried processing both samples with Salmon's `--useVBOpt` flag --- causing it to use the variational bayesian optimization algorithm, which yields considerably more *regularized* estimates. The posterior distributions obtained using the VB optimizer are:. ### Run A (VB Opt). ![image](https://cloud.githubusercontent.com/assets/361470/20741629/916b3446-b699-11e6-9f92-b8b6d3519981.png). ![image](https://cloud.githubusercontent.com/assets/361470/20741636/98510f06-b699-11e6-8d9f-34f1c353c3e6.png). ### Run B (VB Opt). ![image](https://cloud.githubusercontent.com/assets/361470/20741642/a1341686-b699-11e6-9a87-8a30f87cd49c.png). ![image](https://cloud.githubusercontent.com/assets/361470/20741645/a7340d5c-b699-11e6-90dd-55f9795bac8f.png). So, while there are some small differences for Run A and transcript `MSAD_200218.t1` in Run B, you can see that the most striking difference is `MSAD_157177.t1` in Run B. The number of estimated reads isn't quite as high as with eXpress, but a considerable number of reads map to `MSAD_157177.t1` (and the ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/107#issuecomment-263793798:1517,test,test,1517,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/107#issuecomment-263793798,1,['test'],['test']
Testability," ```. I don't know if that hint makes you suspect anything in `Salmon`. . Now, for some tests only task 2 runs and it turns out that task 2 has a smaller fastq file than the other 2:. ```bash; $ ls -lh merged_fastq/R1000[1-3]*; -rw-r--r-- 1 lcollado lieber_jaffe 6.2G Feb 20 12:39 merged_fastq/R10001_D2B1WACXX.fastq.gz; -rw-r--r-- 1 lcollado lieber_jaffe 6.3G Feb 20 12:40 merged_fastq/R10001_D2B1WACXX_read2.fastq.gz; -rw-r--r-- 1 lcollado lieber_jaffe 4.6G Feb 20 12:42 merged_fastq/R10002_C29P7ACXX.fastq.gz; -rw-r--r-- 1 lcollado lieber_jaffe 4.7G Feb 20 12:44 merged_fastq/R10002_C29P7ACXX_read2.fastq.gz; -rw-r--r-- 1 lcollado lieber_jaffe 7.1G Feb 20 12:47 merged_fastq/R10003_D19KGACXX.fastq.gz; -rw-r--r-- 1 lcollado lieber_jaffe 7.1G Feb 20 12:50 merged_fastq/R10003_D19KGACXX_read2.fastq.gz; ```. where R10001* is task 1, R10002* is task 2, R10003* is task 3. So it looks like at some point Salmon is asking for some memory based on the input data. ## Strace test with low memory (but above reported usage when requesting 90GB). Mark taught me about `strace` and we ran the following test:. ```bash; #!/bin/bash; #$ -cwd; #$ -pe local 2; #$ -l mem_free=7G,h_vmem=8G,h_fsize=100G; #$ -N step6-salmon_test11.gsk_phaseII; #$ -o ./logs/salmon_test11.$TASK_ID.txt; #$ -e ./logs/salmon_test11.$TASK_ID.txt; #$ -t 1-3; #$ -hold_jid pipeline_setup,step4-featCounts-alzheimer.gsk_phaseII; #$ -m e; echo ""**** Job starts ****""; date. echo ""**** JHPCE info ****""; echo ""User: ${USER}""; echo ""Job id: ${JOB_ID}""; echo ""Job name: ${JOB_NAME}""; echo ""Hostname: ${HOSTNAME}""; echo ""Task id: ${TASK_ID}"". FILE1=$(awk 'BEGIN {FS=""\t""} {print $1}' /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk ""NR==${SGE_TASK_ID}""); if [ TRUE == ""TRUE"" ] ; then; FILE2=$(awk 'BEGIN {FS=""\t""} {print $3}' /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk ""NR==${SGE_TASK_ID}""); fi; ID=$(cat /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk '{print $NF}' | awk """,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:2171,test,test,2171,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,1,['test'],['test']
Testability," between pre-processed and fully-processed non-coding RNA transcripts. I'm attaching an image showing an example ncRNA; the two tracks are the same data, but the lower one shows abundance on a log scale. In this particular sample, it's easy to estimate that ~5-10% of the transcripts are pre-processed (the transcripts still have neighboring genomic DNA). I wanted to see how this ratio changes between samples (for example, in a snoRNA processing-defective mutant strain), but quickly realized this is not easily done in salmon or any other quant tools because the processed transcript is entirely a subset of the sequence of the pre-processed transcript. The only way to accurately quantify it is to use the coverage information, which as you agreed is not really taken into account downstream. If Salmon could incorporate the coverage information to solve this class of problem, that would indeed be a **huge win**. I think the ncRNA example would be both a great biologically-interesting motivating problem, as well as a good technical benchmark for implementing any new methods. It could even be used as a secondary RNA velocity measure in scRNA seq data, provided the method used can detect these (non-polyadenylated) transcripts. > The big questions are (1) how do you fold this type of intuition formally into the probabilistic model and (2) is it possible to incorporate this information efficiently?. This is definitely your domain of expertise (and I know it's a rhetorical question but I'd love to throw some ideas out here)... I can think of a few mostly heuristical approaches.... . 1) when apportioning reads to transcripts, after the mapping phase, incorporate a notion of ""evenness"" into the EM step... reads that decrease the variance in coverage are favored over reads that increase the variance (so, define read depth per 10 bp window or something and calculate the variance across all windows for the transcript, then try to assign reads such that they minimize read depth varianc",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-623963851:2256,benchmark,benchmark,2256,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-623963851,2,['benchmark'],['benchmark']
Testability," fragments that induce exactly the same type of variation under uncertainty; and since that uncertainty is baked into the sample, it cannot and should not be removed. Having exact replication of a sample at a numerical threshold below the inferential uncertainty for a transcript conveys false confidence in the precision of the estimate. This is why, for transcript-level analysis, we highly recommend having salmon produce posterior gibbs samples (with the `--numGibbsSamples` flag). This will draw samples from the posterior distribution over the abundance estimates and allow determination of what inferences can be made robustly and what cannot. We have spent a good deal of time thinking about how to properly perform statistical inference on these uncertain quantities, and so I'd point you at [swish](https://bioconductor.org/packages/release/bioc/vignettes/fishpond/inst/doc/swish.html), which is a tool for differential analysis at the transcript level that makes uses of a non-parametric test over the inferential replicates (Gibbs samples) to incorporate uncertainty into the differential analysis. We also developed a tool [terminus](https://academic.oup.com/bioinformatics/article/36/Supplement_1/i102/5870485) that makes use of the Gibbs samples and point estimates of salmon to group together transcripts whose individual abundances cannot be reliably inferred given the fragments in the sample. While the best way to properly assess, propagate and handle uncertainty in transcript-level inference is still, in my opinion, an active area of research in the field, these are some solutions we've come up with to address this challenge so far. And while, as a computer scientist myself, I _certainly_ appreciate the desire to be able to have e.g. exactly the same numerical output for a particular sample, we feel that doing so might convey a false sense of certainty in the resulting estimates (and it would also be very difficult to do, technically, given the streaming asynchronous p",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/613#issuecomment-757989858:3914,test,test,3914,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/613#issuecomment-757989858,2,['test'],['test']
Testability," index, and the alignments/quants worked. I had to use mem_free=34G for building index. Is that expected?; I will try building the vM25 index again and and post the update.; In the meantime, sha256sum of my vM25 index that I had generated has some mismatches from the one you created. Below is my sha256sum on vM25 index:; `306e9d98b3460859f579059bf876aa3b6e264c8f38c04cde332b03632edc6dfb complete_ref_lens.bin; 636b3df7e097d58fa846bd85ce650ce5bf72c66dc5b2d7566fc9e3db087c5c9c ctable.bin; 1c7501deaa4524f4700152713228cb03949775dce481384eac67bb45458508be ctg_offsets.bin; dbc575fed0d589b4671c26bd8cbcb4b3d52ef41c299a90de978ab940abb751fc duplicate_clusters.tsv; c3ec09a30adc9d47bc95839157cb2ff66530353106a4fd8e75b167ac5db67820 info.json; 430be78bae99a4592fcedc5c800a42313f2b1252e3953f89f347779056c1ee5b mphf.bin; 2fb0b5151f9f2544c06a9f95d03075f7af0494d0fe31745504a5a7da43edc1b1 pos.bin; 15d3bb6a16bcd8c1a6814852bd3dcfa439b60ec84c706f868ee7ec2d5a90581d pre_indexing.log; 8e665e5fdee5af6fcedabc69fd04eda6e66055ef811ebde6de6f86a66521198a rank.bin; 793c79f5fd6046dfea07bbc9587d2835088e54c78197d652d1b1f205c6b16983 refAccumLengths.bin; c5ea8eccca3fdc299ad7c9d2f07a4ed14c8c830940e83c315e7eaad6905a40aa ref_indexing.log; b580b9c6257254a018a9ae22291a64892c1a3715c69272637f5c504fc5545a70 reflengths.bin; 89679603ac0b28042275e5ff04b222bad3fd431cab573f0c2b61e7455aec43e7 refseq.bin; 46bf28001e00d491b68bf8758b99c1f304523c79bd94a97d7797888856594e84 seq.bin; 4c7e56ba28383774e786826099ef412761326fe18ce69f29033ad2886542985d versionInfo.json; `; Following are different.; `ctable.bin; info.json; mphf.bin; pos.bin; pre_indexing.log; ref_indexing.log; seq.bin; versionInfo.json`. I will try creating the vM25 index with increased memory. Wonder if its not building. Just FYI, my sha256sum on vM23 index is:; `9788716f4ce42b049fe7e865108f45392bb8a5847cfcd47369512783dc918239 complete_ref_lens.bin; 9c2453a47ce1808f54733f049b8c4cf38634c9116eb55ed725b73219caa101c5 ctable.bin; 928ba619dc5388ccab6d5c4f8ce162e07a5b5c79028b",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/561#issuecomment-674527480:1025,log,log,1025,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/561#issuecomment-674527480,1,['log'],['log']
Testability," mapped; matenot mapped. read2 : [SRR3212847.24133171] : proper-pair; mapped; matemapped. [2021-01-08 12:42:10.700] [jointLog] [warning] . WARNING: Detected suspicious pair --- ; The names are different:; read1 : SRR3212847.33911054; read2 : SRR3212847.30781941. Segmentation fault (core dumped); ```. ### 3. Sorting with `samtools sort -n`; ```; samtools sort \; -@ 40 \; -n \; -o SRR3212847.Aligned.SortedByName.bam \; SRR3212847.Aligned.SortedByCoord.bam. salmon quant \; -t mRNA.fasta \; -p 20 \; -l A \; -a SRR3212847.Aligned.SortedByName.bam \; -o SRR3212847.Aligned.SortedByName; ```. ```; Version Info: This is the most recent version of salmon.; # salmon (alignment-based) v1.4.0; # [ program ] => salmon ; # [ command ] => quant ; # [ targets ] => { mRNA.fasta }; # [ threads ] => { 20 }; # [ libType ] => { A }; # [ alignments ] => { SRR3212847.Aligned.SortedByName.bam }; # [ output ] => { SRR3212847.Aligned.SortedByName }; Logs will be written to SRR3212847.Aligned.SortedByName/logs; [2021-01-08 13:02:04.845] [jointLog] [info] setting maxHashResizeThreads to 20; [2021-01-08 13:02:04.845] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; Library format { type:paired end, relative orientation:inward, strandedness:unstranded }; [2021-01-08 13:02:04.878] [jointLog] [info] numQuantThreads = 14; parseThreads = 6; Checking that provided alignment files have consistent headers . . . done; Populating targets from aln = ""SRR3212847.Aligned.SortedByName.bam"", fasta = ""mRNA.fasta"" . . .done. processed 0 reads in current roundSegmentation fault (core dumped); ```; (Which is the same as the 1st error. Actually, each time I re-run those two errors switched.). I tried running Salmon on the sorted-by-coordinates bam, and it didn't fail:; ```; nohup salmon quant \; -t mRNA.fasta \; -p 20 \; -l A \; -a SRR3212847.Aligned.SortedByCoord.bam \; -o SRR3212847.Aligned.SortedByCoord \; > SRR3212847.Aligned.SortedByCoord.out &; ```; Ev",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/582#issuecomment-756727212:3576,log,logs,3576,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/582#issuecomment-756727212,1,['log'],['logs']
Testability," mapping and quantifying reads. From the files you shared, it certainly _does_ seem like the index is being created correctly. I'm including here the sha256sum of the index files I get when I build this index on one of our machines. Perhaps we could see if these match: . ```; $:salmon_index [j1] (develop ?) $ sha256sum *; 306e9d98b3460859f579059bf876aa3b6e264c8f38c04cde332b03632edc6dfb complete_ref_lens.bin; 28519aac34b84b4d0570c97340815e719511c204e04a240dd43e365d2872eed3 ctable.bin; 1c7501deaa4524f4700152713228cb03949775dce481384eac67bb45458508be ctg_offsets.bin; dbc575fed0d589b4671c26bd8cbcb4b3d52ef41c299a90de978ab940abb751fc duplicate_clusters.tsv; 987050914456cf247a24136429d8faaa293cf5617bfd57166c64976b2778d95b info.json; 0b7e8cb4ebed78513900831c047f0d66589068921c33bb15c49b3567c84e2edc mphf.bin; 117369928fde1bff4ca278246c331e079cc0860c3b415e34cd4b08f588063abc pos.bin; 297492e67d274b2ff8f026d2fbc8045f96e17793a58dd74c19b5ab1b7156df8a pre_indexing.log; 8e665e5fdee5af6fcedabc69fd04eda6e66055ef811ebde6de6f86a66521198a rank.bin; 793c79f5fd6046dfea07bbc9587d2835088e54c78197d652d1b1f205c6b16983 refAccumLengths.bin; 92acf575c90c6954ff75be1ea791f822eee05e486c6e86c52943d8bc1a0849ca ref_indexing.log; b580b9c6257254a018a9ae22291a64892c1a3715c69272637f5c504fc5545a70 reflengths.bin; 89679603ac0b28042275e5ff04b222bad3fd431cab573f0c2b61e7455aec43e7 refseq.bin; 94cb79a2f4acd811d2164f2926c96869a8103b9118170d0688f57b46e695cd5c seq.bin; 89d56bb135f32c7b5fa337bc3c45814b80c2886a3cccc31ff0533c6324ca11fd versionInfo.json; ```. I'm also including a link [here](https://drive.google.com/file/d/1uxGUy8gaQ20dpEi7-D3ookFF4JYawsIR/view?usp=sharing) to a tarball containing the index I built. Could you see if you can perform quantification with this index? Finally, it might be worth checking that nothing strange / unexpected is going on with how libraries are being resolved in the linker path when you are running salmon. Could you share the output of running `ldd salmon`? If none of those point a",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/561#issuecomment-674454751:1101,log,log,1101,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/561#issuecomment-674454751,1,['log'],['log']
Testability," mismatches from the one you created. Below is my sha256sum on vM25 index:; `306e9d98b3460859f579059bf876aa3b6e264c8f38c04cde332b03632edc6dfb complete_ref_lens.bin; 636b3df7e097d58fa846bd85ce650ce5bf72c66dc5b2d7566fc9e3db087c5c9c ctable.bin; 1c7501deaa4524f4700152713228cb03949775dce481384eac67bb45458508be ctg_offsets.bin; dbc575fed0d589b4671c26bd8cbcb4b3d52ef41c299a90de978ab940abb751fc duplicate_clusters.tsv; c3ec09a30adc9d47bc95839157cb2ff66530353106a4fd8e75b167ac5db67820 info.json; 430be78bae99a4592fcedc5c800a42313f2b1252e3953f89f347779056c1ee5b mphf.bin; 2fb0b5151f9f2544c06a9f95d03075f7af0494d0fe31745504a5a7da43edc1b1 pos.bin; 15d3bb6a16bcd8c1a6814852bd3dcfa439b60ec84c706f868ee7ec2d5a90581d pre_indexing.log; 8e665e5fdee5af6fcedabc69fd04eda6e66055ef811ebde6de6f86a66521198a rank.bin; 793c79f5fd6046dfea07bbc9587d2835088e54c78197d652d1b1f205c6b16983 refAccumLengths.bin; c5ea8eccca3fdc299ad7c9d2f07a4ed14c8c830940e83c315e7eaad6905a40aa ref_indexing.log; b580b9c6257254a018a9ae22291a64892c1a3715c69272637f5c504fc5545a70 reflengths.bin; 89679603ac0b28042275e5ff04b222bad3fd431cab573f0c2b61e7455aec43e7 refseq.bin; 46bf28001e00d491b68bf8758b99c1f304523c79bd94a97d7797888856594e84 seq.bin; 4c7e56ba28383774e786826099ef412761326fe18ce69f29033ad2886542985d versionInfo.json; `; Following are different.; `ctable.bin; info.json; mphf.bin; pos.bin; pre_indexing.log; ref_indexing.log; seq.bin; versionInfo.json`. I will try creating the vM25 index with increased memory. Wonder if its not building. Just FYI, my sha256sum on vM23 index is:; `9788716f4ce42b049fe7e865108f45392bb8a5847cfcd47369512783dc918239 complete_ref_lens.bin; 9c2453a47ce1808f54733f049b8c4cf38634c9116eb55ed725b73219caa101c5 ctable.bin; 928ba619dc5388ccab6d5c4f8ce162e07a5b5c79028be4aee4d838f43a3b9d92 ctg_offsets.bin; 0814d0e7dd8a4b126709c42728816995aefdf5a5bb6337c2d3c048cb0f56094d duplicate_clusters.tsv; dcbf8e140627b3c99d4dbcdaa585447a691fddb620f137811b669e73800f9b3b info.json; 5959abf5969a26481c6aa20fecbdddf19fa558e949cf",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/561#issuecomment-674527480:1269,log,log,1269,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/561#issuecomment-674527480,1,['log'],['log']
Testability," procedure). I know Salmon assumes the alignments are not sorted, so I shuffled these bam files, and then run `salmon quant`. Here are the errors I got in a number of trials:; > ; > ### Fresh installation of Salmon; > ```; > conda create --name salmon -c bioconda salmon; > conda activate salmon; > ```; > ; > ### 1. Shuffling a bam file with `samtools collate`; > ```; > samtools collate \; > -@ 40 \; > -o SRR3212847.Aligned.Shuffled.bam \; > SRR3212847.Aligned.SortedByCoord.bam; > ; > salmon quant \; > -t mRNA.fasta \; > -p 20 \; > -l A \; > -a SRR3212847.Aligned.Shuffled.bam \; > -o SRR3212847.Aligned.Shuffled ; > ```; > ; > ```; > Version Info: This is the most recent version of salmon.; > # salmon (alignment-based) v1.4.0; > # [ program ] => salmon ; > # [ command ] => quant ; > # [ targets ] => { mRNA.fasta }; > # [ threads ] => { 20 }; > # [ libType ] => { A }; > # [ alignments ] => { SRR3212847.Aligned.Shuffled.bam }; > # [ output ] => { SRR3212847.Aligned.Shuffled }; > Logs will be written to SRR3212847.Aligned.Shuffled/logs; > [2021-01-08 12:43:44.680] [jointLog] [info] setting maxHashResizeThreads to 20; > [2021-01-08 12:43:44.680] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; > Library format { type:paired end, relative orientation:inward, strandedness:unstranded }; > [2021-01-08 12:43:44.711] [jointLog] [info] numQuantThreads = 14; > parseThreads = 6; > Checking that provided alignment files have consistent headers . . . done; > Populating targets from aln = ""SRR3212847.Aligned.Shuffled.bam"", fasta = ""mRNA.fasta"" . . .done; > ; > processed 0 reads in current roundSegmentation fault (core dumped); > ```; > ; > ### 2. Shuffling a headless bam file with `samtools collate`; > (I think I saw something about the bam's header in another thread dealing with this issue); > ; > ```; > samtools view \; > -b \; > -@ 40 \; > -o SRR3212847.Aligned.SortedByCoord.NoHeader.bam \; > SRR3212847.Aligned.SortedByCoord",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/582#issuecomment-1343749456:1152,Log,Logs,1152,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/582#issuecomment-1343749456,1,['Log'],['Logs']
Testability," read overhangs off the end of the annotated transcript that no mapping matches the minimum required alignment score. This is likely to be a much more liberal threshold than what STAR allows, so it also explains why you see higher counts than when alignment mode is used. * Other thoughts / suggestions?. * So, there are several things that you might consider doing if you believe the correct behavior in your case is to assign these reads to such genes. First, when run in mapping mode, salmon has a `--softclipOverhangs` flag that will further reduce the penalty for reads overhanging the annotated end of a transcript. This will allow more reads to map to the transcript even if they can't obtain a good alignment score. Likewise, you can combine this with further reducing the required minimum score using the `--minScoreFraction` [parameter](https://salmon.readthedocs.io/en/latest/salmon.html#minscorefraction). Finally, looking forward, we have developed and been testing even more comprehensive solutions to cases when one wants to allow large amounts of soft-clipping (see e.g. [this tutorial](https://combine-lab.github.io/salmon-tutorials/2021/softclip/)). While those features have not yet been migrated into the main salmon branch, you may find the tutorial instructive and the corresponding feature branch useful. If you believe that the annotations themselves are incomplete/incorrect and that may be leading to some of this behavior, you might consider augmenting or updating those annotations. Finally, I'd be reticent to just go with FeatureCounts instead here. While the heuristics employed by the overlap and counting rules may accord with what you expect for this gene or some subset of similar genes, the counting based approach implements several heuristics that can be problematic in a number of other scenarios. Hopefully this helps answer your question about this behavior. If you end up discussing this with the nf-core folks, I'd be happy to be involved in that discussion ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/798#issuecomment-1237133883:3973,test,testing,3973,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/798#issuecomment-1237133883,1,['test'],['testing']
Testability," reasons I have not been able to pinpoint (potentially a bug), the strand information **was accounted for** when I used GRanges to subset the premature sequences. I **did not** need to get the reverse complement of the premature sequences on the minus strand as I had to do for the mature sequences. Yet, I did that anyway. I initially did test my protocol to ensure it produced identical transcript sequences to Gencode, but I only did this for mature sequences. All seemed fine for both + and - strand transcripts. After your feedback, I compared the premature sequences in my transcript fasta against the transcript fasta from Gencode. As you can see in the smoothed dot plots below, the premature sequences of transcripts on the minus strand are in the wrong orientation and have the wrong complementarity!. ![Screenshot from 2021-04-24 00-35-05](https://user-images.githubusercontent.com/10429333/115947355-0d96c880-a495-11eb-92a6-d8d2233c8d2b.png). I included my R code below for this test case for anyone who might stumble upon this issue. Under the code headers “Mature transcript sequences” and “Premature transcript sequences”, you can observe that I used identical protocols for sequence subsetting, yet in the mature case the strand information in the GRanges seems to be disregarded when subsetting from Biostrings, but in the premature case the strand information is used. Of course, this problem is out of the scope of this forum so it will be okay to close this issue. I will reach out to the developers of GenomicRanges and Biostrings to point out this potential problem and seek their guidance. Thank you again for all your help. Rached. ```; # setwd('wd'). options(scipen = 9999). libraries <- lapply(; X = c('data.table', 'magrittr', 'rtracklayer', 'Biostrings', 'reshape2', 'ggplot2'),; FUN = library, character.only = TRUE; ). ### Inputs ####; anot.gtf <- '../../shared_data/annotations/Ensembl/Homo_sapiens.GRCh38.101.gtf.gz' # Ensembl GTF; genome.fasta <- '../../shared_data/a",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/655#issuecomment-826035191:2979,test,test,2979,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/655#issuecomment-826035191,2,['test'],['test']
Testability," response, I sent you earlier, here too. In case it's helpful to some other user. > Hi Alex,. >Thanks again for forwarding the data. I think I have the solution for the problems you are facing in alevin. >Your first question was related to alevin quantifying very less number of reads. To answer that,; if you look at the log, at the first few lines, alevin warns about ~91% of the reads being thrown away because; of the noisy CBs. The problem is alevin’s first “knee"" estimation is overshooting in predicting the first boundary. You will find https://github.com/COMBINE-lab/salmon/issues/362 issue to be; very useful in understanding that. As a summary if you look at the plot I attached it has bi-modalities,; which is generally not the case and alevin is greedily finding the threshold at the first ~100 cells. If this; happens the general direction is to help alevin by proving a upper bound, in case of your data; would be ~14000 cells. You can tell alevin with `—expectCells 14000` and alevin start to work; normally and logs ~12% of the data is noisy. >You second question was a little complicated to answer. Seemingly, your salmon index has transcript with; same exact name `ENST00000399966.9`, occurring twice with different sequences. Just by looking at the index,; I am unsure it’s actually present in the reference or its salmon indexing messing up. If I Assume it was actually; present two times in the reference, alevin should report it instead of exiting abruptly in the middle of quantification.; Although, alevin does warns:; ```; [2019-07-04 14:12:32.519] [alevinLog] [warning] Found 1 transcripts with duplicate names; ```; >However, the bug i.e. not being able to distinguish duplicate names of the transcript, has been ; fixed and pushed in the develop branch of salmon. Alevin was reporting the error at the stage of quantification too, ; if you dump the logs in a file, but it was invisible in the console as it was over written my complex progress bar. . >Once I process it th",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/386#issuecomment-508754845:1086,log,logs,1086,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/386#issuecomment-508754845,2,['log'],['logs']
Testability," sure about this, it's possible if the guide sequences were already reverse-complemented then the above behavior would makes sense. I am a little less familiar with the guideRNA based ECCITE-seq data, although the mRNA library should be 5' and the sequence does come from forward strand but do we expect the guide RNA to be on the forward strand as well ? Unclear . I'll ask around at nygc and would let you know. > Why does increasing --maxNumBarcodes to 200000 results in no barcodes getting corrected? (See log for Run 2 below). What is the rationale for the current default of 100000?. That's again a great question. In short single-cell world is expanding rapidly and alevin was initially designed to work with 10x 3' data and some of the restriction are outdated with combinatorial indexing based multiplexed experiments. To be honest, 100k was just a random high enough number that was put down to throw away the obvious junk data. Having said that, you would notice that in both the logs you attached a significant fraction of barcodes are thrown away i.e., `Skipped 82268 barcodes due to No mapped read`, which is like ~82% of the 100k barcodes. Even if you include the 200k almost everything was thrown away, `[warning] Skipped 184123 barcodes due to No mapped read`. Although your point is important one why things are not getting sequence corrected with 200k, unfortunately I might have to do some more testing on that front to give more precise answer but in your case I'd advise keeping the default 100k bound, unless you are doing combinatorially-indexed data . > For the downstream analysis of such data, I usually work with both the read and UMI counts, but quants_mat.gz only contains the UMI counts. Can Alevin a produce a matrix of read counts as well. It would be a great feature to add. For now, what is easiest way to get the cell x feature matrix of read counts if I use the --dumpEq or --dumpBfh flags? Can tximport be used for this or do I need to use the Python parser firs",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-639048052:1245,log,logs,1245,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-639048052,2,['log'],['logs']
Testability," target unitTests; [100%] Built target salmon; Install the project...; -- Install configuration: ""Release""; -- Installing: /salmon-0.10.2/lib; -- Installing: /salmon-0.10.2/lib/libtbb.so; -- Installing: /salmon-0.10.2/lib/libtbbmalloc.so; -- Installing: /salmon-0.10.2/lib/libtbbmalloc_proxy.so; -- Installing: /salmon-0.10.2/lib/libtbbmalloc.so.2; -- Installing: /salmon-0.10.2/lib/libtbb.so.2; -- Installing: /salmon-0.10.2/lib/pkgconfig; -- Installing: /salmon-0.10.2/lib/libtbbmalloc_proxy.so.2; -- Installing: /salmon-0.10.2/bin/salmon; -- Installing: /salmon-0.10.2/lib/libsalmon_core.a. Installation complete. Please ensure the following paths are set properly.; ==========================================================================; Please add /salmon-0.10.2/bin to your PATH; Please add /salmon-0.10.2/lib to your LD_LIBRARY_PATH; ==========================================================================; root@e08cc9670e4a:/salmon-0.10.2/build# make test; Running tests...; Test project /salmon-0.10.2/build; Start 1: unit_tests; 1/3 Test #1: unit_tests ....................... Passed 0.17 sec; Start 2: salmon_read_test_fmd; 2/3 Test #2: salmon_read_test_fmd ............. Passed 1.78 sec; Start 3: salmon_read_test_quasi; 3/3 Test #3: salmon_read_test_quasi ........... Passed 1.59 sec. 100% tests passed, 0 tests failed out of 3. Total Test time (real) = 3.54 sec; root@e08cc9670e4a:/salmon-0.10.2/build# lsb_release -a; LSB Version: core-9.20160110ubuntu0.2-amd64:core-9.20160110ubuntu0.2-noarch:security-9.20160110ubuntu0.2-amd64:security-9.20160110ubuntu0.2-noarch; Distributor ID: Ubuntu; Description: Ubuntu 16.04.4 LTS; Release: 16.04; Codename: xenial; ```. I built with:. `$ cmake -DFETCH_BOOST=TRUE .. && make install && make test`. I can also install the boost via apt and see if that makes a difference (though I expect not since it looked like TBB was the issue, and I let cmake install that). We can also check our compiler versions, perhaps. I have : . ```; root@e08cc",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/250#issuecomment-404306268:1887,Test,Test,1887,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/250#issuecomment-404306268,1,['Test'],['Test']
Testability," the update. I’ll see about setting up a Linux box in the morning and trying the v1.3.1. I expected some reads to be discharged as this is a mixed intestinal sample so there is likely a lot of bacterial rna as we used rRNA depletion not polyA; selection. We were hoping to align to both the mouse genome and one of the bacteria species of interest. . Given the several orders of magnitude difference in discarded alignments between mine on 1.2.1 and your test run on 1.3.1, would you recommend I redo the whole dataset alignment on 1.3.1? If it runs even close to what you saw it shouldn’t take too long; to rerun. . Thanks again,. Ryan. Sent from my iPhone. On Jun 16, 2020, at 12:13 AM, Rob Patro <notifications@github.com> wrote:. ﻿. I processed the data above using the latest salmon from the develop branch; (the release candidate for 1.3.0), and I got the following time (used 8; threads, so timing is not directly comparable). ```; 4604.57user 43.64system 9:24.15elapsed 823%CPU; ```. The whole log is. ```; [2020-06-15 23:51:54.747] [jointLog] [info] setting maxHashResizeThreads to; 8; [2020-06-15 23:51:54.747] [jointLog] [info] Fragment incompatibility prior; below threshold. Incompatible fragments will be ignored.; [2020-06-15 23:51:54.747] [jointLog] [info] Usage of --validateMappings; implies use of minScoreFraction. Since not explicitly specified, it is; being set to 0.65; [2020-06-15 23:51:54.747] [jointLog] [info] Usage of --validateMappings; implies a default consensus slack of 0.2. Setting consensusSlack to 0.35.; [2020-06-15 23:51:54.747] [jointLog] [info] parsing read library format; [2020-06-15 23:51:54.747] [jointLog] [info] There is 1 library.; [2020-06-15 23:51:54.814] [jointLog] [info] Loading pufferfish index; [2020-06-15 23:51:54.814] [jointLog] [info] Loading dense pufferfish index.; [2020-06-15 23:51:55.555] [jointLog] [info] done; [2020-06-15 23:51:55.555] [jointLog] [info] Index contained 116,248 targets; [2020-06-15 23:51:55.588] [jointLog] [info] Num",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/537#issuecomment-644527727:1021,log,log,1021,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/537#issuecomment-644527727,1,['log'],['log']
Testability," v0.8 and 1.2.1. The one that seems most relevant here is the introduction of selective-alignment to replace the quasi-mapping procedure that was originally used in salmon. Selective-alignment actually scores the mappings found to the transcriptome, and rejects alignments whose quality is below a (user-specified) threshold. Here, you can see that, in 1.2.1. * 39 fragments are mapped within the score threshold; * 216 fragments are discarded because no mapping location has an alignment score above the threshold. all together, this means that the total number of ""mapped"" fragments in 1.2.1 is very similar to 0.8 (1.2.1 maps 39+216 = 255, while 0.8 maps 254). However, 1.2.1 discards 216 of the fragments because no mapping is sufficiently good. The default for ""sufficiently good"", by the way, is to have an alignment score of at least 65% of the maximum possible for a read of the given length. For typical RNA-seq data, this is actually quite liberal / generous, and is similar to the type of noise in alignment that Bowtie2 allows with the sensitive flag. In general, the heuristics used in 1.2.1 (selective-alignment) tend to be more sensitive than those used in 0.8 (quasi-mapping), since the mappings are then validated using alignment scoring. However, this does mean that the quality of the alignment along the whole read matters. Thus, it is more important to do quality / adapter trimming in the newer version compared to the older one. There is also a flag in 1.2.1 (`--softclip`) that will allow mismatches / gaps at the ends of reads to not detract from the alignment score. So, these are the main differences. However, looking at the output logs you provided, a couple of basic questions did come to mind. Why are there so few reads to begin with? Even in 0.8, only 254 reads mapped, which is obviously a very small number of reads. Is there something non-typical about this sample? Is it a full RNA-seq sample? Are these reads something atypical (like long reads — ONT or PacBio)?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/542#issuecomment-651332239:1770,log,logs,1770,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/542#issuecomment-651332239,1,['log'],['logs']
Testability,""", 0x7fffffff1e50) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10001_D2B1WACXX/libParams"", 0x7fffffff1e60) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10001_D2B1WACXX"", {st_mode=S_IFDIR|S_ISGID|0755, st_size=512, ...}) = 0; mkdir(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10001_D2B1WACXX/libParams"", 0777) = 0; stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10001_D2B1WACXX/aux_info"", 0x7fffffff1e50) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10001_D2B1WACXX/aux_info"", 0x7fffffff1e60) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10001_D2B1WACXX"", {st_mode=S_IFDIR|S_ISGID|0755, st_size=512, ...}) = 0; mkdir(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10001_D2B1WACXX/aux_info"", 0777) = 0; open(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10001_D2B1WACXX/logs/salmon_quant.log"", O_WRONLY|O_CREAT|O_APPEND, 0666) = 3; fstat(3, {st_mode=S_IFREG|0644, st_size=0, ...}) = 0; mmap(NULL, 4194304, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7fffbea00000; fstat(3, {st_mode=S_IFREG|0644, st_size=0, ...}) = 0; lseek(3, 0, SEEK_SET) = 0; mmap(NULL, 8388608, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_NORESERVE, -1, 0) = 0x7fffbe200000; mmap(NULL, 1073745920, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_STACK, -1, 0) = 0x7fff3e5eb000; mprotect(0x7fff3e5eb000, 4096, PROT_NONE) = 0; clone(child_stack=0x7fff7e5eaed0, flags=CLONE_VM|CLONE_FS|CLONE_FILES|CLONE_SIGHAND|CLONE_THREAD|CLONE_SYSVSEM|CLONE_SETTLS|CLONE_PARENT_SETTID|CLONE_CHILD_CLEARTID, parent_tidptr=0x7fff7e5eb9d0, tls=0x7fff7e5eb700, child_tidptr=0x7fff7e5eb9d0) = 32683; mmap(NULL, 8388608, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_NORESERVE, -1, 0) = 0x7fffbda000",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:32169,log,logs,32169,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,1,['log'],['logs']
Testability,""", 0x7fffffff1e50) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10002_C29P7ACXX/libParams"", 0x7fffffff1e60) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10002_C29P7ACXX"", {st_mode=S_IFDIR|S_ISGID|0755, st_size=512, ...}) = 0; mkdir(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10002_C29P7ACXX/libParams"", 0777) = 0; stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10002_C29P7ACXX/aux_info"", 0x7fffffff1e50) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10002_C29P7ACXX/aux_info"", 0x7fffffff1e60) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10002_C29P7ACXX"", {st_mode=S_IFDIR|S_ISGID|0755, st_size=512, ...}) = 0; mkdir(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10002_C29P7ACXX/aux_info"", 0777) = 0; open(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10002_C29P7ACXX/logs/salmon_quant.log"", O_WRONLY|O_CREAT|O_APPEND, 0666) = 3; fstat(3, {st_mode=S_IFREG|0644, st_size=0, ...}) = 0; mmap(NULL, 4194304, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7fffbea00000; fstat(3, {st_mode=S_IFREG|0644, st_size=0, ...}) = 0; lseek(3, 0, SEEK_SET) = 0; mmap(NULL, 8388608, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_NORESERVE, -1, 0) = 0x7fffbe200000; mmap(NULL, 1073745920, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_STACK, -1, 0) = 0x7fff3e5eb000; mprotect(0x7fff3e5eb000, 4096, PROT_NONE) = 0; clone(child_stack=0x7fff7e5eaed0, flags=CLONE_VM|CLONE_FS|CLONE_FILES|CLONE_SIGHAND|CLONE_THREAD|CLONE_SYSVSEM|CLONE_SETTLS|CLONE_PARENT_SETTID|CLONE_CHILD_CLEARTID, parent_tidptr=0x7fff7e5eb9d0, tls=0x7fff7e5eb700, child_tidptr=0x7fff7e5eb9d0) = 14650; mmap(NULL, 8388608, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_NORESERVE, -1, 0) = 0x7fffbda000",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:149846,log,logs,149846,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,1,['log'],['logs']
Testability,""", 0x7fffffff1e60) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10001_D2B1WACXX"", {st_mode=S_IFDIR|S_ISGID|0755, st_size=512, ...}) = 0; mkdir(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10001_D2B1WACXX/libParams"", 0777) = 0; stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10001_D2B1WACXX/aux_info"", 0x7fffffff1e50) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10001_D2B1WACXX/aux_info"", 0x7fffffff1e60) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10001_D2B1WACXX"", {st_mode=S_IFDIR|S_ISGID|0755, st_size=512, ...}) = 0; mkdir(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10001_D2B1WACXX/aux_info"", 0777) = 0; open(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10001_D2B1WACXX/logs/salmon_quant.log"", O_WRONLY|O_CREAT|O_APPEND, 0666) = 3; fstat(3, {st_mode=S_IFREG|0644, st_size=0, ...}) = 0; mmap(NULL, 4194304, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7fffbea00000; fstat(3, {st_mode=S_IFREG|0644, st_size=0, ...}) = 0; lseek(3, 0, SEEK_SET) = 0; mmap(NULL, 8388608, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_NORESERVE, -1, 0) = 0x7fffbe200000; mmap(NULL, 1073745920, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_STACK, -1, 0) = 0x7fff3e5eb000; mprotect(0x7fff3e5eb000, 4096, PROT_NONE) = 0; clone(child_stack=0x7fff7e5eaed0, flags=CLONE_VM|CLONE_FS|CLONE_FILES|CLONE_SIGHAND|CLONE_THREAD|CLONE_SYSVSEM|CLONE_SETTLS|CLONE_PARENT_SETTID|CLONE_CHILD_CLEARTID, parent_tidptr=0x7fff7e5eb9d0, tls=0x7fff7e5eb700, child_tidptr=0x7fff7e5eb9d0) = 32683; mmap(NULL, 8388608, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_NORESERVE, -1, 0) = 0x7fffbda00000; mmap(NULL, 1073745920, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_STACK, -1, 0) = 0x7ffefe5ea000; mprotect(0x7ffefe5ea000, 4096, PROT_NONE",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:32187,log,log,32187,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,1,['log'],['log']
Testability,""", 0x7fffffff1e60) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10002_C29P7ACXX"", {st_mode=S_IFDIR|S_ISGID|0755, st_size=512, ...}) = 0; mkdir(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10002_C29P7ACXX/libParams"", 0777) = 0; stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10002_C29P7ACXX/aux_info"", 0x7fffffff1e50) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10002_C29P7ACXX/aux_info"", 0x7fffffff1e60) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10002_C29P7ACXX"", {st_mode=S_IFDIR|S_ISGID|0755, st_size=512, ...}) = 0; mkdir(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10002_C29P7ACXX/aux_info"", 0777) = 0; open(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10002_C29P7ACXX/logs/salmon_quant.log"", O_WRONLY|O_CREAT|O_APPEND, 0666) = 3; fstat(3, {st_mode=S_IFREG|0644, st_size=0, ...}) = 0; mmap(NULL, 4194304, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7fffbea00000; fstat(3, {st_mode=S_IFREG|0644, st_size=0, ...}) = 0; lseek(3, 0, SEEK_SET) = 0; mmap(NULL, 8388608, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_NORESERVE, -1, 0) = 0x7fffbe200000; mmap(NULL, 1073745920, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_STACK, -1, 0) = 0x7fff3e5eb000; mprotect(0x7fff3e5eb000, 4096, PROT_NONE) = 0; clone(child_stack=0x7fff7e5eaed0, flags=CLONE_VM|CLONE_FS|CLONE_FILES|CLONE_SIGHAND|CLONE_THREAD|CLONE_SYSVSEM|CLONE_SETTLS|CLONE_PARENT_SETTID|CLONE_CHILD_CLEARTID, parent_tidptr=0x7fff7e5eb9d0, tls=0x7fff7e5eb700, child_tidptr=0x7fff7e5eb9d0) = 14650; mmap(NULL, 8388608, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_NORESERVE, -1, 0) = 0x7fffbda00000; mmap(NULL, 1073745920, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_STACK, -1, 0) = 0x7ffefe5ea000; mprotect(0x7ffefe5ea000, 4096, PROT_NONE",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:149864,log,log,149864,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,1,['log'],['log']
Testability,"$ sudo make install; [ 7%] Built target libcereal; [ 14%] Built target libdivsufsort; [ 21%] Built target libstadenio; [ 28%] Built target libbwa; [ 36%] Built target libgff; [ 42%] Built target libspdlog; [ 47%] Built target ksw2pp_basic; [ 49%] Built target ksw2pp_sse4; [ 52%] Built target ksw2pp_sse2; [ 53%] Built target ksw2pp; [ 55%] Built target alevin_core; [ 69%] Built target salmon_core; [ 74%] Built target unitTests; [100%] Built target salmon; Install the project...; -- Install configuration: ""Release""; -- Up-to-date: /usr/local/lib; -- Up-to-date: /usr/local/lib/libtbbmalloc.so; -- Up-to-date: /usr/local/lib/pkgconfig; -- Up-to-date: /usr/local/lib/libtbb.so; -- Up-to-date: /usr/local/lib/libtbb.so.2; -- Up-to-date: /usr/local/lib/libtbbmalloc_proxy.so.2; -- Up-to-date: /usr/local/lib/libtbbmalloc_proxy.so; -- Up-to-date: /usr/local/lib/libtbbmalloc.so.2; -- Up-to-date: /usr/local/bin/salmon; -- Up-to-date: /usr/local/lib/libsalmon_core.a. Installation complete. Please ensure the following paths are set properly. Please add /usr/local/bin to your PATH; Please add /usr/local/lib to your LD_LIBRARY_PATH. $ make test; Running tests...; Test project salmon/build; Start 1: unit_tests; 1/3 Test #1: unit_tests .......................***Failed 0.02 sec; Start 2: salmon_read_test_fmd; 2/3 Test #2: salmon_read_test_fmd ............. Passed 1.67 sec; Start 3: salmon_read_test_quasi; 3/3 Test #3: salmon_read_test_quasi ........... Passed 1.62 sec. 67% tests passed, 1 tests failed out of 3. Total Test time (real) = 3.32 sec. The following tests FAILED:; 	 1 - unit_tests (Failed); Errors while running CTest; Makefile:151: recipe for target 'test' failed; make: *** [test] Error 8",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/229#issuecomment-393691425:1139,test,test,1139,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/229#issuecomment-393691425,12,"['Test', 'test']","['Test', 'test', 'tests']"
Testability,"${FILE2} 	-o /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test4/${ID}. echo ""**** Job ends ****""; date; ```. ### Example log file. ```; **** Job starts ****; Wed Mar 29 14:53:43 EDT 2017; **** JHPCE info ****; User: lcollado; Job id: 110316; Job name: step6-salmon_test4.gsk_phaseII; Hostname: compute-067; Task id: ; Version Info: This is the most recent version of Salmon.; ### salmon (mapping-based) v0.8.2; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts }; ### [ threads ] => { 16 }; ### [ libType ] => { ISR }; ### [ mates1 ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/merged_fastq/R10001_D2B1WACXX.fastq.gz }; ### [ mates2 ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/merged_fastq/R10001_D2B1WACXX_read2.fastq.gz }; ### [ output ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test4/R10001_D2B1WACXX }; Logs will be written to /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test4/R10001_D2B1WACXX/logs; [1m[2017-03-29 14:56:39.675] [jointLog] [info] parsing read library format; [00m[1m[2017-03-29 14:56:39.733] [jointLog] [info] There is 1 library.; [00mterminate called without an active exception; /cm/local/apps/sge/var/spool/compute-067/job_scripts/110316: line 31: 64339 Aborted (core dumped) /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon quant -i /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts -p 16 -l ISR -1 ${FILE1} -2 ${FILE2} -o /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test4/${ID}; **** Job ends ****; Wed Mar 29 14:58:05 EDT 2017. ```. ### SGE email example info. ```; Job-array task 110316.1 (step6-salmon_test4.gsk_phaseII) Complete; User = lcollado; Queue = shared.q@compute-067.cm.cluster; Host = compute-067.cm.cluster; Start Time = 03/29/2017 14:53:42; End Time =",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-290516965:6035,Log,Logs,6035,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-290516965,2,"['Log', 'log']","['Logs', 'logs']"
Testability,"+1 for this feature, I would like to be able to use this feature for helping quality control and testing for our larger automated Salmon pipeline. @rekado - do you want to try to develop this and submit a pull request? :)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/185#issuecomment-358792432:97,test,testing,97,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/185#issuecomment-358792432,1,['test'],['testing']
Testability,", 1073745920, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_STACK, -1, 0) = -1 ENOMEM (Cannot allocate memory); futex(0x7fffbf4c3350, FUTEX_WAKE_PRIVATE, 2147483647) = 0; write(2, ""terminate called without an acti""..., 45terminate called without an active exception; ) = 45; rt_sigprocmask(SIG_UNBLOCK, [ABRT], NULL, 8) = 0; write(3, ""[2017-04-05 16:24:38.504] [joint""..., 136) = 136; tgkill(10693, 10693, SIGABRT) = 0; --- SIGABRT (Aborted) @ 0 (0) ---; +++ killed by SIGABRT (core dumped) +++; ```. (371 lines for task 1, 368 for task 2). Basically, both fail at a point where `mmap()` cannot allocate memory. So it definitely looks like a memory issue and I don't know if these information gives you any hints. . ## Bumping memory. Bumping the memory request to 28/30GB. This is a scenario where task 2 seems to work ok but tasks 1 and 3 fail. ```bash; #!/bin/bash; #$ -cwd; #$ -pe local 2; #$ -l mem_free=14G,h_vmem=15G,h_fsize=100G; #$ -N step6-salmon_test12.gsk_phaseII; #$ -o ./logs/salmon_test12.$TASK_ID.txt; #$ -e ./logs/salmon_test12.$TASK_ID.txt; #$ -t 1-3; #$ -hold_jid pipeline_setup,step4-featCounts-alzheimer.gsk_phaseII; #$ -m e; echo ""**** Job starts ****""; date. echo ""**** JHPCE info ****""; echo ""User: ${USER}""; echo ""Job id: ${JOB_ID}""; echo ""Job name: ${JOB_NAME}""; echo ""Hostname: ${HOSTNAME}""; echo ""Task id: ${TASK_ID}"". FILE1=$(awk 'BEGIN {FS=""\t""} {print $1}' /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk ""NR==${SGE_TASK_ID}""); if [ TRUE == ""TRUE"" ] ; then; FILE2=$(awk 'BEGIN {FS=""\t""} {print $3}' /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk ""NR==${SGE_TASK_ID}""); fi; ID=$(cat /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk '{print $NF}' | awk ""NR==${SGE_TASK_ID}""). mkdir -p /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/${ID}. strace /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon quant 	-i /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/A",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:77845,log,logs,77845,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,1,['log'],['logs']
Testability,". Please ensure the following paths are set properly.; ==========================================================================; Please add /salmon-0.10.2/bin to your PATH; Please add /salmon-0.10.2/lib to your LD_LIBRARY_PATH; ==========================================================================; root@e08cc9670e4a:/salmon-0.10.2/build# make test; Running tests...; Test project /salmon-0.10.2/build; Start 1: unit_tests; 1/3 Test #1: unit_tests ....................... Passed 0.17 sec; Start 2: salmon_read_test_fmd; 2/3 Test #2: salmon_read_test_fmd ............. Passed 1.78 sec; Start 3: salmon_read_test_quasi; 3/3 Test #3: salmon_read_test_quasi ........... Passed 1.59 sec. 100% tests passed, 0 tests failed out of 3. Total Test time (real) = 3.54 sec; root@e08cc9670e4a:/salmon-0.10.2/build# lsb_release -a; LSB Version: core-9.20160110ubuntu0.2-amd64:core-9.20160110ubuntu0.2-noarch:security-9.20160110ubuntu0.2-amd64:security-9.20160110ubuntu0.2-noarch; Distributor ID: Ubuntu; Description: Ubuntu 16.04.4 LTS; Release: 16.04; Codename: xenial; ```. I built with:. `$ cmake -DFETCH_BOOST=TRUE .. && make install && make test`. I can also install the boost via apt and see if that makes a difference (though I expect not since it looked like TBB was the issue, and I let cmake install that). We can also check our compiler versions, perhaps. I have : . ```; root@e08cc9670e4a:/salmon-0.10.2/build# g++ --version; g++ (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609; Copyright (C) 2015 Free Software Foundation, Inc.; This is free software; see the source for copying conditions. There is NO; warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. root@e08cc9670e4a:/salmon-0.10.2/build# gcc --version; gcc (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609; Copyright (C) 2015 Free Software Foundation, Inc.; This is free software; see the source for copying conditions. There is NO; warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.; ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/250#issuecomment-404306268:2651,test,test,2651,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/250#issuecomment-404306268,1,['test'],['test']
Testability,... but will try to test the 0.99 too,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/431#issuecomment-537081810:20,test,test,20,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/431#issuecomment-537081810,1,['test'],['test']
Testability,./src/unitTests; ===============================================================================; All tests passed (108 assertions in 4 test cases),MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/229#issuecomment-393687987:102,test,tests,102,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/229#issuecomment-393687987,3,"['assert', 'test']","['assertions', 'test', 'tests']"
Testability,".1 boost/1.70.0-gcc libiconv/1.16; export CC=`which gcc`; export CXX=`which c++`. cd $MODULE_HOME; mkdir -p source/$PACKAGE_NAME/$VERSION; INSTALL_DIR=$MODULE_HOME/modules/$PACKAGE_NAME/$VERSION; mkdir -p $INSTALL_DIR; mkdir -p modfiles/$PACKAGE_NAME. cd source/$PACKAGE_NAME/$VERSION; wget $LATEST_RELEASE -O - | tar -xz --strip-components 1; cmake -DBOOST_ROOT=/global/software/sl-7.x86_64/modules/gcc/7.4.0/boost/1.70.0-gcc -DCMAKE_INSTALL_PREFIX=$INSTALL_DIR; make; ```; And the tail of the output from make:. ```; creating: /clusterfs/vector/home/groups/software/sl-7.x86_64/source/salmon/1.5.1/scripts/../external/pufferfish-salmon-v1.5.1/tests/compile_tests/; inflating: /clusterfs/vector/home/groups/software/sl-7.x86_64/source/salmon/1.5.1/scripts/../external/pufferfish-salmon-v1.5.1/tests/compile_tests/int128_numeric_limits.cpp ; -- fetch PUFFERFISH exit code 0; -- Found ZLIB: /usr/lib64/libz.so (found version ""1.2.11"") ; -- Performing Test Iconv_IS_BUILT_IN; -- Performing Test Iconv_IS_BUILT_IN - Failed; CMake Error at /global/home/groups/consultsw/sl-7.x86_64/modules/cmake/3.15.1/share/cmake-3.15/Modules/FindPackageHandleStandardArgs.cmake:137 (message):; Could NOT find Iconv (missing: Iconv_LIBRARY); Call Stack (most recent call first):; /global/home/groups/consultsw/sl-7.x86_64/modules/cmake/3.15.1/share/cmake-3.15/Modules/FindPackageHandleStandardArgs.cmake:378 (_FPHSA_FAILURE_MESSAGE); /global/home/groups/consultsw/sl-7.x86_64/modules/cmake/3.15.1/share/cmake-3.15/Modules/FindIconv.cmake:120 (find_package_handle_standard_args); CMakeLists.txt:362 (find_package). -- Configuring incomplete, errors occurred!; See also ""/clusterfs/vector/home/groups/software/sl-7.x86_64/source/salmon/1.5.1/CMakeFiles/CMakeOutput.log"".; See also ""/clusterfs/vector/home/groups/software/sl-7.x86_64/source/salmon/1.5.1/CMakeFiles/CMakeError.log"".; ```; I'm also attaching the full CMake logs. This is right at the edge of my knowledge, so I'm not 100% sure I got libiconv installed corre",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/453#issuecomment-862737315:1779,Test,Test,1779,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/453#issuecomment-862737315,2,['Test'],['Test']
Testability,".637] [puff::index::jointLog] [info] chunk 5 = [78,786,480, 94,543,776) ; [2022-04-16 11:19:48.637] [puff::index::jointLog] [info] chunk 6 = [94,543,776, 110,301,072) ; [2022-04-16 11:19:48.638] [puff::index::jointLog] [info] chunk 7 = [110,301,072, 126,058,368) ; [2022-04-16 11:19:48.638] [puff::index::jointLog] [info] chunk 8 = [126,058,368, 141,815,664) ; [2022-04-16 11:19:48.638] [puff::index::jointLog] [info] chunk 9 = [141,815,664, 157,572,960) ; [2022-04-16 11:19:48.638] [puff::index::jointLog] [info] chunk 10 = [157,572,960, 173,330,256) ; [2022-04-16 11:19:48.638] [puff::index::jointLog] [info] chunk 11 = [173,330,256, 189,087,526) ; [2022-04-16 11:19:53.442] [puff::index::jointLog] [info] finished populating pos vector ; [2022-04-16 11:19:53.442] [puff::index::jointLog] [info] writing index components ; [2022-04-16 11:19:55.117] [puff::index::jointLog] [info] finished writing dense pufferfish index ; [2022-04-16 11:19:55.401] [jLog] [info] done building index. and the log for quantification:. > [2022-04-16 11:23:51.572] [jointLog] [info] setting maxHashResizeThreads to 48 ; [2022-04-16 11:23:51.572] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored. ; [2022-04-16 11:23:51.572] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65 ; [2022-04-16 11:23:51.572] [jointLog] [info] Setting consensusSlack to selective-alignment default of 0.35. [2022-04-16 11:23:51.572] [jointLog] [info] parsing read library format ; [2022-04-16 11:23:51.572] [jointLog] [info] There is 1 library. ; [2022-04-16 11:23:51.694] [jointLog] [info] Loading pufferfish index ; [2022-04-16 11:23:51.695] [jointLog] [info] Loading dense pufferfish index. ; [2022-04-16 11:23:53.681] [jointLog] [info] done ; [2022-04-16 11:23:53.681] [jointLog] [info] Index contained 245,261 targets ; [2022-04-16 11:23:53.776] [jointLog] [info] Number of decoys : 0 ; [2022-04-16",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/768#issuecomment-1100734317:15285,log,log,15285,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/768#issuecomment-1100734317,1,['log'],['log']
Testability,".gz \; --read2-in /home/GSE140511/fastq_files/SRR10480618_2.fastq.gz \; --read2-out=/home/GSE140511/SRR10480618_fq/SRR10480618_BC_2.fastq.gz \; --whitelist=/home/GSE140511/SRR10480618_fq/SRR10480618_whitelist.txt; ```. I swapped the reads as:; ```; /salmon-1.8.0_linux_x86_64/bin/salmon alevin \; -l ISR \; -2 /home/GSE140511/SRR10480618_fq/SRR10480618_BC_trimmed_1.fastq.gz \; -1 /home/GSE140511/SRR10480618_fq/SRR10480618_BC_trimmed_2.fastq.gz \; --chromiumV3 \; -i /data/ref_genomes/Mmus_GrCm39 \; -p 32 \; -o /home/GSE140511/salmon_alevin_output/SRR10480618_rev2 \; --expectCells 3000 --forceCells 3000 \; --tgMap /home/txp2gene_SB.tsv; ```; I tried both `ISR` and `ISF` (just in case)...mapping rate ranged from zero point something to one point something.; I also tried with and without `--expectCells 3000 --forceCells 3000` looking at a few suggestions [here](https://github.com/COMBINE-lab/salmon/discussions/506) but it didn't really make any difference. `Alevin.log` from the last run is:; ````; [2022-03-27 05:24:09.430] [alevinLog] [info] Found 116716 transcripts(+0 decoys, +39 short and +0 duplicate names in the index); [2022-03-27 05:24:09.478] [alevinLog] [info] Filled with 116755 txp to gene entries ; [2022-03-27 05:24:09.484] [alevinLog] [info] Found all transcripts to gene mappings; [2022-03-27 05:24:09.495] [alevinLog] [info] Processing barcodes files (if Present) . ; [2022-03-27 05:33:37.411] [alevinLog] [info] Done barcode density calculation.; [2022-03-27 05:33:37.411] [alevinLog] [info] # Barcodes Used: [32m359273127[0m / [31m359277869[0m.; [2022-03-27 05:34:04.367] [alevinLog] [info] Throwing 0 barcodes with < 10 reads; [2022-03-27 05:34:05.069] [alevinLog] [info] Total [32m4000[0m(has [32m999[0m low confidence) barcodes; [2022-03-27 05:34:07.956] [alevinLog] [info] Done True Barcode Sampling; [2022-03-27 05:34:25.703] [alevinLog] [warning] Total 91.5531% reads will be thrown away because of noisy Cellular barcodes.; [2022-03-27 05:34:26.221] [alevinLog] [in",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/763#issuecomment-1082597942:1479,log,log,1479,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/763#issuecomment-1082597942,1,['log'],['log']
Testability,".pdf)). This is sort of akin to what you are suggesting, and post-processes salmon output by looking for anomalous coverage profiles. It can both flag ""suspicious"" transcripts, and can also sometimes move reads around to mitigate anomalous coverage. Another tool / metric you might consider is the junction coverage compatibility (paper [here](https://www.life-science-alliance.org/content/2/1/e201800175)). Excellent papers! Definitely going to give those tools a try on my data. > So, I **completely agree** that a lightweight version of something like SAD would be great to have built _into_ salmon. Specifically, it makes a lot of sense to have some component of the likelihood account for the coverage profile of transcripts. Yes! I've been analyzing a large dataset and my real motivating problem was not really the example I posted above, but distinguishing between pre-processed and fully-processed non-coding RNA transcripts. I'm attaching an image showing an example ncRNA; the two tracks are the same data, but the lower one shows abundance on a log scale. In this particular sample, it's easy to estimate that ~5-10% of the transcripts are pre-processed (the transcripts still have neighboring genomic DNA). I wanted to see how this ratio changes between samples (for example, in a snoRNA processing-defective mutant strain), but quickly realized this is not easily done in salmon or any other quant tools because the processed transcript is entirely a subset of the sequence of the pre-processed transcript. The only way to accurately quantify it is to use the coverage information, which as you agreed is not really taken into account downstream. If Salmon could incorporate the coverage information to solve this class of problem, that would indeed be a **huge win**. I think the ncRNA example would be both a great biologically-interesting motivating problem, as well as a good technical benchmark for implementing any new methods. It could even be used as a secondary RNA velocity mea",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-623963851:1409,log,log,1409,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-623963851,2,['log'],['log']
Testability,"/salmon/lib/graphdump/graphdump-targets.cmake; -- Installing: /salmon/lib/graphdump/graphdump-targets-release.cmake; -- Installing: /salmon/lib/libtwopaco.a; -- Installing: /salmon/lib/twopaco/twopaco-targets.cmake; -- Installing: /salmon/lib/twopaco/twopaco-targets-release.cmake; -- Installing: /salmon/lib/libtbb.so; -- Installing: /salmon/lib/libtbb.so.12; -- Installing: /salmon/lib/libtbb.so.12.5; -- Installing: /salmon/lib/libtbbmalloc.so; -- Installing: /salmon/lib/libtbbmalloc.so.2; -- Installing: /salmon/lib/libtbbmalloc.so.2.5; -- Installing: /salmon/lib/libtbbmalloc_proxy.so; -- Installing: /salmon/lib/libtbbmalloc_proxy.so.2; -- Installing: /salmon/lib/libtbbmalloc_proxy.so.2.5; -- Installing: /salmon/bin/salmon; -- Installing: /salmon/lib/libsalmon_core.a. Installation complete. Please ensure the following paths are set properly.; ==========================================================================; Please add /salmon/bin to your PATH; Please add /salmon/lib to your LD_LIBRARY_PATH; ==========================================================================; root@fd877e359439:/salmon/build# make test; Running tests...; Test project /salmon/build; Start 1: unit_tests; 1/2 Test #1: unit_tests ....................... Passed 0.37 sec; Start 2: salmon_read_test_quasi; 2/2 Test #2: salmon_read_test_quasi ........... Passed 1.80 sec. 100% tests passed, 0 tests failed out of 2. Total Test time (real) = 2.17 sec; ```. The `make test` command itself runs the test the builds the index and maps the reads against it. Either way, I can do that explicitly too (from within build):. ```; $ ./src/salmon index -t ../sample_data/transcripts.fasta -i sample_idx; ```. returns succesfully with a built index. ```; ...; [2023-03-10 05:51:33.748] [puff::index::jointLog] [info] Done wrapping the rank vector with a rank9sel structure.; [2023-03-10 05:51:33.748] [puff::index::jointLog] [info] contig count for validation: 23; [2023-03-10 05:51:33.748] [puff::index::jointLog] [info",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463312554:2687,test,test,2687,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463312554,2,['test'],"['test', 'tests']"
Testability,"00 paired reads. The majority of the TBX21 reads have flags 99 or 147:; (# of reads) | (flag); 4431 | 147; 12 | 355; 14 | 403; 2 | 419; 4432 | 99. I also confirmed that many of these reads are indeed from the TBX21 spliced transcripts (cross splice junctions). I am running Salmon in mapping-based mode on the unaligned fastqs, and it is picking up exactly 0 reads in these transcripts. salmon index -t hg38_salmon_transcriptome.fa -i salmon_hg38_index --type quasi -k 31; salmon quant -i salmon_hg38_index -l ISR -p 8 -1 SRR1615172_1_val_1.fq.gz -2 SRR1615172_2_val_2.fq.gz -o salmon_quant_SRR1615172. The genome-wide distribution of insert size ranges for this sample are unusual (bi-modal), and this is partly why STAR only mapped 65% of the reads. The other issue with the sample is STAR reports 19% multi-mapped reads, but even so, there are still at least 4000 reads uniquely mapping to TBX21. Attached are:; ### Output from Salmon; [salmon_quant.log](https://github.com/COMBINE-lab/salmon/files/3199053/salmon_quant.log); [lib_format_counts.json.zip](https://github.com/COMBINE-lab/salmon/files/3199074/lib_format_counts.json.zip); ### Output from STAR; [SRR1615173.Log.final.out.STAR.txt](https://github.com/COMBINE-lab/salmon/files/3199078/SRR1615173.Log.final.out.STAR.txt); ### Output from samtools view over the TBX21 gene start and end (hg38 17:47733244-47746119); [TBX21_reads.txt](https://github.com/COMBINE-lab/salmon/files/3199054/TBX21_reads.txt); ### FastQC reports of the two fastqs; [SRR1615173_1_val_1.fq_fastqc.zip](https://github.com/COMBINE-lab/salmon/files/3199049/SRR1615173_1_val_1.fq_fastqc.zip); [SRR1615173_2_val_2.fq_fastqc.zip](https://github.com/COMBINE-lab/salmon/files/3199050/SRR1615173_2_val_2.fq_fastqc.zip); ### Output from CollectInsertSizeMetrics; [insert_size_histogram.pdf](https://github.com/COMBINE-lab/salmon/files/3199051/insert_size_histogram.pdf); [insert_size_metrics.txt](https://github.com/COMBINE-lab/salmon/files/3199052/insert_size_metrics.txt)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/218#issuecomment-494079306:1564,log,log,1564,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/218#issuecomment-494079306,3,"['Log', 'log']","['Log', 'log']"
Testability,"001_D2B1WACXX"", {st_mode=S_IFDIR|S_ISGID|0755, st_size=512, ...}) = 0; stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10001_D2B1WACXX/logs"", 0x7fffffff1e50) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10001_D2B1WACXX/logs"", 0x7fffffff1e60) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10001_D2B1WACXX"", {st_mode=S_IFDIR|S_ISGID|0755, st_size=512, ...}) = 0; mkdir(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10001_D2B1WACXX/logs"", 0777) = 0; write(2, ""Logs will be written to "", 24Logs will be written to ) = 24; write(2, ""/dcl01/lieber/ajaffe/lab/libd_al""..., 81/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10001_D2B1WACXX/logs) = 81; write(2, ""\n"", 1; ) = 1; stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10001_D2B1WACXX/libParams"", 0x7fffffff1e50) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10001_D2B1WACXX/libParams"", 0x7fffffff1e60) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10001_D2B1WACXX"", {st_mode=S_IFDIR|S_ISGID|0755, st_size=512, ...}) = 0; mkdir(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10001_D2B1WACXX/libParams"", 0777) = 0; stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10001_D2B1WACXX/aux_info"", 0x7fffffff1e50) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10001_D2B1WACXX/aux_info"", 0x7fffffff1e60) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10001_D2B1WACXX"", {st_mode=S_IFDIR|S_ISGID|0755, st_size=512, ...}) = 0; mkdir(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10001_D2B1WACXX/aux_info"", 0777) = 0; open(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:30950,log,logs,30950,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,1,['log'],['logs']
Testability,"002_C29P7ACXX"", {st_mode=S_IFDIR|S_ISGID|0755, st_size=512, ...}) = 0; stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10002_C29P7ACXX/logs"", 0x7fffffff1e50) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10002_C29P7ACXX/logs"", 0x7fffffff1e60) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10002_C29P7ACXX"", {st_mode=S_IFDIR|S_ISGID|0755, st_size=512, ...}) = 0; mkdir(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10002_C29P7ACXX/logs"", 0777) = 0; write(2, ""Logs will be written to "", 24Logs will be written to ) = 24; write(2, ""/dcl01/lieber/ajaffe/lab/libd_al""..., 81/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10002_C29P7ACXX/logs) = 81; write(2, ""\n"", 1; ) = 1; stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10002_C29P7ACXX/libParams"", 0x7fffffff1e50) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10002_C29P7ACXX/libParams"", 0x7fffffff1e60) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10002_C29P7ACXX"", {st_mode=S_IFDIR|S_ISGID|0755, st_size=512, ...}) = 0; mkdir(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10002_C29P7ACXX/libParams"", 0777) = 0; stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10002_C29P7ACXX/aux_info"", 0x7fffffff1e50) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10002_C29P7ACXX/aux_info"", 0x7fffffff1e60) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10002_C29P7ACXX"", {st_mode=S_IFDIR|S_ISGID|0755, st_size=512, ...}) = 0; mkdir(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10002_C29P7ACXX/aux_info"", 0777) = 0; open(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:148627,log,logs,148627,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,1,['log'],['logs']
Testability,"1-02-15 04:42:28.404] [puff::index::jointLog] [info] Total # of contig vec entries: 7,119,643; [2021-02-15 04:42:28.404] [puff::index::jointLog] [info] bits per offset entry 23; [2021-02-15 04:42:28.590] [puff::index::jointLog] [info] Done constructing the contig vector. 1309433; [2021-02-15 04:42:29.459] [puff::index::jointLog] [info] # segments = 1,309,432; [2021-02-15 04:42:29.459] [puff::index::jointLog] [info] total length = 188,284,293; [2021-02-15 04:42:29.548] [puff::index::jointLog] [info] Reading the reference files ...; [2021-02-15 04:42:31.594] [puff::index::jointLog] [info] positional integer width = 28; [2021-02-15 04:42:31.594] [puff::index::jointLog] [info] seqSize = 188,284,293; [2021-02-15 04:42:31.595] [puff::index::jointLog] [info] rankSize = 188,284,293; [2021-02-15 04:42:31.595] [puff::index::jointLog] [info] edgeVecSize = 0; [2021-02-15 04:42:31.595] [puff::index::jointLog] [info] num keys = 143,763,605; len should not be greater than 64.; ...; ...; ...; len should not be greater than 64.; [2021-02-15 05:07:13.459] [puff::index::jointLog] [info] finished populating pos vector; [2021-02-15 05:07:13.460] [puff::index::jointLog] [info] writing index components; [2021-02-15 05:07:13.760] [puff::index::jointLog] [info] finished writing dense pufferfish index; [2021-02-15 05:07:13.810] [jLog] [info] done building index. When I have just run quantification using this index, it appears again here in the log;. salmon quant -i .../Human_v36_Index_k35 -l A --seqBias --gcBias --posBias -p 12 -o ../Sample_${i}/ -1 ${r1} -2 ${r2} . [2021-02-15 19:11:59.260] [jointLog] [info] done; [2021-02-15 19:11:59.260] [jointLog] [info] Index contained 232,117 targets; [2021-02-15 19:12:05.495] [jointLog] [info] Number of decoys : 0. len should not be greater than 64.; len should not be greater than 64.; len should not be greater than 64.; ...; ...; ...; [It hasn't finished yet]. I've had this issue before, too, but couldn't work out what the problem was. . Thanks,; Dan",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/632#issuecomment-779416548:2267,log,log,2267,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/632#issuecomment-779416548,1,['log'],['log']
Testability,"1/3 loss in performance seems significant, given that presumably the code does something else than just parsing UMIs. I am looking at Boost own comparison and benchmarks, and on long inputs (20MB) it is competitive with PCRE2. But with short inputs (20-30 characters) PCRE2 is consistently faster (by about 30% :thinking: ). And if PCRE2 is feature full, not sure it is the fastest either, especially for simple regexp.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/734#issuecomment-1023320721:159,benchmark,benchmarks,159,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/734#issuecomment-1023320721,2,['benchmark'],['benchmarks']
Testability,"1_S114_L006_R1_001.qc.fq.gz; mgonad-1_S120_L006_R1_001.qc.fq.gz; lightreceptor-2_S115_L006_R1_001.qc.fq.gz; mgonad-2_S121_L005_R1_001.qc.fq.gz mgonad-1_S120_L005_R1_001.qc.fq.gz; lightreceptor-2_S115_L005_R1_001.qc.fq.gz; lightreceptor-1_S114_L005_R1_001.qc.fq.gz; mgonad-2_S121_L004_R1_001.qc.fq.gz mgonad-1_S120_L004_R1_001.qc.fq.gz; lightreceptor-2_S115_L004_R1_001.qc.fq.gz; lightreceptor-1_S114_L004_R1_001.qc.fq.gz -2; mgonad-2_S121_L006_R2_001.qc.fq.gz; lightreceptor-1_S114_L006_R2_001.qc.fq.gz; mgonad-1_S120_L006_R2_001.qc.fq.gz; lightreceptor-2_S115_L006_R2_001.qc.fq.gz; mgonad-2_S121_L005_R2_001.qc.fq.gz mgonad-1_S120_L005_R2_001.qc.fq.gz; lightreceptor-2_S115_L005_R2_001.qc.fq.gz; lightreceptor-1_S114_L005_R2_001.qc.fq.gz; mgonad-2_S121_L004_R2_001.qc.fq.gz mgonad-1_S120_L004_R2_001.qc.fq.gz; lightreceptor-2_S115_L004_R2_001.qc.fq.gz; lightreceptor-1_S114_L004_R2_001.qc.fq.gz ${i} -o ${i}_quant --seqBias; --gcBias --validateMappings; done```. And here is my output from salmon.log. [2019-07-30 10:40:14.624] [jointLog] [info] Fragment incompatibility prior; below threshold. Incompatible fragments will be ignored.; [2019-07-30 10:40:14.624] [jointLog] [error] You passed paired-end files to; salmon, but you passed 12 files to --mates1 and 13 files to --mates2. You; must pass the same number of files to both flags. Thank you in advance for any tips you may have for me. Sara. On Tue, Jul 30, 2019 at 10:30 AM Sara Boles <seboles@ucdavis.edu> wrote:. > Hi Avi,; >; > Here is the salmon log from one of my PE libraries. There are only 12; > libraries for each in the directory, which is why I got confused when it; > said 13. I will try putting in all of the file names and let you know how; > it goes. Thank you for all of your help.; >; > Sara; >; > [2019-07-29 15:58:39.034] [jointLog] [info] Fragment incompatibility prior; > below threshold. Incompatible fragments will be ignored.; > [2019-07-29 15:58:39.034] [jointLog] [info] Usage of --validateMappings; > implies use o",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/408#issuecomment-516521791:1448,log,log,1448,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/408#issuecomment-516521791,1,['log'],['log']
Testability,"20:19 run_salmon.sh; lrwxrwxrwx 1 vale rst_pub 112 Jan 2 20:08 SRP057125_SRS936134_1.fastq -> /nfs/research2/teichmann/valentine/detection-comparison/salmon0.4.2-comparison/mouse/SRP057125_SRS936134_1.fastq; lrwxrwxrwx 1 vale rst_pub 112 Jan 2 20:08 SRP057125_SRS936134_2.fastq -> /nfs/research2/teichmann/valentine/detection-comparison/salmon0.4.2-comparison/mouse/SRP057125_SRS936134_2.fastq; drwxrwxr-x 5 vale rst_pub 4.0K Jan 2 20:20 SRP057125_SRS936134_salmon_out; ```. But when I run the script there, it succeeds, without segfault. ```; [vale@ebi-003 salmon-problem]$ bash run_salmon.sh; Version Info: This is the most recent version of Salmon.; # salmon (mapping-based) v0.6.0; # [ program ] => salmon; # [ command ] => quant; # [ index ] => { mouse_cdna_38.p3.78_repbase_ercc.fa }; # [ libType ] => { IU }; # [ mates1 ] => { SRP057125_SRS936134_1.fastq }; # [ mates2 ] => { SRP057125_SRS936134_2.fastq }; # [ output ] => { SRP057125_SRS936134_salmon_out }; # [ biasCorrect ] => { }; # [ useFSPD ] => { }; Logs will be written to SRP057125_SRS936134_salmon_out/logs; [2016-01-02 20:16:39.349] [jointLog] [info] parsing read library format; there is 1 lib; Loading 32-bit quasi index[2016-01-02 20:16:39.895] [stderrLog] [info] Loading Suffix Array; [2016-01-02 20:16:39.895] [stderrLog] [info] Loading Position Hash; [2016-01-02 20:16:39.894] [jointLog] [info] Loading Quasi index; [2016-01-02 20:16:42.565] [stderrLog] [info] Loading Transcript Info; [2016-01-02 20:16:43.654] [stderrLog] [info] Loading Rank-Select Bit Array; [2016-01-02 20:16:44.075] [stderrLog] [info] There were 104534 set bits in the bit array; [2016-01-02 20:16:44.448] [stderrLog] [info] Computing transcript lengths; [2016-01-02 20:16:44.448] [stderrLog] [info] Waiting to finish loading hash; Index contained 104534 targets; [2016-01-02 20:16:57.606] [stderrLog] [info] Done loading index; [2016-01-02 20:16:57.606] [jointLog] [info] done. processed 12000000 fragments; hits: 24367197, hits per frag: 2.06194+06. [20",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/34#issuecomment-168426741:1549,Log,Logs,1549,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/34#issuecomment-168426741,2,"['Log', 'log']","['Logs', 'logs']"
Testability,"29 15:58:39.034] [jointLog] [info] Usage of --validateMappings; implies use of minScoreFraction. Since not explicitly specified, it is; being set to 0.65; [2019-07-29 15:58:39.034] [jointLog] [info] Usage of --validateMappings,; without --hardFilter implies use of range factorization.; rangeFactorizationBins is being set to 4; [2019-07-29 15:58:39.034] [jointLog] [info] Usage of --validateMappings; implies a default consensus slack of 0.2. Setting consensusSlack to 0.2.; [2019-07-29 15:58:39.034] [jointLog] [info] parsing read library format; [2019-07-29 15:58:39.034] [jointLog] [error] Failed to successfully parse; any complete read libraries. Please make sure you provided arguments; properly to -1, -2 (for paired-end libraries) or -r (for single-end; libraries), and that the library format option (-l) *comes before* the read; libraries. On Mon, Jul 29, 2019 at 4:06 PM Avi Srivastava <notifications@github.com>; wrote:. > Oh Sorry about that what I meant was the salmon.log file or the the; > meta-info.json file created by salmon in the output directory. You can; > check what files salmon is detecting it seems there are 12 files in the; > mate1 and 13 files in the mate2. Can you confirm there are 13 pairs of file; > in that directory and their regex is same as you are using ? Can you also; > try putting the names of the file instead * as regex ?; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/COMBINE-lab/salmon/issues/408?email_source=notifications&email_token=AEHDXAA5DHKAZKVCZY5N7ULQB5ZXXA5CNFSM4IGU4ZTKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOD3CIG3I#issuecomment-516195181>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AEHDXAHE56TJTIQFQDFDGMDQB5ZXXANCNFSM4IGU4ZTA>; > .; >. -- ; Sara E. Boles, MS; PhD Candidate | Whitehead Lab; Pharmacology and Toxicology Graduate Group; Department of Environmental Toxicology; University of Californ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/408#issuecomment-516514620:1403,log,log,1403,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/408#issuecomment-516514620,1,['log'],['log']
Testability,"29P7ACXX"", {st_mode=S_IFDIR|S_ISGID|0755, st_size=33280, ...}) = 0; stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10002_C29P7ACXX/logs"", 0x7fffffff1e50) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10002_C29P7ACXX/logs"", 0x7fffffff1e60) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10002_C29P7ACXX"", {st_mode=S_IFDIR|S_ISGID|0755, st_size=33280, ...}) = 0; mkdir(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10002_C29P7ACXX/logs"", 0777) = 0; write(2, ""Logs will be written to "", 24Logs will be written to ) = 24; write(2, ""/dcl01/lieber/ajaffe/lab/libd_al""..., 81/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10002_C29P7ACXX/logs) = 81; write(2, ""\n"", 1; ) = 1; stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10002_C29P7ACXX/libParams"", 0x7fffffff1e50) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10002_C29P7ACXX/libParams"", 0x7fffffff1e60) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10002_C29P7ACXX"", {st_mode=S_IFDIR|S_ISGID|0755, st_size=33280, ...}) = 0; mkdir(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10002_C29P7ACXX/libParams"", 0777) = 0; stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10002_C29P7ACXX/aux_info"", 0x7fffffff1e50) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10002_C29P7ACXX/aux_info"", 0x7fffffff1e60) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10002_C29P7ACXX"", {st_mode=S_IFDIR|S_ISGID|0755, st_size=33280, ...}) = 0; mkdir(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10002_C29P7ACXX/aux_info"", 0777) = 0; open(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salm",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:67722,log,logs,67722,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,1,['log'],['logs']
Testability,"2B1WACXX"", {st_mode=S_IFDIR|S_ISGID|0755, st_size=33280, ...}) = 0; stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10001_D2B1WACXX/logs"", 0x7fffffff1e50) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10001_D2B1WACXX/logs"", 0x7fffffff1e60) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10001_D2B1WACXX"", {st_mode=S_IFDIR|S_ISGID|0755, st_size=33280, ...}) = 0; mkdir(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10001_D2B1WACXX/logs"", 0777) = 0; write(2, ""Logs will be written to "", 24Logs will be written to ) = 24; write(2, ""/dcl01/lieber/ajaffe/lab/libd_al""..., 81/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10001_D2B1WACXX/logs) = 81; write(2, ""\n"", 1; ) = 1; stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10001_D2B1WACXX/libParams"", 0x7fffffff1e50) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10001_D2B1WACXX/libParams"", 0x7fffffff1e60) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10001_D2B1WACXX"", {st_mode=S_IFDIR|S_ISGID|0755, st_size=33280, ...}) = 0; mkdir(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10001_D2B1WACXX/libParams"", 0777) = 0; stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10001_D2B1WACXX/aux_info"", 0x7fffffff1e50) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10001_D2B1WACXX/aux_info"", 0x7fffffff1e60) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10001_D2B1WACXX"", {st_mode=S_IFDIR|S_ISGID|0755, st_size=33280, ...}) = 0; mkdir(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10001_D2B1WACXX/aux_info"", 0777) = 0; open(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salm",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:106304,log,logs,106304,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,1,['log'],['logs']
Testability,"2_linux_x86_64/bin/salmon quant -i /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts -p 16 -l ISR -1 ${FILE1} -2 ${FILE2} -o /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test4/${ID}; **** Job ends ****; Wed Mar 29 14:58:05 EDT 2017. ```. ### SGE email example info. ```; Job-array task 110316.1 (step6-salmon_test4.gsk_phaseII) Complete; User = lcollado; Queue = shared.q@compute-067.cm.cluster; Host = compute-067.cm.cluster; Start Time = 03/29/2017 14:53:42; End Time = 03/29/2017 14:58:05; User Time = 00:00:00; System Time = 00:05:39; Wallclock Time = 00:04:23; CPU = 00:05:39; Max vmem = 24.202G; Exit Status = 0; ```. Note that in this case, it didn't read the maximum memory requested (16 * 3 = 48 GB). ## Large memory, p 1. ### Bash. ```bash; #!/bin/bash; #$ -cwd; #$ -l mem_free=80G,h_vmem=90G,h_fsize=100G; #$ -N step6-salmon_test5.gsk_phaseII; #$ -pe local 1; #$ -o ./logs/salmon_test5.$TASK_ID.txt; #$ -e ./logs/salmon_test5.$TASK_ID.txt; #$ -t 1-3; #$ -hold_jid pipeline_setup,step4-featCounts-alzheimer.gsk_phaseII; #$ -m e; echo ""**** Job starts ****""; date. echo ""**** JHPCE info ****""; echo ""User: ${USER}""; echo ""Job id: ${JOB_ID}""; echo ""Job name: ${JOB_NAME}""; echo ""Hostname: ${HOSTNAME}""; echo ""Task id: ${TASK_ID}"". FILE1=$(awk 'BEGIN {FS=""\t""} {print $1}' /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk ""NR==${SGE_TASK_ID}""); if [ TRUE == ""TRUE"" ] ; then; FILE2=$(awk 'BEGIN {FS=""\t""} {print $3}' /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk ""NR==${SGE_TASK_ID}""); fi; ID=$(cat /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk '{print $NF}' | awk ""NR==${SGE_TASK_ID}""). mkdir -p /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test5/${ID}. /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon quant 	-i /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gen",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-290516965:7496,log,logs,7496,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-290516965,1,['log'],['logs']
Testability,"30-some MB to 7.5GB ... that's some damn good compression. While strace won't let me see the offending function, the log *definitely* indicates that there's just a bunch of threads waiting. This must mean that there's the potential for a deadlock condition somewhere. Is it the case that this happened once the Gibbs sampler had started? That's the code I've been looking in, but all of the threading there is handled by Intel's TBB library (apart from a call to actually dump each recorded Gibbs sample, which uses a `std::lock_guard`, which, hopefully, isn't broken).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267424145:117,log,log,117,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267424145,1,['log'],['log']
Testability,42.622] [jLog] [info] building index; [2019-07-01 12:32:42.628] [jointLog] [info] [Step 1 of 4] : counting k-mers. <Several warnings about transcripts that are disliked>. [2019-07-01 12:33:02.020] [jointLog] [info] Replaced 3801867 non-ATCG nucleotides; [2019-07-01 12:33:02.020] [jointLog] [info] Clipped poly-A tails from 1630 transcripts; [2019-07-01 12:33:02.041] [jointLog] [info] Building rank-select dictionary and saving to disk; [2019-07-01 12:33:02.248] [jointLog] [info] done; Elapsed time: 0.20793s; [2019-07-01 12:33:02.252] [jointLog] [info] Writing sequence data to file . . . ; [2019-07-01 12:33:04.501] [jointLog] [info] done; Elapsed time: 2.24861s; [2019-07-01 12:33:04.572] [jointLog] [info] Building 32-bit suffix array (length of generalized text is 469043886); [2019-07-01 12:33:08.681] [jointLog] [info] Building suffix array . . . ; success; saving to disk . . . done; Elapsed time: 61.4932s; done; Elapsed time: 171.743s; processed 12000000 positionsKilled. I can send log files if required. The problem I have is that I cannot seem to run quant without the quant function. salmon quant --validateMappings ; -i /home/RnaSeq/transcriptome_gencode_v29/human_GENCODEv29/combined_index -l IU ; -1 /home/RnaSeq/fastq/DM_4a_H_1.fq.gz /home/RnaSeq/fastq/DM_4b_H_1.fq.gz /home/RnaSeq/fastq/DM_4c_H_1.fq.gz ; -2 /home/RnaSeq/fastq/DM_4a_H_2.fq.gz /home/RnaSeq/fastq/DM_4b_H_2.fq.gz /home/RnaSeq/fastq/DM_4c_H_2.fq.gz ; -o /home/RnaSeq/salmon_output_files/out/DM4h; Version Info: Could not resolve upgrade information in the alotted time.; Check for upgrades manually at https://combine-lab.github.io/salmon; ### salmon (mapping-based) v0.14.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { /home/RnaSeq/transcriptome_gencode_v29/human_GENCODEv29/combined_index }; ### [ libType ] => { IU }; ### [ mates1 ] => { /home/RnaSeq/fastq/DM_4a_H_1.fq.gz /home/RnaSeq/fastq/DM_4b_H_1.fq.gz /home/RnaSeq/fastq/DM_4c_H_1.fq.gz }; ### [ mates2 ] => { /home/RnaSeq/fas,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/389#issuecomment-507253562:1750,log,log,1750,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/389#issuecomment-507253562,1,['log'],['log']
Testability,"493] [jointLog] [info] Loading Quasi index; [2018-07-19 22:55:38.494] [jointLog] [info] Loading 32-bit quasi index; [2018-07-19 22:55:38.549] [jointLog] [info] done; [2018-07-19 22:55:38.549] [jointLog] [info] Index contained 179 targets. [2018-07-19 22:55:38.385] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify. [2018-07-19 22:55:38.385] [alevinLog] [info] parsing read library format; [2018-07-19 22:55:38.495] [stderrLog] [info] Loading Suffix Array ; [2018-07-19 22:55:38.498] [stderrLog] [info] Loading Transcript Info ; [2018-07-19 22:55:38.499] [stderrLog] [info] Loading Rank-Select Bit Array; [2018-07-19 22:55:38.500] [stderrLog] [info] There were 179 set bits in the bit array; [2018-07-19 22:55:38.501] [stderrLog] [info] Computing transcript lengths; [2018-07-19 22:55:38.501] [stderrLog] [info] Waiting to finish loading hash; processed 87 Million fragmentserrLog] [info] Done loading index; hits: 468892, hits per frag: 0.00535907. [2018-07-19 23:03:35.740] [jointLog] [info] Computed 150 rich equivalence classes for further processing; [2018-07-19 23:03:35.740] [jointLog] [info] Counted 412868 total reads in the equivalence classes ; [2018-07-19 23:03:35.741] [jointLog] [warning] Only 412868 fragments were mapped, but the number of burn-in fragments was set to 5000000.; The effective lengths have been computed using the observed mappings. [2018-07-19 23:03:35.741] [jointLog] [info] Mapping rate = 0.469385%. [2018-07-19 23:03:35.741] [jointLog] [info] finished quantifyLibrary(); [2018-07-19 23:03:35.755] [alevinLog] [info] Starting optimizer. Analyzed 5238 cells (100% of all).; Skipped Barcodes are from High Confidence Region; `$ls -ltrha alevin_output/alevin/`; total 256K; drwxrwx--- 6 zare G-816158 4.0K Jul 19 22:36 ..; -rw-rw---- 1 zare G-816158 960 Jul 19 23:03 alevin.log; drwxrwx--- 2 zare G-816158 4.0K Jul 19 23:03 .; -rw-rw---- 1 zare G-816158 81K Jul 19 23:03 quants_mat_rows.txt; -rw-rw---- 1 zare G-816158 160K Jul 19 23:03 quants_mat.gz",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/253#issuecomment-406597243:4207,log,log,4207,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/253#issuecomment-406597243,1,['log'],['log']
Testability,"4; [2020-06-16 00:01:17.131] [jointLog] [info] Finished optimizer; [2020-06-16 00:01:17.131] [jointLog] [info] writing output; ```. So, you can note that the number of mappings discarded because of alignment; score is still quite big (134M) and, indeed, this took longer than I would; normally expect for; a sample with ~30M reads. However, it is _massively_ smaller (~116 times); than the 15.6B in your run. Thus, it may have been the same issue as in; the other GitHub issue. You can try the pre-compiled linux binary I linked; there if you have access to a linux machine to test on. By the way, the; issue there was a bunch of reads plagued by super-repetitive homopolymer; segments, I haven't looked at these reads yet for evidence of that though. On Mon, Jun 15, 2020 at 11:09 PM shalercr <notifications@github.com> wrote:. >; >; >; >; >; > Hi Rob,; >; >; > Thanks for the quick response. The other computer was OSX, should I try a; > linux machine?; >; >; > Here are some dropbox links to two of the files. I believe this is the set; > for the logs I posted.; >; >; > https://www.dropbox.com/s/8c3p9hmgmadgj89/31_1.trimmed.fastq.gz?dl=0; >; >; > https://www.dropbox.com/s/2y9jfvaphe9h21x/31_2.trimmed.fastq.gz?dl=0; >; >; >; >; > Thanks,; >; >; > Ryan; >; >; >; >; >; > On Jun 15, 2020, at 9:32 PM, Rob Patro <notifications@github.com> wrote:; >; >; >; >; > Thank you for the report. Can you share one of the samples where you see; > this issue? Also, out of curiosity, was the other machine you tried on also; > OSX, or was it a linux machine?; > —; > You are receiving this because you authored the thread.; > Reply to this email directly,; > view it on GitHub, or; > unsubscribe.; >; > —; > You are receiving this because you commented.; > Reply to this email directly, view it on GitHub; > <https://github.com/COMBINE-lab/salmon/issues/537#issuecomment-644504783>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AACYH7UHOYB7KYKDASFB5RDRW3O7HANCNFSM4N7EOYSQ>; > .; >",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/537#issuecomment-644520228:4726,log,logs,4726,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/537#issuecomment-644520228,1,['log'],['logs']
Testability,"50GB of memory, I also tested with 32G and 16GB of memory, just to see what impact this would have on the times. Those jobs are still running (it's only been about 4hrs as of this writing, I'll update my post if/when they complete). Current logs are showing that they quickly consume all the available memory, but have not yet crashed. I've also got versions with 128-512GB of memory requested (by powers of 2) for comparison. Some random notes: both the 31-mer index experienced about twice as many soft page reclaims with the new/faster version and experienced a few hard page faults (the previous version saw none of the latter). The 17-mer version experienced fewer page reclaims than any of the 31-mer indices and far fewer than with the prior version. Again, a few page faults crept in, but relatively few by percentage and likely not contributing any significant amount of time overall. [index-qacct-17mer.log](https://github.com/COMBINE-lab/salmon/files/4246516/index-qacct-17mer.log); [index-qacct-31mer.log](https://github.com/COMBINE-lab/salmon/files/4246517/index-qacct-31mer.log). **UPDATE**; The 16GB version finished running. It actually only took a little over 4 hours to run, as well. The troubling thing about this job seems to be that, despite having successfully completed, according to the accounting log it used over 20GB of memory... which should be impossible to do. Our resident experts suspect there's a race condition occurring at the tail end of the job and that all of that extra memory is being allocated before the scheduler can kill it for exceeding the limit. Whatever the case, though, this throws into question some of those numbers that I've been grabbing from the accounting logs --- it's either being misreported, or the memory gobbling is happening so rapidly that it may not, in fact, be being properly recorded. I tested the index anyway. It *appears* to be working just fine. Nothing faulted or crashed when I attempted to quantify some reads against it. [ind",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/476#issuecomment-590516702:1688,log,log,1688,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/476#issuecomment-590516702,1,['log'],['log']
Testability,"8ab940abb751fc duplicate_clusters.tsv; c3ec09a30adc9d47bc95839157cb2ff66530353106a4fd8e75b167ac5db67820 info.json; 430be78bae99a4592fcedc5c800a42313f2b1252e3953f89f347779056c1ee5b mphf.bin; 2fb0b5151f9f2544c06a9f95d03075f7af0494d0fe31745504a5a7da43edc1b1 pos.bin; 15d3bb6a16bcd8c1a6814852bd3dcfa439b60ec84c706f868ee7ec2d5a90581d pre_indexing.log; 8e665e5fdee5af6fcedabc69fd04eda6e66055ef811ebde6de6f86a66521198a rank.bin; 793c79f5fd6046dfea07bbc9587d2835088e54c78197d652d1b1f205c6b16983 refAccumLengths.bin; c5ea8eccca3fdc299ad7c9d2f07a4ed14c8c830940e83c315e7eaad6905a40aa ref_indexing.log; b580b9c6257254a018a9ae22291a64892c1a3715c69272637f5c504fc5545a70 reflengths.bin; 89679603ac0b28042275e5ff04b222bad3fd431cab573f0c2b61e7455aec43e7 refseq.bin; 46bf28001e00d491b68bf8758b99c1f304523c79bd94a97d7797888856594e84 seq.bin; 4c7e56ba28383774e786826099ef412761326fe18ce69f29033ad2886542985d versionInfo.json; `; Following are different.; `ctable.bin; info.json; mphf.bin; pos.bin; pre_indexing.log; ref_indexing.log; seq.bin; versionInfo.json`. I will try creating the vM25 index with increased memory. Wonder if its not building. Just FYI, my sha256sum on vM23 index is:; `9788716f4ce42b049fe7e865108f45392bb8a5847cfcd47369512783dc918239 complete_ref_lens.bin; 9c2453a47ce1808f54733f049b8c4cf38634c9116eb55ed725b73219caa101c5 ctable.bin; 928ba619dc5388ccab6d5c4f8ce162e07a5b5c79028be4aee4d838f43a3b9d92 ctg_offsets.bin; 0814d0e7dd8a4b126709c42728816995aefdf5a5bb6337c2d3c048cb0f56094d duplicate_clusters.tsv; dcbf8e140627b3c99d4dbcdaa585447a691fddb620f137811b669e73800f9b3b info.json; 5959abf5969a26481c6aa20fecbdddf19fa558e949cfbda5760205f38bb907b9 mphf.bin; 28460131b85c74ffb7627761a291614757e72b4e3b82971dcc048a50cc8d9e7f pos.bin; b5eb5e3fb0d03509d9fc90f6b5461c6aecc44423068f3303553cc07fffc7c1b9 pre_indexing.log; eca518136526233f3dc28d9684926793cb84327242d54c1a8a20c66aa1928fad rank.bin; a990247ba2b351fd0921de6470bf0c3505472d8f463e6f8b9ec7c221b6b56af8 refAccumLengths.bin; 436199afbb35045a70fdc7b9",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/561#issuecomment-674527480:1674,log,log,1674,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/561#issuecomment-674527480,1,['log'],['log']
Testability,"8c830940e83c315e7eaad6905a40aa ref_indexing.log; b580b9c6257254a018a9ae22291a64892c1a3715c69272637f5c504fc5545a70 reflengths.bin; 89679603ac0b28042275e5ff04b222bad3fd431cab573f0c2b61e7455aec43e7 refseq.bin; 46bf28001e00d491b68bf8758b99c1f304523c79bd94a97d7797888856594e84 seq.bin; 4c7e56ba28383774e786826099ef412761326fe18ce69f29033ad2886542985d versionInfo.json; `; Following are different.; `ctable.bin; info.json; mphf.bin; pos.bin; pre_indexing.log; ref_indexing.log; seq.bin; versionInfo.json`. I will try creating the vM25 index with increased memory. Wonder if its not building. Just FYI, my sha256sum on vM23 index is:; `9788716f4ce42b049fe7e865108f45392bb8a5847cfcd47369512783dc918239 complete_ref_lens.bin; 9c2453a47ce1808f54733f049b8c4cf38634c9116eb55ed725b73219caa101c5 ctable.bin; 928ba619dc5388ccab6d5c4f8ce162e07a5b5c79028be4aee4d838f43a3b9d92 ctg_offsets.bin; 0814d0e7dd8a4b126709c42728816995aefdf5a5bb6337c2d3c048cb0f56094d duplicate_clusters.tsv; dcbf8e140627b3c99d4dbcdaa585447a691fddb620f137811b669e73800f9b3b info.json; 5959abf5969a26481c6aa20fecbdddf19fa558e949cfbda5760205f38bb907b9 mphf.bin; 28460131b85c74ffb7627761a291614757e72b4e3b82971dcc048a50cc8d9e7f pos.bin; b5eb5e3fb0d03509d9fc90f6b5461c6aecc44423068f3303553cc07fffc7c1b9 pre_indexing.log; eca518136526233f3dc28d9684926793cb84327242d54c1a8a20c66aa1928fad rank.bin; a990247ba2b351fd0921de6470bf0c3505472d8f463e6f8b9ec7c221b6b56af8 refAccumLengths.bin; 436199afbb35045a70fdc7b9e542ef805b57170f41d6bc6a0ba4d88a8ca267fc ref_indexing.log; 65ce60d16b43f9e739cf68edb194daa63562c6d064a6e6bf441f612baec66983 reflengths.bin; 4f3fc9b3785f8cd0e1355e31d61df87226eb7e14e4438c0afc68706937df94a3 refseq.bin; 075122d399bd2c5cfd2e9e7405b2f2778c45178e9bf3a4a93f17750c808df7e0 seq.bin; 4c7e56ba28383774e786826099ef412761326fe18ce69f29033ad2886542985d versionInfo.json`. Summary: vM23 is working and I will proceed with it. In the meantime I will troubleshot vM25 as well as try your tarball. Thank you very much for your quick help. Hari",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/561#issuecomment-674527480:2493,log,log,2493,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/561#issuecomment-674527480,2,['log'],['log']
Testability,"9.107] [alevinLog] [warning] rrna file not provided; using is 1 less feature for whitelisting; [2019-01-29 09:55:59.107] [alevinLog] [info] Starting to make feature Matrix; [2019-01-29 09:55:59.115] [alevinLog] [info] Done making regular featues; [2019-01-29 09:55:59.115] [alevinLog] [info] Done making feature Matrix; [2019-01-29 09:55:59.123] [alevinLog] [info] Finished white listing; [2019-01-29 09:55:59.126] [alevinLog] [info] Finished optimizer; ``` . Concat fastq:; ```; salmon alevin -l ISR -1 big.fastq.1.gz -2 big.fastq.2.gz --chromium -i geneset.dir/geneset_coding_exons.salmon.index/ -o salmon.dir/ --tgMap transcript2geneMap.tsv --dumpCsvCounts; Version Info: ### PLEASE UPGRADE SALMON ###; ### A newer version of Salmon with important bug fixes and improvements is available. ####; ###; The newest version, available at https://github.com/COMBINE-lab/salmon/releases; contains new features, improvements, and bug fixes; please upgrade at your; earliest convenience.; ###; Logs will be written to salmon.dir/logs; ### alevin (dscRNA-seq quantification) v0.11.3; ### [ program ] => salmon ; ### [ command ] => alevin ; ### [ libType ] => { ISR }; ### [ mates1 ] => { big.fastq.1.gz }; ### [ mates2 ] => { big.fastq.2.gz }; ### [ chromium ] => { }; ### [ index ] => { geneset.dir/geneset_coding_exons.salmon.index/ }; ### [ output ] => { salmon.dir/ }; ### [ tgMap ] => { transcript2geneMap.tsv }; ### [ dumpCsvCounts ] => { }. [2019-01-29 09:56:37.731] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2019-01-29 09:56:37.749] [alevinLog] [info] Processing barcodes files (if Present) . ; processed 2 Million barcodes. [2019-01-29 09:56:43.029] [alevinLog] [info] Done barcode density calculation.; [2019-01-29 09:56:43.029] [alevinLog] [info] # Barcodes Used: 2695632 / 2712324.; [2019-01-29 09:56:52.900] [alevinLog] [info] Knee found left boundary at 692 ; [2019-01-29 09:56:53.219] [alevinLog] [info] Gauss Corrected Bounda",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/337#issuecomment-458481722:6351,Log,Logs,6351,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/337#issuecomment-458481722,1,['Log'],['Logs']
Testability,": /salmon-0.10.2/lib/libtbb.so.2; -- Installing: /salmon-0.10.2/lib/pkgconfig; -- Installing: /salmon-0.10.2/lib/libtbbmalloc_proxy.so.2; -- Installing: /salmon-0.10.2/bin/salmon; -- Installing: /salmon-0.10.2/lib/libsalmon_core.a. Installation complete. Please ensure the following paths are set properly.; ==========================================================================; Please add /salmon-0.10.2/bin to your PATH; Please add /salmon-0.10.2/lib to your LD_LIBRARY_PATH; ==========================================================================; root@e08cc9670e4a:/salmon-0.10.2/build# make test; Running tests...; Test project /salmon-0.10.2/build; Start 1: unit_tests; 1/3 Test #1: unit_tests ....................... Passed 0.17 sec; Start 2: salmon_read_test_fmd; 2/3 Test #2: salmon_read_test_fmd ............. Passed 1.78 sec; Start 3: salmon_read_test_quasi; 3/3 Test #3: salmon_read_test_quasi ........... Passed 1.59 sec. 100% tests passed, 0 tests failed out of 3. Total Test time (real) = 3.54 sec; root@e08cc9670e4a:/salmon-0.10.2/build# lsb_release -a; LSB Version: core-9.20160110ubuntu0.2-amd64:core-9.20160110ubuntu0.2-noarch:security-9.20160110ubuntu0.2-amd64:security-9.20160110ubuntu0.2-noarch; Distributor ID: Ubuntu; Description: Ubuntu 16.04.4 LTS; Release: 16.04; Codename: xenial; ```. I built with:. `$ cmake -DFETCH_BOOST=TRUE .. && make install && make test`. I can also install the boost via apt and see if that makes a difference (though I expect not since it looked like TBB was the issue, and I let cmake install that). We can also check our compiler versions, perhaps. I have : . ```; root@e08cc9670e4a:/salmon-0.10.2/build# g++ --version; g++ (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609; Copyright (C) 2015 Free Software Foundation, Inc.; This is free software; see the source for copying conditions. There is NO; warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. root@e08cc9670e4a:/salmon-0.10.2/build# gcc --version; gcc (U",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/250#issuecomment-404306268:2252,Test,Test,2252,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/250#issuecomment-404306268,1,['Test'],['Test']
Testability,"; ### [ output ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10001_D2B1WACXX }; ) = 594; stat(""/etc/localtime"", {st_mode=S_IFREG|0644, st_size=3519, ...}) = 0; stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10001_D2B1WACXX"", {st_mode=S_IFDIR|S_ISGID|0755, st_size=512, ...}) = 0; stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10001_D2B1WACXX"", {st_mode=S_IFDIR|S_ISGID|0755, st_size=512, ...}) = 0; stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10001_D2B1WACXX/logs"", 0x7fffffff1e50) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10001_D2B1WACXX/logs"", 0x7fffffff1e60) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10001_D2B1WACXX"", {st_mode=S_IFDIR|S_ISGID|0755, st_size=512, ...}) = 0; mkdir(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10001_D2B1WACXX/logs"", 0777) = 0; write(2, ""Logs will be written to "", 24Logs will be written to ) = 24; write(2, ""/dcl01/lieber/ajaffe/lab/libd_al""..., 81/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10001_D2B1WACXX/logs) = 81; write(2, ""\n"", 1; ) = 1; stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10001_D2B1WACXX/libParams"", 0x7fffffff1e50) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10001_D2B1WACXX/libParams"", 0x7fffffff1e60) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10001_D2B1WACXX"", {st_mode=S_IFDIR|S_ISGID|0755, st_size=512, ...}) = 0; mkdir(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10001_D2B1WACXX/libParams"", 0777) = 0; stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10001_D2B1WACXX/aux_info"", 0x7fffffff1e50) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:30734,log,logs,30734,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,2,"['Log', 'log']","['Logs', 'logs']"
Testability,"; ### [ output ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10002_C29P7ACXX }; ) = 594; stat(""/etc/localtime"", {st_mode=S_IFREG|0644, st_size=3519, ...}) = 0; stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10002_C29P7ACXX"", {st_mode=S_IFDIR|S_ISGID|0755, st_size=512, ...}) = 0; stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10002_C29P7ACXX"", {st_mode=S_IFDIR|S_ISGID|0755, st_size=512, ...}) = 0; stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10002_C29P7ACXX/logs"", 0x7fffffff1e50) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10002_C29P7ACXX/logs"", 0x7fffffff1e60) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10002_C29P7ACXX"", {st_mode=S_IFDIR|S_ISGID|0755, st_size=512, ...}) = 0; mkdir(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10002_C29P7ACXX/logs"", 0777) = 0; write(2, ""Logs will be written to "", 24Logs will be written to ) = 24; write(2, ""/dcl01/lieber/ajaffe/lab/libd_al""..., 81/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10002_C29P7ACXX/logs) = 81; write(2, ""\n"", 1; ) = 1; stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10002_C29P7ACXX/libParams"", 0x7fffffff1e50) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10002_C29P7ACXX/libParams"", 0x7fffffff1e60) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10002_C29P7ACXX"", {st_mode=S_IFDIR|S_ISGID|0755, st_size=512, ...}) = 0; mkdir(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10002_C29P7ACXX/libParams"", 0777) = 0; stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10002_C29P7ACXX/aux_info"", 0x7fffffff1e50) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:148411,log,logs,148411,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,2,"['Log', 'log']","['Logs', 'logs']"
Testability,"> Hi Brian,; > ; > In general, I would argue that one should be cautious with removing PCR duplicates in RNA-seq data (unless you are dealing with reads with UMI tags). This is because reads that align to the same reference position can easily have come from alternative transcripts sharing the same underlying sequence. Hence, the normal tests used to infer PCR duplicates with e.g. DNA-seq reads can yield false-positives in RNA-seq. This is particularly true for highly abundant transcripts (or transcripts from highly-abundant genes).; > ; > We are currently working on the code that will do duplicate removal when UMI tags are present. That methodology can be extended to remove duplicates even without UMI tags --- though I'd generally caution against that for the reasons mentioned above. However, for the time being, if you have a strong need or desire to filter PCR duplicates, you could use alignment-based Salmon with a BAM file that has duplicates removed.; > ; > Finally, regarding the error you are getting during SAM validation; this sounds like a different issue. Would you mind providing a piece of that SAM file for me to take a look at? Specifically, I don't believe the quasi-mapping output file should even contain unmapped reads (unless you consider unmapped mates of orphaned reads).; > ; > --Rob. It is in the latest Salmon release?. Thanks",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/136#issuecomment-446191570:339,test,tests,339,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/136#issuecomment-446191570,1,['test'],['tests']
Testability,"> Ok, when I attempt the build the way you say above, I get the following error during CMake:; > ; > ```; > -- fetch PUFFERFISH exit code 127; > CMake Error at CMakeLists.txt:317 (message):; > Could not fetch pufferfish source [fetchPufferfish.sh returned exit code; > 127]. Did you do the. ```; apt build-dep salmon; ```. step? I can't imagine that you get this problem if you follow my log step by step. Debian is usually using dynamic linking. By having all Build-Dependencies (which is ensured in the step above) the existence of the libraries is granted and the options for cmake I specified are ensuring that the libs are found. Kind regards, Andreas.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1464176548:388,log,log,388,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1464176548,1,['log'],['log']
Testability,"> Thanks!! Looking into it, replied. Hi,. I am having a similar issue when running salmon 1.4 on stranded single end data. Transcript count is over 4,000 for certain genes when analyzed by STAR, but salmon does not detect the transcript. Is there any newer version of this branch or suggested configuration that I can use to test my data? Thank you.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/218#issuecomment-1145373488:325,test,test,325,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/218#issuecomment-1145373488,1,['test'],['test']
Testability,> but I suspect the issue is also related to this log message. I wondered about that too but other samples gave me 2 and 3 degenerate classes and still passed...,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/229#issuecomment-393579057:50,log,log,50,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/229#issuecomment-393579057,1,['log'],['log']
Testability,"> thank you so much for your help today!. Sure, after all it is quite selfish ;-). I have been trying to generate smaller transcript db and fastq files but to no avail (can't make it fail again). However it looks like your test `if (denom <= ::minEQClassWeight)` could be not stringent enough:; invDenom:inf count:1 denom:2.77171e-321 minEQClassWeight:4.94066e-324; invDenom:inf count:1 denom:4.69042e-316 minEQClassWeight:4.94066e-324. These two lines result from:; groupSize: 2; i:0 tid:83966 aux:0.756044 expTheta[tid]:0; i:1 tid:83967 aux:0.243956 expTheta[tid]:7.23806e-321. groupSize: 2; i:0 tid:190925 aux:0.542131 expTheta[tid]:0; i:1 tid:272773 aux:0.457869 expTheta[tid]:6.2423e-316",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/229#issuecomment-393842202:223,test,test,223,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/229#issuecomment-393842202,1,['test'],['test']
Testability,"@GWW,. First, thanks for trying this out and for filing the report. We're eager to reproduce this, figure out what's going on, and fix it. It's theoretically possible to use something like [cgroups](http://man7.org/linux/man-pages/man7/cgroups.7.html) to limit the number of threads that the process could even allocate. However, it really should not be allocating more threads than are being given (+1 for the asynchronous logger thread). Can you please provide some details about the specific OS and version you're running on where you are seeing this behavior?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-395826503:424,log,logger,424,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-395826503,1,['log'],['logger']
Testability,"@Gaura So with the changes implemented, custom geometry is ~19% slower here than the hand-coded sci-seq3 protocol (improved from ~1/3 slower); is that correct? That's a nice improvement. @gmarcais — do you think it's worth testing out PCRE2? Most of these regexes are *very* short — and if boost is ~20% slower than PCRE2 and we are ~20% slower than the custom parsing code .... maybe that's the whole gap? Any idea how difficult this would be to try?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/734#issuecomment-1023346183:223,test,testing,223,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/734#issuecomment-1023346183,1,['test'],['testing']
Testability,@cljacobs : yes; great point. This has been [fixed in develop](https://github.com/COMBINE-lab/salmon/blob/develop/CMakeLists.txt#L1). It was an oversight due to our testing infrastructure already having a newer version of CMake that didn't run into this problem.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/453#issuecomment-557703985:165,test,testing,165,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/453#issuecomment-557703985,1,['test'],['testing']
Testability,"@ctb — One thing that would be required for this (apart from some engineering of the command-line parsing / validation code) is a trustworthy, efficient, _multithreaded_ `FAST(A/Q)` parser for interleaved format reads. Right now, Salmon (& Sailfish, &RapMap, & most of the other HTS-centric methods we're developing) use the Jellyfish 2 read parser. I've made this choice since it's fairly simple to use, yet provides nice parallel performance and, most importantly, is fairly well-tested and trust-worthy. Can you suggest a reliable, well-tested, concurrency-enabled library for parsing reads in interleaved format?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/29#issuecomment-152827801:482,test,tested,482,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/29#issuecomment-152827801,4,['test'],['tested']
Testability,"@deevdevil88,. Great! Please do let us know if you have any questions or run into any issues when testing it out :).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/538#issuecomment-825303038:98,test,testing,98,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/538#issuecomment-825303038,1,['test'],['testing']
Testability,"@ialbert,. Thanks again for the detailed bug report and reproducible example for this. We (@mohsenzakeri and I) have pushed experimental support for soft-clipping to the develop branch. You can enable this feature by passing `--softclip` flag to the `quant` command. We have also made a pre-compiled binary that includes this feature [here](https://drive.google.com/open?id=1Si1BqGXLievhol-e3RWjhxzajvVHY2mS). If you have a chance to test this on some of your data to see if the soft-clipping is working as expected in IGV on a larger scale (we tested on the data you provided), we'd be happy to have any feedback. In a future version, we will likely provide the ability to write the full CIGAR string (with mismatches, indels, etc.) out, but that requires the merging and testing of two branches of pufferfish upstream, and so will probably be reserved for a future release.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/475#issuecomment-596774053:434,test,test,434,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/475#issuecomment-596774053,6,['test'],"['test', 'tested', 'testing']"
Testability,"@k3yavi @rob-p ; Thank you for the prompt responses! I executed the following but seems to get no ""quant.sf"" as output (in fact no other output except for the log file). I don't find ""AlignmentLibrary"" object even though the log states that it did. Do you know what went wrong? Thank you!. Command:; ```bash; salmon quant -e ./aux_info/eq_classes.txt.gz --libType IU -o ./; ```. Output log:; [2020-09-18 20:01:55.879] [jointLog] [info] setting maxHashResizeThreads to 8; [2020-09-18 20:01:55.879] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2020-09-18 20:01:55.879] [jointLog] [info] numQuantThreads = 4; [2020-09-18 20:02:50.408] [jointLog] [warning] Missing effective lens for 47121 transcripts; setting to 100.0.; [2020-09-18 20:02:50.408] [jointLog] [warning] NOTE: Since effective lengths are not provided, please do not rely on the TPM field ; in the ouput quantifications. Only the NumReads field will be reliable.; [2020-09-18 20:02:50.410] [jointLog] [info] Found total 187671 eqclasses and 47121 transcripts; [2020-09-18 20:02:50.682] [jointLog] [info] Created AlignmentLibrary object. My Salmon version is v1.3.0.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/567#issuecomment-695157454:159,log,log,159,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/567#issuecomment-695157454,3,['log'],['log']
Testability,"@kikegoni this is something I started to work on but then quickly abandoned. I've uploaded the utility (`transcoorder`) that I started writing (https://github.com/mdshw5/transcoorder) for this purpose. If you find it useful and want to help finish the work please do. Currently the `transcoord` command will take a SAM/BAM, a GTF and matching genomic FASTA, and will convert reads from transcript to genomic coordinates, with appropriate reference names and offsets. However, it is not tested, and will only properly handle reads that fall entirely within an exon. Spliced reads shouldn't be too hard to add, but I just don't have the time right now. . ```; $ transcoord -h; usage: transcoord [-h] [-o OUT] [-t TAG_NAME] [--debug] [--version] gtf bam fasta. positional arguments:; gtf GTF file containing transcripts; bam SAM or BAM files aligned to transcriptome; fasta FASTA format assembly coresponding to GTF. optional arguments:; -h, --help show this help message and exit; -o OUT, --out OUT output file for genomic SAM (default: stdout); -t TAG_NAME, --tag-name TAG_NAME; SAM tag name for storing transcript identifier. default: ZT; --debug enable debugging; --version display version number; ```. The command is veeeeeery slow, but should process a typical RNAseq library in a few hours.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/193#issuecomment-736948709:486,test,tested,486,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/193#issuecomment-736948709,1,['test'],['tested']
Testability,@lananh-ngn . if it is direct RNA seq as you mentioned then would it make more sense to run `minimap2` as folow:; `minimap2 -ax splice -uf -k14 transcriptom.fa test.fastq > result.sam `. `-ax map-ont ` is for Oxford Nanopore genomic reads as stated in minimap2 github.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/786#issuecomment-1184344483:160,test,test,160,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/786#issuecomment-1184344483,1,['test'],['test']
Testability,"@macmanes — Heng's code is very well-tested, but afaik, completely serialized. Of course, that's nothing that we couldn't handle internally by throwing the reported reads into our concurrent queue. Actually, I think that the Jellyfish 2 parser (for a single `FAST(A/Q)` file) would be easy to make work in this context. The trick is to require that the read ""batches"" always end on an even-indexed boundary, so that we never have an (interleaved) read pair spit across batch boundaries. I'm not sure how easy or difficult that is to enforce. I might just ask Guillaume about the best way to enforce this.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/29#issuecomment-152828484:37,test,tested,37,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/29#issuecomment-152828484,1,['test'],['tested']
Testability,"@mohsenzakeri — if you have any insight here, I'd be interested to know your thoughts. Check out the following test from the ksw2 cli program (modified to output the contents of the `ksw_extz_t` structure:. *with extz*. ```; ./ksw2-test -s -t extz AGCAGAAGCGGGTATTGAGGAGCGTAAATTGTAGTTA TCGGGCATTACCGGATC; first second -48 max:0 max_t:-1 max_q:-1 mqe:-18 mte:-48 mqe_t:13 mte_q:16; ```. *with extz2sse*. ```; ./ksw2-test -s -t extz2_sse AGCAGAAGCGGGTATTGAGGAGCGTAAATTGTAGTTA TCGGGCATTACCGGATC; first second -48 max:0 max_t:-1 max_q:-1 mqe:-18 mte:-48 mqe_t:13 mte_q:3; ```. note, specifically, the differences in the `mte_q` field. Presumably, using the sse instructions should simply speed things up, not change the results! The strings here are taken from the actual strings for the test read. The first `AGCAGAAGCGGGTATTGAGGAGCGTAAATTGTAGTTA` is the buffer of the reference and the second `TCGGGCATTACCGGATC` is the bit of the read before the first MEM.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/475#issuecomment-574491993:111,test,test,111,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/475#issuecomment-574491993,8,['test'],['test']
Testability,"@rob-p . I did notice that the header was missing so I am looking into getting the original. I downloaded/unzipped the files you sent and seem to still have the same issue, though. ; ```; $ conda activate salmon; $ cd ~/opt/anaconda2/envs/salmon; $ ./bin/salmon quant -l IU -t transcripts.fa -a sample_alignments.sam -o quant_directory; Version Info: This is the most recent version of salmon.; # salmon (alignment-based) v1.2.0; # [ program ] => salmon ; # [ command ] => quant ; # [ libType ] => { IU }; # [ targets ] => { transcripts.fa }; # [ alignments ] => { sample_alignments.sam }; # [ output ] => { quant_directory }; Logs will be written to quant_directory/logs; [2020-04-21 11:46:41.365] [jointLog] [critical] Note: Alignment-free mapping (i.e. mapping without subsequent selective-alignment) has not yet been throughly tested under the pufferfish-based index and using the pufferfish-based mapping strategies. Thus, disabling of selective-alignment is not currently allowed. We may, potentially explore re-enabling this option in future versions of salmon. ```. To set up Salmon, I entered the following per the Getting Started Guide:; `$ conda config --add channels conda-forge`; `$ conda config --add channels bioconda`; `$ conda create -n salmon salmon`. Then, set the wd to `~opt/anaconda2/envs/salmon`. To run, I dropped the `transcripts.fa` and `seq.bam`/`seq.sam` file into the ~opt/anaconda2/envs/salmon and ran it. I noticed that if I moved the files to an entirely separate directory or deleted them all together and ran `./bin/salmon quant -l IU -t transcripts.fa -a sample_alignments.sam -o quant_directory`, the same error came up. Is it possible that there is an issue with Salmon reading the files?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/511#issuecomment-617263834:627,Log,Logs,627,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/511#issuecomment-617263834,3,"['Log', 'log', 'test']","['Logs', 'logs', 'tested']"
Testability,"@rob-p . That's odd! Well, what you sent above works perfect the sample files you provided earlier. I am still not able to process my own - perhaps because of the header issue?. ```; $ ./bin/salmon --no-version-check quant -l OSR -t sequence.fasta -a myseq.sam -o quant; # salmon (alignment-based) v1.2.0; # [ program ] => salmon ; # [ command ] => quant ; # [ libType ] => { OSR }; # [ targets ] => { sequence.fasta }; # [ alignments ] => { myseq.sam }; # [ output ] => { quant }. Logs will be written to auts2_quant/logs; [2020-04-21 18:36:46.762] [jointLog] [info] setting maxHashResizeThreads to 8; [2020-04-21 18:36:46.762] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; Library format { type:paired end, relative orientation:outward, strandedness:(antisense, sense) }; [2020-04-21 18:36:46.764] [jointLog] [info] numQuantThreads = 4; parseThreads = 4; Checking that provided alignment files have consistent headers . . . done; Populating targets from aln = ""myseq.sam"", fasta = ""sequence.fasta"" . . .done; Reference seq chr7 unknown; processed 0 reads in current roundSegmentation fault: 11; ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/511#issuecomment-617454680:482,Log,Logs,482,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/511#issuecomment-617454680,2,"['Log', 'log']","['Logs', 'logs']"
Testability,"@rob-p I think it's reasonable to support only ""accession.version"" since that seems common (it's used for ensemble at least), and allowing more user parameters means more work implementing, testing, fixing... I'm sure you don't need it, but I implemented something similar to allow a user to pass a custom ""key function"" in one of my python packages: https://github.com/mdshw5/pyfaidx#keyfn. I'm not sure how you would allow custom functions since you're using C++, and you might have to come up with an entire domain-specific language for this, but maybe something exists for this purpose...",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/122#issuecomment-282331518:190,test,testing,190,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/122#issuecomment-282331518,1,['test'],['testing']
Testability,"@rob-p There are other applications (e.g. RNA from extracellular vesicles, low input RNASeq) that use UMIs. I'm not sure this should be restricted just to the scRNA-seq case. I don't know how the models would differ for each use case. I don't have any firm thoughts on it at the moment, but happy to help test the different approaches.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/93#issuecomment-259998653:305,test,test,305,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/93#issuecomment-259998653,1,['test'],['test']
Testability,@rob-p alright! Thank you for the report! I will take note of it.; Congrats for passing the test!; Feel free to close this pull-request :),MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/276#issuecomment-416356167:92,test,test,92,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/276#issuecomment-416356167,1,['test'],['test']
Testability,"@rob-p thank you for the merging!. Okay, maybe when I want to send a pull-request, it looks better to `develop` branch in general. > However, since this is just relevant to a single file, I might cherry pick to master as well anyway ;P. I might see it on master branch too. How about below questions? Do you agree?. > * I want to replace current case gcc-7 to latest version gcc-8 if you like. > * There are commented out area at the bottom of .travis.yml. However as we can run git log -p .travis.yml to check past modification, shall we remove the commented out ""whitelist"" area?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/273#issuecomment-414358792:483,log,log,483,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/273#issuecomment-414358792,1,['log'],['log']
Testability,"@tdsone I _think_ this is the right logic: https://github.com/COMBINE-lab/salmon/blob/master/include/LibraryTypeDetector.hpp. . The main source of my confusion on this post was that I think Salmon just chucks back 'IU' for read numbers below 50k. It confused me less on realistic read numbers. I've simplified [quite a bit](https://github.com/nf-core/rnaseq/blob/bc6189f09954c0d00a71ac43b2ccf69ef22bbd82/subworkflows/local/utils_nfcore_rnaseq_pipeline/main.nf#L587) to just work with the strandedness component, using the numbers from lib_format_counts.json. It seems to produce results broadly as expected, but might be a bit naive, for example the numbers are mappings rather than fragments which could throw things off a bit.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/938#issuecomment-2175817517:36,log,logic,36,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/938#issuecomment-2175817517,2,['log'],['logic']
Testability,"@vals, it shouldn't be a coverage issue, at least as compared to previous versions of Salmon. Hopefully we'll have a chance to look at this soon and see if we can figure out what might be causing the performance ""regression"" when `--useVBOpt` is enabled. As @dcjones suggests, we haven't really seen any performance degradation with the VB option in our other testing, so I suspect something characteristic of this dataset. @dcjones; it's great to see you drop by! I'm actually looking for a reasonable collection of datasets to do (automated) regression testing on new releases of salmon --- something to replace my fairly simple and manual existing regression tests. I'd greatly appreciate any suggestions or advice you may have about this! Such tests will become even more useful as we're experimenting with a few inference approaches and it would be great to have a reasonable spread of data to see the effects of different strategies.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/6#issuecomment-112224408:360,test,testing,360,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/6#issuecomment-112224408,8,['test'],"['testing', 'tests']"
Testability,"@zhangchipku — here's a pre-compiled binary to test, in case you're unable to build a binary from develop on the target machine. [SalmonBeta-0.7.1-pre-aug20_linux_x86_64.tar.gz](https://github.com/COMBINE-lab/salmon/files/428673/SalmonBeta-0.7.1-pre-aug20_linux_x86_64.tar.gz)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/78#issuecomment-241237213:47,test,test,47,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/78#issuecomment-241237213,1,['test'],['test']
Testability,"A bit delayed, but this relates to the questions I've been asking on the salmon gitter. . First, it's worth pointing out that the new 10x (v2) sequencing is a lot more like other bead methods, where (i) index reads (i7/i5) are for labelling biological samples (ii) read1 contains the combined cell and molecular/UMI barcodes (ii) read2 is the transcript 3' read. So it seems there is now some data format convergence. Either way, I'd guess that ongoing iterations of the high throughput platforms will keep one read for the transcript 3', reserving the other 2 or 3 reads for some combination of the sample, cell and molecular barcodes. . Before thinking about how to best collapse UMIs, there's also the issue of how best to QC the barcodes and beads. Jim Namesh has [some functions](http://mccarrolllab.com/wp-content/uploads/2016/03/Drop-seqAlignmentCookbookv1.2Jan2016.pdf); as does [Vasilis Ntranos](https://github.com/pachterlab/scRNA-Seq-TCC-prep/blob/master/README.md). Arguably this has nothing to do with salmon/kallisto though I think the kallisto guys were smart to include it. It's a good filter even if only for speeding things up. Then it's really what might be the most appropriate demultiplexing of fastqs to allow compatibility between tecnhiques, I guess. I quite like how the kallisto workflow ends up with a fastq per cell together with a matching UMI file. Then at the very least one can ignore the UMIs (perhaps going with what @vals suggests). Not sure if that's helpful. But thought to chime in as somebody we would love to see salmon working on the high throughput single-cell platforms that have sample, cell and molecular barcodes. Even if only to test how worthwhile UMIs genuinely are for most applications. This may be a controversial comment, but I suspect for me UMIs will largely end up the same way as spike-ins: useful for quantifying endogenous RNA recovered per cell but perhaps not all that useful beyond that for low read depth single-cell signature profiling.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/93#issuecomment-265619589:1702,test,test,1702,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/93#issuecomment-265619589,1,['test'],['test']
Testability,A couple of more questions just to understand the problem since I double checked it's passing our unit tests. * Can you try `./salmon alevin --help` to check if the `--celseq2` is present in the help of the created binary ?; * Can you please share the command you are using to run alevin ?,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/325#issuecomment-443516685:103,test,tests,103,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/325#issuecomment-443516685,1,['test'],['tests']
Testability,A couple of question before you fix the pipeline to do this though: ; * In general what fraction of the CB does SoupX expects to have from 1-10 CB ?; * In our experience. a usual setup has <1% of the High confidence CB which alevin reports at the end. If you are keeping 10% of the CB then you already have >9% of the low quality stuff. I might have to read the SoupX paper again but I feel it's a lot of low quality data to begin with.; * Can you check what was the frequency of the last CB which was reported ? Because I do see; `Skipped 330862 barcodes due to No mapped read` in the log which mean even if there was >0 reads for the CB that doesn't map to the reference and alevin end up skipping it.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/379#issuecomment-503356703:586,log,log,586,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/379#issuecomment-503356703,1,['log'],['log']
Testability,A quick grep shows these as the only uses of `digamma` in the code:. ```; ../src/CollapsedEMOptimizer.cpp:117: double logNorm = boost::math::digamma(alphaSum);; ../src/CollapsedEMOptimizer.cpp:126: std::exp(boost::math::digamma(ap) - logNorm);; ../src/CollapsedEMOptimizer.cpp:257: double logNorm = boost::math::digamma(alphaSum);; ../src/CollapsedEMOptimizer.cpp:270: std::exp(boost::math::digamma(ap) - logNorm);; ```,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/229#issuecomment-393628182:118,log,logNorm,118,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/229#issuecomment-393628182,4,['log'],['logNorm']
Testability,"Absolutely! And thank you for your quick responses! Just trying to make an index from Homo_sapiens.GRCh38.cdna.all.fa.gz (ftp://ftp.ensembl.org/pub/release-95/fasta/homo_sapiens/cdna/Homo_sapiens.GRCh38.cdna.all.fa.gz) to use for a ENCODE fastq file (test file is https://www.encodeproject.org/files/ENCFF163DLM/@@download/ENCFF163DLM.fastq.gz). I'm working from a cluster computer in a salmon environment with biopython as the only other thing installed ; <img width=""750"" alt=""screen shot 2019-02-25 at 2 50 38 pm"" src=""https://user-images.githubusercontent.com/18176863/53374317-d1936780-390c-11e9-8370-51504ffb0996.png"">. Index is here: https://drive.google.com/file/d/1iKD-qfJKIViePE7Uu_1Wsp8z71oGipjN/view?usp=sharing",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/197#issuecomment-467217789:251,test,test,251,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/197#issuecomment-467217789,1,['test'],['test']
Testability,"Actually, homo sap long is causing this error, homo sap short is causing the related JSON error (`rapidjson internal assertion failure: IsObject()`)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/321#issuecomment-442612022:117,assert,assertion,117,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/321#issuecomment-442612022,1,['assert'],['assertion']
Testability,"All tests pass, hurray!; The solution was to uninstall `libtbb-dev`, which I have prior installed via `apt-get` (it was version 4.4, hence salmon installed a new version while `make`ing). So it seems there was a conflict between the tbb installed via apt-get and salmon itself.; Shall I close the issue or do you need any further info?; Thanks for the help in debugging ;)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/250#issuecomment-404546040:4,test,tests,4,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/250#issuecomment-404546040,1,['test'],['tests']
Testability,"Alright, I'll have a go at the simple model. @mikelove, once I have it implemented we can figure out a reasonable test. Actually, enabling the feature was _way_ easier than I thought. The actual bias application code (via re-estimation of effective lengths) can remain the same. I now have code-paths to build GC bias models treating single-end reads as equal to the _conditional_ mean fragment length (given the transcript). Let me know what you think would be a good way to test it.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/83#issuecomment-245366321:114,test,test,114,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/83#issuecomment-245366321,4,['test'],['test']
Testability,"Also I just observed, Is it true that you have ~167k genes in your transcript to gene mapping file? That might be one of the reason since the matrix size as shown in the log is `5344x167268` and given we have doubles as the type of matrix it might add up to ~7G and possibly giving `bad_alloc`.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/328#issuecomment-445013593:170,log,log,170,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/328#issuecomment-445013593,1,['log'],['log']
Testability,"Also getting segmentation fault. Any progress on this? This is salmon v1.3.0, installed with conda or using the binary, running in slurm. I do not get a segmentation fault if I pass only a single file, but I do if I pass two files. ```; $ ./src/salmon-latest_linux_x86_64/bin/salmon quant --threads $(nproc) --libType U -t GRCh38_latest_rna.fa -a data/processed/bwa-mem/SRR10571655.sam data/processed/bwa-mem/SRR10571656.sam -o _tmp/ ; Version Info Exception: server did not respond before timeout; # salmon (alignment-based) v1.3.0; # [ program ] => salmon ; # [ command ] => quant ; # [ threads ] => { 32 }; # [ libType ] => { U }; # [ targets ] => { GRCh38_latest_rna.fa }; # [ alignments ] => { data/processed/bwa-mem/SRR10571655.sam data/processed/bwa-mem/SRR10571656.sam }; # [ output ] => { _tmp/ }; Logs will be written to _tmp/logs; [2020-10-12 16:13:21.969] [jointLog] [info] setting maxHashResizeThreads to 32; [2020-10-12 16:13:21.969] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; Library format { type:single end, relative orientation:none, strandedness:unstranded }; [2020-10-12 16:13:21.969] [jointLog] [info] numQuantThreads = 26; parseThreads = 6; Checking that provided alignment files have consistent headers . . . done; Populating targets from aln = ""data/processed/bwa-mem/SRR10571655.sam"", fasta = ""GRCh38_latest_rna.fa"" . . .done; [2020-10-12 16:13:26.979] [jointLog] [info] replaced 5 non-ACGT nucleotides with random nucleotides. processed 103000000 reads in current round[1] 1994 segmentation fault (core dumped) ./src/salmon-latest_linux_x86_64/bin/salmon quant --threads $(nproc) --libTyp; ```. Always at 103000000 reads.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/271#issuecomment-707334655:807,Log,Logs,807,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/271#issuecomment-707334655,2,"['Log', 'log']","['Logs', 'logs']"
Testability,"Also, it's worth noting that the number you see in the interactive log is an artifact of the way the console refreshes in asynchronous logging. That is, salmon does not think it observed that many unique fragments. You can verify this, as the sum of the NumReads column in quant.sf is an upper bound on the total mapped fragments and thus the uniquely mapped fragments. The nymber of mapped fragments is also reported in aux_info/meta_info.json.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/368#issuecomment-498038220:67,log,log,67,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/368#issuecomment-498038220,2,['log'],"['log', 'logging']"
Testability,And any status updates? I'd be interested to test drive a quasi-mapping-based fusion caller!,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/52#issuecomment-280756041:45,test,test,45,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/52#issuecomment-280756041,1,['test'],['test']
Testability,And here's the log of the Salmon run that I got the backtrace from:. ```; Version Info: This is the most recent **development version** of Salmon.; ### salmon (mapping-based) v0.7.3; ### [ program ] => salmon; ### [ command ] => quant; ### [ index ] => { /home/ryan/references/hg38/Salmon_index_hg38.analysisSet_knownGene }; ### [ libType ] => { SR }; ### [ unmatedReads ] => { fastq_files/SRR2454069.fq.gz }; ### [ threads ] => { 8 }; ### [ seqBias ] => { }; ### [ gcBias ] => { }; ### [ useVBOpt ] => { }; ### [ dumpEq ] => { }; ### [ dumpEqWeights ] => { }; ### [ geneMap ] => { /home/ryan/references/hg38/Salmon_index_hg38.analysisSet_knownGene/genemap.txt }; ### [ output ] => { salmon_temp/REF/SRR2454069 }; ### [ auxDir ] => { aux_info }; ### [ numGibbsSamples ] => { 10 }; Logs will be written to salmon_temp/REF/SRR2454069/logs; [2016-12-15 15:58:50.157] [jointLog] [info] parsing read library format; [2016-12-15 15:58:50.157] [jointLog] [info] There is 1 library.; [2016-12-15 15:58:50.189] [jointLog] [info] Loading Quasi index; [2016-12-15 15:58:50.189] [jointLog] [info] Loading 32-bit quasi index; [2016-12-15 15:58:50.189] [stderrLog] [info] Loading Suffix Array; [2016-12-15 15:58:50.513] [stderrLog] [info] Loading Transcript Info; [2016-12-15 15:58:50.599] [stderrLog] [info] Loading Rank-Select Bit Array; [2016-12-15 15:58:50.661] [stderrLog] [info] There were 182608 set bits in the bit array; [2016-12-15 15:58:50.677] [stderrLog] [info] Computing transcript lengths; [2016-12-15 15:58:50.677] [stderrLog] [info] Waiting to finish loading hash; [2016-12-15 15:58:50.677] [stderrLog] [info] Done loading index; [2016-12-15 15:58:50.677] [jointLog] [info] done; [2016-12-15 15:58:50.677] [jointLog] [info] Index contained 182608 targets; [2016-12-15 15:58:51.587] [jointLog] [warning] Fragment GC bias correction is currently *experimental* in single-end libraries. Please use this option with caution. processed 16500000 fragments; hits: 44017772; hits per frag: 2.67057. [2016-1,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267489196:15,log,log,15,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267489196,3,"['Log', 'log']","['Logs', 'log', 'logs']"
Testability,"Apologies- I deleted my earlier comment because I realized you don't really need any alevin output from me. . I also can't seem to find actual barcode sequences on the Rosenberg data, the cells seem to just be indexed from 0-163068, which is not going to be helpful here. I assume you haven't heard back from the authors yet about the actual barcode sequences for these matrices? If not, I think I know of a few other published papers that we may be able to use as test cases instead",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-983984806:465,test,test,465,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-983984806,1,['test'],['test']
Testability,"Argghh --- that's gonna be a thinker. Can you try running it under GDB?. ```; $ gdb salmon; (gdb) r quant \; -i mouse_cdna_38.p3.78_repbase_ercc.fa \; -l IU \; -1 SRP057125_SRS936134_1.fastq \; -2 SRP057125_SRS936134_2.fastq \; -o SRP057125_SRS936134_salmon_out \; -g /nfs/research2/teichmann/reference/mus-musculus/salmon/mouse_cdna38.78_repbase_ercc_index_gene_map.txt \; --biasCorrect \; --useFSPD; ```. when it segfaults, you can issue the `bt` command to at least see where. If its still inside of JeMalloc, I can build another binary with just the standard allocator to see if the problem persists there (its strange that it depends on where the file is coming from! I don't have any NFS mounts either to test on).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/34#issuecomment-168428123:711,test,test,711,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/34#issuecomment-168428123,1,['test'],['test']
Testability,"Awesome! I have a slight preference for 0.6.0_1, since there's no real change to the _codebase_ from 0.6.0. Is it easy to test this against develop (can I tell it to pull from there)? I'd like to test that as well so that, hopefully, I can get 0.7.0 out the door and we can get it in homebrew science by Tues. when the students will be using it.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/70#issuecomment-239631598:122,test,test,122,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/70#issuecomment-239631598,2,['test'],['test']
Testability,"BTW I don't know if it could be related but `make test` gives me:; Running tests...; Test project salmon/build; Start 1: unit_tests; 1/3 Test #1: unit_tests .......................***Failed 0.02 sec; Start 2: salmon_read_test_fmd; 2/3 Test #2: salmon_read_test_fmd ............. Passed 1.74 sec; Start 3: salmon_read_test_quasi; 3/3 Test #3: salmon_read_test_quasi ........... Passed 1.62 sec. 67% tests passed, 1 tests failed out of 3. Total Test time (real) = 3.37 sec. The following tests FAILED:; 	 1 - unit_tests (Failed); Errors while running CTest; Makefile:151: recipe for target 'test' failed; make: *** [test] Error 8",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/229#issuecomment-393672412:50,test,test,50,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/229#issuecomment-393672412,12,"['Test', 'test']","['Test', 'test', 'tests']"
Testability,"Btw the same thing happens when using gencode transcriptome. ```bash; wget https://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_mouse/release_M25/gencode.vM25.transcripts.fa.gz; # better name; mv gencode.vM25.transcripts.fa.gz Mus_musculus_GENCODE_v25_GRCm38.fa.gz ; ````. ```; ./generateDecoyTranscriptome.sh \; -a /no_backup/genome_annots/Mus_musculus_ENSEMBL_v_102_GRCm38.gtf \; -g /no_backup/genome_seqs/Mmu10_gDNA.fasta \; -t /no_backup/transcriptome_seqs/Mus_musculus_GENCODE_v25_GRCm38.fa.gz \; -o /no_backup/indexes/salmon/gencode_mm10; ```. Which generates 2 files:; ```; ls -1 /no_backup/indexes/salmon/gencode_mm10; decoys.txt; gentrome.fa; ```. And then if I try to build an index with:. ```; salmon index \; -t /no_backup/indexes/salmon/gencode_mm10/gentrome.fa \; -i /no_backup/indexes/salmon/gencode_mm10 \; -d /no_backup/indexes/salmon/gencode_mm10/decoys.txt \; -k 28 --threads 8; ```. the job starts running but dies immediately for the same error:. ```; tail -n 4 /no_backup/indexes/salmon/gencode_mm10/ref_indexing.log . [warning] Removed 1612 transcripts that were sequence duplicates of indexed transcripts.; [puff::index::jointLog] [warning] If you wish to retain duplicate transcripts, please use the `--keepDuplicates` flag; [puff::index::jointLog] [critical] The decoy file contained the names of 55 decoy sequences, but 0 were matched by sequences in the reference file provided. To prevent unintentional errors downstream, please ensure that the decoy file exactly matches with the fasta file that is being indexed.; [puff::index::jointLog] [error] The fixFasta phase failed with exit code 1; ````. I do believe that the names in `decoys.txt` match some fasta headers in `gentrome.fa` as show here:. ```; head -n 1 decoys.txt; GL456210.1. zgrep ""GL456210.1"" gentrome.fa ; >GL456210.1; ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/731#issuecomment-1001151467:1034,log,log,1034,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/731#issuecomment-1001151467,1,['log'],['log']
Testability,Can you share the full log @tmms1 ?,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/739#issuecomment-1019516869:23,log,log,23,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/739#issuecomment-1019516869,1,['log'],['log']
Testability,"Confirmed with v0.6.0:. ```; Version Info: Could not resolve upgrade information in the alotted time.; Check for upgrades manually at https://combine-lab.github.io/salmon; # salmon (mapping-based) v0.6.0; # [ program ] => salmon; # [ command ] => quant; # [ index ] => { ... }; # [ libType ] => { IU }; # [ mates1 ] => { ... }; # [ mates2 ] => { ... }; # [ output ] => {... }; # [ threads ] => { 16 }; Logs will be written to ...; there is 1 lib; [2016-01-22 17:59:17.894] [jointLog] [info] parsing read library format; Loading 32-bit quasi index[2016-01-22 17:59:18.735] [stderrLog] [info] Loading Suffix Array; [2016-01-22 17:59:18.736] [stderrLog] [info] Loading Position Hash; [2016-01-22 17:59:18.731] [jointLog] [info] Loading Quasi index; [2016-01-22 18:00:59.879] [stderrLog] [info] Loading Transcript Info; [2016-01-22 18:01:25.157] [stderrLog] [info] Loading Rank-Select Bit Array; [2016-01-22 18:01:30.642] [stderrLog] [info] There were 552702 set bits in the bit a; [2016-01-22 18:01:31.487] [stderrLog] [info] Computing transcript lengths; [2016-01-22 18:01:31.491] [stderrLog] [info] Waiting to finish loading hash; Index contained 552702 targets; [2016-01-22 18:04:43.717] [jointLog] [info] done; [2016-01-22 18:04:43.717] [stderrLog] [info] Done loading index; ```. I'll check the index creation logs, but didn't notice anything out of the ordinary...",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/37#issuecomment-174082911:402,Log,Logs,402,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/37#issuecomment-174082911,2,"['Log', 'log']","['Logs', 'logs']"
Testability,"Corner cases are hard to catch. The drop-seq dataset I was probing was from 2-3 years ago and it appeared very noisy. When I tried Alevin with a morden 10x V2 dataset there was no issue at all. ; Anyway, thank you for the quick fix. I tested it and it worked well.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/374#issuecomment-502230996:235,test,tested,235,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/374#issuecomment-502230996,1,['test'],['tested']
Testability,"Could you please share one of the output directories? It's not immediately obvious what the problem might be, since the log ends with . ```; [2020-06-03 23:47:15.955] [jointLog] [info] Computing gene-level abundance estimates; ```. which suggests the function to aggregate abundances to the gene level should be activated. On a related note, though we are definitely interesting in figuring out what might being going awry here, the recommended way to aggregate transcript-level abundances from salmon to the gene level is to use [tximport](https://bioconductor.org/packages/release/bioc/html/tximport.html), as it accounts for across-sample variability in expressed gene length, and makes it trivial to get your corresponding gene counts into a downstream DE tool like DESeq2, EdgeR, etc.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/530#issuecomment-638453196:120,log,log,120,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/530#issuecomment-638453196,1,['log'],['log']
Testability,"Dear @callumparr,. Thank you for bringing this up. So you are correct that the `--noLengthCorrection` flag should be passed to salmon when quantifying data that does not have a ""fragmentation effect"", that is, where the number of fragments we expect to draw from a transcript is not dependent upon the length of that transcript. In the ONT protocols, it is usually the case that we get 1 read -> 1 transcript, even if we don't read the whole thing. We have tested the effect of this in ONT data with spike ins, and have verified that using `--noLengthCorrection` does generally lead to improved accuracy with respect to quantification estimates. We have informed ONT of this, and I would guess they may optimize the flags that are used soon (we have also developed an error model that works correctly for these long reads, and that should make it into the next release of salmon). Regarding the effect this has on the `NumReads` values reported by salmon, it's not as simple as with the `TPM` estimates. The length affects the assigned reads through the probabilistic model on which inference is done. With the length effect we have that P(f | t_i) ∝ P( position | f, t_i ) * P( alignment | f, t_i) --- forgetting the alignment term for the time being, we have that with length correction P( position | f, t_i ) ∝ 1 / l_i and without length correction the l_i term goes away. In other words, the probability of allocating reads has a term that depends on the effective length when the `--noLengthCorrection` flag is not passed, but that term goes away when it is passed. This is not quite as drastic as with TPM where the normalization includes the length directly in the normalization (note, however, that when the `--noLengthCorrection` flag is passed, this adjusts the TPM as well). Further, the `NumReads` is still better than TPM in this regard because it still encodes the effect size (i.e. `NumReads` will sum to the total number of aligned reads). Anyway TLDR: Passing the `--noLengthCorrectio",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/651#issuecomment-821995147:457,test,tested,457,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/651#issuecomment-821995147,2,['test'],['tested']
Testability,"Dear Rob,; a brief update:; 1) with the flag -DNO_IPO=TRUE the compilation worked perfectly. thank you . 2)following a guide found at stackoverlow ([Find which assembly instruction caused an Illegal Instruction error without debugging], I discover that the illegal instruction is **vfmsubsd**. ; I am not an expert at all in the field, but googling it seems to be a standard SSE instruction.; I am surprised indeed.; cpus tested: ; Intel Xeon Gold 5220 (72) ; Intel Xeon Gold 5317 (48); Intel i7-10750H (12). Best and thanks again; Silvano. Program terminated with signal SIGILL, Illegal instruction.; #0 0x00007fa222c47396 in __ieee754_pow_fma4 () from /dataraw/mouse/salmon-1.8.0_linux_x86_64/bin/../lib/libm.so.6. 0x7fa222c47396 <__ieee754_pow_fma4+182> vfmsubsd %xmm3,%xmm6,%xmm3,%xmm7",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/783#issuecomment-1145687835:422,test,tested,422,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/783#issuecomment-1145687835,2,['test'],['tested']
Testability,"Dear all. Thank you for your prompt reply. ; @mikelove yes, the CPM is only cross-sample normalisation, but not cross genes. TPM is both cross-sample and cross-gene normalisation. Thus, in my mind, TPM is more suitable for downstream RNA-seq analysis, including clustering analysis, differential expression testing using Wilcoxon rank-sum test. Also, for accurately detecting differentially expressed genes, is it reasonable to overlap the results from different methods, such as edgeR+Wilcoxon rank-sum test?. Best regards,; Zheng zhuqing",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/812#issuecomment-1324468833:307,test,testing,307,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/812#issuecomment-1324468833,3,['test'],"['test', 'testing']"
Testability,"Does it make sense to have '^' and/or '$' around the regex? Having anchors usually speeds up a regex. Otherwise, I am not sure. Have we tested other libraries than boost::regexp?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/734#issuecomment-1013343046:136,test,tested,136,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/734#issuecomment-1013343046,1,['test'],['tested']
Testability,"Excellent! Now we should do some internal testing to see if this has any negative performance impact on machines that _do_ have SSE4. Then we can determine if we can just make this the default, or if it's worth cutting a release under 2 configurations.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/500#issuecomment-610602162:42,test,testing,42,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/500#issuecomment-610602162,1,['test'],['testing']
Testability,"FInally, it took like 25 hours, I am attaching the log. ; [salmon_quant.log](https://github.com/COMBINE-lab/salmon/files/4706992/salmon_quant.log)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/527#issuecomment-636410253:51,log,log,51,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/527#issuecomment-636410253,3,['log'],['log']
Testability,"FYI - for the sample in question, there are **9,974** ""filtered"" barcodes and **737,280** ""raw"" barcodes (from CellRanger). If I take the larger list of ""raw"" barcodes and I remove the ""-1"" from each of them, then that is what I am currently testing for Alevin.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/682#issuecomment-878607734:242,test,testing,242,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/682#issuecomment-878607734,1,['test'],['testing']
Testability,"Following are some weird thing I am noticing in your log:. ```; 2019-11-02T16:23:27.745502492Z [2019-11-02 16:23:27.745] [puff::index::jointLog] [warning] The decoy name JH584303.1 was encountered more than once --- please be sure all decoy names and sequences are unique.; 2019-11-02T16:23:27.745504753Z [2019-11-02 16:23:27.745] [puff::index::jointLog] [warning] The decoy name JH584304.1 was encountered more than once --- please be sure all decoy names and sequences are unique.; 2019-11-02T16:24:33.408457659Z [2019-11-02 16:24:33.408] [puff::index::jointLog] [warning] The decoy file contained the names of 88 decoy sequences, but 66 were matched by sequences in the reference file provided.; ```; Where we expect only 66 decoys (genomic targets) to start with. I think it's the issue with the gencode reference names having blank space as a delimiter in its target name with repeated names. The ipython notebook was right but I missed to update the static website, in the prepare metadata section I have updated the decoy name extracting step to:. ```; grep ""^>"" <(zcat GRCm38.primary_assembly.genome.fa.gz) | cut -d "" "" -f 1 > decoys.txt; ```. That is I splitting the genomic target names by space and taking just the first part as the target name. I working on checking what's happening if I follow the step of using the full gencode names and would update you.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/441#issuecomment-549146224:53,log,log,53,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/441#issuecomment-549146224,1,['log'],['log']
Testability,"For clarification: From memory, using the same cluster, I had the same error at the same stage but only with particular data sets and confirmed this was not an issue of available memory. @k3yavi may remember some more of the details but we never got to the bottom of it. . @Acribbs Testing on another cluster would be a good idea in case this is a very specific cluster configuration issue",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/337#issuecomment-458160685:282,Test,Testing,282,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/337#issuecomment-458160685,1,['Test'],['Testing']
Testability,Forgot the file...; [test.fa.gz](https://github.com/COMBINE-lab/salmon/files/2057739/test.fa.gz),MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/228#issuecomment-393482330:21,test,test,21,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/228#issuecomment-393482330,2,['test'],['test']
Testability,"GAGCACGC_lane-004-chunk-002.fastq.gz; ./fastq/fastqs/flowcell1/read-I1_si-TTCGTGAA_lane-001-chunk-001.fastq.gz; ./fastq/fastqs/flowcell1/read-I1_si-TTCGTGAA_lane-002-chunk-000.fastq.gz; ./fastq/fastqs/flowcell1/read-I1_si-TTCGTGAA_lane-003-chunk-003.fastq.gz; ./fastq/fastqs/flowcell1/read-I1_si-TTCGTGAA_lane-004-chunk-002.fastq.gz]; Version Info: This is the most recent version of salmon.; [2018-12-06 11:14:56.513] [alevinLog] [info] A custom protocol (END, BC length, UMI length) = (5, 14, 5) is being used. Updating UMI k-mer length accordingly.; Logs will be written to ./fastq/test/logs; [2018-12-06 11:14:56.533] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; ### alevin (dscRNA-seq quantification) v0.12.0; ### [ program ] => salmon ; ### [ command ] => alevin ; ### [ libType ] => { ISR }; ### [ gemcode ] => { }; ### [ index ] => { ./transcripts_index_salmon/ }; ### [ threads ] => { 8 }; ### [ output ] => { ./fastq/test/ }; ### [ tgMap ] => { ./hg_transcriptome/tx2tx.tsv }; ### [ end ] => { 5 }; ### [ umiLength ] => { 5 }; ### [ barcodeLength ] => { 14 }; ### [ dumpCsvCounts ] => { }; ### [ mates1 ] => { /tmp/tmp.p28w2nGvAn/p1.fa }; ### [ mates2 ] => { /tmp/tmp.p28w2nGvAn/p2.fa }; ### [ unmatedReads ] => { ./fastq/fastqs/flowcell1/read-I1_si-ACTTCACT_lane-001-chunk-001.fastq.gz ./fastq/fastqs/flowcell1/read-I1_si-ACTTCACT_lane-002-chunk-000.fastq.gz ./fastq/fastqs/flowcell1/read-I1_si-ACTTCACT_lane-003-chunk-003.fastq.gz ./fastq/fastqs/flowcell1/read-I1_si-ACTTCACT_lane-004-chunk-002.fastq.gz ./fastq/fastqs/flowcell1/read-I1_si-CGAAGTTG_lane-001-chunk-001.fastq.gz ./fastq/fastqs/flowcell1/read-I1_si-CGAAGTTG_lane-002-chunk-000.fastq.gz ./fastq/fastqs/flowcell1/read-I1_si-CGAAGTTG_lane-003-chunk-003.fastq.gz ./fastq/fastqs/flowcell1/read-I1_si-CGAAGTTG_lane-004-chunk-002.fastq.gz ./fastq/fastqs/flowcell1/read-I1_si-GAGCACGC_lane-001-chunk-001.fastq.gz ./fastq/fastqs/flowcell1/read-I1_si-GAGCACGC_lane-002-chu",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/328#issuecomment-445008548:2588,test,test,2588,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/328#issuecomment-445008548,1,['test'],['test']
Testability,"Good to hear, I checked the release log but I wasn't able to confirm whether I was using the bugged conda build since we are using docker biocontainers (build v1.9.0--h7e5ed60_1). I'll upgrade our pipeline and close the issue after a new run of the same data if the problem seems to be resolved. Best,; Alex",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/876#issuecomment-1739857661:36,log,log,36,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/876#issuecomment-1739857661,1,['log'],['log']
Testability,"Got it working. The ""short"" form for how to do so in Centos 6.9 is:. ```; 1. install current versions of autoconf, automake, and cmake; 2. install the boost 1.57 set of RPMS if they are not already present; 3. install devtoolset-4 (or higher); 4. download and unpack salmon; 5. modify CMakeLists.txt; #around line 220, remove condition testing, set it to just; set (Boost_USE_STATIC_LIBS OFF); #around line 310; set(Boost_ADDITIONAL_VERSIONS ""1.57.0"" ""1.59.0"" ""1.60.0"" ""1.61.0"" ""1.62"" ""1.63"" ""1.64"" ""1.65"" ""1.66""); find_package(Boost 1.57.0 COMPONENTS iostreams filesystem system thread timer chrono program_options); 6. in top level of salmon do; mkdir build; cd build; nice scl enable devtoolset-4 '~/bin/cmake -DBoost_DEBUG=ON -DCMAKE_VERBOSE_MAKEFILE:BOOL=ON -DBoost_NO_BOOST_CMAKE=BOOL:ON -DBOOST_LIBRARYDIR=/usr/lib64/boost157 -DBOOST_INCLUDEDIR=/usr/include/boost157 ../CMakeLists.txt' >try_cmake2.log 2>&1 &; 7. in top level of salmon do; nice scl enable devtoolset-4 'make' >build_2018_06_13a.log 2>&1 &; There will be lots of warnings but it should run to completion; 8. make install; cp bin/salmon $WHEREVER/bin/salmon; rmdir lib/pkgconfig; cp lib/* $WHEREVER/lib; rm -rf bin; rm -rf lib; export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$WHEREVER/lib; make test; ```. Is it OK to delete the (large) salmon directory at this point, or is the binary hardwired to find things in it?; I know that this does not work:. ```; cd ..; mv salmon not_salmon; cd not_salmon; make test; ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/236#issuecomment-397050436:336,test,testing,336,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/236#issuecomment-397050436,5,"['log', 'test']","['log', 'test', 'testing']"
Testability,"Got it, thanks for the heads up. I'd probably reach out to the refgenie people about the hg38 specific versions. It makes sense to have the feature of having the gtf at the time of indexing. The only concern I have is that mandating to have the gtf might restrict the overall workflow by a bit. Specifically because a user might not always have the full GTF available for every use case, although we can always make having GTF as an optional requirement for indexing. Adding the support should not be too difficult but it will certainly add a new logic path which would need thorough testing. . We'll certainly keep you updated with the feature as we progress although it can take some time to get back. In terms of your pipeline one option would be to actually save the GTF explicitly in the salmon index folder post indexing. Although it's definitely not a very computer science friendly solution but it will help maintain the consistency while we work on the feature.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/595#issuecomment-738200842:547,log,logic,547,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/595#issuecomment-738200842,2,"['log', 'test']","['logic', 'testing']"
Testability,"Great suggestion, thanks @rob-p and @gmarcais . Somehow, I missed it. I added it in the latest commit. Speed now from 3 runs:; ```; real 1m19.884s 1m15.891s 1m21.462s ; user 8m9.189s 9m1.100s 9m48.764s ; sys 0m5.079s 0m5.170s 0m3.477s; ```; 50% improvement over the past results, i.e., about 33% slower than specific protocol flag now. Although, ideally I should have ran the earlier tests thrice but the sd is small so results should be valid. Nonetheless, I'll do more speed tests with versions in the future. . Let me know what other thoughts you have and what else have I missed. I have some minor improvements in mind too.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/734#issuecomment-1013326966:384,test,tests,384,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/734#issuecomment-1013326966,2,['test'],['tests']
Testability,"Great! One thing I found is that if I `INSTALL` the unitTests like I've been doing, they fail to find the appropriate libraries (again if they were fetched). I pushed a fix for this in develop. Basically, you just have to copy, not install, the unit test executable. That's done with the following incantation:. ```; add_custom_command(TARGET unitTests POST_BUILD; COMMAND ${CMAKE_COMMAND} -E copy $<TARGET_FILE:unitTests> ${GAT_SOURCE_DIR}/tests/$<TARGET_FILE_NAME:unitTests>; COMMENT ""Copying unitTests""; ); ```. I don't know if this is necessary for homebrew or not, since it has no effect on the salmon binary itself.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/70#issuecomment-239632810:250,test,test,250,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/70#issuecomment-239632810,2,['test'],"['test', 'tests']"
Testability,"Great; hopefully I'll be able to repro the issue with the other sample. No rush, as I'll be finishing putting together the final for my class tomorrow morning (and so will be testing the sample between writing exam questions ;P). I just hope this doesn't turn out to be an environment / machine-specific behavior (those are *the worst* bugs to track down and fix).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-266948036:175,test,testing,175,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-266948036,1,['test'],['testing']
Testability,"Great; this will test against develop, right? Not master. Because 0.7.0 is coming from develop.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/70#issuecomment-239628911:17,test,test,17,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/70#issuecomment-239628911,1,['test'],['test']
Testability,"Great; would you like help testing the pipeline, and integrating it into bcbio? We could help with both :)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/52#issuecomment-255123178:27,test,testing,27,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/52#issuecomment-255123178,1,['test'],['testing']
Testability,"HI @gianfilippo ,; I think #245 might help understanding the problem better.; Specifically to answer your questions, I am guessing `737K-august-2016.txt` is all the set of Cellular Barcodes(CB) being whitelisted by 10xGenomics protocol while in Alevin when you are giving external whitelist it assumes that the user is pretty confident about the presence of *all* the given CBs in their experiment. for example if you want to compare Alevin and cellranger apple to apple then you might have to give the `barcodes.tsv`(usually is present along with the `mtx` file) generated by the cellranger. (after removing `-1` from the CB names). ; `[alevinLog] [error] Barcode not found in frequency table`: This error means some of the CB given externally through the whitelist command seems to have no reads at all which violates the above assumption, you can potentially skip this error by using `--debug` flag with alevin (only if have version v0.11.3) but this mode has is yet to be extensively tested.; In case where you don't externally give whitelist CB, Alevin uses knee and KDE based method to identify the cutoff on the knee (and later correct for it) of the CB distribution. Based on your specific dataset it is possible that the method might be overshooting and aggressively identifying less number of clusters. If you can share the log and some part of your data then we can take a look what's going on. Hope this helps.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/284#issuecomment-417964393:988,test,tested,988,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/284#issuecomment-417964393,2,"['log', 'test']","['log', 'tested']"
Testability,"Happy to compare notes! For benchmarking accuracy I'm mostly using data from SEQC. There are four reference samples, each sequenced quite deeply at several different labs. I took 20 lanes from BGI, which is about 100 million reads, which I compare it to TaqMan (~800 genes), PrimePCR on (~18000 genes), and ERCC spike-ins. . On top of that, to get more directly at isoform-level accuracy, I'm simulating data using rlsim, which I've found to be the least awful RNA-Seq simulator. Unlike most simulators, it models some technical effects/bias. I think it underestimates these, but still a lot better than most that assume perfect uniform random sampling, etc. I also have a set of benchmarks designed to get at the question of consistency or stability of estimates, which is one of the main thrusts of the paper I'm working on. The other aspect I've been fretting about a lot the last month has been just what metric to use. You should check out this paper if you haven't seen it, which is pretty eye-opening as to the problems with using correlation on compositional gene expression data. > Lovell, D., Pawlowsky-Glahn, V., Egozcue, J. J., Marguerat, S., & Bähler, J. (2015). Proportionality: a valid alternative to correlation for relative data. PLoS Computational Biology, 11(3), e1004075. http://doi.org/10.1371/journal.pcbi.1004075. Those problems aren't unique to correlation. E.g. the ""median relative difference"" approach taken by the Kallisto paper is very much affected by this, I think even more so than correlation. The method I've adopted is to use the ""proportionality correlation"" they propose on page 9, and add 0.1 TPM to expression values to account for zeros and tiny values. It's not terribly sensitive to the additive constant and gives pretty reliable results in my experience. I have a somewhat horrifying labyrinth of makefiles and julia code that runs all this which I'll probably make public on github in the next few weeks, which may or may not be helpful.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/6#issuecomment-112291922:28,benchmark,benchmarking,28,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/6#issuecomment-112291922,2,['benchmark'],"['benchmarking', 'benchmarks']"
Testability,"Hello @k3yavi and thank you for the pointer,. I obtained the same bug with v.0.12.0 (also Compiled from source). Here's the console log :. ```; ~/software/salmon/scripts/v1_10x/run.sh ~/software/salmon-0.12.0/bin/salmon alevin -l ISR -b ./fastq/fastqs/flowcell1/ --gemcode -i ./transcripts_index_salmon/ -p 8 -o ./fastq/test/ --tgMap ./hg_transcriptome/tx2tx.tsv --end 5 --umiLength 5 --barcodeLength 14 --dumpCsvCounts. TEMPDIR is /tmp/tmp.p28w2nGvAn; Running command [/home/ebecht/software/salmon-0.12.0/bin/salmon alevin -l ISR --gemcode -i ./transcripts_index_salmon/ -p 8 -o ./fastq/test/ --tgMap ./hg_transcriptome/tx2tx.tsv --end 5 --umiLength 5 --barcodeLength 14 --dumpCsvCounts -1 /tmp/tmp.p28w2nGvAn/p1.fa -2 /tmp/tmp.p28w2nGvAn/p2.fa -r ./fastq/fastqs/flowcell1/read-I1_si-ACTTCACT_lane-001-chunk-001.fastq.gz; ./fastq/fastqs/flowcell1/read-I1_si-ACTTCACT_lane-002-chunk-000.fastq.gz; ./fastq/fastqs/flowcell1/read-I1_si-ACTTCACT_lane-003-chunk-003.fastq.gz; ./fastq/fastqs/flowcell1/read-I1_si-ACTTCACT_lane-004-chunk-002.fastq.gz; ./fastq/fastqs/flowcell1/read-I1_si-CGAAGTTG_lane-001-chunk-001.fastq.gz; ./fastq/fastqs/flowcell1/read-I1_si-CGAAGTTG_lane-002-chunk-000.fastq.gz; ./fastq/fastqs/flowcell1/read-I1_si-CGAAGTTG_lane-003-chunk-003.fastq.gz; ./fastq/fastqs/flowcell1/read-I1_si-CGAAGTTG_lane-004-chunk-002.fastq.gz; ./fastq/fastqs/flowcell1/read-I1_si-GAGCACGC_lane-001-chunk-001.fastq.gz; ./fastq/fastqs/flowcell1/read-I1_si-GAGCACGC_lane-002-chunk-000.fastq.gz; ./fastq/fastqs/flowcell1/read-I1_si-GAGCACGC_lane-003-chunk-003.fastq.gz; ./fastq/fastqs/flowcell1/read-I1_si-GAGCACGC_lane-004-chunk-002.fastq.gz; ./fastq/fastqs/flowcell1/read-I1_si-TTCGTGAA_lane-001-chunk-001.fastq.gz; ./fastq/fastqs/flowcell1/read-I1_si-TTCGTGAA_lane-002-chunk-000.fastq.gz; ./fastq/fastqs/flowcell1/read-I1_si-TTCGTGAA_lane-003-chunk-003.fastq.gz; ./fastq/fastqs/flowcell1/read-I1_si-TTCGTGAA_lane-004-chunk-002.fastq.gz]; Version Info: This is the most recent version of salmon.; [2018-12-",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/328#issuecomment-445008548:132,log,log,132,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/328#issuecomment-445008548,3,"['log', 'test']","['log', 'test']"
Testability,"Hello Avi,. Here is my out put log. Thank you in advance for an help you can provide. [2019-07-29 15:58:39.034] [jointLog] [info] Fragment incompatibility prior; below threshold. Incompatible fragments will be ignored.; [2019-07-29 15:58:39.034] [jointLog] [info] Usage of --validateMappings; implies use of minScoreFraction. Since not explicitly specified, it is; being set to 0.65; [2019-07-29 15:58:39.034] [jointLog] [info] Usage of --validateMappings,; without --hardFilter implies use of range factorization.; rangeFactorizationBins is being set to 4; [2019-07-29 15:58:39.034] [jointLog] [info] Usage of --validateMappings; implies a default consensus slack of 0.2. Setting consensusSlack to 0.2.; [2019-07-29 15:58:39.034] [jointLog] [info] parsing read library format; [2019-07-29 15:58:39.034] [jointLog] [error] Failed to successfully parse; any complete read libraries. Please make sure you provided arguments; properly to -1, -2 (for paired-end libraries) or -r (for single-end; libraries), and that the library format option (-l) *comes before* the read; libraries. Best,. Sara. On Mon, Jul 29, 2019 at 3:25 PM Avi Srivastava <notifications@github.com>; wrote:. > You passed paired-end files; > to salmon, but you passed 12 files to --mates1 and 13 files to --mates2.; > You must pass the same number of files to both flags; >; > Is this true ? Can you share the log ?; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/COMBINE-lab/salmon/issues/408?email_source=notifications&email_token=AEHDXAH7HQIR4ZVWMTE2KXLQB5U5LA5CNFSM4IGU4ZTKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOD3CF3JY#issuecomment-516185511>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AEHDXAG7WI3B7QBMJOSXTATQB5U5LANCNFSM4IGU4ZTA>; > .; >. -- ; Sara E. Boles, MS; PhD Candidate | Whitehead Lab; Pharmacology and Toxicology Graduate Group; Department of Environmental Toxicology; Univer",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/408#issuecomment-516194201:31,log,log,31,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/408#issuecomment-516194201,1,['log'],['log']
Testability,Here is the duplicate clusters (extension edited for uploading as .txt) and log. ; [quasi_index.log](https://github.com/COMBINE-lab/salmon/files/2474978/quasi_index.log). [duplicate_clusters (copy).txt](https://github.com/COMBINE-lab/salmon/files/2474977/duplicate_clusters.copy.txt),MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/301#issuecomment-429502243:76,log,log,76,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/301#issuecomment-429502243,3,['log'],['log']
Testability,"Here is the part of the log I've left out previously; <img width=""978"" alt=""Screen Shot 2019-11-03 at 8 41 57 PM"" src=""https://user-images.githubusercontent.com/17168657/68090974-860d6200-fe7a-11e9-972f-d529453bbea8.png"">. I've downloaded Linux executables on 11/02/ from the following link: https://github.com/COMBINE-lab/salmon/releases/download/v1.0.0/salmon-1.0.0_linux_x86_64.tar.gz. Decoys and gentrome files seem to be ok since they are working properly with bioconda version of salmon. I am sharing a Dockerfile in case you would like to reproduce the entire environment I was using. [Dockerfile](https://github.com/COMBINE-lab/salmon/files/3802055/Dockerfile)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/441#issuecomment-549171596:24,log,log,24,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/441#issuecomment-549171596,1,['log'],['log']
Testability,"Hey @Gaura - I have a test dataset for us to use. I'm about to set up an alevin run of my own, but wanted to pass it on to you in the meantime. I haven't yet done any testing or exploration of my own yet, though the data comes from a collaborator of ours. The raw (FASTQ) and processed data (UMI counts matrix) is accessible from GEO at [GSE137941](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE137941) and SRA (`fastq-dump --split-files SRR10174292`). These data were generated with the original SPLiT-seq method (your ""v1""). The caveat is that they did NOT combine the oligo-dT and random hexamer barcodes, meaning they are separate cells/columns in their processed data matrix. This means we should be able to run `alevin`/`alevin-fry` directly on these FASTQs, bypassing `splitp` for now, and get something that hopefully matches their processed data matrix. . According to the methods section [of their paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7366517/), they used GENCODE v28 annotations, and ultimately kept 6,888 nuclei after filtering. Their processed data matrix seems to have 25,000 columns, so I suppose this is pre-filtering. . Let me know what you think!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-984646381:22,test,test,22,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-984646381,2,['test'],"['test', 'testing']"
Testability,"Hey @alexvpickering ,; I agree, it does makes sense to index the transcript and gene relationship while creating the salmon indexing but I don't see how it solves this problem i.e. if the idea is to ignore the transcripts which doesn't having transcript to gene mapping then it may bias the analysis as we are considering lesser number of transcripts than known; having said that an argument about unknown splice junction can still be made. regarding the link for `gencode_29`, may I ask what version of salmon you are using ? Because I just tried to run alevin with the links you forwarded and it works fine for me. If possible forwarding the log will help too.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/336#issuecomment-496246321:644,log,log,644,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/336#issuecomment-496246321,1,['log'],['log']
Testability,"Hey @jeremymsimon! I checked the protocol and the [pipeline code](https://github.com/yjzhang/split-seq-pipeline/blob/master/split_seq/tools.py). The protocol you described is v1 and the Parsebio is v2. I have implemented v2 in salmon and would be testing it this week. v1 can be similarly implemented. I read the paper and other available resources but I am not clear about the random hexamer usage and it's effects on the barcode. Can you please explain what you meant by BC1s being paired and what's the use of random hexamer, please? Thanks.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-936331597:247,test,testing,247,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-936331597,2,['test'],['testing']
Testability,"Hey @k3yavi . The data is from a public dataset hosted on the 10x genomics website:. [200 Sorted Cells from Human Glioblastoma Multiforme, 3’ LT v3.1](https://support.10xgenomics.com/single-cell-gene-expression/datasets/6.0.0/Brain_Tumor_3p_LT). I downloaded the data and subsampled the FASTQ files to 1,000 reads. It was an arbitary choice, I just needed a small dataset to test a pipeline I was building.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/647#issuecomment-821522673:375,test,test,375,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/647#issuecomment-821522673,1,['test'],['test']
Testability,"Hey @k3yavi, bootstrapping really improved my population studies so I figured I would try it with sc, but I haven't even seen the run get there when I use the multiple files... after `processed X Million barcodes` there are no more logs produced on-screen..",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/329#issuecomment-446185405:232,log,logs,232,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/329#issuecomment-446185405,1,['log'],['logs']
Testability,"Hey @k3yavi,; salmon version is 0.13.1. I don't have the logs at the moment as I am trying the ensembl-based solution suggested by @sarahhcarl using Homo_sapiens.GRCh38.94.chr_patch_hapl_scaff.gtf.gz and equivalent ensembl version for cdna index. After doing so I will reproduce the issue and add the log file here. What about instead of filtering the index based on txp2gene, having some way of padding missing transcripts in txp2gene (e.g. just mapping from the indexes ENST to the same ENST)? I don't understand the algorithm enough to know the best solution - this just seems like an internal detail that the end user should not have to resolve/abandon alevin as a result of. A seperate issue for the [tutorial](https://combine-lab.github.io/alevin-tutorial/2018/setting-up-resources/) that doesn't apply to the accompanying [gist](https://gist.github.com/k3yavi/c501705ed2d29b12b0d10cf78b3ed001): the index is generated using gencode.**v28**.pc_transcripts.fa.gz and the txp2gene.tsv is generated using gencode.**v26**.primary_assembly.annotation.gtf. Perhaps I generated the txp2gene.tsv incorrectly? The bioawk instructions from the tutorial had to be altered (I'm guessing because of version differences). ```bash; bioawk --version; awk version 20110810. # command from tutorial; bioawk -c gff '$feature==""transcript"" {print $group}' <(gunzip -c gencode.v29.annotation.gtf.gz) | awk -F ' ' '{print substr($4,2,length($4)-3) ""\t"" substr($2,2,length($2)-3)}' - > txp2gene.tsv. bioawk: illegal field $(), name ""group""; input record number 7, file /dev/fd/63; source line number 1. # how I modified it; bioawk -c gff '$feature==""transcript"" {print $attribute}' <(gunzip -c gencode.v29.annotation.gtf.gz) | awk -F ' ' '{print substr($4,2,length($4)-3) ""\t"" substr($2,2,length($2)-3)}' - > txp2gene.tsv. cat txp2gene.tsv | head -n 5; ENST00000456328.2 ENSG00000223972.5; ENST00000450305.2 ENSG00000223972.5; ENST00000488147.1 ENSG00000227232.5; ENST00000619216.1 ENSG00000278267.1; ENST00000473358.1",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/336#issuecomment-496251814:57,log,logs,57,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/336#issuecomment-496251814,2,['log'],"['log', 'logs']"
Testability,"Hey @rob-p ,; I know virtually nothing about this, but I've been having somewhat related discussions lately with @mourisl about their method TRUST4 (https://github.com/liulab-dfci/TRUST4). Li seemingly has interest in helping out with this, and coincidentally is the developer of chromap too in case support for ATACseq is also coming soon!. I'll let you both take it from here and looking forward to testing!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/861#issuecomment-1642867731:401,test,testing,401,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/861#issuecomment-1642867731,1,['test'],['testing']
Testability,"Hey @rob-p, you are quite welcome; thanks for the warm response. Being system installed packages most headers and dynamic libraries will be installed using the standard prefixes: /usr/include, /usr/lib/${multiarch-tuple}/, . I've updated the checklist [above](https://github.com/COMBINE-lab/salmon/issues/19#issue-109233280) with links to the file lists so you can see the paths yourself. Interestingly I was able to build, run, and pass all the included tests using the version of BWA in the Debian archive. As for Jellyfish I had to update our package to include 'json.h' which had gotten dropped.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/19#issuecomment-144914246:455,test,tests,455,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/19#issuecomment-144914246,1,['test'],['tests']
Testability,"Hey Rob,. I did manage to test v1.3 this evening. Ran much faster. The same sample that took about 6 hours ran in 45mins. Still not great, but I think it might be intrinsic to some of these samples, also I was running it off my laptop and was running Linux off a; flash drive so not an ideal setup. Either way much more reasonable. Do you want me to attach any logs or anything?. Best,. Ryan . Sent from my iPhone. On Jun 16, 2020, at 10:20 AM, Rob Patro <notifications@github.com> wrote:. ﻿. Hi ; @shalercr,; I agree that if each sample runs as quickly as you see here, it's not a big deal to just re-run them all. Note that, while my avoids ~116 times more (eventually-discarded) alignments than did yours, the difference in the number of discarded; fragments (i.e. fragments that had no mapping) is very small — ~7,000, or 0.023% of the fragments. Thus, despite the huge speed-up, I wouldn't expect many differences in the quantifications. However, I couldn't argue against re-quantifying everything; with the new version just for good measure :). When you have a chance, please do let me know if you see this same performance difference using the pre-compiled (linux) binary. here. Of course, once we finalize this release (soon), we will push to bioconda so we will also have OSX binaries available. However, I just want to make sure this fixes things on your end as well before the release.; —; You are receiving this because you were mentioned.; Reply to this email directly, ; view it on GitHub, or ; unsubscribe.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/537#issuecomment-645119801:26,test,test,26,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/537#issuecomment-645119801,2,"['log', 'test']","['logs', 'test']"
Testability,"Hey Rob, . Sorry for the delay, here is a link to the quants folder if you guys are still interested. Everything worked well, especially with the additional flag. Any idea on the timeline for the bioconda release?. Best, . Ryan . https://www.dropbox.com/sh/rmy4f6brxx5iczo/AACxbyZFxN0XGcP3YRGjGO-pa?dl=0 . On Jun 18, 2020, at 12:21 AM, Ryan, Shaler <shalercr@mcmaster.ca> wrote:. Thanks for the heads up. I gave it a test this evening and wow, it is wicked fast. I’ll send you those quant files tomorrow when I get a chance, but adding that flag and the new version fixed the problem. . Thank you for all your help. . Best,. Ryan . Sent from my iPhone. On Jun 16, 2020, at 11:36 PM, Rob Patro <notifications@github.com> wrote:. ﻿. P.S. ; @shalercr,; I also note that layering --hitFilterPolicy BOTH on top of the new version cuts down the time by another factor of 2 for me; 2163.65user 12.72system 4:21.57elapsed 832%CPU (0avgtext+0avgdata 1221856maxresident)k. and the number of mappings discarded alignments due to score comes down by another factor of ~6X. It might be worth seeing what you get with that option as well.; —; You are receiving this because you were mentioned.; Reply to this email directly, ; view it on GitHub, or ; unsubscribe.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/537#issuecomment-647273636:417,test,test,417,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/537#issuecomment-647273636,1,['test'],['test']
Testability,"Hey Rob. It looks like this was an error in the way I was calling `salmon index`. I've wrapped salmon in a python based pipeline where I manage creation of index files using configuration files. To call `salmon index` I was previously iterating on standard error, capturing your err and logging it after reformatting a bit. It looks like what was happening is:. 1. I opened a subprocess and executed salmon; 2. Salmon worked properly; 3. Salmon stopped producing output on stderr (and sent an EOF marker?) and so my script exited; - killing salmon prematurely; - truncating the salmon index (In a way that salmon found perfectly acceptable during `salmon quant`; - frustrating me quite a bit. I fixed this by doing the right thing and blocking for the process to return an exit code:. ```diff; p = Popen(cmd, stderr=PIPE); - for line in p.stderr:; - line = line.decode(); - if line.endswith('\n'):; - logging.info(line.rstrip()); - else:; - logging.info(line); + _, err = p.communicate(); + logging.info(err); ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/132#issuecomment-303738589:287,log,logging,287,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/132#issuecomment-303738589,4,['log'],['logging']
Testability,"Hi :). `wget` war already installed (to download the sources in the first place, so this one works). ; After `wget`ing the source files again re-`cmake`-ing them again `make install` did work, not sure what happened there in the first place. Also the tests are passing now. I will try to figure out what is different between the clean docker version and my system setup and will report back as soon as I know more.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/250#issuecomment-404536671:251,test,tests,251,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/250#issuecomment-404536671,1,['test'],['tests']
Testability,"Hi @ACastanza,. Thanks for reporting both of these. For the first, I think it is just the case that the message needs to be updated. In fact, the `--validateMappings` flag is now deprecated since selective-alignment is used by default (and can't be turned off, except in the single-cell mapping context, with the `--sketchMode` flag, which is currently only in the develop branch). We'll update that message.; Regarding the misplaced newline, the issue is that the other messages are written by the logger, which is asynchronous. So, sometimes it will get to the appropriate place and write a newline before the fragment counter starts, and sometimes it won't. I'll look into if there is a way to better clear the line, even if the update is asynchronous. Thanks!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/587#issuecomment-729044670:499,log,logger,499,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/587#issuecomment-729044670,2,['log'],['logger']
Testability,"Hi @Beatzekatze,. The issue with test 1 seems to be from CMake being unable to find the unit test to execute under certain configurations. I'll consider this a bug in the CMake file, and look into fixing it. The failure of tests 2 and 3 is more interesting, as one would definitely not expect this given that the program compiled without error. Does indexing fail only with `--type fmd`, or also with `--type quasi` (or no `--type` as that is the default)? Would it be possible to run the command under gdb and report the stack trace? That would be something like:. ```; $ gdb --args salmon index -t transcripts.fasta -i sample_salmon_fmd_index --type fmd; ```. and then, when you encounter the segfault issuing the back-trace `bt` command. This would give insight into where, exactly this is showing up. One issue I've seen before is when the resident installation of Boost is _not_ compiled with `--std=c++11` (or 14 or 17), since this leads to an incompatible ABI between salmon and the Boost library. If that's what's going on, it should be evident from the backtrace. Finally, while I'd want to figure out what's going on with this build from source, it would also be useful to know if you encounter the same behavior when installing via bioconda. Thanks for the detailed report!. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/250#issuecomment-404223014:33,test,test,33,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/250#issuecomment-404223014,3,['test'],"['test', 'tests']"
Testability,"Hi @ChelseaCHENX ,. Thanks for raising the issue.; I think if you can share the alevin log (say for 1192 cells ?) we can comment much more about the details. However, if you ask me to guess then I believe the initial whitelisting of alevin seems to be predicting a lot less cells, if you check the alevin log, it would say what % of CB are thrown due to noisy cellular barcodes. If the number is `>20%`, then the chances are indeed ""knee"" estimates are shooting up. The way to get better estimates from there would be to help alevin with a ballpark number of cells (as you are giving to cellranger with --expect-cell 8000, you can provide alevin with --expectCells 8000). Even after that if you get a lot of noisy CB prediction then you can force alevin to use certain number of cells with `--forceCells` option. https://github.com/COMBINE-lab/salmon/issues/362 this issue might help you understand more the details of the pipeline.; Hope it helps !",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/396#issuecomment-510540540:87,log,log,87,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/396#issuecomment-510540540,2,['log'],['log']
Testability,"Hi @Davidwei7,. Thank you for the very detailed bug report! So, I have two initial responses / thoughts about your issue. First, you asked if the issue may be related to a memory allocation error wherein the index didn't build successfully. This is quite possible (and the error you see during quantification is consistent with that). The *full* decoy index is substantially larger than the index on just the transcriptome (after all, it is indexing the entire human genome in addition to the transcriptome). One thing you might try to test this hypothesis, other than requesting to build on a node with more RAM, is to compute a hash (e.g. md5 or sha256 sum) on all of the files in the index, and also record their sizes. Then we can build the index on the same version of the files on our end and compare. Second — and perhaps more importantly for your end goal — the main purpose of the decoy-aware index is to improve specificity rather than sensitivity. That is, the decoys are designed to help avoid _spurious_ mapping of reads to an annotated transcript when a better explanation for the read exists elsewhere in the genome. However, the reads that are mapped to decoys are not otherwise used for quantification. Thus, using the decoy aware transcriptome index is unlikely to improve your mapping rate. I agree that your mapping rate does seem rather low. There are a few potential culprits here, and some diagnostics we can look at to see what might be going wrong. First, you can take a look at the file `aux_info/meta_info.json` in the salmon quantification directories to get a few more details about why reads were not mapped. If you share one of those files here I can describe the relevant fields. Also, I have two more rather common things to consider that might affect the mapping rate. One is to add the sequence for the ribosomal RNAs to your transcriptome before indexing and then quantifying. If your mapping rate increases considerably, this is evidence of rather inefficient depl",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/603#issuecomment-744162850:536,test,test,536,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/603#issuecomment-744162850,1,['test'],['test']
Testability,"Hi @DobbyLikesPenguins,. ### conda idea. So, if you want to try with conda again, I would first recommend that you create a new environment for salmon. ```; conda create --name salmon; ```. which you can then activate with . ```; conda activate salmon; ```. From this environment, you should be able to install the latest version. ```; conda install salmon; ```. or specifying version explicitly like . ```; conda install salmon=1.4.0; ```. ### using the pre-compiled executable. The simplest thing would be to simply add it to your PATH. Assuming you are using bash or a similar shell, you can do something like:. ```; export PATH=<path_to_salmon_directory>/bin:$PATH; ```. to add salmon to your path. It should choose this version when you use `salmon`. However, this will be reset when you logout. To make the change permanent, then you add this command to your bash profile (usually `~/.bash_profile`). It's a little bit different (but very similar) if you are using a different shell. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/483#issuecomment-775273715:793,log,logout,793,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/483#issuecomment-775273715,2,['log'],['logout']
Testability,"Hi @Gaura :; ```shell; ./; ├── alevin_out; │   ├── alevin; │   │   └── alevin.log; │   ├── aux_info; │   │   └── meta_info.json; │   ├── cmd_info.json; │   ├── libParams; │   ├── logs; │   │   └── salmon_quant.log; │   ├── map.rad; │   └── unmapped_bc_count.bin; ├── count; │   ├── alevin; │   │   ├── quants_mat_cols.txt; │   │   ├── quants_mat.mtx; │   │   └── quants_mat_rows.txt; │   ├── featureDump.txt; │   └── quant.json; └── permit_knee_out; ├── all_freq.bin; ├── collate.json; ├── generate_permit_list.json; ├── map.collated.rad; ├── permit_freq.bin; ├── permit_map.bin; └── unmapped_bc_count_collated.bin; ```; I follow the output of the tutorial, it seems that there is no file `alevin_out/alevin/raw_cb_frequency.txt`, it may be that the parameter --dumpFeatures is not added during runtime, I add the --dumpFeatures parameter to try",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/774#issuecomment-1126137203:78,log,log,78,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/774#issuecomment-1126137203,3,['log'],"['log', 'logs']"
Testability,"Hi @Hoohm ,; Thanks for the feature request.; Currently `Alevin` do have a hidden feature, where you can explicitly specify the CB and UMI length. Although we have not yet extensively tested these options but in your settings you might have to specify the following command line argument:; ```; --barcodeLength 7 --umiLength 9 --end 5; ```; Please let us know how it works out for you in these settings, it will help validate these options for `Alevin`. PS: Just a quick question for my understanding, is there a specific reason you chose to use the length of the UMI longer than CB in your experiment ?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/247#issuecomment-402349013:184,test,tested,184,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/247#issuecomment-402349013,1,['test'],['tested']
Testability,"Hi @Kisekya,. So BWA-MEM and BWA-MEM2 are somewhat of a problem to begin with because they perform local alignment, which isn't really ideal for aligning RNA-seq reads to the transcriptome. If you really wish to use an aligner, we've had good experiences with Bowtie2 (when used in the appropriate end-to-end alignment mode) and with STAR (using the alignments projected to the transcriptome with `--quantMode TranscriptomeSAM` flag to output the alignments in transcriptomic coordinates as required by salmon). Apart from the local alignment issue, sorting the BAM file is _absolutely_ a problem for salmon, and is likely why you get the strange library type. When run in alignment mode, just like RSEM, salmon requires the alignments for the the mates of a read pair to appear subsequently in the file, and for all alignments for a given read to appear contiguously in the file. This allows parsing the reads without having to require potentially unbounded memory (holding the record for one end of a fragment in memory while waiting for the record for the other end). In fact, given that you've sorted the alignments here, I'm surprised you're not getting the ""suspicious pair"" warnings in your logs. The ISR library with 40% mapping is likely a more reliable number. The obvious question here is why might the mapping rate be this low? There are a few reasons you might see something like this. One, for example, is poor ribosomal depletion, paired with not having all of the rRNA sequences in your index. In this case, you have many fewer reads coming from the rest of the transcriptome and you get depleted mapping rates like this. . Could you say a bit more about the experimental setup? Is this in a well-annotated organism like human / mouse etc.? Is this a polyA selection or ribosomal depletion prep? Anything else that might be relevant to sample quality?. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/676#issuecomment-873519594:1198,log,logs,1198,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/676#issuecomment-873519594,1,['log'],['logs']
Testability,"Hi @Munfred , ; Thanks again for testing Alevin with your dataset. Extrapolating from the log, It indeed looks like a challenging dataset. In default settings Alevin pipeline starts with finding a knee in the curve (which itself is a non-trivial problem) and then use KDE w/ gaussian correction to adjust for the right probability. In your case it looks like knee is overshooting (if true number of CB is 300 ) but more troubling part for me is gaussian correction is coming out 0. Now based on your motivation for using Alevin, I can propose two solutions:. 1. If the motivation is to get gene-level count without worrying about the whitelisted CB prediction then the easiest way is to use external whitelist. Alevin can use external whitelist using flag `--whitelist` and would generate gene level counts for specified list of CB.; 2. If you need full end-to-end run of Alevin, then I propose using command line flag `--dumpFeatures` along with Alevin default. This flag tells Alevin to dump various features, the important one here would be a file named `frequency.txt`, what this file basically tells you is the frequency of all the observed CB in a order. From there we can manually select a knee in the frequency curve and use that as a whitelist. In terms of improving the task for improving the knee selection in Alevin, if you can share the `frequency.txt` file then I can look into what's causing the issue for gaussian correction or the knee selection itself. Thanks again for your interest !",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/245#issuecomment-402547744:33,test,testing,33,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/245#issuecomment-402547744,2,"['log', 'test']","['log', 'testing']"
Testability,"Hi @OnlyHigh,. Indeed, the _default_ behavior of salmon is to de-duplicate transcripts (to avoid that behavior and allow salmon to index duplicate transcripts, you need to pass the `--keepDuplicates` flag to the indexer). When it does this, it will log the duplicate transcripts in the index. If you look in the directory containing the salmon index, you will find a file called `duplicate_clusters.tsv`. This is a 2 column TSV file with a row for each transcript that was collapsed during indexing. The first column says which retained transcript was identical to the collapsed transcript. We do not write down the specific sequence of these transcripts, but with the original fasta file on which the index was built, you can easily extract this. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/299#issuecomment-428612513:249,log,log,249,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/299#issuecomment-428612513,1,['log'],['log']
Testability,"Hi @PeteHaitch ,; I have just pushed a potentially testable version in Alevin for cel-seq2 ( activated by `--celseq` command line flag ), although to make it work the develop branch has to compiled from source.; A couple of points to note:; * I assumed the the length of both CB and UMI to be 6 as in the original cel-seq2 paper.; * The deduplication algorithm is still same as default and nothing has been changed in the part. Please let us know how it works out for you and if at all it's useful / comparable to the output generated by the traditional cel-seq2 pipeline.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/269#issuecomment-418570247:51,test,testable,51,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/269#issuecomment-418570247,1,['test'],['testable']
Testability,"Hi @PlantDr430,. Thanks for the detailed report. I'll provjde a detailed explanation of the bootstrap variance later when I'm at my computer. However, regarding the gibbs issue with the log file not being properly populated; you still get the appropriate gibbs samples as output, right? The issue is just with writing the log? We'll check into what might be causing this.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/466#issuecomment-568768688:186,log,log,186,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/466#issuecomment-568768688,2,['log'],['log']
Testability,"Hi @Ryan-Zhu ,. Thanks a lot for bringing this to our attention.; We have fixed this in the latest commit of the develop branch https://github.com/COMBINE-lab/salmon/commit/e93d6cee19c46d56d603e75097dbe17ab18e6811 and will merge in the next release . Usually the number of skipped Barcodes due to no mapped reads are relatively few that's why this corner case slipped from our testing. If it's possible for you to compile salmon from source you can use the develop branch to generate the new binary otherwise let us know we can provide a temporary linux binary until the next release.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/374#issuecomment-501943370:377,test,testing,377,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/374#issuecomment-501943370,1,['test'],['testing']
Testability,"Hi @Ryan-Zhu ,; Can you please share the logs ?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/374#issuecomment-501681776:41,log,logs,41,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/374#issuecomment-501681776,1,['log'],['logs']
Testability,"Hi @alexg9010 ,. A apologize profusely for dropping the ball on this. Would it be possible to test with the latest release of salmon? I am still not able to reproduce this behavior on any of our test machines.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/210#issuecomment-395199735:94,test,test,94,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/210#issuecomment-395199735,2,['test'],['test']
Testability,"Hi @alexmascension ,. Thanks for confirming. I'll paste my response, I sent you earlier, here too. In case it's helpful to some other user. > Hi Alex,. >Thanks again for forwarding the data. I think I have the solution for the problems you are facing in alevin. >Your first question was related to alevin quantifying very less number of reads. To answer that,; if you look at the log, at the first few lines, alevin warns about ~91% of the reads being thrown away because; of the noisy CBs. The problem is alevin’s first “knee"" estimation is overshooting in predicting the first boundary. You will find https://github.com/COMBINE-lab/salmon/issues/362 issue to be; very useful in understanding that. As a summary if you look at the plot I attached it has bi-modalities,; which is generally not the case and alevin is greedily finding the threshold at the first ~100 cells. If this; happens the general direction is to help alevin by proving a upper bound, in case of your data; would be ~14000 cells. You can tell alevin with `—expectCells 14000` and alevin start to work; normally and logs ~12% of the data is noisy. >You second question was a little complicated to answer. Seemingly, your salmon index has transcript with; same exact name `ENST00000399966.9`, occurring twice with different sequences. Just by looking at the index,; I am unsure it’s actually present in the reference or its salmon indexing messing up. If I Assume it was actually; present two times in the reference, alevin should report it instead of exiting abruptly in the middle of quantification.; Although, alevin does warns:; ```; [2019-07-04 14:12:32.519] [alevinLog] [warning] Found 1 transcripts with duplicate names; ```; >However, the bug i.e. not being able to distinguish duplicate names of the transcript, has been ; fixed and pushed in the develop branch of salmon. Alevin was reporting the error at the stage of quantification too, ; if you dump the logs in a file, but it was invisible in the console as it was ove",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/386#issuecomment-508754845:380,log,log,380,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/386#issuecomment-508754845,2,['log'],['log']
Testability,"Hi @alexmascension ,. Thanks for raising this.; Quick question thought, the issue header say : ; > Out of Range error for txp to gene Map. But I don't see that error in the log, did you skip copying that ?; Also, I should have raised this in the previous issue too but it should not matter at least in this error case, however, you should use `-lISR` instead of `-lU` with alevin as the reads are expected to come from the reverse strand. It seems a lot of reads `91.1983%` are supposedly getting thrown away, weren't you using the whitelisted CB instead of ""knee"" thresholding ?; If possible, can you share a small set of reads, like these `even some of them fail just when starting the analysis of the cells`, on which I can replicate the issue? it'd help resolve the issue much faster.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/386#issuecomment-504952404:173,log,log,173,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/386#issuecomment-504952404,1,['log'],['log']
Testability,"Hi @alexvpickering ,. Thanks for raising the issue. It seems #377 and #379 are connected .; Alevin is in fact suppose to output whitelist.txt file when provided with the flags you provided.; I think what's happening in your case is since `--keepCBFraction 1`, alevin is using all the CB for quantification and it couldn't find (any or very low) CB from the low confidence region needed for the whitelisting. ; Basically in the above screenshot, alevin never finished. It should have failed more gracefully, I'll make sure of that in the next release. In the meantime you can use the exit code 0 or ""Finished Optimizer"" log for successful finish. Also, try playing with the lower values for the `keepCBFracion` may be around (0.4 / 0.5) and `--freqThreshold` for changing the minimum frequency of a CB to consider, currently set to 10. You can also follow https://github.com/COMBINE-lab/salmon/issues/362 for more details.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/379#issuecomment-502818453:619,log,log,619,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/379#issuecomment-502818453,1,['log'],['log']
Testability,"Hi @apeltzer ,. Thanks for this info. I've fixed the issues related to the bwa files in the develop branch. I tested things out using an Alpine Linux docker image to re-create your environment. Unfortunately, there seems to be a bigger issue for building from source on Alpine Linux that is actually far beyond the scope of Salmon itself. Apparently, Alpine linux uses [musl])(https://www.musl-libc.org/), a non-standard libc replacement that is missing some of the calls used by [Intel's TBB](http://forum.alpinelinux.org/forum/general-discussion/compilation-tbb). I imagine this would affect quite a bit of scientific software on this distribution. I currently haven't found a work-around, but let me know if you're aware of anything. In the mean time, does the pre-compiled binary (or the docker image) work for you?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/162#issuecomment-345752365:110,test,tested,110,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/162#issuecomment-345752365,1,['test'],['tested']
Testability,"Hi @asher1234,. Thanks for the detailed bug report. The detection of the library type as `MU` certainly does raise some flags as that is not something that would be expected. Moreover, in the v0.12.0 log you posted, we see messages like:. ```; Thread saw mini-batch with a maximum of 90.16% zero probability fragments; ```. Which means that e.g. ~90% of the fragments, even though they map, are being assigned a 0 probability under the model (because of e.g. incompatibility with the library type). Would you be able to share one of these samples and the reference transcriptome against which you are quantifying? Also, do things look any different if you force the library type to be something more common (e.g. `-l IU`)?. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/346#issuecomment-469108517:200,log,log,200,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/346#issuecomment-469108517,1,['log'],['log']
Testability,"Hi @asher1234,. Thanks. I'll try and grab the data now. The 0.12.0 log here is quite informative. It looks like the problem is that none of the reads are making through the likelihood filter, which explains why you see the output you do. I'll take a look and see if there is a clear reason why. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/346#issuecomment-469412869:67,log,log,67,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/346#issuecomment-469412869,2,['log'],['log']
Testability,"Hi @astrdhr,. Ok, so the difference between the version you get on the command line, versus the version you get when you actually attempt to run your script to process your data, is certainly a point of concern. In general, the behavior you are seeing during runtime seems like it may be an artifact of not having a compatible index. Is it possible for you to do a ""test run"" outside of the Nextflow script? Since you are getting v1.10.2 locally, and this version should work without segmentation fault, that would at least let us narrow the issue down to different versions of salmon being invoked at different stages of the pipeline. At that point, it may be a Nextflow / nf-core issue, but those folks are *great* and will be able to help in a jiffy!. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/881#issuecomment-1766508995:366,test,test,366,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/881#issuecomment-1766508995,1,['test'],['test']
Testability,"Hi @biobenkj,. Congratulations on publishing your new single-cell technology, and thanks for your interest in adding support to alevin(fry). . After adding the functionality to provide custom geometry for UMI and cellular barcode sequence through command line flags like `--umi-geometry` and `--barcode-geometry,` our general guidelines have been shifted against adding technology-specific command line flags to the alevin codebase. Rob might have more comments on that. Regarding the 0-length cell barcode, I recommend first trying to add the dummy CB before the UMI sequence as a test case. If it helps with your use case, we can discuss adding the ; 0-length cellular barcode functionality to the main codebase. Previously, paired-end read processing was not possible under the alevin framework, but with the publication of alevin-fry, the support for paired-end read (I think) has been added. @DongzeHE and @Gaura might have better thoughts on this.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/805#issuecomment-1282467290:582,test,test,582,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/805#issuecomment-1282467290,2,['test'],['test']
Testability,"Hi @bsipos,. This is caused primarily by salmon's desire to apply an error model (by default) to the CIGAR strings. For secondary alignments, as you note, minmap2 doesn't write the read string, and so when salmon is trying to score the alignments under the error model, it can't find the relevant characters in the read. In general, it's not clear to me if one would actually want to apply the error model (designed primarily for short reads) when quantifying long reads (this is something we are currently testing in the lab). For the time being, I'd probably recommend disabling the error model when quantifying alignments from long reads (`--noErrorModel`). In that case, the errors should hopefully go away. Please let me know, and we'll be sure to keep you updated on best practices for long reads as we figure things out.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/289#issuecomment-420295665:507,test,testing,507,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/289#issuecomment-420295665,2,['test'],['testing']
Testability,"Hi @bzmby ,. I am sure you are aware of this but just wanted to clear that salmon is primarily designed for transcriptome quantification.; Ideally, there should not be a problem with indexing genome, also from the log you shared it looks like a warning. ; Having said that if you will index the genome then at the end of the day you will get quantification of the chromosomes, is that what you wan't ?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/741#issuecomment-1024655023:214,log,log,214,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/741#issuecomment-1024655023,2,['log'],['log']
Testability,"Hi @cfischer1991,. Thanks for the report. There have certainly been _a lot_ of improvements and changes to salmon between v0.8.1 and v1.3.0. The built-in mapping functionality has been largely overhauled. However, I can see that you're not using that here (you're quantifying from alignments). There have been a number of improvements in the alignment-based codepath as well. However, I'd guess that one of the biggest differences in the results you're seeing is due to a changes in the variational Bayes prior that happened between these versions. Specifically, the prior was adjusted to be smaller, and the default was changed from a `per-nucleotide` prior to a `per-transcript` prior. You can try and achieve the newer functionality in 0.8.1 by setting `--perTranscriptPrior` and `--vbPrior 0.01` and seeing, under those settings, how differently things look between 0.8.1 and 1.3.0. *Also*, another important change is in the handling of _incompatible_ alignments — alignments that do not match the prescribed library type. The incompatibility prior used to be set to a small but non-zero value by default `9.9999999999999995e-21`, but has since been changed to `0` by default. Both of these changes in the default have been results of a lot of internal testing suggesting these settings improve quantification results _in general_ (of course, given the complexity in of the quantification problem, there is likely no universal set of parameters that are optimal with respect to every experiment). I'd suggest trying to set these parameters to be the same between versions and to see how much of the variance is controlled by these changes in default values. Then you can determine which settings you believe make more sense in your context, with the understanding that the newer settings have been chosen, in general, to optimize quantification accuracy. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/562#issuecomment-674855490:1258,test,testing,1258,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/562#issuecomment-674855490,1,['test'],['testing']
Testability,"Hi @cliftonlewis, . Sorry for the delay. I tested it on another file and it worked fine. I would like to look at some info from your file. Could you:; 1. Post the `salmon` log of the first run, the one that you did with `--justAlign`; 2. There should be a `map.rad` file in your output directory (`SRR17122012`). Can you run the command: `alevin-fry view --rad map.rad > rad.txt` and share the rad.txt file? . Thanks.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/813#issuecomment-1344650063:43,test,tested,43,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/813#issuecomment-1344650063,2,"['log', 'test']","['log', 'tested']"
Testability,"Hi @cljacobs,. There was at least one unnecessarily large allocation within our pufferfish code, and now Ilia has also massively optimized the intermediate disk space usage behavior of TwoPaCo. An updated binary that incorporates these changes can be obtained [here](https://drive.google.com/open?id=1QHYCT3Vs9bRD7UmJY6JJKjlzmmUE4wRl). If you have a chance, it would be fantastic if you could test this out and see how the resource requirements change for you.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/476#issuecomment-587082126:393,test,test,393,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/476#issuecomment-587082126,1,['test'],['test']
Testability,"Hi @dhy2002,. The message at the beginning is just a result of salmon not being able to complete the version check — that is not related to any issues building the index. What is at the end of the log file?. Also, I'll note that we've seen before some issues related to building the index directly on a network file system mounted partition — the tool we use for compacted de Bruijn graph construction, TwoPaCo, can create many small intermediate files that causes issues for NFS. If this is the problem, I might suggest building the index on the local scratch disk of a node, and then copying over the completed index when it's finished. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/755#issuecomment-1050468212:197,log,log,197,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/755#issuecomment-1050468212,1,['log'],['log']
Testability,"Hi @dritoshi ,. Thanks for your request. I'd be happy to add the support for Quartz-seq2 into alevin but it'd be great if you can answer a few questions for us. Is it possible to share some reads/fastq file on which we can test alevin ? Also, please excuse my ignorance, what type of PCR amplification is performed in `Quartz-seq2` protocol, is it CelSeq type IVT (linear) amplification or Drop-Seq type template switching PCR amplification ?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/416#issuecomment-521747003:223,test,test,223,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/416#issuecomment-521747003,1,['test'],['test']
Testability,"Hi @ehiggs, You're right; there's no real reason we shouldn't be able to support ICC. The only issue is that we currently don't have access to a machine with icc, so this prevents us from testing the build ourselves. Is there a (free) resource (similar to Travis) that would allow us to test ICC builds? I'd be willing to add CMake support either way, but it would obviously be better if we could iron out the details ourself rather than wait for users to report issues building with icc.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/9#issuecomment-126348908:188,test,testing,188,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/9#issuecomment-126348908,2,['test'],"['test', 'testing']"
Testability,"Hi @francicco ,. I've dug further, and in addition to these problems with the input file, there was also a specific bug in salmon's processing of the alignments for the error model. Specifically, it was triggered when an alignment ended with a soft-clip of the reference. I have now fixed this issue in the develop branch, and, after some more testing, will push it to a new release.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/231#issuecomment-394859031:344,test,testing,344,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/231#issuecomment-394859031,1,['test'],['testing']
Testability,"Hi @fweghorst,. My guess is that a large fraction of this high number come from `N` bases in the underlying genome assembly (since you are making a gentrome index). To test this hypothesis, you could also build an index with just the cdna (or edna + ncrna) and see what that number is. At the end of the day, of course, it makes sense to use the gentrome index anyway, but this will at least give you an idea of what fraction of nucleotides are being replaced from the decoy (genome) versus the target transcript sequences. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/766#issuecomment-1082558366:168,test,test,168,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/766#issuecomment-1082558366,1,['test'],['test']
Testability,"Hi @gambardella,. Thank you for the detailed bug report. I agree that, though the issue seems to be arising from the input, a seg fault should not happen in any case. Judging from the place in the log from which this is arising, it seems to be happening during the TwoPaCo construction of the compacted de Bruijn graph. We'll dig into this and see if we can figure out how to handle this in a better way.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/521#issuecomment-627508722:197,log,log,197,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/521#issuecomment-627508722,1,['log'],['log']
Testability,"Hi @gianfilippo ,; Thanks for forwarding the logs.; It does look like Alevin knee selection is over-shooting and allowing only ~250 cells as a whitelist.; Although not very frequent but we do have observed this behavior with Alevin knee selection in couple of other experiments and are working on more robust thresholding. I am closing this issue regarding the barcode frequency but will open a new one regarding the aggressive thresholding and would tag you in too, in case you wan't to track.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/284#issuecomment-418813606:45,log,logs,45,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/284#issuecomment-418813606,1,['log'],['logs']
Testability,"Hi @gianfilippo ,; it looks like the logs which you forwarded are for externally given whitelists, can you rerun alevin w/o that?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/284#issuecomment-418130349:37,log,logs,37,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/284#issuecomment-418130349,1,['log'],['logs']
Testability,"Hi @gianfilippo,. Thank you for the report and for including the log File. Can you share one of the problematic samples and the reference against which you are aligning? One big difference is that the alignment rate reported by HISAT2 is to the genome, while for salmon it is with respect to the genome. For certain samples (e.g. if you get a bad sample with poor rRNA depletion etc.) you can have many reads align to the genome, but none of them align to the annotated transcriptome. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/616#issuecomment-764188266:65,log,log,65,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/616#issuecomment-764188266,1,['log'],['log']
Testability,"Hi @grantcramer,. I was able to successfully index and map against the fasta file you link above (on linux). I was also able to index and map against the index on OSX, using the salmon from bioconda (v 0.9.1). So, I'm not _yet_ able to reproduce this. It seems the file you uploaded for your pre-built index is no longer available, so I couldn't try that out. I'd be happy to give it a try if you can put it up on dropbox or some such. Otherwise, I wonder if there could be some sort of binary compatibility issue. Did you build the index on the same machine you're quantifying on? The OSX I tested on is 10.13.1. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/209#issuecomment-375509050:592,test,tested,592,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/209#issuecomment-375509050,1,['test'],['tested']
Testability,"Hi @guidohooiveld, . Regarding your questions:. (1) The motivation behind asking users to use Bioconda to install the binary is to limit the number of variables we may encounter when someone is reporting a bug --- i.e. if there are fewer distribution channels there is less maintenance overhead. Nonetheless, as you can see, I've had to make the binary available anyway, because it was the only way some people could easily get the program. Therefore, I think I'll start attaching binaries to releases again. (2) Yes, though this functionality is not part of Salmon itself. I *highly* recommend the [MultiQC](http://multiqc.info/) tool. MultiQC has a salmon module, which will parse all of the salmon log files in an experiment directory and produce a report. This report will contain the mapping percentages for all of the samples extracted from the salmon logs (and will color them nicely). It will also produce other QC information from the salmon runs. We are currently working on an improved multi-QC module, which will also provide summaries for things like GC / seq bias by analyzing the models that salmon learns, but this module isn't yet complete. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/252#issuecomment-405442271:701,log,log,701,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/252#issuecomment-405442271,4,['log'],"['log', 'logs']"
Testability,"Hi @hliu5259 ,; can you forward the log ?; There can be multiple reasons, did you gave external whitelist ? When you say 9253 samples do you mean 9253 cells ? How did you fix the number of cells ?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/375#issuecomment-501828238:36,log,log,36,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/375#issuecomment-501828238,1,['log'],['log']
Testability,"Hi @jan-g1,. The length of a feature is used during inference to determine the likelihood that multimapping reads should be allocated to different targets. You're describing what is essentially a simplified model where P(f | t) (i.e., the probability of a fragment given a transcript) is independent of length(t). There's currently no option to disable length normalization completely in Salmon, and you can't ""de-normalize"" by simply multiplying by a factor because those weights are considered during each and every round of the EM (or VBEM) algorithm. However, supporting this should actually be very straight-forward. We simply assign a uniform and identical length to all transcripts for the purpose of inference. I can add such a flag in the next release, though it will initially have to be incompatible with bias correction (since it's not clear right now how the biases for which we account interact with this type of sequencing). Also, it would be possible to run salmon with `--dumpEq`, and then to have a little script / tool that simply re-runs the EM, but without different length factors, using the equivalence class file. I might be able to hack something like that together on short notice if you'd be interested in testing it out. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/108#issuecomment-264659889:1233,test,testing,1233,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/108#issuecomment-264659889,2,['test'],['testing']
Testability,"Hi @jckhearn,. The documentation could definitely be more clear, so let me try and clarify here and make a note to clean up the documentation more as well. I'll answer in reverse order:. > Given the above command should I go back to a non-decoy aware transcriptome?. No. What the statement in the documentation means to convey is that if you are using the basic quasi-mapping algorithm (not selective-alignment as enabled by `--validateMappings`, `--mimicBT2` or `--mimicStrictBT2`), then you should not be using a decoy-aware transcriptome. We have not tested the effect of decoys on the basic quasi-mapping approach, and though that may be supported in the future, it is not right now. However, if you are using any flavor of selective-alignment, then please _do_ use the decoy-aware transcriptome. . Regarding ""combining"" `--validateMappings`, `--mimicBT2` and `--mimicStrictBT2`, this is not possible. That is, you should view `--mimicBT2` and `--mimicStrictBT2` as ""meta-flags"" that enable selective-alignment and also set a few other options that are meant to mimic the BT2 behavior more closely. We generally do _not_ recommend `--mimicStrictBT2`, and so the main choice is between simply using `--validateMappings` vs. `--mimicBT2`. The main differences here are that `--mimicBT2` sets slightly more sensitive parameters to find alignments, but is also stricter in what it reports. The biggest differences is that `--validateMappings` will allow orphaned mappings (where one end of a paired-end fragment aligns but the mate doesn't), while `--mimicBT2` will not allow such mappings. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/399#issuecomment-511884297:554,test,tested,554,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/399#issuecomment-511884297,2,['test'],['tested']
Testability,"Hi @jeremymsimon — @Gaura is going to take a look at unfiltered permit listing and will share those results here later. Regarding frameshift errors, I think that's certainly out of scope for the alevin -> fry phase, but that type of thing *could* be in scope for `splitp`. Basically, my logic / reasoning is this: I'd like to avoid further complicating the already immense salmon/alevin codebase with special implementations handling problems outside of their core function (e.g. mapping reads to the reference efficiently and quantifying UMIs/barcode). Since most protocols (and the most common) have quite simple barcode geometry, it makes sense for this code to live there. I'm fully supportive of enabling support for more complex barcode geometries and preprocessing requirements if there are folks whom it would help, but it feels like that essential complexity belongs upstream of alevin / fry, so that by the time the reads get to alevin, it can assume a straightforward geometry. So TLDR : I think we'd be willing to investigate what is required to address potential frameshift errors, and how much of a difference that makes, but I think that analysis and eventual implementation (if we decide it's worth it), belongs in `splitp`.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-988030837:287,log,logic,287,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-988030837,2,['log'],['logic']
Testability,"Hi @jeremymsimon! In order to test and validate the implementation I would need a count matrix generated on samples. Do you have a sample and count matrix from that? The Rosenberg submission of the data has an unclear way of specifying barcodes and I have emailed him about it. If you have count matrix and matching fastqs that we can use to validate, we can wrap it up soon.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-982878463:30,test,test,30,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-982878463,1,['test'],['test']
Testability,"Hi @jeremymsimon,. A few quick thoughts on this.; ; > -Is quantification via alevin-fry (rather than alevin itself) mandatory here? I ask since your run seems successful whereas my full alevin run had a very poor BC detection and mapping rate.; ; I don't think we've been able to successfully obtain the same concordance with alevin yet (as opposed to alevin-fry). There is more sophisticated _internal_ barcode logic going on there, and we may need to pull @k3yavi in to see what is happening outside of the RAD -> fry pipeline.; ; > -I see you specified -l A - can you comment on what the detected/correct library type was here?; ; Unlike `alevin`, when you run with in `--rad` or `--sketch` mode, the library type isn't really relevant. All mappings are passed through to the rad file. Subsequently, in `alevin-fry` there is a `-d` (direction) flag that is used to filter mappings that don't concord with the expected orientation. I'm not sure what @Gaura used in the run above — the default is to keep reads from either orientation.; ; > -I assume all of this will also work in conjunction with --expectCells or --keepCBFraction if those parameters were needed? Your ~7k cells detected is very close to the published number post-filtering, but no similar filtering has been done here yet. My guess is that the proportion of cells that pass these filters will be higher for alevin, but we may still be under-estimating the number of real cells by a little bit here.; ; According to the commands listed, @Gaura used `alevin-fry`'s built-in knee-like filtering. This tries to use a knee on the cumulative read count histogram to determine a good cutoff for ""reliable"" cells versus poor quality cells. Alternatively, one can provide an external permit list with `-u` (unfiltered permit list) to quantify all cells that match any known barcode. This will generally result in *many* more quantified cells, which you will then want to filter post-quantification.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-988011633:412,log,logic,412,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-988011633,1,['log'],['logic']
Testability,"Hi @jeremymsimon,. I've discussed the support for SPLiT-seq/ParseBio with @Gaura in some depth. Honestly, I think the cleanest solution right now is just to have a more streamlined (and streaming) way to match / replace the random hexamers upstream of alevin-fry. By my understanding, if we can simply replace barcode 1 appropriately (as your Perl script currently does), everything should work downstream in alevin/alevin-fry.; ; To that end, I've thrown together a small rust program based on your Perl script. Currently that lives [here](https://github.com/COMBINE-lab/splitp). It reads the same basic parameters as the Perl script, and writes its output to stdout so that it can be used with named pipes. For example, something like:; ; ```; <normal salmon command> -1 read_file_1.fq -2 <(splitp --read-file read_file_2.fq --bc-map bcSharing_example.txt --start 79 --end 86 --one-hamming); ```. which will transform the second fastq file and stream the transformed reads out which can then be read by alevin-fry. One important thing to note is that while *alevin* requires the input reads to be a real file (i.e. you can't stream reads in because it does 2 passes), if you are mapping these reads for processing with *alevin-fry* you can use the process substitution trick above. As you hinted, this program works considerably faster than the Perl script. For example, for the first 10,000,000 reads in `SRR6750042`, the Perl script took 2m 48s to transform the reads and `splitp` took ~6s (if the output wasn't being written to a file on disk it took <4s). This should generally be fast enough to not be a speed bottleneck. So, perhaps the next step is to try to help you walk through this approach with a test dataset (and ideally using alevin-fry) to see if things are turning out as expected?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-961598108:1711,test,test,1711,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-961598108,2,['test'],['test']
Testability,"Hi @jeremymsimon,. So I'm trying to think about what issues _could_ be reasonably dealt with here. . 1) If the length of the sequence in the BAM header and the sequence provided in the FASTA file are different, this seems like a very difficult error to recover from since records can then contain alignments to bases about which we don't know. 2) If the same transcript appears multiple times in the input BAM header, but with different lengths, this also seems a difficult situation to allow. Exact duplicates are one thing, but I'm not sure if sequences ever appear with the same name but different lengths. If so, I'm thinking this would be a hard error. So, I think at least one situation we could reasonably deal with is that the input FASTA file contains multiple entries with the same name (and same length / sequence). In this case, we could retain only one of them, and document / log the fact that multiple identical entries were present in the input. Of course, there would still be an issue if we had a mismatch as with your example STAR input, where STAR concatenated all 3 occurences of an identical transcript. Are there other cases you can think of where it would make sense to somehow deal with the issue in salmon and continue with processing (perhaps with some extra warnings / log info)?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/282#issuecomment-418412904:890,log,log,890,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/282#issuecomment-418412904,2,['log'],['log']
Testability,"Hi @juugii ,. I tried to simulate the coverage/depth bias by subsampling a fraction of the data and then correcting it using a very trivial approach, which seems to be working fine, at least for the dataset I simulated. It would be great if you can also test the same on your dataset too and let us know how it looks for your use case. The gist of the notebook can be found [here](https://gist.github.com/k3yavi/55be0c0c660f1c0034f2d11df31bec00).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/305#issuecomment-433593259:254,test,test,254,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/305#issuecomment-433593259,1,['test'],['test']
Testability,"Hi @k3yavi , ; You are absolutely correct, that the tsv file only had one column, I fixed it above. . But the txdf was my backup... I tried your bioawk script, but I keep getting this error; `bioawk: illegal field $(), name ""group""` . [alevin.log](https://github.com/COMBINE-lab/salmon/files/2639709/alevin.log); [salmon_quant.log](https://github.com/COMBINE-lab/salmon/files/2639710/salmon_quant.log)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/326#issuecomment-443718326:243,log,log,243,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/326#issuecomment-443718326,4,['log'],['log']
Testability,"Hi @k3yavi ,. I'm using alevin to process 10X V3 data and encountered similar problem with this issue. I've tried run the pipeline using default whitelisting by alevin, `--whitelist barcode.txt` which from cellranger v.3.1.0 run (including 7938 barcodes), `--expectCells 10000`, and `--expectCells 30000`. But no matter how I change the parameter, the log shows that there are always about 50% percent reads has been thrown away, and the mapping rate was between 18.7%-19.1%. . the salmon version is `salmon 1.4.0`; the reference genome is sequenced by ourselves, and it's a plant.; my reads layout is paired end 150bp, . > R1: ; @A00582:424:HJYLGDSXY:3:1101:1090:1000 1:N:0:ACCGGCTC; TAACCAGGTCGAGTGAGTATTTAAGGCGCGCGGCGCACCAACGCACTCCCAACAACAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA; > +; FFFFFFFFFFFFFFFFFFFFFFFFFFFF,,:,,FF:,,,::FF,,:F,,,,,,F:,,,:,::FF::::::,FFF:F:FF:FFFFFFF::FF::FF,F:F:FF:F,FFFF,:FF,FFFFF:,FF:::FF:FFF:FF:FF:FFFFFFFFFF:; > R2:; @A00582:424:HJYLGDSXY:3:1101:1090:1000 2:N:0:ACCGGCTC; NCCTAGAAGCAGCCACCCTTGAAAGAGTGCGTAATAGCTCACTGATCGAGCGCTCTTGCGCCGAAGATGAACGGGGCTAAGCGATCTGCCGAAGCTGTGGGATGTAAAAATACATCGGTAGGGGAGCGTTCCGCCTTAGAGAGAAGCCTC; > +; #FF:FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF:FFFFFFFFFFFFFFFFFFFFFFFFFFF:FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF:FFFFFFFFFFFF::FFFFFFFFFF:FFFFFFFFFFFFF:FFFFFF:FFFFFFF:. Here is the logs. ## Default setting ; `salmon alevin -l ISR -1 ../clean/sample_S1_L001_R1_001.fastq -2 ../clean/sample_S1_L001_R2_001.fastq --chromiumV3 -i ../../dna/00.ref_genome/sample/salmon_index_allmRNA -p 40 -o test_alevin_allmRNA --tgMap ../../dna/00.ref_genome/sample/alltxp2gene.tsv`. > [2021-01-25 16:22:09.565] [alevinLog] [info] Found 43030 transcripts(+0 decoys, +0 short and +0 duplicate names in the index); [2021-01-25 16:22:09.615] [alevinLog] [info] Filled with 43030 txp to gene entries; [2021-01-25 16:22:09.620] [alevinLog] [info] Found all transcripts to gene mappings; [2021-01-25 16:22:09.631] [alevinLog] [info",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/340#issuecomment-766311567:352,log,log,352,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/340#issuecomment-766311567,1,['log'],['log']
Testability,"Hi @k3yavi ,; Using the 5238 barcodes that are specific to this experiment, and also removing the quotes from the transcript to gene map file [bcNotFound-2018-07-19b.tar.gz](https://github.com/COMBINE-lab/salmon/files/2214018/bcNotFound-2018-07-19b.tar.gz), this time Alevin finished with no error. However, I did not get a count matrix in csv format. Also, the quants_mat_cols.txt file is missing, and I do not know how to read the binary quants.mat file. `salmon alevin -l ISR -1 SRR6327122_1.fastq.gz -2 SRR6327122_2.fastq.gz --chromium -i index -p 2 -o alevin_output --tgMap transposon_sequence_set.fa.tsv --whitelist barcode_seq_5K.txt --dumpCsvCounts`; Version Info: ### A newer version of Salmon is available. ####; ###; The newest version, available at https://github.com/COMBINE-lab/salmon/releases; contains new features, improvements, and bug fixes; please upgrade at your; earliest convenience.; ###; Logs will be written to alevin_output/logs; [2018-07-19 22:53:27.709] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; ### salmon (single-cell-based) v0.10.2; ### [ program ] => salmon ; ### [ command ] => alevin ; ### [ libType ] => { ISR }; ### [ mates1 ] => { SRR6327122_1.fastq.gz }; ### [ mates2 ] => { SRR6327122_2.fastq.gz }; ### [ chromium ] => { }; ### [ index ] => { index }; ### [ threads ] => { 2 }; ### [ output ] => { alevin_output }; ### [ tgMap ] => { transposon_sequence_set.fa.tsv }; ### [ whitelist ] => { barcode_seq_5K.txt }; ### [ dumpCsvCounts ] => { }. [2018-07-19 22:53:27.714] [alevinLog] [info] Processing barcodes files (if Present) . ; processed 87 Million barcodes. [2018-07-19 22:55:37.299] [alevinLog] [info] Done barcode density calculation.; [2018-07-19 22:55:37.299] [alevinLog] [info] # Barcodes Used: 86885223 / 87959276.; [2018-07-19 22:55:37.303] [alevinLog] [info] Done importing white-list Barcodes; [2018-07-19 22:55:37.303] [alevinLog] [info] Total 5238 white-listed Barcodes; [2018-07-1",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/253#issuecomment-406597243:913,Log,Logs,913,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/253#issuecomment-406597243,2,"['Log', 'log']","['Logs', 'logs']"
Testability,"Hi @k3yavi . I have added all the log files I could find of one sample. If you need anything else, please let me know. [salmon_quant.log](https://github.com/COMBINE-lab/salmon/files/7943404/salmon_quant.log); [alevin.log](https://github.com/COMBINE-lab/salmon/files/7943405/alevin.log). Thanks in advance for looking into this.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/739#issuecomment-1022373628:34,log,log,34,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/739#issuecomment-1022373628,5,['log'],['log']
Testability,"Hi @k3yavi, ; My local repository now contains the latest commit, and the run proceeds past the `processed X Million barcodes` however, I have been stuck at `Analyzed 95 cells (100% of all)` for the past few hours.. I am sorry this is giving you guys such issues :( . I also tried this on `cat *R1*.fq.gz` of the files, and had the same issue.; [alevin.log](https://github.com/COMBINE-lab/salmon/files/2672819/alevin.log); [salmon_quant.log](https://github.com/COMBINE-lab/salmon/files/2672821/salmon_quant.log). ```; Logs will be written to path/to/alevin_outputSingleLibrary/quantSC/logs; Check for upgrades manually at https://combine-lab.github.io/salmon; [2018-12-12 15:07:42.022] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; ### alevin (dscRNA-seq quantification) v0.12.1; ### [ program ] => salmon ; ### [ command ] => alevin ; ### [ index ] => { /path/to/gencode_annot/AlevinIndex/ }; ### [ libType ] => { ISR }; ### [ mates1 ] => { 12_CTTGTA_L001_R1_001.fastq.gz 12_CTTGTA_L001_R1_002.fastq.gz 12_CTTGTA_L001_R1_003.fastq.gz 12_CTTGTA_L001_R1_004.fastq.gz 12_CTTGTA_L001_R1_005.fastq.gz 12_CTTGTA_L001_R1_006.fastq.gz 12_CTTGTA_L001_R1_007.fastq.gz 12_CTTGTA_L001_R1_008.fastq.gz 12_CTTGTA_L001_R1_009.fastq.gz 12_CTTGTA_L001_R1_010.fastq.gz 12_CTTGTA_L002_R1_001.fastq.gz 12_CTTGTA_L002_R1_002.fastq.gz 12_CTTGTA_L002_R1_003.fastq.gz 12_CTTGTA_L002_R1_004.fastq.gz 12_CTTGTA_L002_R1_005.fastq.gz 12_CTTGTA_L002_R1_006.fastq.gz 12_CTTGTA_L002_R1_007.fastq.gz 12_CTTGTA_L002_R1_008.fastq.gz 12_CTTGTA_L002_R1_009.fastq.gz 12_CTTGTA_L002_R1_010.fastq.gz }; ### [ mates2 ] => { 12_CTTGTA_L001_R2_001.fastq.gz 12_CTTGTA_L001_R2_002.fastq.gz 12_CTTGTA_L001_R2_003.fastq.gz 12_CTTGTA_L001_R2_004.fastq.gz 12_CTTGTA_L001_R2_005.fastq.gz 12_CTTGTA_L001_R2_006.fastq.gz 12_CTTGTA_L001_R2_007.fastq.gz 12_CTTGTA_L001_R2_008.fastq.gz 12_CTTGTA_L001_R2_009.fastq.gz 12_CTTGTA_L001_R2_010.fastq.gz 12_CTTGTA_L002_R2_001.fastq.gz 12_CTTGTA_L002",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/329#issuecomment-446668422:353,log,log,353,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/329#issuecomment-446668422,6,"['Log', 'log']","['Logs', 'log', 'logs']"
Testability,"Hi @kate-simonova,. While I would certainly recommend updating to the latest version of salmon (which, given the pre 1.0.0 to post 1.0.0 difference would require you to rebuild the index), I don't think that would have a substantial effect on a mapping rate that is this low. If the Fastqscreen report suggests that most of the reads map to the genome (>75%), but you are seeing an 8% mapping rate in salmon, this highly suggests that most of the reads are, for some reason, arising from outside of an annotated gene. I would then have two suggestions to test out:. 1.) Check for mtRNA contamination. Try adding extra mitochondrial RNA to your reference fasta, re-indexing, and re-quantifying. If mtRNA depletion or polyA enrichment failed, then it's possible that you have most of your RNA-seq reads coming from mt genes. I've seen this before a number of times and it results in a situation where most of the reads map back to the genome — but not the annotated transcriptome, which often has an incomplete set of mtRNA sequences. 2.) Try mapping the reads to the genome and see how many reads overlap known genes. This is what you would do with a ""counting-based"" RNA-seq pipeline, so something like STAR+feature-counts or subread+feature-counts. While I would generally not recommend this for quantification, it can be instructive to see the fraction of reads that map to the genome but not to known transcripts. Likewise, you could (with the newest salmon) build an index on the transcriptome with the genome added as a decoy (see about our decoy-aware indexing), then the `meta_info.json` will let you know the fraction of reads that were discarded because they were best matched to a decoy sequence (in this case, the genome, but not some annotated transcript). This should help clarify what's going on, and might suggest some issues with the sample that are preventing a reasonable mapping rate to the annotated transcriptome. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/679#issuecomment-1036524215:555,test,test,555,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/679#issuecomment-1036524215,1,['test'],['test']
Testability,"Hi @keithgmitchell,. Alevin is designed for droplet-based, tagged-end protocols, and in the vast majority of these protocols, transcript-level quantification isn't really reliable enough to be useful. Since most tagged-end protocols sequence information from only the 3' end of the transcripts, there is a highly-biased coverage signal, and discerning UMI assignment at the transcript level is usually not possible. Therefore, I wouldn't generally recommend trying to obtain transcript-level counts from alevin and we haven't tested it in this context. If you have a particular reason you want to look at transcript counts and believe it may be reasonable in your specific use-case, you can alway pass in a gene-to-transcript map that just maps each transcript to itself, which will result in a transcript-level output matrix. However, I anticipate that the resolution problem will become more difficult in this case, and there will be much more uncertainty in the assignments. @k3yavi, please feel free to add anything you think I may have missed. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/588#issuecomment-729974232:526,test,tested,526,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/588#issuecomment-729974232,1,['test'],['tested']
Testability,"Hi @knokknok ,. Thanks for reporting this (and for testing out 0.10.0 so quickly)! Is this read set & reference txome available to try and reproduce this? Also, would it be possible to check if this occurs using the bioconda-packaged release?. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/228#issuecomment-393218241:51,test,testing,51,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/228#issuecomment-393218241,1,['test'],['testing']
Testability,"Hi @knokknok,. Nice catch ! K1 bad k2 are just two bit encoding of the UMI sequences, it passed my unit test because I was testing it with 10x data but you are right it should be dynamic based on the umi length. I'll make the changes to reflect that in the develop branch. Thanks !",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/430#issuecomment-535015422:104,test,test,104,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/430#issuecomment-535015422,2,['test'],"['test', 'testing']"
Testability,"Hi @kzkedzierska,. I'm not sure why the virtual memory usage here is so high, and am also not aware of a great way to predict it. One thing I might ask is if you could test this executable on your system ( [salmon-1.2.0-beta](https://drive.google.com/open?id=1QHYCT3Vs9bRD7UmJY6JJKjlzmmUE4wRl)). This is the near-final beta version of 1.2.0 whose release is imminent. One of the big changes in this version is a considerably more memory-efficient construction. We have been measuring this in terms of resident memory, but it may also apply to virtual memory. Would you mind giving it a try if you have a chance?. Thanks!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/441#issuecomment-605106040:168,test,test,168,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/441#issuecomment-605106040,1,['test'],['test']
Testability,"Hi @litongda007,. Thanks for the updated. I grabbed these and ... basically saw the same thing:. ```; 23R1F : has null = False; 23R2F : has null = False; 23R3F : has null = False; 23R4F : has null = False; R1ST1 : has null = False; R2ST1 : has null = False; R3ST1 : has null = False; R4ST1 : has null = False; ```. I am thinking that perhaps the error is popping up somewhere _downstream_ of salmon. I presume you are using the `salmon` -> `wasabi` -> `sleuth` pipeline, is that correct? If so, I can try and see if I get the same thing importing in R. The tests above were using the python importer from [here](https://github.com/COMBINE-lab/pluribus). **Update**: Ok, that, too, has failed. I converted all of the quantifications to hdf5 files using wasabi, and then checked for nans in the converted files:. ```python; import h5py; import numpy as np; def get_num_nan(x):; nbs = int(x['aux']['num_bootstrap'].value[0]); s = 0; for i in range(nbs):; s += np.isnan(x['bootstrap']['bs{}'.format(i)].value).sum(); return s. samps = ['23R1F', '23R2F', '23R3F', '23R4F', 'R1ST1', 'R2ST1', 'R3ST1', 'R4ST1']; for s in samps:; d = h5py.File('quant/{}/abundance.h5'.format(s)) # abundance.h5 created by wasabi; null_count = get_num_nan(d); print(""{} : null count = {}"".format(s, null_count)); d.close(); ```. The output, as above, is : . ```; 23R1F : null count = 0; 23R2F : null count = 0; 23R3F : null count = 0; 23R4F : null count = 0; R1ST1 : null count = 0; R2ST1 : null count = 0; R3ST1 : null count = 0; R4ST1 : null count = 0; ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/529#issuecomment-638553711:557,test,tests,557,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/529#issuecomment-638553711,1,['test'],['tests']
Testability,"Hi @mathog,. > Is it really the case that Salmon cannot use 1.57.0?. It may be able to. We set the minimum required version to the lowest boost version we use in any of our testing machines where we run regression tests. Currently, this is 1.59.0. If you change the relevant `CMakeLists.txt` line, you *really* need to make sure you clear out the CMake cache. You can do this by removing `CMakeCache.txt` in your build directory, as well as the directory `CMakeFiles`. However, it might be easiest just to remove and remake the entire `build` directory. You may also try passing `-DBoost_NO_SYSTEM_PATHS=Bool:ON` to your cmake command. Finally, note that the build system is probably looking for the static libraries --- you can elide that preference by modifying [this line](https://github.com/COMBINE-lab/salmon/blob/master/CMakeLists.txt#L222). Finally, since salmon uses C++11, it's important that whatever boost you link against exposes a C++11 compatible ABI. Unfortunately, `FindBoost.cmake` is the most finicky of the module finding packages I know about 😦. If you use `-DFETCH_BOOST=TRUE`, then CMake will fetch a recent boost and build the libraries it needs and link them statically. I realize you want to avoid this, so hopefully one of the ideas above will help.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/236#issuecomment-396781869:173,test,testing,173,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/236#issuecomment-396781869,4,['test'],"['testing', 'tests']"
Testability,"Hi @mdeyssen,. Thanks for reporting this. This is really strange, as the compute note you're using here should be much more than capable of building this index reasonably quickly. Furthermore, stage 0 is the construction of the compacted de Bruijn graph for which we use a modified version of TwoPaCo. One strange thing seems to be that there is no disk read / disk write happening at this point, though TwoPaCo should have written its intermediate files to disk by this point in the algorithm.; ; I'm not sure what the best way to try to debug is at this point. Does the indexing complete correctly when you build it on just the transcriptome (leaving out the decoys)? Can you provide any information about the specific instance type used (and particularly the storage)? We'll see if we can think how to further test what might be going on in this case. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/687#issuecomment-885886146:813,test,test,813,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/687#issuecomment-885886146,1,['test'],['test']
Testability,"Hi @najibveto,. I do not have access to a windows machine, unfortunately, so I can not test this directly. It would seem that somehow the appropriate version of `libstdc++` is not available or is not being found? I would recommend to raise this issue over on the [`bioconda` repository](https://github.com/bioconda/bioconda-recipes/issues) or in their [gitter channel](https://app.gitter.im/#/room/#bioconda_Lobby:gitter.im). Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/864#issuecomment-1660467862:87,test,test,87,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/864#issuecomment-1660467862,1,['test'],['test']
Testability,"Hi @nazeeefa,. In this case, you need to make sure the relevant path is in your library path. Try the following:. ```; LD_LIBRARY_PATH=path/to/salmondir/lib:$LD_LIBRARY_PATH path/to/salmon quant -t fasta_file -l A -a bam_file -o output_dir; ```. If that works you can make the change to the library path automatic at login by putting . ```; ecport LD_LIBRARY_PATH=path/to/salmondir/lib:$LD_LIBRARY_PATH ; ```; In your `.bashrc` file and then opening a new terminal (assuming you are using a bash compatible shell). Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/219#issuecomment-386273154:317,log,login,317,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/219#issuecomment-386273154,1,['log'],['login']
Testability,"Hi @nh13,. This is not something for which we currently have support or something that we currently plan. I'd be open to it, but I'm honestly not sure how to cleanly do it in the current architecture, and doing so would certainly incur a performance hit. Salmon runs 2 phases of inference; and online phase and an offline phase. The online phase has access to _fragment-level_ information that is then summarized away during the offline phase (like the specific locations of each read, the length of each observed fragment, etc.). That information goes away when the reads are summarized into range-factorized equivalence classes. Moreover, some of the model parameters learned during the online phase will depend (in their details) on the order in which observations are made. Ostensibly, observing the same data in the same order **and issuing updates to shared model parameters from worker threads in the same order** should result in identical values, however this has never been tested and was never a design goal. The reason for this is that differences between runs are within the bounds of the inherent inferential uncertainty of the estimated parameters anyway. That is, if one is relying on a specific value at a level of precision such that a different run of salmon would produce a value different enough to change a downstream analysis, then one is imparting more precision on the estimates than they can provide. Other methods that produce identical results between runs for these values may produce the same output, but the accuracy of the output at that level shouldn't be trusted in this case. The uncertainty of the parameter estimates can be evaluated based on the Gibb samples (or bootstrap replicates) that salmon computes. Of course, the small differences between runs rarely lead to differences in downstream analysis (almost certainly at the gene level and also at the transcript level if you use a differential testing method that is aware of inferential uncertainty). On the ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/102#issuecomment-2159300538:984,test,tested,984,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/102#issuecomment-2159300538,2,['test'],['tested']
Testability,"Hi @nskbe,. The issue you're seeing with the mapping file name is related to this note in the release notes:. > Note: In the 0.7.2 release, the file provided to --writeMappings must use a qualified path (e.g. --writeMappings=./out.sam rather than --writeMappings=out.sam), this constraint is already addressed on develop and will be fixed in the next release. . Essentially, the code should internally qualify the filepath before checking if a directory exists, but it doesn't. The fix for this is to pass the file name as a qualified path (i.e. adding `./` before the file name when you want it in the current directory). This is already resolved in develop and the fix for this annoyance will make it into the next release. Regarding the issue with writing the information to `stdout`; actually, all of the logging messages are written to `stderr`. If you don't redirect `stdout`, then you'll see everything, but the intended usage for that mode is something like:. ```; salmon quant -i idx [other options] --writeMappings > out.sam; ```. This will redirect standard out to out.sam. You'll still see the logging messages on the console, since they are written to `stderr`, but all of the mapping contents are redirected to the file. Let me know if this resolves your issue. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/90#issuecomment-247072758:809,log,logging,809,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/90#issuecomment-247072758,2,['log'],['logging']
Testability,"Hi @oligomyeggo,. Thank you for the **incredibly** detailed report :). The problem is the following (derived from your `B13_MeOH_cells_Jurkat_Cas9_EGR1_1_simulated.out.err.txt` log above):. ```; ### [ index ] => { /beevol/home/winklerc/projects/scifi_pipeline/scifi/ref/idx/complete_ref_lens.bin }; ```. So it looks like what your rule is passing to the mapping command is not the path to the index directory, but the path to this specific file, `complete_ref_lens.bin` **within** the index directory. The argument passed to the `-i` flag of `salmon alevin` must be the directory where all of the index files live. I think you just need to have the directory itself stored in a variable upon index creation, and then you can pass it to the mapping rule. Let me know if this helps!. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/713#issuecomment-941839528:177,log,log,177,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/713#issuecomment-941839528,1,['log'],['log']
Testability,"Hi @pinin4fjords ,. Apologies for the delayed response and thanks for your interest in Alevin.; Unfortunately, there is no one straight answer for your question. ; Other people have been using Alevin for various microwell based protocols like (CEL-seq https://github.com/COMBINE-lab/salmon/issues/269 ) but from our side we have not extensively tested alevin on non-droplet based protocols. However, we are open to provide any kind of help you may need to test the microwell-seq protocol and extend the support for alevin. If you happen to have been already testing alevin please let us know of your experience and how we can improve aleivn.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/358#issuecomment-490089165:345,test,tested,345,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/358#issuecomment-490089165,3,['test'],"['test', 'tested', 'testing']"
Testability,"Hi @pinin4fjords,. We have the same use case, trying to automate as much as possible; for some datasets there really isn't anything you can do; if it is super bad both methods are bad. This function does a pretty reasonable job of picking a cutoff based on that histogram:. ```; def guess_depth_cutoff(cb_histogram):; ''' Guesses at an appropriate barcode cutoff; '''; with read_cbhistogram(cb_histogram) as fh:; cb_vals = [int(p.strip().split()[1]) for p in fh]; histo = np.histogram(np.log10(cb_vals), bins=50); vals = histo[0]; edges = histo[1]; mids = np.array([(edges[i] + edges[i+1])/2 for i in range(edges.size - 1)]); wdensity = vals * (10**mids) / sum(vals * (10**mids)); baseline = np.median(wdensity); wdensity = list(wdensity); # find highest density in upper half of barcode distribution; peak = wdensity.index(max(wdensity[len(wdensity)/2:])); cutoff = None; for index, dens in reversed(list(enumerate(wdensity[1:peak]))):; if dens < 2 * baseline:; cutoff = index; break; if not cutoff:; return None; else:; cutoff = 10**mids[cutoff]; logger.info('Setting barcode cutoff to %d' % cutoff); return cutoff; ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/362#issuecomment-490160480:1049,log,logger,1049,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/362#issuecomment-490160480,1,['log'],['logger']
Testability,"Hi @pophipi ,; Thanks for the interesting question, but unfortunately in the current version of Alevin you can't tweak the mismatch rate option although based on the type of error/noise in the reads you can try reducing the size of the k from default 31 to something smaller and see if it helps. We are working on tweaking the mapping algorithm for Alevin allowing mismatches but it's still in testing phase and has not been integrated yet. We'll let you know as soon as we have version supporting that.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/280#issuecomment-416969420:394,test,testing,394,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/280#issuecomment-416969420,1,['test'],['testing']
Testability,"Hi @rached-97,. First of all, thank you for the _incredibly-detailed_ report. All of the information you provided made it easy to pull down the data and to test what might be going on. I pulled down the first sample, consisting of `SRR9071838_1.fastq` and `SRR9071838_2.fastq`, which was recognized as `IU` for you. . However, since I didn't have access to the annotation you used or the specific scripts you used to extract the transcriptome reference, I instead quantified directly against [gencode v37](ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_37/gencode.v37.transcripts.fa.gz). When I did this, salmon calls the library format type as `ISR`, which is what we would expect. The `lib_format_count.json` is as such:. ```; {; ""read_files"": ""[ SRR9071838_1.fastq.gz, SRR9071838_2.fastq.gz]"",; ""expected_format"": ""ISR"",; ""compatible_fragment_ratio"": 1.0,; ""num_compatible_fragments"": 31944161,; ""num_assigned_fragments"": 31944161,; ""num_frags_with_concordant_consistent_mappings"": 29445487,; ""num_frags_with_inconsistent_or_orphan_mappings"": 2576421,; ""strand_mapping_bias"": 0.000022006283676957945,; ""MSF"": 0,; ""OSF"": 0,; ""ISF"": 648,; ""MSR"": 0,; ""OSR"": 0,; ""ISR"": 29445487,; ""SF"": 1098610,; ""SR"": 1477163,; ""MU"": 0,; ""OU"": 0,; ""IU"": 0,; ""U"": 0; }; ```. As you can see, the strand mapping bias reported is `0.000022006283676957945` (to an insanely higher level of precision than we actually need). This is, of course, drastically different from the value of `0.36810071818291797` that showed up in your table for this sample. While it is true that salmon is quite conservative about calling a library as stranded (i.e. it would rather make the mistake of calling stranded library as unstranded than vice-versa, as the latter would discard reads while the former would not), in this case it looks like the culprit is likely the transcriptome reference being used. When quantified under the standard gencode transcriptome, this sample is inferred as `ISR` with very high confidence ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/655#issuecomment-825393464:156,test,test,156,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/655#issuecomment-825393464,1,['test'],['test']
Testability,"Hi @radlinsky,. I've downloaded the read data and am looking into this. In the meantime, I did notice some relevant output from your log. First, when I run with the automatic library type, I get that the most likely library type is `ISF` rather than `ISR`. Second, I note that ~4M fragments are discarded because they produce dovetailing reads. We discard dovetailing reads by default (this was a recent change in default behavior, though it is the same default choice made by e.g. Bowtie2). You can allow these reads to be mapped and quantified by passing salmon the `--allowDovetail` flag during quantification. Does this make any different in the alignments you see for this gene?. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/218#issuecomment-494208884:133,log,log,133,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/218#issuecomment-494208884,1,['log'],['log']
Testability,"Hi @rbenel , I just tested it on a couple of datasets we have, it seems to work fine.; Can you check if you can replicate the issue with two pairs and if possible forward some data to replicate the issue?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/329#issuecomment-446191229:20,test,tested,20,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/329#issuecomment-446191229,1,['test'],['tested']
Testability,"Hi @rbenel ,; Thanks for raising the issue. Just a heads up I am not very experienced in `R` and I may be doing something wrong but can you please forward your `gencode.primary_assemblyv29.tsv` because it seems the file generate after following your R code to generate txp to gene map does not seem to be right. It looks like somehow `as.data.frame(txdf$TXNAME, txdf$GENEID)`is not doing the expected thing i.e. it's dumping only the gene names, at least in my testing. One alternative would be to use bioawk script from [here](https://combine-lab.github.io/alevin-tutorial/2018/setting-up-resources/) or may be use `do.call(rbind, Map(data.frame, A=txdf$TXNAME, B=txdf$GENEID))` in R, I am not sure about the latter though.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/326#issuecomment-443712972:461,test,testing,461,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/326#issuecomment-443712972,1,['test'],['testing']
Testability,"Hi @red-plant,. So, I have some update from our end. @mohsenzakeri dug into the data a bit (specifically `SRR7985407`). What he found is that there are a considerable number of reads (~13%) have long stretches of polyA or polyT that are matching in a hyper-repetitive manner internally within a certain set of transcripts (i.e. these are not matching polyA tails, because those are already trimmed). These matches are, obviously, minimally informative, but we had not special-cased ignoring them yet. Specifically, what seems to be prevalent in these reads are read pairs where one read has polyA, the other has polyT, and the keep matching to the same positions. However, the rest of the reads don't match the transcript, so a bunch of time is wasted on validating (and discarding) these mappings. To test this hypothesis, we made a small change to the mapping algorithm to special case and ignore k-mers that are purely homopolymers. I'll note that in this data, this has no effect on the mapping rate. I get the following performance profile running the trimmed version of this data (having trimmed with `fastp`) using 4 threads, and _without_ the additional `--hitFilterPolicy BOTH` flag. ```; 1306.86user 4.79system 4:42.54elapsed 464%CPU (0avgtext+0avgdata 592704maxresident)k; ```. I was wondering if you might test this altered version out and see if it has a similarly beneficial effect for you as well. Probably, the time will be different, since the processors themselves are, and since I elided all non-essential flags here, but I would hope this version is faster than the current (even with the altered `hitFilterPolicy`). You can find a tarball with the pre-compiled binary [here](https://drive.google.com/file/d/1tPyOPW3Y8l86RS0-zBRLh0wCt3VTpkNw/view?usp=sharing). It should work on any relatively recent linux system.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/527#issuecomment-637568013:802,test,test,802,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/527#issuecomment-637568013,2,['test'],['test']
Testability,"Hi @red-plant,. This is actually an issue that is a result of the range-factorized equivalence classes that are induced by the validate mappings option. We noticed this side-effect of range-factorization in our own testing, and the issue causing it was fixed in 0.13.0. However, it is worth noting that `--validateMappings` will generally map reads in a much more sensitive way than the default quasi-mapping, and so it is likely that if a read maps to one allele, it will also map to the other but with a lower alignment score (which the algorithm accounts for during quantification). If you really only want to consider the best mappings for a read, and not weight read assignments by alignment score, then you can use the `--hardFilter` option that is also introduced in 0.13.0. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/347#issuecomment-469750859:215,test,testing,215,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/347#issuecomment-469750859,1,['test'],['testing']
Testability,"Hi @reganhayward,. Thank you for the detailed report. It's interesting that this happens when running with STAR but not when running with selective alignment. However, salmon will attempt to solve the optimization problem with the alignments it is given, regardless of if those come from STAR or from it's built-in selective alignment. While I would generally expect these to be similar, the alignment algorithms are different; see [e.g. the differences between SA/SAF & STAR here](https://genomebiology.biomedcentral.com/articles/10.1186/s13059-020-02151-8). Nonetheless, it is possible that for a small subset of transcripts, the probabilistic allocations are _so_ ambiguous, that you get large swings in the resulting quantification estimates based on tiny variations in where the optimization starts (which is, itself, stochastic due to the asynchronous nature of salmon's online inference phase). One way we can test this hypothesis is as follows. You can run salmon with `--numGibbsSamples 100` and `-d`. This will tell salmon to perform posterior Gibbs sampling (`--numGibbsSamples 100`) and to dump the range-factorized equivalence classes used for offline quantification (`-d`). The Gibbs sampling files will contain the traces for the transcripts in question over the various iterations of the sampling procedure. Transcripts where there is a tremendous amount of ambiguity will tend to have highly anti-correlated posterior samples, and similarly, if you were to consider the abundance output of these transcripts as a *group*, there would be a large reduction in inferential relative variance. In fact, we [wrote a whole paper on this topic](https://academic.oup.com/bioinformatics/article/36/Supplement_1/i102/5870485). Consider this example from that paper:. ![image](https://user-images.githubusercontent.com/361470/101438021-706d3600-38df-11eb-9ada-a54ea9092d2d.png). The x-axis is samples from the Gibbs chains, and the y-values denote the estimated number of reads assigned to both t",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/600#issuecomment-740363115:917,test,test,917,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/600#issuecomment-740363115,2,['test'],['test']
Testability,"Hi @rfarouni ,. Thanks for the detailed answer.; > I am not sure why the ISF option didn't work, but probably it has something to do with the guide sequences I was provided. At any rate, I have a few other questions I hope you can help me answer. I'm not sure about this, it's possible if the guide sequences were already reverse-complemented then the above behavior would makes sense. I am a little less familiar with the guideRNA based ECCITE-seq data, although the mRNA library should be 5' and the sequence does come from forward strand but do we expect the guide RNA to be on the forward strand as well ? Unclear . I'll ask around at nygc and would let you know. > Why does increasing --maxNumBarcodes to 200000 results in no barcodes getting corrected? (See log for Run 2 below). What is the rationale for the current default of 100000?. That's again a great question. In short single-cell world is expanding rapidly and alevin was initially designed to work with 10x 3' data and some of the restriction are outdated with combinatorial indexing based multiplexed experiments. To be honest, 100k was just a random high enough number that was put down to throw away the obvious junk data. Having said that, you would notice that in both the logs you attached a significant fraction of barcodes are thrown away i.e., `Skipped 82268 barcodes due to No mapped read`, which is like ~82% of the 100k barcodes. Even if you include the 200k almost everything was thrown away, `[warning] Skipped 184123 barcodes due to No mapped read`. Although your point is important one why things are not getting sequence corrected with 200k, unfortunately I might have to do some more testing on that front to give more precise answer but in your case I'd advise keeping the default 100k bound, unless you are doing combinatorially-indexed data . > For the downstream analysis of such data, I usually work with both the read and UMI counts, but quants_mat.gz only contains the UMI counts. Can Alevin a produce a matri",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-639048052:764,log,log,764,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-639048052,2,['log'],['log']
Testability,"Hi @rmurray2,. Thank you for the report. First, I just want to mention that I don't believe v0.99.0 to be an officially released version number. That is, there was a v0.14.x and a (released in source only v0.15.0), and then the versions moved to 1.0.0 and beyond. However, this behavior certainly isn't related to that. There are 2 things going on that can lead to this effect. The first one, which is relatively easy to test, is that there may be small changes in when the inferred library type starts to be enforced (if it is not `IU`) when auto type detection is used (see [this issue and comments therein](https://github.com/COMBINE-lab/salmon/issues/489)). The second and more fundamental thing going on is that the observed behavior is intended. Even with a single thread of execution provided to salmon for mapping and quantification, there is a separate background thread that simply consumes reads from file and puts them in memory for quantification, and while e.g. pairing information between files is guaranteed to be preserved, exact read order is not. This can lead to differences in the order in which reads are processed and, as a result, differences in the initialization conditions of the optimization. The ultimate result is that for transcripts that have large inferential uncertainty, different numbers of reads can be assigned between runs. We have thought *a lot* about this behavior, what it means, and how the `NumRead` values should best be communicated to users. At the end of the day, the `NumReads` constitute the expected value of latent variables inferred in a _very_ high-dimensional space (# of parameters is at least the number of transcripts). Therefore, there are certain transcripts, whose estimated number of reads simply have _tremendous_ inferential uncertainty — and small perturbations in the initial conditions of the optimization will lead to different estimated values for their abundances. For those transcripts where you observe such fluctuations between",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/613#issuecomment-757989858:421,test,test,421,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/613#issuecomment-757989858,2,['test'],['test']
Testability,"Hi @rob-p , @mdshw5 , . I did a local run, it crashed again, but now at least with some more information and a core dump. ; So the process failed with this error:; ```; /bin/bash: line 1: 31345 Aborted (core dumped) /home/agosdsc/pigx/pigx_rnaseq/.guix-profile/bin/salmon quant -i /scratch/AG_Akalin/agosdsc/projects/mrg1_rnaseq/analysis_v2/salmon_index -l A -p 8 -1 /scratch/AG_Akalin/agosdsc/projects/mrg1_rnaseq/analysis_v2/trimmed_reads/N2_1_R1.fastq.gz -2 /scratch/AG_Akalin/agosdsc/projects/mrg1_rnaseq/analysis_v2/trimmed_reads/N2_1_R2.fastq.gz -o /scratch/AG_Akalin/agosdsc/projects/mrg1_rnaseq/analysis_v2/salmon_output/N2_1 --seqBias --gcBias -g /data/akalin/Base/Annotation/ce11/ENSEMBL91/Caenorhabditis_elegans.WBcel235.91.gtf >> /scratch/AG_Akalin/agosdsc/projects/mrg1_rnaseq/analysis_v2/logs/salmon_quant_N2_1.log 2>&1; ```; I uploaded the files and the dump, such that you can try to debug this: ; https://1drv.ms/f/s!AqRdeUKlw8lFjDV7eDqqQbN7cQPa",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/210#issuecomment-377190490:802,log,logs,802,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/210#issuecomment-377190490,2,['log'],"['log', 'logs']"
Testability,"Hi @rob-p , thank you for so quick response. I spent some time organizing my demo data. Here is link for demo: ftp://bioinfo.noble.org/pub/for-github/. Two genes, with transcript name MSAD_157177.t1 and MSAD_200218.t1, get significantly different expression value in two runs, although they are almost identical. . Below are NumReads from Salmon:; ```; runA runB; MSAD_200218.t1 636.8 12201.2; MSAD_157177.t1 9307.1 0.8; ```. I agree with the necessity of allocating mulit-mapping reads. However, our problem is MSAD_157177.t1 received most of mapping reads in runA (9307 vs 636) but lost all of mapping reads in runB (0.8 vs 12201). And MSAD_200218.t1 has totally opposite result. Such different behavior for two genes make downstream Deseq2 reported both genes as significantly DE genes across samples but we know it is false result. Look at histogram.jpg , you will find it is pretty common phenomena over samples in terms of normalized RPKM. . I did a quick test for runB using eXpress, here is eff_counts:; ```; MSAD_200218.t1 5406; MSAD_157177.t1 3990; ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/107#issuecomment-263783167:962,test,test,962,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/107#issuecomment-263783167,1,['test'],['test']
Testability,"Hi @rob-p ,. It works! Thank you so much!; I tried all of the k-mer values in your advice (19, 21, 23, 25) for building indices and set the `--minAssignedFrags` parameter rather small to 3 and got a pretty nice mapping rate. And among them `-k` of 19 seemed to have the highest mapping rate. . Please let me know if anything looks abnormal!. Here is the command I used for indexing (same for `-k` = 19, 21, 23, 25):. `salmon index -t gencode.v40.transcripts.fa.gz -k 19 -p 12 -i salmon_index_19 --gencode`. And here is my command for quantification:. `salmon quant -i ../ref/salmon_index_19 -l IU -1 SRR493372_1.fastq SRR493373_1.fastq SRR493374_1.fastq SRR493375_1.fastq SRR493376_1.fastq SRR493377_1.fastq -2 SRR493372_2.fastq SRR493373_2.fastq SRR493374_2.fastq SRR493375_2.fastq SRR493376_2.fastq SRR493377_2.fastq --validateMappings --minAssignedFrags 3 -o transcripts_quant_19`. And the log file for indexing:. > [2022-04-16 11:15:45.756] [jLog] [info] building index ; out : salmon_index_23 ; [2022-04-16 11:15:45.778] [puff::index::jointLog] [info] Running fixFasta [Step 1 of 4] : counting k-mers ; [2022-04-16 11:15:46.377] [puff::index::jointLog] [warning] Entry with header [ENST00000682202.1|ENSG00000243480.8|OTTHUMG00000011023.3|-|AMY2A-204|AMY2A|19|processed_transcript|], had length less than equal to the k-mer length of 23 (perhaps after poly-A clipping) [2022-04-16 11:15:49.574] [puff::index::jointLog] [warning] Entry with header [ENST00000603775.1|ENSG00000271544.1|OTTHUMG00000184300.1|OTTHUMT00000468575.1|ENST00000603775|ENSG00000271544|23|processed_pseudogene|], had length less than equal to the k-mer length of 23 (perhaps after poly-A clipping) [2022-04-16 11:15:52.071] [puff::index::jointLog] [warning] Entry with header [ENST00000632684.1|ENSG00000282431.1|OTTHUMG00000190602.2|OTTHUMT00000485301.2|TRBD1-202|TRBD1|12|TR_D_gene|], had length less than equal to the k-mer length of 23 (perhaps after poly-A clipping) [2022-04-16 11:15:55.682] [puff::index::jointLog] [w",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/768#issuecomment-1100734317:893,log,log,893,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/768#issuecomment-1100734317,1,['log'],['log']
Testability,"Hi @rob-p ,. thank you very much for your quick and detailed answer. I really appreciate that you will include this feature in your next release.; Indeed, I'm interested in testing out your suggested script/tool !. Best,; Jan",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/108#issuecomment-264812173:173,test,testing,173,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/108#issuecomment-264812173,1,['test'],['testing']
Testability,"Hi @rob-p ,; After removing ""-pg"" flag in ""salmon/external/pufferfish/CMakeLists.txt"", it's able to be compiled successfully now using Debug mode. To reproduce (in salmon/build directory):; ISSUE 1: The second test failed, I'm wondering whether this should happen or not.; > /root/cmake-3.13.4-Linux-x86_64/bin/cmake -DFETCH_BOOST=TRUE -DTBB_INSTALL_DIR=/usr/include -DCMAKE_BUILD_TYPE=Debug -DNO_IPO=TRUE -DCMAKE_INSTALL_PREFIX=../stage ..; > make // to get /root/salmon/external/pufferfish/CMakeLists.txt file; > vim /root/salmon/external/pufferfish/CMakeLists.txt // remove the ""-pg"" flag on line 131 ; > make // successfully compiled after removing ""-pg"" flag; > make install ; > make test; ![second_test_failed](https://user-images.githubusercontent.com/24876498/103263448-e4809280-49e2-11eb-9be9-7bbedfa2f1a5.png). (in /mammoth/salmon_data directory):; ISSUE 2: segmentation fault occurs after ""wrote [count] cleaned references"" (the same place as Release mode); > /root/salmon/stage/bin/salmon index -t gentrome.fa.gz -d decoys.txt -p 12 -i salmon_index --gencode (data from your tutorial https://combine-lab.github.io/alevin-tutorial/2019/selective-alignment/); ![image](https://user-images.githubusercontent.com/24876498/103263653-75576e00-49e3-11eb-9661-abd69de73a5e.png). gdb /root/salmon/stage/bin/salmon core.23591; (it seems to crash at cereal::OutputArchive, fixFasta, fixFastaMain, etc.); ![image](https://user-images.githubusercontent.com/24876498/103263925-2100be00-49e4-11eb-8918-01f9adf52d98.png)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/609#issuecomment-751968056:210,test,test,210,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/609#issuecomment-751968056,2,['test'],['test']
Testability,"Hi @rob-p ,; thank you for your help. I got my hands on this kind of data for the first time today and followed the tutorial <https://combine-lab.github.io/alevin-fry-tutorials/2022/split-seq/> to test my data, but following the tutorial I ended up with a matrix file, doesn't seem to generate the file alevin_out/aux_info/alevin_meta_info.json, I actually want to get a report like 10X cellranger summary.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/774#issuecomment-1126090795:197,test,test,197,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/774#issuecomment-1126090795,1,['test'],['test']
Testability,"Hi @rob-p . Before I answer your question and layout my logic, I want to mention that I am **_not_** suggesting fastp is not doing its job, **_neither am I stating that fastp is working incorrectly_**. Now to my answer(s) and logic:; 1. With fastp, I am not sure if adapter trimming happens first and then quality trimming OR vice-versa. I could not find info on this from their README and **_I could be wrong here with my next line_** - [Based on Figure 1 of this paper, it looks to me as though quality trimming is done before adapter trimming](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6129281/figure/bty560-F1/). - [To quote Brian Bushnell (author of BBTools)]( http://seqanswers.com/forums/showpost.php?p=140819&postcount=5), . > It's best to do adapter-trimming first, then quality-trimming, because if you do quality-trimming first, sometimes adapters will be partially trimmed and become too short to be recognized as adapter sequence. When you run BBDuk with both quality-trimming and adapter-trimming in the same run, it will do adapter-trimming first, then quality-trimming. 2. I very well know that the advantage of using fastp is that it can do adapter trimming, etc in a automatic fashion - no need to provide external sequences (example adapter sequences). Yes, I know one can also provide a fasta file of adapters and fatsp will work off it. There are many fatsp issues in GH about adapter detection:. - fail to detect adpaters automatically - (https://github.com/OpenGene/fastp/issues/222 and https://github.com/OpenGene/fastp/issues/205). - [incorrect automatic adapter detection](https://github.com/OpenGene/fastp/issues/240). - [inconsistent behavior with different runs](https://github.com/OpenGene/fastp/issues/231). 3. When I see the above, I am bit skeptical using fastp for qc/adapter trimming. . After lot of trials with bbduk and fastp, I have decided to use bbduk and bbmap for my high throughput analysis. Below, I explain my reasoning behind those choices: . **_```Not",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-597393209:56,log,logic,56,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-597393209,4,['log'],['logic']
Testability,"Hi @rob-p . Sorry, but we couldn't test again the index I used to report the issue. Instead, we used a smaller one with the following characteristics:. ```; counted k-mers for 16040000 transcripts; Elapsed time: 726.738s. Replaced 5730782 non-ATCG nucleotides; Clipped poly-A tails from 530 transcripts; Building rank-select dictionary and saving to disk done; Elapsed time: 13.1116s; Writing sequence data to file . . . done; Elapsed time: 118.505s; [info] Building 64-bit suffix array (length of generalized text is 12671064288 ); Building suffix array . . . success; saving to disk . . . done; Elapsed time: 877.586s; done; Elapsed time: 3607.17s; processed 12671000000 positions; khash had 5905993560 keys; saving hash to disk . . . done; Elapsed time: 1249.59s; [2017-03-22 06:39:06.131] [jLog] [info] done building index; ```. Using this new index and salmon v0.8.2 precompiled binaries we didn't have any problems. Hope this helps. Thanks!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/129#issuecomment-288675236:35,test,test,35,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/129#issuecomment-288675236,1,['test'],['test']
Testability,Hi @rob-p . _**Salmon index command used**_; ```; salmon index -t rnor_gentrome.fa -d decoys.txt -k 17 --keepFixedFasta --keepDuplicates -p 16 -i rnor_ENSEMBL_96_index; ```. **_Directory size after indexing completes_**; ```; du -sh .; 45G; ```. **_Listing of files and their sizes_**; ```; 4.2K ref_indexing.log; 115 pre_indexing.log; 126 versionInfo.json; 944M mphf.bin; 6.0G pos.bin; 1004 info.json; 256K refAccumLengths.bin; 701M refseq.bin; 15G ctable.bin; 2.5G ctg_offsets.bin; 128K reflengths.bin; 2.9G seq.bin; 1.5G rank.bin; 128K complete_ref_lens.bin; 2.8G ref_k17_fixed.fa; 22K duplicate_clusters.tsv; ```,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/505#issuecomment-613224352:309,log,log,309,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/505#issuecomment-613224352,2,['log'],['log']
Testability,"Hi @rob-p ; I did use the pre-compiled binaries and the system I use is ubuntu 14.04.; Hmm.. even with the change you wrote, I seem to be getting similar results.; Does the order of parameters matter? I.e. in my command line, should I put -o first and then --writeMappings?. EDIT: Sorry, actually this might have worked, it's just that my read files were too big, and the run didn't actually even finish because I ran out of memory, and at the time of run cancellation I didn't see the resulting file (but all the other files Salmon output files were present) so I assumed it hasn't even been generated. My command-line window also froze up, so I couldn't see if what the stdout looked like. ; I'll definitely re-test when I find smaller files. . EDIT2: Ok, so I retested with smaller files, the run was successful, but still no resulting file. I'll be rechecking this for any mistakes, if I did something wrong. Here's the logs in case it means anything:. Version Info: This is the most recent version of Salmon.; salmon (mapping-based) v0.7.2; [ program ] => salmon; [ command ] => quant; [ index ] => { ucsc.hg19.transcriptome_salmon_index }; [ libType ] => { A }; [ mates1 ] => { reads.pe_1.fastq }; [ mates2 ] => { reads.pe_2.fastq }; [ output ] => { reads.pe_salmon_quant }; [ threads ] => { 2 }; [ auxDir ] => { aux_info }; [ writeMappings ] => { }; [ ] => { reads.pe.salmon_quant_mapping_info.sam }; Logs will be written to reads.pe_salmon_quant/logs",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/86#issuecomment-244780040:713,test,test,713,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/86#issuecomment-244780040,4,"['Log', 'log', 'test']","['Logs', 'logs', 'test']"
Testability,"Hi @rob-p ; So I tried testing again, running Salmon without any scripts, and again I keep having the same issue. The command line part with the parameter in question is (copy-pasted): ; ""--writeMappings test_output/mappings_info"" ; and the cmd_info.json file looks the same as before, with the """" key. ; Do I need to call that parameter differently, like --writeMappings=file_name, or...? ; If I did made some stupid mistake, sorry then upfront for wasting your time, in the meantime I'll try and test this a couple of more times in the next few days and try and see what's up.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/86#issuecomment-244903765:23,test,testing,23,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/86#issuecomment-244903765,2,['test'],"['test', 'testing']"
Testability,"Hi @rob-p! Thanks for all the great suggestions and comments. I have addressed all of them. I also tested the speed after the changes. The test was done 3 times in the same way as done earlier. . 1. `--sciseq3` ; ```; real 0m58.463s 0m57.884s 0m57.413s; user 7m0.652s 7m1.731s 7m1.278s; sys 0m3.305s 0m3.078s 0m2.665s; ```. 2. `--custom-geo`; ```; real 1m7.411s 1m14.988s 1m3.868s; user 8m8.795s 8m40.302s 7m49.107s; sys 0m4.194s 0m6.412s 0m2.969s; ```. The real time in case 1. was 57.92 ± 0.57s and for case 2. it was 68.75 ± 5.68s, which is about 19% slower.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/734#issuecomment-1023219391:99,test,tested,99,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/734#issuecomment-1023219391,2,['test'],"['test', 'tested']"
Testability,"Hi @rob-p, The version we see the fault on is Red Hat Enterprise Release 6.10 (Scientific linux). I have a version of ubuntu that I can test on but not sure when I can get around to it at the moment.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/337#issuecomment-458145886:136,test,test,136,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/337#issuecomment-458145886,1,['test'],['test']
Testability,"Hi @rob-p, thanks a lot for the detailed info - sounds great. I tried pretty much exactly what you proposed with 10k reads yesterday, and it only took a couple of seconds, so 100k seems like a great compromise to do this as fast and accurate as possible. We'll do some tests for this with different library types in the next couple of weeks (it's not super urgent for us) and we'll get back at you. Perhaps it's a use case of Salmon you would like to document for others as well... :)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/138#issuecomment-585837124:269,test,tests,269,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/138#issuecomment-585837124,1,['test'],['tests']
Testability,"Hi @rob-p,. I was finally able to grab some time to try running the beta version you linked (see attached logs). This certainly helped, although I'm still nowhere near a time-frame of ~30min. Here are my results:. The 31-mer running took a bit over an hour and consumed ~17GB of memory. This is about half the running time as the previous version, but approx. the same amount of memory requirement (more on that below). The 17-mer running, took 4.5hrs to complete and consumed ~64GB of memory. This particular running is again, about twice as fast, although the time really depends on the memory limitations I gave it. Since it appears that this version no longer crashes when given less than about 250GB of memory, I also tested with 32G and 16GB of memory, just to see what impact this would have on the times. Those jobs are still running (it's only been about 4hrs as of this writing, I'll update my post if/when they complete). Current logs are showing that they quickly consume all the available memory, but have not yet crashed. I've also got versions with 128-512GB of memory requested (by powers of 2) for comparison. Some random notes: both the 31-mer index experienced about twice as many soft page reclaims with the new/faster version and experienced a few hard page faults (the previous version saw none of the latter). The 17-mer version experienced fewer page reclaims than any of the 31-mer indices and far fewer than with the prior version. Again, a few page faults crept in, but relatively few by percentage and likely not contributing any significant amount of time overall. [index-qacct-17mer.log](https://github.com/COMBINE-lab/salmon/files/4246516/index-qacct-17mer.log); [index-qacct-31mer.log](https://github.com/COMBINE-lab/salmon/files/4246517/index-qacct-31mer.log). **UPDATE**; The 16GB version finished running. It actually only took a little over 4 hours to run, as well. The troubling thing about this job seems to be that, despite having successfully completed, accordi",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/476#issuecomment-590516702:106,log,logs,106,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/476#issuecomment-590516702,3,"['log', 'test']","['logs', 'tested']"
Testability,"Hi @rob-p,. Thank you for your reply.; It's a BWA-mem2 aligment with this command:. ```; ""bwa-mem2 mem -M -t {threads} -v 2 {input.reference} {input.reads} | samtools view -q 20 -F 3844 --threads {threads} -Sb -> {output.inter_bam} && ""; ""samtools sort -@ {threads} -O bam {output.inter_bam} > {output.final_bam} && samtools index -@ {threads} {output.final_bam} && samtools flagstat {output.final_bam} > {output.flag} ""; ```; I don't if it's because I use BWA which is a non-splicing aligner? Or because I sorted my BAM file?; I am developing a pipeline and the first step is to test the data with bwa-mem2 with salmon. Is it really a problem to use the results with the MU lib? The 60% may be wrong and reflect alignments that don't exist and ignore good alignments because of the wrong lib?. ### Edit. I tried to do the mapping and the aligment with salmon:; ```. {; ""read_files"": ""[ ../results/trimmed/3373-1_CCGCGGTT-CTAGCGCT-AHV5HLDSXY_L004_R1_trimmed.fastq.gz, ../results/trimmed/3373-1_CCGCGGTT-CTAGCGCT-AHV5HLDSXY_L004_R2_trimmed.fastq.gz]"",; ""expected_format"": ""ISR"",; ""compatible_fragment_ratio"": 1.0,; ""num_compatible_fragments"": 35843765,; ""num_assigned_fragments"": 35843765,; ""num_frags_with_concordant_consistent_mappings"": 29709658,; ""num_frags_with_inconsistent_or_orphan_mappings"": 6209768,; ""strand_mapping_bias"": 0.000008381042727599249,; ""MSF"": 0,; ""OSF"": 0,; ""ISF"": 249,; ""MSR"": 0,; ""OSR"": 0,; ""ISR"": 29709658,; ""SF"": 2520360,; ""SR"": 3689159,; ""MU"": 0,; ""OU"": 0,; ""IU"": 0,; ""U"": 0; }; ```; It's the ISR library but I have only 40% of mapping , it's really confusing.... Best,; Kisekya",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/676#issuecomment-866187414:580,test,test,580,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/676#issuecomment-866187414,1,['test'],['test']
Testability,"Hi @rob-p,. Thanks for the prompt response. I think I may have realised my mistake. It seems like a silly mistake where I wasn't, in fact, using the same version of salmon for the indexing and quantification. . Also yes they would have been running on different machines. I will try to test this and get back to you.; Thanks again",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/345#issuecomment-466130305:286,test,test,286,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/345#issuecomment-466130305,1,['test'],['test']
Testability,"Hi @rob-p,. Thanks for the speedy reply! There are definitely some strange things going on here. I can confirm that the second run (and the others that timed out) didn't produce any information about mapping. The outdir only contained empty subdirs + an empty log file:. ![image](https://user-images.githubusercontent.com/11418858/220816388-0a6272d4-a0c8-4e26-bf9f-15afda61cc44.png). 1. Thanks for the suggestion, I've now been investigating the potential of an index-related issue. Firstly, I downloaded the pre-built salmon index from refgenie using `refgenie pull hg38/salmon_sa_index`. I then ran `salmon quant` using this index and the singularity image of salmon v1.9.0. What, would you know: it worked in about 11 minutes. ```; <truncated>; [2023-02-23 14:46:31.892] [jointLog] [info] Aggregating expressions to gene level; [2023-02-23 14:46:32.452] [jointLog] [info] done; ```. This pre-built index does appear to be decoy-aware:. ```; [2023-02-23 14:38:21.709] [jointLog] [info] Number of decoys : 195; [2023-02-23 14:38:21.709] [jointLog] [info] First decoy index : 177412 ; ```. Secondly, I created a new transcriptome-only salmon index (`singularity run -B /data $SALMON_SIMG salmon index -t genome.transcripts.fa -i salmon_index -k 31`), then ran `salmon quant` again (as above) but using the new transcriptome-only index. Note: 'genome.transcripts.fa' is the transcripts file created during the `nf-core/rnaseq` pipeline. Again, this analysis completed properly in a reasonable time. Seems like there is something very wrong with the 'gentrome.fa' file that's being created by `nf-core/rnaseq`! It's just so odd that _some_ samples would work and others wouldn't. 2. It's definitely worth noting that I originally opted against using `star_salmon` with the following command:. ```; nextflow run nf-core/rnaseq --max_memory 55.GB --fasta /data/reference_genomes/GRCh38/Homo_sapiens.GRCh38.dna_sm.primary_assembly.fa.gz --gtf /data/reference_genomes/GRCh38/Homo_sapiens.GRCh38.106.gtf.gz -",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/830#issuecomment-1441194948:260,log,log,260,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/830#issuecomment-1441194948,1,['log'],['log']
Testability,"Hi @rob-p,. We ran the tests you requested and the main problem remains. The memory load is lower than before, but for some reason `Salmon` (0.8.2) only works in the SGE cluster we have access to when we increase the memory limits (just like 0.7.2). (Edit: we used 0.8.2 to build a new index). I'll ask the cluster admins as they might have a clue on how to proceed. ## Low memory test. ### bash script. ```bash; #!/bin/bash; #$ -cwd; #$ -l mem_free=14G,h_vmem=15G,h_fsize=100G; #$ -N step6-salmon_test3.gsk_phaseII; #$ -pe local 1; #$ -o ./logs/salmon_test3.$TASK_ID.txt; #$ -e ./logs/salmon_test3.$TASK_ID.txt; #$ -t 1-3; #$ -hold_jid pipeline_setup,step4-featCounts-alzheimer.gsk_phaseII; #$ -m e; echo ""**** Job starts ****""; date. echo ""**** JHPCE info ****""; echo ""User: ${USER}""; echo ""Job id: ${JOB_ID}""; echo ""Job name: ${JOB_NAME}""; echo ""Hostname: ${HOSTNAME}""; echo ""Task id: ${TASK_ID}"". FILE1=$(awk 'BEGIN {FS=""\t""} {print $1}' /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk ""NR==${SGE_TASK_ID}""); if [ TRUE == ""TRUE"" ] ; then; FILE2=$(awk 'BEGIN {FS=""\t""} {print $3}' /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk ""NR==${SGE_TASK_ID}""); fi; ID=$(cat /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk '{print $NF}' | awk ""NR==${SGE_TASK_ID}""). mkdir -p /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test3/${ID}. /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon quant 	-i /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts -p 1 -l ISR 	-1 ${FILE1} -2 ${FILE2} 	-o /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test3/${ID}. echo ""**** Job ends ****""; date; ```. ### Example log file. ```; **** Job starts ****; Wed Mar 29 14:51:10 EDT 2017; **** JHPCE info ****; User: lcollado; Job id: 110315; Job name: step6-salmon_test3.gsk_phaseII; Hostname: compute-061; Task id: ; Version Info: This is the most recen",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-290516965:23,test,tests,23,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-290516965,4,"['log', 'test']","['logs', 'test', 'tests']"
Testability,"Hi @rob-p,. i have pasted the three .json file data below. The way i installed was by first installing boost (./bootstrap.sh --prefix=/usr/local), and setting up boost. I did install clang 3.9 too. Then i did use ; cmake -DBOOST_ROOT=/usr/local, make and sudo make install and make test. Then i copied the executable made in bin to /usr/local/bin as sudo. May be it's me using sudo make install which is goofing stuff.. Let me try to reinstall without ""sudo"". I have used salmon 0.8.1, with no problems on another machine. So, on this machine this is a fresh install. I do think there is a script which does fetch Rapmap.. Thanks. Sudeep. #header.json. ""value0"": {; ""IndexType"": 1,; ""IndexVersion"": ""q5"",; ""UsesKmers"": true,; ""KmerLen"": 31,; ""BigSA"": false,; ""PerfectHash"": false,; ""SeqHash"": ""bc7ce7a64f79aeb355818ffc5050bf682f281160738498d11dbc3330b67c4889"",; ""NameHash"": ""3843f236fc87b02e5c477daa29053725d376d8725c10ec23ee2225e8fab6326e""; }; }. #refino.json; {; ""ReferenceFiles"": [; ""Equus_caballus.EquCab2.cds.all.fa""; ]; }. #versioninfo.json. {; ""indexVersion"": 2,; ""hasAuxIndex"": false,; ""auxKmerLength"": 31,; ""indexType"": 1; }",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/135#issuecomment-299885992:282,test,test,282,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/135#issuecomment-299885992,1,['test'],['test']
Testability,"Hi @rob-p,; I am aware of that, but we were off on bwa anyway. I decided to follow your advice and used STAR with this order:. ` ""STAR --runThreadN {threads} --runMode alignReads --genomeDir {input.ref} --readFilesIn {input.fq1} {input.fq2} --readFilesCommand zcat --outSAMtype BAM Unsorted SortedByCoordinate --quantMode TranscriptomeSAM GeneCounts --outFileNamePrefix {output} --outStd Log {log} ""`. I then got this final.out:; ```. Started job on |	Jul 05 07:51:09; Started mapping on |	Jul 05 07:51:13; Finished on |	Jul 05 10:01:38; Mapping speed, Million of reads per hour |	39.36. Number of input reads |	85547657; Average input read length |	298; UNIQUE READS:; Uniquely mapped reads number |	36980651; Uniquely mapped reads % |	43.23%; Average mapped length |	283.47; Number of splices: Total |	943061; Number of splices: Annotated (sjdb) |	0; Number of splices: GT/AG |	411198; Number of splices: GC/AG |	39101; Number of splices: AT/AC |	13983; Number of splices: Non-canonical |	478779; Mismatch rate per base, % |	0.56%; Deletion rate per base |	0.03%; Deletion average length |	4.89; Insertion rate per base |	0.03%; Insertion average length |	4.88; MULTI-MAPPING READS:; Number of reads mapped to multiple loci |	1029261; % of reads mapped to multiple loci |	1.20%; Number of reads mapped to too many loci |	565; % of reads mapped to too many loci |	0.00%; UNMAPPED READS:; Number of reads unmapped: too many mismatches |	0; % of reads unmapped: too many mismatches |	0.00%; Number of reads unmapped: too short |	47533174; % of reads unmapped: too short |	55.56%; Number of reads unmapped: other |	4006; % of reads unmapped: other |	0.00%; CHIMERIC READS:; Number of chimeric reads |	0; % of chimeric reads |	0.00%. ```. I filtered it by samtools -f 2 -F 3840 . and Salmon gave me this result which is still very weak: 24323638 counts. So I decided to reduce the parameters as indicated in this link: https://github.com/alexdobin/STAR/issues/169; Because I trimmed my sequence and some ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/676#issuecomment-874540664:388,Log,Log,388,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/676#issuecomment-874540664,3,"['Log', 'log']","['Log', 'log']"
Testability,"Hi @rob-p. I'm using a SGE-based cluster. The disk I'm writing to is a networked disk that is mounted via NFS on the machines the cluster runs on. I've attached the output of running `qconf -sconf`, which provides details on how the cluster has been configured (I've edited out some lines about the admin e-mails, etc.). I'm not sure how useful much of this information is. A lot of it has to do with scheduling of jobs -- how many jobs/resources users can attempt to claim, that kind of thing. Let me know if there's something else that would be more useful in this context. I've also attached the log that was generated by the indexing run itself (just for the 17mer index), just in case. I can say one thing from having inspected the logs of these things failing a number of times before I finally caved and started giving it insane amounts of memory: by far the longest time and (most likely) the biggest resource hog is between the first and second pass. Even with only 16GB, it manages to complete the first pass (it still takes quite a while, though):. ```; Pass	Filling	Filtering; 1	718	3236	; 2	1839	237; ```. [qconf-sconf.txt](https://github.com/COMBINE-lab/salmon/files/4172585/qconf-sconf.txt); [index_GRCm38_GENCODE_M23_PRI_17mer.log.txt](https://github.com/COMBINE-lab/salmon/files/4172594/index_GRCm38_GENCODE_M23_PRI_17mer.log.txt). EDIT: Oh, I should also probably say, that I'm only seeing this slowdown on index creation. I'm sure that was implied, but I just wanted to be clear that at the moment, I'm happy enough to let the index build for a few hours every once in a while. I'm still saving huge amounts of mapping time, relative to ""full"" aligners.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/476#issuecomment-583567362:599,log,log,599,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/476#issuecomment-583567362,8,['log'],"['log', 'logs']"
Testability,"Hi @ryanpe13002,. The bootstrap has no effect on the main `quant.sf` file (that is always the result of the main maximum likelihood estimate). All bootstrap samples are written to the `bootstraps.gz` file. If you load your data with the `fishpond` package in `R`, you can request to load the bootstraps to investigate them. Otherwise, if you use an uncertainty aware tool like [`swish`](https://bioconductor.org/packages/release/bioc/vignettes/fishpond/inst/doc/swish.html) for differential testing, it will make use of the bootstraps automatically to account for inferential uncertainty when performing differential testing. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/818#issuecomment-1354070141:491,test,testing,491,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/818#issuecomment-1354070141,2,['test'],['testing']
Testability,"Hi @s1corley,. Congratulations on your publication! The `--noLengthCorrection` flag has been around for a long time (e.g. where it is suggested in the post to which @tamuanand [links](https://groups.google.com/forum/#!msg/sailfish-users/VIfqBwgF6xQ/fw-rgC_kAwAJ)). However, given our limited access to QuantSeq and our limited (student) bandwidth to do extensive testing on alternative tech, we have kept this flag marked as experimental. As I mention above, it was introduced since, _conceptually_, the QuantSeq protocol should not exhibit a length effect and so the one may not wish to account for the length when determining assignment probabilities during the variational Bayesian optimization. However, the empirical testing of this has been limited. Now that your paper is published, and contains what look to be some _very through_ assessment methodologies, we may be able to look into this and determine if there is anything we can do to, perhaps, optimize salmon even more for accurate quantification from the QuantSeq protocol. We would welcome any suggestions or feedback you may have. Congratulations again on the paper!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-565474848:363,test,testing,363,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-565474848,4,['test'],['testing']
Testability,"Hi @schelhorn,. Yes; we are _actively_ looking at fusion prediction based on quasi-mapping. The initial results are promising, but we're still working on improving and refining the method. I'll be sure to let you know when we have something that is ready to test :). Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/52#issuecomment-202593692:258,test,test,258,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/52#issuecomment-202593692,1,['test'],['test']
Testability,"Hi @seanken,. Thank you for reporting this. I agree this error message should always show up. My guess is that this is related to the fact that the error is reported through the asynchronous logger, which is notoriously picky about how it must be torn down to avoid dropping messages on atypical (non-zero) program exit. I'll see if I can make this one show up reliably. By the way, do you have a small pair of FASTQ files that will trigger this error?. Thanks,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/736#issuecomment-1018119606:191,log,logger,191,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/736#issuecomment-1018119606,1,['log'],['logger']
Testability,"Hi @shalercr,. Thanks for reporting back! I agree that there are some challenging reads in these samples that are likely at the root of the slightly-longer-than-normal runtime. If you could upload the quant dir for this sample (that contains the logs), that would be useful. We (specifically, my student @mohsenzakeri, who is one of the main developers of the new selective-alignment algorithm) can poke around a bit to see if there is anything strange going on that can be characterized, but it might just be an inherent property of samples with very repetitive reads. Regardless, we'll be happy to take a look. Thanks!. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/537#issuecomment-645122746:246,log,logs,246,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/537#issuecomment-645122746,1,['log'],['logs']
Testability,"Hi @sjackman , Thanks for you question. It is indeed a good observation to use salmon for combining separate CB and read-sequence fastq files.; Having said that, we have designed alevin to work with, and tested it on 10x-chromium `cellranger` pipeline which itself has a feature similar to mentioned above by you (enabled by flag `--dumpfq`). This feature takes in two separate files: one with CB+UMI and another with read-sequence, and performs initial whitelisting (knee based , more intelligent whitelisting happens downstream and needs deduplicated UMI counts or one can just optionally provide external whitelist), error corrects the CB, attaches it to the header (although not with tag `BX:Z`) of the read-sequence in the second file, and dumps it to the standard out. I might have to read a bit about `longranger` and its `FASTQ` format, but if you are familiar with the `longranger` pipeline and are sure that it uses 16+10 (CB+UMI) in one file and read-sequence in the second file, then I think you are good to try alevin with `--dumpfq` flag. Let us know how it goes and if you face any problem. . Note: Just put an extra flag `--noQuant` so that alevin knows to stop after dumping the fastq otherwise it will start performing downstream tasks.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/233#issuecomment-395174284:204,test,tested,204,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/233#issuecomment-395174284,1,['test'],['tested']
Testability,"Hi @sudeep71 ,. Can you try `--decoys` I think there is one `-` is missing from the command line argument or just use `-d`. If this doesn't work can you share the logs ?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/389#issuecomment-506494653:163,log,logs,163,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/389#issuecomment-506494653,1,['log'],['logs']
Testability,"Hi @summerrfair,. So, your BAM file looks like a SAM file (which is still OK), *but*, it's missing a header. I'm attaching here a sample SAM file you can use with the test data from the repository. Note, this SAM file is zipped (GitHub made me zip it before attaching it, so unzip it before you process it):. [sample_alignments.sam.zip](https://github.com/COMBINE-lab/salmon/files/4510467/sample_alignments.sam.zip). Once you've unzipped this file, you can run salmon as:. ```~bash; ./bin/salmon quant -l IU -t transcripts.fa -a sample_alignments.sam -o quant_directory; ```. where the `transcripts.fa` is the sample transcriptome distributed with salmon that you can get by unzipping this file : [transcripts.fasta.zip](https://github.com/COMBINE-lab/salmon/files/4510488/transcripts.fasta.zip). When I run this with the latest salmon, I get the following output:. ```; # salmon (alignment-based) v1.2.0; # [ program ] => salmon; # [ command ] => quant; # [ libType ] => { IU }; # [ alignments ] => { sample_alignments.sam }; # [ targets ] => { ../sample_data/transcripts.fasta }; # [ output ] => { sample_aln_quant }; Logs will be written to sample_aln_quant/logs; Library format { type:paired end, relative orientation:inward, strandedness:unstranded }; [2020-04-21 10:11:42.553] [jointLog] [info] setting maxHashResizeThreads to 8; [2020-04-21 10:11:42.553] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2020-04-21 10:11:42.553] [jointLog] [info] numQuantThreads = 4; parseThreads = 4; Checking that provided alignment files have consistent headers . . . done; Populating targets from aln = ""sample_alignments.sam"", fasta = ""../sample_data/transcripts.fasta"" . . .done; [2020-04-21 10:11:43.180] [jointLog] [info] replaced 0 non-ACGT nucleotides with random nucleotides. processed 0 reads in current round; killing thread 3 . . . done. Freeing memory used by read queue . . . 00; Joined parsing thread . . . ""sample_alignments.sam""; Cl",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/511#issuecomment-617206094:167,test,test,167,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/511#issuecomment-617206094,1,['test'],['test']
Testability,"Hi @tamuanand,. Ok, it seems something simple with the preparation of the decoys.txt file. I'm looking into it. If you watch the log, you see the following output before the (intentional exit with status code 1):. ```; [2020-04-14 09:44:12.991] [puff::index::jointLog] [critical] The decoy file contained the names of 955 decoy sequences, but 953 were matched by sequences in the reference file provided. To prevent unintentional errors downstream, please ensure that the decoy file exactly matches with the fasta file that is being indexed.; [2020-04-14 09:44:13.304] [puff::index::jointLog] [error] The fixFasta phase failed with exit code 1; Command exited with non-zero status 1; 56.66user 9.14system 1:04.69elapsed 101%CPU (0avgtext+0avgdata 6902936maxresident)k; 3792inputs+16outputs (30major+3629051minor)pagefaults 0swaps; ```. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/505#issuecomment-613451792:129,log,log,129,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/505#issuecomment-613451792,2,['log'],['log']
Testability,"Hi @tamuanand,. Sure; is there anything specific about bbduk and bbmap for quality / adapter trimming that you think would be provided beyond or in addition to what fastp provides? Also, we have a beta implementation of soft-clipping and are looking for a wide net of testing data. Any suggestions to that end would be welcome!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-597344801:268,test,testing,268,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-597344801,1,['test'],['testing']
Testability,"Hi @tamuanand,. Thanks again for your detailed questions and thoughts on this issue. Just to follow-up / expand a bit on what @k3yavi has said (and to answer your other question): Yes, one would imagine that, given the details of the QuantSeq protocol, turning off length correction would make the most sense. The main reason this flag is listed as _experimental_, is simply that it was designed based on the expected characteristics of the protocol. Conceptually, the protocol is performing tagged-end sequencing, and so there should be little-to-no length effect. However, since we haven't done extensive internal validation on QuantSeq data, we have left this flag as experimental until it is further tested by ourselves or others. > Also @rob-p , weren't you referring to the RSEM caveat with QuantSeq data analysis wherein one cannot ask RSEM to disable lengthCorrection and hence the count statistics might be misleading?. Correct; as far as we are aware, there is no way to disable the built-in length-dependent assumptions of RSEM. One could use the `--estimate-rspd` flag to allow learning of a non-uniform read distribution (the equivalent of `--posBias` in salmon), though it's unclear / unlikely if this would be as effective as fully disabling the length correction for this type of tagged-end data. If you have any good empirical assessment mechanism for QuantSeq data, and a chance to test out these different salmon options, we'd be happy to get feedback and discuss details further!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-565285540:704,test,tested,704,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-565285540,4,['test'],"['test', 'tested']"
Testability,"Hi @taylorreiter,. First thing first — this sat for way too long before I got to it, so apologies for that!. So, the reason that they don’t show up in the unmapped.txt file is that is that reads mapped to decoys occupy a sort of “no man’s land” with respect to their mapping status. That is, they *do* map to the index, but just not to a valid target within the index. In other words, if you write a BAM output from `salmon`, the decoy aligned reads will actually show up there, with the information about the decoy to which they are aligned. This is because they are mapped to something in the index, it just happens to be a decoy rather than a “valid target”. However, the output BAM files are big, so I absolutely understand the desire to have them appear in the unmapped names list as well — it's a much smaller and easier thing to go through. I think the right thing to handle this would be to add a specific code/category to the set of unmapped codes used in the `unmapped.txt` file, to designate this is read best mapped to a decoy (rather than that this read is completely unmapped to the index). This shouldn't be too hard to do — I will try to find a few cycles to implement and test it. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/748#issuecomment-1098426758:1189,test,test,1189,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/748#issuecomment-1098426758,1,['test'],['test']
Testability,"Hi @teshomem,. If you want to proceed with transcript-level differential expression, _all transcripts are relevant_. That is, the relevant tools (e.g. DESeq2, limma-voom, Sleuth, etc.) will expect to be provided with _all_ quantified isoforms for each gene. They will then automatically apply their own filtering criteria to determine which transcripts to actually test for DE. . If you want to proceed with DE at the gene level (and hence want to aggregate the quantification information from the level of transcripts to genes), the easiest option is to use the [tximport](http://bioconductor.org/packages/release/bioc/html/tximport.html) package. It can import all of the quantifications from multiple runs of Salmon, aggregate them to the gene level, and produce a count matrix that can then be used with traditional count-based gene-level DE tools. I would recommend the pipeline Salmon => tximport => DESeq2 for gene-level DE analysis. Finally, the best place for questions like this, that don't have to do with a specific bug or feature request for the Salmon software, is the [Google user group](https://groups.google.com/forum/#!forum/sailfish-users). This way, other users will be more likely to provide you with feedback and help answer your questions.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/154#issuecomment-329974141:365,test,test,365,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/154#issuecomment-329974141,2,['test'],['test']
Testability,"Hi @tharvesh — The error suggests that memory allocation failed when trying to build the suffix array. I'm guessing from what I can tell from the log (e.g. the fact that the 64-bit index is being invoked, suggesting the input contains > 2^31 nucleotides), that you actually tried to build an index on the GENCODE **genome** plus a set of extra transcripts. Salmon (unlike Cufflinks, but like RSEM, TIGAR, eXpress, etc.) should be used with the **transcriptome**, not the **genome** of the target organism. That is, if you want to use GENCODE (say, in human), you should be indexing either (ftp://ftp.sanger.ac.uk/pub/gencode/Gencode_human/release_24/gencode.v24.transcripts.fa.gz) or (ftp://ftp.sanger.ac.uk/pub/gencode/Gencode_human/release_24/gencode.v24.pc_transcripts.fa.gz), not e.g. (ftp://ftp.sanger.ac.uk/pub/gencode/Gencode_human/release_24/GRCh38.primary_assembly.genome.fa.gz).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/39#issuecomment-176783177:146,log,log,146,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/39#issuecomment-176783177,1,['log'],['log']
Testability,"Hi @tillea and @nileshpatra, thanks for the report (and ping). Can you point me to a Docker / Singularity container of the relevant Debian build so I can try and reproduce locally? This will make debugging much easier. For example, I am unable to reproduce this issue building the latest release from the `master` branch using the latest [official Debian image](https://hub.docker.com/_/debian). In particular, release 1.10 addresses a rare (but stubborn) segfault that certainly was present in 1.9. However, the fix for this is in the corresponding tagged release of pufferfish, which is pulled in by the build script when salmon is built.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1462538853:446,stub,stubborn,446,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1462538853,1,['stub'],['stubborn']
Testability,"Hi @tillea and @nileshpatra,. Ok, I dug deeper and found out what's going on. The culprit is, in fact, `libcereal`. The problem is that `libcereal` bumped patch versions only since the version corresponding to the headers included in `pufferfish`, but their changes are not, in fact, backwards compatible! This lead to a version mismatch between the headers used in `pufferfish` and the headers found from the installed package, ultimately resulting in an assertion failure in `rapidjson` (which cereal is using) and a segfault. On the plus side, this was relatively easy to fix by bumping the included cereal headers in pufferfish. I also updated the `Findcereal.cmake` module and added a version constraint so that we now require the new version (1.3.2). This is now tagged and released as `salmon 1.10.1`. Please give that a go when you have a chance. I'll note that, before this is added upstream in debian, I'd still advocate for fixing the `libstaden` package to update to the new version. I'd also recommend moving to dependencies like the ones I've included above to remove some really antiquated dependencies that salmon no longer requires but are still being pulled in. Thanks!; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1465096711:456,assert,assertion,456,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1465096711,1,['assert'],['assertion']
Testability,"Hi @tillea,. It seems this is exactly the problem. The build deps here are not quite correct. There are dependencies that salmon no longer has, and some of the dependencies it does have are out of date and can't be used from upstream (e.g. libstaden in the latest version, among others). On the bright side, it's not the dynamic linking alone that is problematic. The following works fine on my end:. ```{bash}; $ docker pull debian:testing; $ docker run -it debian:testing; $ echo ""deb-src http://deb.debian.org/debian unstable main"" > /etc/apt/sources.list.d/10-debsrc.list; $ apt-get update; $ apt-get upgrade; $ apt-get install build-essential git libboost-all-dev liblzma-dev libbz2-dev cmake zlib1g-dev curl unzip wget libcurl4-openssl-dev libtbb-dev libtbb12 liblzma-dev libjemalloc2 pkg-config libgff-dev; $ wget https://github.com/COMBINE-lab/salmon/archive/refs/tags/v1.10.0.tar.gz; $ tar xaf v1.10.0.tar.gz; $ cd salmon-1.10.0; $ mkdir build && cd build; $ cmake -DCMAKE_BUILD_TYPE=Release -DUSE_SHARED_LIBS=TRUE -DBZIP2_LIBRARIES=-lbz2 -DBZIP2_INCLUDE_DIR=/usr/include -DLIBLZMA_INCLUDE_DIR=/usr/include/ -DLIBLZMA_LIBRARY=lzma -DCMAKE_MODULE_PATH=/usr/share/cmake/Modules -DTBB_WILL_RECONFIGURE=FALSE -DBOOST_WILL_RECONFIGURE=FALSE ..; $ make -j8; $ make install; $ make test; ```. This is preferring dynamic linking, and the resulting installed executable runs fine without a segfault. Can you try this on your end? Then the thing to do may be to find what is discordant between the packages I install above and what gets pulled in by `apt build-dep salmon`. Thanks,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1464182279:433,test,testing,433,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1464182279,3,['test'],"['test', 'testing']"
Testability,"Hi @tillea,. So I went through the list of deps pulled in by `apt build-dep salmon` and the minimal set I gave above. I tried to make the smallest number of changes I could to the `apt build-dep salmon` list while also removing things that are clearly outdated (we no longer use jellyfish, rapmap, etc. and we use the header-only version of spdlog). As a result I came up with this list of dependencies. The offending dependency seems to be `libcereal-dev`. Specifically, I was able to install just this list of dependencies (minus `libcereal-dev`) atop a clean `debian:testing` and get a working version where the only thing downloaded from the internet was the appropriate version of the pufferfish files grabbed by `fetchPufferfish.sh` in the `1.10.0` release. Once I installed `libcereal-dev` with `apt-get install`, and rebuilt, then I got the segfault mentioned at the top of this issue. So, it seems that we either have to let `salmon` build it's own libcereal, or figure out what the problem is with the library upstream. Please let me know if this you observe this same behavior as well (also @nileshpatra may want to try this out). If so, perhaps we can get `libstaden` updated upstream, and then use this as the new dep list for `salmon`. I installed these deps with a simple `xargs apt-get install -y < deps_sorted_updated.txt` (without `libcereal-dev` for the working version, and with it included, as below, for the segfault). Best,; Rob. [deps_sorted_updated.txt](https://github.com/COMBINE-lab/salmon/files/10949233/deps_sorted_updated.txt)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1464986376:570,test,testing,570,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1464986376,2,['test'],['testing']
Testability,"Hi @tomsing1,. Thanks for following up on this --- I was scratching my head about why multiple libraries might be causing an issue. Both `--seqBias` and `--gcBias` are relatively new features, and have definitely undergone more testing under the ""quasi-mapping"" codepath than the alignment-based codepath (though it's passed our internal regression tests on both). That being said, bias correction is equally valid regardless of whether you're using quasi-mapping or quantifying from a bam file directly. I'd be happy to take a look if you can provide a small example (a subset of the reads in the bam file?) that triggers the behavior. One thought might be that, for some reason, positions in the bam file could disagree with what's provided in the corresponding fasta. However, that's just a guess and I'd have to try and debug the segfault once I can reproduce it. Thanks again for the detailed error report and the update!. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/104#issuecomment-261738431:228,test,testing,228,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/104#issuecomment-261738431,2,['test'],"['testing', 'tests']"
Testability,"Hi @uros-sipetic!. Unfortunately, as you suggest, there really is no good way to infer the fragment length distribution from only single-end reads. Rather, this flag determines how the conditional probability of single-end fragments near the beginning (if in the rc orientation) or end (if in the forward orientation) of the transcript are determined. A single-end read does not have any known fragment length. But we do know that e.g. fragments very close to the end or beginning of the transcript are rather unlikely. In this case, we can integrate (sum) over all possibilities to assign a conditional probability. This is what salmon does. For a single-end read (assume forward orientation for simplicity) at position i on a transcript of length n, we consider the conditional fragment length probability to be given by F_n(n-i), where f_n is the conditional fragment length distribution conditioned on the transcript length (maximum observable length) being n and F_n is the cumulative distribution function of f_n. Intuitively, this means that fragments very close to transcript ends will get a smaller conditional probability, while those farther from the end will get larger conditional probabilities. The `--noSingleFragProb` flag simply turns off this conditional probability all together. It is _not_ recommended to disable the single-end fragment length probability modeling. We have evidence from testing that it improves quantification accuracy. Thus, I would suggest _not_ setting the `--noSingleFragProb` flag. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/575#issuecomment-711061553:1409,test,testing,1409,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/575#issuecomment-711061553,2,['test'],['testing']
Testability,"Hi @uros-sipetic,. Thanks for reporting this. I can't reproduce the issue that, when I pass an argument to `writeMappings`, the SAM data is still written to stdout. Could you tell me if you're using the pre-compiled binary, and if so, what type of system you're running on? However, I can produce a different issue which may be related (and might be an issue with the logic for checking if a directory exists). Can you try the following command in your case and tell me what happens?. `salmon quant -i ucsc.hg19.transcriptome_salmon_index -1 reads.pe_1.fastq -2 reads.pe_2.fastq --writeMappings test_output/mappings_info -o test_output -l A -p 2`. also, you should be able to do `--writeMappings ./mappings_info`. The problem appears to be with the code that checks if the parent path where the mapping info is to be written exists or not:. ``` c++; // get the parent directory; bfs::path qmDir = boost::filesystem::path(sopt.qmFileName).parent_path();; // if it's not already a directory that exists; bool qmDirSuccess = boost::filesystem::is_directory(qmDir);; ```. The issue is that `sopt.qmFileName` need not be a ""canonical"" path, so that the call to parent_path might return the empty string, which results in an exception being thrown (and, at least caught and reported) when boost tries to create the parent directory """". The solution is to canonicalize the path, which I'm doing now. However, if you provide a qualified path (either fully-qualified or even relatively qualified), then it should work. Specifically, if I provide a non-empty argument to `--writeMappings` I don't get any output on stdout.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/86#issuecomment-244773065:368,log,logic,368,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/86#issuecomment-244773065,1,['log'],['logic']
Testability,"Hi @vals,. So there was a very subtle bug in `useFSPD` that would (in a very non-reproducible manner) trigger such a segfault. It was related to some very tricky locking behavior. However, the manner in which `useFSPD` corrected for position specific bias isn't actually compatible with our new sequence-specific and fragment-gc bias models. Thus, I've deprecated `useFSPD`. The replacement is the flag `posBias`. This models the same type of positional bias, but does so in a way that is compatible with our other bias models. It also doesn't rely on the tricky threading behavior, so it should be more stable. Unlike sequence-specific and fragment-gc bias, however, the `posBias` option is still _experimental_ in the 0.7.0 release. However, we have been testing it internally, and I'd be very grateful for your feedback if you have a chance to try it out. Assuming things look good, we can promote it from experimental in the next release.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/64#issuecomment-241234373:757,test,testing,757,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/64#issuecomment-241234373,2,['test'],['testing']
Testability,"Hi @vals,. This is very interesting, as we've been doing quite a bit of testing and (to the contrary) have found v0.4.0 to perform substantially _better_ than v0.3.x. Out of curiosity, could you check how v0.4.0 performs _without_ `--useVBOpt`? Obviously, if you continue to see this regression, I'll be happy to try and dig down deeper, but I might need you to provide some testing data. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/6#issuecomment-111538228:72,test,testing,72,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/6#issuecomment-111538228,2,['test'],['testing']
Testability,"Hi @vals,; I'm still trying to track down this bug and figure out why it occurred in the first place. I've been working on a different way to deal with reclaiming the resources that caused the problem before and was wondering if you'd be willing to test the attached binary to see if it still segfaults on your data. ; Thanks! [SalmonBeta-0.6.1_DebianSqueeze.tar.gz](https://github.com/COMBINE-lab/salmon/files/87914/SalmonBeta-0.6.1_DebianSqueeze.tar.gz)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/34#issuecomment-171038135:249,test,test,249,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/34#issuecomment-171038135,1,['test'],['test']
Testability,"Hi @vertesy ,. Thanks for asking the very interesting question.; I'd say the answer might depend on what's your downstream use case. Traditionally, no quantification pipeline, in my knowledge, has used the pre-mRNA counts alone to bump up the gene counts, however, recent method of estimating RNA-velocity does utilizes the intronic counts for extracting the ratio of spliced/unspliced counts. If you are interested in disjoint signals (gene count matrix) for spliced and unspliced molecules you can use the recent scheme of decoy indexing from our latest [preprint](https://www.biorxiv.org/content/10.1101/657874v2). We (mostly @csoneson) have been testing alevin with following scheme for generating spliced and unspliced counts. 1.) Spliced Counts: Index transcriptome w/ pre-mRNA sequence as the decoys.; 2) Unspliced Counts: Index pre-mRNA sequence w/ transcriptome as the decoys. The third case is a little tricky because if you index both pre-mRNA and transcriptome, due to relatively longer length of pre-mRNA sequence compared to transcripts it might end-up biasing the UMI deduplication algorithm towards unspliced counts. To summarize, the best way to have an additive spliced and unspliced counts is still an open area of research.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/450#issuecomment-555136444:650,test,testing,650,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/450#issuecomment-555136444,1,['test'],['testing']
Testability,"Hi @vivekabarath,. The final v0.12.0 has been released and is available via both the release page on github and via bioonda, so I recommend you use the official version. Regarding your specific question, the failure of the unit tests should not be a problem and doesn't affect salmon. However there was previously an issue that could cause the `make test` to fail if `make install` was not run first. This should be resolved in the latest release as well. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/315#issuecomment-444971569:228,test,tests,228,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/315#issuecomment-444971569,2,['test'],"['test', 'tests']"
Testability,"Hi @zhangchipku,. The referenced commit should fix this issue. I've tested `--incompatPrior 0` in alignment and read-based mode with and without VB. The bug was the result of a double-precision floating point comparison close to machine precision returning an unexpected result. The behavior has been fixed (and modified). I'm still planning to do more testing, but feel free to test this out if you can build from source (on the develop branch). --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/78#issuecomment-241225575:68,test,tested,68,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/78#issuecomment-241225575,3,['test'],"['test', 'tested', 'testing']"
Testability,"Hi Andrea,. The bias correction time depends on the number of expressed transcripts. There is a flag to speed it up `--biasSpeedSamp`. It takes a value by which to downsample the fragment length pmf for bias modeling. The larger this number, the faster bias correction will become. The default is 1, and is super conservative (we are probably going to make the default 5 in the next release because it is much faster with no real difference in modeling quality). In fact, values up to at least 10 seem to work quite well with respect to the baseline. So, I'd recommend testing this parameter on a sample until you are happy with the speed, and then using that on all samples. Let me know how it goes, and if my description makes sense. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/201#issuecomment-369766969:569,test,testing,569,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/201#issuecomment-369766969,1,['test'],['testing']
Testability,"Hi Avi,. Here is the salmon log from one of my PE libraries. There are only 12; libraries for each in the directory, which is why I got confused when it; said 13. I will try putting in all of the file names and let you know how; it goes. Thank you for all of your help. Sara. [2019-07-29 15:58:39.034] [jointLog] [info] Fragment incompatibility prior; below threshold. Incompatible fragments will be ignored.; [2019-07-29 15:58:39.034] [jointLog] [info] Usage of --validateMappings; implies use of minScoreFraction. Since not explicitly specified, it is; being set to 0.65; [2019-07-29 15:58:39.034] [jointLog] [info] Usage of --validateMappings,; without --hardFilter implies use of range factorization.; rangeFactorizationBins is being set to 4; [2019-07-29 15:58:39.034] [jointLog] [info] Usage of --validateMappings; implies a default consensus slack of 0.2. Setting consensusSlack to 0.2.; [2019-07-29 15:58:39.034] [jointLog] [info] parsing read library format; [2019-07-29 15:58:39.034] [jointLog] [error] Failed to successfully parse; any complete read libraries. Please make sure you provided arguments; properly to -1, -2 (for paired-end libraries) or -r (for single-end; libraries), and that the library format option (-l) *comes before* the read; libraries. On Mon, Jul 29, 2019 at 4:06 PM Avi Srivastava <notifications@github.com>; wrote:. > Oh Sorry about that what I meant was the salmon.log file or the the; > meta-info.json file created by salmon in the output directory. You can; > check what files salmon is detecting it seems there are 12 files in the; > mate1 and 13 files in the mate2. Can you confirm there are 13 pairs of file; > in that directory and their regex is same as you are using ? Can you also; > try putting the names of the file instead * as regex ?; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/COMBINE-lab/salmon/issues/408?email_source=notifications&email_token=AEHDXAA5DH",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/408#issuecomment-516514620:28,log,log,28,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/408#issuecomment-516514620,1,['log'],['log']
Testability,"Hi Avi,. Thanks for the detailed reply. I was able to run it (see logs below), but I had to use `ISR`, not `ISF` to get it to work. I also had to add these two settings as well; `--freqThreshold 1 --lowRegionMinNumBarcodes 100`. . I am not sure why the `ISF` option didn't work, but probably it has something to do with the guide sequences I was provided. At any rate, I have a few other questions I hope you can help me answer. 1. Why does increasing --maxNumBarcodes to 200000 results in no barcodes getting corrected? (See log for Run 2 below). What is the rationale for the current default of 100000? ; 2. For the downstream analysis of such data, I usually work with both the read and UMI counts, but `quants_mat.gz` only contains the UMI counts. Can Alevin a produce a matrix of read counts as well. It would be a great feature to add. For now, what is easiest way to get the cell x feature matrix of read counts if I use the ` --dumpEq` or `--dumpBfh` flags? Can *tximport* be used for this or do I need to use the Python [parser]([https://github.com/k3yavi/vpolo/blob/master/vpolo/alevin/parser.pyl]) first?. I will be sending you some reads from the experiments for unit testing shortly. Thanks!. Run 1: `salmon alevin -l ISR --citeseq --barcodeLength 16 --umiLength 10 --end 5 --featureStart 19 --featureLength 21 --maxNumBarcodes 100000 --freqThreshold 1 --lowRegionMinNumBarcodes 100`. > 20-06-04 12:24:47.610] [alevinLog] [info] set CITE-seq minScoreFraction parameter to : 0.797619; > [2020-06-04 12:24:47.610] [alevinLog] [info] Found 64 transcripts(+0 decoys, +0 short and +0 duplicate names in the index); > [2020-06-04 12:24:47.610] [alevinLog] [info] Filled with 64 txp to gene entries ; > [2020-06-04 12:24:47.610] [alevinLog] [info] Found all transcripts to gene mappings; > [2020-06-04 12:24:47.616] [alevinLog] [info] Processing barcodes files (if Present) ; > ; > [2020-06-04 12:26:04.322] [alevinLog] [info] Done barcode density calculation.; > [2020-06-04 12:26:04.322] [alev",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-638991199:66,log,logs,66,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-638991199,4,['log'],"['log', 'logs']"
Testability,"Hi Bill,. One thing I noticed is that your log says :; ```; [2018-10-12 18:13:10.808] [jointLog] [warning] Removed 7582 transcripts that were sequence duplicates of indexed transcripts.; ```. while my run said:. ```; [2018-10-12 17:29:14.651] [jointLog] [warning] Removed 11851 transcripts that were sequence duplicates of indexed transcripts.; ```. that's a non-trivial difference in number. My run was from the fasta file using *this* link (ftp://ftp.ensembl.org/pub/release-94/fasta/homo_sapiens/cdna/Homo_sapiens.GRCh38.cdna.all.fa.gz). Was yours the same? Digging into the _other_ version now to see if I can find anything.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/301#issuecomment-429503523:43,log,log,43,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/301#issuecomment-429503523,1,['log'],['log']
Testability,"Hi Bill,. Strange indeed! Can you share the log salmon made during indexing and the `duplicate_clusters.tsv` file you do get?. Thanks,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/301#issuecomment-429502024:44,log,log,44,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/301#issuecomment-429502024,1,['log'],['log']
Testability,"Hi Brian,. In general, I would argue that one should be cautious with removing PCR duplicates in RNA-seq data (unless you are dealing with reads with UMI tags). This is because reads that align to the same reference position can easily have come from alternative transcripts sharing the same underlying sequence. Hence, the normal tests used to infer PCR duplicates with e.g. DNA-seq reads can yield false-positives in RNA-seq. This is particularly true for highly abundant transcripts (or transcripts from highly-abundant genes). We are currently working on the code that will do duplicate removal when UMI tags are present. That methodology can be extended to remove duplicates even without UMI tags --- though I'd generally caution against that for the reasons mentioned above. However, for the time being, if you have a strong need or desire to filter PCR duplicates, you could use alignment-based Salmon with a BAM file that has duplicates removed. Finally, regarding the error you are getting during SAM validation; this sounds like a different issue. Would you mind providing a piece of that SAM file for me to take a look at? Specifically, I don't believe the quasi-mapping output file should even contain unmapped reads (unless you consider unmapped mates of orphaned reads). --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/136#issuecomment-305317281:331,test,tests,331,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/136#issuecomment-305317281,1,['test'],['tests']
Testability,Hi Hamdi. Bit confused about your logic here - why would you not want to use tximport in R when your next step (DESeq2) is still going to be R? . I am curious to know your reasoning . > I am processing the data on one platform and then transfer to another platform for R/DESeq2 analysis. I would like to be able to generate the output of the first part (salmon) without using an R library.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/437#issuecomment-549185551:34,log,logic,34,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/437#issuecomment-549185551,1,['log'],['logic']
Testability,"Hi James,. Surprisingly, it looks like I don't actually log exactly the version of salmon used in the index. In the index directory, the `header.json` will give you some info. It will tell you the *index* version, but many versions of salmon can correspond to the same *index* version. The info in that file might help to discriminate a little bit. Can you try *indexing* with v0.10.2 (the one you are aligning with)?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/301#issuecomment-429497594:56,log,log,56,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/301#issuecomment-429497594,1,['log'],['log']
Testability,"Hi Jenny,. Thanks for this detailed report. I'd be interested in taking a look at some of the data if it is public or possible to share for the purposes of testing. It is true that if a read is equally explicable by a short and long transcript (and if there is not a lot of other read evidence of the long transcript), the inference algorithm will prefer to assign the read to the shorter isoform, since this will increase the overall likelihood of the observed sequenced fragments. Of course, one could always run salmon's Gibbs sampler `--numGibbsSamples` or bootstrap sampler `--numBootstraps` to determine the variance in these point estimates. I'm on travel for the next couple of days, but will be happy to look into this more deeply when I return. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/133#issuecomment-296703263:156,test,testing,156,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/133#issuecomment-296703263,1,['test'],['testing']
Testability,"Hi Josh,. My best guess is that something is awry with the 64-bit index. That code-path is less well-tested (since I don't really have any transcriptomes in my collection that exceed the size of a 32-bit signed int). If you're able to share the txome and / or the index itself, I'd be happy to try and reproduce and fix this. Actually, I'd be really happy to squash any bugs in the 64-bit code path. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/54#issuecomment-203627077:101,test,tested,101,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/54#issuecomment-203627077,1,['test'],['tested']
Testability,"Hi Kivanc,. Indeed, it looks from the logs as if, in the low mapping-rate samples, SAF with decoys is confidently assigning a lot of reads to decoy sequence. For example, out of `11225446` fragments, `6809189` map best to decoys and `3069202` map best to the annotation. This is compared to without decoys where `6166065` reads map to the annotation. Interestingly, you can see that with the decoys, the total number of reads accounted for is considerably higher. I agree that the results of SAF may be closer to that of STAR. One thing I'd be curious to know is how many of those reads aligned by STAR can be confidently assigned to exons. That's the number that you'd want to most-directly compare against the mapping rate of salmon to non-decoy targets. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/479#issuecomment-579314493:38,log,logs,38,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/479#issuecomment-579314493,1,['log'],['logs']
Testability,"Hi Nick,. No problem at all; sorry for not providing a better explanation (I'm planning on writing one up for when this feature is listed in the next official release). In terms of strategy, my recommendation would be to use the default (the `dense hash`) unless indexing memory becomes a problem. The main differences are the following:; - The perfect hash uses an external memory algorithm to construct the hash function, and so requires less memory.; - Because the perfect hash function is built in external memory, **construction** of the hash using this data structure is sower. I don't have longitudinal benchmarks, but it is somewhere between 2 and 5x slower to populate the perfect hash than the dense hash.; - Once constructed, the perfect hash is _considerably_ smaller, and so quantification on an index built using a perfect hash will require only ~50% of the memory that is required when using a dense hash. Obviously if you're quantifying on the same machine that was able to build the index, this isn't a problem. However, if you're shipping the index to smaller memory computers, then this is something to consider.; - The performance difference in terms of mapping speed is very minimal; the minimum perfect hash can be 5-10% slower than the dense hash, but this difference is usually only a matter of seconds. Also, the total runtime difference can be even less since the smaller perfect hash can be read more quickly from disk than the larger dense hash. So, the standard recommendation would be use the default unless you run into memory problems building the index; in that case, try enabling the `--perfectHash` flag.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/53#issuecomment-204069238:610,benchmark,benchmarks,610,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/53#issuecomment-204069238,1,['benchmark'],['benchmarks']
Testability,"Hi Peter,. Obviously, I got tied up with other obligations a bit longer than I thought! Sorry for the delay. Anyway, I've run both of these samples with the newest release, using parameters as close as I can (given that the bias correction flags have changed in 0.7.0). Both samples seem to run cleanly. Would you mind testing with the latest release and seeing if the issue is resolved? Here is the procedure I used:. Index with k=19 (I think this is what you did), using the default `quasi` index. ```; > salmon index -t Canis_familiaris.CanFam3.1.cdna.all.fa.gz -i index -k 19; ```. Run sample `SRR636842`:. ```; > salmon quant -i index -p 16 -l IU -1 SRR636842_1.fastq.gz -2 SRR636842_2.fastq.gz --seqBias -o quant_SRR636842 --useVBOpt; ```. here, the mapping rate was ~78.8%. Run sample `SRR636843`:. ```; >salmon quant -i index -p 16 -l IU -1 SRR636843_1.fastq.gz -2 SRR636843_2.fastq.gz --seqBias -o quant_SRR636843 --useVBOpt; ```. here, the mapping rate was ~79.5%. The mapping rates may differ for you a bit, since I used [this](ftp://ftp.ensembl.org/pub/release-85/fasta/canis_familiaris/cdna/Canis_familiaris.CanFam3.1.cdna.all.fa.gz) Ensembl transcript set directly.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/66#issuecomment-241235054:319,test,testing,319,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/66#issuecomment-241235054,1,['test'],['testing']
Testability,"Hi Rob ; Thanks for your reply, May I just show another exmaple. This is the log.final.out from STAR. Number of input reads | 39258388; Average input read length | 300; UNIQUE READS:; Uniquely mapped reads number | 33103781; Uniquely mapped reads % | 84.32%; Average mapped length | 297.80; Number of splices: Total | 23754767; Number of splices: Annotated (sjdb) | 23730217; Number of splices: GT/AG | 23569617; Number of splices: GC/AG | 108014; Number of splices: AT/AC | 18563; Number of splices: Non-canonical | 58573; Mismatch rate per base, % | 0.26%; Deletion rate per base | 0.03%; Deletion average length | 3.17; Insertion rate per base | 0.01%; Insertion average length | 1.45; MULTI-MAPPING READS:; Number of reads mapped to multiple loci | 2524124; % of reads mapped to multiple loci | 6.43%; Number of reads mapped to too many loci | 518050; % of reads mapped to too many loci | 1.32%; UNMAPPED READS:; Number of reads unmapped: too many mismatches | 0; % of reads unmapped: too many mismatches | 0.00%; Number of reads unmapped: too short | 1717592; % of reads unmapped: too short | 4.38%; Number of reads unmapped: other | 1394841; % of reads unmapped: other | 3.55%; CHIMERIC READS:; Number of chimeric reads | 0; % of chimeric reads | 0.00%; sample6/align_6BE_Log.final.out (END). I run the same sample with salmon index generated as discussed above and got this report ; [2022-05-14 01:26:06.437] [jointLog] [info] Computed 380,631 rich equivalence classes for further processing; [2022-05-14 01:26:06.437] [jointLog] [info] Counted 22,462,069 total reads in the equivalence classes ; [2022-05-14 01:26:06.454] [jointLog] [info] Number of mappings discarded because of alignment score : 236,393,072; [2022-05-14 01:26:06.454] [jointLog] [info] Number of fragments entirely discarded because of alignment score : 3,028,418; [2022-05-14 01:26:06.454] [jointLog] [info] Number of fragments discarded because they are best-mapped to decoys : 0; [2022-05-14 01:26:06.454] [jointLog] [inf",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/775#issuecomment-1126593943:77,log,log,77,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/775#issuecomment-1126593943,1,['log'],['log']
Testability,"Hi Rob, . For example, here is the log output when I try to index the GENCODE Human transcript set v36, using the below code;. salmon index --keepDuplicates -k 35 --gencode -t gencode.v36.transcripts.fa -i Human_v36_Index_k35. Here is where the phrase is found in the log, and is then repeated a lot until the end. Number of ones: 1309432; Number of ones per inventory item: 512; Inventory entries filled: 2558; 1309432; [2021-02-15 04:42:27.548] [puff::index::jointLog] [info] Done wrapping the rank vector with a rank9sel structure.; [2021-02-15 04:42:27.565] [puff::index::jointLog] [info] contig count for validation: 1,309,432; [2021-02-15 04:42:28.338] [puff::index::jointLog] [info] Total # of Contigs : 1,309,432; [2021-02-15 04:42:28.339] [puff::index::jointLog] [info] Total # of numerical Contigs : 1,309,432; [2021-02-15 04:42:28.404] [puff::index::jointLog] [info] Total # of contig vec entries: 7,119,643; [2021-02-15 04:42:28.404] [puff::index::jointLog] [info] bits per offset entry 23; [2021-02-15 04:42:28.590] [puff::index::jointLog] [info] Done constructing the contig vector. 1309433; [2021-02-15 04:42:29.459] [puff::index::jointLog] [info] # segments = 1,309,432; [2021-02-15 04:42:29.459] [puff::index::jointLog] [info] total length = 188,284,293; [2021-02-15 04:42:29.548] [puff::index::jointLog] [info] Reading the reference files ...; [2021-02-15 04:42:31.594] [puff::index::jointLog] [info] positional integer width = 28; [2021-02-15 04:42:31.594] [puff::index::jointLog] [info] seqSize = 188,284,293; [2021-02-15 04:42:31.595] [puff::index::jointLog] [info] rankSize = 188,284,293; [2021-02-15 04:42:31.595] [puff::index::jointLog] [info] edgeVecSize = 0; [2021-02-15 04:42:31.595] [puff::index::jointLog] [info] num keys = 143,763,605; len should not be greater than 64.; ...; ...; ...; len should not be greater than 64.; [2021-02-15 05:07:13.459] [puff::index::jointLog] [info] finished populating pos vector; [2021-02-15 05:07:13.460] [puff::index::jointLog] [info] wr",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/632#issuecomment-779416548:35,log,log,35,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/632#issuecomment-779416548,2,['log'],['log']
Testability,"Hi Rob, . Thank you for the fast reply. I did some tests and ran the suggestions you told me. Everything comes down to the reference i used. The mapping rates are still low (44 - 54 %) but they have increased when I mapped the reads with Salmon allowing for more genes in the reference. Thank you for the useful suggestions though, I will incorporate them in my future evaluations.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/212#issuecomment-379253109:51,test,tests,51,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/212#issuecomment-379253109,1,['test'],['tests']
Testability,"Hi Rob, ; I'd like to ask a follow-up question to this thread:. In your reply above, you said:; > the library type is used as a ""soft"" rather than a ""hard"" filter when determining where a read may originate from (i.e. Orientations other than the expected type have a probability orders of magnitude smaller than the expected type, but still non-zero). Thus, if the only mapping for a read disagrees with the expected type, it will still be used. There is a way to modify this behavior, but since stranded library prep is imperfect, the default behavior is the most reasonable for most situations. I wonder how can I enforce the ""correct"" usage of the strand information by Salmon. I am testing Salmon on some data and there seem to be cases of overlap between two genes (on opposite strands), when the values produced by Salmon seem suspicious. Best, ; Alex",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/67#issuecomment-388851366:686,test,testing,686,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/67#issuecomment-388851366,1,['test'],['testing']
Testability,"Hi Rob,. I would still like to test your branch with selective-alignment if you can provide the linux executable. Tnx!; Klaas",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/196#issuecomment-379190396:31,test,test,31,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/196#issuecomment-379190396,1,['test'],['test']
Testability,"Hi Rob,. Thanks for the update. I’ll see about setting up a Linux box in the morning and trying the v1.3.1. I expected some reads to be discharged as this is a mixed intestinal sample so there is likely a lot of bacterial rna as we used rRNA depletion not polyA; selection. We were hoping to align to both the mouse genome and one of the bacteria species of interest. . Given the several orders of magnitude difference in discarded alignments between mine on 1.2.1 and your test run on 1.3.1, would you recommend I redo the whole dataset alignment on 1.3.1? If it runs even close to what you saw it shouldn’t take too long; to rerun. . Thanks again,. Ryan. Sent from my iPhone. On Jun 16, 2020, at 12:13 AM, Rob Patro <notifications@github.com> wrote:. ﻿. I processed the data above using the latest salmon from the develop branch; (the release candidate for 1.3.0), and I got the following time (used 8; threads, so timing is not directly comparable). ```; 4604.57user 43.64system 9:24.15elapsed 823%CPU; ```. The whole log is. ```; [2020-06-15 23:51:54.747] [jointLog] [info] setting maxHashResizeThreads to; 8; [2020-06-15 23:51:54.747] [jointLog] [info] Fragment incompatibility prior; below threshold. Incompatible fragments will be ignored.; [2020-06-15 23:51:54.747] [jointLog] [info] Usage of --validateMappings; implies use of minScoreFraction. Since not explicitly specified, it is; being set to 0.65; [2020-06-15 23:51:54.747] [jointLog] [info] Usage of --validateMappings; implies a default consensus slack of 0.2. Setting consensusSlack to 0.35.; [2020-06-15 23:51:54.747] [jointLog] [info] parsing read library format; [2020-06-15 23:51:54.747] [jointLog] [info] There is 1 library.; [2020-06-15 23:51:54.814] [jointLog] [info] Loading pufferfish index; [2020-06-15 23:51:54.814] [jointLog] [info] Loading dense pufferfish index.; [2020-06-15 23:51:55.555] [jointLog] [info] done; [2020-06-15 23:51:55.555] [jointLog] [info] Index contained 116,248 targets; [2020-06-15 23:51:55.588] [jo",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/537#issuecomment-644527727:474,test,test,474,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/537#issuecomment-644527727,1,['test'],['test']
Testability,"Hi Rob,. The file that I am building the index on is a cdna.all fasta file from Ensembl, ; exactly this one here : ftp://ftp.ensembl.org/pub/release-91/fasta/caenorhabditis_elegans/cdna/Caenorhabditis_elegans.WBcel235.cdna.all.fa.gz . . It was unzipped and then used with `salmon index`. ; This is the log of the indexing process:; ```; Version Info: Could not resolve upgrade information in the alotted time.; Check for upgrades manually at https://combine-lab.github.io/salmon; [2018-03-20 17:41:44.417] [jLog] [info] building index; RapMap Indexer. [Step 1 of 4] : counting k-mers; [2018-03-20 17:41:48.639] [jointLog] [warning] Entry with header [W03F8.6d], had length less than the k-mer length of 31 (perhaps after poly-A clipping); Elapsed time: 4.82575s. [2018-03-20 17:41:49.262] [jointLog] [warning] Removed 414 transcripts that were sequence duplicates of indexed transcripts.; [2018-03-20 17:41:49.263] [jointLog] [warning] If you wish to retain duplicate transcripts, please use the `--keepDuplicates` flag; Replaced 0 non-ATCG nucleotides; Clipped poly-A tails from 20 transcripts; Building rank-select dictionary and saving to disk done; Elapsed time: 0.0570225s; Writing sequence data to file . . . done; Elapsed time: 0.286971s; [info] Building 32-bit suffix array (length of generalized text is 56718041); Building suffix array . . . success; saving to disk . . . done; Elapsed time: 0.959095s; done; Elapsed time: 8.1189s; ^M^Mprocessed 0 positions^M^Mprocessed 1000000 positions^M^Mprocessed 2000000 positions^M^Mprocessed 3000000 positions^M^Mprocessed 4000000 positions^M^Mprocessed 5000000 positions^M^Mprocessed 6000000 positions^M^Mprocessed 7000000 positions^M^Mprocessed 8000000 positions^M^Mprocessed 9000000 positions^M^Mprocessed 10000000 positions^M^Mprocessed 11000000 positions^M^Mprocessed 12000000 positions^M^Mprocessed 13000000 positions^M^Mprocessed 14000000 positions^M^Mprocessed 15000000 positions^M^Mprocessed 16000000 positions^M^Mprocessed 17000000 position",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/210#issuecomment-376093497:302,log,log,302,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/210#issuecomment-376093497,1,['log'],['log']
Testability,"Hi Rob,; I haven't got a chance to test whether the suggestions help or not. But I guess it's due to the fact that the read is super short, single-end only as well, thus introduce a huge ambiguity in the quasi-mapping step. Anyway, I will try to test it later.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/120#issuecomment-281555424:35,test,test,35,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/120#issuecomment-281555424,2,['test'],['test']
Testability,"Hi Rob,; That seemed to be the problem. I rebuilt the index on my laptop and salmon worked perfectly on my laptop!; Thanks,; Grant. On Mar 22, 2018, at 6:21 PM, Rob Patro <notifications@github.com<mailto:notifications@github.com>> wrote:. Hi @grantcramer<https://na01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Fgrantcramer&data=01%7C01%7Ccramer%40unr.edu%7C54d34feceb114e30a61b08d5905c7a7b%7C523b4bfc0ebd4c03b2b96f6a17fd31d8%7C1&sdata=w1ED%2B5ZBUY6Z8fTiIs62IZJizv0HcvVzw8CtfEdK32E%3D&reserved=0>,. I was able to successfully index and map against the fasta file you link above (on linux). I was also able to index and map against the index on OSX, using the salmon from bioconda (v 0.9.1). So, I'm not yet able to reproduce this. It seems the file you uploaded for your pre-built index is no longer available, so I couldn't try that out. I'd be happy to give it a try if you can put it up on dropbox or some such. Otherwise, I wonder if there could be some sort of binary compatibility issue. Did you build the index on the same machine you're quantifying on? The OSX I tested on is 10.13.1. Best,; Rob. —; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://na01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2FCOMBINE-lab%2Fsalmon%2Fissues%2F209%23issuecomment-375509050&data=01%7C01%7Ccramer%40unr.edu%7C54d34feceb114e30a61b08d5905c7a7b%7C523b4bfc0ebd4c03b2b96f6a17fd31d8%7C1&sdata=5XDT2ix1q1Uz%2B3kTchI%2B5K9Hzu7UuGkyQAz8KB9ko4o%3D&reserved=0>, or mute the thread<https://na01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Fnotifications%2Funsubscribe-auth%2FAj0RizznzcCphH-HJ9Q8uXvndQ4Lsg9Oks5thE43gaJpZM4Sw28q&data=01%7C01%7Ccramer%40unr.edu%7C54d34feceb114e30a61b08d5905c7a7b%7C523b4bfc0ebd4c03b2b96f6a17fd31d8%7C1&sdata=7DLxrFx74WqeN71%2Bs5cfSxEA1NRxj%2F7uqvp9SrGgjck%3D&reserved=0>.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/209#issuecomment-375683475:1092,test,tested,1092,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/209#issuecomment-375683475,1,['test'],['tested']
Testability,"Hi Rob, . Thanks for the quick response. The other computer was OSX, should I try a linux machine? . Here are some dropbox links to two of the files. I believe this is the set for the logs I posted. . https://www.dropbox.com/s/8c3p9hmgmadgj89/31_1.trimmed.fastq.gz?dl=0. https://www.dropbox.com/s/2y9jfvaphe9h21x/31_2.trimmed.fastq.gz?dl=0. Thanks, . Ryan . On Jun 15, 2020, at 9:32 PM, Rob Patro <notifications@github.com> wrote:. Thank you for the report. Can you share one of the samples where you see this issue? Also, out of curiosity, was the other machine you tried on also OSX, or was it a linux machine?; —; You are receiving this because you authored the thread.; Reply to this email directly, ; view it on GitHub, or ; unsubscribe.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/537#issuecomment-644504783:184,log,logs,184,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/537#issuecomment-644504783,1,['log'],['logs']
Testability,"Hi Valentine,. Thanks for all of the detailed info to reproduce this; I'll try and take a look at it soon. Since there is _a lot_ of work going on in the develop branch (and good stuff coming in v0.7.0), it actually looks like `--useFSPD` will be replaced with a `--posBias` flag that models both 5' and 3' position specific bias. Of course, we're still working on / testing that feature. In the mean time, I'll see if I can find what's causing this problem. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/64#issuecomment-227424950:367,test,testing,367,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/64#issuecomment-227424950,1,['test'],['testing']
Testability,"Hi Valentine,. That's not good! I suppose that testing the gibbs sampling should be added to our standard set of regression tests. Can you provide me with a data set that reproduces this issue? I'll track it down and figure out why Gibbs is behaving badly. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/58#issuecomment-218878561:47,test,testing,47,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/58#issuecomment-218878561,2,['test'],"['testing', 'tests']"
Testability,"Hi again @GWW,. We have a hotfix for this that we are currently testing, but feel free to try it out if you have a chance. If you download the source from [here](https://github.com/COMBINE-lab/salmon/archive/hash-resize-hotfix.zip), or checkout the branch `hash-resize-hotfix`, you can pass alevin an extra hidden option `--maxHashResizeThreads` that allows you to limit the maximum number of threads used during the hash table resize. If you use `--maxHashResizeThreads 1`, at most one extra thread should be created during hash table resizing. Hopefully, this should fix the issue occurring in your execution environment. If so, please let us know so we can merge the fix back into develop (and then master).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-395907924:64,test,testing,64,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-395907924,1,['test'],['testing']
Testability,"Hi again,. Together with Mark Miller (JHPCE's admin) we ran more tests. We verified that `Salmon` does indeed use at least 2 threads so now I'm always requesting 2 from SGE. We also noticed that when the jobs fail due to memory (the actual issue in this thread) they fail after the `There is 1 library` message as shown below for one test:. ```; [2017-04-05 14:28:09.021] [jointLog] [info] parsing read library format; [2017-04-05 14:28:09.035] [jointLog] [info] There is 1 library.; terminate called without an active exception; /cm/local/apps/sge/var/spool/compute-064/job_scripts/420662: line 31: 28651 Aborted (core dumped) /dcl01/lieber/ajaffe/Emily/RNAseq-pipelin; e/Software/Salmon-0.8.2_linux_x86_64/bin/salmon quant -i /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode; .v25.transcripts -p 1 -l ISR -1 ${FILE1} -2 ${FILE2} -o /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test7/${ID}; ```. Files that work well, keep on going:. ```; [2017-04-05 14:30:23.757] [jointLog] [info] parsing read library format; [2017-04-05 14:30:23.767] [jointLog] [info] There is 1 library.; [2017-04-05 14:30:24.378] [jointLog] [info] Loading Quasi index; ```. I don't know if that hint makes you suspect anything in `Salmon`. . Now, for some tests only task 2 runs and it turns out that task 2 has a smaller fastq file than the other 2:. ```bash; $ ls -lh merged_fastq/R1000[1-3]*; -rw-r--r-- 1 lcollado lieber_jaffe 6.2G Feb 20 12:39 merged_fastq/R10001_D2B1WACXX.fastq.gz; -rw-r--r-- 1 lcollado lieber_jaffe 6.3G Feb 20 12:40 merged_fastq/R10001_D2B1WACXX_read2.fastq.gz; -rw-r--r-- 1 lcollado lieber_jaffe 4.6G Feb 20 12:42 merged_fastq/R10002_C29P7ACXX.fastq.gz; -rw-r--r-- 1 lcollado lieber_jaffe 4.7G Feb 20 12:44 merged_fastq/R10002_C29P7ACXX_read2.fastq.gz; -rw-r--r-- 1 lcollado lieber_jaffe 7.1G Feb 20 12:47 merged_fastq/R10003_D19KGACXX.fastq.gz; -rw-r--r-- 1 lcollado lieber_jaffe 7.1G Feb 20 12:50 merged_fastq/R10003_D19KGACXX_read2.fastq.g",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:65,test,tests,65,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,2,['test'],"['test', 'tests']"
Testability,"Hi all,. I'm just chiming in here to say that we are _definitely_ interested in supporting scRNA-seq data ""out of the box"". At this point, it's really just a matter of deciding what the best approach is. That is, do we have a sufficiently good idea of the appropriate ""model"" for scRNA-seq to implement that, or is a de-duplicated UMI count over transcripts and equivalence classes the best we can do at this point. I'm open to ideas, thoughts, and suggests on how to test this as we start incorporating this feature into Salmon. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/93#issuecomment-259996802:468,test,test,468,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/93#issuecomment-259996802,1,['test'],['test']
Testability,"Hi guys,. I'm certainly open to adding this type of thing if there's sufficient desire for it. I agree with @vals that making umi tags compatible with a data generation model based on expected coverage seems very difficult. Then, the question just becomes what is the best way to support umi-tagged data. I'm open to suggestions, as well as to good datasets against which different approaches may be tested. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/93#issuecomment-251217506:400,test,tested,400,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/93#issuecomment-251217506,1,['test'],['tested']
Testability,"Hi scott,. Thank you for the detailed report. Im trying to reproduce the issue. So far, i have been unable to reproduce the issue on an ubuntu 16.04 or OSX box with either 0.11.1 or 0.9.1. My next test is to try on an ubuntu 14.04 docker container. I'm afraid there may be a system library issue involved. Could you try upgrading via bioconda as well to see if that helps? The latest linux release is available on bioconda.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/271#issuecomment-413855775:197,test,test,197,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/271#issuecomment-413855775,1,['test'],['test']
Testability,"Hi! I'm really sorry for taking so long to get back to you; things have been quite hectic this semester. The reason it's not being show is because it's been placed in a parameter group that is not made visible by default; the `--posBias` option itself is still available. It's definitely still experimental in that it has not been tested nearly as thoroughly as the other bias models. However, it is useable. Once we have performed more testing, it will migrate into the normal options and be better documented. If you gather any useful data while using this flag, we'd love some feedback!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/191#issuecomment-367448963:331,test,tested,331,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/191#issuecomment-367448963,4,['test'],"['tested', 'testing']"
Testability,"Hi, . Sorry for not mentioning it previously, can you please also attach/add the error log you are getting.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/549#issuecomment-660248736:87,log,log,87,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/549#issuecomment-660248736,1,['log'],['log']
Testability,"Hi, I had previousl tried using the `--whitelist` option using the 10x barcode whitelist (they're available at `cellranger-2.0.0/cellranger-cs/2.0.0/tenkit/lib/python/tenkit/barcodes/737K-august-2016.txt` and `4M-with-alts-february-2016.txt`). This had the same output as not using them. I just reran alevin with the `--dumpFeatures` flag, attached are the barcodes. I forgot to mention that with cellranger we saw that the knee was very soft, there was no sharp drop, and that might be what's confusing salmon. I had looked at the documentation but did not see a way to manually specify the cutoff. It is also desirable to manually the first few barcodes, because those have abnormally more counts than would be expected. Here's a log-log histogram of the alevin frequency output; ![image](https://user-images.githubusercontent.com/12504176/42296042-b9a944c6-7fa5-11e8-9f33-02a178d249ce.png). [frequency.txt](https://github.com/COMBINE-lab/salmon/files/2164480/frequency.txt)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/245#issuecomment-402569828:732,log,log-log,732,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/245#issuecomment-402569828,1,['log'],['log-log']
Testability,"Hi, I have some kind the same error. I download the prebuild index from refgenie and I got exactly the same error message. . refgenie pull hg38/salmon_sa_index <- I downloaded the 16Gb of the index files. [2020-05-04 21:30:58.648] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2020-05-04 21:30:58.648] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2020-05-04 21:30:58.648] [jointLog] [info] Usage of --validateMappings, without --hardFilter implies use of range factorization. rangeFactorizationBins is being set to 4; [2020-05-04 21:30:58.648] [jointLog] [info] Usage of --validateMappings implies a default consensus slack of 0.2. Setting consensusSlack to 0.2.; [2020-05-04 21:30:58.648] [jointLog] [info] parsing read library format; [2020-05-04 21:30:58.648] [jointLog] [info] There is 1 library.; [2020-05-04 21:30:58.701] [jointLog] [info] Loading Quasi index; Exception : [rapidjson internal assertion failure: IsObject()]; salmon quant was invoked improperly.; For usage information, try salmon quant --help; Exiting. The son files of the index show this;; ls -lrth *json; -rwxrwxrwx 1 usr usr 1007 dic 14 00:41 info.json; -rwxrwxrwx 1 usr usr 96 dic 14 00:44 versionInfo.json. Any idea would be really appreciated,. Kind regards, ; Fer",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/251#issuecomment-623664770:1053,assert,assertion,1053,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/251#issuecomment-623664770,1,['assert'],['assertion']
Testability,"Hi, Rob, thanks for the quick reply! By the way, great job on salmon!. Using ./ did fix the issue. About the stdout issue, I'm running:. ~/programs/Salmon-0.7.2_linux_x86_64/bin/salmon quant -i /data/reference/salmon/gencode.grch37.v19/ -r test.fastq --seqBias --gcBias --posBias -p 12 --geneMap /data/reference/salmon/gencode.grch37.v19/geneMap.txt --libType U -o x --writeMappings > out.sam. and not all messages are output to stderr (I'm not using 2> ). The ones starting with ### do, but others end up in out.sam. out.sam starts with:. ESC[1m[2016-09-14 11:37:38.908] [jointLog] [info] parsing read library format; ESC[00mESC[1m[2016-09-14 11:37:38.908] [jointLog] [info] There is 1 library.; ESC[00mESC[1m[2016-09-14 11:37:43.996] [jointLog] [info] Loading Quasi index; ESC[00mESC[1m[2016-09-14 11:37:43.996] [jointLog] [info] Loading 32-bit quasi index; ESC[00mESC[1m[2016-09-14 11:37:43.996] [stderrLog] [info] Loading Suffix Array ; ESC[00mESC[1m[2016-09-14 11:38:06.669] [stderrLog] [info] Loading Transcript Info ; ESC[00mESC[1m[2016-09-14 11:38:12.374] [stderrLog] [info] Loading Rank-Select Bit Array; ESC[00mESC[1m[2016-09-14 11:38:12.444] [stderrLog] [info] There were 95309 set bits in the bit array; ESC[00mESC[1m[2016-09-14 11:38:12.700] [stderrLog] [info] Computing transcript lengths; ESC[00mESC[1m[2016-09-14 11:38:12.700] [stderrLog] [info] Waiting to finish loading hash; ESC[00mESC[1m[2016-09-14 11:39:49.792] [stderrLog] [info] Successfully loaded position hash; ESC[00mESC[1m[2016-09-14 11:39:49.792] [stderrLog] [info] Done loading index; ESC[00mESC[1m[2016-09-14 11:39:49.792] [jointLog] [info] done; ESC[00mESC[1m[2016-09-14 11:39:49.792] [jointLog] [info] Index contained 95309 targets; ESC[00mESC[33mESC[1m[2016-09-14 11:40:18.128] [jointLog] [warning] Fragment GC bias correction is currently only implemented for paired-end libraries. Disabling fragment GC bias correction for this run; ESC[00m@HD VN:1.0 SO:unknown",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/90#issuecomment-247078586:240,test,test,240,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/90#issuecomment-247078586,1,['test'],['test']
Testability,"Hi, Rob. I'm migrating the previous known-good formula from the deprecated Homebrew/science tap to the new Brewsci/bio tap. I usually first migrate the last known-good formula, and then in a second PR bump the version to the most recent version. I'll bump the version know though for the sake of troubleshooting. Here's the build log for 0.9.1: https://circleci.com/gh/brewsci/homebrew-bio/500. ~~By default CircleCI runs with `make -j32`. Is it perhaps an issue with the Makefile not liking parallel?~~; I see that it's already being run with `make -j1` because it's known not to like being run in parallel. > Any idea why this might be happening? Does the CI environment prohibit this for some reason?. I'm not aware of any reason that it wouldn't be run. `curl` is installed.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/181#issuecomment-367734290:330,log,log,330,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/181#issuecomment-367734290,1,['log'],['log']
Testability,"Hi, Rob. I'm seeing this same error `Cannot find source file`; ```; -- Configuring done; CMake Error at src/CMakeLists.txt:113 (add_executable):; Cannot find source file:; /tmp/salmon-20180222-8345-abjxc0/salmon-0.8.2/external/install/src/rapmap/RapMapFileSystem.cpp; Tried extensions .c .C .c++ .cc .cpp .cxx .m .M .mm .h .hh .h++ .hm .hpp; .hxx .in .txx; ```; See the complete build log at https://circleci.com/gh/brewsci/homebrew-bio/491; Any ideas?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/181#issuecomment-367590842:385,log,log,385,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/181#issuecomment-367590842,1,['log'],['log']
Testability,"Hi, is it possible to share the logs and the minimal version of the data on which we can replicate the bug?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/407#issuecomment-514929400:32,log,logs,32,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/407#issuecomment-514929400,1,['log'],['logs']
Testability,"Hi, this got rectified by using ENSEMBL gene ids rather than gene symbol/gene names.; Other issues are : none of my mitochondrial and ribosomal gene lists are able to find in the reference index.; The log file attached:; [alevin.log](https://github.com/COMBINE-lab/salmon/files/3430327/alevin.log); The index reference genome is from gencodeV31.pc.transcripts.fa.gz from gencode human; The txptogene contains list of ENST* -- > ENSG*",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/407#issuecomment-514935938:201,log,log,201,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/407#issuecomment-514935938,3,['log'],['log']
Testability,"Hi, this is the log. I give the external whitelist which inculed 9185 barcodes. ; Yeah, I mean the 9253 cells. It comes from the output from the paper. . Bests,; Hongyu. > On Jun 13, 2019, at 2:33 PM, Avi Srivastava <notifications@github.com> wrote:; > ; > Hi @hliu5259 <https://github.com/hliu5259> ,; > can you forward the log ?; > There can be multiple reasons, did you gave external whitelist ? When you say 9253 samples do you mean 9253 cells ? How did you fix the number of cells ?; > ; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub <https://github.com/COMBINE-lab/salmon/issues/375?email_source=notifications&email_token=AK7LCF6ALRVM7WPLKREVDT3P2KHI3A5CNFSM4HX4WLH2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGODXUUVDQ#issuecomment-501828238>, or mute the thread <https://github.com/notifications/unsubscribe-auth/AK7LCF5HE6PY2FLHJB26QO3P2KHI3ANCNFSM4HX4WLHQ>.; >",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/375#issuecomment-501831515:16,log,log,16,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/375#issuecomment-501831515,2,['log'],['log']
Testability,"Hi,. I think keeping this all in one issue is best. First, i applaud your Herculean effort! I don't have access to a FreeBSD or OpenBSD box, which is partly why we hadn't seen these issues. I can look into this, but testing is hard b/c i don't have the target environment. In the meantime, if you are just trying to use the software, perhaps give the Docker image a try (as i hear Docket can be cajoled to work on FreeBSD).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/162#issuecomment-337396709:216,test,testing,216,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/162#issuecomment-337396709,1,['test'],['testing']
Testability,"Hi,. We'll install the latest version of Salmon, make new indexes and run the tests against the new indexes. It'll take us a bit to report back. Best,; Leo",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-289539265:78,test,tests,78,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-289539265,1,['test'],['tests']
Testability,"Hi,. sorry about it. Here they are. [alevin.log](https://github.com/COMBINE-lab/salmon/files/2346583/alevin.log); [salmon_quant.log](https://github.com/COMBINE-lab/salmon/files/2346584/salmon_quant.log)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/284#issuecomment-418196261:44,log,log,44,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/284#issuecomment-418196261,4,['log'],['log']
Testability,"Hi,. thanks for the prompt reply and suggestions. I rerun it as you suggested, using the cellranger generated barcode file and it looks much better now. I am attaching the log files. How much of the FASTQ files would you need ?. Thanks; [salmon_quant.log.txt](https://github.com/COMBINE-lab/salmon/files/2343857/salmon_quant.log.txt); [alevin.log.txt](https://github.com/COMBINE-lab/salmon/files/2343858/alevin.log.txt)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/284#issuecomment-417970098:172,log,log,172,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/284#issuecomment-417970098,5,['log'],['log']
Testability,"Hi,. thanks for the prompt reply. you are right, I went back to the FASTQ qc and noticed that this set of; samples all have a very low total number of reads and I would discard them.; I guess, it makes sense that the salmon did not assign fragments to any; transcripts. I should have caught it. Sorry. Thanks for your help. On Wed, Jan 20, 2021 at 9:22 PM Rob Patro <notifications@github.com> wrote:. > Hi @gianfilippo <https://github.com/gianfilippo>,; >; > Thank you for the report and for including the log File. Can you share one; > of the problematic samples and the reference against which you are; > aligning? One big difference is that the alignment rate reported by HISAT2; > is to the genome, while for salmon it is with respect to the genome. For; > certain samples (e.g. if you get a bad sample with poor rRNA depletion; > etc.) you can have many reads align to the genome, but none of them align; > to the annotated transcriptome.; >; > --Rob; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/COMBINE-lab/salmon/issues/616#issuecomment-764188266>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/ACPSFVD3TOPU3IYXVD6ZWKDS26FXVANCNFSM4WL6CV6A>; > .; >",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/616#issuecomment-764205368:506,log,log,506,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/616#issuecomment-764205368,1,['log'],['log']
Testability,"Hi,; I'm having a similar issue with specification of library type. I'm quantifying a single-end library of type SF with salmon 1.3.0. ; The two commands being compared are:. auto detect:. salmon --no-version-check quant --writeMappings -i target --incompatPrior 0.0 --validateMappings -l A -r d218056_dedup.fastq -p 4 -o d218056_A.quant > d218056_A.sam. specify SF:. salmon --no-version-check quant --writeMappings -i target --incompatPrior 0.0 --validateMappings -l SF -r d218056_dedup.fastq -p 4 -o d218056_SF.quant > d218056_SF.sam. The log files indicate that salmon correctly identifies the library as SF in the auto case. I noticed the issue when examining a pair of genes with overlapping 3'UTRs. The forward strand gene (GQ67_03478) is expressed at a much lower level than the reverse strand gene (GQ67_03479). The sam files contain the same number of reads mapped to each transcript without regard to how the libtype is specified:. egrep -v '^@' d218056_A.sam|grep -c GQ67_03478 ; 382; egrep -v '^@' d218056_A.sam|grep -c GQ67_03479; 399; egrep -v '^@' d218056_SF.sam|grep -c GQ67_03478 ; 382; egrep -v '^@' d218056_SF.sam|grep -c GQ67_03479; 399. The quantitation is very different with 120 counts assigned to the forward strand gene in the A case and a much more accurate (based on examination of the sam file) 10 counts in the SF case:. grep GQ67_03478 d218056_A.quant/quant.sf ; GQ67_03478T0 2914 2664.000 202.831978 119.926. grep GQ67_03478 d218056_SF.quant/quant.sf ; GQ67_03478T0 2914 2664.000 17.066270 10.000. For the reverse strand gene, the auto case undercounts due to reads being assigned to the forward strand gene. grep GQ67_03479 d218056_A.quant/quant.sf ; GQ67_03479T0 1383 1133.000 1245.013842 313.074. grep GQ67_03479 d218056_SF.quant/quant.sf ; GQ67_03479T0 1383 1133.000 1589.051981 396.000. I've been using salmon with -l A thinking that if the software correctly recognizes the libtype, the results would be nearly identical to explicitly specifying the libtype but th",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/489#issuecomment-738804437:541,log,log,541,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/489#issuecomment-738804437,1,['log'],['log']
Testability,"Hi,; Sorry for reviving this old thread, but could you confirm that this option was indeed implemented and tested, and let me know which version of Salmon it was implemented on?; Thanks",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/83#issuecomment-291810537:107,test,tested,107,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/83#issuecomment-291810537,1,['test'],['tested']
Testability,"Hi,; it goes literally in panic: . ```; panic: runtime error: slice bounds out of range. goroutine 1 [running]:; github.com/sylabs/singularity/internal/pkg/util/uri.Split(0x7ffd422b2b65, 0x1f, 0xc00003c195, 0xc0004852f0, 0xc0004e5c78, 0x929217); 	/tools/others_tools/Go/go-1.11.2/src/github.com/sylabs/singularity/internal/pkg/util/uri/uri.go:104 +0x13e; github.com/sylabs/singularity/cmd/singularity/cli.replaceURIWithImage(0x19d2a60, 0xc0000b8900, 0x11, 0x12); 	/tools/others_tools/Go/go-1.11.2/src/github.com/sylabs/singularity/cmd/singularity/cli/actions.go:189 +0x5d; github.com/sylabs/singularity/vendor/github.com/spf13/cobra.(*Command).execute(0x19d2a60, 0xc000030160, 0x12, 0x12, 0x19d2a60, 0xc000030160); 	/tools/others_tools/Go/go-1.11.2/src/github.com/sylabs/singularity/vendor/github.com/spf13/cobra/command.go:755 +0x4ed; github.com/sylabs/singularity/vendor/github.com/spf13/cobra.(*Command).ExecuteC(0x19d65c0, 0x0, 0xf6, 0xfc0b01); 	/tools/others_tools/Go/go-1.11.2/src/github.com/sylabs/singularity/vendor/github.com/spf13/cobra/command.go:852 +0x2fd; github.com/sylabs/singularity/vendor/github.com/spf13/cobra.(*Command).Execute(0x19d65c0, 0x4, 0x1133611); 	/tools/others_tools/Go/go-1.11.2/src/github.com/sylabs/singularity/vendor/github.com/spf13/cobra/command.go:800 +0x2b; github.com/sylabs/singularity/cmd/singularity/cli.ExecuteSingularity(); 	/tools/others_tools/Go/go-1.11.2/src/github.com/sylabs/singularity/cmd/singularity/cli/singularity.go:114 +0x110; main.main(); 	/tools/others_tools/Go/go-1.11.2/src/github.com/sylabs/singularity/cmd/singularity/cli.go:16 +0x20; ```; with -e you clean environment before running container.; I haven't found how to add the environmental variable, but logging in as shell and exporting the variable, it works ( or at least, I discover that I have to rebuild the index since it was built with the old verision in RapMap). I'll see if there is another way to import the variable or I'll build an image with the env; Thanks ; Claudio",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/447#issuecomment-553005722:1719,log,logging,1719,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/447#issuecomment-553005722,1,['log'],['logging']
Testability,"Hi. I just did:. ```; salmon index -t /no_backup/indexes/salmon/gencode_mm10/gentrome.fa \; -i /no_backup/indexes/salmon/gencode_mm10 \; -d /no_backup/indexes/salmon/gencode_mm10/decoys.txt \; -k 29 --threads 8; ````. And the log file says:. ```; Version Info: This is the most recent version of salmon.; [2021-12-30 00:46:18.878] [jLog] [info] building index; out : /no_backup/indexes/salmon/gencode_mm10; [2021-12-30 00:46:18.881] [puff::index::jointLog] [info] Running fixFasta. [Step 1 of 4] : counting k-mers; [2021-12-30 00:46:18.914] [puff::index::jointLog] [warning] It appears that this may be a GENCODE transcriptome (from analyzing the separators in the FASTA header). However, you have not set '|' as a header separator. If this is a GENCODE transcriptome, consider passing --gencode to the pufferfish index command. [2021-12-30 00:46:19.915] [puff::index::jointLog] [warning] Entry with header [ENSMUST00000229312.1|ENSMUSG00000056486.18|OTTMUSG00000013428.7|OTTMUST00000171565.1|Chn1-211|Chn1|20|processed_transcript|], had length less than equal to the k-mer length of 29 (perhaps after poly-A clipping). # [omissis]. [2021-12-30 00:46:27.227] [puff::index::jointLog] [warning] Entry with header [ENSMUST00000226172.1|ENSMUSG00000002249.21|OTTMUSG00000024245.6|OTTMUST00000167695.2|Tead3-208|Tead3|11|processed_transcript|], had length less than equal to the k-mer length of 29 (perhaps after poly-A clipping); [2021-12-30 00:46:28.327] [puff::index::jointLog] [warning] Removed 1612 transcripts that were sequence duplicates of indexed transcripts.; [2021-12-30 00:46:28.327] [puff::index::jointLog] [warning] If you wish to retain duplicate transcripts, please use the `--keepDuplicates` flag; [2021-12-30 00:46:28.327] [puff::index::jointLog] [critical] The decoy file contained the names of 55 decoy sequences, but 0 were matched by sequences in the reference file provided. To prevent unintentional errors downstream, please ensure that the decoy file exactly matches with the fast",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/731#issuecomment-1002817868:226,log,log,226,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/731#issuecomment-1002817868,1,['log'],['log']
Testability,Hi. I'm having a similar issue. When I run the Salmon exec I get:. `MacBook-Pro-31:~ alex$ /Users/alex/Desktop/Code/Salmon-v0.8.0_macOS_10.12/bin/salmon ; exit;; dyld: Library not loaded: /usr/local/opt/tbb/lib/libtbbmalloc_proxy.dylib; Referenced from: /Users/alex/Desktop/Code/Salmon-v0.8.0_macOS_10.12/bin/salmon; Reason: image not found; Abort trap: 6; logout; `. I'm running Sierra 10.12.2. Can you advise? What do I specifically need to do to get Salmon to work?. Thanks.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/117#issuecomment-279257362:357,log,logout,357,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/117#issuecomment-279257362,1,['log'],['logout']
Testability,"Hmm, something's up. I just deleted my previous transcripts_quan directory, replaced salmon with this newer version, and ran the same command. It finishes almost immediately with a return value of 1. ```; $ /home/jorvis/salmon/bin/salmon quant -p 24 -i transcripts_index -l IU -1 R1.trimmed.PE.fastq -2 R2.trimmed.PE.fastq -o transcripts_quan; Version Info: This is the most recent version of Salmon.; # salmon (mapping-based) v0.6.0; # [ program ] => salmon ; # [ command ] => quant ; # [ threads ] => { 24 }; # [ index ] => { transcripts_index }; # [ libType ] => { IU }; # [ mates1 ] => { R1.trimmed.PE.fastq }; # [ mates2 ] => { R2.trimmed.PE.fastq }; # [ output ] => { transcripts_quan }; Logs will be written to transcripts_quan/logs; there is [2016-03-31 12:30:21.714] [jointLog] [info] parsing read library format; 1 lib; [jorvis@grid-1-3-4 salmon]$ echo $?; 1; [jorvis@grid-1-3-4 salmon]$ ls transcripts_quan; logs; [jorvis@grid-1-3-4 salmon]$ ls transcripts_quan/logs/; salmon_quant.log; [jorvis@grid-1-3-4 salmon]$ cat transcripts_quan/logs/salmon_quant.log ; [2016-03-31 12:30:21.714] [jointLog] [info] parsing read library format; ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/54#issuecomment-204011075:694,Log,Logs,694,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/54#issuecomment-204011075,7,"['Log', 'log']","['Logs', 'log', 'logs']"
Testability,"Hrmm, I seem to be able to load and map against that index (though I'm testing with the latest develop version). Is there anything specific about the machines / vms where this is failing versus succeeding?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/321#issuecomment-442557809:71,test,testing,71,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/321#issuecomment-442557809,1,['test'],['testing']
Testability,"Hrmm, it doesn't seem so. I am able to do cmake with exactly these options and it still runs the `fetchRapMap.sh` script. I tried this under both 0.8.2 and 0.9.1. Let me look more through the logs. Also, parallel builds *should* work in newer releases (our internal build does parallel make on our CI).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/181#issuecomment-367755018:192,log,logs,192,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/181#issuecomment-367755018,1,['log'],['logs']
Testability,"Hrmm, that shouldn't happen (i.e. that's why the log is called `stderrLog`). So something is strange there. I'll take a look. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/90#issuecomment-247079124:49,log,log,49,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/90#issuecomment-247079124,1,['log'],['log']
Testability,"I actually didn't test it :). I'll confirm the current behavior tomorrow. Thanks for following up on this!. > On Jan 3, 2016, at 8:37 PM, Rob Patro notifications@github.com wrote:; > ; > Actually, @mdshw5 --- it's not quite clear to me why the parser isn't doing the right thing in this case. If you take a look at how the paired-end sequence parser is actually populating the internal buffer (e.g. here), it is reading one entry from stream1 and then one entry from stream2. I'm guessing there may be some issue with having two different handles open to the same fifo? However, that doesn't seem like it should be a problem. Given the way the code is actually reading from the different streams, it's not clear to me why it's not currently working as expected. I'll try and take a deeper look.; > ; > —; > Reply to this email directly or view it on GitHub.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/29#issuecomment-168566647:18,test,test,18,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/29#issuecomment-168566647,2,['test'],['test']
Testability,"I agree – I wasn’t aware of that one. I’ve tested that and it has the same effect as the other flag, performance looks good.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/966#issuecomment-2416748677:43,test,tested,43,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/966#issuecomment-2416748677,1,['test'],['tested']
Testability,"I already attach the file. Can you see it right now?. Bests. > On Jun 13, 2019, at 3:07 PM, Avi Srivastava <notifications@github.com> wrote:; > ; > I think you forgot to attach the log file ?; > ; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub <https://github.com/COMBINE-lab/salmon/issues/375?email_source=notifications&email_token=AK7LCF6HIQSMM4UTPONU37TP2KLH5A5CNFSM4HX4WLH2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGODXUXQJA#issuecomment-501839908>, or mute the thread <https://github.com/notifications/unsubscribe-auth/AK7LCFZKFOYIZEGYU5YOIX3P2KLH5ANCNFSM4HX4WLHQ>.; >",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/375#issuecomment-501845900:181,log,log,181,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/375#issuecomment-501845900,1,['log'],['log']
Testability,"I also have had to submit indexing jobs with much larger resources and times since the switch to the new indexing method with whole genome decoys. Prior to this I could built and index asking for only 16GB of ram in minutes. Now, I have to request ~256GB of memory and it runs for 7-10 hours. These are just ""standard"" mouse transcriptomes (GENCODE M23). I should note that using 17-mers as my kmer length dramatically increased these requirements. I re-ran using 31-mers, and the time reduces to a couple of hours and only used ~20GB of memory. I've attached two files that have summaries of the resources used in the jobs I ran in the above. Everything about these jobs is the same, except for the k-mer lengths. I requested the same amount of resources for each, but you can see that the one labeled 31mer has drastically less ""ru_maxrss"", which is the maximum amount of memory used by the process (it's in KB, although it's not labeled in the log). I also noted that there weren't any hard page faults for either of the jobs (""ru_majflt""). The longer job did have more soft page faults/page reclaims (""ru_minflt""). I don't know if that's useful information or not. [qacct-17mer.log](https://github.com/COMBINE-lab/salmon/files/4172209/qacct-17mer.log); [qacct-31mer.log](https://github.com/COMBINE-lab/salmon/files/4172210/qacct-31mer.log)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/476#issuecomment-583526416:947,log,log,947,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/476#issuecomment-583526416,5,['log'],['log']
Testability,"I also tried on the `testing` image. For more detail, here are the steps performed (perhaps taking a look at the installed packages will highlight a difference, as I did this from a clean testing Docker image, so my environment had nothing else in it). ### Attempt to reproduce segfault on Debian:testing. ```{bash}; $ docker pull debian:testing. $ docker run -it debian:testing. $ apt-get update. $ apt-get install build-essential git libboost-all-dev liblzma-dev libbz2-dev cmake zlib1g-dev curl unzip wget libcurl4-openssl-dev. $ git clone https://github.com/COMBINE-lab/salmon.git; $ cd salmon; $ mkdir build && cd build; $ cmake -DNO_IPO=TRUE .. # GCC still doesn't handle LTO robustly; $ make -j8; $ make install; $ make test; ```. which leads to the output. ```; root@fd877e359439:/salmon/build# make install; [ 7%] Built target libcereal; [ 13%] Built target libtbb; [ 16%] Built target ntcard; [ 19%] Built target graphdump; [ 27%] Built target twopaco; [ 29%] Built target ksw2pp_sse2; [ 32%] Built target ksw2pp_sse4; [ 37%] Built target ksw2pp_basic; [ 38%] Built target ksw2pp; [ 59%] Built target puffer; [ 73%] Built target salmon_core; [ 76%] Built target alevin_core; [ 77%] Built target UnitTestsMain; [ 81%] Built target unitTests; [100%] Built target salmon; Install the project...; -- Install configuration: ""Release""; -- Installing: /salmon/lib/libntcard.a; -- Installing: /salmon/lib/ntcard/ntcard-targets.cmake; -- Installing: /salmon/lib/ntcard/ntcard-targets-release.cmake; -- Installing: /salmon/lib/libgraphdump.a; -- Installing: /salmon/lib/graphdump/graphdump-targets.cmake; -- Installing: /salmon/lib/graphdump/graphdump-targets-release.cmake; -- Installing: /salmon/lib/libtwopaco.a; -- Installing: /salmon/lib/twopaco/twopaco-targets.cmake; -- Installing: /salmon/lib/twopaco/twopaco-targets-release.cmake; -- Installing: /salmon/lib/libtbb.so; -- Installing: /salmon/lib/libtbb.so.12; -- Installing: /salmon/lib/libtbb.so.12.5; -- Installing: /salmon/lib/libtbbmalloc",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463312554:21,test,testing,21,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463312554,6,['test'],"['test', 'testing']"
Testability,"I am assuming you gave the `--chromium` to `pbmc_4k` data too and it's throwing error, since the above log doesn't seems to have it. I am puzzled because it should have complained much before starting reading the fastq. Can you please try the following command: ; ```; salmon alevin -p 10 -lISR --chromium --no-version-check -1 /path/to/downloads/10xPBMC/pbmc4k_S1_L001_R1_001.fastq.gz -2 /path/to/downloads/10xPBMC/pbmc4k_S1_L001_R2_001.fastq.gz -i /path/to/salmonIndex -o alevin_output --tgMap tx2gene.tsv; ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/264#issuecomment-410328801:103,log,log,103,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/264#issuecomment-410328801,1,['log'],['log']
Testability,"I am unsure what qualifies as many but on an input of 20M reads and an unsorted BAM file, I get around 600 lines of error in the log file, some of the reads have many alignments so the errors are redundant to some extent. The no. of unique reads' alignments that cause an error is perhaps 300.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/701#issuecomment-1427049939:129,log,log,129,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/701#issuecomment-1427049939,1,['log'],['log']
Testability,"I assumed it was latter :) I can re-run it in a few days with more memory and actually benchmark (time, max memory, etc) it if that's helpful!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/476#issuecomment-575858246:87,benchmark,benchmark,87,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/476#issuecomment-575858246,1,['benchmark'],['benchmark']
Testability,"I believe this is because unlike the `salmon` target, the unitTests that run when `make test` is executed aren't installed via the `install` command [see e.g.](https://github.com/COMBINE-lab/salmon/blob/master/src/CMakeLists.txt#L312). This is due, I presume, to my naive usage of CMake as it relates to the testing target. I've yet to find a solid resource that explains the ""right way"" to handle this using (modern) CMake. That, of course, goes to your point of the pain of CMake.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/236#issuecomment-397080244:88,test,test,88,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/236#issuecomment-397080244,2,['test'],"['test', 'testing']"
Testability,"I can confirm that the problem in the log is not creating the exception error raised by this issue and the indexing procedure took care of the potential duplicates due to repeated names. There is something else going on. I used the binary from github and indexed, it seems to work on our end. @rob-p thoughts ?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/441#issuecomment-549155511:38,log,log,38,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/441#issuecomment-549155511,1,['log'],['log']
Testability,"I can try '^' and '$' after lunch. I didn't test any other library, since boost was already a pre-requisite for salmon and my focus was on getting it to work first. But now that it is done, other libraries can be tried. However, at this moment, I'm not clear about the effort and speed-up ratio.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/734#issuecomment-1013348732:44,test,test,44,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/734#issuecomment-1013348732,2,['test'],['test']
Testability,"I did not previously test that, but I am currently running the analysis with the extra `--expectCells 10000` parameter. I will post an update. If all goes well, I will then close the ticket. Thank you again for your help!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/682#issuecomment-883784536:21,test,test,21,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/682#issuecomment-883784536,1,['test'],['test']
Testability,"I did not see any output. That's the reason why the test stopped with the timeout.; Ref: https://travis-ci.org/COMBINE-lab/salmon/builds/419012959. Here is my commit on this PR. You can do cherry-pick to check it.; https://github.com/junaruga/salmon/commits/hotfix/develop-unrecognized-cxx-std-14_3. If you add `--verbose` or `--debug` to the `ctest`, you might see something?. ```; /usr/local/cmake-3.9.2/bin/ctest --force-new-ctest-process --verbose --debug; ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/276#issuecomment-416155226:52,test,test,52,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/276#issuecomment-416155226,1,['test'],['test']
Testability,"I didn't do more full testing, but it looks like the latter problem is indeed coming from `alevin-fry quant` (and this is a temporary but expected behavior). https://github.com/COMBINE-lab/alevin-fry/blob/967f5cbb404fb86a71291d88a73afa071570b575/libradicl/src/quant.rs#L1622-L1651. I'm not familiar enough with rust to know whether this will result in overwriting `cmd_info.json` and `meta_info.json` files that exist, but it does seem to me a good behavior would be to merge the info from `salmon alevin` and `alevin-fry`, particularly for the `meta_info.json` file, where both tools add useful information.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/688#issuecomment-883468182:22,test,testing,22,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/688#issuecomment-883468182,1,['test'],['testing']
Testability,"I didn't realize the resolver was so screwed up. And yeah, I get it that it's not your responsibility to fix it! In retrospect, as we're always specify versions in Snakemake profiles, the problem should be a non-issue. I was just doing some local testing when I encountered the ""issue"". Thx,; Adam",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/895#issuecomment-1784111111:247,test,testing,247,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/895#issuecomment-1784111111,1,['test'],['testing']
Testability,"I don't see any files named `*CMakeLog*`. Which file exactly do you need? I see…; ```; CMakeFiles/CMakeError.log CMakeFiles/CMakeRuleHashes.txt; CMakeFiles/CMakeOutput.log CMakeFiles/TargetDirectories.txt; ```; Here's a gist: https://gist.github.com/sjackman/6e15b7dfebaaad99b9476aa5ce269fda; This error is reproducible like so:; ```sh; docker run -it linuxbrew/linuxbrew brew install -sdv https://raw.githubusercontent.com/sjackman/homebrew-bio/dab661f902c5841e0d498eb338975c47080a1118/Formula/salmon.rb; ```. Ignore `FormulaUnavailableError: No available formula with the name ""xorg""`; and select `5. shell` to get a shell prompt",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/181#issuecomment-367793075:109,log,log,109,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/181#issuecomment-367793075,2,['log'],['log']
Testability,"I edited in the results of my 16GB test to the post above. There's something a bit weird going on with that job in particular. However, I can say that despite the (relatively) severe memory limitation, it appears that everything worked out just fine in ~4hrs. Not the fastest time overall, but factoring the times that I was stuck waiting for resources on those huge jobs, this is definitely an improvement.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/476#issuecomment-590592852:35,test,test,35,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/476#issuecomment-590592852,1,['test'],['test']
Testability,"I explicitly preallocate the output array/vector for pcre and re2. Boost regex doesn't seem to offer that (at least, I don't know). Regarding xpressive: yeah, what a disappointment. And I don't actually save the capture with xpressive. I thought the automaton was entirely generated and optimize at compile time. Apparently creating an automaton with C++ template system must be really hard because the generated code is garbage. Or I am using it wrong. In any case, xpressive as I use it is entirely static (I haven't tested the dynamic version). So it is not useful in our case. I was just curious if it could match hand crafted code. What was I thinking!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/734#issuecomment-1024206420:519,test,tested,519,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/734#issuecomment-1024206420,1,['test'],['tested']
Testability,"I guess there can be many things and it's hard to say without the logs, can you share the alevin and the salmon logs ?; Like @rob-p mentioned you can try changing ISR to ISF and/or using alevin-fry and check if that makes a difference, although if it's about mapping then probably it won't matter. I did notice one strange thing in the `umi extract` command though, please recheck this through the UMI tools package but you used `--stdout GSE140511/fastq_files/SRR10480618_BC_1.fastq.gz` and `--read2-out GSE140511/fastq_files/SRR10480618_BC_2.fastq.gz` in the umi tools command, which are the two files that probably should be provided as `-1` and `-2` flags to alevin. I am not sure why you are using `GSE140511/fastq_files/SRR10480618_1.fastq.gz` as the `-2` flag, which looks wrong to me, may be that will solve the issue. . Hope it helps.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/763#issuecomment-1073009028:66,log,logs,66,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/763#issuecomment-1073009028,2,['log'],['logs']
Testability,"I have a pretty wide array of benchmarks and I haven't seen any regression with the VB option on 0.4.1, including ERCC spike-ins on the SEQC data, where it does very well. But I haven't tested 0.4.0. @vals your data looks really compelling, I wonder if you'd humor me and try something, if it's not too much trouble: Could you try recomputing these correlations excluding ERCC-00074 and ERCC-00130? I've seen some data suggesting these might be misannotated by the vendor, which can cause these two to have a large effect on something like Pearson correlation, especially with methods like salmon and cufflinks that do bias correction. In benchmarks I've done, excluding them leads to more reliable results. I'm really curious if doing the same in your data changes anything.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/6#issuecomment-111743583:30,benchmark,benchmarks,30,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/6#issuecomment-111743583,3,"['benchmark', 'test']","['benchmarks', 'tested']"
Testability,I have attached a small subset of the bam for testing. ; [in.bam.zip](https://github.com/COMBINE-lab/salmon/files/3337430/in.bam.zip),MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/387#issuecomment-506585956:46,test,testing,46,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/387#issuecomment-506585956,1,['test'],['testing']
Testability,"I have tried to dichotomise my transcript db. The 2nd transcript in the attached file, crashes with the 2x12 paired-end fastq I have tried (ISR or IU). index was generated with:; salmon index -t test.fa --gencode -k 31 -i index. quantification with:; salmon quant -i index -l A -1 /tmp/r1.fastq.gz -2 /tmp/r2.fastq.gz --validateMappings -o test",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/228#issuecomment-393482153:195,test,test,195,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/228#issuecomment-393482153,2,['test'],['test']
Testability,"I haven't done too much testing with the quality of inferring the fragment start position distribution with few samples. 5 million is probably overkill, as it's a fairly low-dimensional model --- you could try setting the number of burnin fragments to a lower number.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/33#issuecomment-168354132:24,test,testing,24,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/33#issuecomment-168354132,1,['test'],['testing']
Testability,"I increased ram to 24G. Segmentation fault happens even faster. I have fiddled with swap memory, to no avail, but I am not a good swap fiddler.; libs with malloc in their name, installed in directory /salmon-latest_linux_x86_64/ib adjacent to /salmon-latest_linux_x86_64/bin, are the same as elsewhere already on my system. conda and bioconda are not available for FreeBSD. What OS would work?; I have looked through the published papers and find no mention of which OS should work. My attempted command for compiling the sources from unzipped directory salmon-0.14.1 is: cmake -S src -B build; Many errors result, starting with:; TBB_LIBRARIES = ; Setting libdivsufsort = /external/install/lib/libdivsufsort.a; Setting libdivsufsort64 = /external/install/lib/libdivsufsort64.a; -- Configuring done; CMake Error at CMakeLists.txt:196 (add_executable):; Cannot find source file:. /tests/UnitTests.cpp. Tried extensions .c .C .c++ .cc .cpp .cxx .cu .m .M .mm .h .hh .h++ .hm; .hpp .hxx .in .txx. CMake Error at CMakeLists.txt:196 (add_executable):; Target ""unitTests"" links to target ""Threads::Threads"" but the target was; not found. Perhaps a find_package() call is missing for an IMPORTED; target, or an ALIAS target is missing?. CMake Error at CMakeLists.txt:162 (add_library):; Cannot find source file:. /src/jellyfish/mer_dna.cc. Tried extensions .c .C .c++ .cc .cpp .cxx .cu .m .M .mm .h .hh .h++ .hm; .hpp .hxx .in .txx. Apparently the so-called sources do not include many files ending in .cpp, for instance. Please, I repeat, what linux OS should be able to install salmon? ; And/Or what command could compile salmon?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/419#issuecomment-522626638:880,test,tests,880,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/419#issuecomment-522626638,1,['test'],['tests']
Testability,"I just tried the /dev/fd/0 approach. First I ran. ```; salmon quant -i /nfs/research2/teichmann/reference/mus-musculus/salmon/quasi/mouse_cdna_38.p3.78_repbase_ercc.fa -l IU -1 reads_1.fastq -2 reads_2.fastq -o normal_salmon_out; ```. In this case the following is the content of the `salmon_quant.log`. ```; [2016-01-03 00:33:37.001] [jointLog] [info] parsing read library format; [2016-01-03 00:33:37.510] [jointLog] [info] Loading Quasi index; [2016-01-03 00:33:53.646] [jointLog] [info] done; [2016-01-03 00:34:14.501] [jointLog] [info] Computed 13742 rich equivalence classes for further processing; [2016-01-03 00:34:14.501] [jointLog] [info] Counted 335230 total reads in the equivalence classes; [2016-01-03 00:34:14.501] [fileLog] [info]; At end of round 0; ==================; Observed 3835342 total fragments (3835342 in most recent round). [2016-01-03 00:34:20.992] [jointLog] [warning] Only 335230 fragments were mapped, but the number of burn-in fragments was set to 5000000.; The effective lengths have been computed using the observed mappings. [2016-01-03 00:34:20.992] [jointLog] [info] Mapping rate = 8.74055%. [2016-01-03 00:34:20.992] [jointLog] [info] finished quantifyLibrary(); [2016-01-03 00:34:20.992] [jointLog] [info] Starting optimizer; [2016-01-03 00:34:21.028] [jointLog] [info] Marked 0 weighted equivalence classes as degenerate; [2016-01-03 00:34:21.030] [jointLog] [info] iteration = 0 | max rel diff. = 23.4889; [2016-01-03 00:34:21.167] [jointLog] [info] iteration = 100 | max rel diff. = 0.150549; [2016-01-03 00:34:21.304] [jointLog] [info] iteration = 200 | max rel diff. = 0.0517672; [2016-01-03 00:34:21.447] [jointLog] [info] iteration = 300 | max rel diff. = 0.0368208; [2016-01-03 00:34:21.578] [jointLog] [info] iteration = 400 | max rel diff. = 0.0237254; [2016-01-03 00:34:21.705] [jointLog] [info] iteration = 500 | max rel diff. = 0.0147784; [2016-01-03 00:34:21.834] [jointLog] [info] iteration = 600 | max rel diff. = 0.0131134; [2016-01-03 00:34:21",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/29#issuecomment-168447784:298,log,log,298,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/29#issuecomment-168447784,1,['log'],['log']
Testability,I just tried to index the GRCh38 transcriptome with decoys on a local machine (macOS Catalina 16GB) and it seemed to be doing ok for a while but after ~3hrs it got stuck (see log attached). I waited a good long while before killing it. Any suggestions?; These are the files I'm using:; ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_33/gencode.v33.transcripts.fa.gz; ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_33/GRCh38.primary_assembly.genome.fa.gz. [ref_indexing.log](https://github.com/COMBINE-lab/salmon/files/4377206/ref_indexing.log). EDIT: works fine without using decoys.; EDIT2: do you recommend using the indexes you link to here: http://bit.ly/30yn3FJ ? Or is there someway you could link to updated versions for the latest Salmon? ; thanks!,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/476#issuecomment-603455186:175,log,log,175,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/476#issuecomment-603455186,3,['log'],['log']
Testability,I made myself a plot to illustrate @roryk 's approach (hopefully got it right)- just leaving it here in case others are interested. ![compare_droplet_threshold](https://user-images.githubusercontent.com/5775915/57373557-9032fa00-7190-11e9-9cec-15b0a32f88aa.png). Code here: https://github.com/ebi-gene-expression-group/jon-sandbox/tree/master/droplet_cutoffs.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/362#issuecomment-490391990:323,sandbox,sandbox,323,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/362#issuecomment-490391990,1,['sandbox'],['sandbox']
Testability,"I might add that the progress display is pretty, but having an option to exclude it from the stderr logging, or even have no status updates, would be helpful for log file analysis.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/55#issuecomment-209989267:100,log,logging,100,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/55#issuecomment-209989267,2,['log'],"['log', 'logging']"
Testability,"I processed the data above using the latest salmon from the develop branch; (the release candidate for 1.3.0), and I got the following time (used 8; threads, so timing is not directly comparable). ```; 4604.57user 43.64system 9:24.15elapsed 823%CPU; ```. The whole log is. ```; [2020-06-15 23:51:54.747] [jointLog] [info] setting maxHashResizeThreads to; 8; [2020-06-15 23:51:54.747] [jointLog] [info] Fragment incompatibility prior; below threshold. Incompatible fragments will be ignored.; [2020-06-15 23:51:54.747] [jointLog] [info] Usage of --validateMappings; implies use of minScoreFraction. Since not explicitly specified, it is; being set to 0.65; [2020-06-15 23:51:54.747] [jointLog] [info] Usage of --validateMappings; implies a default consensus slack of 0.2. Setting consensusSlack to 0.35.; [2020-06-15 23:51:54.747] [jointLog] [info] parsing read library format; [2020-06-15 23:51:54.747] [jointLog] [info] There is 1 library.; [2020-06-15 23:51:54.814] [jointLog] [info] Loading pufferfish index; [2020-06-15 23:51:54.814] [jointLog] [info] Loading dense pufferfish index.; [2020-06-15 23:51:55.555] [jointLog] [info] done; [2020-06-15 23:51:55.555] [jointLog] [info] Index contained 116,248 targets; [2020-06-15 23:51:55.588] [jointLog] [info] Number of decoys : 0; [2020-06-16 00:00:59.666] [jointLog] [info] Computed 344,764 rich; equivalence classes for further processing; [2020-06-16 00:00:59.666] [jointLog] [info] Counted 12,956,134 total reads; in the equivalence classes; [2020-06-16 00:00:59.673] [jointLog] [warning] 0.0736383% of fragments were; shorter than the k used to build the index.; If this fraction is too large, consider re-building the index with a; smaller k.; The minimum read size found was 1. [2020-06-16 00:00:59.673] [jointLog] [info] Number of mappings discarded; because of alignment score : 134,091,887; [2020-06-16 00:00:59.673] [jointLog] [info] Number of fragments entirely; discarded because of alignment score : 2,429,390; [2020-06-16 00:00:59.673]",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/537#issuecomment-644520228:265,log,log,265,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/537#issuecomment-644520228,1,['log'],['log']
Testability,"I realized that most of these unassigned reads are probably paired-end reads that didn't match the specified the libType, which was ""IU"", or inward, not stranded. So I ran `samtools stats` on my BAM file to verify that.; ```; SN inward oriented pairs: 6191674; SN outward oriented pairs: 13515; ```; The inward pairs 6191674 is close to the pairs Salmon assigned, which was 6192944, but not the same. That's OK, considering Salmon and samtools probably have different ways of defining inward, outward read pairs.; I think it's helpful if Salmon can say in the log how many reads were excluded, for what reason. Thanks.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/952#issuecomment-2292317033:560,log,log,560,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/952#issuecomment-2292317033,1,['log'],['log']
Testability,"I really hope it doesn't 😟 , but the testing I've been doing is on 64-bit 14.10. I have a 16.04 box I can try it on as well. running on the 16.10 machine now to see if I can repro.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-266936224:37,test,testing,37,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-266936224,1,['test'],['testing']
Testability,"I see, we might have to tweak a bit based on the use case for `longranger basic`.; In `v0.10`, alevin should still be able to do CB correction, and attach the corrected CBs to the header of the second file, although the remaining template sequence (128 bases) from the first file might get loss, since `cellranger` was using template sequencing in only one file. Like @rob-p was saying we can work on making this step more generalized, once we confirm that the error-correction model for `cellranger` and `longranger` can be used interchangeably. In theory we can still concatenate the remaining 128 bases into an interleaved format since alevin has hidden options to provide the lengths explicitly but we have not tested this feature extensively. We will keep this at the top of our feature-request list and would inform you as soon as we have a stable version with this feature. Thanks again for the interest !!. re: *interleaved format* -- indeed an interleave format does makes sense and should be the default dumping format, but I believe since the default mode of 10x's `mkfastq` is to dump separate `FASTQ`, we should not use resources to create an interim interleaved format and then consume it downstream (since`FASTQ` itself is not very efficient), instead, in alevin we just consume the two separate `FASTQ` into our own interim data-structure to perform the downstream analysis.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/233#issuecomment-395195411:715,test,tested,715,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/233#issuecomment-395195411,1,['test'],['tested']
Testability,I seem to be having this same problem attempting to compile salmon 0.7.2 using GCC 5.3 (linuxbrew) on our server cluster. Works fine on my Mac though. Any ideas? I can post the log.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/46#issuecomment-247394237:177,log,log,177,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/46#issuecomment-247394237,1,['log'],['log']
Testability,I tested against the released 0.6.0 tarball.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/70#issuecomment-239631165:2,test,tested,2,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/70#issuecomment-239631165,1,['test'],['tested']
Testability,"I tested changing the parameters, and I am still getting the same error message:. ```; [2021-07-08 16:05:50.979] [alevinLog] [info] Done importing white-list Barcodes; [2021-07-08 16:05:50.979] [alevinLog] [error] Wrong whitelist provided; Please check https://salmon.readthedocs.io/en/develop/alevin.html#whitelist; ```. However, I will look into the other information and see if I can understand what is happening. I can also test not using a white list and see if that changes the number to be something like an order of magnitude different that what I would expect from the other sample. So, I will post an update when I can run alevin without an error message, and try to give some sense of the results that are quantified.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/682#issuecomment-877303669:2,test,tested,2,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/682#issuecomment-877303669,2,['test'],"['test', 'tested']"
Testability,"I think I see the issue, and we might not actually need the data.; The issue being the list of CBs in `whitelist.txt` is too many. It seems the data is very noisy and `knee` finding algorithm is failing. I'd suggest to use `--dumpFeatures` flag with alevin (you can also do `--noQuant` to stop alevin before mapping). This flag will generate `raw_cb_frequency.txt` file i.e. the frequency of all the observed CB and making the histogram will help visually find if there is possible knee in the data, generally it is in a real experiment. re: the mapping rate, in the alevin log you'll observe there were 50% of the CB which were thrown away if you use `forceCells 3000` w/o whitelist, basically alevin is taking top `3000` cells into consideration and throwing everything away. While the rise in mapping rate when externally provided with whitelist is actually by allowing more CB to go through. The two options `forceCells` and `whitelist` wan't intended to be use simultaneously because if provided with external whitelist alevin assumes the user is confident with the set of CBs, in your case this list is huge (~700k). Are you using the 10x whitelist from their website? If yes, then it's not what alevin expect with `--whitelist` option. One work around here would be to look at the CB frequency histogram and making a file with only the CB sequences which you thing are above knee. Providing that file as the `--whitelist` is the intended use case for alevin. Hope this makes sense.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/340#issuecomment-458718943:574,log,log,574,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/340#issuecomment-458718943,1,['log'],['log']
Testability,I think logging non-error output to stderr is OK.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/55#issuecomment-237040761:8,log,logging,8,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/55#issuecomment-237040761,1,['log'],['logging']
Testability,"I think we should sort out this issue step by step. If you say `libstaden` has an important bugfix we should upgrade to the latest version in any case. Do you have a link to this bug? I admit this update simply slipped through - we should have upgraded this in the beginning of this year. Usually we try to follow upstream closely (which we failed for salmon blatantly for several reasons - one is the close connection to pufferfish).; Regarding `pufferfish`: We tried hard to get `pufferfish` packaged but failed (due to the use of other versions of `spdlog`, `cereal`, and `fmt`) However, since we can't run `fetchPufferfish.sh` *inside the build process* I was running it separately and added the downloaded source in [debian/external/pufferfish](https://salsa.debian.org/med-team/salmon/-/tree/master/debian/external/pufferfish) So I think the requirement of salmon should be fulfilled. I confirm your feeling that pufferfish is important for the current issue.; However, in the test I did when opening this bug report I did not do that pre-downloading of pufferfish since I was building right in the downloaded source tarball. `libpufferfish-dev` was not installed by `apt build-dep salmon` since this package does not exist.; Kind regards, Andreas.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1464878371:983,test,test,983,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1464878371,2,['test'],['test']
Testability,I think you forgot to attach the log file ?,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/375#issuecomment-501839908:33,log,log,33,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/375#issuecomment-501839908,1,['log'],['log']
Testability,"I think you're right wrt conda. I was able to install 1.10.2 with mamba fairly easily. We've been moving away from conda (towards mamba) but this didn't cross my mind when I was playing in my sandbox. Might be some cluster latency issues combined with conda's snail's pace causing the problem on our end. Thx for the quick replies!. Adam H. Freedman, PhD; Data Scientist; Faculty of Arts & Sciences Informatics Group; Harvard University; 38 Oxford St; Cambridge, MA 02138; phone: +001 310 415 7145; ________________________________; From: Rob Patro ***@***.***>; Sent: Sunday, October 29, 2023 11:01 AM; To: COMBINE-lab/salmon ***@***.***>; Cc: Freedman, Adam ***@***.***>; Mention ***@***.***>; Subject: Re: [COMBINE-lab/salmon] anaconda version of salmon outdated, missing decoys option (Issue #895). Hi @adamfreedman<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_adamfreedman&d=DwMCaQ&c=WO-RGvefibhHBZq3fL85hQ&r=MITI_LEJgyr1a24IMFAlSaZIPxMpOUT21T7L3fg4CjA&m=40O3raH84f_BIZ3HF7nqTYSO2FehGrGHL9b7sqT7LIpWZjFmA3BLxNDTHoz420jp&s=kxY9gCLGWZJp-dp7l31S6M5u2RuUTeWXVrKmaydpo5o&e=>,. I think this is just conda being very very very slow (and potentially broken). The following works fine for me (and finishes in ~1 minute):. mamba create -n salmon -c conda-forge -c bioconda salmon=1.10.2. Can you use the mamba resolver in your environment? Conda has become hardly usable over the years, but mamba works quite well as a fast replacement. I'll also note that I swapped the order of conda-forge and bioconda as the docs specify that bioconda should preferably come last in the list of channels. --Rob. —; Reply to this email directly, view it on GitHub<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_COMBINE-2Dlab_salmon_issues_895-23issuecomment-2D1784137337&d=DwMCaQ&c=WO-RGvefibhHBZq3fL85hQ&r=MITI_LEJgyr1a24IMFAlSaZIPxMpOUT21T7L3fg4CjA&m=40O3raH84f_BIZ3HF7nqTYSO2FehGrGHL9b7sqT7LIpWZjFmA3BLxNDTHoz420jp&s=GNiCXqUbJLM16QBJ5PNAqv-rsgDdpCpcvezPXO_riWk&e=>, or unsubscribe<",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/895#issuecomment-1784196835:192,sandbox,sandbox,192,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/895#issuecomment-1784196835,2,['sandbox'],['sandbox']
Testability,"I tried using Homo_sapiens.GRCh38.94.chr_patch_hapl_scaff.gtf.gz for the annotation file and ftp://ftp.ensembl.org/pub/release-94/fasta/homo_sapiens/cdna/Homo_sapiens.GRCh38.cdna.all.fa.gz to build the index but got a similar error. Here are the logs (I modified the salmon log a bit because it didn't have the error message that printed to stdout). [alevin.log](https://github.com/COMBINE-lab/salmon/files/3224429/alevin.log); [salmon_quant.log](https://github.com/COMBINE-lab/salmon/files/3224440/salmon_quant.log). One curious thing that I noticed:. ```; Index contained 175,775 targets; ...; ERROR: Txp to Gene Map not found for 175775 transcripts; ```; It seems to not be finding any of the transcripts? This was also the case for the gencode attempt that I made previously.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/336#issuecomment-496258062:246,log,logs,246,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/336#issuecomment-496258062,6,['log'],"['log', 'logs']"
Testability,"I tried wrapping the code around alphaSum but it didn't work.; I also set digammaMin to 1e-9 but no change.; What I find weird is that the following code works... ```cpp; #include <boost/math/special_functions/digamma.hpp>. int main() {; double logNorm = boost::math::digamma(1e-50);; printf(""%f\n"", logNorm);; return logNorm;; }; ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/229#issuecomment-393598770:245,log,logNorm,245,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/229#issuecomment-393598770,3,['log'],['logNorm']
Testability,"I wonder if the max 1-edit distance restriction is too stringent for 21 length barcodes. One important flag to play with is the `--minScoreFraction`. The basic rule to set that is define [here](https://github.com/COMBINE-lab/salmon/blob/91091fc3650a3220f657a9f31616916513f0ad02/src/SalmonUtils.cpp#L3242-L3253). The gist being say if we wan't max k-edit we allow all the reads above the following threshold score (as in the log ):. ```; [2020-06-04 17:55:11.700] [alevinLog] [info] set CITE-seq minScoreFraction parameter to : 0.797619; ```; i.e. we use the equation `(max_score + edit_cost) - 0.5) / max_score`; where `max_score` = 2 * length of barcode = 2 * 21 = 42,; and `edit_cost`= `min( k * (mismatch - match), k * (go + ge - match)`;; `mismatch` penalty = -4; `match` = 2; `go` gap open penalty = -4; `ge` gap extend penalty = -2. For k=1, we had `edit_cost = 8` leading to automatic setting of `minScoreFraction` of 0.797619.; we have looked at 15 length barcodes, but it's possible longer barcodes might have more sequencing error. Let's try allowing more edits i.e. k=2, by setting `--minScoreFraction 0.607` and see if it improves the mapping rate.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-639235133:424,log,log,424,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-639235133,1,['log'],['log']
Testability,I wonder if there is any output from the `unit_tests` that are hanging. Does the travis log provide anything?,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/276#issuecomment-416087043:88,log,log,88,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/276#issuecomment-416087043,1,['log'],['log']
Testability,"I would think the best way to test it would be as Mike says: run Salmon on a paired-end library with bias-correction enabled, and then re-run it on only read 1 of the same library, only read 2, and on all the reads but treating it as single-end, and see how close it comes in each case. I would say it's also important to test whether the bias estimation is robust against modest misspecification of the mean fragment size, since that is often not known very accurately.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/83#issuecomment-246164791:30,test,test,30,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/83#issuecomment-246164791,2,['test'],['test']
Testability,"I'm also at a loss for exactly what could bre going on here. Specifically, this bit confused me:. > It looks like the log points to a sample that completed successfully at 19:45:18.487 before the sample at the top of the post started 19:51:56.392. So, unless the clock is messed up, it seems the successful completion (which, obviously required loading the complete index for alignment) happens *before* the exception. Further, the output you printed around the exception happens at the start of program execution, so I don't understand the timeline of events here for a single run / execution.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/512#issuecomment-618093803:118,log,log,118,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/512#issuecomment-618093803,1,['log'],['log']
Testability,"I'm going to cc @dpryan79 on this — does it just not finish? It seems to work within our GitHub CI, where we have to grab the prebuilt salmon to test `simpleaf`.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/895#issuecomment-1784122719:145,test,test,145,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/895#issuecomment-1784122719,2,['test'],['test']
Testability,I'm still experiencing this `cmake` error:. ```; -- extracting... [tar xfz]; CMake Error: Problem with archive_write_finish_entry(): Can't restore time; CMake Error: Problem extracting tar: /var/tmp/sjackman/salmon20160307-4399-1vksuoo/salmon-0.6.0/external/libdivsufsort.zip; -- extracting... [error clean up]; CMake Error at /var/tmp/sjackman/salmon20160307-4399-1vksuoo/salmon-0.6.0/libdivsufsort-prefix/src/libdivsufsort-stamp/extract-libdivsufsort.cmake:33 (message):; error: extract of; '/var/tmp/sjackman/salmon20160307-4399-1vksuoo/salmon-0.6.0/external/libdivsufsort.zip'; failed; ```. Here's a gist of the logs:; https://gist.github.com/sjackman/2bbfcf212c555fb20505#file-02-make-L397-L404,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/10#issuecomment-193515060:616,log,logs,616,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/10#issuecomment-193515060,1,['log'],['logs']
Testability,"I'm testing it now. ``` sh; brew edit salmon; ```. Then add. ``` ruby; patch do; url ""https://github.com/COMBINE-lab/salmon/pull/70.patch""; sha256 ""7129eac8591ad954cca30576519071b1f5ea2a36206f973a1aef0bc1eb5d20da""; end; ```. Then. ``` sh; brew install salmon --build-bottle; brew bottle salmon --json -v; ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/70#issuecomment-239628714:4,test,testing,4,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/70#issuecomment-239628714,1,['test'],['testing']
Testability,I'm testing now whether `develop` bd7096e0fa055e0a71ab03a52d99977bcb61c905 is relocatable.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/70#issuecomment-239634152:4,test,testing,4,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/70#issuecomment-239634152,1,['test'],['testing']
Testability,"I've addressed this in a recent [commit](https://github.com/COMBINE-lab/salmon/commit/05859ef8412687be14de5084f3b1e0e688fb3e76). Now, `version`, `help`, `cite` and `swim` will print to stdout, while other normal logging messages will print to stderr. Basically, if it was specifically requested by the user, send it to stdout; otherwise send it to stderr.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/148#issuecomment-378405708:212,log,logging,212,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/148#issuecomment-378405708,1,['log'],['logging']
Testability,"I've run into this as well, but's proving tricky to track down. I'm by no mean a expert on build chains (or a C/C++ for that matter), but as far as I can figure, this issue seems specific to RedHat systems. I get exactly the same linking error on RH6 and RH7 using any GCC compiler I have access to on those systems (4.8.5, 5.2.0, 7.2.0). Compiling on an Arch system with GCC 9.2.0 (glibc 2.30) sees no issue. Unfortunately I don't have easy access to the same compiler versions on both systems. I'm compiling GCC 5.2.0 (with glibc2.28) on the Arch system to test this now, but it's going to be a little while before I even know if I have a working toolchain that can use it.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/455#issuecomment-558714532:559,test,test,559,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/455#issuecomment-558714532,1,['test'],['test']
Testability,"I've tried to reproduce the issue in docker by using the Build-Depends that are used in Debian:. $ docker pull debian:testing; $ docker run -it debian:testing; $ echo ""deb-src http://deb.debian.org/debian unstable main"" > /etc/apt/sources.list.d/10-debsrc.list; $ apt update; $ apt upgrade; $ apt build-dep salmon; $ wget https://github.com/COMBINE-lab/salmon/archive/refs/tags/v1.10.0.tar.gz; $ tar xaf v1.10.0.tar.gz; $ cd salmon-1.10.0; $ mkdir build && cd build; $ cmake -DNO_IPO=TRUE ..; $ make -j8; make -j8; [ 3%] Built target ksw2pp_sse4; [ 6%] Built target ntcard; [ 15%] Built target twopaco; [ 18%] Built target graphdump; [ 21%] Built target ksw2pp_sse2; [ 27%] Built target ksw2pp_basic; [ 43%] Built target salmon_core; [ 67%] Built target puffer; [ 68%] Built target ksw2pp; [ 69%] Built target UnitTestsMain; [ 73%] Built target alevin_core; [ 74%] Linking CXX executable unitTests; /usr/bin/ld: /usr/lib/x86_64-linux-gnu/libcurl.a(libcurl_gnutls_la-psl.o): in function `Curl_psl_destroy':; (.text+0x21): undefined reference to `psl_free'; /usr/bin/ld: /usr/lib/x86_64-linux-gnu/libcurl.a(libcurl_gnutls_la-psl.o): in function `Curl_psl_use':; (.text+0xbc): undefined reference to `psl_latest'; /usr/bin/ld: (.text+0x157): undefined reference to `psl_builtin'; /usr/bin/ld: /usr/lib/x86_64-linux-gnu/libcurl.a(libcurl_gnutls_la-version.o): in function `curl_version':; (.text+0x129): undefined reference to `BrotliDecoderVersion'; /usr/bin/ld: (.text+0x16f): undefined reference to `ZSTD_versionNumber'; /usr/bin/ld: (.text+0x1e3): undefined reference to `idn2_check_version'; /usr/bin/ld: (.text+0x20e): undefined reference to `psl_get_version'; /usr/bin/ld: /usr/lib/x86_64-linux-gnu/libcurl.a(libcurl_gnutls_la-version.o): in function `curl_version_info':; (.text+0x386): undefined reference to `idn2_check_version'; /usr/bin/ld: (.text+0x3ad): undefined reference to `BrotliDecoderVersion'; /usr/bin/ld: (.text+0x3b8): undefined reference to `BrotliDecoderVersion'; /usr/bin/ld: (.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463708855:118,test,testing,118,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463708855,2,['test'],['testing']
Testability,"If i use the smaller set of barcodes, then I progress further. However, I still receive an error message (and there no **quants_mat_rows.txt** file):. ```; [2021-07-13 13:59:07.109] [alevinLog] [info] Total 0.00 UMI after deduplicating.; [2021-07-13 13:59:07.109] [alevinLog] [info] Total 0 BiDirected Edges.; [2021-07-13 13:59:07.109] [alevinLog] [info] Total 0 UniDirected Edges.; [2021-07-13 13:59:07.134] [alevinLog] [info] Finished optimizer; /var/spool/slurmd/job3050767/slurm_script: line 23: 10494 Floating point exception../../Ref_Generation/salmon-1.5.1_linux_x86_64/bin/salmon alevin -l ISF --chromium -1 $R1 -2 $R2 -i $REF -p 4 -o $ID --tgMap $MAP --whitelist $CBWL. ```. If the barcode is on the opposite read, then I am not sure if I should really be using the reverse or reverse complement (possibly even for the full barcode list)?. However, for the sake of this discussion, I will now test not providing any white list. If that works, then I will close the ticket again. **Update (7/14/2021)**: I have added the full log file here: [cluster_log.log](https://github.com/COMBINE-lab/salmon/files/6819402/cluster_log.log)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/682#issuecomment-879497561:902,test,test,902,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/682#issuecomment-879497561,4,"['log', 'test']","['log', 'test']"
Testability,If salmon would just read stdin using a symbolic `-` then you should be able to do something like:. ``` bash; interleaved_fastq_emitter | salmon --mates1 - --mates2 - ; ```. ...as long as the fastq reading logic is operating on 4-lines at a time. This way there's no new arguments added to salmon.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/29#issuecomment-163361739:206,log,logic,206,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/29#issuecomment-163361739,1,['log'],['logic']
Testability,If you need testers for this I'm glad to help.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/37#issuecomment-188285598:12,test,testers,12,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/37#issuecomment-188285598,1,['test'],['testers']
Testability,"If you'd like to commit the equivalent of this PR into develop, I can test it for you. Give me the PR or commit SHA1, and I'll test it.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/70#issuecomment-239632730:70,test,test,70,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/70#issuecomment-239632730,2,['test'],['test']
Testability,"In terms of an intermediate update:. **Setting 1**:. _Command 1_:; `/path/to/salmon alevin -l ISF --chromium -1 $R1 -2 $R2 -i $REF -p 4 -o $ID --tgMap $MAP`; _End of Log 1_:; ```; [2021-07-13 20:12:34.651] [alevinLog] [info] Starting white listing of 814 cells; [2021-07-13 20:12:34.651] [alevinLog] [info] Starting to make feature Matrix; [2021-07-13 20:12:34.654] [alevinLog] [info] Done making feature Matrix; [2021-07-13 20:12:35.447] [alevinLog] [info] Finished white listing; [2021-07-13 20:12:36.158] [alevinLog] [info] Finished optimizer; 0.0408521	8.9925e-05	0.000114595	636780	18682.9	; 0.0290163	6.61624e-05	0.000111685	230922	8010.3	; ```; _Size of quants_mat_rows.txt 1_: 814 lines/barcodes. **Setting 2:**:; _Command 1_:; `/path/to/salmon alevin -l ISR --chromium -1 $R1 -2 $R2 -i $REF -p 4 -o $ID --tgMap $MAP`; _End of Log 1_:; ```; [2021-07-14 09:51:38.564] [alevinLog] [info] Starting white listing of 814 cells; [2021-07-14 09:51:38.564] [alevinLog] [info] Starting to make feature Matrix; [2021-07-14 09:51:38.566] [alevinLog] [info] Done making feature Matrix; [2021-07-14 09:51:39.347] [alevinLog] [info] Finished white listing; [2021-07-14 09:51:39.541] [alevinLog] [info] Finished optimizer; [2021-07-14 09:51:39.564] [jointLog] [warning] NOTE: Read Lib [[ ../Reads/5309-CT-2_S01_L005_R1_001.fastq.gz, ../Reads/5309-CT-2_S01_L005_R2_001.fastq.gz]] :. Greater than 5% of the fragments disagreed with the provided library type; check the file: 5309-CT-2/lib_format_counts.json for details. 0.0408521	8.9925e-05	0.000114595	636780	18682.9	; 0.0290163	6.61624e-05	0.000111685	230922	8010.3	; ```; _Size of quants_mat_rows.txt 1_: 814 lines/barcodes. Technically, this means that the program ran without generating an error message, but this seems strange to me. So, I think I would prefer to keep the issue open a little bit longer.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/682#issuecomment-880273749:166,Log,Log,166,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/682#issuecomment-880273749,2,['Log'],['Log']
Testability,"Internal testing suggests that these errors are gone, but feel free to report back here (and reopen this) if you still encounter it.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/50#issuecomment-303617599:9,test,testing,9,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/50#issuecomment-303617599,1,['test'],['testing']
Testability,"Is it possible for you to share the alevin log, then I can explain better the numbers ?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/379#issuecomment-503319334:43,log,log,43,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/379#issuecomment-503319334,1,['log'],['log']
Testability,Is there any output to the terminal when salmon is running that would suggest it couldn't interpret the GTF properly? Can you share the salmon log file?,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/569#issuecomment-709325079:143,log,log,143,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/569#issuecomment-709325079,1,['log'],['log']
Testability,"It appears that you're trying to index the entire mm9 genome using salmon. Both salmon and rapmap are designed to work with a smaller sequence space such as what you would find in a transcriptome. Your log file shows that salmon processes 615,000,000 bases from the genome and then aborts. Depending on how many transcripts are in your feature file, a human transcriptome [might be 5-10X smaller](http://seqanswers.com/forums/showthread.php?t=5298).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/49#issuecomment-197862096:202,log,log,202,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/49#issuecomment-197862096,1,['log'],['log']
Testability,It does seem that this option is implemented on the latest release (0.8.2). With single-end data with the --gcBias flag there is a warning about the implementation being experimental. Have you had a chance to test the results? Would be very interested to hear,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/83#issuecomment-320479168:209,test,test,209,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/83#issuecomment-320479168,1,['test'],['test']
Testability,"It looks like the first several runs crashed with:. ```; ...; [2016-12-18 12:10:47.956] [jointLog] [info] iteration = 519 | max rel diff. = 0.00832947; [2016-12-18 12:10:47.962] [jointLog] [info] Finished optimizer; [2016-12-18 12:10:47.962] [jointLog] [info] writing output. salmon: /usr/include/boost/random/gamma_distribution.hpp:117: boost::random::gamma_distribution<RealType>::gamma_distribution(const result_type&, const result_type&) [with RealType; = double; boost::random::gamma_distribution<RealType>::result_type = double]: Assertion `_alpha > result_type(0)' failed.; ```. And then a run finally hung with:. ```; [2016-12-18 13:31:06.283] [jointLog] [info] iteration = 517 | max rel diff. = 0.00871129; [2016-12-18 13:31:06.289] [jointLog] [info] Finished optimizer; [2016-12-18 13:31:06.289] [jointLog] [info] writing output. [2016-12-18 13:31:06.703] [jointLog] [info] Starting Gibbs Sampler; 0% [> ] ETA > 1 week; ```. Here's another batch of 100 backtraces: [salmon-gdb-bt.zip](https://github.com/COMBINE-lab/salmon/files/659757/salmon-gdb-bt.zip)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267855087:536,Assert,Assertion,536,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267855087,1,['Assert'],['Assertion']
Testability,"It must be a different `unitTest` executable that is running, since `make test` is just using CMake to run the same executable in `./src/unitTests`. I'm happy to help debug this further, but I'm currently most interested in how a transcript gets an infinite count after round 0.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/229#issuecomment-393692302:74,test,test,74,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/229#issuecomment-393692302,1,['test'],['test']
Testability,"It took ~1.5H for V1.2.1 with ```--hitFilterPolicy BOTH```. Attaching log and fastp report, which shows normal tetramer over-representation. By the insert size determined by fastp I suspect there's quite a bit of dovetailing, I did had extremely slow performance with dovetailed libraries (for example SRR7945268, which is insert size 100, and its a PE 150 [not my data]) even allowing dovetails, to the point I ended up mapping them as single end and not using one of the pairs. Even then it took its time. Edit: allowing dovetails only increased the mapping rate by 0.0277%. As an additional note, not ```--minAlnProb 0.1``` nor ```--hardFilter``` help. . [fastp.pdf](https://github.com/COMBINE-lab/salmon/files/4711278/fastp.pdf); [salmon_quant.log](https://github.com/COMBINE-lab/salmon/files/4711259/salmon_quant.log)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/527#issuecomment-636837126:70,log,log,70,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/527#issuecomment-636837126,3,['log'],['log']
Testability,"It's possible this is [related to the other issue](https://github.com/COMBINE-lab/salmon/issues/321), since I'm also seeing:. ```; 2018-11-28 18:01:19,745 i-05ef169a0611966c7 data_refinery_workers.processors.utils ERROR [pipeline_applied: SALMON] [failure_reason: Shell call to salmon failed because: ### salmon (; ### [ program ] => salmon; ### [ command ] => quant; ### [ libType ] => { A }; ### [ biasSpeedSamp ] => { 5 }; ### [ index ] => { /home/user/data_store/TRANSCRIPTOME_INDEX/HOMO_SAPIENS/long }; ### [ mates1 ] => { /home/user/data_store/processor_job_405995/SRR2963482_1.fastq }; ### [ mates2 ] => { /home/user/data_store/processor_job_405995/SRR2963482_2.fastq }; ### [ threads ] => { 16 }; ### [ output ] => { /home/user/data_store/processor_job_405995/SRR2963482_output/ }; ### [ seqBias ] => { }; ### [ gcBias ] => { }; ### [ dumpEq ] => { }; ### [ writeUnmappedNames ] => { }; Logs will be written to /home/user/data_store/processor_job_405995/SRR2963482_output/logs; [2018-11-28 18:01:15.711] [jointLog] [info] parsing read library format; [2018-11-28 18:01:15.711] [jointLog] [info] There is 1 library.; [2018-11-28 18:01:15.761] [stderrLog] [info] Loading Suffix Array; [2018-11-28 18:01:15.761] [jointLog] [info] Loading Quasi index; [2018-11-28 18:01:15.761] [jointLog] [info] Loading 32-bit quasi index; Exception : [Failed to read 1176099240 bytes from input stream! Read 872415224]; ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/322#issuecomment-442548280:895,Log,Logs,895,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/322#issuecomment-442548280,2,"['Log', 'log']","['Logs', 'logs']"
Testability,"Just a bit more information:. I installed through conda salmon=0.11.3 and executed command on two different fastq files. The first one was on a single lane of the data and the second was on a concatenated file across 4 lanes. I managed to run the single lane file but got a seg dump error for the ""big""er file. Both times it seems to output the correct files. . Single lane:; ```; salmon alevin -l ISR -1 hgmm_100_S1_L001_001.fastq.1.gz -2 hgmm_100_S1_L001_001.fastq.2.gz --chromium -i geneset.dir/geneset_coding_exons.salmon.index/ -o salmon.dir/ --tgMap transcript2geneMap.tsv --dumpCsvCounts; Version Info: ### PLEASE UPGRADE SALMON ###; ### A newer version of Salmon with important bug fixes and improvements is available. ####; ###; The newest version, available at https://github.com/COMBINE-lab/salmon/releases; contains new features, improvements, and bug fixes; please upgrade at your; earliest convenience.; ###; Logs will be written to salmon.dir/logs; ### alevin (dscRNA-seq quantification) v0.11.3; ### [ program ] => salmon ; ### [ command ] => alevin ; ### [ libType ] => { ISR }; ### [ mates1 ] => { hgmm_100_S1_L001_001.fastq.1.gz }; ### [ mates2 ] => { hgmm_100_S1_L001_001.fastq.2.gz }; ### [ chromium ] => { }; ### [ index ] => { geneset.dir/geneset_coding_exons.salmon.index/ }; ### [ output ] => { salmon.dir/ }; ### [ tgMap ] => { transcript2geneMap.tsv }; ### [ dumpCsvCounts ] => { }. [2019-01-29 09:54:57.898] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2019-01-29 09:54:57.916] [alevinLog] [info] Processing barcodes files (if Present) . ; processed 0 Million barcodes. [2019-01-29 09:54:59.693] [alevinLog] [info] Done barcode density calculation.; [2019-01-29 09:54:59.693] [alevinLog] [info] # Barcodes Used: 902561 / 912145.; [2019-01-29 09:55:04.490] [alevinLog] [info] Knee found left boundary at 391 ; [2019-01-29 09:55:04.817] [alevinLog] [info] Gauss Corrected Boundary at 99 ; [2019-01-29 09:55:04.81",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/337#issuecomment-458481722:923,Log,Logs,923,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/337#issuecomment-458481722,2,"['Log', 'log']","['Logs', 'logs']"
Testability,May as well post `brew gist-logs salmon` for the record.; I'll build a precompiled binary bottle for salmon 0.7.2.; https://github.com/Linuxbrew/homebrew-science/pull/282,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/46#issuecomment-247475711:28,log,logs,28,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/46#issuecomment-247475711,1,['log'],['logs']
Testability,"My apologies for the late reply, somehow I missed the reply.; I am glad to hear that and thanks for testing alevin with BD Rhapsody.; Let us know if you need help with anything else, we'd be happy to help. Closing this issue but feel free to reopen.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/445#issuecomment-565298381:100,test,testing,100,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/445#issuecomment-565298381,1,['test'],['testing']
Testability,"My little testing: https://github.com/OceanGenomics/RegexBench. Some results on matching 1 million short strings with ~90% positive match and ~10% random strings:; ```; time-manual:	Elapsed (wall clock) time (h:mm:ss or m:ss): 0:00.06; time-boostregex:	Elapsed (wall clock) time (h:mm:ss or m:ss): 0:00.28; time-pcre2:	Elapsed (wall clock) time (h:mm:ss or m:ss): 0:00.23; time-retwo:	Elapsed (wall clock) time (h:mm:ss or m:ss): 0:00.63; time-boostxpressive:	Elapsed (wall clock) time (h:mm:ss or m:ss): 0:05.76; time-grep:	Elapsed (wall clock) time (h:mm:ss or m:ss): 0:00.17; ```. retwo is RE2. It is surprisingly highly affected by the number of captures. With 4 captures as above, it is the slowest. Without any it is as fast as grep. And xpressive is very slow, while I expected it to be the fastest!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/734#issuecomment-1024181953:10,test,testing,10,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/734#issuecomment-1024181953,1,['test'],['testing']
Testability,"NCODEv29/combined_index -l IU ; -1 /home/RnaSeq/fastq/DM_4a_H_1.fq.gz /home/RnaSeq/fastq/DM_4b_H_1.fq.gz /home/RnaSeq/fastq/DM_4c_H_1.fq.gz ; -2 /home/RnaSeq/fastq/DM_4a_H_2.fq.gz /home/RnaSeq/fastq/DM_4b_H_2.fq.gz /home/RnaSeq/fastq/DM_4c_H_2.fq.gz ; -o /home/RnaSeq/salmon_output_files/out/DM4h; Version Info: Could not resolve upgrade information in the alotted time.; Check for upgrades manually at https://combine-lab.github.io/salmon; ### salmon (mapping-based) v0.14.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { /home/RnaSeq/transcriptome_gencode_v29/human_GENCODEv29/combined_index }; ### [ libType ] => { IU }; ### [ mates1 ] => { /home/RnaSeq/fastq/DM_4a_H_1.fq.gz /home/RnaSeq/fastq/DM_4b_H_1.fq.gz /home/RnaSeq/fastq/DM_4c_H_1.fq.gz }; ### [ mates2 ] => { /home/RnaSeq/fastq/DM_4a_H_2.fq.gz /home/RnaSeq/fastq/DM_4b_H_2.fq.gz /home/RnaSeq/fastq/DM_4c_H_2.fq.gz }; ### [ validateMappings ] => { }; ### [ output ] => { /home/RnaSeq/salmon_output_files/out/DM4h }; Logs will be written to /home/RnaSeq/salmon_output_files/out/DM4h/logs; [2019-07-01 12:51:42.856] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2019-07-01 12:51:42.856] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2019-07-01 12:51:42.856] [jointLog] [info] Usage of --validateMappings, without --hardFilter implies use of range factorization. rangeFactorizationBins is being set to 4; [2019-07-01 12:51:42.856] [jointLog] [info] Usage of --validateMappings implies a default consensus slack of 0.2. Setting consensusSlack to 0.2.; [2019-07-01 12:51:42.856] [jointLog] [info] parsing read library format; [2019-07-01 12:51:42.856] [jointLog] [info] There is 1 library.; Exception : [Error: The index version file /home/RnaSeq/transcriptome_gencode_v29/human_GENCODEv29/combined_index/versionInfo.json doesn't seem to exist. Please try re-buil",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/389#issuecomment-507253562:2945,Log,Logs,2945,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/389#issuecomment-507253562,2,"['Log', 'log']","['Logs', 'logs']"
Testability,"No additional ideas from me. I didn't cover single-end when coding up alpine, but I would go about it just as you describe. re: ""under the naive implementation in the single-end case"", I guess the _super-naive_ implementation is to just use the FLD mean to compute the observed GC model (ignore the distribution for this estimation task). It might get close enough. I guess one could test by comparing the GC bias estimates from running paired with read 1 & 2 vs running single end with just 1 or 2.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/83#issuecomment-243845991:384,test,test,384,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/83#issuecomment-243845991,1,['test'],['test']
Testability,"No, that shouldn't cause a problem. When I ran your command (including the `ISF` and placing the `--libType` after the set of reads), my run still completed successfully (and didn't produce any warnings during Gibbs sampling). Salmon's behavior when running in unstranded mode on stranded data is simply to map the reads in the orientation they match, and to report on the console (and in the log) that there was a mapping bias (i.e. that the data look stranded). Specifically, here is what I get when I run (a close approximation of) your command. ```; $salmon quant --index Salmon_index_hg38.analysisSet_knownGene --unmatedReads SRR2454059.fq.gz --libType ISF --useVBOpt --output test_quant --; numGibbsSamples 100 --threads 16; Version Info: This is the most recent **development version** of Salmon.; ### salmon (mapping-based) v0.7.3; ### [ program ] => salmon; ### [ command ] => quant; ### [ index ] => { Salmon_index_hg38.analysisSet_knownGene }; ### [ unmatedReads ] => { SRR2454059.fq.gz }; ### [ libType ] => { ISF }; ### [ useVBOpt ] => { }; ### [ output ] => { test_quant }; ### [ numGibbsSamples ] => { 100 }; ### [ threads ] => { 16 }; Logs will be written to test_quant/logs; [2016-12-13 22:38:54.413] [jointLog] [info] parsing read library format; [2016-12-13 22:38:54.413] [jointLog] [info] There is 1 library.; [2016-12-13 22:38:56.240] [stderrLog] [info] Loading Suffix Array; [2016-12-13 22:38:56.240] [jointLog] [info] Loading Quasi index; [2016-12-13 22:38:56.240] [jointLog] [info] Loading 32-bit quasi index; [2016-12-13 22:39:01.268] [stderrLog] [info] Loading Transcript Info; [2016-12-13 22:39:02.630] [stderrLog] [info] Loading Rank-Select Bit Array; [2016-12-13 22:39:03.041] [stderrLog] [info] There were 182608 set bits in the bit array; [2016-12-13 22:39:03.159] [stderrLog] [info] Computing transcript lengths; [2016-12-13 22:39:03.160] [stderrLog] [info] Waiting to finish loading hash; [2016-12-13 22:39:07.653] [stderrLog] [info] Done loading index; [2016-12-13 22",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-266934878:393,log,log,393,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-266934878,2,['log'],['log']
Testability,"Nominally, you can use `info locals` and `p x` (where x is a specific variable name) to look at the value of variables in the stack. However, without debug flags, the ability to peek at such values is questionable. Alternatively we could log the values that gamma is being called with before each call . . . but that's going to lead to some crazy logs until the hang occurs.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267842038:238,log,log,238,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267842038,2,['log'],"['log', 'logs']"
Testability,"OK --- very strange. I've been testing it out on different data and have been unable to reproduce the segfault. I'll try on your dataset when it's ready to see if the problem pops up. I actually hope it does, because it will be a very tricky bug to fix if it only happens on certain hosts!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/34#issuecomment-168424793:31,test,testing,31,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/34#issuecomment-168424793,1,['test'],['testing']
Testability,"OK, could you send me a private e-mail address so I don't post links for; the data publicly?. On Wed, Mar 30, 2016 at 3:42 PM, Rob Patro notifications@github.com wrote:. > Hi Josh,; > ; > My best guess is that something is awry with the 64-bit index. That; > code-path is less well-tested (since I don't really have any transcriptomes; > in my collection that exceed the size of a 32-bit signed int). If you're; > able to share the txome and / or the index itself, I'd be happy to try and; > reproduce and fix this. Actually, I'd be really happy to squash any bugs in; > the 64-bit code path.; > ; > --Rob; > ; > —; > You are receiving this because you authored the thread.; > Reply to this email directly or view it on GitHub; > https://github.com/COMBINE-lab/salmon/issues/54#issuecomment-203627077",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/54#issuecomment-203633436:282,test,tested,282,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/54#issuecomment-203633436,1,['test'],['tested']
Testability,"OK, so it seems like adding the UMI <-> eq class counting should be pretty straightforward. @vals, so when you say effective length should be kept constant, you mean we shouldn't adjust for bias, or that we don't expect a transcript length effect at all? Also, is there a basic primer I can read up on regarding the details of the data format (e.g. where in each read I should look for the tag, how long the tag is expected to be, etc.)? I'll be relying on you guys to test stuff out and point me at relevant data sets as I go forward with implementing this.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/108#issuecomment-269069945:469,test,test,469,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/108#issuecomment-269069945,1,['test'],['test']
Testability,Oh Sorry about that what I meant was the salmon.log file or the the meta-info.json file created by salmon in the output directory. You can check what files salmon is detecting it seems there are 12 files in the mate1 and 13 files in the mate2. Can you confirm there are 13 pairs of file in that directory and their regex is same as you are using ? Can you also try putting the names of the file instead `*` as regex ?,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/408#issuecomment-516195181:48,log,log,48,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/408#issuecomment-516195181,1,['log'],['log']
Testability,"Oh one more thing, is it possible to share a few hundred reads for your experiment, just for some unit testing on my side?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-638388616:103,test,testing,103,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-638388616,1,['test'],['testing']
Testability,"Oh wow 14k v 126k is indeed a big difference, is it possible to share the Alevin log for your run ? From the logs you attached it's not clear what's the mapping rate. May I also ask to look at another log file inside the logs folder, called salmon_quant.log. that would have more information regarding the mapping rate.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-639161938:81,log,log,81,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-639161938,10,['log'],"['log', 'logs']"
Testability,"Oh, so multiple things can go wrong based on how you sampled the read like CB frequency not being aligning with the expected experiment. I'd say if you have to try a small experiment, may be sample all the reads from say ~10 Cellular barcode and specify them to alevin using `--whitelist` flag. I just tested the data it seems to work with the following log.; ```; [2021-04-16 15:57:26.183] [jointLog] [info] Mapping rate = 48.8769%. [2021-04-16 15:57:26.183] [jointLog] [info] finished quantifyLibrary(); [2021-04-16 15:57:26.360] [alevinLog] [info] Starting optimizer; ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/647#issuecomment-821529523:302,test,tested,302,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/647#issuecomment-821529523,2,"['log', 'test']","['log', 'tested']"
Testability,"Ok ... so, now it's hanging in single-threaded code, and it does so in a call to std::gamma_distribution. I'm running out of logical possibilities here. Either (1) undefined behavior somewhere else is affecting the hanging here or (2) `std::gamma_distribution` is in an infinite loop. I'll note that `gamma_distribution` does contain a while loop, but I'd be immensely surprised if the standard libraries distribution sampler had an undiscovered infinite loop.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267840129:125,log,logical,125,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267840129,1,['log'],['logical']
Testability,"Ok @DarwinAwardWinner, I think it's fixed for real this time. The issue was stemming from an uninitialized prior value in the Gibbs sampler under VBOpt mode (the initialization code was updated on the develop branch, which is where the bug was introduced). This, in turn, was leading to `nan` being passed as the alpha parameter of `std::gamma_distribution`. With the `-Ofast` optimization flags, at least, this leads `std::gamma_distribution()` to hang forever in an infinite loop. Clearly, `nan` should not be passed to `std::gamma_distribution()`, but I'd argue the behavior of looping forever here is not great. Anyway, I fixed the initialization bug, so that this nan should never pop up. Just to be safe, I also changed the default optimization flag to `-O3` so that at least `nan` and `inf` can be properly tested. Since the TBB code and the parallel sampling weren't causing the issue, I've added them back in. Could you please test the latest push (40584e62859fb65463188b50d132c1eb622b21f0) and verify that this resolves the issue for you (*hopefully*!)?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267877253:814,test,tested,814,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267877253,2,['test'],"['test', 'tested']"
Testability,"Ok, I have an strace file from a hung run. I couldn't attach with gdb because the default system security settings prohibit it. I'll change the settings and try to get a gdb backtrace, but in the meantime, here's the strace log. Note that it was hung for about 2 hours before I was able to collect the log. https://www.dropbox.com/s/zn7qzo55wtcrbyg/salmon-strace.log.gz?dl=0",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267413760:224,log,log,224,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267413760,3,['log'],['log']
Testability,"Ok, I realized that the Segmentation fault was not caused by passing multiple bam files, but by including either the `--seqBias` or `--gcBias` arguments. . The following command generates the segmentation fault:. ```; salmon quant -t transcripts.fasta -g gene_annotations.gtf -l IU -p 8 -o quantitation -a Aligned.toTranscriptome.bam --seqBias --gcBias; ```. and returns the following output before exiting:. ```; # salmon (alignment-based) v0.7.2; # [ program ] => salmon; # [ command ] => quant; # [ targets ] => { transcripts.fasta }; # [ geneMap ] => { gene_annotations.gtf }; # [ libType ] => { IU }; # [ threads ] => { 8 }; # [ output ] => { quantitation }; # [ alignments ] => {Aligned.toTranscriptome.bam }; # [ seqBias ] => { }; # [ gcBias ] => { }; Library format { type:paired end, relative orientation:inward, strandedness:unstranded }; Logs will be written to quantitation/logs; numQuantThreads = 4; parseThreads = 4; Checking that provided alignment files have consistent headers . . . done; Populating targets from aln = ""Aligned.toTranscriptome.bam"", fasta = ""transcripts.fasta"" . . .WARNING: Transcript ENSMUST00000185127 appears in the reference but did not appear in the BAM; WARNING: Transcript ENSMUST00000180893 appears in the reference but did not appear in the BAM; WARNING: Transcript ENSMUST00000206884 appears in the reference but did not appear in the BAM; WARNING: Transcript ENSMUST00000181916 appears in the reference but did not appear in the BAM; WARNING: Transcript ENSMUST00000202657 appears in the reference but did not appear in the BAM; [truncated]. replaced 3 non-ACGT nucleotides with random nucleotides; done. processed 0 reads in current round; ```. follow by the segmentation fold. The same command without the `--seqBias --gcBias` arguments succeeds. Perhas bias correction is not supported (or even necessary) when quantifying from a bam file?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/104#issuecomment-261738122:849,Log,Logs,849,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/104#issuecomment-261738122,2,"['Log', 'log']","['Logs', 'logs']"
Testability,"Ok, I'll give it a try with the --expectCells flag. I'm working on implementing Salmon and Alevin (along with support for full and partial decoy indexing and preprocessing to add intron flanking sequences for velocity) in GenePattern so I needed to test that flag anyway.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/625#issuecomment-776212333:249,test,test,249,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/625#issuecomment-776212333,1,['test'],['test']
Testability,"Ok, I'm tagging @k3yavi since I believe he tested the hot fix with the data you shared. Hey may have some more insight on what's going on here. By the way, the command you quote above still contains the `--citeseq` flag, but I assume that's just a typo.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/670#issuecomment-860925409:43,test,tested,43,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/670#issuecomment-860925409,1,['test'],['tested']
Testability,"Ok, new plan:. ```sh; while true; do; strace -s 99 -f -o salmon-strace.log \; salmon quant \; --index /home/ryan/references/hg38/Salmon_index_$REF \; --libType SR --unmatedReads fastq_files/$SAMPLE.fq.gz\; --threads 8 --seqBias --gcBias --useVBOpt --dumpEq --dumpEqWeights \; --geneMap /home/ryan/references/hg38/Salmon_index_$REF/genemap.txt \; --output salmon_temp/REF/$SAMPLE \; --auxDir aux_info \; --numGibbsSamples 100; done; ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267357651:71,log,log,71,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267357651,1,['log'],['log']
Testability,"Ok, pushed to [bioconda](https://github.com/bioconda/bioconda-recipes/pull/17922/checks?check_run_id=248588035), should be available in a couple of hours. Once it's available I'll make the official release too on the github. It'd be great if you can quickly test the new release for the bug once it's available. Thanks again !",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/431#issuecomment-538581395:258,test,test,258,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/431#issuecomment-538581395,1,['test'],['test']
Testability,"Ok, salmon V1.0.0 finished in 5H 15 min, so about 5 times faster, the exact same library and parameters, and achieved almost the same mapping rate (85.1058% with V1.2.0 vs 84.6341% with V1.0.0) attaching log. I must add I did not trim this library for adapters nor quality, nor did anything to it. Just mapped as is. But fastQC showed excellent levels of quality even at the ends and no or minimal adapter content. ; Also no changes have been done one my OS other than regular updates, but still Ubuntu 18.04. I don't remember any specific changes I've done to it. ; Pearson's correlation in transcript abundance (isoform lelvel) is 0.9984013. Spearman's is 0.9899048. ; Also, I did checked that salmon was actually using 4 threads in both cases, and it was fully using those.; [salmon_quant.log](https://github.com/COMBINE-lab/salmon/files/4707443/salmon_quant.log)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/527#issuecomment-636447127:204,log,log,204,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/527#issuecomment-636447127,3,['log'],['log']
Testability,"Ok, the assertion is useful. That argument shouldn't be 0. But it's also the case that if Boost validates the arguments appropriately, it shouldn't *hang*.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267856046:8,assert,assertion,8,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267856046,1,['assert'],['assertion']
Testability,"Ok, when I attempt the build the way you say above, I get the following error during CMake:. ```; -- fetch PUFFERFISH exit code 127; CMake Error at CMakeLists.txt:317 (message):; Could not fetch pufferfish source [fetchPufferfish.sh returned exit code; 127]. -- Configuring incomplete, errors occurred!; See also ""/salmon-1.10.0/build/CMakeFiles/CMakeOutput.log"".; ```. It seems `wget`, `curl` and `unzip` were missing, and I had to install them. After that, I was able to build and install. At that point, I was able to reproduce the issue! So, it seems to me the underlying problem is coming from one of the upstream dependencies (i.e. libraries being linked to). I will try see if I can find the offender. In general, we like to statically link salmon for exactly this reason. Outside of package systems with which I am familiar (e.g. conda), we don't have a lot of experience in specifying dependent package version constrains, which I believe to be at fault here.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463973824:358,log,log,358,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463973824,1,['log'],['log']
Testability,Ok; that is _super_ strange since (obviously) it cannot both complete successfully and throw an exception. It looks like the log points to a sample that completed successfully at `19:45:18.487` before the sample at the top of the post started `19:51:56.392`. Is this the quant directory for the same sample?,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/512#issuecomment-618029055:125,log,log,125,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/512#issuecomment-618029055,1,['log'],['log']
Testability,"Oki, so I have updated a couple of things in the latest commit on the develop branch, which should make the things more streamlined. . * `maxNumBarcodes`: As you have initially used `maxNumBarcodes` which is by default set to 100k it means. by default alevin quantifies 100k CBs which includes both the low and high confidence CB count. You can change this number accordingly to set the universe of the top CB to quantify.; * `KeepCBFraction` : It defines what fraction of `maxNumBarcodes` to be used as the high confidence barcodes and should definitely generate the quants for. If set to 1 then everything is high confidence and the whitelisting cannot be performed. Thanks to this issue, alevin will not fail without error when there is no low confidence CB is found instead it checks if the number of low confidence CB is less than `lowRegionMinBarcodes` (default to 200), alevin will warn and not perform the whitelisting.; * `freqThreshold`: This is used to filter out most obvious cases to filter out CB with frequency less than set by the parameter (default to 10). Hope this help ! I am also testing on my end for any other potential bug. Please let me know if you get a chance to check the develop branch .",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/379#issuecomment-503396823:1101,test,testing,1101,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/379#issuecomment-503396823,1,['test'],['testing']
Testability,"RIVATE|MAP_ANONYMOUS|MAP_STACK, -1, 0) = -1 ENOMEM (Cannot allocate memory); futex(0x7fffbf4c3350, FUTEX_WAKE_PRIVATE, 2147483647) = 0; write(2, ""terminate called without an acti""..., 45terminate called without an active exception; ) = 45; rt_sigprocmask(SIG_UNBLOCK, [ABRT], NULL, 8) = 0; write(3, ""[2017-04-05 16:24:38.504] [joint""..., 136) = 136; tgkill(10693, 10693, SIGABRT) = 0; --- SIGABRT (Aborted) @ 0 (0) ---; +++ killed by SIGABRT (core dumped) +++; ```. (371 lines for task 1, 368 for task 2). Basically, both fail at a point where `mmap()` cannot allocate memory. So it definitely looks like a memory issue and I don't know if these information gives you any hints. . ## Bumping memory. Bumping the memory request to 28/30GB. This is a scenario where task 2 seems to work ok but tasks 1 and 3 fail. ```bash; #!/bin/bash; #$ -cwd; #$ -pe local 2; #$ -l mem_free=14G,h_vmem=15G,h_fsize=100G; #$ -N step6-salmon_test12.gsk_phaseII; #$ -o ./logs/salmon_test12.$TASK_ID.txt; #$ -e ./logs/salmon_test12.$TASK_ID.txt; #$ -t 1-3; #$ -hold_jid pipeline_setup,step4-featCounts-alzheimer.gsk_phaseII; #$ -m e; echo ""**** Job starts ****""; date. echo ""**** JHPCE info ****""; echo ""User: ${USER}""; echo ""Job id: ${JOB_ID}""; echo ""Job name: ${JOB_NAME}""; echo ""Hostname: ${HOSTNAME}""; echo ""Task id: ${TASK_ID}"". FILE1=$(awk 'BEGIN {FS=""\t""} {print $1}' /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk ""NR==${SGE_TASK_ID}""); if [ TRUE == ""TRUE"" ] ; then; FILE2=$(awk 'BEGIN {FS=""\t""} {print $3}' /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk ""NR==${SGE_TASK_ID}""); fi; ID=$(cat /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk '{print $NF}' | awk ""NR==${SGE_TASK_ID}""). mkdir -p /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/${ID}. strace /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon quant 	-i /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:77886,log,logs,77886,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,1,['log'],['logs']
Testability,"RP057125_SRS936134_2.fastq \; > -o SRP057125_SRS936134_salmon_out \; > -g /nfs/research2/teichmann/reference/mus-musculus/salmon/mouse_cdna38.78_repbase_ercc_index_gene_map.txt \; > --biasCorrect \; > --useFSPD; Version Info: This is the most recent version of Salmon.; # salmon (mapping-based) v0.6.0; # [ program ] => salmon; # [ command ] => quant; # [ index ] => { /nfs/research2/teichmann/reference/mus-musculus/salmon/quasi/mouse_cdna_38.p3.78_repbase_ercc.fa }; # [ libType ] => { IU }; # [ mates1 ] => { /nfs/research2/teichmann/valentine/detection-comparison/salmon0.4.2-comparison/mouse/SRP057125_SRS936134_1.fastq }; # [ mates2 ] => { /nfs/research2/teichmann/valentine/detection-comparison/salmon0.4.2-comparison/mouse/SRP057125_SRS936134_2.fastq }; # [ output ] => { SRP057125_SRS936134_salmon_out }; # [ geneMap ] => { /nfs/research2/teichmann/reference/mus-musculus/salmon/mouse_cdna38.78_repbase_ercc_index_gene_map.txt }; # [ biasCorrect ] => { }; # [ useFSPD ] => { }; Logs will be written to SRP057125_SRS936134_salmon_out/logs; [2016-01-02 20:22:59.800] [jointLog] [info] parsing read library format; there is 1 lib; Loading 32-bit quasi index[2016-01-02 20:23:00.830] [stderrLog] [info] Loading Suffix Array; [2016-01-02 20:23:00.830] [stderrLog] [info] Loading Position Hash; [2016-01-02 20:23:00.829] [jointLog] [info] Loading Quasi index; [2016-01-02 20:23:03.751] [stderrLog] [info] Loading Transcript Info; [2016-01-02 20:23:04.776] [stderrLog] [info] Loading Rank-Select Bit Array; [2016-01-02 20:23:05.009] [stderrLog] [info] There were 104534 set bits in the bit array; [2016-01-02 20:23:05.325] [stderrLog] [info] Computing transcript lengths; [2016-01-02 20:23:05.325] [stderrLog] [info] Waiting to finish loading hash; Index contained 104534 targets; [2016-01-02 20:23:16.571] [stderrLog] [info] Done loading index; [2016-01-02 20:23:16.571] [jointLog] [info] done. processed 12000001 fragments; hits: 24367128, hits per frag: 2.04044. [2016-01-02 20:23:49.850] [jointL",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/34#issuecomment-168426741:7454,Log,Logs,7454,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/34#issuecomment-168426741,2,"['Log', 'log']","['Logs', 'logs']"
Testability,"Ran with only --validateMappings and -p 4 options. Wow, it took less than 15 minutes! Thanks a lot to you and your team for looking into this.; Best,; Jose; [salmon_quant.log](https://github.com/COMBINE-lab/salmon/files/4717767/salmon_quant.log)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/527#issuecomment-637581730:171,log,log,171,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/527#issuecomment-637581730,2,['log'],['log']
Testability,Realized I haven't run the gene quantification yet and its looking for quant.genes.sf not quant.sf like the log says?,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/662#issuecomment-845350603:108,log,log,108,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/662#issuecomment-845350603,1,['log'],['log']
Testability,"Right --- such classes should be removed (specifically because they can cause such underflow issues). I suspect that I just need to make the bound for evaluation more conservative. I chose the smallest value that worked on my testing machine, but I imagine that when underflow occurs could be slightly different on different machines. I should just find / choose a stricter bound.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/229#issuecomment-393580320:226,test,testing,226,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/229#issuecomment-393580320,1,['test'],['testing']
Testability,"Right, that might explain it. So first of all I indeed used the `--dumpFeature` option to get the `MappedUMI.txt`, sorry for that. I will check the file once again and rerun the analysis, which I did on my machine at home. It might be that the 17M I told from the top of my head is actually incorrect. Unfortunately, the 10x crashes with a memory error on our clusters (I tested 2 different machines), for which I will open a separate thread (I think I saw someone else reporting a similar issue; will look that up). Celseq2 runs fine. I will check the analysis and the `mappedUMI.txt` a.s.a.p. I fear this issue will soon be resolved where both of us have a memory problem to deal with ;-). Cheers,; Wout",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/361#issuecomment-490115088:372,test,tested,372,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/361#issuecomment-490115088,1,['test'],['tested']
Testability,"Rob,. Thanks for the --no-version-check option, I did not see it. regarding issue (2). I have been able to process these files without any problem with other; tools.; I have the same problem with the 10x pbmc4k fastq files:. salmon --no-version-check alevin -p 10 -lISR -1; /path/to/downloads/10xPBMC/pbmc4k_S1_L001_R1_001.fastq.gz -2; /path/to/downloads/10xPBMC/pbmc4k_S1_L001_R2_001.fastq.gz -i; /path/to/salmonIndex -o alevin_output --tgMap tx2gene.tsv; Logs will be written to alevin_output/logs; ### salmon (single-cell-based) v0.11.1; ### [ program ] => salmon; ### [ command ] => alevin; ### [ threads ] => { 10 }; ### [ libType ] => { ISR }; ### [ mates1 ] => {; /path/to/downloads/10xPBMC/pbmc4k_S1_L001_R1_001.fastq.gz }; ### [ mates2 ] => {; /path/to/downloads/10xPBMC/pbmc4k_S1_L001_R2_001.fastq.gz }; ### [ index ] => { /path/to/salmonIndex }; ### [ output ] => { alevin_output }; ### [ tgMap ] => { tx2gene.tsv }. [2018-08-03 19:20:57.848] [jointLog] [info] Fragment incompatibility; prior below threshold. Incompatible fragments will be ignored.; [2018-08-03 19:20:57.867] [alevinLog] [info] Processing barcodes files; (if Present). processed 189 Million barcodes. Segmentation error (core dumped). Avi,. You are right, I did miss the --chromium option. However, I just tried; again with the above command with --chromium and I still get the; segmentation error.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/264#issuecomment-410325090:457,Log,Logs,457,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/264#issuecomment-410325090,2,"['Log', 'log']","['Logs', 'logs']"
Testability,"Seems to work on some of the test at my end, let me know if its still a problem. The command to use would be; ```; salmon alevin -l ISR --citeseq --barcodeLength 16 --umiLength 10 --end 5 --featureStart 19 --featureLength 21; ```. One thing to note, since it's a 5' protocol, you might have to change `-lISR` to `-lISF` since the 5` protocol expects the single-cell reads from the forward strand, unlike 3' where we expect the reads from reverse. It should not be a problem for the guide/feature barcodes though.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-638444905:29,test,test,29,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-638444905,2,['test'],['test']
Testability,"So, it took ~30 min (impressively fast) for V1.0.0 with ```--hitFilterPolicy BOTH```, it seems that you are right. Attaching the log and running again in V1.2.1. Thanks again; José ; [salmon_quant.log](https://github.com/COMBINE-lab/salmon/files/4710898/salmon_quant.log)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/527#issuecomment-636790517:129,log,log,129,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/527#issuecomment-636790517,3,['log'],['log']
Testability,"Solved with ; `-DFETCH_STADEN=TRUE`. to recap, installing on an Ubuntu 20.04: ; ```; git clone --depth=1 https://github.com/COMBINE-lab/salmon.git; cd salmon; git checkout tags/v1.5.2. apt-get build-dep -y salmon; cmake -DFETCH_BOOST=FALSE --log-level=VERBOSE -DCMAKE_INSTALL_PREFIX=/directory_to_place/salmon/1.5.2 -DFETCH_STADEN=TRUE -DNO_IPO=TRUE && make && make install; ```. Please note you can't mkdir build and cd build as the cmake files are bundled under the git's root dir. You'll need to move the files (but i'm not familiar with cmake so i just run it from the git root). Compilation is required as the distributed binaries use the older libc (GLIBC_2.29)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/425#issuecomment-962540229:242,log,log-level,242,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/425#issuecomment-962540229,1,['log'],['log-level']
Testability,"Some progress. Found a src rpm for cereal, rebuilt that into an RPM and installed. Then this (ROOT_* env variables come from the respective module load commands):. ```; cmake \; -DCMAKE_INSTALL_PREFIX=$TOPDIR \; -DSTADEN_ROOT=$ROOT_IO_LIB \; -DGFF_ROOT=$ROOT_LIBGFF \; -DTBB_ROOT=$ROOT_LIBTBB \; -DCMAKE_VERBOSE_MAKEFILE:BOOL=ON \; -DBOOST_LIBRARYDIR=/usr/lib64/boost169 \; -DBOOST_INCLUDEDIR=/usr/include/boost169 \; -DBoost_NO_SYSTEM_PATHS=ON \; .. 2>&1 | tee cmake_2020_06_09.log; ```; found everything. The ""make"" went along pretty well until here:; ```; [100%] Linking CXX executable salmon; cd /usr/common/src/salmon-1.2.1/build/src && /usr/common/src/cmake-3.17.1/bin/cmake -E cmake_link_script CMakeFiles/salmon.dir/link.txt --verbose=1; /usr/lib64/ccache/c++ -O3 -DNDEBUG -flto -fno-fat-lto-objects CMakeFiles/salmon.dir/EMUtils.cpp.o CMakeFiles/salmon.dir/CollapsedEMOptimizer.cpp.o CMakeFiles/salmon.dir/CollapsedCellOptimizer.cpp.o CMakeFiles/salmon.dir/CollapsedGibbsSampler.cpp.o CMakeFiles/salmon.dir/Salmon.cpp.o CMakeFiles/salmon.dir/BuildSalmonIndex.cpp.o CMakeFiles/salmon.dir/Graph.cpp.o CMakeFiles/salmon.dir/DedupUMI.cpp.o CMakeFiles/salmon.dir/Alevin.cpp.o CMakeFiles/salmon.dir/AlevinHash.cpp.o CMakeFiles/salmon.dir/SalmonAlevin.cpp.o CMakeFiles/salmon.dir/WhiteList.cpp.o CMakeFiles/salmon.dir/SalmonQuantify.cpp.o CMakeFiles/salmon.dir/FragmentLengthDistribution.cpp.o CMakeFiles/salmon.dir/FragmentStartPositionDistribution.cpp.o CMakeFiles/salmon.dir/GZipWriter.cpp.o CMakeFiles/salmon.dir/SalmonQuantMerge.cpp.o CMakeFiles/salmon.dir/ProgramOptionsGenerator.cpp.o CMakeFiles/salmon.dir/FASTAParser.cpp.o CMakeFiles/salmon.dir/AlignmentModel.cpp.o CMakeFiles/salmon.dir/SalmonQuantifyAlignments.cpp.o CMakeFiles/salmon.dir/BAMUtils.cpp.o -o salmon -L/usr/common/src/salmon-1.2.1/lib -L/usr/common/src/salmon-1.2.1/external/install/lib -Wl,-rpath,""\$ORIGIN/../lib:\$ORIGIN/../../lib:\$ORIGIN/:\$ORIGIN/../../external/install/lib"" ../external/pufferfish/src/libpuffer.a libs",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641531162:479,log,log,479,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641531162,1,['log'],['log']
Testability,"Sorry :// Another issue... . Version Info: This is the most recent version of salmon.; ### salmon (mapping-based) v1.2.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { /media/usr/Hybrid_02/Unidad_Bioinf/FER_Scripts/Index/hg38/salmon_sa_index/default }; ### [ libType ] => { A }; ### [ gcBias ] => { }; ### [ validateMappings ] => { }; ### [ mates1 ] => { /media/usr/trimmed_fastq_files/PAIRED_trimmed_fastq_files/APSa16_1P.fq.gz }; ### [ mates2 ] => { /media/usr/trimmed_fastq_files/PAIRED_trimmed_fastq_files/APSa16_2P.fq.gz }; ### [ threads ] => { 7 }; ### [ output ] => { /media/usr/quantification/APSa16.fq.gz_quant }; Logs will be written to /media/usr/quantification/APSa16.fq.gz_quant/logs; [2020-05-05 09:19:06.171] [jointLog] [info] setting maxHashResizeThreads to 7; [2020-05-05 09:19:06.171] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2020-05-05 09:19:06.171] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2020-05-05 09:19:06.171] [jointLog] [info] Usage of --validateMappings implies a default consensus slack of 0.2. Setting consensusSlack to 0.35.; [2020-05-05 09:19:06.171] [jointLog] [info] parsing read library format; [2020-05-05 09:19:06.171] [jointLog] [info] There is 1 library.; [2020-05-05 09:19:06.278] [jointLog] [info] Loading pufferfish index; [2020-05-05 09:19:06.278] [jointLog] [warning] The index did not record if the `--keepDuplicates` flag was used. Please consider re-indexing with a newer version of salmon that will propagate this information.; [2020-05-05 09:19:06.278] [jointLog] [info] Loading dense pufferfish index.; -----------------------------------------; | Loading contig table | Time = 30.609 s; -----------------------------------------; size = 36981178; -----------------------------------------; | Loading contig offsets | Time = 1.3312 s; --------------------------",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/518#issuecomment-623910021:651,Log,Logs,651,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/518#issuecomment-623910021,2,"['Log', 'log']","['Logs', 'logs']"
Testability,"Sorry for the confusion, what I meant was the alevin log, it should be inside the alevin folder of your output subdirectory with the name `alevin.log`.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/396#issuecomment-510545906:53,log,log,53,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/396#issuecomment-510545906,2,['log'],['log']
Testability,"Sorry for the inconvenience. I completely missed this point. My test set was too small and none were doubles. I was in the process of writting a bug fix... Anyway, thanks for the correction.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/356#issuecomment-486109301:64,test,test,64,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/356#issuecomment-486109301,1,['test'],['test']
Testability,"Sorry if I wasn't clear. I did try with and without the --chromium; option, with the same error. I just have try the exact command you provided (including the --chromium; flag), with option in the same order. The command log is then:; ### salmon (single-cell-based) v0.11.1; ### [ program ] => salmon; ### [ command ] => alevin; ### [ threads ] => { 10 }; ### [ libType ] => { ISR }; ### [ chromium ] => { }; ### [ mates1 ] => {; /path/to/downloads/10xPBMC/pbmc4k_S1_L001_R1_001.fastq.gz }; ### [ mates2 ] => {; /path/to/downloads/10xPBMC/pbmc4k_S1_L001_R2_001.fastq.gz }; ### [ index ] => { /path/to/salmonIndex }; ### [ output ] => { alevin_output }; ### [ tgMap ] => { tx2gene.tsv }. Now it seems to work. I'll tell you if the whole alignment is; successfull when it will end. Note that when I use the --chromium flag earlier in the command, ie:. salmon --no-version-check --chromium alevin -p 10 -lISR -1 [...]. The log contains:; ### salmon (single-cell-based) v0.11.1; ### [ program ] => salmon; ### [ command ] => alevin; ### [ ] => { alevin }; ### [ threads ] => { 10 }; ### [ libType ] => { ISR }",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/264#issuecomment-410331030:221,log,log,221,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/264#issuecomment-410331030,4,['log'],['log']
Testability,"Sorry, I shouldn't have used that sample as an example. That's just the first of many, and there was some issue causing a super low mapping rate. Here is another example:. ```; Processing sample RHM5942; Version Info: This is the most recent version of Salmon.; ### salmon (mapping-based) v0.11.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { /data2/csijcs/hg38/hg38.transcriptome.index }; ### [ libType ] => { A }; ### [ mates1 ] => { /data2/csijcs/AML/RNA_seq/AML_total_MNC/total_MNCs/Fresh_samples/RHM5942/RHM5942_R1_001.fastq.gz }; ### [ mates2 ] => { /data2/csijcs/AML/RNA_seq/AML_total_MNC/total_MNCs/Fresh_samples/RHM5942/RHM5942_R2_001.fastq.gz }; ### [ threads ] => { 32 }; ### [ output ] => { /data2/csijcs/AML/RNA_seq/AML_total_MNC/total_MNCs/Fresh_samples/salmon_quants/RHM5942 }; Logs will be written to /data2/csijcs/AML/RNA_seq/AML_total_MNC/total_MNCs/Fresh_samples/salmon_quants/RHM5942/logs; [2018-07-27 16:24:55.658] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2018-07-27 16:24:55.658] [jointLog] [info] parsing read library format; [2018-07-27 16:24:55.658] [jointLog] [info] There is 1 library.; [2018-07-27 16:25:01.242] [jointLog] [info] Loading Quasi index; [2018-07-27 16:25:01.242] [jointLog] [info] Loading 32-bit quasi index; [2018-07-27 16:25:01.243] [stderrLog] [info] Loading Suffix Array ; [2018-07-27 16:25:42.630] [stderrLog] [info] Loading Transcript Info ; [2018-07-27 16:25:45.683] [stderrLog] [info] Loading Rank-Select Bit Array; [2018-07-27 16:25:47.834] [stderrLog] [info] There were 203027 set bits in the bit array; [2018-07-27 16:25:48.128] [stderrLog] [info] Computing transcript lengths; [2018-07-27 16:25:48.200] [stderrLog] [info] Waiting to finish loading hash; [2018-07-27 16:25:48.331] [stderrLog] [info] Done loading index; [2018-07-27 16:25:48.331] [jointLog] [info] done; [2018-07-27 16:25:48.331] [jointLog] [info] Index contained 203027 targets. proces",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/261#issuecomment-409427898:822,Log,Logs,822,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/261#issuecomment-409427898,2,"['Log', 'log']","['Logs', 'logs']"
Testability,"Sorry,. > Version Info: Could not resolve upgrade information in the alotted time.; Check for upgrades manually at https://combine-lab.github.io/salmon; # salmon (alignment-based) v0.9.1; # [ program ] => salmon; # [ command ] => quant; # [ targets ] => { transcripts.fa }; # [ libType ] => { A }; # [ alignments ] => { A549_S1_001.bam }; # [ output ] => { A549_S1_quant }; Logs will be written to A549_S1_quant/logs; Malformed key:value pair at line 44017: ""@PG ID:OSA IsCdna:True ReferenceLibraryID:Human.B37.3_RefGene20121217 VN:7.2""; ============; Exception : [ERROR: Failed to open file A549_S1_001.bam, exiting!]; ============; ./bin/salmon alignment-quant was invoked improperly.; For usage information, try ./bin/salmon quant --help-alignments; Exiting.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/222#issuecomment-387497883:374,Log,Logs,374,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/222#issuecomment-387497883,2,"['Log', 'log']","['Logs', 'logs']"
Testability,"Still looking, but this is very strange! It happens when the program is exiting, during the destruction of some objects. Strangely, it doesn't happen on the test data (also it's strange that it doesn't happen in the version compiled from source).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/34#issuecomment-168357540:157,test,test,157,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/34#issuecomment-168357540,1,['test'],['test']
Testability,"Strangely enough - with the above error message of mine. when I go to the logs directory and look up salmon_quant.log, it has correct info (last line below); ```; [2020-04-22 19:45:18.487] [jointLog] [info] Finished Bootstrapping; ```. And the output directory has a `quant.sf` file and it has all the records I want -- however, salmon is exiting with the above error message",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/512#issuecomment-618027626:74,log,logs,74,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/512#issuecomment-618027626,2,['log'],"['log', 'logs']"
Testability,"Strictly speaking, barcodes.tsv**.gz** files are provided. I was viewing the uncompressed file in Notepad++, so I think that number (from the line numbers on the left) should be correct. I will double-check the next time that I am on my work computer. I will test using the smaller number of barcodes. However, unlike the larger file, I think this would be different for every sample. If part of the reason that I wanted to run Alevin is that I wanted an independent quantification (which takes less time), then that may be a notable limitation. However, for whatever reason, this seems to only be an issue with the v2 sample (the v3 sample worked fine). So, I will test that, and I will at least confirm if I see the same error message or not.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/682#issuecomment-878693769:259,test,test,259,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/682#issuecomment-878693769,2,['test'],['test']
Testability,"Sure thing. Here's a small quants file. It's just the top 2500 lines of one of the files I was testing with. I double checked and this one gets cut at 17 lines (it has ""Erdr1""). [quant.genes.sf.txt](https://github.com/COMBINE-lab/salmon/files/3066421/quant.genes.sf.txt). And here is the mapping I was using:. [map.tsv.gz](https://github.com/COMBINE-lab/salmon/files/3066425/map.tsv.gz). If you need anything else, I'm happy to oblige.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/356#issuecomment-481924188:95,test,testing,95,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/356#issuecomment-481924188,1,['test'],['testing']
Testability,"Sure, thanks for pointing this out, we have updated the document now !; We are gonna do testing at our end too, but let us know if you have any other issue.; Happy Weekend !",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-395912965:88,test,testing,88,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-395912965,1,['test'],['testing']
Testability,"Thank you in advance for developing this amazing thing. . I have some little suggestions. I have little background on algorithm used in salmon, and need to give a quick test on the data. I read through the documents, and it's very difficult for me to understand the rational running behind for some options without reading series of original algorithm papers. I guess some import details are missed in the document, for example, what's the difference of quasi-mapping model and light-weight alignment based model, and how salmon deal with pair end reads that not concordantly aligned. To be honest, it's not very friendly to end-user of this tool, and prevents some of us using it extensively. obenno",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/248#issuecomment-402909186:169,test,test,169,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/248#issuecomment-402909186,1,['test'],['test']
Testability,"Thank you very much, @k3yavi ! The references to the other discussion is very helpful. I am testing what happens if I use `-lISF` (instead of `-lISR`). Thanks again!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/682#issuecomment-876797474:92,test,testing,92,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/682#issuecomment-876797474,1,['test'],['testing']
Testability,"Thank you very much, @k3yavi !. There was a different 10x white list that worked for a different sample (with a different 10x design), and there is a 3rd dataset that is a BD Rhapsody experiment (where I can't use CellRanger). However, for this particular sample, I also have the CellRanger results. So, I can test as you have described, and close the ticket. If I have additional questions about the different cell counts from the different methods, then I will open a different ticket for that separate topic. Thanks again!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/682#issuecomment-877526812:310,test,test,310,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/682#issuecomment-877526812,1,['test'],['test']
Testability,"Thanks @Ryan-Zhu ,. A couple of thoughts.; To me the data seem a little noisy as a lot of CB/reads are thrown away due to ""knee"" thresholding.; Check https://github.com/COMBINE-lab/salmon/issues/362 if you wanna play with how to customize alevin for user-define whitelisting. Having said that this is how you can parse the data from alevin.; Alevin use 1277 CB after its knee thresholding + 638 low confidence Barcode for downstream whitelisting = total 1915 CBs.; If you check the warning in the log it says :. ```; [2019-06-12 15:07:08.152] [alevinLog] [warning] Skipped 313 barcodes due to No mapped read; ```; Basically it means out of 1915, 313 didn't had any read mapped to them, so alevin doesn't report them in the output matrix. Alevin reports 1915 - 313 = 1602 CBs both in `.mtx` and `quants_mat.gz` file. You can check the order of the CB in the `quants_mat_rows.txt` file, which has 1602 rows/CBs. If you don't provide alevin with external whitelist alevin tries to do post whitelisting of it's own. Basically out of the 1277 high confidence CBs alevin initially find out through knee it assigns 647 CBs as final whitelisted CB as found in the `whitelist.txt` file. If you wan't to subsample these CBs you have to extract the information from the `.mtx` or `quants_mat.gz` file. You can check a simple python parse of the `quants_mat.gz` file [here](https://github.com/k3yavi/vpolo/blob/master/vpolo/alevin/parser.py#L187-L230).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/374#issuecomment-501846672:497,log,log,497,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/374#issuecomment-501846672,2,['log'],['log']
Testability,Thanks @dritoshi for the data and info. Let me play a bit with the data over the weekend. It should be very straightforward to add but I might have to check some unit test. I'll keep you updated.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/416#issuecomment-521863053:167,test,test,167,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/416#issuecomment-521863053,1,['test'],['test']
Testability,Thanks @k3yavi - I think those options would really help us use Alevin in production- look forward to the next release. . I'll do some more testing in the meantime.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/362#issuecomment-490859077:140,test,testing,140,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/362#issuecomment-490859077,1,['test'],['testing']
Testability,Thanks @k3yavi . [alevin.log](https://github.com/COMBINE-lab/salmon/files/3303575/alevin.log); [salmon_quant.log](https://github.com/COMBINE-lab/salmon/files/3303576/salmon_quant.log),MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/379#issuecomment-503326828:25,log,log,25,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/379#issuecomment-503326828,4,['log'],['log']
Testability,Thanks @k3yavi! I'm not aware of the issues with previous version. I tested it with the [test data](https://github.com/indrops/indrops/tree/master/test/seq_runs/run_v2_single_file) and the data I mentioned earlier and it worked fine. Let me know how the review goes and if I have missed something.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/703#issuecomment-920995572:69,test,tested,69,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/703#issuecomment-920995572,3,['test'],"['test', 'tested']"
Testability,"Thanks @rfarouni ! A small dataset with few thousand reads would be great to have, the one I currently had was too few to test things on.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-639622262:122,test,test,122,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-639622262,1,['test'],['test']
Testability,"Thanks @rfarouni for the updates. > With --minScoreFraction 0.607 I get a way much better mapping rate. I wonder if there is way to determine the optimal value empirically?. Glad to hear that, may I ask what percent of the reads are mapping now ? It's not clear from the alevin logs you shared but I think the total number of deduplicated UMIs are similar to your baseline experiment. I think defining an optimal empirical threshold is a great idea but the issue is that 21 length barcodes are kind of in the middle i.e. a tad longer than the regular barcodes and somewhat smaller than a full read. The full read alignment process indeed allows more erroneous reads to map but 21 is a bit too short to work with. @rob-p might have more thoughts on this one. > But now there are a lot of barcodes that are not in the whitelist. Thanks again for checking this, it is indeed concerning. However, as I was mentioning earlier in a regular single-cell experiment we end up throwing away almost all of these very low frequency count cellular barcodes. I'd say even 45 reads CBs are most probably a noise and will be filtered away, because only a fraction of the reads will map and after deduplication it'll result in significantly low count in 1 cellular barcode. > Also with the default setting of --freqThreshold, no CB correction gets done. I can check why is this happening, let me know once you have a toy dataset to play with.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-640093397:278,log,logs,278,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-640093397,2,['log'],['logs']
Testability,"Thanks @rob-p,. Your explanations are helpful, and I think it may my concern may just be more associated with your general thought as I've tested this with multiple parameters. The one I represented here was just an example, but I also can see how the parameters can be affecting these results. It was just strange to see such a huge shift with the addition/removal of one gene, which makes me think it more associated with how the inference of the variables are conditioned. . As for providing the meta_info.json files, I currently have thousands of them as I am running triplicates of ~150 parameter combinations for multiple tissue types and stages. In the end I don't think it will be necessary as we will likely be changing our approach a bit, which should be fine with the system I have in place. . Also, as for `--scoreExp` our main goal is to try and use Salmon to get quantification of individual genes (primary versus spliced forms). From my analysis, it appears that some genes perform better with scores > 0, however, some genes do perform better with a `--scoreExp` of 0. Although, this could be a factor in running Salmon with such a narrow view (i.e. two transcripts and some housekeeping genes) and might not be the case as more genes are added to the run.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/523#issuecomment-633062608:139,test,tested,139,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/523#issuecomment-633062608,1,['test'],['tested']
Testability,"Thanks @roryk and @k3yavi . The issue we have is that we're trying to run a pipeline in a fairly high-throughput manner to get a sensible 'enough' matrix without too much manual intervention. So I'm trying to avoid anything that requires an eyeballing step, accepting that the matrix we get will be less optimal than one you'd get from manual optimisation. Where possible, our curators are extracting the expected cell numbers from publications, so sometimes I have at least a general idea of where to look for an elbow/ feature. @roryk - have you used your alternate view on the data to automatically derive cutoffs? Does it work well?. @k3yavi:. As I say, first point is that this is for cases where I have a rough idea of the target cell number- we're generally working with pre-published data (though cell numbers per run are not always available). . From https://github.com/COMBINE-lab/salmon/issues/340 I'd inferred that --expectCells gives Alevin ballpark to look for a knee within, while --forceCells is a strict cuttoff. Is that correct? . That being the case, my thought was to try --expectCells first, and failing that --forceCells. The problem is that I need to parse the STDOUT/ERR to detect the boundary error from --expectCells, which is not a very robust way of doing things. If you returned informative error codes (anything but 1) on this and other errors, I could detect the error and implement the logic I describe.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/362#issuecomment-490157428:1418,log,logic,1418,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/362#issuecomment-490157428,1,['log'],['logic']
Testability,"Thanks @shalercr,. I'll grab those files once they are finished uploading. I don't know if all samples show similar behavior, but these are called `31_1` and `31_2`, while in your logs you had `13_1` and `13_2`. Regarding OSX vs. linux, it should not really matter, obviously (salmon should work well under both, but I'm just curious since this is obviously atypical and unexpected behavior). --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/537#issuecomment-644505526:180,log,logs,180,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/537#issuecomment-644505526,1,['log'],['logs']
Testability,"Thanks Jeremy! Yes, that's what I was hinting at with different v1/v2 protocols. From their code, you can see differences in amplicon sequences:; - For v1: 'NNNNNNNNNNIIIIIIIIGTGGCCGATGTTTCGCATCGGCGTACGACTIIIIIIIIATCCACGTGCTTGAGAGGCCAGAGCATTCGIIIIIIII'; - For v2: 'NNNNNNNNNNIIIIIIIIGTGGCCGATGTTTCGCATCGGCGTACGACTIIIIIIIIATCCACGTGCTTGAGACTGTGGIIIIIIII'; where the `IIIIIIII` sequence corresponds to barcode. This is from the pipeline code I mentioned earlier used for [this paper](https://www.nature.com/articles/s41593-021-00872-y). Do you have a the pairing file for the BC1 barcodes? Is it the Supp Table S12 in the Rosenberg paper? It is needed for development and testing.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-951080577:669,test,testing,669,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-951080577,1,['test'],['testing']
Testability,"Thanks Matt for the response and fix, unfortunately the error persists;; Might need to re-align using a different pipeline?. > Version Info: Could not resolve upgrade information in the alotted time.; Check for upgrades manually at https://combine-lab.github.io/salmon; # salmon (alignment-based) v0.9.1; # [ program ] => salmon; # [ command ] => quant; # [ targets ] => { transcripts.fa }; # [ libType ] => { A }; # [ alignments ] => { A549_S1_001.bam }; # [ output ] => { A549_S1_quant }; Logs will be written to A549_S1_quant/logs; Malformed key:value pair at line 44017: ""@PG ID:OSA IsCdna:True ReferenceLibraryID:Human.B37.3_RefGene20121217 VN:7.2""; ============; Exception : [ERROR: Failed to open file A549_S1_001.bam, exiting!]; ============; ./bin/salmon alignment-quant was invoked improperly.; For usage information, try ./bin/salmon quant --help-alignments; Exiting.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/222#issuecomment-387497579:491,Log,Logs,491,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/222#issuecomment-387497579,2,"['Log', 'log']","['Logs', 'logs']"
Testability,Thanks for helping to look into this @hiraksarkar ; That seems like a logical outcome re the higher number of connected transcripts - interesting. As requested - I've added in the bootstrap folder - here are the new links:; [Selective alignment](https://drive.google.com/file/d/11TfZXuBZqMbtCL6BwZwI7ms3gzPNipav/view?usp=sharingl); [Alignment based - STAR](https://drive.google.com/file/d/12piPEagYNuDcPC861CKHYjQ1AVDu8QYP/view?usp=sharing),MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/600#issuecomment-757553955:70,log,logical,70,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/600#issuecomment-757553955,1,['log'],['logical']
Testability,"Thanks for making these available! I'm looking through. Though it's not directly related to the `fetchRapMap.sh` script, I do find [this](https://gist.github.com/sjackman/6e15b7dfebaaad99b9476aa5ce269fda#file-cmakeerror-log-L47) disconcerting. Any idea what's up there?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/181#issuecomment-367795756:220,log,log-,220,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/181#issuecomment-367795756,1,['log'],['log-']
Testability,"Thanks for reporting back (with the nice plots!). This is interesting, because, at least in our other testing, the VB seems to be performing slightly _better_ than the EM. One guess I have is that the VB Opt tends to produce slightly sparser solutions than the EM opt. Usually, this is a ""good thing"". However, if you're dealing with such small datasets (n ~50), then dropping a few points could make a significant difference. Since you can reproduce the previous behavior when dropping the VB option, there's no rush. However, if you are able to share some of the data at some point, I'd be interested in digging in and figuring out exactly what's happening here. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/6#issuecomment-111604379:102,test,testing,102,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/6#issuecomment-111604379,1,['test'],['testing']
Testability,Thanks for reporting it @cliftonlewis. I have tested the fix and it works both with and without rad mode (`--justAlign`). The solution is in pr #817.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/813#issuecomment-1344736974:46,test,tested,46,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/813#issuecomment-1344736974,1,['test'],['tested']
Testability,"Thanks for testing that out. In this case, I'll try an dig more deeply into why you're having issues compiling from source. In the mean time, I hope the pre-compiled binary will work for you. edit: I wonder if the error might be related to the fact that the build system things TBB was compiled with GCC 4.4? From the log:. > /usr/local/packages/intel-tbb.4.4.3.181/compilers_and_libraries_2016.2.181/linux/tbb/lib/intel64_lin/**gcc4.4**/libtbb.so.2",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/51#issuecomment-201332198:11,test,testing,11,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/51#issuecomment-201332198,2,"['log', 'test']","['log', 'testing']"
Testability,"Thanks for the heads up. I gave it a test this evening and wow, it is wicked fast. I’ll send you those quant files tomorrow when I get a chance, but adding that flag and the new version fixed the problem. . Thank you for all your help. . Best,. Ryan . Sent from my iPhone. On Jun 16, 2020, at 11:36 PM, Rob Patro <notifications@github.com> wrote:. ﻿. P.S. ; @shalercr,; I also note that layering --hitFilterPolicy BOTH on top of the new version cuts down the time by another factor of 2 for me; 2163.65user 12.72system 4:21.57elapsed 832%CPU (0avgtext+0avgdata 1221856maxresident)k. and the number of mappings discarded alignments due to score comes down by another factor of ~6X. It might be worth seeing what you get with that option as well.; —; You are receiving this because you were mentioned.; Reply to this email directly, ; view it on GitHub, or ; unsubscribe.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/537#issuecomment-645762627:37,test,test,37,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/537#issuecomment-645762627,1,['test'],['test']
Testability,"Thanks for the quick answer!; Here is the log file:. [2020-04-22 12:53:21.437] [jointLog] [info] setting maxHashResizeThreads to 8; [2020-04-22 12:53:21.437] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2020-04-22 12:53:21.437] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2020-04-22 12:53:21.437] [jointLog] [info] Usage of --validateMappings implies a default consensus slack of 0.2. Setting consensusSlack to 0.35.; [2020-04-22 12:53:21.437] [jointLog] [info] parsing read library format; [2020-04-22 12:53:21.437] [jointLog] [info] There is 1 library.; [2020-04-22 12:53:21.501] [jointLog] [info] Loading pufferfish index; [2020-04-22 12:53:21.503] [jointLog] [info] Loading dense pufferfish index.; [2020-04-22 12:54:13.540] [jointLog] [info] done; [2020-04-22 12:54:13.713] [jointLog] [info] Index contained 228,799 targets; [2020-04-22 12:54:29.422] [jointLog] [info] Number of decoys : 84; [2020-04-22 12:54:29.466] [jointLog] [info] First decoy index : 228,673 ; [2020-04-22 13:00:24.946] [jointLog] [info] Automatically detected most likely library type as ISR; [2020-04-23 00:06:31.287] [jointLog] [info] Thread saw mini-batch with a maximum of 1.06% zero probability fragments; [2020-04-23 00:06:41.198] [jointLog] [info] Thread saw mini-batch with a maximum of 1.08% zero probability fragments; [2020-04-23 00:06:50.741] [jointLog] [info] Thread saw mini-batch with a maximum of 1.02% zero probability fragments; [2020-04-23 00:06:56.260] [jointLog] [info] Thread saw mini-batch with a maximum of 1.08% zero probability fragments; [2020-04-23 00:06:56.781] [jointLog] [info] Thread saw mini-batch with a maximum of 1.04% zero probability fragments; [2020-04-23 00:07:03.636] [jointLog] [info] Thread saw mini-batch with a maximum of 1.04% zero probability fragments; [2020-04-23 00:07:03.759] [jointLog] [info] Thread saw mini-batch ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/516#issuecomment-621872756:42,log,log,42,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/516#issuecomment-621872756,1,['log'],['log']
Testability,Thanks for the report @bernt-matthias. It's interesting that the exception propagation ends up at this place in the code. Would it be possible to also provide the log file for the indexing at the point you catch the indexing in this state? That will help us figure out which allocation could be going awry and why it is propagating to this location rather than causing the program to exit more abruptly.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/484#issuecomment-588455026:163,log,log,163,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/484#issuecomment-588455026,1,['log'],['log']
Testability,Thanks for this bug report @gringer! I have pushed a change to develop that should address this. Would you need me to produce an executable to test this out?,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/806#issuecomment-1293938189:143,test,test,143,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/806#issuecomment-1293938189,1,['test'],['test']
Testability,"Thanks for your help. @TomSmithCGAT suggested that it could be our cluster, as he had issues he could resolve with the same cluster. I have a second cluster I can test on. I will do testing on this first and see if I can come to the bottom of it and will get back to you.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/337#issuecomment-458159405:163,test,test,163,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/337#issuecomment-458159405,2,['test'],"['test', 'testing']"
Testability,"Thanks for your input sir. On Sat, Nov 23, 2019 at 3:07 AM Rob Patro <notifications@github.com> wrote:. > @cljacobs <https://github.com/cljacobs> : yes; great point. This has been fixed; > in develop; > <https://github.com/COMBINE-lab/salmon/blob/develop/CMakeLists.txt#L1>.; > It was an oversight due to our testing infrastructure already having a; > newer version of CMake that didn't run into this problem.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/COMBINE-lab/salmon/issues/453?email_source=notifications&email_token=AN2V7HXRZ7T5IT4HH7XJX2DQVBGLJA5CNFSM4JP7NHKKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEE66GMI#issuecomment-557703985>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AN2V7HTSAKLGW4THGPC2QSDQVBGLJANCNFSM4JP7NHKA>; > .; >. -- ; *Shanmugavadivel, P. S.*; *Scientist (Agricultural Biotechnology),*. *#216, Block A,*; *ICAR-Indian Institute of Pulses Research,*. *Min. of Agriculture & Farmers Welfare,*. *Govt. of India,Kanpur - 208 024.*; *email: shanmugavadivel.ps@icar.gov.in <shanmugavadivel.ps@icar.gov.in>*; *www.iipr.res.in <http://www.iipr.res.in>*",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/453#issuecomment-557774500:309,test,testing,309,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/453#issuecomment-557774500,1,['test'],['testing']
Testability,"Thanks for your quickly reply! It really worked @k3yavi; Then I run the command line ; `salmon alevin -l ISR /home/lailab/disk/gjw/Ascite-1_R1.fq.gz -2 /home/lailab/disk/gjw/Ascite-1_R2.fq.gz --chromium --index /home/lailab/disk/gjw/default/ -p 10 -o /home/lailab/disk/gjw/alevin_out --tgMap /home/lailab/disk/gjw/txp2gene.tsv`. ```; Version Server Response: Not Found; Logs will be written to /home/lailab/disk/gjw/alevin_out/logs; [2021-05-27 14:31:00.318] [jointLog] [info] setting maxHashResizeThreads to 10; [2021-05-27 14:31:00.318] [jointLog] [info] The --mimicBT2, --mimicStrictBT2 and --hardFilter flags imply mapping validation (--validateMappings). Enabling mapping validation.; [2021-05-27 14:31:00.318] [jointLog] [error] You passed paired-end files to salmon, but you passed 0 files to --mates1 and 1 files to --mates2. You must pass the same number of files to both flags; [2021-05-27 14:31:00.318] [jointLog] [info] Using default value of 0.87 for minScoreFraction in Alevin; Using default value of 0.6 for consensusSlack in Alevin; [2021-05-27 14:31:00.318] [alevinLog] [error] Could not properly process salmon-level options!; ```; Is it the problem with my data?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/663#issuecomment-850151665:370,Log,Logs,370,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/663#issuecomment-850151665,2,"['Log', 'log']","['Logs', 'logs']"
Testability,Thanks so much @k3yavi! We will take a look and see about adding a small function to add a synthetic cell barcode in front of the UMI on read 2. I do think there is value in adding in 0-length cell barcode functionality for a variety of plate-based single cell approaches as well as allow for UMI containing bulk RNA-seq. We will follow up after @jamorrison and I discuss and test. @DongzeHE and @Gaura I'd love to hear your thoughts on this too. Thanks again!,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/805#issuecomment-1282574837:376,test,test,376,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/805#issuecomment-1282574837,1,['test'],['test']
Testability,"Thanks! I don't have a CentOS 5 setup anywhere where I could test, but if it should be fixed then I'll go ahead and update the formula and bug you about it if anyone runs into problems.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/89#issuecomment-245930320:61,test,test,61,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/89#issuecomment-245930320,1,['test'],['test']
Testability,"Thanks! Worked with a Mapping rate = 73.4157%. See log below. However, I only get half the number of mapped reads per cell-feature. I still need to examine the existing alignment to understand why. ![image](https://user-images.githubusercontent.com/9895004/84175848-8c863c80-aa4e-11ea-8d36-986e7d6f04b5.png). > [2020-06-09 12:31:05.494] [alevinLog] [info] Found 64 transcripts(+0 decoys, +0 short and +0 duplicate names in the index); > [2020-06-09 12:31:05.494] [alevinLog] [info] Filled with 64 txp to gene entries ; > [2020-06-09 12:31:05.494] [alevinLog] [info] Found all transcripts to gene mappings; > [2020-06-09 12:31:05.499] [alevinLog] [info] Processing barcodes files (if Present) ; > ; > ; > [2020-06-09 12:32:20.000] [alevinLog] [info] Done barcode density calculation.; > [2020-06-09 12:32:20.000] [alevinLog] [info] # Barcodes Used: [32m52200250[0m / [31m52200250[0m.; > [2020-06-09 12:32:20.285] [alevinLog] [info] Done importing white-list Barcodes; > [2020-06-09 12:32:20.423] [alevinLog] [warning] Skipping 672237 Barcodes as no read was mapped; > [2020-06-09 12:32:20.578] [alevinLog] [info] Total 65042 white-listed Barcodes; > [2020-06-09 12:32:20.578] [alevinLog] [info] Sorting and dumping raw barcodes; > [2020-06-09 12:32:21.060] [alevinLog] [info] Total 5.06742% reads will be thrown away because of noisy Cellular barcodes.; > [2020-06-09 12:32:23.856] [alevinLog] [info] Done populating Z matrix; > [2020-06-09 12:32:23.882] [alevinLog] [info] Total 79207 CB got sequence corrected. > [2020-06-09 12:32:23.893] [alevinLog] [info] Done indexing Barcodes; > [2020-06-09 12:32:23.893] [alevinLog] [info] Total Unique barcodes found: 604589; > [2020-06-09 12:32:23.893] [alevinLog] [info] Used Barcodes except Whitelist: 71340; > [2020-06-09 12:32:24.004] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify; > ; > [2020-06-09 12:32:24.004] [alevinLog] [info] parsing read library format; > [2020-06-09 12:33:33.719] [alevinLog] [info] Starting optimizer; ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-641426690:51,log,log,51,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-641426690,1,['log'],['log']
Testability,"Thanks, I usually do not trim reads. I am surprised to see such a difference from version 0.8.3. Do you have a recommendation for --minScoreFraction if I do not trim reads? Or maybe I should go back to NOT using --validateMappings?; For testing purposes, I will try trimming the reads for this sample. Will report back.; Oh, and this sample was prepared by ultra-low RNA input protocol, so the issues of adapter contamination could be present.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-586475673:237,test,testing,237,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-586475673,1,['test'],['testing']
Testability,"Thanks, for the response and I'll wait for the detail explanation. . As for the Gibbs, yes I get the appropriate gibbs sample outputs, it's just appears that the log file is not being written.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/466#issuecomment-568769945:162,log,log,162,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/466#issuecomment-568769945,1,['log'],['log']
Testability,"Thanks. I noticed that you forked BWA. I'm guessing my substitution of mainline BWA for your forked version is behind the last error. If we get int64_t defined, that might resolve it. I'd be happy to test, and can submit some patches for my other edits to CMakefiles.txt . I will try the Docker image. I was hesitant to use it because it relies on ZFS, and I'm not sure how ZFS will interact with my jail. Probably the easier path right now though.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/162#issuecomment-337616760:200,test,test,200,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/162#issuecomment-337616760,1,['test'],['test']
Testability,"That is . . . strange! Salmon _literally_ uses the RapMap index (and the RapMap functions) directly to obtain the quasi-mappings. One thing I noticed is that you seem to be using `pseudoindex` which is our independent re-implementation of pseudo-alignment. However, Salmon (and Sailfish) use quasi-mapping (RapMap's `quasiindex` and `quasimap` commands, as [we found this to be more accurate](http://biorxiv.org/content/biorxiv/early/2016/01/16/029652.full.pdf)). I presume that if you used the quasi-mapping functionality, you might observe the bug. If you don't (i.e. if RapMap performs quasi-mapping properly), then this is a real thinker (and I'd be happy to take a look myself if you can share the file). P.S. The same caveat I mentioned above may apply. That is, it is possible that a polyA transcript that is completely removed from the input could cause a problem unless we check for it in the quasi-index, but may not affect the pseudo-index. This is because the quasi-index relies on a packed representation of the transcriptome and an associated sparse bit-vector to perform the mapping, and it assumes that all of the transcripts will have a non-zero length (if this is the culprit, it is, of course, easy to fix with an explicit check). You could also test this hypothesis by generating the quasi-index with the `--noClip` option, which will disable poly-A clipping when building the index.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/37#issuecomment-175088841:1265,test,test,1265,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/37#issuecomment-175088841,1,['test'],['test']
Testability,"That is totally unexpected. There is nothing obvious from the output above. Could you share the output directory itself? It will also contain a log file with time stamps so we can see where the time went. Regarding the mapping rate; that is a bit on the low end, but not catastrophically so (May be worth trimming to see if that changes things at all). The number of decoy fragments is also quite high, meaning a good number of reads arising outside of annotated transcripts.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/516#issuecomment-621834194:144,log,log,144,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/516#issuecomment-621834194,1,['log'],['log']
Testability,"That's very strange in that it doesn't even seem to be trying to load the index! I obviously don't have the same set of reads you do, but here is what I get when using this pre-compiled binary on the 64-bit index (this is a small read set from single-cell data, which is why the total # of reads is so small). ```; rob@feynman:/mnt/scratch3/rob/JoshTest$ ~/SoftwareStaging/salmon/scripts/SalmonBeta-0.6.5-pre_CentOS5/bin/salmon quant -p 15 -i salmon_index -l IU -1 ../strange_peak/19232_1_1.fastq -2 ../strange_peak/19232_1_2.fastq -o quant_binary; Version Info: This is the most recent version of Salmon.; # salmon (mapping-based) v0.6.0; # [ program ] => salmon; # [ command ] => quant; # [ threads ] => { 15 }; # [ index ] => { salmon_index }; # [ libType ] => { IU }; # [ mates1 ] => { ../strange_peak/19232_1_1.fastq }; # [ mates2 ] => { ../strange_peak/19232_1_2.fastq }; # [ output ] => { quant_binary }; Logs will be written to quant_binary/logs; there is 1[2016-03-31 14:05:14.184] [jointLog] [info] parsing read library format; lib; Loading 64-bit quasi index[2016-03-31 14:05:14.266] [stderrLog] [info] Loading Suffix Array; [2016-03-31 14:05:14.266] [jointLog] [info] Loading Quasi index. [2016-03-31 14:07:58.647] [stderrLog] [info] Loading Transcript Info; [2016-03-31 14:08:59.703] [stderrLog] [info] Loading Rank-Select Bit Array; [2016-03-31 14:09:06.744] [stderrLog] [info] There were 2027284 set bits in the bit array; [2016-03-31 14:09:08.123] [stderrLog] [info] Computing transcript lengths; [2016-03-31 14:09:08.240] [stderrLog] [info] Waiting to finish loading hash; Index contained 2027284 targets; [2016-03-31 14:09:15.789] [jointLog] [info] done; [2016-03-31 14:09:15.786] [stderrLog] [info] Successfully loaded position hash; [2016-03-31 14:09:15.789] [stderrLog] [info] Done loading index. [2016-03-31 14:09:36.623] [jointLog] [info] Computed 8083 rich equivalence classes for further processing; [2016-03-31 14:09:36.623] [jointLog] [info] Counted 159824 total reads in th",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/54#issuecomment-204066023:912,Log,Logs,912,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/54#issuecomment-204066023,2,"['Log', 'log']","['Logs', 'logs']"
Testability,"The bash script looks good to me, and I am not aware of any hard limit on the number of files as input. However, I just did tested on 24 files as an input and it seems to work. Hard to tell what's wrong, without being able to replicate the issue.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/329#issuecomment-446208541:124,test,tested,124,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/329#issuecomment-446208541,1,['test'],['tested']
Testability,"The current behavior, which I think is the most reasonable for now, is to keep logging messages to stderr, even if they are not errors. This lets us use stdout for output which may need to be redirected to other programs (e.g. mapping results).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/55#issuecomment-245804636:79,log,logging,79,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/55#issuecomment-245804636,1,['log'],['logging']
Testability,"The following bash code will detect and parse either format of gtf into an appropriately versioned two column tx2gene file. test=$(zless -S $gtf | grep -v ""#"" | awk '$3==""transcript""' | head -n 1| cut -f9 | tr -s "";"" "" "" | awk '{print$3}' | sort | uniq | sed 's/\""//g'); if [[ $test == ""transcript_id"" ]]; then; zless -S $gtf | grep -v ""#"" | awk '$3==""transcript""' | cut -f9 | tr -s "";"" "" "" | awk '{print$4""\t""$2}' | sort | uniq | sed 's/\""//g' > txp2gene.tsv; elif [[ $test == ""gene_version"" ]]; then; echo ""Separate version field (ensembl, non-gencode transcriptome, eg. rat, etc)""; zless -S $gtf | grep -v ""#"" | awk '$3==""transcript""' | cut -f9 | tr -s "";"" "" "" | awk '{print$6 ""."" $8""\t""$2 ""."" $4}' | sort | uniq | sed 's/\""//g' > txp2gene.tsv; fi",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/598#issuecomment-737617544:124,test,test,124,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/598#issuecomment-737617544,3,['test'],['test']
Testability,"The implementation to output mapping information from within salmon (not yet full alignments) is almost complete. The feature needs some testing, but it will definitely make it into the next release.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/38#issuecomment-242924562:137,test,testing,137,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/38#issuecomment-242924562,1,['test'],['testing']
Testability,"The indexing log shows nothing out of the ordinary:. ```; [2016-01-22 15:11:57.283] [jointLog] [info] building index; [2016-01-22 15:40:12.318] [jointLog] [info] done building index; ```. There was actually a blank line at the very end of the transcriptome FASTA which I though might be related to #22, so I removed this line, re-indexed and have the same behavior. I'll check on the nucleotide size of the transcriptome now. cc @jmerkin",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/37#issuecomment-174533495:13,log,log,13,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/37#issuecomment-174533495,1,['log'],['log']
Testability,"The last patch display the error with `std::cerr << ...`, because `log->critical(...)` does not seem to work. Not sure how to fix it.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/617#issuecomment-835404939:67,log,log,67,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/617#issuecomment-835404939,1,['log'],['log']
Testability,"The latest recommended way is through [tximport](https://github.com/mikelove/tximport). In case you need to check more benchmarks comparing different output format, please check [EDS](https://github.com/COMBINE-lab/EDS/blob/master/README.md). Closing this issue but feel free to reopen in case you still have problems.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/354#issuecomment-548616000:119,benchmark,benchmarks,119,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/354#issuecomment-548616000,1,['benchmark'],['benchmarks']
Testability,"The relevant parts of the log are here:; ```; [2019-10-04 10:37:22.243] [ff::console] [warning] Removed 89618 transcripts that were sequence duplicates of indexed transcripts.; [2019-10-04 10:37:22.243] [ff::console] [warning] If you wish to retain duplicate transcripts, please use the `--keepDuplicates` flag; [2019-10-04 10:37:22.318] [ff::console] [info] Replaced 1,775,734,603 non-ATCG nucleotides; [2019-10-04 10:37:22.318] [ff::console] [info] Clipped poly-A tails from 422 transcripts; wrote 593292 cleaned references; seqHash 256 : bd425816a78195ed31cf17ce9df99c2bf56bff98f0df5ace1e958b263d805390; seqHash 512 : 845b625de6f8f018796e464f7c49f6596d2b31b28a58771d56ece24b3d9cad98b8189572ff43d6a3eb8ef24b5d3bc5ac0f89845a57e3682498a56a1bc920e7b7; nameHash 256 : 3bd11eac1e6b05e93689676ca056c165e7c26723c4b137fd284bb8b40ef5df62; nameHash 512 : e68449cfd99f5968182735275b00779b8a396e413a3629beef933e51bd18902c821c26e2a5461c687d023ef85168e58d76bacd5fe1f0a3111bfccc34af9c4035; [2019-10-04 10:37:37.931] [console] [info] Filter size not provided; estimating from number of distinct k-mers; [2019-10-04 10:38:33.012] [console] [info] ntHll estimated 2765935300 distinct k-mers, setting filter size to 2^36; Threads = 8; Vertex length = 31; Hash functions = 5; Filter size = 68719476736; Capacity = 2; Files:; test_pufferfish_index/ref_k31_fixed.fa; --------------------------------------------------------------------------------; Round 0, 0:68719476736; Pass Filling Filtering; 1 385 3124; 2 1258 2; True junctions count = 5437144; False junctions count = 4410615; Hash table size = 9847759; Candidate marks count = 26276463; --------------------------------------------------------------------------------; Reallocating bifurcations time: 6; True marks count: 20290262; Edges construction time: 5004; --------------------------------------------------------------------------------; Distinct junctions = 5437144. approximateContigTotalLength: 1543877663; counters:; 49076 936 921 40; Exception : [std:",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/432#issuecomment-538547108:26,log,log,26,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/432#issuecomment-538547108,1,['log'],['log']
Testability,The script was running `cmake && make install` with no `make`. Could that be it? I've added `make` before `make install`. I'll get that log file for you.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/181#issuecomment-367756380:136,log,log,136,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/181#issuecomment-367756380,1,['log'],['log']
Testability,"The specific error message seems to be coming from [the serialization library we use](https://github.com/USCiLab/cereal/blob/master/include/cereal/archives/portable_binary.hpp#L245). This was upgraded recently, so I'm hoping that they didn't introduce a new bug upstream. As soon as I can reproduce this, I can test if rolling back the version of the serialization library fixes the issue (which I don't believe occurred in 0.7.2).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/129#issuecomment-287255919:311,test,test,311,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/129#issuecomment-287255919,1,['test'],['test']
Testability,"There are quant.sf files in each one of folders. But i get the error saying ""doesn't contain quant.sf "". aux_info cmd_info.json lib_format_counts.json libParams logs quant.sf",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/179#issuecomment-543271953:161,log,logs,161,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/179#issuecomment-543271953,1,['log'],['logs']
Testability,"There is a long literature about why we use counts or CPM (in either case, optionally with an effective transcript length offset) instead of raw TPM for statistical modeling. Using TPM throws out information about the sampling variation. It can be recovered in large sample datasets, but in small sample datasets, it's too much information loss. With respect to Wilcoxon, again, it's good to incorporate the inherent sampling variation of counts into the test statistic even with nonparametric schemes. This occurs in SAMseq (2013). https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4605138/. ...and also in our method Swish (2019), which is based on SAMseq but designed specifically for output of methods like Salmon. https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6765120/. Note that Swish is both 1) nonparametric 2) takes into account the multinomial-based sampling nature of sequencing data 3) also takes into account inferential uncertainty from multimapping reads (across isoforms, alleles, or genes).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/812#issuecomment-1325134215:455,test,test,455,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/812#issuecomment-1325134215,1,['test'],['test']
Testability,"They should be unnecessary to diagnose, but if you want to extract the first 100k reads or so, we can try and use them for test quantification.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/561#issuecomment-674423103:123,test,test,123,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/561#issuecomment-674423103,1,['test'],['test']
Testability,"Thinking more about the another problem can be the salmon index i.e. since it's gencode and if not already specified, you might wanna add `--gencode` as the command line flag while creating the index. The problem is the _full_ name in the reference fasta and the GTF does not align, only a prefix from the fasta does. Another thing I noticed in the logs you forwarded is that the number of CB detected by our knee heuristic seems to be undershooting. I might have to look into the data to tell more about it but the alternatives would be to explicitly specify the true/expected CB through a tsv file using flag `--whitelist` or you can force Alevin to use top X highly expressed CB with flag `--forceCells X`. Hope this helps.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/326#issuecomment-443715231:349,log,logs,349,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/326#issuecomment-443715231,1,['log'],['logs']
Testability,"This happens when there was no read in the same length bin during training period (the first so many reads are used for training) as the read under consideration. So Salmon can't assigned a valid log likelihood and an error is reported. The 3 errors are really the same one. The error log likelihood of 3 models are added (based on position of first mismatch/indel, length of clipping at each end of the read). If the length bin is empty for 1 model, it is likely empty for the other 2 models, and 3 warnings are printed when 1 would have been enough. This read gets a error likelihood of 1 and is mostly ignored by Salmon after that. Such reads should be rare by definition (unless the input BAM was not randomized, or there is bug) and this warning should be rare as well. So unless you see many such warnings, you can safely ignore it.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/701#issuecomment-1421264240:196,log,log,196,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/701#issuecomment-1421264240,2,['log'],['log']
Testability,"This is failing on our local drone CI during runtime. The log output is :. ```; + echo ""[Testing quant]""; [Testing quant]; + ./.drone/test_quant.sh; Holy build box activated; Prefix: /hbb_exe; CFLAGS: -g -O2 -fvisibility=hidden -I/hbb_exe/include ; LDFLAGS: -L/hbb_exe/lib -static-libstdc++; STATICLIB_CFLAGS: -g -O2 -fvisibility=hidden -I/hbb_exe/include ; SHLIB_CFLAGS: -g -O2 -fvisibility=hidden -I/hbb_exe/include ; SHLIB_LDFLAGS: -L/hbb_exe/lib -static-libstdc++; [Drone test] current path : /drone/src/github.com/COMBINE-lab/salmon; [Drone test] making quant test directory; [Drone test] run nextflow pipeline; N E X T F L O W ~ version 0.29.1; Launching `tests/test_quant.nf` [curious_gilbert] - revision: 4f25b30301; [warm up] executor > local; [91/922fac] Submitted process > buildIndex; ERROR ~ Error executing process > 'buildIndex'; Caused by:; Process `buildIndex` terminated with an error exit status (127); Command executed:; /drone/src/github.com/COMBINE-lab/salmon/bin/salmon index -t Homo_sapiens.GRCh37.75.cdna.pc.fa -i nfindex; Command exit status:; 127; Command output:; (empty); Command error:; /drone/src/github.com/COMBINE-lab/salmon/bin/salmon: error while loading shared libraries: libjemalloc.so.2: cannot open shared object file: No such file or directory; Work dir:; /drone/src/github.com/COMBINE-lab/salmon/work/91/922facec25da43edd4a2ce82f2289d; Tip: when you have fixed the problem you can continue the execution appending to the nextflow command line the option `-resume`; -- Check '.nextflow.log' file for detail; ```. So, it seems to be due to failure to find the dynamic shared library for jemalloc. Any idea why that might be?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/348#issuecomment-472495264:58,log,log,58,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/348#issuecomment-472495264,16,"['Test', 'log', 'test']","['Testing', 'log', 'test', 'tests']"
Testability,"This is the initial output log, where it reports an inccorrect gene annotation:. ---; Version Info: This is the most recent version of salmon.; -----------------------------------------; | Loading contig table | Time = 13.512 s; -----------------------------------------; size = 16145665; -----------------------------------------; | Loading contig offsets | Time = 382.03 ms; -----------------------------------------; -----------------------------------------; | Loading reference lengths | Time = 9.4861 ms; -----------------------------------------; -----------------------------------------; | Loading mphf table | Time = 2.4236 s; -----------------------------------------; size = 1057188904; Number of ones: 16145664; Number of ones per inventory item: 512; Inventory entries filled: 31535; -----------------------------------------; | Loading contig boundaries | Time = 4.031 s; -----------------------------------------; size = 1057188904; -----------------------------------------; | Loading sequence | Time = 1.983 s; -----------------------------------------; size = 572818984; -----------------------------------------; | Loading positions | Time = 14.658 s; -----------------------------------------; size = 942318702; -----------------------------------------; | Loading reference sequence | Time = 1.4932 s; -----------------------------------------; -----------------------------------------; | Loading reference accumulative lengths | Time = 10.959 ms; -----------------------------------------; Error: invalid feature coordinates (end<start!) at line:; NC_029855.1	RefSeq	gene	406748	107842	.	+	.	gene_id ""A5N79_gp28""; db_xref ""GeneID:27215502""; exception ""trans-splicing""; gbkey ""Gene""; gene ""nad2""; gene_biotype ""protein_coding""; locus_tag ""A5N79_gp28""; ; --- . After I remove the erroneous entry, there is no more complaint:. ---; Version Info: This is the most recent version of salmon.; -----------------------------------------; | Loading contig table | Time = 14.648 s; -----",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/569#issuecomment-709699746:27,log,log,27,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/569#issuecomment-709699746,1,['log'],['log']
Testability,"This seems to be a separate issue than the other (and a more informative exception). Once I've resolved the other issue, I would probably try to bug you for a sample that causes this --- though I have a reasonable idea about how to fix it. It would be nice to have the fix for both issues in the same hotfix. To be more specific : this is, as the exception says, a numeric underflow issue when evaluating the digamma function. The solution here is just to bump up the value that is required before evaluating this function. This should be straightforward, but I suspect the issue is also related to this log message:. > [2018-05-31 17:08:11.488] [jointLog] [info] Marked 1 weighted equivalence classes as degenerate",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/229#issuecomment-393571565:604,log,log,604,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/229#issuecomment-393571565,1,['log'],['log']
Testability,"UPDATE: On @rob-p 's suggestion, I removed the `--recoverOrphans` option and then all 60 samples did finished without segfaulting. Perhaps there were too many orphans to handle - alignments rates were a dismal 0.5-23%. These were heavily degraded samples that the sequencing center recommended not to sequence but the PI wanted to try it anyway. If you want a pair of fastq files (full or cutdown to ~5 M reads) to test this weird edge case, I can see about getting them to you. Thanks!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/668#issuecomment-862525216:415,test,test,415,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/668#issuecomment-862525216,1,['test'],['test']
Testability,"Uh, why then does ""make test"" fail if the root directory name is changed? That was using the binary/libraries in $WHEREVER, after bin and lib below the root directory were removed. Typically that sort of operation doesn't care what the top level is named. For some future release, perhaps the run time dynamic loading of libraries could look up the path to libtbb.so.2 and try that first, before falling back to LD_LIBRARY_PATH? On my system ldd of salmon shows a link to libtbb.so.2, no LD_LIBRARY_PATH needed. ldd does not show any links to libtbb.malloc*. The program will do at least ""salmon --help' that way without any errors or warnings. That isn't sufficient to pass ""make test"" though (even when the directory has not been renamed). It seems that libtbb.malloc* libraries are used during that test, and that use requires LD_LIBRARY_PATH. Only when they are found that way does ""make test"" work.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/236#issuecomment-397063656:24,test,test,24,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/236#issuecomment-397063656,4,['test'],['test']
Testability,"Unfortunately, I don't necessarily have a great data set to test on, since my motivation for requesting this feature was that I'm working on a single-end dataset.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/83#issuecomment-246164908:60,test,test,60,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/83#issuecomment-246164908,1,['test'],['test']
Testability,"Very strange, I'd like to start with first apologizing for relatively poor documentation for all these meta files (`MappedUMI`) and I think that's the point of confusion. The expected behavior is as follows:; * `--dumpFeature` dumps various meta files like `filtered_cb_frequency.txt` which gives number of reads in each CB after sequence correction and `MappedUMI,txt` which is a subset of reads from the `filtered_cb_frequency.txt` which are mapped by alevin and should be reflective of the mapping rate.; * `--dumpUmiGraph` dumps the internal graphical structure used by alevin for deduplication. Having said that, I was curious that the sum of count in the `MappedUMI.txt` is coming out to be 17M. I tested the same at my end and it's coming out to be ~200M . I am puzzled why the counts are so low for your run, can you please double check if alevin has finished ? It seems the behavior you are observing in the CEL-seq data is the right one. For counting the number of mapped reads use the file `MappedUMI.txt` and for counting number of deduplicated reads use `quants_mat.gz`.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/361#issuecomment-490105924:704,test,tested,704,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/361#issuecomment-490105924,1,['test'],['tested']
Testability,"We do no have access to BSD-based systems (apart from the extent to which OSX can be said to be BSD-based) on which to test during development. Bioconda works on many linux distributions; though I do not have a comprehensive list. For example, we regularly run on Ubuntu, CentOS, RedHat and Debian. If you have the facilities to use Docker on this machine, you can also pull down a docker image of the latest release from https://hub.docker.com/r/combinelab/salmon.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/419#issuecomment-522628674:119,test,test,119,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/419#issuecomment-522628674,1,['test'],['test']
Testability,"We might have to go through the paper and the dropseq guidelines to check what really changed.; You might wanna check https://github.com/COMBINE-lab/salmon/issues/247, we actually have a hidden option to do customized umi/CB length options, however this goes into a little more unexplored territory and requires a bit more testing. We'd appreciate your feedback if you happen to run this mode.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/258#issuecomment-408191888:323,test,testing,323,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/258#issuecomment-408191888,2,['test'],['testing']
Testability,"We shy away from using `native` arch anywhere, and instead try to be explicit about the instruction sets used. My current best guess is that we assume SSE4 (at least [here](https://github.com/COMBINE-lab/pufferfish/blob/master/CMakeLists.txt#L77)). I believe this processor does not fully support SSE4.0. I can try and see if there are any other places we make this assumption, and then perhaps make a test pre-compiled binary without it.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/500#issuecomment-610580721:402,test,test,402,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/500#issuecomment-610580721,1,['test'],['test']
Testability,"Well, it doesn't matter how long the log is, since we only need the last line, right?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267842175:37,log,log,37,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267842175,1,['log'],['log']
Testability,Well... `./src/unitTests` seems to always pass and `make test` to always fail...,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/229#issuecomment-393689032:57,test,test,57,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/229#issuecomment-393689032,1,['test'],['test']
Testability,"When I do with proxy I got : . ```; Last login: Thu Jun 30 15:10:26 on ttys001; Benjamin@u932-ulm-2-57030119-6834 ~ % all_proxy= url:port conda install salmon; Collecting package metadata (current_repodata.json): failed. # >>>>>>>>>>>>>>>>>>>>>> ERROR REPORT <<<<<<<<<<<<<<<<<<<<<<. Traceback (most recent call last):; File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/conda/exceptions.py"", line 1082, in __call__; return func(*args, **kwargs); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/conda/cli/main.py"", line 87, in _main; exit_code = do_call(args, p); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/conda/cli/conda_argparse.py"", line 84, in do_call; return getattr(module, func_name)(args, parser); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/conda/cli/main_install.py"", line 20, in execute; install(args, parser, 'install'); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/conda/cli/install.py"", line 260, in install; unlink_link_transaction = solver.solve_for_transaction(; File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/conda/core/solve.py"", line 152, in solve_for_transaction; unlink_precs, link_precs = self.solve_for_diff(update_modifier, deps_modifier,; File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/conda/core/solve.py"", line 195, in solve_for_diff; final_precs = self.solve_final_state(update_modifier, deps_modifier, prune, ignore_pinned,; File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/conda/core/solve.py"", line 300, in solve_final_state; ssc = self._collect_all_metadata(ssc); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/conda/common/io.py"", line 88, in decorated; return f(*args, **kwds); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/conda/core/solve.py"", line 463, in _collect_all_metadata; index, r = self._prepare(prepared_specs); File ""/usr/local/Ca",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/724#issuecomment-1171208515:41,log,login,41,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/724#issuecomment-1171208515,1,['log'],['login']
Testability,"Whoaa! Ok. This is something. It's hanging in a place where we have no client (i.e., Salmon) threading code. It's inside an Intel TBB for loop. But, according to gdb, the TBB libraries that are executing at this point are system ones (/usr/lib/x86_64-linux-gnu/libtbb.so.2). Also interesting is that the full backtrace is into a call to the logarithm function, which shouldn't block. Could you spin up another Salmon process but with Salmon's copy of TBB in the LD_LIBRARY_PATH before the system one, just to make sure that's not the issue? It's likely not, but it's worth being sure. Whatever ends up causing this, I have a feeling it will be something very strange.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267491370:341,log,logarithm,341,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267491370,1,['log'],['logarithm']
Testability,"Yea, so Drop-seq data tends to be a bit more noisier than 10x, at least in my experience. ; I had a quick look at the logs and it seems the ""knee"" method is under estimating a bit. I highly recommend playing with the alevin flags from the discussion I forwarded, I think it should work fine with `--expectCells 3000` or `--forceCells 3000`. You can check and process the featureDump file from the alevin if you use `--dumpFeatures` flag to choose the number of barcodes to provide in the expectCells or forceCells command.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/625#issuecomment-776205702:118,log,logs,118,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/625#issuecomment-776205702,1,['log'],['logs']
Testability,"Yeah, I haven't heard back yet. Any test case is fine where the data is publicly accessible. Thanks.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-983999718:36,test,test,36,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-983999718,1,['test'],['test']
Testability,"Yep that sounds reasonable to me.; In case you wan't to avoid multiple round of alevin runs, the idea in the develop branch is to use `--freqThreshold 0 --maxNumBarcodes 4294967295 --keepCBFraction 0.95` i.e. maxNumBarcodes is almost infinity which will force alevin to consider all CB for processing while keeping 95% of the CB as high confidence and hopefully the last 5% would be `>200` CBs which will make alevin run whitelisting. Thanks again for testing alevin and its features !",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/379#issuecomment-503624687:452,test,testing,452,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/379#issuecomment-503624687,1,['test'],['testing']
Testability,"Yep, check this line in the log:; > Total 41.2673% reads will be thrown away because of noisy Cellular barcodes. I think the CB frequency is most probably a bimodal distribution, I'd suggest you to try `--expectCells 8000` command line flag along with the regular command you are using above and check if the numbers in the log comes down to `~15%`.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/396#issuecomment-510549172:28,log,log,28,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/396#issuecomment-510549172,2,['log'],['log']
Testability,"Yes ! it's other error that I can't find . but I try : . ```; Last login: Thu Jun 30 15:14:51 on ttys002; Benjamin@u932-ulm-2-57030119-6834 ~ % conda config --add channels defaults; conda config --add channels bioconda; conda config --add channels conda-forge; Warning: 'conda-forge' already in 'channels' list, moving to the top; Benjamin@u932-ulm-2-57030119-6834 ~ % conda install salmon; Collecting package metadata (current_repodata.json): failed. CondaHTTPError: HTTP 000 CONNECTION FAILED for url <https://conda.anaconda.org/conda-forge/osx-arm64/current_repodata.json>; Elapsed: -. An HTTP error occurred when trying to retrieve this URL.; HTTP errors are often intermittent, and a simple retry will get you on your way.; 'https://conda.anaconda.org/conda-forge/osx-arm64'; ```. ```; Benjamin@u932-ulm-2-57030119-6834 ~ % conda config --show channels ; channels:; - conda-forge; - bioconda; - defaults; ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/724#issuecomment-1171223414:67,log,login,67,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/724#issuecomment-1171223414,2,['log'],['login']
Testability,"Yes, @rob-p! It's an improvement from ~33% to ~19% slower (I'm not sure why sd is high for custom testing though). Yeah, I'm eager to hear your views too, @gmarcais.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/734#issuecomment-1023351185:98,test,testing,98,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/734#issuecomment-1023351185,1,['test'],['testing']
Testability,"Yes, all have entry in the *.fa file but are missing from *.gtf file. > grep ""ENST00000615101"" Homo_sapiens.GRCh38.87.cdna.ncrna.fa; >ENST00000615101 ncrna chromosome:GRCh38:CHR_HSCHR15_4_CTG8:30951585:30951821:1 gene:ENSG00000276152 gene_biotype:misc_RNA transcript_biotype:misc_RNA gene_symbol:Metazoa_SRP description:Metazoan signal recognition particle RNA [Source:RFAM;Acc:RF00017]. >grep ""ENST00000615101"" Homo_sapiens.GRCh38.87.gtf; > NA. Did you ever test salmon using ENSEMBL build?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/122#issuecomment-283461979:459,test,test,459,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/122#issuecomment-283461979,1,['test'],['test']
Testability,"Yes, this is a set of transcripts assembled using a few different Trinity and Velvet/Oases protocols, merged together. I'm testing reduction with different tools along with relative abundance estimation.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/54#issuecomment-204098008:123,test,testing,123,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/54#issuecomment-204098008,1,['test'],['testing']
Testability,"You can pull from this commit sha on develop to test the equivalent changes on that branch `bd7096e0fa055e0a71ab03a52d99977bcb61c905`. If this works, I think I'm pretty much good to go for the release. Just doing some last minute clean up and finishing up the release notes.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/70#issuecomment-239632891:48,test,test,48,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/70#issuecomment-239632891,1,['test'],['test']
Testability,You can see the added cmake file lint test case as allowed failures on Travis here.; It's good to see how the `cmakelint` works.; https://travis-ci.org/COMBINE-lab/salmon/builds/427929967,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/293#issuecomment-421432387:38,test,test,38,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/293#issuecomment-421432387,1,['test'],['test']
Testability,"You do not need a different transcriptome for each readset. Your general workflow should be... 1. prepare a transcriptome in fasta format; 2. For each sample, align that sample to the transcriptome to create a bam file using hisat2 and samtools; 3. For each bam file, run salmon quant using that bam file and the transcriptome as input; 4. merge output using salmon quantmerge; . ...I'm curious why you are using hisat2 though. Every benchmark I've seen suggests that just using salmons psuedo-mapper works just as well.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/740#issuecomment-1139144572:434,benchmark,benchmark,434,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/740#issuecomment-1139144572,1,['benchmark'],['benchmark']
Testability,"Yup, but I'm just trying to work backward. That is, first figure out what's going on with the `minEqWeight` error, and then figure out if that's related to what was causing it to hang. The issue right now is just that I can't seem to easily repro either Gibbs error. I just ran using the binary you compiled with the following command, and got this output:. ```; $LD_LIBRARY_PATH=~/SoftwareStaging/salmon/lib:$LD_LIBRARY_PATH ./salmon quant --index Salmon_index_hg38.analysisSet_knownGene --unmatedReads SRR2454059.fq.gz --libType ISF --us; eVBOpt --output test_quant --numGibbsSamples 100 --threads 16; Version Info: This is the most recent **development version** of Salmon.; ### salmon (mapping-based) v0.7.3; ### [ program ] => salmon; ### [ command ] => quant; ### [ index ] => { Salmon_index_hg38.analysisSet_knownGene }; ### [ unmatedReads ] => { SRR2454059.fq.gz }; ### [ libType ] => { ISF }; ### [ useVBOpt ] => { }; ### [ output ] => { test_quant }; ### [ numGibbsSamples ] => { 100 }; ### [ threads ] => { 16 }; Logs will be written to test_quant/logs; [2016-12-13 22:44:07.409] [jointLog] [info] parsing read library format; [2016-12-13 22:44:07.409] [jointLog] [info] There is 1 library.; [2016-12-13 22:44:09.318] [jointLog] [info] Loading Quasi index; [2016-12-13 22:44:09.318] [jointLog] [info] Loading 32-bit quasi index; [2016-12-13 22:44:09.318] [stderrLog] [info] Loading Suffix Array; [2016-12-13 22:44:15.002] [stderrLog] [info] Loading Transcript Info; [2016-12-13 22:44:16.278] [stderrLog] [info] Loading Rank-Select Bit Array; [2016-12-13 22:44:16.625] [stderrLog] [info] There were 182608 set bits in the bit array; [2016-12-13 22:44:16.680] [stderrLog] [info] Computing transcript lengths; [2016-12-13 22:44:16.681] [stderrLog] [info] Waiting to finish loading hash; [2016-12-13 22:44:20.485] [stderrLog] [info] Done loading index; [2016-12-13 22:44:20.485] [jointLog] [info] done; [2016-12-13 22:44:20.485] [jointLog] [info] Index contained 182608 targets. processed 19000",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-266935584:1024,Log,Logs,1024,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-266935584,2,"['Log', 'log']","['Logs', 'logs']"
Testability,"[ output ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10002_C29P7ACXX }; ) = 594; stat(""/etc/localtime"", {st_mode=S_IFREG|0644, st_size=3519, ...}) = 0; stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10002_C29P7ACXX"", {st_mode=S_IFDIR|S_ISGID|0755, st_size=33280, ...}) = 0; stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10002_C29P7ACXX"", {st_mode=S_IFDIR|S_ISGID|0755, st_size=33280, ...}) = 0; stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10002_C29P7ACXX/logs"", 0x7fffffff1e50) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10002_C29P7ACXX/logs"", 0x7fffffff1e60) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10002_C29P7ACXX"", {st_mode=S_IFDIR|S_ISGID|0755, st_size=33280, ...}) = 0; mkdir(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10002_C29P7ACXX/logs"", 0777) = 0; write(2, ""Logs will be written to "", 24Logs will be written to ) = 24; write(2, ""/dcl01/lieber/ajaffe/lab/libd_al""..., 81/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10002_C29P7ACXX/logs) = 81; write(2, ""\n"", 1; ) = 1; stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10002_C29P7ACXX/libParams"", 0x7fffffff1e50) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10002_C29P7ACXX/libParams"", 0x7fffffff1e60) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10002_C29P7ACXX"", {st_mode=S_IFDIR|S_ISGID|0755, st_size=33280, ...}) = 0; mkdir(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10002_C29P7ACXX/libParams"", 0777) = 0; stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10002_C29P7ACXX/aux_info"", 0x7fffffff1e50) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test1",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:67506,log,logs,67506,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,2,"['Log', 'log']","['Logs', 'logs']"
Testability,"[ output ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10001_D2B1WACXX }; ) = 594; stat(""/etc/localtime"", {st_mode=S_IFREG|0644, st_size=3519, ...}) = 0; stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10001_D2B1WACXX"", {st_mode=S_IFDIR|S_ISGID|0755, st_size=33280, ...}) = 0; stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10001_D2B1WACXX"", {st_mode=S_IFDIR|S_ISGID|0755, st_size=33280, ...}) = 0; stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10001_D2B1WACXX/logs"", 0x7fffffff1e50) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10001_D2B1WACXX/logs"", 0x7fffffff1e60) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10001_D2B1WACXX"", {st_mode=S_IFDIR|S_ISGID|0755, st_size=33280, ...}) = 0; mkdir(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10001_D2B1WACXX/logs"", 0777) = 0; write(2, ""Logs will be written to "", 24Logs will be written to ) = 24; write(2, ""/dcl01/lieber/ajaffe/lab/libd_al""..., 81/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10001_D2B1WACXX/logs) = 81; write(2, ""\n"", 1; ) = 1; stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10001_D2B1WACXX/libParams"", 0x7fffffff1e50) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10001_D2B1WACXX/libParams"", 0x7fffffff1e60) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10001_D2B1WACXX"", {st_mode=S_IFDIR|S_ISGID|0755, st_size=33280, ...}) = 0; mkdir(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10001_D2B1WACXX/libParams"", 0777) = 0; stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10001_D2B1WACXX/aux_info"", 0x7fffffff1e50) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test1",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:106088,log,logs,106088,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,2,"['Log', 'log']","['Logs', 'logs']"
Testability,"[SRR3212847.24133171] : proper-pair; mapped; matemapped; > ; > [2021-01-08 12:42:10.700] [jointLog] [warning] ; > ; > WARNING: Detected suspicious pair --- ; > The names are different:; > read1 : SRR3212847.33911054; > read2 : SRR3212847.30781941; > ; > Segmentation fault (core dumped); > ```; > ; > ### 3. Sorting with `samtools sort -n`; > ```; > samtools sort \; > -@ 40 \; > -n \; > -o SRR3212847.Aligned.SortedByName.bam \; > SRR3212847.Aligned.SortedByCoord.bam; > ; > salmon quant \; > -t mRNA.fasta \; > -p 20 \; > -l A \; > -a SRR3212847.Aligned.SortedByName.bam \; > -o SRR3212847.Aligned.SortedByName; > ```; > ; > ```; > Version Info: This is the most recent version of salmon.; > # salmon (alignment-based) v1.4.0; > # [ program ] => salmon ; > # [ command ] => quant ; > # [ targets ] => { mRNA.fasta }; > # [ threads ] => { 20 }; > # [ libType ] => { A }; > # [ alignments ] => { SRR3212847.Aligned.SortedByName.bam }; > # [ output ] => { SRR3212847.Aligned.SortedByName }; > Logs will be written to SRR3212847.Aligned.SortedByName/logs; > [2021-01-08 13:02:04.845] [jointLog] [info] setting maxHashResizeThreads to 20; > [2021-01-08 13:02:04.845] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; > Library format { type:paired end, relative orientation:inward, strandedness:unstranded }; > [2021-01-08 13:02:04.878] [jointLog] [info] numQuantThreads = 14; > parseThreads = 6; > Checking that provided alignment files have consistent headers . . . done; > Populating targets from aln = ""SRR3212847.Aligned.SortedByName.bam"", fasta = ""mRNA.fasta"" . . .done; > ; > processed 0 reads in current roundSegmentation fault (core dumped); > ```; > ; > (Which is the same as the 1st error. Actually, each time I re-run those two errors switched.); > ; > I tried running Salmon on the sorted-by-coordinates bam, and it didn't fail:; > ; > ```; > nohup salmon quant \; > -t mRNA.fasta \; > -p 20 \; > -l A \; > -a SRR3212847.Aligned.Sorte",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/582#issuecomment-1343749456:3811,Log,Logs,3811,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/582#issuecomment-1343749456,1,['Log'],['Logs']
Testability,"] [info] Finished optimizer; [2020-06-16 00:01:17.131] [jointLog] [info] writing output. ```. So, you can note that the number of mappings discarded because of alignment; score is still quite big (134M) and, indeed, this took longer than I would; normally expect for; a sample with ~30M reads. However, it is _massively_ smaller (~116 times); than the 15.6B in your run. Thus, it may have been the same issue as in; the other GitHub issue. You can try the pre-compiled linux binary I linked; there if you have access to a linux machine to test on. By the way, the; issue there was a bunch of reads plagued by super-repetitive homopolymer; segments, I haven't looked at these reads yet for evidence of that though. On Mon, Jun 15, 2020 at 11:09 PM shalercr <notifications@github.com> wrote:. >; >; >; >; >; > Hi Rob,; >; >; > Thanks for the quick response. The other computer was OSX, should I try a; > linux machine?; >; >; > Here are some dropbox links to two of the files. I believe this is the set; > for the logs I posted.; >; >; > https://www.dropbox.com/s/8c3p9hmgmadgj89/31_1.trimmed.fastq.gz?dl=0; >; >; > https://www.dropbox.com/s/2y9jfvaphe9h21x/31_2.trimmed.fastq.gz?dl=0; >; >; >; >; > Thanks,; >; >; > Ryan; >; >; >; >; >; > On Jun 15, 2020, at 9:32 PM, Rob Patro <notifications@github.com> wrote:; >; >; >; >; > Thank you for the report. Can you share one of the samples where you see; > this issue? Also, out of curiosity, was the other machine you tried on also; > OSX, or was it a linux machine?; > —; > You are receiving this because you authored the thread.; > Reply to this email directly,; > view it on GitHub, or; > unsubscribe.; >; > —; > You are receiving this because you commented.; > Reply to this email directly, view it on GitHub; > <https://github.com/COMBINE-lab/salmon/issues/537#issuecomment-644504783>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AACYH7UHOYB7KYKDASFB5RDRW3O7HANCNFSM4N7EOYSQ>; > .; >; —; You are receiving this because yo",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/537#issuecomment-644527727:5482,log,logs,5482,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/537#issuecomment-644527727,1,['log'],['logs']
Testability,"_URL=https://api.github.com/repos/COMBINE-lab/salmon/releases/latest; VERSION=$(curl -s $GITHUB_URL | \; grep '""tag_name"":' | \; cut -d : -f 2,3 | \; tr -d \"",v | \; xargs); LATEST_RELEASE=$(curl -s $GITHUB_URL | \; grep '""tarball_url""' | \; cut -d : -f 2,3 | \; tr -d \"", | \; xargs); module load gcc/7.4.0 cmake/3.15.1 boost/1.70.0-gcc libiconv/1.16; export CC=`which gcc`; export CXX=`which c++`. cd $MODULE_HOME; mkdir -p source/$PACKAGE_NAME/$VERSION; INSTALL_DIR=$MODULE_HOME/modules/$PACKAGE_NAME/$VERSION; mkdir -p $INSTALL_DIR; mkdir -p modfiles/$PACKAGE_NAME. cd source/$PACKAGE_NAME/$VERSION; wget $LATEST_RELEASE -O - | tar -xz --strip-components 1; cmake -DBOOST_ROOT=/global/software/sl-7.x86_64/modules/gcc/7.4.0/boost/1.70.0-gcc -DCMAKE_INSTALL_PREFIX=$INSTALL_DIR; make; ```; And the tail of the output from make:. ```; creating: /clusterfs/vector/home/groups/software/sl-7.x86_64/source/salmon/1.5.1/scripts/../external/pufferfish-salmon-v1.5.1/tests/compile_tests/; inflating: /clusterfs/vector/home/groups/software/sl-7.x86_64/source/salmon/1.5.1/scripts/../external/pufferfish-salmon-v1.5.1/tests/compile_tests/int128_numeric_limits.cpp ; -- fetch PUFFERFISH exit code 0; -- Found ZLIB: /usr/lib64/libz.so (found version ""1.2.11"") ; -- Performing Test Iconv_IS_BUILT_IN; -- Performing Test Iconv_IS_BUILT_IN - Failed; CMake Error at /global/home/groups/consultsw/sl-7.x86_64/modules/cmake/3.15.1/share/cmake-3.15/Modules/FindPackageHandleStandardArgs.cmake:137 (message):; Could NOT find Iconv (missing: Iconv_LIBRARY); Call Stack (most recent call first):; /global/home/groups/consultsw/sl-7.x86_64/modules/cmake/3.15.1/share/cmake-3.15/Modules/FindPackageHandleStandardArgs.cmake:378 (_FPHSA_FAILURE_MESSAGE); /global/home/groups/consultsw/sl-7.x86_64/modules/cmake/3.15.1/share/cmake-3.15/Modules/FindIconv.cmake:120 (find_package_handle_standard_args); CMakeLists.txt:362 (find_package). -- Configuring incomplete, errors occurred!; See also ""/clusterfs/vector/home/groups/sof",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/453#issuecomment-862737315:1474,test,tests,1474,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/453#issuecomment-862737315,2,['test'],['tests']
Testability,"_lane-002-chunk-000.fastq.gz; ./fastq/fastqs/flowcell1/read-I1_si-CGAAGTTG_lane-003-chunk-003.fastq.gz; ./fastq/fastqs/flowcell1/read-I1_si-CGAAGTTG_lane-004-chunk-002.fastq.gz; ./fastq/fastqs/flowcell1/read-I1_si-GAGCACGC_lane-001-chunk-001.fastq.gz; ./fastq/fastqs/flowcell1/read-I1_si-GAGCACGC_lane-002-chunk-000.fastq.gz; ./fastq/fastqs/flowcell1/read-I1_si-GAGCACGC_lane-003-chunk-003.fastq.gz; ./fastq/fastqs/flowcell1/read-I1_si-GAGCACGC_lane-004-chunk-002.fastq.gz; ./fastq/fastqs/flowcell1/read-I1_si-TTCGTGAA_lane-001-chunk-001.fastq.gz; ./fastq/fastqs/flowcell1/read-I1_si-TTCGTGAA_lane-002-chunk-000.fastq.gz; ./fastq/fastqs/flowcell1/read-I1_si-TTCGTGAA_lane-003-chunk-003.fastq.gz; ./fastq/fastqs/flowcell1/read-I1_si-TTCGTGAA_lane-004-chunk-002.fastq.gz]; Version Info: This is the most recent version of salmon.; [2018-12-06 11:14:56.513] [alevinLog] [info] A custom protocol (END, BC length, UMI length) = (5, 14, 5) is being used. Updating UMI k-mer length accordingly.; Logs will be written to ./fastq/test/logs; [2018-12-06 11:14:56.533] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; ### alevin (dscRNA-seq quantification) v0.12.0; ### [ program ] => salmon ; ### [ command ] => alevin ; ### [ libType ] => { ISR }; ### [ gemcode ] => { }; ### [ index ] => { ./transcripts_index_salmon/ }; ### [ threads ] => { 8 }; ### [ output ] => { ./fastq/test/ }; ### [ tgMap ] => { ./hg_transcriptome/tx2tx.tsv }; ### [ end ] => { 5 }; ### [ umiLength ] => { 5 }; ### [ barcodeLength ] => { 14 }; ### [ dumpCsvCounts ] => { }; ### [ mates1 ] => { /tmp/tmp.p28w2nGvAn/p1.fa }; ### [ mates2 ] => { /tmp/tmp.p28w2nGvAn/p2.fa }; ### [ unmatedReads ] => { ./fastq/fastqs/flowcell1/read-I1_si-ACTTCACT_lane-001-chunk-001.fastq.gz ./fastq/fastqs/flowcell1/read-I1_si-ACTTCACT_lane-002-chunk-000.fastq.gz ./fastq/fastqs/flowcell1/read-I1_si-ACTTCACT_lane-003-chunk-003.fastq.gz ./fastq/fastqs/flowcell1/read-I1_si-ACTTCACT_lane-004-chunk-",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/328#issuecomment-445008548:2152,Log,Logs,2152,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/328#issuecomment-445008548,1,['Log'],['Logs']
Testability,"```; /usr/bin/ld: cannot find -lpthreads; ```; That's normal. Cmake is probing to determine the name of the pthreads library on this system, and it's named `-lpthread` not `-lpthreads`, so this test fails, and is expected to fail.; ```; ❯❯❯ ls /usr/lib/x86_64-linux-gnu/libpthread.so; /usr/lib/x86_64-linux-gnu/libpthread.so; ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/181#issuecomment-367796621:194,test,test,194,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/181#issuecomment-367796621,1,['test'],['test']
Testability,"```; > ; > ```; > Version Info: This is the most recent version of salmon.; > # salmon (alignment-based) v1.4.0; > # [ program ] => salmon ; > # [ command ] => quant ; > # [ targets ] => { mRNA.fasta }; > # [ threads ] => { 20 }; > # [ libType ] => { A }; > # [ alignments ] => { SRR3212847.Aligned.SortedByName.bam }; > # [ output ] => { SRR3212847.Aligned.SortedByName }; > Logs will be written to SRR3212847.Aligned.SortedByName/logs; > [2021-01-08 13:02:04.845] [jointLog] [info] setting maxHashResizeThreads to 20; > [2021-01-08 13:02:04.845] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; > Library format { type:paired end, relative orientation:inward, strandedness:unstranded }; > [2021-01-08 13:02:04.878] [jointLog] [info] numQuantThreads = 14; > parseThreads = 6; > Checking that provided alignment files have consistent headers . . . done; > Populating targets from aln = ""SRR3212847.Aligned.SortedByName.bam"", fasta = ""mRNA.fasta"" . . .done; > ; > processed 0 reads in current roundSegmentation fault (core dumped); > ```; > ; > (Which is the same as the 1st error. Actually, each time I re-run those two errors switched.); > ; > I tried running Salmon on the sorted-by-coordinates bam, and it didn't fail:; > ; > ```; > nohup salmon quant \; > -t mRNA.fasta \; > -p 20 \; > -l A \; > -a SRR3212847.Aligned.SortedByCoord.bam \; > -o SRR3212847.Aligned.SortedByCoord \; > > SRR3212847.Aligned.SortedByCoord.out &; > ```; > ; > Even so, `SRR3212847.Aligned.SortedByCoord.out` contained ~3.5GB worth of the warnings above.; > ; > Any help would be much appreciated. Thanks!. hello,i have the same problem,thanks for your answer. Your SRR3212847.Aligned.SortedByCoord.out contained ~3.5GB worth of the warnings above, What is the warning message? And in my log file,the warning as follow:. ![image](https://user-images.githubusercontent.com/45484925/206608510-b5cc88bd-18ac-42eb-bfa1-a5be862b0873.png); Can i ignore these warnings?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/582#issuecomment-1343749456:5261,log,log,5261,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/582#issuecomment-1343749456,1,['log'],['log']
Testability,"```; You passed paired-end files; to salmon, but you passed 12 files to --mates1 and 13 files to --mates2.; You must pass the same number of files to both flags; ```. Is this true ? Can you share the log ?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/408#issuecomment-516185511:200,log,log,200,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/408#issuecomment-516185511,1,['log'],['log']
Testability,"a from the repository. Note, this SAM file is zipped (GitHub made me zip it before attaching it, so unzip it before you process it):. [sample_alignments.sam.zip](https://github.com/COMBINE-lab/salmon/files/4510467/sample_alignments.sam.zip). Once you've unzipped this file, you can run salmon as:. ```~bash; ./bin/salmon quant -l IU -t transcripts.fa -a sample_alignments.sam -o quant_directory; ```. where the `transcripts.fa` is the sample transcriptome distributed with salmon that you can get by unzipping this file : [transcripts.fasta.zip](https://github.com/COMBINE-lab/salmon/files/4510488/transcripts.fasta.zip). When I run this with the latest salmon, I get the following output:. ```; # salmon (alignment-based) v1.2.0; # [ program ] => salmon; # [ command ] => quant; # [ libType ] => { IU }; # [ alignments ] => { sample_alignments.sam }; # [ targets ] => { ../sample_data/transcripts.fasta }; # [ output ] => { sample_aln_quant }; Logs will be written to sample_aln_quant/logs; Library format { type:paired end, relative orientation:inward, strandedness:unstranded }; [2020-04-21 10:11:42.553] [jointLog] [info] setting maxHashResizeThreads to 8; [2020-04-21 10:11:42.553] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2020-04-21 10:11:42.553] [jointLog] [info] numQuantThreads = 4; parseThreads = 4; Checking that provided alignment files have consistent headers . . . done; Populating targets from aln = ""sample_alignments.sam"", fasta = ""../sample_data/transcripts.fasta"" . . .done; [2020-04-21 10:11:43.180] [jointLog] [info] replaced 0 non-ACGT nucleotides with random nucleotides. processed 0 reads in current round; killing thread 3 . . . done. Freeing memory used by read queue . . . 00; Joined parsing thread . . . ""sample_alignments.sam""; Closed all files . . .; Emptied frag queue. . . [2020-04-21 10:11:43.477] [jointLog] [info]. Completed first pass through the alignment file.; Total # of mapped reads : 10000; #",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/511#issuecomment-617206094:1120,Log,Logs,1120,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/511#issuecomment-617206094,2,"['Log', 'log']","['Logs', 'logs']"
Testability,"aco/twopaco-targets.cmake; -- Installing: /salmon/lib/twopaco/twopaco-targets-release.cmake; -- Installing: /salmon/lib/libtbb.so; -- Installing: /salmon/lib/libtbb.so.12; -- Installing: /salmon/lib/libtbb.so.12.5; -- Installing: /salmon/lib/libtbbmalloc.so; -- Installing: /salmon/lib/libtbbmalloc.so.2; -- Installing: /salmon/lib/libtbbmalloc.so.2.5; -- Installing: /salmon/lib/libtbbmalloc_proxy.so; -- Installing: /salmon/lib/libtbbmalloc_proxy.so.2; -- Installing: /salmon/lib/libtbbmalloc_proxy.so.2.5; -- Installing: /salmon/bin/salmon; -- Installing: /salmon/lib/libsalmon_core.a. Installation complete. Please ensure the following paths are set properly.; ==========================================================================; Please add /salmon/bin to your PATH; Please add /salmon/lib to your LD_LIBRARY_PATH; ==========================================================================; root@fd877e359439:/salmon/build# make test; Running tests...; Test project /salmon/build; Start 1: unit_tests; 1/2 Test #1: unit_tests ....................... Passed 0.37 sec; Start 2: salmon_read_test_quasi; 2/2 Test #2: salmon_read_test_quasi ........... Passed 1.80 sec. 100% tests passed, 0 tests failed out of 2. Total Test time (real) = 2.17 sec; ```. The `make test` command itself runs the test the builds the index and maps the reads against it. Either way, I can do that explicitly too (from within build):. ```; $ ./src/salmon index -t ../sample_data/transcripts.fasta -i sample_idx; ```. returns succesfully with a built index. ```; ...; [2023-03-10 05:51:33.748] [puff::index::jointLog] [info] Done wrapping the rank vector with a rank9sel structure.; [2023-03-10 05:51:33.748] [puff::index::jointLog] [info] contig count for validation: 23; [2023-03-10 05:51:33.748] [puff::index::jointLog] [info] Total # of Contigs : 23; [2023-03-10 05:51:33.748] [puff::index::jointLog] [info] Total # of numerical Contigs : 23; [2023-03-10 05:51:33.748] [puff::index::jointLog] [info] Total # of c",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463312554:2711,Test,Test,2711,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463312554,2,['Test'],['Test']
Testability,"al # of Contigs : 23; [2023-03-10 05:51:33.748] [puff::index::jointLog] [info] Total # of numerical Contigs : 23; [2023-03-10 05:51:33.748] [puff::index::jointLog] [info] Total # of contig vec entries: 36; [2023-03-10 05:51:33.748] [puff::index::jointLog] [info] bits per offset entry 6; [2023-03-10 05:51:33.748] [puff::index::jointLog] [info] Done constructing the contig vector. 24; [2023-03-10 05:51:33.748] [puff::index::jointLog] [info] # segments = 23; [2023-03-10 05:51:33.748] [puff::index::jointLog] [info] total length = 19592; [2023-03-10 05:51:33.748] [puff::index::jointLog] [info] Reading the reference files ...; [2023-03-10 05:51:33.750] [puff::index::jointLog] [info] positional integer width = 15; [2023-03-10 05:51:33.750] [puff::index::jointLog] [info] seqSize = 19592; [2023-03-10 05:51:33.750] [puff::index::jointLog] [info] rankSize = 19592; [2023-03-10 05:51:33.750] [puff::index::jointLog] [info] edgeVecSize = 0; [2023-03-10 05:51:33.750] [puff::index::jointLog] [info] num keys = 18902; for info, total work write each : 2.331 total work inram from level 3 : 4.322 total work raw : 25.000; [Building BooPHF] 100 % elapsed: 0 min 0 sec remaining: 0 min 0 sec; Bitarray 105024 bits (100.00 %) (array + ranks ); final hash 0 bits (0.00 %) (nb in final hash 0); [2023-03-10 05:51:33.781] [puff::index::jointLog] [info] mphf size = 0.0125198 MB; [2023-03-10 05:51:33.781] [puff::index::jointLog] [info] chunk size = 9796; [2023-03-10 05:51:33.781] [puff::index::jointLog] [info] chunk 0 = [0, 9796); [2023-03-10 05:51:33.781] [puff::index::jointLog] [info] chunk 1 = [9796, 19562); [2023-03-10 05:51:33.784] [puff::index::jointLog] [info] finished populating pos vector; [2023-03-10 05:51:33.784] [puff::index::jointLog] [info] writing index components; [2023-03-10 05:51:33.784] [puff::index::jointLog] [info] finished writing dense pufferfish index; [2023-03-10 05:51:33.784] [jLog] [info] done building index; ```. So on `testing` at least, I can't yet reproduce this issue.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463312554:5512,test,testing,5512,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463312554,1,['test'],['testing']
Testability,"alevinLog] [info] parsing read library format; > [2020-06-04 17:57:36.339] [alevinLog] [info] Starting optimizer; > ; > ; > [2020-06-04 17:57:37.051] [alevinLog] [warning] mrna file not provided; using is 1 less feature for whitelisting; > [2020-06-04 17:57:37.051] [alevinLog] [warning] rrna file not provided; using is 1 less feature for whitelisting; > [2020-06-04 17:57:37.338] [alevinLog] [info] Total 23937.00 UMI after deduplicating.; > [2020-06-04 17:57:37.338] [alevinLog] [info] Total 91 BiDirected Edges.; > [2020-06-04 17:57:37.338] [alevinLog] [info] Total 82 UniDirected Edges.; > [2020-06-04 17:57:37.338] [alevinLog] [warning] Skipped 82268 barcodes due to No mapped read; > [2020-06-04 17:57:37.341] [alevinLog] [info] Clearing EqMap; Might take some time.; > [2020-06-04 17:57:37.348] [alevinLog] [warning] Num Low confidence barcodes too less 1 < 10.Can't performing whitelisting; Skipping; > [2020-06-04 17:57:37.348] [alevinLog] [info] Finished optimizer; > ; > . salmon_quant.log. > [2020-06-04 17:55:11.700] [jointLog] [info] setting maxHashResizeThreads to 7; > [2020-06-04 17:55:11.700] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; > [2020-06-04 17:55:11.700] [jointLog] [info] The --mimicBT2, --mimicStrictBT2 and --hardFilter flags imply mapping validation (--validateMappings). Enabling mapping validation.; > [2020-06-04 17:55:11.700] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; > [2020-06-04 17:55:11.700] [jointLog] [info] The use of range-factorized equivalence classes does not make sense in conjunction with --hardFilter. Disabling range-factorized equivalence classes. ; > [2020-06-04 17:55:11.700] [jointLog] [info] Usage of --validateMappings implies a default consensus slack of 0.2. Setting consensusSlack to 0.35.; > [2020-06-04 17:55:11.700] [jointLog] [info] Using default value of 0.797619 for minScoreF",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-639196415:2691,log,log,2691,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-639196415,1,['log'],['log']
Testability,"alevinLog] [info] parsing read library format; [2019-06-06 19:24:55.716] [jointLog] [info] There is 1 library.; [2019-06-06 19:24:55.889] [jointLog] [info] Loading Quasi index; [2019-06-06 19:24:55.889] [jointLog] [info] Loading 32-bit quasi index; [2019-06-06 19:24:55.890] [stderrLog] [info] Loading Suffix Array ; [2019-06-06 19:24:56.791] [stderrLog] [info] Loading Transcript Info ; [2019-06-06 19:24:57.025] [stderrLog] [info] Loading Rank-Select Bit Array; [2019-06-06 19:24:57.061] [stderrLog] [info] There were 136,011 set bits in the bit array; [2019-06-06 19:24:57.084] [stderrLog] [info] Computing transcript lengths; [2019-06-06 19:24:57.084] [stderrLog] [info] Waiting to finish loading hash; [2019-06-06 19:25:06.552] [jointLog] [info] done; [2019-06-06 19:25:06.552] [jointLog] [info] Index contained 136,011 targets; [2019-06-06 19:25:06.552] [stderrLog] [info] Done loading index; [2019-06-06 19:25:06.728] [alevinLog] [error] Barcode not found in frequency table; ```. Salmon Quant log is this. ```; [2019-06-06 19:23:29.519] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2019-06-06 19:23:29.519] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2019-06-06 19:23:29.520] [jointLog] [info] Usage of --validateMappings, without --hardFilter implies use of range factorization. rangeFactorizationBins is being set to 4; [2019-06-06 19:23:29.520] [jointLog] [info] Usage of --validateMappings implies a default consensus slack of 0.2. Setting consensusSlack to 0.2.; [2019-06-06 19:23:29.520] [jointLog] [info] Using default value of 0.87 for minScoreFraction in Alevin; Using default value of 0.6 for consensusSlack in Alevin; [2019-06-06 19:24:55.716] [jointLog] [info] There is 1 library.; [2019-06-06 19:24:55.889] [jointLog] [info] Loading Quasi index; [2019-06-06 19:24:55.889] [jointLog] [info] Loading 32-bit quasi index; [2019",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/369#issuecomment-499592790:2145,log,log,2145,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/369#issuecomment-499592790,1,['log'],['log']
Testability,"alloc tbbmalloc_proxy; TBB_LIBRARIES = /apps/gentoo/usr/lib/libtbbmalloc_proxy.so;/apps/gentoo/usr/lib/libtbbmalloc.so;/apps/gentoo/usr/lib/libtbb.so; Build system will compile libgff; ==================================================================; ==================================================================; Build system will compile Staden IOLib; ==================================================================; Build system will fetch SPDLOG; ==================================================================; -- Found PkgConfig: /apps/gentoo/usr/bin/pkg-config (found version ""0.29.2""); -- Found Jemalloc: /apps/gentoo/usr/lib/libjemalloc.so (found version """"); Found Jemalloc library --- using this memory allocator; CPACK_SOURCE_IGNORE_FILES = /src/PCA.cpp;/src/PCAUtils.cpp;/build/;/scripts/AggregateToGeneLevel.py;/scripts/ExpressionTools.py;/scripts/GenerateExpressionFiles.sh;/scripts/ParseSoftFile.py;/scripts/PlotCorrelation.py;/scripts/junk;/scripts/sfstrace.log;/scripts/SFPipeline.py;/bin/;/lib/;/sample_data/;PublishREADMEToWebsite.sh;/external/;/src/obsolete/;/include/obsolete/;WebsiteHeader.txt;/experimental_configs/;.git/; TBB_LIBRARIES = /apps/gentoo/usr/lib/libtbbmalloc_proxy.so;/apps/gentoo/usr/lib/libtbbmalloc.so;/apps/gentoo/usr/lib/libtbb.so; -- Configuring done; CMake Error at src/CMakeLists.txt:158 (add_executable):; Cannot find source file:. $blah/salmon-0.10.2/external/install/src/rapmap/RapMapFileSystem.cpp. Tried extensions .c .C .c++ .cc .cpp .cxx .cu .m .M .mm .h .hh .h++ .hm; .hpp .hxx .in .txx. CMake Error at src/CMakeLists.txt:160 (add_executable):; Cannot find source file:. $blah/salmon-0.10.2/external/install/src/rapmap/rank9b.cpp. Tried extensions .c .C .c++ .cc .cpp .cxx .cu .m .M .mm .h .hh .h++ .hm; .hpp .hxx .in .txx. CMake Error at src/CMakeLists.txt:158 (add_executable):; No SOURCES given to target: salmon. CMake Error at src/CMakeLists.txt:160 (add_executable):; No SOURCES given to target: unitTests. -- Build files have ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/19#issuecomment-399775387:4606,log,log,4606,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/19#issuecomment-399775387,1,['log'],['log']
Testability,"almon-0.13.1/build && /usr/local/Cellar/cmake/3.13.4/bin/cmake -E cmake_depends ""Unix Makefiles"" /Users/gabriel/Projects/salmon-0.13.1 /Users/gabriel/Projects/salmon-0.13.1 /Users/gabriel/Projects/salmon-0.13.1/build /Users/gabriel/Projects/salmon-0.13.1/build /Users/gabriel/Projects/salmon-0.13.1/build/CMakeFiles/libstadenio.dir/DependInfo.cmake --color=; /Applications/Xcode.app/Contents/Developer/usr/bin/make -f CMakeFiles/libstadenio.dir/build.make CMakeFiles/libstadenio.dir/build; [ 9%] Performing configure step for 'libstadenio'; cd /Users/gabriel/Projects/salmon-0.13.1/external/staden-io_lib && ./configure --enable-shared=no --without-libcurl --prefix=/Users/gabriel/Projects/salmon-0.13.1/external/install LDFLAGS= CFLAGS= CC=/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/cc CXX=/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/c++; checking for a BSD-compatible install... /usr/local/bin/ginstall -c; checking whether build environment is sane... yes; checking for a thread-safe mkdir -p... /usr/local/bin/gmkdir -p; checking for gawk... gawk; checking whether make sets $(MAKE)... yes; checking whether make supports nested variables... yes; checking whether to enable maintainer-specific portions of Makefiles... no; checking for gcc... /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/cc; checking whether the C compiler works... yes; checking for C compiler default output file name... a.out; checking for suffix of executables...; checking whether we are cross compiling... configure: error: in `/Users/gabriel/Projects/salmon-0.13.1/external/staden-io_lib':; configure: error: cannot run C compiled programs.; If you meant to cross compile, use `--host'.; See `config.log' for more details; make[2]: *** [libstadenio-prefix/src/libstadenio-stamp/libstadenio-configure] Error 1; make[1]: *** [CMakeFiles/libstadenio.dir/all] Error 2; make: *** [all] Error 2; ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/348#issuecomment-472500713:3253,log,log,3253,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/348#issuecomment-472500713,1,['log'],['log']
Testability,"and for the detailed report! This is an interesting observation. The most likely reason you are seeing this behavior is that the fast mapping algorithms are, in a sense, quite greedy in how they attempt to map reads. This can lead them to suffer with compared to more traditional alignment algorithms like Bowtie2 and BWA-MEM with respect to both sensitivity and specificity. Here, you are likely seeing a manifestation of the former. Specifically, greedy behavior can lead to spurious matches. Many of these spurious matches are filtered out when applying a consensus mechanism to the series of matches produced by a read; however, this can result in the read going unmapped. We have noticed this behavior where spurious matches can ""mask"" better overall mappings, and we have developed an algorithm to overcome these limitations (called selective-alignment). This is currently implemented in [this branch](https://github.com/COMBINE-lab/salmon/tree/rescue-orphan) of the Salmon repo (if you want to test it out and have trouble building, we can build you a linux executable). This algorithm explores more potential mappings and then applies a fast algorithm for filtering potentially poor ones. In our benchmarks, it exhibits sensitivity and specificity very close to Bowtie2 (which is among the best of the alignment-based methods we considered). Also, I will note that, though the speed and statistical optimization procedures used in fast transcript abundance estimation tools make them a potentially desirable choice for microbiomic / metagenomic abundance estimation, their indices are typically optimized for speed and not size. For small numbers of bacterial species this can be okay, but if one wishes to index large collections of species, the memory usage can become a problem. To this end, we have developed a new indexing scheme (software [here](https://github.com/COMBINE-lab/pufferfish), slightly out-of-date pre-print [here](https://www.biorxiv.org/content/early/2017/09/21/191874)).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/196#issuecomment-365337297:1041,test,test,1041,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/196#issuecomment-365337297,1,['test'],['test']
Testability,"ap to a decoy, and is not used for the purposes of quantification. Consistent with the behavior I hypothesized above for STAR, if you have many softclipped bases at the end of the read that nonetheless match what is in the genome downstream of the end of the annotated transcript, you'll likely see these reads assigned as decoys. To check this, you can look at salmon's `meta_info.json` output file to see how many reads were mapped best to decoys. * Why do I see much higher counts for this gene with FeatureCounts?. * It depends on the specific behavior you invoke. However, my guess is that FeatureCounts is being run with flags such that reads that only somewhat overlap a feature are nonetheless assigned to it. This suggests that while no good alignment may actually exist to the annotated transcript, FeatureCounts is still assigning the read to that feature because it overlaps it to some degree and matches the corresponding location on the genome. Again, you can test this by changing the required overlap fraction of FeatureCounts. * Why does running salmon outside of nf-core produce much higher counts?. * Since you are indexing *just* the transcriptome, and not including the genome as decoy sequence (as is done in nf-core), then the only thing that will prevent reads from being assigned to the gene in question is if so much of the read overhangs off the end of the annotated transcript that no mapping matches the minimum required alignment score. This is likely to be a much more liberal threshold than what STAR allows, so it also explains why you see higher counts than when alignment mode is used. * Other thoughts / suggestions?. * So, there are several things that you might consider doing if you believe the correct behavior in your case is to assign these reads to such genes. First, when run in mapping mode, salmon has a `--softclipOverhangs` flag that will further reduce the penalty for reads overhanging the annotated end of a transcript. This will allow more reads to ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/798#issuecomment-1237133883:2627,test,test,2627,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/798#issuecomment-1237133883,1,['test'],['test']
Testability,"appings that result when one considers only the transcriptome as a source of mapping. There are a number of ways to proceed on this front, but this is a good place to first check for discrepancy (and the paper gives a good overview of the relative tradeoffs and merits of different alignment approaches). * Salmon and RSEM use related but distinct optimization algorithms by default. RSEM uses the EM algorithm, and salmon uses the variational Bayesian EM algorithm. The latter tends to induce more sparse solutions. This is simply because they are optimizing slightly different objectives. It is very difficult to say in general if one is ""better"" than the other in a blanket way, but [there is previous literature to support that the VBEM may be more accurate](https://academic.oup.com/bioinformatics/article/29/18/2292/239795). However, while RSEM only implements the EM algorithm, salmon actually implements and provides a switch to use either. So, if you want to test the effect of this difference, you can run salmon with the `--useEM` algorithm. This will tell salmon to use the ""classic"" EM algorithm and will eliminate this source of variation. * As with the other question you asked, there may be a _small_ discrepancy depending on when enforcement of a stranded library kicks in under salmon's `A` library type. You can eliminate that variable by simply providing `-l SF` to match the library type being used with RSEM. * Coming back to the `IndelSoftclipSingleend` parameter I mentioned in the first point; RSEM disallows indels in the alignments that it quantifies. This means that to produce RSEM-compatible input, STAR must not align reads that contain indels. While this won't generally have a big effect for many transcripts, it can certainly affect the abundance estimates for transcripts in your sample where the sample you are quantifying has (indel) variation with respect to the reference annotation. We touch upon that a bit as well in the [paper I mentioned above](https://gen",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/612#issuecomment-758004590:3282,test,test,3282,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/612#issuecomment-758004590,2,['test'],['test']
Testability,"are always about 50% percent reads has been thrown away, and the mapping rate was between 18.7%-19.1%. . the salmon version is `salmon 1.4.0`; the reference genome is sequenced by ourselves, and it's a plant.; my reads layout is paired end 150bp, . > R1: ; @A00582:424:HJYLGDSXY:3:1101:1090:1000 1:N:0:ACCGGCTC; TAACCAGGTCGAGTGAGTATTTAAGGCGCGCGGCGCACCAACGCACTCCCAACAACAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA; > +; FFFFFFFFFFFFFFFFFFFFFFFFFFFF,,:,,FF:,,,::FF,,:F,,,,,,F:,,,:,::FF::::::,FFF:F:FF:FFFFFFF::FF::FF,F:F:FF:F,FFFF,:FF,FFFFF:,FF:::FF:FFF:FF:FF:FFFFFFFFFF:; > R2:; @A00582:424:HJYLGDSXY:3:1101:1090:1000 2:N:0:ACCGGCTC; NCCTAGAAGCAGCCACCCTTGAAAGAGTGCGTAATAGCTCACTGATCGAGCGCTCTTGCGCCGAAGATGAACGGGGCTAAGCGATCTGCCGAAGCTGTGGGATGTAAAAATACATCGGTAGGGGAGCGTTCCGCCTTAGAGAGAAGCCTC; > +; #FF:FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF:FFFFFFFFFFFFFFFFFFFFFFFFFFF:FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF:FFFFFFFFFFFF::FFFFFFFFFF:FFFFFFFFFFFFF:FFFFFF:FFFFFFF:. Here is the logs. ## Default setting ; `salmon alevin -l ISR -1 ../clean/sample_S1_L001_R1_001.fastq -2 ../clean/sample_S1_L001_R2_001.fastq --chromiumV3 -i ../../dna/00.ref_genome/sample/salmon_index_allmRNA -p 40 -o test_alevin_allmRNA --tgMap ../../dna/00.ref_genome/sample/alltxp2gene.tsv`. > [2021-01-25 16:22:09.565] [alevinLog] [info] Found 43030 transcripts(+0 decoys, +0 short and +0 duplicate names in the index); [2021-01-25 16:22:09.615] [alevinLog] [info] Filled with 43030 txp to gene entries; [2021-01-25 16:22:09.620] [alevinLog] [info] Found all transcripts to gene mappings; [2021-01-25 16:22:09.631] [alevinLog] [info] Processing barcodes files (if Present); [2021-01-25 16:26:35.067] [alevinLog] [info] Done barcode density calculation.; [2021-01-25 16:26:35.067] [alevinLog] [info] # Barcodes Used: 188934609 / 188934609.; [2021-01-25 16:26:42.979] [alevinLog] [info] Knee found left boundary at 21; [2021-01-25 16:27:05.707] [alevinLog] [warning] Gauss Prediction 4969 Too far from knee",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/340#issuecomment-766311567:1377,log,logs,1377,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/340#issuecomment-766311567,1,['log'],['logs']
Testability,"arget salmon_core; [ 77%] Built target unitTests; [100%] Built target salmon; Install the project...; -- Install configuration: ""Release""; -- Installing: /salmon-0.10.2/lib; -- Installing: /salmon-0.10.2/lib/libtbb.so; -- Installing: /salmon-0.10.2/lib/libtbbmalloc.so; -- Installing: /salmon-0.10.2/lib/libtbbmalloc_proxy.so; -- Installing: /salmon-0.10.2/lib/libtbbmalloc.so.2; -- Installing: /salmon-0.10.2/lib/libtbb.so.2; -- Installing: /salmon-0.10.2/lib/pkgconfig; -- Installing: /salmon-0.10.2/lib/libtbbmalloc_proxy.so.2; -- Installing: /salmon-0.10.2/bin/salmon; -- Installing: /salmon-0.10.2/lib/libsalmon_core.a. Installation complete. Please ensure the following paths are set properly.; ==========================================================================; Please add /salmon-0.10.2/bin to your PATH; Please add /salmon-0.10.2/lib to your LD_LIBRARY_PATH; ==========================================================================; root@e08cc9670e4a:/salmon-0.10.2/build# make test; Running tests...; Test project /salmon-0.10.2/build; Start 1: unit_tests; 1/3 Test #1: unit_tests ....................... Passed 0.17 sec; Start 2: salmon_read_test_fmd; 2/3 Test #2: salmon_read_test_fmd ............. Passed 1.78 sec; Start 3: salmon_read_test_quasi; 3/3 Test #3: salmon_read_test_quasi ........... Passed 1.59 sec. 100% tests passed, 0 tests failed out of 3. Total Test time (real) = 3.54 sec; root@e08cc9670e4a:/salmon-0.10.2/build# lsb_release -a; LSB Version: core-9.20160110ubuntu0.2-amd64:core-9.20160110ubuntu0.2-noarch:security-9.20160110ubuntu0.2-amd64:security-9.20160110ubuntu0.2-noarch; Distributor ID: Ubuntu; Description: Ubuntu 16.04.4 LTS; Release: 16.04; Codename: xenial; ```. I built with:. `$ cmake -DFETCH_BOOST=TRUE .. && make install && make test`. I can also install the boost via apt and see if that makes a difference (though I expect not since it looked like TBB was the issue, and I let cmake install that). We can also check our compiler versions, per",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/250#issuecomment-404306268:1863,test,test,1863,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/250#issuecomment-404306268,2,['test'],"['test', 'tests']"
Testability,"aseII; #$ -m e; echo ""**** Job starts ****""; date. echo ""**** JHPCE info ****""; echo ""User: ${USER}""; echo ""Job id: ${JOB_ID}""; echo ""Job name: ${JOB_NAME}""; echo ""Hostname: ${HOSTNAME}""; echo ""Task id: ${TASK_ID}"". FILE1=$(awk 'BEGIN {FS=""\t""} {print $1}' /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk ""NR==${SGE_TASK_ID}""); if [ TRUE == ""TRUE"" ] ; then; FILE2=$(awk 'BEGIN {FS=""\t""} {print $3}' /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk ""NR==${SGE_TASK_ID}""); fi; ID=$(cat /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk '{print $NF}' | awk ""NR==${SGE_TASK_ID}""). mkdir -p /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/${ID}. strace /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon quant 	-i /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts -p 1 -l ISR 	-1 ${FILE1} -2 ${FILE2} 	-o /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/${ID} 2> logs/strace_test12_${SGE_TASK_ID}.txt. echo ""**** Job ends ****""; date; ```. Again, here is the `strace` output for task 1 (411 lines):. ```; execve(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon"", [""/dcl01/lieber/ajaffe/Emily/RNAse""..., ""quant"", ""-i"", ""/dcl01/lieber/ajaffe/Emily/RNAse""..., ""-p"", ""1"", ""-l"", ""ISR"", ""-1"", ""/dcl01/lieber/ajaffe/lab/libd_al""..., ""-2"", ""/dcl01/lieber/ajaffe/lab/libd_al""..., ""-o"", ""/dcl01/lieber/ajaffe/lab/libd_al""...], [/* 107 vars */]) = 0; brk(0) = 0xc2c000; mmap(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7fffbfffd000; readlink(""/proc/self/exe"", ""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon"", 4096) = 88; access(""/etc/ld.so.preload"", R_OK) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/tls/x86_64/libpthread.so.0",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:79035,log,logs,79035,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,1,['log'],['logs']
Testability,"astq/R10001_D2B1WACXX.fastq.gz; -rw-r--r-- 1 lcollado lieber_jaffe 6.3G Feb 20 12:40 merged_fastq/R10001_D2B1WACXX_read2.fastq.gz; -rw-r--r-- 1 lcollado lieber_jaffe 4.6G Feb 20 12:42 merged_fastq/R10002_C29P7ACXX.fastq.gz; -rw-r--r-- 1 lcollado lieber_jaffe 4.7G Feb 20 12:44 merged_fastq/R10002_C29P7ACXX_read2.fastq.gz; -rw-r--r-- 1 lcollado lieber_jaffe 7.1G Feb 20 12:47 merged_fastq/R10003_D19KGACXX.fastq.gz; -rw-r--r-- 1 lcollado lieber_jaffe 7.1G Feb 20 12:50 merged_fastq/R10003_D19KGACXX_read2.fastq.gz; ```. where R10001* is task 1, R10002* is task 2, R10003* is task 3. So it looks like at some point Salmon is asking for some memory based on the input data. ## Strace test with low memory (but above reported usage when requesting 90GB). Mark taught me about `strace` and we ran the following test:. ```bash; #!/bin/bash; #$ -cwd; #$ -pe local 2; #$ -l mem_free=7G,h_vmem=8G,h_fsize=100G; #$ -N step6-salmon_test11.gsk_phaseII; #$ -o ./logs/salmon_test11.$TASK_ID.txt; #$ -e ./logs/salmon_test11.$TASK_ID.txt; #$ -t 1-3; #$ -hold_jid pipeline_setup,step4-featCounts-alzheimer.gsk_phaseII; #$ -m e; echo ""**** Job starts ****""; date. echo ""**** JHPCE info ****""; echo ""User: ${USER}""; echo ""Job id: ${JOB_ID}""; echo ""Job name: ${JOB_NAME}""; echo ""Hostname: ${HOSTNAME}""; echo ""Task id: ${TASK_ID}"". FILE1=$(awk 'BEGIN {FS=""\t""} {print $1}' /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk ""NR==${SGE_TASK_ID}""); if [ TRUE == ""TRUE"" ] ; then; FILE2=$(awk 'BEGIN {FS=""\t""} {print $3}' /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk ""NR==${SGE_TASK_ID}""); fi; ID=$(cat /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk '{print $NF}' | awk ""NR==${SGE_TASK_ID}""). mkdir -p /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/${ID}. strace /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon quant 	-i /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:2480,log,logs,2480,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,1,['log'],['logs']
Testability,"astq/fastqs/flowcell1/read-I1_si-CGAAGTTG_lane-003-chunk-003.fastq.gz; ./fastq/fastqs/flowcell1/read-I1_si-CGAAGTTG_lane-004-chunk-002.fastq.gz; ./fastq/fastqs/flowcell1/read-I1_si-GAGCACGC_lane-001-chunk-001.fastq.gz; ./fastq/fastqs/flowcell1/read-I1_si-GAGCACGC_lane-002-chunk-000.fastq.gz; ./fastq/fastqs/flowcell1/read-I1_si-GAGCACGC_lane-003-chunk-003.fastq.gz; ./fastq/fastqs/flowcell1/read-I1_si-GAGCACGC_lane-004-chunk-002.fastq.gz; ./fastq/fastqs/flowcell1/read-I1_si-TTCGTGAA_lane-001-chunk-001.fastq.gz; ./fastq/fastqs/flowcell1/read-I1_si-TTCGTGAA_lane-002-chunk-000.fastq.gz; ./fastq/fastqs/flowcell1/read-I1_si-TTCGTGAA_lane-003-chunk-003.fastq.gz; ./fastq/fastqs/flowcell1/read-I1_si-TTCGTGAA_lane-004-chunk-002.fastq.gz]; Version Info: This is the most recent version of salmon.; [2018-12-06 11:14:56.513] [alevinLog] [info] A custom protocol (END, BC length, UMI length) = (5, 14, 5) is being used. Updating UMI k-mer length accordingly.; Logs will be written to ./fastq/test/logs; [2018-12-06 11:14:56.533] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; ### alevin (dscRNA-seq quantification) v0.12.0; ### [ program ] => salmon ; ### [ command ] => alevin ; ### [ libType ] => { ISR }; ### [ gemcode ] => { }; ### [ index ] => { ./transcripts_index_salmon/ }; ### [ threads ] => { 8 }; ### [ output ] => { ./fastq/test/ }; ### [ tgMap ] => { ./hg_transcriptome/tx2tx.tsv }; ### [ end ] => { 5 }; ### [ umiLength ] => { 5 }; ### [ barcodeLength ] => { 14 }; ### [ dumpCsvCounts ] => { }; ### [ mates1 ] => { /tmp/tmp.p28w2nGvAn/p1.fa }; ### [ mates2 ] => { /tmp/tmp.p28w2nGvAn/p2.fa }; ### [ unmatedReads ] => { ./fastq/fastqs/flowcell1/read-I1_si-ACTTCACT_lane-001-chunk-001.fastq.gz ./fastq/fastqs/flowcell1/read-I1_si-ACTTCACT_lane-002-chunk-000.fastq.gz ./fastq/fastqs/flowcell1/read-I1_si-ACTTCACT_lane-003-chunk-003.fastq.gz ./fastq/fastqs/flowcell1/read-I1_si-ACTTCACT_lane-004-chunk-002.fastq.gz ./fastq/fastqs/flowc",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/328#issuecomment-445008548:2184,test,test,2184,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/328#issuecomment-445008548,2,"['log', 'test']","['logs', 'test']"
Testability,"b/libtbb.so.12.5; -- Installing: /salmon/lib/libtbbmalloc.so; -- Installing: /salmon/lib/libtbbmalloc.so.2; -- Installing: /salmon/lib/libtbbmalloc.so.2.5; -- Installing: /salmon/lib/libtbbmalloc_proxy.so; -- Installing: /salmon/lib/libtbbmalloc_proxy.so.2; -- Installing: /salmon/lib/libtbbmalloc_proxy.so.2.5; -- Installing: /salmon/bin/salmon; -- Installing: /salmon/lib/libsalmon_core.a. Installation complete. Please ensure the following paths are set properly.; ==========================================================================; Please add /salmon/bin to your PATH; Please add /salmon/lib to your LD_LIBRARY_PATH; ==========================================================================; root@fd877e359439:/salmon/build# make test; Running tests...; Test project /salmon/build; Start 1: unit_tests; 1/2 Test #1: unit_tests ....................... Passed 0.37 sec; Start 2: salmon_read_test_quasi; 2/2 Test #2: salmon_read_test_quasi ........... Passed 1.80 sec. 100% tests passed, 0 tests failed out of 2. Total Test time (real) = 2.17 sec; ```. The `make test` command itself runs the test the builds the index and maps the reads against it. Either way, I can do that explicitly too (from within build):. ```; $ ./src/salmon index -t ../sample_data/transcripts.fasta -i sample_idx; ```. returns succesfully with a built index. ```; ...; [2023-03-10 05:51:33.748] [puff::index::jointLog] [info] Done wrapping the rank vector with a rank9sel structure.; [2023-03-10 05:51:33.748] [puff::index::jointLog] [info] contig count for validation: 23; [2023-03-10 05:51:33.748] [puff::index::jointLog] [info] Total # of Contigs : 23; [2023-03-10 05:51:33.748] [puff::index::jointLog] [info] Total # of numerical Contigs : 23; [2023-03-10 05:51:33.748] [puff::index::jointLog] [info] Total # of contig vec entries: 36; [2023-03-10 05:51:33.748] [puff::index::jointLog] [info] bits per offset entry 6; [2023-03-10 05:51:33.748] [puff::index::jointLog] [info] Done constructing the contig vector",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463312554:2928,test,tests,2928,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463312554,2,['test'],['tests']
Testability,"b; -- Installing: /salmon-0.10.2/lib/libtbb.so; -- Installing: /salmon-0.10.2/lib/libtbbmalloc.so; -- Installing: /salmon-0.10.2/lib/libtbbmalloc_proxy.so; -- Installing: /salmon-0.10.2/lib/libtbbmalloc.so.2; -- Installing: /salmon-0.10.2/lib/libtbb.so.2; -- Installing: /salmon-0.10.2/lib/pkgconfig; -- Installing: /salmon-0.10.2/lib/libtbbmalloc_proxy.so.2; -- Installing: /salmon-0.10.2/bin/salmon; -- Installing: /salmon-0.10.2/lib/libsalmon_core.a. Installation complete. Please ensure the following paths are set properly.; ==========================================================================; Please add /salmon-0.10.2/bin to your PATH; Please add /salmon-0.10.2/lib to your LD_LIBRARY_PATH; ==========================================================================; root@e08cc9670e4a:/salmon-0.10.2/build# make test; Running tests...; Test project /salmon-0.10.2/build; Start 1: unit_tests; 1/3 Test #1: unit_tests ....................... Passed 0.17 sec; Start 2: salmon_read_test_fmd; 2/3 Test #2: salmon_read_test_fmd ............. Passed 1.78 sec; Start 3: salmon_read_test_quasi; 3/3 Test #3: salmon_read_test_quasi ........... Passed 1.59 sec. 100% tests passed, 0 tests failed out of 3. Total Test time (real) = 3.54 sec; root@e08cc9670e4a:/salmon-0.10.2/build# lsb_release -a; LSB Version: core-9.20160110ubuntu0.2-amd64:core-9.20160110ubuntu0.2-noarch:security-9.20160110ubuntu0.2-amd64:security-9.20160110ubuntu0.2-noarch; Distributor ID: Ubuntu; Description: Ubuntu 16.04.4 LTS; Release: 16.04; Codename: xenial; ```. I built with:. `$ cmake -DFETCH_BOOST=TRUE .. && make install && make test`. I can also install the boost via apt and see if that makes a difference (though I expect not since it looked like TBB was the issue, and I let cmake install that). We can also check our compiler versions, perhaps. I have : . ```; root@e08cc9670e4a:/salmon-0.10.2/build# g++ --version; g++ (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609; Copyright (C) 2015 Free Software Foundati",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/250#issuecomment-404306268:2043,Test,Test,2043,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/250#issuecomment-404306268,1,['Test'],['Test']
Testability,"bb/2020.5-CentOS-vanilla/lib/libtbb.so -lgomp /usr/lib64/libjemalloc.so -lrt ../external/pufferfish/src/libksw2pp.a libalevin_core.a -ldl -pthread ; /tmp/cc91ASWS.ltrans1.ltrans.o: In function `boost::iostreams::basic_gzip_compressor<std::allocator<char> >::basic_gzip_compressor(boost::iostreams::gzip_params const&, long) [clone .constprop.783]':; <artificial>:(.text+0xdca4): undefined reference to `boost::iostreams::detail::zlib_base::zlib_base()'; <artificial>:(.text+0xdcbc): undefined reference to `boost::iostreams::detail::zlib_base::do_init(boost::iostreams::zlib_params const&, bool, void* (*)(void*, unsigned int, unsigned int), void (*)(void*, void*), void*)'; <artificial>:(.text+0xddc8): undefined reference to `boost::iostreams::zlib::best_compression'; <artificial>:(.text+0xddd4): undefined reference to `boost::iostreams::zlib::best_speed'; /tmp/cc91ASWS.ltrans1.ltrans.o: In function `GZipWriter::writeMtx(std::shared_ptr<spdlog::logger>&, boost::filesystem::path&, unsigned long, unsigned long, unsigned long) [clone .constprop.780]':; <artificial>:(.text+0xe056): undefined reference to `boost::iostreams::zlib::default_strategy'; <artificial>:(.text+0xe05d): undefined reference to `boost::iostreams::zlib::deflated'; <artificial>:(.text+0xe2d1): undefined reference to `boost::filesystem::detail::status(boost::filesystem::path const&, boost::system::error_code*)'; ...; ```. The boost related errors go on forever. There is nothing about ""boost"" in that command line, so apparently the relevant pieces never made it into the makefile. Running that very long command line with this added on the end:. ```; -L/usr/lib64/boost169 -lboost_filesystem -lboost_system -lboost_program_options -lboost_iostreams; ```; ; let Salmon link (with no other warnings). The resulting binary will do; ""salmon -h"" correctly but has so far not been tested further. So, in short CMakeLists.txt's handling of boost is still badly broken on CentOS, 8 this time, but it was terrible on 7 and 6 too.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641531162:4467,test,tested,4467,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641531162,1,['test'],['tested']
Testability,"be computationally challenging (at least for existing methods). zUMIs, for example, does an automatic barcode detection based on fixed barcode positions like we're doing here with alevin, so it would mis-detect cells like the shifted ones you pasted above. For SPLiT-seq, we do know exactly which barcodes go into the wells, however, so it is technically possible to restrict based on all possible known combinations of barcodes instead and be more positionally flexible. But deciding how many indel bases are allowable, and presumably doing multiple passes through the data to establish an include-list could be time-consuming. Further, the zUMIs developer rightly mentions [in this thread](https://github.com/sdparekh/zUMIs/issues/63) that there are likely going to be _many_ unused barcode combinations this way, so lots of time could be spent looking for ""cells"" that don't actually exist in the data. The authors of the paper from which our test dataset was derived describe in their methods using a Drop-seq computational framework, so I'm not sure which approach theirs is more similar to. . The simplest approach here is certainly the automatic detection, but it will come at the cost of losing meaningful reads to frameshift errors. . My guess is this falls well out of the scope of alevin, but if you're interested in improving on that, there may be a middle ground between the two approaches above, one that I'm not sure if your group or others have attempted for other methods: we could essentially do a 2-pass barcode detection. The first pass would restrict based on positions like we're already doing, and establish an include-list of possible barcodes seen in the data. Then we could pass through the barcode sequences a second time, looking only for those sequence combinations, but allowing 1-2bp flexibility in the positions they occur, potentially rescuing some of the ones missed during the first pass. This would get around the issue of searching for thousands (or more) barcodes",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-985554883:1019,test,test,1019,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-985554883,2,['test'],['test']
Testability,"ble difference is because (1) the reads are assumed to arrive in a random order (2) this is only a very small fraction of the total data and (3) if the unoriented reads map to a target in the ""wrong"" direction, they will also align to the proper target in the ""right"" direction and, once the orientation filter is applied for future reads, the weight of evidence should turn the probability of assignment of these unoriented reads toward the proper target. However, I'm guessing there is an edge case you're seeing here where the conditions don't induce this behavior. So, there are 2 immediate solutions to the problem. First, if you know the library type explicitly, you can use that. Second (and some other folks have discussed this here for other reasons), you can do a ""throw-away"" run of salmon on a small prefix of the read file (e.g. `salmon quant ... -lA --skipQuant -r <(gunzip -c reads.fq.gz | head -n 400000)`) to get the output of the automatic library type determination, and then run the full dataset with that library type. Finally, moving forward, I'm happy to consider working on modifying this default behavior. That is, we could (though it would be a little bit of work) modify the default behavior. The idea here is to basically run as we do now for the first 10,000 aligned reads to get the library type and then ""reset"" the whole quantification pipeline. The main challenge here is that salmon is designed to work with streaming FASTQ input, and we don't want to break that. So we can't do something as easy as ""reset the file pointer"". I think the best option is to make a copy of the first X reads in memory, detection the library type with them, and then start quantifying them and continue with the rest of the file. That complicates the logic a bit, because now the input source for reads changes dynamically during quantification --- but I think it could be done. Please let me know if you both have interest in this feature and it's worth putting on the list. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/489#issuecomment-738830213:3066,log,logic,3066,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/489#issuecomment-738830213,1,['log'],['logic']
Testability,"c duplicate_clusters.tsv; c3ec09a30adc9d47bc95839157cb2ff66530353106a4fd8e75b167ac5db67820 info.json; 430be78bae99a4592fcedc5c800a42313f2b1252e3953f89f347779056c1ee5b mphf.bin; 2fb0b5151f9f2544c06a9f95d03075f7af0494d0fe31745504a5a7da43edc1b1 pos.bin; 15d3bb6a16bcd8c1a6814852bd3dcfa439b60ec84c706f868ee7ec2d5a90581d pre_indexing.log; 8e665e5fdee5af6fcedabc69fd04eda6e66055ef811ebde6de6f86a66521198a rank.bin; 793c79f5fd6046dfea07bbc9587d2835088e54c78197d652d1b1f205c6b16983 refAccumLengths.bin; c5ea8eccca3fdc299ad7c9d2f07a4ed14c8c830940e83c315e7eaad6905a40aa ref_indexing.log; b580b9c6257254a018a9ae22291a64892c1a3715c69272637f5c504fc5545a70 reflengths.bin; 89679603ac0b28042275e5ff04b222bad3fd431cab573f0c2b61e7455aec43e7 refseq.bin; 46bf28001e00d491b68bf8758b99c1f304523c79bd94a97d7797888856594e84 seq.bin; 4c7e56ba28383774e786826099ef412761326fe18ce69f29033ad2886542985d versionInfo.json; `; Following are different.; `ctable.bin; info.json; mphf.bin; pos.bin; pre_indexing.log; ref_indexing.log; seq.bin; versionInfo.json`. I will try creating the vM25 index with increased memory. Wonder if its not building. Just FYI, my sha256sum on vM23 index is:; `9788716f4ce42b049fe7e865108f45392bb8a5847cfcd47369512783dc918239 complete_ref_lens.bin; 9c2453a47ce1808f54733f049b8c4cf38634c9116eb55ed725b73219caa101c5 ctable.bin; 928ba619dc5388ccab6d5c4f8ce162e07a5b5c79028be4aee4d838f43a3b9d92 ctg_offsets.bin; 0814d0e7dd8a4b126709c42728816995aefdf5a5bb6337c2d3c048cb0f56094d duplicate_clusters.tsv; dcbf8e140627b3c99d4dbcdaa585447a691fddb620f137811b669e73800f9b3b info.json; 5959abf5969a26481c6aa20fecbdddf19fa558e949cfbda5760205f38bb907b9 mphf.bin; 28460131b85c74ffb7627761a291614757e72b4e3b82971dcc048a50cc8d9e7f pos.bin; b5eb5e3fb0d03509d9fc90f6b5461c6aecc44423068f3303553cc07fffc7c1b9 pre_indexing.log; eca518136526233f3dc28d9684926793cb84327242d54c1a8a20c66aa1928fad rank.bin; a990247ba2b351fd0921de6470bf0c3505472d8f463e6f8b9ec7c221b6b56af8 refAccumLengths.bin; 436199afbb35045a70fdc7b9e542ef805b5717",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/561#issuecomment-674527480:1692,log,log,1692,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/561#issuecomment-674527480,1,['log'],['log']
Testability,can you try `make install` before `make test`?,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/229#issuecomment-393690468:40,test,test,40,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/229#issuecomment-393690468,1,['test'],['test']
Testability,cat Testing/Temporary/LastTestsFailed.log; 1:unit_tests,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/229#issuecomment-393679453:4,Test,Testing,4,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/229#issuecomment-393679453,2,"['Test', 'log']","['Testing', 'log']"
Testability,"cho ""User: ${USER}""; echo ""Job id: ${JOB_ID}""; echo ""Job name: ${JOB_NAME}""; echo ""Hostname: ${HOSTNAME}""; echo ""Task id: ${TASK_ID}"". FILE1=$(awk 'BEGIN {FS=""\t""} {print $1}' /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk ""NR==${SGE_TASK_ID}""); if [ TRUE == ""TRUE"" ] ; then; FILE2=$(awk 'BEGIN {FS=""\t""} {print $3}' /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk ""NR==${SGE_TASK_ID}""); fi; ID=$(cat /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk '{print $NF}' | awk ""NR==${SGE_TASK_ID}""). mkdir -p /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test3/${ID}. /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon quant 	-i /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts -p 1 -l ISR 	-1 ${FILE1} -2 ${FILE2} 	-o /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test3/${ID}. echo ""**** Job ends ****""; date; ```. ### Example log file. ```; **** Job starts ****; Wed Mar 29 14:51:10 EDT 2017; **** JHPCE info ****; User: lcollado; Job id: 110315; Job name: step6-salmon_test3.gsk_phaseII; Hostname: compute-061; Task id: ; Version Info: This is the most recent version of Salmon.; ### salmon (mapping-based) v0.8.2; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts }; ### [ threads ] => { 1 }; ### [ libType ] => { ISR }; ### [ mates1 ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/merged_fastq/R10001_D2B1WACXX.fastq.gz }; ### [ mates2 ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/merged_fastq/R10001_D2B1WACXX_read2.fastq.gz }; ### [ output ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test3/R10001_D2B1WACXX }; Logs will be written to /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test3/R10001_D2B1WACXX/logs; [1m[2017-03-29 14:51:11.533] [join",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-290516965:1768,log,log,1768,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-290516965,1,['log'],['log']
Testability,"cho ""User: ${USER}""; echo ""Job id: ${JOB_ID}""; echo ""Job name: ${JOB_NAME}""; echo ""Hostname: ${HOSTNAME}""; echo ""Task id: ${TASK_ID}"". FILE1=$(awk 'BEGIN {FS=""\t""} {print $1}' /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk ""NR==${SGE_TASK_ID}""); if [ TRUE == ""TRUE"" ] ; then; FILE2=$(awk 'BEGIN {FS=""\t""} {print $3}' /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk ""NR==${SGE_TASK_ID}""); fi; ID=$(cat /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk '{print $NF}' | awk ""NR==${SGE_TASK_ID}""). mkdir -p /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test5/${ID}. /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon quant 	-i /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts -p 1 -l ISR 	-1 ${FILE1} -2 ${FILE2} 	-o /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test5/${ID}. echo ""**** Job ends ****""; date; ```. ### Example log file. ```; **** Job starts ****; Wed Mar 29 23:27:11 EDT 2017; **** JHPCE info ****; User: lcollado; Job id: 110632; Job name: step6-salmon_test5.gsk_phaseII; Hostname: compute-066; Task id: ; Version Info: This is the most recent version of Salmon.; ### salmon (mapping-based) v0.8.2; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts }; ### [ threads ] => { 1 }; ### [ libType ] => { ISR }; ### [ mates1 ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/merged_fastq/R10001_D2B1WACXX.fastq.gz }; ### [ mates2 ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/merged_fastq/R10001_D2B1WACXX_read2.fastq.gz }; ### [ output ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test5/R10001_D2B1WACXX }; Logs will be written to /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test5/R10001_D2B1WACXX/logs; [1m[2017-03-29 23:59:18.699] [join",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-290516965:8683,log,log,8683,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-290516965,1,['log'],['log']
Testability,"conda create never seems to even get out of the gate ... a little bit of testing strongly suggests that version of salmon can't be found :. conda create -n owlVsunicorn -c bioconda owlVsunicorn; Collecting package metadata (current_repodata.json): done; Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.; Collecting package metadata (repodata.json): / Killed. this is the first time I've encountered an issue where something that is ""supposed"" to be there can't be found. Adam H. Freedman, PhD; Data Scientist; Faculty of Arts & Sciences Informatics Group; Harvard University; 38 Oxford St; Cambridge, MA 02138; phone: +001 310 415 7145; ________________________________; From: Rob Patro ***@***.***>; Sent: Sunday, October 29, 2023 10:01 AM; To: COMBINE-lab/salmon ***@***.***>; Cc: Freedman, Adam ***@***.***>; State change ***@***.***>; Subject: Re: [COMBINE-lab/salmon] anaconda version of salmon outdated, missing decoys option (Issue #895). I'm going to cc @dpryan79<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_dpryan79&d=DwMFaQ&c=WO-RGvefibhHBZq3fL85hQ&r=MITI_LEJgyr1a24IMFAlSaZIPxMpOUT21T7L3fg4CjA&m=mSC4skssR3kpqIDO5fXv00Vk9PrFQeVf0OH62EOgXZ9hbM31qjkaQra0z60JiEA_&s=hPsmfTmSAfiwDhS2JFQyD0EUHl5m5sbj_n46DYj6tdM&e=> on this — does it just not finish? It seems to work within our GitHub CI, where we have to grab the prebuilt salmon to test simpleaf. —; Reply to this email directly, view it on GitHub<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_COMBINE-2Dlab_salmon_issues_895-23issuecomment-2D1784122719&d=DwMFaQ&c=WO-RGvefibhHBZq3fL85hQ&r=MITI_LEJgyr1a24IMFAlSaZIPxMpOUT21T7L3fg4CjA&m=mSC4skssR3kpqIDO5fXv00Vk9PrFQeVf0OH62EOgXZ9hbM31qjkaQra0z60JiEA_&s=6Y-rQOzzAA-t9QV8NyfcMVeySD2an4xeN1HsDqa6VpQ&e=>, or unsubscribe<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_notifications_unsubscribe-2Dauth_ADBMMUDFRQIHN4AMNBHWCN3YBZOUTAVCNFSM6AAAAAA6UYYPGOVHI2DSMVQWIX3LMV43OSLTON2WKQ3PN",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/895#issuecomment-1784126021:73,test,testing,73,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/895#issuecomment-1784126021,2,['test'],['testing']
Testability,"cript. 3. I loaded the reference genome fasta acquired from Ensembl using the Biostrings package. GRanges and Biostrings are tightly integrated, allowing me to subset sequences from a Biostrings object using the GRanges object. **I believe the problem lies here.** It appears that when subsetting the mature exonic sequences from Biostrings using GRanges, the strand field in the GRanges object **was not** utilized. I.e., I needed to get the reverse complement of the extracted sequences for transcripts on the minus strand. I had done that and assumed that this behaviour would be consistent. However, for reasons I have not been able to pinpoint (potentially a bug), the strand information **was accounted for** when I used GRanges to subset the premature sequences. I **did not** need to get the reverse complement of the premature sequences on the minus strand as I had to do for the mature sequences. Yet, I did that anyway. I initially did test my protocol to ensure it produced identical transcript sequences to Gencode, but I only did this for mature sequences. All seemed fine for both + and - strand transcripts. After your feedback, I compared the premature sequences in my transcript fasta against the transcript fasta from Gencode. As you can see in the smoothed dot plots below, the premature sequences of transcripts on the minus strand are in the wrong orientation and have the wrong complementarity!. ![Screenshot from 2021-04-24 00-35-05](https://user-images.githubusercontent.com/10429333/115947355-0d96c880-a495-11eb-92a6-d8d2233c8d2b.png). I included my R code below for this test case for anyone who might stumble upon this issue. Under the code headers “Mature transcript sequences” and “Premature transcript sequences”, you can observe that I used identical protocols for sequence subsetting, yet in the mature case the strand information in the GRanges seems to be disregarded when subsetting from Biostrings, but in the premature case the strand information is used. Of cou",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/655#issuecomment-826035191:2328,test,test,2328,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/655#issuecomment-826035191,2,['test'],['test']
Testability,"criptome using BWA-mem and then sorted them by coordinates (as a regular procedure). I know Salmon assumes the alignments are not sorted, so I shuffled these bam files, and then run `salmon quant`.; Here are the errors I got in a number of trials:. ### Fresh installation of Salmon; ```; conda create --name salmon -c bioconda salmon; conda activate salmon; ```. ### 1. Shuffling a bam file with `samtools collate`; ```; samtools collate \; -@ 40 \; -o SRR3212847.Aligned.Shuffled.bam \; SRR3212847.Aligned.SortedByCoord.bam. salmon quant \; -t mRNA.fasta \; -p 20 \; -l A \; -a SRR3212847.Aligned.Shuffled.bam \; -o SRR3212847.Aligned.Shuffled ; ```. ```; Version Info: This is the most recent version of salmon.; # salmon (alignment-based) v1.4.0; # [ program ] => salmon ; # [ command ] => quant ; # [ targets ] => { mRNA.fasta }; # [ threads ] => { 20 }; # [ libType ] => { A }; # [ alignments ] => { SRR3212847.Aligned.Shuffled.bam }; # [ output ] => { SRR3212847.Aligned.Shuffled }; Logs will be written to SRR3212847.Aligned.Shuffled/logs; [2021-01-08 12:43:44.680] [jointLog] [info] setting maxHashResizeThreads to 20; [2021-01-08 12:43:44.680] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; Library format { type:paired end, relative orientation:inward, strandedness:unstranded }; [2021-01-08 12:43:44.711] [jointLog] [info] numQuantThreads = 14; parseThreads = 6; Checking that provided alignment files have consistent headers . . . done; Populating targets from aln = ""SRR3212847.Aligned.Shuffled.bam"", fasta = ""mRNA.fasta"" . . .done. processed 0 reads in current roundSegmentation fault (core dumped); ```. ### 2. Shuffling a headless bam file with `samtools collate`; (I think I saw something about the bam's header in another thread dealing with this issue); ```; samtools view \; -b \; -@ 40 \; -o SRR3212847.Aligned.SortedByCoord.NoHeader.bam \; SRR3212847.Aligned.SortedByCoord.bam. samtools collate \; -@ 40 \; -o SRR321284",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/582#issuecomment-756727212:1070,Log,Logs,1070,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/582#issuecomment-756727212,1,['Log'],['Logs']
Testability,"e 31: 54922 Aborted (core dumped) /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon quant -i /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts -p 1 -l ISR -1 ${FILE1} -2 ${FILE2} -o /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test3/${ID}; **** Job ends ****; Wed Mar 29 14:51:13 EDT 2017; ```. ### SGE email info example. ```; Job-array task 110315.1 (step6-salmon_test3.gsk_phaseII) Complete; User = lcollado; Queue = shared.q@compute-061.cm.cluster; Host = compute-061.cm.cluster; Start Time = 03/29/2017 14:51:09; End Time = 03/29/2017 14:51:13; User Time = 00:00:00; System Time = 00:00:02; Wallclock Time = 00:00:04; CPU = 00:00:02; Max vmem = 14.820G; Exit Status = 0; ```. ## 16 cores. ### Bash. ```bash; #!/bin/bash; #$ -cwd; #$ -l mem_free=2G,h_vmem=3G,h_fsize=100G; #$ -N step6-salmon_test4.gsk_phaseII; #$ -pe local 16; #$ -o ./logs/salmon_test4.$TASK_ID.txt; #$ -e ./logs/salmon_test4.$TASK_ID.txt; #$ -t 1-3; #$ -hold_jid pipeline_setup,step4-featCounts-alzheimer.gsk_phaseII; #$ -m e; echo ""**** Job starts ****""; date. echo ""**** JHPCE info ****""; echo ""User: ${USER}""; echo ""Job id: ${JOB_ID}""; echo ""Job name: ${JOB_NAME}""; echo ""Hostname: ${HOSTNAME}""; echo ""Task id: ${TASK_ID}"". FILE1=$(awk 'BEGIN {FS=""\t""} {print $1}' /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk ""NR==${SGE_TASK_ID}""); if [ TRUE == ""TRUE"" ] ; then; FILE2=$(awk 'BEGIN {FS=""\t""} {print $3}' /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk ""NR==${SGE_TASK_ID}""); fi; ID=$(cat /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk '{print $NF}' | awk ""NR==${SGE_TASK_ID}""). mkdir -p /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test4/${ID}. /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon quant 	-i /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gen",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-290516965:3989,log,logs,3989,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-290516965,1,['log'],['logs']
Testability,"e conda evironment) is going differently ! Skip to Try 2. below for success; Try 1.; Index seemed to go the same as before, using the command [from a script]; salmon index -t decoys/gentrome.fa -d decoys/decoys.txt -i salmonIndexDecoyMouse; but then command; salmon quant -p 3 -i salmonIndexDecoyMouse -l A -1 SRR1818187_2.fastq.gz -2 SRR1818187_1.fastq.gz --validateMappings -o Salmontranscripts_quant; Fails as follows, saying it cannot find a .json file(s); ---------------------------------------------------------------------; (salmon) wayne@Ubuntu19:~/rnaseq$ sh salmonQuantDecoy.sh ; Version Info: This is the most recent version of salmon.; ### salmon (mapping-based) v0.14.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ threads ] => { 3 }; ### [ index ] => { salmonIndexDecoyMouse }; ### [ libType ] => { A }; ### [ mates1 ] => { SRR1818187_2.fastq.gz }; ### [ mates2 ] => { SRR1818187_1.fastq.gz }; ### [ validateMappings ] => { }; ### [ output ] => { Salmontranscripts_quant }; Logs will be written to Salmontranscripts_quant/logs; [2019-08-25 11:40:44.518] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2019-08-25 11:40:44.518] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2019-08-25 11:40:44.518] [jointLog] [info] Usage of --validateMappings, without --hardFilter implies use of range factorization. rangeFactorizationBins is being set to 4; [2019-08-25 11:40:44.518] [jointLog] [info] Usage of --validateMappings implies a default consensus slack of 0.2. Setting consensusSlack to 0.2.; [2019-08-25 11:40:44.518] [jointLog] [info] parsing read library format; [2019-08-25 11:40:44.518] [jointLog] [info] There is 1 library.; Exception : [Error: The index version file salmonIndexDecoyMouse/versionInfo.json doesn't seem to exist. Please try re-building the salmon index.]; salmon quant was invoked improperly.; For ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/419#issuecomment-524651435:1138,Log,Logs,1138,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/419#issuecomment-524651435,2,"['Log', 'log']","['Logs', 'logs']"
Testability,"e it appears that this version no longer crashes when given less than about 250GB of memory, I also tested with 32G and 16GB of memory, just to see what impact this would have on the times. Those jobs are still running (it's only been about 4hrs as of this writing, I'll update my post if/when they complete). Current logs are showing that they quickly consume all the available memory, but have not yet crashed. I've also got versions with 128-512GB of memory requested (by powers of 2) for comparison. Some random notes: both the 31-mer index experienced about twice as many soft page reclaims with the new/faster version and experienced a few hard page faults (the previous version saw none of the latter). The 17-mer version experienced fewer page reclaims than any of the 31-mer indices and far fewer than with the prior version. Again, a few page faults crept in, but relatively few by percentage and likely not contributing any significant amount of time overall. [index-qacct-17mer.log](https://github.com/COMBINE-lab/salmon/files/4246516/index-qacct-17mer.log); [index-qacct-31mer.log](https://github.com/COMBINE-lab/salmon/files/4246517/index-qacct-31mer.log). **UPDATE**; The 16GB version finished running. It actually only took a little over 4 hours to run, as well. The troubling thing about this job seems to be that, despite having successfully completed, according to the accounting log it used over 20GB of memory... which should be impossible to do. Our resident experts suspect there's a race condition occurring at the tail end of the job and that all of that extra memory is being allocated before the scheduler can kill it for exceeding the limit. Whatever the case, though, this throws into question some of those numbers that I've been grabbing from the accounting logs --- it's either being misreported, or the memory gobbling is happening so rapidly that it may not, in fact, be being properly recorded. I tested the index anyway. It *appears* to be working just fine. Nothi",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/476#issuecomment-590516702:1613,log,log,1613,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/476#issuecomment-590516702,1,['log'],['log']
Testability,"e not sorted, so I shuffled these bam files, and then run `salmon quant`. Here are the errors I got in a number of trials:; > ; > ### Fresh installation of Salmon; > ```; > conda create --name salmon -c bioconda salmon; > conda activate salmon; > ```; > ; > ### 1. Shuffling a bam file with `samtools collate`; > ```; > samtools collate \; > -@ 40 \; > -o SRR3212847.Aligned.Shuffled.bam \; > SRR3212847.Aligned.SortedByCoord.bam; > ; > salmon quant \; > -t mRNA.fasta \; > -p 20 \; > -l A \; > -a SRR3212847.Aligned.Shuffled.bam \; > -o SRR3212847.Aligned.Shuffled ; > ```; > ; > ```; > Version Info: This is the most recent version of salmon.; > # salmon (alignment-based) v1.4.0; > # [ program ] => salmon ; > # [ command ] => quant ; > # [ targets ] => { mRNA.fasta }; > # [ threads ] => { 20 }; > # [ libType ] => { A }; > # [ alignments ] => { SRR3212847.Aligned.Shuffled.bam }; > # [ output ] => { SRR3212847.Aligned.Shuffled }; > Logs will be written to SRR3212847.Aligned.Shuffled/logs; > [2021-01-08 12:43:44.680] [jointLog] [info] setting maxHashResizeThreads to 20; > [2021-01-08 12:43:44.680] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; > Library format { type:paired end, relative orientation:inward, strandedness:unstranded }; > [2021-01-08 12:43:44.711] [jointLog] [info] numQuantThreads = 14; > parseThreads = 6; > Checking that provided alignment files have consistent headers . . . done; > Populating targets from aln = ""SRR3212847.Aligned.Shuffled.bam"", fasta = ""mRNA.fasta"" . . .done; > ; > processed 0 reads in current roundSegmentation fault (core dumped); > ```; > ; > ### 2. Shuffling a headless bam file with `samtools collate`; > (I think I saw something about the bam's header in another thread dealing with this issue); > ; > ```; > samtools view \; > -b \; > -@ 40 \; > -o SRR3212847.Aligned.SortedByCoord.NoHeader.bam \; > SRR3212847.Aligned.SortedByCoord.bam; > ; > samtools collate \; > -@ 40 \; > -o SRR",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/582#issuecomment-1343749456:1204,log,logs,1204,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/582#issuecomment-1343749456,1,['log'],['logs']
Testability,"e of --validateMappings; > implies use of minScoreFraction. Since not explicitly specified, it is; > being set to 0.65; > [2019-07-29 15:58:39.034] [jointLog] [info] Usage of --validateMappings,; > without --hardFilter implies use of range factorization.; > rangeFactorizationBins is being set to 4; > [2019-07-29 15:58:39.034] [jointLog] [info] Usage of --validateMappings; > implies a default consensus slack of 0.2. Setting consensusSlack to 0.2.; > [2019-07-29 15:58:39.034] [jointLog] [info] parsing read library format; > [2019-07-29 15:58:39.034] [jointLog] [error] Failed to successfully parse; > any complete read libraries. Please make sure you provided arguments; > properly to -1, -2 (for paired-end libraries) or -r (for single-end; > libraries), and that the library format option (-l) *comes before* the read; > libraries.; >; > On Mon, Jul 29, 2019 at 4:06 PM Avi Srivastava <notifications@github.com>; > wrote:; >; >> Oh Sorry about that what I meant was the salmon.log file or the the; >> meta-info.json file created by salmon in the output directory. You can; >> check what files salmon is detecting it seems there are 12 files in the; >> mate1 and 13 files in the mate2. Can you confirm there are 13 pairs of file; >> in that directory and their regex is same as you are using ? Can you also; >> try putting the names of the file instead * as regex ?; >>; >> —; >> You are receiving this because you were mentioned.; >> Reply to this email directly, view it on GitHub; >> <https://github.com/COMBINE-lab/salmon/issues/408?email_source=notifications&email_token=AEHDXAA5DHKAZKVCZY5N7ULQB5ZXXA5CNFSM4IGU4ZTKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOD3CIG3I#issuecomment-516195181>,; >> or mute the thread; >> <https://github.com/notifications/unsubscribe-auth/AEHDXAHE56TJTIQFQDFDGMDQB5ZXXANCNFSM4IGU4ZTA>; >> .; >>; >; >; > --; > Sara E. Boles, MS; > PhD Candidate | Whitehead Lab; > Pharmacology and Toxicology Graduate Group; > Department of Environmental Toxic",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/408#issuecomment-516521791:3393,log,log,3393,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/408#issuecomment-516521791,1,['log'],['log']
Testability,"e seg fault on each one. However the number that appears immediately before ""Segmentation fault"" (914 below) varies from one invocation to the next, even on the same data file. . I appreciate any help you can offer and I apologize in advance if there's something obvious I should have read or known about. (it seems like the lines below that are preceded by ### are coming out in fold face. They are not meant to.). (salmon) MacBook-Pro-2:salmon-tutorial brent$ bash quant_tut_samples.sh; Processing sample DRR016125; Version Info: Could not resolve upgrade information in the alotted time.; Check for upgrades manually at https://combine-lab.github.io/salmon; ### salmon (mapping-based) v0.11.3; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { athal_index }; ### [ libType ] => { A }; ### [ mates1 ] => { data/DRR016125/DRR016125_1.fastq.gz }; ### [ mates2 ] => { data/DRR016125/DRR016125_2.fastq.gz }; ### [ threads ] => { 8 }; ### [ output ] => { quants/DRR016125_quant }; Logs will be written to quants/DRR016125_quant/logs; [2018-11-24 15:08:09.785] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2018-11-24 15:08:09.785] [jointLog] [info] parsing read library format; [2018-11-24 15:08:09.785] [jointLog] [info] There is 1 library.; [2018-11-24 15:08:09.877] [jointLog] [info] Loading Quasi index; [2018-11-24 15:08:09.877] [jointLog] [info] Loading 32-bit quasi index; [2018-11-24 15:08:09.877] [stderrLog] [info] Loading Suffix Array ; [2018-11-24 15:08:10.319] [stderrLog] [info] Loading Transcript Info ; [2018-11-24 15:08:10.423] [stderrLog] [info] Loading Rank-Select Bit Array; [2018-11-24 15:08:10.432] [stderrLog] [info] There were 40,812 set bits in the bit array; [2018-11-24 15:08:10.435] [stderrLog] [info] Computing transcript lengths; [2018-11-24 15:08:10.435] [stderrLog] [info] Waiting to finish loading hash. quant_tut_samples.sh: line 2: 914 Segmentation fault: 11 salmon quant -i athal_i",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/317#issuecomment-441396828:1303,Log,Logs,1303,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/317#issuecomment-441396828,2,"['Log', 'log']","['Logs', 'logs']"
Testability,"ed by your `auto-load safe-path' set to ""$debugdir:$datadir/auto-load"".; To enable execution of this file add; add-auto-load-safe-path /u/user/local/lib64/libstdc++.so.6.0.21-gdb.py; line to your configuration file ""/u/user/.gdbinit"".; To completely disable this security protection add; set auto-load safe-path /; line to your configuration file ""/u/user/.gdbinit"".; For more information about this security protection see the; ""Auto-loading safe path"" section in the GDB manual. E.g., run from the shell:; info ""(gdb)Auto-loading safe path""; [New Thread 0x7fff7e0f4700 (LWP 14274)]; Version Info: ### A newer version of Salmon is available. ####; [Thread 0x7fff7e0f4700 (LWP 14274) exited]; ###; The newest version, available at https://github.com/COMBINE-lab/salmon/releases; contains new features, improvements, and bug fixes; please upgrade at your; earliest convenience.; ###; [New Thread 0x7fff7d273700 (LWP 14275)]; Logs will be written to pbmc4k/alevin/logs; [New Thread 0x7ffefc3f1700 (LWP 14276)]; [New Thread 0x7ffe7b56f700 (LWP 14277)]; [New Thread 0x7ffdfa6ed700 (LWP 14278)]; ### salmon (single-cell-based) v0.10.1; ### [ program ] => salmon; ### [ command ] => alevin; ### [ libType ] => { ISR }; ### [ chromium ] => { }; ### [ threads ] => { 8 }; ### [ output ] => { pbmc4k/alevin }; ### [ mates1 ] => { /dev/fd/63 }; ### [ mates2 ] => { /dev/fd/62 }; ### [ index ] => { /u/user/ref/cellranger/salmon/transcripts_index }; ### [ tgMap ] => { tx2gene.txt }. [2018-06-08 13:37:41.409] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [New Thread 0x7ffd795e7700 (LWP 14279)]; [New Thread 0x7ffcf95e6700 (LWP 14280)]; [New Thread 0x7ffc795e5700 (LWP 14281)]; [2018-06-08 13:37:41.419] [alevinLog] [info] Processing barcodes files (if Present). processed 6 Million barcodes[New Thread 0x7ffbf7063700 (LWP 14333)]; [New Thread 0x7ffb77062700 (LWP 14334)]; [New Thread 0x7ffaf7061700 (LWP 14335)]; [New Thread 0x7ffa77060700 (LWP 1433",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-395836214:3098,Log,Logs,3098,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-395836214,2,"['Log', 'log']","['Logs', 'logs']"
Testability,"en I build this index on one of our machines. Perhaps we could see if these match: . ```; $:salmon_index [j1] (develop ?) $ sha256sum *; 306e9d98b3460859f579059bf876aa3b6e264c8f38c04cde332b03632edc6dfb complete_ref_lens.bin; 28519aac34b84b4d0570c97340815e719511c204e04a240dd43e365d2872eed3 ctable.bin; 1c7501deaa4524f4700152713228cb03949775dce481384eac67bb45458508be ctg_offsets.bin; dbc575fed0d589b4671c26bd8cbcb4b3d52ef41c299a90de978ab940abb751fc duplicate_clusters.tsv; 987050914456cf247a24136429d8faaa293cf5617bfd57166c64976b2778d95b info.json; 0b7e8cb4ebed78513900831c047f0d66589068921c33bb15c49b3567c84e2edc mphf.bin; 117369928fde1bff4ca278246c331e079cc0860c3b415e34cd4b08f588063abc pos.bin; 297492e67d274b2ff8f026d2fbc8045f96e17793a58dd74c19b5ab1b7156df8a pre_indexing.log; 8e665e5fdee5af6fcedabc69fd04eda6e66055ef811ebde6de6f86a66521198a rank.bin; 793c79f5fd6046dfea07bbc9587d2835088e54c78197d652d1b1f205c6b16983 refAccumLengths.bin; 92acf575c90c6954ff75be1ea791f822eee05e486c6e86c52943d8bc1a0849ca ref_indexing.log; b580b9c6257254a018a9ae22291a64892c1a3715c69272637f5c504fc5545a70 reflengths.bin; 89679603ac0b28042275e5ff04b222bad3fd431cab573f0c2b61e7455aec43e7 refseq.bin; 94cb79a2f4acd811d2164f2926c96869a8103b9118170d0688f57b46e695cd5c seq.bin; 89d56bb135f32c7b5fa337bc3c45814b80c2886a3cccc31ff0533c6324ca11fd versionInfo.json; ```. I'm also including a link [here](https://drive.google.com/file/d/1uxGUy8gaQ20dpEi7-D3ookFF4JYawsIR/view?usp=sharing) to a tarball containing the index I built. Could you see if you can perform quantification with this index? Finally, it might be worth checking that nothing strange / unexpected is going on with how libraries are being resolved in the linker path when you are running salmon. Could you share the output of running `ldd salmon`? If none of those point at anything obvious, I might also suggest seeing if it runs as expected inside a Docker container. You can grab a dockerfile for salmon [here](https://hub.docker.com/r/combinelab/salmon).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/561#issuecomment-674454751:1345,log,log,1345,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/561#issuecomment-674454751,1,['log'],['log']
Testability,"environment: failed with repodata from current_repodata.json, will retry with next repodata source.; Collecting package metadata (repodata.json): / Killed. this is the first time I've encountered an issue where something that is ""supposed"" to be there can't be found. Adam H. Freedman, PhD; Data Scientist; Faculty of Arts & Sciences Informatics Group; Harvard University; 38 Oxford St; Cambridge, MA 02138; phone: +001 310 415 7145; ________________________________; From: Rob Patro ***@***.***>; Sent: Sunday, October 29, 2023 10:01 AM; To: COMBINE-lab/salmon ***@***.***>; Cc: Freedman, Adam ***@***.***>; State change ***@***.***>; Subject: Re: [COMBINE-lab/salmon] anaconda version of salmon outdated, missing decoys option (Issue #895). I'm going to cc @dpryan79<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_dpryan79&d=DwMFaQ&c=WO-RGvefibhHBZq3fL85hQ&r=MITI_LEJgyr1a24IMFAlSaZIPxMpOUT21T7L3fg4CjA&m=mSC4skssR3kpqIDO5fXv00Vk9PrFQeVf0OH62EOgXZ9hbM31qjkaQra0z60JiEA_&s=hPsmfTmSAfiwDhS2JFQyD0EUHl5m5sbj_n46DYj6tdM&e=> on this — does it just not finish? It seems to work within our GitHub CI, where we have to grab the prebuilt salmon to test simpleaf. —; Reply to this email directly, view it on GitHub<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_COMBINE-2Dlab_salmon_issues_895-23issuecomment-2D1784122719&d=DwMFaQ&c=WO-RGvefibhHBZq3fL85hQ&r=MITI_LEJgyr1a24IMFAlSaZIPxMpOUT21T7L3fg4CjA&m=mSC4skssR3kpqIDO5fXv00Vk9PrFQeVf0OH62EOgXZ9hbM31qjkaQra0z60JiEA_&s=6Y-rQOzzAA-t9QV8NyfcMVeySD2an4xeN1HsDqa6VpQ&e=>, or unsubscribe<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_notifications_unsubscribe-2Dauth_ADBMMUDFRQIHN4AMNBHWCN3YBZOUTAVCNFSM6AAAAAA6UYYPGOVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMYTOOBUGEZDENZRHE&d=DwMFaQ&c=WO-RGvefibhHBZq3fL85hQ&r=MITI_LEJgyr1a24IMFAlSaZIPxMpOUT21T7L3fg4CjA&m=mSC4skssR3kpqIDO5fXv00Vk9PrFQeVf0OH62EOgXZ9hbM31qjkaQra0z60JiEA_&s=ckSFRx1FekMV-wL0KtdZFPdtgCB1DiAziHIsdrF0cKQ&e=>.; You are receiving this because you mo",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/895#issuecomment-1784126021:1420,test,test,1420,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/895#issuecomment-1784126021,2,['test'],['test']
Testability,"es. Those jobs are still running (it's only been about 4hrs as of this writing, I'll update my post if/when they complete). Current logs are showing that they quickly consume all the available memory, but have not yet crashed. I've also got versions with 128-512GB of memory requested (by powers of 2) for comparison. Some random notes: both the 31-mer index experienced about twice as many soft page reclaims with the new/faster version and experienced a few hard page faults (the previous version saw none of the latter). The 17-mer version experienced fewer page reclaims than any of the 31-mer indices and far fewer than with the prior version. Again, a few page faults crept in, but relatively few by percentage and likely not contributing any significant amount of time overall. [index-qacct-17mer.log](https://github.com/COMBINE-lab/salmon/files/4246516/index-qacct-17mer.log); [index-qacct-31mer.log](https://github.com/COMBINE-lab/salmon/files/4246517/index-qacct-31mer.log). **UPDATE**; The 16GB version finished running. It actually only took a little over 4 hours to run, as well. The troubling thing about this job seems to be that, despite having successfully completed, according to the accounting log it used over 20GB of memory... which should be impossible to do. Our resident experts suspect there's a race condition occurring at the tail end of the job and that all of that extra memory is being allocated before the scheduler can kill it for exceeding the limit. Whatever the case, though, this throws into question some of those numbers that I've been grabbing from the accounting logs --- it's either being misreported, or the memory gobbling is happening so rapidly that it may not, in fact, be being properly recorded. I tested the index anyway. It *appears* to be working just fine. Nothing faulted or crashed when I attempted to quantify some reads against it. [index-qacct-17mer-16gigs.log](https://github.com/COMBINE-lab/salmon/files/4247214/index-qacct-17mer-16gigs.log)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/476#issuecomment-590516702:2022,log,log,2022,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/476#issuecomment-590516702,5,"['log', 'test']","['log', 'logs', 'tested']"
Testability,"essor; Department of Biochemistry and Molecular Biology, Howard Building Room 205, Mail Stop 330; University of Nevada, Reno; Reno, NV 89557; (775) 784-4204; cramer@unr.edu<mailto:cramer@unr.edu>; http://www.ag.unr.edu/cramer/. On Mar 22, 2018, at 6:21 PM, Rob Patro <notifications@github.com<mailto:notifications@github.com>> wrote:. Hi @grantcramer<https://na01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Fgrantcramer&data=01%7C01%7Ccramer%40unr.edu%7C54d34feceb114e30a61b08d5905c7a7b%7C523b4bfc0ebd4c03b2b96f6a17fd31d8%7C1&sdata=w1ED%2B5ZBUY6Z8fTiIs62IZJizv0HcvVzw8CtfEdK32E%3D&reserved=0>,. I was able to successfully index and map against the fasta file you link above (on linux). I was also able to index and map against the index on OSX, using the salmon from bioconda (v 0.9.1). So, I'm not yet able to reproduce this. It seems the file you uploaded for your pre-built index is no longer available, so I couldn't try that out. I'd be happy to give it a try if you can put it up on dropbox or some such. Otherwise, I wonder if there could be some sort of binary compatibility issue. Did you build the index on the same machine you're quantifying on? The OSX I tested on is 10.13.1. Best,; Rob. —; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://na01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2FCOMBINE-lab%2Fsalmon%2Fissues%2F209%23issuecomment-375509050&data=01%7C01%7Ccramer%40unr.edu%7C54d34feceb114e30a61b08d5905c7a7b%7C523b4bfc0ebd4c03b2b96f6a17fd31d8%7C1&sdata=5XDT2ix1q1Uz%2B3kTchI%2B5K9Hzu7UuGkyQAz8KB9ko4o%3D&reserved=0>, or mute the thread<https://na01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Fnotifications%2Funsubscribe-auth%2FAj0RizznzcCphH-HJ9Q8uXvndQ4Lsg9Oks5thE43gaJpZM4Sw28q&data=01%7C01%7Ccramer%40unr.edu%7C54d34feceb114e30a61b08d5905c7a7b%7C523b4bfc0ebd4c03b2b96f6a17fd31d8%7C1&sdata=7DLxrFx74WqeN71%2Bs5cfSxEA1NRxj%2F7uqvp9SrGgjck%3D&reserved=0>.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/209#issuecomment-375513800:1574,test,tested,1574,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/209#issuecomment-375513800,1,['test'],['tested']
Testability,"ext+0x475): undefined reference to `nghttp2_version'; /usr/bin/ld: /usr/lib/x86_64-linux-gnu/libcurl.a(libcurl_gnutls_la-libssh2.o): in function `ssh_attach':; (.text+0x3e1): undefined reference to `libssh2_session_abstract'; /usr/bin/ld: /usr/lib/x86_64-linux-gnu/libcurl.a(libcurl_gnutls_la-libssh2.o): in function `ssh_statemach_act':; (.text+0x4b1): undefined reference to `libssh2_session_set_blocking'; /usr/bin/ld: (.text+0x4fb): undefined reference to `libssh2_session_handshake'; /usr/bin/ld: (.text+0x58d): undefined reference to `libssh2_hostkey_hash'; /usr/bin/ld: (.text+0x6a0): undefined reference to `libssh2_hostkey_hash'; /usr/bin/ld: (.text+0x75d): undefined reference to `libssh2_knownhost_free'; ... So somehow this does not build - but I have the impression that the linker issues are caused by some missing CMAKE options (as well as using the build directory). Thus I used the cmake command line as its used in the Debian packaging:. $ docker pull debian:testing; $ docker run -it debian:testing; $ echo ""deb-src http://deb.debian.org/debian unstable main"" > /etc/apt/sources.list.d/10-debsrc.list; $ apt update; $ apt upgrade; $ apt build-dep salmon; $ wget https://github.com/COMBINE-lab/salmon/archive/refs/tags/v1.10.0.tar.gz; $ tar xaf v1.10.0.tar.gz; $ cd salmon-1.10.0; $ cmake -DCMAKE_BUILD_TYPE=Release -DUSE_SHARED_LIBS=TRUE -DBZIP2_LIBRARIES=-lbz2 -DBZIP2_INCLUDE_DIR=/usr/include -DLIBLZMA_INCLUDE_DIR=/usr/include/ -DLIBLZMA_LIBRARY=lzma -DCMAKE_MODULE_PATH=/usr/share/cmake/Modules -DTBB_WILL_RECONFIGURE=FALSE -DBOOST_WILL_RECONFIGURE=FALSE; $ make; $ tar xaf sample_data.tgz; # src/salmon index -t sample_data/transcripts.fasta -i sample_salmon_quasi_index; Version Info: This is the most recent version of salmon.; index [""sample_salmon_quasi_index""] did not previously exist . . . creating it; [2023-03-10 11:56:01.434] [jLog] [warning] The salmon index is being built without any decoy sequences. It is recommended that decoy sequence (either computed auxiliar",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463708855:3125,test,testing,3125,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463708855,2,['test'],['testing']
Testability,"h read, the length of each observed fragment, etc.). That information goes away when the reads are summarized into range-factorized equivalence classes. Moreover, some of the model parameters learned during the online phase will depend (in their details) on the order in which observations are made. Ostensibly, observing the same data in the same order **and issuing updates to shared model parameters from worker threads in the same order** should result in identical values, however this has never been tested and was never a design goal. The reason for this is that differences between runs are within the bounds of the inherent inferential uncertainty of the estimated parameters anyway. That is, if one is relying on a specific value at a level of precision such that a different run of salmon would produce a value different enough to change a downstream analysis, then one is imparting more precision on the estimates than they can provide. Other methods that produce identical results between runs for these values may produce the same output, but the accuracy of the output at that level shouldn't be trusted in this case. The uncertainty of the parameter estimates can be evaluated based on the Gibb samples (or bootstrap replicates) that salmon computes. Of course, the small differences between runs rarely lead to differences in downstream analysis (almost certainly at the gene level and also at the transcript level if you use a differential testing method that is aware of inferential uncertainty). On the other hand, if you are in need of something that produces identical output between runs (but that still also lets you assess uncertainty), then you can give [piscem](https://github.com/COMBINE-lab/piscem) => [piscem-infer](https://github.com/COMBINE-lab/piscem-infer) a try. That tool already works well, but it is in active development and we'd certainly be happy to help build features that you and others might find useful, and would be happy to chat about that if you like.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/102#issuecomment-2159300538:1936,test,testing,1936,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/102#issuecomment-2159300538,2,['test'],['testing']
Testability,ha ... that log isn't particularly interesting --- what happens if you run `./src/unitTests` from the build directory?,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/229#issuecomment-393687065:12,log,log,12,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/229#issuecomment-393687065,1,['log'],['log']
Testability,"hello! have you by any chance figured it out? I have quite similiar problem. . I am running salmon v.1.1.0 on my ubuntu machine with 128GB of RAM. I set the limit for vitrual memory at ~75GB to not overload the system:. ```bash; ○ → ulimit -a; core file size (blocks, -c) 0; data seg size (kbytes, -d) unlimited; scheduling priority (-e) 0; file size (blocks, -f) unlimited; pending signals (-i) 514510; max locked memory (kbytes, -l) 65536; max memory size (kbytes, -m) unlimited; open files (-n) 1024; pipe size (512 bytes, -p) 8; POSIX message queues (bytes, -q) 819200; real-time priority (-r) 0; stack size (kbytes, -s) 8192; cpu time (seconds, -t) unlimited; max user processes (-u) 514510; virtual memory (kbytes, -v) 75331648; file locks (-x) unlimited; ```. I am building the index with the following command:. ```bash; salmon index \; -t /mnt/rescomp/ref/hg38/gentrome.fa.gz \; -i /mnt/rescomp/ref/hg38/salmon_index -k 31 \; --decoys /mnt/rescomp/ref/hg38/decoys.txt \; --threads 16 \; --gencode |& tee logs/salmon_index.log; ```. gentrome is created based on the gencode transcriptome (v33) and genome primary algnment sequence (GRCh38.p13). [salmon_index.log](https://github.com/COMBINE-lab/salmon/files/4392725/salmon_index.log). The output directory:; ```; ○ → ll /mnt/rescomp/ref/hg38/salmon_index; total 7.9G; drwxr-sr-x 1 37304 723 4.0K Mar 27 01:36 ./; drwxr-sr-x 1 37304 723 4.0K Mar 26 22:13 ../; -rw-r--r-- 1 37304 723 888K Mar 27 00:32 complete_ref_lens.bin; -rw-r--r-- 1 37304 723 31K Mar 27 00:27 duplicate_clusters.tsv; -rw-r--r-- 1 37304 723 674M Mar 27 01:46 path.bin; -rw-r--r-- 1 37304 723 55 Mar 27 01:46 pre_indexing.log; -rw-r--r-- 1 37304 723 40K Mar 27 01:46 ref_indexing.log; -rw-r--r-- 1 37304 723 3.3G Mar 27 00:32 ref_k31_fixed.fa; -rw-r--r-- 1 37304 723 703 Mar 27 00:32 ref_sigs.json; -rw-r--r-- 1 37304 723 4.1G Mar 27 01:36 tmp_dbg.bin; ```; I know for a fact that the memory usage did not go over 16GB. Any hints how to proceed?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/441#issuecomment-604919589:1013,log,logs,1013,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/441#issuecomment-604919589,6,['log'],"['log', 'logs']"
Testability,"hi @jma1991 ,. Thanks for reaching out. You may have already noticed it but may I ask do you expect such a low number of read mapping ? Alevin is logging only 3% of the reads as mapped.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/647#issuecomment-821477730:146,log,logging,146,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/647#issuecomment-821477730,1,['log'],['logging']
Testability,"ho ""User: ${USER}""; echo ""Job id: ${JOB_ID}""; echo ""Job name: ${JOB_NAME}""; echo ""Hostname: ${HOSTNAME}""; echo ""Task id: ${TASK_ID}"". FILE1=$(awk 'BEGIN {FS=""\t""} {print $1}' /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk ""NR==${SGE_TASK_ID}""); if [ TRUE == ""TRUE"" ] ; then; FILE2=$(awk 'BEGIN {FS=""\t""} {print $3}' /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk ""NR==${SGE_TASK_ID}""); fi; ID=$(cat /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk '{print $NF}' | awk ""NR==${SGE_TASK_ID}""). mkdir -p /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test4/${ID}. /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon quant 	-i /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts -p 16 -l ISR 	-1 ${FILE1} -2 ${FILE2} 	-o /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test4/${ID}. echo ""**** Job ends ****""; date; ```. ### Example log file. ```; **** Job starts ****; Wed Mar 29 14:53:43 EDT 2017; **** JHPCE info ****; User: lcollado; Job id: 110316; Job name: step6-salmon_test4.gsk_phaseII; Hostname: compute-067; Task id: ; Version Info: This is the most recent version of Salmon.; ### salmon (mapping-based) v0.8.2; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts }; ### [ threads ] => { 16 }; ### [ libType ] => { ISR }; ### [ mates1 ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/merged_fastq/R10001_D2B1WACXX.fastq.gz }; ### [ mates2 ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/merged_fastq/R10001_D2B1WACXX_read2.fastq.gz }; ### [ output ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test4/R10001_D2B1WACXX }; Logs will be written to /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test4/R10001_D2B1WACXX/logs; [1m[2017-03-29 14:56:39.675] [joi",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-290516965:5177,log,log,5177,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-290516965,1,['log'],['log']
Testability,"ily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon quant -i /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts -p 16 -l ISR -1 ${FILE1} -2 ${FILE2} -o /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test4/${ID}; **** Job ends ****; Wed Mar 29 14:58:05 EDT 2017. ```. ### SGE email example info. ```; Job-array task 110316.1 (step6-salmon_test4.gsk_phaseII) Complete; User = lcollado; Queue = shared.q@compute-067.cm.cluster; Host = compute-067.cm.cluster; Start Time = 03/29/2017 14:53:42; End Time = 03/29/2017 14:58:05; User Time = 00:00:00; System Time = 00:05:39; Wallclock Time = 00:04:23; CPU = 00:05:39; Max vmem = 24.202G; Exit Status = 0; ```. Note that in this case, it didn't read the maximum memory requested (16 * 3 = 48 GB). ## Large memory, p 1. ### Bash. ```bash; #!/bin/bash; #$ -cwd; #$ -l mem_free=80G,h_vmem=90G,h_fsize=100G; #$ -N step6-salmon_test5.gsk_phaseII; #$ -pe local 1; #$ -o ./logs/salmon_test5.$TASK_ID.txt; #$ -e ./logs/salmon_test5.$TASK_ID.txt; #$ -t 1-3; #$ -hold_jid pipeline_setup,step4-featCounts-alzheimer.gsk_phaseII; #$ -m e; echo ""**** Job starts ****""; date. echo ""**** JHPCE info ****""; echo ""User: ${USER}""; echo ""Job id: ${JOB_ID}""; echo ""Job name: ${JOB_NAME}""; echo ""Hostname: ${HOSTNAME}""; echo ""Task id: ${TASK_ID}"". FILE1=$(awk 'BEGIN {FS=""\t""} {print $1}' /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk ""NR==${SGE_TASK_ID}""); if [ TRUE == ""TRUE"" ] ; then; FILE2=$(awk 'BEGIN {FS=""\t""} {print $3}' /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk ""NR==${SGE_TASK_ID}""); fi; ID=$(cat /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk '{print $NF}' | awk ""NR==${SGE_TASK_ID}""). mkdir -p /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test5/${ID}. /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon quant 	-i /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-290516965:7456,log,logs,7456,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-290516965,1,['log'],['logs']
Testability,"iple loci |	1.20%; Number of reads mapped to too many loci |	565; % of reads mapped to too many loci |	0.00%; UNMAPPED READS:; Number of reads unmapped: too many mismatches |	0; % of reads unmapped: too many mismatches |	0.00%; Number of reads unmapped: too short |	47533174; % of reads unmapped: too short |	55.56%; Number of reads unmapped: other |	4006; % of reads unmapped: other |	0.00%; CHIMERIC READS:; Number of chimeric reads |	0; % of chimeric reads |	0.00%. ```. I filtered it by samtools -f 2 -F 3840 . and Salmon gave me this result which is still very weak: 24323638 counts. So I decided to reduce the parameters as indicated in this link: https://github.com/alexdobin/STAR/issues/169; Because I trimmed my sequence and some can have a size between 100pb -150pb. ` ""STAR --runThreadN {threads} --runMode alignReads --genomeDir {input.ref} --readFilesIn {input.fq1} {input.fq2} --readFilesCommand zcat --outSAMtype BAM Unsorted SortedByCoordinate --outFilterScoreMinOverLread 0 --outFilterMatchNminOverLread 0 --quantMode TranscriptomeSAM GeneCounts --outFileNamePrefix {output} --outStd Log {log} ""`. I got this final.out:; ```; Started job on |	Jul 05 14:25:19; Started mapping on |	Jul 05 14:25:23; Finished on |	Jul 05 16:37:44; Mapping speed, Million of reads per hour |	38.78. Number of input reads |	85547657; Average input read length |	298; UNIQUE READS:; Uniquely mapped reads number |	70090369; Uniquely mapped reads % |	81.93%; Average mapped length |	191.51; Number of splices: Total |	1068826; Number of splices: Annotated (sjdb) |	0; Number of splices: GT/AG |	470490; Number of splices: GC/AG |	43525; Number of splices: AT/AC |	15865; Number of splices: Non-canonical |	538946; Mismatch rate per base, % |	1.29%; Deletion rate per base |	0.03%; Deletion average length |	4.76; Insertion rate per base |	0.03%; Insertion average length |	5.23; MULTI-MAPPING READS:; Number of reads mapped to multiple loci |	15205492; % of reads mapped to multiple loci |	17.77%; Number o",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/676#issuecomment-874540664:2363,Log,Log,2363,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/676#issuecomment-874540664,3,"['Log', 'log']","['Log', 'log']"
Testability,"itional alignment algorithms like Bowtie2 and BWA-MEM with respect to both sensitivity and specificity. Here, you are likely seeing a manifestation of the former. Specifically, greedy behavior can lead to spurious matches. Many of these spurious matches are filtered out when applying a consensus mechanism to the series of matches produced by a read; however, this can result in the read going unmapped. We have noticed this behavior where spurious matches can ""mask"" better overall mappings, and we have developed an algorithm to overcome these limitations (called selective-alignment). This is currently implemented in [this branch](https://github.com/COMBINE-lab/salmon/tree/rescue-orphan) of the Salmon repo (if you want to test it out and have trouble building, we can build you a linux executable). This algorithm explores more potential mappings and then applies a fast algorithm for filtering potentially poor ones. In our benchmarks, it exhibits sensitivity and specificity very close to Bowtie2 (which is among the best of the alignment-based methods we considered). Also, I will note that, though the speed and statistical optimization procedures used in fast transcript abundance estimation tools make them a potentially desirable choice for microbiomic / metagenomic abundance estimation, their indices are typically optimized for speed and not size. For small numbers of bacterial species this can be okay, but if one wishes to index large collections of species, the memory usage can become a problem. To this end, we have developed a new indexing scheme (software [here](https://github.com/COMBINE-lab/pufferfish), slightly out-of-date pre-print [here](https://www.biorxiv.org/content/early/2017/09/21/191874)). That code already implements a tool for taxonomic read assignment (a la the excellent [Kraken](https://github.com/DerrickWood/kraken)), but not yet abundance estimation (that is coming soon). So, depending on how much you want to scale up, you might want to keep an eye on",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/196#issuecomment-365337297:1244,benchmark,benchmarks,1244,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/196#issuecomment-365337297,1,['benchmark'],['benchmarks']
Testability,"k_phaseII; #$ -m e; echo ""**** Job starts ****""; date. echo ""**** JHPCE info ****""; echo ""User: ${USER}""; echo ""Job id: ${JOB_ID}""; echo ""Job name: ${JOB_NAME}""; echo ""Hostname: ${HOSTNAME}""; echo ""Task id: ${TASK_ID}"". FILE1=$(awk 'BEGIN {FS=""\t""} {print $1}' /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk ""NR==${SGE_TASK_ID}""); if [ TRUE == ""TRUE"" ] ; then; FILE2=$(awk 'BEGIN {FS=""\t""} {print $3}' /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk ""NR==${SGE_TASK_ID}""); fi; ID=$(cat /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk '{print $NF}' | awk ""NR==${SGE_TASK_ID}""). mkdir -p /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/${ID}. strace /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon quant 	-i /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts -p 1 -l ISR 	-1 ${FILE1} -2 ${FILE2} 	-o /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/${ID} 2> logs/strace_${SGE_TASK_ID}.txt. echo ""**** Job ends ****""; date; ```. This requests SGE 2 cores with a total free memory of 2 * 7 = 14 GB and a maximum memory of 16 GB. This is the `strace` output for task 1:. ```; execve(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon"", [""/dcl01/lieber/ajaffe/Emily/RNAse""..., ""quant"", ""-i"", ""/dcl01/lieber/ajaffe/Emily/RNAse""..., ""-p"", ""1"", ""-l"", ""ISR"", ""-1"", ""/dcl01/lieber/ajaffe/lab/libd_al""..., ""-2"", ""/dcl01/lieber/ajaffe/lab/libd_al""..., ""-o"", ""/dcl01/lieber/ajaffe/lab/libd_al""...], [/* 107 vars */]) = 0; brk(0) = 0xc2c000; mmap(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7fffbfffd000; readlink(""/proc/self/exe"", ""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon"", 4096) = 88; access(""/etc/ld.so.preload"", R_OK) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipel",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:3629,log,logs,3629,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,1,['log'],['logs']
Testability,"lib/libtbbmalloc.so.2; -- Installing: /salmon-0.10.2/lib/libtbb.so.2; -- Installing: /salmon-0.10.2/lib/pkgconfig; -- Installing: /salmon-0.10.2/lib/libtbbmalloc_proxy.so.2; -- Installing: /salmon-0.10.2/bin/salmon; -- Installing: /salmon-0.10.2/lib/libsalmon_core.a. Installation complete. Please ensure the following paths are set properly.; ==========================================================================; Please add /salmon-0.10.2/bin to your PATH; Please add /salmon-0.10.2/lib to your LD_LIBRARY_PATH; ==========================================================================; root@e08cc9670e4a:/salmon-0.10.2/build# make test; Running tests...; Test project /salmon-0.10.2/build; Start 1: unit_tests; 1/3 Test #1: unit_tests ....................... Passed 0.17 sec; Start 2: salmon_read_test_fmd; 2/3 Test #2: salmon_read_test_fmd ............. Passed 1.78 sec; Start 3: salmon_read_test_quasi; 3/3 Test #3: salmon_read_test_quasi ........... Passed 1.59 sec. 100% tests passed, 0 tests failed out of 3. Total Test time (real) = 3.54 sec; root@e08cc9670e4a:/salmon-0.10.2/build# lsb_release -a; LSB Version: core-9.20160110ubuntu0.2-amd64:core-9.20160110ubuntu0.2-noarch:security-9.20160110ubuntu0.2-amd64:security-9.20160110ubuntu0.2-noarch; Distributor ID: Ubuntu; Description: Ubuntu 16.04.4 LTS; Release: 16.04; Codename: xenial; ```. I built with:. `$ cmake -DFETCH_BOOST=TRUE .. && make install && make test`. I can also install the boost via apt and see if that makes a difference (though I expect not since it looked like TBB was the issue, and I let cmake install that). We can also check our compiler versions, perhaps. I have : . ```; root@e08cc9670e4a:/salmon-0.10.2/build# g++ --version; g++ (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609; Copyright (C) 2015 Free Software Foundation, Inc.; This is free software; see the source for copying conditions. There is NO; warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. root@e08cc9670e4a:/salmon",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/250#issuecomment-404306268:2207,test,tests,2207,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/250#issuecomment-404306268,2,['test'],['tests']
Testability,"libthread_db.so.1"".; warning: File ""/u/user/local/lib64/libstdc++.so.6.0.21-gdb.py"" auto-loading has been declined by your `auto-load safe; -path' set to ""$debugdir:$datadir/auto-load"".; To enable execution of this file add; add-auto-load-safe-path /u/user/local/lib64/libstdc++.so.6.0.21-gdb.py; line to your configuration file ""/u/user/.gdbinit"".; To completely disable this security protection add; set auto-load safe-path /; line to your configuration file ""/u/user/.gdbinit"".; For more information about this security protection see the; ""Auto-loading safe path"" section in the GDB manual. E.g., run from the shell:; info ""(gdb)Auto-loading safe path""; [New Thread 0x7fff7dbff700 (LWP 21437)]; [Thread 0x7fff7dbff700 (LWP 21437) exited]; Version Info: Could not resolve upgrade information in the alotted time.; Check for upgrades manually at https://combine-lab.github.io/salmon; [New Thread 0x7ffefcfff700 (LWP 21653)]; Logs will be written to BM_1/alevin/logs; [New Thread 0x7ffe7cffe700 (LWP 21654)]; [New Thread 0x7ffdfcffd700 (LWP 21655)]; [New Thread 0x7ffd7cffc700 (LWP 21656)]; ### salmon (single-cell-based) v0.10.3; ### [ program ] => salmon; ### [ command ] => alevin; ### [ libType ] => { ISR }; ### [ chromium ] => { }; ### [ threads ] => { 4 }; ### [ output ] => { BM_1/alevin }; ### [ mates1 ] => { ./BM_1/run1/bm_S10_L001_R1_001.fastq.gz }; ### [ mates2 ] => { ./BM_1/run1/bm_S10_L001_R2_001.fastq.gz }; ### [ maxHashResizeThreads ] => { 2 }; ### [ index ] => { /u/user/ref/cellranger/salmon/transcripts_index }; ### [ tgMap ] => { tx2gene.txt }. [2018-06-10 16:07:09.798] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [New Thread 0x7ffcfcffb700 (LWP 21657)]; [Thread 0x7ffcfcffb700 (LWP 21657) exited]; [New Thread 0x7ffc7cffa700 (LWP 21658)]; [New Thread 0x7ffbfcff9700 (LWP 21659)]o[Thread 0x7ffc7cffa700 (LWP 21658) exited]; [Thread 0x7ffbfcff9700 (LWP 21659) exited]; [New Thread 0x7ffb7cff8700 (LWP 21660)]; [Thr",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-396078627:2556,Log,Logs,2556,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-396078627,2,"['Log', 'log']","['Logs', 'logs']"
Testability,"lmon/lib/libtbbmalloc.so; -- Installing: /salmon/lib/libtbbmalloc.so.2; -- Installing: /salmon/lib/libtbbmalloc.so.2.5; -- Installing: /salmon/lib/libtbbmalloc_proxy.so; -- Installing: /salmon/lib/libtbbmalloc_proxy.so.2; -- Installing: /salmon/lib/libtbbmalloc_proxy.so.2.5; -- Installing: /salmon/bin/salmon; -- Installing: /salmon/lib/libsalmon_core.a. Installation complete. Please ensure the following paths are set properly.; ==========================================================================; Please add /salmon/bin to your PATH; Please add /salmon/lib to your LD_LIBRARY_PATH; ==========================================================================; root@fd877e359439:/salmon/build# make test; Running tests...; Test project /salmon/build; Start 1: unit_tests; 1/2 Test #1: unit_tests ....................... Passed 0.37 sec; Start 2: salmon_read_test_quasi; 2/2 Test #2: salmon_read_test_quasi ........... Passed 1.80 sec. 100% tests passed, 0 tests failed out of 2. Total Test time (real) = 2.17 sec; ```. The `make test` command itself runs the test the builds the index and maps the reads against it. Either way, I can do that explicitly too (from within build):. ```; $ ./src/salmon index -t ../sample_data/transcripts.fasta -i sample_idx; ```. returns succesfully with a built index. ```; ...; [2023-03-10 05:51:33.748] [puff::index::jointLog] [info] Done wrapping the rank vector with a rank9sel structure.; [2023-03-10 05:51:33.748] [puff::index::jointLog] [info] contig count for validation: 23; [2023-03-10 05:51:33.748] [puff::index::jointLog] [info] Total # of Contigs : 23; [2023-03-10 05:51:33.748] [puff::index::jointLog] [info] Total # of numerical Contigs : 23; [2023-03-10 05:51:33.748] [puff::index::jointLog] [info] Total # of contig vec entries: 36; [2023-03-10 05:51:33.748] [puff::index::jointLog] [info] bits per offset entry 6; [2023-03-10 05:51:33.748] [puff::index::jointLog] [info] Done constructing the contig vector. 24; [2023-03-10 05:51:33.748] [puf",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463312554:2973,Test,Test,2973,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463312554,1,['Test'],['Test']
Testability,"lmonQuantifyAlignments.cpp:39:; /usr/local/salmon-0.10.2/include/eigen3/Eigen/src/Core/AssignEvaluator.h:90:50: warning: enum constant in boolean context [-Wint-in-bool-context]; MaySliceVectorize = bool(MightVectorize) && bool(DstHasDirectAccess); ^~~~~~~~~~~~~~~~~~~~~~~~; At global scope:; cc1plus: warning: unrecognized command line option ‘-Wno-unused-local-typedef’; cc1plus: warning: unrecognized command line option ‘-Wno-unused-local-typedef’; make[2]: *** [src/CMakeFiles/salmon.dir/SalmonQuantifyAlignments.cpp.o] Error 1; make[1]: *** [src/CMakeFiles/salmon.dir/all] Error 2; make: *** [all] Error 2; ```. I also tried installing it through bioconda. Apparently, it installs it correctly, but when I try to use Trinity (I'm installing Salmon as a Trinity requirement) this is what happens: . ```; salmon: /opt/conda/conda-bld/salmon_1528409373758/work/salmon-0.10.2/include/eigen3/Eigen/src/Core/util/Memory.h:161: void* Eigen::internal::aligned_malloc(std::size_t): Assertion `(size<16 || (std::size_t(result)%16)==0) && ""System's malloc returned an unaligned pointer. Compile with EIGEN_MALLOC_ALREADY_ALIGNED=0 to fallback to handmade alignd memory allocator.""' failed.; Error, cmd:; salmon --no-version-check quant -i /home/federicoplazzi/test_Trinity_Assembly/trinity_out_dir/read_partitions/Fb_0/CBin_0/c30.trinity.reads.fa.out/Trinity.fasta.tmp.salmon.idx -l U -r /home/federicoplazzi/test_Trinity_Assembly/trinity_out_dir/read_partitions/Fb_0/CBin_0/c30.trinity.reads.fa.out/single.fa -o salmon_outdir -p 1 --minAssignedFrags 1; died with ret (6) at /usr/local/trinityrnaseq-Trinity-v2.6.6/util/support_scripts/../../PerlLib/Process_cmd.pm line 19.; Process_cmd::process_cmd(""salmon --no-version-check quant -i /home/federicoplazzi/test_""...) called at /usr/local/trinityrnaseq-Trinity-v2.6.6/util/support_scripts/salmon_runner.pl line 26; Trinity run failed. Must investigate error above.; warning, cmd: /usr/local/trinityrnaseq-Trinity-v2.6.6/util/support_scripts/../../Trinity -",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/235#issuecomment-398081403:1499,Assert,Assertion,1499,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/235#issuecomment-398081403,1,['Assert'],['Assertion']
Testability,ls -l /work/yu_liu/resource/salmon_gencodev28_index/; total 2234181; -rw-r--r-- 1 yu_liu data-sci 179889 Jul 13 19:43 duplicate_clusters.tsv; -rw-r--r-- 1 yu_liu data-sci 673607680 Jul 13 19:47 hash.bin; -rw-r--r-- 1 yu_liu data-sci 0 Jul 13 19:47 header.json; -rw-r--r-- 1 yu_liu data-sci 0 Jul 13 19:47 indexing.log; -rw-r--r-- 1 yu_liu data-sci 8192 Jul 13 19:47 quasi_index.log; -rw-r--r-- 1 yu_liu data-sci 0 Jul 13 19:47 refInfo.json; -rw-r--r-- 1 yu_liu data-sci 38621520 Jul 13 19:43 rsd.bin; -rw-r--r-- 1 yu_liu data-sci 1235888364 Jul 13 19:44 sa.bin; -rw-r--r-- 1 yu_liu data-sci 336807483 Jul 13 19:43 txpInfo.bin; -rw-r--r-- 1 yu_liu data-sci 0 Jul 13 19:47 versionInfo.json,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/251#issuecomment-404957888:314,log,log,314,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/251#issuecomment-404957888,2,['log'],['log']
Testability,"lt still segfaults. It still needed an edit of the CMakeLists.txt file. Still, for future reference:. ```; pversion=1.2.1; package=salmon; TOPDIR=/usr/common/modules/el8/x86_64/software/${package}/${pversion}-CentOS-vanilla; wget https://github.com/COMBINE-lab/salmon/archive/v1.2.1.tar.gz; gunzip -c v1.2.1.tar.gz | tar -xf -; /bin/rm v1.2.1.tar.gz; cd ${package}-${pversion}; mv CMakeLists.txt CMakeLists.txt.dist; cat >mypatch <<'EOD'; --- CMakeLists.txt.dist	2020-04-21 22:31:07.000000000 -0700; +++ CMakeLists.txt	2020-06-09 14:55:02.733885772 -0700; @@ -419,6 +419,10 @@; find_package(Boost 1.59.0 COMPONENTS iostreams filesystem system timer chrono program_options); message(""BOOST_INCLUDEDIR = ${BOOST_INCLUDEDIR}""); message(""BOOST_LIBRARYDIR = ${BOOST_LIBRARYDIR}""); +message(""Forcing Boost_FOUND to TRUE""); +set(Boost_FOUND TRUE); +set(Boost_LIBRARY_DIRS ""/usr/lib64/boost169""); +set(Boost_LIBRARIES -lboost_iostreams -lboost_filesystem -lboost_system -lboost_timer -lboost_chrono -lboost_program_options); message(""Boost_FOUND = ${Boost_FOUND}""); endif(); ; EOD; patch -p0 <mypatch; module load cmake; module load io_lib; module load libgff; module load libtbb; mkdir build; cd build; export CFLAGS=""-g -O0""; export CXXFLAGS=""-g -O0""; cmake \; -DCMAKE_INSTALL_PREFIX=$TOPDIR \; -DSTADEN_ROOT=$ROOT_IO_LIB \; -DGFF_ROOT=$ROOT_LIBGFF \; -DTBB_ROOT=$ROOT_LIBTBB \; -DCMAKE_VERBOSE_MAKEFILE:BOOL=ON \; -DBOOST_LIBRARYDIR=/usr/lib64/boost169 \; -DBOOST_INCLUDEDIR=/usr/include/boost169 \; -DBoost_NO_SYSTEM_PATHS=ON \; .. 2>&1 | tee cmake_2020_06_09.log; make -j 4 2>&1 | tee build_2020_06_09.log. ```. Since it was compiled ""-g -O0"" this time it was easier to step through it. Well, somewhat. In Salmon.cpp line 195 is the last place a break point works. If one is set for 197 it segfaults before reaching it. Line 195 is:. `	 po::store(parsed, vm);; `; I tried briefly to trace inward from there but couldn't make heads or tails of the path it was taking through an endless series of headers.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641612831:1604,log,log,1604,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641612831,2,['log'],['log']
Testability,"n, my reading is that the command does not include anything to link boost libraries. So telling cmake where the libraries are, where the include files are, and that boost was found was not sufficient. There must be some other set of symbols which need to be defined. `/opt/rh/devtoolset-4/root/usr/bin/c++ -pthread -ftree-vectorize -funroll-loops -fPIC -fomit-frame-pointer -O3 -DRAPMAP_SALMON_SUPPORT -DHAVE_ANSI_TERM -DHAVE_SSTREAM -Wall -Wno-unknown-pragmas -Wno-reorder -Wno-unused-variable -std=c++11 -Wreturn-type -Werror=return-type -Wno-unused-function -Wno-unused-local-typedef -static-libstdc++ -Wno-unused-local-typedefs -pthread -ftree-vectorize -funroll-loops -fPIC -fomit-frame-pointer -O3 -DRAPMAP_SALMON_SUPPORT -DHAVE_ANSI_TERM -DHAVE_SSTREAM -Wall -Wno-unknown-pragmas -Wno-reorder -Wno-unused-variable -std=c++11 -Wreturn-type -Werror=return-type -Wno-unused-function -Wno-unused-local-typedef -static-libstdc++ -Wno-unused-local-typedefs -rdynamic CMakeFiles/unitTests.dir/__/tests/UnitTests.cpp.o CMakeFiles/unitTests.dir/FragmentLengthDistribution.cpp.o CMakeFiles/unitTests.dir/__/external/install/src/rapmap/rank9b.cpp.o CMakeFiles/unitTests.dir/__/external/install/src/rapmap/bit_array.c.o -o unitTests -L/home/mathog/src/salmon/lib -L/home/mathog/src/salmon/external/install/lib -Wl,-rpath,""\$ORIGIN/../lib:\$ORIGIN/../../lib:\$ORIGIN/:\$ORIGIN/../../external/install/lib"" libsalmon_core.a libalevin_core.a -lgff -lpthread ../external/install/lib/libstaden-read.a -lz ../external/install/lib/libdivsufsort.a ../external/install/lib/libdivsufsort64.a ../external/install/lib/libbwa.a -lm -llzma -lbz2 -ltbb -lgomp -lrt ../external/install/lib/libjemalloc.a -lrt -ldl ../external/install/lib/libjemalloc.a -ldl`. Oh, I also had to update automake and autoconf because the 2 year old versions on this system were not new enough. Is there a static binary version of salmon available for download, Linux 64 bit? It looks like the default links are that way anyway, and that would ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/236#issuecomment-397025719:2673,test,tests,2673,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/236#issuecomment-397025719,1,['test'],['tests']
Testability,"nad-1_S120_L006_R2_001.qc.fq.gz; lightreceptor-2_S115_L006_R2_001.qc.fq.gz; mgonad-2_S121_L005_R2_001.qc.fq.gz mgonad-1_S120_L005_R2_001.qc.fq.gz; lightreceptor-2_S115_L005_R2_001.qc.fq.gz; lightreceptor-1_S114_L005_R2_001.qc.fq.gz; mgonad-2_S121_L004_R2_001.qc.fq.gz mgonad-1_S120_L004_R2_001.qc.fq.gz; lightreceptor-2_S115_L004_R2_001.qc.fq.gz; lightreceptor-1_S114_L004_R2_001.qc.fq.gz ${i} -o ${i}_quant --seqBias; --gcBias --validateMappings; done```. And here is my output from salmon.log. [2019-07-30 10:40:14.624] [jointLog] [info] Fragment incompatibility prior; below threshold. Incompatible fragments will be ignored.; [2019-07-30 10:40:14.624] [jointLog] [error] You passed paired-end files to; salmon, but you passed 12 files to --mates1 and 13 files to --mates2. You; must pass the same number of files to both flags. Thank you in advance for any tips you may have for me. Sara. On Tue, Jul 30, 2019 at 10:30 AM Sara Boles <seboles@ucdavis.edu> wrote:. > Hi Avi,; >; > Here is the salmon log from one of my PE libraries. There are only 12; > libraries for each in the directory, which is why I got confused when it; > said 13. I will try putting in all of the file names and let you know how; > it goes. Thank you for all of your help.; >; > Sara; >; > [2019-07-29 15:58:39.034] [jointLog] [info] Fragment incompatibility prior; > below threshold. Incompatible fragments will be ignored.; > [2019-07-29 15:58:39.034] [jointLog] [info] Usage of --validateMappings; > implies use of minScoreFraction. Since not explicitly specified, it is; > being set to 0.65; > [2019-07-29 15:58:39.034] [jointLog] [info] Usage of --validateMappings,; > without --hardFilter implies use of range factorization.; > rangeFactorizationBins is being set to 4; > [2019-07-29 15:58:39.034] [jointLog] [info] Usage of --validateMappings; > implies a default consensus slack of 0.2. Setting consensusSlack to 0.2.; > [2019-07-29 15:58:39.034] [jointLog] [info] parsing read library format; > [2019-07-29 15:58:3",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/408#issuecomment-516521791:1959,log,log,1959,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/408#issuecomment-516521791,1,['log'],['log']
Testability,"ncreasing --maxNumBarcodes to 200000 results in no barcodes getting corrected? (See log for Run 2 below). What is the rationale for the current default of 100000?. That's again a great question. In short single-cell world is expanding rapidly and alevin was initially designed to work with 10x 3' data and some of the restriction are outdated with combinatorial indexing based multiplexed experiments. To be honest, 100k was just a random high enough number that was put down to throw away the obvious junk data. Having said that, you would notice that in both the logs you attached a significant fraction of barcodes are thrown away i.e., `Skipped 82268 barcodes due to No mapped read`, which is like ~82% of the 100k barcodes. Even if you include the 200k almost everything was thrown away, `[warning] Skipped 184123 barcodes due to No mapped read`. Although your point is important one why things are not getting sequence corrected with 200k, unfortunately I might have to do some more testing on that front to give more precise answer but in your case I'd advise keeping the default 100k bound, unless you are doing combinatorially-indexed data . > For the downstream analysis of such data, I usually work with both the read and UMI counts, but quants_mat.gz only contains the UMI counts. Can Alevin a produce a matrix of read counts as well. It would be a great feature to add. For now, what is easiest way to get the cell x feature matrix of read counts if I use the --dumpEq or --dumpBfh flags? Can tximport be used for this or do I need to use the Python parser first?. Congratulations on the awesome paper :). We were actually discussing yesterday about your paper and potentially modifying alevin to include model for correcting index-hoping, although it's still in discussion phase. To answer your question, thanks for the feature request, I can add that feature on the weekend if it's urgent. However, you can also generate that with the current version using the `--dumpBfh` flag and `bfh",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-639048052:1669,test,testing,1669,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-639048052,2,['test'],['testing']
Testability,"ndex_test/salmon_0.8.2_index_gencode.v25.transcripts }; ### [ threads ] => { 1 }; ### [ libType ] => { ISR }; ### [ mates1 ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/merged_fastq/R10001_D2B1WACXX.fastq.gz }; ### [ mates2 ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/merged_fastq/R10001_D2B1WACXX_read2.fastq.gz }; ### [ output ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10001_D2B1WACXX }; ) = 594; stat(""/etc/localtime"", {st_mode=S_IFREG|0644, st_size=3519, ...}) = 0; stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10001_D2B1WACXX"", {st_mode=S_IFDIR|S_ISGID|0755, st_size=512, ...}) = 0; stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10001_D2B1WACXX"", {st_mode=S_IFDIR|S_ISGID|0755, st_size=512, ...}) = 0; stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10001_D2B1WACXX/logs"", 0x7fffffff1e50) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10001_D2B1WACXX/logs"", 0x7fffffff1e60) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10001_D2B1WACXX"", {st_mode=S_IFDIR|S_ISGID|0755, st_size=512, ...}) = 0; mkdir(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10001_D2B1WACXX/logs"", 0777) = 0; write(2, ""Logs will be written to "", 24Logs will be written to ) = 24; write(2, ""/dcl01/lieber/ajaffe/lab/libd_al""..., 81/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10001_D2B1WACXX/logs) = 81; write(2, ""\n"", 1; ) = 1; stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10001_D2B1WACXX/libParams"", 0x7fffffff1e50) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10001_D2B1WACXX/libParams"", 0x7fffffff1e60) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10001_D2B1WACXX"", {st_mode=S_IFDIR|S_ISGID|0755, st_size=512, ...}",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:30299,log,logs,30299,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,2,['log'],['logs']
Testability,"ndex_test/salmon_0.8.2_index_gencode.v25.transcripts }; ### [ threads ] => { 1 }; ### [ libType ] => { ISR }; ### [ mates1 ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/merged_fastq/R10002_C29P7ACXX.fastq.gz }; ### [ mates2 ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/merged_fastq/R10002_C29P7ACXX_read2.fastq.gz }; ### [ output ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10002_C29P7ACXX }; ) = 594; stat(""/etc/localtime"", {st_mode=S_IFREG|0644, st_size=3519, ...}) = 0; stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10002_C29P7ACXX"", {st_mode=S_IFDIR|S_ISGID|0755, st_size=512, ...}) = 0; stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10002_C29P7ACXX"", {st_mode=S_IFDIR|S_ISGID|0755, st_size=512, ...}) = 0; stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10002_C29P7ACXX/logs"", 0x7fffffff1e50) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10002_C29P7ACXX/logs"", 0x7fffffff1e60) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10002_C29P7ACXX"", {st_mode=S_IFDIR|S_ISGID|0755, st_size=512, ...}) = 0; mkdir(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10002_C29P7ACXX/logs"", 0777) = 0; write(2, ""Logs will be written to "", 24Logs will be written to ) = 24; write(2, ""/dcl01/lieber/ajaffe/lab/libd_al""..., 81/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10002_C29P7ACXX/logs) = 81; write(2, ""\n"", 1; ) = 1; stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10002_C29P7ACXX/libParams"", 0x7fffffff1e50) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10002_C29P7ACXX/libParams"", 0x7fffffff1e60) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10002_C29P7ACXX"", {st_mode=S_IFDIR|S_ISGID|0755, st_size=512, ...}",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:147976,log,logs,147976,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,2,['log'],['logs']
Testability,"ng] If you wish to retain duplicate transcripts, please use the `--keepDuplicates` flag; [2019-10-04 10:37:22.318] [ff::console] [info] Replaced 1,775,734,603 non-ATCG nucleotides; [2019-10-04 10:37:22.318] [ff::console] [info] Clipped poly-A tails from 422 transcripts; wrote 593292 cleaned references; seqHash 256 : bd425816a78195ed31cf17ce9df99c2bf56bff98f0df5ace1e958b263d805390; seqHash 512 : 845b625de6f8f018796e464f7c49f6596d2b31b28a58771d56ece24b3d9cad98b8189572ff43d6a3eb8ef24b5d3bc5ac0f89845a57e3682498a56a1bc920e7b7; nameHash 256 : 3bd11eac1e6b05e93689676ca056c165e7c26723c4b137fd284bb8b40ef5df62; nameHash 512 : e68449cfd99f5968182735275b00779b8a396e413a3629beef933e51bd18902c821c26e2a5461c687d023ef85168e58d76bacd5fe1f0a3111bfccc34af9c4035; [2019-10-04 10:37:37.931] [console] [info] Filter size not provided; estimating from number of distinct k-mers; [2019-10-04 10:38:33.012] [console] [info] ntHll estimated 2765935300 distinct k-mers, setting filter size to 2^36; Threads = 8; Vertex length = 31; Hash functions = 5; Filter size = 68719476736; Capacity = 2; Files:; test_pufferfish_index/ref_k31_fixed.fa; --------------------------------------------------------------------------------; Round 0, 0:68719476736; Pass Filling Filtering; 1 385 3124; 2 1258 2; True junctions count = 5437144; False junctions count = 4410615; Hash table size = 9847759; Candidate marks count = 26276463; --------------------------------------------------------------------------------; Reallocating bifurcations time: 6; True marks count: 20290262; Edges construction time: 5004; --------------------------------------------------------------------------------; Distinct junctions = 5437144. approximateContigTotalLength: 1543877663; counters:; 49076 936 921 40; Exception : [std::bad_alloc]; ./testing/src/novartis-pisces/pisces/redist/salmon/bin/salmon index was invoked improperly.; For usage information, try ./testing/src/novartis-pisces/pisces/redist/salmon/bin/salmon index --help; Exiting.; ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/432#issuecomment-538547108:2016,test,testing,2016,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/432#issuecomment-538547108,2,['test'],['testing']
Testability,not sure what's the best way to share the 34G fastqs for your test.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/340#issuecomment-458713282:62,test,test,62,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/340#issuecomment-458713282,1,['test'],['test']
Testability,"nt:; read1 [SRR3212847.24133171] : no proper-pair; not mapped; matenot mapped. read2 : [SRR3212847.24133171] : proper-pair; mapped; matemapped. [2021-01-08 12:42:10.700] [jointLog] [warning] . WARNING: Detected suspicious pair --- ; The names are different:; read1 : SRR3212847.33911054; read2 : SRR3212847.30781941. Segmentation fault (core dumped); ```. ### 3. Sorting with `samtools sort -n`; ```; samtools sort \; -@ 40 \; -n \; -o SRR3212847.Aligned.SortedByName.bam \; SRR3212847.Aligned.SortedByCoord.bam. salmon quant \; -t mRNA.fasta \; -p 20 \; -l A \; -a SRR3212847.Aligned.SortedByName.bam \; -o SRR3212847.Aligned.SortedByName; ```. ```; Version Info: This is the most recent version of salmon.; # salmon (alignment-based) v1.4.0; # [ program ] => salmon ; # [ command ] => quant ; # [ targets ] => { mRNA.fasta }; # [ threads ] => { 20 }; # [ libType ] => { A }; # [ alignments ] => { SRR3212847.Aligned.SortedByName.bam }; # [ output ] => { SRR3212847.Aligned.SortedByName }; Logs will be written to SRR3212847.Aligned.SortedByName/logs; [2021-01-08 13:02:04.845] [jointLog] [info] setting maxHashResizeThreads to 20; [2021-01-08 13:02:04.845] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; Library format { type:paired end, relative orientation:inward, strandedness:unstranded }; [2021-01-08 13:02:04.878] [jointLog] [info] numQuantThreads = 14; parseThreads = 6; Checking that provided alignment files have consistent headers . . . done; Populating targets from aln = ""SRR3212847.Aligned.SortedByName.bam"", fasta = ""mRNA.fasta"" . . .done. processed 0 reads in current roundSegmentation fault (core dumped); ```; (Which is the same as the 1st error. Actually, each time I re-run those two errors switched.). I tried running Salmon on the sorted-by-coordinates bam, and it didn't fail:; ```; nohup salmon quant \; -t mRNA.fasta \; -p 20 \; -l A \; -a SRR3212847.Aligned.SortedByCoord.bam \; -o SRR3212847.Aligned.SortedByCoord",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/582#issuecomment-756727212:3520,Log,Logs,3520,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/582#issuecomment-756727212,1,['Log'],['Logs']
Testability,"o lieber_jaffe 6.2G Feb 20 12:39 merged_fastq/R10001_D2B1WACXX.fastq.gz; -rw-r--r-- 1 lcollado lieber_jaffe 6.3G Feb 20 12:40 merged_fastq/R10001_D2B1WACXX_read2.fastq.gz; -rw-r--r-- 1 lcollado lieber_jaffe 4.6G Feb 20 12:42 merged_fastq/R10002_C29P7ACXX.fastq.gz; -rw-r--r-- 1 lcollado lieber_jaffe 4.7G Feb 20 12:44 merged_fastq/R10002_C29P7ACXX_read2.fastq.gz; -rw-r--r-- 1 lcollado lieber_jaffe 7.1G Feb 20 12:47 merged_fastq/R10003_D19KGACXX.fastq.gz; -rw-r--r-- 1 lcollado lieber_jaffe 7.1G Feb 20 12:50 merged_fastq/R10003_D19KGACXX_read2.fastq.gz; ```. where R10001* is task 1, R10002* is task 2, R10003* is task 3. So it looks like at some point Salmon is asking for some memory based on the input data. ## Strace test with low memory (but above reported usage when requesting 90GB). Mark taught me about `strace` and we ran the following test:. ```bash; #!/bin/bash; #$ -cwd; #$ -pe local 2; #$ -l mem_free=7G,h_vmem=8G,h_fsize=100G; #$ -N step6-salmon_test11.gsk_phaseII; #$ -o ./logs/salmon_test11.$TASK_ID.txt; #$ -e ./logs/salmon_test11.$TASK_ID.txt; #$ -t 1-3; #$ -hold_jid pipeline_setup,step4-featCounts-alzheimer.gsk_phaseII; #$ -m e; echo ""**** Job starts ****""; date. echo ""**** JHPCE info ****""; echo ""User: ${USER}""; echo ""Job id: ${JOB_ID}""; echo ""Job name: ${JOB_NAME}""; echo ""Hostname: ${HOSTNAME}""; echo ""Task id: ${TASK_ID}"". FILE1=$(awk 'BEGIN {FS=""\t""} {print $1}' /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk ""NR==${SGE_TASK_ID}""); if [ TRUE == ""TRUE"" ] ; then; FILE2=$(awk 'BEGIN {FS=""\t""} {print $3}' /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk ""NR==${SGE_TASK_ID}""); fi; ID=$(cat /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk '{print $NF}' | awk ""NR==${SGE_TASK_ID}""). mkdir -p /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/${ID}. strace /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon quant 	-i /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/A",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:2439,log,logs,2439,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,1,['log'],['logs']
Testability,"odel for data generated from any technology and that's what we have been trying to do with salmon for years, piece by piece. Having said that, we don't mean to discourage people from trying salmon, that's one of the way we learn how can we improve the model even further. Now, coming back to your original question about using QuantSeq with salmon and how the paper above approach to solve it. I have a couple of thoughts:; 1.) Like you said, from the reading of their command line argument they didn't use the `nolengthcorrection` and I am surprised about the results myself. Since you have experience with the technology, you are best person to explore the difference in using and not using the length correction with salmon, that's why I shared.; 2.) Salmon models the transcript lengths in its quantification model. The basic intuition being longer length transcripts have higher probability of a read being sampled from them and has to be corrected for when using relative count metrices (like TPM) to avoid length bias. The logic behind `noLengthCorrection` is to _not_ correct for length for 3' protocol since we expect all the reads from one end of the transcript and if we do length correction, I hypothesize, we might end up biasing the estimates on the opposite direction; however the effect size of this hypothesis is still an open question and seemingly from the results from the paper it has minor effect. On the flip side may be it does have effect but their baseline estimates were not great and any improvement is good, for that again since you have experience with the data it's good to know / test what's going on.; 3.) A little experimental thought, although `noLengthCorrection` flag can generate decent estimates, it's actually fully disabling the length effect, which in my opinion we can do better as you look at Figure 1B of the paper it shows some length based affect but again we don't know how much difference it can create in generating the estimates. . I Hope it helps .",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-565256512:2013,log,logic,2013,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-565256512,4,"['log', 'test']","['logic', 'test']"
Testability,"og] [info] chunk 5 = [185,776,605, 222,931,953); [2021-12-31 11:28:47.220] [puff::index::jointLog] [info] chunk 6 = [222,931,953, 260,087,274); [2021-12-31 11:28:47.220] [puff::index::jointLog] [info] chunk 7 = [260,087,274, 297,242,536); [2021-12-31 11:28:57.275] [puff::index::jointLog] [info] finished populating pos vector; [2021-12-31 11:28:57.275] [puff::index::jointLog] [info] writing index components; [2021-12-31 11:28:59.670] [puff::index::jointLog] [info] finished writing dense pufferfish index; [2021-12-31 11:28:59.944] [jLog] [info] done building index; Threads = 8; Vertex length = 29; Hash functions = 5; Filter size = 4294967296; Capacity = 2; Files: ; /no_backup/indexes/salmon/mm10_gencode/ref_k29_fixed.fa; --------------------------------------------------------------------------------; Round 0, 0:4294967296; Pass	Filling	Filtering; 1	22	34	; 2	9	0; True junctions count = 1275494; False junctions count = 1606379; Hash table size = 2881873; Candidate marks count = 14783512; --------------------------------------------------------------------------------; Reallocating bifurcations time: 0; True marks count: 12564712; Edges construction time: 10; --------------------------------------------------------------------------------; Distinct junctions = 1275494. for info, total work write each : 2.331 total work inram from level 3 : 4.322 total work raw : 25.000 ; Bitarray 1252655360 bits (100.00 %) (array + ranks ); final hash 0 bits (0.00 %) (nb in final hash 0); ```. And these files are present in the index folder:; ```; ls -1 /no_backup/indexes/salmon/mm10_gencode; complete_ref_lens.bin; ctable.bin; ctg_offsets.bin; duplicate_clusters.tsv; info.json; mphf.bin; pos.bin; pre_indexing.log; rank.bin; refAccumLengths.bin; ref_indexing.log; reflengths.bin; refseq.bin; seq.bin; versionInfo.json; ```. So the problem was that the transcript file I provided to the `generateDecoyTranscriptome.sh` was gzipped and failed with `cat`.... 🤦‍♂️. Thanks a lot the help!; Nicco",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/731#issuecomment-1003342883:6582,log,log,6582,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/731#issuecomment-1003342883,2,['log'],['log']
Testability,"ogram_options); message(""BOOST_INCLUDEDIR = ${BOOST_INCLUDEDIR}""); message(""BOOST_LIBRARYDIR = ${BOOST_LIBRARYDIR}""); message(""Boost_FOUND 1.57.0 = ${Boost_FOUND}""); set(Boost_FOUND ""1""); message(""Boost_FOUND FORCED = ${Boost_FOUND}""); include(ExternalProject); ```; This emits:; ```. -- Could NOT find Boost; Boost_FOUND 1.57 = 0; -- Could NOT find Boost; BOOST_INCLUDEDIR = /usr/include/boost157; BOOST_LIBRARYDIR = /usr/lib64; Boost_FOUND 1.57.0 = 0; Boost_FOUND FORCED = 1; BOOST INCLUDE DIR = /usr/include/boost157; BOOST INCLUDE DIRS = /usr/include/boost157; BOOST LIB DIR = /usr/lib64; BOOST LIBRARIES = ; ```; That at least allowed cmake to complete when it was run with:. `nice scl enable devtoolset-4 '~/bin/cmake -DCMAKE_VERBOSE_MAKEFILE:BOOL=ON -DBoost_NO_BOOST_CMAKE=BOOL:ON -DBOOST_LIBRARYDIR=/usr/lib64 -DBOOST_INCLUDEDIR=/usr/include/boost157 ../CMakeLists.txt' >try_cmake.log 2>&1 &; `. Then tried to build it. ```; cd ..; nice scl enable devtoolset-4 'make' >build_2018_06_13d.log 2>&1 &. ```. It failed at this command because of missing boost symbols in a link operation, my reading is that the command does not include anything to link boost libraries. So telling cmake where the libraries are, where the include files are, and that boost was found was not sufficient. There must be some other set of symbols which need to be defined. `/opt/rh/devtoolset-4/root/usr/bin/c++ -pthread -ftree-vectorize -funroll-loops -fPIC -fomit-frame-pointer -O3 -DRAPMAP_SALMON_SUPPORT -DHAVE_ANSI_TERM -DHAVE_SSTREAM -Wall -Wno-unknown-pragmas -Wno-reorder -Wno-unused-variable -std=c++11 -Wreturn-type -Werror=return-type -Wno-unused-function -Wno-unused-local-typedef -static-libstdc++ -Wno-unused-local-typedefs -pthread -ftree-vectorize -funroll-loops -fPIC -fomit-frame-pointer -O3 -DRAPMAP_SALMON_SUPPORT -DHAVE_ANSI_TERM -DHAVE_SSTREAM -Wall -Wno-unknown-pragmas -Wno-reorder -Wno-unused-variable -std=c++11 -Wreturn-type -Werror=return-type -Wno-unused-function -Wno-unused-local-typedef",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/236#issuecomment-397025719:1583,log,log,1583,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/236#issuecomment-397025719,1,['log'],['log']
Testability,"oh, Then can I rm duplicate identical reads in my bam file? Will this affect my results?; because i got the warning in log file: ; ![image](https://user-images.githubusercontent.com/45484925/211450308-2c13c0c6-7a63-4a08-9658-d991c4bf285a.png); and i check the bam file, actually, there are indeed three identical reads, its not paired,so got the warnings.(may be another read was filtered).; ![image](https://user-images.githubusercontent.com/45484925/211451982-e5c9dc34-b9f9-4120-82b0-4827aa4ffd92.png). So I wonder if duplicate reads can be deleted?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/822#issuecomment-1376654942:119,log,log,119,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/822#issuecomment-1376654942,1,['log'],['log']
Testability,"okies, I think I see the issue. So look at the following lines in the log:; ```; [2019-06-17 21:21:44.518] [alevinLog] [info] Total 824863; [2019-06-17 21:22:47.680] [alevinLog] [info] Total Unique barcodes found: 3474567; ```; What it means is alevin found total: `3,474,567` unique CB in the whole sample and keeps `824,863` CB for further processing which is ~23% of the CB. So all the `keepCBFraction` values above 0.23 would have no effect. If you wan't to generate the `whitelist.txt`, alevin has to have some low confidence CB to learn from, so I am guessing in your case any value from 0.15-0.20 should ideally work. Having said that, I am still exploring why even setting `freqThreshold` to 0, alevin not considers all `3M` CB for processing, I guess there is some kind of filter which is coming into the picture but I might need a bit more time to explore that. I will update here once I figure it out. Thanks again for raising the issue and investing your time in improving alevin.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/379#issuecomment-503344686:70,log,log,70,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/379#issuecomment-503344686,2,['log'],['log']
Testability,"omatic adapter detection](https://github.com/OpenGene/fastp/issues/240). - [inconsistent behavior with different runs](https://github.com/OpenGene/fastp/issues/231). 3. When I see the above, I am bit skeptical using fastp for qc/adapter trimming. . After lot of trials with bbduk and fastp, I have decided to use bbduk and bbmap for my high throughput analysis. Below, I explain my reasoning behind those choices: . **_```Note - edited this on 02-Apr-2020 to have the correct order of operations ```_** . 1. **_STEP 1 - run bbmap.sh on raw fatsq file to remove contaminants as appropriate (rRNA, mitochondrial, chloroplast)_**; - You have alluded to the importance of removing contaminants [in this post](https://github.com/COMBINE-lab/salmon/issues/160#issuecomment-334762498); >However, the other thing to try is simply to align one of these samples to the genome with a tool like STAR or HISAT2 and look at their mapping rate to known features. If it's similar, then the other reads could be accounted for by e.g. intron retention or even contamination. Finally, [@vals has an excellent series of blog posts on investigating and addressing low mapping rates](http://www.nxn.se/valent/2017/9/18/low-mapping-rate-5-human-dna-contamination); - bbmap Command ([based of this biostars post](https://www.biostars.org/p/143019/#210890)):; `bbmap.sh in=read_1.fq.gz ref=rRNA_Chlor_Mito.fa maxindel=1 minid=0.95 outu=clean_read_1.fq.gz nodisk`; - Strategy:; `use the rRNA+Mito+Chloroplast file and map the reads using bbmap, then collect the unmapped reads (clean_read_1.fq.gz) for my downstream analysis`. 2. **_STEP 2 - run bbduk.sh on the outu files from bbmap step -- the outu stands for output unmapped - as stated in the logic above, anything that is unmapped to the rRNA_Chlor_Mito.fa is a clean read for downstream analysis_**. I use bbduk with adapter trimming and quality trimming in same command line - also, the adapters.fa file that ships with BBTools can be used in all runs. Hope that helps.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-597393209:3297,log,logic,3297,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-597393209,2,['log'],['logic']
Testability,"on for the problems you are facing in alevin. >Your first question was related to alevin quantifying very less number of reads. To answer that,; if you look at the log, at the first few lines, alevin warns about ~91% of the reads being thrown away because; of the noisy CBs. The problem is alevin’s first “knee"" estimation is overshooting in predicting the first boundary. You will find https://github.com/COMBINE-lab/salmon/issues/362 issue to be; very useful in understanding that. As a summary if you look at the plot I attached it has bi-modalities,; which is generally not the case and alevin is greedily finding the threshold at the first ~100 cells. If this; happens the general direction is to help alevin by proving a upper bound, in case of your data; would be ~14000 cells. You can tell alevin with `—expectCells 14000` and alevin start to work; normally and logs ~12% of the data is noisy. >You second question was a little complicated to answer. Seemingly, your salmon index has transcript with; same exact name `ENST00000399966.9`, occurring twice with different sequences. Just by looking at the index,; I am unsure it’s actually present in the reference or its salmon indexing messing up. If I Assume it was actually; present two times in the reference, alevin should report it instead of exiting abruptly in the middle of quantification.; Although, alevin does warns:; ```; [2019-07-04 14:12:32.519] [alevinLog] [warning] Found 1 transcripts with duplicate names; ```; >However, the bug i.e. not being able to distinguish duplicate names of the transcript, has been ; fixed and pushed in the develop branch of salmon. Alevin was reporting the error at the stage of quantification too, ; if you dump the logs in a file, but it was invisible in the console as it was over written my complex progress bar. . >Once I process it through the modified pipeline, alevin finished normally and I am attaching the quants generated; by alevin. >Thanks again for forwarding the data.; Best,; —Avi",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/386#issuecomment-508754845:1936,log,logs,1936,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/386#issuecomment-508754845,2,['log'],['logs']
Testability,"on/modules/el8/x86_64/software/libtbb/2020.5-CentOS-vanilla/lib/libtbb.so -lgomp /usr/lib64/libjemalloc.so -lrt ../external/pufferfish/src/libksw2pp.a libalevin_core.a -ldl -pthread ; /tmp/cc91ASWS.ltrans1.ltrans.o: In function `boost::iostreams::basic_gzip_compressor<std::allocator<char> >::basic_gzip_compressor(boost::iostreams::gzip_params const&, long) [clone .constprop.783]':; <artificial>:(.text+0xdca4): undefined reference to `boost::iostreams::detail::zlib_base::zlib_base()'; <artificial>:(.text+0xdcbc): undefined reference to `boost::iostreams::detail::zlib_base::do_init(boost::iostreams::zlib_params const&, bool, void* (*)(void*, unsigned int, unsigned int), void (*)(void*, void*), void*)'; <artificial>:(.text+0xddc8): undefined reference to `boost::iostreams::zlib::best_compression'; <artificial>:(.text+0xddd4): undefined reference to `boost::iostreams::zlib::best_speed'; /tmp/cc91ASWS.ltrans1.ltrans.o: In function `GZipWriter::writeMtx(std::shared_ptr<spdlog::logger>&, boost::filesystem::path&, unsigned long, unsigned long, unsigned long) [clone .constprop.780]':; <artificial>:(.text+0xe056): undefined reference to `boost::iostreams::zlib::default_strategy'; <artificial>:(.text+0xe05d): undefined reference to `boost::iostreams::zlib::deflated'; <artificial>:(.text+0xe2d1): undefined reference to `boost::filesystem::detail::status(boost::filesystem::path const&, boost::system::error_code*)'; ...; ```. The boost related errors go on forever. There is nothing about ""boost"" in that command line, so apparently the relevant pieces never made it into the makefile. Running that very long command line with this added on the end:. ```; -L/usr/lib64/boost169 -lboost_filesystem -lboost_system -lboost_program_options -lboost_iostreams; ```; ; let Salmon link (with no other warnings). The resulting binary will do; ""salmon -h"" correctly but has so far not been tested further. So, in short CMakeLists.txt's handling of boost is still badly broken on CentOS, 8 this time, ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641531162:3563,log,logger,3563,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641531162,1,['log'],['logger']
Testability,"on; Install the project...; -- Install configuration: ""Release""; -- Installing: /salmon-0.10.2/lib; -- Installing: /salmon-0.10.2/lib/libtbb.so; -- Installing: /salmon-0.10.2/lib/libtbbmalloc.so; -- Installing: /salmon-0.10.2/lib/libtbbmalloc_proxy.so; -- Installing: /salmon-0.10.2/lib/libtbbmalloc.so.2; -- Installing: /salmon-0.10.2/lib/libtbb.so.2; -- Installing: /salmon-0.10.2/lib/pkgconfig; -- Installing: /salmon-0.10.2/lib/libtbbmalloc_proxy.so.2; -- Installing: /salmon-0.10.2/bin/salmon; -- Installing: /salmon-0.10.2/lib/libsalmon_core.a. Installation complete. Please ensure the following paths are set properly.; ==========================================================================; Please add /salmon-0.10.2/bin to your PATH; Please add /salmon-0.10.2/lib to your LD_LIBRARY_PATH; ==========================================================================; root@e08cc9670e4a:/salmon-0.10.2/build# make test; Running tests...; Test project /salmon-0.10.2/build; Start 1: unit_tests; 1/3 Test #1: unit_tests ....................... Passed 0.17 sec; Start 2: salmon_read_test_fmd; 2/3 Test #2: salmon_read_test_fmd ............. Passed 1.78 sec; Start 3: salmon_read_test_quasi; 3/3 Test #3: salmon_read_test_quasi ........... Passed 1.59 sec. 100% tests passed, 0 tests failed out of 3. Total Test time (real) = 3.54 sec; root@e08cc9670e4a:/salmon-0.10.2/build# lsb_release -a; LSB Version: core-9.20160110ubuntu0.2-amd64:core-9.20160110ubuntu0.2-noarch:security-9.20160110ubuntu0.2-amd64:security-9.20160110ubuntu0.2-noarch; Distributor ID: Ubuntu; Description: Ubuntu 16.04.4 LTS; Release: 16.04; Codename: xenial; ```. I built with:. `$ cmake -DFETCH_BOOST=TRUE .. && make install && make test`. I can also install the boost via apt and see if that makes a difference (though I expect not since it looked like TBB was the issue, and I let cmake install that). We can also check our compiler versions, perhaps. I have : . ```; root@e08cc9670e4a:/salmon-0.10.2/build# g++ --version",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/250#issuecomment-404306268:1947,Test,Test,1947,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/250#issuecomment-404306268,1,['Test'],['Test']
Testability,"over the TBX21 region, I get back >4000 paired reads. The majority of the TBX21 reads have flags 99 or 147:; (# of reads) | (flag); 4431 | 147; 12 | 355; 14 | 403; 2 | 419; 4432 | 99. I also confirmed that many of these reads are indeed from the TBX21 spliced transcripts (cross splice junctions). I am running Salmon in mapping-based mode on the unaligned fastqs, and it is picking up exactly 0 reads in these transcripts. salmon index -t hg38_salmon_transcriptome.fa -i salmon_hg38_index --type quasi -k 31; salmon quant -i salmon_hg38_index -l ISR -p 8 -1 SRR1615172_1_val_1.fq.gz -2 SRR1615172_2_val_2.fq.gz -o salmon_quant_SRR1615172. The genome-wide distribution of insert size ranges for this sample are unusual (bi-modal), and this is partly why STAR only mapped 65% of the reads. The other issue with the sample is STAR reports 19% multi-mapped reads, but even so, there are still at least 4000 reads uniquely mapping to TBX21. Attached are:; ### Output from Salmon; [salmon_quant.log](https://github.com/COMBINE-lab/salmon/files/3199053/salmon_quant.log); [lib_format_counts.json.zip](https://github.com/COMBINE-lab/salmon/files/3199074/lib_format_counts.json.zip); ### Output from STAR; [SRR1615173.Log.final.out.STAR.txt](https://github.com/COMBINE-lab/salmon/files/3199078/SRR1615173.Log.final.out.STAR.txt); ### Output from samtools view over the TBX21 gene start and end (hg38 17:47733244-47746119); [TBX21_reads.txt](https://github.com/COMBINE-lab/salmon/files/3199054/TBX21_reads.txt); ### FastQC reports of the two fastqs; [SRR1615173_1_val_1.fq_fastqc.zip](https://github.com/COMBINE-lab/salmon/files/3199049/SRR1615173_1_val_1.fq_fastqc.zip); [SRR1615173_2_val_2.fq_fastqc.zip](https://github.com/COMBINE-lab/salmon/files/3199050/SRR1615173_2_val_2.fq_fastqc.zip); ### Output from CollectInsertSizeMetrics; [insert_size_histogram.pdf](https://github.com/COMBINE-lab/salmon/files/3199051/insert_size_histogram.pdf); [insert_size_metrics.txt](https://github.com/COMBINE-lab/salmon/f",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/218#issuecomment-494079306:1494,log,log,1494,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/218#issuecomment-494079306,1,['log'],['log']
Testability,"ovided; using is 1 less feature for whitelisting; [2019-01-29 09:55:59.107] [alevinLog] [info] Starting to make feature Matrix; [2019-01-29 09:55:59.115] [alevinLog] [info] Done making regular featues; [2019-01-29 09:55:59.115] [alevinLog] [info] Done making feature Matrix; [2019-01-29 09:55:59.123] [alevinLog] [info] Finished white listing; [2019-01-29 09:55:59.126] [alevinLog] [info] Finished optimizer; ``` . Concat fastq:; ```; salmon alevin -l ISR -1 big.fastq.1.gz -2 big.fastq.2.gz --chromium -i geneset.dir/geneset_coding_exons.salmon.index/ -o salmon.dir/ --tgMap transcript2geneMap.tsv --dumpCsvCounts; Version Info: ### PLEASE UPGRADE SALMON ###; ### A newer version of Salmon with important bug fixes and improvements is available. ####; ###; The newest version, available at https://github.com/COMBINE-lab/salmon/releases; contains new features, improvements, and bug fixes; please upgrade at your; earliest convenience.; ###; Logs will be written to salmon.dir/logs; ### alevin (dscRNA-seq quantification) v0.11.3; ### [ program ] => salmon ; ### [ command ] => alevin ; ### [ libType ] => { ISR }; ### [ mates1 ] => { big.fastq.1.gz }; ### [ mates2 ] => { big.fastq.2.gz }; ### [ chromium ] => { }; ### [ index ] => { geneset.dir/geneset_coding_exons.salmon.index/ }; ### [ output ] => { salmon.dir/ }; ### [ tgMap ] => { transcript2geneMap.tsv }; ### [ dumpCsvCounts ] => { }. [2019-01-29 09:56:37.731] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2019-01-29 09:56:37.749] [alevinLog] [info] Processing barcodes files (if Present) . ; processed 2 Million barcodes. [2019-01-29 09:56:43.029] [alevinLog] [info] Done barcode density calculation.; [2019-01-29 09:56:43.029] [alevinLog] [info] # Barcodes Used: 2695632 / 2712324.; [2019-01-29 09:56:52.900] [alevinLog] [info] Knee found left boundary at 692 ; [2019-01-29 09:56:53.219] [alevinLog] [info] Gauss Corrected Boundary at 100 ; [2019-01-29 09:56:53.219] [alevin",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/337#issuecomment-458481722:6386,log,logs,6386,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/337#issuecomment-458481722,1,['log'],['logs']
Testability,"pool/compute-061/job_scripts/110315: line 31: 54922 Aborted (core dumped) /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon quant -i /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts -p 1 -l ISR -1 ${FILE1} -2 ${FILE2} -o /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test3/${ID}; **** Job ends ****; Wed Mar 29 14:51:13 EDT 2017; ```. ### SGE email info example. ```; Job-array task 110315.1 (step6-salmon_test3.gsk_phaseII) Complete; User = lcollado; Queue = shared.q@compute-061.cm.cluster; Host = compute-061.cm.cluster; Start Time = 03/29/2017 14:51:09; End Time = 03/29/2017 14:51:13; User Time = 00:00:00; System Time = 00:00:02; Wallclock Time = 00:00:04; CPU = 00:00:02; Max vmem = 14.820G; Exit Status = 0; ```. ## 16 cores. ### Bash. ```bash; #!/bin/bash; #$ -cwd; #$ -l mem_free=2G,h_vmem=3G,h_fsize=100G; #$ -N step6-salmon_test4.gsk_phaseII; #$ -pe local 16; #$ -o ./logs/salmon_test4.$TASK_ID.txt; #$ -e ./logs/salmon_test4.$TASK_ID.txt; #$ -t 1-3; #$ -hold_jid pipeline_setup,step4-featCounts-alzheimer.gsk_phaseII; #$ -m e; echo ""**** Job starts ****""; date. echo ""**** JHPCE info ****""; echo ""User: ${USER}""; echo ""Job id: ${JOB_ID}""; echo ""Job name: ${JOB_NAME}""; echo ""Hostname: ${HOSTNAME}""; echo ""Task id: ${TASK_ID}"". FILE1=$(awk 'BEGIN {FS=""\t""} {print $1}' /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk ""NR==${SGE_TASK_ID}""); if [ TRUE == ""TRUE"" ] ; then; FILE2=$(awk 'BEGIN {FS=""\t""} {print $3}' /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk ""NR==${SGE_TASK_ID}""); fi; ID=$(cat /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk '{print $NF}' | awk ""NR==${SGE_TASK_ID}""). mkdir -p /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test4/${ID}. /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon quant 	-i /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-290516965:3949,log,logs,3949,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-290516965,1,['log'],['logs']
Testability,"probably unrelated, but also unexpected. Make test on my linux and osx box looks like:. ```; $ make test; Running tests...; Test project /Users/rob/salmon/build; Start 1: unit_tests; 1/3 Test #1: unit_tests ....................... Passed 0.13 sec; Start 2: salmon_read_test_fmd; 2/3 Test #2: salmon_read_test_fmd ............. Passed 0.87 sec; Start 3: salmon_read_test_quasi; 3/3 Test #3: salmon_read_test_quasi ........... Passed 0.39 sec. 100% tests passed, 0 tests failed out of 3. Total Test time (real) = 1.41 sec; ```. It looks the same on the continuous integration server : . ```; Running tests...; /usr/local/cmake-3.9.2/bin/ctest --force-new-ctest-process ; Test project /home/travis/build/COMBINE-lab/salmon/build; Start 1: unit_tests; 1/3 Test #1: unit_tests ....................... Passed 0.13 sec; Start 2: salmon_read_test_fmd; 2/3 Test #2: salmon_read_test_fmd ............. Passed 2.55 sec; Start 3: salmon_read_test_quasi; 3/3 Test #3: salmon_read_test_quasi ........... Passed 1.72 sec; 100% tests passed, 0 tests failed out of 3; Total Test time (real) = 4.41 sec; ```. Also, you can look, in the build directory, in the subdirectory `Testing/Temporary/LastTestsFailed.log` which will give details of which specific test failed.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/229#issuecomment-393676260:46,test,test,46,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/229#issuecomment-393676260,21,"['Test', 'log', 'test']","['Test', 'Testing', 'log', 'test', 'tests']"
Testability,"r -xz --strip-components 1; cmake -DBOOST_ROOT=/global/software/sl-7.x86_64/modules/gcc/7.4.0/boost/1.70.0-gcc -DCMAKE_INSTALL_PREFIX=$INSTALL_DIR; make; ```; And the tail of the output from make:. ```; creating: /clusterfs/vector/home/groups/software/sl-7.x86_64/source/salmon/1.5.1/scripts/../external/pufferfish-salmon-v1.5.1/tests/compile_tests/; inflating: /clusterfs/vector/home/groups/software/sl-7.x86_64/source/salmon/1.5.1/scripts/../external/pufferfish-salmon-v1.5.1/tests/compile_tests/int128_numeric_limits.cpp ; -- fetch PUFFERFISH exit code 0; -- Found ZLIB: /usr/lib64/libz.so (found version ""1.2.11"") ; -- Performing Test Iconv_IS_BUILT_IN; -- Performing Test Iconv_IS_BUILT_IN - Failed; CMake Error at /global/home/groups/consultsw/sl-7.x86_64/modules/cmake/3.15.1/share/cmake-3.15/Modules/FindPackageHandleStandardArgs.cmake:137 (message):; Could NOT find Iconv (missing: Iconv_LIBRARY); Call Stack (most recent call first):; /global/home/groups/consultsw/sl-7.x86_64/modules/cmake/3.15.1/share/cmake-3.15/Modules/FindPackageHandleStandardArgs.cmake:378 (_FPHSA_FAILURE_MESSAGE); /global/home/groups/consultsw/sl-7.x86_64/modules/cmake/3.15.1/share/cmake-3.15/Modules/FindIconv.cmake:120 (find_package_handle_standard_args); CMakeLists.txt:362 (find_package). -- Configuring incomplete, errors occurred!; See also ""/clusterfs/vector/home/groups/software/sl-7.x86_64/source/salmon/1.5.1/CMakeFiles/CMakeOutput.log"".; See also ""/clusterfs/vector/home/groups/software/sl-7.x86_64/source/salmon/1.5.1/CMakeFiles/CMakeError.log"".; ```; I'm also attaching the full CMake logs. This is right at the edge of my knowledge, so I'm not 100% sure I got libiconv installed correctly. Compilation completed without error, and I added the bin, include, and lib directories to PATH, CPATH, and LD_LIBRARY_PATH, respectively. [CMakeError.log](https://github.com/COMBINE-lab/salmon/files/6665942/CMakeError.log); [CMakeOutput.log](https://github.com/COMBINE-lab/salmon/files/6665943/CMakeOutput.log)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/453#issuecomment-862737315:2573,log,log,2573,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/453#issuecomment-862737315,14,['log'],"['log', 'logs']"
Testability,"r one test:. ```; [2017-04-05 14:28:09.021] [jointLog] [info] parsing read library format; [2017-04-05 14:28:09.035] [jointLog] [info] There is 1 library.; terminate called without an active exception; /cm/local/apps/sge/var/spool/compute-064/job_scripts/420662: line 31: 28651 Aborted (core dumped) /dcl01/lieber/ajaffe/Emily/RNAseq-pipelin; e/Software/Salmon-0.8.2_linux_x86_64/bin/salmon quant -i /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode; .v25.transcripts -p 1 -l ISR -1 ${FILE1} -2 ${FILE2} -o /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test7/${ID}; ```. Files that work well, keep on going:. ```; [2017-04-05 14:30:23.757] [jointLog] [info] parsing read library format; [2017-04-05 14:30:23.767] [jointLog] [info] There is 1 library.; [2017-04-05 14:30:24.378] [jointLog] [info] Loading Quasi index; ```. I don't know if that hint makes you suspect anything in `Salmon`. . Now, for some tests only task 2 runs and it turns out that task 2 has a smaller fastq file than the other 2:. ```bash; $ ls -lh merged_fastq/R1000[1-3]*; -rw-r--r-- 1 lcollado lieber_jaffe 6.2G Feb 20 12:39 merged_fastq/R10001_D2B1WACXX.fastq.gz; -rw-r--r-- 1 lcollado lieber_jaffe 6.3G Feb 20 12:40 merged_fastq/R10001_D2B1WACXX_read2.fastq.gz; -rw-r--r-- 1 lcollado lieber_jaffe 4.6G Feb 20 12:42 merged_fastq/R10002_C29P7ACXX.fastq.gz; -rw-r--r-- 1 lcollado lieber_jaffe 4.7G Feb 20 12:44 merged_fastq/R10002_C29P7ACXX_read2.fastq.gz; -rw-r--r-- 1 lcollado lieber_jaffe 7.1G Feb 20 12:47 merged_fastq/R10003_D19KGACXX.fastq.gz; -rw-r--r-- 1 lcollado lieber_jaffe 7.1G Feb 20 12:50 merged_fastq/R10003_D19KGACXX_read2.fastq.gz; ```. where R10001* is task 1, R10002* is task 2, R10003* is task 3. So it looks like at some point Salmon is asking for some memory based on the input data. ## Strace test with low memory (but above reported usage when requesting 90GB). Mark taught me about `strace` and we ran the following test:. ```bash; #!/bin/bash; #$ ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:1288,test,tests,1288,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,1,['test'],['tests']
Testability,"ragment incompatibility prior; below threshold. Incompatible fragments will be ignored.; [2019-07-29 15:58:39.034] [jointLog] [info] Usage of --validateMappings; implies use of minScoreFraction. Since not explicitly specified, it is; being set to 0.65; [2019-07-29 15:58:39.034] [jointLog] [info] Usage of --validateMappings,; without --hardFilter implies use of range factorization.; rangeFactorizationBins is being set to 4; [2019-07-29 15:58:39.034] [jointLog] [info] Usage of --validateMappings; implies a default consensus slack of 0.2. Setting consensusSlack to 0.2.; [2019-07-29 15:58:39.034] [jointLog] [info] parsing read library format; [2019-07-29 15:58:39.034] [jointLog] [error] Failed to successfully parse; any complete read libraries. Please make sure you provided arguments; properly to -1, -2 (for paired-end libraries) or -r (for single-end; libraries), and that the library format option (-l) *comes before* the read; libraries. Best,. Sara. On Mon, Jul 29, 2019 at 3:25 PM Avi Srivastava <notifications@github.com>; wrote:. > You passed paired-end files; > to salmon, but you passed 12 files to --mates1 and 13 files to --mates2.; > You must pass the same number of files to both flags; >; > Is this true ? Can you share the log ?; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/COMBINE-lab/salmon/issues/408?email_source=notifications&email_token=AEHDXAH7HQIR4ZVWMTE2KXLQB5U5LA5CNFSM4IGU4ZTKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOD3CF3JY#issuecomment-516185511>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AEHDXAG7WI3B7QBMJOSXTATQB5U5LANCNFSM4IGU4ZTA>; > .; >. -- ; Sara E. Boles, MS; PhD Candidate | Whitehead Lab; Pharmacology and Toxicology Graduate Group; Department of Environmental Toxicology; University of California, Davis, CA 95616; http://whiteheadresearch.wordpress.com/; https://sites.google.com/a/ucdavis.edu/sara-e-boles/",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/408#issuecomment-516194201:1377,log,log,1377,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/408#issuecomment-516194201,1,['log'],['log']
Testability,"rdinates (as a regular procedure). I know Salmon assumes the alignments are not sorted, so I shuffled these bam files, and then run `salmon quant`.; Here are the errors I got in a number of trials:. ### Fresh installation of Salmon; ```; conda create --name salmon -c bioconda salmon; conda activate salmon; ```. ### 1. Shuffling a bam file with `samtools collate`; ```; samtools collate \; -@ 40 \; -o SRR3212847.Aligned.Shuffled.bam \; SRR3212847.Aligned.SortedByCoord.bam. salmon quant \; -t mRNA.fasta \; -p 20 \; -l A \; -a SRR3212847.Aligned.Shuffled.bam \; -o SRR3212847.Aligned.Shuffled ; ```. ```; Version Info: This is the most recent version of salmon.; # salmon (alignment-based) v1.4.0; # [ program ] => salmon ; # [ command ] => quant ; # [ targets ] => { mRNA.fasta }; # [ threads ] => { 20 }; # [ libType ] => { A }; # [ alignments ] => { SRR3212847.Aligned.Shuffled.bam }; # [ output ] => { SRR3212847.Aligned.Shuffled }; Logs will be written to SRR3212847.Aligned.Shuffled/logs; [2021-01-08 12:43:44.680] [jointLog] [info] setting maxHashResizeThreads to 20; [2021-01-08 12:43:44.680] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; Library format { type:paired end, relative orientation:inward, strandedness:unstranded }; [2021-01-08 12:43:44.711] [jointLog] [info] numQuantThreads = 14; parseThreads = 6; Checking that provided alignment files have consistent headers . . . done; Populating targets from aln = ""SRR3212847.Aligned.Shuffled.bam"", fasta = ""mRNA.fasta"" . . .done. processed 0 reads in current roundSegmentation fault (core dumped); ```. ### 2. Shuffling a headless bam file with `samtools collate`; (I think I saw something about the bam's header in another thread dealing with this issue); ```; samtools view \; -b \; -@ 40 \; -o SRR3212847.Aligned.SortedByCoord.NoHeader.bam \; SRR3212847.Aligned.SortedByCoord.bam. samtools collate \; -@ 40 \; -o SRR3212847.Aligned.Shuffled.NoHeader.bam \; SRR3212847.Ali",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/582#issuecomment-756727212:1122,log,logs,1122,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/582#issuecomment-756727212,1,['log'],['logs']
Testability,"salmon/lib/libtbb.so; -- Installing: /salmon/lib/libtbb.so.12; -- Installing: /salmon/lib/libtbb.so.12.5; -- Installing: /salmon/lib/libtbbmalloc.so; -- Installing: /salmon/lib/libtbbmalloc.so.2; -- Installing: /salmon/lib/libtbbmalloc.so.2.5; -- Installing: /salmon/lib/libtbbmalloc_proxy.so; -- Installing: /salmon/lib/libtbbmalloc_proxy.so.2; -- Installing: /salmon/lib/libtbbmalloc_proxy.so.2.5; -- Installing: /salmon/bin/salmon; -- Installing: /salmon/lib/libsalmon_core.a. Installation complete. Please ensure the following paths are set properly.; ==========================================================================; Please add /salmon/bin to your PATH; Please add /salmon/lib to your LD_LIBRARY_PATH; ==========================================================================; root@fd877e359439:/salmon/build# make test; Running tests...; Test project /salmon/build; Start 1: unit_tests; 1/2 Test #1: unit_tests ....................... Passed 0.37 sec; Start 2: salmon_read_test_quasi; 2/2 Test #2: salmon_read_test_quasi ........... Passed 1.80 sec. 100% tests passed, 0 tests failed out of 2. Total Test time (real) = 2.17 sec; ```. The `make test` command itself runs the test the builds the index and maps the reads against it. Either way, I can do that explicitly too (from within build):. ```; $ ./src/salmon index -t ../sample_data/transcripts.fasta -i sample_idx; ```. returns succesfully with a built index. ```; ...; [2023-03-10 05:51:33.748] [puff::index::jointLog] [info] Done wrapping the rank vector with a rank9sel structure.; [2023-03-10 05:51:33.748] [puff::index::jointLog] [info] contig count for validation: 23; [2023-03-10 05:51:33.748] [puff::index::jointLog] [info] Total # of Contigs : 23; [2023-03-10 05:51:33.748] [puff::index::jointLog] [info] Total # of numerical Contigs : 23; [2023-03-10 05:51:33.748] [puff::index::jointLog] [info] Total # of contig vec entries: 36; [2023-03-10 05:51:33.748] [puff::index::jointLog] [info] bits per offset entry 6; [202",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463312554:2862,Test,Test,2862,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463312554,1,['Test'],['Test']
Testability,"so, I did fix the `umi_tools` commands as; ```; umi_tools whitelist \; -I /home/GSE140511/fastq_files/SRR10480618_1.fastq.gz \; --bc-pattern=CCCCCCCCCCCCCCCCNNNNNNNNNNNN \; --log=/home/GSE140511/SRR10480618_fq/SRR10480618_log_whitelist.log \; --log2stderr > /home/GSE140511/SRR10480618_fq/SRR10480618_whitelist.txt. umi_tools extract \; --bc-pattern=CCCCCCCCCCCCCCCCNNNNNNNNNNNN \; --stdin /home/GSE140511/fastq_files/SRR10480618_1.fastq.gz \; --stdout /home/GSE140511/SRR10480618_fq/SRR10480618_BC_1.fastq.gz \; --read2-in /home/GSE140511/fastq_files/SRR10480618_2.fastq.gz \; --read2-out=/home/GSE140511/SRR10480618_fq/SRR10480618_BC_2.fastq.gz \; --whitelist=/home/GSE140511/SRR10480618_fq/SRR10480618_whitelist.txt; ```. I swapped the reads as:; ```; /salmon-1.8.0_linux_x86_64/bin/salmon alevin \; -l ISR \; -2 /home/GSE140511/SRR10480618_fq/SRR10480618_BC_trimmed_1.fastq.gz \; -1 /home/GSE140511/SRR10480618_fq/SRR10480618_BC_trimmed_2.fastq.gz \; --chromiumV3 \; -i /data/ref_genomes/Mmus_GrCm39 \; -p 32 \; -o /home/GSE140511/salmon_alevin_output/SRR10480618_rev2 \; --expectCells 3000 --forceCells 3000 \; --tgMap /home/txp2gene_SB.tsv; ```; I tried both `ISR` and `ISF` (just in case)...mapping rate ranged from zero point something to one point something.; I also tried with and without `--expectCells 3000 --forceCells 3000` looking at a few suggestions [here](https://github.com/COMBINE-lab/salmon/discussions/506) but it didn't really make any difference. `Alevin.log` from the last run is:; ````; [2022-03-27 05:24:09.430] [alevinLog] [info] Found 116716 transcripts(+0 decoys, +39 short and +0 duplicate names in the index); [2022-03-27 05:24:09.478] [alevinLog] [info] Filled with 116755 txp to gene entries ; [2022-03-27 05:24:09.484] [alevinLog] [info] Found all transcripts to gene mappings; [2022-03-27 05:24:09.495] [alevinLog] [info] Processing barcodes files (if Present) . ; [2022-03-27 05:33:37.411] [alevinLog] [info] Done barcode density calculation.; [2022-03-27 05:33:37",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/763#issuecomment-1082597942:175,log,log,175,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/763#issuecomment-1082597942,2,['log'],['log']
Testability,"test/salmon_0.8.2_index_gencode.v25.transcripts }; ### [ threads ] => { 1 }; ### [ libType ] => { ISR }; ### [ mates1 ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/merged_fastq/R10001_D2B1WACXX.fastq.gz }; ### [ mates2 ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/merged_fastq/R10001_D2B1WACXX_read2.fastq.gz }; ### [ output ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10001_D2B1WACXX }; ) = 594; stat(""/etc/localtime"", {st_mode=S_IFREG|0644, st_size=3519, ...}) = 0; stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10001_D2B1WACXX"", {st_mode=S_IFDIR|S_ISGID|0755, st_size=33280, ...}) = 0; stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10001_D2B1WACXX"", {st_mode=S_IFDIR|S_ISGID|0755, st_size=33280, ...}) = 0; stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10001_D2B1WACXX/logs"", 0x7fffffff1e50) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10001_D2B1WACXX/logs"", 0x7fffffff1e60) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10001_D2B1WACXX"", {st_mode=S_IFDIR|S_ISGID|0755, st_size=33280, ...}) = 0; mkdir(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10001_D2B1WACXX/logs"", 0777) = 0; write(2, ""Logs will be written to "", 24Logs will be written to ) = 24; write(2, ""/dcl01/lieber/ajaffe/lab/libd_al""..., 81/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10001_D2B1WACXX/logs) = 81; write(2, ""\n"", 1; ) = 1; stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10001_D2B1WACXX/libParams"", 0x7fffffff1e50) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10001_D2B1WACXX/libParams"", 0x7fffffff1e60) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10001_D2B1WACXX"", {st_mode=S_IFDIR|S_ISGID|0755, st_size=33280, .",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:105651,log,logs,105651,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,2,['log'],['logs']
Testability,"test/salmon_0.8.2_index_gencode.v25.transcripts }; ### [ threads ] => { 1 }; ### [ libType ] => { ISR }; ### [ mates1 ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/merged_fastq/R10002_C29P7ACXX.fastq.gz }; ### [ mates2 ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/merged_fastq/R10002_C29P7ACXX_read2.fastq.gz }; ### [ output ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10002_C29P7ACXX }; ) = 594; stat(""/etc/localtime"", {st_mode=S_IFREG|0644, st_size=3519, ...}) = 0; stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10002_C29P7ACXX"", {st_mode=S_IFDIR|S_ISGID|0755, st_size=33280, ...}) = 0; stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10002_C29P7ACXX"", {st_mode=S_IFDIR|S_ISGID|0755, st_size=33280, ...}) = 0; stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10002_C29P7ACXX/logs"", 0x7fffffff1e50) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10002_C29P7ACXX/logs"", 0x7fffffff1e60) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10002_C29P7ACXX"", {st_mode=S_IFDIR|S_ISGID|0755, st_size=33280, ...}) = 0; mkdir(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10002_C29P7ACXX/logs"", 0777) = 0; write(2, ""Logs will be written to "", 24Logs will be written to ) = 24; write(2, ""/dcl01/lieber/ajaffe/lab/libd_al""..., 81/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10002_C29P7ACXX/logs) = 81; write(2, ""\n"", 1; ) = 1; stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10002_C29P7ACXX/libParams"", 0x7fffffff1e50) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10002_C29P7ACXX/libParams"", 0x7fffffff1e60) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10002_C29P7ACXX"", {st_mode=S_IFDIR|S_ISGID|0755, st_size=33280, .",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:67069,log,logs,67069,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,2,['log'],['logs']
Testability,"tested with 32G and 16GB of memory, just to see what impact this would have on the times. Those jobs are still running (it's only been about 4hrs as of this writing, I'll update my post if/when they complete). Current logs are showing that they quickly consume all the available memory, but have not yet crashed. I've also got versions with 128-512GB of memory requested (by powers of 2) for comparison. Some random notes: both the 31-mer index experienced about twice as many soft page reclaims with the new/faster version and experienced a few hard page faults (the previous version saw none of the latter). The 17-mer version experienced fewer page reclaims than any of the 31-mer indices and far fewer than with the prior version. Again, a few page faults crept in, but relatively few by percentage and likely not contributing any significant amount of time overall. [index-qacct-17mer.log](https://github.com/COMBINE-lab/salmon/files/4246516/index-qacct-17mer.log); [index-qacct-31mer.log](https://github.com/COMBINE-lab/salmon/files/4246517/index-qacct-31mer.log). **UPDATE**; The 16GB version finished running. It actually only took a little over 4 hours to run, as well. The troubling thing about this job seems to be that, despite having successfully completed, according to the accounting log it used over 20GB of memory... which should be impossible to do. Our resident experts suspect there's a race condition occurring at the tail end of the job and that all of that extra memory is being allocated before the scheduler can kill it for exceeding the limit. Whatever the case, though, this throws into question some of those numbers that I've been grabbing from the accounting logs --- it's either being misreported, or the memory gobbling is happening so rapidly that it may not, in fact, be being properly recorded. I tested the index anyway. It *appears* to be working just fine. Nothing faulted or crashed when I attempted to quantify some reads against it. [index-qacct-17mer-16gigs.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/476#issuecomment-590516702:1713,log,log,1713,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/476#issuecomment-590516702,1,['log'],['log']
Testability,"two settings as well; `--freqThreshold 1 --lowRegionMinNumBarcodes 100`. . I am not sure why the `ISF` option didn't work, but probably it has something to do with the guide sequences I was provided. At any rate, I have a few other questions I hope you can help me answer. 1. Why does increasing --maxNumBarcodes to 200000 results in no barcodes getting corrected? (See log for Run 2 below). What is the rationale for the current default of 100000? ; 2. For the downstream analysis of such data, I usually work with both the read and UMI counts, but `quants_mat.gz` only contains the UMI counts. Can Alevin a produce a matrix of read counts as well. It would be a great feature to add. For now, what is easiest way to get the cell x feature matrix of read counts if I use the ` --dumpEq` or `--dumpBfh` flags? Can *tximport* be used for this or do I need to use the Python [parser]([https://github.com/k3yavi/vpolo/blob/master/vpolo/alevin/parser.pyl]) first?. I will be sending you some reads from the experiments for unit testing shortly. Thanks!. Run 1: `salmon alevin -l ISR --citeseq --barcodeLength 16 --umiLength 10 --end 5 --featureStart 19 --featureLength 21 --maxNumBarcodes 100000 --freqThreshold 1 --lowRegionMinNumBarcodes 100`. > 20-06-04 12:24:47.610] [alevinLog] [info] set CITE-seq minScoreFraction parameter to : 0.797619; > [2020-06-04 12:24:47.610] [alevinLog] [info] Found 64 transcripts(+0 decoys, +0 short and +0 duplicate names in the index); > [2020-06-04 12:24:47.610] [alevinLog] [info] Filled with 64 txp to gene entries ; > [2020-06-04 12:24:47.610] [alevinLog] [info] Found all transcripts to gene mappings; > [2020-06-04 12:24:47.616] [alevinLog] [info] Processing barcodes files (if Present) ; > ; > [2020-06-04 12:26:04.322] [alevinLog] [info] Done barcode density calculation.; > [2020-06-04 12:26:04.322] [alevinLog] [info] # Barcodes Used: [32m52200250[0m / [31m52200250[0m.; > [2020-06-04 12:26:04.435] [alevinLog] [info] Forcing to use 100000 cells; > [2020-",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-638991199:1180,test,testing,1180,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-638991199,2,['test'],['testing']
Testability,"uld have on the times. Those jobs are still running (it's only been about 4hrs as of this writing, I'll update my post if/when they complete). Current logs are showing that they quickly consume all the available memory, but have not yet crashed. I've also got versions with 128-512GB of memory requested (by powers of 2) for comparison. Some random notes: both the 31-mer index experienced about twice as many soft page reclaims with the new/faster version and experienced a few hard page faults (the previous version saw none of the latter). The 17-mer version experienced fewer page reclaims than any of the 31-mer indices and far fewer than with the prior version. Again, a few page faults crept in, but relatively few by percentage and likely not contributing any significant amount of time overall. [index-qacct-17mer.log](https://github.com/COMBINE-lab/salmon/files/4246516/index-qacct-17mer.log); [index-qacct-31mer.log](https://github.com/COMBINE-lab/salmon/files/4246517/index-qacct-31mer.log). **UPDATE**; The 16GB version finished running. It actually only took a little over 4 hours to run, as well. The troubling thing about this job seems to be that, despite having successfully completed, according to the accounting log it used over 20GB of memory... which should be impossible to do. Our resident experts suspect there's a race condition occurring at the tail end of the job and that all of that extra memory is being allocated before the scheduler can kill it for exceeding the limit. Whatever the case, though, this throws into question some of those numbers that I've been grabbing from the accounting logs --- it's either being misreported, or the memory gobbling is happening so rapidly that it may not, in fact, be being properly recorded. I tested the index anyway. It *appears* to be working just fine. Nothing faulted or crashed when I attempted to quantify some reads against it. [index-qacct-17mer-16gigs.log](https://github.com/COMBINE-lab/salmon/files/4247214/index-qacct",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/476#issuecomment-590516702:1788,log,log,1788,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/476#issuecomment-590516702,1,['log'],['log']
Testability,"vided; using is 1 less feature for whitelisting; [2022-03-27 05:46:42.064] [alevinLog] [warning] rrna file not provided; using is 1 less feature for whitelisting; [2022-03-27 05:49:49.761] [alevinLog] [info] Total 535438.00 UMI after deduplicating.; [2022-03-27 05:49:49.761] [alevinLog] [info] Total 2317116 BiDirected Edges.; [2022-03-27 05:49:49.761] [alevinLog] [info] Total 867878 UniDirected Edges.; [2022-03-27 05:49:49.761] [alevinLog] [warning] Skipped 955 barcodes due to No mapped read; [2022-03-27 05:49:49.766] [alevinLog] [info] Clearing EqMap; Might take some time.; [2022-03-27 05:49:50.011] [alevinLog] [info] Starting white listing of 3044 cells; [2022-03-27 05:49:50.011] [alevinLog] [info] Starting to make feature Matrix; [2022-03-27 05:49:50.014] [alevinLog] [info] Done making feature Matrix; [2022-03-27 05:49:50.717] [alevinLog] [info] Finished white listing; [2022-03-27 05:49:51.422] [alevinLog] [info] Finished optimizer; ````. and the `salmon_quant.log` looks like:; ```; [2022-03-27 05:24:09.395] [jointLog] [info] setting maxHashResizeThreads to 32; [2022-03-27 05:24:09.395] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2022-03-27 05:24:09.395] [jointLog] [info] The --mimicBT2, --mimicStrictBT2 and --hardFilter flags imply mapping validation (--validateMappings). Enabling mapping validation.; [2022-03-27 05:24:09.395] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2022-03-27 05:24:09.395] [jointLog] [info] The use of range-factorized equivalence classes does not make sense in conjunction with --hardFilter. Disabling range-factorized equivalence classes. ; [2022-03-27 05:24:09.395] [jointLog] [info] Setting consensusSlack to selective-alignment default of 0.35.; [2022-03-27 05:24:09.395] [jointLog] [info] Using default value of 0.87 for minScoreFraction in Alevin; Using default value of 0.6 for consensu",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/763#issuecomment-1082597942:4136,log,log,4136,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/763#issuecomment-1082597942,1,['log'],['log']
Testability,"which we are making the inference are actually changing. It is possible e.g. that some uniquely mapped reads may not be chosen in some bootstrap sample (since we are re-sampling the observed read count, but doing so _with replacement_), and so the estimates of sets of related isoforms will change in those samples. Thus, since the observations themselves are changing, we expect the estimates to display greater variance. In fact, this is the main goal of performing the bootstrapping (or Gibbs sampling) — to estimate the uncertainty due to inference if we had observed many reads coming from the same underlying ""population"" as the ones we have in our specific sample, but subject to the random sampling effect induced by sequencing and all of the subsequent downstream effects it has on our estimator (i.e. salmon's computational procedure for estimating transcript abundance via the variational Bayesian optimization algorithm). From the practical perspective, one would not necessarily expect taking the average of the bootstrap estimates to produce a more accurate point estimate than taking the normal point estimate produced by salmon. The main purpose of performing the Gibbs sampling or bootstrapping is to allow accurate assessment of the _posterior variance_ of the point estimates (to build things like credible intervals). The mean of the bootstrap estimates should be highly-correlated with the normal point estimates, but I wouldn't expect it to be identical. Also, you might try seeing what you get with a different summary statistic, like the median. However, the main point of producing this information is to allow you to assess the posterior variance, and also to pass these samples to uncertainty-aware differential analysis tools, like [swish](https://academic.oup.com/nar/article/47/18/e105/5542870), downstream of salmon. . Anyway, thanks again for the detailed report! We'll look into the logging issue, and please let me know if my description above answers your question.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/466#issuecomment-568828362:3308,log,logging,3308,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/466#issuecomment-568828362,2,['log'],['logging']
Testability,"x rel diff.; = 0.229724; [2020-06-16 00:01:10.426] [jointLog] [info] iteration = 600 | max rel diff.; = 0.242741; [2020-06-16 00:01:12.163] [jointLog] [info] iteration = 700 | max rel diff.; = 0.196958; [2020-06-16 00:01:14.015] [jointLog] [info] iteration = 800 | max rel diff.; = 0.239461; [2020-06-16 00:01:15.803] [jointLog] [info] iteration = 900 | max rel diff.; = 0.197651; [2020-06-16 00:01:17.095] [jointLog] [info] iteration = 969 | max rel diff.; = 0.00714824; [2020-06-16 00:01:17.131] [jointLog] [info] Finished optimizer; [2020-06-16 00:01:17.131] [jointLog] [info] writing output. ```. So, you can note that the number of mappings discarded because of alignment; score is still quite big (134M) and, indeed, this took longer than I would; normally expect for; a sample with ~30M reads. However, it is _massively_ smaller (~116 times); than the 15.6B in your run. Thus, it may have been the same issue as in; the other GitHub issue. You can try the pre-compiled linux binary I linked; there if you have access to a linux machine to test on. By the way, the; issue there was a bunch of reads plagued by super-repetitive homopolymer; segments, I haven't looked at these reads yet for evidence of that though. On Mon, Jun 15, 2020 at 11:09 PM shalercr <notifications@github.com> wrote:. >; >; >; >; >; > Hi Rob,; >; >; > Thanks for the quick response. The other computer was OSX, should I try a; > linux machine?; >; >; > Here are some dropbox links to two of the files. I believe this is the set; > for the logs I posted.; >; >; > https://www.dropbox.com/s/8c3p9hmgmadgj89/31_1.trimmed.fastq.gz?dl=0; >; >; > https://www.dropbox.com/s/2y9jfvaphe9h21x/31_2.trimmed.fastq.gz?dl=0; >; >; >; >; > Thanks,; >; >; > Ryan; >; >; >; >; >; > On Jun 15, 2020, at 9:32 PM, Rob Patro <notifications@github.com> wrote:; >; >; >; >; > Thank you for the report. Can you share one of the samples where you see; > this issue? Also, out of curiosity, was the other machine you tried on also; > OSX, or was ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/537#issuecomment-644527727:5009,test,test,5009,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/537#issuecomment-644527727,1,['test'],['test']
Testability,"x rel diff.; = 0.229724; [2020-06-16 00:01:10.426] [jointLog] [info] iteration = 600 | max rel diff.; = 0.242741; [2020-06-16 00:01:12.163] [jointLog] [info] iteration = 700 | max rel diff.; = 0.196958; [2020-06-16 00:01:14.015] [jointLog] [info] iteration = 800 | max rel diff.; = 0.239461; [2020-06-16 00:01:15.803] [jointLog] [info] iteration = 900 | max rel diff.; = 0.197651; [2020-06-16 00:01:17.095] [jointLog] [info] iteration = 969 | max rel diff.; = 0.00714824; [2020-06-16 00:01:17.131] [jointLog] [info] Finished optimizer; [2020-06-16 00:01:17.131] [jointLog] [info] writing output; ```. So, you can note that the number of mappings discarded because of alignment; score is still quite big (134M) and, indeed, this took longer than I would; normally expect for; a sample with ~30M reads. However, it is _massively_ smaller (~116 times); than the 15.6B in your run. Thus, it may have been the same issue as in; the other GitHub issue. You can try the pre-compiled linux binary I linked; there if you have access to a linux machine to test on. By the way, the; issue there was a bunch of reads plagued by super-repetitive homopolymer; segments, I haven't looked at these reads yet for evidence of that though. On Mon, Jun 15, 2020 at 11:09 PM shalercr <notifications@github.com> wrote:. >; >; >; >; >; > Hi Rob,; >; >; > Thanks for the quick response. The other computer was OSX, should I try a; > linux machine?; >; >; > Here are some dropbox links to two of the files. I believe this is the set; > for the logs I posted.; >; >; > https://www.dropbox.com/s/8c3p9hmgmadgj89/31_1.trimmed.fastq.gz?dl=0; >; >; > https://www.dropbox.com/s/2y9jfvaphe9h21x/31_2.trimmed.fastq.gz?dl=0; >; >; >; >; > Thanks,; >; >; > Ryan; >; >; >; >; >; > On Jun 15, 2020, at 9:32 PM, Rob Patro <notifications@github.com> wrote:; >; >; >; >; > Thank you for the report. Can you share one of the samples where you see; > this issue? Also, out of curiosity, was the other machine you tried on also; > OSX, or was ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/537#issuecomment-644520228:4253,test,test,4253,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/537#issuecomment-644520228,1,['test'],['test']
Testability,"x7fffffff1e50) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10002_C29P7ACXX/libParams"", 0x7fffffff1e60) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10002_C29P7ACXX"", {st_mode=S_IFDIR|S_ISGID|0755, st_size=33280, ...}) = 0; mkdir(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10002_C29P7ACXX/libParams"", 0777) = 0; stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10002_C29P7ACXX/aux_info"", 0x7fffffff1e50) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10002_C29P7ACXX/aux_info"", 0x7fffffff1e60) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10002_C29P7ACXX"", {st_mode=S_IFDIR|S_ISGID|0755, st_size=33280, ...}) = 0; mkdir(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10002_C29P7ACXX/aux_info"", 0777) = 0; open(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10002_C29P7ACXX/logs/salmon_quant.log"", O_WRONLY|O_CREAT|O_APPEND, 0666) = 3; fstat(3, {st_mode=S_IFREG|0644, st_size=0, ...}) = 0; mmap(NULL, 4194304, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7fffbea00000; fstat(3, {st_mode=S_IFREG|0644, st_size=0, ...}) = 0; lseek(3, 0, SEEK_SET) = 0; mmap(NULL, 8388608, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_NORESERVE, -1, 0) = 0x7fffbe200000; mmap(NULL, 1073745920, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_STACK, -1, 0) = 0x7fff3e5eb000; mprotect(0x7fff3e5eb000, 4096, PROT_NONE) = 0; clone(child_stack=0x7fff7e5eaed0, flags=CLONE_VM|CLONE_FS|CLONE_FILES|CLONE_SIGHAND|CLONE_THREAD|CLONE_SYSVSEM|CLONE_SETTLS|CLONE_PARENT_SETTID|CLONE_CHILD_CLEARTID, parent_tidptr=0x7fff7e5eb9d0, tls=0x7fff7e5eb700, child_tidptr=0x7fff7e5eb9d0) = 10740; mmap(NULL, 8388608, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_NORESERVE, -1, 0) = 0x7fffbda000",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:68945,log,logs,68945,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,1,['log'],['logs']
Testability,"x7fffffff1e50) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10001_D2B1WACXX/libParams"", 0x7fffffff1e60) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10001_D2B1WACXX"", {st_mode=S_IFDIR|S_ISGID|0755, st_size=33280, ...}) = 0; mkdir(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10001_D2B1WACXX/libParams"", 0777) = 0; stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10001_D2B1WACXX/aux_info"", 0x7fffffff1e50) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10001_D2B1WACXX/aux_info"", 0x7fffffff1e60) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10001_D2B1WACXX"", {st_mode=S_IFDIR|S_ISGID|0755, st_size=33280, ...}) = 0; mkdir(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10001_D2B1WACXX/aux_info"", 0777) = 0; open(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10001_D2B1WACXX/logs/salmon_quant.log"", O_WRONLY|O_CREAT|O_APPEND, 0666) = 3; fstat(3, {st_mode=S_IFREG|0644, st_size=0, ...}) = 0; mmap(NULL, 4194304, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7fffbea00000; fstat(3, {st_mode=S_IFREG|0644, st_size=0, ...}) = 0; lseek(3, 0, SEEK_SET) = 0; mmap(NULL, 8388608, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_NORESERVE, -1, 0) = 0x7fffbe200000; mmap(NULL, 1073745920, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_STACK, -1, 0) = 0x7fff3e5eb000; mprotect(0x7fff3e5eb000, 4096, PROT_NONE) = 0; clone(child_stack=0x7fff7e5eaed0, flags=CLONE_VM|CLONE_FS|CLONE_FILES|CLONE_SIGHAND|CLONE_THREAD|CLONE_SYSVSEM|CLONE_SETTLS|CLONE_PARENT_SETTID|CLONE_CHILD_CLEARTID, parent_tidptr=0x7fff7e5eb9d0, tls=0x7fff7e5eb700, child_tidptr=0x7fff7e5eb9d0) = 51998; mmap(NULL, 8388608, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_NORESERVE, -1, 0) = 0x7fffbda000",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:107527,log,logs,107527,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,1,['log'],['logs']
Testability,"x7fffffff1e60) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10002_C29P7ACXX"", {st_mode=S_IFDIR|S_ISGID|0755, st_size=33280, ...}) = 0; mkdir(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10002_C29P7ACXX/libParams"", 0777) = 0; stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10002_C29P7ACXX/aux_info"", 0x7fffffff1e50) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10002_C29P7ACXX/aux_info"", 0x7fffffff1e60) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10002_C29P7ACXX"", {st_mode=S_IFDIR|S_ISGID|0755, st_size=33280, ...}) = 0; mkdir(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10002_C29P7ACXX/aux_info"", 0777) = 0; open(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10002_C29P7ACXX/logs/salmon_quant.log"", O_WRONLY|O_CREAT|O_APPEND, 0666) = 3; fstat(3, {st_mode=S_IFREG|0644, st_size=0, ...}) = 0; mmap(NULL, 4194304, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7fffbea00000; fstat(3, {st_mode=S_IFREG|0644, st_size=0, ...}) = 0; lseek(3, 0, SEEK_SET) = 0; mmap(NULL, 8388608, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_NORESERVE, -1, 0) = 0x7fffbe200000; mmap(NULL, 1073745920, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_STACK, -1, 0) = 0x7fff3e5eb000; mprotect(0x7fff3e5eb000, 4096, PROT_NONE) = 0; clone(child_stack=0x7fff7e5eaed0, flags=CLONE_VM|CLONE_FS|CLONE_FILES|CLONE_SIGHAND|CLONE_THREAD|CLONE_SYSVSEM|CLONE_SETTLS|CLONE_PARENT_SETTID|CLONE_CHILD_CLEARTID, parent_tidptr=0x7fff7e5eb9d0, tls=0x7fff7e5eb700, child_tidptr=0x7fff7e5eb9d0) = 10740; mmap(NULL, 8388608, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_NORESERVE, -1, 0) = 0x7fffbda00000; mmap(NULL, 1073745920, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_STACK, -1, 0) = 0x7ffefe5ea000; mprotect(0x7ffefe5ea000, 4096, PROT_NONE",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:68963,log,log,68963,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,1,['log'],['log']
Testability,"x7fffffff1e60) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10001_D2B1WACXX"", {st_mode=S_IFDIR|S_ISGID|0755, st_size=33280, ...}) = 0; mkdir(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10001_D2B1WACXX/libParams"", 0777) = 0; stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10001_D2B1WACXX/aux_info"", 0x7fffffff1e50) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10001_D2B1WACXX/aux_info"", 0x7fffffff1e60) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10001_D2B1WACXX"", {st_mode=S_IFDIR|S_ISGID|0755, st_size=33280, ...}) = 0; mkdir(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10001_D2B1WACXX/aux_info"", 0777) = 0; open(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10001_D2B1WACXX/logs/salmon_quant.log"", O_WRONLY|O_CREAT|O_APPEND, 0666) = 3; fstat(3, {st_mode=S_IFREG|0644, st_size=0, ...}) = 0; mmap(NULL, 4194304, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7fffbea00000; fstat(3, {st_mode=S_IFREG|0644, st_size=0, ...}) = 0; lseek(3, 0, SEEK_SET) = 0; mmap(NULL, 8388608, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_NORESERVE, -1, 0) = 0x7fffbe200000; mmap(NULL, 1073745920, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_STACK, -1, 0) = 0x7fff3e5eb000; mprotect(0x7fff3e5eb000, 4096, PROT_NONE) = 0; clone(child_stack=0x7fff7e5eaed0, flags=CLONE_VM|CLONE_FS|CLONE_FILES|CLONE_SIGHAND|CLONE_THREAD|CLONE_SYSVSEM|CLONE_SETTLS|CLONE_PARENT_SETTID|CLONE_CHILD_CLEARTID, parent_tidptr=0x7fff7e5eb9d0, tls=0x7fff7e5eb700, child_tidptr=0x7fff7e5eb9d0) = 51998; mmap(NULL, 8388608, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_NORESERVE, -1, 0) = 0x7fffbda00000; mmap(NULL, 1073745920, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_STACK, -1, 0) = 0x7ffefe5ea000; mprotect(0x7ffefe5ea000, 4096, PROT_NONE",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:107545,log,log,107545,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,1,['log'],['log']
Testability,"yes `--no-version-check` does the trick, but among all the users of the cluster I'm pretty sure some of them will forgot ;-). on our local installation I disabled the getVersionMessage even if salmon handle the no network cleanly. (I tested using `unshare -n salmon whatever you want`); NB debian maintainer also disabled the phone home call in their packages. sorry if it it may sound harsh",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/486#issuecomment-617310271:234,test,tested,234,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/486#issuecomment-617310271,1,['test'],['tested']
Testability,"ype` after the set of reads), my run still completed successfully (and didn't produce any warnings during Gibbs sampling). Salmon's behavior when running in unstranded mode on stranded data is simply to map the reads in the orientation they match, and to report on the console (and in the log) that there was a mapping bias (i.e. that the data look stranded). Specifically, here is what I get when I run (a close approximation of) your command. ```; $salmon quant --index Salmon_index_hg38.analysisSet_knownGene --unmatedReads SRR2454059.fq.gz --libType ISF --useVBOpt --output test_quant --; numGibbsSamples 100 --threads 16; Version Info: This is the most recent **development version** of Salmon.; ### salmon (mapping-based) v0.7.3; ### [ program ] => salmon; ### [ command ] => quant; ### [ index ] => { Salmon_index_hg38.analysisSet_knownGene }; ### [ unmatedReads ] => { SRR2454059.fq.gz }; ### [ libType ] => { ISF }; ### [ useVBOpt ] => { }; ### [ output ] => { test_quant }; ### [ numGibbsSamples ] => { 100 }; ### [ threads ] => { 16 }; Logs will be written to test_quant/logs; [2016-12-13 22:38:54.413] [jointLog] [info] parsing read library format; [2016-12-13 22:38:54.413] [jointLog] [info] There is 1 library.; [2016-12-13 22:38:56.240] [stderrLog] [info] Loading Suffix Array; [2016-12-13 22:38:56.240] [jointLog] [info] Loading Quasi index; [2016-12-13 22:38:56.240] [jointLog] [info] Loading 32-bit quasi index; [2016-12-13 22:39:01.268] [stderrLog] [info] Loading Transcript Info; [2016-12-13 22:39:02.630] [stderrLog] [info] Loading Rank-Select Bit Array; [2016-12-13 22:39:03.041] [stderrLog] [info] There were 182608 set bits in the bit array; [2016-12-13 22:39:03.159] [stderrLog] [info] Computing transcript lengths; [2016-12-13 22:39:03.160] [stderrLog] [info] Waiting to finish loading hash; [2016-12-13 22:39:07.653] [stderrLog] [info] Done loading index; [2016-12-13 22:39:07.653] [jointLog] [info] done; [2016-12-13 22:39:07.653] [jointLog] [info] Index contained 182608 ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-266934878:1151,Log,Logs,1151,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-266934878,3,"['Log', 'log']","['Logs', 'logs']"
Testability,"{Boost_FOUND}""); find_package(Boost 1.57.0 COMPONENTS iostreams filesystem system thread timer chrono program_options); message(""BOOST_INCLUDEDIR = ${BOOST_INCLUDEDIR}""); message(""BOOST_LIBRARYDIR = ${BOOST_LIBRARYDIR}""); message(""Boost_FOUND 1.57.0 = ${Boost_FOUND}""); set(Boost_FOUND ""1""); message(""Boost_FOUND FORCED = ${Boost_FOUND}""); include(ExternalProject); ```; This emits:; ```. -- Could NOT find Boost; Boost_FOUND 1.57 = 0; -- Could NOT find Boost; BOOST_INCLUDEDIR = /usr/include/boost157; BOOST_LIBRARYDIR = /usr/lib64; Boost_FOUND 1.57.0 = 0; Boost_FOUND FORCED = 1; BOOST INCLUDE DIR = /usr/include/boost157; BOOST INCLUDE DIRS = /usr/include/boost157; BOOST LIB DIR = /usr/lib64; BOOST LIBRARIES = ; ```; That at least allowed cmake to complete when it was run with:. `nice scl enable devtoolset-4 '~/bin/cmake -DCMAKE_VERBOSE_MAKEFILE:BOOL=ON -DBoost_NO_BOOST_CMAKE=BOOL:ON -DBOOST_LIBRARYDIR=/usr/lib64 -DBOOST_INCLUDEDIR=/usr/include/boost157 ../CMakeLists.txt' >try_cmake.log 2>&1 &; `. Then tried to build it. ```; cd ..; nice scl enable devtoolset-4 'make' >build_2018_06_13d.log 2>&1 &. ```. It failed at this command because of missing boost symbols in a link operation, my reading is that the command does not include anything to link boost libraries. So telling cmake where the libraries are, where the include files are, and that boost was found was not sufficient. There must be some other set of symbols which need to be defined. `/opt/rh/devtoolset-4/root/usr/bin/c++ -pthread -ftree-vectorize -funroll-loops -fPIC -fomit-frame-pointer -O3 -DRAPMAP_SALMON_SUPPORT -DHAVE_ANSI_TERM -DHAVE_SSTREAM -Wall -Wno-unknown-pragmas -Wno-reorder -Wno-unused-variable -std=c++11 -Wreturn-type -Werror=return-type -Wno-unused-function -Wno-unused-local-typedef -static-libstdc++ -Wno-unused-local-typedefs -pthread -ftree-vectorize -funroll-loops -fPIC -fomit-frame-pointer -O3 -DRAPMAP_SALMON_SUPPORT -DHAVE_ANSI_TERM -DHAVE_SSTREAM -Wall -Wno-unknown-pragmas -Wno-reorder -Wno-un",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/236#issuecomment-397025719:1477,log,log,1477,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/236#issuecomment-397025719,1,['log'],['log']
Usability," >when you say cellranger subsampling, do you mean the cellranger aggregate pipeline?. Yes, sorry for not clearly stating it. I did use the cellranger aggregate function indeed, which by default subsample the expression matrices with high sequencing depth depending on amount of mapped reads, if I understand well. >Use Alevin w/o any modification to the fastq on both of your sample to generate the gene count matrices. I already did that, in downstream analyses I have a batch effect issue related to the sequencing depth. >that's why we recommend using the Seurat package downstream of the Alevin quantified matrices. I have some experience with downstream analyses with Seurat, Pagoda, Scater, scanpy and a few other tools, and I am aware of batch correction methods like CCA or MNN. But that is not what I am looking for here. I did both CCA and MNN but I loose some important information in the resulting eigenspaces or corrected matrix. I believe the proper way to correct my batch effect is to simply fix the difference between my two libraries, ie. the sequencing depth in this case. As I explained in my first message, cellranger aggregate (subsampling based on the amount of mapped reads) works very well in my case, correct the effect without any loss or modification of important genes in our scientific question. Not CCA or MNN. I would like to be able to do the same from the alevin quantifications. So I am looking for a proper way to apply a correction before/during/after the alevin quantification, in a way similar to what cellranger do with STAR. Alternatively, could a subsampling covariate be added to the probalistic quantification model of alevin (if I understand it well), in sort that such a discrepency bewteen samples would be corrected?. I did look at the mappedUMI file:. ![image](https://user-images.githubusercontent.com/34892073/47551835-85ef9380-d903-11e8-893f-2a684576437b.png). So an option you would recommend is to simply compute the subsampling coefficient for ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/305#issuecomment-433319913:1611,simpl,simply,1611,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/305#issuecomment-433319913,2,['simpl'],['simply']
Usability," BAM Unsorted --quantMode TranscriptomeSAM --outSAMattributes NH HI AS NM MD --quantTranscriptomeBan IndelSoftclipSingleend`; note that last parameter that I will come back to later. Also, the paper referenced above also describes a new capability present in recent versions of salmon that allow it to index the entire genome (as well as the transcriptome) to have the former act as a decoy. This allows avoiding what might otherwise be spurious mappings that result when one considers only the transcriptome as a source of mapping. There are a number of ways to proceed on this front, but this is a good place to first check for discrepancy (and the paper gives a good overview of the relative tradeoffs and merits of different alignment approaches). * Salmon and RSEM use related but distinct optimization algorithms by default. RSEM uses the EM algorithm, and salmon uses the variational Bayesian EM algorithm. The latter tends to induce more sparse solutions. This is simply because they are optimizing slightly different objectives. It is very difficult to say in general if one is ""better"" than the other in a blanket way, but [there is previous literature to support that the VBEM may be more accurate](https://academic.oup.com/bioinformatics/article/29/18/2292/239795). However, while RSEM only implements the EM algorithm, salmon actually implements and provides a switch to use either. So, if you want to test the effect of this difference, you can run salmon with the `--useEM` algorithm. This will tell salmon to use the ""classic"" EM algorithm and will eliminate this source of variation. * As with the other question you asked, there may be a _small_ discrepancy depending on when enforcement of a stranded library kicks in under salmon's `A` library type. You can eliminate that variable by simply providing `-l SF` to match the library type being used with RSEM. * Coming back to the `IndelSoftclipSingleend` parameter I mentioned in the first point; RSEM disallows indels in the align",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/612#issuecomment-758004590:2839,simpl,simply,2839,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/612#issuecomment-758004590,2,['simpl'],['simply']
Usability," anot.pre$premature_group <- sapply(; split(; names(anot.pre),; paste(anot.pre$gene_id, anot.pre$transcript_range, sep = '_'); ),; paste, collapse = ';'; )[; paste(anot.pre$gene_id, anot.pre$transcript_range, sep = '_'); ]. # ... need to convert GR to data.table before unique because unique method for GR class ignores metadata and rownames; anot.pre <- as.data.table(anot.pre) %>% unique %>% makeGRangesFromDataFrame(., keep.extra.columns = T); names(anot.pre) <- anot.pre$premature_group. ### Read human genome sequence ####; message('Loading genome sequence...'). dna <- readDNAStringSet(filepath = genome.fasta). # simplify chromosome names; names(dna) <- sapply(strsplit(names(dna), ' '), '[', 1). dna <- dna[chromosomes] # subset chrom 1-22, X, Y, MT. ### Read Gencode transcript sequences ####; gencode <- readDNAStringSet(gencode.tx.fasta); names(gencode) <- gsub(; pattern = '\\|.*', replacement = '',; x = names(gencode); ). ### Sample transcripts on + and - strand (and avoid premature transcripts with multiple mature counterparts for simplicity); anot.pre <- anot.pre[order(width(anot.pre), decreasing = F), ]. chosenOnesP <- anot.pre[; strand(anot.pre) == '+' & !grepl(';', anot.pre$premature_group) & anot.pre$premature_group %in% names(gencode) & !duplicated(anot.pre$premature_group) &; anot.pre$premature_group %in% anot[anot$transcript_source == 'ensembl_havana']$transcript_id; ]$premature_group[1]. chosenOnesM <- anot.pre[; strand(anot.pre) == '-' & !grepl(';', anot.pre$premature_group) & anot.pre$premature_group %in% names(gencode) & !duplicated(anot.pre$premature_group) &; anot.pre$premature_group %in% anot[anot$transcript_source == 'ensembl_havana']$transcript_id; ]$premature_group[1]. chosenOnes <- c(chosenOnesP, chosenOnesM). # subset chosed ones; anot.ori <- anot; anot.pre.ori <- anot.pre. anot <- anot[anot$transcript_id %in% chosenOnes, ]; anot.pre <- anot.pre[anot.pre$premature_group %in% chosenOnes, ]. # sanity check (make sure strand information is the same ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/655#issuecomment-826035191:6211,simpl,simplicity,6211,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/655#issuecomment-826035191,2,['simpl'],['simplicity']
Usability," corrected; [2021-01-25 16:27:07.414] [alevinLog] [info] Done indexing Barcodes; [2021-01-25 16:27:07.414] [alevinLog] [info] Total Unique barcodes found: 3896665; [2021-01-25 16:27:07.414] [alevinLog] [info] Used Barcodes except Whitelist: 3667; [2021-01-25 16:27:07.498] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify; [2021-01-25 16:27:07.498] [alevinLog] [info] parsing read library format; [2021-01-25 16:30:54.542] [alevinLog] [info] Starting optimizer; [2021-01-25 16:30:54.782] [alevinLog] [warning] mrna file not provided; using is 1 less feature for whitelisting; [2021-01-25 16:30:54.782] [alevinLog] [warning] rrna file not provided; using is 1 less feature for whitelisting; [2021-01-25 16:30:55.950] [alevinLog] [info] Total 1350278.00 UMI after deduplicating.; [2021-01-25 16:30:55.950] [alevinLog] [info] Total 30909 BiDirected Edges.; [2021-01-25 16:30:55.950] [alevinLog] [info] Total 8817 UniDirected Edges.; [2021-01-25 16:30:55.969] [alevinLog] [info] Clearing EqMap; Might take some time.; [2021-01-25 16:30:56.294] [alevinLog] [warning] Num High confidence barcodes too less 20 < 90.Can't performing whitelisting; Skipping; [2021-01-25 16:30:56.297] [alevinLog] [info] Finished optimizer. ## with `--exceptCells 7000`; > [2021-01-21 09:24:45.891] [alevinLog] [info] Found 43030 transcripts(+0 decoys, +0 short and +0 duplicate names in the index); [2021-01-21 09:24:45.942] [alevinLog] [info] Filled with 43030 txp to gene entries; [2021-01-21 09:24:45.947] [alevinLog] [info] Found all transcripts to gene mappings; [2021-01-21 09:24:45.967] [alevinLog] [info] Processing barcodes files (if Present); [2021-01-21 09:33:35.885] [alevinLog] [info] Done barcode density calculation.; [2021-01-21 09:33:35.885] [alevinLog] [info] # Barcodes Used: 188934609 / 188934609.; [2021-01-21 09:33:37.337] [alevinLog] [info] Total 10016(has 1000 low confidence) barcodes; [2021-01-21 09:33:38.202] [alevinLog] [info] Done True Barcode Sampling; [2021-01-21 09:33:39.137",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/340#issuecomment-766311567:3916,Clear,Clearing,3916,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/340#issuecomment-766311567,1,['Clear'],['Clearing']
Usability," exact read order is not. This can lead to differences in the order in which reads are processed and, as a result, differences in the initialization conditions of the optimization. The ultimate result is that for transcripts that have large inferential uncertainty, different numbers of reads can be assigned between runs. We have thought *a lot* about this behavior, what it means, and how the `NumRead` values should best be communicated to users. At the end of the day, the `NumReads` constitute the expected value of latent variables inferred in a _very_ high-dimensional space (# of parameters is at least the number of transcripts). Therefore, there are certain transcripts, whose estimated number of reads simply have _tremendous_ inferential uncertainty — and small perturbations in the initial conditions of the optimization will lead to different estimated values for their abundances. For those transcripts where you observe such fluctuations between runs, this is simply evidence that the precision that can be confidently placed on those estimates is below the degree of variation you observe. Treating these transcripts in downstream analysis as more certain can easily lead to spurious inferences regarding things like differential transcript expression or usage. . One can make an argument for trying to provide a way to enforce removal of this variation (which, granted, would be a challenge). However, the reason we decided against even attempting this is because it doesn't properly address any issue with respect to an actual biological analysis. That is, even if you could fix, precisely, the update order and initialization conditions for a specific sample to eliminate any variation between runs, almost all experiments consist of multiple samples. In other samples, the same transcript fractions could give rise to a slightly different set of observed fragments that induce exactly the same type of variation under uncertainty; and since that uncertainty is baked into the samp",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/613#issuecomment-757989858:2016,simpl,simply,2016,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/613#issuecomment-757989858,2,['simpl'],['simply']
Usability," here with alevin, so it would mis-detect cells like the shifted ones you pasted above. For SPLiT-seq, we do know exactly which barcodes go into the wells, however, so it is technically possible to restrict based on all possible known combinations of barcodes instead and be more positionally flexible. But deciding how many indel bases are allowable, and presumably doing multiple passes through the data to establish an include-list could be time-consuming. Further, the zUMIs developer rightly mentions [in this thread](https://github.com/sdparekh/zUMIs/issues/63) that there are likely going to be _many_ unused barcode combinations this way, so lots of time could be spent looking for ""cells"" that don't actually exist in the data. The authors of the paper from which our test dataset was derived describe in their methods using a Drop-seq computational framework, so I'm not sure which approach theirs is more similar to. . The simplest approach here is certainly the automatic detection, but it will come at the cost of losing meaningful reads to frameshift errors. . My guess is this falls well out of the scope of alevin, but if you're interested in improving on that, there may be a middle ground between the two approaches above, one that I'm not sure if your group or others have attempted for other methods: we could essentially do a 2-pass barcode detection. The first pass would restrict based on positions like we're already doing, and establish an include-list of possible barcodes seen in the data. Then we could pass through the barcode sequences a second time, looking only for those sequence combinations, but allowing 1-2bp flexibility in the positions they occur, potentially rescuing some of the ones missed during the first pass. This would get around the issue of searching for thousands (or more) barcodes that never exist. . However, for your above sequences in red, we would still need to somehow collapse the barcodes `GATAGACA`, `ATAGACAT`, and `ATAGACAG`, but perhaps t",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-985554883:1176,simpl,simplest,1176,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-985554883,2,['simpl'],['simplest']
Usability," read apportionment, such that as the vbPrior increased the two transcripts became increasingly similar in their final expression (presumably they would eventually hit 50/50). It's good to know how that settings affects my data, but this is not quite what I was hoping for... . Ideally, the short transcript would get nearly *all* of the reads, rather than splitting the reads 50/50 or, with the default settings, giving nearly all the reads to the longer transcript. I realized that, as a human, the reason the short transcript is obviously the dominant one is how the reads pileup in the alignment. There are hundreds of reads mapping to both transcripts, but NO reads map to the 5' of the long transcript. As I understand the selective alignment, the alignment scores are passed to the quantification step, but the *position* of the reads is not used downstream. In order to pass my human intuition along here, the software would need to pay attention to the coverage bias of the reads mapping to the transcripts and assign a penalty when two otherwise identical transcripts have a different coverage variance across the transcript. This sounds like what the --posBias flag should incorporate into the effective lengths, but it doesn't have much effect on these transcripts for me (FYI, I am getting a segfault when I run only --posBias in the current salmon version, but if I run all the models together like --gcBias --seqBias --posBias, it completes fine). . Also, my intuition for these transcripts is not really a coverage ""bias"" as much as the read depth absolutely plummeting at the 5' end of the long transcript. It would be neat if Salmon could detect these kinds of dramatic dropoffs and add a warning or something... even if not incorporating the information into the quants... it could even be a good QC step to identify large deletions/insertions over a gene body. As far as I know, there are NO rnaseq quant programs that would handle this, because even something like a STAR -> RSEM",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-623043651:1049,intuit,intuition,1049,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-623043651,2,['intuit'],['intuition']
Usability," the premature sequences in my transcript fasta against the transcript fasta from Gencode. As you can see in the smoothed dot plots below, the premature sequences of transcripts on the minus strand are in the wrong orientation and have the wrong complementarity!. ![Screenshot from 2021-04-24 00-35-05](https://user-images.githubusercontent.com/10429333/115947355-0d96c880-a495-11eb-92a6-d8d2233c8d2b.png). I included my R code below for this test case for anyone who might stumble upon this issue. Under the code headers “Mature transcript sequences” and “Premature transcript sequences”, you can observe that I used identical protocols for sequence subsetting, yet in the mature case the strand information in the GRanges seems to be disregarded when subsetting from Biostrings, but in the premature case the strand information is used. Of course, this problem is out of the scope of this forum so it will be okay to close this issue. I will reach out to the developers of GenomicRanges and Biostrings to point out this potential problem and seek their guidance. Thank you again for all your help. Rached. ```; # setwd('wd'). options(scipen = 9999). libraries <- lapply(; X = c('data.table', 'magrittr', 'rtracklayer', 'Biostrings', 'reshape2', 'ggplot2'),; FUN = library, character.only = TRUE; ). ### Inputs ####; anot.gtf <- '../../shared_data/annotations/Ensembl/Homo_sapiens.GRCh38.101.gtf.gz' # Ensembl GTF; genome.fasta <- '../../shared_data/annotations/Ensembl/Homo_sapiens.GRCh38.dna.primary_assembly.fa.gz' # Genome fasta from Ensembl; gencode.tx.fasta <- '../../shared_data/annotations/Gencode/gencode.v35.transcripts.fa.gz' # Gencode transcript FASTA. dotPlot.fname <- '../ouput/dotPlots.pdf'. ### Read exon annotations ####; message('Loading Ensembl exon annotation (1-22, X, Y, MT)...'). chromosomes <- c(1:22, 'X', 'Y', 'MT'). anot <- import(anot.gtf, feature = 'exon') %>% sort; anot <- anot[seqnames(anot) %in% chromosomes, ]. # append gene and transcript version numbers to IDs; a",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/655#issuecomment-826035191:3591,guid,guidance,3591,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/655#issuecomment-826035191,2,['guid'],['guidance']
Usability," the right end of the transcript which is inconsistent with the coverage profile and, as hoped, salmon did not assign any reads to that variant. So, in these two scenarios the default options produce nice results in line with our human intuition. 2. **Failure scenario with default options:** ; ![PDI1_example](https://user-images.githubusercontent.com/10292386/86509895-3df36600-bda0-11ea-8f0b-df0de4fefa31.png); <img width=""383"" alt=""PDI1_table"" src=""https://user-images.githubusercontent.com/10292386/86509897-40ee5680-bda0-11ea-9566-9f2bdab464f0.png"">. In this example there are four genes (oriented in the same direction) with wildly different expression levels. I added a ""PDI1_SuperTranscript"" which stretches from the 5' end of PDI1 to the 3' end of POF1 (so, all reads from all 4 genes would multimap to the super transcript). This is a contrived example to illustrate the technical details, but you could imagine similar biological scenarios, especially regarding splicing isoforms. With the default options, you get the counterintuitive result that all of the reads from just MGR1 and POF1 (the two lowest abundance transcripts) are assigned to the super transcript. EMC1 loses ~50% of its reads to the super transcript, and PDI1 only loses ~10%. I'm not showing it, but if you remove the default PDI1 transcript from the index (so it's just the super transcript + the 3 genes MGR1/EMC1/POF1), all three of them lose all of their reads to the super transcript... meaning that whether or not EMC1 gets assigned any reads depends entirely on the presence of a non-overlapping gene, PDI1, in the salmon index. This is definitely at odds with our intuition from looking at the coverage plots, but makes sense when you break all the transcripts down to a simple reads per kb equation. As before, if you turn off length modeling then all of the reads get assigned to the super transcript. I hope this was insightful and cleared up the issue a bit. Feel free to e-mail or reply here. Best,; Jason",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-653747847:6540,intuit,intuition,6540,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-653747847,6,"['clear', 'intuit', 'simpl']","['cleared', 'intuition', 'simple']"
Usability," transcripts). Similarly, if you can provide the quantification directory, we can help examine this too. If this is the case, that the posterior distributions are highly anti-correlated, it is likely that the ambiguity you are seeing is simply inherent given the alignments salmon is being provided. If you have the quantification folder resulting from the same sample using selective alignment, we could compare and contrast the two. At that point, there are a few options depending on how deeply you want to dive. You could try to see how STAR and selective alignment are mapping differently to these transcripts. One potential difference is that STAR is _a lot_ more happy to softclip reads, which selective alignment won't do by default (you can test the effect with the `--softclipOverhangs` to allow selective alignment to softclip reads that hang off the transcript end or `--softclip` to allow softclips anywhere). Note that selective alignment may _still_ be a bit more conservative than STAR about softclips simply because of the nature of the scoring function it uses. This might give you a sense if one of these alignment methodologies is more consistent with your expectations in this case. Another option is to consider doing a grouping with `terminus`. This will reduce the set of ""genes"" that you can call as DE, because it will be happy to group together transcripts from different genes. However, it should help considerably in eliminating DE from highly-uncertain point estimates. Finally, you might consider performing DE with swish (cc @mikelove as he might have some input here) rather than DESeq2 (though we've typically been using swish at the transcript level rather than the gene level). Unlike DESeq2, swish will explicitly take into account the inferential uncertainty in the abundance estimates, using the Gibbs samples produced by salmon. This will allow it to avoid spurious DE calls that might otherwise occur when you have highly uncertain transcripts that, by chance,",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/600#issuecomment-740363115:3867,simpl,simply,3867,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/600#issuecomment-740363115,2,['simpl'],['simply']
Usability,"--unmatedReads ] arg List of files containing unmated reads ; of (e.g. single-end reads); -1 [ --mates1 ] arg File containing the #1 mates; -2 [ --mates2 ] arg File containing the #2 mates. alevin-specific Options:; --noDedup Stops the pipeline after CB sequence ; correction and quasi-mapping reads.; --dropseq Use DropSeq Single Cell protocol for ; the library; --chromium Use 10x chromium v2 Single Cell ; protocol for the library.; --gemcode Use 10x gemcode v1 Single Cell protocol; for the library.; --whitelist arg File containing white-list barcodes; --noQuant Don't run downstream barcode-salmon ; model.; --naive Run Gene level naive deduplication; --noSoftMap Don't use soft-assignment for quant ; instead do hard-assignment.; --mrna arg path to a file containing mito-RNA ; gene, one per line; --rrna arg path to a file containing ribosomal ; RNA, one per line; --useCorrelation Use pair-wise pearson correlation with ; True barcodes as a feature for ; white-list creation.; --dumpfq Dump barcode modified fastq file for ; downstream analysis by using coin toss ; for multi-mapping.; --debug Enabling this mode mode will try to ; ignore segfaults based on no whitelist ; mapping or no whitelist deduplicated ; count; --dumpBfh dump the big hash with all the barcodes; and the UMI sequence.; --dumpFeatures Dump features for whitelist and ; downstream analysis.; --dumpCsvCounts Dump cell v transcripts count matrix in; csv format.; --lowRegionMinNumBarcodes arg (=200) Minimum Number of CB to use for ; learning Low confidence region ; (Default: 200).; --maxNumBarcodes arg (=100000) Maximum allowable limit to process the ; cell barcodes. (Default: 100000); --tgMap arg transcript to gene map tsv file; ```; 2) `salmon alevin -lISR -1 cells_CTTGTA_L001_R1_001.fastq.gz -2 cells_CTTGTA_L001_R2_001.fastq.gz --celseq2 -i AlevinIndex_develop/ -p 8 -o alevin_output --tgMap gencode.primary_assembly.tsv`. **The tsv I created myself (with tximport), but I don't think that is the issue here...",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/325#issuecomment-443517536:1865,learn,learning,1865,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/325#issuecomment-443517536,2,['learn'],['learning']
Usability,"-0.7.12.3/bwamem.c; bwa-0.7.12.3/bwamem.h; bwa-0.7.12.3/bwamem_extra.c; bwa-0.7.12.3/bwamem_pair.c; bwa-0.7.12.3/bwape.c; bwa-0.7.12.3/bwase.c; bwa-0.7.12.3/bwase.h; bwa-0.7.12.3/bwaseqio.c; bwa-0.7.12.3/bwashm.c; bwa-0.7.12.3/bwt.c; bwa-0.7.12.3/bwt.h; bwa-0.7.12.3/bwt_gen.c; bwa-0.7.12.3/bwt_lite.c; bwa-0.7.12.3/bwt_lite.h; bwa-0.7.12.3/bwtaln.c; bwa-0.7.12.3/bwtaln.h; bwa-0.7.12.3/bwtgap.c; bwa-0.7.12.3/bwtgap.h; bwa-0.7.12.3/bwtindex.c; bwa-0.7.12.3/bwtsw2.h; bwa-0.7.12.3/bwtsw2_aux.c; bwa-0.7.12.3/bwtsw2_chain.c; bwa-0.7.12.3/bwtsw2_core.c; bwa-0.7.12.3/bwtsw2_main.c; bwa-0.7.12.3/bwtsw2_pair.c; bwa-0.7.12.3/example.c; bwa-0.7.12.3/fastmap.c; bwa-0.7.12.3/is.c; bwa-0.7.12.3/kbtree.h; bwa-0.7.12.3/khash.h; bwa-0.7.12.3/kopen.c; bwa-0.7.12.3/kseq.h; bwa-0.7.12.3/ksort.h; bwa-0.7.12.3/kstring.c; bwa-0.7.12.3/kstring.h; bwa-0.7.12.3/ksw.c; bwa-0.7.12.3/ksw.h; bwa-0.7.12.3/kthread.c; bwa-0.7.12.3/kvec.h; bwa-0.7.12.3/main.c; bwa-0.7.12.3/malloc_wrap.c; bwa-0.7.12.3/malloc_wrap.h; bwa-0.7.12.3/maxk.c; bwa-0.7.12.3/pemerge.c; bwa-0.7.12.3/qualfa2fq.pl; bwa-0.7.12.3/utils.c; bwa-0.7.12.3/utils.h; bwa-0.7.12.3/xa2multi.pl; [ 50%] No patch step for 'libbwa'; [ 50%] No update step for 'libbwa'; [ 51%] No configure step for 'libbwa'; [ 51%] Performing build step for 'libbwa'; /bin/ld: cannot find -lz; collect2: error: ld returned 1 exit status; make[3]: *** [bwa] Error 1; make[2]: *** [libbwa-prefix/src/libbwa-stamp/libbwa-build] Error 2; make[1]: *** [CMakeFiles/libbwa.dir/all] Error 2; make: *** [all] Error 2. So as you said I'd say its having issued finding the zlibs library. Similar to how I used 'DZLIB_LIBRARY=/users/work/jake/bin/zlib-1.2.11/zlib.h' to specify the zlib library for 'cmake', is there a way to do it for the 'make' command? I've tried using the following but haven't had success:; make -I /users/work/jake/bin/zlib-1.2.11/zlib.h; make --include-dir=/users/work/jake/bin/zlib-1.2.11/zlib.h. Sorry for the very basic questions.... I'm kind of learning as I go.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/141#issuecomment-314451873:4138,learn,learning,4138,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/141#issuecomment-314451873,2,['learn'],['learning']
Usability,".1',; 'ENST00000493496.5',; 'ENST00000460361.1',; 'ENST00000441953.6',; 'ENST00000431735.6',; 'ENST00000462670.1',; 'ENST00000491795.5',; 'ENST00000468378.1',; 'ENST00000383214.8',; 'ENST00000383213.8',; 'ENST00000486373.5',; 'ENST00000491702.1',; 'ENST00000478834.1',; 'ENST00000444757.5',; 'ENST00000429042.5',; 'ENST00000454420.5',; 'ENST00000425069.5',; 'ENST00000414757.5',; 'ENST00000414916.5']; ```; and, the other transcript is connected to ; ```; ['ENST00000376621.7',; 'ENST00000487166.1',; 'ENST00000383450.3',; 'ENST00000497332.1',; 'ENST00000441604.5',; 'ENST00000481420.1',; 'ENST00000487687.1',; 'ENST00000454829.5',; 'ENST00000490227.1',; 'ENST00000437917.5',; 'ENST00000481380.1',; 'ENST00000383596.6',; 'ENST00000488456.1',; 'ENST00000417834.5',; 'ENST00000486264.1',; 'ENST00000462708.1',; 'ENST00000478748.1',; 'ENST00000465483.1',; 'ENST00000478986.1',; 'ENST00000480572.1',; 'ENST00000497917.1',; 'ENST00000469494.1',; 'ENST00000489631.1',; 'ENST00000433809.1',; 'ENST00000456550.1',; 'ENST00000450423.1',; 'ENST00000435788.1',; 'ENST00000416639.1',; 'ENST00000443235.1',; 'ENST00000458592.1',; 'ENST00000430236.1',; 'ENST00000464231.1',; 'ENST00000496960.1',; 'ENST00000492408.1',; 'ENST00000479883.1',; 'ENST00000467241.1',; 'ENST00000483987.1',; 'ENST00000495838.1',; 'ENST00000467550.1']; ```; Clearly, in the alignment-based is connected to a lot of other transcripts connected, so their different behaviors is expected. ; I think this makes the solution so unstable that EM assigns all the reads to one rather than distributing them to other members. We need to look at the actual bootstrap/gibbs to have more insight. . I would also like to add, as @rob-p suggested previously, this is a classic example where EM algorithm is not that reliable, b/c of uncertainty and `terminus` might be the best answer. . Here is the [script](https://gist.github.com/hiraksarkar/30d8ce2d52035181e00be1479be50a57) for constructing the graph from the equivalence class file. . Best; Hirak",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/600#issuecomment-757504634:2329,Clear,Clearly,2329,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/600#issuecomment-757504634,1,['Clear'],['Clearly']
Usability,"1/3 loss in performance seems significant, given that presumably the code does something else than just parsing UMIs. I am looking at Boost own comparison and benchmarks, and on long inputs (20MB) it is competitive with PCRE2. But with short inputs (20-30 characters) PCRE2 is consistently faster (by about 30% :thinking: ). And if PCRE2 is feature full, not sure it is the fastest either, especially for simple regexp.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/734#issuecomment-1023320721:405,simpl,simple,405,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/734#issuecomment-1023320721,2,['simpl'],['simple']
Usability,"10x Genomics Chromium genomic DNA sequencing selects roughly one million barcodes at random with replacement from a possible pool of four million barcodes. Most errors likely result from DNA oligo synthesis rather than sequencing errors (intuition but unconfirmed). There's on other open source tool that does this task `ema preproc`: https://github.com/arshajii/ema#usage. The authors of `ema` have reported that correcting off-by-one errors is sufficient. Their tool corrects off-by-one errors by default, and can optionally correct off-by-two errors. Long Ranger Basic corrects off-by-two errors. The uncorrected barcode may be stored in the `RX:Z` tag. The corrected barcode is stored in the `BX:Z` tag. Thanks for considering this feature request!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/233#issuecomment-395182521:238,intuit,intuition,238,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/233#issuecomment-395182521,2,['intuit'],['intuition']
Usability,200250[0m / [31m52200250[0m.; > [2020-06-04 12:42:01.300] [alevinLog] [info] Forcing to use 200000 cells; > [2020-06-04 12:42:02.037] [alevinLog] [info] Throwing 0 barcodes with < 1 reads; > [2020-06-04 12:42:02.738] [alevinLog] [info] Total [32m197328[0m(has [32m101[0m low confidence) barcodes; > [2020-06-04 12:42:03.656] [alevinLog] [info] Done True Barcode Sampling; > [2020-06-04 12:42:03.830] [alevinLog] [info] Total 0.780192% reads will be thrown away because of noisy Cellular barcodes.; > [2020-06-04 12:42:13.353] [alevinLog] [info] Done populating Z matrix; > [2020-06-04 12:42:13.353] [alevinLog] [info] Total 0 CB got sequence corrected; > [2020-06-04 12:42:13.353] [alevinLog] [info] Done indexing Barcodes; > [2020-06-04 12:42:13.353] [alevinLog] [info] Total Unique barcodes found: 604589; > [2020-06-04 12:42:13.353] [alevinLog] [info] Used Barcodes except Whitelist: 0; > [2020-06-04 12:42:13.555] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify; > ; > [2020-06-04 12:42:13.556] [alevinLog] [info] parsing read library format; > [2020-06-04 12:43:22.789] [alevinLog] [info] Starting optimizer; > ; > [2020-06-04 12:43:23.499] [alevinLog] [warning] mrna file not provided; using is 1 less feature for whitelisting; > [2020-06-04 12:43:23.499] [alevinLog] [warning] rrna file not provided; using is 1 less feature for whitelisting; > [2020-06-04 12:43:23.835] [alevinLog] [info] Total 24009.00 UMI after deduplicating.; > [2020-06-04 12:43:23.835] [alevinLog] [info] Total 89 BiDirected Edges.; > [2020-06-04 12:43:23.835] [alevinLog] [info] Total 82 UniDirected Edges.; > [2020-06-04 12:43:23.835] [alevinLog] [warning] Skipped 184123 barcodes due to No mapped read; > [2020-06-04 12:43:23.840] [alevinLog] [info] Clearing EqMap; Might take some time.; > [2020-06-04 12:43:23.846] [alevinLog] [warning] Num Low confidence barcodes too less 1 < 100.Can't performing whitelisting; Skipping; > [2020-06-04 12:43:23.846] [alevinLog] [info] Finished optimizer,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-638991199:6642,Clear,Clearing,6642,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-638991199,1,['Clear'],['Clearing']
Usability,31m52200250[0m.; > [2020-06-05 13:09:43.576] [alevinLog] [info] Forcing to use 100000 cells; > [2020-06-05 13:09:43.653] [alevinLog] [info] Throwing 0 barcodes with < 1 reads; > [2020-06-05 13:09:43.673] [alevinLog] [info] Total [32m95377[0m(has [32m11[0m low confidence) barcodes; > [2020-06-05 13:09:43.875] [alevinLog] [info] Done True Barcode Sampling; > [2020-06-05 13:09:44.027] [alevinLog] [info] Total 1.2299% reads will be thrown away because of noisy Cellular barcodes.; > [2020-06-05 13:09:48.338] [alevinLog] [info] Done populating Z matrix; > [2020-06-05 13:09:48.376] [alevinLog] [info] Total 118774 CB got sequence corrected; > [2020-06-05 13:09:48.389] [alevinLog] [info] Done indexing Barcodes; > [2020-06-05 13:09:48.389] [alevinLog] [info] Total Unique barcodes found: 604589; > [2020-06-05 13:09:48.389] [alevinLog] [info] Used Barcodes except Whitelist: 88156; > [2020-06-05 13:09:49.130] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify; > ; > [2020-06-05 13:09:49.132] [alevinLog] [info] parsing read library format; > [2020-06-05 13:11:01.670] [alevinLog] [info] Starting optimizer; > ; > ; > [2020-06-05 13:11:02.377] [alevinLog] [warning] mrna file not provided; using is 1 less feature for whitelisting; > [2020-06-05 13:11:02.377] [alevinLog] [warning] rrna file not provided; using is 1 less feature for whitelisting; > [2020-06-05 13:11:04.408] [alevinLog] [info] Total 322945.00 UMI after deduplicating.; > [2020-06-05 13:11:04.408] [alevinLog] [info] Total 15972 BiDirected Edges.; > [2020-06-05 13:11:04.408] [alevinLog] [info] Total 176951 UniDirected Edges.; > [2020-06-05 13:11:04.408] [alevinLog] [warning] Skipped 12046 barcodes due to No mapped read; > [2020-06-05 13:11:04.415] [alevinLog] [info] Clearing EqMap; Might take some time.; > [2020-06-05 13:11:04.455] [alevinLog] [warning] Num Low confidence barcodes too less 8 < 10.Can't performing whitelisting; Skipping; > [2020-06-05 13:11:04.455] [alevinLog] [info] Finished optimizer,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-639642373:2461,Clear,Clearing,2461,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-639642373,1,['Clear'],['Clearing']
Usability,31m52200250[0m.; > [2020-06-05 13:39:18.623] [alevinLog] [info] Forcing to use 100000 cells; > [2020-06-05 13:39:19.364] [alevinLog] [info] Throwing 49909 barcodes with < 10 reads; > [2020-06-05 13:39:20.065] [alevinLog] [info] Total [32m50092[0m(has [32m201[0m low confidence) barcodes; > [2020-06-05 13:39:20.928] [alevinLog] [info] Done True Barcode Sampling; > [2020-06-05 13:39:21.057] [alevinLog] [info] Total 1.70493% reads will be thrown away because of noisy Cellular barcodes.; > [2020-06-05 13:39:23.175] [alevinLog] [info] Done populating Z matrix; > [2020-06-05 13:39:23.175] [alevinLog] [info] Total 0 CB got sequence corrected; > [2020-06-05 13:39:23.175] [alevinLog] [info] Done indexing Barcodes; > [2020-06-05 13:39:23.175] [alevinLog] [info] Total Unique barcodes found: 604589; > [2020-06-05 13:39:23.175] [alevinLog] [info] Used Barcodes except Whitelist: 0; > [2020-06-05 13:39:23.278] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify; > ; > [2020-06-05 13:39:23.278] [alevinLog] [info] parsing read library format; > [2020-06-05 13:40:35.769] [alevinLog] [info] Starting optimizer; > ; > ; > [2020-06-05 13:40:36.476] [alevinLog] [warning] mrna file not provided; using is 1 less feature for whitelisting; > [2020-06-05 13:40:36.476] [alevinLog] [warning] rrna file not provided; using is 1 less feature for whitelisting; > [2020-06-05 13:40:37.933] [alevinLog] [info] Total 227279.00 UMI after deduplicating.; > [2020-06-05 13:40:37.933] [alevinLog] [info] Total 14712 BiDirected Edges.; > [2020-06-05 13:40:37.933] [alevinLog] [info] Total 173086 UniDirected Edges.; > [2020-06-05 13:40:37.933] [alevinLog] [warning] Skipped 5326 barcodes due to No mapped read; > [2020-06-05 13:40:37.936] [alevinLog] [info] Clearing EqMap; Might take some time.; > [2020-06-05 13:40:37.962] [alevinLog] [warning] Num Low confidence barcodes too less 165 < 200.Can't performing whitelisting; Skipping; > [2020-06-05 13:40:37.962] [alevinLog] [info] Finished optimizer,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-639663002:2575,Clear,Clearing,2575,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-639663002,1,['Clear'],['Clearing']
Usability,"33:39.994] [alevinLog] [info] Total Unique barcodes found: 3896665; [2021-01-21 09:33:39.994] [alevinLog] [info] Used Barcodes except Whitelist: 34503; [2021-01-21 09:33:40.718] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify; [2021-01-21 09:33:40.718] [alevinLog] [info] parsing read library format; [2021-01-21 09:48:11.430] [alevinLog] [info] Starting optimizer; [2021-01-21 09:48:12.160] [alevinLog] [warning] mrna file not provided; using is 1 less feature for whitelisting; [2021-01-21 09:48:12.160] [alevinLog] [warning] rrna file not provided; using is 1 less feature for whitelisting; [2021-01-21 09:48:36.288] [alevinLog] [info] Total 19031525.00 UMI after deduplicating.; [2021-01-21 09:48:36.288] [alevinLog] [info] Total 454402 BiDirected Edges.; [2021-01-21 09:48:36.288] [alevinLog] [info] Total 113688 UniDirected Edges.; [2021-01-21 09:48:36.288] [alevinLog] [warning] Skipped 44 barcodes due to No mapped read; [2021-01-21 09:48:36.307] [alevinLog] [info] Clearing EqMap; Might take some time.; [2021-01-21 09:48:41.314] [alevinLog] [info] Starting white listing of 9971 cells; [2021-01-21 09:48:41.314] [alevinLog] [info] Starting to make feature Matrix; [2021-01-21 09:48:41.337] [alevinLog] [info] Done making feature Matrix; [2021-01-21 09:48:41.557] [alevinLog] [info] Finished white listing; [2021-01-21 09:48:41.580] [alevinLog] [info] Finished optimizer. > {; ""total_reads"": 188934609,; ""reads_with_N"": 0,; ""noisy_cb_reads"": 98310747,; ""noisy_umi_reads"": 16600,; ""used_reads"": 90607262,; ""mapping_rate"": 18.89108045842464,; ""reads_in_eqclasses"": 35691789,; ""total_cbs"": 3896665,; ""used_cbs"": 44518,; ""initial_whitelist"": 9015,; ""low_conf_cbs"": 1000,; ""num_features"": 5,; ""no_read_mapping_cbs"": 44,; ""final_num_cbs"": 6765,; ""deduplicated_umis"": 19031525,; ""mean_umis_per_cell"": 2813,; ""mean_genes_per_cell"": 1315; }. ## My best result with `--exceptCells 30000`; > ...; [2021-01-23 11:07:52.910] [alevinLog] [info] Done barcode density calculation.; [2021-",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/340#issuecomment-766311567:6262,Clear,Clearing,6262,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/340#issuecomment-766311567,1,['Clear'],['Clearing']
Usability,":26.234] [alevinLog] [info] Total Unique barcodes found: 127233006; [2022-03-27 05:34:26.234] [alevinLog] [info] Used Barcodes except Whitelist: 50131; [2022-03-27 05:34:26.966] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify. [2022-03-27 05:34:26.966] [alevinLog] [info] parsing read library format; [2022-03-27 05:46:41.876] [alevinLog] [info] Starting optimizer. [2022-03-27 05:46:42.064] [alevinLog] [warning] mrna file not provided; using is 1 less feature for whitelisting; [2022-03-27 05:46:42.064] [alevinLog] [warning] rrna file not provided; using is 1 less feature for whitelisting; [2022-03-27 05:49:49.761] [alevinLog] [info] Total 535438.00 UMI after deduplicating.; [2022-03-27 05:49:49.761] [alevinLog] [info] Total 2317116 BiDirected Edges.; [2022-03-27 05:49:49.761] [alevinLog] [info] Total 867878 UniDirected Edges.; [2022-03-27 05:49:49.761] [alevinLog] [warning] Skipped 955 barcodes due to No mapped read; [2022-03-27 05:49:49.766] [alevinLog] [info] Clearing EqMap; Might take some time.; [2022-03-27 05:49:50.011] [alevinLog] [info] Starting white listing of 3044 cells; [2022-03-27 05:49:50.011] [alevinLog] [info] Starting to make feature Matrix; [2022-03-27 05:49:50.014] [alevinLog] [info] Done making feature Matrix; [2022-03-27 05:49:50.717] [alevinLog] [info] Finished white listing; [2022-03-27 05:49:51.422] [alevinLog] [info] Finished optimizer; ````. and the `salmon_quant.log` looks like:; ```; [2022-03-27 05:24:09.395] [jointLog] [info] setting maxHashResizeThreads to 32; [2022-03-27 05:24:09.395] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2022-03-27 05:24:09.395] [jointLog] [info] The --mimicBT2, --mimicStrictBT2 and --hardFilter flags imply mapping validation (--validateMappings). Enabling mapping validation.; [2022-03-27 05:24:09.395] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.6",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/763#issuecomment-1082597942:3701,Clear,Clearing,3701,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/763#issuecomment-1082597942,1,['Clear'],['Clearing']
Usability,":41.122] [stderrLog] [info] Done loading index. processed 0 Million fragments; hits: 161433, hits per frag: 0.32698. [2019-01-29 09:55:54.788] [alevinLog] [info] Starting optimizer; [2019-01-29 09:55:54.742] [jointLog] [info] Computed 6,346 rich equivalence classes for further processing; [2019-01-29 09:55:54.742] [jointLog] [info] Counted 80,300 total reads in the equivalence classes ; [2019-01-29 09:55:54.754] [jointLog] [warning] Only 80300 fragments were mapped, but the number of burn-in fragments was set to 5000000.; The effective lengths have been computed using the observed mappings. [2019-01-29 09:55:54.754] [jointLog] [info] Mapping rate = 8.80342%. [2019-01-29 09:55:54.754] [jointLog] [info] finished quantifyLibrary(). Analyzed 289 cells (100% of all).; [2019-01-29 09:55:56.858] [alevinLog] [info] Total 72037 UMI after deduplicating.; [2019-01-29 09:55:56.858] [alevinLog] [warning] Skipped 151 barcodes due to No mapped read; [2019-01-29 09:55:56.876] [alevinLog] [info] Clearing EqMap; Might take some time.; [2019-01-29 09:55:56.917] [alevinLog] [info] Starting Import of the gene count matrix.; [2019-01-29 09:55:57.130] [alevinLog] [info] Done Importing gene count matrix for dimension 138x19879; [2019-01-29 09:55:57.130] [alevinLog] [info] Starting dumping cell v gene counts in csv format; 0.00215799	7.4911e-08	0.000194712	11697.8	; 0.00705206	1.19109e-07	30039.7	29692.8	; [2019-01-29 09:55:59.105] [alevinLog] [info] Finished dumping csv counts; [2019-01-29 09:55:59.106] [alevinLog] [info] Starting white listing; [2019-01-29 09:55:59.107] [alevinLog] [info] Done importing order of barcodes ""quants_mat_rows.txt"" file.; [2019-01-29 09:55:59.107] [alevinLog] [info] Total 138 barcodes found; [2019-01-29 09:55:59.107] [alevinLog] [warning] mrna file not provided; using is 1 less feature for whitelisting; [2019-01-29 09:55:59.107] [alevinLog] [warning] rrna file not provided; using is 1 less feature for whitelisting; [2019-01-29 09:55:59.107] [alevinLog] [info] St",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/337#issuecomment-458481722:4498,Clear,Clearing,4498,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/337#issuecomment-458481722,1,['Clear'],['Clearing']
Usability,"> Default RPATH settings; > By default if you don't change any RPATH related settings, CMake will link the executables and shared libraries with full RPATH to all used libraries in the build tree. When installing, it will clear the RPATH of these targets so they are installed with an empty RPATH. https://cmake.org/Wiki/CMake_RPATH_handling#Default_RPATH_settings. We want this default `RPATH` behaviour from `cmake`. I'm unsure why we're getting non-default behaviour.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/70#issuecomment-239534893:222,clear,clear,222,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/70#issuecomment-239534893,2,['clear'],['clear']
Usability,"> Yep use --end 5 --umiLength 8 --barcodeLength 18. Thanks again, I forgot, however, to specify that the sequence is composed first of BC and then of UMI (BC + UMI) (I'm not sure if it was clear in the issue).; Does the command remain the same?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/494#issuecomment-601087573:189,clear,clear,189,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/494#issuecomment-601087573,2,['clear'],['clear']
Usability,"@Hoohm , I believe the custom length options looks good from our end. Feel free to reopen the issue if you face any problem while using alevin in this mode. Re: More customizable options like a regex for extracting CB and UMI is still in development and has been raised in issue #233 and will keep that issue open until we have more generic extraction. . Thanks again for the feedback and useful comments.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/247#issuecomment-412352707:376,feedback,feedback,376,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/247#issuecomment-412352707,2,['feedback'],['feedback']
Usability,"@apeltzer ,. I tried to use the pre-compiled binary myself under alpine within Docker. Initially, it suffers from the same issue (lack of a compliant libc). However, by installing the glibc compatibility layer (which was simply a few commands as laid out [here](https://github.com/sgerrand/alpine-pkg-glibc)), I was able to get the pre-compiled binary to work without issue. Actually, this layer may also fix building from source, but I have not checked yet.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/162#issuecomment-345761296:221,simpl,simply,221,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/162#issuecomment-345761296,2,['simpl'],['simply']
Usability,"@ctb — One thing that would be required for this (apart from some engineering of the command-line parsing / validation code) is a trustworthy, efficient, _multithreaded_ `FAST(A/Q)` parser for interleaved format reads. Right now, Salmon (& Sailfish, &RapMap, & most of the other HTS-centric methods we're developing) use the Jellyfish 2 read parser. I've made this choice since it's fairly simple to use, yet provides nice parallel performance and, most importantly, is fairly well-tested and trust-worthy. Can you suggest a reliable, well-tested, concurrency-enabled library for parsing reads in interleaved format?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/29#issuecomment-152827801:390,simpl,simple,390,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/29#issuecomment-152827801,2,['simpl'],['simple']
Usability,"@demis001 salmon currently makes exact matches between the fasta headers and transcript annotations in the GTF, so no - it doesn't work. Since gene level summarization is pretty simple you could just use something like https://github.com/daler/gffutils to read your GTF, drop the version numbers from the GTF entries, then drop the version numbers from the salmon quant.sf file, and join the two yourself. The summarization from tx->gene is just summing each gene's transcripts' TPM values. @rob-p: I do think this is a common enough issue that salmon could handle dropping accession.version numbers with an extra option.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/122#issuecomment-282048231:178,simpl,simple,178,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/122#issuecomment-282048231,2,['simpl'],['simple']
Usability,@hariiyer16 I have not! The index works in an older version of salmon but not the newer one even though it was built in a way that should be usable by the newer Salmon version.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/559#issuecomment-674765288:141,usab,usable,141,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/559#issuecomment-674765288,2,['usab'],['usable']
Usability,"@ialbert,. Thanks again for the detailed bug report and reproducible example for this. We (@mohsenzakeri and I) have pushed experimental support for soft-clipping to the develop branch. You can enable this feature by passing `--softclip` flag to the `quant` command. We have also made a pre-compiled binary that includes this feature [here](https://drive.google.com/open?id=1Si1BqGXLievhol-e3RWjhxzajvVHY2mS). If you have a chance to test this on some of your data to see if the soft-clipping is working as expected in IGV on a larger scale (we tested on the data you provided), we'd be happy to have any feedback. In a future version, we will likely provide the ability to write the full CIGAR string (with mismatches, indels, etc.) out, but that requires the merging and testing of two branches of pufferfish upstream, and so will probably be reserved for a future release.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/475#issuecomment-596774053:605,feedback,feedback,605,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/475#issuecomment-596774053,2,['feedback'],['feedback']
Usability,"@k3yavi — might it be worthwhile exploring the effect of changing the min score fraction here, or enabling softclipping? I do recall that this seems in the ballpark of drop-seq data mapping to the annotated (spliced) transcriptome, but is it clear _why_ the mapping rates for this technology are so low?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/738#issuecomment-1019515038:242,clear,clear,242,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/738#issuecomment-1019515038,2,['clear'],['clear']
Usability,"@k3yavi,. The backtrace seems to suggest the issue is arising from [here](https://github.com/COMBINE-lab/salmon/blob/master/src/Alevin.cpp#L648), and functions called within. Any idea how something untoward could happen with the number of threads being spawned? Also, it looks like here we are simply spawning and joining threads manually --- so we can't blame that on tbb ;P.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-395869990:294,simpl,simply,294,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-395869990,2,['simpl'],['simply']
Usability,"@mdshw5 — I certainly think that this information could be useful (and bias terms are taken into effect when computing the effective length, when bias modeling is enabled). The problem is that the position-specific start distribution is learned globally (well, conditioned on a few different length classes), rather than being transcript specific. So, it's not exactly clear how it would help too much in Shaun's case, since this is a particular transcript, where a splicing variation is causing a huge portion of the transcript to have no mapped reads. Unless this happens in many transcripts (globally), this particular transcript's contribution to the global position-specific start distribution will likely be rather small.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/8#issuecomment-237931240:237,learn,learned,237,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/8#issuecomment-237931240,4,"['clear', 'learn']","['clear', 'learned']"
Usability,"@mdshw5, the best option I've found so far is actually [rsem-prepare-reference](http://deweylab.biostat.wisc.edu/rsem/rsem-prepare-reference.html). It's a bit slower than gtf-to-fasta, but, so far, seems to do a better job producing a usable transcriptome in the general case.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/15#issuecomment-144478110:235,usab,usable,235,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/15#issuecomment-144478110,2,['usab'],['usable']
Usability,"@mohsenzakeri — if you have any insight here, I'd be interested to know your thoughts. Check out the following test from the ksw2 cli program (modified to output the contents of the `ksw_extz_t` structure:. *with extz*. ```; ./ksw2-test -s -t extz AGCAGAAGCGGGTATTGAGGAGCGTAAATTGTAGTTA TCGGGCATTACCGGATC; first second -48 max:0 max_t:-1 max_q:-1 mqe:-18 mte:-48 mqe_t:13 mte_q:16; ```. *with extz2sse*. ```; ./ksw2-test -s -t extz2_sse AGCAGAAGCGGGTATTGAGGAGCGTAAATTGTAGTTA TCGGGCATTACCGGATC; first second -48 max:0 max_t:-1 max_q:-1 mqe:-18 mte:-48 mqe_t:13 mte_q:3; ```. note, specifically, the differences in the `mte_q` field. Presumably, using the sse instructions should simply speed things up, not change the results! The strings here are taken from the actual strings for the test read. The first `AGCAGAAGCGGGTATTGAGGAGCGTAAATTGTAGTTA` is the buffer of the reference and the second `TCGGGCATTACCGGATC` is the bit of the read before the first MEM.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/475#issuecomment-574491993:677,simpl,simply,677,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/475#issuecomment-574491993,2,['simpl'],['simply']
Usability,"@mousepixels Apologies for slow reply, I found myself circling back to this same issue with another project and thought I'd update the thread. Seems like there was some guidance all along regarding dealing with ONT data. See this [link ](https://combine-lab.github.io/salmon-tutorials/2021/ont-long-read-quantification/). . To summarize, looks like they advise _-N 100 -p 1.0_ for minimap2, which coincidently is what I have been doing as well. Hope that's helpful if you haven't already come up with a strategy.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/790#issuecomment-2028185516:169,guid,guidance,169,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/790#issuecomment-2028185516,2,['guid'],['guidance']
Usability,"@rob-p . I did notice that the header was missing so I am looking into getting the original. I downloaded/unzipped the files you sent and seem to still have the same issue, though. ; ```; $ conda activate salmon; $ cd ~/opt/anaconda2/envs/salmon; $ ./bin/salmon quant -l IU -t transcripts.fa -a sample_alignments.sam -o quant_directory; Version Info: This is the most recent version of salmon.; # salmon (alignment-based) v1.2.0; # [ program ] => salmon ; # [ command ] => quant ; # [ libType ] => { IU }; # [ targets ] => { transcripts.fa }; # [ alignments ] => { sample_alignments.sam }; # [ output ] => { quant_directory }; Logs will be written to quant_directory/logs; [2020-04-21 11:46:41.365] [jointLog] [critical] Note: Alignment-free mapping (i.e. mapping without subsequent selective-alignment) has not yet been throughly tested under the pufferfish-based index and using the pufferfish-based mapping strategies. Thus, disabling of selective-alignment is not currently allowed. We may, potentially explore re-enabling this option in future versions of salmon. ```. To set up Salmon, I entered the following per the Getting Started Guide:; `$ conda config --add channels conda-forge`; `$ conda config --add channels bioconda`; `$ conda create -n salmon salmon`. Then, set the wd to `~opt/anaconda2/envs/salmon`. To run, I dropped the `transcripts.fa` and `seq.bam`/`seq.sam` file into the ~opt/anaconda2/envs/salmon and ran it. I noticed that if I moved the files to an entirely separate directory or deleted them all together and ran `./bin/salmon quant -l IU -t transcripts.fa -a sample_alignments.sam -o quant_directory`, the same error came up. Is it possible that there is an issue with Salmon reading the files?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/511#issuecomment-617263834:1140,Guid,Guide,1140,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/511#issuecomment-617263834,1,['Guid'],['Guide']
Usability,@rob-p Thank you very much for the clear explanation. That answers my question.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/510#issuecomment-617275380:35,clear,clear,35,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/510#issuecomment-617275380,2,['clear'],['clear']
Usability,"@rob-p can you elaborate on this a bit more: . > The effect of --minScoreFraction depends, to some extent, on how you set the match/mismatch/gap parameters. With the default parameters, 0.9 is actually higher than 90% sequence identity, because the default mismatch penalty is twice the match score. If you assume only matches and mismatches, then the --minScoreFraction you want to set is the one such that x * (match_score * read_length) <= (match_score * read_length) - (m * read_length * match_score) + (m * read_length * mismatch_penalty), where m is the mismatch fraction (0.1 in your case). So, for example, if the match_score is 2 and mismatch penalty is -4, and the read length is 100, you want to set it so that: x * 200 = 200 - (0.1 * 100 * 2) + (0.1 * 100 * -4) = 200 - 20 - 40 = 140 so, the appropriate x would be ~0.7. Of course, if you want to make the calculation simple, you can set the match score to 1 and mismatch penalty to 0, and then the interpretation (modulo gaps) is straightforward (and 0.9 means what you want). Would the two parameter sets mentioned above have the same effect assuming read length 100?. Also, it says Alevin has a default minScoreFraction of 0.87. Would it be safe to assume differentiating between isoforms with Alevin is a similar problem to differentiating between orthologous genes in metagenomics/transcriptomics?. Which parameters would be relevant to control for this?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/330#issuecomment-2249029869:880,simpl,simple,880,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/330#issuecomment-2249029869,2,['simpl'],['simple']
Usability,"@roryk I don't think an R package is the right answer :) . My real motivation is to load into Degust: http://www.vicbioinformatics.com/degust/. It can be done with simple Unix cut/paste or with a python script too. But I don't want to depend on R for the pipeline, or even littler. @vals I'll take a look at your script, but still be better if part of Salmon.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/77#issuecomment-240556885:164,simpl,simple,164,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/77#issuecomment-240556885,2,['simpl'],['simple']
Usability,"@tamuanand,. Right now, I added the code to dump the _salmon_ version into versionInfo.json. Which is a standard json file that goes in the index directory. Actually, that file already contains an index version key, which is simply a number that is incremented every time there is a change made that alters the binary representation of the index on disk. That is particularly useful because not every salmon version requires re-building the index. Regarding the feature I've added. It's fairly standard practice for us to put information that is meant to be read by both humans and machines (scripts, R packages downstream, etc.) into a JSON file. This makes it easy to access it simply from many languages, and to have _some_ (but not too much) structure to this data. There are even slick command line tools for pulling info out of JSON files (like [jq](https://stedolan.github.io/jq/)). If there is a strong reason that you need the _salmon_ version in its own text file, I'm willing to oblige and duplicate the information there. Just let me know.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/498#issuecomment-605694474:225,simpl,simply,225,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/498#issuecomment-605694474,4,['simpl'],['simply']
Usability,"@tamuanand,. Thank you for pointing out the relevant literature, and I definitely appreciate your clarity on this issue. Also, I completely agree with your suggested re-wordings in the manuscript, as they correct the mistaken terminology and make the overall intent even more clear. We will be sure to address this when we revise the pre-print. Thanks again!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/365#issuecomment-499544736:276,clear,clear,276,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/365#issuecomment-499544736,2,['clear'],['clear']
Usability,"@tdsone I _think_ this is the right logic: https://github.com/COMBINE-lab/salmon/blob/master/include/LibraryTypeDetector.hpp. . The main source of my confusion on this post was that I think Salmon just chucks back 'IU' for read numbers below 50k. It confused me less on realistic read numbers. I've simplified [quite a bit](https://github.com/nf-core/rnaseq/blob/bc6189f09954c0d00a71ac43b2ccf69ef22bbd82/subworkflows/local/utils_nfcore_rnaseq_pipeline/main.nf#L587) to just work with the strandedness component, using the numbers from lib_format_counts.json. It seems to produce results broadly as expected, but might be a bit naive, for example the numbers are mappings rather than fragments which could throw things off a bit.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/938#issuecomment-2175817517:299,simpl,simplified,299,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/938#issuecomment-2175817517,2,['simpl'],['simplified']
Usability,"@vals, it shouldn't be a coverage issue, at least as compared to previous versions of Salmon. Hopefully we'll have a chance to look at this soon and see if we can figure out what might be causing the performance ""regression"" when `--useVBOpt` is enabled. As @dcjones suggests, we haven't really seen any performance degradation with the VB option in our other testing, so I suspect something characteristic of this dataset. @dcjones; it's great to see you drop by! I'm actually looking for a reasonable collection of datasets to do (automated) regression testing on new releases of salmon --- something to replace my fairly simple and manual existing regression tests. I'd greatly appreciate any suggestions or advice you may have about this! Such tests will become even more useful as we're experimenting with a few inference approaches and it would be great to have a reasonable spread of data to see the effects of different strategies.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/6#issuecomment-112224408:624,simpl,simple,624,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/6#issuecomment-112224408,2,['simpl'],['simple']
Usability,"@zhangchipku,. The default value of `--minScoreFraction` is quite reasonable, I think. It depends on the read length, but for a 100-bp read, it corresponds to 8 mismatches under the default scoring parameters. So the read pair could have up to 16 mismatches before being discarded. I understand that the recommendation to trim reads is a new one, but I think it is a standard best-practice anyway. However, we are looking at the possibility of allowing read-end soft-clipping in future releases, which could mitigate this need in the most common case. It is worth noting that, if you *don't* want to use selective alignment, then the last version of salmon that you can use is the one tagged as `0.15.0`. As of version 1.0.0, the index structure and default mapping algorithm changed, so that selective alignment is ""always on"". This is discussed in some detail in the release notes for version 1.0.0. Generally, we think that the benefits offered by selective-alignment are important, and, unless there is a very strong reason not to, one should generally ensure that reads sharing some exact matches with the reference also produce reasonable quality alignments at the implied loci. However, we also try to be very receptive and responsive to our users' workflows and desiderata, so if the soft-clipping feature is something that would make your experience much smoother, we will certainly consider prioritizing that feature for a future release.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-586478704:1231,responsiv,responsive,1231,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-586478704,2,['responsiv'],['responsive']
Usability,"A follow up on this (with a lot of help from @raungar; thanks!) led to the conclusion that the problem was that insufficient memory was allocated to the cluster job during indexing (indexing this transcriptome takes ~4.3G). Allocating more memory to the job resolves the issue. The strange thing is that the cluster manager seemed to kill the job rather than refuse to allocate the memory (which would have resulted in a `bad_alloc` exception that would have made the problem clear). So, if you're indexing with salmon on a cluster and see this behavior, be aware of the memory allocation and that the cluster software may surreptitiously kill the process rather than simply fail to allocate the memory!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/197#issuecomment-467720836:476,clear,clear,476,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/197#issuecomment-467720836,4,"['clear', 'simpl']","['clear', 'simply']"
Usability,"Actually, @mdshw5 --- it's not quite clear to me why the parser isn't doing the right thing in this case. If you take a look at how the paired-end sequence parser is actually populating the internal buffer (e.g. [here](https://github.com/COMBINE-lab/salmon/blob/master/include/PairSequenceParser.hpp#L182)), it is reading one entry from stream1 and then one entry from stream2. I'm guessing there may be some issue with having two different handles open to the same fifo? However, that doesn't seem like it should be a problem. Given the way the code is actually reading from the different streams, it's not clear to me why it's not currently working as expected. I'll try and take a deeper look.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/29#issuecomment-168563402:37,clear,clear,37,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/29#issuecomment-168563402,4,['clear'],['clear']
Usability,"Actually, I was only checking the package for building it on Debian, I don't use it personally. ; From that point of view of packaging the software for Debian it would be desirable to be able to build the software without any downloads during the build process. The reason for this is that building packages on the Debian build servers does not allow downloads for the very simple reason that this would bypass the QA checks for proper licensing of all files required to build some software (The same is true for Ubuntu and Linux distributions based on Debian). . Best, ; Gert",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/181#issuecomment-357167540:374,simpl,simple,374,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/181#issuecomment-357167540,2,['simpl'],['simple']
Usability,"Alright, I'll have a go at the simple model. @mikelove, once I have it implemented we can figure out a reasonable test. Actually, enabling the feature was _way_ easier than I thought. The actual bias application code (via re-estimation of effective lengths) can remain the same. I now have code-paths to build GC bias models treating single-end reads as equal to the _conditional_ mean fragment length (given the transcript). Let me know what you think would be a good way to test it.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/83#issuecomment-245366321:31,simpl,simple,31,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/83#issuecomment-245366321,2,['simpl'],['simple']
Usability,"Also - the problem does not happen for Danio rerio indexes, which were created on the same machine. We have also had successes with Homo sap. _short_, but not Homo sap. _long_. Is it possible that some of the indexes were simply corrupted during creation? Although you're able to map to the index I provided above. I have no idea.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/321#issuecomment-442610783:222,simpl,simply,222,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/321#issuecomment-442610783,2,['simpl'],['simply']
Usability,"Biostrings object using the GRanges object. **I believe the problem lies here.** It appears that when subsetting the mature exonic sequences from Biostrings using GRanges, the strand field in the GRanges object **was not** utilized. I.e., I needed to get the reverse complement of the extracted sequences for transcripts on the minus strand. I had done that and assumed that this behaviour would be consistent. However, for reasons I have not been able to pinpoint (potentially a bug), the strand information **was accounted for** when I used GRanges to subset the premature sequences. I **did not** need to get the reverse complement of the premature sequences on the minus strand as I had to do for the mature sequences. Yet, I did that anyway. I initially did test my protocol to ensure it produced identical transcript sequences to Gencode, but I only did this for mature sequences. All seemed fine for both + and - strand transcripts. After your feedback, I compared the premature sequences in my transcript fasta against the transcript fasta from Gencode. As you can see in the smoothed dot plots below, the premature sequences of transcripts on the minus strand are in the wrong orientation and have the wrong complementarity!. ![Screenshot from 2021-04-24 00-35-05](https://user-images.githubusercontent.com/10429333/115947355-0d96c880-a495-11eb-92a6-d8d2233c8d2b.png). I included my R code below for this test case for anyone who might stumble upon this issue. Under the code headers “Mature transcript sequences” and “Premature transcript sequences”, you can observe that I used identical protocols for sequence subsetting, yet in the mature case the strand information in the GRanges seems to be disregarded when subsetting from Biostrings, but in the premature case the strand information is used. Of course, this problem is out of the scope of this forum so it will be okay to close this issue. I will reach out to the developers of GenomicRanges and Biostrings to point out this potenti",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/655#issuecomment-826035191:2516,feedback,feedback,2516,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/655#issuecomment-826035191,2,['feedback'],['feedback']
Usability,"Choosing the top 500 barcodes from the `frequency.txt` list worked! Thanks for bringing my attention to that, I had not realized how do the cuttoff manually. You might want to expand a bit more about the `--dumpFeatures` flag in the documentation (https://salmon.readthedocs.io/en/latest/alevin.html) and possibly mention it in the tutorial (https://combine-lab.github.io/alevin-tutorial/2018/running-alevin/). I think using the `features.txt` to pick barcodes should be more clearly advertised, since it's not straightforward with cell ranger and many people will find it useful. . Thanks!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/245#issuecomment-402627049:476,clear,clearly,476,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/245#issuecomment-402627049,2,['clear'],['clearly']
Usability,"Dear @callumparr,. Thank you for bringing this up. So you are correct that the `--noLengthCorrection` flag should be passed to salmon when quantifying data that does not have a ""fragmentation effect"", that is, where the number of fragments we expect to draw from a transcript is not dependent upon the length of that transcript. In the ONT protocols, it is usually the case that we get 1 read -> 1 transcript, even if we don't read the whole thing. We have tested the effect of this in ONT data with spike ins, and have verified that using `--noLengthCorrection` does generally lead to improved accuracy with respect to quantification estimates. We have informed ONT of this, and I would guess they may optimize the flags that are used soon (we have also developed an error model that works correctly for these long reads, and that should make it into the next release of salmon). Regarding the effect this has on the `NumReads` values reported by salmon, it's not as simple as with the `TPM` estimates. The length affects the assigned reads through the probabilistic model on which inference is done. With the length effect we have that P(f | t_i) ∝ P( position | f, t_i ) * P( alignment | f, t_i) --- forgetting the alignment term for the time being, we have that with length correction P( position | f, t_i ) ∝ 1 / l_i and without length correction the l_i term goes away. In other words, the probability of allocating reads has a term that depends on the effective length when the `--noLengthCorrection` flag is not passed, but that term goes away when it is passed. This is not quite as drastic as with TPM where the normalization includes the length directly in the normalization (note, however, that when the `--noLengthCorrection` flag is passed, this adjusts the TPM as well). Further, the `NumReads` is still better than TPM in this regard because it still encodes the effect size (i.e. `NumReads` will sum to the total number of aligned reads). Anyway TLDR: Passing the `--noLengthCorrectio",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/651#issuecomment-821995147:968,simpl,simple,968,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/651#issuecomment-821995147,2,['simpl'],['simple']
Usability,"Dear @juugii,. Thanks for reporting these. Regarding . (1) : Yes, it is possible to skip the version check. Simply place `--no-version-check` before any command. For example:. ```; salmon --no-version-check index <... parameters for indexing>; ```. and . ```; salmon --no-version-check quant <... parameters for quantification>; ```; This will let you avoid the network timeout. Regarding issue (2), it's difficult to say what's happening without seeing the data. I'm looping in @k3yavi to help take a look into this.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/264#issuecomment-410255823:108,Simpl,Simply,108,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/264#issuecomment-410255823,1,['Simpl'],['Simply']
Usability,"Dear Rob,. Thank you so much for your guidance. I appreciate you taking the time to help me. I was able to run salmon, no problem. All the best,; Craig",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/520#issuecomment-625604855:38,guid,guidance,38,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/520#issuecomment-625604855,2,['guid'],['guidance']
Usability,"Dear Rob,; a brief update:; 1) with the flag -DNO_IPO=TRUE the compilation worked perfectly. thank you . 2)following a guide found at stackoverlow ([Find which assembly instruction caused an Illegal Instruction error without debugging], I discover that the illegal instruction is **vfmsubsd**. ; I am not an expert at all in the field, but googling it seems to be a standard SSE instruction.; I am surprised indeed.; cpus tested: ; Intel Xeon Gold 5220 (72) ; Intel Xeon Gold 5317 (48); Intel i7-10750H (12). Best and thanks again; Silvano. Program terminated with signal SIGILL, Illegal instruction.; #0 0x00007fa222c47396 in __ieee754_pow_fma4 () from /dataraw/mouse/salmon-1.8.0_linux_x86_64/bin/../lib/libm.so.6. 0x7fa222c47396 <__ieee754_pow_fma4+182> vfmsubsd %xmm3,%xmm6,%xmm3,%xmm7",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/783#issuecomment-1145687835:119,guid,guide,119,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/783#issuecomment-1145687835,2,['guid'],['guide']
Usability,Done the required work. Sorry for bothering everyone. Downloaded the refGene.gtf file from UCSC for mm9 having transcript information and then used `gffread` to build the transcript.fa for the mm9. Finally ran salmon indexes and to my surprise it finished in matter of few minutes < 3'. Thanks for all the suggestions. This is something which I always like getting to learn something new every day. Closing the issue.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/49#issuecomment-197975002:368,learn,learn,368,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/49#issuecomment-197975002,2,['learn'],['learn']
Usability,"Even I am not sure how to add the flags in the make command explicitly.; But, I'd suggest you can try couple of things:; Like I said before installing zlib to apt-get/brew would be the easiest.; If not can you try `-DZLIB_LIBRARY=/users/work/jake/bin/zlib-1.2.11/` i.e. remove `zlib.h`.; As you can see I am learning on the go too 😜",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/141#issuecomment-314454908:308,learn,learning,308,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/141#issuecomment-314454908,2,['learn'],['learning']
Usability,"FYI, miniconda works fine on FreeBSD. It's not too difficult to configure manually, but to make it even easier:. As root:. ```; pkg install auto-admin linux-miniconda-installer; auto-install-linux_base; ```; As a non-root user:. ```; miniconda-installer; conda-shell; conda config --add channels conda-forge; conda config --add channels bioconda; conda create -n salmon salmon; ```; Note: Just running `conda install salmon` instead of `conda create -n salmon salmon` will install a very old version rather than the latest. This utilizes the Linux compatibility module, which simply adds Linux system calls to the FreeBSD kernel. Unlike a virtual machine, there's no performance penalty and memory overhead is trivial. In fact, Linux binaries sometimes run slightly faster on FreeBSD than they do on Linux. Average speed is about the same. I'd only use conda as a stop-gap, though. There's a large and growing selection of bioinformatics software in FreeBSD ports that can be more easily installed and used, e.g. 'pkg install samtools bwa'. Also I'm working on a native FreeBSD port for salmon:. https://github.com/COMBINE-lab/salmon/issues/162. Best,. Jason",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/419#issuecomment-917648051:576,simpl,simply,576,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/419#issuecomment-917648051,2,['simpl'],['simply']
Usability,"From my somewhat superficial understanding, I have feeling that it is the only the soft clipping (deletion at either end) that causes the problem (and not INDELs in general). I think it might be better if the CIGAR string contained the soft clipping operations (the POS would still need to be shifted) of course. Right now when one visualizes the BAM file various distracting artifacts manifest themselves with both salmon and kallisto even when the POS field is correct. See the image below:. ![Alignments](https://www.ialbert.me/static/down/pseudo_alignments/pseudo_aln.png). (Top Kallisto, second Salmon, bottom Hisat. ). The soft clipped sequences are not marked as such, therefore lead to ugly misalignment at the ends, that in turn dominate the visualization. . Ideally, the pseudo-bam should look a little more like Hisat, I don't know how feasible that is though, perhaps knowing that only the ends need to be fixed makes for a simpler solution.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/475#issuecomment-574738566:936,simpl,simpler,936,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/475#issuecomment-574738566,2,['simpl'],['simpler']
Usability,Get it - here it is:; ```; [2019-07-09 09:07:39.162] [alevinLog] [info] Processing barcodes files (if Present) . ; [2019-07-09 09:16:59.454] [alevinLog] [info] Done barcode density calculation.; [2019-07-09 09:16:59.454] [alevinLog] [info] # Barcodes Used: [32m877102495[0m / [31m877935734[0m.; [2019-07-09 09:17:06.234] [alevinLog] [info] Knee found left boundary at [32m 4375 [0m; [2019-07-09 09:17:07.572] [alevinLog] [info] Gauss Corrected Boundary at [32m 795 [0m; [2019-07-09 09:17:07.572] [alevinLog] [info] Learned InvCov: 173.265 normfactor: 1097.45; [2019-07-09 09:17:07.597] [alevinLog] [info] Total 41.2673% reads will be thrown away because of noisy Cellular barcodes.; [2019-07-09 09:17:07.597] [alevinLog] [info] Total [32m1192[0m(has [32m397[0m low confidence) barcodes; [2019-07-09 09:17:07.765] [alevinLog] [info] Done True Barcode Sampling; [2019-07-09 09:17:08.039] [alevinLog] [info] Done populating Z matrix; [2019-07-09 09:17:08.067] [alevinLog] [info] Done indexing Barcodes; [2019-07-09 09:17:08.067] [alevinLog] [info] Total Unique barcodes found: 7881525; [2019-07-09 09:17:08.067] [alevinLog] [info] Used Barcodes except Whitelist: 84951; [2019-07-09 09:17:08.128] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify. [2019-07-09 09:17:08.128] [alevinLog] [info] parsing read library format; [2019-07-09 10:02:26.992] [alevinLog] [info] Starting optimizer. [2019-07-09 10:13:56.661] [alevinLog] [info] Total 99488568.00 UMI after deduplicating.; [2019-07-09 10:13:56.701] [alevinLog] [info] Clearing EqMap; Might take some time.; [2019-07-09 10:14:11.020] [alevinLog] [info] Starting Import of the gene count matrix of size 1192x60053.; [2019-07-09 10:14:11.286] [alevinLog] [info] Done initializing the empty matrix.; [2019-07-09 10:14:13.421] [alevinLog] [info] Done Importing gene count matrix for dimension 1192x60053; [2019-07-09 10:14:13.622] [alevinLog] [info] Starting white listing; [2019-07-09 10:14:13.627] [alevinLog] [info] Done imp,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/396#issuecomment-510547693:523,Learn,Learned,523,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/396#issuecomment-510547693,1,['Learn'],['Learned']
Usability,"Glad to hear that it worked for you. Thanks for the suggestions, we will surely update the document soon and be more clear about the manual cutoff.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/245#issuecomment-402759530:117,clear,clear,117,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/245#issuecomment-402759530,2,['clear'],['clear']
Usability,"Glad to hear that, let us know if you need any other help or have suggestions / feedbacks to improve Alevin.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/258#issuecomment-415102037:80,feedback,feedbacks,80,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/258#issuecomment-415102037,2,['feedback'],['feedbacks']
Usability,Great to learn that. Let us know if you have any other issue. :),MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/774#issuecomment-1185670648:9,learn,learn,9,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/774#issuecomment-1185670648,2,['learn'],['learn']
Usability,"Great; thanks for reporting this and helping us track it down. Please let us know if you run into anything else, or if you have other general feedback / suggestions regarding alevin!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-396325784:142,feedback,feedback,142,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-396325784,2,['feedback'],['feedback']
Usability,"HI @jamesrhowe ,; A couple of things, we have made major upgrades into Alevin with the release `v0.12.0` and would be releasing soon and it would take care of the problems you are facing.; We are still working on improving the tutorials and guide for using Alevin but for 10xV3 we added a new flag into `0.12.0` since the UMI length has increased; with the command line flag `--chromiumV3`. You might have to swap `--chromium` with `--chromiumV3`. I'd let you know once we release the latest version otherwise if you can compile from source, compiling `develop` should do the job for you.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/324#issuecomment-443218599:241,guid,guide,241,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/324#issuecomment-443218599,2,['guid'],['guide']
Usability,"HI @mfansler ,; Thanks for asking the very important question.; Alevin is primarily (till current release) designed to work with 3'-tagged end, droplet based sequencing where the primary assumption is that most of the reads would ideally be sequenced from the 3'-end of the molecule. Although, Salmon is a transcript quantification tool for *bulk* RNA-seq but we believe in singe-cell (3'-tagged) sequencing, generating quantification at transcript level is fundamentally hard problem to solve. Specifically, one of the reason is, a lot of transcripts share the terminal exon, and the features like length effect which are used in bulk RNA-seq to resolve ambiguity is not directly usable in single-cell for resolving the transcript ambiguity making the problem hard.; It's possible in the future that assays are designed to help incorporate more information e.g. sequencing from both 5' or 3' end sequencing or use SMART-seq2 which sequence the full molecule. In latter case people have been using Salmon as-is for generating the transcript level quantification. . _In summary_: We believe it's a trade-off based on your use case i.e. if you wan't to generate transcript level counts then most-likely single cell protocols which sequence from the full length of the molecules like smart-seq2 is better suited but if the motivation is to get higher number of cell coverage w/ decent gene-level molecule counts that's where 3'-end tagged end sequencing protocols shines most. _One Liner_; Alevin generates only gene-level counts for droplet based sequencing (til latest release v0.11.2).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/287#issuecomment-420627713:681,usab,usable,681,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/287#issuecomment-420627713,2,['usab'],['usable']
Usability,"Hello @Starahoush, greetings from Brazil! I'm an undergraduate student in Biomedical Informatics at the Federal University of Paraná, currently involved in a scientific initiation project in an immunology lab. I'm working extensively with FASTQ files from samples sequenced on the BD Rhapsody V1 platform and I've been facing a challenge: a significant portion of the reads are being discarded due to ""noisy cellular barcodes"", with around 50% of the reads affected. Could you please share if you've encountered a similar situation in your experiment or provide some guidance on how to address this issue? I appreciate your attention and assistance!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/850#issuecomment-2052164298:567,guid,guidance,567,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/850#issuecomment-2052164298,2,['guid'],['guidance']
Usability,"Hello! I did some work with the oxford nanopore error model last summer. There's a blog post about the ONT long read quantification here: https://combine-lab.github.io/salmon-tutorials/2021/ont-long-read-quantification/ . In terms of length correction, the --ont flag basically turns off length correction (since it doesn't really apply to long reads). The error model that the current version of salmon uses for the --ont flag (found in src/ONTAlignmentModel.cpp) basically bins reads by length (into 4 bins by default, I believe). Then for each bin it learns a binomial/geometric distribution for the number of errors (mismatches or indels) in the alignment of the reads in the bin, as well as distributions for the number of bases softclipped at the beginning and end of the read. It then uses these models to penalize reads that have an amount of errors/softclips that is very different from the center of the learned distribution, only if the number of errors/softclips is larger than what we expect for that bin (since a smaller than expected number of errors in the alignment is generally a good, not a bad sign for how likely the read is to map to this transcript). I'm not the original author/creator of this model, so I don't have all the details on specifics of how it works/the design decisions that went into it, but let me know if you have any other questions I can answer!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/924#issuecomment-2148242254:554,learn,learns,554,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/924#issuecomment-2148242254,4,['learn'],"['learned', 'learns']"
Usability,"Hello, @rob-p and first of all big thanks from me (and the community in general!) for being so reactive and helpful, and that's not even mentioning the tool you and your colleagues provided, which is very cool!. > do transcript assembly in these samples (using e.g. scallop or StringTie2) and then re-quantify using salmon under the expanded annotation. Could you please point me (and others who might be reading this topic) to a guide on how to convert this purported _de novo_ transcriptome to common gene/transcriptome names already known for the organism?? I am not even sure how that would work since many of us use well-known model organisms like mice or fruit flies, for which both the genome and transcriptome are well-described... What kind of genes/transcripts will I be looking at, exactly, after assembling this particular _de novo_ transcriptome which in theory came from mus musculus but in practice is only applicable to this particular single experiment???. Best regards,; Emile",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/533#issuecomment-1453502593:430,guid,guide,430,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/533#issuecomment-1453502593,2,['guid'],['guide']
Usability,"Hello,; Thank you for your guidance on this question. However, I encountered the same error despite using the latest versions of Trinityrnaseq and salmon. I ran Trinity version 2.15.1 to generate Fasta files. I attempted to use Salmon version 1.10.1 for indexing, but I encountered this exception. Upon checking the Docker link provided in the comment, I found that the salmon version listed is 1.5.0. So, I tried using Salmon 1.5.0 and encountered the same error. Could you please advise me on how to resolve this issue? Thank you. ```; $./trinityrnaseq-v2.15.1/Trinity --seqType fq --max_memory 6 --samples_file sample.txt --min_kmer_cov 2 --no_parallel_norm_stats --output trinity_test_0210_1019 --CPU 6. ... $ ~/tools/salmon-latest_linux_x86_64/bin/salmon index --index quasi --type quasi --transcripts ~/first_try_Gall/trinity_test_0210_1019.Trinity.fasta ; Version Info: This is the most recent version of salmon.; Exception : [Error: RapMap-based indexing is not supported in this version of salmon.]; /home/ubuntu/tools/salmon-latest_linux_x86_64/bin/salmon index was invoked improperly.; For usage information, try /home/ubuntu/tools/salmon-latest_linux_x86_64/bin/salmon index --help; Exiting.; ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/832#issuecomment-1990328443:27,guid,guidance,27,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/832#issuecomment-1990328443,2,['guid'],['guidance']
Usability,"Hey @jeremymsimon! I checked the protocol and the [pipeline code](https://github.com/yjzhang/split-seq-pipeline/blob/master/split_seq/tools.py). The protocol you described is v1 and the Parsebio is v2. I have implemented v2 in salmon and would be testing it this week. v1 can be similarly implemented. I read the paper and other available resources but I am not clear about the random hexamer usage and it's effects on the barcode. Can you please explain what you meant by BC1s being paired and what's the use of random hexamer, please? Thanks.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-936331597:362,clear,clear,362,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-936331597,2,['clear'],['clear']
Usability,"Hey Rob, not sure if I understood your answer. ; During cDNA synthesis, we use random 9-mer (not 6-mer). My impression from the documentation is that -seqbias can only be used if cDNA synthesis was done using 6-mer. This point is not clear in your answer for me. ; Could you please clarify?; Many thanks",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/880#issuecomment-1757735883:234,clear,clear,234,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/880#issuecomment-1757735883,2,['clear'],['clear']
Usability,"Heya, we had the same problem with unclear knee-plots like this. We make an alternative plot that looks like these. The first is on high quality data from Allon's K562 data from the original inDrop paper; a knee plot works well on this dataset. ![image](https://user-images.githubusercontent.com/414586/57312464-9e631680-70bb-11e9-961d-5bf2c3ede38a.png). and this is from blood in the Zebrafish, the data is of less good quality. The knee plot for this data wasn't clear enough to draw a reasonable cutoff but this alternative plot makes it easier to pick the cutoff:. ![image](https://user-images.githubusercontent.com/414586/57312538-c3578980-70bb-11e9-910c-84017a5dbcde.png). These plots are made like this:. ```; barcode_plot = function(bcs, sample) {; bcs_hist = hist(log10(bcs$count), plot=FALSE, n=50); fLog = bcs_hist$count; xLog = bcs_hist$mids; y = fLog * (10^xLog) / sum(fLog * (10^xLog)); print(qplot(xLog, y) + geom_point() + theme_bw() + ggtitle(sample)); return(data.frame(x=xLog, y=y, sample=sample)); }; ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/362#issuecomment-490143007:465,clear,clear,465,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/362#issuecomment-490143007,2,['clear'],['clear']
Usability,"Hi @ACastanza,. Thanks for reporting both of these. For the first, I think it is just the case that the message needs to be updated. In fact, the `--validateMappings` flag is now deprecated since selective-alignment is used by default (and can't be turned off, except in the single-cell mapping context, with the `--sketchMode` flag, which is currently only in the develop branch). We'll update that message.; Regarding the misplaced newline, the issue is that the other messages are written by the logger, which is asynchronous. So, sometimes it will get to the appropriate place and write a newline before the fragment counter starts, and sometimes it won't. I'll look into if there is a way to better clear the line, even if the update is asynchronous. Thanks!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/587#issuecomment-729044670:704,clear,clear,704,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/587#issuecomment-729044670,2,['clear'],['clear']
Usability,"Hi @Alecrim24,. It looks like the list of r1 files are being interpreted as a single, long, filename. Same with the list of r2 files. Any idea why that's the case? They should be a space-separated list (of course, there *are* a ton of them here, but the error clearly suggests they are being interpreted as a single, long, filename). --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/870#issuecomment-1694754832:260,clear,clearly,260,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/870#issuecomment-1694754832,2,['clear'],['clearly']
Usability,"Hi @Anto007,. Sounds like an interesting experiment! A couple of questions: (1) are you quantifying the meta-transcriptome or the metagenomes? What I mean is, are your target sequences the specific genes from the microbes, or the entire microbial genomes? Is the sequencing data RNA-seq from sequencing the mixture of expressed gene transcripts, or DNA-seq of the microbes? This will have an effect on how you expect reads to be generated. The effect of `--minScoreFraction` depends, to some extent, on how you set the match/mismatch/gap parameters. With the default parameters, `0.9` is actually higher than 90% sequence identity, because the default mismatch penalty is twice the match score. If you assume only matches and mismatches, then the `--minScoreFraction` you want to set is the one such that ; x * (match_score * read_length) <= (match_score * read_length) - (m * read_length * match_score) + (m * read_length * mismatch_penalty), where m is the mismatch fraction (0.1 in your case). So, for example, if the match_score is 2 and mismatch penalty is -4, and the read length is 100, you want to set it so that:. x * 200 = 200 - (0.1 * 100 * 2) + (0.1 * 100 * -4) = 200 - 20 - 40 = 140 . so, the appropriate x would be ~0.7. Of course, if you want to make the calculation simple, you can set the match score to 1 and mismatch penalty to 0, and then the interpretation (modulo gaps) is straightforward (and 0.9 means what you want). Finally, I'd typically avoid using `--mimicStrictBT2`, since those are pretty harsh parameters. Of course, you could try mapping both with and without that flag and see how it affects your mapping rate.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/330#issuecomment-447589060:1282,simpl,simple,1282,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/330#issuecomment-447589060,2,['simpl'],['simple']
Usability,"Hi @BenLangmead!. Thanks for the formal feature request. This is, indeed, a great idea, and something I've been interested in for quite a while. As far as I can tell, the main impediment to this is the hash table (https://github.com/greg7mdp/sparsepp) used in the index. The suffix array used by the mapping algorithm (by virtue of simply being a flat array of either 32 or 64-bit integers) is trivial to load via shared memory, as is the flat representation of the concatenated text itself. The bitvector and rank data structure that separate individual transcript sequences might be a bit trickier, but is also small enough to exist per-process. However, it's unclear to me if there is an easy or straightforward way to have the hash table reside in shared memory, and this is usually the single largest element of the index. As I mentioned, this is a feature that I've thought would be very useful for quite a while, and I'm interested in seeing it implemented. If you have any suggestions on what might be the best approach, I'm all 👂s.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/335#issuecomment-455905666:332,simpl,simply,332,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/335#issuecomment-455905666,2,['simpl'],['simply']
Usability,"Hi @ChelseaCHENX ,. Thanks for confirming the counts of the number of predicted cells.; As much as I'd love to give you an exact answers, but in realty w/ current settings it requires a little more exploratory analysis. Whitelisting traditionally is done by making some greedy choices and generally can results in different number of predicted cells, and having an exact answer is difficult to have. For example, if you run alevin with `--dumpFeatures` and plot the frequency of CB, as dumped in the `raw_cb_frequency.txt`, you will observe a monotonically non-increasing function. Different tools try to get the ""knee"" in the distribution, so as alevin, as the first round of whitelisting. For cellranger, at least in my understanding, they try to take the top X% (I think it's 10) of the value suggested through `expectCells` command as high confidence and use all the CB which has the frequency greater than the lowest frequency of the high confidence barcodes for quantification. To counter the greediness of the CB calling, we in our suggested method for alevin, proposed a naive bayes based approach by learning features from not only CB frequency but various other features. There had been other methods like ""emptyDrops"" which you can try for more fine-grained whitelisting post quantification using alevin quants. Having said that, if you use expectCells with bigger value, alevin will start to include more and more cells. However as the frequency of the new CB which gets included as high confidence with each new iteration drops exponentially, and even though the new CB gets merged to a high confidence barcode its chance of affecting the quantification also drops. In summary, if you are sure about your experiment to have more cells then it's ideal to increase the value otherwise, I think, with the increased expectCells value the quants can potentially be effected but most probably not by a lot. Hope it helps !",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/396#issuecomment-510628771:1109,learn,learning,1109,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/396#issuecomment-510628771,2,['learn'],['learning']
Usability,"Hi @Cold7,. Thanks for the report. So, could you provide the full output that you get on the terminal when you run this? Your command line looks fine to me. Since version 1.0.0, `--validateMappings` has become the default behavior and so this flag technically has no effect (it is marked as ""deprecated""). However, the argument parser should _absolutely_ accept it, and it's not clear to me why it might be giving you this error. The full output from the terminal may help to diagnose this.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/563#issuecomment-680250718:379,clear,clear,379,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/563#issuecomment-680250718,2,['clear'],['clear']
Usability,"Hi @DawnEve,. Thanks for your feedback, and I'm sorry this caused you such a headache. You're right that it would be a good idea to link to the most common transcriptomes for model organisms (e.g. human and mouse) directly in the documentation. I'll add this in the future. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/186#issuecomment-359218368:30,feedback,feedback,30,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/186#issuecomment-359218368,2,['feedback'],['feedback']
Usability,"Hi @DobbyLikesPenguins,. ### conda idea. So, if you want to try with conda again, I would first recommend that you create a new environment for salmon. ```; conda create --name salmon; ```. which you can then activate with . ```; conda activate salmon; ```. From this environment, you should be able to install the latest version. ```; conda install salmon; ```. or specifying version explicitly like . ```; conda install salmon=1.4.0; ```. ### using the pre-compiled executable. The simplest thing would be to simply add it to your PATH. Assuming you are using bash or a similar shell, you can do something like:. ```; export PATH=<path_to_salmon_directory>/bin:$PATH; ```. to add salmon to your path. It should choose this version when you use `salmon`. However, this will be reset when you logout. To make the change permanent, then you add this command to your bash profile (usually `~/.bash_profile`). It's a little bit different (but very similar) if you are using a different shell. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/483#issuecomment-775273715:484,simpl,simplest,484,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/483#issuecomment-775273715,4,['simpl'],"['simplest', 'simply']"
Usability,"Hi @ECuris,. Yes, the values you give are used to form a normal distribution, which is then truncated on the left at 0. So, the parameters you provide are the mean and standard deviation of the distribution *prior* to truncation. However, I'll note that the values are such that 0 is usually sufficiently far (in terms of standard deviations from the mean) that the mean and standard deviation of the fragment length distribution are very similar before and after the 0 truncation. Finally, I'll mention that, if you have paired-end reads, Salmon will *always* learn the empirical fragment length distribution (since the experiment, itself, is the best estimator of the true distribution), but the `--fldMean` and `--fldSD` parameters define the prior distribution that is updated with observed fragment lengths.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/127#issuecomment-285686442:561,learn,learn,561,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/127#issuecomment-285686442,2,['learn'],['learn']
Usability,"Hi @EPunzi,. I'm glad you were able to get this to work. Thanks for the detailed feedback. This is, indeed, interesting to us. Though, it looks like it's a bug in the Boost build. Could you let me know what OS (& version), and compiler you're using? I can report this upstream to Boost. Thanks again!; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/235#issuecomment-398454333:81,feedback,feedback,81,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/235#issuecomment-398454333,2,['feedback'],['feedback']
Usability,"Hi @GWW,. Thanks for the link. We'll look into this. In the meantime, I also noticed something that gave me pause. Specifically, in your output, you have:. ```; ### [ mates1 ] => { /dev/fd/63 }; ### [ mates2 ] => { /dev/fd/62 }; ```. Which makes me think that you are using pipe / process substitution to feed the reads to alevin. While this works fine with normal salmon, it's not currently possible with alevin. This is because alevin goes through the barcode file once by itself, and then goes through both the barcode and read files in unison to assign reads to cells using the initial barcode mapping. Thus, the pipe can't be reset to read from the beginning again, which is a problem. Are you, in fact, using process substitution here? Alevin can read directly from gzipped fastq files, so that's not necessary. Could you see if you encounter the issue if you remove the process substitution (if you're using it)?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-395843922:108,pause,pause,108,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-395843922,2,['pause'],['pause']
Usability,"Hi @HamletShaoE --- what version of Salmon are you using? If you are using the latest version, in addition to the `quant.sf` file, there is a file in the output directory called `stats.tsv`. The format of this file is a list of key-value pairs. The first key-value pair lists the total number of observed fragments in the input (and can be ignored for your purposes). Each subsequent line lists a transcript id followed by that transcript's computed effective length. You can simply take these values and join them (in the database / data frame sense) with the main quantification results. I should note that the next version of Salmon (v0.6.0), which should be out shortly, in addition to including a number of improvements and new features, will make these effective length values easier to get at --- they will appear in the main `quant.sf` file (versions compiled from the develop branch will already do this). For the time being, however, the `stats.tsv` file is the place to get this info. Finally, I'd mention that, though I don't know your use case, I'd be cautious of using FPKM any place that TPM might be used instead. Within a sample, they are proportional (thus the equation you provide), but between samples, FPKM values have un-necessary variation based on the average lengths of the expressed transcripts in the samples; an arbitrary variation for which TPM corrects.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/32#issuecomment-166890654:476,simpl,simply,476,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/32#issuecomment-166890654,2,['simpl'],['simply']
Usability,"Hi @Jensen416,. Thank you for reporting this. Certain versions of the GCC compiler are not capable of performing full program link time optimization (`lto`) for this codebase. This is a known issue — and there are other programs that exhibit this same behavior. This is something that GCC must fix upstream — an internal compiler error is something that really shouldn't happen. Luckily, the solution is simple; just don't use whole program inter procedural optimization. Try using this `cmake` invocation (after clearing out your build directory):. ```; cmake -DNO_IPO=TRUE -DFETCH_BOOST=TRUE -DTBB_INSTALL_DIR= ~/anaconda3/pkgs/tbb-2021.5.0-hd09550d_0/ -DCMAKE_INSTALL_PREFIX= ~/salmon/; ```. The `-DNO_IPO` tells `cmake` to invoke the compiler without inter procedural optimization (i.e. `lto`). Let me know if this works for you. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/778#issuecomment-1134776478:404,simpl,simple,404,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/778#issuecomment-1134776478,4,"['clear', 'simpl']","['clearing', 'simple']"
Usability,"Hi @Liripo - if I'm understanding correctly, your UMI/barcodes are on R2 but `alevin` is incorrectly extracting them from the R1 file? If so, you should be able to simply reverse your inputs, e.g.:. ```; salmon alevin -i ../../GRch38_splici_idx \; -l A \; -1 2.fq.gz \; -2 1.fq.gz \; -p 32 \; --splitseqV1 \; -o alevin_out \; --tgMap ../../transcriptome_splici_fl86/transcriptome_splici_fl86_t2g.tsv \; --dumpFeatures --whitelist ../white_barcode.txt; ```; I've needed to do this for my own projects sometimes, since our cDNA/barcode reads are opposite that of the original Rosenberg paper, and it works fine. Can you give that a try and see if it solves your issue? Or if I'm misunderstanding, can you elaborate more on what you expected the output to look like?. And seconding @rob-p's suggestion above - you should be using `alevin` -> `alevin-fry`",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/774#issuecomment-1127073879:164,simpl,simply,164,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/774#issuecomment-1127073879,2,['simpl'],['simply']
Usability,"Hi @Melkaz,; These options have been added as of commit c207d0f28e5782f9a16747a72ac6f06c277fd4ed. There are some new options, all of which have reasonable defaults (the ones that were hard coded before). The relevant options here are: `--fldMean` which you can use to specify the expected mean length of the fragment distribution and `--fldSD` which you can use to specify the expected standard deviation of the fragment length distribution. These values are used to set the _prior_ on the fragment length distribution. This means that if you're using paired-end reads, the observations will overwhelm this prior quickly and we'll learn the empirical distribution. If you're using single-end data, then the prior won't really be updated and the values you specify above are what will be used in practice (e.g. to compute effective transcript lengths). Please let us know if you run into any trouble using this new feature. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/2#issuecomment-103974922:631,learn,learn,631,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/2#issuecomment-103974922,2,['learn'],['learn']
Usability,"Hi @Miserlou,. I'm not necessarily opposed to this. What exactly would the dry-run do? For example, would it simply check if the input files exist, try to load the index, etc.? This seems like it could be useful functionality, though, in my experience `--dry-run` commands usually aren't effectful (i.e. they usually don't create directories or output files). --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/189#issuecomment-362155044:109,simpl,simply,109,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/189#issuecomment-362155044,2,['simpl'],['simply']
Usability,"Hi @Munfred , thanks for all the useful comments and glad to hear that you were able to run alevin successfully. ; I agree, in the next release we can work on adding the flag for ignoring the reads below a certain length.; Regarding the Transcript to gene Mapping file, all `bioawk` script does it to generate a `tsv` file with the first column as transcript name (as present in the reference) and the second column is the relevant gene id to the transcript. We have described the format [here](http://salmon.readthedocs.io/en/latest/alevin.html) but we can also update the tutorial to reflect the same more clearly. I agree with your last point too, we are working on writing a python parser, to parse the binary format and would update the tutorial soon with the relevant code. Thanks again for using our tool and let us know if you have any other feedback / suggestion regarding improving the alevin pipeline.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/237#issuecomment-400439678:608,clear,clearly,608,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/237#issuecomment-400439678,4,"['clear', 'feedback']","['clearly', 'feedback']"
Usability,"Hi @Munfred ,. Apologies for the delayed response.; Thanks for your very important question. We are aware of the problem and are extensively working on improving the downstream processing of the alevin output. Unfortunately, in current form there is no other direct way of loading alevin output matrix. We are thinking of alternative options like using `loompy` but it's a work in progress. We will definitely inform here once we have a simpler working version.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/354#issuecomment-490091075:437,simpl,simpler,437,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/354#issuecomment-490091075,2,['simpl'],['simpler']
Usability,"Hi @PeteHaitch ,; Thanks for your interest in *Alevin*.; Although in current Alevin we have concentrated mainly on learning more about Droplet based 3'-tagged single cell protocols, especially 10x; we are very much interested in extending it towards other protocols like CEL-seq.; However, there are couple of challenges/difference which should be considered before incorporating it into the Alevin pipeline. Currently Alevin relies on the fact that the droplet based protocols use PCR amplification of the library and the UMI deduplication phase of Alevin assumes an exponential model, I am not sure how true is this with CEL-seq? Another issue is that CEL-seq is a Fluidigm based system while the current application for Alevin is for microfluidics based. In general we have observed that the 10x cell isolation step is pretty robust in reporting the Cellular Barcodes(CB) and although we have a probabilisitic model to handle the CB based uncertainty but the ambiguous case like that are very less frequent, (although not true for Drop-Seq). Having said that, we might have to do some analysis to actually figure out the right model for Barcode correction in Fluidigm based system. Also, please do let us know of your experience in using the solution proposed in #247 . Looking forward to hearing back from you.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/269#issuecomment-414162302:115,learn,learning,115,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/269#issuecomment-414162302,2,['learn'],['learning']
Usability,"Hi @PeteHaitch! I agree with @PeteHaitch here --- I think we should provide an easy way to specify custom cb & umi parameters paired with a particular protocol. For 10x v2, since it's a very standard commercial protocol, I think simply having a `--chromium` flag is probably OK. But we should make it easy for ppl to tweak their CB & UMI lengths.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/269#issuecomment-418580112:229,simpl,simply,229,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/269#issuecomment-418580112,2,['simpl'],['simply']
Usability,"Hi @PlantDr430,. Thanks for the context! As always, we'd be interested in learning anything interesting you find about the general behavior of salmon in different contexts and with different parameter settings etc. Out of curiosity, when you mention that genes perform ""better"" with one or another `--scoreExp`, is it the case that this is data where you have some sort of ground truth expectation for the abundance of the primary vs. spliced forms? If so, super interesting!. One other thought I had about this. While it is true, as I mentioned in my original post, that the conditioning on the transcripts is _fundamental_ in the case of salmon and other transcript expression tools that don't, themselves, try to assemble new transcripts, it's not necessarily true that there is no evidence in the quantifications that something my be awry. Specifically, I noticed that you are using posterior confidence estimation (bootstrapping). We actually have a [recent paper](https://www.biorxiv.org/content/10.1101/2020.04.07.029967v1.full) that discusses how to use the uncertainty estimates from salmon (though we rely on the Gibbs sampler rather than bootstrapping) to group together transcripts whose abundances cannot be individually estimated with confidence (with evidenced provided by the posterior samples). It might be useful to identify such cases in your analysis. Let me know if there's any other way I can help!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/523#issuecomment-633091638:74,learn,learning,74,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/523#issuecomment-633091638,2,['learn'],['learning']
Usability,"Hi @SeBaBInf,. Thanks for reporting this. I'm pinging @k3yavi for his thoughts here. Two quick thoughts though -- the first is that the abstract for this paper mentions 5' tagged end sequencing, thus it might be necessary to swap the reads so that the biological and technical reads are in the expected order. Second, it's likely also worth seeing if and how the data look different if you process with alevin-fry rather than alevin. I'll let @k3yavi provide more detailed guidance here. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/763#issuecomment-1073004001:473,guid,guidance,473,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/763#issuecomment-1073004001,2,['guid'],['guidance']
Usability,"Hi @TSL-RamKrishna,. Thanks for the report. However, it's not exactly clear to me how this is related specifically to salmon. Generally, if the libm you have is _newer_ than the one salmon was built with, you should be OK. So, one option would be to simply remove the `libm.so.6` from the salmon `lib` directory and see what happens.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/290#issuecomment-424523688:70,clear,clear,70,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/290#issuecomment-424523688,4,"['clear', 'simpl']","['clear', 'simply']"
Usability,"Hi @Tima-Ze,. This should not cause any trouble with downstream analysis. The indexing procedure is simply informing you that these transcripts (about which you are being warned) are shorter than the seed length used for alignment. This means that it simply won't be possible for fragments to align to these transcripts, and so they will always have a 0 abundance in the resulting `quant.sf` files. This isn't a problem, as these transcripts are too short to be measured via RNA-seq anyway. The indexing messages just let you know this in advance. You can safely ignore these warnings for your downstream analysis.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/214#issuecomment-751366278:100,simpl,simply,100,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/214#issuecomment-751366278,4,['simpl'],['simply']
Usability,"Hi @Tima-Ze,. Yes, salmon can be used to quantify these reads, but the results will depend (somewhat) on the `--fldMean` and `--fldSD` flags that are used. It's important to note that this is not a unique characteristic of salmon, and any transcript-level quantification tool using a probabilistic model (e.g. RSEM, eXpress, BitSeq, etc.) have the same requirement. That is, the fragment length distribution should be known so that _effective_ transcript lengths can be estimated, which have an effect on fragment assignment probabilities. If the wrong fragment length distribution is specified, then the _effective_ transcript lengths will be off and this can affect the assignment of some fragments. This is only a requirement with single-end reads, since with paired-end reads the fragment length distribution is learned from the data. Further, the inference procedure is somewhat robust to these choices (small changes in fld mean and sd don't generally lead to drastically different results). If you have access to the BioAnalyzer results for the sequencing run, those can give information about the fragment length distribution (even in a single end experiment). If not, you can proceed with the default values. Even if they don't exactly match the true distribution in the single-end sample, at least the same values will be applied in all samples and so, ideally, most results of misspecification will wash out in subsequent differential analysis. . Finally, it's worth noting that the same restriction holds in both alignment-based and mapping-based modes. This is because in neither mode do single-end fragments provide sufficient information to estimate the fragment length distribution from the data. We only know where one end of a fragment mapped and cannot infer where the other end would be. This is not an alignment versus mapping (versus selective-alignment) issue, but rather is fundamental to having only observed one side of the entire fragment generated during fragmentation and ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/127#issuecomment-750920243:816,learn,learned,816,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/127#issuecomment-750920243,2,['learn'],['learned']
Usability,"Hi @Vivianstats ,. Thanks for reaching out. You can certainly dump the CB and UMI tagged Bam file, however, the problem is we can't mark a subset of reads as deduplicated. Alevin's algorithm does not deduplicate UMI at the read level instead we deduplicate at the level of an arboreacence. Basically, the problems is it's not clear which alignment / read should be marked as primary because of following reasons:. 1.) Alevin does fractional assignment of ambiguous reads.; 2.) If there are multiple equally good alignment of a read which alignment should be marked primary for the deduplication ? ; 3.) Even in the UMI tools world, a UMI from a single gene can come from a range of genomic loci, because of the random process of sequence fragmentation. I am not quite sure what UMI tools does, I can check with the developers, but I feel randomly marking one among multiple equally good choice can hide the full picture. Hope it helps. @rob-p feel free to add if I missed something.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/574#issuecomment-710738799:326,clear,clear,326,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/574#issuecomment-710738799,2,['clear'],['clear']
Usability,"Hi @Zhuxitong, . You can easily change the k-mer length used for indexing by passing the desired value to the `-k` option of the `index` command. So, that part isn't technically a problem. The bigger issue is that Ribo-seq data doesn't follow the same basic model as RNA-seq data. That is, the coverage variation in RNA-seq is more often an issue to be corrected (e.g. evidence of bias during library prep / sequencing), whereas it is integral to the interpretation of Ribo-seq data (i.e. the peaks are primary features of interest). Therefore, it's not clear to me that using any RNA-seq abundance estimation software on Ribo-seq data ""off-the-shelf"" is conceptually the right thing to do, though you are welcome to experiment with it. However, there is some interesting work on combining transcript abundance profiles with Ribo-seq data to infer isoform-level information in the Ribo-seq data. For example, [this recent pre-print](https://www.biorxiv.org/content/10.1101/582031v3) provides a pipeline for this.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/454#issuecomment-557558554:554,clear,clear,554,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/454#issuecomment-557558554,2,['clear'],['clear']
Usability,"Hi @adamfreedman,. I think this is just conda being very very very slow. For me, the below command, replacing `mamba` with `conda` (but keeping the switched channel order) eventually did work, but took several minutes to ""collect package metadata"". However, the following works fine for me (and finishes in ~1 minute):. ```; mamba create -n salmon -c conda-forge -c bioconda salmon=1.10.2; ```. Can you use the `mamba` resolver in your environment? Conda has become hardly usable over the years, but `mamba` works quite well as a fast replacement. I'll also note that I swapped the order of `conda-forge` and `bioconda` as the docs specify that `bioconda` should preferably come last in the list of channels. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/895#issuecomment-1784137337:473,usab,usable,473,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/895#issuecomment-1784137337,2,['usab'],['usable']
Usability,"Hi @aedavids,. Thanks for catching that this is undocumented! This means that the mapping type was determined as mapping to a _decoy_ sequence. When we added this output into the code, the documentation wasn't updated accordingly. We'll update the documentation. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/657#issuecomment-833857753:48,undo,undocumented,48,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/657#issuecomment-833857753,2,['undo'],['undocumented']
Usability,"Hi @afkoeppel,. Thanks for reporting this. While I completely understand that this is not the desired behavior, it is the expected behavior. That is, when collapsing duplicates during indexing, the invariant that is maintained is that all sequence-identical transcripts will be ""collapsed"" and a single representative maintained. In practice (i.e. in implementation), the transcript that is maintained is the first one encountered. In the short-term, your suggested solution is the best. That is you can simply remove the non-canonical transcripts from the input fasta file. Alternatively, you could re-order the entries in the file so that the canonical transcript occurs first. In the longer term, I'd be happy to implement a de-duplication procedure that is more aware of the semantics of the transcript names. However, I'd want to figure out how to do this that is agnostic to where the transcripts are coming from (i.e. that doesn't work only for Gencode, human etc., and that does something sensible when the transcripts are e.g. _de novo_ assembled contigs). On that front, I'm completely open to suggestions. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/249#issuecomment-404220623:504,simpl,simply,504,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/249#issuecomment-404220623,2,['simpl'],['simply']
Usability,"Hi @amaer ,. Yes, exactly. The input is a simple TSV where the first column is transcript names and the second column is the gene names (note, that the keys in column 1 are unique, but that many transcripts can map to the same gene). This is the same type of input accepted by tximport to do the transcript => gene mapping. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/198#issuecomment-366005924:42,simpl,simple,42,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/198#issuecomment-366005924,2,['simpl'],['simple']
Usability,"Hi @amitpande74 ,. May be you are already aware of this but just to make it clear, the idea behind decoy indexing is to ""exclude"" those sequences from the transcriptome quantification and that's why you don't see the indexed transposon sequence in the salmon output. The motivation behind such indexing is to remove false mapping reads i.e. exclude RNA-seq reads from the quantification pipelines which maps better to the decoy sequences compared to the provided transcriptome. . I hope that clarifies your doubt and if you wan't to quantify GFP sequences then you have to concatenate them with the transcriptome sequence ""not"" the decoy sequence, although I just wanted to give you heads up that this analysis goes into an unexplored territory as we personally have not explored such use cases. Unless Rob have more thoughts on it.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/737#issuecomment-1024668469:76,clear,clear,76,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/737#issuecomment-1024668469,2,['clear'],['clear']
Usability,"Hi @apredeus,. In short, what you explain in the first paragraph is right and is the expected behavior. However, to simplify the parsing algorithm (i.e. to ensure that BAM input can be parsed in bounded memory), both `salmon` and `RSEM` require that all of the alignments for a given read are adjacent within the input BAM file. If this is violated, they will be treated as different reads. In other words, if you have something like:. ```; read1:aln1; read1:aln2; read1:aln3; read2:aln1; read2:aln2; read2:aln3; ```. then in total, 2 ""reads"" worth of mass will be assigned (probabilistically across the targets). However, if you have. ```; read1:aln1; read1:aln2; read2:aln1; read1:aln3; read2:aln2; read2:aln3; ```. Then there will be *4* total reads assigned. Each time the query name (read name modulo 1/2 of a paired-end read) changes in the BAM stream, it is assumed to be a new read, and its alignments are dealt with separately. Both Bowtie2 and STAR (when projecting genomic alignments to the transcriptome) will follow this convention by default, but I'm not certain the same is true for other aligners. Again, this restriction is present in both `RSEM` and `salmon`, and it's an optimization that is made because otherwise there can be unbounded distance in the worst case between the different alignments for a read and so the parser would either have to hold all alignments in memory (which is very bad), or make many passes over the input BAM (which is also very bad) to perform quantification. Let me know if you think this may be the issue in your case. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/844#issuecomment-1518485720:116,simpl,simplify,116,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/844#issuecomment-1518485720,2,['simpl'],['simplify']
Usability,"Hi @asher1234,. Thanks. I'll try and grab the data now. The 0.12.0 log here is quite informative. It looks like the problem is that none of the reads are making through the likelihood filter, which explains why you see the output you do. I'll take a look and see if there is a clear reason why. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/346#issuecomment-469412869:277,clear,clear,277,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/346#issuecomment-469412869,2,['clear'],['clear']
Usability,"Hi @atasub,. It's hard to say exactly if this mapping rate is much lower than expected or not. Many RNA-seq experiments do end up with a mapping rate of 65-70%. One thing that might contribute to a lower mapping rate would be short reads relative to the minimum required exact match length (default of 31). If your reads are relatively short (after trimming, which it looks like you are doing here) --- say ~50bp, then one might try lowering the k value with which the index is built. This will allow more sensitive mapping. However, the other thing to try is simply to align one of these samples to the genome with a tool like STAR or HISAT2 and look at their mapping rate _to known features_. If it's similar, then the other reads could be accounted for by e.g. intron retention or even contamination. Finally, @vals has an [*excellent* series of blog posts](http://www.nxn.se/valent/2017/9/18/low-mapping-rate-5-human-dna-contamination) on investigating and addressing low mapping rates (albeit in single-cell data) that you might find useful. Let me know what you find.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/160#issuecomment-334762498:560,simpl,simply,560,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/160#issuecomment-334762498,2,['simpl'],['simply']
Usability,"Hi @biobenkj,. Congratulations on publishing your new single-cell technology, and thanks for your interest in adding support to alevin(fry). . After adding the functionality to provide custom geometry for UMI and cellular barcode sequence through command line flags like `--umi-geometry` and `--barcode-geometry,` our general guidelines have been shifted against adding technology-specific command line flags to the alevin codebase. Rob might have more comments on that. Regarding the 0-length cell barcode, I recommend first trying to add the dummy CB before the UMI sequence as a test case. If it helps with your use case, we can discuss adding the ; 0-length cellular barcode functionality to the main codebase. Previously, paired-end read processing was not possible under the alevin framework, but with the publication of alevin-fry, the support for paired-end read (I think) has been added. @DongzeHE and @Gaura might have better thoughts on this.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/805#issuecomment-1282467290:326,guid,guidelines,326,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/805#issuecomment-1282467290,2,['guid'],['guidelines']
Usability,"Hi @bsipos,. This is caused primarily by salmon's desire to apply an error model (by default) to the CIGAR strings. For secondary alignments, as you note, minmap2 doesn't write the read string, and so when salmon is trying to score the alignments under the error model, it can't find the relevant characters in the read. In general, it's not clear to me if one would actually want to apply the error model (designed primarily for short reads) when quantifying long reads (this is something we are currently testing in the lab). For the time being, I'd probably recommend disabling the error model when quantifying alignments from long reads (`--noErrorModel`). In that case, the errors should hopefully go away. Please let me know, and we'll be sure to keep you updated on best practices for long reads as we figure things out.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/289#issuecomment-420295665:342,clear,clear,342,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/289#issuecomment-420295665,2,['clear'],['clear']
Usability,"Hi @bzmby ,. I am sure you are aware of this but just wanted to clear that salmon is primarily designed for transcriptome quantification.; Ideally, there should not be a problem with indexing genome, also from the log you shared it looks like a warning. ; Having said that if you will index the genome then at the end of the day you will get quantification of the chromosomes, is that what you wan't ?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/741#issuecomment-1024655023:64,clear,clear,64,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/741#issuecomment-1024655023,2,['clear'],['clear']
Usability,"Hi @citron96,. The patch is quite simple and i have verified it and it works for salmon-1.1.0 version that i compiled. Here is the patch content:. --- salmon-1.1.0/CMakeLists.txt.orig 2020-03-24 08:50:22.681000000 -0700; +++ salmon-1.1.0/CMakeLists.txt 2020-03-24 08:51:41.786000000 -0700; @@ -596,7 +596,7 @@; message(""Build system will fetch and build Intel Threading Building Blocks""); message(""==================================================================""); # These are useful for the custom install step we'll do later; -set(TBB_SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/tbb-2019_U8); +set(TBB_SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/oneTBB-2019_U8); set(TBB_INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install). if(""${TBB_COMPILER}"" STREQUAL ""gcc""); @@ -610,9 +610,9 @@; externalproject_add(libtbb; DOWNLOAD_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external; DOWNLOAD_COMMAND curl -k -L https://github.com/intel/tbb/archive/2019_U8.tar.gz -o tbb-2019_U8.tgz &&; - ${SHASUM} 7b1fd8caea14be72ae4175896510bf99c809cd7031306a1917565e6de7382fba tbb-2019_U8.tgz &&; + ${SHASUM} 6b540118cbc79f9cbc06a35033c18156c21b84ab7b6cf56d773b168ad2b68566 tbb-2019_U8.tgz &&; tar -xzvf tbb-2019_U8.tgz; - SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/tbb-2019_U8; + SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/oneTBB-2019_U8; INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install; PATCH_COMMAND ""${TBB_PATCH_STEP}""; CONFIGURE_COMMAND """". Rob, ; I understand that you don't want to push changes to older releases but perhaps one; can issue a README/NOTE for all prior releases that are affected by this. The explanation of; what changed will allow people to create their own patches for their specific releases. Regards,; Nadya",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/497#issuecomment-603916394:34,simpl,simple,34,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/497#issuecomment-603916394,2,['simpl'],['simple']
Usability,"Hi @come-raczy,. Thanks for reporting this, it is addressed now in commit efe26b1ca2ced305256357e3b2e95f0e51e3376d. While the function that returns this value is called in two places `normalizeAlphas()` and `writeAbundances()`, the latter of these is actually deprecated and so is not used (we should clean up that code). So, while this value should clearly be initialized, the only potential effect here is through `normalizeAlphas()`, is called before the optimization, and which modifies the alphas that will be used for setting the _initial conditions_ of the VBEM. Therefore, the effect is likely to be limited since, even if the value of `totalCount_` was incorrectly initialized, it should only affect the initialization condition of the optimization. Thank you again for the detailed bug report, and the patch! This is now fixed in develop and will be in the next release.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/355#issuecomment-480004146:350,clear,clearly,350,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/355#issuecomment-480004146,2,['clear'],['clearly']
Usability,"Hi @curtisd0886,. So, issues relevant to processing this data should be resolved in the new release (v1.5.1). However, for technical reasons in the way different modes are handled internally, we had to simplify the mixing and matching of certain different options. Specifically, one can no longer use the `--citeseq` flag in conjunction with the custom geometry flags. So, if you have non-standard `--citeseq` geometry, the recommendation is to just use the new barcode specification format (e.g. `--umi-geometry`, `--bc-geometry` and `--read-geometry`), along with a couple of other flags. Specifically, you should explicitly provide `--keepCBFraction 1.0` and a tgMap file (even if it is just a trivial one mapping each feature to itself). @k3yavi can elaborate further if I've overlooked anything. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/670#issuecomment-860704025:202,simpl,simplify,202,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/670#issuecomment-860704025,2,['simpl'],['simplify']
Usability,"Hi @danphillips28,. Oh ok! Now I see what's going on. We really should be more stringent about catching the issue here. . The problem is that using k > 32 is not permitted in the current implementation. This is because we use a 64-bit machine word to encode k-mers, and you can only fit up to 32 nucleotides in a word. In reality, anything > 31 is not allowed, since the k-mer should be odd so that the orientation can be inferred from the canonical (lexicographically smaller) version. There is nothing fundamentally problematic about using a larger k, it's just that it would require some modifications throughout the codebase we've not yet made. Further, we've not really found cases where having such large k really help. Specifically, the larger k, the fewer errors you need to render a read unmappable (if there is an error in every k-mer, you can't map the read). On the other hand, selective alignment will do a good job of filtering out poor matches where there is insufficient similarity between the read and reference. Thus, we set a default value of k=31. You can go lower (with any odd value), but it's not currently possible to go higher. I hope this clears things up, and thanks for bringing this to our attention. I think the indexer should bail with an error in this case, until (and unless) this feature is supported. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/632#issuecomment-779418628:1165,clear,clears,1165,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/632#issuecomment-779418628,2,['clear'],['clears']
Usability,"Hi @davidaknowles,. Assuming that the total size of all cell barcodes doesn't exceed 32 nucleotides, then it should be possible to simply specify them using a custom geometry string. Of course for that to work, we need to know where the 4th barcode is located, so that we can generate the correct custom geometry string to extract it. I'll ping @DongzeHE and @k3yavi here to see if either of them are familiar with this chemistry already. As always, I'd also suggest running this through `alevin-fry` (or using the `simpleaf` wrapper). While we continue to support `alevin`, `alevin-fry` (largely interfaced by `simpleaf`) is where most of our development effort is currently going, and hopefully we can make the user experience there as smooth and easy as possible!. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/874#issuecomment-1732428996:131,simpl,simply,131,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/874#issuecomment-1732428996,8,"['simpl', 'user experience']","['simpleaf', 'simply', 'user experience']"
Usability,"Hi @davidaknowles,. Indeed — the barcode extraction will happen either in `salmon alevin` or, if you are using the new `piscem` module for mapping prior to quantification (both are exposed in the `simpleaf` wrapper tool to simplify single-cell processing with `alevin-fry`), then it will happen there. We have a new very general and much more capable module in the works that will be able to handle all manners of single-cell geometry, but nothing about the Parse library seems beyond the capabilities of the current geometry processing code. If you share some reads, we can also try and take a look and figure out where the last BC resides. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/874#issuecomment-1733872331:197,simpl,simpleaf,197,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/874#issuecomment-1733872331,4,['simpl'],"['simpleaf', 'simplify']"
Usability,"Hi @davidnboone and @mcfwoodruff,. So, I should have mentioned that if you want to use the pre-compiled binary I provide, you have to put the `lib` folder in your path. One way to accomplish this is to run salmon as follows:. ```; DYLD_FALLBACK_LIBRARY_PATH=<path_to_salmon_folder>/lib <path_to_salmon_folder>/bin/salmon ; ```; Where `<path_to_salmon_folder>` is simply the top-level directory where you decompressed salmon. You can, of course, make a little wrapper script to make launching it less ugly.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/295#issuecomment-421417111:363,simpl,simply,363,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/295#issuecomment-421417111,2,['simpl'],['simply']
Usability,"Hi @deevdevil88,. The challenges I faced with this issue made me switch over to `kallisto` which has some nice advantages as far as speed. I didn't see any obvious affects on quality for my samples although I did have to re-implement some of the auto-detection that `alevin` and `salmon` do for you. . I personally observed some strange behaviour with Soupx - visually apparent differences in gene expression between samples that at the time I felt were artefactual of the adjustment by Soupx. I eventually rolled-my-own strategy where I omitted ambient outlier genes from differential expression. Ambient outliers were defined by taking droplets with UMI counts <10 with using a boxplot in R to define outliers. The osca.bioconductor.org [recommendations](https://osca.bioconductor.org/multi-sample-comparisons.html#ambient-problems) ended up being very similar. They also describe some of the pitfalls of adjusting counts. Best of luck! Always appreciative of all the great work and responsiveness of @k3yavi and the team!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/538#issuecomment-646058370:985,responsiv,responsiveness,985,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/538#issuecomment-646058370,2,['responsiv'],['responsiveness']
Usability,"Hi @demis001,. I see. There is only one behavior built in (i.e., report the transcript as it's own gene). You can easily filter the gene -level quantification file to get rid of transcripts like this though. The easiest way would be something like:. ```; > cat <(head -1 quant.genes.sf) <(grep ""ENSG*"" quant.genes.sf) > quant.genes.filtered.sf; ```; That is, simply filter the `quant.genes.sf` file for any line that matches `ENSG`, leaving the rest behind (and adding the header line). --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/122#issuecomment-283477075:359,simpl,simply,359,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/122#issuecomment-283477075,2,['simpl'],['simply']
Usability,"Hi @evofish,. Unless you have a particular reason to build from source, it is much easier to install salmon via bioconda, or to simply download our pre-compiled executable from the releases page. Nonetheless, your error stems from not having the `curl` program installed, which is used by the build system to automatically fetch all dependencies.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/331#issuecomment-447689917:128,simpl,simply,128,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/331#issuecomment-447689917,2,['simpl'],['simply']
Usability,"Hi @francicco ,. Thanks for sharing the data. I'm able to re-create the problem and am trying to debug it now. The reason you see this behavior in 0.10.1 but not in 0.8.1 is because in 0.10.1 the error model is enabled by default, while it is not in 0.8.1. If you run the newest salmon with `--noErrorModel` (the default in 0.8.1), your sample runs to completion. However, using the error model helps (which is why I made it the default), so I'm trying to debug what's happening there. I'll keep you posted. One more point worth mentioning. I noticed you are passing a coordinate sorted BAM file. For quantification with salmon, you really should not be passing a coordinate sorted BAM. This is because Salmon expects the alignments to appear in a random order, which is important for how the streaming stochastic variational algorithm learns the auxiliary parameters. Sorting by coordinates biases the models towards the isoforms that appear earliest in the BAM file.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/231#issuecomment-394764686:836,learn,learns,836,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/231#issuecomment-394764686,2,['learn'],['learns']
Usability,"Hi @francicco,. It looks like the problem is that the compiler being used is newer than the linker being used to link bzip2 here (see e.g. [this](https://stackoverflow.com/questions/46058050/unable-to-compile-unrecognized-relocation)). You should try and make sure the appropriate (newer) linker is present in your path before the older one. Another option, of course, would be to simply install salmon through Bioconda, which will take care of such issues for you. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/231#issuecomment-394164828:381,simpl,simply,381,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/231#issuecomment-394164828,2,['simpl'],['simply']
Usability,"Hi @gresteban ,. Thanks for the kind words. I'm working on improving the documentation even more for v0.7.0, which should land soon. Regarding your question, what you're seeing is expected behavior. That is, for the vast majority of transcripts, Salmon will simply do the ""right thing"" regardless of the library type. This is because the library type is used as a ""soft"" rather than a ""hard"" filter when determining where a read may originate from (i.e. Orientations other than the expected type have a probability orders of magnitude smaller than the expected type, but still non-zero). Thus, if the only mapping for a read disagrees with the expected type, it will still be used. There is a way to modify this behavior, but since stranded library prep is imperfect, the default behavior is the most reasonable for most situations. The reason that you'll see consistency in most cases, regardless of the library type, is as follows. Imagine that I have a read that maps to transcript 1 in the forward orientation and transcript 2 in the reverse orientation. Further, imagine I have a stranded library, and I expect all reads to map in the reverse orientation. If the mapping to transcript 1 is ""spurious"", there are unlikely to be many othe reads mapping to that transcript in this manner, while we would expect other reads to map to transcript 2 in the prescribed manner. Since Salmon considers all of the reads in its probabilistic model when deciding how each read should be allocated, the fact that many reads map to transcript 2 will increase its abundance and, likewise, increase the probability that we assign this read to transcript 2 --- that is, the other mappings will help us make the right choice, regardless of the fact that we neglected to assign a stranded library type. That said, there are situations where the library type makes a difference. This is most often for a few transcripts that are very sequence similar (e.g. Paralogs that happen to be on opposite strands). In this cas",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/67#issuecomment-238090033:258,simpl,simply,258,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/67#issuecomment-238090033,2,['simpl'],['simply']
Usability,"Hi @gringer,. Yes, we can add a section for this in the docs. It will replace the old way for specifying geometry soon, as its just easier and more flexible. We talk about it in the 1.4.0 release notes. I copy the relevant info below (@k3yavi pulled for the 1-based indexing and won out ... this time):. generic barcode / umi / read geometry syntax : Alevin learned to support a generic syntax to specify the read sequence that should be used for barcodes, UMIs and the read sequence. The syntax allows one to specify how the pattern corresponding to the barcode, UMI, and read sequence should be pieced together, and the syntax is meant to be intuitive and general. For example, one can specify the 10Xv2 geometry in the following manner using the generic syntax:. --read-geometry 2[1-end] --bc-geometry 1[1-16] --umi-geometry 1[17-26]. This specifies that the ""sequence"" read (the biological sequence to be aligned) comes from read 2, and it spans from the first index 1 (this syntax used 1-based indexing) until the end of the read. Likewise, the barcode derives from read 1 and occupies positions 1-16, and the UMI comes from read 1 and occupies positions 17-26. The syntax can specify multiple ranges, and they will simply be concatenated together to produce the string. For example, one could specify --bc-geometry 1[1-8,16-23] to designate that the barcode should be taken from the substring in positions 1-8 of read 1 followed by the substring in positions 16-23 of read 1. It is even possible to have the string pieced together across both reads, but that functionality is only available if you are running with --rad or --sketch and preparing a RAD file for alevin-fry. If you are running classic alevin, the barcode must reside on a single read. The robust parsing of the flexible geometry syntax is made possible by the cpp-peglib project.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/445#issuecomment-777884823:358,learn,learned,358,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/445#issuecomment-777884823,6,"['intuit', 'learn', 'simpl']","['intuitive', 'learned', 'simply']"
Usability,"Hi @guidohooiveld, . Regarding your questions:. (1) The motivation behind asking users to use Bioconda to install the binary is to limit the number of variables we may encounter when someone is reporting a bug --- i.e. if there are fewer distribution channels there is less maintenance overhead. Nonetheless, as you can see, I've had to make the binary available anyway, because it was the only way some people could easily get the program. Therefore, I think I'll start attaching binaries to releases again. (2) Yes, though this functionality is not part of Salmon itself. I *highly* recommend the [MultiQC](http://multiqc.info/) tool. MultiQC has a salmon module, which will parse all of the salmon log files in an experiment directory and produce a report. This report will contain the mapping percentages for all of the samples extracted from the salmon logs (and will color them nicely). It will also produce other QC information from the salmon runs. We are currently working on an improved multi-QC module, which will also provide summaries for things like GC / seq bias by analyzing the models that salmon learns, but this module isn't yet complete. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/252#issuecomment-405442271:4,guid,guidohooiveld,4,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/252#issuecomment-405442271,4,"['guid', 'learn']","['guidohooiveld', 'learns']"
Usability,"Hi @guidohooiveld,. Yes, the original cutoff was set to accomodate TITIN, which, at the time, was the longest human transcript. Note, this warning doesn't prevent the transcript from being indexed, it just notifies the user its exceptionally long. I think updating the warning threshold makes sense so that gencode indexes cleanly in this regard. We'll update this. Thanks for the report!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/591#issuecomment-733736492:4,guid,guidohooiveld,4,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/591#issuecomment-733736492,2,['guid'],['guidohooiveld']
Usability,"Hi @jan-g1,. The length of a feature is used during inference to determine the likelihood that multimapping reads should be allocated to different targets. You're describing what is essentially a simplified model where P(f | t) (i.e., the probability of a fragment given a transcript) is independent of length(t). There's currently no option to disable length normalization completely in Salmon, and you can't ""de-normalize"" by simply multiplying by a factor because those weights are considered during each and every round of the EM (or VBEM) algorithm. However, supporting this should actually be very straight-forward. We simply assign a uniform and identical length to all transcripts for the purpose of inference. I can add such a flag in the next release, though it will initially have to be incompatible with bias correction (since it's not clear right now how the biases for which we account interact with this type of sequencing). Also, it would be possible to run salmon with `--dumpEq`, and then to have a little script / tool that simply re-runs the EM, but without different length factors, using the equivalence class file. I might be able to hack something like that together on short notice if you'd be interested in testing it out. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/108#issuecomment-264659889:196,simpl,simplified,196,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/108#issuecomment-264659889,10,"['clear', 'simpl']","['clear', 'simplified', 'simply']"
Usability,"Hi @jashapiro,. So there are definitely a few things going on here. The first is that you correctly diagnosed the missing cmd_info.json information when `alevin` is run in RAD mode. That was simply an oversight, and there is no reason that file shouldn't have been written. Second, there is also useful information that belongs in `meta_info.json` in the `aux_info` directory (like the SHA hash of the reference sequences); that was also missing but has now been added.; ; In addition to salmon's `alevin` command, each step of `alevin-fry` also writes some useful metadata when it executes. For example, there is a json file written by the `generate-permit-list` step, one written by the `collate` step, and one written by the `quant` step. We've never run into the problem of the output of `alevin-fry` overwriting the output of `alevin` because we use a directory structure where the output quantifications reside in a separate directory from the input RAD file. However, I can now see that if you're writing the quants in the same place as the input, then there will be a conflict in the file names, and the existing files will be overwritten with the new ones. I agree that both tools output useful information. I'm a *bit* ambivalent about assuming the salmon-generated files exist, and merging them into one output file, as I think there might be cases where those files aren't present and `alevin-fry` should still run properly since it doesn't require them to perform it's processing. One option would be to rename the `alevin-fry` output files to prefix/postfix them so they don't collide with the salmon files even if they live in the same directory. Then, one could (now or later) write a small command to merge the relevant json files into a unified output if that would be more convenient downstream. Let me know your thoughts. Thanks!; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/688#issuecomment-883497669:191,simpl,simply,191,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/688#issuecomment-883497669,2,['simpl'],['simply']
Usability,"Hi @jasonvrogers,. First of all thank you so much for sharing this thorough analysis with us, it was very clear and helpful for understanding the details of the problem you are referring to. Secondly, I apologize for the long time it took me to get back at you. I would like you to know that we have been and are still working on possible solutions for addressing this problem, and here I would like to share some updates with you. . About the success cases, it was nice to know that the current model of Salmon with length correction works pretty well in recovering the right estimates for those ""easier"" cases where one transcript is fully contained in another one. Turning off the length correction, tells the Salmon model not to consider the effective length of each transcript for computing the conditional probabilities of originating a fragment from a transcript. So, for the RNA-seq data there is no reason to turn off this term of the model, and we highly recommend not to use that flag for the bulk RNA-seq abundance estimation with Salmon. Looking more carefully at the 2nd case you have posted as the failure case, it is interesting to see that there is a very nice visual evidence on the super transcript that the long transcript might not be expressed at all. I am referring to the zero coverage regions on the Super Transcript between the regions corresponding to the smaller transcripts, e. g., between POF1 and EMC1. So, we tried a solution that inspects the coverage profile of all transcripts and calculates the probability of observing a zero coverage region on each transcript. If this probability is too low, this would be counted as an evidence for a transcript not being expressed at all. This approach seems to be working fine on this example that you have shared here. however, one problem was that there were considerable number of reads in the sample that were uniquely mapping only to the Super Transcript and turning of the expression of that transcript would result in t",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-666512703:106,clear,clear,106,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-666512703,2,['clear'],['clear']
Usability,"Hi @jckhearn,. The documentation could definitely be more clear, so let me try and clarify here and make a note to clean up the documentation more as well. I'll answer in reverse order:. > Given the above command should I go back to a non-decoy aware transcriptome?. No. What the statement in the documentation means to convey is that if you are using the basic quasi-mapping algorithm (not selective-alignment as enabled by `--validateMappings`, `--mimicBT2` or `--mimicStrictBT2`), then you should not be using a decoy-aware transcriptome. We have not tested the effect of decoys on the basic quasi-mapping approach, and though that may be supported in the future, it is not right now. However, if you are using any flavor of selective-alignment, then please _do_ use the decoy-aware transcriptome. . Regarding ""combining"" `--validateMappings`, `--mimicBT2` and `--mimicStrictBT2`, this is not possible. That is, you should view `--mimicBT2` and `--mimicStrictBT2` as ""meta-flags"" that enable selective-alignment and also set a few other options that are meant to mimic the BT2 behavior more closely. We generally do _not_ recommend `--mimicStrictBT2`, and so the main choice is between simply using `--validateMappings` vs. `--mimicBT2`. The main differences here are that `--mimicBT2` sets slightly more sensitive parameters to find alignments, but is also stricter in what it reports. The biggest differences is that `--validateMappings` will allow orphaned mappings (where one end of a paired-end fragment aligns but the mate doesn't), while `--mimicBT2` will not allow such mappings. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/399#issuecomment-511884297:58,clear,clear,58,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/399#issuecomment-511884297,4,"['clear', 'simpl']","['clear', 'simply']"
Usability,"Hi @jeremymsimon — @Gaura is going to take a look at unfiltered permit listing and will share those results here later. Regarding frameshift errors, I think that's certainly out of scope for the alevin -> fry phase, but that type of thing *could* be in scope for `splitp`. Basically, my logic / reasoning is this: I'd like to avoid further complicating the already immense salmon/alevin codebase with special implementations handling problems outside of their core function (e.g. mapping reads to the reference efficiently and quantifying UMIs/barcode). Since most protocols (and the most common) have quite simple barcode geometry, it makes sense for this code to live there. I'm fully supportive of enabling support for more complex barcode geometries and preprocessing requirements if there are folks whom it would help, but it feels like that essential complexity belongs upstream of alevin / fry, so that by the time the reads get to alevin, it can assume a straightforward geometry. So TLDR : I think we'd be willing to investigate what is required to address potential frameshift errors, and how much of a difference that makes, but I think that analysis and eventual implementation (if we decide it's worth it), belongs in `splitp`.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-988030837:608,simpl,simple,608,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-988030837,2,['simpl'],['simple']
Usability,"Hi @jeremymsimon,. I've discussed the support for SPLiT-seq/ParseBio with @Gaura in some depth. Honestly, I think the cleanest solution right now is just to have a more streamlined (and streaming) way to match / replace the random hexamers upstream of alevin-fry. By my understanding, if we can simply replace barcode 1 appropriately (as your Perl script currently does), everything should work downstream in alevin/alevin-fry.; ; To that end, I've thrown together a small rust program based on your Perl script. Currently that lives [here](https://github.com/COMBINE-lab/splitp). It reads the same basic parameters as the Perl script, and writes its output to stdout so that it can be used with named pipes. For example, something like:; ; ```; <normal salmon command> -1 read_file_1.fq -2 <(splitp --read-file read_file_2.fq --bc-map bcSharing_example.txt --start 79 --end 86 --one-hamming); ```. which will transform the second fastq file and stream the transformed reads out which can then be read by alevin-fry. One important thing to note is that while *alevin* requires the input reads to be a real file (i.e. you can't stream reads in because it does 2 passes), if you are mapping these reads for processing with *alevin-fry* you can use the process substitution trick above. As you hinted, this program works considerably faster than the Perl script. For example, for the first 10,000,000 reads in `SRR6750042`, the Perl script took 2m 48s to transform the reads and `splitp` took ~6s (if the output wasn't being written to a file on disk it took <4s). This should generally be fast enough to not be a speed bottleneck. So, perhaps the next step is to try to help you walk through this approach with a test dataset (and ideally using alevin-fry) to see if things are turning out as expected?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-961598108:295,simpl,simply,295,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-961598108,2,['simpl'],['simply']
Usability,"Hi @jonahcullen,. No need to apologize! We should better document these numbers. Basically, the elements you point out : `num_decoy_fragments`, `num_dovetail_fragments` and `num_fragments_filtered_vm` are the fragments where alignment was *attempted* but subsequently failed. In these cases because (1) the read best mapped to a decoy, (2) the best alignment was dovetailed or (3) no alignment passed the alignment score threshold. In addition to this, fragments can fail to align when no sufficiently good seed is found such that alignment is not even attempted. This can happen e.g. if no 31-mer from the read matches the transcriptome/genome, or if the only matching 31-mers are degenerate in terms of their frequency (appear thousands of times and are therefore not useful for alignment). So, the most likely occurrence here is that these ~1M fragments simply had no alignment attempted. Let me know if this answers your question. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/782#issuecomment-1142131363:857,simpl,simply,857,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/782#issuecomment-1142131363,2,['simpl'],['simply']
Usability,"Hi @junaruga --- so, I cherry picked your changes into develop (thanks again!) and did some more exploring. It looks like `jemalloc` is to blame for the unitTests hanging on the travis server. I modified `unitTests` to not link against `jemalloc` (but still linked salmon against it), and everything passes. I did see some potentially related issues on the `jemalloc` github issues, but it's not clear _exactly_ what is causing this behavior.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/276#issuecomment-416348427:396,clear,clear,396,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/276#issuecomment-416348427,2,['clear'],['clear']
Usability,"Hi @juugii ,; Thanks a lot for starting an interesting discussion related to Alevin. It does sound really interesting. If I may, I'd like to ask a couple of questions before going deeper into your questions. ; * When you say you try subsampling the `Fastq`, did you sample randomly across the full `Fastq` or chose the top X reads. One can imagine that if you simply, sample just the top X reads and the `Fastq` has not been generated in random order then a certain subset of CB will get all the reads and you'd still observe the coverage bias in them. I'd suggest can you please try subsampling randomly across the full `Fastq` if you haven't tried that already.; * `re: subsampling coefficient:` If you are looking for per-CB level mapping rate for your sample that would be very easy to calculate, although getting one number for the full sample might be little tricky since the mapping rate might have large variance across the sample, but it would be an interesting plot to generate, do let us know how it looks in your case.; If you run Alevin with `--dumpFeatures` flag, alevin will generate a file `featureDump.txt`, whose first column will be the per CB level mapping rate i.e. `#mapped reads/#raw reads`. If you wan't absolute values for per-CB reads and mapped reads, it should be in the file `filtered_cb_frequency.txt` and `mappedUMI.txt` respectively.; * `re: cellranger subsampling:` Correct me if I am wrong, when you say cellranger subsampling, do you mean the `cellranger aggregate` pipeline? It's possible you are talking about some other step which I am not aware of but if it's `aggregate` then I think it happens downstream of all the quantification. Indeed coverage bias correction is an important part of the aggregation step but in general it's not the only one and that's why we recommend using the `Seurat` package downstream of the Alevin quantified matrices. We will be more than happy to write a tutorial on, ""how to perform batch correction downstream of Alevin"" but in ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/305#issuecomment-433169468:360,simpl,simply,360,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/305#issuecomment-433169468,2,['simpl'],['simply']
Usability,"Hi @k3yavi - thanks for the response. We have been looking at using Alevin to support our wider pipelines in the gene expression group at the EBI, as a generic way of quantifying droplet experiments. It has worked well for the 10X v2 studies I've tried, but I'm experiencing some trouble with the drop-seq studies I've tried thus far due to noisy barcodes. May just be bad data, but I'll post an issue or two when I'm clearer.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/358#issuecomment-490095148:418,clear,clearer,418,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/358#issuecomment-490095148,2,['clear'],['clearer']
Usability,"Hi @k3yavi . Thank you for linking me to your script to parse the bfh file from alevin. I think I could figure out the structure of the bfh file. I will write it down underneath with the help of an example. Could you confirm it is correct? . Everything up and until the listing of the barcodes is clear. I will start with a line from after the barcodes. ; ""7	90480	90486	107507	107990	108641	109149	112915	1	1	105	1	TGGGATTT	1"". I think that each such line corresponds to an equivalence class (EC). The first entry on each row is the number of transcripts in the EC. This is followed by the transcripts (more correctly, indices you can use to obtain the transcripts). Then you have the number of reads with in the EC, followed by the number of barcodes (~cells). For each barcode, you have an index that can be used to retrieve the identity of the barcode, followed by the number of UMIs within that barcode, the sequence of the UMI and lastly the number of reads associated with that UMI. . My goal is create a expression matrix where the ECs are the rows and the columns are the cells. If I want the UMI counts, do I need to count the number of reads associated with each UMI or just the number of UMIs per cell? . Thanks in advance.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/728#issuecomment-1028272923:297,clear,clear,297,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/728#issuecomment-1028272923,2,['clear'],['clear']
Usability,"Hi @k3yavi . Thank you very much for the answer. . I am interested in the equivalence class counts (ECC) per cell and the transcripts that belong to each equivalence class. I think bfh.txt is file that contains that information, but I couldn't figure out how the file is structured. I looked at the function you linked to, but the schema hasn't become totally clear. Could you provide some more information? . Thanks in advance.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/728#issuecomment-1022365298:360,clear,clear,360,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/728#issuecomment-1022365298,2,['clear'],['clear']
Usability,"Hi @k3yavi, ; So there is no issue when I manually add 2 pairs. Is there a max amount of input files? ; Below is the simple bash script to organize the data and find the correct files; ```; #!/bin/bash; #this script calls alevin for multiple library pairs of files . #where salmon located; salmon=""/usr/local/bin/salmon"". index=""path/to/gencode_annot/AlevinIndex/""; echo ${index}. #output folder path; output_folder=""path/to/alevin_outputTest""; echo ${output_folder}. #where the raw files are; samples_folder=""path/to/Raw_data/Sample_cells/"". cd ${samples_folder}. sample1=$(ls *R1*.fastq.gz -p | grep -v / | tr '\n' ' ') #this gives us a space seperated list of all the R1 files; #this is from the alevin tutorial ""Often, a single library may be split into multiple FASTA/Q files. Also, sometimes one may wish to quantify multiple; #replicates or samples together, treating them as if they are one library""; echo ""Value of sample1:""; echo ${sample1}. echo ""Value of sample2:""; sample2=${sample1//R1/R2} #switch the R1 with R2 to find the second pair for ALL (//) occurances; echo ${sample2}. tgMap=""path/to/gencode.primary_assembly.v29.tsv""; #this is a transcript --> gene map tsv file. Can create this using tximport. whitelist=""path/to/my_barcode.tsv""; #a list of true barcodes; salmonCommand=""${salmon} alevin -i $index -lISR -1 ${sample1} -2 ${sample2} -p 8 --celseq2 --dumpCsvCounts -o ${output_folder}/quantSC --tgMap ${tgMap} --whitelist ${whitelist}""; #--numCellBootstraps 100; #numCellBootstraps args -- generate a mean and varience for cell x; #dumpCSVcounts - dumps cell v. transcripts count matrix in csv format; echo ${salmonCommand}; if ${salmonCommand}; then; touch ${output_folder}/qauntSC_complete.txt; else; touch ${output_folder}/quantSC_failed_to_complete.txt; fi; ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/329#issuecomment-446199327:117,simpl,simple,117,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/329#issuecomment-446199327,2,['simpl'],['simple']
Usability,"Hi @k3yavi,; Many thanks for you prompt answer, once again. >When you say you try subsampling the Fastq, did you sample randomly across the full Fastq or chose the top X reads. Yes, I did perform a random subsampling, ie. taking a read with a p probability while reading the fastq files, p being the subsampling coefficient I did mention (pE[0;1]). An implementation of this approach as an option during the transcript quantification would be great. I can provide you with the simple python script I use for the subsampling, but I am not sure if it is the proper way to subsample during alevin quantification. >when you say cellranger subsampling, do you mean the cellranger aggregate pipeline?. Yes, sorry for not clearly stating it. I did use the cellranger aggregate function indeed, which by default subsample the expression matrices with high sequencing depth depending on amount of mapped reads, if I understand well. >Use Alevin w/o any modification to the fastq on both of your sample to generate the gene count matrices. I already did that, in downstream analyses I have a batch effect issue related to the sequencing depth. >that's why we recommend using the Seurat package downstream of the Alevin quantified matrices. I have some experience with downstream analyses with Seurat, Pagoda, Scater, scanpy and a few other tools, and I am aware of batch correction methods like CCA or MNN. But that is not what I am looking for here. I did both CCA and MNN but I loose some important information in the resulting eigenspaces or corrected matrix. I believe the proper way to correct my batch effect is to simply fix the difference between my two libraries, ie. the sequencing depth in this case. As I explained in my first message, cellranger aggregate (subsampling based on the amount of mapped reads) works very well in my case, correct the effect without any loss or modification of important genes in our scientific question. Not CCA or MNN. I would like to be able to do the same from the a",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/305#issuecomment-433319913:477,simpl,simple,477,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/305#issuecomment-433319913,4,"['clear', 'simpl']","['clearly', 'simple']"
Usability,"Hi @kvittingseerup,. No need to apologize, I think it was I who was not clear. What I am saying is that this is *already* the way that Salmon handles such a case. That is, if you have a paired-end read, and one of the reads maps but the other doesn't (due to e.g., adapter contamination or just very low quality), then Salmon will consider the remaining (mapping) end of the read as representative of an entire fragment, and will resolve the fragment origin accordingly during optimization. Generally, not having both ends of a paired-end read leads to increased ambiguity, but this isn't a particularly big problem if it only happens to a generally small fraction of the reads. Further, since you cannot reliably infer the implied fragment length on a transcript from only a single-end read, such mappings will not contribute to the bias model. Again, however, as long as this doesn't happen to the vast majority of fragments, it should have only a negligible effect on quantification and bias correction. Please let me know if this description makes sense. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/150#issuecomment-355881997:72,clear,clear,72,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/150#issuecomment-355881997,2,['clear'],['clear']
Usability,"Hi @kvittingseerup,. Sorry for letting this sit for so long without responding. Currently, Salmon does not support mixed paired-end and single-end library types, so this is presumably what is causing the error (granted, the error message here could be considerably better). Practically, I'd be curious what the difference is between allowing this and simply running Salmon with the _non-quality-trimmed_ paired-end reads. Specifically, if Salmon is not able to map a pair concordantly, but it can map one of the ends of the read, then it will already do so. . However, in the case that there's a really compelling reason to want to quality trim the reads prior to quantification (and to include the reads such that the mate has been completely quality-trimmed away), we would be able to support this. It will require a bit of modification to allow different library types to be processed back to back and to contribute to the same quantification estimates. In this case, I imagine what we would want to do for the orphans is essentially what Salmon would do internally if it can't map the mate. That is, we would learn essentially all of the parameters and biases from the pairs that do map concordantly, and then just include the orphaned reads as indicating an entire fragment but of unknown length. Let me know if you have any thoughts about the above, and sorry again for the delay!. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/150#issuecomment-353196630:351,simpl,simply,351,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/150#issuecomment-353196630,4,"['learn', 'simpl']","['learn', 'simply']"
Usability,"Hi @lauraht,. So I decided to explore just one of these to see if I could figure out what might be going on. The below is with respect to `SRR9007475`. So first, even though I processed the data with the latest version of the develop branch (which will become 1.2.0), I got basically identical results to what you reported. Simply aligning the data against an index built on a human Gencode v26 transcriptome (with no decoys) gives me a mapping rate of `0.00378202832148367%`. The first thing I did was to quality and adapter trim the data (using `fastp -i SRR9007475.fastq.gz -o SRR9007475_trimmed.fastq.gz -q 10 -w 8`) and ... whoa. This is the fastp html report [fastp.html.zip](https://github.com/COMBINE-lab/salmon/files/4176345/fastp.html.zip). So the first astounding statistic, the mean read length before trimming is 51bp (these are relatively short single-end reads). The mean read length after trimming is 21bp! So, the average read length is, in fact, less than the k-mer length used for indexing (default is k=31). On the trimmed data, the mapping rate goes up to `2.3545475882931305%`, still very low, but now there's somewhat of an explanation, the average read is shorter than a single k-mer. So, the next thing I tried was indexing with a smaller k; a _really_ small one in this case,`k=15`. Then, I re-ran on the _trimmed_ reads (the fact that the trimming took us from 51-21bp suggests that the reads had a lot of low quality bases, adapter contamination, or both). Under this setting, I still get a very low mapping rate, but it was _much_ higher — `16.766993524863488%`. The final thing I tried was seeing how the mapping rate changed as I altered `--minScoreFraction`, which is the salmon parameter that determines the alignment score that a read must achieve in order to be mapped validly. The default is 0.65. This means that the read cannot have a score < 0.65 * the maximum achievable score for the read given it's length. In the case of a 21bp read, the best score would be ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/482#issuecomment-583799668:324,Simpl,Simply,324,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/482#issuecomment-583799668,1,['Simpl'],['Simply']
Usability,"Hi @mathog,. > Is it really the case that Salmon cannot use 1.57.0?. It may be able to. We set the minimum required version to the lowest boost version we use in any of our testing machines where we run regression tests. Currently, this is 1.59.0. If you change the relevant `CMakeLists.txt` line, you *really* need to make sure you clear out the CMake cache. You can do this by removing `CMakeCache.txt` in your build directory, as well as the directory `CMakeFiles`. However, it might be easiest just to remove and remake the entire `build` directory. You may also try passing `-DBoost_NO_SYSTEM_PATHS=Bool:ON` to your cmake command. Finally, note that the build system is probably looking for the static libraries --- you can elide that preference by modifying [this line](https://github.com/COMBINE-lab/salmon/blob/master/CMakeLists.txt#L222). Finally, since salmon uses C++11, it's important that whatever boost you link against exposes a C++11 compatible ABI. Unfortunately, `FindBoost.cmake` is the most finicky of the module finding packages I know about 😦. If you use `-DFETCH_BOOST=TRUE`, then CMake will fetch a recent boost and build the libraries it needs and link them statically. I realize you want to avoid this, so hopefully one of the ideas above will help.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/236#issuecomment-396781869:333,clear,clear,333,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/236#issuecomment-396781869,2,['clear'],['clear']
Usability,"Hi @mdshw5,. @k3yavi was originally developing the barcode algorithm in a separate repo, but all of this work has been merged into the salmon repo now. The new `alevin` command runs the single-cell method, which handles barcode identification and correction, mapping and UMI deduplication, and which is described in this [bioRxiv preprint](https://www.biorxiv.org/content/early/2018/06/01/335000) that just landed. We're still actively developing and improving the method and very much welcome any feedback!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/93#issuecomment-394000666:498,feedback,feedback,498,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/93#issuecomment-394000666,2,['feedback'],['feedback']
Usability,"Hi @mej54,. First, thanks for using salmon and for providing detailed feedback! There are two main points I'd like to make in response to the points you raise. . First, v0.9.1 is _very_ old, and there have been a large number of bug fixes and substantial improvements to salmon since that version (though it's much better than people who are still using 0.8.2 from, like, 3 years ago!). Specifically, I'd highly recommend upgrading to the latest version (1.1.0, with 1.2.0 coming out shortly). We've added (and made standard) selective-alignment, which is a procedure that provides alignment scoring for the assigned reads to avoid spurious mappings that arise with fast lightweight mapping procedures. Second, the observation of mismatching bases at the provided alignment location is the expected behavior with the mappings written by salmon with the `--writeMappings` option. Specifically, while newer versions of salmon (0.15.0 and greater) will do alignment scoring and removal of low score alignments by default, salmon still does not compute or write out a full CIGAR string for its alignments. Instead, it uses a _score-only_ dynamic program to compute the optimal alignment score at the given location, but it ""spoofs"" the CIGAR string. Thus, if there is e.g. a small indel in the read, this will show up in an IGV visualization as a large number of mismatches after that indeed location. I'm not sure that is what is happening in the screenshot you show above, and, in fact, may of these mappings may disappear with selective-alignment. However, it will definitely still be possible to see a cigar string showing full matches, where there are mismatches in IGV. This is intended behavior due to score-only alignment. However, it's also true that newer versions of salmon will report the alignment score in an `AS` tag, so that you can see how high the alignment quality was at the particular location.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/491#issuecomment-597349699:70,feedback,feedback,70,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/491#issuecomment-597349699,2,['feedback'],['feedback']
Usability,"Hi @mmokrejs ,. I have written [a script](https://github.com/COMBINE-lab/salmon/blob/master/scripts/runner.sh) for users with this need (i.e., running with interleaved FASTQ files). It simply splits the interleaved file into two streams, however, and so won't deal with unsynchronized streams where not all reads are properly paired. Because this solutions is sort of piecemeal, I've not added it to the official documentation. However, full support for interleaved FASTQ files is something I'd be interested in if we can peel off the time to write up proper support. P.S. Thanks for the suggestions on the documentation, I'll go ahead and make the suggested changes.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/240#issuecomment-399944991:185,simpl,simply,185,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/240#issuecomment-399944991,2,['simpl'],['simply']
Usability,"Hi @mmokrejs,. Thanks again for all the feedback, we'll work on these. I'll mention that (2) is not quite simple as it seems. Specifically, if you write mappings (`--writeMappings, -z`), the implicit file is STDOUT. I believe this has been discussed with @tseemann in the past. This is intentional so that one can immediately pipe that output to e.g. samtools to convert the SAM format to a BAM format. I am open to cleaner solutions that (ideally) don't involve having to write the BAM files directly.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/242#issuecomment-400056707:40,feedback,feedback,40,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/242#issuecomment-400056707,4,"['feedback', 'simpl']","['feedback', 'simple']"
Usability,"Hi @mojakab ,; Thanks for your interest in Alevin. Currently most of our research efforts have gone into developing Alevin for droplet based 3' tag sequencing like 10x chromium and DropSeq. Although similar but Cel-Seq2 relies on a different cell isolation step which can potentially create assay specific bias between the experiments. Basically Alevin is designed to work with single-cell protocols which follows the following criteria:; * Droplet based cell isolation.; * 3' tag sequencing.; * Fragmentation post Amplification. We have similar such request in https://github.com/COMBINE-lab/salmon/issues/269, where the user was able to use Alevin with Cel-Seq2 but currently we have not explored the full potential of Alevin with Cel-Seq2 and might require more careful consideration. If you happen to use Alevin on Cel-Seq2 data we'd appreciate your feedback based on your experience.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/311#issuecomment-439527284:854,feedback,feedback,854,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/311#issuecomment-439527284,2,['feedback'],['feedback']
Usability,"Hi @mugpeng,. This is because it is covered by the custom geometry specification (as laid out in the docs). I agree it's nice to have a specific flag for each geometry, rather than to have to e.g. specify the custom geometry each time. We are working on good solutions to that at a higher level (e.g. in our `simpleaf` tool where users can register their own custom geometry specifications and refer to them by name). However, in `salmon`/`alevin` right now, the named geometries are hard-coded, and so to have a specific `--indropV2` flag, that would have to be added to the argument parser and then mapped to the specific underlying geometry in the code. This isn't hard, but as the number of different chemistries proliferates, it's not ultimately a scalable solution. So, the current recommendation would be to use the custom geometry flags as specified in the documentation, or adopt a wrapper like `simpleaf` and add `indropV2` to your custom geometry specification library. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/878#issuecomment-1758171139:309,simpl,simpleaf,309,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/878#issuecomment-1758171139,4,['simpl'],['simpleaf']
Usability,"Hi @nh13,. This is not something for which we currently have support or something that we currently plan. I'd be open to it, but I'm honestly not sure how to cleanly do it in the current architecture, and doing so would certainly incur a performance hit. Salmon runs 2 phases of inference; and online phase and an offline phase. The online phase has access to _fragment-level_ information that is then summarized away during the offline phase (like the specific locations of each read, the length of each observed fragment, etc.). That information goes away when the reads are summarized into range-factorized equivalence classes. Moreover, some of the model parameters learned during the online phase will depend (in their details) on the order in which observations are made. Ostensibly, observing the same data in the same order **and issuing updates to shared model parameters from worker threads in the same order** should result in identical values, however this has never been tested and was never a design goal. The reason for this is that differences between runs are within the bounds of the inherent inferential uncertainty of the estimated parameters anyway. That is, if one is relying on a specific value at a level of precision such that a different run of salmon would produce a value different enough to change a downstream analysis, then one is imparting more precision on the estimates than they can provide. Other methods that produce identical results between runs for these values may produce the same output, but the accuracy of the output at that level shouldn't be trusted in this case. The uncertainty of the parameter estimates can be evaluated based on the Gibb samples (or bootstrap replicates) that salmon computes. Of course, the small differences between runs rarely lead to differences in downstream analysis (almost certainly at the gene level and also at the transcript level if you use a differential testing method that is aware of inferential uncertainty). On the ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/102#issuecomment-2159300538:670,learn,learned,670,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/102#issuecomment-2159300538,2,['learn'],['learned']
Usability,"Hi @nicolasstransky --- thanks for reporting this. Now the question is, how should this be handled? I see at least 2 obvious possibilities :; 1. Assume that the transcript name should be split at the first whitespace character **or** `|`. Currently,; it is only split at the first whitespace.; 2. If a gtf is provided for gene-level quantification, ensure that some non-trivial number of genes (e.g.; more than half?) have at least 1 transcript in the index corresponding to them. If not, then complain. Of course, there are also potentially other, better solutions; so I'm open to suggestions. The problem with 1 is that _de-novo_ assemblers may have transcript names that are not unique up to the first `|`, so that the whole name needs to be taken into account. The problem with 2 is that it alerts the user of this potential issue, but doesn't resolve it. In the latter case, the user could provide the transcript-to-gene mapping using the provided transcript names in the ""simple"" format — i.e. > a simple tab-delimited format where each line contains the name of a transcript and the gene to which it belongs separated by a tab. which is also accepted by the `--geneMap` option. I sort of lean toward 2, but, as I said, am happy to consider other suggestions.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/15#issuecomment-144471362:978,simpl,simple,978,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/15#issuecomment-144471362,4,['simpl'],['simple']
Usability,"Hi @nskbe,. I apologize for the slow reply. Things have been super-busy over the ""break"" trying to get things done before the semester starts here. Let me see if I can answer your question satisfactorily. In retrospect, I think that the raw `lib_format_counts.json` file can be quite confusing, and I should definitely provide a more thorough description of it in the documentation (or include a tool to generate a more digestible report from it). Basically, the report records the number of each type of _mapping_ observed. By _mapping_, I mean the particular correspondence between a read and a transcript. A given read can have many mappings, and so can contribute multiple times to the entries of the `lib_format_counts.json` file. The reason changing the library type doesn't change the results of this file is because this file records how fragments _mapped_ to the reference, not necessarily how they were _assigned_ during quantification. So, for example, a read map map in both the forward `SF` and reverse complement `SR` orientations. If you pass the library type `-l SR` to Salmon, then the reverse complement mapping will be strongly preferred for assignment of the read to the forward mapping. However, before the read was probabilistically assigned to a transcript, both types of mappings were observed. From the report you have provided, you quite clearly have a `SR` library type. One other thing that I should note. As I mention above, Salmon will assign a higher probability to the preferred library type, but not, by default, a probability of 1. If you want to force Salmon to only assign reads that arise from mappings in the prescribed orientation, you should pass the flag `--incompatPrior 0.0`. This will tell Salmon that it should assign a probability of 0 to any read that maps to a transcript in a way that disagrees with the provided library type. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/183#issuecomment-359218185:1364,clear,clearly,1364,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/183#issuecomment-359218185,2,['clear'],['clearly']
Usability,"Hi @pinin4fjords ,; Thanks for raising an important question and running alevin for the training.; I think there is a confusion regarding the `quantmerge` command. That command works only with bulk RNA-seq quants not with alevin output. To answer your question of running multiple alevin instance for multiple file pair, might depend on what are the separate files from, are they from separate lanes or are they separated based on cellular barcode ? The basic intuition is after initial barcode assignment, alevin works on each cell disjointly meaning as long as you are confident that each file pair is cell disjoint then at the end you can just cat the output of the alevin quants. Also, depending on what's the training about you can think of multiple workarounds like you can use very small 100 cell (7 million reads) datasets from 10x and combine it all together in one file if size and multiple files is a problem.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/434#issuecomment-540033932:460,intuit,intuition,460,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/434#issuecomment-540033932,2,['intuit'],['intuition']
Usability,"Hi @pophipi ,; Thanks for reporting the issue.; It looks like a bug has creeped in while merging the `drop-seq` pipeline to alevin [here](https://github.com/COMBINE-lab/salmon/blob/ad4f74a4e3d7424bcd0ec0c1ec2af300dcbffc44/src/AlevinUtils.cpp#L47-L48).; If it's an urgent requirement you can swap the above two lines by: . ```; umi = read.substr(pt.barcodeLength, pt.umiLength);; return true;; ```. If it's too much trouble to compile from source, we will release a version w/ the hot-fix by today/tomorrow and would update you soon.; Thanks again !. P.S: I was curious how did the `chromium` pipeline went through, since the length requirement of 10x based pipeline is longer and it should break much earlier. The experiment you forwarded above seems to have 25 length bases for CB+UMI sequences. I wonder has any of the Drop-seq guideline changed? I was in the impression it was 12 base CB and 8 base UMI if not, then `--dropseq` flag would not be ideal thing to use since it will just use 20 bases out of 25 present in the fastq files.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/258#issuecomment-408168390:830,guid,guideline,830,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/258#issuecomment-408168390,2,['guid'],['guideline']
Usability,"Hi @rfarouni ,. Is it possible to visualize the above two plots on the same scale ? ; Regarding the few cells not from 10x whitelist, I should have been more clear last time. ; Basically, what I meant earlier when I said that 10x data is clean is that we do observe some cells from the non whitelist file _but_ they have very few UMI and we discard them anyway. I am guessing here your motivation is a bit different i.e. considering very low confidence (even with 1 UMI) barcodes, while generally we discard anything below 10 as noise. Thanks a lot for offering to help with index-hopping idea. I agree, it'd be great to include the model in the alevin framework. Currently I just got the gist of your paper, let us go through the paper in a bit more detail and we'll get back to you as soon as we have some free cycles for the integration.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-639137897:158,clear,clear,158,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-639137897,2,['clear'],['clear']
Usability,"Hi @rfarouni ,. Please use [this](https://drive.google.com/file/d/11lav7dOQkn5VuSNZwC2CZUgx_eeXpBmx/view?usp=sharing) link to download a linux compatible binary, the fix will be available by default with the next release . > Also, does Alevin use 10x cell barcode whitelist internally to correct barcodes?. In our experiments, we find that, in expectation, the 10x generated experiments are clean enough that we don't need the 10x whitelisted barcode to be explicitly specified or used. > And do you recommend using the `--naiveEqclass` only 64 guide sequences as features ?. That's a very good question. Basically the answer lies in how complicated the UMI graph network is. Experiment with the antibody derived barcodes (ADT) with 20 protein panel, generally, doesn't need the `--naiveEqclass` mode UMI deduplication, unless the experiment is super deeply sequenced. However, for super low diversity like 4-8 barcodes e.g. for HTO like sample barcodes, the graphical network becomes exponentially hard to solve and significantly increases the running time for alevin. . In general, I'd recommend if you expect very low diversity in the number of barcodes in your experiment, use `--naiveEqclass` otherwise prefer avoiding it. Generally, the experiment with low diversity barcodes results in such a highly dense count matrix that a few error in UMI deduplication won't matter and you can tradeoff extra long running time with reasonable under/over UMI deduplicated counts. . _In short_, 64 guide sequences are relatively high diversity and I'd advise skipping `--naiveEqclass` in your command line argument. Hope it helps !",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-638576983:545,guid,guide,545,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-638576983,4,['guid'],['guide']
Usability,"Hi @rfarouni ,. Thanks for the detailed answer.; > I am not sure why the ISF option didn't work, but probably it has something to do with the guide sequences I was provided. At any rate, I have a few other questions I hope you can help me answer. I'm not sure about this, it's possible if the guide sequences were already reverse-complemented then the above behavior would makes sense. I am a little less familiar with the guideRNA based ECCITE-seq data, although the mRNA library should be 5' and the sequence does come from forward strand but do we expect the guide RNA to be on the forward strand as well ? Unclear . I'll ask around at nygc and would let you know. > Why does increasing --maxNumBarcodes to 200000 results in no barcodes getting corrected? (See log for Run 2 below). What is the rationale for the current default of 100000?. That's again a great question. In short single-cell world is expanding rapidly and alevin was initially designed to work with 10x 3' data and some of the restriction are outdated with combinatorial indexing based multiplexed experiments. To be honest, 100k was just a random high enough number that was put down to throw away the obvious junk data. Having said that, you would notice that in both the logs you attached a significant fraction of barcodes are thrown away i.e., `Skipped 82268 barcodes due to No mapped read`, which is like ~82% of the 100k barcodes. Even if you include the 200k almost everything was thrown away, `[warning] Skipped 184123 barcodes due to No mapped read`. Although your point is important one why things are not getting sequence corrected with 200k, unfortunately I might have to do some more testing on that front to give more precise answer but in your case I'd advise keeping the default 100k bound, unless you are doing combinatorially-indexed data . > For the downstream analysis of such data, I usually work with both the read and UMI counts, but quants_mat.gz only contains the UMI counts. Can Alevin a produce a matri",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-639048052:142,guid,guide,142,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-639048052,8,['guid'],"['guide', 'guideRNA']"
Usability,"Hi @rmurray2,. Thank you for the report. First, I just want to mention that I don't believe v0.99.0 to be an officially released version number. That is, there was a v0.14.x and a (released in source only v0.15.0), and then the versions moved to 1.0.0 and beyond. However, this behavior certainly isn't related to that. There are 2 things going on that can lead to this effect. The first one, which is relatively easy to test, is that there may be small changes in when the inferred library type starts to be enforced (if it is not `IU`) when auto type detection is used (see [this issue and comments therein](https://github.com/COMBINE-lab/salmon/issues/489)). The second and more fundamental thing going on is that the observed behavior is intended. Even with a single thread of execution provided to salmon for mapping and quantification, there is a separate background thread that simply consumes reads from file and puts them in memory for quantification, and while e.g. pairing information between files is guaranteed to be preserved, exact read order is not. This can lead to differences in the order in which reads are processed and, as a result, differences in the initialization conditions of the optimization. The ultimate result is that for transcripts that have large inferential uncertainty, different numbers of reads can be assigned between runs. We have thought *a lot* about this behavior, what it means, and how the `NumRead` values should best be communicated to users. At the end of the day, the `NumReads` constitute the expected value of latent variables inferred in a _very_ high-dimensional space (# of parameters is at least the number of transcripts). Therefore, there are certain transcripts, whose estimated number of reads simply have _tremendous_ inferential uncertainty — and small perturbations in the initial conditions of the optimization will lead to different estimated values for their abundances. For those transcripts where you observe such fluctuations between",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/613#issuecomment-757989858:885,simpl,simply,885,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/613#issuecomment-757989858,2,['simpl'],['simply']
Usability,"Hi @rob-p ,. Thank you for your explanation, that is very clear and helpful. Yes, the transcriptome annotation was not originally from my RNA-seq data and I may try using stringtie to discover new isoforms, probably that would cover more of my reads.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/533#issuecomment-638961902:58,clear,clear,58,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/533#issuecomment-638961902,2,['clear'],['clear']
Usability,"Hi @rob-p, ; Thank you for getting back to me so quickly and thank you for the explanation. ; I found this info about the `--eqclasses ` parameter in the Salmon quant help manual for alignment-based mode:; <img width=""626"" alt=""Screenshot 2023-10-03 at 11 40 56"" src=""https://github.com/COMBINE-lab/salmon/assets/76558077/dc98c406-759f-4543-8cdd-5299d24775eb"">; Everything else I tried was a guess.; I wasn’t sure how to get the right file, so I thought it might be the **eq_classes.txt.gz** file, made using the `--dumpEq` option. I read about [—dumpEq option ](https://salmon.readthedocs.io/en/latest/salmon.html#dumpeq) and I found some explanation of [equivalence class file](https://salmon.readthedocs.io/en/latest/file_formats.html#equivalence-class-file). So, I made this file using the `--dumpEq` option and then used it with `--eqclasses` option, but I made mistake by also providing a BAM file with `-a` option. When I got the error, i thought maybe this file was supposed to be used instead of the alignment BAM file, not together with, and now i understand.; I'm still not clear: is this file only used when I want to analyze the same sample multiple times, with different options?; Also, I noticed the `--eqclasses` parameter isn’t in the help manual for salmon quant in mapping-based mode because it’s not there when I run `salmon quant --help-reads`.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/877#issuecomment-1744787632:1085,clear,clear,1085,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/877#issuecomment-1744787632,2,['clear'],['clear']
Usability,"Hi @rob-p,. Ah, I hadn't looked carefully at the outputs, so I was overlooking the fact that the `meta_info.json` for `salmon alevin` is in the `aux_info` subdirectory, while the one for `alevin-fry quant` is in the output directory, so I don't _think_ there will be a conflict. (We have been using the same directory in our pipeline for simplicity.) However, I do think having them named the same thing is a potential source of confusion. Is there a reason not to name the file produced by `alevin-fry quant` something more like `quant.json` or `quant_info.json` to be more in parallel with the `collate.json` and `generate_permit_list.json` files generated at those steps? Either way, I agree that merging the files within `alevin-fry` is probably _not_ the best solution. . The `cmd_info.json` file, seems a special case: I am not sure what the ultimate goal for that file is; it seems now to be included ""for R compatibility"" though I am not fully clear on what that means (with `.mtx` input we don't need it, but `tximeta`/`tximport` may be looking for it?). If the final quant output directory does need the file, it would seem to make sense to copy it along somehow from the `salmon alevin --rad` output directory (with a stop along the way in the `collate` output I guess?). Presumably the `aux_info` would also be desired for `tximeta` if/when `alevin-fry` support is implemented there?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/688#issuecomment-883524316:338,simpl,simplicity,338,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/688#issuecomment-883524316,4,"['clear', 'simpl']","['clear', 'simplicity']"
Usability,"Hi @rob-p,. I am also seeking guidance on the use of Salmon for metatranscriptomes. Similar to this issue and issue #350 I am using the predicted genes from a metagenome assembly as the 'reference transcriptome' and would like to quantify gene expression from the corresponding metatranscriptome data. My metaT data is unstranded. What flags are most appropriate for this purpose? `--meta`? Something else? Are there any assumptions within Salmon that make it unsuitable for metagenomic/metatranscriptomic data (for example, the probability of observing a fragment when organisms are present at different abudances)?. Rachael",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/195#issuecomment-598522020:30,guid,guidance,30,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/195#issuecomment-598522020,2,['guid'],['guidance']
Usability,"Hi @rob-p,; thanks a lot for your investigation. Could you please be more verbose on those incorrect Build-Depends? What dependencies can be removed (if not used they should not really harm, thought but you are correct that it makes sense to remove these) and more importantly which can not be used. For instance if we can't use libstaden as packaged we have a problem. All preconditions for a Debian package have to be packaged first. Fetching something from network is not permitted at package build time.; Thus I simply tried changing the cmake options to. ```; $ cmake -DCMAKE_BUILD_TYPE=Release -DUSE_SHARED_LIBS=TRUE -DBZIP2_LIBRARIES=-lbz2 -DBZIP2_INCLUDE_DIR=/usr/include -DLIBLZMA_INCLUDE_DIR=/usr/include/ -DLIBLZMA_LIBRARY=lzma -DCMAKE_MODULE_PATH=/usr/share/cmake/Modules -DTBB_WILL_RECONFIGURE=FALSE -DBOOST_WILL_RECONFIGURE=FALSE ..; ```. which does not change the SEGFAULT problem. If the issue belongs to something we need to download from somewhere please let me know what looks suspicious to you. This would be helpful since we could either add it to the Debian package source in debian/missing-sources ... or rather fix the predependency that would break salmon.; Kind regards, Andreas.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1464471988:516,simpl,simply,516,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1464471988,2,['simpl'],['simply']
Usability,"Hi @rob-p. I'm using a SGE-based cluster. The disk I'm writing to is a networked disk that is mounted via NFS on the machines the cluster runs on. I've attached the output of running `qconf -sconf`, which provides details on how the cluster has been configured (I've edited out some lines about the admin e-mails, etc.). I'm not sure how useful much of this information is. A lot of it has to do with scheduling of jobs -- how many jobs/resources users can attempt to claim, that kind of thing. Let me know if there's something else that would be more useful in this context. I've also attached the log that was generated by the indexing run itself (just for the 17mer index), just in case. I can say one thing from having inspected the logs of these things failing a number of times before I finally caved and started giving it insane amounts of memory: by far the longest time and (most likely) the biggest resource hog is between the first and second pass. Even with only 16GB, it manages to complete the first pass (it still takes quite a while, though):. ```; Pass	Filling	Filtering; 1	718	3236	; 2	1839	237; ```. [qconf-sconf.txt](https://github.com/COMBINE-lab/salmon/files/4172585/qconf-sconf.txt); [index_GRCm38_GENCODE_M23_PRI_17mer.log.txt](https://github.com/COMBINE-lab/salmon/files/4172594/index_GRCm38_GENCODE_M23_PRI_17mer.log.txt). EDIT: Oh, I should also probably say, that I'm only seeing this slowdown on index creation. I'm sure that was implied, but I just wanted to be clear that at the moment, I'm happy enough to let the index build for a few hours every once in a while. I'm still saving huge amounts of mapping time, relative to ""full"" aligners.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/476#issuecomment-583567362:1492,clear,clear,1492,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/476#issuecomment-583567362,2,['clear'],['clear']
Usability,"Hi @roryk ; I know about tximport but is there any way to generate the input data for DESeq2 without using R? I am processing the data on one platform and then transfer to another platform for R/DESeq2 analysis. I would like to be able to generate the output of the first part (salmon) without using an R library. . If it is not possible and I have run R to get the count matrix for DEseq2, I can figure out a way to do it. DESeq2 input file is a simple matrix of counts and ""salmon quantmerge"" already generates this, can you please explain to me why an external library is required ? Is there something I am missing that tximport package is doing to the data? Does tximport takes into account gene lengths or library size to generate the output? . Thanks; Best Regards; Hamdi",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/437#issuecomment-545201602:447,simpl,simple,447,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/437#issuecomment-545201602,2,['simpl'],['simple']
Usability,"Hi @roryk,. Salmon doesn't currently have the ability to output a pseudobam, but that is definitely possible (and not too difficult). We have a related feature planned; perhaps you could tell me if it suits your use case. However, first, I should mention that if you'd simply like a pseudobam for _all_ the mapping locations of the reads, you can use [RapMap](https://github.com/COMBINE-lab/RapMap). RapMap implements the quasi-mapping algorithm upon which Salmon and Sailfish are based (and RapMap is used as a library in the Salmon and Sailfish codebases). Given an index and set of reads, RapMap will report all of the multi-mapping locations that Salmon and Sailfish would consider during quantification. The other feature we have in the works is to have Salmon optionally output a `.bam` file (with actual alignments) post-quantification. It turns out that, given the quasi-mapping information and the quantification results, taking the extra step from quasi-mapping to an actual _alignment_ can be done fairly efficiently. In this mode, Salmon would make one more pass over the reads and, considering the estimated abundances, sample a single alignment for each multi-mapping read proportional to the relative abundance of the different multi-mapping targets (i.e. it would perform a sampling over the multi-mapping locations that would, in expectation, give the same abundances as the _soft_ assignments computed by the optimization algorithm). This feature will be very useful for [transrate](https://github.com/Blahah/transrate). However, given that your goal is to use outside information to perform the filtering yourself, this option may not be ideal for you.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/38#issuecomment-175092553:269,simpl,simply,269,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/38#issuecomment-175092553,2,['simpl'],['simply']
Usability,"Hi @s1corley,. Congratulations on your publication! The `--noLengthCorrection` flag has been around for a long time (e.g. where it is suggested in the post to which @tamuanand [links](https://groups.google.com/forum/#!msg/sailfish-users/VIfqBwgF6xQ/fw-rgC_kAwAJ)). However, given our limited access to QuantSeq and our limited (student) bandwidth to do extensive testing on alternative tech, we have kept this flag marked as experimental. As I mention above, it was introduced since, _conceptually_, the QuantSeq protocol should not exhibit a length effect and so the one may not wish to account for the length when determining assignment probabilities during the variational Bayesian optimization. However, the empirical testing of this has been limited. Now that your paper is published, and contains what look to be some _very through_ assessment methodologies, we may be able to look into this and determine if there is anything we can do to, perhaps, optimize salmon even more for accurate quantification from the QuantSeq protocol. We would welcome any suggestions or feedback you may have. Congratulations again on the paper!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-565474848:1074,feedback,feedback,1074,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-565474848,2,['feedback'],['feedback']
Usability,"Hi @saipra003,. Thank you for posting the issue, and also following up with the resolution. It’s not immediately clear why there would have been an issue with 1.2.1, but we’ll be sure to make not of this for anyone else who runs into such an issue with older releases. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/690#issuecomment-886279790:113,clear,clear,113,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/690#issuecomment-886279790,2,['clear'],['clear']
Usability,"Hi @satta,. Thanks for bringing this to my attention. I am of two minds on this proposal. On one hand, I agree that it is cleaner, in theory, to have a RapMap shared library to which Salmon could simply link. Currently, Salmon pulls in the relevant portions of the RapMap code to call what is essentially an ill-defined public API for mapping. On the other hand, I have two concerns about separating the code at this point, one is major the other minor. The major concern is that both Salmon and RapMap are still very much under active development, core code and even the interfaces are undergoing reasonably rapid changes (thus the versioning < 1.0). This allows me to easily add features that may potentially benefit Salmon to the RapMap codebase, and then to synchronize Salmon releases with particular commits (tags) in the RapMap codebase. The current build system makes it very easy to pull in the appropriately versioned RapMap code. On the other hand, I have very little experience in properly versioning shared libraries so I would have to understand that better and how this could be done without complicating the build process. My _minor_ concern is that I don't know what effect, if any, separating the code into a separate shared library might have on compiler optimizations. Right now, since the relevant RapMap code is compiled alongside Salmon and they are linked together into the same module, certain optimizations may be possible that would not be so when linking to a shared library. My educated guess is that the effect of such optimizations would be negligible, but it's something that may be worth some exploration first. Overall, I'm very open to this idea, but I think I need to do some homework on it before we can commit and undertake the change.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/87#issuecomment-246027704:196,simpl,simply,196,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/87#issuecomment-246027704,2,['simpl'],['simply']
Usability,"Hi @schelhorn,. Sorry for the uncharacteristically slow response on this. We're going full steam ahead for the RECOMB deadline, so I've been less responsive than usual. Anyway, I've invited you to the repository for the fusion project (it's currently private). Feel free to poke around, but it's probably not useful until we can send you a short writeup describing the current pipeline (since things are still very ""alpha""). Regarding calling fusions from the sam output of Salmon, one can't do this directly because there are, by default, no encompassing reads (i.e. individual reads split between transcripts) and, to improve abundance estimation, salmon is conservative with it's use of spanning reads. However, we can get at this information from quasi-mapping, so I can definitely consider adding some flags to provide this info (this is the type of thing we output in the fusion pipeline currently, and then we have to postprocess it).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/52#issuecomment-256045452:146,responsiv,responsive,146,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/52#issuecomment-256045452,2,['responsiv'],['responsive']
Usability,"Hi @summerrfair ,. I can't see anything obviously wrong with the command line. Do you have a small example of the transcripts.fa and myseq.bam file you could share? The message indicates that salmon thinks its running in mapping-based mode (with input fastq files), but you are clearly running in alignment based mode. Is the behavior any different if you put the -a argument first?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/511#issuecomment-616870047:278,clear,clearly,278,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/511#issuecomment-616870047,2,['clear'],['clearly']
Usability,"Hi @tamuanand and @uros-sipetic,. Thanks for the feedback on this! I just cut v1.2.1 which ""fixes"" the behavior. It will simply discard any duplicate _decoy_ sequences, which resolves this problem without requiring manual intervention.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/505#issuecomment-617830355:49,feedback,feedback,49,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/505#issuecomment-617830355,4,"['feedback', 'simpl']","['feedback', 'simply']"
Usability,"Hi @tamuanand,. Nope; these values are right. The `indexVersion` is a global identifier with respect to previous versions of salmon. It is a global number that is incremented each time (a) a backward-incompatible change to the index is introduced or (b) a fundamentally new piece of information is contained in the index. This field took a value of `1` way back when we started versioning the salmon index a number of years ago, and version `1` was based on the RapMap index (rather than pufferfish like the current one). This is simply a global identifier that we can use internally to determine whether the version of salmon reading this index can be expected to make use of it. The other field `indexType` corresponds to the value from an internal enumeration used in the salmon code. Over the years (since it was first released in 2014), salmon has used a number of different data structures for its underlying index. First, it used a modified version of the FMD index that BWA is based upon, then, it used the RapMap index (based upon a sparse hash map and an uncompressed suffix array), and now it uses the pufferfish index. This `indexType` filed just records the type of this index. In modern (post 1.0.0) versions of salmon, the pufferfish index (`2`) is the only valid version. There's a lot of history to these values, but they all make sense internally within salmon, which is how the contents of this file are primarily used (i.e. to make sure there is compatibility between the version of salmon being run and the index we are trying to consume). Hopefully, this description clears things up a bit. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/504#issuecomment-613217080:530,simpl,simply,530,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/504#issuecomment-613217080,4,"['clear', 'simpl']","['clears', 'simply']"
Usability,"Hi @tamuanand,. Ok, it seems something simple with the preparation of the decoys.txt file. I'm looking into it. If you watch the log, you see the following output before the (intentional exit with status code 1):. ```; [2020-04-14 09:44:12.991] [puff::index::jointLog] [critical] The decoy file contained the names of 955 decoy sequences, but 953 were matched by sequences in the reference file provided. To prevent unintentional errors downstream, please ensure that the decoy file exactly matches with the fasta file that is being indexed.; [2020-04-14 09:44:13.304] [puff::index::jointLog] [error] The fixFasta phase failed with exit code 1; Command exited with non-zero status 1; 56.66user 9.14system 1:04.69elapsed 101%CPU (0avgtext+0avgdata 6902936maxresident)k; 3792inputs+16outputs (30major+3629051minor)pagefaults 0swaps; ```. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/505#issuecomment-613451792:39,simpl,simple,39,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/505#issuecomment-613451792,2,['simpl'],['simple']
Usability,"Hi @tamuanand,. Thanks again for your detailed questions and thoughts on this issue. Just to follow-up / expand a bit on what @k3yavi has said (and to answer your other question): Yes, one would imagine that, given the details of the QuantSeq protocol, turning off length correction would make the most sense. The main reason this flag is listed as _experimental_, is simply that it was designed based on the expected characteristics of the protocol. Conceptually, the protocol is performing tagged-end sequencing, and so there should be little-to-no length effect. However, since we haven't done extensive internal validation on QuantSeq data, we have left this flag as experimental until it is further tested by ourselves or others. > Also @rob-p , weren't you referring to the RSEM caveat with QuantSeq data analysis wherein one cannot ask RSEM to disable lengthCorrection and hence the count statistics might be misleading?. Correct; as far as we are aware, there is no way to disable the built-in length-dependent assumptions of RSEM. One could use the `--estimate-rspd` flag to allow learning of a non-uniform read distribution (the equivalent of `--posBias` in salmon), though it's unclear / unlikely if this would be as effective as fully disabling the length correction for this type of tagged-end data. If you have any good empirical assessment mechanism for QuantSeq data, and a chance to test out these different salmon options, we'd be happy to get feedback and discuss details further!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-565285540:368,simpl,simply,368,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-565285540,6,"['feedback', 'learn', 'simpl']","['feedback', 'learning', 'simply']"
Usability,"Hi @tamuanand,. Thanks for the suggestion. You're right, of course, and we should change the wording in that readme. The cause of the sequence similarity is not always known, and frankly, not important for our particular application. We adopted this term as shorthand given it's common use and also because the version of MashMap used to compute these sequence-similar regions was introduced in the paper [A fast adaptive algorithm for computing whole-genome homology maps](https://academic.oup.com/bioinformatics/article/34/17/i748/5093242). In the preprint itself, we're generally careful to simply refer to these as sequence-similar regions ;).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/365#issuecomment-499476462:594,simpl,simply,594,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/365#issuecomment-499476462,2,['simpl'],['simply']
Usability,"Hi @taylorreiter,. I was wrong — there was simply a bug that, in single end mode, everything was being written out with the `u` flag. This is now fixed in develop. It will be in the next release. Sorry about that!. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/748#issuecomment-1146205498:43,simpl,simply,43,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/748#issuecomment-1146205498,2,['simpl'],['simply']
Usability,"Hi @teshomem,. If you want to proceed with transcript-level differential expression, _all transcripts are relevant_. That is, the relevant tools (e.g. DESeq2, limma-voom, Sleuth, etc.) will expect to be provided with _all_ quantified isoforms for each gene. They will then automatically apply their own filtering criteria to determine which transcripts to actually test for DE. . If you want to proceed with DE at the gene level (and hence want to aggregate the quantification information from the level of transcripts to genes), the easiest option is to use the [tximport](http://bioconductor.org/packages/release/bioc/html/tximport.html) package. It can import all of the quantifications from multiple runs of Salmon, aggregate them to the gene level, and produce a count matrix that can then be used with traditional count-based gene-level DE tools. I would recommend the pipeline Salmon => tximport => DESeq2 for gene-level DE analysis. Finally, the best place for questions like this, that don't have to do with a specific bug or feature request for the Salmon software, is the [Google user group](https://groups.google.com/forum/#!forum/sailfish-users). This way, other users will be more likely to provide you with feedback and help answer your questions.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/154#issuecomment-329974141:1222,feedback,feedback,1222,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/154#issuecomment-329974141,2,['feedback'],['feedback']
Usability,"Hi @tillea,. So I went through the list of deps pulled in by `apt build-dep salmon` and the minimal set I gave above. I tried to make the smallest number of changes I could to the `apt build-dep salmon` list while also removing things that are clearly outdated (we no longer use jellyfish, rapmap, etc. and we use the header-only version of spdlog). As a result I came up with this list of dependencies. The offending dependency seems to be `libcereal-dev`. Specifically, I was able to install just this list of dependencies (minus `libcereal-dev`) atop a clean `debian:testing` and get a working version where the only thing downloaded from the internet was the appropriate version of the pufferfish files grabbed by `fetchPufferfish.sh` in the `1.10.0` release. Once I installed `libcereal-dev` with `apt-get install`, and rebuilt, then I got the segfault mentioned at the top of this issue. So, it seems that we either have to let `salmon` build it's own libcereal, or figure out what the problem is with the library upstream. Please let me know if this you observe this same behavior as well (also @nileshpatra may want to try this out). If so, perhaps we can get `libstaden` updated upstream, and then use this as the new dep list for `salmon`. I installed these deps with a simple `xargs apt-get install -y < deps_sorted_updated.txt` (without `libcereal-dev` for the working version, and with it included, as below, for the segfault). Best,; Rob. [deps_sorted_updated.txt](https://github.com/COMBINE-lab/salmon/files/10949233/deps_sorted_updated.txt)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1464986376:244,clear,clearly,244,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1464986376,4,"['clear', 'simpl']","['clearly', 'simple']"
Usability,"Hi @tmms1 ,. > I think that each such line corresponds to an equivalence class (EC). The first entry on each row is the number of transcripts in the EC. This is followed by the transcripts (more correctly, indices you can use to obtain the transcripts). Then you have the number of reads with in the EC, followed by the number of barcodes (~cells). For each barcode, you have an index that can be used to retrieve the identity of the barcode, followed by the number of UMIs within that barcode, the sequence of the UMI and lastly the number of reads associated with that UMI. This is correct !. Unfortunately you goal is not very clear to me and the output matrix depends on that. I understand that you wan't a matrix of dimension |eq_class X cells| but if you wan't the values in the matrix to be read count then you have to add the counts of all the UMIs in class across the cells; and if you wan't the values in the matrix to be the frequency of the unique UMIs then just count the UMIs you wan't instead of reads.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/728#issuecomment-1029328067:630,clear,clear,630,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/728#issuecomment-1029328067,2,['clear'],['clear']
Usability,"Hi @tobi-te ,; Salmon is a two-phase algorithm i.e. online and offline. The first phase i.e. online-phase learns various parameters before starting the offline-phase (order doesn't matter). Like most online learning algorithm Salmon also expects the input to be randomized enough to avoid bias or in the case of Salmon *possibly* nudge the offline-phase towards a local-minima, which can vary according to the data (not always). I think in your case even though the learnt online parameters are biased (because of non-random order) the estimated abundances at the end are corrected by the offline-phase pretty well and you are observing the similar results.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/155#issuecomment-331262951:106,learn,learns,106,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/155#issuecomment-331262951,6,['learn'],"['learning', 'learns', 'learnt']"
Usability,"Hi @tomsing1 ,; Apologies for the slow response, I was out of country for a while. Thanks for your kind words and starting a very interesting suggestion.; It’s fascinating to see, how methods being used in single-cell RNA-seq is coming full circle back to the bulk RNA-seq experiments. We have to do some more digging to say clearly about the caveats of using Alevin with the mentioned 3’ bulk RNA-seq experiments but given the understanding from the picture of the shared image we don’t see any obvious show stoppers; although below mentioned concerns should be kept in mind while using Alevin for bulk data deduplication:. Alevin solves the problem pretty well for protocols where fragmentation of the cDNA molecule happens post PCR amplification. There might be some concerns about over-deduplication of the UMI if fragmenation happens before amplification. Although in current form, Illumina sample index can be given as an external whitelist to Alevin but user should be aware that Alevin performs a sequence correction step before starting any optimizations.; Alevin is designed for droplets based protocols, where one end of Paired end read is just the CB/UMI (i.e. no read sequence) and therefore Alevin can’t optimally use the full paired end information of the bulk 3' protocol if its both end has read-sequence for example the ambiguous mapping resolution based on a previously/empirically known approximate fragment length. We would be more than happy to help/discuss, how does the results look in bulk 3’ tagged protocols or if you have particular suggestions about what improvements can be done in Alevin.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/306#issuecomment-439530193:325,clear,clearly,325,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/306#issuecomment-439530193,2,['clear'],['clearly']
Usability,"Hi @uros-sipetic!. Unfortunately, as you suggest, there really is no good way to infer the fragment length distribution from only single-end reads. Rather, this flag determines how the conditional probability of single-end fragments near the beginning (if in the rc orientation) or end (if in the forward orientation) of the transcript are determined. A single-end read does not have any known fragment length. But we do know that e.g. fragments very close to the end or beginning of the transcript are rather unlikely. In this case, we can integrate (sum) over all possibilities to assign a conditional probability. This is what salmon does. For a single-end read (assume forward orientation for simplicity) at position i on a transcript of length n, we consider the conditional fragment length probability to be given by F_n(n-i), where f_n is the conditional fragment length distribution conditioned on the transcript length (maximum observable length) being n and F_n is the cumulative distribution function of f_n. Intuitively, this means that fragments very close to transcript ends will get a smaller conditional probability, while those farther from the end will get larger conditional probabilities. The `--noSingleFragProb` flag simply turns off this conditional probability all together. It is _not_ recommended to disable the single-end fragment length probability modeling. We have evidence from testing that it improves quantification accuracy. Thus, I would suggest _not_ setting the `--noSingleFragProb` flag. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/575#issuecomment-711061553:697,simpl,simplicity,697,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/575#issuecomment-711061553,5,"['Intuit', 'simpl']","['Intuitively', 'simplicity', 'simply']"
Usability,"Hi @vals,. So there was a very subtle bug in `useFSPD` that would (in a very non-reproducible manner) trigger such a segfault. It was related to some very tricky locking behavior. However, the manner in which `useFSPD` corrected for position specific bias isn't actually compatible with our new sequence-specific and fragment-gc bias models. Thus, I've deprecated `useFSPD`. The replacement is the flag `posBias`. This models the same type of positional bias, but does so in a way that is compatible with our other bias models. It also doesn't rely on the tricky threading behavior, so it should be more stable. Unlike sequence-specific and fragment-gc bias, however, the `posBias` option is still _experimental_ in the 0.7.0 release. However, we have been testing it internally, and I'd be very grateful for your feedback if you have a chance to try it out. Assuming things look good, we can promote it from experimental in the next release.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/64#issuecomment-241234373:814,feedback,feedback,814,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/64#issuecomment-241234373,2,['feedback'],['feedback']
Usability,"Hi @vasisht,. Actually, the settings of these flags aren't incorrect according to the [SAM spec](https://samtools.github.io/hts-specs/SAMv1.pdf):. > Bit 0x4 is the only reliable place to tell whether the read is unmapped. If 0x4 is set, no assumptions can be made about RNAME, POS, CIGAR, MAPQ, and bits 0x2, 0x100, and 0x800. That is, if the unmapped flag is set, then there is not a specific ""correct"" setting for these other fields, since they should most likely be ignored anyway. That being said, concordant with some small changes in the [most-recent RapMap](https://github.com/COMBINE-lab/RapMap/releases/tag/v0.4.0), the CIGAR string will be set to `*` for unmapped reads in future versions of Salmon. We may consider setting other fields to `*` for unmapped reads to simplify the output, but, as the SAM spec suggests, these fields offer quite a bit of freedom in terms of ""legal"" values if the unmapped flag is set anyway.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/94#issuecomment-250350189:776,simpl,simplify,776,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/94#issuecomment-250350189,2,['simpl'],['simplify']
Usability,"Hi @wdecoster,. Thanks for reporting this. One restriction that needs to be better documented (actually, I have to make sure it is properly documented at all!) is that the library type should come _before_ the reads they describe. That is, you should consider passing `-l SF -r {}` rather than `-r {} -l SF`. The reason for this is that the `-r` and `-1,-2` parameters are repeatable so you could, conceivably, pass multiple reads of different library types. However, this is a feature that nobody uses and frankly doesn't make too much sense (so I'll consider removing it in the future to simplify library type parsing). For the time being, I'll also consider printing a warning message when a read file is encountered without an explicitly pre-defined library type (in that case, the behavior, as you saw, is to assume an unstranded library). Could you let me know if passing `-l` before `-r` resolves the issue for you. As to your other suggestion. The internal capitalization rules follow those for camel-case naming of variables (as opposed to separating words with`_`). However, I realize this is somewhat esoteric and even among those who are familiar with such conventions, an arbitrary preference. I'll look into aliasing this flag (and maybe others) to be usable with different names as well. I just have to check how to do this (and if it is possible) with boost's program options.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/177#issuecomment-347524360:590,simpl,simplify,590,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/177#issuecomment-347524360,4,"['simpl', 'usab']","['simplify', 'usable']"
Usability,"Hi @xinbindai,. What you are seeing in both Salmon and RSEM is the expected behavior. This is because, to a large extent, the entire purpose of these tools is to appropriately allocate mulit-mapping reads. In your case, it is likely the case that one of the two very similar transcripts could account for all of the reads, while the other could not. For example, image I have a simple scenario where I have two transcripts:. ```; ACACACTGTGTGTG; ACACACGGTGTGTG; ```. Now, imagine I observe the ""reads"":. ```; ACAC; ACAC; CACA; CACA; ACTG; CTGT; GTGT; TGTG; TGTG; ```. The majority of these reads could have come from either transcript (and are equally likely to have come from both). However, the fact that we observe `ACGT` and `CTGT` is rather strong evidence that we could explain all of the reads via the first transcript while positing 0 (or close to 0) abundance for the second. On a much larger scale, this is what Salmon and RSEM are doing --- they are finding the most likely abundances of the transcripts given the observed data (the reads). When there is unique evidence of one of the two variants, and no unique evidence of the other, the maximum likelihood estimate for the variant with no unique evidence is very small. I'm not sure how many reads you are mapping, but you likely got a somewhat different estimate from eXpress since it tends to regularize it's abundance estimates a bit more strongly than Salmon or RSEM. That being said, this is the intended behavior of these tools, they are meant to probabilistically allocate multi-mapping fragments to similar transcripts in a manner that maximizes a global likelihood, so I don't think that what you are seeing is un-expected. In fact, it is consistent with the probabilistic model that underlies all three tools.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/107#issuecomment-263408444:378,simpl,simple,378,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/107#issuecomment-263408444,2,['simpl'],['simple']
Usability,"Hi @yagam-fluent,. Thanks for the excellent question. We should update the documentation regarding this option. Basically, in `salmon alevin`, we assumptions about expected read orientation are applied as ""hard filters"". That is, the behavior is equivalent to `--incompatPrior 0`, so that aligninments not in the prescribed orientation are simply not considered as invalid alignments. This is because in the case of single-cell processing, we (the community in general) currently do not have as sophisticated of probabilistic models for resolving UMI origins and gene abundances, and so algorithms typically do not take into account a ""wrong orientation"" probability. So, in `salmon alevin` if you are using alevin itself for the quantification, then hard filtering will be applied based on the expectations of `--libType`. On the other hand, if you are using `salmon alevin` to simply map the reads for subsequent processing with [`alevin-fry`](https://github.com/COMBINE-lab/alevin-fry) (i.e. `salmon alevin .... --rad` or `salmon alevin ... --sketch`), then *no* filtering is applied to mapping orientation, and instead you filter reads by orientation later in `alevin-fry`'s `generate-permit-list` step. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/749#issuecomment-1038325742:340,simpl,simply,340,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/749#issuecomment-1038325742,4,['simpl'],['simply']
Usability,"Hi @yeodynasty,. There are two different ways to tackle this question. The first relies on the fact that the correction employed by salmon for GC bias is done via the adjustment of transcript effective lengths. Here, you could compare the effective length in the quant.sf file to the effective length you would get ignoring GC-fragment (or other bias). Granted, the latter is not written down in the file here, but it is straightforward to calculate since salmon also writes out the fragment length distribution. ; The effective length discarding bias estimates is simply the transcript length, minus the mean of the conditional fragment length distribution (the fragment length distribution from 0 up to the transcript length, re-normalized to be an appropriate probability distribution). If you look at the differences between these values, you can infer how much bias correction was applied. Specifically, when the bias-corrected length is longer than the non bias-corrected length, then these transcripts are over-represented in sequencing and the bias correction aims to reduce their estimated abundance. On the other hand, when the bias-corrected length is shorter than the non bias-corrected length, then these transcripts are under-represented in sequencing and the bias correction aims to increase their estimated abundance.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/578#issuecomment-717267531:565,simpl,simply,565,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/578#issuecomment-717267531,2,['simpl'],['simply']
Usability,"Hi Alex,. The appropriate way to _force_ salmon to use the library type as a hard constraint is to pass the option `--incompatPrior 0.0` on the command line. This will tell salmon that it should consider a fragment mapping different than the library type to be impossible (i.e. this mapping should simply be discarded). This will actually be the default behavior starting from the next release anyway, as the current behavior seems to confuse more people than not. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/67#issuecomment-388863963:298,simpl,simply,298,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/67#issuecomment-388863963,2,['simpl'],['simply']
Usability,"Hi Avi,. Thanks for the detailed reply. I was able to run it (see logs below), but I had to use `ISR`, not `ISF` to get it to work. I also had to add these two settings as well; `--freqThreshold 1 --lowRegionMinNumBarcodes 100`. . I am not sure why the `ISF` option didn't work, but probably it has something to do with the guide sequences I was provided. At any rate, I have a few other questions I hope you can help me answer. 1. Why does increasing --maxNumBarcodes to 200000 results in no barcodes getting corrected? (See log for Run 2 below). What is the rationale for the current default of 100000? ; 2. For the downstream analysis of such data, I usually work with both the read and UMI counts, but `quants_mat.gz` only contains the UMI counts. Can Alevin a produce a matrix of read counts as well. It would be a great feature to add. For now, what is easiest way to get the cell x feature matrix of read counts if I use the ` --dumpEq` or `--dumpBfh` flags? Can *tximport* be used for this or do I need to use the Python [parser]([https://github.com/k3yavi/vpolo/blob/master/vpolo/alevin/parser.pyl]) first?. I will be sending you some reads from the experiments for unit testing shortly. Thanks!. Run 1: `salmon alevin -l ISR --citeseq --barcodeLength 16 --umiLength 10 --end 5 --featureStart 19 --featureLength 21 --maxNumBarcodes 100000 --freqThreshold 1 --lowRegionMinNumBarcodes 100`. > 20-06-04 12:24:47.610] [alevinLog] [info] set CITE-seq minScoreFraction parameter to : 0.797619; > [2020-06-04 12:24:47.610] [alevinLog] [info] Found 64 transcripts(+0 decoys, +0 short and +0 duplicate names in the index); > [2020-06-04 12:24:47.610] [alevinLog] [info] Filled with 64 txp to gene entries ; > [2020-06-04 12:24:47.610] [alevinLog] [info] Found all transcripts to gene mappings; > [2020-06-04 12:24:47.616] [alevinLog] [info] Processing barcodes files (if Present) ; > ; > [2020-06-04 12:26:04.322] [alevinLog] [info] Done barcode density calculation.; > [2020-06-04 12:26:04.322] [alev",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-638991199:324,guid,guide,324,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-638991199,2,['guid'],['guide']
Usability,"Hi Avi,. Yes I just asked and the guide sequences were reverse complemented. I was looking through the results and comparing it with the output of another alignment software. I noticed that there are substantially fewer UMI per guide (in cell) throughout ( see figures for comparison). . ![image](https://user-images.githubusercontent.com/9895004/83803410-7eb16f80-a67a-11ea-832d-562c88dafef3.png) ; ![image](https://user-images.githubusercontent.com/9895004/83803427-8709aa80-a67a-11ea-9ea4-f66ca447a65c.png). Also, the number of UMIs per cell barcode is consistently lower and there is around 796 barcodes that are not found in the 10X whitelist, the majority of which tend to have 1 UMI count only. Here is tally, where the TRUE column indicates the barcode is found in the whitelist. The row names indicate the total number of UMIs; ; ![image](https://user-images.githubusercontent.com/9895004/83803984-7279e200-a67b-11ea-8578-fc863f94f714.png). It would be great if you can implement the index hopping correction in Alevin. The software we have works fine if the number of samples is not too large. If had known how to code in C++, I would have implemented part of the code more efficiently using Rcpp. Please let me know if you ever decide to add this feature to Salmon. I am more than happy to help. Rick,",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-639088909:34,guid,guide,34,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-639088909,4,['guid'],['guide']
Usability,"Hi Jason,. Thanks for the kind words, and for the detailed issue! This is sort of a tough one, since salmon tries to work out the relative abundance of these different transcripts in the way that maximizes the likelihood of the observed data (or, more specifically, maximized the ELBO in the variational Bayesian framework). Of course, you seem to know that already :). One thought that comes to mind, though, is the following. The default settings for salmon favor sparsity of the solution pretty strongly — it is important to explain the data with as few distinct transcripts as possible. While this often seems a nice thing to do, it can tend to lead to the type of behavior that you are seeing. The way to modify this is to alter the `--vbPrior` parameter to salmon. Basically, this number encodes the prior observation weight that should be attributed to each isoform _before_ accounting for the data. The default value for this parameter is 0.01. Small values (<< 1) are sparsity inducing, while larger values are not (and values close to 1 and above actually penalize sparsity). You could try quantifying with a few (larger) values of this parameter to see if any of them give allocations among these isoforms that seem to make more sense to you (or that agree more strongly with any alternative assays). Actually, I'd be very interested in hearing any feedback you have about this if you find a setting that is more in line with what you expect!. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-622566744:1360,feedback,feedback,1360,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-622566744,2,['feedback'],['feedback']
Usability,"Hi Jason,. Thanks for the super-detailed feedback! A couple of thoughts / questions:. > FYI, I am getting a segfault when I run only --posBias in the current salmon version, but if I run all the models together like --gcBias --seqBias --posBias, it completes fine. ~~Do you have a small example (ref / read pair) that reproduces this? It would be great to figure out why and fix it. We could split that into a new issue if you'd rather.~~. P.S. Nevermind; thanks to you mentioning this, I was able to track it down and fix it in develop!. > As I understand the selective alignment, the alignment scores are passed to the quantification step, but the position of the reads is not used downstream. . Well, yes and no. We make extensive use of the position when estimate the implied fragment length (distance between paired end reads) and then model the conditional probability of this fragment based on the global fragment length distribution. This is just as much as is done by e.g. RSEM. However, you are right that there is no notion of using the coverage profile in estimation (more on this below)!. > Also, my intuition for these transcripts is not really a coverage ""bias"" . My intuition agrees with yours here completely. First, this isn't really a coverage bias as we use the normal definition of the term. Second, the positional bias modeling in salmon is not on a per-transcript level (since that would be an astronomical number of different parameters to learn, and any procedure would almost certainly overfit). Instead, it groups transcripts into length bins, and learns a distinct coverage bias model per-bin. > It would be neat if Salmon could detect these kinds of dramatic dropoffs and add a warning or something... even if not incorporating the information into the quants... it could even be a good QC step to identify large deletions/insertions over a gene body. As far as I know, there are NO rnaseq quant programs that would handle this, because even something like a STAR -> RSEM ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-623047035:41,feedback,feedback,41,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-623047035,2,['feedback'],['feedback']
Usability,"Hi Kadir,. So, the short answer is that on a _single sample_ the `-g` flag and `tximport` do something very similar. However, the real benefit of `tximport` is that it has access to _all_ of the samples when doing transcript to gene-level aggregation. . So, while Salmon with the `-g` flag will estimate the average expressed gene length in each sample, `tximport` will also have knowledge of how the average gene length varies across all samples. Also, `tximport` provides a few different options for how, exactly, you wish to aggregate. Generally, the `-g` option is completely reasonable, but `tximport` is the same in the simple case and better in the general case.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/169#issuecomment-341731522:626,simpl,simple,626,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/169#issuecomment-341731522,2,['simpl'],['simple']
Usability,"Hi Kivanc,. Thanks for the kind words, and thank you for the _extremely detailed_ report. Reports like this are a model of what every developer wishes a user did before filing an issue :). First, let me clear up what seems like might be a small source of confusion. Since both of the salmon runs are from v1.1.0, _neither_ of these are making use of quasi-mapping. Specifically, newer versions of salmon _only_ perform selective alignment (and this makes the `--validateMappings` command line argument redundant in newer versions, though we keep it so as to maximize backward compatibility with command line parameters people may be using). So, the main difference between your two salmon runs is inclusion of the decoy set. This almost certainly means that the reads that map in your second set of salmon runs but not your first are being assigned to decoys in the first case. To try and get a better handle on this, could you upload a `meta_info.json` file from both runs? This file lives in the `aux_info` directory, and it will provide information about e.g. how many reads were best mapped to decoys and were discarded for this reason. The guarantee you get from the selective alignment is that, if the fragment is discarded by decoy mapping, it maps _strictly better_ to the decoy than to the non-decoy sequence. There are many reasons this could happen. One is rRNA contamination, another could be that reads are coming from processed pseudogenes that are not properly in your annotation, yet a third is that your sample has a considerable fraction of reads spanning exon-intron junctions (in this case, the read will map better to the corresponding location on the genome, and worse to the annotate transcript where the intronic sequence is not present). Now, figuring out exactly which of these cases you are in is a bit more difficult, but one approach would be to pick one of the samples with the biggest differences and map to the reads to the genome with e.g. STAR or HISAT2 to see what y",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/479#issuecomment-578848875:203,clear,clear,203,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/479#issuecomment-578848875,2,['clear'],['clear']
Usability,"Hi Rob, . Thanks for the quick reply. I'm looking into it and will try this with an updated install of GCC >= 5.2.; The system default gcc is 4.8.5 but I set it to use a different install using environment modules to load gcc-4.9.2 but some environment variables may not have been set correctly, hence why the build file switches to a lower-version GCC but it isn't clear why it looks for 4.8.2 despite that.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/296#issuecomment-422891645:366,clear,clear,366,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/296#issuecomment-422891645,2,['clear'],['clear']
Usability,"Hi Rob,. Thanks! That's brilliant. Just what I needed. Now I've realised what I've done. I simply hadn't checked the manual for a while and in my mind the default (max) k had morphed from 31 into 35 (silly me, really need to check the manual more). . All the best, and thanks again!; Dan",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/632#issuecomment-779421124:91,simpl,simply,91,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/632#issuecomment-779421124,2,['simpl'],['simply']
Usability,"Hi Rob,. The joint distribution of the read and UMI counts can contain important information. The majority of observations (CB + guide combination) lie along a well defined experiment-specific mean trend whose slope is given by the coverage ( ratio of reads to UMIs). Also the same regularity can be observed when aggregating across the cell barcodes. See figure below. The points below the black horizontal line are cells with less than 100 reads. ![image](https://user-images.githubusercontent.com/9895004/83791774-30937080-a668-11ea-9b44-937ba8f69b34.png). At the guide level, it would look like this . ![image](https://user-images.githubusercontent.com/9895004/83792096-941d9e00-a668-11ea-9b26-976332f639fe.png). In general, I often find myself needing to work with read counts. For example, the read counts can be used to estimate the hopping rate and detect hopped reads in multiplexed scRNAseq data as we show in this recent paper https://www.nature.com/articles/s41467-020-16522-z . Rick,",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-639005220:129,guid,guide,129,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-639005220,4,['guid'],['guide']
Usability,"Hi Rob. I thought about this a little bit more. I am confused. We build the index from decoys. My understanding is that only reads that map to the decoy will be quantified. I am surprised to see that the name for mapped reads would show up in the unmapped_names.txt file. It seems like I need to use something like. Grep -v “$d”. to find the reads that did not map. Is this correct? I have been given the task of exploring our unmapped reads. Running grep is not a big deal. I just want to make sure I do not mess up my downstream analysis. By the way our lab is a huge fan of Salmon. ctrl.1.unmapped]$ cut -d "" "" -f 2 aux_info/unmapped_names.txt | sort | uniq -c; 519916 d; 39097 m1; 34534 m2; 747447 u. Kind regards. Andy. From: Rob Patro ***@***.***>; Reply-To: COMBINE-lab/salmon ***@***.***>; Date: Thursday, May 6, 2021 at 1:53 PM; To: COMBINE-lab/salmon ***@***.***>; Cc: ""andrew e. davidson"" ***@***.***>, Mention ***@***.***>; Subject: Re: [COMBINE-lab/salmon] salmon --writeUnmappedNames produced undocumented result (#657). Hi @aedavids<https://github.com/aedavids>,. Thanks for catching that this is undocumented! This means that the mapping type was determined as mapping to a decoy sequence. When we added this output into the code, the documentation wasn't updated accordingly. We'll update the documentation. Best,; Rob. —; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://github.com/COMBINE-lab/salmon/issues/657#issuecomment-833857753>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AN3VWAQ35L6PU3DKXYIM4ODTML6TPANCNFSM44HLOFXQ>.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/657#issuecomment-833928924:1007,undo,undocumented,1007,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/657#issuecomment-833928924,4,['undo'],['undocumented']
Usability,"Hi Rob. Thanks for the explination. Andy. From: Rob Patro ***@***.***>; Reply-To: COMBINE-lab/salmon ***@***.***>; Date: Friday, May 14, 2021 at 1:41 PM; To: COMBINE-lab/salmon ***@***.***>; Cc: ""andrew e. davidson"" ***@***.***>, Mention ***@***.***>; Subject: Re: [COMBINE-lab/salmon] salmon --writeUnmappedNames produced undocumented result (#657). Hi @aedavids<https://github.com/aedavids>,. Sorry for the delay in replying to your reply here. So I think what you suggest is the right solution, and there are some strange historical reasons we write the decoy names out in the unmapped file. We build the index from decoys. My understanding is that only reads that map to the decoy will be quantified. I am surprised to see that the name for mapped reads would show up in the unmapped_names.txt file. Well, it's the case the decoys are not be quantified. That is, only the target transcripts will appear in the quant.sf file, no decoys should be present there. The main purpose of the decoys is to account for reads not from target transcripts that might otherwise be sequenced in the sample. The reason we report the decoy mapping fragments in the unmapped names file is, as I said, a historical contingency. Basically, since we're not mapping the decoys to targets and counting them toward quantification, one might be interested in knowing where the decoy sequences come from. At some point, the easiest way to do this was just to place the name of these fragments in the unmapped names file (with the d tag) and then grab the reads and go fishing with them in some other way. However, I totally understand why including them in the unmapped names file is confusing. During selective-alignment, if we assign a fragment as best mapping to a decoy, it doesn't get assigned to a quantifiable target, but it's not technically unmapped in the same sense as the other unmapped reads. That is, we know it comes from the decoy sequence, that the alignment score is at least the minimum required, and tha",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/657#issuecomment-843255628:323,undo,undocumented,323,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/657#issuecomment-843255628,2,['undo'],['undocumented']
Usability,"Hi Ryan,. The difficulty is, indeed, exactly as you specify. Given a single-end read, one does not know the length of the _fragment_ from which it originates. In this case the ""right"" thing to do (the best thing we can do) is to consider the read as starting / ending a fragment of every possible length allowed by the user-provided fragment length distribution (with the contribution of each possible fragment weighted by the probability of observing a fragment of that length). In order to make this computationally feasible, one would have to do some clever pre-computation and thing a bit more about how to efficiently update the observed GC model (right now, each mapping contributes a single weight to the model, but under the naive implementation in the single-end case, each mapping would contribute different weights to each bin of the observed GC-bias curve, which would slow things down considerably). Also, as you point out, the quality of the correction would depend somewhat on the user providing appropriate parameters for the fragment length distribution mean and standard deviation — but this seems reasonable in the single-end case. That being said, I'm sure there's a way to handle this efficiently, I'd just have to think about it a bit. Regarding your second question; Salmon learns the fragment length distribution in paired-end data, but not with single-end data. Single-end data can provide a little bit of information (e.g. there is in upper bound on fragment lengths that one can infer based on single-end reads based on how far they map from the end of the transcript), but not enough information to reliably infer a fragment length distribution. cc @mikelove in case he has any thoughts on this.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/83#issuecomment-243833424:1297,learn,learns,1297,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/83#issuecomment-243833424,2,['learn'],['learns']
Usability,"Hi Stephen,. So, the variation you see when you re-run salmon multiple times is _expected_ to be different (and _much_ smaller) than the variance you see when bootstrapping. Why is this? When you re-run salmon, the only variance you are seeing is due to small differences in the order of observations / updates from the streaming collapsed variational Bayes phase of the algorithm. This, in turn can have a _slight_ effect on the initialization conditions of the offline phase of the algorithm, and some of the parameters learned for the auxiliary parameters. However, in each run, you are observing _exactly_ the same set of reads and salmon is producing _exactly_ the same set of alignments; only the order and therefore some of the streaming updates change. So, we expect the final estimated abundances to be _very_ similar to each other. However, when salmon performs bootstrapping, it is actually resampling _with replacement_, from the counts of the range-factorized equivalence classes. Roughly, we expect this resampling to be similar to if we re-sampled _with replacement_ from the original set of input reads. That is, we are re-sampling from our population sample — the observed set of reads — to estimate the variance due to inference. So, for the bootstrap re-samplings, we expect significantly more variance than between subsequent runs of salmon, because the observations from which we are making the inference are actually changing. It is possible e.g. that some uniquely mapped reads may not be chosen in some bootstrap sample (since we are re-sampling the observed read count, but doing so _with replacement_), and so the estimates of sets of related isoforms will change in those samples. Thus, since the observations themselves are changing, we expect the estimates to display greater variance. In fact, this is the main goal of performing the bootstrapping (or Gibbs sampling) — to estimate the uncertainty due to inference if we had observed many reads coming from the same under",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/466#issuecomment-568828362:522,learn,learned,522,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/466#issuecomment-568828362,2,['learn'],['learned']
Usability,"Hi Warren,. I apologize for the short response --- I'm on my way to a meeting. I'm assuming that what was happening before was simply that the problem was diagnosed during VBEM as soon as it pops up, whereas, the NaNs are allowed to propagate during the standard EM. If I had to guess (and this is just a guess), I would blame edge effects in the FSPD for the appearance of `NaN`s (not sure why this goes away without bias correction though!). Also, were I to disable a feature, that (`--useFSPD`) would be the one I would choose to disable since it usually has a negligible effect. That being said, I would be **very** grateful if you were able to produce a dataset that exhibits this issue, as I'd like to fix this ASAP. My guess is that it's a rather small issue, but the problem is that NANs propagate quickly and without mercy!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/50#issuecomment-197891864:127,simpl,simply,127,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/50#issuecomment-197891864,2,['simpl'],['simply']
Usability,"Hi all (@Gaura / @gmarcais),. While this has languished somewhat as we try to figure out what regex engine to include and how best to package it, I wanted to mention that I am attempting something similar in rust (which has a canonical regex crate which, I believe, is supposed to be among the fast ones). That repo is over on [seq_geom_xform](https://github.com/COMBINE-lab/seq_geom_xform) and it relies on [seq_geom_parser](https://github.com/COMBINE-lab/seq_geom_parser). I like @Gaura's geometry string specification, so we're going with that for time time being. If you want to chime in or start a discussion on either of those repos, please do let me know if you have any other thoughts on this generalized scheme. The purpose of the `seq_geom_xform` crate is actually that it will be *both* a rust library (to allow parsing complex geometry descriptions as a regex and extract the relevant sequence) *and* a stand-alone executable that can do streaming sequence transformation from a ""complex"" barcode geometry (e.g. the sciseq3 above) to a ""simple"" geometry (fixed position and fixed length barcode and UMI). Thus, one could imagine (at the cost of sticking a rust executable in the invocation here) replacing this feature by a streaming invocation to `seq_geom_xform` that would take the compressed fastq files as input along with the geometry specification, and which would output two streams (one for each read) with a simplified geometry that could be parsed in the simpler format. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/734#issuecomment-1447552961:1049,simpl,simple,1049,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/734#issuecomment-1447552961,6,['simpl'],"['simple', 'simpler', 'simplified']"
Usability,"Hi guys,. Which existing dependencies would you like to be able to use? There are some of these libraries that cannot be replaced by already installed variants. Specifically,; - BWA --- since the version that is pulled in and used actually requires we expose certain functionality for our lightweight alignment procedure (though this dependency may go away all together if we deprecate lightweight alignment in favor of quasi-mapping).; - Jellyfish --- here, we require the ability to use jellyfish as a library. Specifically, we rely on some headers that are not installed with the standard package. Perhaps here there could be some synergy with Guillaume on making all of the things Salmon uses part of the standard Jellyfish install, but, at least currently, this isn't the case. The CMake build system already looks for existing versions of the following before fetching them:; - Boost; - tbb; - jemalloc. So, the the remaining guys are `libgff` (which is just some small libraryification of a gff parser that I put together a while ago, I don't know that it's in any package manager --- is it? It doesn't even have an associated install script) and `staden IO lib`. For Staden, I'd be happy to have it look for an existing installation, but there is no FindStaden.cmake that I know of, and I don't really know how to write FindX.cmake files appropriately. However, I'd be happy to learn and / or accept pull requests.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/19#issuecomment-193559957:1386,learn,learn,1386,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/19#issuecomment-193559957,2,['learn'],['learn']
Usability,"Hi vals,; Cutoffs for Salmon as well as STAR+featurecounts/RSEM are all >0, no matter it is normalized value (RPKM, TPM) or rawcount. To my knowledge, there shouldn't be a hugh difference between different pipeline in terms of number of detected genes. Somehow, I think Salmon is over-sensitive to some extent. It's good to know that there will be small >0 expression on most genes. That makes the thing clear~. Best!; Gary",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/120#issuecomment-279960488:404,clear,clear,404,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/120#issuecomment-279960488,2,['clear'],['clear']
Usability,"Hi! I'm really sorry for taking so long to get back to you; things have been quite hectic this semester. The reason it's not being show is because it's been placed in a parameter group that is not made visible by default; the `--posBias` option itself is still available. It's definitely still experimental in that it has not been tested nearly as thoroughly as the other bias models. However, it is useable. Once we have performed more testing, it will migrate into the normal options and be better documented. If you gather any useful data while using this flag, we'd love some feedback!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/191#issuecomment-367448963:580,feedback,feedback,580,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/191#issuecomment-367448963,2,['feedback'],['feedback']
Usability,"Hi,; Basically Alevin performs CB sequence correction within 1 distance hamming ball, the intuition being the set of real CB should ideally be more than 1 edit distance away.; Here I think the x axis gives you the count of reads for a CB before sequence correction and on y axis post sequence correction. Hope it helps",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/488#issuecomment-591733839:90,intuit,intuition,90,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/488#issuecomment-591733839,2,['intuit'],['intuition']
Usability,"Hi,; Thank you for the detailed explanation. ; For the first question, ideally you should include the alternate alleles. But they should be part of the transcriptome, instead of the genome. We expect the size of the decoys to double if alt alleles are included in the genome. This is because the decoys are simply regions of high sequence identity between a transcript and the genome. Hence, with alleles as part of the genome, each transcript will map almost equally well to alleles.; If you're running salmon in the alignment mode, the input bam/sam file should include the CIGAR string as well. There is a flag, `--noErrorModel`, to ignore the CIGAR but that is not recommended, since salmon uses the information for scoring the alignments. ; I hope that answers your concerns.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/371#issuecomment-501432106:307,simpl,simply,307,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/371#issuecomment-501432106,2,['simpl'],['simply']
Usability,"I actually didn't test it :). I'll confirm the current behavior tomorrow. Thanks for following up on this!. > On Jan 3, 2016, at 8:37 PM, Rob Patro notifications@github.com wrote:; > ; > Actually, @mdshw5 --- it's not quite clear to me why the parser isn't doing the right thing in this case. If you take a look at how the paired-end sequence parser is actually populating the internal buffer (e.g. here), it is reading one entry from stream1 and then one entry from stream2. I'm guessing there may be some issue with having two different handles open to the same fifo? However, that doesn't seem like it should be a problem. Given the way the code is actually reading from the different streams, it's not clear to me why it's not currently working as expected. I'll try and take a deeper look.; > ; > —; > Reply to this email directly or view it on GitHub.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/29#issuecomment-168566647:224,clear,clear,224,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/29#issuecomment-168566647,4,['clear'],['clear']
Usability,"I also wonder why salmon not output original reads counts. update:. Because it is more accurate. DeSeq2 should accept it. As for now, maybe we could simply round to the nearest integer. > NumReads — This is salmon’s estimate of the number of reads mapping to each transcript that was quantified. It is an “estimate” insofar as it is the expected number of reads that have originated from each transcript given the structure of the uniquely mapping and multi-mapping reads and the relative abundance estimates for each transcript.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/437#issuecomment-751189286:149,simpl,simply,149,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/437#issuecomment-751189286,2,['simpl'],['simply']
Usability,"I am not sure what this `-m` flag refers to. It is not currently an option, and doesn't appear to clearly have been one in the past either.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/678#issuecomment-1138623879:98,clear,clearly,98,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/678#issuecomment-1138623879,2,['clear'],['clearly']
Usability,"I am trying to quantify these data at the transcript level which is why the number of features is this big. For the PBMC3k I was trying with a transcript to gene --tgMap but was still seeing the same error. I realized I forgot to update the path to the run.sh script when calling the 0.12.0 binary (I updated the path to the binary but no to the script). When running the wrapper in the 0.12.0 folder I could succesfully run alevin on the CD14 dataset, with or without the --forceCells 4000 flag. I tried to run alevin-0.12.0 on the PBMC 3k dataset but I got the same error. I am now trying to run it on all the FACS-sorted samples and I will see how that goes. I feel this is happening slightly inconsistently (although very frequently). Notably, it either happens after `Clearing EqMap; Might take some time.` or `Starting Import of the gene count matrix of size 5344x167268.`. I have had it happen once in the middle of the `Analyzed xxx cells (yy% of all)` phase. I just managed to succesfully process the CD19+ B cells from the 10x v1 dataset, I'll attempt to process the other FACS sorted samples overnight and let you know how it went. Thank you",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/328#issuecomment-445109075:773,Clear,Clearing,773,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/328#issuecomment-445109075,1,['Clear'],['Clearing']
Usability,"I can try '^' and '$' after lunch. I didn't test any other library, since boost was already a pre-requisite for salmon and my focus was on getting it to work first. But now that it is done, other libraries can be tried. However, at this moment, I'm not clear about the effort and speed-up ratio.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/734#issuecomment-1013348732:253,clear,clear,253,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/734#issuecomment-1013348732,2,['clear'],['clear']
Usability,"I faced the same problem and found a simple solution. The trick is at line 585 of the cMakeList.txt. ""if (${TBB_VERSION} VERSION_GREATER_EQUAL 2018.0)"". It checks if you have tbb version 2018 or above. If you install tbb BEFORE running cmake, it will fulfill the requirement and bypass installing tbb in the make command, hence bypass the error. The solution:; 1. Delete the salmon folder and download a fresh one from github; 2. sudo apt update (this step is very important, to update the packages to be above version 2018) ; 3. sudo apt-get install libtbb-dev; 4. (Optional) apt-cache policy libtbb-dev (check the version of libtbb, it should be 2019 or above); 5. Then follows the standard installation (cmake, make etc.) The error should disappear and compile successfully. Thanks!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/497#issuecomment-610977958:37,simpl,simple,37,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/497#issuecomment-610977958,2,['simpl'],['simple']
Usability,"I have a similar problem.; Attached are:; 1. gtf file, where clearly, the gene_ id and transcript_id are provided; 2. quant files are as followed for gene and transcripts; 3. my command as followed:; ---. /gpfsdata/apps/salmon-latest_linux_x86_64/bin/salmon quant \; -i /gpfshome/hockchuan/SALMON/GCF_900626175.2_cs10_index \; -l ISR \; -1 /gpfsdata/JangiLab/hockchuan/170302/2.Trimmomatic_output/clean_HEADBANDSTEM_1.fastq.gz \; -2 /gpfsdata/JangiLab/hockchuan/170302/2.Trimmomatic_output/clean_HEADBANDSTEM_2.fastq.gz \; --seqBias \; --gcBias \; --posBias \; --incompatPrior 0.0 \; --geneMap /gpfsdata/JangiLab/hockchuan/cs10_reference_genome/GCF_900626175.2_cs10_genomic.gtf \; --recoverOrphans \; --allowDovetail \; --threads $NSLOTS \; --dumpEq \; --minScoreFraction 0.65 \; --writeMappings /gpfshome/hockchuan/SALMON/MAP/HEADBANDSTEM \; --fldMean 250 \; --fldSD 25 \; --writeOrphanLinks \; --writeUnmappedNames \; --quiet \; -o /gpfshome/hockchuan/SALMON/HEADBANDSTEM_quant; ---. [fewLines.gtf.txt](https://github.com/COMBINE-lab/salmon/files/5383013/fewLines.gtf.txt); [quant.genes.txt](https://github.com/COMBINE-lab/salmon/files/5382998/quant.genes.txt); [quant.txt](https://github.com/COMBINE-lab/salmon/files/5382999/quant.txt)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/569#issuecomment-708949661:61,clear,clearly,61,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/569#issuecomment-708949661,2,['clear'],['clearly']
Usability,"I have already run them all (successfully) separately as pairs, but for downstream analysis I need them to be a single library, so I thought it would be simpler to run them as multiple input files..?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/329#issuecomment-446212203:153,simpl,simpler,153,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/329#issuecomment-446212203,2,['simpl'],['simpler']
Usability,"I have couple of simple question on ""list of dir"" to supply part.; 1) DO i have to supply the complete path or just names of dir as a txt file?. I tried both and it does not work! But when i try one folder in the dir it works. salmon quantmerge --quants barcode01_quant -o all_barcodes_merged.txt; Version Info: This is the most recent version of salmon.; [2019-10-16 14:15:06.726] [mergeLog] [info] samples: [ barcode01_quant ]; [2019-10-16 14:15:06.726] [mergeLog] [info] sample names : [ barcode01_quant ]; [2019-10-16 14:15:06.726] [mergeLog] [info] output column : TPM; [2019-10-16 14:15:06.726] [mergeLog] [info] output file : all_barcodes_merged.txt; [2019-10-16 14:15:06.726] [mergeLog] [info] Parsing barcode01_quant/quant.sf. ###; When i try a list of all the folders. almon quantmerge --quants quant_dir_list.txt -o all_barcodes_merged.txt; Version Info: This is the most recent version of salmon.; [2019-10-16 14:15:54.698] [mergeLog] [info] samples: [ quant_dir_list.txt ]; [2019-10-16 14:15:54.698] [mergeLog] [info] sample names : [ quant_dir_list.txt ]; [2019-10-16 14:15:54.698] [mergeLog] [info] output column : TPM; [2019-10-16 14:15:54.698] [mergeLog] [info] output file : all_barcodes_merged.txt; [2019-10-16 14:15:54.698] [mergeLog] [critical] The sample directory quant_dir_list.txt either doesn't exist, or doesn't contain a quant.sf file. head quant_dir_list.txt; barcode01_quant; barcode02_quant; barcode03_quant; barcode04_quant; barcode05_quant; barcode06_quant; barcode07_quant; barcode08_quant. I have even tried with complete path to the dir and it fails. What am i doing wrong. Thanks",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/179#issuecomment-542828122:17,simpl,simple,17,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/179#issuecomment-542828122,2,['simpl'],['simple']
Usability,"I like the opt-in structure, I think in general keeping models simple by default is a good way of doing things. I know people just run programs without reading documentation and expect it to work perfectly. But I think somewhere, maybe even in the default quantification help, there should be a table or decision tree with information about how to choose options. E.g. > ""Did you do random hexamer priming? -> Use the --seqBias option.""",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/109#issuecomment-267003338:63,simpl,simple,63,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/109#issuecomment-267003338,2,['simpl'],['simple']
Usability,"I see. TopHat actually aligns the reads to the genome (using Bowtie and a strategy to perform split-read mapping). The results of TopHat, then, are meant to be used with tools like Cufflinks, which expects reads to be mapped directly to the genome rather than to the transcriptome. Salmon, on the other hand, works like tools such as RSEM / eXpress, which expect alignments to the transcriptome directly. This can be accomplished by either mapping the reads directly to the transcript sequences (using e.g. Bowtie2 / BWA-MEM) or by mapping the reads to the genome using a tool such as STAR, and telling it to project the alignments onto genomic coordinates. However, I should mention that the easiest thing to do is to simply have Salmon build and index on your transcript set and then pass it the raw (compressed) FASTQ files directly. Since Salmon provides an accurate and lightweight alignment proxy, it can accurately assess transcript abundance estimates directly from the raw (unaligned) sequenced reads. If you have questions about using either of these modes, please take a look at [the documentation](https://salmon.readthedocs.io/en/latest/). I'd also be happy to answer any other questions you might have.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/131#issuecomment-293273710:719,simpl,simply,719,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/131#issuecomment-293273710,2,['simpl'],['simply']
Usability,"I think we should sort out this issue step by step. If you say `libstaden` has an important bugfix we should upgrade to the latest version in any case. Do you have a link to this bug? I admit this update simply slipped through - we should have upgraded this in the beginning of this year. Usually we try to follow upstream closely (which we failed for salmon blatantly for several reasons - one is the close connection to pufferfish).; Regarding `pufferfish`: We tried hard to get `pufferfish` packaged but failed (due to the use of other versions of `spdlog`, `cereal`, and `fmt`) However, since we can't run `fetchPufferfish.sh` *inside the build process* I was running it separately and added the downloaded source in [debian/external/pufferfish](https://salsa.debian.org/med-team/salmon/-/tree/master/debian/external/pufferfish) So I think the requirement of salmon should be fulfilled. I confirm your feeling that pufferfish is important for the current issue.; However, in the test I did when opening this bug report I did not do that pre-downloading of pufferfish since I was building right in the downloaded source tarball. `libpufferfish-dev` was not installed by `apt build-dep salmon` since this package does not exist.; Kind regards, Andreas.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1464878371:204,simpl,simply,204,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1464878371,2,['simpl'],['simply']
Usability,I tried re-installing salmon today after seeing your message. A simple `conda install salmon` worked for me this time. I don't know why it was giving me an error back then and not one now though....,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/724#issuecomment-1137154359:64,simpl,simple,64,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/724#issuecomment-1137154359,2,['simpl'],['simple']
Usability,I will be trying your suggestion out. I might be able to share with you a toy dataset with a fewer number of guides. I will update you as soon as I get it.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-639618956:109,guid,guides,109,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-639618956,2,['guid'],['guides']
Usability,"I'll have to check if the ignoring of the `CPPFLAGS` is a problem with bwa's build system, or if I'm simply neglecting to pass the environment along properly.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/45#issuecomment-193960879:101,simpl,simply,101,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/45#issuecomment-193960879,2,['simpl'],['simply']
Usability,"I'm curious too if there is any specific feedback from the devs on whether using salmon on bacterial coding sequences is generally seen as appropriate or not? (sorry if this information is already available elsewhere, I've looked a bit and not seen it yet)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/350#issuecomment-582077473:41,feedback,feedback,41,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/350#issuecomment-582077473,2,['feedback'],['feedback']
Usability,"I'm going to cc @dpryan79 on this — does it just not finish? It seems to work within our GitHub CI, where we have to grab the prebuilt salmon to test `simpleaf`.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/895#issuecomment-1784122719:151,simpl,simpleaf,151,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/895#issuecomment-1784122719,2,['simpl'],['simpleaf']
Usability,"I'm in touch with the people administrating the cluster as well and based on their guidance I ran alevin with exclusive access, however that did not help.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/328#issuecomment-447403587:83,guid,guidance,83,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/328#issuecomment-447403587,2,['guid'],['guidance']
Usability,"I've run into this (or a similar) issue attempting to install Salmon on the UC Berkeley HPC cluster. Iconv was present within one of our Python installs, but that didn't seem to have the header files, so I installed libiconv/1.16 thinking this was a dependency issue. Unfortunately this didn't seem to help. Any guidance would be greatly appreciated. Here is my build script to the point of failure:; ```sh; #!/bin/sh ; MODULE_HOME=/clusterfs/vector/home/groups/software/sl-7.x86_64; PACKAGE_NAME=salmon; GITHUB_URL=https://api.github.com/repos/COMBINE-lab/salmon/releases/latest; VERSION=$(curl -s $GITHUB_URL | \; grep '""tag_name"":' | \; cut -d : -f 2,3 | \; tr -d \"",v | \; xargs); LATEST_RELEASE=$(curl -s $GITHUB_URL | \; grep '""tarball_url""' | \; cut -d : -f 2,3 | \; tr -d \"", | \; xargs); module load gcc/7.4.0 cmake/3.15.1 boost/1.70.0-gcc libiconv/1.16; export CC=`which gcc`; export CXX=`which c++`. cd $MODULE_HOME; mkdir -p source/$PACKAGE_NAME/$VERSION; INSTALL_DIR=$MODULE_HOME/modules/$PACKAGE_NAME/$VERSION; mkdir -p $INSTALL_DIR; mkdir -p modfiles/$PACKAGE_NAME. cd source/$PACKAGE_NAME/$VERSION; wget $LATEST_RELEASE -O - | tar -xz --strip-components 1; cmake -DBOOST_ROOT=/global/software/sl-7.x86_64/modules/gcc/7.4.0/boost/1.70.0-gcc -DCMAKE_INSTALL_PREFIX=$INSTALL_DIR; make; ```; And the tail of the output from make:. ```; creating: /clusterfs/vector/home/groups/software/sl-7.x86_64/source/salmon/1.5.1/scripts/../external/pufferfish-salmon-v1.5.1/tests/compile_tests/; inflating: /clusterfs/vector/home/groups/software/sl-7.x86_64/source/salmon/1.5.1/scripts/../external/pufferfish-salmon-v1.5.1/tests/compile_tests/int128_numeric_limits.cpp ; -- fetch PUFFERFISH exit code 0; -- Found ZLIB: /usr/lib64/libz.so (found version ""1.2.11"") ; -- Performing Test Iconv_IS_BUILT_IN; -- Performing Test Iconv_IS_BUILT_IN - Failed; CMake Error at /global/home/groups/consultsw/sl-7.x86_64/modules/cmake/3.15.1/share/cmake-3.15/Modules/FindPackageHandleStandardArgs.cmake:137 (message",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/453#issuecomment-862737315:312,guid,guidance,312,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/453#issuecomment-862737315,2,['guid'],['guidance']
Usability,"If you can already use DESeq2, then using tximport should not make it any harder at all. Given the tximport data, getting it into DESeq2 is as easy as. ```; dds <- DESeqDataSetFromTximport(txi, sampleTable, ~condition); ```. as shown in the [tximport vignette](https://bioconductor.org/packages/release/bioc/vignettes/tximport/inst/doc/tximport.html#Introduction). . Regarding outputting ""original read counts""; salmon *does* output the estimates for the number of reads deriving from each transcript. If the question is, why is this number not an integer, that's because the best estimate (the maximum likelihood estimate) is often not integral. Tools that simply count reads (e.g. HTSeq) produce integer counts, but these are in no way ""original read counts"" for the corresponding genes, and are usually less accurate (farther from the true number of fragments deriving from a transcript / gene) than the estimates produced by salmon. The fact that the best estimate is often not an integer is a direct result of the fact one is considering a statistical model and taking expectations.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/437#issuecomment-751190682:658,simpl,simply,658,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/437#issuecomment-751190682,2,['simpl'],['simply']
Usability,"In this case, it is likely treating the left and right reads as orphans when mapping. Therefore, you're losing basically all of the benefit of having paired-end reads (which can be considerable) and also increasing the probability of spurious mapping (orphans generally map much more ambiguously than properly paired reads). Since you have the paired-end files, you should try to repair them (using something like BBMap's [re-pair tool](https://jgi.doe.gov/data-and-tools/software-tools/bbtools/bb-tools-user-guide/repair-guide/)) to get back properly-paired FASTQ files for analysis. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/793#issuecomment-1220164752:509,guid,guide,509,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/793#issuecomment-1220164752,4,['guid'],['guide']
Usability,"Just a heads up, issue #266 has been added and the solution is currently available in the source build from the develop branch. We will include this to master with the next planned release of Salmon v0.11.3. Thanks again for the useful feedbacks and comments.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/253#issuecomment-412352411:236,feedback,feedbacks,236,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/253#issuecomment-412352411,2,['feedback'],['feedbacks']
Usability,"Just an idea. Would it be possible to assign an environment variable, such as SALMON_NO_VERSION_CHECK, whose existence overrides version checking? This wouldn't break compatibility with older scripts because they wouldn't have the variable in the first place. In non-networked nodes, an admin can simply set this variable and users will run salmon as usual.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/486#issuecomment-617326919:297,simpl,simply,297,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/486#issuecomment-617326919,2,['simpl'],['simply']
Usability,"Just in case it helps, I've written a script to splice out cell barcode linker sequences and shift them to before the polyA. In the process of doing this, it also does a 2-distance hamming correction of cell barcode and linker regions. All operations assume there are no INDELs:. https://gitlab.com/gringer/bioinfscripts/-/blob/master/synthSquish.pl. [usual disclaimers apply: I cannot guarantee that this works; use at your own risk]. This script could be used as a stop-gap measure to pre-process Rhapsody reads for use with Alevin via the undocumented custom length settings [--end 5, --barcodeLength 27, --umiLength 8]",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/628#issuecomment-776417938:542,undo,undocumented,542,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/628#issuecomment-776417938,2,['undo'],['undocumented']
Usability,"Lemme work with the reads you forwarded, is it possible to share the guide sequence as well ? Otherwise I won't be able to check the mapping rate.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-639204641:69,guid,guide,69,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-639204641,2,['guid'],['guide']
Usability,"No, that shouldn't cause a problem. When I ran your command (including the `ISF` and placing the `--libType` after the set of reads), my run still completed successfully (and didn't produce any warnings during Gibbs sampling). Salmon's behavior when running in unstranded mode on stranded data is simply to map the reads in the orientation they match, and to report on the console (and in the log) that there was a mapping bias (i.e. that the data look stranded). Specifically, here is what I get when I run (a close approximation of) your command. ```; $salmon quant --index Salmon_index_hg38.analysisSet_knownGene --unmatedReads SRR2454059.fq.gz --libType ISF --useVBOpt --output test_quant --; numGibbsSamples 100 --threads 16; Version Info: This is the most recent **development version** of Salmon.; ### salmon (mapping-based) v0.7.3; ### [ program ] => salmon; ### [ command ] => quant; ### [ index ] => { Salmon_index_hg38.analysisSet_knownGene }; ### [ unmatedReads ] => { SRR2454059.fq.gz }; ### [ libType ] => { ISF }; ### [ useVBOpt ] => { }; ### [ output ] => { test_quant }; ### [ numGibbsSamples ] => { 100 }; ### [ threads ] => { 16 }; Logs will be written to test_quant/logs; [2016-12-13 22:38:54.413] [jointLog] [info] parsing read library format; [2016-12-13 22:38:54.413] [jointLog] [info] There is 1 library.; [2016-12-13 22:38:56.240] [stderrLog] [info] Loading Suffix Array; [2016-12-13 22:38:56.240] [jointLog] [info] Loading Quasi index; [2016-12-13 22:38:56.240] [jointLog] [info] Loading 32-bit quasi index; [2016-12-13 22:39:01.268] [stderrLog] [info] Loading Transcript Info; [2016-12-13 22:39:02.630] [stderrLog] [info] Loading Rank-Select Bit Array; [2016-12-13 22:39:03.041] [stderrLog] [info] There were 182608 set bits in the bit array; [2016-12-13 22:39:03.159] [stderrLog] [info] Computing transcript lengths; [2016-12-13 22:39:03.160] [stderrLog] [info] Waiting to finish loading hash; [2016-12-13 22:39:07.653] [stderrLog] [info] Done loading index; [2016-12-13 22",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-266934878:297,simpl,simply,297,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-266934878,2,['simpl'],['simply']
Usability,"Nope; nothing special. Once you've installed conda, you simply do:. ```; $ conda config --add channels conda-forge; $ conda config --add channels bioconda; $ conda create -n salmon salmon=0.10.1; ```. then it will give you instructions on how to activate the environment to run salmon.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/232#issuecomment-394755128:56,simpl,simply,56,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/232#issuecomment-394755128,2,['simpl'],['simply']
Usability,"Oh wow 14k v 126k is indeed a big difference, is it possible to share the Alevin log for your run ? From the logs you attached it's not clear what's the mapping rate. May I also ask to look at another log file inside the logs folder, called salmon_quant.log. that would have more information regarding the mapping rate.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-639161938:136,clear,clear,136,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-639161938,2,['clear'],['clear']
Usability,"Ok @DarwinAwardWinner, I think it's fixed for real this time. The issue was stemming from an uninitialized prior value in the Gibbs sampler under VBOpt mode (the initialization code was updated on the develop branch, which is where the bug was introduced). This, in turn, was leading to `nan` being passed as the alpha parameter of `std::gamma_distribution`. With the `-Ofast` optimization flags, at least, this leads `std::gamma_distribution()` to hang forever in an infinite loop. Clearly, `nan` should not be passed to `std::gamma_distribution()`, but I'd argue the behavior of looping forever here is not great. Anyway, I fixed the initialization bug, so that this nan should never pop up. Just to be safe, I also changed the default optimization flag to `-O3` so that at least `nan` and `inf` can be properly tested. Since the TBB code and the parallel sampling weren't causing the issue, I've added them back in. Could you please test the latest push (40584e62859fb65463188b50d132c1eb622b21f0) and verify that this resolves the issue for you (*hopefully*!)?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267877253:483,Clear,Clearly,483,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267877253,1,['Clear'],['Clearly']
Usability,"Ok all; another update. The issue I raise above still exists (differences between calls to `ksw_extz` and `ksw_extz2sse`). *However*, I think that what is happening in this case is actually explained more simply. That is, the positions being reported by salmon are _correct_ given the optimal alignment. Specifically, salmon is performing an end-to-end alignment of the read, and the optimal alignment here includes an indel of length 3 in the initial portion of the read. If we were outputting the CIGAR string along with the position, then the bases would line up because the ""off by 3"" issue that happens above for the reads would be addressed when walking the CIGAR. However, we don't (currently) output the CIGAR — rather, we output a decoy CIGAR that does not represent the optimal alignment as computed by ksw2. So, if we assume all matches / mismatches (an indel-free prefix for this read), then we see the position shift noted in the initial bug report. I think the easiest solution, for the time being at least, is to report the position as if the prefix before the first MEM is indel free under the optimal alignment (even if it is not and the optimal score reflects that). However, if there are other suggestions for the best way to address this, I'm open to those as well.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/475#issuecomment-574719940:205,simpl,simply,205,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/475#issuecomment-574719940,2,['simpl'],['simply']
Usability,"Ok, I figured it out :) — these two *decoy* references are (1) identical with each other and (2) collide with *another* decoy reference. Currently, the way we process decoys, we don't allow duplicate decoys (it makes even less sense to allow duplicate decoys than to allow duplicate transcripts). However, the reason indexing worked with `k=17` is not because of `k` but because of the `--keepDuplicates` flag. With that flag, these decoys get added. I think the right thing for us to do on our part is to remove duplicate *decoys* if they appear in the reference and the user has not passed `--keepDuplicates`. . However, for the time being, I think the best thing to do is simply to remove `AABR07022993.1` and `AABR07023006.1` from the `toplevel` file and from `decoys.txt`, since the sequence they contain is already represented in the decoy part of the index. This will represent a full and comprehensive SAF index. I'm pinging @k3yavi to see if he has any good idea about the easiest way to cull these duplicate refs from the input files.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/505#issuecomment-613480649:675,simpl,simply,675,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/505#issuecomment-613480649,2,['simpl'],['simply']
Usability,"Okay my alevin run finished, and I got a mapping rate of just 6.1% and 2254 cells detected. My `lib_format_counts.json` contains the following:. ```; {; ""read_files"": ""[ SRR10174292_2.fastq.gz, SRR10174292_1.fastq.gz]"",; ""expected_format"": ""ISR"",; ""compatible_fragment_ratio"": 1.0,; ""num_compatible_fragments"": 15259749,; ""num_assigned_fragments"": 15259749,; ""num_frags_with_concordant_consistent_mappings"": 0,; ""num_frags_with_inconsistent_or_orphan_mappings"": 61866895,; ""strand_mapping_bias"": 0.0,; ""MSF"": 0,; ""OSF"": 0,; ""ISF"": 0,; ""MSR"": 0,; ""OSR"": 0,; ""ISR"": 0,; ""SF"": 0,; ""SR"": 0,; ""MU"": 0,; ""OU"": 0,; ""IU"": 0,; ""U"": 0; }; ```. so lots of fragments are discarded for one reason or another, and it's not clear whether the library type assignment is working properly, sort of like my initial example above. Separately, I'm running zUMIs on the same files and will report back with those data when the run is complete",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-985038970:709,clear,clear,709,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-985038970,2,['clear'],['clear']
Usability,"Okay, thanks @k3yavi. Just to be clear- you're saying I should derive the whitelist from the filtered_cb_frequency rather than the raw? This is a much smaller file in the case of the bad data above (more so than I'd expect from the cb correction, 984), so I was afraid it had already been subjected to knee detection. I also note that it's also not in fact sorted by default.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/362#issuecomment-490914214:33,clear,clear,33,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/362#issuecomment-490914214,2,['clear'],['clear']
Usability,"On Sun, Nov 01, 2015 at 06:15:19AM -0800, Rob Patro wrote:. > I, too, would like to see the relative performance of the two libraries. The only challenge is in making the comparison apples-to-apples (i.e. enabling multi-threaded parsing in seqtk with minimal overhead ??? a concurrent queue is cheap, but not free). . Other points worth considering:; - there's a runtime overhead to constantly changing sequencing formats. Some; programs want split, others want interleaved. We've settled on interleaved; because it enables streaming, which is a major win (2-4x performance); and; also because having one file is better than having 2 or 4.; - the management overhead to keeping track of many files is less for experts,; but is pretty significant for beginners. Enabling multiple input formats ++. So I think it'd be great to have the basic functionality, identify where; there are performance problems, and then simply note them for future ;). I would like to enable -1 and -2 in khmer scripts, but for our usual use cases; (multiple sequencing files being normalized and/or partitioned and/or error; trimmed) the command line syntax is too confusing ATM.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/29#issuecomment-152829225:912,simpl,simply,912,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/29#issuecomment-152829225,2,['simpl'],['simply']
Usability,"Pinging @mikelove, who is certainly the person to give the best answer here. One clear difference to note though is that TPM is a length-normalized measure, while CPM is not. This alone means they will exhibit nontrivial differences.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/812#issuecomment-1323774035:81,clear,clear,81,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/812#issuecomment-1323774035,2,['clear'],['clear']
Usability,"Rob,. Brilliant - I forgot that I built the boost libraries from whatever version of gcc was on the standard distribution. I have included -DFETCH_BOOST=TRUE, do you know why I am receiving the following error regarding a missing when executing make?. [ 5%] Performing configure step for 'libboost'; Building Boost.Build engine with toolset gcc... tools/build/src/engine/bin.linuxx86_64/b2; Detecting Python version... 2.7; Detecting Python root... /usr; Unicode/ICU support for Boost.Regex?... not found.; Generating Boost.Build configuration in project-config.jam... Bootstrapping is done. To build, run:. ./b2. To adjust configuration, edit 'project-config.jam'.; Further information:. - Command line help:; ./b2 --help. - Getting started guide:; http://www.boost.org/more/getting_started/unix-variants.html. - Boost.Build documentation:; http://www.boost.org/build/doc/html/index.html. using gcc : : /opt/gcc-8.2.0/bin/g++ ); [ 6%] Performing build step for 'libboost'; opt.jam: No such file or directory; /opt/salmon/external/boost_1_66_0/tools/build/src/build/toolset.jam:43: in toolset.using; ERROR: rule ""opt.init"" unknown in module ""toolset"".; /opt/salmon/external/boost_1_66_0/tools/build/src/build-system.jam:461: in process-explicit-toolset-requests; /opt/salmon/external/boost_1_66_0/tools/build/src/build-system.jam:527: in load; /opt/salmon/external/boost_1_66_0/tools/build/src/kernel/modules.jam:295: in import; /opt/salmon/external/boost_1_66_0/tools/build/src/kernel/bootstrap.jam:139: in boost-build; /opt/salmon/external/boost_1_66_0/boost-build.jam:17: in module scope; make[2]: *** [libboost-prefix/src/libboost-stamp/libboost-build] Error 1; make[1]: *** [CMakeFiles/libboost.dir/all] Error 2; make: *** [all] Error 2. Thanks for all your help!. Nate",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/309#issuecomment-436834099:742,guid,guide,742,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/309#issuecomment-436834099,2,['guid'],['guide']
Usability,"Seems to work on some of the test at my end, let me know if its still a problem. The command to use would be; ```; salmon alevin -l ISR --citeseq --barcodeLength 16 --umiLength 10 --end 5 --featureStart 19 --featureLength 21; ```. One thing to note, since it's a 5' protocol, you might have to change `-lISR` to `-lISF` since the 5` protocol expects the single-cell reads from the forward strand, unlike 3' where we expect the reads from reverse. It should not be a problem for the guide/feature barcodes though.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-638444905:482,guid,guide,482,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-638444905,2,['guid'],['guide']
Usability,"Side note: does Salmon learn the fragment length distribution from the data, using the user-provided values as a starting point? Is it even possible to do this for stranded single-end data? (I know it's possible for unstranded single-end.)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/83#issuecomment-243813359:23,learn,learn,23,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/83#issuecomment-243813359,2,['learn'],['learn']
Usability,"So I got the data and am trying to repro the issue now (thanks!). Quick question. I noticed in your example command you have `--libType ISF`. However, you have single-end reads, so the appropriate library type would be `SF` (i.e., they can't be ""inward"" facing reads, b/c there is no mate for each read). When I run your command as is, but replace `ISF` as `SF`, my run completes successfully, and I don't get any `errorminEQClassWeight` output. Could you let me know if this makes any difference for you (also, sorry that, apparently, we're not outputting a useful error message when one passes in a paired-end library type with single-end data). edit: Actually, it's even stranger. I noticed that in your command the library type comes *after* the reads to which it refers, but in this case, Salmon will not apply that library type to those reads (which explains why you're not getting a warning message). The restriction that the `--libType` flag comes before the reads it describes is buried in [the docs](http://salmon.readthedocs.io/en/latest/salmon.html#using-salmon), but I definitely need to make that clearer. Anyway, the point is that, in this case, Salmon should apply the ""default"" single-end library type (i.e., `U`) to your reads. So, presumably, that was what was happening when you saw the strange behavior during Gibbs sampling (and is also what was happening when my Gibbs sampling run completed successfully).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-266927204:1111,clear,clearer,1111,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-266927204,2,['clear'],['clearer']
Usability,"So, it turns out that with the dependency setup that is pulled in, I can't even get `salmon` to build without `USE_SHARED=TRUE`. I think at this point, it's not clear the segfault is due to something that is broken / can be fixed in the salmon code itself. Rather, it's likely due to a misversioning of a dependency that is pulled in and then linked against. For the time being, I think the options are to do a more ""standard"" build (i.e. like the first one I suggested that pull in only that minimal set of dependencies and let salmon itself statically link the rest), or to try and look at the upstream shared libraries being linked and figure out which of them is misversioned. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1464124885:161,clear,clear,161,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1464124885,2,['clear'],['clear']
Usability,"Sorry if I wasn't clear. Also, maybe I am trying to bluntly transpose a; metric that comes from alignment-based quantification. Yes, sequencing; saturation relies on UMI, using the transcript reads associated to the UMIs. I am not sure to understand the difference between resolving ambiguity; or collision at the transcript level, with the evaluation of sequencing; saturation in mind. To be more precise, I am not sure to see how it; could be a problem in this computation. But I am probably missing an; important point?. The idea of quasi-mapping as I understand is identifying the transcripts; from which the reads could have originated, generating a quantification.; For the sequencing saturation, we don't really need to know where the; read align on the transcript sequence, we just want to know that the; read comes from one single transcript, a unique UMI. So if I am right,; it is possible to summarize this quantification at the level of UMIs,; and have an idea of the duplication level of the transcripts that have; been tagged with UMIs. From what I understand, this is where alevin; perform the deduplication computation to have a correct idea of the; transcript amount when UMI are added, prior amplifications resulting; from the RT/PCR steps. So I was imagining it could be possible to take the gene quantifications; from (de)duplicated UMIs, gene quantifications from unique UMIs, using; them to have an idea of the amount/ratio of redundant information in the; sequencing data, producing a metric very similar to the seq sat from the; 10x definition.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/267#issuecomment-414331344:18,clear,clear,18,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/267#issuecomment-414331344,2,['clear'],['clear']
Usability,"Sorry if I wasn't clear. I did try with and without the --chromium; option, with the same error. I just have try the exact command you provided (including the --chromium; flag), with option in the same order. The command log is then:; ### salmon (single-cell-based) v0.11.1; ### [ program ] => salmon; ### [ command ] => alevin; ### [ threads ] => { 10 }; ### [ libType ] => { ISR }; ### [ chromium ] => { }; ### [ mates1 ] => {; /path/to/downloads/10xPBMC/pbmc4k_S1_L001_R1_001.fastq.gz }; ### [ mates2 ] => {; /path/to/downloads/10xPBMC/pbmc4k_S1_L001_R2_001.fastq.gz }; ### [ index ] => { /path/to/salmonIndex }; ### [ output ] => { alevin_output }; ### [ tgMap ] => { tx2gene.tsv }. Now it seems to work. I'll tell you if the whole alignment is; successfull when it will end. Note that when I use the --chromium flag earlier in the command, ie:. salmon --no-version-check --chromium alevin -p 10 -lISR -1 [...]. The log contains:; ### salmon (single-cell-based) v0.11.1; ### [ program ] => salmon; ### [ command ] => alevin; ### [ ] => { alevin }; ### [ threads ] => { 10 }; ### [ libType ] => { ISR }",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/264#issuecomment-410331030:18,clear,clear,18,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/264#issuecomment-410331030,2,['clear'],['clear']
Usability,"Sounds good, just wanted to give you the heads up, as we are working on some other part of the salmon pipeline, currently I can't give you an ETA when would the new version of salmon be available. If For the time being the choice are either you can compile the develop branch of salmon or I can forward you a linux usable salmon binary.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/416#issuecomment-523090214:315,usab,usable,315,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/416#issuecomment-523090214,2,['usab'],['usable']
Usability,"Thank you @rached-97, for the incredibly thorough follow-up to the original issue. I agree that the work you put into not only reporting the issue thoroughly to begin with, but following up with your findings, will certainly help others who might encounter related issues in the future. Since salmon seems not to be at fault here, I'll close the issue. I do recommend taking this over to the bioconductor forums, where the community is _incredibly_ responsive; I imagine you'll have a resolution in no time. Thanks again for the excellent report and follow-up!. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/655#issuecomment-826117612:449,responsiv,responsive,449,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/655#issuecomment-826117612,2,['responsiv'],['responsive']
Usability,"Thank you for the clear and thorough explanation, @rob-p . Now I understand exactly why this is happening. I like your idea for the “throw-away” run for Salmon, and the short example command you sketched out is exactly what I had said in mind as I read your words. Reworking the core Salmon algorithm to do some gymnastics with re-processing the first 10,000 reads would not be elegant or worth your time. I think the workaround you proposed is a perfectly good solution. If in the long run many other people find this useful, perhaps an easier fix would be to make a new command in Salmon that just bails after the first 10k reads automatically and returns the detected library orientation upon termination of the command; e.g. in Bash:. `mylibtype=$(salmon quant —getLibType -r reads.fq.gz)`; `salmon quant —libType $mylibtype -r reads.fq.gz`. Thank you for the great software and for being so attentive to detail and our questions.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/489#issuecomment-738896890:18,clear,clear,18,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/489#issuecomment-738896890,2,['clear'],['clear']
Usability,"Thank you for the swift answer!. We are working with [BD Rhapsody](https://www.bdbiosciences.com/en-us/instruments/research-instruments/single-cell-multiomics/single-cell-analysis-system), which uses a complex barcode structure (you can read about this in their [bioinformatics handbook](https://www.bd.com/documents/guides/user-guides/GMX_BD-Rhapsody-genomics-informatics_UG_EN.pdf) on page 14). The extracted, combined CB is 27bp long, which is why the default sanity check was too low for our purposes. In terms of cell numbers, BD Rhapsody appears to generate a lot of ""false-positive cells"", actually (we are seeing up to 90% of false positives). This is expected, and also mentioned in their bioinformatics handbook (pages 23-25), but appears to be an issue for the alevin cell detection: with standard settings this is approximately two orders of magnitude lower than expected, `--expectCells` improves matters drastically, however. We have opted for removing the false positives in post-processing ourselves - the low count depth population is very easily identifiable. In terms of performance, a complete alevin run on 150M reads (25k expected cells) takes around 1.5 hours using 10 threads, which is perfectly reasonable for us.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/445#issuecomment-551083490:317,guid,guides,317,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/445#issuecomment-551083490,4,['guid'],['guides']
Usability,"Thank you for verifying @zhangchipku, and thank you very much for the kind words! We appreciate the feedback and input from our users like yourself. We'll prioritize the soft-clipping functionality for upcoming releases (maybe even the next if we can make that work in time). For the time being, I can recommend `fastp` as a fairly efficient / fast trimmer that. It might even be able to work in a streaming fashion so that you could pipe the trimmed reads directly to salmon.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-586548443:100,feedback,feedback,100,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-586548443,2,['feedback'],['feedback']
Usability,"Thank you, well I do have valid pairs and remaining singletons in different files, it just was not clear one cannot use a file with interleaved reads. Of course I dropped the file (as an intermediate from the disk as I hoped to keep only the combined, interleaved file with pairs). So I re-created it. BTW, I can recommend `reformat.sh` from https://sourceforge.net/projects/bbmap/ bundle, it is a nice tool to split/reorder/merge FASTQ files. I infer you suggest people to use only pairs and forget the singletons, right? Or, could combine the results of two executions somehow together ...? Maybe not worth the efforts? I have quite a few singleton reads in addition to valid pairs, though.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/240#issuecomment-400057894:99,clear,clear,99,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/240#issuecomment-400057894,2,['clear'],['clear']
Usability,"Thanks @Munfred for sharing the file. I'll take a look into this. re> whitelist; I should have been more clear about this. I didn't mean to say the full 737k CB, what I meant was using the actual whitelisted CB by cellranger, which are as you say was 300. Usually they are stored in a folder with name `filtered_gene_bc_matrices`, Although you might have to remove `-1` from their name since cellranger adds it to specify the sample index.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/245#issuecomment-402571397:105,clear,clear,105,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/245#issuecomment-402571397,2,['clear'],['clear']
Usability,"Thanks @Ryan-Zhu ,. A couple of thoughts.; To me the data seem a little noisy as a lot of CB/reads are thrown away due to ""knee"" thresholding.; Check https://github.com/COMBINE-lab/salmon/issues/362 if you wanna play with how to customize alevin for user-define whitelisting. Having said that this is how you can parse the data from alevin.; Alevin use 1277 CB after its knee thresholding + 638 low confidence Barcode for downstream whitelisting = total 1915 CBs.; If you check the warning in the log it says :. ```; [2019-06-12 15:07:08.152] [alevinLog] [warning] Skipped 313 barcodes due to No mapped read; ```; Basically it means out of 1915, 313 didn't had any read mapped to them, so alevin doesn't report them in the output matrix. Alevin reports 1915 - 313 = 1602 CBs both in `.mtx` and `quants_mat.gz` file. You can check the order of the CB in the `quants_mat_rows.txt` file, which has 1602 rows/CBs. If you don't provide alevin with external whitelist alevin tries to do post whitelisting of it's own. Basically out of the 1277 high confidence CBs alevin initially find out through knee it assigns 647 CBs as final whitelisted CB as found in the `whitelist.txt` file. If you wan't to subsample these CBs you have to extract the information from the `.mtx` or `quants_mat.gz` file. You can check a simple python parse of the `quants_mat.gz` file [here](https://github.com/k3yavi/vpolo/blob/master/vpolo/alevin/parser.py#L187-L230).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/374#issuecomment-501846672:1307,simpl,simple,1307,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/374#issuecomment-501846672,2,['simpl'],['simple']
Usability,"Thanks @Ryan-Zhu for your feedbacks and the suggestion.; I apologize for the trouble you had to face while working with the alevin output.; We will prepare better from the next release and try updating the external dependencies first before making an official release. ; Just wanted to give you the heads up that I have also updated the bug for the scientific notation in the `mtx` format. It's in the develop branch of alevin, if you have time please let me know if it works for you. Thanks again.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/380#issuecomment-502828416:26,feedback,feedbacks,26,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/380#issuecomment-502828416,2,['feedback'],['feedbacks']
Usability,"Thanks @k3yavi !If you can forward me a Linux portable binary that would be great. Whenever I try to compile something on my computer, I fail half of the time . I have Ubuntu 18.04. I will ask permission to share with you part of the data and get back to you. Also, does Alevin use 10x cell barcode whitelist internally to correct barcodes? And do you recommend using the `--naiveEqclass`; option when there are only 64 guide sequences as features?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-638487530:420,guid,guide,420,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-638487530,2,['guid'],['guide']
Usability,"Thanks @k3yavi for the clarification. In my example case the files are not cell disjoint, being multiple lanes run from the same library. Obviously I can use just one lane for the training, but to be clear: in the real world in this situation all files for a library need to be run together, right?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/434#issuecomment-540400660:200,clear,clear,200,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/434#issuecomment-540400660,2,['clear'],['clear']
Usability,"Thanks @rfarouni for the updates. > With --minScoreFraction 0.607 I get a way much better mapping rate. I wonder if there is way to determine the optimal value empirically?. Glad to hear that, may I ask what percent of the reads are mapping now ? It's not clear from the alevin logs you shared but I think the total number of deduplicated UMIs are similar to your baseline experiment. I think defining an optimal empirical threshold is a great idea but the issue is that 21 length barcodes are kind of in the middle i.e. a tad longer than the regular barcodes and somewhat smaller than a full read. The full read alignment process indeed allows more erroneous reads to map but 21 is a bit too short to work with. @rob-p might have more thoughts on this one. > But now there are a lot of barcodes that are not in the whitelist. Thanks again for checking this, it is indeed concerning. However, as I was mentioning earlier in a regular single-cell experiment we end up throwing away almost all of these very low frequency count cellular barcodes. I'd say even 45 reads CBs are most probably a noise and will be filtered away, because only a fraction of the reads will map and after deduplication it'll result in significantly low count in 1 cellular barcode. > Also with the default setting of --freqThreshold, no CB correction gets done. I can check why is this happening, let me know once you have a toy dataset to play with.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-640093397:256,clear,clear,256,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-640093397,2,['clear'],['clear']
Usability,"Thanks @rob-p I am glad you and others have found it useful. The actual bbmap.sh and bbduk.sh commands for SE data are in the links to Phil Ewels' multiqc GH. . Just like salmon indexing kmer size choice, one can tinker with the **_```k, hdist, minq and other parameters```_** of bbduk depending on how good/bad the data is. Needless to state, bbduk is the swiss-army-knife for sequence reads quality assessment with whole range of parameters to tweak . https://jgi.doe.gov/data-and-tools/bbtools/bb-tools-user-guide/bbduk-guide/ suggests; ![image](https://user-images.githubusercontent.com/8467214/78302368-a3695980-7508-11ea-990d-4b6e008e3f07.png)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-608105756:511,guid,guide,511,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-608105756,4,['guid'],['guide']
Usability,"Thanks @tamuanand for the (as always) detailed and clear question! Since this directly involves `tximport` and `DESeq2` downstream, let me also ping @mikelove here.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/581#issuecomment-719143923:51,clear,clear,51,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/581#issuecomment-719143923,2,['clear'],['clear']
Usability,"Thanks Rob!; For both providing the binary download again, and pointing me to MultiQC (meanwhile got a informative QC report). :); Guido",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/252#issuecomment-405540123:131,Guid,Guido,131,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/252#issuecomment-405540123,1,['Guid'],['Guido']
Usability,"Thanks Rob. I am using alevin with libType of ISR. When I looked at the SAM file after setting the writeMapping option, I observed that ~1% had the ""reverse alignment"" flag set to 1 (the only flags field that had this flag set was 341, all the rest had that bit set to 0). It's not clear to me whether alevin uses those reads for UMI counting, and if so, what's the best way to turn off this behavior.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/749#issuecomment-1038381121:282,clear,clear,282,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/749#issuecomment-1038381121,2,['clear'],['clear']
Usability,"Thanks a lot @rob-p and @k3yavi .; I wanted your advise on something more intricate. Asking since you people are the pioneers in this aspect of problem solving.; I have to determine the expression of GFP and Transposon sequence in the transcriptome.; I read the material posted on the link https://salmon.readthedocs.io/en/latest/salmon.html.; It instructs this to be done in 2 different ways-; There are two options for generating a decoy-aware transcriptome:. The first is to compute a set of decoy sequences by mapping the annotated transcripts you wish to index against a hard-masked version of the organism’s genome. This can be done with e.g. MashMap2, and we provide some simple scripts to greatly simplify this whole process. Specifically, you can use the generateDecoyTranscriptome.sh script, whose instructions you can find in this README. The second is to use the entire genome of the organism as the decoy sequence. This can be done by concatenating the genome to the end of the transcriptome you want to index and populating the decoys.txt file with the chromosome names. Detailed instructions on how to prepare this type of decoy sequence is available here. This scheme provides a more comprehensive set of decoys, but, obviously, requires considerably more memory to build the index. I tried the 2nd approach. Combined the GFP,Transposon and the genome FASTA files, indexed it , constructed the decoy according to the given instructions given here https://combine-lab.github.io/alevin-tutorial/2019/selective-alignment/.; When I ran Salmon (version 1.2.1_linux_x86_64) it did not report anything in the quant files (I know that these samples have high GFP and Transposon expression in these samples). The 1st approach is giving me problems to the construction of the GTF file and then memory usage. The instructions say - generateDecoyTranscriptome.sh — Located in the scripts/ directory, this is a preprocessing script for creating augmented hybrid fasta file for salmon index. It cons",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/737#issuecomment-1022416973:679,simpl,simple,679,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/737#issuecomment-1022416973,4,['simpl'],"['simple', 'simplify']"
Usability,"Thanks for the feedback!. I tried playing with the vbPrior setting and observed that, as you noted, higher increases of the vbPrior tended to flatten out the read apportionment, such that as the vbPrior increased the two transcripts became increasingly similar in their final expression (presumably they would eventually hit 50/50). It's good to know how that settings affects my data, but this is not quite what I was hoping for... . Ideally, the short transcript would get nearly *all* of the reads, rather than splitting the reads 50/50 or, with the default settings, giving nearly all the reads to the longer transcript. I realized that, as a human, the reason the short transcript is obviously the dominant one is how the reads pileup in the alignment. There are hundreds of reads mapping to both transcripts, but NO reads map to the 5' of the long transcript. As I understand the selective alignment, the alignment scores are passed to the quantification step, but the *position* of the reads is not used downstream. In order to pass my human intuition along here, the software would need to pay attention to the coverage bias of the reads mapping to the transcripts and assign a penalty when two otherwise identical transcripts have a different coverage variance across the transcript. This sounds like what the --posBias flag should incorporate into the effective lengths, but it doesn't have much effect on these transcripts for me (FYI, I am getting a segfault when I run only --posBias in the current salmon version, but if I run all the models together like --gcBias --seqBias --posBias, it completes fine). . Also, my intuition for these transcripts is not really a coverage ""bias"" as much as the read depth absolutely plummeting at the 5' end of the long transcript. It would be neat if Salmon could detect these kinds of dramatic dropoffs and add a warning or something... even if not incorporating the information into the quants... it could even be a good QC step to identify large de",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-623043651:15,feedback,feedback,15,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-623043651,2,['feedback'],['feedback']
Usability,"Thanks for the quick reply. Do you have a place you could share the contents of `outputs/hs.grch39.index`? It seems to me that the index is clearly not being fully constructed, but it would be ideal to compare this with an index that I know is correct and look for specific differences. Thanks,; Rob. P.s. any details about your specific system might also be useful to help debug.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/197#issuecomment-467214391:140,clear,clearly,140,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/197#issuecomment-467214391,2,['clear'],['clearly']
Usability,"Thanks for the thorough suggestions. Actually, we fall into the easier case since Salmon does not support mixing single and paired-end reads in a single BAM file. When performing quantification on a single sample, the reads for that sample must follow a uniform library type. For paired-end reads, the BAM file can contain paired-end and single-end alignments (i.e. orphans), but the reads must all have been paired _in sequencing_. Mixing different library types in the BAM file makes it difficult to assess the compatibility of a fragment with the expected library type, especially if fragments from the different library types are expected to exist in a specific ratio in the input. Anyway, my main motivation for having the separate `AS` and `AP` types was to prevent the need to ""peek"" in the file, since, currently, there is not an easy way to peek the first read without opening the first file twice. However, I've decided that the benefit of having the same uniform (and simpler) interface of `A` always representing automatic library type detection is probably worth it, so I've pushed this implementation (commit 6116b2a). So, when the user provides the `A` library type, Salmon will peek into the first record in the BAM file to determine if the fragment was paired in sequencing or not, and will then set the single / paired-end status on that basis. The only corollary to this is that, in alignment-based mode, the `A` flag is not compatible with an input stream (i.e. the input must be a regular file). I will be sure to document this when I update the docs for the version bump.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/79#issuecomment-242399463:979,simpl,simpler,979,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/79#issuecomment-242399463,2,['simpl'],['simpler']
Usability,"Thanks- Jonathan. Yikes, that bad quality one looks like particularly bad quality, I have an example that looks like that in my failed examples. Were you able to recover usable data from it?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/362#issuecomment-490510234:170,usab,usable,170,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/362#issuecomment-490510234,2,['usab'],['usable']
Usability,"That is interesting. The attempt in the double redirect was to include all alignment records from the second sam file simply concatenated to the first. Assuming the SAM files contain the same header, this should be OK (simply another way to treat them as a single input). However this warning suggests that there were references in the file passed to `-t` that did not have a corresponding entry in the SAM file. Yet, with the redirect, the first sam file should contain the full header. I don't have a clear understanding of why this would happen yet.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/271#issuecomment-707349051:118,simpl,simply,118,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/271#issuecomment-707349051,6,"['clear', 'simpl']","['clear', 'simply']"
Usability,That sounds like a very good way of doing it :-). I'm sorry I was not clear enough - my question was acutally meant for a single sequence - let me try again:; Lets say we have a read pair where one mate maps fine - but the other mate have a problem - half of it is an adapter (or low quality sequence with to many errors). How would Salmon currently handle this situation where the first half of a sequence (e.g. nt 1-50) could be quasi-mapped to a transcript but the second half (nt 51-100) did not match anywhere? Would the the second half cause the whole sequence to be discarded or would it be enough that the first half matched for it to be considered/counted?,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/150#issuecomment-354955072:70,clear,clear,70,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/150#issuecomment-354955072,2,['clear'],['clear']
Usability,The Arabidopsis example in the getting started guide ([https://combine-lab.github.io/salmon/getting_started/](https://combine-lab.github.io/salmon/getting_started/)) seems to work fine on FreeBSD 13.0 with salmon installed via miniconda per instructions above.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/419#issuecomment-989865038:47,guid,guide,47,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/419#issuecomment-989865038,2,['guid'],['guide']
Usability,"The `AS:i:-2147483648` is a sentinel value basically meaning the alignment was below the minimum acceptable quality. You can simply ignore those (its the min signed 32-bit integer). Let me think about your other question (and ping @mikelove), and get back to you.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/528#issuecomment-639157711:125,simpl,simply,125,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/528#issuecomment-639157711,2,['simpl'],['simply']
Usability,"The easiest way is probably to mount the external data / the relevant external directories as a [volume](https://docs.docker.com/engine/admin/volumes/volumes/#create-and-manage-volumes) when you run the docker command. The TLDR version of that page is [here](https://stackoverflow.com/questions/42625947/docker-input-output-outside-the-container). Basically, you simply map some location on your host system to some directory _inside_ the docker image, and then the executable in the container can read and write directly to that volume.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/164#issuecomment-338278307:363,simpl,simply,363,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/164#issuecomment-338278307,2,['simpl'],['simply']
Usability,"The issue relates to the error message, so maybe I will close the issue in terms of being able to run the program without generating the error message. However, I think something still doesn't seem right, and I thought I should make that clear. <table>; <tbody>; <tr>; <th align=""center"">Method</th>; <th align=""center"">SRR13313130</th>; <th align=""center"">10x_pbmc_5k</th>; </tr>; <tr>; 	 <td align=""left"">CellRanger</td>; <td align=""center"">9,974 cells</td>; <td align=""center"">4,956 cells</td>; </tr>; <tr>; 	 <td align=""left"">STARsolo</td>; <td align=""center"">7,587 cells</br><i>(Summary.csv)</i></td>; <td align=""center"">4,586 cells</br><i>(Summary.csv)</i></td>; </tr>; <tr>; 	 <td align=""left"">Alevin</td>; <td align=""center""><b>814 cell barcodes?</b></td>; <td align=""center""> 856,224 cell barcodes</td>; </tr>; <tr>; 	 <td align=""left"">Kallisto</td>; <td align=""center"">79,254 cells</br><i>(BUSpaRse)</i></td>; <td align=""center"">47,598 cells</br><i>(BUSpaRse)</i></td>; </tr>; <tr>. </tbody>; </table>. For Alevin and Kallisto, I am not so worried about the exact values for cell barcodes (versus cells), since I was expecting extra work was needed to estimate a cell count from a distribution of measurements for each cell barcode. However, the number of cell barcodes should be larger than the number of cells, and that seems to match for everything except Alevin for this sample (SRR13313130). In other words, for sample, I think that this is the command that generates the fewest errors/warnings/notes:. `/path/to/salmon alevin -l ISF --chromium -1 $R1 -2 $R2 -i $REF -p 4 -o $ID --tgMap $MAP`. However, I think the cell barcode count is too small. **Is there anything else that you would recommend trying?**",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/682#issuecomment-882751952:238,clear,clear,238,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/682#issuecomment-882751952,2,['clear'],['clear']
Usability,"These messages have been removed in 0.9.0. Also, the read parser has had a considerable overhaul to avoid simply busy waiting in a situation like this where the processing is much slower than the disk. Let me know if this problem is resolved on your end.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/152#issuecomment-346981211:106,simpl,simply,106,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/152#issuecomment-346981211,2,['simpl'],['simply']
Usability,"This is failing on our local drone CI during runtime. The log output is :. ```; + echo ""[Testing quant]""; [Testing quant]; + ./.drone/test_quant.sh; Holy build box activated; Prefix: /hbb_exe; CFLAGS: -g -O2 -fvisibility=hidden -I/hbb_exe/include ; LDFLAGS: -L/hbb_exe/lib -static-libstdc++; STATICLIB_CFLAGS: -g -O2 -fvisibility=hidden -I/hbb_exe/include ; SHLIB_CFLAGS: -g -O2 -fvisibility=hidden -I/hbb_exe/include ; SHLIB_LDFLAGS: -L/hbb_exe/lib -static-libstdc++; [Drone test] current path : /drone/src/github.com/COMBINE-lab/salmon; [Drone test] making quant test directory; [Drone test] run nextflow pipeline; N E X T F L O W ~ version 0.29.1; Launching `tests/test_quant.nf` [curious_gilbert] - revision: 4f25b30301; [warm up] executor > local; [91/922fac] Submitted process > buildIndex; ERROR ~ Error executing process > 'buildIndex'; Caused by:; Process `buildIndex` terminated with an error exit status (127); Command executed:; /drone/src/github.com/COMBINE-lab/salmon/bin/salmon index -t Homo_sapiens.GRCh37.75.cdna.pc.fa -i nfindex; Command exit status:; 127; Command output:; (empty); Command error:; /drone/src/github.com/COMBINE-lab/salmon/bin/salmon: error while loading shared libraries: libjemalloc.so.2: cannot open shared object file: No such file or directory; Work dir:; /drone/src/github.com/COMBINE-lab/salmon/work/91/922facec25da43edd4a2ce82f2289d; Tip: when you have fixed the problem you can continue the execution appending to the nextflow command line the option `-resume`; -- Check '.nextflow.log' file for detail; ```. So, it seems to be due to failure to find the dynamic shared library for jemalloc. Any idea why that might be?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/348#issuecomment-472495264:1497,resume,resume,1497,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/348#issuecomment-472495264,2,['resume'],['resume']
Usability,This seems like a fairly simple job for an external tool as well. What did you have in mind? Just transcript --> genomic coordinates in a table or are you interested in visualizing the pseudobam output mapped to genomic coordinates?,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/193#issuecomment-371818629:25,simpl,simple,25,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/193#issuecomment-371818629,2,['simpl'],['simple']
Usability,"To keep the code simpler:. ```; txi <- tximport(files, type = ""salmon"", tx2gene = tx2gene, countsFromAbundance = ""lengthScaledTPM""); # then below...; dds <- DESeqDataSetFromTximport(txi, sampleTable, ~condition); ```. DESeq2 will do the right thing based on the value of `txi$countsFromAbundance`. This is the point of the importer functions. We also have them in tximeta for edgeR and limma. (You can still use tximeta with organisms other than human, mouse, or fly, you just have to run `makeLinkedTxome` and point to the GTF for your organism. It's just one step really.)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/581#issuecomment-719806601:17,simpl,simpler,17,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/581#issuecomment-719806601,2,['simpl'],['simpler']
Usability,"Updated Expected behavior: ; A clear and concise description of what you expected to happen.; I aim to retain all gene IDs, and for those represented by multiple lines, I intend to calculate the sum of values for each unique gene ID. I came across a few posts regarding this issue, but have not found a good solution for salmon quantmerge yet",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/910#issuecomment-1918166379:31,clear,clear,31,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/910#issuecomment-1918166379,2,['clear'],['clear']
Usability,"Use Gencode is the simple solution. Also Gencode combines coding and non-coding while Ensembl has these as two FASTA files. What I'm thinking is that, `tximeta` can solve this for Ensembl post-hoc by simply renaming the duplicate transcripts after looking up the name of the transcript from the standard chromosome. it won't disrupt the function of `tximeta` because we index the sequence of the txome which doesn't care about the names of the duplicate transcripts",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/249#issuecomment-407831888:19,simpl,simple,19,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/249#issuecomment-407831888,4,['simpl'],"['simple', 'simply']"
Usability,"Using the rest of the same configure flags without `-DUSE_SHARED_LIBS=TRUE`, the build does not link properly. I think you should try building without these extra flags. Since the LTO seems not to be a problem on this system, a simple `cmake .. && make` should work. In the mean time, I'll try and pare back the configure command line to find the maximum viable interpolation between our different configurations. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1464012294:228,simpl,simple,228,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1464012294,2,['simpl'],['simple']
Usability,"We might have to go through the paper and the dropseq guidelines to check what really changed.; You might wanna check https://github.com/COMBINE-lab/salmon/issues/247, we actually have a hidden option to do customized umi/CB length options, however this goes into a little more unexplored territory and requires a bit more testing. We'd appreciate your feedback if you happen to run this mode.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/258#issuecomment-408191888:54,guid,guidelines,54,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/258#issuecomment-408191888,4,"['feedback', 'guid']","['feedback', 'guidelines']"
Usability,"Well, if they *were* paired end, they would be ISF. I assumed that Salmon would simply ignore the pairing information if you fed it single-end reads. (I think this is how some other tools work, maybe?) I'll retry with fixed library specifications and see if that fixes things. Edit: I just noticed your edit. I'll reply again in a minute.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-266932730:80,simpl,simply,80,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-266932730,2,['simpl'],['simply']
Usability,"Where does `extract-libdivsufsort.cmake` live? I don't find it in the `salmon` repository. Is it generated automatically by `cmake`? The following patch/hack using `unzip` works around the `cmake -E tar xfz` bug for me. It seems to only affect extracting the `libdivsufsort.zip`, perhaps because it's a `.zip`. If that is the case, and there's a `.tar.gz` distribution of `libdivsufsort`, then there may be a simple fix. ``` diff; --- libdivsufsort-prefix/src/libdivsufsort-stamp/extract-libdivsufsort.cmake.orig 2016-03-07 22:02:35.000000000 -0800; +++ libdivsufsort-prefix/src/libdivsufsort-stamp/extract-libdivsufsort.cmake 2016-03-07 22:06:49.000000000 -0800; @@ -23,7 +23,7 @@; # Extract it:; #; message(STATUS ""extracting... [tar xfz]""); -execute_process(COMMAND ${CMAKE_COMMAND} -E tar xfz ${filename}; +execute_process(COMMAND unzip ${filename}; WORKING_DIRECTORY ${ut_dir}; RESULT_VARIABLE rv). ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/10#issuecomment-193623757:409,simpl,simple,409,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/10#issuecomment-193623757,2,['simpl'],['simple']
Usability,"While I definitely trust the jemalloc devs, I do know that such things are possible, as a release is simply associated with a tagged commit, which _can_ be changed via a forced update to the tags. I know because, in my early days using git + GitHub, I did such a foolish thing. So, while I'm sure that the jemalloc devs wouldn't change the file associated with a tag, and while there are safeguards (e.g. check that the file we get matches the SHA of what we expect), simply pulling from a fork is a convenient way to handle this ""generally"" (for packages not as production-quality as jemalloc, or where the developers might not have tagged a release corresponding to what we need). I completely understand that you don't want to link against a standard jemalloc if we compile some strange version with custom modifications. However, here, we simply want to use the vanilla jemalloc. In fact, when salmon is built under bioconda, this is exactly what we do (we link against the conda jemalloc >= 5.1.0).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/288#issuecomment-420339510:101,simpl,simply,101,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/288#issuecomment-420339510,6,['simpl'],['simply']
Usability,"Yea; so I think the only way to do this currently (without me modifying the jellyfish parser) is to just use 2 fifos. I could put together a simple bash or python script together for this if there is interest (until we support interleaved format natively, which I'll add to the feature list).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/29#issuecomment-168516778:141,simpl,simple,141,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/29#issuecomment-168516778,2,['simpl'],['simple']
Usability,"Yeah, this is definitely not your issue. In fact, I just figured out that my explanation above was incomplete. **You don't need to investigate anything on your end**. I simply didn't flush the entire contents of a FASTA file to disk before calling `salmon index`. In the course of tracking down the issue I fixed some of my code indentation, bringing some of my code into a more global scope, where the `with` context handler I was using to hold the FASTA file open went out of scope, flushing my final writes to disk. Sigh...",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/132#issuecomment-303813062:169,simpl,simply,169,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/132#issuecomment-303813062,2,['simpl'],['simply']
Usability,"Yep, I think that's right and it is expected that every sample would have different number of cells/cellular barcodes. The general idea is to use a frequency distribution to separate high quality barcodes from low quality post quantification. I'm sorry that you are facing issues with v2, but the error simply means you are providing the full list of 737k barcodes which is not an expected behavior for the `--whitelist` flag and in a typical 10x/ Dropseq based experiment one would expect ~10-12k cells/CB.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/682#issuecomment-878695672:303,simpl,simply,303,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/682#issuecomment-878695672,2,['simpl'],['simply']
Usability,"Yes ! it's other error that I can't find . but I try : . ```; Last login: Thu Jun 30 15:14:51 on ttys002; Benjamin@u932-ulm-2-57030119-6834 ~ % conda config --add channels defaults; conda config --add channels bioconda; conda config --add channels conda-forge; Warning: 'conda-forge' already in 'channels' list, moving to the top; Benjamin@u932-ulm-2-57030119-6834 ~ % conda install salmon; Collecting package metadata (current_repodata.json): failed. CondaHTTPError: HTTP 000 CONNECTION FAILED for url <https://conda.anaconda.org/conda-forge/osx-arm64/current_repodata.json>; Elapsed: -. An HTTP error occurred when trying to retrieve this URL.; HTTP errors are often intermittent, and a simple retry will get you on your way.; 'https://conda.anaconda.org/conda-forge/osx-arm64'; ```. ```; Benjamin@u932-ulm-2-57030119-6834 ~ % conda config --show channels ; channels:; - conda-forge; - bioconda; - defaults; ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/724#issuecomment-1171223414:689,simpl,simple,689,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/724#issuecomment-1171223414,2,['simpl'],['simple']
Usability,"Yes, I wonder if there is some sort of simple formatting issue that could be at fault here. Having a look at the file(s) would make it much easier to diagnose.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/540#issuecomment-648250382:39,simpl,simple,39,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/540#issuecomment-648250382,2,['simpl'],['simple']
Usability,"Yes, absolutely, above I meant in scRNA-seq context, my apologies if it was not clear.; Here, you are right we might have to think of ways to provide whitelist cellular barcode. One another thing you can try is providing the full 10x expected whitelisted cellular barcodes to alevin through `--whitelist` command.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-640698401:80,clear,clear,80,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-640698401,2,['clear'],['clear']
Usability,"Yup, and the fact that this ended up as `MU` is strange, since the library type frequencies clearly suggest `IU` (since `ISF` and `ISR` counts seem to dominate). Could it be the result of having the FASTQ files generated by converting from BAM which some sort of bias in the beginning reads? The automatic detection uses the first 10,000 reads to decide --- if these are mapped in a biased way, that could be the cause.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/137#issuecomment-406366598:92,clear,clearly,92,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/137#issuecomment-406366598,2,['clear'],['clearly']
Usability,"Yup, the execution is *definitely* inside the Gibbs sampler at that point, since that's the code that sets up the progress bar etc. So, I'll focus my attention there until (if/when) we can get a specific offending function name. Thanks so much for all your help tracking this down so far; I really appreciate it!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267428600:114,progress bar,progress bar,114,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267428600,2,['progress bar'],['progress bar']
Usability,"Yup; I think there are some potential places for improvement (e.g. the interleaved splitting code could be incorporated directly into this script, and the parsing could be improved to handle multiple interleaved files directly), but it seems to work pretty well. Also, when making this, I learned about the `trap` command, which should do what we want in terms of ensuring that any created fifos are cleaned up.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/29#issuecomment-168727465:289,learn,learned,289,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/29#issuecomment-168727465,2,['learn'],['learned']
Usability,"[Here's](https://gist.github.com/rob-p/963848ba35fb49fefaa3) a sketch of a shell script-based solution that might work. It relies on [this](https://gist.github.com/nathanhaigh/3521724) shell script to do the de-interleaving (but it can use whichever tool we might decide is best for the job). You'd run it with the interleaved file like so:. ```; ./runner.sh salmon quant -i index -l IU --interleaved interleaved.fq -o interleaved_quant; ```. Basically, the script checks to see if the `--interleaved` parameter is present. If so, it handles making the fifos and constructing the proper salmon command with them. Otherwise, if there is no --interleaved file, it simply runs the command as given.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/29#issuecomment-168582355:662,simpl,simply,662,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/29#issuecomment-168582355,2,['simpl'],['simply']
Usability,"] [info] Total Unique barcodes found: 604589; > [2020-06-04 12:26:10.936] [alevinLog] [info] Used Barcodes except Whitelist: 88156; > [2020-06-04 12:26:11.113] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify; > ; > [2020-06-04 12:26:11.113] [alevinLog] [info] parsing read library format; > [2020-06-04 12:27:21.373] [alevinLog] [info] Starting optimizer; > ; > [2020-06-04 12:27:22.086] [alevinLog] [warning] mrna file not provided; using is 1 less feature for whitelisting; > [2020-06-04 12:27:22.086] [alevinLog] [warning] rrna file not provided; using is 1 less feature for whitelisting; > [2020-06-04 12:27:22.409] [alevinLog] [info] Total 23937.00 UMI after deduplicating.; > [2020-06-04 12:27:22.409] [alevinLog] [info] Total 91 BiDirected Edges.; > [2020-06-04 12:27:22.409] [alevinLog] [info] Total 82 UniDirected Edges.; > [2020-06-04 12:27:22.409] [alevinLog] [warning] Skipped 82268 barcodes due to No mapped read; > [2020-06-04 12:27:22.412] [alevinLog] [info] Clearing EqMap; Might take some time.; > [2020-06-04 12:27:22.418] [alevinLog] [warning] Num Low confidence barcodes too less 1 < 100.Can't performing whitelisting; Skipping; > [2020-06-04 12:27:22.418] [alevinLog] [info] Finished optimizer. Run 2: `salmon alevin -l ISR --citeseq --barcodeLength 16 --umiLength 10 --end 5 --featureStart 19 --featureLength 21 --maxNumBarcodes 200000 --freqThreshold 1 --lowRegionMinNumBarcodes 100`. > [2020-06-04 12:40:45.455] [alevinLog] [info] set CITE-seq minScoreFraction parameter to : 0.797619; > [2020-06-04 12:40:45.456] [alevinLog] [info] Found 64 transcripts(+0 decoys, +0 short and +0 duplicate names in the index); > [2020-06-04 12:40:45.456] [alevinLog] [info] Filled with 64 txp to gene entries ; > [2020-06-04 12:40:45.456] [alevinLog] [info] Found all transcripts to gene mappings; > [2020-06-04 12:40:45.461] [alevinLog] [info] Processing barcodes files (if Present) ; > ; > [2020-06-04 12:42:01.202] [alevinLog] [info] Done barcode density calculation.; ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-638991199:3804,Clear,Clearing,3804,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-638991199,1,['Clear'],['Clearing']
Usability,"```; Benjamin@u932-ulm-2-57030119-6834 ~ % conda install salmon; Collecting package metadata (current_repodata.json): failed. CondaHTTPError: HTTP 000 CONNECTION FAILED for url <https://conda.anaconda.org/conda-forge/osx-arm64/current_repodata.json>; Elapsed: -. An HTTP error occurred when trying to retrieve this URL.; HTTP errors are often intermittent, and a simple retry will get you on your way.; 'https://conda.anaconda.org/conda-forge/osx-arm64'; ```. ```; Benjamin@u932-ulm-2-57030119-6834 ~ % conda config --show channels; channels:; - conda-forge; ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/724#issuecomment-1171204474:363,simpl,simple,363,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/724#issuecomment-1171204474,2,['simpl'],['simple']
Usability,"alignment, the alignment scores are passed to the quantification step, but the position of the reads is not used downstream. . Well, yes and no. We make extensive use of the position when estimate the implied fragment length (distance between paired end reads) and then model the conditional probability of this fragment based on the global fragment length distribution. This is just as much as is done by e.g. RSEM. However, you are right that there is no notion of using the coverage profile in estimation (more on this below)!. > Also, my intuition for these transcripts is not really a coverage ""bias"" . My intuition agrees with yours here completely. First, this isn't really a coverage bias as we use the normal definition of the term. Second, the positional bias modeling in salmon is not on a per-transcript level (since that would be an astronomical number of different parameters to learn, and any procedure would almost certainly overfit). Instead, it groups transcripts into length bins, and learns a distinct coverage bias model per-bin. > It would be neat if Salmon could detect these kinds of dramatic dropoffs and add a warning or something... even if not incorporating the information into the quants... it could even be a good QC step to identify large deletions/insertions over a gene body. As far as I know, there are NO rnaseq quant programs that would handle this, because even something like a STAR -> RSEM pipeline just projects read counts to the transcriptome and doesn't incorporate the coverage information. These are **great** points! A couple of thoughts. First, you are right that salmon, RSEM, etc. don't use coverage information in the way you describe here. One piece of software you might look into is [Salmon Anomaly Detection](https://github.com/Kingsford-Group/sad) (paper [here](https://www.cell.com/cell-systems/pdf/S2405-4712(19)30381-3.pdf)). This is sort of akin to what you are suggesting, and post-processes salmon output by looking for anomalous coverage",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-623047035:1575,learn,learns,1575,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-623047035,2,['learn'],['learns']
Usability,"approach right. I believe, It takes time and understanding to develop a good model for data generated from any technology and that's what we have been trying to do with salmon for years, piece by piece. Having said that, we don't mean to discourage people from trying salmon, that's one of the way we learn how can we improve the model even further. Now, coming back to your original question about using QuantSeq with salmon and how the paper above approach to solve it. I have a couple of thoughts:; 1.) Like you said, from the reading of their command line argument they didn't use the `nolengthcorrection` and I am surprised about the results myself. Since you have experience with the technology, you are best person to explore the difference in using and not using the length correction with salmon, that's why I shared.; 2.) Salmon models the transcript lengths in its quantification model. The basic intuition being longer length transcripts have higher probability of a read being sampled from them and has to be corrected for when using relative count metrices (like TPM) to avoid length bias. The logic behind `noLengthCorrection` is to _not_ correct for length for 3' protocol since we expect all the reads from one end of the transcript and if we do length correction, I hypothesize, we might end up biasing the estimates on the opposite direction; however the effect size of this hypothesis is still an open question and seemingly from the results from the paper it has minor effect. On the flip side may be it does have effect but their baseline estimates were not great and any improvement is good, for that again since you have experience with the data it's good to know / test what's going on.; 3.) A little experimental thought, although `noLengthCorrection` flag can generate decent estimates, it's actually fully disabling the length effect, which in my opinion we can do better as you look at Figure 1B of the paper it shows some length based affect but again we don't know how ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-565256512:1813,intuit,intuition,1813,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-565256512,2,['intuit'],['intuition']
Usability,"be present there. The main purpose of the decoys is to account for reads not from target transcripts that might otherwise be sequenced in the sample. The reason we report the decoy mapping fragments in the unmapped names file is, as I said, a historical contingency. Basically, since we're not mapping the decoys to targets and counting them toward quantification, one might be interested in knowing where the decoy sequences come from. At some point, the easiest way to do this was just to place the name of these fragments in the unmapped names file (with the d tag) and then grab the reads and go fishing with them in some other way. However, I totally understand why including them in the unmapped names file is confusing. During selective-alignment, if we assign a fragment as best mapping to a decoy, it doesn't get assigned to a quantifiable target, but it's not technically unmapped in the same sense as the other unmapped reads. That is, we know it comes from the decoy sequence, that the alignment score is at least the minimum required, and that it maps better to the decoy than to any non-decoy target. That's quite different that ""truly"" unmapped fragments where we find no mapping for the fragment within the required score threshold. Anyway, I hope the answer is useful for you. If you want to select only unmapped reads that were matched to neither your target sequences (transcripts) nor to the decoy sequences, then your grep command should do the trick. However, if you want to look at all of the reads that simply didn't contribute to the counts in the quant.sf file, then you'd want to look at everything in the unmapped names file. Let me know if you have any other questions!. Best,; Rob. —; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://github.com/COMBINE-lab/salmon/issues/657#issuecomment-841492751>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AN3VWAUROTOCPHB6SKMA2ETTNWDF5ANCNFSM44HLOFXQ>.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/657#issuecomment-843255628:2473,simpl,simply,2473,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/657#issuecomment-843255628,2,['simpl'],['simply']
Usability,"bit on a few of @k3yavi's answers. 1&2) Yes; if you want to use SAF, you no longer need mashmap, as what you are essentially doing is treating the entire genome as a ""decoy"". As @k3yavi alludes, SA is still useful when you need to run in a very memory-constrained environment. After adopting the new [pufferfish-based](https://github.com/COMBINE-lab/pufferfish/tree/develop) index, the size of the transcriptome plush mashmap 2 decoys becomes considerably smaller than the previous size of the transcriptome in earlier versions of salmon (<= 0.15.0). However, depending on the organism, indexing the entire genome as decoy, even though it yields the best accuracy, does require a bit more memory, as specified in the release notes for the 0.99 betas and 1.0.0. 3) Yes; it is still possible to use `salmon index` without any decoy sequence. In this case, one can expect results similar to if you had aligned to the target transcriptome using Bowtie2. In this case, you perform indexing by simply not providing any `--decoy` flag to the `index` command. In that case, all of the records in the target fasta will be treated as valid and quantifiable targets. Of course, for reasons detailed in the pre-print --- the high _sensitivity_ of both Bowtie2 and selective-alignment --- we recommend including either mashmap-derived decoys or the organism's genome as a decoy whenever possible. . 4) Related to @k3yavi's response and my elaboration above: we have dropped quasi-mapping from 1.0.0 (though something akin to it may return in the future if there is sufficient demand and if the shortcomings described in the manuscript can be overcome). However, as I mention in part 3 above, this doesn't mean it's not possible to use v1.0.0 without an explicit decoy sequence. The `--decoy` flag of the indexing command is optional, not required. We will update this in the documentation making it more explicit. However, as @k3yavi points out, it is true that if you wish to use quasi-mapping and selective-alig",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/442#issuecomment-549195390:1061,simpl,simply,1061,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/442#issuecomment-549195390,2,['simpl'],['simply']
Usability,"ctor: 1097.45; [2019-07-09 09:17:07.597] [alevinLog] [info] Total 41.2673% reads will be thrown away because of noisy Cellular barcodes.; [2019-07-09 09:17:07.597] [alevinLog] [info] Total [32m1192[0m(has [32m397[0m low confidence) barcodes; [2019-07-09 09:17:07.765] [alevinLog] [info] Done True Barcode Sampling; [2019-07-09 09:17:08.039] [alevinLog] [info] Done populating Z matrix; [2019-07-09 09:17:08.067] [alevinLog] [info] Done indexing Barcodes; [2019-07-09 09:17:08.067] [alevinLog] [info] Total Unique barcodes found: 7881525; [2019-07-09 09:17:08.067] [alevinLog] [info] Used Barcodes except Whitelist: 84951; [2019-07-09 09:17:08.128] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify. [2019-07-09 09:17:08.128] [alevinLog] [info] parsing read library format; [2019-07-09 10:02:26.992] [alevinLog] [info] Starting optimizer. [2019-07-09 10:13:56.661] [alevinLog] [info] Total 99488568.00 UMI after deduplicating.; [2019-07-09 10:13:56.701] [alevinLog] [info] Clearing EqMap; Might take some time.; [2019-07-09 10:14:11.020] [alevinLog] [info] Starting Import of the gene count matrix of size 1192x60053.; [2019-07-09 10:14:11.286] [alevinLog] [info] Done initializing the empty matrix.; [2019-07-09 10:14:13.421] [alevinLog] [info] Done Importing gene count matrix for dimension 1192x60053; [2019-07-09 10:14:13.622] [alevinLog] [info] Starting white listing; [2019-07-09 10:14:13.627] [alevinLog] [info] Done importing order of barcodes ""quants_mat_rows.txt"" file.; [2019-07-09 10:14:13.627] [alevinLog] [info] Total 1192 barcodes found; [2019-07-09 10:14:13.627] [alevinLog] [warning] mrna file not provided; using is 1 less feature for whitelisting; [2019-07-09 10:14:13.627] [alevinLog] [warning] rrna file not provided; using is 1 less feature for whitelisting; [2019-07-09 10:14:13.627] [alevinLog] [info] Starting to make feature Matrix; [2019-07-09 10:14:13.885] [alevinLog] [info] Done making regular featues; [2019-07-09 10:14:13.885] [alevinLog] [info] Do",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/396#issuecomment-510547693:1547,Clear,Clearing,1547,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/396#issuecomment-510547693,1,['Clear'],['Clearing']
Usability,"d handle this, because even something like a STAR -> RSEM pipeline just projects read counts to the transcriptome and doesn't incorporate the coverage information. These are **great** points! A couple of thoughts. First, you are right that salmon, RSEM, etc. don't use coverage information in the way you describe here. One piece of software you might look into is [Salmon Anomaly Detection](https://github.com/Kingsford-Group/sad) (paper [here](https://www.cell.com/cell-systems/pdf/S2405-4712(19)30381-3.pdf)). This is sort of akin to what you are suggesting, and post-processes salmon output by looking for anomalous coverage profiles. It can both flag ""suspicious"" transcripts, and can also sometimes move reads around to mitigate anomalous coverage. Another tool / metric you might consider is the junction coverage compatibility (paper [here](https://www.life-science-alliance.org/content/2/1/e201800175)). While both of these approaches get at some of the core intuitions you raise in your response, they are both rather ""heavyweight"", and neither, of course, is built into salmon. So, I **completely agree** that a lightweight version of something like SAD would be great to have built _into_ salmon. Specifically, it makes a lot of sense to have some component of the likelihood account for the coverage profile of transcripts. While I don't know of any widely-used and actively maintained quantification tools that do this, the idea for this was proposed in the [iReckon paper](https://www.ncbi.nlm.nih.gov/pubmed/23204306) and a coverage-based heuristic was introduced. However, the coverage was not directly incorporated into the likelihood. Rather, a variant of the normal likelihood function was used and then coverage was used to select between different potential solutions that were otherwise of similar likelihood. Given issues like the one you see here, and the ones that we observed in the JCC paper and that Cong and Carl observed in the SAD paper, it seems clear that it would b",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-623047035:2911,intuit,intuitions,2911,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-623047035,2,['intuit'],['intuitions']
Usability,"detection:. - fail to detect adpaters automatically - (https://github.com/OpenGene/fastp/issues/222 and https://github.com/OpenGene/fastp/issues/205). - [incorrect automatic adapter detection](https://github.com/OpenGene/fastp/issues/240). - [inconsistent behavior with different runs](https://github.com/OpenGene/fastp/issues/231). 3. When I see the above, I am bit skeptical using fastp for qc/adapter trimming. . After lot of trials with bbduk and fastp, I have decided to use bbduk and bbmap for my high throughput analysis. Below, I explain my reasoning behind those choices: . **_```Note - edited this on 02-Apr-2020 to have the correct order of operations ```_** . 1. **_STEP 1 - run bbmap.sh on raw fatsq file to remove contaminants as appropriate (rRNA, mitochondrial, chloroplast)_**; - You have alluded to the importance of removing contaminants [in this post](https://github.com/COMBINE-lab/salmon/issues/160#issuecomment-334762498); >However, the other thing to try is simply to align one of these samples to the genome with a tool like STAR or HISAT2 and look at their mapping rate to known features. If it's similar, then the other reads could be accounted for by e.g. intron retention or even contamination. Finally, [@vals has an excellent series of blog posts on investigating and addressing low mapping rates](http://www.nxn.se/valent/2017/9/18/low-mapping-rate-5-human-dna-contamination); - bbmap Command ([based of this biostars post](https://www.biostars.org/p/143019/#210890)):; `bbmap.sh in=read_1.fq.gz ref=rRNA_Chlor_Mito.fa maxindel=1 minid=0.95 outu=clean_read_1.fq.gz nodisk`; - Strategy:; `use the rRNA+Mito+Chloroplast file and map the reads using bbmap, then collect the unmapped reads (clean_read_1.fq.gz) for my downstream analysis`. 2. **_STEP 2 - run bbduk.sh on the outu files from bbmap step -- the outu stands for output unmapped - as stated in the logic above, anything that is unmapped to the rRNA_Chlor_Mito.fa is a clean read for downstream analysis_**. I us",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-597393209:2391,simpl,simply,2391,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-597393209,2,['simpl'],['simply']
Usability,"ecoy will be quantified. I am surprised to see that the name for mapped reads would show up in the unmapped_names.txt file.; ; Well, it's the case the decoys are *not* be quantified. That is, only the target transcripts will appear in the `quant.sf` file, no decoys should be present there. The main purpose of the decoys is to account for reads _not_ from target transcripts that might otherwise be sequenced in the sample.; ; The reason we report the decoy mapping fragments in the unmapped names file is, as I said, a historical contingency. Basically, since we're not mapping the decoys to targets and counting them toward quantification, one might be interested in knowing _where_ the decoy sequences come from. At some point, the easiest way to do this was just to place the name of these fragments in the unmapped names file (with the `d` tag) and then grab the reads and go fishing with them in some other way. However, I totally understand why including them in the unmapped names file is confusing. During selective-alignment, if we assign a fragment as best mapping to a decoy, it doesn't get assigned to a quantifiable target, but it's not technically unmapped in the same sense as the other unmapped reads. That is, we know it comes from the decoy sequence, that the alignment score is at least the minimum required, and that it maps better to the decoy than to any non-decoy target. That's quite different that ""truly"" unmapped fragments where we find no mapping for the fragment within the required score threshold. Anyway, I hope the answer is useful for you. If you want to select only unmapped reads that were matched to *neither* your target sequences (transcripts) *nor* to the decoy sequences, then your `grep` command should do the trick. However, if you want to look at all of the reads that simply didn't contribute to the counts in the `quant.sf` file, then you'd want to look at everything in the unmapped names file. Let me know if you have any other questions!. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/657#issuecomment-841492751:2120,simpl,simply,2120,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/657#issuecomment-841492751,2,['simpl'],['simply']
Usability,"efault. RSEM uses the EM algorithm, and salmon uses the variational Bayesian EM algorithm. The latter tends to induce more sparse solutions. This is simply because they are optimizing slightly different objectives. It is very difficult to say in general if one is ""better"" than the other in a blanket way, but [there is previous literature to support that the VBEM may be more accurate](https://academic.oup.com/bioinformatics/article/29/18/2292/239795). However, while RSEM only implements the EM algorithm, salmon actually implements and provides a switch to use either. So, if you want to test the effect of this difference, you can run salmon with the `--useEM` algorithm. This will tell salmon to use the ""classic"" EM algorithm and will eliminate this source of variation. * As with the other question you asked, there may be a _small_ discrepancy depending on when enforcement of a stranded library kicks in under salmon's `A` library type. You can eliminate that variable by simply providing `-l SF` to match the library type being used with RSEM. * Coming back to the `IndelSoftclipSingleend` parameter I mentioned in the first point; RSEM disallows indels in the alignments that it quantifies. This means that to produce RSEM-compatible input, STAR must not align reads that contain indels. While this won't generally have a big effect for many transcripts, it can certainly affect the abundance estimates for transcripts in your sample where the sample you are quantifying has (indel) variation with respect to the reference annotation. We touch upon that a bit as well in the [paper I mentioned above](https://genomebiology.biomedcentral.com/articles/10.1186/s13059-020-02151-8). * Finally, and likely the smallest source of potential differences, is that there are other implementation details that differ between salmon and RSEM (e.g. exactly how the fragment length distribution is used to compute the effective transcript length, exactly how the alignment score of a read is used to as",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/612#issuecomment-758004590:3672,simpl,simply,3672,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/612#issuecomment-758004590,2,['simpl'],['simply']
Usability,"ellranger to aggregate the counts and it looks like the following:; * As I was saying earlier aggregation step was happening downstream of count/quantification of the gene count matrix, at least in cellranger pipeline.; > When doing large studies involving multiple biological samples (or multiple libraries or replicates of the same sample), it is best to run cellranger count on each of the libraries individually, and then pool the results using cellranger aggr. * It looks like they have three different modes to normalize the libraries; > There are three normalization modes:; mapped: (default) Subsample reads from higher-depth libraries until they all have an equal number of confidently mapped reads per cell.; raw: Subsample reads from higher-depth libraries until they all have an equal number of total (i.e. raw, mapping-independent) reads per cell.; none: Do not normalize at all. * Although it's not clear, what do they mean by `equal number of confidently mapped reads per cell`, does it mean median reads per cell ? Like you tried to show in the above plot the distribution can be very uneven. But the part that troubles me more is once `count` information has been generated it has lost the read level information, since we have deduplicated them, then how do they use the read counts to normalize. Unless that is dumped too, not clear. Quoting your text from above:; > Alternatively, could a subsampling covariate be added to the probabilistic quantification model of alevin. I think we can definitely work on correcting the subsampling bias in the probabilistic model of Alevin but we might need a little more understanding of what's going on with the cellranger and why your way of aggregation is not working as intended. Unfortunately, I think we have to dig deeper into the cellranger codebase to really understand that and if possible, might need some subset of the relevant data to replicate your issue and work on improving that. Also, I am wondering, what's your way of check",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/305#issuecomment-433453155:1312,clear,clear,1312,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/305#issuecomment-433453155,2,['clear'],['clear']
Usability,"environment: failed with repodata from current_repodata.json, will retry with next repodata source.; Collecting package metadata (repodata.json): / Killed. this is the first time I've encountered an issue where something that is ""supposed"" to be there can't be found. Adam H. Freedman, PhD; Data Scientist; Faculty of Arts & Sciences Informatics Group; Harvard University; 38 Oxford St; Cambridge, MA 02138; phone: +001 310 415 7145; ________________________________; From: Rob Patro ***@***.***>; Sent: Sunday, October 29, 2023 10:01 AM; To: COMBINE-lab/salmon ***@***.***>; Cc: Freedman, Adam ***@***.***>; State change ***@***.***>; Subject: Re: [COMBINE-lab/salmon] anaconda version of salmon outdated, missing decoys option (Issue #895). I'm going to cc @dpryan79<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_dpryan79&d=DwMFaQ&c=WO-RGvefibhHBZq3fL85hQ&r=MITI_LEJgyr1a24IMFAlSaZIPxMpOUT21T7L3fg4CjA&m=mSC4skssR3kpqIDO5fXv00Vk9PrFQeVf0OH62EOgXZ9hbM31qjkaQra0z60JiEA_&s=hPsmfTmSAfiwDhS2JFQyD0EUHl5m5sbj_n46DYj6tdM&e=> on this — does it just not finish? It seems to work within our GitHub CI, where we have to grab the prebuilt salmon to test simpleaf. —; Reply to this email directly, view it on GitHub<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_COMBINE-2Dlab_salmon_issues_895-23issuecomment-2D1784122719&d=DwMFaQ&c=WO-RGvefibhHBZq3fL85hQ&r=MITI_LEJgyr1a24IMFAlSaZIPxMpOUT21T7L3fg4CjA&m=mSC4skssR3kpqIDO5fXv00Vk9PrFQeVf0OH62EOgXZ9hbM31qjkaQra0z60JiEA_&s=6Y-rQOzzAA-t9QV8NyfcMVeySD2an4xeN1HsDqa6VpQ&e=>, or unsubscribe<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_notifications_unsubscribe-2Dauth_ADBMMUDFRQIHN4AMNBHWCN3YBZOUTAVCNFSM6AAAAAA6UYYPGOVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMYTOOBUGEZDENZRHE&d=DwMFaQ&c=WO-RGvefibhHBZq3fL85hQ&r=MITI_LEJgyr1a24IMFAlSaZIPxMpOUT21T7L3fg4CjA&m=mSC4skssR3kpqIDO5fXv00Vk9PrFQeVf0OH62EOgXZ9hbM31qjkaQra0z60JiEA_&s=ckSFRx1FekMV-wL0KtdZFPdtgCB1DiAziHIsdrF0cKQ&e=>.; You are receiving this because you mo",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/895#issuecomment-1784126021:1425,simpl,simpleaf,1425,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/895#issuecomment-1784126021,2,['simpl'],['simpleaf']
Usability,"er,; s2 = as.vector(gencode[[x]]) %>% as.character; ). out2 <- reshape2::melt(out2) %>% as.data.table; colnames(out2) <- c('myFasta', 'GencodeMatureFasta', 'seqMatch'); out2[ , myFastaSeqType := 'premature']. # my premature complement vs gencode mature; out3 <- smoothDot(; s1 = as.vector(premature.tx[[x]] %>% complement) %>% as.character,; s2 = as.vector(gencode[[x]]) %>% as.character; ). out3 <- reshape2::melt(out3) %>% as.data.table; colnames(out3) <- c('myFasta', 'GencodeMatureFasta', 'seqMatch'); out3[ , myFastaSeqType := 'premature (complement)']. out <- rbind(out1, out2, out3); out[ , tx_strand := strand(anot[which(anot$transcript_id == x)[1], ]) %>% as.character]. return(out); }; ) %>% rbindlist(., idcol = 'tx_id'). # pdf(dotPlot.fname, width = 8, height = 6). ggp <- ggplot(mapping = aes(x = myFasta, y = GencodeMatureFasta, fill = seqMatch), data = to.plot) +; geom_tile(width = 1, height = 1) +; scale_fill_manual(; values = c('TRUE' = 'black', 'FALSE' = 'white'),; guide = F; ) + scale_x_continuous(; expand = c(0, 0); ) + scale_y_continuous(; expand = c(0, 0); ) +; theme_bw(base_size = 10) +; theme(; panel.grid = element_blank(), panel.background = element_blank() # element_rect(fill = 'grey'); ) +; facet_wrap(paste('tx strand:', tx_strand) ~ paste('tx ID:', tx_id) + paste('myFasta seq type:', myFastaSeqType), ncol = 3, scales = 'free'). print(ggp). # dev.off(). ```. R session info:; ```; R version 4.0.2 (2020-06-22); Platform: x86_64-pc-linux-gnu (64-bit); Running under: CentOS Linux 7 (Core). Matrix products: default; BLAS/LAPACK: [hidden]/easybuild/software/2017/Core/imkl/2018.3.222/compilers_and_libraries_2018.3.222/linux/mkl/lib/intel64_lin/libmkl_gf_lp64.so. locale:; [1] LC_CTYPE=en_CA.UTF-8 LC_NUMERIC=C LC_TIME=en_CA.UTF-8 LC_COLLATE=en_CA.UTF-8 ; [5] LC_MONETARY=en_CA.UTF-8 LC_MESSAGES=en_CA.UTF-8 LC_PAPER=en_CA.UTF-8 LC_NAME=C ; [9] LC_ADDRESS=C LC_TELEPHONE=C LC_MEASUREMENT=en_CA.UTF-8 LC_IDENTIFICATION=C . attached base packages:; [1] parallel stats4",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/655#issuecomment-826035191:10493,guid,guide,10493,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/655#issuecomment-826035191,2,['guid'],['guide']
Usability,"ge of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2018-12-06 11:14:56.533] [jointLog] [info] Usage of --validateMappings implies use of range factorization. rangeFactorizationBins is being set to 4; [2018-12-06 11:14:56.534] [jointLog] [info] Usage of --validateMappings implies a default consensus slack of 1. Setting consensusSlack to 1.; [2018-12-06 11:14:56.534] [jointLog] [info] Using default value of 0.8 for minScoreFraction in Alevin; [2018-12-06 11:14:56.540] [alevinLog] [info] Processing barcodes files (if Present) . ; processed 267 Million barcodes. [2018-12-06 11:16:47.491] [alevinLog] [info] Done barcode density calculation.; [2018-12-06 11:16:47.491] [alevinLog] [info] # Barcodes Used: 267451749 / 267548197.; [2018-12-06 11:16:52.732] [alevinLog] [info] Knee found left boundary at 11955 ; [2018-12-06 11:16:54.977] [alevinLog] [info] Gauss Corrected Boundary at 4345 ; [2018-12-06 11:16:54.977] [alevinLog] [info] Learned InvCov: 713.683 normfactor: 1183.93; [2018-12-06 11:16:54.985] [alevinLog] [info] Total 31.0106% reads will be thrown away because of noisy Cellular barcodes.; [2018-12-06 11:16:54.985] [alevinLog] [info] Total 5344(has 999 low confidence) barcodes; [2018-12-06 11:16:55.059] [alevinLog] [info] Done True Barcode Sampling; [2018-12-06 11:16:55.395] [alevinLog] [info] Done populating Z matrix; [2018-12-06 11:16:55.453] [alevinLog] [info] Done indexing Barcodes; [2018-12-06 11:16:55.453] [alevinLog] [info] Total Unique barcodes found: 4180559; [2018-12-06 11:16:55.453] [alevinLog] [info] Used Barcodes except Whitelist: 134856; [2018-12-06 11:16:56.218] [jointLog] [info] There are 2 libraries.; [2018-12-06 11:16:56.292] [jointLog] [info] Loading Quasi index; [2018-12-06 11:16:56.294] [jointLog] [info] Loading 32-bit quasi index; [2018-12-06 11:16:56.205] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify. [2018-12-06 11:16:56.218] [alevinLog] [info] parsing read l",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/328#issuecomment-445008548:5296,Learn,Learned,5296,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/328#issuecomment-445008548,1,['Learn'],['Learned']
Usability,gram ] => salmon ; ### [ command ] => alevin ; ### [ libType ] => { ISR }; ### [ mates1 ] => { hgmm_100_S1_L001_001.fastq.1.gz }; ### [ mates2 ] => { hgmm_100_S1_L001_001.fastq.2.gz }; ### [ chromium ] => { }; ### [ index ] => { geneset.dir/geneset_coding_exons.salmon.index/ }; ### [ output ] => { salmon.dir/ }; ### [ tgMap ] => { transcript2geneMap.tsv }; ### [ dumpCsvCounts ] => { }. [2019-01-29 09:54:57.898] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2019-01-29 09:54:57.916] [alevinLog] [info] Processing barcodes files (if Present) . ; processed 0 Million barcodes. [2019-01-29 09:54:59.693] [alevinLog] [info] Done barcode density calculation.; [2019-01-29 09:54:59.693] [alevinLog] [info] # Barcodes Used: 902561 / 912145.; [2019-01-29 09:55:04.490] [alevinLog] [info] Knee found left boundary at 391 ; [2019-01-29 09:55:04.817] [alevinLog] [info] Gauss Corrected Boundary at 99 ; [2019-01-29 09:55:04.817] [alevinLog] [info] Learned InvCov: 114.535 normfactor: 147.323; [2019-01-29 09:55:04.817] [alevinLog] [info] Total 289(has 190 low confidence) barcodes; [2019-01-29 09:55:04.822] [alevinLog] [info] Done True Barcode Sampling; [2019-01-29 09:55:04.855] [alevinLog] [info] Done populating Z matrix; [2019-01-29 09:55:04.855] [alevinLog] [info] Done indexing Barcodes; [2019-01-29 09:55:04.855] [alevinLog] [info] Total Unique barcodes found: 70316; [2019-01-29 09:55:04.855] [alevinLog] [info] Used Barcodes except Whitelist: 184; [2019-01-29 09:55:04.882] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify. [2019-01-29 09:55:04.882] [alevinLog] [info] parsing read library format; [2019-01-29 09:55:05.014] [stderrLog] [info] Loading Suffix Array ; [2019-01-29 09:55:04.882] [jointLog] [info] There is 1 library.; [2019-01-29 09:55:05.012] [jointLog] [info] Loading Quasi index; [2019-01-29 09:55:05.013] [jointLog] [info] Loading 32-bit quasi index; [2019-01-29 09:55:06.105] [stderrLog] [info] Load,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/337#issuecomment-458481722:2023,Learn,Learned,2023,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/337#issuecomment-458481722,1,['Learn'],['Learned']
Usability,"here, for instance. What do the flags and qualities represent?. It is just a SAM file without CIGAR strings. The flags have the same (normal) interpretation for SAM records. However the CIGAR strings are not meaningful (apart from what is required for the file to undergo valid processing with samtools). The records additionally contain tags about the number of targets to which a fragment multi-maps, and the alignment score of the read pair to the current target (in the `AS` flag). The records themself are just normal SAM records, but with a trivial CIGAR strong. > More importantly, is there a way to filter the pseudobam files to find the reads corresponding to the counts/NumReads in the quant.sf output file? Do the normal samtools quality and flag filters work to subset e.g. uniquely-mapped reads, or do those concepts not really apply to these pseudobams?. There is no easy way to filter so the above condition is satisfied, as the NumReads are obtained by proportional allocation of the reads according to the underlying probabilistic model of salmon. Specifically, the NumReads column of the quantification file corresponds to summing over the _expectation_ of all of the latent variables that represent fragment to transcript assignment so that, apart from uniquely-mapped reads, there is no way to say that a fragment _definitely_ came from a transcript. However, you should still be able to easily filter out uniquely mapped reads, and you can interpret them in a relatively unambiguous way. Also, you could filter on the `AS` tag as well. For a given read, if there is a single transcript where the `AS` value is much larger than the others for this read, it is overwhelmingly likely that the read originated from the transcript with the unique best `AS` score. @shangguandong1996 : The SAM file _does_ contain positions (and orientations, and alignment scores) for each read. It is simply that the positions are with respect to the transcriptome and not with respect to the genome.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/528#issuecomment-639065653:3146,simpl,simply,3146,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/528#issuecomment-639065653,2,['simpl'],['simply']
Usability,"how the data are processed that is worth being aware of before you write such samples off. * There is a change in default behavior between salmon < 0.13 and >= 0.13 with which mappings are considered as ""concordant"" and therefore used for quantification by default. Specifically, starting with 0.14, ""dovetail"" alignments [(as described in the Bowtie2 manual)](http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-dovetail) are considered discordant. This is the same default behavior imposed by Bowtie2. If you look in the `meta_info.json` file for some of these samples (which is in the `aux_info` subdirectory of the quantification directory for a sample), you can see how many mappings are being discarded by virtue of being dovetail mappings. It is possible to allow such alignments (consider them as concordant) by passing the `--allowDovetail` flag. It is not the case that such alignments are always ""bad"", its simply that one would not expect many fragments to align in such a way, and if these constitute the overwhelming majority of the mappings, one might be suspicious about the underlying data. * Selective alignment actually _aligns_ the reads to the transcriptome. For this purpose, it performs end-to-end alignment. This means that if you suspect that the sample may contain adapters or very low-quality read ends, the reads should be trimmed prior to quantification. It is, therefore, worth checking how the mapping rate changes for some of these samples if the reads are trimmed first. * Selective alignment is more robust than quasi-mapping to the chosen value of `-k`, the minimum match length used when searching for alignments. I noticed that some of the samples contain relatively short reads, so you might see if the mapping rate changes if you adopt a smaller value of `-k` in the index (e.g. we use `23` in the [pre-print](https://www.biorxiv.org/content/10.1101/657874v2.full.pdf)). * You mention that this index doesn't contain any decoy sequence. This ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/482#issuecomment-582734798:2407,simpl,simply,2407,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/482#issuecomment-582734798,2,['simpl'],['simply']
Usability,"ias in the current salmon version, but if I run all the models together like --gcBias --seqBias --posBias, it completes fine. ~~Do you have a small example (ref / read pair) that reproduces this? It would be great to figure out why and fix it. We could split that into a new issue if you'd rather.~~. P.S. Nevermind; thanks to you mentioning this, I was able to track it down and fix it in develop!. > As I understand the selective alignment, the alignment scores are passed to the quantification step, but the position of the reads is not used downstream. . Well, yes and no. We make extensive use of the position when estimate the implied fragment length (distance between paired end reads) and then model the conditional probability of this fragment based on the global fragment length distribution. This is just as much as is done by e.g. RSEM. However, you are right that there is no notion of using the coverage profile in estimation (more on this below)!. > Also, my intuition for these transcripts is not really a coverage ""bias"" . My intuition agrees with yours here completely. First, this isn't really a coverage bias as we use the normal definition of the term. Second, the positional bias modeling in salmon is not on a per-transcript level (since that would be an astronomical number of different parameters to learn, and any procedure would almost certainly overfit). Instead, it groups transcripts into length bins, and learns a distinct coverage bias model per-bin. > It would be neat if Salmon could detect these kinds of dramatic dropoffs and add a warning or something... even if not incorporating the information into the quants... it could even be a good QC step to identify large deletions/insertions over a gene body. As far as I know, there are NO rnaseq quant programs that would handle this, because even something like a STAR -> RSEM pipeline just projects read counts to the transcriptome and doesn't incorporate the coverage information. These are **great** points! A cou",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-623047035:1113,intuit,intuition,1113,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-623047035,2,['intuit'],['intuition']
Usability,"ion](https://github.com/Kingsford-Group/sad) (paper [here](https://www.cell.com/cell-systems/pdf/S2405-4712(19)30381-3.pdf)). This is sort of akin to what you are suggesting, and post-processes salmon output by looking for anomalous coverage profiles. It can both flag ""suspicious"" transcripts, and can also sometimes move reads around to mitigate anomalous coverage. Another tool / metric you might consider is the junction coverage compatibility (paper [here](https://www.life-science-alliance.org/content/2/1/e201800175)). While both of these approaches get at some of the core intuitions you raise in your response, they are both rather ""heavyweight"", and neither, of course, is built into salmon. So, I **completely agree** that a lightweight version of something like SAD would be great to have built _into_ salmon. Specifically, it makes a lot of sense to have some component of the likelihood account for the coverage profile of transcripts. While I don't know of any widely-used and actively maintained quantification tools that do this, the idea for this was proposed in the [iReckon paper](https://www.ncbi.nlm.nih.gov/pubmed/23204306) and a coverage-based heuristic was introduced. However, the coverage was not directly incorporated into the likelihood. Rather, a variant of the normal likelihood function was used and then coverage was used to select between different potential solutions that were otherwise of similar likelihood. Given issues like the one you see here, and the ones that we observed in the JCC paper and that Cong and Carl observed in the SAD paper, it seems clear that it would be a big win for a quantification tool to include some sort of built-in lightweight model for things like this. The big questions are (1) how do you fold this type of intuition formally into the probabilistic model and (2) is it possible to incorporate this information efficiently? I'm _very_ interested in pursuing something like this if it can be made to work efficiently. Thanks!; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-623047035:3922,clear,clear,3922,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-623047035,4,"['clear', 'intuit']","['clear', 'intuition']"
Usability,"it's not clear if the right fix is to pin the boost version [here](https://github.com/bioconda/bioconda-recipes/blob/master/recipes/salmon/meta.yaml), or just to go with the ""always use conda-forge on installs"" strategy in the documentation. I will consult with experts.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/480#issuecomment-579829090:9,clear,clear,9,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/480#issuecomment-579829090,2,['clear'],['clear']
Usability,"jointLog] [info] Loading Quasi index; [2018-12-06 11:16:56.294] [jointLog] [info] Loading 32-bit quasi index; [2018-12-06 11:16:56.205] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify. [2018-12-06 11:16:56.218] [alevinLog] [info] parsing read library format; [2018-12-06 11:16:56.296] [stderrLog] [info] Loading Suffix Array ; [2018-12-06 11:16:56.846] [stderrLog] [info] Loading Transcript Info ; [2018-12-06 11:16:57.009] [stderrLog] [info] Loading Rank-Select Bit Array; [2018-12-06 11:16:57.046] [stderrLog] [info] There were 167,268 set bits in the bit array; [2018-12-06 11:16:57.063] [stderrLog] [info] Computing transcript lengths; [2018-12-06 11:16:57.064] [stderrLog] [info] Waiting to finish loading hash; [2018-12-06 11:17:00.929] [jointLog] [info] done; [2018-12-06 11:17:00.929] [jointLog] [info] Index contained 167,268 targets. processed 267 Million fragmentsrrLog] [info] Done loading index; hits: 844899161, hits per frag: 3.15864^[[D. [2018-12-06 11:45:12.188] [jointLog] [info] Computed 118,295 rich equivalence classes for further processing; [2018-12-06 11:45:12.188] [jointLog] [info] Counted 154,595,094 total reads in the equivalence classes ; [2018-12-06 11:45:12.188] [jointLog] [warning] Found 115077 reads with `N` in the UMI sequence and ignored the reads.; Please report on github if this number is too large; [2018-12-06 11:45:12.188] [jointLog] [info] Mapping rate = 57.7821%. [2018-12-06 11:45:12.188] [jointLog] [info] finished quantifyLibrary(); [2018-12-06 11:45:13.385] [alevinLog] [info] Starting optimizer. Analyzed 5344 cells (100% of all).; [2018-12-06 11:49:42.634] [alevinLog] [info] Total 4845644.00 UMI after deduplicating.; [2018-12-06 11:49:42.722] [alevinLog] [info] Clearing EqMap; Might take some time.; [2018-12-06 11:49:47.400] [alevinLog] [info] Starting Import of the gene count matrix of size 5344x167268.; Exception : [std::bad_alloc]; alevin was invoked improperly.; For usage information, try alevin --help; Exiting.; ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/328#issuecomment-445008548:7766,Clear,Clearing,7766,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/328#issuecomment-445008548,1,['Clear'],['Clearing']
Usability,"l have neighboring genomic DNA). I wanted to see how this ratio changes between samples (for example, in a snoRNA processing-defective mutant strain), but quickly realized this is not easily done in salmon or any other quant tools because the processed transcript is entirely a subset of the sequence of the pre-processed transcript. The only way to accurately quantify it is to use the coverage information, which as you agreed is not really taken into account downstream. If Salmon could incorporate the coverage information to solve this class of problem, that would indeed be a **huge win**. I think the ncRNA example would be both a great biologically-interesting motivating problem, as well as a good technical benchmark for implementing any new methods. It could even be used as a secondary RNA velocity measure in scRNA seq data, provided the method used can detect these (non-polyadenylated) transcripts. > The big questions are (1) how do you fold this type of intuition formally into the probabilistic model and (2) is it possible to incorporate this information efficiently?. This is definitely your domain of expertise (and I know it's a rhetorical question but I'd love to throw some ideas out here)... I can think of a few mostly heuristical approaches.... . 1) when apportioning reads to transcripts, after the mapping phase, incorporate a notion of ""evenness"" into the EM step... reads that decrease the variance in coverage are favored over reads that increase the variance (so, define read depth per 10 bp window or something and calculate the variance across all windows for the transcript, then try to assign reads such that they minimize read depth variance per isoform). The problem here is actual coverage biases may then masquerade as alternative transcript isoforms... 2) Use the information from the unique sequences between the transcripts... the read depth over unique regions updates the prior on the overall transcript abundance, and the otherwise non-unique reads get ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-623963851:2510,intuit,intuition,2510,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-623963851,2,['intuit'],['intuition']
Usability,ld is just the GNU linker.; I still think it's not able to find the zlib **library** file since the error at `-lz` where `-l` gives the namespace of the library.; If you are confident about the inclusion of the `Zlib` then can you try clearing the cmake cache (i.e. remove the file CMakeCache.txt) and build again?,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/141#issuecomment-314430634:235,clear,clearing,235,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/141#issuecomment-314430634,2,['clear'],['clearing']
Usability,"mon for mapping and quantification, there is a separate background thread that simply consumes reads from file and puts them in memory for quantification, and while e.g. pairing information between files is guaranteed to be preserved, exact read order is not. This can lead to differences in the order in which reads are processed and, as a result, differences in the initialization conditions of the optimization. The ultimate result is that for transcripts that have large inferential uncertainty, different numbers of reads can be assigned between runs. We have thought *a lot* about this behavior, what it means, and how the `NumRead` values should best be communicated to users. At the end of the day, the `NumReads` constitute the expected value of latent variables inferred in a _very_ high-dimensional space (# of parameters is at least the number of transcripts). Therefore, there are certain transcripts, whose estimated number of reads simply have _tremendous_ inferential uncertainty — and small perturbations in the initial conditions of the optimization will lead to different estimated values for their abundances. For those transcripts where you observe such fluctuations between runs, this is simply evidence that the precision that can be confidently placed on those estimates is below the degree of variation you observe. Treating these transcripts in downstream analysis as more certain can easily lead to spurious inferences regarding things like differential transcript expression or usage. . One can make an argument for trying to provide a way to enforce removal of this variation (which, granted, would be a challenge). However, the reason we decided against even attempting this is because it doesn't properly address any issue with respect to an actual biological analysis. That is, even if you could fix, precisely, the update order and initialization conditions for a specific sample to eliminate any variation between runs, almost all experiments consist of multiple samp",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/613#issuecomment-757989858:1753,simpl,simply,1753,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/613#issuecomment-757989858,2,['simpl'],['simply']
Usability,"mple - this is confusing to explain in text format, but all comes down to the sequential nature of how the cells acquire barcodes in this protocol. We start with a 96-well plate, where each of the top 48 wells contain BOTH an oligo-dT barcode and random hexamer barcode. The samples then get added to each well. Biochemistry happens. Then you pool all the cells together, split them back out into 48 wells again, and each well gets its own BC2. Then repeat for BC3. . So a given transcript may get amplified via one of two amplification primers (oligo-dT or random hexamer), but after that, will get a single BC2 sequence and BC3 sequence added after that. In Fig 1A of the Rosenberg paper, it's as though there isn't _just_ an orange sequence carrying out reverse transcription, there are actually two different (known) sequences associated with different routes of amplification per cell. . The net effect is that a given cell can contain transcripts that have a sequence like this:; AACGTGAT-CTGTAGCC-ACACAGAA. or like this:; GATAGACA-CTGTAGCC-ACACAGAA. where maybe the first sequence was amplified by oligo-dT and the second was amplified via a random hexamer. Because they have the same BC2 and BC3 sequence, and the BC1 sequences match a known pairing, we know they come from the same cell and therefore the data should be merged. . Any lab running these experiments will have a table of known pairings (ie the two barcodes added to each of first 48 wells), so that they can be merged and treated as though they came from the same cell. This can either be handled upstream of salmon/alevin as a preprocessing step, like what my slow perl script can do, or it can be handled internally. Having alevin do the collapsing would likely be a lot faster and means the FASTQs don't need any editing, which would be preferable, but I would understand if that is out of scope for you all. . Hopefully that explanation is clear, but if you have any other questions on this I'd be happy to meet and discuss",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-937918722:2333,clear,clear,2333,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-937918722,2,['clear'],['clear']
Usability,"nfo] Total Unique barcodes found: 604589; > [2020-06-04 17:56:29.557] [alevinLog] [info] Used Barcodes except Whitelist: 88156; > [2020-06-04 17:56:30.294] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify; > ; > [2020-06-04 17:56:30.294] [alevinLog] [info] parsing read library format; > [2020-06-04 17:57:36.339] [alevinLog] [info] Starting optimizer; > ; > ; > [2020-06-04 17:57:37.051] [alevinLog] [warning] mrna file not provided; using is 1 less feature for whitelisting; > [2020-06-04 17:57:37.051] [alevinLog] [warning] rrna file not provided; using is 1 less feature for whitelisting; > [2020-06-04 17:57:37.338] [alevinLog] [info] Total 23937.00 UMI after deduplicating.; > [2020-06-04 17:57:37.338] [alevinLog] [info] Total 91 BiDirected Edges.; > [2020-06-04 17:57:37.338] [alevinLog] [info] Total 82 UniDirected Edges.; > [2020-06-04 17:57:37.338] [alevinLog] [warning] Skipped 82268 barcodes due to No mapped read; > [2020-06-04 17:57:37.341] [alevinLog] [info] Clearing EqMap; Might take some time.; > [2020-06-04 17:57:37.348] [alevinLog] [warning] Num Low confidence barcodes too less 1 < 10.Can't performing whitelisting; Skipping; > [2020-06-04 17:57:37.348] [alevinLog] [info] Finished optimizer; > ; > . salmon_quant.log. > [2020-06-04 17:55:11.700] [jointLog] [info] setting maxHashResizeThreads to 7; > [2020-06-04 17:55:11.700] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; > [2020-06-04 17:55:11.700] [jointLog] [info] The --mimicBT2, --mimicStrictBT2 and --hardFilter flags imply mapping validation (--validateMappings). Enabling mapping validation.; > [2020-06-04 17:55:11.700] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; > [2020-06-04 17:55:11.700] [jointLog] [info] The use of range-factorized equivalence classes does not make sense in conjunction with --hardFilter. Disabling range-factorized equiva",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-639196415:2429,Clear,Clearing,2429,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-639196415,1,['Clear'],['Clearing']
Usability,"ng 32-bit quasi index; [2019-01-29 09:56:54.551] [stderrLog] [info] Loading Transcript Info ; [2019-01-29 09:56:54.826] [stderrLog] [info] Loading Rank-Select Bit Array; [2019-01-29 09:56:54.883] [stderrLog] [info] There were 80,511 set bits in the bit array; [2019-01-29 09:56:54.908] [stderrLog] [info] Computing transcript lengths; [2019-01-29 09:56:54.908] [stderrLog] [info] Waiting to finish loading hash; [2019-01-29 09:57:09.336] [stderrLog] [info] Done loading index; [2019-01-29 09:57:09.336] [jointLog] [info] done; [2019-01-29 09:57:09.336] [jointLog] [info] Index contained 80,511 targets. processed 2 Million fragments; hits: 812181, hits per frag: 0.326777. [2019-01-29 09:57:36.647] [alevinLog] [info] Starting optimizer; [2019-01-29 09:57:36.587] [jointLog] [info] Computed 12,933 rich equivalence classes for further processing; [2019-01-29 09:57:36.587] [jointLog] [info] Counted 242,520 total reads in the equivalence classes ; [2019-01-29 09:57:36.601] [jointLog] [warning] Only 242520 fragments were mapped, but the number of burn-in fragments was set to 5000000.; The effective lengths have been computed using the observed mappings. [2019-01-29 09:57:36.601] [jointLog] [info] Mapping rate = 8.94141%. [2019-01-29 09:57:36.601] [jointLog] [info] finished quantifyLibrary(). Analyzed 293 cells (100% of all).; [2019-01-29 09:57:40.090] [alevinLog] [info] Total 206902 UMI after deduplicating.; [2019-01-29 09:57:40.091] [alevinLog] [warning] Skipped 71 barcodes due to No mapped read; [2019-01-29 09:57:40.110] [alevinLog] [info] Clearing EqMap; Might take some time.; [2019-01-29 09:57:40.176] [alevinLog] [info] Starting Import of the gene count matrix.; [2019-01-29 09:57:41.168] [alevinLog] [info] Done Importing gene count matrix for dimension 222x19879; [2019-01-29 09:57:41.168] [alevinLog] [info] Starting dumping cell v gene counts in csv format; Segmentation fault (core dumped); ```. I then installed through conda salmon=0.12.0. Both times it failed with core dump.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/337#issuecomment-458481722:9901,Clear,Clearing,9901,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/337#issuecomment-458481722,1,['Clear'],['Clearing']
Usability,"ng of these considerations. It’s good to think about how data processing choices may affect your results and you are being thoughtful here. I wouldn’t say that, generally, alignment-free tools are more accurate than alignment-based ones. For example, you might look at our recent paper on how [alignment and mapping methodology can influence abundance estimation even when holding the quantification approach fixed](https://genomebiology.biomedcentral.com/articles/10.1186/s13059-020-02151-8), or [this paper on the corner cases of alignment-free methodology](https://bmcgenomics.biomedcentral.com/articles/10.1186/s12864-018-4869-5) (note the second paper pre-dates the first, and the new selective-alignment methodology in salmon should largely address the issues raised in that paper). However, the bigger and more meaningful distinction is between methods that attempt to properly quantify abundance (generally using a generative statistical model) — including methods like RSEM, BitSeq, salmon, etc., and those that try to simply count aligned reads — including methods like HTSeq and featureCounts. Generally, the former type of methods are more accurate than the latter at both the gene level and the former can also offer transcript-level estimates if desired (counting based methods generally cannot). Finally, to your question more directly, I don’t believe that model misspecification that may result due to not knowing the fragment length distribution will generally have enough of a deleterious effect on the probabilistic quantification methods to degrade their performance to the level of counting based methods. I would still argue to prefer probabilistic quantification (i.e. salmon) to read counting, even if you don’t know the fragment length distribution. As I mentioned above, it may change the maximum likelihood estimates a bit, but should do so across all samples, hopefully minimizing the downstream effects on differential analysis. Good luck with your analysis!. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/127#issuecomment-750943952:1081,simpl,simply,1081,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/127#issuecomment-750943952,2,['simpl'],['simply']
Usability,ntification) v0.11.3; ### [ program ] => salmon ; ### [ command ] => alevin ; ### [ libType ] => { ISR }; ### [ mates1 ] => { big.fastq.1.gz }; ### [ mates2 ] => { big.fastq.2.gz }; ### [ chromium ] => { }; ### [ index ] => { geneset.dir/geneset_coding_exons.salmon.index/ }; ### [ output ] => { salmon.dir/ }; ### [ tgMap ] => { transcript2geneMap.tsv }; ### [ dumpCsvCounts ] => { }. [2019-01-29 09:56:37.731] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2019-01-29 09:56:37.749] [alevinLog] [info] Processing barcodes files (if Present) . ; processed 2 Million barcodes. [2019-01-29 09:56:43.029] [alevinLog] [info] Done barcode density calculation.; [2019-01-29 09:56:43.029] [alevinLog] [info] # Barcodes Used: 2695632 / 2712324.; [2019-01-29 09:56:52.900] [alevinLog] [info] Knee found left boundary at 692 ; [2019-01-29 09:56:53.219] [alevinLog] [info] Gauss Corrected Boundary at 100 ; [2019-01-29 09:56:53.219] [alevinLog] [info] Learned InvCov: 114.414 normfactor: 148.807; [2019-01-29 09:56:53.219] [alevinLog] [info] Total 293(has 193 low confidence) barcodes; [2019-01-29 09:56:53.224] [alevinLog] [info] Done True Barcode Sampling; [2019-01-29 09:56:53.254] [alevinLog] [info] Done populating Z matrix; [2019-01-29 09:56:53.255] [alevinLog] [info] Done indexing Barcodes; [2019-01-29 09:56:53.255] [alevinLog] [info] Total Unique barcodes found: 125401; [2019-01-29 09:56:53.255] [alevinLog] [info] Used Barcodes except Whitelist: 1256; [2019-01-29 09:56:53.281] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify. [2019-01-29 09:56:53.281] [alevinLog] [info] parsing read library format; [2019-01-29 09:56:53.412] [stderrLog] [info] Loading Suffix Array ; [2019-01-29 09:56:53.281] [jointLog] [info] There is 1 library.; [2019-01-29 09:56:53.410] [jointLog] [info] Loading Quasi index; [2019-01-29 09:56:53.411] [jointLog] [info] Loading 32-bit quasi index; [2019-01-29 09:56:54.551] [stderrLog] [info] Lo,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/337#issuecomment-458481722:7420,Learn,Learned,7420,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/337#issuecomment-458481722,1,['Learn'],['Learned']
Usability,"okies, I think I see the issue. So look at the following lines in the log:; ```; [2019-06-17 21:21:44.518] [alevinLog] [info] Total 824863; [2019-06-17 21:22:47.680] [alevinLog] [info] Total Unique barcodes found: 3474567; ```; What it means is alevin found total: `3,474,567` unique CB in the whole sample and keeps `824,863` CB for further processing which is ~23% of the CB. So all the `keepCBFraction` values above 0.23 would have no effect. If you wan't to generate the `whitelist.txt`, alevin has to have some low confidence CB to learn from, so I am guessing in your case any value from 0.15-0.20 should ideally work. Having said that, I am still exploring why even setting `freqThreshold` to 0, alevin not considers all `3M` CB for processing, I guess there is some kind of filter which is coming into the picture but I might need a bit more time to explore that. I will update here once I figure it out. Thanks again for raising the issue and investing your time in improving alevin.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/379#issuecomment-503344686:537,learn,learn,537,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/379#issuecomment-503344686,2,['learn'],['learn']
Usability,"on for the problems you are facing in alevin. >Your first question was related to alevin quantifying very less number of reads. To answer that,; if you look at the log, at the first few lines, alevin warns about ~91% of the reads being thrown away because; of the noisy CBs. The problem is alevin’s first “knee"" estimation is overshooting in predicting the first boundary. You will find https://github.com/COMBINE-lab/salmon/issues/362 issue to be; very useful in understanding that. As a summary if you look at the plot I attached it has bi-modalities,; which is generally not the case and alevin is greedily finding the threshold at the first ~100 cells. If this; happens the general direction is to help alevin by proving a upper bound, in case of your data; would be ~14000 cells. You can tell alevin with `—expectCells 14000` and alevin start to work; normally and logs ~12% of the data is noisy. >You second question was a little complicated to answer. Seemingly, your salmon index has transcript with; same exact name `ENST00000399966.9`, occurring twice with different sequences. Just by looking at the index,; I am unsure it’s actually present in the reference or its salmon indexing messing up. If I Assume it was actually; present two times in the reference, alevin should report it instead of exiting abruptly in the middle of quantification.; Although, alevin does warns:; ```; [2019-07-04 14:12:32.519] [alevinLog] [warning] Found 1 transcripts with duplicate names; ```; >However, the bug i.e. not being able to distinguish duplicate names of the transcript, has been ; fixed and pushed in the develop branch of salmon. Alevin was reporting the error at the stage of quantification too, ; if you dump the logs in a file, but it was invisible in the console as it was over written my complex progress bar. . >Once I process it through the modified pipeline, alevin finished normally and I am attaching the quants generated; by alevin. >Thanks again for forwarding the data.; Best,; —Avi",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/386#issuecomment-508754845:2022,progress bar,progress bar,2022,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/386#issuecomment-508754845,2,['progress bar'],['progress bar']
Usability,"ort as many use cases as possible but since it involves multiples developers it's hard to know the intrinsic details about every use-case by all the developers. Having said that, salmon is primarily designed for bulk RNA-seq quantification and as the help page you shared says -- `noLengthCorrection` is experimental. . I agree with all three comments above regarding the paper I shared. In fact, that was my reading as well, like I said I am not sure about the intricacies involved with QuantSeq ""technology"" and that's why I forwarded to you for confirming. I understand the difference between Lexogen and Quantseq but what I meant was more data specific knowledge as I _personally_ don't find ""one model fits all"" kind of approach right. I believe, It takes time and understanding to develop a good model for data generated from any technology and that's what we have been trying to do with salmon for years, piece by piece. Having said that, we don't mean to discourage people from trying salmon, that's one of the way we learn how can we improve the model even further. Now, coming back to your original question about using QuantSeq with salmon and how the paper above approach to solve it. I have a couple of thoughts:; 1.) Like you said, from the reading of their command line argument they didn't use the `nolengthcorrection` and I am surprised about the results myself. Since you have experience with the technology, you are best person to explore the difference in using and not using the length correction with salmon, that's why I shared.; 2.) Salmon models the transcript lengths in its quantification model. The basic intuition being longer length transcripts have higher probability of a read being sampled from them and has to be corrected for when using relative count metrices (like TPM) to avoid length bias. The logic behind `noLengthCorrection` is to _not_ correct for length for 3' protocol since we expect all the reads from one end of the transcript and if we do length correc",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-565256512:1206,learn,learn,1206,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-565256512,2,['learn'],['learn']
Usability,"ple_S1_L001_R1_001.fastq -2 ../clean/sample_S1_L001_R2_001.fastq --chromiumV3 -i ../../dna/00.ref_genome/sample/salmon_index_allmRNA -p 40 -o test_alevin_allmRNA --tgMap ../../dna/00.ref_genome/sample/alltxp2gene.tsv`. > [2021-01-25 16:22:09.565] [alevinLog] [info] Found 43030 transcripts(+0 decoys, +0 short and +0 duplicate names in the index); [2021-01-25 16:22:09.615] [alevinLog] [info] Filled with 43030 txp to gene entries; [2021-01-25 16:22:09.620] [alevinLog] [info] Found all transcripts to gene mappings; [2021-01-25 16:22:09.631] [alevinLog] [info] Processing barcodes files (if Present); [2021-01-25 16:26:35.067] [alevinLog] [info] Done barcode density calculation.; [2021-01-25 16:26:35.067] [alevinLog] [info] # Barcodes Used: 188934609 / 188934609.; [2021-01-25 16:26:42.979] [alevinLog] [info] Knee found left boundary at 21; [2021-01-25 16:27:05.707] [alevinLog] [warning] Gauss Prediction 4969 Too far from knee prediction skipping it; [2021-01-25 16:27:05.707] [alevinLog] [info] Learned InvCov: 556.394 normfactor: 9159.58; [2021-01-25 16:27:05.707] [alevinLog] [info] Total 222(has 201 low confidence) barcodes; [2021-01-25 16:27:06.573] [alevinLog] [info] Done True Barcode Sampling; [2021-01-25 16:27:07.383] [alevinLog] [warning] Total **96.7029% reads will be thrown away** because of noisy Cellular barcodes.; [2021-01-25 16:27:07.412] [alevinLog] [info] Done populating Z matrix; [2021-01-25 16:27:07.414] [alevinLog] [info] Total 3667 CB got sequence corrected; [2021-01-25 16:27:07.414] [alevinLog] [info] Done indexing Barcodes; [2021-01-25 16:27:07.414] [alevinLog] [info] Total Unique barcodes found: 3896665; [2021-01-25 16:27:07.414] [alevinLog] [info] Used Barcodes except Whitelist: 3667; [2021-01-25 16:27:07.498] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify; [2021-01-25 16:27:07.498] [alevinLog] [info] parsing read library format; [2021-01-25 16:30:54.542] [alevinLog] [info] Starting optimizer; [2021-01-25 16:30:54.782] [alevinLog] ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/340#issuecomment-766311567:2443,Learn,Learned,2443,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/340#issuecomment-766311567,1,['Learn'],['Learned']
Usability,"ples (or multiple libraries or replicates of the same sample), it is best to run cellranger count on each of the libraries individually, and then pool the results using cellranger aggr. * It looks like they have three different modes to normalize the libraries; > There are three normalization modes:; mapped: (default) Subsample reads from higher-depth libraries until they all have an equal number of confidently mapped reads per cell.; raw: Subsample reads from higher-depth libraries until they all have an equal number of total (i.e. raw, mapping-independent) reads per cell.; none: Do not normalize at all. * Although it's not clear, what do they mean by `equal number of confidently mapped reads per cell`, does it mean median reads per cell ? Like you tried to show in the above plot the distribution can be very uneven. But the part that troubles me more is once `count` information has been generated it has lost the read level information, since we have deduplicated them, then how do they use the read counts to normalize. Unless that is dumped too, not clear. Quoting your text from above:; > Alternatively, could a subsampling covariate be added to the probabilistic quantification model of alevin. I think we can definitely work on correcting the subsampling bias in the probabilistic model of Alevin but we might need a little more understanding of what's going on with the cellranger and why your way of aggregation is not working as intended. Unfortunately, I think we have to dig deeper into the cellranger codebase to really understand that and if possible, might need some subset of the relevant data to replicate your issue and work on improving that. Also, I am wondering, what's your way of checking the batch effect and comparing Alevin and Cellranger aggregation? Just a guess, the tSNE plots of the two samples are separating out very clearly, if possible if you can share the figures and the analysis (may be a notebook) to us, we can help and investigate more thoroughly.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/305#issuecomment-433453155:1745,clear,clear,1745,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/305#issuecomment-433453155,4,['clear'],"['clear', 'clearly']"
Usability,"ranscript_id); anot.pre <- anot.pre[lengths(anot.pre) > 1] %>% range %>% unlist %>% sort # only consider transcripts with > 1 exon. anot.pre$transcript_range <- as.character(anot.pre); anot.pre$gene_id <- anot[match(names(anot.pre), anot$transcript_id), ]$gene_id. # collapse replicate pre-mature transcripts per gene...; names(anot.pre) <- anot.pre$premature_group <- sapply(; split(; names(anot.pre),; paste(anot.pre$gene_id, anot.pre$transcript_range, sep = '_'); ),; paste, collapse = ';'; )[; paste(anot.pre$gene_id, anot.pre$transcript_range, sep = '_'); ]. # ... need to convert GR to data.table before unique because unique method for GR class ignores metadata and rownames; anot.pre <- as.data.table(anot.pre) %>% unique %>% makeGRangesFromDataFrame(., keep.extra.columns = T); names(anot.pre) <- anot.pre$premature_group. ### Read human genome sequence ####; message('Loading genome sequence...'). dna <- readDNAStringSet(filepath = genome.fasta). # simplify chromosome names; names(dna) <- sapply(strsplit(names(dna), ' '), '[', 1). dna <- dna[chromosomes] # subset chrom 1-22, X, Y, MT. ### Read Gencode transcript sequences ####; gencode <- readDNAStringSet(gencode.tx.fasta); names(gencode) <- gsub(; pattern = '\\|.*', replacement = '',; x = names(gencode); ). ### Sample transcripts on + and - strand (and avoid premature transcripts with multiple mature counterparts for simplicity); anot.pre <- anot.pre[order(width(anot.pre), decreasing = F), ]. chosenOnesP <- anot.pre[; strand(anot.pre) == '+' & !grepl(';', anot.pre$premature_group) & anot.pre$premature_group %in% names(gencode) & !duplicated(anot.pre$premature_group) &; anot.pre$premature_group %in% anot[anot$transcript_source == 'ensembl_havana']$transcript_id; ]$premature_group[1]. chosenOnesM <- anot.pre[; strand(anot.pre) == '-' & !grepl(';', anot.pre$premature_group) & anot.pre$premature_group %in% names(gencode) & !duplicated(anot.pre$premature_group) &; anot.pre$premature_group %in% anot[anot$transcript_source =",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/655#issuecomment-826035191:5783,simpl,simplify,5783,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/655#issuecomment-826035191,2,['simpl'],['simplify']
Usability,"re being discarded because they have no alignment to annotated transcripts above the minimum allowable score, and an additional `1,099,008` are being discarded because they have only dovetail mappings. . We discard dovetail mappings by default, but you can admit them with `--allowDovetail`. The other `2,776,678` fragments are discarded because, though there are seeds for mapping that match, they do not have sufficiently high alignment score to be allowed for mapping. This default behavior, too, can be modified. The main flags that affect the behavior here are `--minScoreFraction`, where a lower number allows lower-quality alignments through and also the `--softclipOverhangs` flag which will decrease the penalty on alignments that overhang the end of an annotated transcript. However, it's worth noting that this is up to `3,875,686` more reads that might be mappable. This number is non-trivial, but quite far from the 90% rate of STAR. The rest of the reads, however, simply don't have support for alignment against the annotated transcriptome. **This suggests to me that STAR is probably aligning a lot of reads outside of annotated genes**. If you build the salmon index [using a full decoy of the genome](https://combine-lab.github.io/alevin-tutorial/2019/selective-alignment/), then you might be able to evaluate intergenic mapping in the output in terms of `Number of fragments discarded because they are best-mapped to decoys`. However, in that case, these reads still won't contribute to transcript expression, as they do not align to annotated transcripts. Finally, if you suspect these reads might be coming from genes expressed in your sample but not present in the annotation, you might consider performing a transcript assembly on your data, using a tool like [scallop2](https://github.com/Shao-Group/scallop2) or [stringtie](https://github.com/gpertea/stringtie). Best,; Rob. P.S. I'm closing the thread, since I think the above answers your direct question, but please feel fr",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/775#issuecomment-1126361719:1039,simpl,simply,1039,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/775#issuecomment-1126361719,2,['simpl'],['simply']
Usability,"script set and the vector of conditional probability bins into which the mapping falls with respect to each transcript in the equivalence class. This means that range-factorized equivalence classes can have multiple classes of fragments that map to the same set of transcripts, but with different conditional probabilities. Additionally, for each bin, the average conditional probability of fragments arising from that bin is maintained. What you are seeing printed out are the transcript sets, followed by the conditional bin indexes. Starting in the next release (and currently in the develop branch), we've cleaned up the interaction of the range-factorized equivalence classes with the `--dumpEq` and `--dumpEqWeights` flags. If you run with the `--dumpEqWeights` flags, salmon will dump the transcript sets, followed by the conditional probability vector, followed by the fragment count. If you run with the `--dumpEq` flag, it will collapse all of the range-factorized equivalence classes into ""simple"" equivalence classes by combining classes with the same transcript set (but different conditional probability vectors) and summing the corresponding fragment counts. This, of course, is a lossy transformation, and the equivalence classes will no longer represent the relevant conditional probabilities used during inference. Also, since the range-factorized equivalence classes allow for (but probabilistically down-weight) non-optimal mappings of fragments to transcripts, these collapsed equivalence classes will tend to have bigger labels (i.e. more transcripts) which might be difficult to properly interpret without the relevant conditional probabilities. The `--hardFilter` flag will filter out transcripts that have non-best alignment scores (a big component of the conditional fragment probability), but that can have a negative effect on the modeling and inference. We'll update the documentation accordingly when we cut the next release to make all of these interactions more clear.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/402#issuecomment-517041654:1906,simpl,simple,1906,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/402#issuecomment-517041654,4,"['clear', 'simpl']","['clear', 'simple']"
Usability,"sue if you'd rather.~~. P.S. Nevermind; thanks to you mentioning this, I was able to track it down and fix it in develop!. > As I understand the selective alignment, the alignment scores are passed to the quantification step, but the position of the reads is not used downstream. . Well, yes and no. We make extensive use of the position when estimate the implied fragment length (distance between paired end reads) and then model the conditional probability of this fragment based on the global fragment length distribution. This is just as much as is done by e.g. RSEM. However, you are right that there is no notion of using the coverage profile in estimation (more on this below)!. > Also, my intuition for these transcripts is not really a coverage ""bias"" . My intuition agrees with yours here completely. First, this isn't really a coverage bias as we use the normal definition of the term. Second, the positional bias modeling in salmon is not on a per-transcript level (since that would be an astronomical number of different parameters to learn, and any procedure would almost certainly overfit). Instead, it groups transcripts into length bins, and learns a distinct coverage bias model per-bin. > It would be neat if Salmon could detect these kinds of dramatic dropoffs and add a warning or something... even if not incorporating the information into the quants... it could even be a good QC step to identify large deletions/insertions over a gene body. As far as I know, there are NO rnaseq quant programs that would handle this, because even something like a STAR -> RSEM pipeline just projects read counts to the transcriptome and doesn't incorporate the coverage information. These are **great** points! A couple of thoughts. First, you are right that salmon, RSEM, etc. don't use coverage information in the way you describe here. One piece of software you might look into is [Salmon Anomaly Detection](https://github.com/Kingsford-Group/sad) (paper [here](https://www.cell.com/cell-sy",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-623047035:1464,learn,learn,1464,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-623047035,2,['learn'],['learn']
Usability,"thanks. From: Rob Patro ***@***.***>; Reply-To: COMBINE-lab/salmon ***@***.***>; Date: Thursday, May 6, 2021 at 1:53 PM; To: COMBINE-lab/salmon ***@***.***>; Cc: ""andrew e. davidson"" ***@***.***>, Mention ***@***.***>; Subject: Re: [COMBINE-lab/salmon] salmon --writeUnmappedNames produced undocumented result (#657). Hi @aedavids<https://github.com/aedavids>,. Thanks for catching that this is undocumented! This means that the mapping type was determined as mapping to a decoy sequence. When we added this output into the code, the documentation wasn't updated accordingly. We'll update the documentation. Best,; Rob. —; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://github.com/COMBINE-lab/salmon/issues/657#issuecomment-833857753>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AN3VWAQ35L6PU3DKXYIM4ODTML6TPANCNFSM44HLOFXQ>.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/657#issuecomment-833861332:290,undo,undocumented,290,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/657#issuecomment-833861332,4,['undo'],['undocumented']
Usability,"the case for reads from unspliced pre-mRNAs that are even extending a small fraction into the introns (hence better scoring on the decoys). The 2 FASTQ files for one of the samples I was describing above can be found as R4171*.fastq.gz at this globus link: http://research.libd.org/globus/jhpce_bsp2-dlpfc/index.html. I used just the main chromosomes with Gencode v41 annotation (slightly ""curated"" to remove read-through and ""retained intron"" annotated transcripts). I am attaching 3 `meta_info.json` outputs for the 3 ways I ran salmon on this sample:. - [tx_only.meta_info.json.gz](https://github.com/COMBINE-lab/salmon/files/11006627/tx_only.meta_info.json.gz) : no decoys, **without** `--validateMappings`; - [gentrome_full.meta_info.json.gz](https://github.com/COMBINE-lab/salmon/files/11006628/gentrome_full.meta_info.json.gz) : with `--validateMappings`, decoys are full chromosome sequences appended to the transcripts file, ; - [gentrome_mashed.meta_info.json.gz](https://github.com/COMBINE-lab/salmon/files/11006629/gentrome_mashed.meta_info.json.gz) : with `--validateMappings`, decoys prepared with mashmap as instructed [here](https://github.com/COMBINE-lab/SalmonTools/blob/master/README.md). It would be great to be able to use Salmon's ""wicked fast"" mapping engine to estimate intronic and intergenic reads at the same time, so I'm considering to make better use of the `writeMappings` output for that purpose, by preparing the decoys in a specific way (extracting intronic and intergenic sequences as distinctively labeled decoys and count the mappings to each label from Salmon's SAM output -- would that work?). I am wondering, due to pre-mRNAs found in rRNA-depletion (ribo-zero) samples, it might be better to artifically add the unspliced transcripts into the mix along with the ""reference"" annotation transcripts, so they also get quantified during the EM-guided probabilistic distribution of reads across this mix of pre-mRNAs + mature RNAs in each locus.. What do you think?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/779#issuecomment-1474451463:1938,guid,guided,1938,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/779#issuecomment-1474451463,2,['guid'],['guided']
Usability,"thubusercontent.com/10292386/86509800-6b8bdf80-bd9f-11ea-9a9f-bbfea99e2703.png); <img width=""485"" alt=""KCC4_table"" src=""https://user-images.githubusercontent.com/10292386/86509801-6d55a300-bd9f-11ea-9c69-8e269fc3ab1c.png"">. In this example, there are two regions in KCC4 with obviously different coverage. Ideally we would be able to have a default KCC4 transcript and a truncated isoform in the salmon index, and it would assign the reads appropriately, even though all of the reads that map to the truncated form would also multimap to the long form. Again, you can see in the table that salmon assigns reads parsimoniously to both transcripts with the default options, but with the length bias modeling turned off ALL of the reads are assigned to the long transcript. I also added a third transcript to the right end of the transcript which is inconsistent with the coverage profile and, as hoped, salmon did not assign any reads to that variant. So, in these two scenarios the default options produce nice results in line with our human intuition. 2. **Failure scenario with default options:** ; ![PDI1_example](https://user-images.githubusercontent.com/10292386/86509895-3df36600-bda0-11ea-8f0b-df0de4fefa31.png); <img width=""383"" alt=""PDI1_table"" src=""https://user-images.githubusercontent.com/10292386/86509897-40ee5680-bda0-11ea-9566-9f2bdab464f0.png"">. In this example there are four genes (oriented in the same direction) with wildly different expression levels. I added a ""PDI1_SuperTranscript"" which stretches from the 5' end of PDI1 to the 3' end of POF1 (so, all reads from all 4 genes would multimap to the super transcript). This is a contrived example to illustrate the technical details, but you could imagine similar biological scenarios, especially regarding splicing isoforms. With the default options, you get the counterintuitive result that all of the reads from just MGR1 and POF1 (the two lowest abundance transcripts) are assigned to the super transcript. EMC1 loses ~50% o",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-653747847:5122,intuit,intuition,5122,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-653747847,2,['intuit'],['intuition']
Usability,"together like --gcBias --seqBias --posBias, it completes fine. ~~Do you have a small example (ref / read pair) that reproduces this? It would be great to figure out why and fix it. We could split that into a new issue if you'd rather.~~. P.S. Nevermind; thanks to you mentioning this, I was able to track it down and fix it in develop!. > As I understand the selective alignment, the alignment scores are passed to the quantification step, but the position of the reads is not used downstream. . Well, yes and no. We make extensive use of the position when estimate the implied fragment length (distance between paired end reads) and then model the conditional probability of this fragment based on the global fragment length distribution. This is just as much as is done by e.g. RSEM. However, you are right that there is no notion of using the coverage profile in estimation (more on this below)!. > Also, my intuition for these transcripts is not really a coverage ""bias"" . My intuition agrees with yours here completely. First, this isn't really a coverage bias as we use the normal definition of the term. Second, the positional bias modeling in salmon is not on a per-transcript level (since that would be an astronomical number of different parameters to learn, and any procedure would almost certainly overfit). Instead, it groups transcripts into length bins, and learns a distinct coverage bias model per-bin. > It would be neat if Salmon could detect these kinds of dramatic dropoffs and add a warning or something... even if not incorporating the information into the quants... it could even be a good QC step to identify large deletions/insertions over a gene body. As far as I know, there are NO rnaseq quant programs that would handle this, because even something like a STAR -> RSEM pipeline just projects read counts to the transcriptome and doesn't incorporate the coverage information. These are **great** points! A couple of thoughts. First, you are right that salmon, RSEM, etc. ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-623047035:1182,intuit,intuition,1182,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-623047035,2,['intuit'],['intuition']
Usability,"too many mismatches |	0; % of reads unmapped: too many mismatches |	0.00%; Number of reads unmapped: too short |	0; % of reads unmapped: too short |	0.00%; Number of reads unmapped: other |	4006; % of reads unmapped: other |	0.00%; CHIMERIC READS:; Number of chimeric reads |	0; % of chimeric reads |	0.00%; ```. It was really better but I am afraid that I have really low quality (I try the parameter 0.3 when I wrote these lines ), I filtered again with samtools -f 2 -F3840 and the salmon counts which is still very low : 24323720 counts. I used samtools flagstat to see what happens after the filter and we get this?; ```; 48983692 + 0 in total (QC-passed reads + QC-failed reads); 0 + 0 secondary; 0 + 0 supplementary; 0 + 0 duplicates; 48983692 + 0 mapped (100.00% : N/A); 48983692 + 0 paired in sequencing; 24491846 + 0 read1; 24491846 + 0 read2; 48983692 + 0 properly paired (100.00% : N/A); 48983692 + 0 with itself and mate mapped; 0 + 0 singletons (0.00% : N/A); 0 + 0 with mate mapped to a different chr; 0 + 0 with mate mapped to a different chr (mapQ>=5); ```. I don't understand why I'm losing so many counts, is it because I'm filtering? But still I have to filter to get the properly pairs... For the sorting it's totally my fault I read the doc wrong but even by not sorting I get very low results not usable less than 26%. The experimentation is done on oak, on 4 times 3 late samples and 3 early samples of dormancy were recovered and we made a TruSeq stranded illumina on these samples. I use a gene model built by my team with the 25808 genes that the oak has as reference. For this part ""Is this a polyA selection or ribosomal depletion prep"" I don't know, I'll find out. To be honest I am totally lost because I don't understand what's wrong in my analysis.... Thank you very much for your help once again . Kisekya. EDIT:. I discover that I have 59 millions of duplicates in my data...; I tried to delete it after filtering my proper pair I get bad records 38% of mapping ...",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/676#issuecomment-874540664:4711,usab,usable,4711,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/676#issuecomment-874540664,2,['usab'],['usable']
Usability,"top is what you get if you sum the abundances of these two transcripts. The main point is that the inferential relative variance (adjusted ratio of the variance over the mean) is _much_ smaller for the sum of these transcripts than for either individually. This is strong evidence that they are _inherently_ uncertain given the read evidence and alignments used for quantification. The tool described in that paper, called [`terminus`](https://github.com/COMBINE-lab/terminus), is a tool for automatically finding such groups of transcripts. Anyway, once you have the Gibbs samples in hand, we can walk you though how to do some assessment of these transcripts (tagging @hiraksarkar here since he's most likely to have access to scripts that will let us look at the posterior samples from individual transcripts). Similarly, if you can provide the quantification directory, we can help examine this too. If this is the case, that the posterior distributions are highly anti-correlated, it is likely that the ambiguity you are seeing is simply inherent given the alignments salmon is being provided. If you have the quantification folder resulting from the same sample using selective alignment, we could compare and contrast the two. At that point, there are a few options depending on how deeply you want to dive. You could try to see how STAR and selective alignment are mapping differently to these transcripts. One potential difference is that STAR is _a lot_ more happy to softclip reads, which selective alignment won't do by default (you can test the effect with the `--softclipOverhangs` to allow selective alignment to softclip reads that hang off the transcript end or `--softclip` to allow softclips anywhere). Note that selective alignment may _still_ be a bit more conservative than STAR about softclips simply because of the nature of the scoring function it uses. This might give you a sense if one of these alignment methodologies is more consistent with your expectations in this case",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/600#issuecomment-740363115:3086,simpl,simply,3086,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/600#issuecomment-740363115,2,['simpl'],['simply']
Usability,"tting the reads 50/50 or, with the default settings, giving nearly all the reads to the longer transcript. I realized that, as a human, the reason the short transcript is obviously the dominant one is how the reads pileup in the alignment. There are hundreds of reads mapping to both transcripts, but NO reads map to the 5' of the long transcript. As I understand the selective alignment, the alignment scores are passed to the quantification step, but the *position* of the reads is not used downstream. In order to pass my human intuition along here, the software would need to pay attention to the coverage bias of the reads mapping to the transcripts and assign a penalty when two otherwise identical transcripts have a different coverage variance across the transcript. This sounds like what the --posBias flag should incorporate into the effective lengths, but it doesn't have much effect on these transcripts for me (FYI, I am getting a segfault when I run only --posBias in the current salmon version, but if I run all the models together like --gcBias --seqBias --posBias, it completes fine). . Also, my intuition for these transcripts is not really a coverage ""bias"" as much as the read depth absolutely plummeting at the 5' end of the long transcript. It would be neat if Salmon could detect these kinds of dramatic dropoffs and add a warning or something... even if not incorporating the information into the quants... it could even be a good QC step to identify large deletions/insertions over a gene body. As far as I know, there are NO rnaseq quant programs that would handle this, because even something like a STAR -> RSEM pipeline just projects read counts to the transcriptome and doesn't incorporate the coverage information. So, for now my workaround is to just modify the transcripts so they are non-overlapping in the transcriptome fasta or to manually count reads after looking at the alignments, but I'd love to hear any more thoughts you have on this problem. Thanks,; Jason",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-623043651:1631,intuit,intuition,1631,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-623043651,2,['intuit'],['intuition']
Usability,"ulty of Arts & Sciences Informatics Group; Harvard University; 38 Oxford St; Cambridge, MA 02138; phone: +001 310 415 7145; ________________________________; From: Rob Patro ***@***.***>; Sent: Sunday, October 29, 2023 11:01 AM; To: COMBINE-lab/salmon ***@***.***>; Cc: Freedman, Adam ***@***.***>; Mention ***@***.***>; Subject: Re: [COMBINE-lab/salmon] anaconda version of salmon outdated, missing decoys option (Issue #895). Hi @adamfreedman<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_adamfreedman&d=DwMCaQ&c=WO-RGvefibhHBZq3fL85hQ&r=MITI_LEJgyr1a24IMFAlSaZIPxMpOUT21T7L3fg4CjA&m=40O3raH84f_BIZ3HF7nqTYSO2FehGrGHL9b7sqT7LIpWZjFmA3BLxNDTHoz420jp&s=kxY9gCLGWZJp-dp7l31S6M5u2RuUTeWXVrKmaydpo5o&e=>,. I think this is just conda being very very very slow (and potentially broken). The following works fine for me (and finishes in ~1 minute):. mamba create -n salmon -c conda-forge -c bioconda salmon=1.10.2. Can you use the mamba resolver in your environment? Conda has become hardly usable over the years, but mamba works quite well as a fast replacement. I'll also note that I swapped the order of conda-forge and bioconda as the docs specify that bioconda should preferably come last in the list of channels. --Rob. —; Reply to this email directly, view it on GitHub<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_COMBINE-2Dlab_salmon_issues_895-23issuecomment-2D1784137337&d=DwMCaQ&c=WO-RGvefibhHBZq3fL85hQ&r=MITI_LEJgyr1a24IMFAlSaZIPxMpOUT21T7L3fg4CjA&m=40O3raH84f_BIZ3HF7nqTYSO2FehGrGHL9b7sqT7LIpWZjFmA3BLxNDTHoz420jp&s=GNiCXqUbJLM16QBJ5PNAqv-rsgDdpCpcvezPXO_riWk&e=>, or unsubscribe<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_notifications_unsubscribe-2Dauth_ADBMMUCOMVRRPOAZQL2EIITYBZVT5AVCNFSM6AAAAAA6UYYPGOVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMYTOOBUGEZTOMZTG4&d=DwMCaQ&c=WO-RGvefibhHBZq3fL85hQ&r=MITI_LEJgyr1a24IMFAlSaZIPxMpOUT21T7L3fg4CjA&m=40O3raH84f_BIZ3HF7nqTYSO2FehGrGHL9b7sqT7LIpWZjFmA3BLxNDTHoz420jp&s=54-iPwwQkGRgqbmGQptKb3",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/895#issuecomment-1784196835:1378,usab,usable,1378,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/895#issuecomment-1784196835,2,['usab'],['usable']
Usability,"w/o any modification to the fastq on both of your sample to generate the gene count matrices. I already did that, in downstream analyses I have a batch effect issue related to the sequencing depth. >that's why we recommend using the Seurat package downstream of the Alevin quantified matrices. I have some experience with downstream analyses with Seurat, Pagoda, Scater, scanpy and a few other tools, and I am aware of batch correction methods like CCA or MNN. But that is not what I am looking for here. I did both CCA and MNN but I loose some important information in the resulting eigenspaces or corrected matrix. I believe the proper way to correct my batch effect is to simply fix the difference between my two libraries, ie. the sequencing depth in this case. As I explained in my first message, cellranger aggregate (subsampling based on the amount of mapped reads) works very well in my case, correct the effect without any loss or modification of important genes in our scientific question. Not CCA or MNN. I would like to be able to do the same from the alevin quantifications. So I am looking for a proper way to apply a correction before/during/after the alevin quantification, in a way similar to what cellranger do with STAR. Alternatively, could a subsampling covariate be added to the probalistic quantification model of alevin (if I understand it well), in sort that such a discrepency bewteen samples would be corrected?. I did look at the mappedUMI file:. ![image](https://user-images.githubusercontent.com/34892073/47551835-85ef9380-d903-11e8-893f-2a684576437b.png). So an option you would recommend is to simply compute the subsampling coefficient for a median ratio bewteen samples? I am expecting quite uneven distributions/variance in the mappedUMI between samples (partly due to a huge difference in term of proliferation that occur with a fraction of cells in only one sample). Still, cellranger aggregate correct it nicely. Thanks again for your prompt answer and comments.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/305#issuecomment-433319913:2562,simpl,simply,2562,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/305#issuecomment-433319913,2,['simpl'],['simply']
