quality_attribute,sentence,source,author,repo,version,id,keyword,matched_word,match_idx,wiki,url,total_similar,target_keywords,target_matched_words
Deployability,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. setuptools-scm can't find the package version when running `pip install -e` or `pip install .`. I stepped through `scanpy/_metadata.py`, and it does appear to be able to get `__version__` via `setuptools_scm.get_version` as opposed to using `._compat`. It seems like it may either be an issue with `setuptools_scm` itself or the combination of my environment and `pyproject.toml`. Any ideas?. ### Minimal code sample (that we can copy&paste without having any data). ```bash; pip install -e .; ```. ```pytb; File ""/tmp/tmp7fu14tjf"", line 280, in <module>; main(); File ""/tmp/tmp7fu14tjf"", line 263, in main; json_out['return_val'] = hook(**hook_input['kwargs']); File ""/tmp/tmp7fu14tjf"", line 133, in prepare_metadata_for_build_wheel; return hook(metadata_directory, config_settings); File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/build_meta.py"", line 161, in prepare_metadata_for_build_wheel self.run_setup(); File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/build_meta.py"", line 145, in run_setup; exec(compile(code, __file__, 'exec'), locals()) File ""setup.py"", line 17, in <module>; setup(; File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/__init__.py"", line 153, in setup; return distutils.core.setup(**attrs); File ""/usr/lib/python3.8/distutils/core.py"", line 108, in setup; _setup_distribution = dist = klass(attrs); File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 423, in __init__; _Distribution.__init__(self, {; File ""/usr/lib/python3.8/distutils/dist.py"", line 292, in __init__; self.finalize_options() File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 695, in finaliz",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1496:293,install,install,293,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496,3,['install'],['install']
Deployability,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---; **Hello Scanpy,; When I'm running sc.pp.highly_variable_genes(adata, n_top_genes=5000, flavor='seurat_v3'), it asks me to install scikit-misc, which is already installed. Please see the picture below.; Could you please help me to solve this issue?; Thanks!; Best,; YJ**; **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; # Your code here; ```; ![image](https://user-images.githubusercontent.com/75048821/145125005-64f8607e-9cb0-4740-8dca-7c80e35d30ef.png). ```pytb; [Paste the error output produced by the above code here]; ```. #### Versions. <details>3.8. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>scanpy==1.8.2 anndata==0.7.8 umap==0.5.2 numpy==1.20.3 scipy==1.7.2 pandas==1.3.4 scikit-learn==1.0.1 statsmodels==0.13.1 python-igraph==0.9.8 pynndescent==0.5.5; scvelo==0.2.4 scanpy==1.8.2 anndata==0.7.8 loompy==3.0.6 numpy==1.20.3 scipy==1.7.2 matplotlib==3.5.0 sklearn==1.0.1 pandas==1.3.4 ; cellrank==1.5.0 scanpy==1.8.2 anndata==0.7.8 numpy==1.20.3 numba==0.54.1 scipy==1.7.2 pandas==1.3.4 pygpcca==1.0.2 scikit-learn==1.0.1 statsmodels==0.13.1 python-igraph==0.9.8 scvelo==0.2.4 pygam==0.8.0 matplotlib==3.5.0 seaborn==0.11.2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2073:351,install,install,351,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2073,2,['install'],"['install', 'installed']"
Deployability,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. When running the `Integrating spatial data with scRNA-seq using scanorama` [tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/spatial/integration-scanorama.html#Data-integration-and-label-transfer-from-scRNA-seq-dataset) with the provided sample data, the following error occurs. This may be related to the following warning I also see. `<string>:6: VisibleDeprecationWarning: Creating an ndarray from nested sequences exceeding the maximum number of dimensions of 32 is deprecated. If you mean to do this, you must specify 'dtype=object' when creating the ndarray.`. How can I overcome this issue?. Example code below has how I downloaded the data in the `Data integration and label transfer from scRNA-seq dataset` section of the tutorial and then just the code block where the error actually occurs. ---. ### Minimal code sample (that we can copy&paste without having any data). ![scanorama_error](https://user-images.githubusercontent.com/52245296/154322971-c45606d2-54d7-42da-8ac6-85f91359e3c8.png). ```python. import subprocess; from pathlib import Path. if Path('./downloaded_data/adata_processed.h5ad').is_file():; print(""Data previously downloaded, skipping to next step""); else:; subprocess.run(['wget', '-O', './downloaded_data/adata_processed.h5ad', 'https://hmgubox.helmholtz-muenchen.de/f/4ef254675e2a41f89835/?dl=1']). adata_cortex = sc.read(""./downloaded_data/adata_processed.h5ad""). embedding_anterior = np.concatenate(integrated_anterior, axis=0); adata_cortex_anterior.obsm[""scanorama_embedding""] = embedding_anterior. embedding_posterior = np.concatenate(integrated_posterior, axis=0); adata_cortex_posterior.obsm[""scanorama_embedding""] = embedding_posterior; ```. ```pytb. <string>:6: VisibleDeprecationWarning: Creating an ndarray from nested se",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2143:242,Integrat,Integrating,242,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2143,4,"['Integrat', 'integrat']","['Integrating', 'integration', 'integration-and-label-transfer-from-scRNA-seq-dataset', 'integration-scanorama']"
Deployability,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] **Updated:** I have confirmed this bug exists on the master branch of scanpy. ### Minimal code sample. Start from a fresh venv. (Tested on Python 3.9.2 on Debian Bullseye.). ```; (new-venv) $ pip install scanpy==1.9.1; ```. Then from within that venv:. ```python; import scanpy; ```. ```pytb; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File "".../site-packages/scanpy/__init__.py"", line 16, in <module>; from . import plotting as pl; File "".../site-packages/scanpy/plotting/__init__.py"", line 1, in <module>; from ._anndata import (; File "".../site-packages/scanpy/plotting/_anndata.py"", line 28, in <module>; from . import _utils; File "".../site-packages/scanpy/plotting/_utils.py"", line 35, in <module>; class _AxesSubplot(Axes, axes.SubplotBase, ABC):; TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases; ```. ### Versions. You can't get to `scanpy.logging.print_versions()` on account of the crash.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2411:150,Update,Updated,150,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2411,2,"['Update', 'install']","['Updated', 'install']"
Deployability,- [x] Tests included or not required because: comment/docstring nits; - [x] Release notes not necessary because: comment/docstring nits,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3311:76,Release,Release,76,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3311,1,['Release'],['Release']
Deployability,- [x] reordered existing ones; - [ ] added new ones. With the new structure we don’t even need `:noteversion:` anymore and should just make the headers links to the GitHub releases.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/951:172,release,releases,172,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/951,1,['release'],['releases']
Deployability,"- [✔] I have checked that this issue has not already been reported.; - [✔ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ✔] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. Hello Scanpy,; I installed Scanpy, scVelo, CellRank, bbknn 2 months ago and never upgrade the packages. They were running very smoothly until I reimage my PC and reinstall Scanpy in anaconda today (Anaconda3-2021.05-Windows-x86_64, python3.8.12).; I tired `pip install scanpy[leiden]`. Tried `conda install seaborn scikit-learn statsmodels numba pytables`, `conda install -c conda-forge python-igraph leidenalg`. Tried installing `Java` and `visual C++ 2012-2022 redistributable`. Also tried rebuilding a new environment and reinstalled everything. Whatever I try, this bug still exists when I import Scanpy.; I guess it may be the incompatibility issue of packages. Some dependency packages which were upgraded by the developer in these months caused this incompatibility issue. Could you please help me with this bug?; Thanks!; Best,; YJ. ### Minimal code sample (that we can copy&paste without having any data). ```python; import numpy as np; import pandas as pd; import scanpy as sc; import scanpy.external as sce; import scipy; sc.settings.verbosity = 3; sc.logging.print_header(); sc.set_figure_params(dpi=100, dpi_save=600); ; import matplotlib.pyplot as pl; from matplotlib import rcParams; ```. ```pytb; ImportError Traceback (most recent call last); ~\AppData\Local\Temp/ipykernel_7844/2696797780.py in <module>; 1 import numpy as np; 2 import pandas as pd; ----> 3 import scanpy as sc; 4 import scanpy.external as sce; 5 import scipy. ~\.conda\envs\Python38\lib\site-packages\scanpy\__init__.py in <module>; 12 # (start with settings as several tools are using it); 13 from ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2108:433,install,installed,433,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2108,6,"['install', 'upgrade']","['install', 'installed', 'installing', 'upgrade']"
Deployability,"- [✔] I have checked that this issue has not already been reported.; - [✔] I have confirmed this bug exists on the latest version of scanpy.; - [✔] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. Hello Scanpy,; It's very smooth to subset the adata by HVGs when doing `adata = adata[:, adata.var.highly_variable]` in the Scanpy pipeline. But when using the same coding to subeset a new raw adata, it generate errors. Could you please help me to check this issue?; Thanks!; Best,; YJ. ### Minimal code sample (that we can copy&paste without having any data). ```python; ACT_sub2 = sc.read('C:/Users/Park_Lab/Documents/ACT_sub2.h5ad') # Scanpy proceeded data; ACT_sub2; AnnData object with n_obs × n_vars = 2636 × 5000; obs: 'leiden', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'total_counts_rpl', 'pct_counts_rpl', 'total_counts_rps', 'pct_counts_rps'; var: 'Accession', 'Chromosome', 'End', 'Start', 'Strand', 'n_cells', 'mt', 'rpl', 'rps', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'mean', 'std'; uns: 'hvg', 'leiden', 'leiden_colors', 'neighbors', 'pca', 'rank_genes_groups', 'umap'; obsm: 'X_pca', 'X_umap'; varm: 'PCs'; layers: 'ambiguous', 'matrix', 'spliced', 'unspliced'; obsp: 'connectivities', 'distances'. adata = sc.read_loom(filename='C:/Users/Park_Lab/Documents/cellsorted_Apc_Cracd_Tumor_KPVDV.loom') # raw data; adata.var_names_make_unique(); adata; AnnData object with n_obs × n_vars = 13499 × 32285; var: 'Accession', 'Chromosome', 'End', 'Start', 'Strand'; layers: 'matrix', 'ambiguous', 'spliced', 'unspliced'. adata.var['highly_variable']=ACT_sub2.var['highly_variable']; adata = adata[:, adata.var.highly_variable] # subset ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2095:545,pipeline,pipeline,545,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2095,1,['pipeline'],['pipeline']
Deployability,"- [✔] I have checked that this issue has not already been reported.; - [✔] I have confirmed this bug exists on the latest version of scanpy.; - [✔] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. Hello Scanpy,; This BUG is quite weird. It starts since we installed Anaconda3-v2021.11 on 3 individual Windows PCs. We run the same dataset by the same coding. However, it generates 3 different UMAPs. The coding is as below.; UMAP of Windows PC2 is consistent with our previous UMAPs done on PC1 and PC2 in November with Anaconda3-v2021.05.; Could you please help us with this issue?; Thanks!; Best,; YJ. ### Minimal code sample (that we can copy&paste without having any data). ```python; import numpy as np; import pandas as pd; import scanpy as sc; import scanpy.external as sce; import scipy; sc.settings.verbosity = 3; sc.logging.print_header(); sc.set_figure_params(dpi=100, dpi_save=600). adata = sc.read_loom(filename='C:/Users/Park_Lab/Documents/Tumor.loom'); adata.var_names_make_unique(); adata; sc.pl.highest_expr_genes(adata, n_top=20); sc.pp.filter_cells(adata, min_genes=100); sc.pp.filter_genes(adata, min_cells=25); adata.var['mt'] = adata.var_names.str.startswith('mt-'); adata.var['rpl'] = adata.var_names.str.startswith('Rpl'); adata.var['rps'] = adata.var_names.str.startswith('Rps'); adata; sc.pp.calculate_qc_metrics(adata, qc_vars=['mt','rpl','rps'], percent_top=None, log1p=False, inplace=True); sc.pl.violin(adata, keys=['n_genes_by_counts', 'total_counts', 'pct_counts_mt','pct_counts_rpl','pct_counts_rps'], jitter=0.4, multi_panel=True); adata; sc.pl.scatter(adata, x='total_counts', y='pct_counts_mt'); sc.pl.scatter(adata, x='total_counts', y='pct_counts_rpl'); sc.pl.scatter(adata, x='total_counts', y='pct_counts_rps'); sc.pl.scatter(adata, x='total_cou",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2114:473,install,installed,473,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2114,1,['install'],['installed']
Deployability,"-----------------------------------------------; ImportError Traceback (most recent call last); <ipython-input-2-0074c9bc0b31> in <module>; ----> 1 import scanpy as sc. ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/scanpy/__init__.py in <module>; 3 from ._metadata import __version__, __author__, __email__; 4 ; ----> 5 from ._utils import check_versions; 6 ; 7 check_versions(). ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/scanpy/_utils.py in <module>; 16 from numpy import random; 17 from scipy import sparse; ---> 18 from anndata import AnnData, __version__ as anndata_version; 19 from textwrap import dedent; 20 from packaging import version. ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/anndata/__init__.py in <module>; 5 if not within_flit():; 6 del within_flit; ----> 7 from ._core.anndata import AnnData, ImplicitModificationWarning; 8 from ._core.merge import concat; 9 from ._core.raw import Raw. ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/anndata/_core/anndata.py in <module>; 15 from typing import Tuple, List # Generic; 16 ; ---> 17 import h5py; 18 from natsort import natsorted; 19 import numpy as np. ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/h5py/__init__.py in <module>; 31 raise; 32 ; ---> 33 from . import version; 34 ; 35 if version.hdf5_version_tuple != version.hdf5_built_version_tuple:. ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/h5py/version.py in <module>; 13 ; 14 from collections import namedtuple; ---> 15 from . import h5 as _h5; 16 import sys; 17 import numpy. h5py/h5.pyx in init h5py.h5(). ImportError: /home/karl/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/h5py/defs.cpython-38-x86_64-linux-gnu.so: undefined symbol: H5Pset_fapl_ros3; ```. </Details>. Before, when I was trying to update `h5py` and getting lots of conflicts, I let conda try to figure out all of them, printing out a huge list that reached the output limit of my console (~6000 lines). Let me know if I should post the list.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1850#issuecomment-847928310:20564,update,update,20564,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1850#issuecomment-847928310,1,['update'],['update']
Deployability,"---. Hello, I have been working locally with scanpy where everything works well; I can save anndata objects as `.h5ad` files and read them later. However, when sharing this file with a colleague on a remote server she was unable to read in the file (a file that I have confirmed that I can read in locally) using scanpy. After some troubleshooting I was unable to identify the problem. If I had to guess I think one of 2 things could be going wrong--though they both seem unlikely to me. 1) She is having issues because her environment is slightly different. (unlikely because packages look comparable); 2) The file is not getting copied to the server properly and getting corrupted. (unlikely because file size looks correct). Below I have both the error and the different packages installed in both environments. Thank you for your time and patience!. ```python; adata = sc.read_h5ad('/base/lab/student/acb/sc_labeled.h5ad'); ```. ```pytb; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); ~/.local/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs); 176 try:; --> 177 return func(elem, *args, **kwargs); 178 except Exception as e:. ~/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group); 526 if encoding_type:; --> 527 EncodingVersions[encoding_type].check(; 528 group.name, group.attrs[""encoding-version""]. /broad/software/free/Linux/redhat_7_x86_64/pkgs/anaconda3_2020.07/lib/python3.8/enum.py in __getitem__(cls, name); 343 def __getitem__(cls, name):; --> 344 return cls._member_map_[name]; 345 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last); <ipython-input-2-2626ee07d023> in <module>; ----> 1 sc.read_h5ad('/xchip/beroukhimlab/michelle/jjeang_plgg/sc_labeled.h5ad'). ~/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2310:783,install,installed,783,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2310,1,['install'],['installed']
Deployability,"---; anndata 0.7.8; scanpy 1.8.2; sinfo 0.3.1; -----; PIL 8.4.0; anndata 0.7.8; asciitree NA; attr 21.2.0; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; cffi 1.15.0; cloudpickle 2.0.0; colorama 0.4.4; concurrent NA; cycler 0.10.0; cython_runtime NA; dask 2021.11.1; dateutil 2.8.0; debugpy 1.5.1; decorator 5.1.0; defusedxml 0.7.1; encodings NA; entrypoints 0.3; fasteners NA; fsspec 2021.11.0; genericpath NA; h5py 3.4.0; idna 3.1; igraph 0.9.8; ipykernel 6.5.0; ipython_genutils 0.2.0; ipywidgets 7.6.5; jedi 0.18.0; jinja2 3.0.3; joblib 1.1.0; jsonschema 4.2.1; kiwisolver 1.3.2; leidenalg 0.8.8; llvmlite 0.36.0; louvain 0.7.0; markupsafe 2.0.1; matplotlib 3.4.3; mpl_toolkits NA; natsort 8.0.0; nbformat 5.1.3; nbinom_ufunc NA; ntpath NA; numba 0.53.1; numcodecs 0.9.1; numexpr 2.7.3; numpy 1.21.4; opcode NA; packaging 21.0; pandas 1.3.4; parso 0.8.2; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; posixpath NA; prometheus_client NA; prompt_toolkit 3.0.22; psutil 5.8.0; ptyprocess 0.7.0; pvectorc NA; pyarrow 9.0.0; pydev_ipython NA; pydevconsole NA; pydevd 2.6.0; pydevd_concurrency_analyser NA; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pydoc_data NA; pyexpat NA; pygments 2.10.0; pyparsing 3.0.6; pyrsistent NA; pytz 2021.3; scanpy 1.8.2; scipy 1.7.2; seaborn 0.11.2; send2trash NA; setuptools_scm NA; sinfo 0.3.1; six 1.16.0; sklearn 1.0.1; sphinxcontrib NA; sre_compile NA; sre_constants NA; sre_parse NA; statsmodels 0.13.1; tables 3.6.1; terminado 0.12.1; texttable 1.6.4; threadpoolctl 3.0.0; tlz 0.11.2; toolz 0.11.2; tornado 6.1; traitlets 5.1.1; typing_extensions NA; wcwidth 0.2.5; xmlrpc NA; yaml 6.0; zarr 2.10.2; zmq 22.3.0; -----; IPython 7.29.0; jupyter_client 7.0.6; jupyter_core 4.9.1; notebook 6.4.5; -----; Python 3.9.7 | packaged by conda-forge | (default, Sep 29 2021, 19:20:46) [GCC 9.4.0]; Linux-4.18.0-80.7.1.el8_0.x86_64-x86_64-with-glibc2.17; 224 logical CPU cores, x86_64; -----; Session information updated at 2022-10-24 15:07. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2361:2728,update,updated,2728,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361,1,['update'],['updated']
Deployability,"-12 NaN (-0.00411, 0.205] 0.0 False; 32737 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. [32738 rows x 5 columns]; >>> ; >>> # This raises ValueError again; >>> pbmc.obs['batch'] = 'A'; >>> column_index = pbmc.obs.columns.get_indexer(['batch']); >>> pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'; >>> sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch""); .venv/lib/python3.10/site-packages/scipy/sparse/_data.py:133: RuntimeWarning: overflow encountered in expm1; result = op(self._deduped_data()); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File "".venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 459, in highly_variable_genes; hvg = _highly_variable_genes_single_batch(; File "".venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 215, in _highly_variable_genes_single_batch; df['mean_bin'] = pd.cut(df['means'], bins=n_bins); File "".venv/lib/python3.10/site-packages/pandas/core/reshape/tile.py"", line 263, in cut; raise ValueError(; ValueError: cannot specify integer `bins` when input data contains infinity. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. -----; anndata 0.8.0; scanpy 1.9.1; -----; PIL 9.3.0; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; google NA; h5py 3.7.0; joblib 1.2.0; kiwisolver 1.4.4; llvmlite 0.39.1; matplotlib 3.6.2; mpl_toolkits NA; natsort 8.2.0; numba 0.56.4; numpy 1.23.5; packaging 22.0; pandas 1.5.2; psutil 5.9.4; pyarrow 10.0.1; pyparsing 3.0.9; pytz 2022.7; scipy 1.9.3; session_info 1.0.0; sitecustomize NA; six 1.16.0; sklearn 1.2.0; threadpoolctl 3.1.0; typing_extensions NA; yaml 6.0; zoneinfo NA; -----; Python 3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0]; Linux-5.15.0-57-generic-x86_64-with-glibc2.35; -----; Session information updated at 2023-01-09 18:53. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2396:6114,update,updated,6114,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396,1,['update'],['updated']
Deployability,-30clip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[toarray-float32-100n-inftheta-noclip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_embedding_plots.py::test_missing_values_categorical[pca-na_color.black_tup-na_in_legend.False-legend.on_data-groups.all] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-200n-100theta-30clip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200n-inftheta-30clip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100n-inftheta-noclip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[toarray-int64-100n-100theta-infclip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_embedding_plots.py::test_missing_values_categorical[pca-na_color.black_tup-na_in_legend.False-legend.on_right-groups.3] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[toarray-float32-100n-inftheta-infclip-subset] - NotImplementedError: Failed in nopython mode p,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:37084,pipeline,pipeline,37084,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['pipeline'],['pipeline']
Deployability,"-4-5d47edb05ae7> in <module>; ----> 1 sc.pp.neighbors(adata). ~/Projects/scanpy/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy); 137 adata._init_as_actual(adata.copy()); 138 neighbors = Neighbors(adata); --> 139 neighbors.compute_neighbors(; 140 n_neighbors=n_neighbors,; 141 knn=knn,. ~/Projects/scanpy/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds); 806 # we need self._distances also for method == 'gauss' if we didn't; 807 # use dense distances; --> 808 self._distances, self._connectivities = _compute_connectivities_umap(; 809 knn_indices,; 810 knn_distances,. ~/Projects/scanpy/scanpy/neighbors/__init__.py in _compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity); 385 # umap 0.5.0; 386 warnings.filterwarnings(""ignore"", message=r""Tensorflow not installed""); --> 387 from umap.umap_ import fuzzy_simplicial_set; 388 ; 389 X = coo_matrix(([], ([], [])), shape=(n_obs, 1)). ~/miniconda3/envs/scanpy_dev/lib/python3.8/site-packages/umap/__init__.py in <module>; 1 from warnings import warn, catch_warnings, simplefilter; ----> 2 from .umap_ import UMAP; 3 ; 4 try:; 5 with catch_warnings():. ~/miniconda3/envs/scanpy_dev/lib/python3.8/site-packages/umap/umap_.py in <module>; 30 import umap.distances as dist; 31 ; ---> 32 import umap.sparse as sparse; 33 ; 34 from umap.utils import (. ~/miniconda3/envs/scanpy_dev/lib/python3.8/site-packages/umap/sparse.py in <module>; 10 import numpy as np; 11 ; ---> 12 from umap.utils import norm; 13 ; 14 locale.setlocale(locale.LC_NUMERIC, ""C""). ~/miniconda3/envs/scanpy_dev/lib/python3.8/site-packages/umap/utils.py in <module>; 38 ; 39 @numba.njit(""i4(i8[:])""); ---> 40 def tau_rand_int(state):; 41 """"""A fast (pseudo)-random number generator.; 42 . ~/miniconda3/envs/scanpy_dev/lib/python3.8/site-",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1756#issuecomment-846931466:1364,install,installed,1364,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1756#issuecomment-846931466,1,['install'],['installed']
Deployability,"-packages/anndata/compat.py in pkg_version(package); 56 try:; ---> 57 from importlib.metadata import version as v; 58 except ImportError:. ModuleNotFoundError: No module named 'importlib.metadata'. During handling of the above exception, another exception occurred:. ModuleNotFoundError Traceback (most recent call last); <ipython-input-11-495a6d84c058> in <module>; 1 import os; ----> 2 import scanpy as sc; 3 import numpy as np; 4 import pandas as pd; 5 import loompy as lp. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/__init__.py in <module>; 1 # some technical stuff; 2 import sys; ----> 3 from .utils import check_versions, annotate_doc_types; 4 from ._version import get_versions # version generated by versioneer; 5 . ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/utils.py in <module>; 17 from pandas.api.types import CategoricalDtype; 18 ; ---> 19 from ._settings import settings; 20 from . import logging as logg; 21 import warnings. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/_settings.py in <module>; 7 from typing import Tuple, Union, Any, List, Iterable, TextIO, Optional; 8 ; ----> 9 from . import logging; 10 from .logging import _set_log_level, _set_log_file, RootLogger; 11 . ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/logging.py in <module>; 7 from typing import Optional; 8 ; ----> 9 import anndata.logging; 10 ; 11 . ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/anndata/__init__.py in <module>; 93 from .compat import pkg_version; 94 ; ---> 95 __version__ = pkg_version(__name__); 96 del pkg_version. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/anndata/compat.py in pkg_version(package); 57 from importlib.metadata import version as v; 58 except ImportError:; ---> 59 from importlib_metadata import version as v; 60 return version.parse(v(package)); 61 . ModuleNotFoundError: No module named 'importlib_metadata'. And, when I try to install the module, it says that I already installed it. Thank you",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1154#issuecomment-611202845:3719,install,install,3719,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1154#issuecomment-611202845,2,['install'],"['install', 'installed']"
Deployability,"-packages/pandas/io/parsers/readers.py:1891) f = self.handles.handle. File ~\AppData\Roaming\Python\Python312\site-packages\pandas\io\common.py:765, in get_handle(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options); [761](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/common.py:761) if compression == ""gzip"":; [762](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/common.py:762) if isinstance(handle, str):; [763](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/common.py:763) # error: Incompatible types in assignment (expression has type; [764](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/common.py:764) # ""GzipFile"", variable has type ""Union[str, BaseBuffer]""); --> [765](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/common.py:765) handle = gzip.GzipFile( # type: ignore[assignment]; [766](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/common.py:766) filename=handle,; [767](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/common.py:767) mode=ioargs.mode,; [768](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/common.py:768) **compression_args,; [769](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pm",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3214:16624,Pipeline,PipelineDevelope,16624,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3214,1,['Pipeline'],['PipelineDevelope']
Deployability,"-packages/setuptools/build_meta.py"", line 145, in run_setup; exec(compile(code, __file__, 'exec'), locals()) File ""setup.py"", line 17, in <module>; setup(; File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/__init__.py"", line 153, in setup; return distutils.core.setup(**attrs); File ""/usr/lib/python3.8/distutils/core.py"", line 108, in setup; _setup_distribution = dist = klass(attrs); File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 423, in __init__; _Distribution.__init__(self, {; File ""/usr/lib/python3.8/distutils/dist.py"", line 292, in __init__; self.finalize_options() File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 695, in finalize_options; ep(self); File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 702, in _finalize_setup_keywords; ep.load()(self, ep.name, value); File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/integration.py"", line 17, in version_keyword; dist.metadata.version = _get_version(config); File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/__init__.py"", line 148, in _get_version; parsed_version = _do_parse(config); File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/__init__.py"", line 110, in _do_parse raise LookupError(; LookupError: setuptools-scm was unable to detect version for '/home/ubuntu/code/scanpy'.; Make sure you're either building from a fully intact git repository or PyPI tarballs. Most other sources (such as GitHub's tarballs, a git checkout without the .git folder) don't contain the necessary metadata and will not work.; ; For example, if you're using pip, instead of https://github.com/user/proj/archive/master.zip use git+https://github.com/user/proj.git#egg=proj```; ```; #### Versions. <details>. scanpy; problem is with installation, so scanpy.logging.print_versions(); commit: ef5a8ee57c2aef7778a069a49101a8998718e6d5. python; 3.8.5. pip; 2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1496:2245,integrat,integration,2245,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496,1,['integrat'],['integration']
Deployability,". # t-SNE; tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means; k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs; sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(); tr=time.time(); adata = sc.read(input_file); adata.var_names_make_unique(); adata.shape; print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(); # To reduce the number of cells:; USE_FIRST_N_CELLS = 1300000; adata = adata[0:USE_FIRST_N_CELLS]; adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell); sc.pp.filter_cells(adata, max_genes=max_genes_per_cell); sc.pp.filter_genes(adata, min_cells=min_cells_per_gene); sc.pp.normalize_total(adata, target_sum=1e4); print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(); sc.pp.log1p(adata); print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes; sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression; for marker in markers:; adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes; adata = adata[:, adata.var.highly_variable]. #Regress out confounding factors (number of counts, mitochondrial gene expression); mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX); n_counts = np.array(adata.X.sum(axis=1)); adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts; adata.obs['n_counts'] = n_counts. ts=time.time(); sc.pp.regress_out(adata, ['n_counts', 'percent_mito']); print(""Total regress out time : %s"" % (time.time()-ts)); ```; <!-- Please check (“- [x]”) and fill in the following boxes -->; - [ ] Closes #; - [ ] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3284:3423,release,release,3423,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3284,2,"['Release', 'release']","['Release', 'release']"
Deployability,". It can definitely make the transition from R to Python more difficult (I can attest, as I'm going through it right now :P). R packages just tend to come with very thorough vignettes, documenting how the package is supposed to be used end-to-end, highlighting special use-cases, etc. I think [Seurat](http://satijalab.org/seurat/get_started.html), [Monocle](http://cole-trapnell-lab.github.io/monocle-release/), or really any Bioconductor package (eg. [Scater](https://bioconductor.org/packages/release/bioc/vignettes/scater/inst/doc/vignette-intro.html)) are great examples. Jupyter notebooks are fantastic for helping get an idea of how to use a package, but sometimes the documentation within them is lacking, making it hard to understand what's going on at each step without having to dive into source code. I find Scanpy's straight forward to follow though. I really appreciate the modular design of Scanpy. At least if you're familiar with single-cell analysis, you can recognize the steps quite easily and just string together the appropriate functions for your analysis pipeline. Some other packages are bit trickier. For example, I found Velocyto (which I love btw) incredibly hard to navigate. There are functions that are used in some analysis notebooks but not all of them, so it becomes unclear what the standard analysis pipeline with it should be. Obviously you can dive into the paper, understand the statistical guts of the method, go through all the source code and see what's there, but then it starts becoming a barrier to newer users adapting it. . Anyway, this is just a general thing I also noticed moving from R to Python. Not saying that it's something that necessarily needs changing, but it does create a little bit of friction to newer users, so it may be worth thinking about as a community. I suspect this will improve as the genomics user-base of Python increases, and as all these packages have more time to develop. Also, I understand that this is more of a ""communit",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/74#issuecomment-363820657:1241,pipeline,pipeline,1241,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74#issuecomment-363820657,1,['pipeline'],['pipeline']
Deployability,.0.1; Jinja2 3.1.2; jmespath 1.0.1; joblib 1.3.2; json5 0.9.14; jsonpatch 1.33; jsonpointer 2.4; jsonschema 4.19.1; jsonschema-specifications 2023.7.1; jupyter 1.0.0; jupyter_client 8.3.1; jupyter-console 6.6.3; jupyter_core 5.3.2; jupyter-events 0.7.0; jupyter-lsp 2.2.0; jupyter_server 2.7.3; jupyter_server_terminals 0.4.4; jupyterlab 4.0.6; jupyterlab-pygments 0.2.2; jupyterlab_server 2.25.0; jupyterlab-widgets 3.0.9; keyring 24.2.0; kiwisolver 1.4.5; lazy_loader 0.3; lazy-object-proxy 1.9.0; leidenalg 0.9.1; libarchive-c 5.0; libmambapy 1.5.1; linkify-it-py 2.0.0; llvmlite 0.40.1; locket 1.0.0; lxml 4.9.2; lz4 4.3.2; Markdown 3.5; markdown-it-py 3.0.0; MarkupSafe 2.1.3; matplotlib 3.8.0; matplotlib-inline 0.1.6; mccabe 0.7.0; mdit-py-plugins 0.4.0; mdurl 0.1.0; mistune 3.0.1; mkl-service 2.4.0; more-itertools 10.1.0; mpmath 1.3.0; msgpack 1.0.6; multidict 6.0.4; multipledispatch 0.6.0; multiprocess 0.70.15; munkres 1.1.4; mypy-extensions 1.0.0; natsort 8.4.0; natsort 8.4.0; navigator-updater 0.4.0; nbclient 0.8.0; nbconvert 7.9.2; nbformat 5.9.2; nest-asyncio 1.5.6; networkx 3.1; nltk 3.8.1; notebook 7.0.4; notebook_shim 0.2.3; numba 0.57.1; numexpr 2.8.7; numpy 1.24.4; numpydoc 1.5.0; openpyxl 3.1.2; overrides 7.4.0; packaging 23.2; pandas 2.1.1; pandocfilters 1.5.0; panel 1.2.3; parallel-fastq-dump 0.6.7; param 1.13.0; parsel 1.8.1; parso 0.8.3; partd 1.4.1; pathspec 0.11.2; patsy 0.5.3; pep8 1.7.1; pexpect 4.8.0; pickleshare 0.7.5; Pillow 10.0.1; pip 23.2.1; pkce 1.0.3; pkginfo 1.9.6; pkgutil_resolve_name 1.3.10; plac 1.3.5; platformdirs 3.11.0; plotly 5.17.0; pluggy 1.3.0; ply 3.11; pooch 1.7.0; prometheus-client 0.17.1; prompt-toolkit 3.0.39; Protego 0.3.0; psutil 5.9.5; ptyprocess 0.7.0; PuLP 2.7.0; pure-eval 0.2.2; py-cpuinfo 9.0.0; pyarrow 13.0.0; pyasn1 0.5.0; pyasn1-modules 0.3.0; pycodestyle 2.10.0; pycosat 0.6.6; pycparser 2.21; pyct 0.4.6; pycurl 7.45.1; pydantic 1.10.13; pydeseq2 0.4.1; PyDispatcher 2.0.5; pydocstyle 6.3.0; pyerfa 2.0.0.3; pyflakes 3,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2680:7051,update,updater,7051,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680,1,['update'],['updater']
Deployability,".0.1; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2022.7.0; dateutil 2.8.2; debugpy 1.5.1; decorator 5.1.1; defusedxml 0.7.1; deprecate 0.3.2; dill 0.3.4; docrep 0.3.2; entrypoints 0.4; etils 0.8.0; flax 0.6.1; fsspec 2022.7.1; google NA; graphviz 0.20; h5py 3.7.0; idna 3.4; igraph 0.10.2; ipykernel 6.15.2; ipython_genutils 0.2.0; ipywidgets 7.6.5; jax 0.3.23; jaxlib 0.3.22; jedi 0.18.1; jinja2 2.11.3; jmespath 0.10.0; joblib 1.1.1; jupyter_server 1.18.1; kiwisolver 1.4.2; leidenalg 0.8.10; llvmlite 0.39.1; louvain 0.8.0; lz4 3.1.3; markupsafe 2.0.1; matplotlib 3.5.2; matplotlib_inline 0.1.6; ml_collections NA; mpl_toolkits NA; msgpack 1.0.3; mudata 0.2.0; multipledispatch 0.6.0; natsort 8.1.0; nbinom_ufunc NA; numba 0.56.3; numexpr 2.8.3; numpy 1.22.4; numpyro 0.10.1; opt_einsum v3.3.0; optax 0.1.3; packaging 21.3; pandas 1.4.4; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; plotly 5.9.0; prompt_toolkit 3.0.20; psutil 5.9.0; ptyprocess 0.7.0; pydev_ipython NA; pydevconsole NA; pydevd 2.6.0; pydevd_concurrency_analyser NA; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.11.2; pyparsing 3.0.9; pyro 1.8.2; pytorch_lightning 1.7.7; pytz 2022.1; regex 2.5.116; requests 2.28.1; rich NA; scipy 1.7.3; scvi 0.18.0; session_info 1.0.0; setuptools 63.4.1; simplejson 3.17.6; six 1.16.0; sklearn 1.1.2; snappy NA; socks 1.7.1; sphinxcontrib NA; storemagic NA; tblib 1.7.0; tensorboard 2.9.1; texttable 1.6.4; threadpoolctl 2.2.0; tlz 0.11.0; toolz 0.11.2; torch 1.12.1; torchmetrics 0.10.0; torchvision 0.13.1; tornado 6.1; tqdm 4.64.1; traitlets 5.1.1; tree 0.1.7; typing_extensions NA; urllib3 1.26.12; wcwidth 0.2.5; wrapt 1.14.1; yaml 6.0; zipp NA; zmq 23.2.0; zope NA; -----; IPython 7.31.1; jupyter_client 7.3.4; jupyter_core 4.11.1; jupyterlab 3.4.4; notebook 6.4.12; -----; Python 3.9.12 (main, Jun 1 2022, 06:36:29) [Clang 12.0.0 ]; macOS-10.16-x86_64-i386-64bit; -----; Session information updated at 2022-10-22 15:12. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2359:4627,update,updated,4627,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359,1,['update'],['updated']
Deployability,".0; opt_einsum v3.3.0; optax 0.1.4; packaging 23.0; pandas 1.5.3; parso 0.8.3; paste NA; patsy 0.5.3; petsc4py 3.19.0; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; platformdirs 3.0.0; progressbar 4.2.0; prometheus_client NA; prompt_toolkit 3.0.38; psutil 5.9.4; ptyprocess 0.7.0; pure_eval 0.2.2; pvectorc NA; pycparser 2.21; pydev_ipython NA; pydevconsole NA; pydevd 2.9.5; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pydot 1.4.2; pygam 0.8.0; pygments 2.14.0; pygpcca 1.0.4; pyparsing 3.0.9; pyro 1.8.4+9ed468d; pyrsistent NA; python_utils NA; pythonjsonlogger NA; pytorch_lightning 1.9.3; pytz 2022.7.1; pywt 1.4.1; requests 2.28.2; rfc3339_validator 0.1.4; rfc3986_validator 0.1.1; rich NA; scHPL NA; scarches 0.5.7; sccoda 0.1.9; scipy 1.10.1; scvelo 0.2.5; scvi 0.20.1; seaborn 0.12.2; send2trash NA; session_info 1.0.0; setuptools 67.4.0; six 1.16.0; skewnorm_ufunc NA; skimage 0.19.3; sklearn 1.2.1; slepc4py 3.19.0; sniffio 1.3.0; socks 1.7.1; squidpy 1.2.2; stack_data 0.6.2; statsmodels 0.13.5; tblib 1.7.0; tcr_embedding NA; tensorboard 2.11.2; tensorflow 2.11.0; tensorflow_probability 0.19.0; termcolor NA; texttable 1.6.7; threadpoolctl 3.1.0; tifffile 2023.2.28; tlz 0.12.0; toolz 0.12.0; torch 1.13.1; torch_cluster 1.6.0; torch_geometric 2.2.0; torch_scatter 2.1.0; torch_sparse 0.6.15; torchmetrics 0.11.3; torchvision 0.14.1; tornado 6.2; tqdm 4.64.1; traitlets 5.9.0; tree 0.1.7; typing_extensions NA; unicodedata2 NA; uri_template NA; urllib3 1.26.14; validators 0.20.0; wcwidth 0.2.6; webcolors 1.11.1; websocket 1.5.1; wrapt 1.15.0; xarray 2023.2.0; xarray_einstats 0.5.1; yaml 6.0; zarr 2.13.6; zipp NA; zmq 25.0.0; zoneinfo NA; zope NA; -----; IPython 8.11.0; jupyter_client 8.0.3; jupyter_core 5.2.0; jupyterlab 3.6.1; notebook 6.5.2; -----; Python 3.10.9 | packaged by conda-forge | (main, Feb 2 2023, 20:20:04) [GCC 11.3.0]; Linux-3.10.0-1160.83.1.el7.x86_64-x86_64-with-glibc2.17; -----; Session information updated at 2023-05-26 01:06. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2493:4181,update,updated,4181,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2493,1,['update'],['updated']
Deployability,".0; scanpy 1.9.1; -----; PIL 9.2.0; PyObjCTools NA; appnope 0.1.2; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; bottleneck 1.3.5; cffi 1.15.1; cloudpickle 2.0.0; colorama 0.4.5; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2022.7.0; dateutil 2.8.2; debugpy 1.5.1; decorator 5.1.1; defusedxml 0.7.1; entrypoints 0.4; fsspec 2022.7.1; h5py 3.7.0; hypergeom_ufunc NA; igraph 0.10.2; ipykernel 6.15.2; ipython_genutils 0.2.0; jedi 0.18.1; jinja2 2.11.3; joblib 1.1.0; jupyter_server 1.18.1; kiwisolver 1.4.2; leidenalg 0.9.0; llvmlite 0.38.0; louvain 0.8.0; lxml 4.9.1; lz4 3.1.3; markupsafe 2.0.1; matplotlib 3.5.2; mkl 2.4.0; mpl_toolkits NA; natsort 8.2.0; nbinom_ufunc NA; ncf_ufunc NA; numba 0.55.1; numexpr 2.8.3; numpy 1.21.5; openpyxl 3.0.10; packaging 21.3; pandas 1.4.4; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; plotly 5.9.0; prompt_toolkit 3.0.20; psutil 5.9.0; ptyprocess 0.7.0; pydev_ipython NA; pydevconsole NA; pydevd 2.6.0; pydevd_concurrency_analyser NA; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.11.2; pyparsing 3.0.9; pytz 2022.1; scipy 1.9.1; session_info 1.0.0; setuptools 63.4.1; six 1.16.0; sklearn 1.0.2; snappy NA; sphinxcontrib NA; storemagic NA; tblib 1.7.0; texttable 1.6.7; threadpoolctl 2.2.0; tlz 0.11.0; toolz 0.11.2; tornado 6.1; traitlets 5.1.1; typing_extensions NA; wcwidth 0.2.5; xlrd 2.0.1; yaml 6.0; zipp NA; zmq 23.2.0; zope NA; -----; IPython 7.31.1; jupyter_client 7.3.4; jupyter_core 4.11.1; jupyterlab 3.4.4; notebook 6.4.12; -----; Python 3.9.13 (main, Aug 25 2022, 18:29:29) [Clang 12.0.0 ]; macOS-10.16-x86_64-i386-64bit; -----; Session information updated at 2022-11-26 11:30]. </details>; When trying to read-in the .xlsx file, I get the error that the sheet does not exist. A screen shot of the excel file is attached. <img width=""1399"" alt=""Screenshot 2022-11-26 at 11 33 18 AM"" src=""https://user-images.githubusercontent.com/119125018/204099054-96ba4b72-815b-45fa-8bdc-a9f7d91ba662.png"">",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2371:5429,update,updated,5429,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2371,1,['update'],['updated']
Deployability,".1; backcall 0.2.0; brotli NA; certifi 2022.12.07; cffi 1.15.1; charset_normalizer 2.0.4; cloudpickle 2.2.1; comm 0.1.3; cycler 0.10.0; cython_runtime NA; dask 2023.5.1; dateutil 2.8.2; debugpy 1.6.7; decorator 5.1.1; defusedxml 0.7.1; entrypoints 0.4; executing 1.2.0; fasteners 0.18; fastjsonschema NA; fqdn NA; h5py 3.8.0; idna 3.4; igraph 0.10.4; ipykernel 6.23.1; isoduration NA; jedi 0.18.2; jinja2 3.1.2; joblib 1.2.0; json5 NA; jsonpointer 2.3; jsonschema 4.17.3; jupyter_events 0.6.3; jupyter_server 2.6.0; jupyterlab_server 2.22.1; kiwisolver 1.4.4; leidenalg 0.9.1; llvmlite 0.40.1; markupsafe 2.1.2; matplotlib 3.7.1; mpl_toolkits NA; msgpack 1.0.5; natsort 8.3.1; nbformat 5.8.0; numba 0.57.1; numcodecs 0.11.0; numpy 1.23.4; overrides NA; packaging 23.1; pandas 2.0.1; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; platformdirs 3.5.1; prometheus_client NA; prompt_toolkit 3.0.38; psutil 5.9.5; ptyprocess 0.7.0; pure_eval 0.2.2; pyarrow 12.0.1; pycparser 2.21; pydev_ipython NA; pydevconsole NA; pydevd 2.9.5; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.15.1; pynndescent 0.5.10; pyparsing 3.0.9; pyrsistent NA; pythonjsonlogger NA; pytz 2023.3; requests 2.28.1; rfc3339_validator 0.1.4; rfc3986_validator 0.1.1; scipy 1.10.1; send2trash NA; session_info 1.0.0; setuptools 66.0.0; six 1.16.0; sklearn 1.2.2; sniffio 1.3.0; socks 1.7.1; stack_data 0.6.2; tblib 2.0.0; texttable 1.6.7; threadpoolctl 3.1.0; tlz 0.12.0; toolz 0.12.0; torch 1.13.1; tornado 6.3.2; tqdm 4.65.0; traitlets 5.9.0; typing_extensions NA; umap 0.5.3; uri_template NA; urllib3 1.26.15; wcwidth 0.2.6; webcolors 1.13; websocket 1.5.2; yaml 6.0; zarr 2.14.2; zipp NA; zmq 25.1.0; zoneinfo NA; -----; IPython 8.13.2; jupyter_client 8.2.0; jupyter_core 5.3.0; jupyterlab 4.0.1; -----; Python 3.10.11 (main, Apr 20 2023, 19:02:41) [GCC 11.2.0]; Linux-3.10.0-1160.66.1.el7.x86_64-x86_64-with-glibc2.17; -----; Session information updated at 2023-08-02 14:21; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2587:4985,update,updated,4985,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2587,1,['update'],['updated']
Deployability,.2 py38h06a4308_0 ; boto 2.49.0 py38_0 ; bottleneck 1.3.2 py38heb32a55_1 ; brotlipy 0.7.0 py38h27cfd23_1003 ; bwidget 1.9.11 1 ; bzip2 1.0.8 h7b6447c_0 ; c-ares 1.17.1 h27cfd23_0 ; ca-certificates 2021.4.13 h06a4308_1 ; cached-property 1.5.2 py_0 ; cachetools 4.2.2 pypi_0 pypi; cairo 1.14.12 h8948797_3 ; capital 1.0.0 pypi_0 pypi; cellrank 1.2.0 pypi_0 pypi; certifi 2020.12.5 py38h06a4308_0 ; cffi 1.14.0 py38h2e261b9_0 ; chardet 4.0.0 py38h06a4308_1003 ; click 8.0.0 pypi_0 pypi; cloudpickle 1.6.0 py_0 ; clyent 1.2.2 py38_1 ; cmake 3.18.4.post1 pypi_0 pypi; colorama 0.4.4 pyhd3eb1b0_0 ; conda-pack 0.6.0 pyhd3eb1b0_0 ; contextlib2 0.6.0.post1 py_0 ; cryptography 3.4.7 py38hd23ed53_0 ; curl 7.69.1 hbc83047_0 ; cycler 0.10.0 py38_0 ; cython 0.29.22 pypi_0 pypi; cytoolz 0.11.0 py38h7b6447c_0 ; dask 2021.4.0 pyhd3eb1b0_0 ; dask-core 2021.4.0 pyhd3eb1b0_0 ; dbus 1.13.18 hb2f20db_0 ; decorator 5.0.9 pyhd3eb1b0_0 ; defusedxml 0.7.1 pyhd3eb1b0_0 ; deprecated 1.2.11 pypi_0 pypi; diff-match-patch 20200713 py_0 ; distributed 2021.5.0 py38h06a4308_0 ; docrep 0.3.2 pyh44b312d_0 conda-forge; docutils 0.17.1 py38h06a4308_1 ; dorothea-py 1.0.3 pypi_0 pypi; entrypoints 0.3 py38_0 ; et_xmlfile 1.1.0 py38h06a4308_0 ; expat 2.4.1 h2531618_2 ; fa2 0.3.5 pypi_0 pypi; fastcache 1.1.0 py38h7b6447c_0 ; fbpca 1.0 pypi_0 pypi; fcsparser 0.2.1 pypi_0 pypi; filelock 3.0.12 pyhd3eb1b0_1 ; flake8 3.9.0 pyhd3eb1b0_0 ; flask 1.1.2 pyhd3eb1b0_0 ; fontconfig 2.13.1 h6c09931_0 ; freetype 2.10.4 h5ab3b9f_0 ; fribidi 1.0.10 h7b6447c_0 ; fsspec 0.9.0 pyhd3eb1b0_0 ; funcargparse 0.2.3 pypi_0 pypi; future 0.18.2 py38_1 ; future_fstrings 1.2.0 py38h32f6830_2 conda-forge; gcc_impl_linux-64 7.3.0 habb00fd_1 ; gcc_linux-64 7.3.0 h553295d_15 ; geosketch 1.2 pypi_0 pypi; get_terminal_size 1.0.0 haa9412d_0 ; get_version 2.1 py_1 conda-forge; gevent 21.1.2 py38h27cfd23_1 ; gfortran_impl_linux-64 7.3.0 hdf63c60_1 ; gfortran_linux-64 7.3.0 h553295d_15 ; glib 2.63.1 h5a9c865_0 ; glob2 0.7 pyhd3eb1b0_0 ; gmp 6.2.1 h2531,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1850#issuecomment-847928310:6569,patch,patch,6569,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1850#issuecomment-847928310,1,['patch'],['patch']
Deployability,.3; llvmlite 0.42.0; locket 1.0.0; louvain 0.8.1; lz4 4.3.3; mapclassify 2.6.1; Markdown 3.5.2; markdown-it-py 3.0.0; MarkupSafe 2.1.5; matplotlib 3.8.3; matplotlib-inline 0.1.6; mdit-py-plugins 0.4.0; mdurl 0.1.2; mistune 3.0.2; msgpack 1.0.7; mudata 0.2.3; multidict 6.0.5; multipledispatch 0.6.0; munkres 1.1.4; muon 0.1.5; natsort 8.4.0; nbclient 0.8.0; nbconvert 7.16.2; nbformat 5.9.2; nbproject 0.10.1; nest_asyncio 1.6.0; networkx 3.2.1; notebook 7.1.1; notebook_shim 0.2.4; numba 0.59.0; numcodecs 0.12.1; numpy 1.24.4; nvtx 0.2.10; omnipath 1.0.8; openpyxl 3.1.2; orjson 3.9.15; overrides 7.7.0; packaging 24.0; pandas 1.5.3; pandocfilters 1.5.0; panel 1.3.8; param 2.0.2; parso 0.8.3; partd 1.4.1; patsy 0.5.6; pexpect 4.9.0; pickleshare 0.7.5; pillow 10.2.0; pip 24.0; pkgutil_resolve_name 1.3.10; platformdirs 4.2.0; pooch 1.8.1; prometheus_client 0.20.0; prompt-toolkit 3.0.42; protobuf 4.25.3; psutil 5.9.8; ptxcompiler 0.8.1; ptyprocess 0.7.0; pure-eval 0.2.2; pyarrow 14.0.2; pyarrow-hotfix 0.6; pycparser 2.21; pyct 0.5.0; pydantic 1.10.14; pyee 8.1.0; Pygments 2.17.2; pylibcugraph 24.2.0; pylibraft 24.2.0; pynndescent 0.5.11; pynvml 11.4.1; pyparsing 3.1.2; pyppeteer 1.0.2; pyproj 3.6.1; PySocks 1.7.1; python-dateutil 2.9.0; python-json-logger 2.0.7; pytometry 0.1.4; pytz 2024.1; pyviz_comms 3.0.1; PyWavelets 1.4.1; PyYAML 6.0.1; pyzmq 25.1.2; raft-dask 24.2.0; rapids_singlecell 0.9.6; readfcs 1.1.7; referencing 0.33.0; requests 2.31.0; rfc3339-validator 0.1.4; rfc3986-validator 0.1.1; rich 13.7.1; rmm 24.2.0; rpds-py 0.18.0; Rtree 1.2.0; scanpy 1.10.0rc2; scikit-image 0.22.0; scikit-learn 1.4.1.post1; scikit-misc 0.3.1; scipy 1.12.0; seaborn 0.13.2; Send2Trash 1.8.2; session-info 1.0.0; setuptools 69.1.1; shapely 2.0.3; simpervisor 1.0.0; single_cell_helper 0.0.1 ; six 1.16.0; sniffio 1.3.1; sortedcontainers 2.4.0; soupsieve 2.5; stack-data 0.6.2; statsmodels 0.14.1; stdlib-list 0.10.0; streamz 0.6.4; tblib 3.0.0; terminado 0.18.0; texttable 1.7.0; threadpoolctl,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2964:4897,hotfix,hotfix,4897,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2964,1,['hotfix'],['hotfix']
Deployability,".5.1; win32api NA; win32com NA; win32security NA; yaml 5.3.1; zmq 19.0.2; zope NA; -----; IPython 7.19.0; jupyter_client 6.1.7; jupyter_core 4.6.3; jupyterlab 2.2.6; notebook 6.1.4; -----; Python 3.8.5 (default, Sep 3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]; Windows-10-10.0.19041-SP0; 4 logical CPU cores, Intel64 Family 6 Model 78 Stepping 3, GenuineIntel; -----; Session information updated at 2021-09-09 14:23. </details>\. Reading this stackoverflow (https://stackoverflow.com/questions/58518554/attributeerror-graph-object-has-no-attribute-node) I tried downgrading to networkx version 2.3 instead of 2.6.2 and it fixed this issue, but raised a separate incompatibility between networkx and matplotlib. ```pytb; AttributeError: module 'matplotlib.cbook' has no attribute 'iterable'; ```; ; which traces back to an issue in networkx rather than scanpy.; The following stackoverflow suggests that the older networkx2.3 requires matplotlib2.2.3 which is quite a large downgrade from my current matplatlib3.4.3 (current as of this date), so downgrading both networkx and matplotlib is not a great solution: https://stackoverflow.com/questions/63198347/attributeerror-module-matplotlib-cbook-has-no-attribute-iterable,. How i fixed it: ; After all that I went to line 860-862 of plotting/_tools/paga.py in my own scanpy installation and simply changed all the 'node' to 'nodes':; ```python; for count, n in enumerate(nx_g_solid.nodes()):; nx_g_solid.node[count]['label'] = str(node_labels[count]); nx_g_solid.node[count]['color'] = str(colors[count]); nx_g_solid.node[count]['viz'] = dict(; ```; to; ```python; for count, n in enumerate(nx_g_solid.nodes()):; nx_g_solid.nodes[count]['label'] = str(node_labels[count]); nx_g_solid.nodes[count]['color'] = str(colors[count]); nx_g_solid.nodes[count]['viz'] = dict(; ```. which apparently solved the issue; ```pytb; gexf=sc.pl.paga(paul15, labels=None, color='paul15_clusters', export_to_gexf=True); WARNING: exporting to write\paga_graph.gexf; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1997:3525,install,installation,3525,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1997,1,['install'],['installation']
Deployability,".6218119e-04]]; ```. #### Versions. I am running scanpy in this singularity container: https://singularity-hub.org/collections/5095. <details>. ```. -----; anndata 0.7.5; scanpy 1.7.1; sinfo 0.3.1; -----; PIL 8.1.2; anndata 0.7.5; anyio NA; attr 20.3.0; babel 2.9.0; backcall 0.2.0; bottleneck 1.3.2; brotli NA; cairo 1.20.0; certifi 2020.12.05; cffi 1.14.5; chardet 4.0.0; cloudpickle 1.6.0; colorama 0.4.4; constants NA; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2021.03.0; dateutil 2.8.1; decorator 4.4.2; future_fstrings NA; get_version 2.1; google NA; h5py 3.1.0; highs_wrapper NA; idna 2.10; igraph 0.8.3; ipykernel 5.5.0; ipython_genutils 0.2.0; jedi 0.18.0; jinja2 2.11.3; joblib 1.0.1; json5 NA; jsonschema 3.2.0; jupyter_server 1.4.1; jupyterlab_server 2.3.0; kiwisolver 1.3.1; legacy_api_wrap 0.0.0; leidenalg 0.8.3; llvmlite 0.35.0; louvain 0.7.0; markupsafe 1.1.1; matplotlib 3.3.4; mpl_toolkits NA; natsort 7.1.1; nbclassic NA; nbformat 5.1.2; numba 0.52.0; numexpr 2.7.3; numpy 1.20.1; packaging 20.9; pandas 1.2.3; parso 0.8.1; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prometheus_client NA; prompt_toolkit 3.0.17; psutil 5.8.0; ptyprocess 0.7.0; pvectorc NA; pycparser 2.20; pygments 2.8.1; pynndescent 0.5.2; pyparsing 2.4.7; pyrsistent NA; pytz 2021.1; requests 2.25.1; scanpy 1.7.1; scipy 1.6.0; send2trash NA; setuptools_scm NA; sinfo 0.3.1; six 1.15.0; sklearn 0.24.1; sniffio 1.2.0; socks 1.7.1; sparse 0.11.2; sphinxcontrib NA; statsmodels 0.12.2; storemagic NA; tables 3.6.1; texttable 1.6.3; tlz 0.11.0; toolz 0.11.1; tornado 6.1; traitlets 5.0.5; typing_extensions NA; umap 0.4.6; urllib3 1.26.3; wcwidth 0.2.5; yaml 5.4.1; zmq 22.0.3; zope NA; -----; IPython 7.21.0; jupyter_client 6.1.11; jupyter_core 4.7.1; jupyterlab 3.0.10; notebook 6.2.0; -----; Python 3.8.5 (default, Sep 4 2020, 07:30:14) [GCC 7.3.0]; Linux-5.8.0-44-generic-x86_64-with-glibc2.10; 28 logical CPU cores; -----; Session information updated at 2021-03-18 12:37. ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1749:3516,update,updated,3516,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1749,1,['update'],['updated']
Deployability,".8/site-packages/IPython/core/interactiveshell.py"", line 3441, in run_code; exec(code_obj, self.user_global_ns, self.user_ns); File ""<ipython-input-52-9844c466c985>"", line 1, in <module>; sc.pl.scatter(adata, x='X', y='Y', color=['paul15_clusters', 'batch']); File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/scanpy/plotting/_anndata.py"", line 131, in scatter; and (color is None or color in adata.obs.keys() or color in adata.var.index); File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/pandas/core/indexes/base.py"", line 4572, in __contains__; hash(key); TypeError: unhashable type: 'list'; ```. #### Versions. <details>. ```; -----; anndata 0.7.6; scanpy 1.8.1; sinfo 0.3.1; -----; IPython 7.25.0; PIL 8.3.1; anndata 0.7.6; backcall 0.2.0; backend_interagg NA; beta_ufunc NA; binom_ufunc NA; cffi 1.14.6; colorama 0.4.4; console_thrift NA; cycler 0.10.0; cython_runtime NA; datalore NA; dateutil 2.8.1; decorator 4.4.2; defusedxml 0.7.1; h5py 2.10.0; igraph 0.9.6; ipython_genutils 0.2.0; jedi 0.18.0; joblib 1.0.1; kiwisolver 1.3.1; llvmlite 0.36.0; louvain 0.7.0; matplotlib 3.4.2; mpl_toolkits NA; natsort 7.1.1; nbinom_ufunc NA; numba 0.53.1; numexpr 2.7.3; numpy 1.18.1; packaging 20.9; pandas 1.3.1; parso 0.8.2; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.19; psutil 5.8.0; ptyprocess 0.7.0; pycparser 2.20; pydev_console NA; pydev_ipython NA; pydevconsole NA; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.9.0; pynndescent 0.5.4; pyparsing 2.4.7; pytz 2021.1; scanpy 1.8.1; scipy 1.7.0; sinfo 0.3.1; sitecustomize NA; six 1.16.0; sklearn 0.24.2; sphinxcontrib NA; tables 3.6.1; texttable 1.6.4; tqdm 4.61.2; traitlets 5.0.5; umap 0.5.1; wcwidth 0.2.5; -----; Python 3.8.10 | packaged by conda-forge | (default, May 11 2021, 07:01:05) [GCC 9.3.0]; Linux-5.13.10-200.fc34.x86_64-x86_64-with-glibc2.10; 16 logical CPU cores; -----; Session information updated at 2021-08-26 10:01. ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1986:2653,update,updated,2653,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1986,1,['update'],['updated']
Deployability,".com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug.; scvi does not have models class anymore to access VAE and LDVAE, please change it to use scvi.module. ### Minimal code sample (that we can copy&paste without having any data). ```python; import scanpy as sc; sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'); ```. ```pytb; File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 116, in scvi; from scvi.models import VAE, LDVAE; ModuleNotFoundError: No module named 'scvi.models'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/data/lab/MCF7/for_PAGA/MCF7_batch_attempt1.py"", line 140, in <module>; sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'); File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 120, in scvi; raise ImportError(; ImportError: Please install scvi package from https://github.com/YosefLab/scVI. ```. #### Versions; >>> scanpy.logging.print_versions() ; WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.5; scanpy 1.7.1; sinfo 0.3.1; -----; PIL 8.2.0; anndata 0.7.5; cffi 1.14.5; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; get_version 2.1; google NA; h5py 3.2.1; igraph 0.9.1; joblib 1.0.1; kiwisolver 1.3.1; legacy_api_wrap 1.2; leidenalg 0.8.3; llvmlite 0.36.0; matplotlib 3.4.1; mpl_toolkits NA; natsort 7.1.1; numba 0.53.1; numexpr 2.7.3; numpy 1.20.2; packaging 20.9; pandas 1.2.3; pkg_resources NA; pyexpat NA; pyparsing 2.4.7; pytz 2021.1; scanpy 1.7.1; scipy 1.6.2; setuptools_scm NA; sinfo 0.3.1; six 1.15.0; sklearn 0.24.1; sphinxcontrib NA; tables 3.6.1; texttable 1.6.3; typing_extensions NA; wcwidth 0.2.5; yaml 5.3.1; -----; Python 3.9.4 (default, Apr 5 2021, 15:43:56) [GCC 7.3.1 20180303 (Red Hat 7.3.1-5)]; Linux-3.10.0-1160.11.1.el7.x86_64-x86_64-wit",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1781:1300,install,install,1300,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1781,1,['install'],['install']
Deployability,".egg-info/dependency_links.txt; writing scanpy.egg-info/PKG-INFO; writing top-level names to scanpy.egg-info/top_level.txt; writing requirements to scanpy.egg-info/requires.txt; warning: manifest_maker: standard file '-c' not found; ; reading manifest file 'scanpy.egg-info/SOURCES.txt'; reading manifest template 'MANIFEST.in'; writing manifest file 'scanpy.egg-info/SOURCES.txt'; Traceback (most recent call last):; File ""<string>"", line 1, in <module>; File ""/tmp/pip-build-33o4crd7/scanpy/setup.py"", line 51, in <module>; 'Topic :: Scientific/Engineering :: Visualization',; File ""/usr/lib/python3.5/distutils/core.py"", line 148, in setup; dist.run_commands(); File ""/usr/lib/python3.5/distutils/dist.py"", line 955, in run_commands; self.run_command(cmd); File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command; cmd_obj.run(); File ""/usr/lib/python3/dist-packages/setuptools/command/install.py"", line 61, in run; return orig.install.run(self); File ""/usr/lib/python3.5/distutils/command/install.py"", line 583, in run; self.run_command('build'); File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command; self.distribution.run_command(command); File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command; cmd_obj.run(); File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run; self.run_command(cmd_name); File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command; self.distribution.run_command(command); File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command; cmd_obj.run(); File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run; _build_py.run(self); File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run; self.build_package_data(); File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data; for package, src_dir, build_dir, filenames in self.data_files:; File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/355:9821,install,install,9821,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355,1,['install'],['install']
Deployability,".egg-info\requires.txt; writing top-level names to fa2.egg-info\top_level.txt; reading manifest file 'fa2.egg-info\SOURCES.txt'; reading manifest template 'MANIFEST.in'; writing manifest file 'fa2.egg-info\SOURCES.txt'; copying fa2\fa2util.c -> build\lib.win-amd64-3.6\fa2; copying fa2\fa2util.pxd -> build\lib.win-amd64-3.6\fa2; running build_ext; skipping 'fa2\fa2util.c' Cython extension (up-to-date); building 'fa2.fa2util' extension; error: Microsoft Visual C++ 14.0 is required. Get it with ""Build Tools for Visual Studio"": https://visualstudio.microsoft.com/downloads/; ----------------------------------------; ERROR: Failed building wheel for fa2; Running setup.py clean for fa2; Failed to build fa2; Installing collected packages: fa2; Running setup.py install for fa2 ... error. ERROR: Command errored out with exit status 1:; command: 'C:\ProgramData\Miniconda3\envs\Jayalal_2_Miniconda\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""'; __file__='""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' install --record 'C:\Users\xkalaj\AppData\Local\Temp\pip-record-y21s2idm\install-record.txt' --single-version-externally-managed --compile --install-headers 'C:\ProgramData\Miniconda3\envs\Jayalal_2_Miniconda\Include\fa2'; cwd: C:\Users\xkalaj\AppData\Local\Temp\pip-install-golo7r_8\fa2\; Complete output (30 lines):; Installing fa2 package (fastest forceatlas2 python implementation). >>>> Cython is installed?; Yes. >>>> Starting to install!. running install; running build; running build_py; creating build; creating build\lib.win-amd64-3.6; creating build\lib.win-amd64-3.6\fa2; copying fa2\fa2util.py -> build\lib.win-amd64-3.6\fa2; copying fa2\forceatlas2.py -> build\lib.win-amd64-3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1256:3233,install,install-,3233,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1256,1,['install'],['install-']
Deployability,.io/gh/scverse/scanpy/pull/3182?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `94.33962%` with `3 lines` in your changes missing coverage. Please review.; > Project coverage is 76.58%. Comparing base [(`d3de744`)](https://app.codecov.io/gh/scverse/scanpy/commit/d3de7442615eb89999abb741ad28825688199de3?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`6c895e8`)](https://app.codecov.io/gh/scverse/scanpy/commit/6c895e8b0e3ecef999924d1c3998b19affe10d8d?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 52 commits behind head on main. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3182?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Patch % | Lines |; |---|---|---|; | [src/scanpy/tools/\_umap.py](https://app.codecov.io/gh/scverse/scanpy/pull/3182?src=pr&el=tree&filepath=src%2Fscanpy%2Ftools%2F_umap.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS90b29scy9fdW1hcC5weQ==) | 66.66% | [2 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3182?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) |; | [src/scanpy/\_utils/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/3182?src=pr&el=tree&filepath=src%2Fscanpy%2F_utils%2F__init__.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9fdXRpbHMvX19pbml0X18ucHk=) | 93.33% | [1 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3182?src=pr&el=tree&utm_medium=referral&utm_source=,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3182#issuecomment-2446491018:1085,Patch,Patch,1085,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3182#issuecomment-2446491018,1,['Patch'],['Patch']
Deployability,.io/gh/scverse/scanpy/pull/3303?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `87.50000%` with `3 lines` in your changes missing coverage. Please review.; > Project coverage is 76.91%. Comparing base [(`388aae5`)](https://app.codecov.io/gh/scverse/scanpy/commit/388aae5fe140ee09c1b3f8c4a84f14667823f31b?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`81f4aa3`)](https://app.codecov.io/gh/scverse/scanpy/commit/81f4aa39a45739c2f832b0f452ad07b717bcecc6?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 2 commits behind head on 1.10.x. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3303?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Patch % | Lines |; |---|---|---|; | [src/scanpy/external/pl.py](https://app.codecov.io/gh/scverse/scanpy/pull/3303?src=pr&el=tree&filepath=src%2Fscanpy%2Fexternal%2Fpl.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9leHRlcm5hbC9wbC5weQ==) | 0.00% | [2 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3303?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) |; | [src/scanpy/plotting/\_utils.py](https://app.codecov.io/gh/scverse/scanpy/pull/3303?src=pr&el=tree&filepath=src%2Fscanpy%2Fplotting%2F_utils.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9wbG90dGluZy9fdXRpbHMucHk=) | 83.33% | [1 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3303?src=pr&el=tree&utm_medium=referral&utm_source=github,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3303#issuecomment-2427060248:1086,Patch,Patch,1086,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3303#issuecomment-2427060248,1,['Patch'],['Patch']
Deployability,.off-groups.all] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[toarray-float32-200n-100theta-infclip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[toarray-int64-200n-100theta-30clip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[toarray-int64-100n-inftheta-infclip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[toarray-int64-200n-inftheta-noclip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[toarray-int64-100n-inftheta-infclip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[toarray-float32-200n-100theta-infclip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-100n-inftheta-noclip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[toarray-int64-200n-inftheta-noclip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILE,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:16896,pipeline,pipeline,16896,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['pipeline'],['pipeline']
Deployability,".patch.draw(renderer); -> 2790 mimage._draw_list_compositing_images(; 2791 renderer, self, artists, self.suppressComposite); 2793 for sfig in self.subfigs:; 2794 sfig.draw(renderer). File ~/anaconda3/envs/ml/lib/python3.9/site-packages/matplotlib/image.py:132, in _draw_list_compositing_images(renderer, parent, artists, suppress_composite); 130 if not_composite or not has_images:; 131 for a in artists:; --> 132 a.draw(renderer); 133 else:; 134 # Composite any adjacent images together; 135 image_group = []. File ~/anaconda3/envs/ml/lib/python3.9/site-packages/matplotlib/artist.py:51, in allow_rasterization.<locals>.draw_wrapper(artist, renderer, *args, **kwargs); 48 if artist.get_agg_filter() is not None:; 49 renderer.start_filter(); ---> 51 return draw(artist, renderer, *args, **kwargs); 52 finally:; 53 if artist.get_agg_filter() is not None:. File ~/anaconda3/envs/ml/lib/python3.9/site-packages/mpl_toolkits/mplot3d/axes3d.py:485, in Axes3D.draw(self, renderer); 480 # Calculate projection of collections and patches and zorder them.; 481 # Make sure they are drawn above the grids.; 482 zorder_offset = max(axis.get_zorder(); 483 for axis in self._get_axis_list()) + 1; 484 for i, col in enumerate(; --> 485 sorted(self.collections,; 486 key=do_3d_projection,; 487 reverse=True)):; 488 col.zorder = zorder_offset + i; 489 for i, patch in enumerate(; 490 sorted(self.patches,; 491 key=do_3d_projection,; 492 reverse=True)):. File ~/anaconda3/envs/ml/lib/python3.9/site-packages/mpl_toolkits/mplot3d/axes3d.py:471, in Axes3D.draw.<locals>.do_3d_projection(artist); 458 """"""; 459 Call `do_3d_projection` on an *artist*, and warn if passing; 460 *renderer*.; (...); 464 *renderer* and raise a warning.; 465 """"""; 467 if artist.__module__ == 'mpl_toolkits.mplot3d.art3d':; 468 # Our 3D Artists have deprecated the renderer parameter, so; 469 # avoid passing it to them; call this directly once the; 470 # deprecation has expired.; --> 471 return artist.do_3d_projection(); 473 _api.warn_deprec",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2285:8117,patch,patches,8117,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2285,1,['patch'],['patches']
Deployability,".py in _compile_cached(self, args, return_type); 137 ; 138 try:; --> 139 retval = self._compile_core(args, return_type); 140 except errors.TypingError as e:; 141 self._failed_cache[key] = e. C:\ProgramData\Anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_core(self, args, return_type); 150 ; 151 impl = self._get_implementation(args, {}); --> 152 cres = compiler.compile_extra(self.targetdescr.typing_context,; 153 self.targetdescr.target_context,; 154 impl,. C:\ProgramData\Anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class); 150 ; 151 impl = self._get_implementation(args, {}); --> 152 cres = compiler.compile_extra(self.targetdescr.typing_context,; 153 self.targetdescr.target_context,; 154 impl,. C:\ProgramData\Anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class); 714 pipeline = pipeline_class(typingctx, targetctx, library,; 715 args, return_type, flags, locals); --> 716 return pipeline.compile_extra(func); 717 ; 718 . C:\ProgramData\Anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(self, func); 450 self.state.lifted = (); 451 self.state.lifted_from = None; --> 452 return self._compile_bytecode(); 453 ; 454 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. C:\ProgramData\Anaconda3\lib\site-packages\numba\core\compiler.py in _compile_bytecode(self); 518 """"""; 519 assert self.state.func_ir is None; --> 520 return self._compile_core(); 521 ; 522 def _compile_ir(self):. C:\ProgramData\Anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self); 497 self.state.status.fail_reason = e; 498 if is_final_pipeline:; --> 499 raise e; 500 else:; 501 raise CompilerError(""All available pipelines exhausted""). C:\ProgramData\Anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self); 484 res = None; 485 try:; --> 4",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1756#issuecomment-1319286325:7433,pipeline,pipeline,7433,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1756#issuecomment-1319286325,2,['pipeline'],['pipeline']
Deployability,".py in reindex_indexer(self, new_axis, indexer, axis, fill_value, allow_dups, copy, consolidate, only_slice); 668 # some axes don't allow reindexing with dups; 669 if not allow_dups:; --> 670 self.axes[axis]._validate_can_reindex(indexer); 671 ; 672 if axis >= self.ndim:. ~/.local/lib/python3.7/site-packages/pandas/core/indexes/base.py in _validate_can_reindex(self, indexer); 3783 # trying to reindex on an axis with duplicates; 3784 if not self._index_as_unique and len(indexer):; -> 3785 raise ValueError(""cannot reindex from a duplicate axis""); 3786 ; 3787 def reindex(. ValueError: cannot reindex from a duplicate axis. ```. #### Versions. <details>. -----; anndata 0.7.5; scanpy 1.9.1; -----; PIL 7.2.0; backcall 0.1.0; beta_ufunc NA; binom_ufunc NA; bottleneck 1.3.2; cffi 1.14.0; cloudpickle 1.3.0; colorama 0.4.3; cycler 0.10.0; cython_runtime NA; cytoolz 0.10.1; dask 2.13.0; dateutil 2.8.1; decorator 4.4.2; google NA; h5py 2.10.0; igraph 0.9.7; ipykernel 5.1.4; ipython_genutils 0.2.0; jedi 0.15.2; joblib 0.17.0; kiwisolver 1.1.0; leidenalg 0.8.8; llvmlite 0.39.1; louvain 0.7.0; matplotlib 3.5.3; mpl_toolkits NA; natsort 7.0.1; nbinom_ufunc NA; numba 0.56.2; numexpr 2.7.3; numpy 1.21.6; packaging 20.3; pandas 1.3.4; parso 0.5.2; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.4; psutil 5.7.0; ptyprocess 0.6.0; pygments 2.6.1; pyparsing 2.4.6; pyteomics NA; pytz 2019.3; scipy 1.7.1; session_info 1.0.0; setuptools_scm NA; six 1.14.0; sklearn 1.0.2; sphinxcontrib NA; storemagic NA; tblib 1.6.0; texttable 1.6.3; threadpoolctl 2.1.0; tlz 0.10.1; toolz 0.10.0; tornado 6.0.4; traitlets 4.3.3; typing_extensions NA; wcwidth NA; yaml 5.3.1; zipp NA; zmq 17.1.2; -----; IPython 7.13.0; jupyter_client 6.1.2; jupyter_core 4.6.3; jupyterlab 1.2.6; notebook 6.0.3; -----; Python 3.7.3 (default, Mar 27 2019, 22:11:17) [GCC 7.3.0]; Linux-3.10.0-957.12.2.el7.x86_64-x86_64-with-centos-7.6.1810-Core; -----; Session information updated at 2022-10-25 16:14. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2364:6933,update,updated,6933,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2364,1,['update'],['updated']
Deployability,".score_genes(adata, ['0']). ~/miniconda3/envs/spols200618/lib/python3.7/site-packages/scanpy/tools/_score_genes.py in score_genes(adata, gene_list, ctrl_size, gene_pool, n_bins, score_name, random_state, copy, use_raw); 174 elif len(gene_list) == 1:; 175 if _adata[:, gene_list].X.ndim == 2:; --> 176 vector = _adata[:, gene_list].X.toarray()[:, 0] # new anndata; 177 else:; 178 vector = _adata[:, gene_list].X # old anndata. AttributeError: 'numpy.ndarray' object has no attribute 'toarray'; ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.4; scanpy 1.6.0; sinfo 0.3.1; -----; PIL 7.1.2; anndata 0.7.4; backcall 0.2.0; bottleneck 1.3.2; cairo 1.19.1; cffi 1.14.0; cloudpickle 1.3.0; colorama 0.4.3; cycler 0.10.0; cython_runtime NA; dask 2.18.1; dateutil 2.8.1; decorator 4.4.2; get_version 2.1; google NA; h5py 2.10.0; igraph 0.8.2; importlib_metadata 1.6.1; ipykernel 5.3.0; ipyparallel 6.3.0; ipython_genutils 0.2.0; jedi 0.17.0; joblib 0.15.1; kiwisolver 1.2.0; legacy_api_wrap 0.0.0; leidenalg 0.8.0; llvmlite 0.32.1; louvain 0.7.0; matplotlib 3.2.1; mpl_toolkits NA; natsort 7.0.1; numba 0.49.1; numexpr 2.7.1; numpy 1.17.5; packaging 20.4; pandas 1.0.5; parso 0.7.0; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.5; psutil 5.7.0; ptyprocess 0.6.0; pygments 2.6.1; pyparsing 2.4.7; pytz 2020.1; scanpy 1.6.0; scipy 1.4.1; setuptools_scm NA; sinfo 0.3.1; six 1.15.0; sklearn 0.23.1; storemagic NA; tables 3.6.1; texttable 1.6.2; tlz 0.10.0; toolz 0.10.0; tornado 6.0.4; traitlets 4.3.3; typing_extensions NA; wcwidth 0.2.4; yaml 5.3.1; zipp NA; zmq 19.0.1; -----; IPython 7.15.0; jupyter_client 6.1.3; jupyter_core 4.6.3; jupyterlab 2.1.4; notebook 6.0.3; -----; Python 3.7.6 | packaged by conda-forge | (default, Jun 1 2020, 18:57:50) [GCC 7.5.0]; Linux-4.12.14-lp151.28.44-default-x86_64-with-glibc2.10; 16 logical CPU cores, x86_64; -----; Session information updated at 2020-08-28 14:42. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1395:2754,update,updated,2754,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1395,1,['update'],['updated']
Deployability,".vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/parsers/readers.py:1885) memory_map=self.options.get(""memory_map"", False),; [1886](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/parsers/readers.py:1886) is_text=is_text,; [1887](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/parsers/readers.py:1887) errors=self.options.get(""encoding_errors"", ""strict""),; [1888](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/parsers/readers.py:1888) storage_options=self.options.get(""storage_options"", None),; [1889](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/parsers/readers.py:1889) ); [1890](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/parsers/readers.py:1890) assert self.handles is not None; [1891](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/parsers/readers.py:1891) f = self.handles.handle. File ~\AppData\Roaming\Python\Python312\site-packages\pandas\io\common.py:765, in get_handle(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options); [761](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/common.py:761) if compression == ""gzip"":; [762](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3214:15185,Pipeline,PipelineDevelope,15185,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3214,1,['Pipeline'],['PipelineDevelope']
Deployability,"/Python/3.6.0/lib/python3.6/distutils/command/build.py"", line 135, in run; self.run_command(cmd_name); File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/cmd.py"", line 313, in run_command; self.distribution.run_command(command); File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 974, in run_command; cmd_obj.run(); File ""/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/versioneer.py"", line 1555, in run; _build_py.run(self); File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 47, in run; File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 103, in build_package_data; File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 59, in __getattr__; File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 86, in _get_data_files; File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 94, in find_data_files; TypeError: must be str, not list. ----------------------------------------; Command ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/bin/python -u -c ""import setuptools, tokenize;__file__='/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /tmp/xs-ttgump/pip-record-v4z7bmhr/install-record.txt --single-version-externally-managed --compile --user --prefix="" failed with error code 1 in /tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/148:7871,install,install-,7871,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148,4,['install'],"['install', 'install-', 'install-record']"
Deployability,"/Python312/site-packages/scanpy/readwrite.py:593) ).T # transpose the data; --> [594](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/scanpy/readwrite.py:594) genes = pd.read_csv(; [595](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/scanpy/readwrite.py:595) path / f""{prefix}{'genes' if is_legacy else 'features'}.tsv{suffix}"",; [596](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/scanpy/readwrite.py:596) header=None,; [597](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/scanpy/readwrite.py:597) sep=""\t"",; [598](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/scanpy/readwrite.py:598) ); [599](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/scanpy/readwrite.py:599) if var_names == ""gene_symbols"":; [600](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/scanpy/readwrite.py:600) var_names_idx = pd.Index(genes[1].values). File ~\AppData\Roaming\Python\Python312\site-packages\pandas\io\parsers\readers.py:1026, in read_csv(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminato",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3214:7829,Pipeline,PipelineDevelope,7829,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3214,1,['Pipeline'],['PipelineDevelope']
Deployability,"/Roaming/Python/Python312/site-packages/pandas/io/parsers/readers.py:1024) kwds.update(kwds_defaults); -> [1026](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/parsers/readers.py:1026) return _read(filepath_or_buffer, kwds). File ~\AppData\Roaming\Python\Python312\site-packages\pandas\io\parsers\readers.py:620, in _read(filepath_or_buffer, kwds); [617](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/parsers/readers.py:617) _validate_names(kwds.get(""names"", None)); [619](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/parsers/readers.py:619) # Create the parser.; --> [620](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/parsers/readers.py:620) parser = TextFileReader(filepath_or_buffer, **kwds); [622](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/parsers/readers.py:622) if chunksize or iterator:; [623](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/parsers/readers.py:623) return parser. File ~\AppData\Roaming\Python\Python312\site-packages\pandas\io\parsers\readers.py:1620, in TextFileReader.__init__(self, f, engine, **kwds); [1617](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/parsers/readers.py:1617) self.options[""has_index_names""] = kwds[""has_index_names""]; [1619](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/Pip",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3214:11161,Pipeline,PipelineDevelope,11161,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3214,1,['Pipeline'],['PipelineDevelope']
Deployability,"/core/typing/npydecl.py:254; - Of which 2 did not match due to:; Operator Overload in function 'iadd': File: unknown: Line unknown.; With argument(s): '(array(bool, 1d, C), array(int64, 1d, C))':; No match for registered cases:; * (int64, int64) -> int64; * (int64, uint64) -> int64; * (uint64, int64) -> int64; * (uint64, uint64) -> uint64; * (float32, float32) -> float32; * (float64, float64) -> float64; * (complex64, complex64) -> complex64; * (complex128, complex128) -> complex128. During: typing of intrinsic-call at /home/sunhao/.conda/envs/h5ad/lib/python3.9/site-packages/scanpy/preprocessing/_qc.py (449). File "".conda/envs/h5ad/lib/python3.9/site-packages/scanpy/preprocessing/_qc.py"", line 449:; def top_segment_proportions_sparse_csr(data, indptr, ns):; <source elided>; for j in range(ns.size):; acc += partitioned[:, prev : ns[j]].sum(axis=1); ```. ### Versions. <details>. ```; >>> import scanpy; scanpy.logging.print_versions(); -----; anndata 0.10.2; scanpy 1.9.6; -----; PIL 10.0.1; beta_ufunc NA; binom_ufunc NA; cffi 1.15.1; cloudpickle 3.0.0; colorama 0.4.6; cycler 0.12.1; cython_runtime NA; cytoolz 0.12.0; dask 2023.11.0; dateutil 2.8.2; exceptiongroup 1.1.3; fastcore 1.5.29; get_annotations NA; h5py 3.7.0; hypergeom_ufunc NA; importlib_resources NA; invgauss_ufunc NA; joblib 1.3.2; kiwisolver 1.4.4; llvmlite 0.41.1; matplotlib 3.8.1; mkl 2.4.0; mpl_toolkits NA; natsort 8.4.0; nbinom_ufunc NA; ncf_ufunc NA; nct_ufunc NA; ncx2_ufunc NA; numba 0.58.1; numpy 1.23.5; packaging 23.2; pandas 1.2.4; psutil 5.9.0; pycparser 2.21; pyparsing 3.0.9; pytz 2023.3.post1; scDenorm NA; scipy 1.10.1; session_info 1.0.0; setuptools 68.0.0; six 1.16.0; skewnorm_ufunc NA; sklearn 1.3.0; threadpoolctl 3.2.0; tlz 0.12.0; toolz 0.12.0; tqdm 4.66.1; typing_extensions NA; yaml 6.0; zipp NA; -----; Python 3.9.13 (main, Oct 13 2022, 21:15:33) [GCC 11.2.0]; Linux-3.10.0-1160.102.1.el7.x86_64-x86_64-with-glibc2.17; -----; Session information updated at 2023-11-17 16:20; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2758:5134,update,updated,5134,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2758,1,['update'],['updated']
Deployability,"/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, args, return_type); 77 ; 78 def compile(self, args, return_type):; ---> 79 status, retval = self._compile_cached(args, return_type); 80 if status:; 81 return retval; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_cached(self, args, return_type); 91 ; 92 try:; ---> 93 retval = self._compile_core(args, return_type); 94 except errors.TypingError as e:; 95 self._failed_cache[key] = e; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_core(self, args, return_type); 104 ; 105 impl = self._get_implementation(args, {}); --> 106 cres = compiler.compile_extra(self.targetdescr.typing_context,; 107 self.targetdescr.target_context,; 108 impl,; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class); 604 pipeline = pipeline_class(typingctx, targetctx, library,; 605 args, return_type, flags, locals); --> 606 return pipeline.compile_extra(func); 607 ; 608 ; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in compile_extra(self, func); 351 self.state.lifted = (); 352 self.state.lifted_from = None; --> 353 return self._compile_bytecode(); 354 ; 355 def compile_ir(self, func_ir, lifted=(), lifted_from=None):; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_bytecode(self); 413 """"""; 414 assert self.state.func_ir is None; --> 415 return self._compile_core(); 416 ; 417 def _compile_ir(self):; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_core(self); 393 self.state.status.fail_reason = e; 394 if is_final_pipeline:; --> 395 raise e; 396 else:; 397 raise CompilerError(""All available pipelines exhausted""); ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _com",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1799:4919,pipeline,pipeline,4919,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799,2,['pipeline'],['pipeline']
Deployability,/gh/scverse/scanpy/pull/3088?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `66.66667%` with `3 lines` in your changes missing coverage. Please review.; > Project coverage is 78.58%. Comparing base [(`698313b`)](https://app.codecov.io/gh/scverse/scanpy/commit/698313b5f38ed726c5b8093c155482d1bfdaf4bc?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`63253ab`)](https://app.codecov.io/gh/scverse/scanpy/commit/63253ab59f2799350c43631bf4033362d3f913bb?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 42 commits behind head on 1.10.x. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3088?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Patch % | Lines |; |---|---|---|; | [scanpy/external/exporting.py](https://app.codecov.io/gh/scverse/scanpy/pull/3088?src=pr&el=tree&filepath=scanpy%2Fexternal%2Fexporting.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L2V4dGVybmFsL2V4cG9ydGluZy5weQ==) | 0.00% | [2 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3088?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) |; | [scanpy/preprocessing/\_combat.py](https://app.codecov.io/gh/scverse/scanpy/pull/3088?src=pr&el=tree&filepath=scanpy%2Fpreprocessing%2F_combat.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3ByZXByb2Nlc3NpbmcvX2NvbWJhdC5weQ==) | 0.00% | [1 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3088?src=pr&el=tree&utm_medium=referral&utm_s,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3088#issuecomment-2144755688:1087,Patch,Patch,1087,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3088#issuecomment-2144755688,1,['Patch'],['Patch']
Deployability,/gh/scverse/scanpy/pull/3227?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `50.00000%` with `2 lines` in your changes missing coverage. Please review.; > Project coverage is 76.62%. Comparing base [(`bec794c`)](https://app.codecov.io/gh/scverse/scanpy/commit/bec794c7e7e28393e7cb6ae6624ecdbd187868ac?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`8d1cb04`)](https://app.codecov.io/gh/scverse/scanpy/commit/8d1cb04fbff869dd70d1b452477b83c151237e4a?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 35 commits behind head on main. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3227?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Patch % | Lines |; |---|---|---|; | [src/scanpy/preprocessing/\_pca.py](https://app.codecov.io/gh/scverse/scanpy/pull/3227?src=pr&el=tree&filepath=src%2Fscanpy%2Fpreprocessing%2F_pca.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9wcmVwcm9jZXNzaW5nL19wY2EucHk=) | 50.00% | [2 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3227?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) |. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3227 +/- ##; ==========================================; - Coverage 76.63% 76.62% -0.02% ; ==========================================; Files 109 109 ; Lines 12533 12536 +3 ; ==========================================; + Hits 9605 9606 +1 ; - Misses 2928 2930 +2 ; ```. | [Files with missing lines](https:,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3227#issuecomment-2346840063:1085,Patch,Patch,1085,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3227#issuecomment-2346840063,1,['Patch'],['Patch']
Deployability,/gh/scverse/scanpy/pull/3275?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `88.88889%` with `1 line` in your changes missing coverage. Please review.; > Project coverage is 77.23%. Comparing base [(`502f738`)](https://app.codecov.io/gh/scverse/scanpy/commit/502f738b78e9ef78506fafd751e05b993d6001b3?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`af65f75`)](https://app.codecov.io/gh/scverse/scanpy/commit/af65f75e459e061460b8cda5d0ef68065e2809d3?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 1 commits behind head on main. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3275?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Patch % | Lines |; |---|---|---|; | [src/scanpy/preprocessing/\_simple.py](https://app.codecov.io/gh/scverse/scanpy/pull/3275?src=pr&el=tree&filepath=src%2Fscanpy%2Fpreprocessing%2F_simple.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9wcmVwcm9jZXNzaW5nL19zaW1wbGUucHk=) | 88.88% | [1 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3275?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) |. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3275 +/- ##; =======================================; Coverage 77.22% 77.23% ; =======================================; Files 111 111 ; Lines 12600 12605 +5 ; =======================================; + Hits 9730 9735 +5 ; Misses 2870 2870 ; ```. | [Files with missing lines](https://app.codecov.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3275#issuecomment-2399522678:1083,Patch,Patch,1083,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3275#issuecomment-2399522678,1,['Patch'],['Patch']
Deployability,/gh/scverse/scanpy/pull/3333?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `90.00000%` with `4 lines` in your changes missing coverage. Please review.; > Project coverage is 77.23%. Comparing base [(`6440515`)](https://app.codecov.io/gh/scverse/scanpy/commit/6440515ebce6e38b62bac5bce6d656f71fbeaa5b?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`bbb9469`)](https://app.codecov.io/gh/scverse/scanpy/commit/bbb94697549e9980eb039d3a5c174b2cc72a51ac?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 1 commits behind head on main. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3333?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Patch % | Lines |; |---|---|---|; | [src/scanpy/\_utils/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/3333?src=pr&el=tree&filepath=src%2Fscanpy%2F_utils%2F__init__.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9fdXRpbHMvX19pbml0X18ucHk=) | 83.33% | [2 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3333?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) |; | [src/scanpy/get/\_aggregated.py](https://app.codecov.io/gh/scverse/scanpy/pull/3333?src=pr&el=tree&filepath=src%2Fscanpy%2Fget%2F_aggregated.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9nZXQvX2FnZ3JlZ2F0ZWQucHk=) | 75.00% | [1 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3333?src=pr&el=tree&utm_medium=referral&utm,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3333#issuecomment-2449625873:1084,Patch,Patch,1084,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3333#issuecomment-2449625873,1,['Patch'],['Patch']
Deployability,/gh/scverse/scanpy/pull/3339?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `76.92308%` with `3 lines` in your changes missing coverage. Please review.; > Project coverage is 77.24%. Comparing base [(`0d04447`)](https://app.codecov.io/gh/scverse/scanpy/commit/0d04447448747337e2d3adb15ecdfdbfa1ad91c7?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`41666cf`)](https://app.codecov.io/gh/scverse/scanpy/commit/41666cffcc228a2ebe0c1837e87c074c5d097367?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 1 commits behind head on main. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3339?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Patch % | Lines |; |---|---|---|; | [src/scanpy/\_utils/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/3339?src=pr&el=tree&filepath=src%2Fscanpy%2F_utils%2F__init__.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9fdXRpbHMvX19pbml0X18ucHk=) | 62.50% | [3 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3339?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) |. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3339 +/- ##; =======================================; Coverage 77.23% 77.24% ; =======================================; Files 111 111 ; Lines 12608 12609 +1 ; =======================================; + Hits 9738 9740 +2 ; + Misses 2870 2869 -1 ; ```. | [Files with missing lines](https://app.codecov.io/gh/scve,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3339#issuecomment-2456762349:1084,Patch,Patch,1084,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3339#issuecomment-2456762349,1,['Patch'],['Patch']
Deployability,"/pandas/io/parsers/readers.py:1888) storage_options=self.options.get(""storage_options"", None),; [1889](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/parsers/readers.py:1889) ); [1890](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/parsers/readers.py:1890) assert self.handles is not None; [1891](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/parsers/readers.py:1891) f = self.handles.handle. File ~\AppData\Roaming\Python\Python312\site-packages\pandas\io\common.py:765, in get_handle(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options); [761](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/common.py:761) if compression == ""gzip"":; [762](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/common.py:762) if isinstance(handle, str):; [763](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/common.py:763) # error: Incompatible types in assignment (expression has type; [764](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/common.py:764) # ""GzipFile"", variable has type ""Union[str, BaseBuffer]""); --> [765](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/common.py:765) handle = gzip.GzipFile( # type: ignore[assignment]; [7",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3214:15982,Pipeline,PipelineDevelope,15982,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3214,1,['Pipeline'],['PipelineDevelope']
Deployability,/preprocessing/_simple.py::scanpy.preprocessing._simple.filter_cells; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200n-100theta-30clip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[toarray-float32-200n-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/plotting/_baseplot_class.py::scanpy.plotting._baseplot_class.BasePlot.add_totals; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100n-100theta-noclip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[toarray-float32-200n-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[toarray-float32-100n-100theta-infclip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200n-inftheta-noclip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100n-100theta-noclip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-200n-100theta-noclip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILE,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:27535,pipeline,pipeline,27535,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['pipeline'],['pipeline']
Deployability,/scanpy/pull/3336?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `90.00000%` with `4 lines` in your changes missing coverage. Please review.; > Project coverage is 77.22%. Comparing base [(`dda1f6e`)](https://app.codecov.io/gh/scverse/scanpy/commit/dda1f6eafad19e1a53947c54401ac4573b0a1cc3?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`c4a1e0a`)](https://app.codecov.io/gh/scverse/scanpy/commit/c4a1e0a829f553e14a91be9c1e441345e6b9a66c?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 5 commits behind head on ig/fix_pca_args. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3336?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Patch % | Lines |; |---|---|---|; | [src/scanpy/\_utils/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/3336?src=pr&el=tree&filepath=src%2Fscanpy%2F_utils%2F__init__.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9fdXRpbHMvX19pbml0X18ucHk=) | 83.33% | [2 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3336?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) |; | [src/scanpy/get/\_aggregated.py](https://app.codecov.io/gh/scverse/scanpy/pull/3336?src=pr&el=tree&filepath=src%2Fscanpy%2Fget%2F_aggregated.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9nZXQvX2FnZ3JlZ2F0ZWQucHk=) | 75.00% | [1 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3336?src=pr&el=tree&utm_medium=referral&utm,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3336#issuecomment-2450270276:1095,Patch,Patch,1095,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3336#issuecomment-2450270276,1,['Patch'],['Patch']
Deployability,/scverse/scanpy/pull/3142?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `86.66667%` with `2 lines` in your changes missing coverage. Please review.; > Project coverage is 76.50%. Comparing base [(`e6e5328`)](https://app.codecov.io/gh/scverse/scanpy/commit/e6e532804a9c087ea37808f26395aa9ed038d6cb?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`a37840f`)](https://app.codecov.io/gh/scverse/scanpy/commit/a37840f6d72e7b3ad980c6603c310f2e5e2305c0?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 43 commits behind head on 1.10.x. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3142?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Patch % | Lines |; |---|---|---|; | [src/scanpy/tools/\_score\_genes.py](https://app.codecov.io/gh/scverse/scanpy/pull/3142?src=pr&el=tree&filepath=src%2Fscanpy%2Ftools%2F_score_genes.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS90b29scy9fc2NvcmVfZ2VuZXMucHk=) | 86.66% | [2 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3142?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) |. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #3142 +/- ##; =======================================; Coverage 76.50% 76.50% ; =======================================; Files 109 109 ; Lines 12474 12485 +11 ; =======================================; + Hits 9543 9552 +9 ; - Misses 2931 2933 +2 ; ```. | [Files with missing lines](https://app.codecov.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3142#issuecomment-2209117430:1087,Patch,Patch,1087,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3142#issuecomment-2209117430,1,['Patch'],['Patch']
Deployability,/scverse/scanpy/pull/3243?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `25.00000%` with `3 lines` in your changes missing coverage. Please review.; > Project coverage is 76.75%. Comparing base [(`bd75839`)](https://app.codecov.io/gh/scverse/scanpy/commit/bd758395a669c31a6c9eaa9239750fde368d3ca7?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`c06bbc8`)](https://app.codecov.io/gh/scverse/scanpy/commit/c06bbc83218ee426fa54e681ab39c8006e1668c0?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 1 commits behind head on main. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3243?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Patch % | Lines |; |---|---|---|; | [src/scanpy/plotting/\_stacked\_violin.py](https://app.codecov.io/gh/scverse/scanpy/pull/3243?src=pr&el=tree&filepath=src%2Fscanpy%2Fplotting%2F_stacked_violin.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9wbG90dGluZy9fc3RhY2tlZF92aW9saW4ucHk=) | 25.00% | [3 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3243?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) |. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3243 +/- ##; ==========================================; + Coverage 76.49% 76.75% +0.25% ; ==========================================; Files 109 109 ; Lines 12544 12548 +4 ; ==========================================; + Hits 9596 9631 +35 ; + Misses 2948 2917 -31 ; ```. | [Files with m,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3243#issuecomment-2363207170:1084,Patch,Patch,1084,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3243#issuecomment-2363207170,1,['Patch'],['Patch']
Deployability,/scverse/scanpy/pull/3250?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `87.87879%` with `4 lines` in your changes missing coverage. Please review.; > Project coverage is 76.71%. Comparing base [(`ffebf12`)](https://app.codecov.io/gh/scverse/scanpy/commit/ffebf124f8a7da65a85622a07c7037ca477bfbef?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`2b269f7`)](https://app.codecov.io/gh/scverse/scanpy/commit/2b269f7a7e579f2ab5af52f240a1e86f93c118b2?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 2 commits behind head on 1.10.x. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3250?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Patch % | Lines |; |---|---|---|; | [src/scanpy/external/tl/\_wishbone.py](https://app.codecov.io/gh/scverse/scanpy/pull/3250?src=pr&el=tree&filepath=src%2Fscanpy%2Fexternal%2Ftl%2F_wishbone.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9leHRlcm5hbC90bC9fd2lzaGJvbmUucHk=) | 50.00% | [1 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3250?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) |; | [src/scanpy/plotting/\_anndata.py](https://app.codecov.io/gh/scverse/scanpy/pull/3250?src=pr&el=tree&filepath=src%2Fscanpy%2Fplotting%2F_anndata.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9wbG90dGluZy9fYW5uZGF0YS5weQ==) | 75.00% | [1 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3250?src=pr&el=tre,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3250#issuecomment-2363580091:1086,Patch,Patch,1086,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3250#issuecomment-2363580091,1,['Patch'],['Patch']
Deployability,/scverse/scanpy/pull/3252?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `33.33333%` with `2 lines` in your changes missing coverage. Please review.; > Project coverage is 76.74%. Comparing base [(`e27e257`)](https://app.codecov.io/gh/scverse/scanpy/commit/e27e257964c358acb3a9a83e4289cccfdfa425ae?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`0744da6`)](https://app.codecov.io/gh/scverse/scanpy/commit/0744da68e4f3593a81bed752d387bd2ca12a5e09?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 1 commits behind head on main. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3252?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Patch % | Lines |; |---|---|---|; | [src/scanpy/plotting/\_stacked\_violin.py](https://app.codecov.io/gh/scverse/scanpy/pull/3252?src=pr&el=tree&filepath=src%2Fscanpy%2Fplotting%2F_stacked_violin.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9wbG90dGluZy9fc3RhY2tlZF92aW9saW4ucHk=) | 33.33% | [2 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3252?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) |. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3252 +/- ##; ==========================================; - Coverage 76.75% 76.74% -0.02% ; ==========================================; Files 109 109 ; Lines 12556 12559 +3 ; ==========================================; + Hits 9637 9638 +1 ; - Misses 2919 2921 +2 ; ```. | [Flag](https://,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3252#issuecomment-2363846754:1084,Patch,Patch,1084,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3252#issuecomment-2363846754,1,['Patch'],['Patch']
Deployability,/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100n-inftheta-30clip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot3-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-200n-inftheta-infclip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_plotting.py::test_heatmap - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot-fn5] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100n-inftheta-30clip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_var_dict-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_group-fn7] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-200n-inftheta-30clip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200n-100theta-noclip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot_std_scale_group-fn3] - AssertionError: Erro,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:42989,pipeline,pipeline,42989,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['pipeline'],['pipeline']
Deployability,"/usr/common/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 2862, in load_entry_point; return ep.load(); File ""/usr/common/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 2462, in load; return self.resolve(); File ""/usr/common/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 2468, in resolve; module = __import__(self.module_name, fromlist=['__name__'], level=0); File ""/home/common/lib/python3.6/site-packages/scanpy-1.5.2.dev7+ge33a2f33-py3.6.egg/scanpy/__init__.py"", line 3, in <module>; from ._utils import pkg_version, check_versions, annotate_doc_types; File ""/home/common/lib/python3.6/site-packages/scanpy-1.5.2.dev7+ge33a2f33-py3.6.egg/scanpy/_utils.py"", line 17, in <module>; from anndata import AnnData; File ""/home/common/lib/python3.6/site-packages/anndata/__init__.py"", line 1, in <module>; from .base import AnnData; File ""/home/common/lib/python3.6/site-packages/anndata/base.py"", line 21, in <module>; from scipy.sparse.sputils import IndexMixin; ImportError: cannot import name 'IndexMixin'; ```. ```bash; #pip3 install works any better?; pip3 install scanpy --target $PYTHONPATH --upgrade; pip3 install scanpy-scripts --target $PYTHONPATH --upgrade; scanpy; #same thing; ```. There are multiple versions of many packages in PYTHONPATH and at some point it seems to be picking the wrong ones. Examples:. ```bash; ls -1 $PYTHONPATH | grep scanpy; scanpy; scanpy-1.4.3.dist-info; scanpy-1.4.3-py3.6.egg; scanpy-1.4.6.dist-info; scanpy-1.5.1.dist-info; scanpy-1.5.2.dev7+ge33a2f33-py3.6.egg; scanpy_scripts; scanpy_scripts-0.2.10.dist-info; scanpy_scripts-0.2.10-py3.6.egg; ls -1 $PYTHONPATH | grep scipy; scipy; scipy-1.2.3.dist-info; scipy-1.2.3-py3.6-linux-x86_64.egg; scipy-1.4.1.dist-info; ls -1 $PYTHONPATH | grep anndata; anndata; anndata-0.6.19.dist-info; anndata-0.6.19-py3.6.egg; anndata-0.7.1.dist-info; anndata-0.7.3.dist-info; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > ...; current git (plus others).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1273:2269,install,install,2269,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273,5,"['install', 'upgrade']","['install', 'upgrade']"
Deployability,"0); Requirement already satisfied: packaging in c:\users\hyjfo\.conda\envs\newpy38\lib\site-packages (from tables) (21.3); Requirement already satisfied: numpy>=1.19.0 in c:\users\hyjfo\.conda\envs\newpy38\lib\site-packages (from tables) (1.21.5); Requirement already satisfied: numexpr>=2.6.2 in c:\users\hyjfo\.conda\envs\newpy38\lib\site-packages (from tables) (2.8.1); Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\users\hyjfo\.conda\envs\newpy38\lib\site-packages (from packaging->tables) (3.0.4). import tables. ImportError Traceback (most recent call last); ~\AppData\Local\Temp/ipykernel_8256/574719567.py in <module>; ----> 1 import tables. ~\.conda\envs\NewPy38\lib\site-packages\tables\__init__.py in <module>; 43 ; 44 # Necessary imports to get versions stored on the cython extension; ---> 45 from .utilsextension import get_hdf5_version as _get_hdf5_version; 46 ; 47 . ImportError: DLL load failed while importing utilsextension; ```; Step 3: As you recommend, I do `!pip uninstall tables` and `conda install -c conda-forge pytables`, then; ```python; import tables # pass. import numpy as np; import pandas as pd; import scanpy as sc; import scanpy.external as sce; import scipy; sc.settings.verbosity = 3; sc.logging.print_header(); sc.set_figure_params(dpi=100, dpi_save=600). ImportError Traceback (most recent call last); ~\AppData\Local\Temp/ipykernel_15024/1710492625.py in <module>; 1 import numpy as np; 2 import pandas as pd; ----> 3 import scanpy as sc; 4 import scanpy.external as sce; 5 import scipy. ~\.conda\envs\NewPy38\lib\site-packages\scanpy\__init__.py in <module>; 4 ; 5 if not within_flit(): # see function docstring on why this is there; ----> 6 from ._utils import check_versions; 7 ; 8 check_versions(). ~\.conda\envs\NewPy38\lib\site-packages\scanpy\_utils\__init__.py in <module>; 19 from numpy import random; 20 from scipy import sparse; ---> 21 from anndata import AnnData, __version__ as anndata_version; 22 from textwrap import dedent; 23 f",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2108#issuecomment-1012790841:3591,install,install,3591,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2108#issuecomment-1012790841,1,['install'],['install']
Deployability,"0); sc.tl.umap(adata,random_state =42); sc.tl.leiden(adata,resolution=10); clusters= np.array(adata.obs[""leiden""]).astype(int); print('num of clusters: '+str(len(set(clusters)))). ###use precomputed cosine distance metrics; dis_mat = cosine_similarity(adata.X). tmp = sc.neighbors._common._get_indices_distances_from_dense_matrix(dis_mat, n_neighbors=15); adata.obsp[""connectivities""] = sc.neighbors._connectivity.umap(; knn_indices = tmp[0],; knn_dists = tmp[1],; n_obs = dis_mat.shape[0],; n_neighbors = 15,; ); adata.uns[""neighbors""] = {""connectivities_key"": ""connectivities"", ""params"": {""method"": None}}; sc.tl.umap(adata,random_state =42); sc.tl.leiden(adata,resolution=10); clusters= np.array(adata.obs[""leiden""]).astype(int); print('num of clusters: '+str(len(set(clusters)))); ```. ### Error output. ```pytb; num of clusters: 85; num of clusters: 170; num of clusters: 183; ```. ### Versions. <details>. ```; -----; anndata 0.10.6; scanpy 1.10.1; -----; IPython 8.22.2; PIL 10.2.0; asttokens NA; console_thrift NA; cycler 0.12.1; cython_runtime NA; dateutil 2.9.0; decorator 5.1.1; executing 2.0.1; h5py 3.10.0; igraph 0.11.4; jedi 0.19.1; joblib 1.3.2; kiwisolver 1.4.5; legacy_api_wrap NA; leidenalg 0.10.2; llvmlite 0.42.0; matplotlib 3.8.3; mpl_toolkits NA; natsort 8.4.0; numba 0.59.1; numpy 1.26.4; packaging 24.0; pandas 2.2.1; parso 0.8.3; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.42; psutil 5.9.0; pure_eval 0.2.2; pydev_console NA; pydev_ipython NA; pydevconsole NA; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.17.2; pynndescent 0.5.11; pyparsing 3.1.2; pytz 2024.1; scipy 1.12.0; session_info 1.0.0; six 1.16.0; sklearn 1.4.1.post1; stack_data 0.6.2; texttable 1.7.0; threadpoolctl 3.4.0; tqdm 4.66.2; traitlets 5.14.2; typing_extensions NA; umap 0.5.5; wcwidth 0.2.13; -----; Python 3.11.7 (main, Dec 15 2023, 12:09:56) [Clang 14.0.6 ]; macOS-14.3.1-arm64-arm-64bit; -----; Session information updated at 2024-04-22 09:58. ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3021:3614,update,updated,3614,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3021,1,['update'],['updated']
Deployability,"0.0 is not a release, it's just a dummy tag. if you upgrade now, the version will be `0.0+216.g2d10bdd`, where `0.0` marks the initial commit, `+216` one is 216 commits later, and `g2d10bdd` marks the installed commit",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/15#issuecomment-298314807:13,release,release,13,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/15#issuecomment-298314807,3,"['install', 'release', 'upgrade']","['installed', 'release', 'upgrade']"
Deployability,"0/#) in __init__(self, ax, mappable, **kw); 1228 they will need to be customized again. However, if the norm only; 1229 changes values of *vmin*, *vmax* or *cmap* then the old formatter; -> 1230 and locator will be preserved.; 1231 """"""; 1232 . TypeError: __init__() got an unexpected keyword argument 'location'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. anndata 0.8.0; scanpy 1.9.1. PIL 7.1.2; astor 0.8.1; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; cached_property 1.5.2; certifi 2022.06.15; cffi 1.15.1; cloudpickle 1.5.0; cycler 0.10.0; cython_runtime NA; dask 2022.02.0; dateutil 2.8.2; debugpy 1.0.0; decorator 4.4.2; fsspec 2022.8.2; google NA; h5py 3.1.0; httplib2 0.17.4; ipykernel 5.3.4; ipython_genutils 0.2.0; jinja2 2.11.3; joblib 1.1.0; kiwisolver 1.4.4; llvmlite 0.39.1; markupsafe 2.0.1; matplotlib 3.2.2; mpl_toolkits NA; natsort 5.5.0; nbinom_ufunc NA; numba 0.56.2; numexpr 2.8.3; numpy 1.21.6; packaging 21.3; pandas 1.3.5; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; portpicker NA; prompt_toolkit 2.0.10; psutil 5.4.8; ptyprocess 0.7.0; pyarrow 6.0.1; pydev_ipython NA; pydevconsole NA; pydevd 2.0.0; pydevd_concurrency_analyser NA; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.6.1; pyparsing 3.0.9; pytz 2022.2.1; scipy 1.7.3; session_info 1.0.0; sitecustomize NA; six 1.15.0; sklearn 1.0.2; socks 1.7.1; sphinxcontrib NA; storemagic NA; tblib 1.7.0; threadpoolctl 3.1.0; tlz 0.12.0; toolz 0.12.0; tornado 5.1.1; traitlets 5.1.1; typing_extensions NA; wcwidth 0.2.5; yaml 6.0; zipp NA; zmq 23.2.1. IPython 7.9.0; jupyter_client 6.1.12; jupyter_core 4.11.1; notebook 5.3.1. Python 3.7.14 (default, Sep 8 2022, 00:06:44) [GCC 7.5.0]; Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic. Session information updated at 2022-09-16 19:14. </details>; ![error](https://user-images.githubusercontent.com/72993520/190715283-6ae522e3-dd86-4179-956b-196f3f2c845b.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2332:4787,update,updated,4787,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2332,1,['update'],['updated']
Deployability,00n-inftheta-noclip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[toarray-int64-100n-100theta-infclip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_embedding_plots.py::test_missing_values_categorical[pca-na_color.black_tup-na_in_legend.False-legend.on_right-groups.3] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[toarray-float32-100n-inftheta-infclip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100n-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-100n-100theta-30clip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-100n-100theta-30clip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-200n-inftheta-noclip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100n-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:38267,pipeline,pipeline,38267,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['pipeline'],['pipeline']
Deployability,00theta-infclip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200n-inftheta-infclip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_embedding_plots.py::test_missing_values_categorical[pca-na_color.black_tup-na_in_legend.True-legend.on_right-groups.3] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[toarray-int64-100n-100theta-noclip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[toarray-float32-100n-100theta-30clip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_embedding_plots.py::test_missing_values_categorical[pca-na_color.black_tup-na_in_legend.True-legend.on_right-groups.all] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-100n-100theta-infclip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-200n-100theta-infclip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100n-100theta-30clip-subset] - NotImplementedError: Failed in,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:31998,pipeline,pipeline,31998,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['pipeline'],['pipeline']
Deployability,"024.8.0; dateutil 2.9.0.post0; debugpy 1.8.1; decorator 5.1.1; defusedxml 0.7.1; dill 0.3.8; exceptiongroup 1.2.1; executing 2.0.1; fastjsonschema NA; fqdn NA; gi 3.42.1; gio NA; glib NA; gobject NA; gtk NA; h5py 3.11.0; idna 3.3; igraph 0.11.5; ipykernel 6.29.4; isoduration NA; jedi 0.19.1; jinja2 3.1.3; joblib 1.4.2; json5 0.9.25; jsonpointer 2.4; jsonschema 4.22.0; jsonschema_specifications NA; jupyter_events 0.10.0; jupyter_server 2.14.0; jupyterlab_server 2.27.1; kiwisolver 1.4.5; legacy_api_wrap NA; leidenalg 0.10.2; llvmlite 0.42.0; louvain 0.8.2; lz4 4.3.3; markupsafe 2.1.5; matplotlib 3.8.4; more_itertools 8.10.0; mpl_toolkits NA; mpmath 1.3.0; natsort 8.4.0; nbformat 5.10.4; netifaces 0.11.0; numba 0.59.1; numexpr 2.10.1; numpy 1.26.4; overrides NA; packaging 24.0; pandas 2.2.2; parso 0.8.4; pkg_resources NA; platformdirs 4.2.1; plotly 5.22.0; prometheus_client NA; prompt_toolkit 3.0.43; psutil 5.9.8; pure_eval 0.2.2; pyarrow 16.0.0; pydev_ipython NA; pydevconsole NA; pydevd 2.9.5; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pydot 2.0.0; pygments 2.17.2; pyparsing 3.1.2; pythonjsonlogger NA; pytz 2022.1; referencing NA; requests 2.31.0; rfc3339_validator 0.1.4; rfc3986_validator 0.1.1; rpds NA; scipy 1.13.0; send2trash NA; session_info 1.0.0; sitecustomize NA; six 1.16.0; sklearn 1.4.2; sniffio 1.3.1; socks 1.7.1; stack_data 0.6.3; sympy 1.12; tblib 3.0.0; texttable 1.7.0; threadpoolctl 3.5.0; tlz 0.12.3; toolz 0.12.1; torch 2.1.2+cu121; torchgen NA; tornado 6.4; tqdm 4.66.4; traitlets 5.14.3; typing_extensions NA; tzdata 2024.1; uri_template NA; urllib3 2.2.1; wcwidth 0.2.13; webcolors 1.13; websocket 1.8.0; xxhash NA; yaml 5.4.1; zipp NA; zmq 26.0.3; zoneinfo NA; -----; IPython 8.24.0; jupyter_client 8.6.1; jupyter_core 5.7.2; jupyterlab 4.2.3; notebook 7.2.0; -----; Python 3.10.12 (main, Jul 29 2024, 16:56:48) [GCC 11.4.0]; Linux-6.5.0-1027-oem-x86_64-with-glibc2.35; -----; Session information updated at 2024-09-02 14:19; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3221:5253,update,updated,5253,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3221,1,['update'],['updated']
Deployability,"03571618 -0.20246665 ... -0.20828792 -0.03336232; -0.03857614]; [ 0.16883004 0.24885994 0.2981057 ... 0.07269898 0.02756566; 0.02458768]; [ 0.09268849 -0.13046254 -0.13968301 ... -0.25285217 -0.10799355; -0.03488484]; ...; [ 0.15258779 0.07010179 -0.436631 ... -0.04219513 0.04722253; -0.01080273]; [-0.20423044 0.18215777 -0.0767504 ... -0.33365571 -0.16421221; 0.00806304]; [-0.03940619 -0.24201192 0.05783679 ... -0.07871751 0.0350191; 0.01995604]]; ```. ### Error output. _No response_. ### Versions. <details>. ```; -----; anndata 0.8.0; scanpy 1.9.1; -----; PIL 9.4.0; asttokens NA; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; cffi 1.15.1; colorama 0.4.6; comm 0.1.2; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.6.6; decorator 5.1.1; entrypoints 0.4; executing 1.2.0; google NA; h5py 3.8.0; hypergeom_ufunc NA; igraph 0.10.3; invgauss_ufunc NA; ipykernel 6.20.2; jedi 0.18.2; joblib 1.2.0; kiwisolver 1.4.4; leidenalg 0.10.1; llvmlite 0.39.1; matplotlib 3.6.3; mpl_toolkits NA; natsort 8.2.0; nbinom_ufunc NA; ncf_ufunc NA; nct_ufunc NA; ncx2_ufunc NA; numba 0.56.4; numpy 1.23.5; packaging 23.0; pandas 1.5.3; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; platformdirs 2.6.2; prompt_toolkit 3.0.36; psutil 5.9.4; ptyprocess 0.7.0; pure_eval 0.2.2; pydev_ipython NA; pydevconsole NA; pydevd 2.9.5; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.14.0; pyparsing 3.0.9; pytz 2022.7.1; scipy 1.10.0; session_info 1.0.0; setuptools 66.1.1; six 1.16.0; skewnorm_ufunc NA; sklearn 1.2.1; stack_data 0.6.2; texttable 1.6.7; threadpoolctl 3.1.0; tornado 6.2; traitlets 5.8.1; typing_extensions NA; wcwidth 0.2.6; yaml 6.0; zipp NA; zmq 25.0.0; zoneinfo NA; -----; IPython 8.8.0; jupyter_client 7.4.9; jupyter_core 5.1.5; -----; Python 3.9.15 | packaged by conda-forge | (main, Nov 22 2022, 15:55:03) [GCC 10.4.0]; Linux-4.18.0-425.3.1.el8.x86_64-x86_64-with-glibc2.28; -----; Session information updated at 2023-09-18 17:04; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2668:3308,update,updated,3308,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2668,1,['update'],['updated']
Deployability,"0; anyio NA; arrow 1.3.0; asttokens NA; attr 23.1.0; attrs 23.1.0; babel 2.13.1; certifi 2023.07.22; cffi 1.16.0; charset_normalizer 3.2.0; comm 0.2.0; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.8.0; decorator 5.1.1; defusedxml 0.7.1; entrypoints 0.4; executing 2.0.1; fastjsonschema NA; fqdn NA; h5py 3.10.0; idna 3.4; igraph 0.10.8; ipykernel 6.27.1; ipython_genutils 0.2.0; ipywidgets 8.1.1; isoduration NA; jedi 0.19.1; jinja2 3.1.2; joblib 1.3.2; json5 NA; jsonpointer 2.4; jsonschema 4.20.0; jsonschema_specifications NA; jupyter_server 1.24.0; jupyterlab_server 2.25.2; kiwisolver 1.4.5; leidenalg 0.10.1; llvmlite 0.41.1; markupsafe 2.1.3; matplotlib 3.7.2; matplotlib_inline 0.1.6; mpl_toolkits NA; mpmath 1.3.0; natsort 8.4.0; nbformat 5.9.2; numba 0.58.1; numpy 1.25.2; packaging 23.1; pandas 2.1.4; parso 0.8.3; patsy 0.5.6; pexpect 4.9.0; platformdirs 4.1.0; plotly 5.18.0; prometheus_client NA; prompt_toolkit 3.0.41; psutil 5.9.6; ptyprocess 0.7.0; pure_eval 0.2.2; pycparser 2.21; pydev_ipython NA; pydevconsole NA; pydevd 2.9.5; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.16.1; pyparsing 3.0.9; pytz 2023.3.post1; referencing NA; requests 2.31.0; rfc3339_validator 0.1.4; rfc3986_validator 0.1.1; rpds NA; scipy 1.11.4; seaborn 0.13.1; send2trash NA; session_info 1.0.0; simplejson 3.19.1; six 1.16.0; sklearn 1.3.2; sniffio 1.3.0; sparse 0.14.0; stack_data 0.6.3; statsmodels 0.14.1; sympy 1.12; terminado 0.18.0; texttable 1.7.0; threadpoolctl 3.2.0; torch 2.1.2+cu121; torchgen NA; tornado 6.4; tqdm 4.66.1; traitlets 5.14.0; typing_extensions NA; uri_template NA; urllib3 2.0.4; wcwidth 0.2.12; webcolors 1.13; websocket 1.7.0; yaml 6.0.1; zmq 24.0.1; -----; IPython 8.18.1; jupyter_client 7.4.9; jupyter_core 5.5.0; jupyterlab 3.6.5; notebook 6.5.6; -----; Python 3.11.3 (main, Aug 25 2023, 17:24:38) [GCC 11.4.0]; Linux-5.15.0-91-generic-x86_64-with-glibc2.35; -----; Session information updated at 2024-02-07 10:05; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2842:3081,update,updated,3081,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2842,1,['update'],['updated']
Deployability,"0; babel 2.15.0; brotli 1.1.0; certifi 2024.07.04; cffi 1.16.0; chardet 5.2.0; charset_normalizer 3.3.2; colorama 0.4.6; comm 0.2.2; cycler 0.12.1; cython_runtime NA; dateutil 2.9.0; debugpy 1.8.1; decorator 5.1.1; defusedxml 0.7.1; exceptiongroup 1.2.0; executing 2.0.1; fastjsonschema NA; fqdn NA; google NA; h5py 3.11.0; idna 3.7; igraph 0.11.5; ipykernel 6.29.4; ipywidgets 8.1.2; isoduration NA; jedi 0.19.1; jinja2 3.1.4; joblib 1.4.2; json5 0.9.25; jsonpointer 2.4; jsonschema 4.22.0; jsonschema_specifications NA; jupyter_events 0.10.0; jupyter_server 2.14.0; jupyterlab_server 2.27.1; kiwisolver 1.4.5; legacy_api_wrap NA; leidenalg 0.10.2; llvmlite 0.43.0; markupsafe 2.1.5; matplotlib 3.9.0; mpl_toolkits NA; natsort 8.4.0; nbformat 5.10.4; numba 0.60.0; numpy 1.26.4; overrides NA; packaging 24.0; pandas 2.2.2; parso 0.8.4; platformdirs 4.2.2; prometheus_client NA; prompt_toolkit 3.0.43; psutil 5.9.8; pure_eval 0.2.2; pyarrow 15.0.2; pydev_ipython NA; pydevconsole NA; pydevd 2.9.5; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.18.0; pyparsing 3.1.2; pythonjsonlogger NA; pytz 2024.1; referencing NA; requests 2.32.2; rfc3339_validator 0.1.4; rfc3986_validator 0.1.1; rich NA; rpds NA; scipy 1.13.0; send2trash NA; session_info 1.0.0; setuptools 69.5.1; setuptools_scm NA; six 1.16.0; sklearn 1.4.2; sniffio 1.3.1; socks 1.7.1; stack_data 0.6.3; texttable 1.7.0; threadpoolctl 3.5.0; tomli 2.0.1; torch 2.3.1+cu121; torchgen NA; tornado 6.4; tqdm 4.66.4; traitlets 5.14.3; typing_extensions NA; uri_template NA; urllib3 2.2.1; vscode NA; wcwidth 0.2.13; webcolors 1.13; websocket 1.8.0; yaml 6.0.1; zmq 26.0.3; zoneinfo NA; -----; IPython 8.24.0; jupyter_client 8.6.1; jupyter_core 5.7.2; jupyterlab 4.2.0; notebook 7.2.0; -----; Python 3.10.14 | packaged by conda-forge | (main, Mar 20 2024, 12:45:18) [GCC 12.3.0]; Linux-3.10.0-1160.119.1.el7.tuxcare.els2.x86_64-x86_64-with-glibc2.17; -----; Session information updated at 2024-10-23 08:47; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3310:4888,update,updated,4888,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3310,1,['update'],['updated']
Deployability,"0].__class__)(*args, **kw); > scanpy/preprocessing/_simple.py:888: in scale_anndata; > X, adata.var[""mean""], adata.var[""std""] = do_scale(; > ../../miniconda3/envs/scanpy/lib/python3.9/site-packages/numba/core/dispatcher.py:468: in _compile_for_args; > error_rewrite(e, 'typing'); > _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _; > ; > e = TypingError('Failed in nopython mode pipeline (step: nopython frontend)\nnon-precise type pyobject\nDuring: typing of ...y the following argument(s):\n- argument 0: Cannot determine Numba type of <class \'scipy.sparse._csr.csr_matrix\'>\n'); > issue_type = 'typing'; > ; > def error_rewrite(e, issue_type):; > """"""; > Rewrite and raise Exception `e` with help supplied based on the; > specified issue_type.; > """"""; > if config.SHOW_HELP:; > help_msg = errors.error_extras[issue_type]; > e.patch_message('\n'.join((str(e).rstrip(), help_msg))); > if config.FULL_TRACEBACKS:; > raise e; > else:; > > raise e.with_traceback(None); > E numba.core.errors.TypingError: Failed in nopython mode pipeline (step: nopython frontend); > E non-precise type pyobject; > E During: typing of argument at /home/zeth/PycharmProjects/scanpy/scanpy/preprocessing/_simple.py (763); > E ; > E File ""scanpy/preprocessing/_simple.py"", line 763:; > E def do_scale(X, maxv, nthr):; > E <source elided>; > E # t0= time.time(); > E s = np.zeros((nthr, X.shape[1])); > E ^ ; > E ; > E This error may have been caused by the following argument(s):; > E - argument 0: Cannot determine Numba type of <class 'scipy.sparse._csr.csr_matrix'>; > ; > ../../miniconda3/envs/scanpy/lib/python3.9/site-packages/numba/core/dispatcher.py:409: TypingError; > ```; > ; > When trying to use the new flavor with the existing test. Hi @Zethson ,; We are not able to see this issue with the latest commit. Can you please retry with the latest commit in scale branch.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2457#issuecomment-1540006717:2160,pipeline,pipeline,2160,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2457#issuecomment-1540006717,1,['pipeline'],['pipeline']
Deployability,0n-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[toarray-int64-200n-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[toarray-float32-100n-100theta-noclip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/preprocessing/_simple.py::scanpy.preprocessing._simple.filter_cells; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200n-100theta-30clip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[toarray-float32-200n-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/plotting/_baseplot_class.py::scanpy.plotting._baseplot_class.BasePlot.add_totals; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100n-100theta-noclip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[toarray-float32-200n-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[toarray-float32-100n-100theta-infclip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200n-inftheta-noclip-subset] - NotImpl,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:26992,pipeline,pipeline,26992,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['pipeline'],['pipeline']
Deployability,"1. How do we xfail stuff from `dev`? https://dev.azure.com/scverse/scanpy/_build/results?buildId=6692&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=99aeec2e-a40e-57fc-1ab3-27c1a626c3e0&l=108 It looks like the UMAP package via `pynndescent` is using something that has been removed (`np.infty`) in an upcoming release of numpy; 2. Codecov, I think, is outright wrong aklthough that might have to do with the failing dev test",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3048#issuecomment-2112257384:314,release,release,314,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048#issuecomment-2112257384,1,['release'],['release']
Deployability,"1. No, I have sampled cells with weights, out of those 1000 rows most; having weight=1, e.g. 1 row has weight 125, then in gene ranking the; expression all genes will multiplied with that specific weight of cell, so; I updated code by calculated weighted mean and variance. Before updating; this I was getting wrong marker genes. Same for plotting points in dotplot,; stacked_violin and heatmap. 2. I suggest that scanpy should support weighted data, I mean PCA should; also be computed for data with weighted observations (PCA in matlab support; weighted observations). Currently my input is weighted PCA data for; clustering, so I don't need to update PCA code, but in future it will be a; good thing to support scanpy for weighted sampled data as well. Thanks,; Khalid. On Tue, May 21, 2019 at 3:00 AM MalteDLuecken <notifications@github.com>; wrote:. > So you want to e.g., downweight the likelihood of sampling cells with a; > particular feature (like a common cell type), and upweight others. What do; > you want to use this weighting for now in the sc.tl.rank_genes_groups; > function? Or in the visualization functions you changed?; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/pull/644?email_source=notifications&email_token=ABREGOHR7Q62WL6MCWX7UWTPWLYOLA5CNFSM4HMZ5G72YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGODVZYS3I#issuecomment-494111085>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ABREGOHHMFZBUTLM4VIJCTLPWLYOLANCNFSM4HMZ5G7Q>; > .; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/644#issuecomment-494119134:219,update,updated,219,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/644#issuecomment-494119134,2,['update'],"['update', 'updated']"
Deployability,"1.4; cycler 0.10.0; cython_runtime NA; cytoolz 0.12.2; dask 2023.2.0; dateutil 2.8.2; debugpy 1.6.8; decorator 5.1.1; defusedxml 0.7.1; executing 1.2.0; fastjsonschema NA; fontTools 4.42.0; fqdn NA; h5py 3.9.0; idna 3.4; igraph 0.10.2; importlib_resources NA; ipykernel 6.25.1; ipywidgets 8.1.0; isoduration NA; jedi 0.19.0; jinja2 3.1.2; joblib 1.3.2; json5 NA; jsonpointer 2.0; jsonschema 4.19.0; jsonschema_specifications NA; jupyter_events 0.7.0; jupyter_server 2.7.1; jupyterlab_server 2.24.0; kiwisolver 1.4.4; leidenalg 0.9.1; llvmlite 0.40.1; lxml 4.9.1; markupsafe 2.1.3; matplotlib 3.7.2; mpl_toolkits NA; natsort 8.4.0; nbformat 5.9.2; numba 0.57.1; numexpr 2.8.4; numpy 1.24.4; overrides NA; packaging 23.1; pandas 2.0.3; parso 0.8.3; patsy 0.5.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; platformdirs 3.10.0; prometheus_client NA; prompt_toolkit 3.0.39; psutil 5.9.5; ptyprocess 0.7.0; pure_eval 0.2.2; pyarrow 11.0.0; pycparser 2.21; pydev_ipython NA; pydevconsole NA; pydevd 2.9.5; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.16.1; pyparsing 3.0.9; pythonjsonlogger NA; pytz 2023.3; referencing NA; requests 2.31.0; rfc3339_validator 0.1.4; rfc3986_validator 0.1.1; rpds NA; scipy 1.10.1; scrublet NA; seaborn 0.12.2; send2trash NA; session_info 1.0.0; setuptools_scm NA; six 1.16.0; sklearn 1.3.0; sniffio 1.3.0; socks 1.7.1; sphinxcontrib NA; stack_data 0.6.2; statsmodels 0.14.0; tblib 1.7.0; texttable 1.6.7; threadpoolctl 3.2.0; tlz 0.12.2; toolz 0.12.0; tornado 6.3.3; traitlets 5.9.0; typing_extensions NA; uri_template NA; urllib3 2.0.4; wcwidth 0.2.6; webcolors 1.13; websocket 1.6.1; yaml 6.0; zipp NA; zmq 25.1.1; -----; IPython 8.7.0; jupyter_client 8.3.0; jupyter_core 5.3.0; jupyterlab 4.0.5; notebook 7.0.2; -----; Python 3.8.15 | packaged by conda-forge | (default, Nov 22 2022, 08:46:39) [GCC 10.4.0]; Linux-4.18.0-348.7.1.el8_5.x86_64-x86_64-with-glibc2.10; -----; Session information updated at 2023-08-20 12:04; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2627:4485,update,updated,4485,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2627,1,['update'],['updated']
Deployability,1.9.4 release notes,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2594:6,release,release,6,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2594,1,['release'],['release']
Deployability,"10/site-packages/numba/parfors/parfor.py:3627, in get_reduce_nodes.<locals>.lookup(var, varonly); 3625 val = defs.get(var.name, None); 3626 if isinstance(val, ir.Var):; -> 3627 return lookup(val); 3628 else:; 3629 return var if (varonly or val is None) else val. [... skipping similar frames: get_reduce_nodes.<locals>.lookup at line 3627 (2946 times)]. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3627, in get_reduce_nodes.<locals>.lookup(var, varonly); 3625 val = defs.get(var.name, None); 3626 if isinstance(val, ir.Var):; -> 3627 return lookup(val); 3628 else:; 3629 return var if (varonly or val is None) else val. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3625, in get_reduce_nodes.<locals>.lookup(var, varonly); 3624 def lookup(var, varonly=True):; -> 3625 val = defs.get(var.name, None); 3626 if isinstance(val, ir.Var):; 3627 return lookup(val). RecursionError: Failed in nopython mode pipeline (step: convert to parfors); maximum recursion depth exceeded while calling a Python object. ```. #### Versions; <details>. -----; anndata 0.8.0; scanpy 1.8.2; sinfo 0.3.1; -----; PIL 9.0.1; anndata 0.8.0; asttokens NA; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; cffi 1.15.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.5.1; decorator 5.1.1; defusedxml 0.7.1; entrypoints 0.4; executing 0.8.3; h5py 3.6.0; hypergeom_ufunc NA; igraph 0.9.9; ipykernel 6.9.1; ipython_genutils 0.2.0; ipywidgets 7.7.0; jedi 0.18.1; joblib 1.1.0; kiwisolver 1.4.0; leidenalg 0.8.9; llvmlite 0.38.0; matplotlib 3.4.3; matplotlib_inline NA; mpl_toolkits NA; natsort 8.1.0; nbinom_ufunc NA; numba 0.55.1; numexpr 2.8.0; numpy 1.21.5; packaging 21.3; pandas 1.4.1; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.27; ptyprocess 0.7.0; pure_eval 0.2.2; pycparser 2.21; pydev_ipython NA; pydevconsole NA; pydevd 2.6.0; pydevd_concurrency_analyser NA; pydevd_file_utils NA; pyde",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2191:11846,pipeline,pipeline,11846,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191,1,['pipeline'],['pipeline']
Deployability,10X Visium-ScRNA-seq integrative analysis,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1386:21,integrat,integrative,21,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1386,1,['integrat'],['integrative']
Deployability,"128 fig.canvas.print_figure(bytes_io, **kw); 129 data = bytes_io.getvalue(); 130 if fmt == 'svg':. ~/.local/lib/python3.7/site-packages/matplotlib/backend_bases.py in print_figure(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs); 2054 orientation=orientation,; 2055 dryrun=True,; -> 2056 **kwargs); 2057 renderer = self.figure._cachedRenderer; 2058 bbox_artists = kwargs.pop(""bbox_extra_artists"", None). ~/.local/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py in print_png(self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs); 525 ; 526 else:; --> 527 FigureCanvasAgg.draw(self); 528 renderer = self.get_renderer(); 529 with cbook._setattr_cm(renderer, dpi=self.figure.dpi), \. ~/.local/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py in draw(self); 386 self.renderer = self.get_renderer(cleared=True); 387 with RendererAgg.lock:; --> 388 self.figure.draw(self.renderer); 389 # A GUI class may be need to update a window using this draw, so; 390 # don't forget to call the superclass. ~/.local/lib/python3.7/site-packages/matplotlib/artist.py in draw_wrapper(artist, renderer, *args, **kwargs); 36 renderer.start_filter(); 37 ; ---> 38 return draw(artist, renderer, *args, **kwargs); 39 finally:; 40 if artist.get_agg_filter() is not None:. ~/.local/lib/python3.7/site-packages/matplotlib/figure.py in draw(self, renderer); 1707 self.patch.draw(renderer); 1708 mimage._draw_list_compositing_images(; -> 1709 renderer, self, artists, self.suppressComposite); 1710 ; 1711 renderer.close_group('figure'). ~/.local/lib/python3.7/site-packages/matplotlib/image.py in _draw_list_compositing_images(renderer, parent, artists, suppress_composite); 133 if not_composite or not has_images:; 134 for a in artists:; --> 135 a.draw(renderer); 136 else:; 137 # Composite any adjacent images together. ~/.local/lib/python3.7/site-packages/matplotlib/artist.py in draw_wrapper(artist, renderer, *args, **kwargs); 36 renderer.start_filter()",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/787:2039,update,update,2039,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/787,1,['update'],['update']
Deployability,"130 if not_composite or not has_images:; 131 for a in artists:; --> 132 a.draw(renderer); 133 else:; 134 # Composite any adjacent images together; 135 image_group = []. File ~/anaconda3/envs/ml/lib/python3.9/site-packages/matplotlib/artist.py:51, in allow_rasterization.<locals>.draw_wrapper(artist, renderer, *args, **kwargs); 48 if artist.get_agg_filter() is not None:; 49 renderer.start_filter(); ---> 51 return draw(artist, renderer, *args, **kwargs); 52 finally:; 53 if artist.get_agg_filter() is not None:. File ~/anaconda3/envs/ml/lib/python3.9/site-packages/mpl_toolkits/mplot3d/axes3d.py:485, in Axes3D.draw(self, renderer); 480 # Calculate projection of collections and patches and zorder them.; 481 # Make sure they are drawn above the grids.; 482 zorder_offset = max(axis.get_zorder(); 483 for axis in self._get_axis_list()) + 1; 484 for i, col in enumerate(; --> 485 sorted(self.collections,; 486 key=do_3d_projection,; 487 reverse=True)):; 488 col.zorder = zorder_offset + i; 489 for i, patch in enumerate(; 490 sorted(self.patches,; 491 key=do_3d_projection,; 492 reverse=True)):. File ~/anaconda3/envs/ml/lib/python3.9/site-packages/mpl_toolkits/mplot3d/axes3d.py:471, in Axes3D.draw.<locals>.do_3d_projection(artist); 458 """"""; 459 Call `do_3d_projection` on an *artist*, and warn if passing; 460 *renderer*.; (...); 464 *renderer* and raise a warning.; 465 """"""; 467 if artist.__module__ == 'mpl_toolkits.mplot3d.art3d':; 468 # Our 3D Artists have deprecated the renderer parameter, so; 469 # avoid passing it to them; call this directly once the; 470 # deprecation has expired.; --> 471 return artist.do_3d_projection(); 473 _api.warn_deprecated(; 474 ""3.4"",; 475 message=""The 'renderer' parameter of ""; 476 ""do_3d_projection() was deprecated in Matplotlib ""; 477 ""%(since)s and will be removed %(removal)s.""); 478 return artist.do_3d_projection(renderer). File ~/anaconda3/envs/ml/lib/python3.9/site-packages/matplotlib/_api/deprecation.py:431, in delete_parameter.<locals>.wrapper(",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2285:8438,patch,patch,8438,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2285,1,['patch'],['patch']
Deployability,"18:; ```; conda create -n temp_env_scanpy; conda activate temp_env_scanpy; (temp_env_scanpy) giov@vm:~$ conda install -c bioconda scanpy. Collecting package metadata (current_repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.; Collecting package metadata (repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: -; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed. UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/linux-64::__cuda==9.1=0. Your installed CUDA driver is: 9.1; ```; Interestingly, this error is not thrown all the time, e.g. in a VM centos 7 without cuda:; ```; Collecting package metadata (current_repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.; Collecting package metadata (repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: \; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed. UnsatisfiableError:; ```; Another student working with me had the same issue in windows. His error was:; ```; UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/win-64::__cuda==10.2=0. Your installed CUDA driver is: 10.2; ```; But on a mac, no problem at all. In all situations, I have at least another environment with scanpy installed.; In all cases, conda was `4.8.3`.; I cannot rule out completely the possibility that my conda in those 2 vms are messed up.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1142:1820,install,installed,1820,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1142,2,['install'],['installed']
Deployability,"1; scanpy 1.9.3; -----; PIL 8.4.0; asciitree NA; asttokens NA; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; bottleneck 1.3.4; cffi 1.15.0; cloudpickle 2.0.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2022.02.1; dateutil 2.8.1; debugpy 1.5.1; decorator 5.1.1; defusedxml 0.7.1; django 4.1.3; entrypoints 0.4; executing 0.8.3; fasteners 0.18; fsspec 2023.4.0; google NA; h5py 3.6.0; igraph 0.10.6; ipykernel 6.9.1; ipython_genutils 0.2.0; ipywidgets 7.6.5; jedi 0.18.1; jinja2 3.1.2; joblib 1.1.0; jupyter_server 1.13.5; kiwisolver 1.2.0; kneed 0.8.3; leidenalg 0.10.1; llvmlite 0.38.0; markupsafe 2.0.1; matplotlib 3.5.1; matplotlib_inline NA; mishalpy NA; mpl_toolkits NA; mpmath 1.2.1; msgpack 1.0.2; natsort 8.3.1; nbinom_ufunc NA; nt NA; ntsecuritycon NA; numba 0.55.1; numcodecs 0.11.0; numexpr 2.8.1; numpy 1.21.6; opt_einsum v3.3.0; packaging 21.3; pandas 1.4.3; parso 0.8.3; pickleshare 0.7.5; pkg_resources NA; plotly 5.6.0; prompt_toolkit 3.0.20; psutil 5.8.0; pure_eval 0.2.2; pycparser 2.21; pydev_ipython NA; pydevconsole NA; pydevd 2.6.0; pydevd_concurrency_analyser NA; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.15.1; pyparsing 2.4.7; pythoncom NA; pytz 2020.1; pywintypes NA; ruamel NA; scipy 1.7.3; seaborn 0.11.2; session_info 1.0.0; setuptools 61.2.0; six 1.15.0; sklearn 1.0.2; snappy NA; sparse 0.14.0; sphinxcontrib NA; stack_data 0.2.0; statsmodels 0.13.2; sympy 1.10.1; tblib 1.7.0; texttable 1.6.7; threadpoolctl 2.2.0; tlz 0.11.0; toolz 0.11.2; torch 2.0.1+cpu; tornado 6.1; tqdm 4.64.0; traitlets 5.9.0; typing_extensions NA; wcwidth 0.2.5; win32api NA; win32com NA; win32security NA; yaml 6.0; zarr 2.14.2; zipp NA; zmq 22.3.0; zope NA; -----; IPython 8.2.0; jupyter_client 6.1.12; jupyter_core 4.9.2; jupyterlab 3.3.2; notebook 6.4.8; -----; Python 3.9.12 (main, Apr 4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]; Windows-10-10.0.22000-SP0; -----; Session information updated at 2023-07-31 10:13; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2579:3290,update,updated,3290,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2579,1,['update'],['updated']
Deployability,"1=h7b6447c_3; - pip:; - anndata==0.7.5; - cached-property==1.5.2; - click==7.1.2; - cycler==0.10.0; - get-version==2.1; - h5py==3.1.0; - importlib-metadata==3.4.0; - joblib==1.0.0; - kiwisolver==1.3.1; - legacy-api-wrap==1.2; - leidenalg==0.8.3; - llvmlite==0.35.0; - loompy==3.0.6; - louvain==0.7.0; - matplotlib==3.3.4; - natsort==7.1.1; - networkx==2.5; - numba==0.52.0; - numexpr==2.7.2; - numpy==1.20.0; - numpy-groupies==0.9.13; - pandas==1.2.1; - patsy==0.5.1; - pillow==8.1.0; - python-igraph==0.8.3; - pytz==2021.1; - scanpy==1.6.1; - scikit-learn==0.24.1; - scipy==1.6.0; - scvelo==0.2.2; - seaborn==0.11.1; - setuptools-scm==5.0.1; - sinfo==0.3.1; - statsmodels==0.12.1; - stdlib-list==0.8.0; - tables==3.6.1; - texttable==1.6.3; - threadpoolctl==2.1.0; - tqdm==4.56.0; - typing-extensions==3.7.4.3; - umap-learn==0.4.6; ```. I can reproduce the issue with a Docker container that only has the minimal conda environment above. Additionally, I already tried installing the exact same dependency versions in the new environment, but got the same results. ; If you need access to the data and the container please contact me and I will make it available to you.; The data is already at the ICB cluster. Code:. ```; from os import path; import numpy as np; import matplotlib.pyplot as plt; import scanpy as sc; import scanpy.external as sce; from os import listdir; import pandas as pd; import seaborn as sb; import datetime, time; import scvelo as scv. from matplotlib.colors import LinearSegmentedColormap. #Define a nice colour map for gene expression; from matplotlib import colors. def timestamp():; ts = time.time(); st = datetime.datetime.fromtimestamp(ts).strftime('%d-%m-%Y %H:%M:%S'); return st. # Exporting folder. folder = ""/output""; sc.settings.figdir = folder + ""Plots/""; sc.set_figure_params(vector_friendly = True, dpi=300). sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3); sc.logging.print_version_and_date(); sc.logging.print_header(). ad",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1625:5374,install,installing,5374,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1625,1,['install'],['installing']
Deployability,"2 layer=layer,; (...); 449 flavor=flavor,; 450 ). File ~/miniconda3/envs/singlecell/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:85, in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, check_values, span, subset, inplace); 83 x = np.log10(mean[not_const]); 84 model = loess(x, y, span=span, degree=2); ---> 85 model.fit(); 86 estimat_var[not_const] = model.outputs.fitted_values; 87 reg_std = np.sqrt(10**estimat_var). File _loess.pyx:899, in _loess.loess.fit(). ValueError: b'reciprocal condition number 6.4708e-16'; ```. ### Versions. <details>. ```; -----; anndata 0.9.1; scanpy 1.9.3; -----; PIL 9.5.0; asttokens NA; backcall 0.2.0; cffi 1.15.1; comm 0.1.2; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.5.1; decorator 5.1.1; defusedxml 0.7.1; executing 0.8.3; h5py 3.8.0; igraph 0.10.4; importlib_resources NA; ipykernel 6.19.2; ipython_genutils 0.2.0; jedi 0.18.1; joblib 1.2.0; jupyter_server 1.23.4; kiwisolver 1.4.4; leidenalg 0.9.1; llvmlite 0.40.0; matplotlib 3.7.1; mpl_toolkits NA; natsort 8.3.1; numba 0.57.0; numpy 1.24.3; packaging 23.0; pandas 2.0.1; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; platformdirs 2.5.2; prompt_toolkit 3.0.36; psutil 5.9.0; ptyprocess 0.7.0; pure_eval 0.2.2; pydev_ipython NA; pydevconsole NA; pydevd 2.6.0; pydevd_concurrency_analyser NA; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.15.1; pyparsing 3.0.9; pytz 2022.7; scipy 1.10.1; session_info 1.0.0; setuptools 66.0.0; six 1.16.0; sklearn 1.2.2; stack_data 0.2.0; texttable 1.6.7; threadpoolctl 3.1.0; tornado 6.2; traitlets 5.7.1; typing_extensions NA; wcwidth 0.2.5; yaml 6.0.1; zipp NA; zmq 25.0.2; -----; IPython 8.12.0; jupyter_client 8.1.0; jupyter_core 5.3.0; jupyterlab 3.5.3; notebook 6.5.4; -----; Python 3.8.16 (default, Mar 2 2023, 03:21:46) [GCC 11.2.0]; Linux-4.15.0-212-generic-x86_64-with-glibc2.17; -----; Session information updated at 2023-09-19 02:18; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2669:3749,update,updated,3749,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2669,1,['update'],['updated']
Deployability,"2); ```. This is my session_info:. ```; Click to view session information; -----; anndata 0.9.2; loguru 0.7.2; matplotlib 3.8.0; numpy 1.26.0; pandas 1.4.3; scanpy 1.9.6; seaborn 0.12.2; session_info 1.0.0; -----; Click to view modules imported as dependencies; PIL 9.4.0; argcomplete NA; asttokens NA; attr 23.1.0; awkward 2.4.2; awkward_cpp NA; backcall 0.2.0; cffi 1.15.1; comm 0.1.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.8.0; decorator 5.1.1; dot_parser NA; etils 1.4.1; exceptiongroup 1.1.3; executing 1.2.0; get_annotations NA; gmpy2 2.1.2; h5py 3.9.0; harmonypy NA; igraph 0.10.8; importlib_metadata NA; importlib_resources NA; ipykernel 6.25.2; ipywidgets 8.1.1; jax 0.4.20; jaxlib 0.4.20; jedi 0.19.0; joblib 1.2.0; kiwisolver 1.4.4; leidenalg 0.10.1; llvmlite 0.41.1; ml_dtypes 0.2.0; mpl_toolkits NA; mpmath 1.3.0; natsort 8.4.0; numba 0.58.1; nvfuser NA; opt_einsum v3.0.0; packaging 23.1; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; platformdirs 3.10.0; prompt_toolkit 3.0.39; psutil 5.9.5; ptyprocess 0.7.0; pure_eval 0.2.2; pyarrow 13.0.0; pycparser 2.21; pydev_ipython NA; pydevconsole NA; pydevd 2.9.5; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pydot 1.4.2; pygments 2.16.1; pynndescent 0.5.5; pyparsing 3.0.9; pytz 2023.3.post1; rich NA; scipy 1.10.1; setuptools 68.0.0; six 1.16.0; sklearn 1.3.2; sparse 0.14.0; stack_data 0.6.2; statsmodels 0.13.1; sympy 1.11.1; texttable 1.6.7; threadpoolctl 3.2.0; torch 2.0.1; tornado 6.3.3; tqdm 4.66.1; traitlets 5.10.0; typing_extensions NA; umap 0.5.3; wcwidth 0.2.6; yaml 6.0; zipp NA; zmq 25.1.1; -----; IPython 8.15.0; jupyter_client 8.3.1; jupyter_core 5.3.1; -----; Python 3.9.18 (main, Sep 11 2023, 13:41:44) [GCC 11.2.0]; Linux-6.2.0-36-generic-x86_64-with-glibc2.35; -----; Session information updated at 2023-11-23 00:08; ```. I uploaded the ipynb file as attachment. 👇. [harmony_test.ipynb.zip](https://github.com/scverse/scanpy/files/13441924/harmony_test.ipynb.zip)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2655#issuecomment-1823084227:4731,update,updated,4731,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2655#issuecomment-1823084227,1,['update'],['updated']
Deployability,2-time 0.2.0; jmespath 0.10.0; joblib 1.2.0; json5 0.9.6; jsonpatch 1.32; jsonpointer 2.1; jsonschema 4.17.3; jupyter 1.0.0; jupyter_client 7.4.9; jupyter-console 6.6.3; jupyter_core 5.3.0; jupyter-events 0.6.3; jupyter-server 1.23.4; jupyter_server_fileid 0.9.0; jupyter_server_ydoc 0.8.0; jupyter-ydoc 0.2.4; jupyterlab 3.6.3; jupyterlab-pygments 0.1.2; jupyterlab_server 2.22.0; jupyterlab-widgets 3.0.5; kaleido 0.2.1; keyring 23.13.1; kiwisolver 1.4.4; lazy_loader 0.2; lazy-object-proxy 1.6.0; libarchive-c 2.9; libmambapy 1.5.1; linkify-it-py 2.0.0; llvmlite 0.40.0; lmdb 1.4.1; locket 1.0.0; lxml 4.9.3; lz4 4.3.2; Markdown 3.4.1; markdown-it-py 2.2.0; MarkupSafe 2.1.1; matplotlib 3.7.2; matplotlib-inline 0.1.6; mccabe 0.7.0; mdit-py-plugins 0.3.0; mdurl 0.1.0; mistune 0.8.4; mkl-fft 1.3.8; mkl-random 1.2.4; mkl-service 2.4.0; more-itertools 8.12.0; mpmath 1.3.0; msgpack 1.0.3; multidict 6.0.2; multipledispatch 0.6.0; multiprocess 0.70.14; munkres 1.1.4; mypy-extensions 1.0.0; navigator-updater 0.4.0; nbclassic 0.5.5; nbclient 0.5.13; nbconvert 6.5.4; nbformat 5.9.2; nest-asyncio 1.5.6; networkx 3.1; nltk 3.8.1; notebook 6.5.4; notebook_shim 0.2.2; numba 0.57.1; numexpr 2.8.4; numpy 1.24.3; numpydoc 1.5.0; openpyxl 3.0.10; packaging 23.1; pandas 2.0.3; pandocfilters 1.5.0; panel 1.2.3; param 1.13.0; parsel 1.6.0; parso 0.8.3; partd 1.4.0; pathlib 1.0.1; pathspec 0.10.3; patsy 0.5.3; pep8 1.7.1; pexpect 4.8.0; pickleshare 0.7.5; Pillow 9.4.0; pip 23.2.1; pkce 1.0.3; pkginfo 1.9.6; platformdirs 3.10.0; plotly 5.9.0; pluggy 1.0.0; ply 3.11; poyo 0.5.0; prometheus-client 0.14.1; prompt-toolkit 3.0.36; Protego 0.1.16; psutil 5.9.0; ptyprocess 0.7.0; pure-eval 0.2.2; py-cpuinfo 8.0.0; pyarrow 11.0.0; pyasn1 0.4.8; pyasn1-modules 0.2.8; pycodestyle 2.10.0; pycosat 0.6.4; pycparser 2.21; pyct 0.5.0; pycurl 7.45.2; pydantic 1.10.8; PyDispatcher 2.0.5; pydocstyle 6.3.0; pyerfa 2.0.0; pyflakes 3.0.1; Pygments 2.15.1; PyJWT 2.4.0; pylint 2.16.2; pylint-venv 2.3.0; pyls-spyder 0.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2706:4695,update,updater,4695,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2706,1,['update'],['updater']
Deployability,"2.0.0->scanpy); Using cached python_dateutil-2.6.1-py2.py3-none-any.whl; Collecting pytz (from matplotlib==2.0.0->scanpy); Using cached pytz-2018.3-py2.py3-none-any.whl; Requirement already up-to-date: six>=1.10 in /cluster/software/lib/python3.6/site-packages (from matplotlib==2.0.0->scanpy); Requirement already up-to-date: numpy>=1.7.1 in /cluster/software/lib/python3.6/site-packages (from matplotlib==2.0.0->scanpy); Requirement already up-to-date: pyparsing!=2.0.0,!=2.0.4,!=2.1.2,!=2.1.6,>=1.5.6 in /cluster/software/lib/python3.6/site-packages (from matplotlib==2.0.0->scan; Requirement already up-to-date: patsy in /cluster/software/lib/python3.6/site-packages (from statsmodels->scanpy); Requirement already up-to-date: decorator>=4.1.0 in /cluster/software/lib/python3.6/site-packages (from networkx->scanpy); Installing collected packages: scanpy, python-dateutil, pytz; Running setup.py install for scanpy: started; Running setup.py install for scanpy: finished with status 'error'; Complete output from command /cluster/software/bin/python3.6 -u -c ""import setuptools, tokenize;__file__='/scratch/tmp/pip-build-g14yf1xi/scanpy/setup.py';; running install; running build; running build_py; creating build; creating build/lib.linux-x86_64-3.6; creating build/lib.linux-x86_64-3.6/scanpy; copying scanpy/settings.py -> build/lib.linux-x86_64-3.6/scanpy; copying scanpy/_version.py -> build/lib.linux-x86_64-3.6/scanpy; copying scanpy/__init__.py -> build/lib.linux-x86_64-3.6/scanpy; copying scanpy/__main__.py -> build/lib.linux-x86_64-3.6/scanpy; copying scanpy/readwrite.py -> build/lib.linux-x86_64-3.6/scanpy; copying scanpy/utils.py -> build/lib.linux-x86_64-3.6/scanpy; copying scanpy/exporting.py -> build/lib.linux-x86_64-3.6/scanpy; copying scanpy/logging.py -> build/lib.linux-x86_64-3.6/scanpy; creating build/lib.linux-x86_64-3.6/scanpy/plotting copying scanpy/plotting/top_genes_visual.py -> build/lib.linux-x86_64-3.6/scanpy/plotting copying scanpy/plotting/rcmod.py -> bui",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/90:2770,install,install,2770,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/90,1,['install'],['install']
Deployability,"2.8.2; debugpy 1.8.0; decorator 5.1.1; defusedxml 0.7.1; executing 2.0.0; fastjsonschema NA; fqdn NA; h5py 3.9.0; idna 3.4; igraph 0.10.8; ipykernel 6.25.2; ipywidgets 8.1.1; isoduration NA; jedi 0.19.1; jinja2 3.1.2; joblib 1.3.2; json5 NA; jsonpointer 2.4; jsonschema 4.19.1; jsonschema_specifications NA; jupyter_events 0.7.0; jupyter_server 2.7.3; jupyterlab_server 2.25.0; kiwisolver 1.4.4; legacy_api_wrap NA; leidenalg 0.10.1; llvmlite 0.41.0; markupsafe 2.1.3; matplotlib 3.7.1; matplotlib_inline 0.1.6; mpl_toolkits NA; mpmath 1.3.0; natsort 8.4.0; nbformat 5.9.2; numba 0.58.0; numpy 1.24.3; opt_einsum v3.3.0; overrides NA; packaging 23.1; pandas 2.0.3; parso 0.8.3; patsy 0.5.3; pickleshare 0.7.5; platformdirs 3.11.0; prometheus_client NA; prompt_toolkit 3.0.39; psutil 5.9.5; pure_eval 0.2.2; pyarrow 15.0.2; pydev_ipython NA; pydevconsole NA; pydevd 2.9.5; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pydot 2.0.0; pygments 2.16.1; pyparsing 3.0.9; pythoncom NA; pythonjsonlogger NA; pytz 2023.3; pywin32_bootstrap NA; pywin32_system32 NA; pywintypes NA; referencing NA; requests 2.31.0; rfc3339_validator 0.1.4; rfc3986_validator 0.1.1; rpds NA; scipy 1.10.1; seaborn 0.13.0; send2trash NA; session_info 1.0.0; simplejson 3.19.2; six 1.16.0; sklearn 1.3.1; sniffio 1.3.0; sparse 0.14.0; stack_data 0.6.3; statsmodels 0.14.0; sympy 1.12; texttable 1.7.0; threadpoolctl 3.2.0; tlz 0.12.0; toolz 0.12.0; torch 2.0.1+cpu; tornado 6.3.3; tqdm 4.66.1; traitlets 5.10.1; typing_extensions NA; uri_template NA; urllib3 2.0.6; vscode NA; wcwidth 0.2.8; webcolors 1.13; websocket 1.6.3; win32api NA; win32com NA; win32con NA; win32trace NA; winerror NA; yaml 6.0.1; zipp NA; zmq 25.1.1; -----; IPython 8.16.1; jupyter_client 8.3.1; jupyter_core 5.3.2; jupyterlab 4.0.7; notebook 7.0.5; -----; Python 3.11.9 (tags/v3.11.9:de54cf5, Apr 2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]; Windows-10-10.0.22621-SP0; -----; Session information updated at 2024-04-23 21:26. ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3025:7486,update,updated,7486,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3025,1,['update'],['updated']
Deployability,"2/site-packages/pandas/io/parsers/readers.py:622) if chunksize or iterator:; [623](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/parsers/readers.py:623) return parser. File ~\AppData\Roaming\Python\Python312\site-packages\pandas\io\parsers\readers.py:1620, in TextFileReader.__init__(self, f, engine, **kwds); [1617](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/parsers/readers.py:1617) self.options[""has_index_names""] = kwds[""has_index_names""]; [1619](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/parsers/readers.py:1619) self.handles: IOHandles | None = None; -> [1620](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/parsers/readers.py:1620) self._engine = self._make_engine(f, self.engine). File ~\AppData\Roaming\Python\Python312\site-packages\pandas\io\parsers\readers.py:1880, in TextFileReader._make_engine(self, f, engine); [1878](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/parsers/readers.py:1878) if ""b"" not in mode:; [1879](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/parsers/readers.py:1879) mode += ""b""; -> [1880](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/parsers/readers.py:1880) self.handles = get_handle(; [1881](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3214:12419,Pipeline,PipelineDevelope,12419,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3214,1,['Pipeline'],['PipelineDevelope']
Deployability,"22.12.07; cffi 1.15.1; charset_normalizer 2.1.1; cloudpickle 2.2.1; colorama 0.4.6; comm 0.1.2; cycler 0.10.0; cython_runtime NA; cytoolz 0.12.0; dask 2023.1.1; dateutil 2.8.2; decorator 5.1.1; defusedxml 0.7.1; executing 1.2.0; fastcluster 1.2.6; fastjsonschema NA; gepdynamics NA; h5py 3.8.0; hypergeom_ufunc NA; idna 3.4; igraph 0.10.4; invgauss_ufunc NA; ipykernel 6.21.1; ipython_genutils 0.2.0; ipywidgets 8.0.4; jedi 0.18.2; jinja2 3.1.2; joblib 1.2.0; json5 NA; jsonschema 4.17.3; jupyter_events 0.5.0; jupyter_server 2.2.1; jupyterlab_server 2.19.0; kiwisolver 1.4.4; leidenalg 0.9.1; llvmlite 0.39.1; louvain 0.8.0; markupsafe 2.1.2; matplotlib 3.6.3; mpl_toolkits NA; natsort 8.2.0; nbformat 5.7.3; nbinom_ufunc NA; ncf_ufunc NA; nct_ufunc NA; ncx2_ufunc NA; numba 0.56.4; numexpr 2.8.3; numpy 1.23.5; packaging 23.0; pandas 1.5.3; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; platformdirs 2.6.2; prometheus_client NA; prompt_toolkit 3.0.36; psutil 5.9.4; ptyprocess 0.7.0; pure_eval 0.2.2; pvectorc NA; pydev_ipython NA; pydevd 1.4.0; pydevd_concurrency_analyser NA; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.14.0; pyparsing 3.0.9; pyrsistent NA; pythonjsonlogger NA; pytz 2022.7.1; requests 2.28.2; scipy 1.10.0; seaborn 0.12.2; send2trash NA; session_info 1.0.0; setuptools 67.1.0; sip NA; sitecustomize NA; six 1.16.0; skewnorm_ufunc NA; sklearn 1.2.1; sniffio 1.3.0; socks 1.7.1; stack_data 0.6.2; statsmodels 0.13.5; texttable 1.6.7; threadpoolctl 3.1.0; tlz 0.12.0; toolz 0.12.0; tornado 6.2; traitlets 5.9.0; typing_extensions NA; unicodedata2 NA; urllib3 1.26.14; wcwidth 0.2.6; websocket 1.5.1; yaml 6.0; zipp NA; zmq 25.0.0; zoneinfo NA; -----; IPython 8.9.0; jupyter_client 8.0.2; jupyter_core 5.2.0; jupyterlab 3.6.1; notebook 6.5.2; -----; Python 3.9.16 | packaged by conda-forge | (main, Feb 1 2023, 21:42:20) [Clang 14.0.6 ]; macOS-13.2.1-x86_64-i386-64bit; -----; Session information updated at 2023-02-15 22:51; </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2418:4261,update,updated,4261,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2418,1,['update'],['updated']
Deployability,"2; running build_ext; skipping 'fa2\fa2util.c' Cython extension (up-to-date); building 'fa2.fa2util' extension; error: Microsoft Visual C++ 14.0 is required. Get it with ""Build Tools for Visual Studio"": https://visualstudio.microsoft.com/downloads/; ----------------------------------------; ERROR: Failed building wheel for fa2; Running setup.py clean for fa2; Failed to build fa2; Installing collected packages: fa2; Running setup.py install for fa2 ... error. ERROR: Command errored out with exit status 1:; command: 'C:\ProgramData\Miniconda3\envs\Jayalal_2_Miniconda\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""'; __file__='""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' install --record 'C:\Users\xkalaj\AppData\Local\Temp\pip-record-y21s2idm\install-record.txt' --single-version-externally-managed --compile --install-headers 'C:\ProgramData\Miniconda3\envs\Jayalal_2_Miniconda\Include\fa2'; cwd: C:\Users\xkalaj\AppData\Local\Temp\pip-install-golo7r_8\fa2\; Complete output (30 lines):; Installing fa2 package (fastest forceatlas2 python implementation). >>>> Cython is installed?; Yes. >>>> Starting to install!. running install; running build; running build_py; creating build; creating build\lib.win-amd64-3.6; creating build\lib.win-amd64-3.6\fa2; copying fa2\fa2util.py -> build\lib.win-amd64-3.6\fa2; copying fa2\forceatlas2.py -> build\lib.win-amd64-3.6\fa2; copying fa2\__init__.py -> build\lib.win-amd64-3.6\fa2; running egg_info; writing fa2.egg-info\PKG-INFO; writing dependency_links to fa2.egg-info\dependency_links.txt; writing requirements to fa2.egg-info\requires.txt; writing top-level names to fa2.egg-info\top_level.txt; reading manifest file 'fa2.egg-info\SOURCES.t",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1256:3528,install,install,3528,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1256,2,['install'],"['install', 'install-record']"
Deployability,"3.1.0; babel 2.12.1; backcall 0.2.0; certifi 2023.05.07; cffi 1.15.1; charset_normalizer 3.1.0; cloudpickle 2.2.1; colorama 0.4.6; comm 0.1.3; cycler 0.10.0; cython_runtime NA; cytoolz 0.12.0; dask 2023.6.0; dateutil 2.8.2; debugpy 1.6.7; decorator 5.1.1; defusedxml 0.7.1; executing 1.2.0; fastjsonschema NA; google NA; h5py 3.9.0; idna 3.4; igraph 0.10.4; importlib_resources NA; ipykernel 6.23.3; ipython_genutils 0.2.0; ipywidgets 8.0.6; jedi 0.18.2; jinja2 3.1.2; joblib 1.2.0; json5 NA; jsonschema 4.17.3; jupyter_events 0.6.3; jupyter_server 2.6.0; jupyterlab_server 2.23.0; kiwisolver 1.4.4; leidenalg 0.9.1; llvmlite 0.40.0; louvain 0.8.0; markupsafe 2.1.3; matplotlib 3.7.1; mpl_toolkits NA; natsort 8.4.0; nbformat 5.9.0; numba 0.57.0; numexpr 2.8.4; numpy 1.24.3; objc 9.2; overrides NA; packaging 23.1; pandas 2.0.2; parso 0.8.3; patsy 0.5.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; platformdirs 3.8.0; prometheus_client NA; prompt_toolkit 3.0.38; psutil 5.9.5; ptyprocess 0.7.0; pure_eval 0.2.2; pvectorc NA; pydev_jupyter_utils NA; pydev_jupyter_vars NA; pydevconsole NA; pydevd_file_utils NA; pydevd_plugins NA; pygments 2.15.1; pyparsing 3.1.0; pyrsistent NA; pythonjsonlogger NA; pytz 2023.3; requests 2.31.0; rfc3339_validator 0.1.4; rfc3986_validator 0.1.1; scipy 1.11.0; seaborn 0.12.2; send2trash NA; session_info 1.0.0; setuptools 68.0.0; six 1.16.0; sklearn 1.2.2; sniffio 1.3.0; socks 1.7.1; stack_data 0.6.2; statsmodels 0.14.0; texttable 1.6.7; threadpoolctl 3.1.0; tlz 0.12.0; toolz 0.12.0; torch 1.12.1; tornado 6.3.2; tqdm 4.65.0; traitlets 5.9.0; typing_extensions NA; urllib3 2.0.3; wcwidth 0.2.6; websocket 1.6.1; yaml 6.0; zipp NA; zmq 25.1.0; zoneinfo NA; -----; IPython 8.14.0; jupyter_client 8.3.0; jupyter_core 5.3.1; jupyterlab 4.0.2; notebook 6.5.4; -----; Python 3.9.16 | packaged by conda-forge | (main, Feb 1 2023, 21:42:20) [Clang 14.0.6 ]; macOS-12.6.6-x86_64-i386-64bit; -----; Session information updated at 2023-06-26 14:43. ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2531#issuecomment-1608050519:2314,update,updated,2314,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2531#issuecomment-1608050519,1,['update'],['updated']
Deployability,"3.2-py3.6.egg/setuptools/command/install.py"", line 61, in run; File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/command/install.py"", line 545, in run; self.run_command('build'); File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/cmd.py"", line 313, in run_command; self.distribution.run_command(command); File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 974, in run_command; cmd_obj.run(); File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/command/build.py"", line 135, in run; self.run_command(cmd_name); File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/cmd.py"", line 313, in run_command; self.distribution.run_command(command); File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 974, in run_command; cmd_obj.run(); File ""/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/versioneer.py"", line 1555, in run; _build_py.run(self); File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 47, in run; File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 103, in build_package_data; File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 59, in __getattr__; File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 86, in _get_data_files; File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 94, in find_data_files; TypeError: must be str, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/148:6675,install,install-,6675,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148,1,['install'],['install-']
Deployability,"312/site-packages/pandas/io/common.py:769) ); [770](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/common.py:770) else:; [771](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/common.py:771) handle = gzip.GzipFile(; [772](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/common.py:772) # No overload variant of ""GzipFile"" matches argument types; [773](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/common.py:773) # ""Union[str, BaseBuffer]"", ""str"", ""Dict[str, Any]""; (...); [776](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/common.py:776) **compression_args,; [777](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/common.py:777) ). File c:\Program Files\Python312\Lib\gzip.py:192, in GzipFile.__init__(self, filename, mode, compresslevel, fileobj, mtime); [190](file:///C:/Program%20Files/Python312/Lib/gzip.py:190) mode += 'b'; [191](file:///C:/Program%20Files/Python312/Lib/gzip.py:191) if fileobj is None:; --> [192](file:///C:/Program%20Files/Python312/Lib/gzip.py:192) fileobj = self.myfileobj = builtins.open(filename, mode or 'rb'); [193](file:///C:/Program%20Files/Python312/Lib/gzip.py:193) if filename is None:; [194](file:///C:/Program%20Files/Python312/Lib/gzip.py:194) filename = getattr(fileobj, 'name', ''). FileNotFoundError: [Errno 2] No such file or directory: 'GSE212966\\GSM6567159_PDAC2_features.tsv.gz'; ```. I have tried with other datasets whi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3214:18692,Pipeline,PipelineDevelope,18692,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3214,1,['Pipeline'],['PipelineDevelope']
Deployability,"3c4f42 NA; absl NA; astunparse 1.6.3; atomicwrites 1.4.1; autoreload NA; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; brotli NA; bs4 4.11.1; certifi 2022.09.14; cffi 1.15.1; chardet 5.0.0; charset_normalizer 2.1.1; cloudpickle 2.2.0; colorama 0.4.5; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.6.3; decorator 5.1.1; defusedxml 0.7.1; dill 0.3.5.1; entrypoints 0.4; flatbuffers 2.0; gast 0.5.3; google NA; h5py 3.7.0; hypergeom_ufunc NA; idna 3.3; igraph 0.9.11; import_all NA; ipykernel 6.15.3; jedi 0.18.1; joblib 1.2.0; keras 2.8.0; keras_preprocessing 1.1.2; kiwisolver 1.4.4; leidenalg 0.8.10; llvmlite 0.38.1; louvain 0.7.1; lxml 4.9.1; matplotlib 3.5.3; matplotlib_inline 0.1.6; mpl_toolkits NA; natsort 8.2.0; nbinom_ufunc NA; ncf_ufunc NA; numba 0.55.2; numpy 1.22.4; opt_einsum v3.3.0; packaging 21.3; pandas 1.4.4; params NA; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; plotly 5.10.0; prompt_toolkit 3.0.31; psutil 5.9.2; ptyprocess 0.7.0; pycparser 2.21; pydev_ipython NA; pydevconsole NA; pydevd 2.8.0; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.13.0; pynndescent 0.5.7; pyparsing 3.0.9; pytz 2022.2.1; requests 2.28.1; scipy 1.9.1; seaborn 0.12.0; session_info 1.0.0; setuptools 65.3.0; sip NA; six 1.16.0; sklearn 1.1.2; socks 1.7.1; soupsieve 2.3.2.post1; sphinxcontrib NA; spyder 5.3.3; spyder_kernels 2.3.3; spydercustomize NA; statsmodels 0.13.2; storemagic NA; tensorboard 2.8.0; tensorflow 2.8.0; termcolor 1.1.0; texttable 1.6.4; threadpoolctl 3.1.0; tornado 6.2; tqdm 4.64.1; traitlets 5.4.0; typing_extensions NA; umap 0.5.3; unicodedata2 NA; urllib3 1.26.11; wcwidth 0.2.5; wrapt 1.14.1; wurlitzer 3.0.2; yaml 6.0; zipp NA; zmq 24.0.0; -----; IPython 7.33.0; jupyter_client 7.3.5; jupyter_core 4.11.1; -----; Python 3.9.13 | packaged by conda-forge | (main, May 27 2022, 16:56:21) [GCC 10.3.0]; Linux-5.4.0-124-generic-x86_64-with-glibc2.31; -----; Session information updated at 2022-09-16 10:24]. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2330:4432,update,updated,4432,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2330,1,['update'],['updated']
Deployability,"4 impl,. C:\ProgramData\Anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class); 714 pipeline = pipeline_class(typingctx, targetctx, library,; 715 args, return_type, flags, locals); --> 716 return pipeline.compile_extra(func); 717 ; 718 . C:\ProgramData\Anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(self, func); 450 self.state.lifted = (); 451 self.state.lifted_from = None; --> 452 return self._compile_bytecode(); 453 ; 454 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. C:\ProgramData\Anaconda3\lib\site-packages\numba\core\compiler.py in _compile_bytecode(self); 518 """"""; 519 assert self.state.func_ir is None; --> 520 return self._compile_core(); 521 ; 522 def _compile_ir(self):. C:\ProgramData\Anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self); 497 self.state.status.fail_reason = e; 498 if is_final_pipeline:; --> 499 raise e; 500 else:; 501 raise CompilerError(""All available pipelines exhausted""). C:\ProgramData\Anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self); 484 res = None; 485 try:; --> 486 pm.run(self.state); 487 if self.state.cr is not None:; 488 break. C:\ProgramData\Anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state); 366 (self.pipeline_name, pass_desc); 367 patched_exception = self._patch_error(msg, e); --> 368 raise patched_exception; 369 ; 370 def dependency_analysis(self):. C:\ProgramData\Anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state); 354 pass_inst = _pass_registry.get(pss).pass_inst; 355 if isinstance(pass_inst, CompilerPass):; --> 356 self._runPass(idx, pass_inst, state); 357 else:; 358 raise BaseException(""Legacy pass in use""). C:\ProgramData\Anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs); 33 def _acquire_compile_lock(*args, **kwargs):; 34 with self:; ---> 35 r",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1756#issuecomment-1319286325:8294,pipeline,pipelines,8294,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1756#issuecomment-1319286325,1,['pipeline'],['pipelines']
Deployability,"4 model.fit(); 85 estimat_var[not_const] = model.outputs.fitted_values; 86 reg_std = np.sqrt(10 ** estimat_var). _loess.pyx in _loess.loess.fit(). ValueError: b'There are other near singularities as well. 0.090619\n'; ```. While looking for a solution, I came across [this](https://github.com/YosefLab/scvi-tools/issues/727#issuecomment-718717033) issue that reports a similar problem. Any ideas of what this may be? . Thanks . #### Versions. <details>. [WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.4; scanpy 1.6.0; sinfo 0.3.1; -----; PIL 8.0.1; SCCAF NA; anndata 0.7.4; backcall 0.1.0; cffi 1.14.3; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; decorator 4.4.1; get_version 2.1; google NA; h5py 2.10.0; igraph 0.8.0; importlib_metadata 1.7.0; ipykernel 5.1.4; ipython_genutils 0.2.0; ipywidgets 7.5.1; jedi 0.16.0; joblib 0.17.0; kiwisolver 1.1.0; legacy_api_wrap 1.2; leidenalg 0.8.2; llvmlite 0.31.0; louvain 0.6.1; matplotlib 3.1.3; mpl_toolkits NA; natsort 7.0.1; numba 0.48.0; numexpr 2.7.1; numpy 1.19.4; packaging 20.4; pandas 1.1.4; parso 0.6.1; patsy 0.5.1; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.3; psutil 5.7.2; ptyprocess 0.6.0; pycparser 2.20; pygments 2.7.2; pyparsing 2.4.7; pytz 2020.1; rich NA; ruamel NA; scanpy 1.6.0; scipy 1.5.4; scvi 0.7.1; seaborn 0.10.0; setuptools_scm NA; sinfo 0.3.1; six 1.15.0; sklearn 0.23.2; statsmodels 0.11.1; storemagic NA; tables 3.6.1; texttable 1.6.2; threadpoolctl 2.1.0; torch 1.6.0; tornado 6.0.3; tqdm 4.32.2; traitlets 4.3.3; typing_extensions NA; umap 0.3.10; wcwidth NA; yaml 5.3.1; zipp NA; zmq 19.0.0; -----; IPython 7.12.0; jupyter_client 6.0.0; jupyter_core 4.6.3; jupyterlab 1.2.5; notebook 6.0.3; -----; Python 3.7.6 | packaged by conda-forge | (default, Jan 7 2020, 22:33:48) [GCC 7.3.0]; Linux-4.4.0-189-generic-x86_64-with-debian-buster-sid; 24 logical CPU cores, x86_64; -----; Session information updated at 2020-11-23 09:17. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1504:3514,update,updated,3514,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504,1,['update'],['updated']
Deployability,4-100n-100theta-infclip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_embedding_plots.py::test_missing_values_categorical[pca-na_color.black_tup-na_in_legend.False-legend.on_right-groups.3] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[toarray-float32-100n-inftheta-infclip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100n-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-100n-100theta-30clip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-100n-100theta-30clip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-200n-inftheta-noclip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100n-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100n-inftheta-infclip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED sca,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:38503,pipeline,pipeline,38503,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['pipeline'],['pipeline']
Deployability,4-200n-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[toarray-float32-100n-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[toarray-int64-200n-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[toarray-float32-100n-100theta-noclip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/preprocessing/_simple.py::scanpy.preprocessing._simple.filter_cells; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200n-100theta-30clip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[toarray-float32-200n-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/plotting/_baseplot_class.py::scanpy.plotting._baseplot_class.BasePlot.add_totals; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100n-100theta-noclip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[toarray-float32-200n-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[toarray-float32-100n-100theta-infclip-subset] - NotImplementedError: ,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:26777,pipeline,pipeline,26777,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['pipeline'],['pipeline']
Deployability,"401, in _compile_for_args; error_rewrite(e, 'typing'); File ""/home/nr/miniconda3/lib/python3.7/site-packages/numba/dispatcher.py"", line 344, in error_rewrite; reraise(type(e), e, None); File ""/home/nr/miniconda3/lib/python3.7/site-packages/numba/six.py"", line 668, in reraise; raise value.with_traceback(tb); numba.errors.TypingError: Failed in nopython mode pipeline (step: nopython frontend); Invalid use of type(CPUDispatcher(<function rdist at 0x7f8ffd913050>)) with parameters (array(float64, 1d, C), array(float32, 1d, C)); Known signatures:; * (array(float32, 1d, A), array(float32, 1d, A)) -> float32; * parameterized; [1] During: resolving callee type: type(CPUDispatcher(<function rdist at 0x7f8ffd913050>)); [2] During: typing of call at /home/nr/miniconda3/lib/python3.7/site-packages/umap/umap_.py (795). File ""miniconda3/lib/python3.7/site-packages/umap/umap_.py"", line 795:; def optimize_layout(; <source elided>. dist_squared = rdist(current, other); ^. This is not usually a problem with Numba itself but instead often caused by; the use of unsupported features or an issue in resolving types. To see Python/NumPy features supported by the latest release of Numba visit:; http://numba.pydata.org/numba-doc/latest/reference/pysupported.html; and; http://numba.pydata.org/numba-doc/latest/reference/numpysupported.html. For more information about typing errors and how to debug them visit:; http://numba.pydata.org/numba-doc/latest/user/troubleshoot.html#my-code-doesn-t-compile. If you think your code should work with Numba, please report the error message; and traceback, along with a minimal reproducer at:; https://github.com/numba/numba/issues/new. ```. I saw a relevant [issue](https://github.com/lmcinnes/umap/issues/179) on the umap package and ; even changed line 1138 in [umap_.py](https://github.com/lmcinnes/umap/blob/80f1247de0d60eb60d7222a3cdf9aef9452ab38e/umap/umap_.py) from `embedding` to `embedding..astype(np.float32, copy=True)`, but no success. Any idea?. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/948:1935,release,release,1935,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/948,1,['release'],['release']
Deployability,"44051 exclude bool, which would return a 2d ndarray; key = com.cast_scalar_indexer(key, warn_float=True); return getitem(key); ; if isinstance(key, slice):; # This case is separated from the conditional above to avoid; # pessimization com.is_bool_indexer and ndim checks.; result = getitem(key); # Going through simple_new for performance.; return type(self)._simple_new(result, name=self._name); ; if com.is_bool_indexer(key):; # if we have list[bools, length=1e5] then doing this check+convert; # takes 166 µs + 2.1 ms and cuts the ndarray.__getitem__; # time below from 3.8 ms to 496 µs; # if we already have ndarray[bool], the overhead is 1.4 µs or .25%; key = np.asarray(key, dtype=bool); ; > result = getitem(key); E IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed. ../../venvs/single-cell/lib/python3.8/site-packages/pandas/core/indexes/base.py:5055: IndexError; ```. #### Versions. <details>. -----; anndata 0.9.0rc2.dev18+g7771f6ee; scanpy 1.10.0.dev50+g3e3427d0; -----; PIL 9.1.1; asciitree NA; beta_ufunc NA; binom_ufunc NA; cffi 1.15.0; cloudpickle 2.2.1; cycler 0.10.0; cython_runtime NA; dask 2023.3.2; dateutil 2.8.2; defusedxml 0.7.1; entrypoints 0.4; fasteners 0.17.3; h5py 3.7.0; hypergeom_ufunc NA; igraph 0.10.4; jinja2 3.1.2; joblib 1.1.0; kiwisolver 1.4.3; leidenalg 0.9.1; llvmlite 0.38.1; markupsafe 2.1.1; matplotlib 3.5.2; mpl_toolkits NA; natsort 8.1.0; nbinom_ufunc NA; numba 0.55.2; numcodecs 0.10.2; numpy 1.22.4; packaging 21.3; pandas 1.4.3; pkg_resources NA; psutil 5.9.1; pyparsing 3.0.9; pytz 2022.1; scipy 1.8.1; session_info 1.0.0; setuptools 67.2.0; setuptools_scm NA; six 1.16.0; sklearn 1.1.1; sphinxcontrib NA; texttable 1.6.7; threadpoolctl 3.1.0; tlz 0.12.0; toolz 0.12.0; typing_extensions NA; wcwidth 0.2.5; yaml 6.0; zarr 2.12.0; zipp NA; -----; Python 3.8.16 (default, Dec 7 2022, 12:42:00) [GCC 12.2.0]; Linux-6.2.10-zen1-1-zen-x86_64-with-glibc2.34; -----; Session information updated at 2023-04-11 15:57. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2465:4965,update,updated,4965,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2465,1,['update'],['updated']
Deployability,"48/lib/site-packages/numba/core/dispatcher.py?line=157) # Check typing error if object mode is used; [159](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/dispatcher.py?line=158) if cres.typing_error is not None and not flags.enable_pyobject:. File D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\numba\core\compiler.py:693, in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class); [669](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=668) """"""Compiler entry point; [670](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=669) ; [671](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=670) Parameter; (...); [689](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=688) compiler pipeline; [690](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=689) """"""; [691](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=690) pipeline = pipeline_class(typingctx, targetctx, library,; [692](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=691) args, return_type, flags, locals); --> [693](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=692) return pipeline.compile_extra(func). File D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\numba\core\compiler.py:429, in CompilerBase.compile_extra(self, func); [427](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=426) self.state.lifted = (); [428](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=427) self.state.lifted_from = None; --> [429](file:///d%3A/Users/xiangrong1/Miniconda3/envs",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2160#issuecomment-1107838659:18717,pipeline,pipeline,18717,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160#issuecomment-1107838659,1,['pipeline'],['pipeline']
Deployability,"4; cycler 0.10.0; cython_runtime NA; cytoolz 0.12.2; dask 2021.04.0; dateutil 2.8.2; debugpy 1.7.0; decorator 5.1.1; defusedxml 0.7.1; entrypoints 0.4; executing 1.2.0; fastcluster 1.2.6; fastjsonschema NA; fqdn NA; fsspec 2023.9.0; google NA; h5py 3.9.0; idna 3.4; igraph 0.10.8; importlib_resources NA; ipykernel 6.25.2; ipython_genutils 0.2.0; isoduration NA; jedi 0.19.0; jinja2 3.1.2; joblib 1.3.2; json5 NA; jsonpointer 2.0; jsonschema 4.19.0; jsonschema_specifications NA; jupyter_server 1.24.0; jupyterlab_server 2.24.0; kiwisolver 1.4.5; leidenalg 0.10.1; llvmlite 0.40.1; louvain 0.8.1; markupsafe 2.1.3; matplotlib 3.7.2; matplotlib_inline 0.1.6; mpl_toolkits NA; natsort 8.4.0; nbformat 5.9.2; numba 0.57.1; numexpr 2.8.6; numpy 1.24.4; packaging 23.1; pandas 1.5.3; parso 0.8.3; patsy 0.5.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; plotly 5.17.0; prometheus_client NA; prompt_toolkit 3.0.39; psutil 5.9.5; ptyprocess 0.7.0; pure_eval 0.2.2; pyarrow 10.0.1; pycparser 2.21; pydev_ipython NA; pydevconsole NA; pydevd 2.9.5; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.16.1; pyparsing 2.4.7; pytz 2023.3.post1; referencing NA; requests 2.31.0; rfc3339_validator 0.1.4; rfc3986_validator 0.1.1; rpds NA; scipy 1.10.1; seaborn 0.12.2; send2trash NA; session_info 1.0.0; setuptools 68.2.2; setuptools_scm NA; six 1.16.0; sklearn 1.3.0; sniffio 1.3.0; socks 1.7.1; stack_data 0.6.2; statsmodels 0.14.0; tblib 1.7.0; terminado 0.17.1; texttable 1.6.7; threadpoolctl 3.2.0; tlz 0.12.2; toolz 0.12.0; tornado 6.1; traitlets 5.9.0; typing_extensions NA; uri_template NA; urllib3 1.26.16; wcwidth 0.2.6; webcolors 1.13; websocket 1.6.3; yaml 6.0.1; zipp NA; zmq 25.1.1; -----; IPython 8.12.0; jupyter_client 7.3.4; jupyter_core 4.12.0; jupyterlab 3.6.5; notebook 6.3.0; -----; Python 3.8.18 (default, Sep 11 2023, 13:40:15) [GCC 11.2.0]; Linux-3.10.0-862.el7.x86_64-x86_64-with-glibc2.17; -----; Session information updated at 2023-09-27 17:56; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2673:5232,update,updated,5232,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2673,1,['update'],['updated']
Deployability,"4f/numba-0.56.4.tar.gz (from scanpy) to build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'; Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba; Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q; Running command python setup.py egg_info; Traceback (most recent call last):; File ""<string>"", line 2, in <module>; File ""<pip-setuptools-caller>"", line 34, in <module>; File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 51, in <module>; _guard_py_ver(); File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 48, in _guard_py_ver; raise RuntimeError(msg.format(cur_py, min_py, max_py)); RuntimeError: Cannot install on Python version 3.11.0; only versions >=3.7,<3.11 are supported.; error: subprocess-exited-with-error; ; × python setup.py egg_info did not run successfully.; │ exit code: 1; ╰─> See above for output.; ; note: This error originates from a subprocess, and is likely not a problem with pip.; full command: /Users/dang/opt/miniconda3/envs2/test/bin/python3.11 -c '; exec(compile('""'""''""'""''""'""'; # This is <pip-setuptools-caller> -- a caller that pip uses to run setup.py; #; # - It imports setuptools before invoking setup.py, to enable projects that directly; # import from `distutils.core` to work with newer packaging standards.; # - It provides a clear error message when setuptools is not installed.; # - It sets `sys.argv[0]` to the underlying `setup.py`, when invoking `setup.py` so; # setuptools doesn'""'""'t think the script is `-c`. This avoids the following warning:; # manifest_maker: standard file '""'""'-c'""'""' not found"".; # - It generates a shim setup.py, for handl",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209:2610,install,install,2610,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209,1,['install'],['install']
Deployability,"51d9588484449eb116f16ee1b89979/setup.py'""'""',), ""<pip-setuptools-caller>"", ""exec""))' egg_info --egg-base /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q; cwd: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/; Preparing metadata (setup.py) ... error; error: metadata-generation-failed. × Encountered error while generating package metadata.; ╰─> See above for output. note: This is an issue with the package mentioned above, not pip.; hint: See above for details.; Exception information:; Traceback (most recent call last):; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/build/metadata_legacy.py"", line 64, in generate_metadata; call_subprocess(; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/utils/subprocess.py"", line 224, in call_subprocess; raise error; pip._internal.exceptions.InstallationSubprocessError: python setup.py egg_info exited with 1. The above exception was the direct cause of the following exception:. Traceback (most recent call last):; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/base_command.py"", line 160, in exc_logging_wrapper; status = run_func(*args); ^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/req_command.py"", line 247, in wrapper; return func(self, options, args); ^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/commands/install.py"", line 400, in run; requirement_set = resolver.resolve(; ^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/resolver.py"", line 92, in resolve; result = self._result = resolver.resolve(; ^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_ve",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209:5262,Install,InstallationSubprocessError,5262,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209,1,['Install'],['InstallationSubprocessError']
Deployability,"52 loess_outputs, loess_prediction,; 53 loess_confidence_intervals, loess_anova). ImportError: DLL load failed while importing _loess: The specified module could not be found.; ```; Step5: run `import skmisc; print(skmisc.__file__)`; ```python; import skmisc; print(skmisc.__file__); C:\Users\Park_Lab\AppData\Roaming\Python\Python38\site-packages\skmisc\__init__.py; ```; Step6: due to Step4, I follow the solution (https://github.com/has2k1/scikit-misc/issues/4) to install Numpy with mkl.; ```python; (base) C:\Users\Park_Lab>conda activate Python38; (Python38) C:\Users\Park_Lab>cd Downloads/; (Python38) C:\Users\Park_Lab\Downloads>pip install numpy-1.21.5+mkl-cp38-cp38-win_amd64.whl; Processing c:\users\park_lab\downloads\numpy-1.21.5+mkl-cp38-cp38-win_amd64.whl; Installing collected packages: numpy; Attempting uninstall: numpy; Found existing installation: numpy 1.21.5; Uninstalling numpy-1.21.5:; Successfully uninstalled numpy-1.21.5; ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.; numba 0.54.1 requires numpy<1.21,>=1.17, but you have numpy 1.21.5+mkl which is incompatible.; Successfully installed numpy-1.21.5+mkl; ```; Step7: check anaconda Python38 environment, numpy-1.21.5+mkl is successfully installed; ![image](https://user-images.githubusercontent.com/75048821/147306587-eb94c188-5c18-40f0-add0-3a899872d786.png). Step8: Scanpy import error. Numpy>v1.20 is conflicted with Scanpy; ```python; import numpy as np; import pandas as pd; import scanpy as sc; import scanpy.external as sce; import scipy; sc.settings.verbosity = 3; sc.logging.print_header(); sc.set_figure_params(dpi=100, dpi_save=600); ; import scvelo as scv; scv.settings.verbosity = 3; scv.settings.presenter_view = True; scv.logging.print_versions(). import cellrank as cr; cr.settings.verbosity = 3; cr.logging.print_versions(). import matplotlib.pyplot as pl; from matplotlib impor",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2073#issuecomment-1000601342:4804,install,installed,4804,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2073#issuecomment-1000601342,1,['install'],['installed']
Deployability,"57 def inner(ax, *args, data=None, **kwargs):; 1458 if data is None:; -> 1459 return func(ax, *map(sanitize_sequence, args), **kwargs); 1461 bound = new_sig.bind(ax, *args, **kwargs); 1462 auto_label = (bound.arguments.get(label_namer); 1463 or bound.kwargs.get(label_namer)). File ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\matplotlib\axes\_axes.py:5665, in Axes.imshow(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, **kwargs); 5657 self.set_aspect(aspect); 5658 im = mimage.AxesImage(self, cmap=cmap, norm=norm,; 5659 interpolation=interpolation, origin=origin,; 5660 extent=extent, filternorm=filternorm,; 5661 filterrad=filterrad, resample=resample,; 5662 interpolation_stage=interpolation_stage,; 5663 **kwargs); -> 5665 im.set_data(X); 5666 im.set_alpha(alpha); 5667 if im.get_clip_path() is None:; 5668 # image does not already have clipping set, clip to axes patch. File ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\matplotlib\image.py:710, in _ImageBase.set_data(self, A); 706 self._A = self._A[:, :, 0]; 708 if not (self._A.ndim == 2; 709 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):; --> 710 raise TypeError(""Invalid shape {} for image data""; 711 .format(self._A.shape)); 713 if self._A.ndim == 3:; 714 # If the input data has values outside the valid range (after; 715 # normalisation), we issue a warning and then clip X to the bounds; 716 # - otherwise casting wraps extreme values, hiding outliers and; 717 # making reliable interpretation impossible.; 718 high = 255 if np.issubdtype(self._A.dtype, np.integer) else 1. TypeError: Invalid shape (633,) for image data; ```. ### Versions. <details>. ```; -----; anndata 0.9.2; scanpy 1.10.1; -----; PIL 9.5.0; anyio NA; arrow 1.3.0; asttokens NA; astunparse 1.6.3; attr 23",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3025:4356,patch,patch,4356,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3025,1,['patch'],['patch']
Deployability,"6 elif isinstance(data, ma.MaskedArray):; 437 import numpy.ma.mrecords as mrecords. /usr/local/lib/python3.8/site-packages/pandas/core/internals/construction.py in init_dict(data, index, columns, dtype); 237 else:; 238 nan_dtype = dtype; --> 239 val = construct_1d_arraylike_from_scalar(np.nan, len(index), nan_dtype); 240 arrays.loc[missing] = [val] * missing.sum(); 241 . /usr/local/lib/python3.8/site-packages/pandas/core/dtypes/cast.py in construct_1d_arraylike_from_scalar(value, length, dtype); 1438 else:; 1439 if not isinstance(dtype, (np.dtype, type(np.dtype))):; -> 1440 dtype = dtype.dtype; 1441 ; 1442 if length and is_integer_dtype(dtype) and isna(value):. AttributeError: type object 'object' has no attribute 'dtype'; ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`!; The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info.; -----; anndata 0.7.4; scanpy 1.6.0; sinfo 0.3.4; -----; MulticoreTSNE NA; PIL 8.0.1; appnope 0.1.2; attr 20.3.0; backcall 0.2.0; cffi 1.14.4; cloudpickle 2.0.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.2; dask 2022.01.0; dateutil 2.8.1; decorator 4.4.2; dunamai 1.7.0; fsspec 2022.01.0; get_version 3.5.3; google NA; h5py 2.10.0; idna 2.10; igraph 0.9.6; ipykernel 5.3.4; ipython_genutils 0.2.0; ipywidgets 7.6.5; jedi 0.17.2; jinja2 2.11.2; joblib 1.0.1; jsonschema 3.2.0; jupyter_server 1.13.3; kiwisolver 1.3.1; legacy_api_wrap 1.2; leidenalg 0.8.0; llvmlite 0.38.0; loompy 3.0.6; louvain 0.7.0; markupsafe 1.1.1; matplotlib 3.3.3; mpl_toolkits NA; natsort 7.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2121:4301,install,installs,4301,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2121,1,['install'],['installs']
Deployability,"6.4.tar.gz"" in the cache; Current age based on date: 1302943; Ignoring unknown cache-control directive: immutable; Freshness lifetime from max-age: 365000000; The response is ""fresh"", returning cached response; 365000000 > 1302943; Using cached numba-0.56.4.tar.gz (2.4 MB); Added numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) to build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'; Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba; Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q; Running command python setup.py egg_info; Traceback (most recent call last):; File ""<string>"", line 2, in <module>; File ""<pip-setuptools-caller>"", line 34, in <module>; File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 51, in <module>; _guard_py_ver(); File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 48, in _guard_py_ver; raise RuntimeError(msg.format(cur_py, min_py, max_py)); RuntimeError: Cannot install on Python version 3.11.0; only versions >=3.7,<3.11 are supported.; error: subprocess-exited-with-error; ; × python setup.py egg_info did not run successfully.; │ exit code: 1; ╰─> See above for output.; ; note: This error originates from a subprocess, and is likely not a problem with pip.; full command: /Users/dang/opt/miniconda3/envs2/test/bin/python3.11 -c '; exec(compile('""'""''""'""''""'""'; # This is <pip-setuptools-caller> -- a caller that pip uses to run setup.py; #; # - It imports setuptools before invoking setup.py, to enable projects that directly; # import from ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209:2266,install,install-,2266,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209,1,['install'],['install-']
Deployability,"6/lib/python3.7/site-packages/umap/spectral.py in spectral_layout(data, graph, dim, random_state, metric, metric_kwds); 304 random_state,; 305 metric=metric,; --> 306 metric_kwds=metric_kwds,; 307 ); 308 . /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/umap/spectral.py in multi_component_layout(data, graph, n_components, component_labels, dim, random_state, metric, metric_kwds); 191 random_state,; 192 metric=metric,; --> 193 metric_kwds=metric_kwds,; 194 ); 195 else:. /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/umap/spectral.py in component_layout(data, n_components, component_labels, dim, random_state, metric, metric_kwds); 120 else:; 121 distance_matrix = pairwise_distances(; --> 122 component_centroids, metric=metric, **metric_kwds; 123 ); 124 . /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/sklearn/utils/validation.py in inner_f(*args, **kwargs); 70 FutureWarning); 71 kwargs.update({k: arg for k, arg in zip(sig.parameters, args)}); ---> 72 return f(**kwargs); 73 return inner_f; 74 . /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/sklearn/metrics/pairwise.py in pairwise_distances(X, Y, metric, n_jobs, force_all_finite, **kwds); 1738 raise ValueError(""Unknown metric %s. ""; 1739 ""Valid metrics are %s, or 'precomputed', or a ""; -> 1740 ""callable"" % (metric, _VALID_METRICS)); 1741 ; 1742 if metric == ""precomputed"":. ValueError: Unknown metric angular. Valid metrics are ['euclidean', 'l2', 'l1', 'manhattan', 'cityblock', 'braycurtis', 'canberra', 'chebyshev', 'correlation', 'cosine', 'dice', 'hamming', 'jaccard', 'kulsinski', 'mahalanobis', 'matching', 'minkowski', 'rogerstanimoto', 'russellrao', 'seuclidean', 'sokalmichener', 'sokalsneath', 'sqeuclidean', 'yule', 'wminkowski', 'nan_euclidean', 'haversine'], or 'precomputed', or a callable; ```. #### Versions. <details>. -----; anndata 0.7.5; scanpy 1.7.2; sinfo 0.3.1; -----; PIL 8.0.1; anndata 0.7.5; a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1989:2844,update,update,2844,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1989,1,['update'],['update']
Deployability,"7.4; beta_ufunc NA; binom_ufunc NA; bottleneck 1.3.4; certifi 2022.05.18.1; cffi 1.15.0; charset_normalizer 2.0.12; cloudpickle 2.1.0; colorama 0.4.5; cycler 0.10.0; cython_runtime NA; dask 2022.6.1; dateutil 2.8.2; debugpy 1.6.0; decorator 5.1.1; defusedxml 0.7.1; deprecated 1.2.13; diffxpy v0.7.4; entrypoints 0.4; executing 0.8.3; flatbuffers NA; fsspec 2022.5.0; future 0.18.2; gast NA; google NA; graphtools 1.5.2; h5py 3.7.0; hypergeom_ufunc NA; idna 3.3; ipykernel 6.15.0; ipython_genutils 0.2.0; ipywidgets 7.7.0; jedi 0.18.1; jinja2 3.1.2; joblib 1.1.0; keras 2.9.0; kiwisolver 1.4.3; llvmlite 0.38.1; magic 3.0.0; markupsafe 2.1.1; matplotlib 3.4.3; matplotlib_inline NA; mkl 2.4.0; mpl_toolkits NA; natsort 8.1.0; nbinom_ufunc NA; numba 0.55.2; numexpr 2.8.1; numpy 1.22.3; opt_einsum v3.3.0; packaging 21.3; pandas 1.4.2; parso 0.8.3; patsy 0.5.2; pcurve NA; pexpect 4.8.0; phate 1.0.7; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.29; psutil 5.9.1; ptyprocess 0.7.0; pure_eval 0.2.2; pydev_ipython NA; pydevconsole NA; pydevd 2.8.0; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.12.0; pygsp 0.5.1; pyparsing 3.0.9; pytz 2022.1; requests 2.28.0; s_gd2 1.8; scipy 1.8.1; scprep 1.2.0; seaborn 0.11.2; session_info 1.0.0; setuptools 62.6.0; six 1.16.0; sklearn 1.1.1; slingshot NA; sparse 0.13.0; stack_data 0.3.0; statsmodels 0.13.2; swig_runtime_data4 NA; tasklogger 1.1.2; tensorboard 2.9.1; tensorflow 2.9.1; termcolor 1.1.0; threadpoolctl 3.1.0; tlz 0.11.2; toolz 0.11.2; torch 1.11.0; tornado 6.1; tqdm 4.64.0; traitlets 5.3.0; typing_extensions NA; unicodedata2 NA; urllib3 1.26.9; wcwidth 0.2.5; wrapt 1.14.1; yaml 6.0; zipp NA; zmq 23.1.0; -----; IPython 8.4.0; jupyter_client 7.3.4; jupyter_core 4.10.0; notebook 6.4.12; -----; Python 3.9.12 | packaged by conda-forge | (main, Mar 24 2022, 23:25:59) [GCC 10.3.0]; Linux-5.10.16.3-microsoft-standard-WSL2-x86_64-with-glibc2.31; -----; Session information updated at 2022-06-28 16:19; </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2285:12634,update,updated,12634,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2285,1,['update'],['updated']
Deployability,"7251754bb/scanpy/neighbors/__init__.py#L105; https://github.com/theislab/scanpy/blob/07606455c524b38c4efec475a0d7ba87251754bb/scanpy/neighbors/__init__.py#L258. There is a chance that this can also be solved with an import from UMAP.; https://github.com/theislab/scanpy/blob/07606455c524b38c4efec475a0d7ba87251754bb/scanpy/tools/_umap.py#L107. As just discussed, @Koncopd, can you look into this and make a PR that gets rid of the umap legacy code?. Thank you so much!; Alex. PS: Just wrote an explanation for the reasons why I intorduced the duplicated code in the first place.; > The duplicated code in Scanpy came about as I wanted to very quickly move forward with a version 1.0 of Scanpy about a year ago. UMAP was just becoming available on GitHub and there wasn’t even a preprint, I think. It changed very quickly and there were dramatic bugs every now and then. Nonetheless it was clear that it’s a major improvement over existing solutions, both in terms of computational performance, quality of the result and ease of installation and use. I wanted to achieve two things: (i) I had to rewrite some parts of UMAP so that I could decompose it a neighbors computing and a dedicated embedding step; you know that in Scanpy, the neighborhood graph is used for many other things other than for the embedding (clustering and trajectory inference). I also added the Gaussian kernel solution that I had before switching to a “UMAP backend” for `pp.neighbors`; which was needed so that results for DPT could be reproduced. All of this would have been quite a discussion with Leland. Until we would have had settled on the “Scanpy needs” that certainly weren’t aligned with the development of an independent young package, PRs would have been integrated to much time would have been lost. Finally, I wanted absolute reproducibility for Scanpy users, which could only be achieved by “freezing the code”. So, I asked Leland whether he is OK if I add a frozen version of umap as an intermediate solution.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/522:2076,integrat,integrated,2076,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/522,1,['integrat'],['integrated']
Deployability,"8 ); --> 590 test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, layer, pts); 592 if check_nonnegative_integers(test_obj.X) and method != 'logreg':; 593 logg.warning(; 594 ""It seems you use rank_genes_groups on the raw count data. ""; 595 ""Please logarithmize your data before calling rank_genes_groups.""; 596 ). File ~/Desktop/data/env/lib/python3.11/site-packages/scanpy/tools/_rank_genes_groups.py:93, in _RankGenes.__init__(self, adata, groups, groupby, reference, use_raw, layer, comp_pts); 82 def __init__(; 83 self,; 84 adata,; (...); 90 comp_pts=False,; 91 ):; ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['log1p']['base'] is not None:; 94 self.expm1_func = lambda x: np.expm1(x * np.log(adata.uns['log1p']['base'])); 95 else:. KeyError: 'base'; ```. I've pasted the output of scanpy.logging.print_versions() details below as requested, which includes a verification of used scanpy version (latest version, 1.9.3). It may not be important, but I also had to install `leidenalg` manually in the middle of the tutorial. That's the only deviation I made from the original tutorial. <details>. ```; -----; anndata 0.9.2; scanpy 1.9.3; -----; PIL 10.0.0; appnope 0.1.3; asttokens NA; backcall 0.2.0; comm 0.1.3; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.6.7; decorator 5.1.1; executing 1.2.0; h5py 3.9.0; igraph 0.10.6; ipykernel 6.25.0; jedi 0.18.2; joblib 1.3.1; kiwisolver 1.4.4; leidenalg 0.10.1; llvmlite 0.40.1; matplotlib 3.7.2; mpl_toolkits NA; natsort 8.4.0; numba 0.57.1; numpy 1.24.4; packaging 23.1; pandas 2.0.3; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; platformdirs 3.9.1; prompt_toolkit 3.0.39; psutil 5.9.5; ptyprocess 0.7.0; pure_eval 0.2.2; pydev_ipython NA; pydevconsole NA; pydevd 2.9.5; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.15.1; pyparsing 3.0.9; pytz 2023.3; scipy 1.11.1; session_info 1.0.0; sitecustomize NA; six 1.16.0; sklearn 1.3.0; stack_data 0.6.2; texttable 1.6.7; ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2440#issuecomment-1652367453:2220,install,install,2220,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2440#issuecomment-1652367453,1,['install'],['install']
Deployability,"87](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/parsers/readers.py:1887) errors=self.options.get(""encoding_errors"", ""strict""),; [1888](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/parsers/readers.py:1888) storage_options=self.options.get(""storage_options"", None),; [1889](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/parsers/readers.py:1889) ); [1890](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/parsers/readers.py:1890) assert self.handles is not None; [1891](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/parsers/readers.py:1891) f = self.handles.handle. File ~\AppData\Roaming\Python\Python312\site-packages\pandas\io\common.py:765, in get_handle(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options); [761](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/common.py:761) if compression == ""gzip"":; [762](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/common.py:762) if isinstance(handle, str):; [763](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/common.py:763) # error: Incompatible types in assignment (expression has type; [764](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/P",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3214:15591,Pipeline,PipelineDevelope,15591,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3214,1,['Pipeline'],['PipelineDevelope']
Deployability,"9522a491da51d00bc9034d43e/setup.py'""'""'; __file__='""'""'/tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' install --record /tmp/pip-record-j38v6hmh/install-record.txt --single-version-externally-managed --user --prefix= --compile --install-headers /home/ube/.local/include/python3.10/llvmlite; cwd: /tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/; Complete output (29 lines):; running install; running build; got version from file /tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/llvmlite/_version.py {'version': '0.34.0', 'full': 'c5889c9e98c6b19d5d85ebdd982d64a03931f8e2'}; running build_ext; /usr/bin/python /tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/ffi/build.py; LLVM version... Traceback (most recent call last):; File ""/tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/ffi/build.py"", line 105, in main_posix; out = subprocess.check_output([llvm_config, '--version']); File ""/usr/lib/python3.10/subprocess.py"", line 420, in check_output; return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,; File ""/usr/lib/python3.10/subprocess.py"", line 501, in run; with Popen(*popenargs, **kwargs) as process:; File ""/usr/lib/python3.10/subprocess.py"", line 966, in __init__; self._execute_child(args, executable, preexec_fn, close_fds,; File ""/usr/lib/python3.10/subprocess.py"", line 1842, in _execute_child; raise child_exception_type(errno_num, err_msg, err_filename); FileNotFoundError: [Errno 2] No such file or directory: 'llvm-config'; ; During handling of the above exception, another exception occurred:; ; Traceback (most recent call last):; File ""/tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/ffi/build.py"", line 191, in <module>; main(); File ""/tmp/pip-install-i_hyvl0s/llvmlite_d91917e9",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2105:1514,install,install-,1514,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2105,1,['install'],['install-']
Deployability,"96 header=None,; 597 sep=""\t"",; 598 ); 599 if var_names == ""gene_symbols"":; 600 var_names_idx = pd.Index(genes[1].values). File ~\AppData\Roaming\Python\Python312\site-packages\pandas\io\parsers\readers.py:1026, in read_csv(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend); 1013 kwds_defaults = _refine_defaults_read(; 1014 dialect,; 1015 delimiter,; (...); 1022 dtype_backend=dtype_backend,; 1023 ); 1024 kwds.update(kwds_defaults); -> 1026 return _read(filepath_or_buffer, kwds). File ~\AppData\Roaming\Python\Python312\site-packages\pandas\io\parsers\readers.py:620, in _read(filepath_or_buffer, kwds); 617 _validate_names(kwds.get(""names"", None)); 619 # Create the parser.; --> 620 parser = TextFileReader(filepath_or_buffer, **kwds); 622 if chunksize or iterator:; 623 return parser. File ~\AppData\Roaming\Python\Python312\site-packages\pandas\io\parsers\readers.py:1620, in TextFileReader.__init__(self, f, engine, **kwds); 1617 self.options[""has_index_names""] = kwds[""has_index_names""]; 1619 self.handles: IOHandles | None = None; -> 1620 self._engine = self._make_engine(f, self.engine). File ~\AppData\Roaming\Python\Python312\site-packages\pandas\io\parsers\readers.py:1880, in TextFileReader._make_engine(self, f, engine); 1878 if ""b"" not in mode:; 1879 mode += ""b""; -> 1880 self.handles = get_handle(; 1881 f,; 1882 mode,; 1883 encoding=self.options.get(""encoding"", None),; 1884 compression=self.options.get(""compression"", None),; 18",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3214:22672,update,update,22672,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3214,1,['update'],['update']
Deployability,"99 (= 3.5-2),; libxau6 (= 1:1.0.9-1),; libxcb-render0 (= 1.14-3),; libxcb-shm0 (= 1.14-3),; libxcb1 (= 1.14-3),; libxcomposite1 (= 1:0.4.5-1),; libxcursor1 (= 1:1.2.0-2),; libxdamage1 (= 1:1.1.5-2),; libxdmcp6 (= 1:1.1.2-3),; libxext6 (= 2:1.3.4-1),; libxfixes3 (= 1:5.0.3-2),; libxft2 (= 2.3.2-2),; libxi6 (= 2:1.8-1),; libxinerama1 (= 2:1.1.4-2),; libxkbcommon0 (= 1.3.1-1),; libxml2 (= 2.9.12+dfsg-5),; libxrandr2 (= 2:1.5.2-1),; libxrender1 (= 1:0.9.10-1),; libxss1 (= 1:1.2.3-1),; libz3-4 (= 4.8.12-1+b1),; libzstd1 (= 1.4.8+dfsg-3),; linux-libc-dev (= 5.14.16-1),; llvm-11 (= 1:11.1.0-4),; llvm-11-linker-tools (= 1:11.1.0-4),; llvm-11-runtime (= 1:11.1.0-4),; login (= 1:4.8.1-2),; lsb-base (= 11.1.0),; m4 (= 1.4.18-5),; mailcap (= 3.70),; make (= 4.3-4.1),; man-db (= 2.9.4-2),; mawk (= 1.3.4.20200120-2),; media-types (= 4.0.0),; mime-support (= 3.66),; mount (= 2.37.2-4),; ncurses-base (= 6.2+20210905-1),; ncurses-bin (= 6.2+20210905-1),; openssl (= 1.1.1l-1),; passwd (= 1:4.8.1-2),; patch (= 2.7.6-7),; perl (= 5.32.1-6),; perl-base (= 5.32.1-6),; perl-modules-5.32 (= 5.32.1-6),; po-debconf (= 1.0.21+nmu1),; procps (= 2:3.3.17-5),; python-matplotlib-data (= 3.3.4-2),; python-tables-data (= 3.6.1-5),; python3 (= 3.9.7-1),; python3-all (= 3.9.7-1),; python3-anndata (= 0.7.5+ds-3),; python3-asciitree (= 0.3.3-3),; python3-attr (= 20.3.0-1),; python3-certifi (= 2020.6.20-1),; python3-cffi-backend (= 1.15.0-1),; python3-chardet (= 4.0.0-1),; python3-cov-core (= 1.15.0-3),; python3-coverage (= 5.1+dfsg.1-2+b2),; python3-cryptography (= 3.3.2-1),; python3-cycler (= 0.11.0-1),; python3-dateutil (= 2.8.1-6),; python3-decorator (= 4.4.2-2),; python3-distutils (= 3.9.8-1),; python3-docutils (= 0.17.1+dfsg-2),; python3-fasteners (= 0.14.1-2),; python3-gi (= 3.42.0-1+b1),; python3-h5py (= 3.3.0-5),; python3-h5py-serial (= 3.3.0-5),; python3-harmony (= 0.7.1-1),; python3-idna (= 2.10-1),; python3-igraph (= 0.9.6-1),; python3-importlib-metadata (= 4.6.4-1),; python3-iniconfig (= 1.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2048#issuecomment-969885616:10418,patch,patch,10418,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2048#issuecomment-969885616,1,['patch'],['patch']
Deployability,9hf0e4da2_0 ; scanpy 1.8.1 pypi_0 pypi; scikit-learn 1.1.2 py39h598ef33_0 conda-forge; scikit-misc 0.3.1 pypi_0 pypi; scipy 1.13.1 py39h3d5391c_0 conda-forge; scvi-tools 0.20.3 pyhd8ed1ab_0 conda-forge; seaborn 0.12.2 hd8ed1ab_0 conda-forge; seaborn-base 0.12.2 pyhd8ed1ab_0 conda-forge; send2trash 1.8.2 py39hca03da5_0 ; session-info 1.0.0 pyhd8ed1ab_0 conda-forge; setuptools 69.5.1 py39hca03da5_0 ; sinfo 0.3.4 pypi_0 pypi; sip 6.7.12 py39h313beb8_0 ; six 1.16.0 pyh6c4a22f_0 conda-forge; sniffio 1.3.0 py39hca03da5_0 ; soupsieve 2.5 py39hca03da5_0 ; sqlite 3.45.3 h80987f9_0 ; stack_data 0.2.0 pyhd3eb1b0_0 ; statsmodels 0.14.2 py39h161d348_0 conda-forge; stdlib-list 0.10.0 pyhd8ed1ab_0 conda-forge; tbb 2021.8.0 h48ca7d4_0 ; terminado 0.17.1 py39hca03da5_0 ; texttable 1.7.0 pyhd8ed1ab_0 conda-forge; threadpoolctl 3.5.0 pyhc1e730c_0 conda-forge; tinycss2 1.2.1 py39hca03da5_0 ; tk 8.6.14 h6ba3021_0 ; tomli 2.0.1 py39hca03da5_0 ; toolz 0.12.1 pyhd8ed1ab_0 conda-forge; torchmetrics 1.0.3 pyhd8ed1ab_0 conda-forge; tornado 6.4.1 py39h80987f9_0 ; tqdm 4.66.4 pyhd8ed1ab_0 conda-forge; traitlets 5.14.3 py39hca03da5_0 ; typing-extensions 4.12.2 hd8ed1ab_0 conda-forge; typing_extensions 4.12.2 pyha770c72_0 conda-forge; tzdata 2024a h04d1e81_0 ; umap-learn 0.5.6 pypi_0 pypi; unicodedata2 15.1.0 py39h0f82c59_0 conda-forge; urllib3 2.2.2 py39hca03da5_0 ; wcwidth 0.2.5 pyhd3eb1b0_0 ; webencodings 0.5.1 py39hca03da5_1 ; websocket-client 1.8.0 py39hca03da5_0 ; wheel 0.43.0 py39hca03da5_0 ; widgetsnbextension 4.0.10 py39hca03da5_0 ; xlrd 1.2.0 pyh9f0ad1d_1 conda-forge; xorg-libxau 1.0.11 hb547adb_0 conda-forge; xorg-libxdmcp 1.1.3 h27ca646_0 conda-forge; xz 5.4.6 h80987f9_1 ; yaml 0.2.5 h3422bc3_2 conda-forge; zeromq 4.3.5 h313beb8_0 ; zipp 3.19.2 pyhd8ed1ab_0 conda-forge; zlib 1.2.13 hfb2fe0b_6 conda-forge; zstd 1.5.6 hb46c0d2_0 conda-forge; ```; Im so sorry somethine else is wrong so scanpy.logging.print_versions() doesn't work at the moment. I'll fix it and update the post; </details>,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3144:16406,update,update,16406,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144,1,['update'],['update']
Deployability,": \n 30' is None. scanpy/tests/conftest.py:35: AssertionError; ----------------------------------------------------------------------------------------------------- Captured stderr call ------------------------------------------------------------------------------------------------------; running PAGA; finished: added; 'paga/connectivities', connectivities adjacency (adata.uns); 'paga/connectivities_tree', connectivities subtree (adata.uns) (0:00:00); --> added 'pos', the PAGA positions (adata.uns['paga']); --> added 'pos', the PAGA positions (adata.uns['paga']); --> added 'pos', the PAGA positions (adata.uns['paga']); --> added 'pos', the PAGA positions (adata.uns['paga']); --> added 'pos', the PAGA positions (adata.uns['paga']); --> added 'pos', the PAGA positions (adata.uns['paga']); --> added 'pos', the PAGA positions (adata.uns['paga']); --> added 'pos', the PAGA positions (adata.uns['paga']); ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>. ```pytb; -----; anndata 0.7.4; scanpy 1.6.1.dev25+g74ac4d37; sinfo 0.3.1; -----; PIL 7.2.0; anndata 0.7.4; asciitree NA; cycler 0.10.0; cython_runtime NA; dask 2.26.0; dateutil 2.8.1; fasteners NA; get_version 2.1; h5py 2.10.0; igraph 0.8.2; importlib_metadata 1.7.0; joblib 0.16.0; kiwisolver 1.2.0; legacy_api_wrap 1.2; leidenalg 0.8.1; llvmlite 0.34.0; louvain 0.7.0; matplotlib 3.3.2; monotonic NA; mpl_toolkits NA; natsort 7.0.1; numba 0.51.2; numcodecs 0.7.2; numexpr 2.7.1; numpy 1.19.2; packaging 20.4; pandas 1.1.2; pkg_resources NA; pyparsing 2.4.7; pytz 2020.1; scanpy 1.6.1.dev25+g74ac4d37; scipy 1.5.2; sinfo 0.3.1; six 1.15.0; sklearn 0.23.2; tables 3.6.1; texttable 1.6.3; tlz 0.10.0; toolz 0.10.0; yaml 5.3.1; zappy NA; zarr 2.4.0; zipp NA; -----; Python 3.7.9 (default, Aug 31 2020, 07:22:35) [Clang 10.0.0 ]; Darwin-19.6.0-x86_64-i386-64bit; 12 logical CPU cores, i386; -----; Session information updated at 2020-09-16 13:37. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1418:5894,update,updated,5894,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1418,1,['update'],['updated']
Deployability,:test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-100n-inftheta-30clip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200n-100theta-30clip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-float32-200n-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[toarray-int64-200n-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[toarray-float32-100n-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[toarray-int64-200n-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[toarray-float32-100n-100theta-noclip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/preprocessing/_simple.py::scanpy.preprocessing._simple.filter_cells; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200n-100theta-30clip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[toarray-float32-200n-subset] - NotImplementedError: Failed in nopython mode pipeli,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:26020,pipeline,pipeline,26020,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['pipeline'],['pipeline']
Deployability,"; 0 FCGR3A 47.682064 5.891937 3.275554e-141 3.579712e-139; 1 FTL 45.653259 2.497682 9.003150e-208 6.887410e-205; ```. it also works for multiple groups:. ```python; print(sc.get.rank_genes_groups_df(adata, None, n_top_genes=2)); ```; ```; group names scores logfoldchanges pvals pvals_adj; 0 0 CD3D 26.250046 3.859759 4.379061e-75 2.233321e-73; 1 0 LDHB 21.207499 2.134979 1.488480e-67 5.993089e-66; 2 1 FCGR3A 47.682064 5.891937 3.275554e-141 3.579712e-139; 3 1 FTL 45.653259 2.497682 9.003150e-208 6.887410e-205; 4 2 LYZ 38.981312 5.096991 1.697105e-172 1.298285e-169; 5 2 CST3 34.241749 4.388617 1.448193e-149 5.539337e-147; 6 3 NKG7 34.214161 6.089183 2.356710e-55 2.575547e-53; 7 3 CTSW 24.584066 5.091688 2.026294e-39 9.118324e-38; 8 4 CD79A 52.583344 6.626956 4.032974e-84 7.713062e-82; 9 4 CD79B 32.102913 4.990217 1.958507e-51 1.872822e-49; 10 5 FTL 26.084383 1.844273 1.236398e-74 2.364611e-72; 11 5 LST1 25.554073 3.170759 5.653851e-81 4.325196e-78; 12 6 LYZ 31.497107 4.328516 9.041131e-106 6.916466e-103; 13 6 CST3 23.850258 3.281016 2.491629e-83 9.530482e-81; 14 7 CST3 33.024582 4.195395 5.768439e-136 4.412856e-133; 15 7 LYZ 31.264187 4.267053 9.712334e-101 1.485987e-98; 16 8 PPIB 39.260998 3.990153 7.159966e-47 3.651583e-45; 17 8 MZB1 33.305500 8.979518 7.611322e-26 1.878278e-24; 18 9 STMN1 27.133045 5.936039 4.998127e-18 8.312102e-17; 19 9 HMGB2 15.229477 5.016804 3.184879e-12 4.060720e-11; 20 10 HNRNPA1 18.405415 2.040915 1.570832e-12 1.560632e-11; 21 10 NPM1 14.230449 2.183721 3.424469e-10 3.046185e-09; ```. This also extends to enrichment queries (this is what I wanted originally):. ```python; sc.queries.enrich(adata, ""1"", n_top_genes=10); ```. For enrichment queries, I added to the doc string that a pval threshold of 0.05 is used. Previously, this was not obvious to me (and for cluster marker genes, this might not always be sensible). I didn't add anything to `docs/release-notes/`, yet. I first wanted to get your opinion. Is it useful, what is still needed here?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2145:2579,release,release-notes,2579,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2145,1,['release'],['release-notes']
Deployability,"; 310 show = settings.autoshow if show is None else show; 311 if save:; --> 312 savefig(writekey, dpi=dpi, ext=ext); 313 if show:; 314 pl.show(). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_utils.py in savefig(writekey, dpi, ext); 280 else:; 281 dpi = rcParams['savefig.dpi']; --> 282 settings.figdir.mkdir(parents=True, exist_ok=True); 283 if ext is None:; 284 ext = settings.file_format_figs. AttributeError: 'str' object has no attribute 'mkdir'; ```. #### Versions. scanpy==1.8.1 anndata==0.7.6 umap==0.5.1 numpy==1.18.5 scipy==1.6.2 pandas==1.1.5 scikit-learn==0.24.2 statsmodels==0.12.2 python-igraph==0.9.4 louvain==0.7.0 pynndescent==0.5.2. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. WARNING: If you miss a compact list, please try `print_header`!; The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info.; -----; anndata 0.7.6; scanpy 1.8.1; sinfo 0.3.4; -----; PIL 8.3.1; anyio NA; appdirs 1.4.4; appnope 0.1.2; attr 21.2.0; babel 2.9.1; backcall 0.2.0; bioservices 1.7.12; bottleneck 1.3.2; brotli NA; bs4 4.9.3; certifi 2021.05.30; cffi 1.14.6; chardet 4.0.0; cloudpickle 1.6.0; colorama 0.4.4; colorlog NA; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2021.07.2; dateutil 2.8.2; decorator 5.0.9; defusedxml 0.7.1; docutils 0.17.1; easydev 0.11.1; fsspec 2021.07.0; gseapy 0.10.5; h5py 2.10.0; html5lib 1.1; idna 2.10; igraph 0.9.4; ipykernel 5.3.4; ipython_genutils 0.2.0; ipywidgets 7.6.3; jedi 0.17.2; jinja2 2.11.3; joblib 1.0.1; json5 NA; jsonschema 3.2.0; jupyter_server 1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1981:3476,install,installs,3476,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1981,1,['install'],['installs']
Deployability,"; 346 patched_exception = self._patch_error(msg, e); --> 347 raise patched_exception; 348 . ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state); 337 if isinstance(pass_inst, CompilerPass):; --> 338 self._runPass(idx, pass_inst, state); 339 else:. ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs); 31 with self:; ---> 32 return func(*args, **kwargs); 33 return _acquire_compile_lock. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in _runPass(self, index, pss, internal_state); 301 with SimpleTimer() as pass_time:; --> 302 mutated |= check(pss.run_pass, internal_state); 303 with SimpleTimer() as finalize_time:. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in check(func, compiler_state); 274 def check(func, compiler_state):; --> 275 mangled = func(compiler_state); 276 if mangled not in (True, False):. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state); 406 # TODO: Pull this out into the pipeline; --> 407 NativeLowering().run_pass(state); 408 lowered = state['cr']. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state); 348 metadata=metadata); --> 349 lower.lower(); 350 if not flags.no_cpython_wrapper:. ~\anaconda3\lib\site-packages\numba\lowering.py in lower(self); 231 # Materialize LLVM Module; --> 232 self.library.add_ir_module(self.module); 233 . ~\anaconda3\lib\site-packages\numba\targets\codegen.py in add_ir_module(self, ir_module); 200 ir = cgutils.normalize_ir_text(str(ir_module)); --> 201 ll_module = ll.parse_assembly(ir); 202 ll_module.name = ir_module.name. ~\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context); 25 mod.close(); ---> 26 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)); 27 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend); LLVM IR parsing error; <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1147:4144,pipeline,pipeline,4144,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147,1,['pipeline'],['pipeline']
Deployability,"; 66 from skmisc.loess import loess; 67 except ImportError:; ---> 68 raise ImportError(; 69 ""Please install skmisc package via `pip install --user scikit-misc""; 70 ); 71 df = pd.DataFrame(index=adata.var_names); 72 data = _get_obs_rep(adata, layer=layer). ImportError: Please install skmisc package via `pip install --user scikit-misc; ```. error when attempting install w/ conda; ```python. (scanpy_env) user@Mac ~ % conda install conda-forge::scikit-misc; Channels:; - defaults; - conda-forge; Platform: osx-arm64; Collecting package metadata (repodata.json): done; Solving environment: failed. PackagesNotFoundError: The following packages are not available from current channels:. - conda-forge::scikit-misc. Current channels:. - defaults; - https://conda.anaconda.org/conda-forge. To search for alternate channels that may provide the conda package you're; looking for, navigate to. https://anaconda.org; ```. Im having trouble reproducing the pip3 install scikit-misc error, which i believe is due to me switching between versions of numpy, heres what I had previously copy pasted. ```python; error: subprocess-exited-with-error; × Preparing metadata (pyproject.toml) did not run successfully.; │ exit code: 1; ╰─> [32 lines of output]; + meson setup /private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e /private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e/.mesonpy-ykxq6c1e -Dbuildtype=release -Db_ndebug=if-release -Db_vscrt=md --native-file=/private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e/.mesonpy-ykxq6c1e/meson-python-native-file.ini; Preparing metadata (pyproject.toml) did not run successfully.; ```. ### Error output. _No response_. ### Versions. <details>. ```; # Name Version Build Channel; absl-py 2.1.0 pyhd8ed1ab_0 conda-forge; anndata 0.10.8 pypi_0 pypi; anyio 4.2.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3144:5022,install,install,5022,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144,1,['install'],['install']
Deployability,"; Failed building wheel for scanpy; Running setup.py clean for scanpy; Running setup.py bdist_wheel for anndata ... done; Stored in directory: /root/.cache/pip/wheels/f1/f0/02/ea67db3107825884bae91e3806e425718f10062c631e2b1367; Running setup.py bdist_wheel for networkx ... done; Stored in directory: /root/.cache/pip/wheels/68/f8/29/b53346a112a07d30a5a84d53f19aeadaa1a474897c0423af91; Successfully built anndata networkx; Failed to build scanpy; Installing collected packages: six, python-dateutil, pytz, numpy, pandas, scipy, h5py, natsort, anndata, pyparsing, cycler, kiwisolver, matplotlib, seaborn, numexpr, tables, scikit-learn, patsy, statsmodels, decorator, networkx, joblib, llvmlite, numba, scanpy; Running setup.py install for scanpy ... error; Complete output from command /usr/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-33o4crd7/scanpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))"" install --record /tmp/pip-65l8zi0l-record/install-record.txt --single-version-externally-managed --compile:; /usr/lib/python3.5/distutils/dist.py:261: UserWarning: Unknown distribution option: 'python_requires'; warnings.warn(msg); running install; running build; running build_py; creating build; creating build/lib; creating build/lib/scanpy; copying scanpy/settings.py -> build/lib/scanpy; copying scanpy/readwrite.py -> build/lib/scanpy; copying scanpy/_version.py -> build/lib/scanpy; copying scanpy/__init__.py -> build/lib/scanpy; copying scanpy/utils.py -> build/lib/scanpy; copying scanpy/logging.py -> build/lib/scanpy; copying scanpy/exporting.py -> build/lib/scanpy; creating build/lib/scanpy/preprocessing; copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing; copying scanpy/preprocessing/highly_variable_genes.py -> build/lib/scanpy/preprocessing; copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing; copying scanpy/preprocessing/magic.py -> build/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/355:3632,install,install,3632,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355,2,['install'],"['install', 'install-record']"
Deployability,"; Package matplotlib conflicts for:; scanpy -> matplotlib[version='3.0.*|>=2.2']; Package scikit-learn conflicts for:; scanpy -> scikit-learn[version='>=0.21.2']; Package natsort conflicts for:; scanpy -> natsort; Package openssl conflicts for:; python=3.7 -> openssl[version='>=1.0.2o,<1.0.3a|>=1.0.2p,<1.0.3a|>=1.1.1a,<1.1.2a|>=1.1.1b,<1.1.2a|>=1.1.1c,<1.1.2a|>=1.1.1d,<1.1.2a']; Package importlib_metadata conflicts for:; scanpy -> importlib_metadata[version='>=0.7']; ```. I can import `scanpy` by opening Python 3 interpreter from the terminal by running `python`. ```; Python 3.7.5 (default, Oct 25 2019, 15:51:11); [GCC 7.3.0] :: Anaconda, Inc. on linux; Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.; >>> import scanpy as sc # this works; ```. Check the `PATH`:. ```; ['', '/home/tsundoku/anaconda3/lib/python37.zip', '/home/tsundoku/anaconda3/lib/python3.7', '/home/tsundoku/anaconda3/lib/python3.7/lib-dynload', '/home/tsundoku/.local/lib/python3.7/site-packages', '/home/tsundoku/anaconda3/lib/python3.7/site-packages']; ```. But it fails to load from `reticulate`. ```; library(reticulate); repl_python(); ```. ```; import pandas as pd; import scanpy as sc; ```. ```; ModuleNotFoundError: No module named 'scanpy'; ```. Check the `PATH`:. ```; import sys; sys.path; ```. ```; ['', '/home/tsundoku/.local/share/r-miniconda/envs/r-reticulate/bin', '/home/tsundoku/.local/share/r-miniconda/envs/r-reticulate/lib/python36.zip', '/home/tsundoku/.local/share/r-miniconda/envs/r-reticulate/lib/python3.6', '/home/tsundoku/.local/share/r-miniconda/envs/r-reticulate/lib/python3.6/lib-dynload', '/home/tsundoku/.local/share/r-miniconda/envs/r-reticulate/lib/python3.6/site-packages', '/home/tsundoku/R/x86_64-pc-linux-gnu-library/3.6/reticulate/python']; ```. Okay so `scanpy` is installed but the `PATH` are different. Not sure why `py_install()` doesn't work. I guess the alternative is including the those paths for reticulate but not sure at the moment how to do that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/990#issuecomment-575281452:15253,install,installed,15253,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/990#issuecomment-575281452,1,['install'],['installed']
Deployability,"; adjustText 1.0.4; asttokens NA; atomicwrites 1.4.1; bottleneck 1.3.5; brotli NA; bs4 4.12.2; certifi 2024.02.02; cffi 1.15.1; chardet 4.0.0; charset_normalizer 2.0.4; cloudpickle 2.2.1; colorama 0.4.6; comm 0.2.1; cycler 0.10.0; cython_runtime NA; cytoolz 0.12.0; dask 2023.6.0; dateutil 2.8.2; debugpy 1.8.1; decorator 5.1.1; defusedxml 0.7.1; dill 0.3.8; executing 2.0.1; gseapy 1.1.2; h5py 3.9.0; html5lib 1.1; idna 3.4; igraph 0.11.3; ipykernel 6.29.2; jedi 0.19.1; jinja2 3.1.2; joblib 1.3.2; kiwisolver 1.4.4; leidenalg 0.10.2; llvmlite 0.42.0; lxml 5.1.0; lz4 4.3.2; markupsafe 2.1.1; matplotlib 3.7.2; matplotlib_inline 0.1.6; mkl 2.4.1; mpl_toolkits NA; natsort 8.4.0; numba 0.59.0; numexpr 2.8.4; numpy 1.24.3; packaging 23.1; pandas 2.0.3; parso 0.8.3; patsy 0.5.3; pickleshare 0.7.5; platformdirs 3.10.0; prompt_toolkit 3.0.42; psutil 5.9.0; pure_eval 0.2.2; pyarrow 11.0.0; pycparser 2.21; pydeseq2 0.4.7; pydev_ipython NA; pydevconsole NA; pydevd 2.9.5; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.17.2; pynndescent 0.5.11; pyparsing 3.0.9; pythoncom NA; pytz 2023.3.post1; pywintypes NA; requests 2.31.0; ruamel NA; scipy 1.12.0; seaborn 0.13.2; session_info 1.0.0; sip NA; six 1.16.0; sklearn 1.4.1.post1; socks 1.7.1; soupsieve 2.4; sparse 0.15.1; sphinxcontrib NA; spyder 5.5.1; spyder_kernels 2.5.0; spydercustomize NA; stack_data 0.6.2; statsmodels 0.14.0; tblib 1.7.0; texttable 1.7.0; threadpoolctl 3.3.0; tlz 0.12.0; toolz 0.12.0; torch 2.2.0+cpu; torchgen NA; tornado 6.3.2; tqdm 4.66.2; traitlets 5.7.1; typing_extensions NA; umap 0.5.5; urllib3 1.26.18; wcwidth 0.2.13; webencodings 0.5.1; win32api NA; win32com NA; yaml 6.0; zipp NA; zmq 25.1.2; zope NA; zstandard 0.19.0; -----; IPython 8.21.0; jupyter_client 8.6.0; jupyter_core 5.3.0; -----; Python 3.11.8 | packaged by conda-forge | (main, Feb 16 2024, 20:40:50) [MSC v.1937 64 bit (AMD64)]; Windows-10-10.0.22631-SP0; -----; Session information updated at 2024-03-25 14:49; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2956:4816,update,updated,4816,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2956,1,['update'],['updated']
Deployability,"; certifi 2021.10.08; cffi 1.14.6; chardet 4.0.0; charset_normalizer 2.0.4; cloudpickle 2.0.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2021.10.0; dateutil 2.8.2; debugpy 1.4.1; decorator 5.1.0; defusedxml 0.7.1; entrypoints 0.3; fastjsonschema NA; fsspec 2021.08.1; h5py 3.3.0; idna 3.2; igraph 0.10.2; ipykernel 6.4.1; ipython_genutils 0.2.0; ipywidgets 7.6.5; jedi 0.18.0; jinja2 3.1.2; joblib 1.1.0; json5 NA; jsonschema 3.2.0; jupyter_server 1.23.3; jupyterlab_server 2.8.2; kiwisolver 1.3.1; leidenalg 0.9.0; llvmlite 0.37.0; markupsafe 2.1.1; matplotlib 3.4.3; matplotlib_inline NA; mkl 2.4.0; mpl_toolkits NA; natsort 8.2.0; nbclassic 0.4.8; nbformat 5.7.0; nbinom_ufunc NA; notebook_shim NA; numba 0.54.1; numexpr 2.7.3; numpy 1.20.3; packaging 21.0; pandas 1.3.4; parso 0.8.2; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; plotly 5.11.0; prometheus_client NA; prompt_toolkit 3.0.20; psutil 5.8.0; ptyprocess 0.7.0; pvectorc NA; pycparser 2.20; pydev_ipython NA; pydevconsole NA; pydevd 2.4.1; pydevd_concurrency_analyser NA; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pyexpat NA; pygments 2.10.0; pynndescent 0.5.8; pyparsing 3.0.4; pyrsistent NA; pytz 2021.3; pywt 1.1.1; requests 2.26.0; scipy 1.7.1; scrublet NA; seaborn 0.11.2; send2trash NA; session_info 1.0.0; settings NA; simplejson 3.17.6; six 1.16.0; skimage 0.18.3; sklearn 0.24.2; sniffio 1.2.0; socks 1.7.1; sphinxcontrib NA; statsmodels 0.12.2; storemagic NA; tblib 1.7.0; terminado 0.9.4; texttable 1.6.4; tlz 0.11.0; toolz 0.11.1; tornado 6.1; tqdm 4.62.3; traitlets 5.1.0; typing_extensions NA; umap 0.5.3; urllib3 1.26.7; wcwidth 0.2.5; websocket 1.4.2; yaml 6.0; zmq 22.2.1; zope NA; -----; IPython 7.29.0; jupyter_client 6.1.12; jupyter_core 4.8.1; jupyterlab 3.2.1; notebook 6.4.5; -----; Python 3.9.7 (default, Sep 16 2021, 13:09:58) [GCC 7.5.0]; Linux-4.18.0-305.45.1.el8_4.x86_64-x86_64-with-glibc2.28; -----; Session information updated at 2022-12-04. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2377:6718,update,updated,6718,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2377,1,['update'],['updated']
Deployability,"; chardet 4.0.0; charset_normalizer 2.0.4; cloudpickle 2.2.1; colorama 0.4.6; comm 0.1.2; cycler 0.10.0; cython_runtime NA; cytoolz 0.12.0; dask 2023.6.0; dateutil 2.8.2; debugpy 1.6.7; decorator 5.1.1; defusedxml 0.7.1; dill 0.3.6; entrypoints 0.4; executing 0.8.3; fastjsonschema NA; gmpy2 2.1.2; h5py 3.9.0; idna 3.4; igraph 0.10.8; ipykernel 6.25.0; ipython_genutils 0.2.0; jedi 0.18.1; jinja2 3.1.2; joblib 1.2.0; json5 NA; jsonpointer 2.1; jsonschema 4.17.3; jupyter_server 1.23.4; jupyterlab_server 2.22.0; kiwisolver 1.4.4; leidenalg 0.10.1; llvmlite 0.40.0; louvain 0.8.1; lz4 4.3.2; markupsafe 2.1.1; matplotlib 3.7.2; mpl_toolkits NA; mpmath 1.3.0; natsort 8.4.0; nbformat 5.9.2; numba 0.57.1; numexpr 2.8.4; numpy 1.24.3; numpydoc 1.5.0; objc 10.0; packaging 23.1; pandas 2.0.3; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; platformdirs 3.10.0; plotly 5.9.0; prometheus_client NA; prompt_toolkit 3.0.36; psutil 5.9.0; ptyprocess 0.7.0; pure_eval 0.2.2; pvectorc NA; pyarrow 11.0.0; pydev_ipython NA; pydevconsole NA; pydevd 2.9.5; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.15.1; pyparsing 3.0.9; pyrsistent NA; pytz 2023.3.post1; requests 2.31.0; rfc3339_validator 0.1.4; rfc3986_validator 0.1.1; ruamel NA; scipy 1.11.1; send2trash NA; session_info 1.0.0; setuptools 68.0.0; six 1.16.0; sklearn 1.3.0; sniffio 1.2.0; socks 1.7.1; sphinxcontrib NA; stack_data 0.2.0; sympy 1.11.1; tblib 1.7.0; terminado 0.17.1; texttable 1.7.0; threadpoolctl 2.2.0; tlz 0.12.0; toolz 0.12.0; torch 2.1.0; torchgen NA; tornado 6.3.2; tqdm 4.65.0; traitlets 5.7.1; typing_extensions NA; urllib3 1.26.16; wcwidth 0.2.5; websocket 0.58.0; xxhash 2.0.2; yaml 6.0; zipp NA; zmq 23.2.0; zope NA; -----; IPython 8.15.0; jupyter_client 7.4.9; jupyter_core 5.3.0; jupyterlab 3.6.3; notebook 6.5.4; -----; Python 3.11.5 (main, Sep 11 2023, 08:31:25) [Clang 14.0.6 ]; macOS-12.5-arm64-arm-64bit; -----; Session information updated at 2023-11-12 16:47; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2748:4078,update,updated,4078,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2748,1,['update'],['updated']
Deployability,"; pvectorc NA; pygments 2.9.0; pyparsing 2.4.7; pyrsistent NA; pytz 2021.1; requests 2.25.1; scanpy 1.7.2; scipy 1.5.3; seaborn 0.11.1; send2trash NA; setuptools_scm NA; sinfo 0.3.1; six 1.16.0; sklearn 0.24.2; sniffio 1.2.0; socks 1.7.1; sphinxcontrib NA; statsmodels 0.12.2; storemagic NA; tables 3.6.1; tblib 1.7.0; terminado 0.10.0; texttable 1.6.3; tlz 0.11.0; toolz 0.11.1; tornado 6.1; traitlets 5.0.5; typing_extensions NA; urllib3 1.26.4; wcwidth 0.2.5; websocket 0.57.0; yaml 5.4.1; zmq 22.0.3; zope NA; -----; IPython 7.23.1; jupyter_client 6.1.12; jupyter_core 4.7.1; jupyterlab 3.0.16; notebook 6.4.0; -----; Python 3.8.10 (default, May 19 2021, 18:05:58) [GCC 7.3.0]; Linux-4.4.0-19041-Microsoft-x86_64-with-glibc2.10; 4 logical CPU cores, x86_64; -----; Session information updated at 2021-05-25 15:50. </Details>. I'm still trying to update h5py in the old environment, which has quite some inconsistencies in it, considerably slowing everything down. At some point it looked like I had success with installing h5py 3.2.1 from conda-forge after running `conda update anaconda` and `conda update --all` (as per [here](https://stackoverflow.com/questions/56072846/how-to-resolve-inconsistent-package-warnings-in-conda)). But now this environment leads to an ImportError when importing scanpy: `ImportError: /home/karl/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/h5py/defs.cpython-38-x86_64-linux-gnu.so: undefined symbol: H5Pset_fapl_ros3`; Can it be that pip version of scanpy doesn't see the updated conda version of h5py?. <Details>; <summary>Inconsistencies in the old environment</summary>. ```; The following packages are causing the inconsistency:. - defaults/linux-64::_anaconda_depends==2020.07=py38_0; - defaults/linux-64::anaconda==custom=py38_1; - defaults/linux-64::cairo==1.14.12=h8948797_3; - defaults/linux-64::graphviz==2.40.1=h21bd128_2; - defaults/linux-64::harfbuzz==1.8.8=hffaf4a1_0; - conda-forge/linux-64::leidenalg==0.8.2=py38habedc41_0; - defaults/linux",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1850#issuecomment-847928310:2198,install,installing,2198,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1850#issuecomment-847928310,1,['install'],['installing']
Deployability,"; sc.pl.umap(adata2, color = 'sample'); ```; ![image](https://user-images.githubusercontent.com/26215587/118843486-04492200-b8c2-11eb-8e2b-6aaf59564721.png). #### Versions. <details>. -----; anndata 0.7.5; scanpy 1.7.1; sinfo 0.3.1; -----; Bio 1.78; PIL 8.2.0; adjustText NA; anndata 0.7.5; annoy NA; backcall 0.2.0; brotli NA; cachecontrol 0.12.6; cairo 1.19.1; certifi 2020.06.20; cffi 1.14.5; changeo 1.0.2; chardet 4.0.0; cloudpickle 1.6.0; cycler 0.10.0; cython_runtime NA; dandelion 0.1.2; dask 2021.03.0; dateutil 2.8.1; decorator 5.0.6; descartes NA; distance NA; get_version 2.1; google NA; h5py 2.10.0; harmonypy NA; hdmedians NA; idna 2.10; igraph 0.8.3; ipykernel 5.3.4; ipython_genutils 0.2.0; ipywidgets 7.6.3; jedi 0.17.0; joblib 1.0.1; kiwisolver 1.3.1; legacy_api_wrap 1.2; leidenalg 0.8.3; llvmlite 0.34.0; matplotlib 3.3.4; mizani 0.7.2; mpl_toolkits NA; msgpack 1.0.2; natsort 7.1.1; networkx 2.5; numba 0.51.2; numexpr 2.7.1; numpy 1.20.2; packaging 20.9; palettable 3.3.0; pandas 1.2.4; parso 0.8.2; patsy 0.5.1; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; plotnine 0.7.1; polyleven NA; presto 0.6.2; prompt_toolkit 3.0.17; ptyprocess 0.7.0; pycparser 2.20; pygments 2.8.1; pynndescent 0.5.2; pyparsing 2.4.7; pytoml NA; pytz 2021.1; pywt 1.1.1; requests 2.25.1; scanpy 1.7.1; scipy 1.6.3; scrublet NA; seaborn 0.11.1; setuptools_scm NA; sinfo 0.3.1; six 1.15.0; skbio 0.5.6; skimage 0.18.1; sklearn 0.23.2; socks 1.7.1; sparse 0.11.2; sphinxcontrib NA; statsmodels 0.12.1; storemagic NA; tables 3.6.1; texttable 1.6.3; tlz 0.11.1; toolz 0.11.1; tornado 6.1; tqdm 4.59.0; traitlets 5.0.5; typing_extensions NA; umap 0.5.1; urllib3 1.26.4; wcwidth 0.2.5; yaml 5.4.1; zmq 20.0.0; -----; IPython 7.22.0; jupyter_client 6.1.12; jupyter_core 4.7.1; notebook 6.3.0; -----; Python 3.8.8 (default, Feb 24 2021, 21:46:12) [GCC 7.3.0]; Linux-4.15.0-142-generic-x86_64-with-glibc2.10; 64 logical CPU cores, x86_64; -----; Session information updated at 2021-05-19 16:44. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1846:3881,update,updated,3881,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1846,1,['update'],['updated']
Deployability,<!-- ; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. closes #1502 . ensure that `legend_loc=None` also removes continuous colorbars for scatterplots like umap,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1821:293,continuous,continuous,293,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1821,1,['continuous'],['continuous']
Deployability,"<!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Closes #2813; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: only dev changes. this tests that `log1p`, `normalize_per_cell`, `filter_cells`, and `filter_genes` return dask arrays when handed dask arrays.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2814:189,release,release,189,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2814,2,"['Release', 'release']","['Release', 'release']"
Deployability,<!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Closes N/A; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2774:187,release,release,187,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2774,2,"['Release', 'release']","['Release', 'release']"
Deployability,"<!-- Please give a clear and concise description of what the bug is: -->; Hi, I was trying to apply the SAM integration on a merged dataset of three example dataset from 10x homepage, in an attempt to compare the result to the PAGA and bbknn integrated umap.; I got a successful run on one of the PBMC dataset with no reprocessing. However in any other case I kept bump into an error:. TypeError: some keyword arguments unexpected. Here is the record. On the other hand, if I want to integrate bbknn with SAM, do I just apply bbknn after the run of SAM like this?. ////; import scanpy.external as sce. sam_obj = sce.tl.sam(adata); sc.pl.umap(sam_obj, color='Sample') . bbknn.bbknn(adata,batch_key='Sample'); #does this change the umap? or do I need to make another call of tl.umap?. sc.pl.umap(sam_obj, color='Sample') ; ////; i. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; ...; ```. import scanpy.external as sce; for adata in adatalist:; sam_obj = sce.tl.sam(adata); sce.pl.sam(adata,projection='X_umap'). <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ... Self-assembling manifold; Running SAM; RUNNING SAM; Iteration: 0, Convergence: 0.016564277393631113; Iteration: 1, Convergence: 0.01278454723440345; Computing the UMAP embedding...; Elapsed time: 50.534051179885864 seconds; Self-assembling manifold; Running SAM; RUNNING SAM; Iteration: 0, Convergence: 0.022868878389371346. ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-17-4514ae92b370> in <module>; 1 import scanpy.external as sce; 2 for adata in adatalist:; ----> 3 sam_obj = sce.tl.sam(adata); 4 sce.pl.sam(adata,projection='X_umap'). ~/.local/lib/python3.7/site-packages/scanpy/external/tl/_sam.py in sam(adata, max_iter, num_norm_avg, k, distance, standardization, weight_pcs, sparse_pca, n_pcs, n_genes, projection, inplace, verbo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1157:108,integrat,integration,108,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1157,3,['integrat'],"['integrate', 'integrated', 'integration']"
Deployability,"<!-- Please give a clear and concise description of what the bug is: -->; I am trying to integrate data using ingest. I followed exactly the same steps and scripts as described in the scanpy tutorial. However, I got the error message that ‘UMAP’ object has no attribute ‘_input_distance_func’ every time when I ran the command of sc.tl.ingest(adata, adata_ref, obs=‘louvain’). I have the same problem even with using the example pbmc3k_processed and pbmc3k_processed as in the tutorial. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```; adata_ref = sc.datasets.pbmc3k_processed(); adata = sc.datasets.pbmc68k_reduced(); var_names = adata_ref.var_names.intersection(adata.var_names); adata_ref = adata_ref[:, var_names]; adata = adata[:, var_names]; sc.pp.pca(adata_ref); sc.pp.neighbors(adata_ref); sc.tl.umap(adata_ref). # problem occurs here; sc.tl.ingest(adata, adata_ref, obs='louvain'); ...; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```; AttributeError Traceback (most recent call last); <ipython-input-12-27e22cc8f823> in <module>(); ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain'). 3 frames; /usr/local/lib/python3.6/dist-packages/umap/umap_.py in transform(self, X); 2006 try:; 2007 # sklearn pairwise_distances fails for callable metric on sparse data; -> 2008 _m = self.metric if self._sparse_data else self._input_distance_func; 2009 dmat = pairwise_distances(; 2010 X, self._raw_data, metric=_m, **self._metric_kwds. AttributeError: 'UMAP' object has no attribute '_input_distance_func'; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.2 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.10.2 python-igraph==0.8.0 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1181:89,integrat,integrate,89,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1181,1,['integrat'],['integrate']
Deployability,"<!-- Please give a clear and concise description of what the bug is: -->; I have `pytorch` and `scanpy` installed inside a conda environment. When I want to import scanpy **after** torch, the import won't finish. The interesting part is that importing scanpy before torch is possible! For example, this code takes a long time and probably does not finish:. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; import torch; import scanpy; ```. But the following example works:. ```python; import scanpy; import torch; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.5.1 anndata==0.7.3 umap==0.4.4 numpy==1.18.5 scipy==1.4.1 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 pytorch==1.1.0 torchvision==0.3.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1286:104,install,installed,104,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1286,1,['install'],['installed']
Deployability,"<!-- Please give a clear and concise description of what the bug is: -->; I have upgraded to scanpy 1.4.6 in a conda environment. Since then I cannot load the package into python, as it gives me the following error: `AttributeError: module 'cairo' has no attribute 'version_info'`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; import scanpy; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/__init__.py"", line 38, in <module>; from . import plotting as pl; File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>; from ._anndata import scatter, violin, ranking, clustermap, stacked_violin, heatmap, dotplot, matrixplot, tracksplot, dendrogram, correlation_matrix; File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 16, in <module>; from matplotlib import pyplot as pl; File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 2349, in <module>; switch_backend(rcParams[""backend""]); File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/__init__.py"", line 833, in __getitem__; plt.switch_backend(rcsetup._auto_backend_sentinel); File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 204, in switch_backend; switch_backend(candidate); File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 221, in switch_backend; backend_mod = importlib.import_module(backend_name); File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/importlib/__init__.py"", line 127, in import_module; return _bootstrap._gcd_import(name[level:], package, leve",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1166:81,upgrade,upgraded,81,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1166,1,['upgrade'],['upgraded']
Deployability,"<!-- Please give a clear and concise description of what the bug is: -->; I installed the package by `pip install scanpy`. When I imported it, there was such an error. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; import scanpy as sc; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/sibcb1/mxqianlab1/common/anaconda/envs/cnmf_env/lib/python3.6/site-packages/scanpy/__init__.py"", line 36, in <module>; from . import tools as tl; File ""/sibcb1/mxqianlab1/common/anaconda/envs/cnmf_env/lib/python3.6/site-packages/scanpy/tools/__init__.py"", line 17, in <module>; from ._sim import sim; File ""/sibcb1/mxqianlab1/common/anaconda/envs/cnmf_env/lib/python3.6/site-packages/scanpy/tools/_sim.py"", line 23, in <module>; from .. import _utils, readwrite, logging as logg; File ""/sibcb1/mxqianlab1/common/anaconda/envs/cnmf_env/lib/python3.6/site-packages/scanpy/readwrite.py"", line 10, in <module>; import tables; File ""/sibcb1/mxqianlab1/common/anaconda/envs/cnmf_env/lib/python3.6/site-packages/tables/__init__.py"", line 93, in <module>; from .utilsextension import (; ImportError: libblosc.so.1: cannot open shared object file: No such file or directory. ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > version 1.5.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1284:76,install,installed,76,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1284,2,['install'],"['install', 'installed']"
Deployability,"<!-- Please give a clear and concise description of what the bug is: -->; I'm using the ""scvelo"" https://scvelo.readthedocs.io/getting_started.html for scRNA data analysis. It underlying called ""scanpy"" function ""umap"" for calculating the coordinates. I tried the release version ""scanpy-1.4.4.post1-py_0"". It can not be imported to Python. Error message: ""ImportError: cannot import name '_Metric' from 'scanpy.neighbors' (/Users/shuzhe/anaconda3/lib/python3.7/site-packages/scanpy/neighbors/__init__.py)"". I finally switch to the developing version for ""scanpy"". When I run ""umap"", it gives me the error message below. I'm wondering what the "".obsp"" is and how it is generated.; ; <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; scv.tl.umap(adata); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-22-391fc8667646> in <module>; ----> 1 scv.tl.umap(adata). ~/scanpy/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key); 125 start = logg.info('computing UMAP'); 126 ; --> 127 neighbors = NeighborsView(adata, neighbors_key); 128 ; 129 if ('params' not in neighbors. ~/scanpy/scanpy/_utils.py in __init__(self, adata, key); 667 self._dists_key = self._neighbors_dict['distances_key']; 668 ; --> 669 if self._conns_key in adata.obsp:; 670 self._connectivities = adata.obsp[self._conns_key]; 671 if self._dists_key in adata.obsp:. AttributeError: 'AnnData' object has no attribute 'obsp'; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.7.dev26+gc255fa10 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.21.2 statsmodels==0.11.0 python-igraph==0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1125:264,release,release,264,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1125,1,['release'],['release']
Deployability,"<!-- Please give a clear and concise description of what the bug is: -->; I've had hard time in figuring this out. This is not a problem of scanpy directly but apparently is related to [scikit-learn 0.21 series](https://github.com/scikit-learn/scikit-learn/issues/14485) which is a dependency of latest scanpy version (1.4.6). Also related to [this comment in pytorch](https://github.com/pytorch/pytorch/issues/2575#issuecomment-523657178). My issue is that I'm using, in addition to scanpy, another library performing a dl_import with static TLS. ; So if I issue; ```python; import scanpy as sc; import graph_tool.all as gt; ```; I get. ```python; ImportError: dlopen: cannot load any more object with static TLS ; ```; error and I'm not able to use the second library. Reversing the order of the imports raises the same error and I'm not able to use `scanpy`. The issue is solved installing scikit-learn 0.20.4 (the last of 0.20 series). What are the exact scikit-learn 0.21.2 dependecies in scanpy?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1121:882,install,installing,882,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1121,1,['install'],['installing']
Deployability,"<!-- Please give a clear and concise description of what the bug is: -->; Loading data using `adata = sc.datasets.visium_sge('V1_Human_Lymph_Node')` with Anndata<0.7rc1 leads to error `'AnnData' object has no attribute 'is_view'`.; The reason is that the function name changed in version 0.7rc1 from `isview` -> `is_view`. I propose two possible solutions:; **Solution A**: Change requirements to `anndata>=0.7rc1`; **Solution B**: Add function to anndata:; ```python; def isview(self):; return self.is_view(); ```; I think solution B is preferable as it provides back-compatibility of anndata. ---; <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; pip install git+https://github.com/theislab/scanpy.git@spatial; import scanpy as sc; adata = sc.datasets.visium_sge('V1_Human_Lymph_Node'); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; Variable names are not unique. To make them unique, call `.var_names_make_unique`.; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-2-59eff31dcd22> in <module>; 1 get_ipython().system('pip install git+https://github.com/theislab/scanpy.git@spatial'); 2 import scanpy as sc; ----> 3 adata = sc.datasets.visium_sge('V1_Human_Lymph_Node'). /opt/conda/lib/python3.7/site-packages/scanpy/datasets/__init__.py in visium_sge(sample_id); 368 ; 369 # read h5 file; --> 370 adata = read_10x_h5(files['counts']); 371 adata.var_names_make_unique(); 372 . /opt/conda/lib/python3.7/site-packages/scanpy/readwrite.py in read_10x_h5(filename, genome, gex_only); 169 if gex_only:; 170 adata = adata[:, list(map(lambda x: x == 'Gene Expression', adata.var['feature_types']))]; --> 171 if adata.is_view:; 172 return adata.copy(); 173 else:. AttributeError: 'AnnData' object has no attribute 'is_view'; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; >",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1027:709,install,install,709,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1027,1,['install'],['install']
Deployability,"<!-- Please give a clear and concise description of what the bug is: -->; Not able to install with conda and no info about the source of error.; <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```bash; (scrna) $ conda install -c bioconda scanpy. Collecting package metadata (current_repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.; Collecting package metadata (repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: | ; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1190:86,install,install,86,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1190,2,['install'],['install']
Deployability,"<!-- Please give a clear and concise description of what the bug is: -->; Running ```sc.pp.regress_out(adata, ['n_counts'])``` or in any other obs, it outputs error on the ""first guess"". I have used the function before with no problems. So I am not sure where the issue is now (I have updated to the latest version of Scanpy 2 days ago...but I dont know if it has anything to do with it). I have followed the steps in this [tutorial](https://github.com/theislab/scanpy-tutorials/blob/master/pbmc3k.ipynb).; I must add that this ```adata``` object is a subset of all cells created by keeping only the cells that express the gene Crabp1, as follows:; ```adata = adata_full[adata_full.obs['Crabp1_cell'] == 'True']```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```; sc.pp.regress_out(adata, ['n_counts']); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```; sc.pp.regress_out(adata, ['n_counts']); regressing out ['n_counts']; /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/families/family.py:179: RuntimeWarning: invalid value encountered in true_divide; return np.sum(resid_dev * freq_weights * var_weights / scale); Traceback (most recent call last):. File ""<ipython-input-6-4693dee26417>"", line 1, in <module>; sc.pp.regress_out(adata, ['n_counts']). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 841, in regress_out; res = list(map(_regress_out_chunk, tasks)). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 867, in _regress_out_chunk; result = sm.GLM(data_chunk[:, col_index], regres, family=sm.families.Gaussian()).fit(). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/generalized_linear_model.py"", line 1027, in fit; cov_kwds=cov_kwds, use_t=use_t, **kwargs). File ""/home/auesro/anaconda3/envs/Sc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1171:285,update,updated,285,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1171,1,['update'],['updated']
Deployability,"<!-- Please give a clear and concise description of what the bug is: -->; Since I update to scanpy==1.4.5.1 I am getting multiple plotting errors. `sc.pl.rank_genes_groups() and sc.pl.violin()` are still working fine but I am getting errors in the rank_genes functions like `sc.pl.rank_genes_groups_violin(`) and `sc.pl.tracksplot()`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; ##still working fine; sc.tl.rank_genes_groups(adata, 'louvain', method='wilcoxon'); sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False); result = adata.uns['rank_genes_groups']; groups = result['names'].dtype.names. pd.DataFrame(; {group + '_' + key[:1]: result[key][group]; for group in groups for key in ['names', 'pvals']}).head(5); ##gives error; sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ---------------------------------------------------------------------------; Exception Traceback (most recent call last); ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value); 3169 try:; -> 3170 value = Series(value); 3171 except:. ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath); 273 data = _sanitize_array(data, index, dtype, copy,; --> 274 raise_cast_failure=True); 275 . ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in _sanitize_array(data, index, dtype, copy, raise_cast_failure); 4160 if isinstance(data, np.ndarray):; -> 4161 raise Exception('Data must be 1-dimensional'); 4162 else:. Exception: Data must be 1-dimensional. During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last); <ipython-input-23-ccdbf8b7836c> in <module>; ----> 1 sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8) ## 200316 error fix later, also when I run ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1114:82,update,update,82,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1114,1,['update'],['update']
Deployability,"<!-- Please give a clear and concise description of what the bug is: -->; Trying for the first time the tutorial notebook and I stumble onto the error below. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; pip install git+https://github.com/theislab/scanpy.git@spatial; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; Collecting git+https://github.com/theislab/scanpy.git@spatial; Cloning https://github.com/theislab/scanpy.git (to revision spatial) to /tmp/pip-req-build-1aajpyr3; Running command git clone -q https://github.com/theislab/scanpy.git /tmp/pip-req-build-1aajpyr3; WARNING: Did not find branch or tag 'spatial', assuming revision or ref.; Running command git checkout -q spatial; error: pathspec 'spatial' did not match any file(s) known to git.; ERROR: Command errored out with exit status 1: git checkout -q spatial Check the logs for full command output.; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1104:267,install,install,267,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1104,1,['install'],['install']
Deployability,"<!-- Please give a clear and concise description of what the bug is: -->; Yesterday I moved to a new server and I had to install miniconda3, Jupiter and all the necessary modules for my scRNA-seq analysis including scanpy. I can read fine an h5ad file and run various steps with scanpy and I can then save the object as an h5ad file and read it back without a problem. However, if I run the rank_genes_groups function, even though I can perfectly fine save my object as an h5ad file I get an error when I am attempting to read it back. I have to say that this exact piece of code used to work with my older modules before updating it. Also, some people seem to have spotted a similar error in the newest numpy package:; https://github.com/numpy/numpy/issues/13431. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; # I have already read in an Ann data object from an h5ad existing file; sc.tl.pca(adata, n_comps=30, svd_solver='arpack'); sc.pp.neighbors(adata, n_neighbors=15); sc.tl.umap(adata). k = 15; communities, graph, Q = sc.external.tl.phenograph(pd.DataFrame(adata.obsm['X_pca']),k=k); adata.obs['PhenoGraph_clusters'] = pd.Categorical(communities); adata.uns['PhenoGraph_Q'] = Q; adata.uns['PhenoGraph_k'] = k. path_to_h5ad_file = '~/test.h5ad'; adata.write_h5ad(path_to_h5ad_file) # works. # but if I run; sc.tl.rank_genes_groups(adata, n_genes=21515,groupby='PhenoGraph_clusters', method='wilcoxon'); rcParams['figure.figsize'] = 4,4; rcParams['axes.grid'] = True; sc.pl.rank_genes_groups(adata); pd.DataFrame(adata.uns['rank_genes_groups']['names']).head(5). path_to_h5ad_file = '~/test.h5ad' # works; adata.write_h5ad(path_to_h5ad_file) # gives ERROR bellow. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-23-cb0bc3c267ae> in <module>; ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/937:121,install,install,121,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/937,1,['install'],['install']
Deployability,"<!-- Please give a clear and concise description of what the bug is: -->; `wx` appears to be a missing scanpy dependancy linked to matplotlib when installing on macOS. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; >>> import scanpy as sc; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/miniconda3/envs/path/lib/python3.7/site-packages/scanpy/__init__.py"", line 38, in <module>; from . import plotting as pl; File ""/miniconda3/envs/path/lib/python3.7/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>; from ._anndata import scatter, violin, ranking, clustermap, stacked_violin, heatmap, dotplot, matrixplot, tracksplot, dendrogram, correlation_matrix; File ""/miniconda3/envs/path/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 16, in <module>; from matplotlib import pyplot as pl; File ""/miniconda3/envs/path/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 2282, in <module>; switch_backend(rcParams[""backend""]); File ""/miniconda3/envs/path/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 221, in switch_backend; backend_mod = importlib.import_module(backend_name); File ""/miniconda3/envs/path/lib/python3.7/importlib/__init__.py"", line 127, in import_module; return _bootstrap._gcd_import(name[level:], package, level); File ""/miniconda3/envs/path/lib/python3.7/site-packages/matplotlib/backends/backend_wxagg.py"", line 1, in <module>; import wx; ModuleNotFoundError: No module named 'wx'; ```. The solution is simple, install `wxPython` https://pypi.org/project/wxPython/. However, it would be nice if scanpy could handle this OS-specific dependancy. #### Versions:; The latest scanpy version (1.5.1) installed via conda- of course I cannot print the versions since the scanpy import fails, other details;. ```; >>> import sys; print(sys.version); 3.7.6 | p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1302:147,install,installing,147,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1302,1,['install'],['installing']
Deployability,"<!-- What kind of feature would you like to request? -->; - [ ] Additional function parameters / changed functionality / changed defaults?. <!-- Please describe your wishes below: -->; Hi there, I have continuously tried to save my dotplots and umaps from scanpy in PDF or SVG; format with the hope to be able and import it on Illustrator for further processing for publication; purposes. Everything works fine with the images, but the text of the labels is not any more recognized ; as text and thus I cannot change the family font/size or correct the text if need be. Any chance you guys have a plan to allow for this type of functionality shortly?. Best,; Anastasia",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1720:202,continuous,continuously,202,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1720,1,['continuous'],['continuously']
Deployability,<!-- What kind of feature would you like to request? -->; - [ ] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; ...; is there a scanpy method to do a correlation between cell types and continuous variables stored in .obs?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1855:542,continuous,continuous,542,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1855,1,['continuous'],['continuous']
Deployability,"<!-- What kind of feature would you like to request? -->; - [ ] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ x ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; I am using Delaunay triangulation to give a continuous and smooth aspect for plotting values at 2D discrete points. I think it would be useful to have it in scanpy/episcanpy for plotting spatial gene expressions, on top of the scatter plot that is currently used. This can also be used for 3D plotting (3D transcriptomics, such as STARMAP, or even 3D epigenomics in the future). One can have the option of slicing the 3D volume image with a user defined plane position, etc... I can provide my scripts and would be happy to contribute. Thank you very much.; Adem Saglam (DZNE-Bonn, AG Schultze)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1287:515,continuous,continuous,515,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1287,1,['continuous'],['continuous']
Deployability,"<!-- What kind of feature would you like to request? -->; - [ ] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [x] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; I am integrating multiple datasets. In the integrated object I wanted to see for each cluster the percentage of each dataset it consisted of (also see [this question](https://scanpy.discourse.group/t/cluster-statistics/134) in the scanpy discourse group). I wrote code for it on my own, but am not sure which part of `sc.pl` you want it to go to, so here is the code for your consideration:. ```python; import matplotlib.pyplot as plt; import scanpy as sc; import numpy as np. # given integrated object adata, clustered via the leiden algorithm and; # with the batch ID in the 'batch' slot, and a collection of batch_names:. # count the number of occurrences of each batch ID for each cluster ID; count_series = adata.obs.groupby(['leiden', 'batch']).size(); new_df = count_series.to_frame(name = 'size').reset_index(); # convert from multi index to pivot; constitution = new_df.pivot(index='leiden', columns='batch')['size']; # convert to %batch (but could be modified to show different things instead; perc_clust = np.array((constitution.T / np.sum(constitution.T, axis=0))); # keep track of the batch, cluster IDs so we can use them for plotting; clusters = adata.obs.leiden.cat.categories; batches = adata.obs.batch.cat.categories. # actual plotting; basically stacked barplots; # replace styling with scanpy defaults probably?; fig, ax = plt.subplots(); ax.grid(False); ax.bar(clusters, perc_clust[0], 0.6, yerr=0, label=platy_names[0]); bottom = np.zeros(clusters.shape); for i, b in enumerate(batches):; ax.bar(clusters, perc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1573:474,integrat,integrating,474,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1573,2,['integrat'],"['integrated', 'integrating']"
Deployability,"<!-- What kind of feature would you like to request? -->; - [ ] Additional function parameters / changed functionality / changed defaults?; - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; Adding multiplex community detection from Leiden: https://leidenalg.readthedocs.io/en/stable/multiplex.html#layer-multiplex. It seems very straightforward and would be the most simple way to integrate two modalities on the graph. We would make great use of it in Squidpy (rna counts+image), but I think it should live in Scanpy becasue it could be useful for other multi-modal data. This is a duplicate of #1107 and it has been extensively discussed in #1117 . In the latter however, lots of thought went into normalization/processing which is superfluous for this case as it is only specific for CITE-seq data. Here we'd just want to allow users to get partitions out of multiple graphs. This could be done in two ways:; - adding arguments to existing `tl.leiden`, so that it accepts multiple graphs and multiple resolutions params per graph.; - creating a separate function `sc.tl.leiden_multiplex`.; Any thoughts on this @ivirshup @Koncopd ?. I think @WeilerP also had some thoughts along these lines. Have you ever tried this out? is there any other analysis tool you explored with a simlar purpose? Would be interested to hear your thoughts!; worth mentioning that another approach, the WNN from seurat, was also mentioned here: https://github.com/theislab/scanpy/pull/1117#issuecomment-777020580; although am not sure how much work that requries.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1818:660,integrat,integrate,660,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1818,1,['integrat'],['integrate']
Deployability,"<!-- What kind of feature would you like to request? -->; - [ ] Additional function parameters / changed functionality / changed defaults?; - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; We are increasingly using ProjectR as a transfer learning technique from one dataset onto others. It would be great if this were part of the scanpy package, since most of the rest of what we do with single-cell uses scanpy. I'm going to start working on integration of the two but doubt I have the data science experience currently to submit a PR to this project for it. Are there any plans already in the works to pull in transfer-learning techniques such as this?. Relevant links:. - [Article in Bioinformatics](https://academic.oup.com/bioinformatics/advance-article-abstract/doi/10.1093/bioinformatics/btaa183/5804979?redirectedFrom=PDF); - [Article in Cell](https://www.cell.com/cell-systems/pdf/S2405-4712(19)30146-2.pdf); - [GitHub](https://github.com/genesofeve/projectR)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1205:723,integrat,integration,723,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1205,1,['integrat'],['integration']
Deployability,"<!-- What kind of feature would you like to request? -->; - [ x] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [x ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?; ...; It would be nice to have something like https://github.com/powellgenomicslab/Nebulosa to plot sparse genes.; On one hand, ordering with highest value on top (top plot) does not always work as what is below top layer is hidden and decreasing point size to combat this is not always good if different regions of UMAP are differently dense, thus creating white patches. On the other hand, random ordering (middle plot) can be hard to look at for sparse genes.; The gene on the plot is highly correlated with pattern from the bottom plot, but this is not so clear when plotting the gene alone. Sort order=True; <img width=""221"" alt=""image"" src=""https://user-images.githubusercontent.com/47607471/136395395-ec372b26-6552-4136-ae91-875713f700cb.png"">; Random cell ordering; <img width=""217"" alt=""image"" src=""https://user-images.githubusercontent.com/47607471/136395363-9e9fad24-e451-4d47-ac64-ff9b6b7b5774.png"">; Strongly correlated with; <img width=""194"" alt=""image"" src=""https://user-images.githubusercontent.com/47607471/136395551-1d6731aa-0749-425b-be68-f57344df0376.png"">",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2013:789,patch,patches,789,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2013,1,['patch'],['patches']
Deployability,"<!-- What kind of feature would you like to request? -->; - [X] Additional function parameters / changed functionality / changed defaults?; - [X] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [X] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; t-SNE is an interative algorithm, and takes numerous iterations to converge, particularly on larger datasets. For example, if MulticoreTSNE is installed, it accepts `n_iter=30000` as opposed to the default `n_iter=1000`. It would be nice to have this parameter exposed. For larger datasets of say 200K cells, 1000 iterations isn't enough to fully converge to its final compact cluster shapes. . Alternatively, is it possible to pass in a kwargs to scanpy tools that wrap other algorithms, so that the advanced user can flexibly look up [additional MulticoreTSNE parameters](https://github.com/DmitryUlyanov/Multicore-TSNE/blob/62dedde52469f3a0aeb22fdd7bce2538f17f77ef/MulticoreTSNE/__init__.py#L55) to modify, without needing to exhaustively enumerate all parameters in the scanpy wrapper?. Finally, it would be even better to have the faster FFT-based tsne to generalize to millions of cells, the most recent re-implementation being https://github.com/pavlin-policar/openTSNE. In the mean time, one has to overwrite the `.X_tsne` attribute after running these other tools separately.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1150:612,install,installed,612,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1150,1,['install'],['installed']
Deployability,"<!-- What kind of feature would you like to request? -->; - [x] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->. Categorical legends can be removed from embedding plots by passing the argument `'none`' to `legend_loc` (e.g. `sc.pp.umap(adata, color=""CellType"", legend_loc='none')`. It would be useful if the drawn colorbar is omitted when plotting continuous data if `legend_loc='none'` is passed.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2127:704,continuous,continuous,704,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2127,1,['continuous'],['continuous']
Deployability,"<!-- What kind of feature would you like to request? -->; - [x] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->. When we visualize gene expression, range of colorbar can be different. ![image](https://user-images.githubusercontent.com/30337666/89102749-a6d10b00-d43e-11ea-99f7-0867f3c31d13.png). Usually, it's fine. But if we want to compare gene expression in control-treat experiment in single-cell level, sometimes this happens. ![image](https://user-images.githubusercontent.com/30337666/89102998-08927480-d441-11ea-9068-3d7f09ab26a3.png)![image](https://user-images.githubusercontent.com/30337666/89103003-1942ea80-d441-11ea-8a6f-091a6cd2f19b.png). It's hard for us to estimate up or down regulation of this gene in different group of cells because colors with same value in the two figures are not consistent. Plotting the two figures with same colorbar range can solve it. So, I want to know that are there parameters solving it in scanpy.pl.umap or some matplotlib methods that can be integrated with Scanpy?. Thank you very much!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1352:1349,integrat,integrated,1349,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1352,1,['integrat'],['integrated']
Deployability,"<!-- What kind of feature would you like to request? -->; - [x] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; ... Hi!. We're considering implementing some of the t-SNE recommendations in https://www.nature.com/articles/s41467-019-13056-x for our single-cell analysis. They use a different t-SNE implementation (https://github.com/KlugerLab/FIt-SNE), and before I ran off doing my own wrapping and plumbing to integrate with Scanpy I thought I'd check: have you considered integrating this yourselves?. Thanks!. Jon",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/996:768,integrat,integrate,768,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/996,2,['integrat'],"['integrate', 'integrating']"
Deployability,"<!-- What kind of feature would you like to request? -->; - [x] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; As more and more technologies allow multimodal characterization of single cells it could be useful to exploit some functionalities of scanpy's toolkit to perform, at least, some rough integrative analysis. Assuming we have to modalities on different layers (say RNA and ATAC), one could create two knn graphs for both layers and use `leidenalg.find_partition_multiplex` to perform a joint call of partitions handling the two (or more) graphs as a multiplex. I have tested myself this approach, described in [leidenalg documentation](https://leidenalg.readthedocs.io/en/latest/multiplex.html), it works and it is highly configurable. ; We can take care of the implementation of enhancement (as `leiden_multiplex()` function?), I just want to be sure that it is not already on the development roadmap and that it is ok to have it into scanpy and not as an external tool.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1107:653,integrat,integrative,653,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1107,1,['integrat'],['integrative']
Deployability,"<!-- What kind of feature would you like to request? -->; [x ] Additional function parameters / changed functionality / changed defaults?; <!-- Please describe your wishes below: -->; When we have discrete colors for clusters or samples, scatter plots (and therefore umap, tsne plots etc.) using a command like this `sc.pl.scatter(adata, color='sample', groups=['A'])` can help emphasize them by plotting only selected colors and all other cells in gray (see attached). This is very useful. But much like with continuous coloring, the order of colors matters. And particularly here, it would be most useful if all cells with selected colors are ""in front"" of all gray cells. Currently some colored selected cells are often invisible behind gray cells, like in the attached example.; [umap-example.pdf](https://github.com/theislab/scanpy/files/3965139/umap-example.pdf)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/954:510,continuous,continuous,510,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/954,1,['continuous'],['continuous']
Deployability,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. - Depends on #2814. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Closes #2777, closes #2807; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:. TODO:. - [x] batched. <table>; <thead>; <tr>; <th scope=row>. `flavor=`. <th>. `""seurat""`. <th>. `""cell_ranger""`. <tbody>; <tr>; <th scope=row>. `n_top_genes=n`. <td>. - [x] &zwnj;. <td>. - [x] (https://github.com/dask/dask/issues/10853). <tr>; <th scope=row>. `{min,max}_{disp,mean}`. <td>. - [x] &zwnj;. <td>. - [x] &zwnj;. </table>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2809:457,release,release,457,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2809,2,"['Release', 'release']","['Release', 'release']"
Deployability,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Only check the following box if you did not include release notes -->. ## TODO:. - [x] Fix tests; - [x] Figure out PCA test case with anndata 0.8.0; - [x] Add CI job; - [x] Rename CI job to be less similar to minimal dependencies, this will probably be `MinVer`; - [x] Bump anndata requirement back down to 0.7.3 (breaks dask tests); - Maybe 0.8 is low enough?; - [x] Bump pandas requirement back down to 1.5 (breaks grouped plots ordering). ## Some thoughts. * Sibling PR to: https://github.com/scverse/anndata/pull/1314; * Not completley sure what to do about plotting tests yet. Possible we just ignore any comparison failures, but ideally we could still know if these are broken.; * Metric consistency test failure is from https://github.com/scverse/scanpy/issues/2688; * Test updates in https://github.com/scverse/scanpy/pull/2705 (plus bumping one test a little lower) fixes it. <!-- Please check (“- [x]”) and fill in the following boxes -->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816:291,release,release,291,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816,2,"['release', 'update']","['release', 'updates']"
Deployability,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [ X] Closes # (New Feature); - [ X] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [X ] Release notes not necessary because:. I thought I would give a shot at contributing to this awesome tool! I added a function to Scanpy's plotting API that I use in my own research for creating stacked barplots for visualizing compositions of cell groups. An example is depicted below:. ![image](https://github.com/scverse/scanpy/assets/5004419/21885a72-e15f-4f94-b1e5-84c1de8ca954). Specifically, this function enables one to plot the fraction of each cell group (e.g., cluster) that are labelled with a specific categorical variable. For example, if the cell groups are clusters, then one might be interested in examining the fraction of each cluster that originates from each ""batch"" of cells or each patient sample. This function also enables ordering of the groups according to a specific value (e.g., a patient number or batch ID) or by agglomerative clustering. An example of ordering the groups based on agglomerative clustering is shown below:. ![image](https://github.com/scverse/scanpy/assets/5004419/bfde8173-4f0d-483f-b37e-849446b65153). The function supplies an argument to specify whether the dendrogram should or should not be plotted. Please let me know if this feature is of interest and if so, what else needs to be adjusted or fixed prior to merging. Thanks!. Matt",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2873:435,release,release,435,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2873,2,"['Release', 'release']","['Release', 'release']"
Deployability,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [ ] Closes # _no existing issue_; - [ ] Tests included or not required because: _No new tests_; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because: _I did not write release notes_. Hi :). I am proposing a change that speeds up `filter_cells` (x1000 speedup) and `filter_genes` (x2 speedup) for CSR sparse matrices. On my personal machine for 1M cells, `sc.pp.filter_cells(adata, min_genes=xx)` runs in 1ms instead of 10s currently. The speedup should be even stronger on sparser modalities like ATAC. In spirit, this simply replaces `np.sum(X > 0, axis=axis)` with `X.getnnz(axis=axis)`, which is much more efficient. But the axis argument in `getnnz` in `csr_array` may be deprecated. I think it should still be fine with `csr_matrix`, but since I don't know for sure I manually implemented it for the CSR case as in https://github.com/scipy/scipy/issues/19405 . What do you think?. Regarding `getnnz`: Of course it would be nicer to be able to write `.getnnz(axis=axis)`, which extends beyond CSR to other sparse matrices. Can we assume that we're getting sparse matrices and not sparse arrays ?. Pinging @dschult from the Scipy issue liked above, who mentioned: . > I'm pretty sure that a reasonable and commonly occuring use-case would be enough to make the developers include this feature somehow. (edited because I confused `csr_array` and `csr_matrix`)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2772:454,release,release,454,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2772,3,"['Release', 'release']","['Release', 'release']"
Deployability,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [ ] Closes #1263; - [ ] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:. Implements something close to what is described here:. * https://github.com/scverse/scanpy/issues/1263#issuecomment-776508554. Doesn't:. * Use ""current"", instead that's just `None`; * Include random, instead lets the user pass an array to order by, so random can be `rng.permutation(adata.n_obs)`; * Do broadcasting. Can either be added later or we can tell people to do this themselves. ## TODO:. - [ ] Check when input order array has repeated values; - [ ] Test sort_order argument deprecation; - [ ] Add support for `pd.Series` array values.; - [ ] Maybe `list`s?; - [ ] ""How to"" or modify existing advanced plotting tutorial; - [ ] Tests for; - [ ] Categorical ordering; - [ ] None is same as `np.arange(N)`; - [ ] direct overlap + ordering is equivalent to masking; - [ ] Continuous ordering; - [ ] ""ascending"" is like `np.argsort(values)` and vice versa; - [ ] ""ascending"" is like ""descending"" for inverted values; - [ ] Check masking for both; - [ ] Errors; - [ ] For incorrectly sized input array; - [ ] incorrect non-array input; - [ ] ""ascending"" is when the highest value goes on top, right?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2998:423,release,release,423,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2998,3,"['Continuous', 'Release', 'release']","['Continuous', 'Release', 'release']"
Deployability,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [ ] Closes #; - [ ] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2872:419,release,release,419,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2872,22,"['Release', 'release']","['Release', 'release']"
Deployability,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [ ] Closes #; - [ ] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:. Hi,; We are submitting PR for speed up of the clipping part of scaling function. ; | | Time(sec)|; | -----------| ----- |; | Original | 11.82 |; | Updated | 1.59 |; | Speedup | 7.433962264 |. experiment setup : AWS r7i.24xlarge. ```python; import time; import numpy as np. import pandas as pd. import scanpy as sc; from sklearn.cluster import KMeans. import os; import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '); warnings.simplefilter('ignore'); input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):; print('Downloading import file...'); wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes; MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out; markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells; min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed; max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes; min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this; n_top_genes = 4000 # Number of highly variable genes to retain. # PCA; n_components = 50 # Number of principal components to compute. # t-SNE; tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means; k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluste",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3100:419,release,release,419,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3100,3,"['Release', 'Update', 'release']","['Release', 'Updated', 'release']"
Deployability,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [ ] Closes #; - [x] Tests included or not required because: docs; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because:,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3001:424,release,release,424,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3001,2,"['Release', 'release']","['Release', 'release']"
Deployability,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [ ] Closes #; - [x] Tests included or not required because: n_components must be less or equal to the number of samples, otherwise it would throw an error, for example, ValueError: n_components=100 must be less or equal to the batch number of samples 40. This error usually happens on the last chunk of the partial_fit.; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because:. For example, my adata.shape[0] is 1041 and I run IncrementalPCA `sc.tl.pca(adata, n_comps=100, chunked=True,chunk_size=1000)`, and I got an error: ValueError: n_components=100 must be less or equal to the batch number of samples 40 on scanpy/preprocessing/_pca.py:256",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3313:679,release,release,679,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3313,2,"['Release', 'release']","['Release', 'release']"
Deployability,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [ ] Closes #; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2779:419,release,release,419,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2779,4,"['Release', 'release']","['Release', 'release']"
Deployability,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [ ] Closes #; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:. @Intron7 . This adds benchmarks for the off axis for all parameters. The off axis peak memory is lower since we `.pop` that layer. If you think that’s confusing I could change it. Regarding big datasets for `_get_mean_var`, I already added that benchmark. You could maybe check if there’s anything else that should go into the `FastSuite`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3147:419,release,release,419,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3147,2,"['Release', 'release']","['Release', 'release']"
Deployability,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [ ] Closes #; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:. Builds on and supersedes #2482,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2977:419,release,release,419,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2977,2,"['Release', 'release']","['Release', 'release']"
Deployability,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [ ] See https://github.com/scverse/scanpy/pull/3216/checks?check_run_id=29482422648; - [ ] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3217:490,release,release,490,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3217,2,"['Release', 'release']","['Release', 'release']"
Deployability,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [ ] Testing for #2969; - [ ] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2976:428,release,release,428,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2976,2,"['Release', 'release']","['Release', 'release']"
Deployability,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [X] #1549; - [X] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2770:416,release,release,416,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2770,2,"['Release', 'release']","['Release', 'release']"
Deployability,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [X] Closes #1549; - [X] Tests included or not required because:; - Added regression test for subsetting var_names; - Added test for when groupby is None; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2771:512,release,release,512,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2771,2,"['Release', 'release']","['Release', 'release']"
Deployability,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [X] Fixes #1867; - [X] Tests included or not required because: New tests included which catch the failure mode described in #1867. Current implementation fails these.; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because: Added entry in release notes. Addresses issue #1867 with a fix as outlined by @jlause and tests which catch the failure mode detected and nicely demonstrated by @jlause.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2757:526,release,release,526,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2757,3,"['Release', 'release']","['Release', 'release']"
Deployability,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Adresses #2088 and adresses #1733; <!-- Only check the following box if you did not include release notes -->; - [x] Tests included or not required because: They are required and some suggested; - [x] Release notes; - [x] Doc update - depending on feedback here; - [x] Doc update - guidance scanpy vs seurat. **Context**; As discussed in issues #2088 and #1733, `sc.pp.highly_variable_genes(adata, flavor=""seurat_v3"", batch_key=SOME_KEY)` potentially differs in the implementation of how HVGs are ranked from its Seurat counterpart:; - either by sorting by number-of-batches-in-which-genes-are-highly-variable and then breaking ties with median-rank-in-batches (this is described in [Stuart et al. 2019](https://www.cell.com/cell/pdf/S0092-8674(19)30559-8.pdf), and implemented in Seurat's [`SelectIntegrationFeatures`](https://satijalab.org/seurat/reference/selectintegrationfeatures)*).; - OR by sorting first by median-rank-in-batches and breaking ties with number-of-batches-in-which-genes-are-highly-variable (this is how `""seurat_v3""` in scanpy is currently implemented); ; causing quite some discrepancy in the results. *I am not an R expert, so this might not be correct: Digging into the code of `SelectIntegrationFeatures`, I suspect the genes _above_ a treshold level of batches in which they are HVGs are [ordered by their median rank](https://github.com/satijalab/seurat/blob/41d19a8a55350bff444340d6ae7d7e03417d4173/R/integration.R#L2988), in contrary to the textual description in Stuart et al.; and only the genes displaying this threshold of number of batches in which they are highly variable are ranked by their median rank - to decide which are kept as highly variable. This w",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2792:397,release,release,397,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2792,4,"['Release', 'release', 'update']","['Release', 'release', 'update']"
Deployability,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Closes #1053; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because:,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2815:423,release,release,423,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2815,2,"['Release', 'release']","['Release', 'release']"
Deployability,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Closes #1633; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:. This adds relies on `_empty` to check which parameters have been specified, and only changes those",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3206:423,release,release,423,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3206,2,"['Release', 'release']","['Release', 'release']"
Deployability,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Closes #173; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:. Docs:; - https://icb-scanpy--2703.com.readthedocs.build/en/2703/release-notes/index.html#version-1-10; - https://icb-scanpy--2703.com.readthedocs.build/en/2703/api/generated/scanpy.pp.scrublet.html; - https://icb-scanpy--2703.com.readthedocs.build/en/2703/api/generated/scanpy.pp.scrublet_simulate_doublets.html; - https://icb-scanpy--2703.com.readthedocs.build/en/2703/api/generated/scanpy.pl.scrublet_score_distribution.html. ### How to review this PR. I made tests quantitative before this PR, so note that the only change that modified tests is 42143d88a0d499130fac8e5ca60eef0c19163734. In that PR, I make it so there are no longer any duplicate simulated doublets being created. This is necessary to be able to support any neighborhood detection algorithm. I also feel like it makes more sense. This is the only algorithmic change to upstream. Please use your own judgement to check if this makes sense to you. ### TODO:. - [x] remove unused utils (plotting, preprocessing); - [ ] figure out what remaining utils to replace with ours; - [x] PCA/SVD: https://github.com/scverse/scanpy/blob/bf5f1f9343f5729df6f90f7c68363682022e0480/scanpy/preprocessing/_scrublet/__init__.py#L415-L417; - [x] mean_center, normalize_variance, zscore: small enough to be left alone I think; - [ ] get_knn_graph: no need to have multiple implementations here, but our current implementation automatically calculates connectivities, which this doesn’t need https://github.com/scverse/scanpy/pull/2723; - [ ] refactor so the class API ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2703:422,release,release,422,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2703,3,"['Release', 'release']","['Release', 'release', 'release-notes']"
Deployability,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Closes #1861; - [ ] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3183:423,release,release,423,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3183,2,"['Release', 'release']","['Release', 'release']"
Deployability,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Closes #1861; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3184:423,release,release,423,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3184,2,"['Release', 'release']","['Release', 'release']"
Deployability,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Closes #1986; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:. This PR moves conversion from `str` to `list[str]` up and changes the check if `color` is in `obs.columns`/`var_names` to a check that can handle collections instead of just a single `color` value.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3299:423,release,release,423,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3299,2,"['Release', 'release']","['Release', 'release']"
Deployability,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Closes #2012; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:. TODO:. - [ ] Figure out and fix this: https://github.com/scverse/scanpy/blob/4fb3dc7d11f1b067f0aea1008cd3e7fbc3e5d54c/scanpy/metrics/_gearys_c.py#L128-L131 (related to https://github.com/numba/numba/issues/6976?); - [x] Maybe remove these: https://github.com/scverse/scanpy/blob/4fb3dc7d11f1b067f0aea1008cd3e7fbc3e5d54c/scanpy/tools/_umap.py#L167-L171 https://github.com/scverse/scanpy/blob/4fb3dc7d11f1b067f0aea1008cd3e7fbc3e5d54c/scanpy/neighbors/_connectivity.py#L120-L123; - [x] release notes,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2870:423,release,release,423,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2870,3,"['Release', 'release']","['Release', 'release']"
Deployability,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Closes #2236; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3286:423,release,release,423,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3286,2,"['Release', 'release']","['Release', 'release']"
Deployability,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Closes #2427; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2782:423,release,release,423,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2782,2,"['Release', 'release']","['Release', 'release']"
Deployability,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Closes #2644; - [x] Tests included or not required because: dev workflow; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: dev workflow. Very simple, following https://docs.pypi.org/trusted-publishers/adding-a-publisher/. The change removes most of the technical parts of making a release including `twine check` which is just done by default by the GH action. The only parts I’m not 100% sure about removing are; - “When to make a pre-release” – I feel like “if UR unsure, make one of these” wasn’t helping here either, so maybe that should just be fleshed out as a section now we’re down a few sections; - “Check the file contents of the wheel” should probably go into “how to code review a PR that touches the build process”, and we don’t have any other guides on how to do code reviews, so …",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2720:436,release,release,436,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2720,4,"['Release', 'release']","['Release', 'release']"
Deployability,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Closes #2680; - [x] Tests included or not required because: this is a longterm fix - failing of this functionality would be captured by existing tests; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2739:514,release,release,514,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2739,2,"['Release', 'release']","['Release', 'release']"
Deployability,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Closes #2688; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: just modifying tests. Fixes tests for metrics. Some notes on an in progress PR:. * Previously xfail tests didn't actually fail because nothing was asserted; * This behavior changes with version of numba.; * numba .56<= seems more reproducible, but differences are greater when they occur (e.g. calculating on sparse vs dense); * Ideally want per metric, per calculation tolerances; * Both threading options can differer; * ~~I think single threaded + `fastmath=False` is reproducible, but need to confirm~~ – still no",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2705:376,release,release,376,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2705,2,"['Release', 'release']","['Release', 'release']"
Deployability,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Closes #2730; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2734:423,release,release,423,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2734,2,"['Release', 'release']","['Release', 'release']"
Deployability,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Closes #2741, Closes #2276; - [x] Tests included or not required because: Only docstring changes; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because: Added. **Notes**. - [x] How does `sc.pp.combat` return `None`? A: when `inplace=True`: it never returns an `AnnData` object though. Hence removed `AnnData` from the return type list. - `sc.pp.normalize` has both `inplace` and `copy` so did not force to harmonize with others; - `sc.pp.pca` allows adata and array/sparsematrix input, so did not force to harmonize with others; - `sc.pp.filter_cells`, `sc.pp.filter_genes` , `sc.pp.subsample` acts on data in different manner (changing dims), so did not force to harmonize with others; - `sc.pp.log1p` , `sc.pp.sqrt` seem to be understandable enough without bloating this up",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2742:460,release,release,460,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2742,2,"['Release', 'release']","['Release', 'release']"
Deployability,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Closes #2746; - [x] Tests included or not required because: this is a minor fix; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: the related code has not been released by scanpy,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2743:443,release,release,443,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2743,3,"['Release', 'release']","['Release', 'release', 'released']"
Deployability,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Closes #2762; - [x] Tests included; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: dev process change. All changes were automatic, except for:. - removing unused imports or replacing them with `__all__`. Much more uncontroversial than AnnData as scanpy’s public modules were more well defined from the start. There were no ambiguous cases except for `sc.get` re-exporting `""_check_mask""`, `""_get_obs_rep""`, and `""_set_obs_rep""`. But since those aren’t documented, we can decide over their fate at a later date.; - Fixing circular imports like `sc.{pp,tl}.pca`. I only needed to create a `neighbors/_doc.py` file for shared neighbors/tools doc parts, and put the `pca` import in `tools` in `__getattr__` (supported since 3.7); - replacing some `with open(p) as f: x = json.loads(f.read())`s with `x = json.loads(Path(p).read_text())`. All in all surprisingly easy",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2761:398,release,release,398,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2761,2,"['Release', 'release']","['Release', 'release']"
Deployability,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Closes #2788; - [x] Tests included; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2789:398,release,release,398,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2789,2,"['Release', 'release']","['Release', 'release']"
Deployability,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Closes #2804; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2928:423,release,release,423,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2928,2,"['Release', 'release']","['Release', 'release']"
Deployability,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Closes #2808; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3340:423,release,release,423,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3340,2,"['Release', 'release']","['Release', 'release']"
Deployability,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Closes #2836; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: dev change. Changes:; - Removes import-time change to globals:; 	- `matplotlib.testing:setup` should be called before each (plotting) test; 	- `sc.set_figure_params(dpi=40, color_map=""viridis"")` seems to be overwritten. When calling it inline, it messes up the figure params; 	- `sc.pl.set_rcParams_defaults()` is redundant, `setup` from above does that.; - Use workaround from https://github.com/pytest-dev/pytest/issues/11759#issuecomment-1888888146",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2838:423,release,release,423,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2838,2,"['Release', 'release']","['Release', 'release']"
Deployability,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Closes #2839; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:. How to review:. 1. https://github.com/scverse/scanpy/compare/585f58c9e4dd82dd7809a831538c4e230b008818...60804430db089f1887085e537ad946b7f691a8b4; 2. 5710a1de4f091db607d76b790676b56f988638f8; 3. https://github.com/scverse/scanpy/compare/5710a1de4f091db607d76b790676b56f988638f8...2cbe106328bcb9585c13def47ac3e1bf9629e448,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2844:423,release,release,423,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2844,2,"['Release', 'release']","['Release', 'release']"
Deployability,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Closes #2842; - [x] Tests included or not required because: it's docs; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because:,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2849:433,release,release,433,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2849,2,"['Release', 'release']","['Release', 'release']"
Deployability,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Closes #2858 ; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: this is a minor quality of life change, and could be tacked onto any other release as opposed to creating a dedicated release",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2859:424,release,release,424,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2859,4,"['Release', 'release']","['Release', 'release']"
Deployability,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Closes #2866; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: technical fix,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3125:423,release,release,423,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3125,2,"['Release', 'release']","['Release', 'release']"
Deployability,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Closes #2878 ; - [x] Tests included or not required because: dev change; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because: dev change,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2879:435,release,release,435,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2879,2,"['Release', 'release']","['Release', 'release']"
Deployability,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Closes #2902; - [ ] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2905:423,release,release,423,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2905,2,"['Release', 'release']","['Release', 'release']"
Deployability,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Closes #2910 ; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2921:424,release,release,424,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2921,2,"['Release', 'release']","['Release', 'release']"
Deployability,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Closes #2929; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: Fixes a bug that wasn't in a release,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2934:423,release,release,423,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2934,3,"['Release', 'release']","['Release', 'release']"
Deployability,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Closes #2930; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: Fixing something that never made it to a release,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2950:423,release,release,423,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2950,3,"['Release', 'release']","['Release', 'release']"
Deployability,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Closes #2931; - [x] Tests included or not required because: doc change; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: No release yet,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2932:434,release,release,434,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2932,3,"['Release', 'release']","['Release', 'release']"
Deployability,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Closes #2935; - [ ] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: Code has not been in a release,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2951:423,release,release,423,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2951,3,"['Release', 'release']","['Release', 'release']"
Deployability,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Closes #2937; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3307:423,release,release,423,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3307,2,"['Release', 'release']","['Release', 'release']"
Deployability,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Closes #2969; - [ ] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:. Seems like this code is super performance sensitive: Having a Python implementation of `getrandbits` in 8572ecb1b38616f98f2af6462aa4fe5a3a8871ae resulted in a slowdown:. | Change | Before [0d4554b4] | After [1b2d9dd5] | Ratio | Benchmark (Parameter) |; |----------|----------------------|---------------------|---------|------------------------------------------|; | + | 15.2±0.03ms |	31.7±0.1ms |	2.09 | preprocessing.time_highly_variable_genes |,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3041:423,release,release,423,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3041,2,"['Release', 'release']","['Release', 'release']"
Deployability,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Closes #2973 ; - [ ] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:. Visium HD stores its coordinates in a `.parquet` file. This loads said file.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2992:424,release,release,424,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2992,2,"['Release', 'release']","['Release', 'release']"
Deployability,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Closes #2993; - [x] Tests included or not required because: fixing dev install; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because:,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2994:376,install,install,376,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2994,3,"['Release', 'install', 'release']","['Release', 'install', 'release']"
Deployability,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Closes #2993; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: dev change. Pytest 8.2 is released and should solve the problem. /edit: it does. It’s installed in the test jobs and works.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3034:423,release,release,423,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3034,4,"['Release', 'install', 'release']","['Release', 'installed', 'release', 'released']"
Deployability,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Closes #3010 ; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because:. no need to backport github changes,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3040:424,release,release,424,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3040,2,"['Release', 'release']","['Release', 'release']"
Deployability,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Closes #3012 ; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:. I added a sparse dataset to cover more code paths in most benchmarks. `regress_out` seems pretty slow with sparse data, maybe that should be tackled instead of hidden by disabling the benchmark.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3031:424,release,release,424,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3031,2,"['Release', 'release']","['Release', 'release']"
Deployability,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Closes #3027; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because: they are, added. This PR fixes the bug reported in the linked issue. A new test which spots the erroneous computations has been added. I would use this chance to refactor the `_highly_variable_genes.py`, rather than using the 2-lines fix suggested in the first commit:; Doing the multi-batch hvg flagging differently for seurat_v3 and seurat/cell_ranger is what made this bug hard to spot in the first place I think.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3042:423,release,release,423,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3042,2,"['Release', 'release']","['Release', 'release']"
Deployability,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Closes #3051; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:. TODO:. - [x] release notes; - [x] some added text explaining things; - [x] run internet tests, implement caching for datasets. Optional:. 1. continue to not run the internet tests in CI. A side effect of this PR is that our tests get less flaky by not running the flaky `ebi_expression_atlas` doctest; 2. run internet tests in CI; 1. add caching to CI; 2. make sure the dataset functions don’t download already-downloaded data; 3. validate cached data instead; 4. run the internet tests (with caching) in CI. ## [Rendered](https://icb-scanpy--3060.com.readthedocs.build/en/3060/api/datasets.html)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3060:423,release,release,423,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3060,3,"['Release', 'release']","['Release', 'release']"
Deployability,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Closes #3062; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3101:423,release,release,423,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3101,2,"['Release', 'release']","['Release', 'release']"
Deployability,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Closes #3074; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: trivial change,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3075:423,release,release,423,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3075,2,"['Release', 'release']","['Release', 'release']"
Deployability,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Closes #3083; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:. Two different fixes:. 1. The `np.asarray` cases are when we e.g. had `spmat.sum(axis=1).A` (i.e. a dense matrix). I could also leave these as `.A`.; 2. the `.toarray()` cases are when we converted a sparse matrix to dense directly.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3084:423,release,release,423,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3084,2,"['Release', 'release']","['Release', 'release']"
Deployability,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Closes #3087; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3089:423,release,release,423,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3089,2,"['Release', 'release']","['Release', 'release']"
Deployability,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Closes #3114; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:. Other things done:. - Rename some variables and reorder functions so the diff between the metrics is minimal for a future unification; - Skip seurat v3 tests with numpy 2 because skmisc isn’t ready: https://github.com/has2k1/scikit-misc/issues/34. This will skip the seurat v3 tests for all but the minimum versions test job for now, but I think that’s OK?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3115:423,release,release,423,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3115,2,"['Release', 'release']","['Release', 'release']"
Deployability,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Closes #3152; - [ ] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3196:423,release,release,423,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3196,2,"['Release', 'release']","['Release', 'release']"
Deployability,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Closes #3157; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3176:423,release,release,423,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3176,2,"['Release', 'release']","['Release', 'release']"
Deployability,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Closes #3158; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3302:423,release,release,423,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3302,2,"['Release', 'release']","['Release', 'release']"
Deployability,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Closes #3199; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3204:423,release,release,423,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3204,2,"['Release', 'release']","['Release', 'release']"
Deployability,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Closes #3226; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:. An alternative would be to subclass `PCA`, but that would involve erroring out or reimplementing all of its options. Ideally #3267 would be merged first and this one integrated into its improved decision tree.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3263:423,release,release,423,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3263,3,"['Release', 'integrat', 'release']","['Release', 'integrated', 'release']"
Deployability,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Closes #3282; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3283:423,release,release,423,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3283,2,"['Release', 'release']","['Release', 'release']"
Deployability,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Closes #3310; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: real small change,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3328:423,release,release,423,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3328,2,"['Release', 'release']","['Release', 'release']"
Deployability,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Closes #3318; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3324:423,release,release,423,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3324,2,"['Release', 'release']","['Release', 'release']"
Deployability,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Closes #761, closes #2322, closes #2229, closes #2267; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:. Also. - documents the parameter better, see #1502; - remove duplicated tests for embedding plots with continuous variables: `legend_loc` does nothing there (yet)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3163:464,release,release,464,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3163,3,"['Release', 'continuous', 'release']","['Release', 'continuous', 'release']"
Deployability,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Closes N/A (infra change for other PRs touching `external`); - [x] Tests included or not required because: works if docs build; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: see above. Adds link targets for `scanpy.external.{pp,tl,pl,…}` like they exist for `scanpy.{pp,tl,pl,…}`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2716:490,release,release,490,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2716,2,"['Release', 'release']","['Release', 'release']"
Deployability,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Closes N/A (see https://github.com/scverse/scanpy/pull/2809#pullrequestreview-1864823464); - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: dev change. Adds a consistency test before #2809 is merged. When these tests were written originally, the `.csv` file extension was used for files that aren’t comma-separated. This fixes that too without changing too many files.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2851:500,release,release,500,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2851,2,"['Release', 'release']","['Release', 'release']"
Deployability,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Closes N/A; - [x] Tests included or not required because: Release documentation; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2726:363,Release,Release,363,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2726,3,"['Release', 'release']","['Release', 'release']"
Deployability,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Closes N/A; - [x] Tests included or not required because: dev fix; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: dev fix,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2845:429,release,release,429,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2845,2,"['Release', 'release']","['Release', 'release']"
Deployability,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Closes N/A; - [x] Tests included or not required because: dev process; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: dev process,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2707:433,release,release,433,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2707,4,"['Release', 'release']","['Release', 'release']"
Deployability,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Closes N/A; - [x] Tests included or not required because: dev process; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: dev process. Filt resulted in the release workflow failing, as it tries to install the package’s runtime dependencies. Backporting the switch to hatch fixes that, now building only needs build deps",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2727:433,release,release,433,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2727,4,"['Release', 'install', 'release']","['Release', 'install', 'release']"
Deployability,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Closes N/A; - [x] Tests included or not required because: dev process; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: dev process. This can help us debug long running tests,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2786:433,release,release,433,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2786,2,"['Release', 'release']","['Release', 'release']"
Deployability,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Closes N/A; - [x] Tests included or not required because: format change; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: format change,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2718:435,release,release,435,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718,2,"['Release', 'release']","['Release', 'release']"
Deployability,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Closes N/A; - [x] Tests included or not required because: manual test: check if logo displays in rendered docs; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: unreleased bug. Seems like GitHub renders .svgs even if the namespace isn’t there, but browsers don’t.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2749:474,release,release,474,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2749,2,"['Release', 'release']","['Release', 'release']"
Deployability,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Closes N/A; - [x] Tests included or not required because: release prep; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2724:363,release,release,363,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2724,3,"['Release', 'release']","['Release', 'release']"
Deployability,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Closes N/A; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2728:421,release,release,421,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2728,6,"['Release', 'release']","['Release', 'release']"
Deployability,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Closes N/A; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: dev change,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2852:421,release,release,421,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2852,2,"['Release', 'release']","['Release', 'release']"
Deployability,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Closes N/A; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: dev changes. This PR contains more quantitative scrublet tests. It should be merged prior to #2703 to make sure our changes don’t change how scrublet works.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2776:421,release,release,421,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2776,2,"['Release', 'release']","['Release', 'release']"
Deployability,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Closes N/A; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: dev process,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2775:421,release,release,421,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2775,2,"['Release', 'release']","['Release', 'release']"
Deployability,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Closes N/A; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: docs change. Also bump scanpydoc so the `[source]` links for wrapped functions work. E.g. `sc.pp.filter_cells` now links to the correct code lines):. ```diff; -<a href=""https://github.com/scverse/scanpy/tree/419c1a45aef26b5531a5b9cf1ec430e5ae67ce97/python3.11/site-packages/legacy_api_wrap/__init__.py#L49-L193"">[source]</a>; +<a href=""https://github.com/scverse/scanpy/tree/2d5bda1e45525354b9b751aa572c0b08175450cf/scanpy/preprocessing/_simple.py#L49-L193"">[source]</a>; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2800:421,release,release,421,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2800,2,"['Release', 'release']","['Release', 'release']"
Deployability,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Closes N/A; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: fixes tests,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2745:421,release,release,421,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2745,2,"['Release', 'release']","['Release', 'release']"
Deployability,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Closes N/A; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: improves an earlier unreleased change. For some reason, PyNNDescent takes >2s to import: https://github.com/lmcinnes/pynndescent/issues/111. This change makes e.g. test collection fast again",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2715:421,release,release,421,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2715,2,"['Release', 'release']","['Release', 'release']"
Deployability,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Closes N/A; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: internal API,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2750:421,release,release,421,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2750,2,"['Release', 'release']","['Release', 'release']"
Deployability,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Closes N/A; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: only minor changes. some small changes before #2809,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2810:421,release,release,421,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2810,2,"['Release', 'release']","['Release', 'release']"
Deployability,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Closes N/A; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: small change. And for broken links, I found the working location manually. The only website that doesn’t have a working HTTPS version is http://vitessce.io (https://github.com/vitessce/vitessce/issues/1121), which is impressive given the late-90s-look of some of those journal websites.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2737:421,release,release,421,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2737,2,"['Release', 'release']","['Release', 'release']"
Deployability,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Closes N/A; - [x] Tests included; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:. Since today, there are some test breakages:. - `adata[:, [True, True]]` now behaves like `adata[:, np.array([1, 1])]` instead of `adata[:, np.array([True, True])]` (exposed through `read_10x_mtx`); - `sc.pl.violin` now creates slightly wider plots through some dependency change. This fixes everything that broke.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2801:396,release,release,396,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2801,2,"['Release', 'release']","['Release', 'release']"
Deployability,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Closes N/A; - [x] Tests included; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: Modifies unreleased features. I made the code and comments/docs more explicit about when the nearest-neighbor-is-cell-itself comes into play and when it doesn’t, and tested a bunch of our utilities. @mumichae this might make it fast for your code; You can install this branch using. ```bash; pip install -U 'scanpy@git+https://github.com/scverse/scanpy.git@improve-neighbors-shortcut'; ```. | | Before | After |; | --------- |--------|--------|; | small data | ![master](https://github.com/scverse/scanpy/assets/291575/d79a7bbd-548d-4aea-9cff-6ee44ca544ac) | ![shortcut](https://github.com/scverse/scanpy/assets/291575/d802b0d5-09e3-4002-862f-4ae4c368b061) |; | bigger data | ![master](https://github.com/scverse/scanpy/assets/291575/627ccd9f-7a42-44be-81d9-7796e54e54b0) | ![shortcut](https://github.com/scverse/scanpy/assets/291575/000b06a4-1c6c-496b-9fda-b479414e182c)|",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2756:396,release,release,396,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2756,4,"['Release', 'install', 'release']","['Release', 'install', 'release']"
Deployability,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Closes N/A; - [x] Tests included; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: dev change. This allows us to test log entries with caplog instead of awkwardly through setting the logfile and dealing with strings,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2855:396,release,release,396,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2855,2,"['Release', 'release']","['Release', 'release']"
Deployability,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Closes N/A; - [x] Tests included; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: original PR not released,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2857:396,release,release,396,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2857,3,"['Release', 'release']","['Release', 'release', 'released']"
Deployability,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Closes N/A; - [x] Tests included; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: small dev change. We already use it everywhere in the lib code, this brings the tests in line",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2817:396,release,release,396,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2817,2,"['Release', 'release']","['Release', 'release']"
Deployability,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Closes N/A; - [x] Tests included; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: tests only change,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2785:396,release,release,396,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2785,2,"['Release', 'release']","['Release', 'release']"
Deployability,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Closes NA; - [x] Tests included or not required because: dev change; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: dev change. This allows clickable links when developing in a path with spaces. TODO: check if nunit attachment URLs are predictable. If yes, emit them instead of paths in CI runs, i.e. instead of the Expected/Actual/Diff part, display just this URL:. display: https://dev.azure.com/scverse/scanpy/_build/results?buildId=5698&view=ms.vss-test-web.build-test-results-tab&runId=18968&resultId=100831&paneView=attachments. /edit: doesn’t seem like it’s possible. The URL contains `resultId=100831`, and I don’t see how this could be known at runtime. I assume those get assigned after the NUnit XML gets uploaded. ----. Once https://github.com/microsoft/vscode/issues/176812 is fixed, we can change this to [OSC 8](https://github.com/Alhadis/OSC8-Adoption) links",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2860:431,release,release,431,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2860,2,"['Release', 'release']","['Release', 'release']"
Deployability,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Closes https://github.com/scverse/anndata/issues/1210; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2719:464,release,release,464,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2719,2,"['Release', 'release']","['Release', 'release']"
Deployability,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Closes https://github.com/scverse/scanpy/issues/2763; - [x] Tests included or not required because: manually checked using rtd PR build; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:. Adds [readthedocs-sphinx-search](https://readthedocs-sphinx-search.readthedocs.io/en/latest/) support via the scanpydoc theme, which contains JS and CSS customizations to make the search extension integrate with the theme. See. - https://github.com/theislab/scanpydoc/pull/121; - https://github.com/theislab/scanpydoc/pull/125. ### [rendered](https://icb-scanpy--2805.com.readthedocs.build/en/2805/). An alternative that looks nicer would be https://github.com/readthedocs/addons, but it’s still in alpha. PS: I didn’t add the same hack as in scanpydoc that makes the search work in PR builds, so you’ll only see “No results found” in the above. Check out https://icb-scanpydoc.readthedocs-hosted.com/en/latest/?rtd_search=scanpydoc to see rendered search results. You can see that the API works for scanpy:. ```console; $ http get https://icb-scanpy.readthedocs-hosted.com/_/api/v3/search/?q=project%3Aicb-scanpy%2Flatest+filter_cells; ╭──────────┬────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮; │ count │ 2 │; │ next │ │; │ previous │ │; │ │ ╭───┬────────────┬────────────────╮ │; │ projects │ │ # │ slug │ versions │ │; │ │ ├───┼────────────┼────────────────┤ │; │ │ │ 0 │ icb-scanpy │ ╭───┬────────╮ │ │;",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2805:499,release,release,499,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2805,3,"['Release', 'integrat', 'release']","['Release', 'integrate', 'release']"
Deployability,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Closes scverse/anndata#1133; - [x] Tests included or not required because: docs only; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: just updates some tutorials. Mainly so we advertise anndata 0.11’s `read_elem_as_dask`: https://icb-scanpy--3216.com.readthedocs.build/en/3216/tutorials/experimental/dask.html,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3216:448,release,release,448,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3216,3,"['Release', 'release', 'update']","['Release', 'release', 'updates']"
Deployability,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Fixes #2830, fixes https://github.com/scverse/spatialdata/issues/440; - [x] Tests included or not required because: Tests are in #2816; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2832:498,release,release,498,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2832,2,"['Release', 'release']","['Release', 'release']"
Deployability,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Fixes #2940 ; - [x] Tests included; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because: tbd. @ilan-gold, I put some comments where I'm most interested in your feedback for a first step forward",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2980:398,release,release,398,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2980,2,"['Release', 'release']","['Release', 'release']"
Deployability,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Handle warnings from https://github.com/scverse/anndata/pull/1682; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: basically a dev change,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3289:476,release,release,476,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3289,2,"['Release', 'release']","['Release', 'release']"
Deployability,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Helps debugging #3068 ; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3069:433,release,release,433,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3069,2,"['Release', 'release']","['Release', 'release']"
Deployability,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] See https://anndata.readthedocs.io/en/latest/release-notes/index.html#rc2-2024-09-24, introduced by #3289. This `io` package did not exist previously; - [x] Tests included or not required because: Tested locally, no way to really test this; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: This is a bug fix of a warning suppression",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3298:350,release,release-notes,350,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3298,3,"['Release', 'release']","['Release', 'release', 'release-notes']"
Deployability,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Tests included or not required because: it's formating; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: it's formatting. Why did we ever configure black?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2701:418,release,release,418,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2701,2,"['Release', 'release']","['Release', 'release']"
Deployability,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Towards #2578 and maybe others? #2764; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because:. Note I did not follow:; https://gist.github.com/Intron7/bbf5058794be7b81d3953ae39c17d8b8. This is because this PR is basically very simple. I just added an `axis_sum` function for dispatching on dask arrays (with sparse chunks) which now handles the needed functionality and then it propagates up to various functions as noted in the release note: `scanpy.pp.scale`, `scanpy.pp.filter_cells`, `scanpy.pp.filter_genes`, `scanpy.pp.scale` and `scanpy.pp.highly_variable_genes`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2856:448,release,release,448,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2856,3,"['Release', 'release']","['Release', 'release']"
Deployability,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. Added the ```n_components``` parameter in the tsne function, similar to the one in umap and updated docstring. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Closes #460; - [ ] Tests included or not required because: Not included but can add tests if necessary.; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: Only minor change.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2803:326,update,updated,326,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2803,3,"['Release', 'release', 'update']","['Release', 'release', 'updated']"
Deployability,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. Fix for #2887. Updated and added basic tests to Leiden and Louvain clustering to check that the parameters are written to the user specified key. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Closes #2887 ; - [x] Tests included; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2889:249,Update,Updated,249,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2889,3,"['Release', 'Update', 'release']","['Release', 'Updated', 'release']"
Deployability,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. Fixes:. * Error caused by new matplotlib release candidate (it had been deprecated for a while, we just hadn't caught it....); * Corrects deprecation warnings in igraph leiden clustering code and pearson residuals code. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [x] Tests included or not required because: just fixin' warnings; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because:",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2999:275,release,release,275,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2999,3,"['Release', 'release']","['Release', 'release']"
Deployability,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. Follow up on https://github.com/scverse/scanpy/issues/2444#issuecomment-2022974986. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Tests included or not required because: it's docs; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2974:497,release,release,497,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2974,2,"['Release', 'release']","['Release', 'release']"
Deployability,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. Hi there, ; I wrote a color annotation function for the Baseplot class called `add_colorblocks()`, which borrows some functionality of the `add_totals()` function and creates a colorblock for the annotation each assigned group. ```; sc.pl.dotplot(adata, [""CD79A"", ""MS4A1""], ""bulk_labels"", return_fig=True, show=False,; #swap_axes=True; ).add_colorblocks(color='Paired', size=0.1).show(); ```; ![image](https://github.com/scverse/scanpy/assets/24408322/eb50f18c-8fd7-4586-b63c-41c4e4f44a93). <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Addresses #2194; - [x] Tests included or not required because: plotting; <!-- Only check the following box if you did not include release notes -->; - [ x] Release notes not necessary because: tbd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3043:926,release,release,926,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3043,2,"['Release', 'release']","['Release', 'release']"
Deployability,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. Hi,; We are submitting PR for speed up of the _get_mean_var function. ; | | Time(sec)|; | -----------| ----- |; | Original | 18.49 |; | Updated | 3.97 |; | Speedup | 4.65743073 |. experiment setup : AWS r7i.24xlarge. ```py; import time; import numpy as np. import pandas as pd. import scanpy as sc; from sklearn.cluster import KMeans. import os; import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '); warnings.simplefilter('ignore'); input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):; print('Downloading import file...'); wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes; MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out; markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells; min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed; max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes; min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this; n_top_genes = 4000 # Number of highly variable genes to retain. # PCA; n_components = 50 # Number of principal components to compute. # t-SNE; tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means; k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs; sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(); tr=time.time(); adata = sc.read(input_file); adata.var_names_make_unique(); adata.shape; print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(); # To redu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3099:370,Update,Updated,370,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3099,1,['Update'],['Updated']
Deployability,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. I tried to follow the feedback described in a previous PR that contributed DensMAP https://github.com/scverse/scanpy/pull/2684#issuecomment-1764564449 but re-implemented on top of the state of the current scanpy main branch. I did not add release notes because the contributor guide says to wait for PR feedback https://scanpy.readthedocs.io/en/latest/dev/documentation.html#adding-to-the-docs. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Closes #1619 ; - [x] Closes #2684; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because:,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2946:473,release,release,473,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2946,3,"['Release', 'release']","['Release', 'release']"
Deployability,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. Sibling PR to: https://github.com/scverse/anndata/pull/1339. Basically, makes sure that we are running the tests on the commits we release from.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2834:365,release,release,365,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2834,1,['release'],['release']
Deployability,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. Since `gen_pca_params` is a generator, not sure how we can control the order besides rolling back the use of sets. So I landed on just sorting the args based on `id` of the pytest. . I was running in to https://github.com/pytest-dev/pytest-xdist/issues/432. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [ ] Closes #; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: just fixing some tests",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3333:319,rolling,rolling,319,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3333,3,"['Release', 'release', 'rolling']","['Release', 'release', 'rolling']"
Deployability,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. The idea here is to raise errors where I have checked that things currently don't work, regardless of the reason why, and do not make any attempt to fix this problem. Once https://github.com/scverse/anndata/pull/1469 is merged, we can make concrete recommendations for how to handle out-of-core data. I think a decorator could work but we would have to check the type in the decorator like (instead of relying on current checks like in `filter_genes`):. ```python; if isinstance(arg1, AnnData) and arg1.isbacked:; raise NotImplementedErrror(...); ```. But then there is something like `log1p` where we quasi-support `backed` via this `chunked` kwarg, which would no really fit the above paradigm. Nonetheless, I think I need to go one-by-one through the functions to check what we support and don't. Separately, we may want to drop support where it exists already (which from my searching, is only `obs_df` and `var_df` and then `subsample_counts`). <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Closes #3004 and closes #2894; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3048:1390,release,release,1390,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048,2,"['Release', 'release']","['Release', 'release']"
Deployability,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. This PR clarifies the docs/handling to make it clear we _only_ support this for correctly chunked CSR-dask. I think that not handling the other case is fine for a few reasons:. 1. CSC chunking would basically require multiple passes at the data. Every chunk (of size `(adata.shape[0], N)`) would need to be `X.T @ Y`-ed over the entire matrix where `X` is the chunk and `Y` is any given column-chunk from the matrix. I can't think of a way around this; 2. Given the above, I don't think there is any reason why we should implement this algorithm. People should just re-write their data to disk as CSR. I can't imagine its worse than this modulo the fact that you need to load the whole matrix into memory. This might be a good reason to change our on-disk format but at the moment, this is about all I think we should do. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Just remembered that this fact needs to be stated clearly. @Intron7 please update the RSC PR as well if you haven't already!; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: edited",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3306:1202,update,update,1202,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3306,3,"['Release', 'release', 'update']","['Release', 'release', 'update']"
Deployability,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. This PR contains commits changing fa2 to fa2_modified as the original fa2 is not maintained anymore and doesn't work with Python3.9+ . [fa2_modified](https://github.com/AminAlam/fa2_modified) has the exact same functionality as the original fa2, but its Cython codes have been modified to make it work with newer version of Python. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Closes #2067; - [x] Tests included or not required because:; No additional rests are required as the already existing tests cover these changes; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3220:839,release,release,839,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3220,2,"['Release', 'release']","['Release', 'release']"
Deployability,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. This is a very small pull request to add `str` to the possible arguments for saving a figure from [`scanpy.pl.rank_genes_groups`][rank-genes-groups]. This addition matches other `save=` arguments, such as from [`scanpy.plotting.highly_variable_genes`][highly-variable-genes], [`sc.plotting.pca_variance_ratio`][pca-variance-ratio], and [`scanpy.plotting.umap`][umap]. [rank-genes-groups]: https://github.com/scverse/scanpy/blob/main/scanpy/plotting/_tools/__init__.py; [highly-variable-genes]: https://github.com/scverse/scanpy/blob/main/scanpy/plotting/_preprocessing.py; [pca-variance-ratio]: https://github.com/scverse/scanpy/blob/main/scanpy/plotting/_tools/__init__.py; [umap]: https://github.com/scverse/scanpy/blob/main/scanpy/plotting/_tools/scatterplots.py. I have not included tests or release notes due to the single-line change nature of this pull request",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3076:1030,release,release,1030,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3076,1,['release'],['release']
Deployability,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->; <!-- Please check (“- [x]”) and fill in the following boxes -->; - [ ] Closes #; - [ ] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:. Hi,; We are submitting PR for speed up of the regress_out function. Here we finding coefficient using Linear regression (Linear Least Squares) rather then GLM for non categorical data. | | Time(sec)|; | -----------| ----- |; | Original | 297|; | Updated | 14.91 |; | Speedup | 19.91 |. experiment setup : AWS r7i.24xlarge. ```python; import time; import numpy as np. import pandas as pd. import scanpy as sc; from sklearn.cluster import KMeans. import os; import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '); warnings.simplefilter('ignore'); input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):; print('Downloading import file...'); wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes; MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out; markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells; min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed; max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes; min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this; n_top_genes = 4000 # Number of highly variable genes to retain. # PCA; n_components = 50 # Number of principal components to compute. # t-SNE; tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means; k = 35 # Number of clusters for k-means. # Ge",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3110:419,release,release,419,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110,3,"['Release', 'Update', 'release']","['Release', 'Updated', 'release']"
Deployability,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->; Added the boolean argument ""add_intercept"" to regress_out, and implemented code to optionally add the intercept back to the residuals in the result of regress_out().; <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Closes https://github.com/theislab/single-cell-tutorial/issues/35; - [ ] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2731:643,release,release,643,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2731,2,"['Release', 'release']","['Release', 'release']"
Deployability,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->; I think this is a better fix since we were already writing out `X_pca`. The tests seem to pass and `pca` should be idempotent so this really shouldn't break anything (hopefully).; <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Closes #3074 ; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because:,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3079:604,release,release,604,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3079,2,"['Release', 'release']","['Release', 'release']"
Deployability,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->; Simple addition of the `layer` argument which is already included in `sc.tl.score_genes` so that you can use your own layer instead of being restricted to what is stored in `adata.X` . <!-- Please check (“- [x]”) and fill in the following boxes -->; - [ ] Closes #; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3138:604,release,release,604,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3138,2,"['Release', 'release']","['Release', 'release']"
Deployability,"<!--; ⚠ If you need help using Scanpy, please ask in https://discourse.scverse.org/ instead ⚠; If you want to know about design decisions and the like, please ask below:; -->; ... Hi,. I noticed that when scanpy reads the spatial information from the ""tisslue_position_list.csv"" file of the 10X visium data, the (x,y) coordinate for pixels is flipped:. positions.columns = [; 'barcode',; 'in_tissue',; 'array_row',; 'array_col',; 'pxl_col_in_fullres',; 'pxl_row_in_fullres',; ]. However, from here: [https://support.10xgenomics.com/spatial-gene-expression/software/pipelines/latest/output/images](url), the pxl_row is supposed to be ahead of pxl_col . Is there any explanation for this?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2251:565,pipeline,pipelines,565,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2251,1,['pipeline'],['pipelines']
Deployability,"<!--; ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠; If you want to know about design decisions and the like, please ask below:; -->; ... Hi,. I notice that even if I set n_jobs=1 in sc.pp.regress_out, all cpus are utilized. This also happens if I set n_jobs to other numbers. Basically there isn't a noticeable difference in cpu usage no matter what number of n_jobs I set. I'm using CentOS6.8 on a machine with 28 physical cores and hyper threading on (appears as 56 cores in the os). Is this an intended behavior, or just my installation? I understand that some numpy functions are naturally multi-threaded because of the setup of BLAS libraries. Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1396:571,install,installation,571,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1396,1,['install'],['installation']
Deployability,"<!--; ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠; If you want to know about design decisions and the like, please ask below:; -->; ...; Hello Scanpy,; In @LuckyMD 's amazing paper (https://www.embopress.org/doi/full/10.15252/msb.20188746), Table 1 shows that using raw data to calculate the maker genes of clusters is the appropriate way. But the raw data was not regressed out with mitochondrial genes, gene counts, cell cycle scores...So there will be so many mito genes ranked on the top of the marker gene list. What shall we do with these mito genes, because usually they represent the dead cell-released RNA contaminations?. In Seurat, they did every downstream analysis and plotting by using the log-transformed and scaled data (see below, the scaled dots in Seurat violin plot). Scanpy draws all plots by setting use_raw=True. I'm wondering which method is better?; ![image](https://user-images.githubusercontent.com/75048821/149461003-ed8d62d9-8aa9-4b5a-905d-e22bd10a1345.png). BTW, logFC will become negative and disappear for the marker genes of clusters when we set `use_raw=False` in `sc.tl.rank_genes_groups(adata, 'leiden', method='wilcoxon'`. Please check this https://github.com/theislab/scanpy/issues/2057. Thanks!; Best,; YJ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2110:647,release,released,647,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2110,1,['release'],['released']
Deployability,"<!--; ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠; If you want to know about design decisions and the like, please ask below:; -->; ...; colors_use = ['red', 'blue', 'green', 'purple', 'yellow', 'brown', 'black', 'peru', 'orange', 'olive',; 'darksage', 'cyan', 'lime', 'pink', 'teal', 'violet', 'darkblue', 'magenta', 'coral', 'gray']; adata = sc.AnnData(embedding); adata.obs[""category""] = label.astype(np.int); adata.obs[""domain""] = batch.astype(np.int); sc.tl.tsne(adata, use_rep = 'X', n_jobs = 10); adata.uns[""category_colors""] = list(colors_use[:len(np.unique(label))]); adata.uns[""domain_colors""] = list(colors_use[:len(np.unique(batch))]); sc.pl.tsne(adata, color = [""category"", ""domain""], title = [""class"", ""domain""],; show = False, size = 50000 / len(label), save = ""/{}.pdf"".format(file)). My scanpy version is 1.4.6, but when I run the above codes, I find that the color is continuous, why cannot set my specific color?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1963:931,continuous,continuous,931,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1963,1,['continuous'],['continuous']
Deployability,<!--pre-commit.ci start-->; updates:; - [github.com/PyCQA/flake8: 4.0.1 → 5.0.4](https://github.com/PyCQA/flake8/compare/4.0.1...5.0.4); <!--pre-commit.ci end-->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2303:28,update,updates,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2303,1,['update'],['updates']
Deployability,<!--pre-commit.ci start-->; updates:; - [github.com/astral-sh/ruff-pre-commit: v0.0.272 → v0.0.275](https://github.com/astral-sh/ruff-pre-commit/compare/v0.0.272...v0.0.275); <!--pre-commit.ci end-->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2535:28,update,updates,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2535,1,['update'],['updates']
Deployability,<!--pre-commit.ci start-->; updates:; - [github.com/astral-sh/ruff-pre-commit: v0.0.275 → v0.0.276](https://github.com/astral-sh/ruff-pre-commit/compare/v0.0.275...v0.0.276); <!--pre-commit.ci end-->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2544:28,update,updates,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2544,1,['update'],['updates']
Deployability,<!--pre-commit.ci start-->; updates:; - [github.com/astral-sh/ruff-pre-commit: v0.0.276 → v0.0.277](https://github.com/astral-sh/ruff-pre-commit/compare/v0.0.276...v0.0.277); <!--pre-commit.ci end-->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2553:28,update,updates,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2553,1,['update'],['updates']
Deployability,<!--pre-commit.ci start-->; updates:; - [github.com/astral-sh/ruff-pre-commit: v0.0.278 → v0.0.280](https://github.com/astral-sh/ruff-pre-commit/compare/v0.0.278...v0.0.280); <!--pre-commit.ci end-->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2573:28,update,updates,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2573,1,['update'],['updates']
Deployability,<!--pre-commit.ci start-->; updates:; - [github.com/astral-sh/ruff-pre-commit: v0.0.280 → v0.0.281](https://github.com/astral-sh/ruff-pre-commit/compare/v0.0.280...v0.0.281); <!--pre-commit.ci end-->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2581:28,update,updates,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2581,1,['update'],['updates']
Deployability,<!--pre-commit.ci start-->; updates:; - [github.com/astral-sh/ruff-pre-commit: v0.0.281 → v0.0.282](https://github.com/astral-sh/ruff-pre-commit/compare/v0.0.281...v0.0.282); <!--pre-commit.ci end-->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2602:28,update,updates,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2602,1,['update'],['updates']
Deployability,<!--pre-commit.ci start-->; updates:; - [github.com/astral-sh/ruff-pre-commit: v0.0.282 → v0.0.284](https://github.com/astral-sh/ruff-pre-commit/compare/v0.0.282...v0.0.284); <!--pre-commit.ci end-->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2617:28,update,updates,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2617,1,['update'],['updates']
Deployability,<!--pre-commit.ci start-->; updates:; - [github.com/astral-sh/ruff-pre-commit: v0.0.284 → v0.0.285](https://github.com/astral-sh/ruff-pre-commit/compare/v0.0.284...v0.0.285); <!--pre-commit.ci end-->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2631:28,update,updates,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2631,1,['update'],['updates']
Deployability,<!--pre-commit.ci start-->; updates:; - [github.com/astral-sh/ruff-pre-commit: v0.0.285 → v0.0.286](https://github.com/astral-sh/ruff-pre-commit/compare/v0.0.285...v0.0.286); <!--pre-commit.ci end-->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2642:28,update,updates,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2642,1,['update'],['updates']
Deployability,<!--pre-commit.ci start-->; updates:; - [github.com/astral-sh/ruff-pre-commit: v0.0.286 → v0.0.287](https://github.com/astral-sh/ruff-pre-commit/compare/v0.0.286...v0.0.287); <!--pre-commit.ci end-->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2651:28,update,updates,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2651,1,['update'],['updates']
Deployability,<!--pre-commit.ci start-->; updates:; - [github.com/astral-sh/ruff-pre-commit: v0.1.11 → v0.1.13](https://github.com/astral-sh/ruff-pre-commit/compare/v0.1.11...v0.1.13); <!--pre-commit.ci end-->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2811:28,update,updates,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2811,1,['update'],['updates']
Deployability,<!--pre-commit.ci start-->; updates:; - [github.com/astral-sh/ruff-pre-commit: v0.1.13 → v0.1.14](https://github.com/astral-sh/ruff-pre-commit/compare/v0.1.13...v0.1.14); <!--pre-commit.ci end-->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2820:28,update,updates,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2820,1,['update'],['updates']
Deployability,<!--pre-commit.ci start-->; updates:; - [github.com/astral-sh/ruff-pre-commit: v0.1.14 → v0.2.0](https://github.com/astral-sh/ruff-pre-commit/compare/v0.1.14...v0.2.0); <!--pre-commit.ci end-->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2841:28,update,updates,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2841,1,['update'],['updates']
Deployability,<!--pre-commit.ci start-->; updates:; - [github.com/astral-sh/ruff-pre-commit: v0.1.3 → v0.1.4](https://github.com/astral-sh/ruff-pre-commit/compare/v0.1.3...v0.1.4); <!--pre-commit.ci end-->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2732:28,update,updates,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2732,1,['update'],['updates']
Deployability,<!--pre-commit.ci start-->; updates:; - [github.com/astral-sh/ruff-pre-commit: v0.1.4 → v0.1.5](https://github.com/astral-sh/ruff-pre-commit/compare/v0.1.4...v0.1.5); <!--pre-commit.ci end-->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2753:28,update,updates,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2753,1,['update'],['updates']
Deployability,<!--pre-commit.ci start-->; updates:; - [github.com/astral-sh/ruff-pre-commit: v0.1.5 → v0.1.7](https://github.com/astral-sh/ruff-pre-commit/compare/v0.1.5...v0.1.7); <!--pre-commit.ci end-->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2760:28,update,updates,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2760,1,['update'],['updates']
Deployability,<!--pre-commit.ci start-->; updates:; - [github.com/astral-sh/ruff-pre-commit: v0.1.7 → v0.1.8](https://github.com/astral-sh/ruff-pre-commit/compare/v0.1.7...v0.1.8); <!--pre-commit.ci end-->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2784:28,update,updates,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2784,1,['update'],['updates']
Deployability,<!--pre-commit.ci start-->; updates:; - [github.com/astral-sh/ruff-pre-commit: v0.1.8 → v0.1.9](https://github.com/astral-sh/ruff-pre-commit/compare/v0.1.8...v0.1.9); <!--pre-commit.ci end-->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2794:28,update,updates,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2794,1,['update'],['updates']
Deployability,<!--pre-commit.ci start-->; updates:; - [github.com/astral-sh/ruff-pre-commit: v0.1.9 → v0.1.11](https://github.com/astral-sh/ruff-pre-commit/compare/v0.1.9...v0.1.11); <!--pre-commit.ci end-->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2799:28,update,updates,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2799,1,['update'],['updates']
Deployability,<!--pre-commit.ci start-->; updates:; - [github.com/astral-sh/ruff-pre-commit: v0.2.0 → v0.2.1](https://github.com/astral-sh/ruff-pre-commit/compare/v0.2.0...v0.2.1); <!--pre-commit.ci end-->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2850:28,update,updates,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2850,1,['update'],['updates']
Deployability,<!--pre-commit.ci start-->; updates:; - [github.com/astral-sh/ruff-pre-commit: v0.2.1 → v0.2.2](https://github.com/astral-sh/ruff-pre-commit/compare/v0.2.1...v0.2.2); <!--pre-commit.ci end-->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2867:28,update,updates,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2867,1,['update'],['updates']
Deployability,<!--pre-commit.ci start-->; updates:; - [github.com/astral-sh/ruff-pre-commit: v0.2.2 → v0.3.2](https://github.com/astral-sh/ruff-pre-commit/compare/v0.2.2...v0.3.2); <!--pre-commit.ci end-->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2907:28,update,updates,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2907,1,['update'],['updates']
Deployability,<!--pre-commit.ci start-->; updates:; - [github.com/astral-sh/ruff-pre-commit: v0.3.2 → v0.3.3](https://github.com/astral-sh/ruff-pre-commit/compare/v0.3.2...v0.3.3); <!--pre-commit.ci end-->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2926:28,update,updates,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2926,1,['update'],['updates']
Deployability,<!--pre-commit.ci start-->; updates:; - [github.com/astral-sh/ruff-pre-commit: v0.3.3 → v0.3.4](https://github.com/astral-sh/ruff-pre-commit/compare/v0.3.3...v0.3.4); <!--pre-commit.ci end-->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2960:28,update,updates,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2960,1,['update'],['updates']
Deployability,<!--pre-commit.ci start-->; updates:; - [github.com/astral-sh/ruff-pre-commit: v0.3.4 → v0.3.5](https://github.com/astral-sh/ruff-pre-commit/compare/v0.3.4...v0.3.5); - [github.com/pre-commit/pre-commit-hooks: v4.5.0 → v4.6.0](https://github.com/pre-commit/pre-commit-hooks/compare/v4.5.0...v4.6.0); <!--pre-commit.ci end-->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2987:28,update,updates,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2987,1,['update'],['updates']
Deployability,<!--pre-commit.ci start-->; updates:; - [github.com/astral-sh/ruff-pre-commit: v0.3.5 → v0.3.7](https://github.com/astral-sh/ruff-pre-commit/compare/v0.3.5...v0.3.7); <!--pre-commit.ci end-->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3008:28,update,updates,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3008,1,['update'],['updates']
Deployability,<!--pre-commit.ci start-->; updates:; - [github.com/astral-sh/ruff-pre-commit: v0.3.7 → v0.4.1](https://github.com/astral-sh/ruff-pre-commit/compare/v0.3.7...v0.4.1); <!--pre-commit.ci end-->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3022:28,update,updates,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3022,1,['update'],['updates']
Deployability,<!--pre-commit.ci start-->; updates:; - [github.com/astral-sh/ruff-pre-commit: v0.4.1 → v0.4.2](https://github.com/astral-sh/ruff-pre-commit/compare/v0.4.1...v0.4.2); <!--pre-commit.ci end-->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3038:28,update,updates,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3038,1,['update'],['updates']
Deployability,<!--pre-commit.ci start-->; updates:; - [github.com/astral-sh/ruff-pre-commit: v0.4.10 → v0.5.0](https://github.com/astral-sh/ruff-pre-commit/compare/v0.4.10...v0.5.0); <!--pre-commit.ci end-->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3131:28,update,updates,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3131,1,['update'],['updates']
Deployability,<!--pre-commit.ci start-->; updates:; - [github.com/astral-sh/ruff-pre-commit: v0.4.2 → v0.4.3](https://github.com/astral-sh/ruff-pre-commit/compare/v0.4.2...v0.4.3); <!--pre-commit.ci end-->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3045:28,update,updates,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3045,1,['update'],['updates']
Deployability,<!--pre-commit.ci start-->; updates:; - [github.com/astral-sh/ruff-pre-commit: v0.4.3 → v0.4.4](https://github.com/astral-sh/ruff-pre-commit/compare/v0.4.3...v0.4.4); <!--pre-commit.ci end-->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3053:28,update,updates,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3053,1,['update'],['updates']
Deployability,<!--pre-commit.ci start-->; updates:; - [github.com/astral-sh/ruff-pre-commit: v0.4.4 → v0.4.5](https://github.com/astral-sh/ruff-pre-commit/compare/v0.4.4...v0.4.5); <!--pre-commit.ci end-->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3078:28,update,updates,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3078,1,['update'],['updates']
Deployability,<!--pre-commit.ci start-->; updates:; - [github.com/astral-sh/ruff-pre-commit: v0.4.5 → v0.4.7](https://github.com/astral-sh/ruff-pre-commit/compare/v0.4.5...v0.4.7); <!--pre-commit.ci end-->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3093:28,update,updates,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3093,1,['update'],['updates']
Deployability,<!--pre-commit.ci start-->; updates:; - [github.com/astral-sh/ruff-pre-commit: v0.4.7 → v0.4.8](https://github.com/astral-sh/ruff-pre-commit/compare/v0.4.7...v0.4.8); <!--pre-commit.ci end-->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3104:28,update,updates,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3104,1,['update'],['updates']
Deployability,<!--pre-commit.ci start-->; updates:; - [github.com/astral-sh/ruff-pre-commit: v0.4.8 → v0.4.9](https://github.com/astral-sh/ruff-pre-commit/compare/v0.4.8...v0.4.9); <!--pre-commit.ci end-->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3109:28,update,updates,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3109,1,['update'],['updates']
Deployability,<!--pre-commit.ci start-->; updates:; - [github.com/astral-sh/ruff-pre-commit: v0.4.9 → v0.4.10](https://github.com/astral-sh/ruff-pre-commit/compare/v0.4.9...v0.4.10); <!--pre-commit.ci end-->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3119:28,update,updates,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3119,1,['update'],['updates']
Deployability,<!--pre-commit.ci start-->; updates:; - [github.com/astral-sh/ruff-pre-commit: v0.5.0 → v0.5.1](https://github.com/astral-sh/ruff-pre-commit/compare/v0.5.0...v0.5.1); <!--pre-commit.ci end-->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3148:28,update,updates,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3148,1,['update'],['updates']
Deployability,<!--pre-commit.ci start-->; updates:; - [github.com/astral-sh/ruff-pre-commit: v0.5.1 → v0.5.4](https://github.com/astral-sh/ruff-pre-commit/compare/v0.5.1...v0.5.4); <!--pre-commit.ci end-->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3156:28,update,updates,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3156,1,['update'],['updates']
Deployability,<!--pre-commit.ci start-->; updates:; - [github.com/astral-sh/ruff-pre-commit: v0.5.4 → v0.5.5](https://github.com/astral-sh/ruff-pre-commit/compare/v0.5.4...v0.5.5); <!--pre-commit.ci end-->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3174:28,update,updates,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3174,1,['update'],['updates']
Deployability,<!--pre-commit.ci start-->; updates:; - [github.com/astral-sh/ruff-pre-commit: v0.5.5 → v0.5.6](https://github.com/astral-sh/ruff-pre-commit/compare/v0.5.5...v0.5.6); <!--pre-commit.ci end-->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3197:28,update,updates,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3197,1,['update'],['updates']
Deployability,<!--pre-commit.ci start-->; updates:; - [github.com/astral-sh/ruff-pre-commit: v0.5.6 → v0.5.7](https://github.com/astral-sh/ruff-pre-commit/compare/v0.5.6...v0.5.7); <!--pre-commit.ci end-->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3207:28,update,updates,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3207,1,['update'],['updates']
Deployability,<!--pre-commit.ci start-->; updates:; - [github.com/astral-sh/ruff-pre-commit: v0.5.7 → v0.6.1](https://github.com/astral-sh/ruff-pre-commit/compare/v0.5.7...v0.6.1); <!--pre-commit.ci end-->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3210:28,update,updates,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3210,1,['update'],['updates']
Deployability,<!--pre-commit.ci start-->; updates:; - [github.com/astral-sh/ruff-pre-commit: v0.6.1 → v0.6.3](https://github.com/astral-sh/ruff-pre-commit/compare/v0.6.1...v0.6.3); <!--pre-commit.ci end-->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3213:28,update,updates,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3213,1,['update'],['updates']
Deployability,<!--pre-commit.ci start-->; updates:; - [github.com/astral-sh/ruff-pre-commit: v0.6.3 → v0.6.4](https://github.com/astral-sh/ruff-pre-commit/compare/v0.6.3...v0.6.4); <!--pre-commit.ci end-->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3225:28,update,updates,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3225,1,['update'],['updates']
Deployability,<!--pre-commit.ci start-->; updates:; - [github.com/astral-sh/ruff-pre-commit: v0.6.4 → v0.6.5](https://github.com/astral-sh/ruff-pre-commit/compare/v0.6.4...v0.6.5); <!--pre-commit.ci end-->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3232:28,update,updates,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3232,1,['update'],['updates']
Deployability,<!--pre-commit.ci start-->; updates:; - [github.com/astral-sh/ruff-pre-commit: v0.6.5 → v0.6.7](https://github.com/astral-sh/ruff-pre-commit/compare/v0.6.5...v0.6.7); <!--pre-commit.ci end-->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3256:28,update,updates,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3256,1,['update'],['updates']
Deployability,<!--pre-commit.ci start-->; updates:; - [github.com/astral-sh/ruff-pre-commit: v0.6.7 → v0.6.8](https://github.com/astral-sh/ruff-pre-commit/compare/v0.6.7...v0.6.8); <!--pre-commit.ci end-->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3270:28,update,updates,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3270,1,['update'],['updates']
Deployability,<!--pre-commit.ci start-->; updates:; - [github.com/astral-sh/ruff-pre-commit: v0.6.8 → v0.7.0](https://github.com/astral-sh/ruff-pre-commit/compare/v0.6.8...v0.7.0); - [github.com/pre-commit/pre-commit-hooks: v4.6.0 → v5.0.0](https://github.com/pre-commit/pre-commit-hooks/compare/v4.6.0...v5.0.0); <!--pre-commit.ci end-->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3274:28,update,updates,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3274,1,['update'],['updates']
Deployability,<!--pre-commit.ci start-->; updates:; - [github.com/astral-sh/ruff-pre-commit: v0.7.0 → v0.7.2](https://github.com/astral-sh/ruff-pre-commit/compare/v0.7.0...v0.7.2); <!--pre-commit.ci end-->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3329:28,update,updates,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3329,1,['update'],['updates']
Deployability,<!--pre-commit.ci start-->; updates:; - [github.com/pre-commit/mirrors-autopep8: v1.6.0 → v1.7.0](https://github.com/pre-commit/mirrors-autopep8/compare/v1.6.0...v1.7.0); <!--pre-commit.ci end-->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2307:28,update,updates,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2307,1,['update'],['updates']
Deployability,<!--pre-commit.ci start-->; updates:; - [github.com/pre-commit/pre-commit-hooks: v4.1.0 → v4.2.0](https://github.com/pre-commit/pre-commit-hooks/compare/v4.1.0...v4.2.0); <!--pre-commit.ci end-->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2232:28,update,updates,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2232,1,['update'],['updates']
Deployability,<!--pre-commit.ci start-->; updates:; - [github.com/pre-commit/pre-commit-hooks: v4.2.0 → v4.3.0](https://github.com/pre-commit/pre-commit-hooks/compare/v4.2.0...v4.3.0); <!--pre-commit.ci end-->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2271:28,update,updates,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2271,1,['update'],['updates']
Deployability,<!--pre-commit.ci start-->; updates:; - [github.com/pre-commit/pre-commit-hooks: v4.4.0 → v4.5.0](https://github.com/pre-commit/pre-commit-hooks/compare/v4.4.0...v4.5.0); <!--pre-commit.ci end-->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2679:28,update,updates,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2679,1,['update'],['updates']
Deployability,<!--pre-commit.ci start-->; updates:; - [github.com/psf/black: 21.12b0 → 22.1.0](https://github.com/psf/black/compare/21.12b0...22.1.0); - [github.com/pre-commit/mirrors-autopep8: v1.5.7 → v1.6.0](https://github.com/pre-commit/mirrors-autopep8/compare/v1.5.7...v1.6.0); <!--pre-commit.ci end-->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2099:28,update,updates,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2099,1,['update'],['updates']
Deployability,<!--pre-commit.ci start-->; updates:; - [github.com/psf/black: 22.10.0 → 23.1.0](https://github.com/psf/black/compare/22.10.0...23.1.0); - [github.com/PyCQA/flake8: 5.0.4 → 6.0.0](https://github.com/PyCQA/flake8/compare/5.0.4...6.0.0); - [github.com/pre-commit/mirrors-autopep8: v2.0.0 → v2.0.1](https://github.com/pre-commit/mirrors-autopep8/compare/v2.0.0...v2.0.1); - [github.com/pre-commit/pre-commit-hooks: v4.3.0 → v4.4.0](https://github.com/pre-commit/pre-commit-hooks/compare/v4.3.0...v4.4.0); <!--pre-commit.ci end-->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2373:28,update,updates,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2373,1,['update'],['updates']
Deployability,<!--pre-commit.ci start-->; updates:; - [github.com/psf/black: 22.3.0 → 22.6.0](https://github.com/psf/black/compare/22.3.0...22.6.0); <!--pre-commit.ci end-->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2289:28,update,updates,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2289,1,['update'],['updates']
Deployability,<!--pre-commit.ci start-->; updates:; - [github.com/psf/black: 22.6.0 → 22.8.0](https://github.com/psf/black/compare/22.6.0...22.8.0); <!--pre-commit.ci end-->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2320:28,update,updates,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2320,1,['update'],['updates']
Deployability,<!--pre-commit.ci start-->; updates:; - [github.com/psf/black: 22.8.0 → 22.10.0](https://github.com/psf/black/compare/22.8.0...22.10.0); - [github.com/pre-commit/mirrors-autopep8: v1.7.0 → v2.0.0](https://github.com/pre-commit/mirrors-autopep8/compare/v1.7.0...v2.0.0); <!--pre-commit.ci end-->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2347:28,update,updates,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2347,1,['update'],['updates']
Deployability,<!--pre-commit.ci start-->; updates:; - [github.com/psf/black: 23.1.0 → 23.3.0](https://github.com/psf/black/compare/23.1.0...23.3.0); - [github.com/pre-commit/mirrors-autopep8: v2.0.1 → v2.0.2](https://github.com/pre-commit/mirrors-autopep8/compare/v2.0.1...v2.0.2); <!--pre-commit.ci end-->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2437:28,update,updates,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2437,1,['update'],['updates']
Deployability,<!--pre-commit.ci start-->; updates:; - [github.com/psf/black: 23.3.0 → 23.7.0](https://github.com/psf/black/compare/23.3.0...23.7.0); - [github.com/astral-sh/ruff-pre-commit: v0.0.277 → v0.0.278](https://github.com/astral-sh/ruff-pre-commit/compare/v0.0.277...v0.0.278); <!--pre-commit.ci end-->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2560:28,update,updates,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2560,1,['update'],['updates']
Deployability,<!--pre-commit.ci start-->; updates:; - [github.com/psf/black: 23.7.0 → 23.9.1](https://github.com/psf/black/compare/23.7.0...23.9.1); - [github.com/astral-sh/ruff-pre-commit: v0.0.287 → v0.0.292](https://github.com/astral-sh/ruff-pre-commit/compare/v0.0.287...v0.0.292); <!--pre-commit.ci end-->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2661:28,update,updates,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2661,1,['update'],['updates']
Deployability,<!--pre-commit.ci start-->; updates:; - [github.com/psf/black: 23.9.1 → 23.10.0](https://github.com/psf/black/compare/23.9.1...23.10.0); - [github.com/astral-sh/ruff-pre-commit: v0.0.292 → v0.1.1](https://github.com/astral-sh/ruff-pre-commit/compare/v0.0.292...v0.1.1); <!--pre-commit.ci end-->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2704:28,update,updates,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2704,1,['update'],['updates']
Deployability,"<details>. ```; anndata 0.10.7; scanpy 1.10.1; -----; PIL 10.3.0; anyio NA; arrow 1.3.0; asttokens NA; attr 23.2.0; attrs 23.2.0; babel 2.14.0; bottleneck 1.3.7; brotli 1.0.9; certifi 2024.02.02; cffi 1.16.0; charset_normalizer 2.0.4; colorama 0.4.6; comm 0.2.2; cycler 0.12.1; cython_runtime NA; dateutil 2.9.0; debugpy 1.8.1; decorator 5.1.1; defusedxml 0.7.1; executing 2.0.1; fastjsonschema NA; fqdn NA; h5py 3.11.0; idna 3.4; ipykernel 6.29.3; isoduration NA; jedi 0.19.1; jinja2 3.1.3; joblib 1.4.0; json5 0.9.25; jsonpointer 2.1; jsonschema 4.21.1; jsonschema_specifications NA; jupyter_events 0.10.0; jupyter_server 2.14.0; jupyterlab_server 2.26.0; kiwisolver 1.4.5; legacy_api_wrap NA; llvmlite 0.42.0; markupsafe 2.1.5; matplotlib 3.8.4; mpl_toolkits NA; natsort 8.4.0; nbformat 5.10.4; numba 0.59.1; numexpr 2.8.7; numpy 1.26.4; overrides NA; packaging 23.1; pandas 2.2.1; parso 0.8.4; pickleshare 0.7.5; platformdirs 3.10.0; prometheus_client NA; prompt_toolkit 3.0.42; psutil 5.9.8; pure_eval 0.2.2; pydev_ipython NA; pydevconsole NA; pydevd 2.9.5; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.17.2; pyparsing 3.1.2; pythoncom NA; pythonjsonlogger NA; pytz 2024.1; pywin32_system32 NA; pywintypes NA; referencing NA; requests 2.31.0; rfc3339_validator 0.1.4; rfc3986_validator 0.1.1; rpds NA; ruamel NA; scipy 1.13.0; send2trash NA; session_info 1.0.0; six 1.16.0; sklearn 1.4.2; sniffio 1.3.1; socks 1.7.1; stack_data 0.6.2; threadpoolctl 3.4.0; tornado 6.4; traitlets 5.14.3; uri_template NA; urllib3 1.26.18; wcwidth 0.2.13; webcolors 1.13; websocket 1.7.0; win32api NA; win32com NA; win32con NA; win32trace NA; winerror NA; yaml 6.0.1; zmq 26.0.2; -----; IPython 8.22.2; jupyter_client 8.6.1; jupyter_core 5.7.2; jupyterlab 4.1.6; notebook 7.1.3; -----; Python 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]; Windows-10-10.0.22631-SP0; -----; Session information updated at 2024-04-24 08:28; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3028:3943,update,updated,3943,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028,1,['update'],['updated']
Deployability,<details>; <summary>Installed scanpy on jupyter notebook/ anaconda: </summary>. ```; pip install scanpy. Requirement already satisfied: scanpy in c:\users\charles\anaconda3\lib\site-packages (1.7.2); Requirement already satisfied: numba>=0.41.0 in c:\users\charles\anaconda3\lib\site-packages (from scanpy) (0.44.1); Requirement already satisfied: tables in c:\users\charles\anaconda3\lib\site-packages (from scanpy) (3.7.0); Requirement already satisfied: anndata>=0.7.4 in c:\users\charles\anaconda3\lib\site-packages (from scanpy) (0.7.6); Requirement already satisfied: legacy-api-wrap in c:\users\charles\anaconda3\lib\site-packages (from scanpy) (1.2); Requirement already satisfied: packaging in c:\users\charles\anaconda3\lib\site-packages (from scanpy) (21.3); Requirement already satisfied: pandas>=0.21 in c:\users\charles\anaconda3\lib\site-packages (from scanpy) (1.3.4); Requirement already satisfied: scipy>=1.4 in c:\users\charles\anaconda3\lib\site-packages (from scanpy) (1.7.3); Requirement already satisfied: umap-learn>=0.3.10 in c:\users\charles\anaconda3\lib\site-packages (from scanpy) (0.5.1); Requirement already satisfied: h5py>=2.10.0 in c:\users\charles\anaconda3\lib\site-packages (from scanpy) (2.10.0); Requirement already satisfied: scikit-learn>=0.21.2 in c:\users\charles\anaconda3\lib\site-packages (from scanpy) (1.0.2); Requirement already satisfied: statsmodels>=0.10.0rc2 in c:\users\charles\anaconda3\lib\site-packages (from scanpy) (0.13.0); Requirement already satisfied: matplotlib>=3.1.2 in c:\users\charles\anaconda3\lib\site-packages (from scanpy) (3.5.1); Requirement already satisfied: numpy>=1.17.0 in c:\users\charles\anaconda3\lib\site-packages (from scanpy) (1.21.5); Requirement already satisfied: seaborn in c:\users\charles\anaconda3\lib\site-packages (from scanpy) (0.11.2); Requirement already satisfied: tqdm in c:\users\charles\anaconda3\lib\site-packages (from scanpy) (4.62.3); Requirement already satisfied: natsort in c:\users\charles\an,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2173#issuecomment-1063704626:20,Install,Installed,20,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2173#issuecomment-1063704626,2,"['Install', 'install']","['Installed', 'install']"
Deployability,<details>; <summary>pip list</summary>. ```; anndata 0.7.8; asttokens 2.0.5; bcrypt 3.2.0; Bottleneck 1.3.2; brotlipy 0.7.0; cached-property 1.5.2; certifi 2021.10.8; cffi 1.15.0; charset-normalizer 2.0.12; chart-studio 1.1.0; click 8.0.4; cmake 3.22.2; colorama 0.4.4; conda 4.11.0; conda-package-handling 1.7.3; cryptography 36.0.1; cycler 0.11.0; Cython 0.29.20; devtools 0.8.0; dunamai 1.9.0; executing 0.8.2; fa2 0.3.5; Fabric 1.6.1; fonttools 4.29.1; get_version 3.5.4; h5py 3.6.0; idna 3.3; igraph 0.9.9; install 1.3.5; joblib 1.1.0; kiwisolver 1.3.2; legacy-api-wrap 1.2; llvmlite 0.38.0; loom 0.0.18; loompy 3.0.6; mamba 0.15.3; matplotlib 3.5.1; mkl-fft 1.3.1; mkl-random 1.2.2; mkl-service 2.4.0; MulticoreTSNE 0.1; natsort 8.1.0; networkx 2.6.3; numba 0.55.1; numexpr 2.8.1; numpy 1.21.2; numpy-groupies 0.9.14; opt-einsum 3.3.0; packaging 21.3; pandas 1.4.1; paramiko 2.9.2; patsy 0.5.2; Pillow 9.0.1; pip 21.2.4; plotly 5.6.0; pycosat 0.6.3; pycparser 2.21; PyNaCl 1.5.0; pynndescent 0.5.6; pyOpenSSL 22.0.0; pyparsing 3.0.7; PyQt5 5.12.3; PyQt5_sip 4.19.18; PyQtChart 5.12; PyQtWebEngine 5.12.1; pyro-api 0.1.2; pyro-ppl 1.8.0; pysam 0.18.0; PySocks 1.7.1; python-dateutil 2.8.2; pytz 2021.3; requests 2.27.1; retrying 1.3.3; ruamel-yaml-conda 0.15.80; scanpy 1.7.0rc1; scikit-learn 1.0.2; scipy 1.7.3; seaborn 0.11.2; setuptools 58.0.4; sinfo 0.3.4; six 1.16.0; statsmodels 0.13.2; stdlib-list 0.8.0; tables 3.7.0; tenacity 8.0.1; texttable 1.6.4; threadpoolctl 3.1.0; torch 1.10.2; tornado 6.1; tqdm 4.62.3; umap-learn 0.4.6; unicodedata2 14.0.0; urllib3 1.26.8; velocyto 0.17.17; wheel 0.37.1; xlrd 1.2.0; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2169#issuecomment-1062402318:512,install,install,512,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169#issuecomment-1062402318,1,['install'],['install']
Deployability,"<samp>; <b>Supported commands</b><br>; <ul type=""none""><li><b>help:</b></li><ul type=""none""><li>Get descriptions, examples and documentation about supported commands</li><li><b>Example: </b>help ""command_name""</li></ul><li><b>list:</b></li><ul type=""none""><li>List all pipelines for this repository using a comment.</li><li><b>Example: </b>""list""</li></ul><li><b>run:</b></li><ul type=""none""><li>Run all pipelines or specific pipelines for this repository using a comment. Use this command by itself to trigger all related pipelines, or specify specific pipelines to run.</li><li><b>Example: </b>""run"" or ""run pipeline_name, pipeline_name, pipeline_name""</li></ul><li><b>where:</b></li><ul type=""none""><li>Report back the Azure DevOps orgs that are related to this repository and org</li><li><b>Example: </b>""where""</li></ul></ul><br>; See <a href=""https://go.microsoft.com/fwlink/?linkid=2056279"">additional documentation.</a>; </samp>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1398#issuecomment-738558280:269,pipeline,pipelines,269,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1398#issuecomment-738558280,5,['pipeline'],['pipelines']
Deployability,<samp>; Azure Pipelines successfully started running 1 pipeline(s).<br>. </samp>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1398#issuecomment-738554080:14,Pipeline,Pipelines,14,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1398#issuecomment-738554080,30,"['Pipeline', 'pipeline']","['Pipelines', 'pipeline']"
Deployability,"=flags, locals=self.locals,; 157 pipeline_class=self.pipeline_class); 158 # Check typing error if object mode is used; 159 if cres.typing_error is not None and not flags.enable_pyobject:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:693, in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class); 669 """"""Compiler entry point; 670 ; 671 Parameter; (...); 689 compiler pipeline; 690 """"""; 691 pipeline = pipeline_class(typingctx, targetctx, library,; 692 args, return_type, flags, locals); --> 693 return pipeline.compile_extra(func). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:429, in CompilerBase.compile_extra(self, func); 427 self.state.lifted = (); 428 self.state.lifted_from = None; --> 429 return self._compile_bytecode(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:497, in CompilerBase._compile_bytecode(self); 493 """"""; 494 Populate and run pipeline for bytecode input; 495 """"""; 496 assert self.state.func_ir is None; --> 497 return self._compile_core(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:476, in CompilerBase._compile_core(self); 474 self.state.status.fail_reason = e; 475 if is_final_pipeline:; --> 476 raise e; 477 else:; 478 raise CompilerError(""All available pipelines exhausted""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:463, in CompilerBase._compile_core(self); 461 res = None; 462 try:; --> 463 pm.run(self.state); 464 if self.state.cr is not None:; 465 break. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:353, in PassManager.run(self, state); 350 msg = ""Failed in %s mode pipeline (step: %s)"" % \; 351 (self.pipeline_name, pass_desc); 352 patched_exception = self._patch_error(msg, e); --> 353 raise patched_exception. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2191:6310,pipeline,pipeline,6310,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191,1,['pipeline'],['pipeline']
Deployability,> * Either upgrade Scanpy to 1.10 (this PR has the fix for your problem): [matplotlib 3.7 compat #2414](https://github.com/scverse/scanpy/pull/2414); > * or upgrade Matplotlib to 3.8. My Anaconda prompts that I can't install Scanpy above 1.10 or Matplotlib above 3.8.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3029#issuecomment-2077224770:11,upgrade,upgrade,11,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029#issuecomment-2077224770,3,"['install', 'upgrade']","['install', 'upgrade']"
Deployability,"> * Shouldn't `var_df` should get similar updates to `obs_df`?. I would suggest a different PR to address this. . > * Could we get tests for `get.obs_df`/ `get.var_df` for the issues you addressed here (repeated indices)?. Sure, I added new tests to `get.obs_df` to check duplicated keys.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1583#issuecomment-765255875:42,update,updates,42,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1583#issuecomment-765255875,1,['update'],['updates']
Deployability,"> . No spesific reason, I just use the one come pre-installed. Thank you anyways.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2208#issuecomment-1089099688:52,install,installed,52,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2208#issuecomment-1089099688,1,['install'],['installed']
Deployability,> 1. Release note please. I'll do so. > 2. Why do we have `N_PCS` in the settings? Wasn't aware of that actually. I don't know I just came across this while working on RSC and thought the behavior was not what I expected. I hope that this is more in line with what the user intended.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2610#issuecomment-1677075979:5,Release,Release,5,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2610#issuecomment-1677075979,1,['Release'],['Release']
Deployability,"> 1302943; Using cached numba-0.56.4.tar.gz (2.4 MB); Added numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) to build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'; Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba; Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q; Running command python setup.py egg_info; Traceback (most recent call last):; File ""<string>"", line 2, in <module>; File ""<pip-setuptools-caller>"", line 34, in <module>; File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 51, in <module>; _guard_py_ver(); File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 48, in _guard_py_ver; raise RuntimeError(msg.format(cur_py, min_py, max_py)); RuntimeError: Cannot install on Python version 3.11.0; only versions >=3.7,<3.11 are supported.; error: subprocess-exited-with-error; ; × python setup.py egg_info did not run successfully.; │ exit code: 1; ╰─> See above for output.; ; note: This error originates from a subprocess, and is likely not a problem with pip.; full command: /Users/dang/opt/miniconda3/envs2/test/bin/python3.11 -c '; exec(compile('""'""''""'""''""'""'; # This is <pip-setuptools-caller> -- a caller that pip uses to run setup.py; #; # - It imports setuptools before invoking setup.py, to enable projects that directly; # import from `distutils.core` to work with newer packaging standards.; # - It provides a clear error message when setuptools is not installed.; # - It sets `sys.argv[0]` to the underlying `setup.py`, when invoking `setup.py` so; # setu",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209:2439,install,install-,2439,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209,1,['install'],['install-']
Deployability,"> 132 a.draw(renderer); 133 else:; 134 # Composite any adjacent images together; 135 image_group = []. File ~/anaconda3/envs/ml/lib/python3.9/site-packages/matplotlib/artist.py:51, in allow_rasterization.<locals>.draw_wrapper(artist, renderer, *args, **kwargs); 48 if artist.get_agg_filter() is not None:; 49 renderer.start_filter(); ---> 51 return draw(artist, renderer, *args, **kwargs); 52 finally:; 53 if artist.get_agg_filter() is not None:. File ~/anaconda3/envs/ml/lib/python3.9/site-packages/mpl_toolkits/mplot3d/axes3d.py:485, in Axes3D.draw(self, renderer); 480 # Calculate projection of collections and patches and zorder them.; 481 # Make sure they are drawn above the grids.; 482 zorder_offset = max(axis.get_zorder(); 483 for axis in self._get_axis_list()) + 1; 484 for i, col in enumerate(; --> 485 sorted(self.collections,; 486 key=do_3d_projection,; 487 reverse=True)):; 488 col.zorder = zorder_offset + i; 489 for i, patch in enumerate(; 490 sorted(self.patches,; 491 key=do_3d_projection,; 492 reverse=True)):. File ~/anaconda3/envs/ml/lib/python3.9/site-packages/mpl_toolkits/mplot3d/axes3d.py:471, in Axes3D.draw.<locals>.do_3d_projection(artist); 458 """"""; 459 Call `do_3d_projection` on an *artist*, and warn if passing; 460 *renderer*.; (...); 464 *renderer* and raise a warning.; 465 """"""; 467 if artist.__module__ == 'mpl_toolkits.mplot3d.art3d':; 468 # Our 3D Artists have deprecated the renderer parameter, so; 469 # avoid passing it to them; call this directly once the; 470 # deprecation has expired.; --> 471 return artist.do_3d_projection(); 473 _api.warn_deprecated(; 474 ""3.4"",; 475 message=""The 'renderer' parameter of ""; 476 ""do_3d_projection() was deprecated in Matplotlib ""; 477 ""%(since)s and will be removed %(removal)s.""); 478 return artist.do_3d_projection(renderer). File ~/anaconda3/envs/ml/lib/python3.9/site-packages/matplotlib/_api/deprecation.py:431, in delete_parameter.<locals>.wrapper(*inner_args, **inner_kwargs); 421 deprecation_addendum = (; 422 f""I",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2285:8475,patch,patches,8475,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2285,1,['patch'],['patches']
Deployability,"> 2. Have the info in notebook. I think I'd be happy to recommend calling `session_info` directly for this. IIRC, we have these functions at all because a package which did a good job of displaying the imported packages and dependencies didn't really exist. . > and leave print_versions unchanged?. With the update to use `session_info`?. I'd even be fine to deprecate the `file` argument, since it's not super useful. Plus `session_info` provides this, right?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2089#issuecomment-998063447:308,update,update,308,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2089#issuecomment-998063447,1,['update'],['update']
Deployability,"> 4\. Small differences in the edge weights of the nearest neighbor graph CAN lead to huge differences in the UMAP projection if the graph has no inherent structure. Exactly this! We have come across the difficulty of exactly reproducing the umap and clustering results in our [single-cell tutorial/best practices](www.github.com/theislab/single-cell-tutorial), however it was always due to the difficulty of defining boundaries in a continuous phenotype. Essentially, that means that the biological interpretations should not rely on this moving boundary anyway. On another note, you may have more luck with reproducibility by setting `PYTHONHASHSEED` as well. Check out the discussion here: #313.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1009#issuecomment-578344362:434,continuous,continuous,434,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1009#issuecomment-578344362,1,['continuous'],['continuous']
Deployability,"> ; > ; > I had a same issue; > ; > My environment is; > ; > ```; > windows10; > python3.8.8 (conda env); > ```; > ; > scanpy installation; > `conda install -c conda-forge -c bioconda scanpy`; > ; > It looks work well on command prompt, but it wasn't work on jupyterlab(3.0); > ; > To solve this, I just installed all packages using pip, not conda.; > here is my install procedure; > ; > ```; > conda create -n test python=3.8; > pip install ipykernel; > pip install jupyterlab; > pip install scanpy; > pip install python-igraph; > pip install leidenalg; > pip install fa2; > ```; > ; > I tired a lot of install and environment combination, but always there was a problem with conda. Thanks! my scanpy was working but stopped reinstalling everything in a new environment again with pip got it working as you suggested",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/454#issuecomment-814972872:126,install,installation,126,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454#issuecomment-814972872,11,['install'],"['install', 'installation', 'installed']"
Deployability,"> ; > ; > Seen this recently exactly on a windows laptop. Not sure but sound like something messed up with the environment, are you working on the base env? Try creating a fresh conda environment and installing scanpy there. Thanks for the suggestion, @giovp. Was doing it in the base env earlier. Made a new env and tried it again, but ran into the same exact error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1147#issuecomment-609495323:200,install,installing,200,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147#issuecomment-609495323,1,['install'],['installing']
Deployability,"> > @giovp looking at this again, it seems you drop the mixed up columns anyway ([scverse/squidpy@`fb069de`/squidpy/read/_read.py#L100](https://github.com/scverse/squidpy/blob/fb069ded7515e8a1386224d32344a8657cbecd2e/squidpy/read/_read.py#L100)) so I'd suggest having one code path with the correct column names. Please let me know if you need more clarity and help getting this over the hump for release.; > ; > Hi @stephenwilliams22 ,; > ; > we drop it from obs since we don't want to save spatial coordinates there, cause they should be only in obsm.; > ; > So the only changes between space rangers version is the name of the tissue position file correct? but the order of the columns remains the same?. Yes, this is correct.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2296#issuecomment-1273309536:397,release,release,397,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2296#issuecomment-1273309536,1,['release'],['release']
Deployability,"> > Sorry for late reply, I think this was fixed in #1138. Could you update your scanpy and try again? For me it seems to work; > > ```python; > > fig, ax = plt.subplots(1,3, figsize=(20,6)); > > sc.pl.spatial(adata, img_key=""hires"", color=""array_row"", size=1.5, ax=ax[0], show=False); > > sc.pl.spatial(bdata, img_key=""hires"", color=""array_row"", size=1.5, ax=ax[1], show=False); > > sc.pl.spatial(cdata, img_key=""hires"", color=""array_row"", size=1.5, ax=ax[2], show=False); > > plt.tight_layout(pad=3.0); > > plt.show(); > > ```; > > ; > > ; > > ; > > ; > > ; > > ; > > ; > > ; > > ; > > ; > > ; > > ![image](https://user-images.githubusercontent.com/25887487/79438766-41165b80-7fd4-11ea-8ed7-f297b22da7c0.png); > ; > Hello, I have a problem, that is why some plots show colorbar but other plots show legend? It seems using same code. I've got the reason: if the data type is category, sc.pl.spetial would append lengend, in others conditon it would append colorbar.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1158#issuecomment-1454702754:69,update,update,69,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1158#issuecomment-1454702754,1,['update'],['update']
Deployability,> > Why have separate package registries for biology vs everything else?; >; > probably because bioconda predates conda-forge?. That would make sense! I think things like bioconda and the bioconductor registry were good things to start and have been very important. I just think some of the initial design decisions are now outdated. > The only downside of this is that we need to update that file manually for every release of scanpy/ anndata. Seems github action-able?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2281#issuecomment-1160598574:381,update,update,381,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281#issuecomment-1160598574,2,"['release', 'update']","['release', 'update']"
Deployability,"> > what about `X_coords` ?; > ; > Ha, I was mostly just trying to get rid of the `X_`! . ah right, anyway good for me!; > ; > > What about re-open the theislab/spatial branch and merge this PR there? I could then work on how to handle the new uns structure in the plotting functions and have a definitive version of multiple slices support in anndata.; > ; > I'd like to merge the changes currently in this PR to master since it fixes a bug with dataset reading. The changes to uns structure could go in another PR, but I'm waiting for an email back from 10x to make sure using the `library_id` as a key makes sense. Either way, the logic of getting the transformed coordinates etc. should be abstracted into a function so it's easy to change.; > . What do you mean by transformed coordinates? Also, to understand the inputs for anndata (output of spaceranger) you might have a look at this, if you are not already familiar with https://support.10xgenomics.com/spatial-gene-expression/software/pipelines/latest/output/overview. ; Also, ok for having `uns` changes in another PR, I can work on that as soon as this is merged.; > Update: heard back, the `library_id` should be fine, at least for this version.; > . good !. > > support for multiple slices should be first; > ; > I'm not sure I'm convinced of this. I've also already got some code ready to go for the connectivities and some examples of what can be done with it.; > ; > I'd like to hear what kind of stuff you want to be able to do with multiple slices. Are you interested in stitching together slides or holding arbitrary slides in an AnnData? I think I'd like to see a more fleshed out idea of what kinds of analysis could be done here before deciding on what kind of an API this should have, and cases we should be ready to handle.; > . support for multiple slices and concatenation of anndata objects is by far the priority to me. It's a really useful functionality since:; * most people don't work with one slide; * having the same ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1088#issuecomment-596965855:995,pipeline,pipelines,995,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1088#issuecomment-596965855,1,['pipeline'],['pipelines']
Deployability,> @Zethson See my comment above. You have a version mismatch between igraph and leidenalg. Use the latest of both. I know. The issue is that `poetry update` defaults to this combination in my environment for pertpy. I'll probably have to set minimum requirements. Thanks nevertheless!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2341#issuecomment-1641903565:149,update,update,149,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2341#issuecomment-1641903565,1,['update'],['update']
Deployability,"> @Zethson re your comment ([#2028 (comment)](https://github.com/theislab/scanpy/pull/2028#issuecomment-956365435)), what were you thinking for a patch?; > ; > Disallowing `0.5.2`? Or make a fix for that version?. Well, I'd accept the [PR](https://github.com/theislab/scanpy/pull/2028) that fixes this. It's targeted enough and I am happy to see people contributing.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2026#issuecomment-959063737:146,patch,patch,146,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2026#issuecomment-959063737,1,['patch'],['patch']
Deployability,"> @awnimo , for me test_phenograph.py fails with `E TypeError: Expected list, got numpy.ndarray`.; > Could you check please?; > This is certainly related to scipy 1.5. With scipy 1.4 the test works fine. Indeed, this error is related to scipy, and we have fixed that in Phenograph new release [1.5.7](https://github.com/dpeerlab/PhenoGraph#version-157). The `test_phenograph.py` does not fail with the new Phenograph release (`pip install -U phenograph`)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1080#issuecomment-703773746:285,release,release,285,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1080#issuecomment-703773746,3,"['install', 'release']","['install', 'release']"
Deployability,"> @flying-sheep mentioned this was known and already fixed though?. I meant the other breakage due to the scipy update, sorry. > We could have blacklisted sklearn versions 0.21.0 and 0.21.1 if it was known, no?. We should do that now. We can do `sklearn >= 0.19.1, != 0.21.0, != 0.21.1` I think.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/654#issuecomment-494706587:112,update,update,112,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/654#issuecomment-494706587,1,['update'],['update']
Deployability,"> @flyingsheep I can assure you, that's the normal case in academic HPC systems. I agree that this is a huge and common problem in many HPC systems. I usually install conda and R packages to non-home directories with bigger space to avoid issues on servers. One can fill up hundreds of MB by just installing a single package e.g. human genome from Bioconductor 😄 . > Do you have a user home? Is there a canonical cache directory outside of the user home? Is there a way to detect that we are on such a system or a environment variable pointing to the canonical cache directory?. There is a user home and the cache is `~/.cache` and $XDG_CACHE_HOME is undefined (at least in my case). Some pip wheel files are there for example. . Although it's painful to work in such systems, I believe it's user's responsibility to fix this. One idea might be to print a warning when the cache directory is created for the first time along with the path itself to inform the user about where files are.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/558#issuecomment-476797878:159,install,install,159,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-476797878,2,['install'],"['install', 'installing']"
Deployability,"> @giovp feel free to approve and merge. One request first:; > ; > Can this get a release note?. for sure, @LLehner could you? think he's is on holiday until next week",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2424#issuecomment-1450549756:82,release,release,82,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2424#issuecomment-1450549756,1,['release'],['release']
Deployability,"> @giovp looking at this again, it seems you drop the mixed up columns anyway ([scverse/squidpy@`fb069de`/squidpy/read/_read.py#L100](https://github.com/scverse/squidpy/blob/fb069ded7515e8a1386224d32344a8657cbecd2e/squidpy/read/_read.py#L100)) so I'd suggest having one code path with the correct column names. Please let me know if you need more clarity and help getting this over the hump for release. Hi @stephenwilliams22 ,. we drop it from obs since we don't want to save spatial coordinates there, cause they should be only in obsm. . So the only changes between space rangers version is the name of the tissue position file correct? but the order of the columns remains the same?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2296#issuecomment-1272277275:395,release,release,395,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2296#issuecomment-1272277275,1,['release'],['release']
Deployability,"> @giovp, should this change happen in scanpy or squidpy?. I would make it happen in both and deprecate this function from the next release (as well as all the other spatial).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2296#issuecomment-1272576192:132,release,release,132,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2296#issuecomment-1272576192,1,['release'],['release']
Deployability,"> @hurleyLi, would you mind opening an issue over on umap that you're unable to get a `__version__` from it? It would be nice to have that fixed/ at least tracked down upstream. Figure it out. In my case it's because I have both `umap` and `umap-learn` installed, see here: https://github.com/theislab/scanpy/issues/2045#issuecomment-963533994",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1978#issuecomment-963537478:253,install,installed,253,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1978#issuecomment-963537478,1,['install'],['installed']
Deployability,"> @ktpolanski I re-created a new conda env and installed scanpy so now it's working. I'm still not sure where the problem lies, though I did realize it starts jumping error after I install another package called stereopy, I'm guessing maybe that package updated something which got in conflict with normal scanpy setting. https://github.com/BGIResearch/stereopy/blob/6345d2732772a58d60351e790058bd5da1301fb5/requirements.txt#L26",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2297#issuecomment-1452144253:47,install,installed,47,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297#issuecomment-1452144253,3,"['install', 'update']","['install', 'installed', 'updated']"
Deployability,"> @macros29 try `pip install anndata --force-reinstall` then import your packages again and try saving. That indeed solved it! Thanks alot, @shayanhoss ! Although I still don't know what caused the issue in the first place exactly.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/515#issuecomment-469502578:21,install,install,21,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/515#issuecomment-469502578,1,['install'],['install']
Deployability,"> @pinin4fjords the tests aren't running since scrublet isn't actually being installed (I'm surprised the build still worked, apparently this is just a warning?). From the travis logs:; > You'll need to add a scrublet entry to `extras_require` here:. Ahh, I see- thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1476#issuecomment-734715153:77,install,installed,77,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476#issuecomment-734715153,1,['install'],['installed']
Deployability,"> After #1156 I will update the function. Wait, does it use OR logic now?? Doesn't AND logic make more sense???",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1213#issuecomment-696776848:21,update,update,21,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1213#issuecomment-696776848,1,['update'],['update']
Deployability,"> Ah I think I see the issue! Feature branches should be based off `master` and directing the pull request there! I think what's happening is that a pre-commit hook was installed, but the config only exists on the `master` branch.; > ; > I think this should largely be manageable by rebasing onto master (e.g. `git rebase --onto master 1.7.x`) and changing the branch the PR is targeting via the github interface:. Thanks a lot, I rebased and changed the PR target to `master` so I hope everything is on track now! ; The pre-commit style checks were working as expected now (auto-edits only in the files / parts I edited). > Side note: We're considering separating the highly_variable_genes interface into multiple functions, since the arguments to the different methods don't always overlap in meaningful or intuitive ways. There's nothing you need to do about this right now, but just a heads up to keep the logic for this method separate from the main function. Sounds good!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1715#issuecomment-795469189:169,install,installed,169,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715#issuecomment-795469189,1,['install'],['installed']
Deployability,> Any update?. I tried that but it's still giving me exactly the same tree : (,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/637#issuecomment-496025833:6,update,update,6,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/637#issuecomment-496025833,1,['update'],['update']
Deployability,"> As you can see, it's a pretty trivial wrapper anyway. Yes, makes sense. > Determining which affinity kernel to use would then be as simple as looking into adata.uns to find which parameter value sc.pp.neighbors was called with. Yes, I like this. > I added exaggeration=None, as is the default in openTSNE. But setting it to 1 instead of None is better, and I should change that in the next release. Ah, right, I somehow overlooked that you did add the exaggeration parameter. That's fine then!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1561#issuecomment-753621515:392,release,release,392,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561#issuecomment-753621515,1,['release'],['release']
Deployability,"> Awesome, Gokcen, thank you! 😁; >. Thank you!; ; > Also, adding an export utility for Gephi was on the list already before. Cool that you found a simple solution for this.; > . Ah ok, didn't know that. Here is what I used so far for gephi:. ```python; # python-igraph from master branch is required; # see https://github.com/igraph/python-igraph/issues/115; from igraph.remote.gephi import GephiConnection, GephiGraphStreamer. sc.tl.draw_graph(adata); # would be also nice have access to igraph object right after sc.tl.draw_graph; g = sc.utils.get_igraph_from_adjacency(adata.uns['data_graph_norm_weights']). # then install latest Gephi and the streaming plugin:; # https://gephi.org/plugins/#/plugin/graphstreaming; # and start the Gephi master server; streamer = GephiGraphStreamer(); conn = GephiConnection(workspace=1). # igraph cannot serialize numpy float32 to json, so it must be converted to float64; g.es['weight'] = [float(x) for x in g.es['weight']]; g.vs['groups'] = adata.obs['louvain_groups'].tolist(); streamer.post(g, conn); ```. Here is the Yifan Hu layout for 3K PBMC:. ![image](https://user-images.githubusercontent.com/1140359/34961174-384c5658-fa0c-11e7-8597-db4e77cbf4e3.png)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/68#issuecomment-357787075:618,install,install,618,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/68#issuecomment-357787075,1,['install'],['install']
Deployability,"> Bumping matplotlib needs updating of google Colab's default matplotlib. As Colab imports matplotlib on start-up this means you have to restart the runtime after installing scanpy. For production I think it's fine, tutorials would require to restart after installing scanpy. You can see this behavior in scverse tutorials using Colab, e.g. https://docs.scvi-tools.org/en/stable/tutorials/notebooks/api_overview.html. Noted!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2208#issuecomment-1089886547:163,install,installing,163,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2208#issuecomment-1089886547,2,['install'],['installing']
Deployability,"> But I actually don't see any docs there, I don't know why it doesn't find the original docstring... That’s because on readthedocs, bbknn isn’t installed, so it uses the dummy version. > We'd like to have the reference to @ktpolanski preprint in the docstring in the first line together with a short summary of what it does and how it does it, just as for any other function. We could do that either by adding a docstring to the dummy version that links to https://bbknn.rtfd.io or by installing bbknn on rtd, and modifying the docstring programmatically. something like:. ```py; try:; from bbknn import bbknn; first_para, rest = bbknn.__doc__.split('\n\n', 1); bbknn.__doc__ =; '{}\n\nFor a graphical explanation, visit '; '`The bbknn project <https://github.com/Teichlab/bbknn>`__-\n\n{}'; .format(first_para, rest); except ImportError:; ...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/361#issuecomment-439855867:145,install,installed,145,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/361#issuecomment-439855867,2,['install'],"['installed', 'installing']"
Deployability,"> CCA does not have code in python, which will make it difficult to integrate, pySCENIC is probably easier but I would rather ask the developers.; > ; > @falexwolf We should consider a way to facilitate scanpy 'plugins'. A quick search shows me that this could be possible: https://packaging.python.org/guides/creating-and-discovering-plugins/ but honestly I don't know how it works. Nevertheless, given the number of tools that continue to appear we should consider a scheme that facilitate how developers can take advantage of scanpy preprocessing, storing, analysis and visualization tools. Pyscenic has been integrated into scanpy now! Here is the hyper link:; https://github.com/aertslab/pySCENIC/blob/master/notebooks/pySCENIC%20-%20Integration%20with%20scanpy.ipynb",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/265#issuecomment-509063881:68,integrat,integrate,68,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/265#issuecomment-509063881,2,['integrat'],"['integrate', 'integrated']"
Deployability,"> Can we call this epi_sc_expression_atlas instead of expression_atlas?. Definitely agree it's good to specify it's from EBI. Would `ebi_expression_atlas` be alright? `ebi_sc_expression_atlas` feels a little verbose for me. I think it's implied it's single cell, plus it's explicit in the doc-string. > For the time being, can we make this settings.datasetsdir instead of settings.dataset_dir and add it here:. Changed the name. It looks like the main docs aren't being generated from `scanpy/scanpy/api/__init__.py`, but from `docs/api/index.rst` instead. Which is correct?. > Can we point it to the home directory by default, I'd say ~/scanpy-datasets/?. Changed. Does this mean config changes should also happen in this PR? I think this may cause trouble (HPC environments with small `~` allocations) without allowing default configuration at the same time. I had previously figured that setting up a config file could be factored out to a separate PR. To be able to put off adding the config for now, we could temporarily special case a `SCANPY_DATASETDIR` environment variable.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/573#issuecomment-478414057:829,configurat,configuration,829,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/573#issuecomment-478414057,1,['configurat'],['configuration']
Deployability,"> Can we keep the docs on what exactly is happening + how to troubleshoot somewhere in this doc? This means things like: How to tag + build locally, twine check, list contents of distributed file etc. Sure, as we agreed on in person, I’ll just add a section to the end of the document.; If the build process or package structure aren’t touched, doing things manually isn’t necessary. > We should also automate some checks to avoid broken releases. As we agreed in person: Let’s postpone this. E.g. don't allow this except on specific branches + probably turn on merge queue so we know only commits that pass tests + doc builds get to those branches. This PR automatically does `twine check`, which is enough improvement over “trust the person doing the release to do that” to be worth the change, even if it wasn’t for the added convenience!. /edit: all addressed",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2720#issuecomment-1785549678:438,release,releases,438,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2720#issuecomment-1785549678,2,['release'],"['release', 'releases']"
Deployability,> Can you elaborate? You can use `sc.pl.violin` independently. OK I just updated my question and attached a sample image. What I want to do is split-violinplot.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1448#issuecomment-706060383:73,update,updated,73,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1448#issuecomment-706060383,1,['update'],['updated']
Deployability,"> Completely agree, Gökcen!; > ; > How I just thought about dealing with this in the past couple of minutes: could we not make a submodule rtools? We could show the contained wrapper functions on an extra page of the API. All of the dependencies of this would be optional. In effect, this would be a very shallow wrapper that is only interesting for people who already have a working R installation etc. and use Scanpy along with R packages. As there are quite many of these people, this is definitely meaningful.; > . That'd make things a lot easier for many people (including myself 😃), I agree. However. 1) There are (and will be) so many R packages about single cell, so once we open the door, there might be so many requests about these packages so that it'd be difficult to decide what to include and what not to include. The decision might be a bit arbitrary. This is why I suggested a contrib repo, which will have everything users request (as soon as there is someone who is willing to maintain it), in a `use at your own risk` way... 2) There might be several bug reports about rpy2 itself or thin wrappers or R installation or R packages themselves. I was wondering whether this might introduce more maintenance burden, although supported packages will be limited. > The code would still look proper. Implementing tests for these wrappers is maybe not so important as these are only shallow interfaces. It would be easier to have this in the main scanpy repository than setting up a scanpy-contrib: I imagine less people will like to contribute and take the burden of maintaining another repository. PS: anndata is a different story. That's something that is meant to be so basic that it doesn't need a lot of maintenance an contributions.; > ; > What do you think?. Alternatively, we can just prepare jupyter notebooks with some Python 3 and some R cells in it (which is super easy via rpy2 magics anyway) for some R packages/functions like mnn or SIMLR and put those in scanpy_usage as a ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/125#issuecomment-382002901:386,install,installation,386,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/125#issuecomment-382002901,1,['install'],['installation']
Deployability,"> Could any noqas added in this PR get something searchable added to them (like # noqa: {rule} TODO: fix me) so we know why it was added?. The noqas already state what they are ignoring. I for now would not try to differentiate between noqas that we want to keep and noqas that we want to get rid of. We want to get rid of all of them in the follow up issue and only when examining all of them we will figure out which ones we want to keep. > Document how to turn off these checks in dev docs. What do you mean? How to ignore a single line? How to fully ignore whole checks? I would always refer to the flake8 documentation, because it will certainly maintained better than the dev documentation. > Add autopep8 to precommit. If things can be fixed automatically, they should be. autopep8 should be able to get it's rules from the flake8 config. I wish it were that easy. autopep8 does not take its configuration from the flake8 config file nor can it fix all pep8 violations nor do Black and autopep8 always work nicely together. Black is an **opiniated** formatter. It formats consistently, but not necessarily compatible with other tools. I would not add autopep8, since I do not see any further benefit to the Black & flake8 combination, only more potential for issues and confused developers. I agree with your other comments and will take care of them as soon as I got your answers :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1689#issuecomment-787424021:899,configurat,configuration,899,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1689#issuecomment-787424021,1,['configurat'],['configuration']
Deployability,> Could you please add a release note?. Sure; I added it.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3220#issuecomment-2324834604:25,release,release,25,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3220#issuecomment-2324834604,1,['release'],['release']
Deployability,"> Do you think you could make a PR with this to sklearn? I'd like to see the response it gets, and judge based on that. My preference would be for this to go there, but I'm very open to having this in our codebase until it's in a `sklearn` release. I'll try and do that soon. For now, I'll focus on providing you with the benchmarks you requested!. > * Datasets size (one small, one large (>50k cells)); > * Implicit centering, densifying centering, no centering; > * single threaded, multi-threaded <---------. I could not find a `n_jobs` argument in `scanpy.pp.pca`. Can you elaborate a little on the single threaded, multi-threaded bit?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1066#issuecomment-589512273:240,release,release,240,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1066#issuecomment-589512273,1,['release'],['release']
Deployability,> Do you want to add a release note entry?. Added. I believe I got the format right.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2733#issuecomment-1799724990:23,release,release,23,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2733#issuecomment-1799724990,1,['release'],['release']
Deployability,"> Except if you plan to not update the scanpy.api module and docs section. Yes, that's the plan. `scanpy.api` is completely phased out an simply there for backwards compatibility.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/406#issuecomment-450877926:28,update,update,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/406#issuecomment-450877926,1,['update'],['update']
Deployability,"> First, thanks for adding more tests!. Sure thing. Thanks for all the great feedback!. > 1. Is the file `scanpy/tests/_images/scatter_filtered_genes_raw.png` meant to be here?. No, thanks for catching that. > 2. Could the tests be broken up by what they are asserting? I would prefer to break up what is being tested by test case ; rather than values of parameters. Yes, I've broken both of the tests down into multiple tests. > 3. Could we cut down on the number of reference images generated since those cause manual maintenance burden on some matplotlib updates. These reference based tests are not great for confirming the correct plot is output, only that their output is consistent across commits.; > I think some of these cases could instead be tested with `check_same_image`, e.g. where it doesn't matter whether raw is `True` or `None`. Also testing for checking cases where `use_raw=True` would be equivalent to passing `pbmc.raw.to_adata()`. I've cut the number of reference images down to two. I couldn't figure out a clever way to use `check_same_image()` instead of `save_and_compare_images()` for these as you did for the others. See below for comments about individual suggestions.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2027#issuecomment-966240677:558,update,updates,558,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2027#issuecomment-966240677,1,['update'],['updates']
Deployability,"> From my error log it seems the only non-noarch dependency is [h5py](https://beta.mamba.pm/channels/conda-forge/packages/h5py). That’s surprising! I think numba is our most complex dependency, and umap’s dependency PyNNDescent is also compiled. I think if this isn’t a mistake and it’s really just about h5py, we can think about it. Trying to install scanpy and following JupyterLite’s debug instructions gives:. ![image](https://github.com/scverse/scanpy/assets/291575/07a30013-e78d-46af-80fd-fb48af71d45b). ```pytb; ValueError: Can't find a pure Python 3 wheel for: 'umap-learn>=0.3.10', 'session-info', 'numba>=0.41.0'; See: https://pyodide.org/en/stable/usage/faq.html#why-can-t-micropip-find-a-pure-python-wheel-for-a-package; ```. (session-info isn’t a problem, it’s just an old package that doesn’t publish wheels)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2667#issuecomment-1803434731:344,install,install,344,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2667#issuecomment-1803434731,1,['install'],['install']
Deployability,"> Given the file sizes nowadays and the number of ""groups"", this is getting fairly computationally intensive. It's one of those simple things your biologists will love (""this is so fast now!""). I agree it doesn't harm to have `rank_genes_groups` parallelized (given that it should be straightforward to implement). ; What @ivirshup was referring to though, is that `rank_genes_groups` on single cells in general isn't seen anymore as best practice for DE analysis because it doesn't account for pseudoreplication bias. Please take a look at @Zethson's [book chapter](https://www.sc-best-practices.org/conditions/differential_gene_expression.html). . > RE: pertpy; >; > Could does this relate to @davidsebfischer and diffxpy?. Diffxpy is currently being reimplemented. Once it is released, it would likely be included in pertpy as an additional method. I.e. pertpy is more general and strives to provide a consistent interface to multiple methods.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2390#issuecomment-1396521226:779,release,released,779,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2390#issuecomment-1396521226,1,['release'],['released']
Deployability,"> Great, thank you!. hi, did you find the ""merge"" or ""integrate"" commond in scanpy?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/702#issuecomment-527330223:54,integrat,integrate,54,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/702#issuecomment-527330223,1,['integrat'],['integrate']
Deployability,"> Had this problem, followed the `scikit-misc` package [issue](https://github.com/has2k1/scikit-misc/issues/12) on a related problem and installed the recommended patch with; > ; > ```; > pip install -i https://test.pypi.org/simple/ ""scikit-misc==0.2.0rc1""; > ```; > ; > Seems to work now for me. Thank you. It just worked for me, in July 2024.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2073#issuecomment-2231704559:137,install,installed,137,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2073#issuecomment-2231704559,3,"['install', 'patch']","['install', 'installed', 'patch']"
Deployability,"> Hey @ywen1407!; > ; > The ideal case is that you don't pre-filter the gene sets before concatenating. Then, if you have aligned both sets of samples to the same genome, everything should be fine and you can filter out genes afterwards. Otherwise an outer join would only assume all values you filtered out were 0, which is probably not the way forward. That's why the only decent option you really have is an inner join. I assume you should have the unfiltered objects somewhere though.; > ; > Regarding memory use: ComBat is something we (actually, this was thanks to @Marius1311) just re-implemented from python and R code that was flying around. We do not generally optimize methods that were published elsewhere. How much RAM are you using that it's crashing? I think Marius even made ComBat usable for sparse matrices, so it's already using less memory than it was before. 38K cells doesn't sound like something that would require more than 16GB RAM. I can run datsasets with 50k locally. You can of course always try other batch correction/data integration methods that are less memory intensive such as BBKNN or scVI. We tested scalability of data integration tools (also BBKNN and ComBat memory use) here: https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2. However, ComBat is one of the least memory intensive methods out there... so maybe there is little room for optimization here... Thanks for the explanation. I tried concatenating all samples with inner join and it actually went well! The overall number of genes do drop from 45K to around 20K but after preprosessing, the clustering looks OK.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1431#issuecomment-699114229:1053,integrat,integration,1053,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1431#issuecomment-699114229,2,['integrat'],['integration']
Deployability,"> Hey, sorry about the late response!. No worries!. > Would you mind separating out the bug fix and feature addition? That was the bug fix can be released more quickly. OK, will do- see https://github.com/theislab/scanpy/pull/2023, https://github.com/theislab/scanpy/pull/2025. > Question about the main idea here: what kind of batches are you expecting to handle here?; > ; > If they were from completely separate sequencing experiments, would you want to have variable expected doublet rates between batches?; > ; > If the batches are multiple samples that were barcoded and multiplexed, would you want to allow for the possibility of multiplets across batches?. So, really, I just want to be able to follow best practice as per the [Scrublet docs](https://github.com/swolock/scrublet#best-practices), to be able to run Scrublet on cells from different samples separately, perhaps batches is the wrong term. Do you have a preferred alternative, or should I just clarify the help text?. > Could you also merge master into this? CI should be fixed now. Done",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1965#issuecomment-953614277:146,release,released,146,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1965#issuecomment-953614277,1,['release'],['released']
Deployability,"> Hi @ChineseBest, installing the following versions in google colab worked for me: `scanpy==1.7.1 pynndescent==0.4.8 numba==0.51.2`. Ok, thanks. In fact I have already changed to local machine to run it. Thx again.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1951#issuecomment-908462363:19,install,installing,19,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1951#issuecomment-908462363,1,['install'],['installing']
Deployability,"> Hi @JackieMium, I remember you said something similar in another issue.; > ; > If there’s things bugging you, how about making a PR that fixes it?. Not sure what you're referring to but I don't think I ever reported color pallette issue before. ; I hope I could help fix things but I am familiar with R/Seurat and Python/scanpy is a whole new universe to me. I am starting to learning the scanpy pipeline. How things work under the hood with scanpy or basically Python plotting are really beyond my capabilities.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1438#issuecomment-1640521040:398,pipeline,pipeline,398,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1438#issuecomment-1640521040,1,['pipeline'],['pipeline']
Deployability,"> Hi @KabitaBaral1 ,; > You can update it using:; > ; > ```; > pip install --upgrade scanpy; > ```; in conda; ```; conda install -c bioconda scanpy=1.4.6; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1154#issuecomment-613413914:32,update,update,32,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1154#issuecomment-613413914,4,"['install', 'update', 'upgrade']","['install', 'update', 'upgrade']"
Deployability,"> Hi @grimwoo,; > ; > The data integration methods MNN and BBKNN are implemented in scanpy externals, which you can find [here](https://scanpy.readthedocs.io/en/stable/external/index.html#batch-effect-correction). You can also use combat correction, which is a simpler, linear batch effect correction approach implemented as `sc.pp.combat()`. Thanks you so much~",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/702#issuecomment-527391920:31,integrat,integration,31,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/702#issuecomment-527391920,1,['integrat'],['integration']
Deployability,"> Hi @grimwoo,; > ; > The data integration methods MNN and BBKNN are implemented in scanpy externals, which you can find [here](https://scanpy.readthedocs.io/en/stable/external/index.html#batch-effect-correction). You can also use combat correction, which is a simpler, linear batch effect correction approach implemented as `sc.pp.combat()`. sorry to bother you again. ; I want to merge adata001, adata002, and adata003 into adata.combined, with mark ""001"", ""002"", and ""003"" respectively. I looked into the help-information of ""help(combat)"", but still don't know how to do so. In Seurat (R), it can be done like: ; adata001$Sample <- ""001""; adata002$Sample <- ""002""; adata002$Sample <- ""003""; adata.anchors <- FindIntegrationAnchors(object.list = list(adata001, adata002, adata003), dims = 1:11); adata.combined <- IntegrateData(anchorset = adata.anchors, dims = 1:11)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/702#issuecomment-527731457:31,integrat,integration,31,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/702#issuecomment-527731457,2,"['Integrat', 'integrat']","['IntegrateData', 'integration']"
Deployability,"> Hi @ivirshup, I've been meaning to get back to this. I've just started on an AnnData-compatible version of Scrublet which should be easy to hook up to Scanpy. Will keep you posted. Any updates on this?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/173#issuecomment-492312537:187,update,updates,187,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/173#issuecomment-492312537,1,['update'],['updates']
Deployability,"> Hi @rbf22 ,; > what's the issue here?. I’ve updated the issue. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1486#issuecomment-723136057:46,update,updated,46,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1486#issuecomment-723136057,1,['update'],['updated']
Deployability,"> Hi @sygongcode,; > ; > Are you referring to differential expression testing between conditions? You can do that with `sc.tl.rank_genes_groups()` or in a more advanced way using `diffxpy`, which is easily integrated with `scanpy`. You can find it [here](https://github.com/theislab/diffxpy). Yes, that is what I want to do. Thank you so much.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/821#issuecomment-529218989:206,integrat,integrated,206,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/821#issuecomment-529218989,1,['integrat'],['integrated']
Deployability,"> Hi, Just wanted to comment that I had this issue. Converted from Seurat to h5ad using SeuratDisk. `adata.raw.var_names` is different than `adata.var_names`. As a result, I couldn't plot since none of my features were found (keys). Using `use_raw=False` worked. Yep, I have the same problem, if you worked on a Seurat-converted h5ad adata.; Any solutions or updates on this? Or we have to use useRaw=False????",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1406#issuecomment-850250397:359,update,updates,359,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1406#issuecomment-850250397,1,['update'],['updates']
Deployability,"> Hi,; > ; > all things that are not transcriptomics should ideally live in our sister packages such as https://github.com/scverse/muon . If you remove all things related to ATAC-seq in this PR we could consider it, but honestly I think that this might better live outside of scanpy external and much rather in the [scverse ecosystem](https://scverse.org/packages/#ecosystem). Hi,; Thank you for your reply. I could remove the ATAC in the PR, actually, this commit [7f74d8c](https://github.com/scverse/scanpy/pull/2355/commits/7f74d8c47005dd630f691ab5926095f0ff277ce8) is the version without ATAC. Please let me know if this does not work, I will commit another PR.; I think scalex is very suitable to be included in pp.external since it was developed based-on scanpy system, which could provide more choices for scanpy users to do single-cell integration.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2355#issuecomment-1376280885:844,integrat,integration,844,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2355#issuecomment-1376280885,1,['integrat'],['integration']
Deployability,> How did you install scanpy? What conda command did you use?. And I'd appreciate an answer here. Just want to rule out that you used bioconda.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2173#issuecomment-1063428175:14,install,install,14,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2173#issuecomment-1063428175,1,['install'],['install']
Deployability,"> How do we xfail stuff from dev?. [`pytest.mark.xfail`](https://docs.pytest.org/en/6.2.x/reference.html#pytest-mark-xfail) takes a condition:. ```py; xfail_if_dev_tests = pytest.mark.xfail(; os.environ.get(""DEPENDENCIES_VERSION"", ""latest"") == ""pre-release"",; reason=""..."",; ). @xfail_if_dev_tests; def test_xzy(): ...; ```. You probably need to change the tests so it makes the CI variable visible as an env variable, I’m not an Azure expert so I don’t know if it already is. > Codecov, I think, is outright wrong aklthough that might have to do with the failing dev test. Yeah, maybe, let’s see once everything passes. I’m also OK with lowering the percentage, I just set it to 75% to have some indication if codecov is broken or working. (Before it would report 20% for a PR and there would be no visual indication that that’s a problem)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3048#issuecomment-2114691148:249,release,release,249,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048#issuecomment-2114691148,1,['release'],['release']
Deployability,"> Huh. This is really weird, since it looks like it's almost entirely due to scipy sparse indexing. Must have something to do with versions. Two things:; > ; > * If you upgrade scipy, do you still run into this error?; > * Could you get the version info from an environment where you've only imported scanpy and run this command?. I will try to update scipy. Here is the output from only import scanpy:; BTW, everything works fine until I updated scanpy to 1.7.0. ```; anndata 0.7.4; scanpy 1.7.0; sinfo 0.3.1; -----; PIL 7.2.0; anndata 0.7.4; backcall 0.2.0; cairo 1.19.1; cffi 1.14.4; colorama 0.4.3; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; decorator 4.4.2; future_fstrings NA; get_version 2.1; h5py 2.10.0; igraph 0.8.2; ipykernel 5.3.4; ipython_genutils 0.2.0; jedi 0.17.2; joblib 0.16.0; kiwisolver 1.2.0; legacy_api_wrap 1.2; leidenalg 0.8.1; llvmlite 0.34.0; louvain 0.7.0; matplotlib 3.3.1; mkl 2.3.0; mpl_toolkits NA; natsort 7.1.1; numba 0.51.2; numexpr 2.7.1; numpy 1.19.1; packaging 20.8; pandas 1.2.1; parso 0.7.1; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.6; psutil 5.7.2; ptyprocess 0.6.0; pygments 2.6.1; pyparsing 2.4.7; pytz 2020.1; scanpy 1.7.0; scipy 1.4.1; setuptools_scm NA; sinfo 0.3.1; six 1.15.0; sklearn 0.23.2; storemagic NA; tables 3.6.1; texttable 1.6.2; tornado 6.0.4; traitlets 4.3.3; wcwidth 0.2.5; zmq 19.0.2; zope NA; -----; IPython 7.17.0; jupyter_client 6.1.6; jupyter_core 4.6.3; notebook 6.1.3; -----; Python 3.8.2 (default, May 7 2020, 20:00:49) [GCC 7.3.0]; Linux-3.10.0-957.12.2.el7.x86_64-x86_64-with-glibc2.10; 64 logical CPU cores, x86_64; -----; Session information updated at 2021-02-21 23:42; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1670#issuecomment-783075376:169,upgrade,upgrade,169,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1670#issuecomment-783075376,4,"['update', 'upgrade']","['update', 'updated', 'upgrade']"
Deployability,> I am not sure what --add does or -c . The following is probably a cleaner way to install. It should not have any unforeseen 'channels' related side effects.; > ; > This worked for me on MacOS Catalina; > ; > ```; > $ conda create --name SCA python=3.8.2; > (base) $ conda activate SCA; > (SCA) $ conda install scanpy --channel conda-forge --channel bioconda; > ```. That's the only way it worked for me. Thanks! Without creating a virtualenv it just did not move forward.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/990#issuecomment-614315370:83,install,install,83,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/990#issuecomment-614315370,2,['install'],['install']
Deployability,"> I created a new environment (see below for package details) and there everything works as it should. Can you use this new environment to do your analysis?. I expect that the previous environment managed to get into a messy state, which can lead to very strange errors. Because of this, I generally avoid trying to update old environments much and instead opt for creating fresh ones frequently.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1850#issuecomment-848441096:316,update,update,316,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1850#issuecomment-848441096,1,['update'],['update']
Deployability,"> I didn't keep perfect track of the steps that I took to solve this or the exact versions of everything that I used but I'll try outlining what I did.; > ; > First I tried to upgrade numba and umap as suggested by the other individuals in the thread:; > ; > ```shell; > pip install --upgrade numba; > pip install --upgrade umap-learn; > ```; > ; > Then I essentially reinstalled scanpy using the steps in their installation docs.; > ; > ```shell; > conda install seaborn scikit-learn statsmodels numba pytables; > conda install -c conda-forge python-igraph leidenalg; > pip install scanpy; > ```; > ; > I think I then ended up with a version of numpy that was incompatible with numba so I ran; > ; > ```shell; > pip install numpy==1.20; > ```; > ; > After each step, you should be able to run the code from above to check if your installations worked, which I used to pinpoint what still needed work in my environment:; > ; > ```shell; > python3 -c ""import numpy as np; import umap; umap.UMAP().fit_transform(np.random.randn(10_000, 20))""; > ```; > ; > This seemed to fix my problems; I hope it's able to help others!. I followed your instruction but it still threw errors:. <frozen importlib._bootstrap>:219: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject. Segmentation fault",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1567#issuecomment-1063184606:176,upgrade,upgrade,176,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1567#issuecomment-1063184606,11,"['install', 'upgrade']","['install', 'installation', 'installations', 'upgrade']"
Deployability,"> I for now would not try to differentiate between noqas that we want to keep and noqas that we want to get rid of. We want to get rid of all of them in the follow up issue and only when examining all of them we will figure out which ones we want to keep. After this merges new ignore messages can be added for reasons like ""this rule is generally good, but not in this specific case"". Each of these will go through PR review, so will be vetted. The ones added here largely have not been vetted, and are just being added so we don't get a failure. I would like to be able to distinguish between these cases. Once more `noqa` cases are added, it gets more complicated to find cases that haven't been vetted if they don't have some associated label. --------------------------. > What do you mean? How to ignore a single line? How to fully ignore whole checks?. How to disable flake8 errors for a line or file. > I would always refer to the flake8 documentation, because it will certainly maintained better than the dev documentation. A link to the section of the flake8 docs on this would be great. -------------------------. > I wish it were that easy. autopep8 does not take its configuration from the flake8 config file . `autopep8` says it does this: https://github.com/hhatto/autopep8#configuration. > It formats consistently, but not necessarily compatible with other tools. I would like changes that are automatically applicable to be automatically applied. I'm thinking of things like white space in docstrings. Is there another way to automate these you can suggest?. ---------. BTW, I've added a few more points to the checklist above. I would recommend trying to build the package and build the docs in the directory you're working in to see what files get generated so they can be added to the `ignore`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1689#issuecomment-787426782:1180,configurat,configuration,1180,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1689#issuecomment-787426782,2,['configurat'],['configuration']
Deployability,"> I found a workaround that does not require downloading the `.whl` file for `numpy=1.19.5`. By default, MKL is included when you install numpy with conda. It's good to do this in a new environment.; > ; > ```; > conda create -n scanpy_env; > conda activate scanpy_env; > conda install numpy=1.19; > conda install seaborn scikit-learn statsmodels numba pytables; > conda install -c conda-forge python-igraph leidenalg; > pip install scanpy; > ```; > ; > Now I can run `sc.pp.highly_variable_genes()` with no problem. Update: this workaround does not seem to work anymore, at least for scanpy 1.8.2 (you'll need to `pip install scanpy==1.8.1`). ; During `pip install scanpy`, a newer version of numpy is installed and version 1.19 is overwritten. This newer version does not have MKL, leading us back to square one. It's also not possible to `conda install numpy 1.19` as the very last step, because this leads to another error (it's related to the fact that scanpy needs to be compiled with the same version of numpy).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2073#issuecomment-1058514241:130,install,install,130,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2073#issuecomment-1058514241,10,"['Update', 'install']","['Update', 'install', 'installed']"
Deployability,"> I had the exact same issue and error message at that step in the tutorial. I installed scanpy using pip, because installing with conda was not working. Same here. I assume there is some issue with the implementation of the setter of adata.X, which prevents `adata.X = adata.X.toarray()` from updating X to its densified version.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1010#issuecomment-578596689:79,install,installed,79,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1010#issuecomment-578596689,2,['install'],"['installed', 'installing']"
Deployability,"> I had the same issue, and it turns out setting up channels solves the problem as follows:; > ; > ```; > conda config --add channels defaults; > conda config --add channels bioconda; > conda config --add channels conda-forge; > ```; > ; > Ref:; > https://bioconda.github.io/recipes/scanpy/README.html; > https://bioconda.github.io/user/install.html#set-up-channels. Thanks, this also worked for me!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/990#issuecomment-762368917:337,install,install,337,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/990#issuecomment-762368917,1,['install'],['install']
Deployability,"> I have got what I want with the following code adapted from dotplot():; > ; > gene_ids = adata.raw.var.index.values clusters = adata.obs['louvain'].cat.categories obs = adata.raw[:,gene_ids].X.toarray() obs = pd.DataFrame(obs,columns=gene_ids,index=adata.obs['louvain']) average_obs = obs.groupby(level=0).mean() obs_bool = obs.astype(bool) fraction_obs = obs_bool.groupby(level=0).sum()/obs_bool.groupby(level=0).count() average_obs.T.to_csv(""average.csv"") fraction_obs.T.to_csv(""fraction.csv""). Love this! Thanks a lot!! ; Just one question, is there a way to get the average expression in different cell types (cluster label 1 ) in different sample (cluster label 2 ) from an integrated object?? ; to get something roughly like this:. Gene 1 Gene 2 ; sample1 sample2 sample3 sample1 sample2 sample3 ..... ....... ....; T-cell; B-cell ; .....; ..... I am not sure if this makes sense, but I have been trying to do this for a while and nothing worked!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/336#issuecomment-1334674713:681,integrat,integrated,681,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/336#issuecomment-1334674713,1,['integrat'],['integrated']
Deployability,"> I know exactly that in PCA I can interpret a component based on its rank (and/or variance contribution). Ah, I meant more specifically that it may be easier to biologically interpret an ICA. > That would say I should try as many decompositions as possible to see when I get a good result. I'm a little unsure of your meaning here. Do you mean decompositions like decomposition techniques? If so, I don't think this is the right conclusion. I think it means: probably PCA for clustering, probably NMF for finding gene modules. I would also suspect something which finds sparser variable loadings like ICA or NMF could be more robust for cross dataset classification. If you mean, if the results are unstable how do we know which to trust – I did ask that question. I think it's the usual: have a validation dataset, maybe some ensemble/ robustness method, or do some sort of enrichment. It's an open question, but a lot of our analysis pipeline is.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/941#issuecomment-560313033:937,pipeline,pipeline,937,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/941#issuecomment-560313033,1,['pipeline'],['pipeline']
Deployability,"> I know that this will cause a little more headache, but could we consider renaming to `rank_genes`?. Would you not maybe do this in stages with a `DeprecationWarning` first for a couple of releases? This change would break nearly everyone's pipelines and published notebooks. It's not a lot of work to change... but it might warrant a longer warning time.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1156#issuecomment-616525603:191,release,releases,191,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1156#issuecomment-616525603,2,"['pipeline', 'release']","['pipelines', 'releases']"
Deployability,"> I sent you an invitation for readthedocs.com about 2 months ago already - I just resent it. :). Well, doesn’t seem like it worked in the past: What I got now was not an invitation that I needed to click, but simply a notification that I’m now member of the team on rtd.com (which I wasn’t before). The changes look good! I would however prefer to do things via `.. include::` instead of duplicating code for the `scanpy` and `scanpy.api` sections. Except if you plan to not update the `scanpy.api` module and docs section.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/406#issuecomment-450818246:476,update,update,476,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/406#issuecomment-450818246,1,['update'],['update']
Deployability,"> I think we should have a 'cookbook' where we can keep this and other information. I've been trying to be organized about keeping notebooks around for this ([here](https://github.com/ivirshup/notebooks/tree/master/plotting)). Of course, I rarely get the notebooks clean enough to push 😆. > > In the end it's about showing which cells are represented per pixel/pixel bin.; >; > I would argue that this would be fair. In the end it's about showing which cells are represented per pixel/pixel bin. Is it fair if coloring by batch and one dataset had fewer samples? Wouldn't you want to know that multiple batches were showing up in this region? I'm fairly convinced there is no good way to show this in one plot, other than telling users some information is hidden. > We could do a quick fix based on random order for now. I'm trying to think of the simplest way to implement this. I would like to keep the behaviour of `sort_order=False` just using the order from the anndata object. Some options:. * `sort_order=""random""`, this would make the order random, but we might need to add a seed argument. Also, do we still plot over null values?; * `sort_order=order_array` where `order_array: np.ndarray[1, int]`. Basically, the user can pass whatever order they like. For random order it would be `np.random.choice(adata.n_obs, adata.n_obs, repeat=False)`. This is pretty flexible since it allows whatever order you want to be used without sorting the object. > larger update that would have to do with updating scanpy plotting to larger cell numbers?. I think this might be worth a separate package, at least to start out. At least with how I'm handling it now, there would be a large number of dependencies. Plus, I think overplottting like this is an unsolved problem, so freedom to experiment in important.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1263#issuecomment-761745895:1465,update,update,1465,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1263#issuecomment-761745895,1,['update'],['update']
Deployability,"> I want the h5ad file to include absolutely everything, so that it can be simply used as a single file distribute the ""full dataset"". This makes more sense now. In that case however I would say that having just raw counts in `adata.raw.X` is fine, no? In the end you are distributing a data file. You can have your version of the normalized data in a layer... and you would be distributing your analysis code as well, so it's always clear how people should use this data file that is being deposited, no?. > Might be important for integration?. Integration works better with HVGs typically, so I don't think these super lowly expressed genes are so relevant here... I would often go with `min_cells=20` or even `50` for larger datasets. In the end I reason that this value will be approximately related to the size of the smallest unique cellular identity you expect to find. > This does run into memory usage problems if want do a densifying transform on the data. Don't understand this entirely... and not sure what a block sparse matrix type is... but can't you subset sparse matrices based on masks? Should be fairly easy to just skip indices that are not in the mask... although i can imagine it might be slower than doing this on dense matrices. Based on above arguments the main issue I see is currently for the case @gokceneraslan mentioned about MT genes or non-coding genes being stored in `.raw`. In this case you might need these genes also during an analysis pipeline (and not just for data storage), so you would like to have them in a separate ""raw"" container that is otherwise not touched. This clashes with the way raw is used in current scanpy pipeline. I think we could deprecate the way `.raw` is used at the moment, and use a `.layer` for this instead (maybe a designated ""raw"" layer?), but then introduce a new `.frozenraw` or sth like that where just the raw data is stored and it's essentially read-only after assignment?. I would be a bit hesitant to not have a replacement f",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1798#issuecomment-820336449:532,integrat,integration,532,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1798#issuecomment-820336449,2,"['Integrat', 'integrat']","['Integration', 'integration']"
Deployability,> I was facing this issue in 0.7.8. Upgrading to 0.8.0 solved the problem. how did you update? pip says that 0.7.8 is the latest version,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1351#issuecomment-1378202005:87,update,update,87,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351#issuecomment-1378202005,1,['update'],['update']
Deployability,"> I wasn't really expecting this feature PR to also include such a large refactor. It would have been necessary for the Dask Dataframe version. Now I 1. did the work and 2. improved readability, so it would be counter productive to undo it. > I'm still not 100% convinced the behaviour here is exactly the same as before. I have done a few tests, which have been okay, but I haven't tried much parameterization. I'm ~80% convinced the results should be the same. If you have any specific things in mind, you should probably make a PR that adds tests for the properties you think we should preserve. We can then merge that one, update this one, and see if it actually breaks something. I can’t check for speculative differences if I have no idea where those could be. > I would note that the dataframe returned when inplace=False has a different index than it did previously. Yup, now it actually matches instead of discarding the original Index and replacing it with a RangeIndex for no reason. > Apart from the comments, can we get a regression test for ""cell_ranger"" (e.g. generate results with an older version)? I don't think we have one in the test suite. Sure! That’s a concrete thing I can do. I’ll do that on thursday, I did the rest of what you asked today",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2809#issuecomment-1930104931:627,update,update,627,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2809#issuecomment-1930104931,1,['update'],['update']
Deployability,"> I wonder why the tests are not working now?. Sorry, I forgot to update `violin.png` after the latest changes to `_anndata.py`. Let's see if the tests pass now.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1422#issuecomment-696705252:66,update,update,66,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1422#issuecomment-696705252,1,['update'],['update']
Deployability,"> I would also like to see this merge. I've put a lot of time and effort into reviewing it, so we can get this over and done with.; > Your contributions are invaluable to the project, and I'd really like to see you contributing to other things. thank you, I really appreciate this :heart: . > The reason I'm so hard on this is that it's critical to our project (and getting new contributors), and it's a part of the stack I don't understand.; > I think you're the only one on the team who has a lot of understanding of the packaging ecosystem. The practical effect of this is that when things around this break, most of us have no idea what could be going wrong. What we have on master right now pretty much works. We've run into issues before, but it's been a while. Right now it's pretty smooth to set up a dev environment and contribute. Totally understood. My motivation to use flit is that it’s simpler and therefore better both for first-time contributors (to get started) and experienced people (to debug), whereas CLI, metadata, and code of setuptools/pip is very complex and a nightmare to debug. I know that due to flit being used less, there needs to be someone who understands the packaging ecosystem to fix things when they’re broken instead of cargo-culting one of the million answers around setuptools on StackOverflow. > Here's what I propose. I think this can be merged basically as is. However, until these issues are resolved: development installation instructions has to have pip install -e listed, and there has to be a note saying flit -s installations will be overridden due to a bug in pip. This stuff can be removed once this is fixed upstream. OK, will do! Can you link me tp the upstream discussion of this problem please?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1527#issuecomment-787454064:1458,install,installation,1458,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527#issuecomment-787454064,3,['install'],"['install', 'installation', 'installations']"
Deployability,"> I would recommend creating fresh conda environments frequently, especially if you mix `conda` and `pip` installation. Upgrading them in finicky, and often results in a broken state. Creating a new environment and reinstalling everything worked for me. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1567#issuecomment-1063371834:106,install,installation,106,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1567#issuecomment-1063371834,1,['install'],['installation']
Deployability,"> I'd really like to have scanpy and anndata work better with dask, but am wary of a high code overhead. Could you provide examples of where you were running into issues with arrays being materialized?. You can see where the materialization occurs by looking for references to `materialize_as_ndarray` in the existing code. For example, in `filter_genes`: https://github.com/theislab/scanpy/blob/master/scanpy/preprocessing/_simple.py#L215, where the gene subset of materialized as an ndarray, then used to subset the anndata. Contrast this to the optimized version where the materialize step is not needed, and the data remains a dask array throughout the `filter_genes` method: https://github.com/tomwhite/scanpy/blob/sparse-dask/scanpy/preprocessing/_dask_optimized.py#L18. > I think this can be worked around in AnnData side in many cases. That would be great. > Any chance you did any profiling of these runs? I'd be interested in seeing the performance impact across the pipeline. The closest I got to this was using the Dask web UI to watch tasks being run (see this part of the benchmark script: https://github.com/tomwhite/scanpy/blob/sparse-dask/benchmark.py#L54-L55). This is useful to see what operations are bottlenecks. The only timings I did were to run the complete recipe. On the GPU questions, these all sound like promising avenues, but I haven't looked into any of them.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/921#issuecomment-555940037:977,pipeline,pipeline,977,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/921#issuecomment-555940037,1,['pipeline'],['pipeline']
Deployability,"> I'll definitely talk to the admin, but I am not sure he would update. An admin that doesn’t take security risks seriously isn’t doing their job properly. ---. > Jupyter Notebook requires JavaScript. that probably means that Jupyter notebook tries to run lynx or www or sone other text-only browser. `jupyter notebook --no-browser` is correct and the tokens aren’t machine-specific. [I set up stuff differently](https://jupyter-notebook.readthedocs.io/en/stable/public_server.html#automatic-password-setup), but @ivirshup’s setup should work perfectly as well.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/561#issuecomment-477525477:64,update,update,64,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/561#issuecomment-477525477,1,['update'],['update']
Deployability,"> I'm not keen to create and maintain a conda R package. That's fair. Might be worth asking the `conos` developers in this case?. Also, does using `install.packages` within a conda environment work for you? I recall that not working well for me in the past. > I'm guessing this is not what already happens in rpy2?. Nah, `rpy2` even copies the data in a particularly slow way by default.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1068#issuecomment-593263880:148,install,install,148,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1068#issuecomment-593263880,1,['install'],['install']
Deployability,"> I'm not sure how you could get any python setup to install R dependencies for you. Maybe a conda package could include dependencies? I think getting a working environment would alleviate a large pain point for this stuff (for example, I currently have no working Seurat install.). Plus making sure packages are up to date for the wrapped functionality. > you'd have to have a a separate data structure that can move been languages. Sort of. The idea is that you could move arrays to R from python without making any copies, they'd just point to the same memory. This is already possible when passing data from R to python. The main idea is making these wrappers faster and take less memory.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1068#issuecomment-590215132:53,install,install,53,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1068#issuecomment-590215132,2,['install'],['install']
Deployability,"> I'm not sure what t-SNE implementation is currently used in scanpy, but would it make sense to switch it to openTSNE? It's a Cython re-implementation of FIt-SNE, it's available on conda and should be very easy to depend on. We use `MulticoreTSNE` if it's installed, but fall back to `sklearn`. > As far as I understand the scanpy architecture, it builds a kNN graph and then runs downstream analysis. Right now, we tend to use a connectivity graph built by UMAP, but are working on making this more generic. We're thinking about allowing the UMAP embedding to be generated on graphs we provide as well. > 1. switch scanpy to using openTSNE for tSNE, using already constructed kNN graph. I think I'd like to see this. That package is much more actively maintained than our current backend, and looks interesting. I would like it if the TSNE was flexible about the graph that was used. I'm not sure that I'll get to this, but a PR would be welcome. I'd have to see some performance/ results before thinking about changing the defaults, or whether this would go into a major or minor version change. > 2. add tSNE support for ingest using openTSNE functionality. @Koncopd do you have any thoughts on this?. > 3. change default tSNE parameters (n_iter, learning rate, initialization) following openTSNE defaults. Again, I'd have to think about backwards compatibility. Maybe this could start as a `sc.tl.opentsne` function?. > 4. add some tSNE ""recipes"". I'd be interested in this. Skimming that paper now, I really like the idea of showing regions of uncertainty for projection would be very useful. I'd be interested in how these ""recipes"" could be wrapped in a function.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1233#issuecomment-631235395:257,install,installed,257,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233#issuecomment-631235395,1,['install'],['installed']
Deployability,"> I'm not to sure what the assumptions are behind each method though. @falexwolf, any reason in particular you've chosen UMAP's method for the KNN calculation?. It's highly competitive in terms of speed and accuracy with other libraries (https://github.com/erikbern/ann-benchmarks, pynndescent is what umap uses, wasn't available at the time for Scanpy), it's a lot easier to install than everything else, and the result has been shown to harmonize well with UMAP, which I expected would become the canonical way of visualizing things.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/277#issuecomment-427333649:376,install,install,376,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/277#issuecomment-427333649,1,['install'],['install']
Deployability,"> I'm wondering if there might be a jax implementation as I'm a bit more keen on that as a dependency. Probably for another discussion -- I like jax as much as anyone, but it's not nearly as easy to install as pytorch, especially on windows and m1 mac.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2154#issuecomment-1062188081:199,install,install,199,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2154#issuecomment-1062188081,1,['install'],['install']
Deployability,"> If anyone is stuck waiting for the new release, you can edit your `.../lib/python3.7/site-packages/scanpy/tools/_louvain.py` with these changes:; > ; > Add: `partition_kwargs[""seed""] = random_state`; > Remove: `louvain.set_rng_seed(random_state)`; > ; > From:; > [b54d67b](https://github.com/theislab/scanpy/commit/b54d67b9d6b41269c1612df0242210d1279ede85). Thankx this worked",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1191#issuecomment-638817267:41,release,release,41,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1191#issuecomment-638817267,1,['release'],['release']
Deployability,"> If norm is passed along at the same time, an error should be thrown. Following up on this a bit, I realized I didn't actually know what matplotlib would do if you passed `norm` and a bound, so I checked it out. Turns out they currently allow it, but it's deprecated, so throwing an error is the right thing to do. ```python; import vega_datasets; import matplotlib as mpl, matplotlib.pyplot as plt. iris = vega_datasets.data.iris(). norm = mpl.colors.LogNorm(). plt.scatter(; iris[""sepalLength""],; iris[""sepalWidth""],; c=iris[""petalLength""],; norm=norm,; vmin=3,; ); plt.colorbar(); ```. ```; MatplotlibDeprecationWarning: Passing parameters norm and vmin/vmax ; simultaneously is deprecated since 3.3 and will become an error two minor releases ; later. Please pass vmin/vmax directly to the norm when creating it.; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1551#issuecomment-748567569:739,release,releases,739,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551#issuecomment-748567569,1,['release'],['releases']
Deployability,"> If the problem is windows, it's possible it will be solved by numpy 2.0. Not sure how easy the upgrade path to numpy 2.0 will be, however.; > ; > * https://numpy.org/devdocs/numpy_2_0_migration_guide.html#windows-default-integer. I can reproduce the error using Numpy 2.0.2.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2969#issuecomment-2326703284:97,upgrade,upgrade,97,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969#issuecomment-2326703284,1,['upgrade'],['upgrade']
Deployability,"> If we need multiple tools in the same container the place to add it would be [BioContainers/multi-package-containers](https://github.com/BioContainers/multi-package-containers). We do make heavy use of optional dependencies, so this might be the way to go regardless. > Curious to know why and if it's something that can be overcome?. ### Practically. * The documentation for bioconda has been incomplete and out of date for years.; * conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated.; * bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on bioconda all our dependents do too – *this could make it extremely painful to do a migration to bioconda*.; * All of our dependencies are on conda-forge; * Fewer channels to search means easier, faster environment solving. ### More philosophically. Why have separate package registries for biology vs everything else? Code for biology isn't particularly special, much of the tooling/ work here is duplicated effort. Why not just put all of bioconda onto conda-forge, but with a special tag saying they are bio packages? All the extra tooling/ maintenance consortiums can be developed orthogonally to the registry. I think there are very clear problems that come out of separate registries. It was a huge pain to install anything from BioJulia until they deprecated the BioJuliaRegistry. If bioconda didn't use it's own build system there wouldn't be out of date docs for that build system. It just seems like a lot of trouble to go through for unclear benefit. I will admit, I think there were more benefits to this model ~a decade ago. But I think these benefits have been mitigated by significantly improved tooling for developing, building, and distributing packages.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2281#issuecomment-1160555404:489,release,release,489,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281#issuecomment-1160555404,3,"['install', 'release']","['install', 'release']"
Deployability,"> If you have integrated embeddings (such ash X_pca_harmony) those will change every time you add new data. . This isn't always true though, e.g., if you use scArches or seurat (which also seems to use this umap transform). On the other hand, the umap transform visualization can be quite deceiving. It can be the case that it qualitatively appears to have no batch effects even when there definitely has been no integration/correction.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2259#issuecomment-1134250744:14,integrat,integrated,14,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2259#issuecomment-1134250744,2,['integrat'],"['integrated', 'integration']"
Deployability,"> In case anyone has this error again, here is what worked for me:; > ; > * go to https://www.lfd.uci.edu/~gohlke/pythonlibs/ and download a .whl file for h5py. For python 3.6 on a 64bit windows OS this is the file h5py‑2.10.0‑cp36‑cp36m‑win_amd64.whl; > * with your conda environment activated, install that wheel file using `python -m pip install --user --force-reinstall h5py‑2.10.0‑cp36‑cp36m‑win_amd64.whl` (change the file name to the one you downloaded).; > * scanpy should work now; > ; > This worked on mine and also on a colleagues windows laptop.; > ; > I guess the problem is that you need a C++ compiler to build the necessary H5DF libraries. This works fine in UNIX based OS (Mac and Linux), but in windows you would need to download the most recent C++ compiler from some microsoft build tools website or alongside Visual Studio. So installing a prebuildt wheel for windows circumwents that problem. I wonder when h5py people will ever fix this for us poor Windows users. this helped me out as well",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/454#issuecomment-966445217:296,install,install,296,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454#issuecomment-966445217,3,['install'],"['install', 'installing']"
Deployability,"> In case anyone has this error again, here is what worked for me:; > ; > * go to https://www.lfd.uci.edu/~gohlke/pythonlibs/ and download a .whl file for h5py. For python 3.6 on a 64bit windows OS this is the file h5py‑2.10.0‑cp36‑cp36m‑win_amd64.whl; > * with your conda environment activated, install that wheel file using `python -m pip install --user --force-reinstall h5py‑2.10.0‑cp36‑cp36m‑win_amd64.whl` (change the file name to the one you downloaded).; > * scanpy should work now; > ; > This worked on mine and also on a colleagues windows laptop.; > ; > I guess the problem is that you need a C++ compiler to build the necessary H5DF libraries. This works fine in UNIX based OS (Mac and Linux), but in windows you would need to download the most recent C++ compiler from some microsoft build tools website or alongside Visual Studio. So installing a prebuildt wheel for windows circumwents that problem. I wonder when h5py people will ever fix this for us poor Windows users. this is the only way I solve my error. I tried every else except reinstall system.; thx!!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/454#issuecomment-871181214:296,install,install,296,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454#issuecomment-871181214,3,['install'],"['install', 'installing']"
Deployability,"> In which I introduced that convention when helping Laleh to make it more efficient. Cool, I didn't know that! Should have made it a lot more efficient! :smile:. > The convention I know is to return two n × k matrices. Right, this is the default in sklearn. But yes, in the end, we want some sort of adjacency matrix for convenience and direct integration with all the graph stuff.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/441#issuecomment-460070455:345,integrat,integration,345,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/441#issuecomment-460070455,1,['integrat'],['integration']
Deployability,"> Is there a widely used processing pipeline which does not adhere to this file naming?. STARsolo generates cell-ranger compatible output, and when multiple multi-mapper resolution strategies are enabled, it will write multiple matrix.mtx.gz files, with different names. e.g: `STARsolo ... --soloMultiMappers Unique EM PropUnique Rescue Uniform` yields:. ```; barcodes.tsv.gz; features.tsv.gz; matrix.mtx.gz; UniqueAndMult-EM.mtx.gz; UniqueAndMult-PropUnique.mtx.gz; UniqueAndMult-Rescue.mtx.gz; UniqueAndMult-Uniform.mtx.gz; ```. Each of these `*.mtx.gz` files matches the same format as `matrix.mtx.gz` and can be read in the same way. (They all share the `*.tsv.gz` files). . A 3-parameter version of the `read_10x_mtx()` function would be my vote as the most flexible option.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/882#issuecomment-2002523593:36,pipeline,pipeline,36,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/882#issuecomment-2002523593,1,['pipeline'],['pipeline']
Deployability,"> Is there anything like [clustree](https://github.com/lazappi/clustree) in python that integrates nicely with scanpy?. I have resorted to writing a small Rscript that takes a saved adata.h5ad file as input, loads it using `reticulate`, runs Clustree, saves it. I then run the script from a notebook using `invoke.run` from the `invoke` package as a function in a notebook and load the output figure as an image in the notebook. Here is the script I use in case it helps:. ```R. suppressPackageStartupMessages({; library(reticulate); library(SingleCellExperiment); library(glue); library(clustree); }); sc <- import(""scanpy""). args <- commandArgs(trailingOnly = TRUE); H5AD_PATH = args[1]; OUT_PATH = args[2]. print(glue(""H5AD_PATH: {H5AD_PATH}"")); print(glue(""OUT_PATH: {OUT_PATH}"")). load_adata = function(h5ad_path) {; adata <- sc$read_h5ad(h5ad_path). return(adata); }. count_clusterings = function(adata){; # Ryan suggests:; # length(grep(""leiden"",names(adata$obs))). clusterings = c(); for (x in adata$obs_keys()){; if (startsWith(x, ""leiden"")){; clusterings = append(clusterings, x); }; }; ; return(length(clusterings)); }. set_fig_dimensions = function(num_clusterings){; width = 10; height = (0.6 * num_clusterings); ; if (height < 8){; height = 8; }; ; png(width = width, height = height); options(repr.plot.width = width, repr.plot.height = height); ; return(list(width=width,height=height)); }. adata = load_adata(h5ad_path=H5AD_PATH). dims = set_fig_dimensions(num_clusterings = count_clusterings(adata)); # dims. # options(repr.plot.width = 10, repr.plot.height = 10). g = clustree(; x=adata$obs,; prefix=""leiden_"",; # suffix = NULL,; # metadata = NULL,; # count_filter = 0,; # prop_filter = 0.1,; # layout = ""sugiyama"",; # layout = ""tree"",; # use_core_edges = FALSE,; # highlight_core = FALSE,; # node_colour = prefix,; # node_colour_aggr = NULL,; # node_size = ""size"",; # node_size_aggr = NULL,; # node_size_range = c(4, 15),; # node_alpha = 1,; # node_alpha_aggr = NULL,; # node_text_",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/670#issuecomment-785309409:88,integrat,integrates,88,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/670#issuecomment-785309409,1,['integrat'],['integrates']
Deployability,"> Just out of curiousity, you use both BBKNN and combat? Does Louvain after ComBat, HVG, and PCA not work as well for you? It's interesting that you go with two different knn graphs for clustering and visualization. @LuckyMD I found that the clustering using the bbknn kNN graph is much cleaner on UMAP, compared to e.g. `sc.pp.neighbors`. From combat, I just obtain the adjusted data, not a kNN graph. . > There seem to have been a few changes in umap between 0.3.8 and 0.3.9 maybe you should try 0.3.9. @flying-sheep Thanks! With `scikit-learn` pinned to `0.20.3` the `umap` version was updated to `0.3.9` (I use a container and rebuilt it). . I guess I will try to create a reproducible example and open an issue in umap.; Edit: https://github.com/lmcinnes/umap/issues/179",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/666#issuecomment-496848304:589,update,updated,589,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/666#issuecomment-496848304,1,['update'],['updated']
Deployability,"> Just to clarify, Jan started this PR because we were explicitly asked by some of the Scanpy core developers to prepare it for the core library. . I see, my comments weren't really directed at anyone in particular -- I know we are all trying to do good work and it's great that you all have thought a lot about this particular normalization -> dim. red. problem. > We view it basically as ""scTransform done right"". And scTransform is already published and is being used. Sure, but my point is that the analytic Pearson residuals method hasn't been peer-reviewed, and while the results in your preprint appear promising there are still questions that remain; e.g., how does it compare to deviance residuals? What is the effect on datasets that do not have so many cell types, i.e, ""continuous"" datasets? What happens when looking at metrics that aren't qualitative evaluation of t-SNE embeddings?. > One option would be to hold this PR until our paper is formally accepted... That makes sense to me, or just put it in external for now, or write generic methods for ""residuals"" that includes analytic, deviance, etc, with deviance as default (and as flavors?)? I'm not sure what is appropriate here, and some guidelines from the core scanpy team would be appreciated. For example, most people I know use the `""seurat_v3""` flavor of HVG selection, but it's not the default. It makes sense to me to change defaults as more information becomes available about performance/popularity.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1715#issuecomment-798687817:782,continuous,continuous,782,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715#issuecomment-798687817,1,['continuous'],['continuous']
Deployability,"> Just to go back to your original problem, in your case you were using as mapping categories that were not present in your groupby key altogether. This is a different issue, and probably the function should have thrown an error saying var_group_labels are not present in categories. Since I just copied the example from the tutorial, I think it would be great fix the handling of heatmap there. There, the problem is sort of two-fold: 1) as you mentioned, the groupby labels NK/T-cell etc. hadn't been defined before, and 2) that only markers for only a subset of the clusters are used (5 out of 9 clusters have markers) are used with `dendrogram=True`. Both of them independently provoke the warning/issue about the reordering.; Maybe an error would be appropriate not only for undefined groupby labels (as you suggested), ; but also for the case where cluster markers for only a subset of clusters are supplied, instead of delivering a warning and a potentially incorrect ordering.; In the latter case, an error with a message suggesting to use `dendrogram=False` would be worthwhile. The danger with just printing a warning is that it might be ; missed/ignored by the user (e.g. if the function is used in a pipeline with lots of other outputs) ; and mismatching color codes might also not be apparent initially. ; For instance, it took me a while to even spot this issue, as i didn't notice the mismatching colors initially.; This confusion could be avoided if heatmap doesn't produce a plot at all when incorrect arguments are used. I agree that your workarounds also work, but they don't fully serve as substitutes to make the plots as in the tutorial yet.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1479#issuecomment-723071522:1212,pipeline,pipeline,1212,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479#issuecomment-723071522,1,['pipeline'],['pipeline']
Deployability,> Let's update the notebook as well. Would be great to understand performance difference before merging + get rid of the horrible densifying operation in `dask.ipynb`. On it: https://github.com/scverse/scanpy-tutorials/pull/137,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3263#issuecomment-2385462999:8,update,update,8,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3263#issuecomment-2385462999,1,['update'],['update']
Deployability,"> Looking through these, I saw that the skmisc isn’t named after the feature it enables. Should we add a more descriptive copy?. I don't have strong feelings. I assume most people try to run the method and then it yells at them telling them exactly what to install and how to do it. The comment is sufficient for me",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2087#issuecomment-999259300:257,install,install,257,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2087#issuecomment-999259300,1,['install'],['install']
Deployability,"> Looks good, thanks for all the work!; > ; > We should add a release note for this at some point, I'm just not sure where yet, probably a section for dev practices. Could you suggest a line for that?; > ; > I was unsure about the variable naming for PAGA, so I've decided to revert that. I couldn't get flake8 to call it a redefinition. :tada: ; Maybe ""Enabled flake8 (https://flake8.pycqa.org/en/latest/) pre-commit to run code style checks""?; Everything else might just be details that people will uncover anyways since the workflows might complain :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1689#issuecomment-801763494:62,release,release,62,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1689#issuecomment-801763494,1,['release'],['release']
Deployability,"> Maybe the only relevant issue would be to change the default color if this clashes with a color already assigned to a category. I'm not sure how to check if colors are similar. But I think @Hrovatin's suggestion could make this obvious enough to users:. > Also, should the NaN and its colour be added to the legend (if categorical) or besides it (if continuous)?. Any suggestions for how to handle this @fidelram?. > Now that you are looking into this, any chance that the missing_color can also be used as the default color when the color parameter is empty? The current default is light gray . Yes, but it took a little bit more work than I expected (https://github.com/matplotlib/matplotlib/issues/18294). Basically we can't just pass an array of nulls for the color values here, since matplotlib throws user visible warnings about this at plot time.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1356#issuecomment-675876471:352,continuous,continuous,352,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356#issuecomment-675876471,1,['continuous'],['continuous']
Deployability,"> More interesting is that regress_out becomes lightning fast when n_jobs = 24 and with BLAS multi threading disabled:. Thats not too surprising to me. This must be significantly over scheduling your machine. --------------------------------. This got me doing a little more digging into this, and it look's like there's actually a solution now! We can use [`threadpoolctl`](https://github.com/joblib/threadpoolctl) to dynamically manage the number of threads BLAS uses via the `threadpool_limits` context manager. . I'm definitely interested in using this inside scanpy to manage the number of threads used here. Not quite sure yet what the right behaviour/ api is. Some options:. * Should all calls use 1 blas thread by default, so parallelization will only happen through the number of jobs?; * Do we only limit the number of threads if `n_jobs` is specified? ; * Do we try and be fancy, with something like `n_threads = n_cpus // n_jobs`?. *Minor update*. [If we use `joblib` (with the `loky` backend) instead of `multiprocessing`, the fancy solution will be used by default.](https://joblib.readthedocs.io/en/latest/parallel.html#avoiding-over-subscription-of-cpu-resources). I think this is what the code would look like inside of `regress_out`:. ```python; from joblib import Parallel, delayed; res = Parallel(n_jobs=n_jobs)(delayed(_regress_out_chunk)(task) for task in tasks); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1396#issuecomment-691913240:951,update,update,951,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1396#issuecomment-691913240,1,['update'],['update']
Deployability,"> Moving 10x reading functions to anndata. I haven't worked much with h5py or tables, is it time-consuming to refactor these functions? It seems like moving to anndata is the most straightforward solution at least logically to me. > scanpy as a requirement. I like scanpy, but the only thing we really *require* in scvi is the data loading part. A user could take their scvi outputs and go use Seurat if that makes them happy. And then like the data loading functions are simple enough that we could just implement them ourselves. I'm sure a lot of people are currently doing this, which inspired the idea to have a standalone package. > Splitting off new modules. Your questions are very valid. I don't really have good answers for them. I could just see a standalone package being widely used and community driven, especially if there is some scanpy backing + maybe optional dependencies/functionality to get your objects ready for R analysis pipelines.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1387#issuecomment-680188365:945,pipeline,pipelines,945,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1387#issuecomment-680188365,1,['pipeline'],['pipelines']
Deployability,"> My idea was to have print_header output very little, plus an expandable region (as it’s the one called in notebooks), and to revert print_versions to just copyable text output. Could we deprecate `print_header` and instead suggest a way to call `session_info` for the equivalent?. If all we're doing is calling `session_info.show` with a couple default arguments, I'm not sure it's worth keeping here. I'd like users to call it directly because:. * Users get access to all of the session_info options without us having to mediate that; * If something doesn't work, it's not our problem. > session_info has no file argument. It has `write_req_file`, which is the same intent – right?. I assume `file` was there from a time when this wrote something that you could `pip install` from?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2089#issuecomment-998837030:770,install,install,770,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2089#issuecomment-998837030,1,['install'],['install']
Deployability,"> New analysis tool: A simple analysis tool you have been using and are missing in sc.tools. What about alternative normalization tools like SCTransform? I read that they are supposed to be better for spatial data. As non-mathematician of course I'm not sure how big the difference will really be in the end but it would be great if there was a easy way to call and test them if it's worth it. > New plotting function: A kind of plot you would like to seein sc.pl?. I think a plot that shows the gene expression profile along a spatial axis would be nice if this is not planned yet. So to draw in e.g. a line in napari and get the gene expression of certain genes along this line. > External tools: Do you know an existing package that should go into sc.external.*?. A package I found very useful and easy to integrate with scanpy is SpatialDE. Are you planning to provide this in `sc.external.*`? And of course tools to integrate sc-RNA-seq and spatial data (like Stereoscope, cell2location,...) would be great! But I think you mentioned that there are plans for own tools, right?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1653#issuecomment-782699618:809,integrat,integrate,809,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1653#issuecomment-782699618,2,['integrat'],['integrate']
Deployability,"> Not sure whether it is resolved, just put here another solution to read_mtx and add to anndata one by one; > ; > ```; > import pandas as pd; > import scanpy as sc; > ```; > ; > ```; > adata = sc.read_mtx('./matrix.mtx'); > adata_bc=pd.read_csv('./barcodes.tsv',header=None); > adata_features=pd.read_csv('./features.tsv',header=None); > adata= adata.T; > adata.obs['cell_id']= adata_bc; > adata.var['gene_name']= adata_features[0].tolist(); > adata.var.index= adata.var['gene_name']; > ```. set the delimiter for the features to tab, then use the second column which contains the gene names and not the gene ensembl id. Using the gene names is better for downstream qc since the scanpy recommended pipeline uses the gene name prefixes to identify mitochondrial genes. ```; adata_features = pd.read_csv('./barcodes.tsv', header = None, delimiter = '\t'); ... # technically don't need to use .values or tolist() since the mtx and features file should ; # have same number of rows resulting in same index in the adata.var and adata_features dataframes. adata.var['gene_name'] = adata_features[1].values; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1916#issuecomment-2241799568:700,pipeline,pipeline,700,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1916#issuecomment-2241799568,1,['pipeline'],['pipeline']
Deployability,"> OK! Please add a release note and we’re good to go I think. Added note, under features",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2792#issuecomment-1944145708:19,release,release,19,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2792#issuecomment-1944145708,1,['release'],['release']
Deployability,"> Oh interesting, I thought it was clear :) I mean you even contributed to the function, no?; > ; > I think we also discussed why not to use intersection by default in the PR: [#614 (comment)](https://github.com/theislab/scanpy/pull/614#issuecomment-485875031); > ; > If intersection is not used by default, why would we write in the documentation that it acts as a lightweight batch correction method. I'm as surprised as you are :). Yes, I fixed sth and reorganized a bit. I also recall our disc on `highly_variable_intersection`. However, I thought your organization of HVGs was only for the ranking in `highly_variable_nbatches`. Didn't see it's also the default for `highly_variable`. I never really looked at the docs... that would have given a hint... I still feel as though I have sth slightly different though if I recall. Will look more carefully once this benchmarking data integration thing is out.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1032#issuecomment-617120764:885,integrat,integration,885,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1032#issuecomment-617120764,1,['integrat'],['integration']
Deployability,> One idea:; > ; > 1. Cluster the graph with leiden; > 2. Coarsen the graph (collapse cells in a single cluster into super nodes); > 3. Assign each supernode a color -- adjacent supernodes in the coarsened graph cannot be the same color; > 4. Assign all cells in each cluster that cluster's color.; > ; > That way you'd probably get nice-looking patches of colors and wouldn't run into the issue @ivirshup mentioned. that sounds reasonable,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1366#issuecomment-698277804:346,patch,patches,346,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1366#issuecomment-698277804,1,['patch'],['patches']
Deployability,"> Please also add a release note!. sorry for the naive question, but how do I add a release note? As a comment in the PR? As a commit?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1506#issuecomment-744276746:20,release,release,20,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506#issuecomment-744276746,2,['release'],['release']
Deployability,"> Removed 3.6. We should keep 3.6 as long as we support it. It's easy to accidentally add features which only work with 3.7+ otherwise. I'd be happy to drop 3.6 once numpy does (and in general roughly follow [NEP 29](https://numpy.org/neps/nep-0029-deprecation_policy.html) as soon as the ecosystem does). > is there any reason why we are currently not additionally using Github Actions?. Depends on the task. Also depends on the definition of github actions I think? We aren't using any of their runners for testing because we'd like the ability to integrate with hosted resources on azure. Also, azure seemed like much more of a standard for numeric python packages at the time we chose it. I'd be happy to have github actions for other things, like `precommit`. `twine check` could be another one, but I haven't looked in to how ""artifact"" type things are handled with github actions to know if we'd be able to recover the built objects. We'd talked about using codecov too, which I'd like to add a check for. I'm not totally clear on the distinction between checks and actions yet.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1602#issuecomment-763590019:550,integrat,integrate,550,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1602#issuecomment-763590019,1,['integrat'],['integrate']
Deployability,"> So is it OK if I go ahead and merge this before more PRs come in with conflicts? . No. There are already open PRs which I'm working on merging, and this will cause conflicts in those. > But even if you don’t fully agree with all of my arguments, there’s still arguments, and zero for not doing it. I've only partially responded because I'm low on time. At first glance, there are a number of things I'm against here. But I'll be able to consider them more thoroughly, and tell you my arguments, once I've got more time – sometime after the 1.7.0 release.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1528#issuecomment-744154930:548,release,release,548,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528#issuecomment-744154930,1,['release'],['release']
Deployability,"> So it might be better to either switch to the numba kernel for larger datasets or take the compile hit for small datasets. The compiled versions should get cached, so it's a one time cost per install. No?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2942#issuecomment-2042381346:194,install,install,194,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2942#issuecomment-2042381346,1,['install'],['install']
Deployability,"> Some pip wheel files are there for example. And scipy is also some 100 MB right?. > Totally agree it's the user's responsibility. I would say that it's the devs responsibility to make it as easy as possible for the user. That's exactly my stance as well. > How about printing the absolute path of the data's destination on download?. I thought that too. Only we should do it not just on download, but on every use, e.g. “reading cached data from ~/.cache/scanpy/paul15.h5ad”. And put help on how to change the cache dir in the settings docs. > I thought the older ones would just be deleted, right?. Since those systems aren't configured well, probably not. On those systems, it would just be another directory. But on a laptop with a common Linux distribution, there would be a pop-up once your disk space gets low, which allows you to clear that directory with a click. > If you had space for a couple datasets, wouldn't it be likely that installing a couple things with pip would clear these datasets on a system like we're describing? I'm not sure I find this behavior intuitive for this use case. You'd not notice it much, because datasets are just being re-downloaded on demand. That's a feature!. > [We don't have XDG_CACHE_HOME set]. Yes, because you only need it if you want your cache files to not be in `~/.cache`. > When I think about example datasets that are available through scientific computing packages I think of […]. I'm on mobile, so I don't want to check all of those, but. - miniconda is somewhere else for me by default, and it contains everything, not just data; - nltk pops up a window asking you to where to put stuff, and [recommends /use/local/share/nltk_data](https://www.nltk.org/data.html) for global installs, with no recommendation for per-user installs. I have a lot more stuff in my cache dir, not just applications. And as said: for good reason, because the OS often knows about this, which helps the user to delete the stuff with one click if needed. ---. My pe",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/558#issuecomment-477102890:943,install,installing,943,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-477102890,1,['install'],['installing']
Deployability,"> Sorry for late reply, I think this was fixed in #1138. Could you update your scanpy and try again? For me it seems to work; > ; > ```python; > fig, ax = plt.subplots(1,3, figsize=(20,6)); > sc.pl.spatial(adata, img_key=""hires"", color=""array_row"", size=1.5, ax=ax[0], show=False); > sc.pl.spatial(bdata, img_key=""hires"", color=""array_row"", size=1.5, ax=ax[1], show=False); > sc.pl.spatial(cdata, img_key=""hires"", color=""array_row"", size=1.5, ax=ax[2], show=False); > plt.tight_layout(pad=3.0); > plt.show(); > ```; > ; > ![image](https://user-images.githubusercontent.com/25887487/79438766-41165b80-7fd4-11ea-8ed7-f297b22da7c0.png). Hello, I have a problem, that is why some plots show colorbar but other plots show legend? It seems using same code.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1158#issuecomment-1454679327:67,update,update,67,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1158#issuecomment-1454679327,1,['update'],['update']
Deployability,"> Tests are failing and I suspect that this is caused by an update on seaborn or matplotlib... Yes, should be as the introduced changes are not linked to the failing tests. I also checked and both `seaborn` and `matplotlib` have been updated in the last few days. See [here](https://pypi.org/project/seaborn/#history) and [here](https://pypi.org/project/matplotlib/#history).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1417#issuecomment-693331949:60,update,update,60,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1417#issuecomment-693331949,2,['update'],"['update', 'updated']"
Deployability,"> Thank you! With “tests” I mean “functions named `test_*` with `assert ...` statements inside”; ; Thanks for your guidance, I have added `test_weightedSampling.py` with a folder named `weighted_sampled` in _data folder. . I have updated scanpy for weighted sampling for later tasks (clustering, finding marking genes and plotting). I also suggest to support it for initial tasks like PCA for data where each observation has weight (as in MATLAB). . Regards, ; Khalid",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/644#issuecomment-493362243:230,update,updated,230,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/644#issuecomment-493362243,1,['update'],['updated']
Deployability,"> Thanks for opening the issue.; > ; > It looks like a problem with pytables, which we are removing as a dependency since it's starting to have problems like this.; > ; > Are you able to update the installation of pytables? Otherwise, you could try a dev version of scanpy. Thank you for pointing out the issue with pytables. Tried a couple things and it works now.; I don't know how this matters. I uninstalled pytables > tried importing scanpy > doesn't work (says tables module not found, which is expected I guess). I reinstalled pytables - now it decides to work. I can't see how that makes a difference since I had the same pytables version before.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2138#issuecomment-1047851057:187,update,update,187,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2138#issuecomment-1047851057,2,"['install', 'update']","['installation', 'update']"
Deployability,"> Thanks for the update. Now is clear.; > ; > We do not offer that possibility as most of those functions are based on seaborn, thus, simply passing the relevant data to seaborn will get you the image that you want.; > ; > Nevertheless, I would like to take a look. How do you think this should work. Just add a variable to show the genes that you would like to see. Or you mean a more generic function just to make split plots between any two categories for the genes that you want to see?. Thanks for your attention. Yes it would be nice if I could compare two .obs categories with regard to expression distributions of a list of genes I supply. . Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1448#issuecomment-707563433:17,update,update,17,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1448#issuecomment-707563433,1,['update'],['update']
Deployability,> Thanks for the updates @pinin4fjords! LGTM. Thanks for the education / help. And for Scanpy of course :-),MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1659#issuecomment-783241825:17,update,updates,17,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1659#issuecomment-783241825,1,['update'],['updates']
Deployability,"> Thanks for your update @rpeys, I will try to convert to scipy csr sparse matrix :). Hello, Massonix, was the problem resolved?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/391#issuecomment-1149904076:18,update,update,18,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/391#issuecomment-1149904076,1,['update'],['update']
Deployability,"> Thanks, I am running the version of `1.4.5.1`. Assuming that it is one of 1.4.1 or 1.5.1 I would suggest that you upgrade to the latest scanpy version. What you are using is quite old. If the problem still occurs we can discuss it further.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2189#issuecomment-1077460049:116,upgrade,upgrade,116,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2189#issuecomment-1077460049,1,['upgrade'],['upgrade']
Deployability,"> That's a great idea. It might require some reorganization, though, because currently use_raw is checked two places: once in sc.pl.scatter(), because it needs to know whether to look for variables in raw or not when deciding how to call _scatter_obs(), and again in _scatter_obs() itself. Would it be possible to not call it again in `scatter_obs`? E.g. could `_scatter_obs` not even need to know about the `raw` field?. > On another note, some pytests that are in files I did not edit are now failing because they can't find anndata.tests to import. I'm not sure if I messed something up by adding tests to test_plotting.py or whether this is a different issue. Aww crap, I think that was me making a new release. On the plus side it means our build system is now working as it's supposed to.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2027#issuecomment-964279124:707,release,release,707,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2027#issuecomment-964279124,1,['release'],['release']
Deployability,"> That's fair. Might be worth asking the `conos` developers in this case?. Yes, could and should do this... but would slow down the process for now I guess. > Also, does using `install.packages` within a conda environment work for you? I recall that not working well for me in the past. It works if you install the R packages last and don't install anything else over the top via conda.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1068#issuecomment-593311808:177,install,install,177,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1068#issuecomment-593311808,3,['install'],['install']
Deployability,"> The Leiden algorithm is now [included](https://igraph.org/python/doc/igraph.Graph-class.html#community_leiden) in the latest release of `python-igraph`, version 0.8.0. I believe this alleviates the need to depend on the `leidenalg` packages. The Leiden algorithm provided in `python-igraph` is substantially faster than the `leidenalg` package. It is simpler though, providing fewer options, but I believe the more extensive options of the `leidenalg` package are not necessarily needed for the purposes of `scanpy`. We provide binary wheels on PyPI and binaries for conda are available from the conda-forge channel, also for Windows. I have now done a speed comparison with adata object of 1.85 million cells. igraph on adata as implemented [above](https://github.com/theislab/scanpy/issues/1053#issuecomment-1039424473) ran in **33 minutes** vs `sc.tl.leiden()` which took **~14 hours**",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1053#issuecomment-1039999011:127,release,release,127,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1053#issuecomment-1039999011,1,['release'],['release']
Deployability,"> The only advantage of sort_order=order_array is that is explicit for the user. Another advantage is that it could be user specified per plot when there are multiple plots. -------------------. I think there is another issue, which is that `sort_order` currently just applies to numeric values while here we are trying to deal with issues around categorical values. To me this suggests a need to have separate arguments for the two cases (`order_categorical`, `order_continuous`), though this raises issues with ""vectorizing"" the argument. Docstrings for these arguments would look something like:. ```rst; order_continuous: Literal[""current"", ""random"", ""ascending"", ""descending""] = ""ascending""; How to order points in plots colored by continuous values. Options include:; * ""current"": use current ordering of AnnData object; * ""random"": randomize the order; * ""ascending"": points with the highest value are plotted on top; * ""descending"": points with lowest value are plotted on top; order_categorical: Literal[""current"", ""random"", ""ascending"", ""descending""] = ""random""; How to order non-null categorical points in the plot. Uses same options as order_continuous.; ```. In this case, `sort_order` would be deprecated, and tell the user to use `order_continuous` instead. ## Potential extensions. * We could also allow users to pass `Callable[Vector, Vector[int]]`s (e.g. function which takes color vector, returns vector of integers) as arguments. ## Possible issues. ### Vectorization could be complicated. Vectorization of argument unclear/ maybe not possible. That is, what if I want the same variable twice, but ordered differently? This would look like: . ```python; sc.pl.umap(adata, color=[""CD8"", ""CD8""], order_continuous=[""ascending"", ""descending""]); ```. Now what if I wanted to also plot a categorical value? Is this: . ```python; sc.pl.umap(adata, color=[""CD8"", ""CD8"", ""leiden""], order_continuous=[""ascending"", ""descending"", None]); ```. ### Null values. This solution assumes we still wa",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1263#issuecomment-776508554:737,continuous,continuous,737,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1263#issuecomment-776508554,1,['continuous'],['continuous']
Deployability,"> The tests don’t fail, but you should still add the extra to setup.py. Is the fact that you don't list `'docs'` in your pip thing (`pip install -e .[louvain,leiden,test]`) purposeful?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/361#issuecomment-438320501:137,install,install,137,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/361#issuecomment-438320501,1,['install'],['install']
Deployability,"> There was a similar report not so long ago but I have not been able to reproduce the issue. Seems to be related with the matplotlib version used. Maybe you can try to update to the latest version.; > […](#); > On 10 May 2019, at 01:38, brianpenghe ***@***.***> wrote: I ran this: ax=sc.pl.heatmap(Mouse10Xdata[NewIndex3,:], sorted_unique_marker_genes, groupby='ident', use_raw=False, vmin=-3, vmax=3, cmap='bwr',show=True,swap_axes=True,figsize=(10,7), var_group_rotation=0, dendrogram=True, save='ClusterMap.png') But the image has something weird. Here are the snapshot: The lines don't align well with the heatmap. Additionally, the lines don't align well with the group ID colors, either And the ID colors seem to be not aligned well with the heatmap either. Any thoughts? — You are receiving this because you are subscribed to this thread. Reply to this email directly, view it on GitHub, or mute the thread. I have been using matplotlib 3.0.3 and I believe it's the latest version already. My Scanpy version was 1.4.1. ; Can it be an issue about duplicated gene names/make unique?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/637#issuecomment-492577684:169,update,update,169,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/637#issuecomment-492577684,1,['update'],['update']
Deployability,"> This is strange, i also tried to run the tests multiple times at the time of committing this and they failed every time. Maybe a dependency had a bugged release at the time?. > I am not sure what king of test. I don't want to add another save_and_compare_images test because plots seem to depend on the system at least sometimes. You could instead use `check_same_image`. Check that running `filter_rank_genes_group` then plotting is equivalent to manually passing those genes to `sc.pl.rank_genes_groups_*` plot on an object that hasn't had `filter_rank_genes_group` run on it. You can search the tests for examples of `check_same_image`. > (i have 3 failing plotting tests locally but they run fine here). Could you open an issue for this and note which tests they are? It would be good to make the tests as resilient as possible on other people's systems.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1942#issuecomment-878134649:155,release,release,155,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1942#issuecomment-878134649,1,['release'],['release']
Deployability,> This might be a case of a `pip install umap` rather than `pip install umap-learn`. Suspecting exactly that :),MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1978#issuecomment-898435220:33,install,install,33,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1978#issuecomment-898435220,2,['install'],['install']
Deployability,"> This might be due to updates in pandas >1.3.0. The command; > `pbmc.rename_categories('phase', new_cluster_names)`; > seems to be deprecated. In particular, the ""inplace"" option is no longer valid, so it seems that one can only create a copy of the renamed categories and store it. Hence, the new command should be; > `pbmc.obs['phase'] = pbmc.obs['phase'].cat.rename_categories(new_cluster_names)`.; > I checked that this works on a different data set, but haven't checked for pbmc. If this fully fixes the problem, only the tutorial needs to be updated (the command for renaming the clusters) and scanpy doesn't need to be modified.; > ; > Reference: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.cat.rename_categories.html. I have verified that this change works in the scanpy clustering tutorial. The exact change I made was; `adata.rename_categories('leiden', new_cluster_names)`; became; `adata.obs['leiden'] =adata.obs['leiden'].cat.rename_categories(new_cluster_names)`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1975#issuecomment-925158522:23,update,updates,23,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1975#issuecomment-925158522,2,['update'],"['updated', 'updates']"
Deployability,"> This seems like pretty bad behavior for a development environment. We definitely don't want the dev install to be uninstalled when a new package gets downloaded. Well, scvelo depends on 1.7 and you have a release candidate of that one installed, so what happened is the only correct behavior: It uninstalled an incompatible version to install a compatible one. If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. That’s annoying but necessary as editable installs are nonstandard and therefore not well integrated into how package metadata works. > Why not just use `pip install -e` here?. Because development installs in general are nonstandard, and `pip install -e` in particular uses the deprecated `setup.py`. Tasks; -----. > - Exclude setup.py from sdist using the standard way, not via .gitignore. sounds good!. > I'm a bit concerned that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes.; > ...; > - flit mangles the build version part of wheel filenames, in a way that pip just started checking for. . No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. AFAIK nothing says there can’t be pluses in there, only that you can’t upload packages with local specifiers in their version to PyPI. Which we don’t do here, so pip should chill. If flit decides to work around that quirk, or pip relaxes, we can unpin pip. > - flit symlinked packages seem to be overwritten if a new package is installed which has the symlinked package as a dependency. Seee above. Has nothing to do with flit. What made you thing that anyway?. > - There is a fairly large workaround to make the package version available if the dependencies are not installed. Is it possible to use something more standard like versioneer here?. No. Either we hardcode a string constant in the `__init__.py` or we leave it like it is un",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1527#issuecomment-781992443:102,install,install,102,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527#issuecomment-781992443,10,"['install', 'integrat', 'release']","['install', 'installed', 'installs', 'integrated', 'release']"
Deployability,"> This seems reasonable to me @flying-sheep . Does using the patched version change results over the unpatched @ashish615 i.e., for a given random seed, unpatched and patched are the same? If the two are the same for a given seed/state, then I think what @flying-sheep is proposing could be done separately (even if we make the dependency optional IMO). However, if the new version does change results, we will need the handling that @flying-sheep describes. @ilan-gold , I didn't check that. I will check that and let you guys know.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3061#issuecomment-2115403898:61,patch,patched,61,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061#issuecomment-2115403898,2,['patch'],['patched']
Deployability,"> Trying to figure out how much of a problem this is, how much does PAGA use forceatlas2?; > ; > From my skimming of the code: it's optional – the default is to use one of the `igraph` layout algorithms. Options I see:; 1. We fork forceatlas2 and create our own release with its own name. Not a fan of this.; 2. Somebody finds a way to contact the author. I already failed through several channels. No response.; 3. We remove support for forceatlas2 since we have another option. @ivirshup how comparable are the forceatlas2 and the igraph implementations when it comes to results? Do you have any idea?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2067#issuecomment-991913417:262,release,release,262,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2067#issuecomment-991913417,1,['release'],['release']
Deployability,"> UPDATE: So after running `sc.pp.neighbors(adata, n_neighbors=15, n_pcs=40)` I was able to run PAGA w/ Seurat clusters using: `sc.tl.paga(adata, groups='seurat_clusters')`.; > ; > Would you guys say this is a legal move to make statistically speaking?; > ; > I am visualizing the trajectory inferences using `scanpy.pl.paga(adata)`. Hi thank you very much for your information. I'm running the same purpose, using the Seurat object with clustering information for Scanpy trajectory analysis. May I ask why your adata object has so much information inside. Mine is: ; ![image](https://github.com/scverse/scanpy/assets/82354685/ef2554df-a067-45f5-8e4f-8527540a7994). What I do is reading the h5ad file and running sc.tl.paga(adata, groups='seurat_clusters'). May I ask if it is correct or not. Thanks again for your kind help.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/680#issuecomment-1756713620:2,UPDATE,UPDATE,2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/680#issuecomment-1756713620,1,['UPDATE'],['UPDATE']
Deployability,"> Unfortunately, we had a prerelease with a bug. the dangers of installing prereleases :wink:. the docker image is on 1.1a1 though :innocent:",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/158#issuecomment-391253208:64,install,installing,64,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/158#issuecomment-391253208,1,['install'],['installing']
Deployability,"> We could wrap it in a function that checks the number of cells and only compiles this to faster code when necessary. So that's what this PR would replace. The reason I thought this could be replaced is that `numba` now allows on-disk cacheing of parallelized functions. This means that the function would only have to be compiled once per install. That cache only get's invalidated if function's source code get's modified, so this shouldn't cause too much pain for development testing times. I've added a note to the documentation mentioning this, so I think it's fine.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/844#issuecomment-534371715:341,install,install,341,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/844#issuecomment-534371715,1,['install'],['install']
Deployability,"> Well, as that issue says, it’s fixed in [lmcinnes/umap#261](https://github.com/lmcinnes/umap/pull/261), which means it’s in umap 0.3.10. @flying-sheep unfortunately `umap==3.10` does not fix this relative to the latest scanpy version on Bioconda (`1.4.4.post1`). The issue is that the UMAP fix does not address the branch of code that scanpy depends on (specifically the call follows [this branch in the UMAP code](https://github.com/lmcinnes/umap/blob/41205248fb48391d1f6e4effcb974307b7c229ce/umap/umap_.py#L1059)), which still just passes the `init_coords` in as is. . Of course, there has been [a workaround in scanpy since 1.4.5.post1](https://github.com/theislab/scanpy/commit/1400d1e35f908d6f5ab8a8681970ac4aba673565). However, I would caution against the advice in that commit's message, which assumed that once `umap==3.10` was released the workaround could be removed.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/948#issuecomment-595355427:838,release,released,838,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/948#issuecomment-595355427,1,['release'],['released']
Deployability,"> Well, scvelo depends on 1.7 and you have a release candidate. `scvelo` depends on `scanpy>=1.5`, so I don't think this is the cause. Do you know why this is happening, and can you provide counter examples where it doesn't happen?. > If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. . I'm not sure what you mean by this. Does `flit install -s --deps=develop` not count as reinstalling? Are you counting `flit install -s` as a development install?. > Because development installs in general are nonstandard, and pip install -e in particular uses the deprecated `setup.py`. I think pinning pip to an old version is worse than using a common, even if non-standard, installation method. > No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. My reading of the PR in `flit` and the subsequent discussion in the `pip` and PEP threads suggests to me that the issue is `pip` validating the metadata name against the wheel, while a spec exists saying the wheel can't contain characters that are allowed by version specs. If anything, `pip` suddenly started expecting exact version specifiers in wheel filenames, while a spec exists that says how the filenames should be mangled. `flit` did the mangling, and `pip` now says that's wrong. It looks like the direction the discussion is headed is PEP 427 is wrong, and `pip` is right. I have no idea what sort of timeframe should be expected here.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1527#issuecomment-782812159:45,release,release,45,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527#issuecomment-782812159,8,"['install', 'release']","['install', 'installation', 'installs', 'release']"
Deployability,"> Well, so essentially, this PR reversed what I did quite some time ago to speed up the CI... Exactly! With the crucial difference that after the first build, binary packages for everything are being cached by pip, *and* now we don’t have to install conda every build. The one you linked to was just this one initial build. The real numbers are now:. &nbsp; | Runtime | Total | Link; --- | --- | --- | ---; Before (conda) | 4m47s | 8m33s | https://travis-ci.org/theislab/scanpy/builds/454438531 ; After (pip) | 3m34s | 5m 2s | https://travis-ci.org/theislab/scanpy/builds/456855724. > But, let's leave it like this. Hopefully, at some point, we'll have a less hackish way than the previous conda install script of dealing with this. The time is now, wheee!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/360#issuecomment-439811200:242,install,install,242,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/360#issuecomment-439811200,2,['install'],['install']
Deployability,"> What the fair way to color this? If it were random, or purely by count this would look mostly like A. I would argue that this would be fair. In the end it's about showing which cells are represented per pixel/pixel bin. And rare cell types shouldn't be up-weighted in that in an unbiased representation (if there is such a thing). In general I do like the idea of density being linked to transparency though. We could do a quick fix based on random order for now though, and then look into transparency for a larger update that would have to do with updating scanpy plotting to larger cell numbers?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1263#issuecomment-761598626:518,update,update,518,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1263#issuecomment-761598626,1,['update'],['update']
Deployability,"> When I run [`conda install python=3.11` and `conda install -c conda-forge scanpy`] I get an error . Yeah no idea how to debug conda conflicts. I’ve often seen things like this: completely unrelated packages “conflicting” containing cryptic symbols like `feature:|@/osx-64::__osx==10.16=0`. No clue what that means. Conda seems to be unable to figure out which user-specified versions are in conflict with each other. Pip seems to do a better job these days:. > Running this with `pip -vv install scanpy` as you suggested indeed gives an error with numba. Exactly, so this is a numba issue. Please follow https://github.com/numba/numba/issues/8304. Once numba supports Python 3.11, you’ll be able to install any dependent project there (including scanpy)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2369#issuecomment-1333418043:21,install,install,21,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1333418043,4,['install'],['install']
Deployability,"> Why do we change Matplotlib ""font.sans-serif"" anyway?. No idea, I don’t even like Arial. Alex updated the fonts last in 6c68b8ba2821f27bd0b8f499a1d543dff9cc51b2, and setting the fonts happened in the initial commit:. https://github.com/theislab/scanpy/blob/c22e48abe45a6ccca5918bbf689637caa4b31250/scanpy/plotting.py#L605. @falexwolf do you recall why you did that? Can we just remove that line?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/805#issuecomment-547000682:96,update,updated,96,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/805#issuecomment-547000682,1,['update'],['updated']
Deployability,"> Why is this PR getting a build if there is no `pr` trigger entry in the yaml?. See 3 paragraphs down:. > If no pr triggers appear in your YAML file, pull request validations are automatically enabled for all branches, as if you wrote the following pr trigger. This configuration triggers a build when any pull request is created, and when commits come into the source branch of any active pull request.; > ; > ```; > pr:; > branches:; > include:; > - '*' # must quote since ""*"" is a YAML reserved character; we want a string; > ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1516#issuecomment-737862275:267,configurat,configuration,267,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1516#issuecomment-737862275,1,['configurat'],['configuration']
Deployability,"> Yeah, this is super weird. I think it's also blocking for adopting flit as recommended way to install scanpy to a dev environment. How has that to do with flit? Will pip just block upgrades things it identifies as “editable installs” from being upgraded while happily upgrading “normally installed” release candidates?. > I still have the concern that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. But we can leave this for now. If getting this wheel issue solved drags on for multiple pip versions, we may need to reconsider. Exactly!. > I'm not 100% confident this isn't an issue, and it would be good to get more opinions on this. It wasn’t an issue for the year this PR has lingered, and now it’s pypa/pip#9628 and related discussions (which are already converging). I would like to meaningfully contribute to scanpy again instead of having to fix merge conflicts in this and discussing what pip broke this time. > In particular, this looks very brittle to me:. It isn’t, as you agreed on like 8 months ago. Worst that happens is “ImportError: cannot import ‘foo’” when building, which we can fix in 5 minutes.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1527#issuecomment-785809453:96,install,install,96,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527#issuecomment-785809453,6,"['install', 'release', 'upgrade']","['install', 'installed', 'installs', 'release', 'upgraded', 'upgrades']"
Deployability,"> You could keep these separate by binarizing the adjacency matrix before doing the multiplication. The neighbors that are only reachable via the Nth-hop should always have a 1 in the N-th matrix product that way. Thats a problem with this strategy. Since it's an undirected graph, a node is it's own second neighbor. Since it's a hexagonal grid my first neighbors are also my second neighbors as well as my nth neighbors (in most cases, if there are edges or missing cells this might not be the case). We would either have to do our own BFS which precludes back tracking (i.e. for each search from each node remove previously visited edges), or we could take the difference of the edge sets at each update. Taking the difference would probably be easier.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1383#issuecomment-705360617:700,update,update,700,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1383#issuecomment-705360617,1,['update'],['update']
Deployability,"> ```; > MatplotlibDeprecationWarning: Passing parameters norm and vmin/vmax ; > simultaneously is deprecated since 3.3 and will become an error two minor releases ; > later. Please pass vmin/vmax directly to the norm when creating it.; > ```. Yeah, that actually re-ignited my idea of adding support for vcenter after upgrading mpl :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1551#issuecomment-748679208:155,release,releases,155,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551#issuecomment-748679208,1,['release'],['releases']
Deployability,"> ```python; > import scanpy as sc; > ; > em_adata = sc.datasets.pbmc3k(); > ; > sc.pp.pca(em_adata, n_comps=50); > sc.pp.neighbors(em_adata); > sc.tl.umap(em_adata); > sc.tl.leiden(em_adata,flavor='igraph',n_iterations=2,random_state=1653,directed=False); > ```. @melonora, would you mind running this on your windows machine with the latest scanpy release to see if you can reproduce it?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2969#issuecomment-2039960139:350,release,release,350,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969#issuecomment-2039960139,1,['release'],['release']
Deployability,"> `hasattr(__builtins__, ""__IPYTHON__"")` now seems to always return False. I'm not seeing this behaviour, could you check what versions you're using?. <details>; <summary> My versions </summary>. ```; -----; sinfo 0.3.1; -----; IPython 7.23.1; jupyter_client 6.1.11; jupyter_core 4.7.0; jupyterlab 2.2.9; notebook 6.3.0; -----; Python 3.8.9 (default, Apr 3 2021, 01:50:09) [Clang 12.0.0 (clang-1200.0.32.29)]; macOS-10.15.7-x86_64-i386-64bit; 16 logical CPU cores, i386; -----; Session information updated at 2021-05-10 10:13; ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1477#issuecomment-835965024:498,update,updated,498,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1477#issuecomment-835965024,1,['update'],['updated']
Deployability,"> `paul15` is downloaded automatically, very practical. Yeah, it’s really cool for interactive use, but not for automated testing / continuous integration I think.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/80#issuecomment-364372580:132,continuous,continuous,132,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/80#issuecomment-364372580,2,"['continuous', 'integrat']","['continuous', 'integration']"
Deployability,"> a np.sum in a prange loop, plus some minor other things. You can check the linked comment info for more details. 🤦 remember having a look but not quite getting it the first time... thank you!. > Argument order. 👍 . > Minor things. 👍 🙏 . I'll had release note, than we can merge it?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1740#issuecomment-802659709:248,release,release,248,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1740#issuecomment-802659709,1,['release'],['release']
Deployability,"> build\lib.win-amd64-3.6\fa2; copying fa2\forceatlas2.py -> build\lib.win-amd64-3.6\fa2; copying fa2\__init__.py -> build\lib.win-amd64-3.6\fa2; running egg_info; writing fa2.egg-info\PKG-INFO; writing dependency_links to fa2.egg-info\dependency_links.txt; writing requirements to fa2.egg-info\requires.txt; writing top-level names to fa2.egg-info\top_level.txt; reading manifest file 'fa2.egg-info\SOURCES.txt'; reading manifest template 'MANIFEST.in'; writing manifest file 'fa2.egg-info\SOURCES.txt'; copying fa2\fa2util.c -> build\lib.win-amd64-3.6\fa2; copying fa2\fa2util.pxd -> build\lib.win-amd64-3.6\fa2; running build_ext; skipping 'fa2\fa2util.c' Cython extension (up-to-date); building 'fa2.fa2util' extension; error: Microsoft Visual C++ 14.0 is required. Get it with ""Build Tools for Visual Studio"": https://visualstudio.microsoft.com/downloads/; ----------------------------------------; ERROR: Failed building wheel for fa2; Running setup.py clean for fa2; Failed to build fa2; Installing collected packages: fa2; Running setup.py install for fa2 ... error. ERROR: Command errored out with exit status 1:; command: 'C:\ProgramData\Miniconda3\envs\Jayalal_2_Miniconda\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""'; __file__='""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' install --record 'C:\Users\xkalaj\AppData\Local\Temp\pip-record-y21s2idm\install-record.txt' --single-version-externally-managed --compile --install-headers 'C:\ProgramData\Miniconda3\envs\Jayalal_2_Miniconda\Include\fa2'; cwd: C:\Users\xkalaj\AppData\Local\Temp\pip-install-golo7r_8\fa2\; Complete output (30 lines):; Installing fa2 package (fastest forceatlas2 python implementation). >>>> Cython is ins",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1256:2927,Install,Installing,2927,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1256,1,['Install'],['Installing']
Deployability,> conda install -c conda-forge pynndescent; > ; > This also fixed my problem. Thanks @FlyPythons for the hint. Thanks!This also work for me.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1567#issuecomment-1592461176:8,install,install,8,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1567#issuecomment-1592461176,1,['install'],['install']
Deployability,"> coverage decreased, I think not detected because some pytest.parametrize were removed?. I think codecov just hadn’t updated its comment yet when you saw that. What you say can’t be, it doesn’t matter how a line was hit: If a line is run, it’ll be reported as hit, if your changes would have caused it to no longer be it, it would have been reported as a miss.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3042#issuecomment-2196399245:118,update,updated,118,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3042#issuecomment-2196399245,1,['update'],['updated']
Deployability,"> flit install --pth-file --deps=production doesn’t work with setuptools-scm (just in conda?); >; > Fix: it needs setuptools_scm, which is in the dev extra. We need to document this. I had run into a problem with. ```; flit install --pth-file --deps=develop; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1527#issuecomment-760135174:7,install,install,7,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527#issuecomment-760135174,2,['install'],['install']
Deployability,"> hi @yotamcons ,; > ; > thanks a lot for the feedback, we'd really appreciate if you could submit a PR fixing these parts of the documentations that needs to be updated. Happy to support if you need any help,; > ; > Thank you!. Would love to starting November, ping me if thats still relevant",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2301#issuecomment-1233189531:162,update,updated,162,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2301#issuecomment-1233189531,1,['update'],['updated']
Deployability,"> in the outs/spatial file, change the tissue_positions.csv to tissue_positions_list.csv, it should work out. Doing this will cause issues when you try to spatially plot the data because the coordinates dtype is a string instead of int. You have to also do this suggestion after: https://github.com/scverse/squidpy/issues/623#issuecomment-1339403351. It would be great if the next scanpy release included the read_visium() update or revisit the idea to [remove it in scanpy in favor of squidpy](https://github.com/scverse/scanpy/issues/2331).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2488#issuecomment-1652910834:388,release,release,388,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2488#issuecomment-1652910834,2,"['release', 'update']","['release', 'update']"
Deployability,"> it would still be the older conda-forge version that gets installed. This could be overcome by pinning the channel but I agree it could be an issue if not explicitly specified. > Also there is [no mention of singularity in the bioconda docs](https://bioconda.github.io/search.html?q=singularity). This is the Github repo used for all of the automation and is hosted by the Galaxy project:; https://github.com/BioContainers/singularity-build-bot. As others have mentioned here, it would be awesome to have the latest versions of `scanpy` on Bioconda because it is the primary channel for most Bioinformatics tools. This also allows other communities like nf-core to piggy back off their automation to make our lives easier when writing reproducible, standardised workflows. @grst did come up with a couple of workarounds like adding a mulled container with scanpy but that adds a maintenance overhead to keep things up-to-date. How much work would it be to make this happen @ivirshup and would you be willing to help?. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2281#issuecomment-1160340283:60,install,installed,60,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281#issuecomment-1160340283,1,['install'],['installed']
Deployability,"> it's annoy. Sounds like annoy is being … annoying :smile:. > In future, could you not force push while responding to review?. Okay! Hmm, generally IDK what the best approach is since I now know how I want to rebase the commits but I’ll probably forget later … Maybe indicate in the message which commit they “fixup”?. Also: can we reenable squash/rebase merges soon?. > Doc builds failures do seem related to this, however. The docs failure is ugly to fix, but I did it …. Since very shortly ago, (pypa/pip#9320) pip validates wheels and for some reason decided that pluses in wheel filenames are not valid (I couldn’t find that in any spec). I hope takluyver/flit#388 gets merged soon to circumvent/fix that. If we want to temporarily circumvent that we’d have to tell readthedocs to use pip 20.3.3 version (like I did in the pipelines yaml). And that’s ugly because we’d have to add a requirements file that contains just `pip==20.3.3`, since readthedocs doesn’t allow to specify a pip version or a literal list of requirements.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1527#issuecomment-777397179:829,pipeline,pipelines,829,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527#issuecomment-777397179,1,['pipeline'],['pipelines']
Deployability,"> just mention this PR with brief description and your name here: https://github.com/theislab/scanpy/blob/master/docs/release-latest.rst. ok, done. I put it in the ""on master"" section",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1506#issuecomment-744317801:118,release,release-latest,118,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506#issuecomment-744317801,1,['release'],['release-latest']
Deployability,"> like pip install .[dev,test$(test_extras))], and run things once with test_extras='' and once with test_extras=',leiden,magic,harmony,scrublet,scanorama,skmisc'. Yeah, I was thinking something like this. Except we could just reduce `test` to include the barebones needed to make tests run, and separately have optional dependencies. The hard part here is structuring the tests so they can run without optional dependencies being present. We'd need to establish patterns for optional dependencies in fixtures and parameterized tests.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2211#issuecomment-1088721539:11,install,install,11,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2211#issuecomment-1088721539,1,['install'],['install']
Deployability,"> pip install git+git://github.com/theislab/scanpy.git . should have worked, there seems to be a problem with your git installation or internet. > importlib_metadata.PackageNotFoundError: scanpy. That’s my mistake, seems like a broke installing from .zips (not that anyone tried so far, installing from git is more convenient). > pip install https://github.com/theislab/scanpy.git. This won’t work, `pip install http...` means “install me a `sdist` or `wheel` downloadable from that URL”, but there’s no sdist or wheel at that URL, but a git repository. > git clone --recursive git://github.com/theislab/scanpy.git. again, this should work, probably a problem with your internet or git installation.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/838#issuecomment-533014138:6,install,install,6,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838#issuecomment-533014138,8,['install'],"['install', 'installation', 'installing']"
Deployability,"> scvelo depends on scanpy>=1.5, so I don't think this is the cause. Do you know why this is happening, and can you provide counter examples where it doesn't happen?. Ah weird. Pip tries to resolve the dependencies, and for that purpose gets all the installed packages’ metadata, then tries to figure out a configuration of upgrades that makes things work. No idea why it sees “1.7.0rc2” and decides “I’ll update this even when not asked to update”. Maybe raise this issue with pip?. > I'm not sure what you mean by this. Does flit install -s --deps=develop not count as reinstalling? Are you counting flit install -s as a development install?. Yes, that’s a reinstall in some development mode. My point was that if a scanpy pre-1.7 version really was installed, maybe pip was correct to update to 1.7 for some reason. However since we’re past 1.7 now, unless you haven’t git-pulled yet, I assume your dev install’s metadata has gone stale. I guess pip wouldn’t uninstall your dev install if you had run `git pull && flit install -s`, therefore updating the metadata. But I could be wrong, as I have no idea why pip thought it necessary to touch scanpy when installing scvelo. > I think pinning pip to an old version is worse than using a common, even if non-standard, installation method. Our setup.py is a compatibility shim solely for fallback use, not something to be relied upon in any part of our process. Usually when something does an arbitrary change making our life harder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right?. > It looks like the direction the discussion is headed is PEP 427 is wrong, and pip is right. Accepted PEPs are specs, so only pip and flit can be right or wrong (as they implement it). If people decide that what pip does happens to be *better* than the currently spec-compliant behavior, the spec can be changed accordingly. Until then pip is wrong, so we should pin its version to one that accepts sp",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1527#issuecomment-783309298:250,install,installed,250,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527#issuecomment-783309298,11,"['configurat', 'install', 'update', 'upgrade']","['configuration', 'install', 'installed', 'update', 'upgrades']"
Deployability,"> see that it can process arrays now, i should check if it better to replace the custom implementation with the updated stats.mannwhitneyu. It still doesn't work with sparse arrays, and our version on a sparse array was much faster than theirs on a dense. I did not compare speeds for dense v dense.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1892#issuecomment-864875522:112,update,updated,112,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1892#issuecomment-864875522,1,['update'],['updated']
Deployability,"> sklearn has also had a PR on this topic out for a long time and it just does not seem to budge. Allowing sparse support for PCA doesn't seem to be high on their priority list(?). I've read that situation as that particular PR being stalled, but it's also just for the random solver. I think sklearn would really like to have this feature. I think there's support for this from the community (where the referenced comment is yours):. > The perfect implementation of implicit data centering must be solver agnostic, allowing any matrix-free sparse PCA and SVD solver from scipy and scikit to be used. E.g., adding support to call any matrix-free scikit SVD/PCA solver in #12794 (comment) would make it perfect PR for implicit data centering. Do you think you could make a PR with this to sklearn? I'd like to see the response it gets, and judge based on that. My preference would be for this to go there, but I'm very open to having this in our codebase until it's in a `sklearn` release. > what's the best way of sharing the reproducing jupyter notebook with you?. Ha, that's actually a difficult question. I'm not quite sure, zip file should be fine. Thanks for sharing!. Ideally what I'd like from a benchmark of performance would be time and memory usage for the product of these conditions:. * Datasets size (one small, one large (>50k cells)); * Implicit centering, densifying centering, no centering; * single threaded, multi-threaded. I'd also lean towards making this the default for sparse data. But to do that, I will need to look a little closer at correctness. For that, could you show the average residual from a few runs (with different seeds) for all output values between implicit vs explicit centering?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1066#issuecomment-589500984:980,release,release,980,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1066#issuecomment-589500984,1,['release'],['release']
Deployability,"> sometimes we have math expressions like var = mean * mean^2 etc. in the docs. Is there a convention for scanpy docs if those should be in code format or just plain text?. I'm not sure, I think with math is nicer but not aware of any convention. @ivirshup ?. > I think the .._pca function is missing from the release note. should I add it there?; The ..pca function also did not use shared docs params yet. I started adding them and can commit tomorrow - is that okay if I just do it like that?. must say I missed those sorry, feel free to add and I'll take a look again tomorrow and wrap it up.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1715#issuecomment-1065373944:310,release,release,310,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715#issuecomment-1065373944,1,['release'],['release']
Deployability,"> tests that check if combinations of input arguments lead to expected output (in terms of returned shapes/columns/...) and don't break the function; tests that check if warnings/errors are raised for ""common mistakes"" (inappropriate data, nonsense input argument combinations..). yes both makes sense, it would also be useful to come up with a dummy example for which the actual output could be tested against. This is done in seurat_v3 for instance, but in that case it's kind of straightforward because the ""expected"" is the output computed with original implementation (and as you catched in #1732 it's still might not be enough 😄 ).; another random thing that comes to mind re this specific case is to make sure that indexing etc. is consistent and robust, as you seem to have to sort and resort a fair bit in the hvg implementation. on another note, I was thinking if it makes sense to also release a short tutorial together with the PR (that would be on theislab/scanpy_tutorials) ? I think that for a lot of people the term ""pearson residuals"" could be alienating, and so they'd rather stick to `normalize_total` for comfort (but they shouldn't!). So maybe just something easy like pearson res norm + umap and hvg plots ? curious to hear what you and the others @ivirshup @LuckyMD think about it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1715#issuecomment-797462245:897,release,release,897,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715#issuecomment-797462245,1,['release'],['release']
Deployability,"> the newest versions of leidenalg and igraph should be compatible with each other. update both, e.g. `pip install -U leidenalg igraph`; > ; > `python-igraph` is no longer necessary, you can remove it. Thanks for your help!that‘s works！！！",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2339#issuecomment-1647473441:84,update,update,84,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2339#issuecomment-1647473441,2,"['install', 'update']","['install', 'update']"
Deployability,"> the problem is related to the palette being used. The color palette is taken from the scatter plots. A way to fix this is by running for example `sc.pl.umap(adata, palette='Blues')`. Then run the heatmap again. Does it work if I manually update the adata.uns['louvain_colors'] ?; It feels weird to run umap just to create the slot for colormap althought it worked for me.; Just want to double check.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/548#issuecomment-490092784:240,update,update,240,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/548#issuecomment-490092784,1,['update'],['update']
Deployability,"> there is still a large amount of changes to the dataframe code here. Not really changes: it’s almost all refactoring, because the code was spaghetti with quite some duplication. I’m doing nothing more than. 1. I introduce helper functions so code gets more readable, e.g. a clean `disp_cut_off = _nth_highest(dispersion_norm, n_top_genes)` instead of a large inline code block that has to be decyphered line by line to figure out that it finds the nth highest value. This is especially necessary for the huge main pile of spaghetti that used to be the `if flavor == ""seurat"":`/`elif flavor == ""cell_ranger"":` branches. I simply put their contents into a `_get_mean_bins` helper and two helpers `_stats_seurat` and `_stats_cell_ranger` (while deduplicating shared code); 2. Making sure pandas indices match up while removing `.to_numpy()`. That way instead of having `.to_numpy()` potentially copy and and convert data in extension arrays, the series are just used directly. Not to mention that three `.to_numpy()` per line make things hard to read.; 3. refactor the 5 cutoff parameters into one value `cutoff` for clarity, less inline code, and better type information (we either have either `n_top_genes: int` or a `_Cutoffs` instance, never both. This way, the type system knows). and that’s it. <ins>potentially</ins> faster, much more maintainable, and almost dask-compatible. After my changes, it should be easier to further refactor things so the seurat_v3 flavor is integrated into the overall structure instead of doing its own thing.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2809#issuecomment-1929321140:1475,integrat,integrated,1475,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2809#issuecomment-1929321140,1,['integrat'],['integrated']
Deployability,"> wait to merge this until skmisc has a new release. Are we in a rush? We are upper bounding right now anyway on the current release, no? I would just wait.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3115#issuecomment-2182869254:44,release,release,44,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3115#issuecomment-2182869254,2,['release'],['release']
Deployability,"> we're not using pytest-xdist here. Ah. you do install it in the minimum-tests PR though. I guess that means that you intended the min-deps install script for local CI as well. anyway, LGTM!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2843#issuecomment-1934505176:48,install,install,48,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2843#issuecomment-1934505176,2,['install'],['install']
Deployability,"> what about `X_coords` ?. Ha, I was mostly just trying to get rid of the `X_`!. > What about re-open the theislab/spatial branch and merge this PR there? I could then work on how to handle the new uns structure in the plotting functions and have a definitive version of multiple slices support in anndata. I'd like to merge the changes currently in this PR to master since it fixes a bug with dataset reading. The changes to uns structure could go in another PR, but I'm waiting for an email back from 10x to make sure using the `library_id` as a key makes sense. Either way, the logic of getting the transformed coordinates etc. should be abstracted into a function so it's easy to change. Update: heard back, the `library_id` should be fine, at least for this version. > support for multiple slices should be first. I'm not sure I'm convinced of this. I've also already got some code ready to go for the connectivities and some examples of what can be done with it. I'd like to hear what kind of stuff you want to be able to do with multiple slices. Are you interested in stitching together slides or holding arbitrary slides in an AnnData? I think I'd like to see a more fleshed out idea of what kinds of analysis could be done here before deciding on what kind of an API this should have, and cases we should be ready to handle. Also, I think spatial plotting code should get moved out of `sc.pl.embedding` before we allow plotting multiple slides at a time.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1088#issuecomment-596860000:692,Update,Update,692,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1088#issuecomment-596860000,1,['Update'],['Update']
Deployability,"> yes, they are annoying particularly because is not possible to actually check why a test failed on the server while passes locally. . @fidelram, from your comment (https://github.com/theislab/scanpy/pull/1551#issuecomment-761117523), makes me think you'd like to enable this? If you okay this, all this needs to be ready to merge is: . - [x] Figure out where result xml should live; - [x] `.gitignore` update; - [x] Remove failing test (just there as an example); - [x] Document where to find this stuff",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1587#issuecomment-761748373:404,update,update,404,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1587#issuecomment-761748373,1,['update'],['update']
Deployability,"> your logging still has fractions of a second in there. Shouldn’t be possible, in 709bafb8ed600daf5f9ee995a0dc845ac1e7e605 I set the microseconds to 0, and in `timedelta.__str__`, microseconds [only get added](https://github.com/python/cpython/blob/83cec020ba177fa27727330ba4ccf60eebc22a54/Lib/datetime.py#L596-L597) if they’re >0. > I tried updating datetime in case that's secretly responsible, as you seem to use it internally for time tracking. How so? It’s a stdlib module, you can’t update it without updating Python itself.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/746#issuecomment-514121664:490,update,update,490,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/746#issuecomment-514121664,1,['update'],['update']
Deployability,">> for normalize_pearson_residual, i think it makes sense to keep normalize in, as it's not the same type of transformation compared to log1p. > Isn't this quite similar to what log1p does though? In that it's a transformation of the matrix?. I think it should stay `normalize_pearson_residuals` because it mirrors `normalize_total`. for the rest, I think we are at a good stage, I'd ask @jlause to build docs locally `cd scanpy/docs` and then `make clean` and `make html` see https://scanpy.readthedocs.io/en/stable/dev/documentation.html#building-the-docs; and check that:; - arguments and doc params match; - typo and other minor issues still present (e.g. difficult phrasing). . if this gets approval, before merging to master todo:; - [x] add release note; - [ ] go over scanpy_tutorials and re run tutorial and merge; - [x] link tutorial in docs. p.s. docs are failing for reasons I have haven't figured out yet",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1715#issuecomment-1054373951:748,release,release,748,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715#issuecomment-1054373951,1,['release'],['release']
Deployability,>Could epiScanpy be used as a multi-modal analysis tool ? @falexwolf. I think this is a question that is best asked in the episcanpy forum:; https://github.com/colomemaria/epiScanpy/issues. They have used it for multiple epigenomics modalities. Not sure if integrated though.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/479#issuecomment-510453095:257,integrat,integrated,257,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/479#issuecomment-510453095,1,['integrat'],['integrated']
Deployability,"?src=pr&el=tree#diff-c2NhbnB5L3Bsb3R0aW5nL19tYXRyaXhwbG90LnB5) | `97.87% <ø> (ø)` | |; | [scanpy/plotting/\_preprocessing.py](https://codecov.io/gh/theislab/scanpy/pull/1693/diff?src=pr&el=tree#diff-c2NhbnB5L3Bsb3R0aW5nL19wcmVwcm9jZXNzaW5nLnB5) | `87.75% <ø> (ø)` | |; | [scanpy/plotting/\_qc.py](https://codecov.io/gh/theislab/scanpy/pull/1693/diff?src=pr&el=tree#diff-c2NhbnB5L3Bsb3R0aW5nL19xYy5weQ==) | `88.23% <ø> (ø)` | |; | [scanpy/plotting/\_rcmod.py](https://codecov.io/gh/theislab/scanpy/pull/1693/diff?src=pr&el=tree#diff-c2NhbnB5L3Bsb3R0aW5nL19yY21vZC5weQ==) | `100.00% <ø> (ø)` | |; | [scanpy/plotting/\_stacked\_violin.py](https://codecov.io/gh/theislab/scanpy/pull/1693/diff?src=pr&el=tree#diff-c2NhbnB5L3Bsb3R0aW5nL19zdGFja2VkX3Zpb2xpbi5weQ==) | `83.75% <ø> (ø)` | |; | [scanpy/plotting/\_tools/\_\_init\_\_.py](https://codecov.io/gh/theislab/scanpy/pull/1693/diff?src=pr&el=tree#diff-c2NhbnB5L3Bsb3R0aW5nL190b29scy9fX2luaXRfXy5weQ==) | `76.27% <ø> (ø)` | |; | [scanpy/plotting/\_tools/paga.py](https://codecov.io/gh/theislab/scanpy/pull/1693/diff?src=pr&el=tree#diff-c2NhbnB5L3Bsb3R0aW5nL190b29scy9wYWdhLnB5) | `67.70% <ø> (ø)` | |; | [scanpy/plotting/\_tools/scatterplots.py](https://codecov.io/gh/theislab/scanpy/pull/1693/diff?src=pr&el=tree#diff-c2NhbnB5L3Bsb3R0aW5nL190b29scy9zY2F0dGVycGxvdHMucHk=) | `86.80% <ø> (ø)` | |; | ... and [58 more](https://codecov.io/gh/theislab/scanpy/pull/1693/diff?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/theislab/scanpy/pull/1693?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/theislab/scanpy/pull/1693?src=pr&el=footer). Last update [c943b93...1cc4115](https://codecov.io/gh/theislab/scanpy/pull/1693?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1693#issuecomment-785678892:3160,update,update,3160,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1693#issuecomment-785678892,1,['update'],['update']
Deployability,@BrianLohman ; I can't reproduce this. Could you please update scanpy and check?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1485#issuecomment-722581382:56,update,update,56,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1485#issuecomment-722581382,1,['update'],['update']
Deployability,"@Intron7 FYI: the release notes were in the wrong file. this is in milestone 1.9.4, so they go in the 1.9.4 file",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2589#issuecomment-1668113430:18,release,release,18,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2589#issuecomment-1668113430,1,['release'],['release']
Deployability,@Intron7 code for below link may work for only csr matrix. ; https://github.com/IntelLabs/Open-Omics-Acceleration-Framework/blob/main/pipelines/single-cell-RNA-seq-analysis/notebooks/fastpp.py#L499-L522,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3135#issuecomment-2275907097:134,pipeline,pipelines,134,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3135#issuecomment-2275907097,1,['pipeline'],['pipelines']
Deployability,@Koncopd Any update on this?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1391#issuecomment-698869934:13,update,update,13,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1391#issuecomment-698869934,1,['update'],['update']
Deployability,"@Koncopd Hi, Thank you for the pointer. It seems to be a problem caused by pytables package. But I still couldn't import tables after installing and uninstalling pytables packages for many times. And I'm in Windows system.; (base) C:\Users\yuhong>python; ```; (base) C:\Users\yuhong>conda list | grep pytables; pytables 3.6.1 py37h14417ae_3 conda-forge ; Python 3.7.8 | packaged by conda-forge | (default, Jul 31 2020, 01:53:57) [MSC v.1916 64 bit (AMD64)] on win32; Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.; >>> import tables; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\tables\__init__.py"", line 99, in <module>; from .utilsextension import (; ImportError: DLL load failed: The specified procedure could not be found.; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1468#issuecomment-716168232:134,install,installing,134,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1468#issuecomment-716168232,1,['install'],['installing']
Deployability,@Koncopd it is a correlation between two continuous variables as celltypes are continuous and age is also continuous. how to correlate X with continuous variables stored in .obs ?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1845#issuecomment-848118263:41,continuous,continuous,41,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1845#issuecomment-848118263,4,['continuous'],['continuous']
Deployability,@Koncopd said in https://github.com/theislab/scanpy/pull/1377#issuecomment-675422847 that he has problems with the package metadata being found. Which is extremely weird as `flit install --symlink` creates both a symlink and package metadata:. ```console; $ ls -l ~/.conda/envs/anndata/lib/python3.8/site-packages/ | grep anndata; lrwxrwxrwx 49 phil 2020-08-18 14:30 anndata -> ~/Dev/Python/Single Cell/anndata/anndata; drwxr-sr-x - phil 2020-08-18 14:30 anndata-0.7.5.dev9_gd32f11b.dist-info; ```. @Koncopd does that help? please post your stack trace before and after this PR so I see what’s going on. And also please post if the `.dist-info` directory has been created. Maybe we need to recommend `--pth-file` for windows users.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1378:179,install,install,179,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1378,1,['install'],['install']
Deployability,"@Koncopd, I just tried out the new release candidate for umap and get errors though out the ingest tests. It looks like `umap` now relies on `pynndescent` and some functions are no longer available. Here's an example traceback:. ```pytb; ------------------------------------------------------------------------------------------------------------------- Captured stderr call -------------------------------------------------------------------------------------------------------------------; running ingest; ______________________________________________________________________________________________________________ test_ingest_map_embedding_umap ______________________________________________________________________________________________________________. def test_ingest_map_embedding_umap():; adata_ref = sc.AnnData(X); adata_new = sc.AnnData(T); ; sc.pp.neighbors(; adata_ref, method='umap', use_rep='X', n_neighbors=4, random_state=0; ); sc.tl.umap(adata_ref, random_state=0); ; > ing = sc.tl.Ingest(adata_ref). scanpy/tests/test_ingest.py:132: ; _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ; scanpy/tools/_ingest.py:270: in __init__; self._init_neighbors(adata); _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . self = <scanpy.tools._ingest.Ingest object at 0x140357550>, adata = AnnData object with n_obs × n_vars = 6 × 5 ; uns: 'neighbors', 'umap'; obsm: 'X_umap'. def _init_neighbors(self, adata):; from umap.distances import named_distances; > from umap.nndescent import (; make_initialisations,; make_initialized_nnd_search,; ); E ImportError: cannot import name 'make_ini",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1036:35,release,release,35,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1036,1,['release'],['release']
Deployability,"@Koncopd, ah, this was as far back as I could trace the code initially: https://github.com/theislab/scanpy/commit/af4a82a2540eee65c732cb5e401d2145846e6d97. Now I've found an earlier commit from @falexwolf at https://github.com/theislab/scanpy/commit/43e71fe8577a8b3a51dc2117bd431911001d9869. @falexwolf, does this change look right to you?. @LuckyMD, I'm not sure if this would count as backward breaking if it's a bug. Should definitely go into the release notes, maybe as warning.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/705#issuecomment-507008710:450,release,release,450,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/705#issuecomment-507008710,1,['release'],['release']
Deployability,"@Koncopd, could we have a meeting or VC on the progress here? Let's discuss via email. 🙂 . @tomwhite, any updates from @lmcinnes regarding integrating the distributed version of `pynndescent` into UMAP itself? I'm not 100% convinced to mingle with private functions within UMAP that might eventually break (another reason for why I copied over code from UMAP back in January/February 2018). It would be nice to have Leland's OK for adding distributed aspects to the package. Scanpy would then just make use of them... @tomwhite, by this, also many other single-cell packages (many of them use UMAP these days) would profit from the new distributed computing capabilities.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/522#issuecomment-476592722:106,update,updates,106,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/522#issuecomment-476592722,2,"['integrat', 'update']","['integrating', 'updates']"
Deployability,"@Koncopd, there was a bugged release of pip. I think this should work now that there has been a bugfix",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2255#issuecomment-1134725877:29,release,release,29,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2255#issuecomment-1134725877,1,['release'],['release']
Deployability,"@LuckyMD . Hi, LuckyMD. I tried pip uninstalling igraph and pip installing python-igraph and got the following error:. ""Installing collected packages: texttable, python-igraph; ERROR: Could not install packages due to an EnvironmentError: [Errno 5] Input/output error: '/home/blahblah/miniconda2/envs/funkyLab/lib/python3.7/site-packages/igraph/drawing/__pycache__' "". It doesn't say anything more. Do you have an idea of what the problem may be? . Thank you.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/807#issuecomment-638548074:64,install,installing,64,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/807#issuecomment-638548074,3,"['Install', 'install']","['Installing', 'install', 'installing']"
Deployability,@LuckyMD Could you also add this fix to the release notes?; https://github.com/theislab/scanpy/blob/master/docs/release-latest.rst,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1464#issuecomment-717201928:44,release,release,44,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1464#issuecomment-717201928,2,['release'],"['release', 'release-latest']"
Deployability,@LuckyMD I checked the commits. Between the Scanpy version on agando and the latest release the `marker_genes_overlap` was not changed. But maybe I am blind.; I'll go for the empirical route and try it out. Will report back!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1625#issuecomment-772439376:84,release,release,84,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1625#issuecomment-772439376,1,['release'],['release']
Deployability,@LuckyMD Ok. For me it seems that the packages can be differentiated by using `from gprofiler import GProfiler` for official package (for `python-gprofiler` this is `from gprofiler import gprofiler`). Possibly this allows to control if `gprofiler-official` is installed and used.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/467#issuecomment-504998754:260,install,installed,260,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/467#issuecomment-504998754,1,['install'],['installed']
Deployability,@LuckyMD is your fix (https://github.com/theislab/scanpy/pull/824) in the released scanpy or still only on master?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/935#issuecomment-559305432:74,release,released,74,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/935#issuecomment-559305432,1,['release'],['released']
Deployability,"@LuckyMD, I think you can get the docker environment travis uses. * [Docker image for travis python env](https://hub.docker.com/r/travisci/ci-python); * [Guide on running it](https://andy-carter.com/blog/setting-up-travis-locally-with-docker-to-test-continuous-integration). I did this a couple years ago, but I know travis has changed a bunch since then. Another good first step would be to figure out if it only fails on the first build, and if caches are being used in any way. Also, do the builds ever fail for forks? I don't think they've been failing [for me](https://travis-ci.org/ivirshup/scanpy/builds).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/580#issuecomment-478823933:250,continuous,continuous-integration,250,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/580#issuecomment-478823933,1,['continuous'],['continuous-integration']
Deployability,"@LuckyMD, do you think you ever saw a change without version updates? I'd like to think we were aware of changes through our tests (in particular tests for plotting and the pbmc notebook). However calculations change for different dataset sizes, so we could be missing cases where there's instability.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1363#issuecomment-678129332:61,update,updates,61,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1363#issuecomment-678129332,1,['update'],['updates']
Deployability,"@LustigePerson, would you be able to add a quick test here? Then this could get into the next release",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2190#issuecomment-1081869351:94,release,release,94,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2190#issuecomment-1081869351,1,['release'],['release']
Deployability,@MichaelPeibo Could you install the version 1.4.5.post1? It is not available in conda and with 1.4.4.post1 I'm getting the same error. Thanks!. ```; conda search -c bioconda scanpy; Loading channels: done; # Name Version Build Channel ; scanpy 1.3.1 py36_0 bioconda ; scanpy 1.3.2 py36_0 bioconda ; scanpy 1.3.3 py36_0 bioconda ; scanpy 1.3.4 py36_0 bioconda ; scanpy 1.3.5 py36_0 bioconda ; scanpy 1.3.6 py36_0 bioconda ; scanpy 1.3.7 py36_0 bioconda ; scanpy 1.4 py_0 bioconda ; scanpy 1.4.1 py_0 bioconda ; scanpy 1.4.2 py_0 bioconda ; scanpy 1.4.3 py_0 bioconda ; scanpy 1.4.4 py_0 bioconda ; scanpy 1.4.4 py_1 bioconda ; scanpy 1.4.4.post1 py_0 bioconda ; scanpy 1.4.4.post1 py_1 bioconda ; scanpy 1.4.4.post1 py_2 bioconda ; ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/942#issuecomment-577681828:24,install,install,24,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/942#issuecomment-577681828,1,['install'],['install']
Deployability,"@Mr-Milk I see. I think right now, it's probably not going to go into scanpy pre 2.0.0 (as marked by the milestone). @flying-sheep is leading the new plotting effort so I'll step back. But roughly from my perspective, 1. seems useful perhaps for some internal stuff but 2. seems perhaps a point against integrating directly since; > this design doesn't make much difference compared to directly using Marsilea. Maybe there's some middle ground? Some definte API for integration into 2.0.0 that wouldn't require full integration but could give this sort of `return` functionality?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2444#issuecomment-2371719939:303,integrat,integrating,303,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2444#issuecomment-2371719939,3,['integrat'],"['integrating', 'integration']"
Deployability,"@PrimozGodec, probably don't add this to `requirements.txt`, since the requirement should be optional for install. I think instead you should mark it with something like:. ```python; from importlib.util import find_spec. @pytest.mark.skipif(find_spec('pointannotator') is None, reason=""pointannotator not installed""); ```. You can add a requirement for the package to this line in `setup.py`: https://github.com/theislab/scanpy/blob/d8f32c040f3a5f4fc07998b269796ca58de84b40/setup.py#L41. Maybe we should eventually have a second requirements file for CI testing, like we do for anndata.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/812#issuecomment-537465652:106,install,install,106,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/812#issuecomment-537465652,2,['install'],"['install', 'installed']"
Deployability,"@RicedeKrispy ; Hi, if you are using Windows, you can try to install python-igraph from the wheel here; https://www.lfd.uci.edu/~gohlke/pythonlibs/#python-igraph",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/138#issuecomment-495938081:61,install,install,61,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/138#issuecomment-495938081,1,['install'],['install']
Deployability,"@RubenVanEsch Yes, and the issue there is that we're not the ones calling `randint`. We may be able to hack it. I'll have a look at how the pipeline errors out on our CI to maybe see where the call is coming from.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2969#issuecomment-2034529457:140,pipeline,pipeline,140,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969#issuecomment-2034529457,1,['pipeline'],['pipeline']
Deployability,"@TheAustinator, can you replicate this in a fresh environment (e.g. conda)? It could help to limit the number of other installed packages. @flying-sheep, any ideas?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1496#issuecomment-729533125:119,install,installed,119,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496#issuecomment-729533125,1,['install'],['installed']
Deployability,"@WeilerP would you be willing to write a tiny test and to add the release note, please?. Thanks! Happy to merge this then if you ping me. @ivirshup generally, I agree. Think that this tiny change doesn't harm though and deprecating the magic ""read"" is something bigger.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1969#issuecomment-1291807007:66,release,release,66,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1969#issuecomment-1291807007,1,['release'],['release']
Deployability,"@Zethson Ready to merge. Thanks for your feedback; I added to the release notes, and rebased on master.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1828#issuecomment-1004540184:66,release,release,66,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1828#issuecomment-1004540184,1,['release'],['release']
Deployability,"@Zethson added a fix for this to #2566. if you install `scanpy[leiden]`, it’ll make sure the correct versions are installed",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2341#issuecomment-1645373691:47,install,install,47,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2341#issuecomment-1645373691,2,['install'],"['install', 'installed']"
Deployability,"@Zethson re your comment (https://github.com/theislab/scanpy/pull/2028#issuecomment-956365435), what were you thinking for a patch?. Disallowing `0.5.2`? Or make a fix for that version?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2026#issuecomment-959058930:125,patch,patch,125,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2026#issuecomment-959058930,1,['patch'],['patch']
Deployability,"@a-munoz-rojas Thanks for checking and thank you very much for the PR :smile! I like your version of the implementation a lot better than the manual one, as the code is much more readable. I don't know why @tcallies added the wilcoxon this way at the time, but I assume for speed and memory reasons. So, I'm very happy to merge this PR; I'll just briefly give this another check today or tomorrow and update the tests so that they don't fail anymore. Regarding the general discussion: Yes, let's just add a disclaimer that several assumptions on how meaningful the null hypotheses are both for wilxocon and t-test for single-cell data, should do the job. Then people will interpret the p-values with care.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/270#issuecomment-427040589:401,update,update,401,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/270#issuecomment-427040589,1,['update'],['update']
Deployability,@adamgayoso A recent update of seaborn caused some trouble with the tests but is now fixed. Can you merge with master to trigger again the tests?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1421#issuecomment-697317906:21,update,update,21,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1421#issuecomment-697317906,1,['update'],['update']
Deployability,@adamgayoso I don't think it fits under the other preprocessing tool headings of Data integration or Imputation. Maybe add a new one called Call hashing or Sample demultiplexing. @fidelram thoughts? Not sure who else to tag,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1483#issuecomment-722042260:86,integrat,integration,86,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1483#issuecomment-722042260,1,['integrat'],['integration']
Deployability,"@adamgayoso, I should definitely get around to merging this. I think I can pretty much do it as is, and open a second issue for getting the docs looking good. I'd like to target an initial `metrics` module for `1.8` (we're working on upping the release cadence as well). Question for your lab, are our implementations equivalent? I haven't actually gotten around to testing against the `VISION` R/C++ version.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/915#issuecomment-763302767:245,release,release,245,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/915#issuecomment-763302767,1,['release'],['release']
Deployability,@aditisk I'm the author of this method https://github.com/calico/solo. it should install relatively easily if you have any issues I'm happy to help. The main functionality it doesn't have is `tag_groups` so you'd have t manually create that if you have used multiple hashes per group.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/351#issuecomment-601407528:81,install,install,81,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/351#issuecomment-601407528,1,['install'],['install']
Deployability,"@alam-shahul I'd suggest you to look into the squidpy plotting functionalities here: https://squidpy.readthedocs.io/en/latest/examples.html#plotting and here: https://squidpy.readthedocs.io/en/latest/api/squidpy.pl.spatial_scatter.html#squidpy.pl.spatial_scatter; they cointain an updated version of the scanpy plotting spatial, which will be deprecated. I'll close this comment and please re open one if relevant in squidpy",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2316#issuecomment-1249573153:281,update,updated,281,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2316#issuecomment-1249573153,1,['update'],['updated']
Deployability,"@andrea-tango @MichaelPeibo To address the filtering of rank_genes_groups (eg. `min.pct = 0.25, logfc.threshold = 0.25`) I recently added a function called `sc.tl.filter_rank_genes_groups`. See https://github.com/theislab/scanpy/pull/425. @falexwolf I don't know why`sc.tl.filter_rank_genes_groups` does not show up in the docs. I will take a look. Also, I just noticed that this PR with updated examples is still open. I think it would be useful to merge: https://github.com/theislab/scanpy_usage/pull/11",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/460#issuecomment-471531524:388,update,updated,388,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/460#issuecomment-471531524,1,['update'],['updated']
Deployability,"@bebatut Thank you for pointing that out. I will as well take a look at it. . @falexwolf I will make sure to keep it in mind for further updates. The restructuring of the package structure came with the update from 1.x to 2.x and was necessary for some major improvements. I'm sorry for caused inconveniences. @bebatut if you have further questions or issues, please let me know, I'd be happy to help you out. Ron",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/310#issuecomment-431115831:137,update,updates,137,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/310#issuecomment-431115831,2,['update'],"['update', 'updates']"
Deployability,"@bgruening I would be interested to hear your perspective on this, and hear any corrections. Apologies if any comments were unfair. My comments were definitely coloured by painful memories of debugging via CI for a release that just went live – which is always an emotional experience 😅. One thing I was wrong about: bioconda does have autoupdates. For whatever reason, it just looks like the scanpy recipe required a fair bit of manual intervention.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2281#issuecomment-1160759818:215,release,release,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281#issuecomment-1160759818,1,['release'],['release']
Deployability,@brianpenghe Hi may I consult how you resolved the problem?. The comment says upgrade anndata to 0.8.0 but mine already is 0.8.0 and the error message remains.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2297#issuecomment-1447928394:78,upgrade,upgrade,78,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297#issuecomment-1447928394,1,['upgrade'],['upgrade']
Deployability,"@brianpenghe I believe it'll work if you manually update `adata.uns[""louvain_colors""]`, at least it does for the scatter plots. It is weird. We've talked a bit about having a better API for this here #596.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/548#issuecomment-490100552:50,update,update,50,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/548#issuecomment-490100552,1,['update'],['update']
Deployability,"@cartal @SamueleSoraggi ; For some reason I decided to integrate Scrublet using Scanpy's functions where possible, rather than making a simple wrapper. The core functionality is up and running in [this fork](https://github.com/swolock/scanpy), and now I just need to add documentation, make some of the code more Scanpythonic(?), and add an example.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/173#issuecomment-492900457:55,integrat,integrate,55,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/173#issuecomment-492900457,1,['integrat'],['integrate']
Deployability,@charles-xu-ru you could also try installing numba from conda before installing scanpy. pytables better to install from conda-forge channel along with h5py.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2173#issuecomment-1065067859:34,install,installing,34,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2173#issuecomment-1065067859,3,['install'],"['install', 'installing']"
Deployability,@chris-rands Any update on this? Does the code from @ivirshup gives you any meaningful results?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/767#issuecomment-526496705:17,update,update,17,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/767#issuecomment-526496705,1,['update'],['update']
Deployability,"@davidsebfischer @falexwolf Also, where can we get this package? I tried doing a pip install, and while the package is listed the installation failed.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/159#issuecomment-420413750:85,install,install,85,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/159#issuecomment-420413750,2,['install'],"['install', 'installation']"
Deployability,"@dawe Could you also please provide a brief tutorial on how to install `scanpy` on M1? I am having troubles. I have followed [this tutorial ](https://medium.com/geekculture/the-best-way-to-setup-your-m1-mac-for-python-development-fb5dffd08fd) to set up python on my M1 Mac. Thus I have installed `miniforge` with `brew`. My versions are `Python 3.9.6` and `pip 21.2.4`. Also I have read that you succeed in install `scanpy` with `python 3.8` but I am not able to downgrade version. The error I face when I run `pip3 install scanpy` is:. ```; ERROR: Command errored out with exit status 1: /opt/homebrew/Caskroom/miniforge/base/bin/python3.9 -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '""'""'/private/var/folders/y_/5kkrlhbj2v1bch8snxxws28c0000gn/T/pip-install-6blz73pw/h5py_c0efce6062af4b4d9f6564a97c24d1a7/setup.py'""'""'; __file__='""'""'/private/var/folders/y_/5kkrlhbj2v1bch8snxxws28c0000gn/T/pip-install-6blz73pw/h5py_c0efce6062af4b4d9f6564a97c24d1a7/setup.py'""'""';f = getattr(tokenize, '""'""'open'""'""', open)(__file__) if os.path.exists(__file__) else io.StringIO('""'""'from setuptools import setup; setup()'""'""');code = f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' install --record /private/var/folders/y_/5kkrlhbj2v1bch8snxxws28c0000gn/T/pip-record-lf5rwuj7/install-record.txt --single-version-externally-managed --compile --install-headers /opt/homebrew/Caskroom/miniforge/base/include/python3.9/h5py Check the logs for full command output.```. Thank you in advance!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1840#issuecomment-930949004:63,install,install,63,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1840#issuecomment-930949004,9,['install'],"['install', 'install-', 'install-headers', 'install-record', 'installed']"
Deployability,"@dawe, I just updated the requirements for `scvelo`. The latest version on `develop/` should now work for you.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1799#issuecomment-822545856:14,update,updated,14,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799#issuecomment-822545856,1,['update'],['updated']
Deployability,"@doncarlos999 , can you please confirm that you have the latest version of MAGIC? You can do this by running; ```; import magic; magic.__version__; ```; MAGIC was only very recently (four days ago!) updated to support scanpy, so if you don't have version 1.1.0, I recommend reinstalling:; ```; pip install --upgrade --user git+git://github.com/KrishnaswamyLab/MAGIC.git#subdirectory=python; ```; Thanks for using MAGIC!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/206#issuecomment-405262289:199,update,updated,199,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/206#issuecomment-405262289,3,"['install', 'update', 'upgrade']","['install', 'updated', 'upgrade']"
Deployability,@dorzhey can you reproduce this with the latest scanpy release? I believe it should be fixed there.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2967#issuecomment-2022656658:55,release,release,55,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2967#issuecomment-2022656658,1,['release'],['release']
Deployability,"@erikadudki If you are willing to dabble in R, the [scDD package](https://www.bioconductor.org/packages/release/bioc/html/scDD.html) seeks to address this problem specifically. It may also be worth looking at for inspiration if you want to pursue your own implementation in python.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1086#issuecomment-615129230:104,release,release,104,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1086#issuecomment-615129230,1,['release'],['release']
Deployability,"@falexwolf , I used '0.4.2' version, I will update to the latest.; Thanks, scanpy is powerful tool for single cell RNASeq data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/94#issuecomment-370292754:44,update,update,44,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/94#issuecomment-370292754,1,['update'],['update']
Deployability,@falexwolf - feedback here would be appreciated. We are weary of rolling our own solution when a standard may be in place or planned.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/106#issuecomment-378689095:65,rolling,rolling,65,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/106#issuecomment-378689095,1,['rolling'],['rolling']
Deployability,"@falexwolf . > we shouldn't transition quickly and immediately; for the cosmetic reasons and for the reason of staying away from creating entry hurdles. Got it! so no “move fast and break things” but instead to identify problems and fix them before they occur. I think the most painful issues here are. 1. the signature rendering in ipython. Fixed in ipython/ipython#11505, We might incorporate a fix right now ourselves by monkey-patching `inspect.Signature.__str__` if we want. 2. losing contributions because of an entry hurdle. Hard to measure if this happens. If we lose someone, they won’t announce it. So maybe friendly [PR/issue templates](https://help.github.com/articles/about-issue-and-pull-request-templates/) or [contributing guidelines](https://help.github.com/articles/setting-guidelines-for-repository-contributors/) might help prevent that!. ---. > if you feel you have bandwidth for improving the cosmetics (thanks for what you did already, also the PR to ipython) that lead to more homogeneous docstrings (I'd say: `Union[a, b] → a, b`), of course, please go ahead. Will do, but a comma is ambiguous, as it could mean union, intersection, or (in Python) tuple. I think `Union[a, b, c]` → `a, b, or c` would be clearer. I think we should leave everything else as is: `Option[...]`, is clear enough, and `Callable` is better than introducing our own syntax (Some other languages know things like `(a, b) -> c` as type for functions, but Python doesn’t). > When we have converged on new docstrings and canonical type annotations so that at least people who really know what they're doing (@ivirshup) don't feel things are ambiguous anymore (say in a year), we can start to rigorously ask for them. good call! I might just edit them in-PR as I did to fix the colormaps in @fidelram’s last PR.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/373#issuecomment-441590874:431,patch,patching,431,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/373#issuecomment-441590874,1,['patch'],['patching']
Deployability,"@falexwolf @ivirshup we have a lot of fixes on master, let’s release 1.4.5.1 after this one. As an aside I think our versioning is a bit weird: Why did we do a feature release called 1.4.5 and not 1.5? Why not semver-lite like python itself?. - major version (x.0) bumps for vast breaking changes; - minor version (1.x) bumps for new features and minor, long-deprecated breaking changes; - patch version (1.4.x) bumps for fixes",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1042:61,release,release,61,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1042,3,"['patch', 'release']","['patch', 'release']"
Deployability,"@falexwolf @pwl i used this one, works fine: https://gist.github.com/flying-sheep/0e003ae3398dd543638955a55c031c8d. i wonder why you didn’t have to install the dev packages though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/43#issuecomment-344278619:148,install,install,148,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/43#issuecomment-344278619,1,['install'],['install']
Deployability,"@falexwolf Can you take a look at the updated gist: https://gist.github.com/fidelram/8b43f786e7519bcfb7ffc0d5ccdbb0fe. Most of the previous and new plots are quite similar. For diffmap I see different results but I suspect that there is a bug in the previous code. Also, I don't have any example with arrows. Do you have any?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/244#issuecomment-420917087:38,update,updated,38,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/244#issuecomment-420917087,1,['update'],['updated']
Deployability,"@falexwolf I think it is worth to have a `scanpy.plugin` or `scanpy.extension` or something shorter like `scanpy.pg` or `scanpy.ext` that aggregates all plugins. First, this clarifies for the user that the tool he/she is using is not directly developed by scanpy. Second, this allows plugins to be installed separately without having to update scanpy's code. The idea is that scanpy will be able to discover any plugins installed. On the side of developers, this could facilitate integration with scanpy. We can get inspired by flask extensions: http://flask.pocoo.org/docs/1.0/extensiondev/",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/265#issuecomment-423915827:298,install,installed,298,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/265#issuecomment-423915827,4,"['install', 'integrat', 'update']","['installed', 'integration', 'update']"
Deployability,"@falexwolf I took the opportunity to add a change that I wanted with respect to the palette which is the ability to set a palette based on a matplotlib colormap. For example using `palette='tab20'`:. ![image](https://user-images.githubusercontent.com/4964309/46139067-dcf34180-c24d-11e8-892a-a6f3bbda2c4b.png). or using `palette='Set3'`. ![image](https://user-images.githubusercontent.com/4964309/46139126-feecc400-c24d-11e8-9e34-f8395c70aeb9.png). I didn't want to modify the previous code that handles setting the palette to avoid breaking other code, but if we have some tests for other functions that use that functionality I could try to update the original methods.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/244#issuecomment-425036021:643,update,update,643,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/244#issuecomment-425036021,1,['update'],['update']
Deployability,@falexwolf I updated the visualizations example notebook to reflect the changes: https://github.com/theislab/scanpy_usage/pull/11,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/528#issuecomment-471660400:13,update,updated,13,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/528#issuecomment-471660400,1,['update'],['updated']
Deployability,"@falexwolf any update on the plug-ins idea for scanpy?. On Sun, Feb 3, 2019 at 4:50 PM Alex Wolf <notifications@github.com> wrote:. > Merged #457 <https://github.com/theislab/scanpy/pull/457> into master.; >; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/pull/457#event-2114366554>, or mute; > the thread; > <https://github.com/notifications/unsubscribe-auth/AEu_1auPPM2VVhh2E_5Gwd8djTqP9ltAks5vJwVLgaJpZM4agJQ1>; > .; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/457#issuecomment-460063532:15,update,update,15,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/457#issuecomment-460063532,1,['update'],['update']
Deployability,"@falexwolf, @flying-sheep . From the discussion on #45, I think some more discussion should be had as to what imputation methods are to be included in scanpy. Validation of and comparisons between the currently available imputation methods are both severely lacking---I only know of [1][2][3][4][5], none of which include comprehensive benchmarks, and the updated MAGIC (#187) article at Cell doesn't include relevant comparisons between current methods. . I'd be very interested in hearing/having an open discussion about the motivation, benefits, and limitations of the various imputation methods available. [1]: Zhang and Zhang, 2017. https://www.biorxiv.org/content/early/2017/12/31/241190; [2]: Lopez et al. 2018, https://www.biorxiv.org/content/early/2018/03/30/292037; [3]: Li and Li, 2018. https://www.nature.com/articles/s41467-018-03405-7; [4]: Eraslan et al. 2018. https://www.biorxiv.org/content/early/2018/04/13/300681; [5]: Huang et al. 2018. https://www.biorxiv.org/content/early/2018/03/08/138677",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/189:356,update,updated,356,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/189,1,['update'],['updated']
Deployability,"@fbrundu I just had the exact same error after installing from cloned master, so just wondering if it's working for you now.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/585#issuecomment-480647524:47,install,installing,47,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/585#issuecomment-480647524,1,['install'],['installing']
Deployability,"@fidelram . * Cool. I think I had gotten confused about some of the labelling on there which I'm going to blame jet lag for 😊; * Using the `inline` backend with ~300k cells, it takes about 5 seconds per plot for me. Since I'm trying to improve the experience of sitting with a biologist figuring out labels for clusters, this is a little slow once you get to 5 or more plots – especially when you just want to update one. From `%prun`, it looks like about half of `matplotlib`'s plotting time is spent figuring out where to put points, and the extents of the plot, so I figured that could be a good target for optimization. I've looked into copying the plot after layout, but before coloring, but I'm not sure how feasible that is.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/244#issuecomment-427228991:410,update,update,410,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/244#issuecomment-427228991,1,['update'],['update']
Deployability,"@fidelram I've made sure that only `use_raw` or `layer` has been specified, though the default of `use_raw` being True is still used if `layer` isn't set. I think it would be good if this was covered in the docs for `use_raw` as well. I also get tripped up by `use_raw` pretty frequently. I think a warning for this behavior would be good, but I don't like the idea of the default setting issuing a warning. What if we changed the default to false? This would need a deprecation warning for a bit and waiting until the next big release though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/730#issuecomment-511257594:528,release,release,528,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/730#issuecomment-511257594,1,['release'],['release']
Deployability,"@fidelram It might be that the new plotting backend doesn't support the ""additional colors"" ([here](https://github.com/theislab/scanpy/blob/7c9fb1a5f2293956adda0673d47e7dec1b32ddfb/scanpy/plotting/utils.py#L166-L186)) anymore. These are colors that are standard in R and used for the Planaria example. We should try to integrate them for the sake of easily moving between python and R.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/286#issuecomment-427909754:319,integrat,integrate,319,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/286#issuecomment-427909754,1,['integrat'],['integrate']
Deployability,"@fidelram Some help with the plotting tests is very much appreciated :) I don't get why only Python 3.6 test passes and others fail. For example; why does [this plot](https://github.com/theislab/scanpy/blob/master/scanpy/tests/_images/master_matrixplot_with_totals.png) which is produced by [this code](https://github.com/theislab/scanpy/blob/master/scanpy/tests/test_plotting.py#L357) where the color legend is defined [here](https://github.com/theislab/scanpy/blob/master/scanpy/plotting/_matrixplot.py#L74) as `Mean expression in group` have the old title which is `Expression level in group`? If the ""ground truth plots"" in the ""_images"" folder are outdated, aren't the tests supposed to fail since the [this commit](https://github.com/theislab/scanpy/commit/d4d373ea58b9add4451091c5650d4da245d025dc#diff-421b3afbcd51c81c45f23dd7e8483697b68668de9172f124ec6bf2f0523840d9L95) i.e. `Expression level in group` -> `Mean expression in group`, but they don't fail, why?. Another example: I have updated [this file](https://github.com/theislab/scanpy/blob/master/scanpy/tests/_images/master_matrixplot_with_totals.png) but not [that file](https://github.com/theislab/scanpy/blob/master/scanpy/tests/_images/master_matrixplot.png) which seem both outdated. But Python 3.6 test still seems to pass. How come? Are plotting tests disabled in Python3.6?. Plotting tests are extremely tricky and make it pretty difficult to contribute I must say :/ I think twice or three times when I want to change anything about plotting... (not a complaint addressed to @fidelram but something we should consider as a team)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1551#issuecomment-751396676:993,update,updated,993,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551#issuecomment-751396676,1,['update'],['updated']
Deployability,"@fidelram Sounds good---I'll update the code and then open a PR to get it added to the ecosystem docs. In my experience with HTOs (and now LMOs & CMOs), GMMs and even poisson/negative binomial mixture models don't work particularly well for all experiments as they tend to only call 50-70% of cells as singlets/multiplets. The remaining ""negatives"" or uncalled cells can really hamper some experimental designs (like when tags correspond to different conditions/perturbations). Anecdotally, multiplexing seems substantially more difficult to get right for tissues rather than blood or cell/organoid lines. . That said, I'd be interested in any plotting code you could share :). I very much appreciate all the plotting functionality you've implemented in scanpy!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/351#issuecomment-759554768:29,update,update,29,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/351#issuecomment-759554768,1,['update'],['update']
Deployability,"@fidelram Thank you for pointing this out. I did miss the `n_neighbors` parameter for `sc.pp.neighbors` function. It has default 15, while Seurat's have default 20 (and yes, they then prune the kNN). Adding this parameter did solve the discrepancy in the first dataset, but not the second, in the investigation (I have not updated the notebook). @LuckyMD Thank you! I really liked applying scArches, and it's also a very natural approach: having a reference, mapping to it. I hope we're moving towards that direction generally. Thank you for pointing out that Leiden is stochastic, I didn't realize that, and the fixed default random seed obscures it a little. I'll try to look at different seeds and assess the distribution of clustering. Can't estimate to which degree different runs would disagree. Indeed, it appears that scanpy does kNN and doesn't do any pruning (judging from my brief glance at the code). I honestly expected that some kind of pruning of the kNN graph would be there. I remember two talks, one from Dana Pe'er and one from Dominic Grün, that mentioned kNN pruning as a strategy to improve analysis. @dawe Thank you for linking to the resolution limit. However, I don't think it's the case here, because 2 of the 3 strategies that I tried did resolve those populations. . If we focus on dataset 2 (SC167) in the investigation, obviously, there's some small kNN topology difference between the strategies tried, that leads to SCT+scanpy strategy being slow to separate DC1 cells from B cells. I am mostly surprised that vanilla (log-norm) strategy does separate those cells. . I wonder how to go about investigating what drives that behaviour?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1531#issuecomment-739436787:323,update,updated,323,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1531#issuecomment-739436787,1,['update'],['updated']
Deployability,"@fidelram Thanks!. > I noticed two parameters in the embedding that I think belong only to the spatial.. Those are bw and alpha_img. In embeddings they do nothing. Yeah, those probably shouldn't get documented for functions like `sc.pl.umap`. > Other issue, that I don't expect to address at the moment, is the increase in parameters is becoming difficult to go through. I agree (related: #956). There are so many that I'm not sure alphabetical always makes sense? Perhaps they could be grouped into sections of related parameters? This would require some work on how the docs are generated. It would definitely be good to note when features were added. Related to this, I want to discuss versioning at the next meeting to figure out when this should go in a release.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1356#issuecomment-678115710:759,release,release,759,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356#issuecomment-678115710,1,['release'],['release']
Deployability,@fidelram i'll update this soon.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1391#issuecomment-698883595:15,update,update,15,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1391#issuecomment-698883595,1,['update'],['update']
Deployability,"@fidelram thanks for letting me know. I am using the command you suggested and still getting an error:. CCBR-KULKAMILT:~ kulkarnia2$ pip install git+https://github.com/theislab/scanpy.git; Collecting git+https://github.com/theislab/scanpy.git; Cloning https://github.com/theislab/scanpy.git to /private/var/folders/56/g1b462hs0d3816ktcj6twm8hmsw5ch/T/pip-req-build-o4lkd6tp; xcrun: error: invalid active developer path (/Library/Developer/CommandLineTools), missing xcrun at: /Library/Developer/CommandLineTools/usr/bin/xcrun; Command ""git clone -q https://github.com/theislab/scanpy.git /private/var/folders/56/g1b462hs0d3816ktcj6twm8hmsw5ch/T/pip-req-build-o4lkd6tp"" failed with error code 1 in None",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/544#issuecomment-475325377:137,install,install,137,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/544#issuecomment-475325377,1,['install'],['install']
Deployability,"@fidelram that's a really great point and something I'd like to discuss at next meeting (already put it in the agenda). Another great example of such examples 😅 is the way @michalk8 set it up for [cellrank](https://cellrank.readthedocs.io/en/latest/auto_examples/index.html) and squidpy [not yet public].; The even nicer thing is that @michalk8 implemented a CI pipeline for the tutorials/examples part of the repo so that every time there is a change in master of the original repo, the examples are refreshed in the notebooks repo, so to have them always up to date. Would be really cool to concentrate efforts and try to get this logic also in scanpy (makes it both very user friendly and robust from a maintainer perspective)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1604#issuecomment-765363376:362,pipeline,pipeline,362,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1604#issuecomment-765363376,1,['pipeline'],['pipeline']
Deployability,"@fidelram, I really like your plotting gallery! Would be cool to have that as part of the tutorials or even integrated in the main documentation (enhance each plotting function with an example image?)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/369#issuecomment-441069177:108,integrat,integrated,108,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/369#issuecomment-441069177,1,['integrat'],['integrated']
Deployability,"@fidelram, I've updated this so the tests pass, and think I've caught a few more bugs. Hopefully I didn't misinterpret your intent here, but I'm merging as we'd like to get a release out. Please let me know if I've messed anything up!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1529#issuecomment-865866325:16,update,updated,16,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1529#issuecomment-865866325,2,"['release', 'update']","['release', 'updated']"
Deployability,"@flying-sheep @falexwolf this is a first stab at reorganizing the release notes to facilitate bugfix releases. Using the example of the current release cycle:. The idea is that PRs which are bug fixes would have their change added to the `1.7.1.rst` release notes. New features are added to `1.8.0.rst` (which will be added in a follow up PR, since this pr will be back ported to the `1.7.x` branch). This way we don't mix all changes on master in one file, meaning we don't have to figure out what changes are included when making a release, as this information has been collected ahead of time. What I'd like to happen, is that `latest` builds will show changes for unreleased `1.7.1` and `1.8.0`, while the the `1.7.x` branch just shows `1.7.1`. ## TODO. - [x] Figure out how exactly release-latest works. What are the latest additions for ""Latest build"" vs. ""Stable"" and how should they differ.; - `release-latest.rst` will differ between stable and dev branches.; - [x] Why isn't release latest being added right to `docs/index.rst`; - [x] Process for adding new release note files should be added to dev docs.; - [x] Fix links to PAGA website",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1628:66,release,release,66,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1628,9,['release'],"['release', 'release-latest', 'releases']"
Deployability,@flying-sheep @ivirshup The default continuous color map is usually set using `sc.set_figure_params` in the example tutorials. I am not totally sure but I think that internally the `rcParams` are modified. Maybe you can also mention this on the improved documentation.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/477#issuecomment-462743341:36,continuous,continuous,36,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/477#issuecomment-462743341,1,['continuous'],['continuous']
Deployability,"@flying-sheep Hi, I tried to install the new version of scanpy, but encountered errors. first, I tried your code ; ```; pip install git+https://github.com/theislab/scanpy.git ; ```; I got ouput as:; ```; Collecting git+https://github.com/theislab/scanpy.git; Cloning https://github.com/theislab/scanpy.git to /tmp/pip-_z2v8och-build; fatal: Unable to find remote helper for 'https'; Command ""git clone -q https://github.com/theislab/scanpy.git /tmp/pip-_z2v8och-build"" failed with error code 128 in None; ```. second, I tried; ```; pip install git+git://github.com/theislab/scanpy.git ; ```; I got ouput as:; ```; Collecting git+git://github.com/theislab/scanpy.git; Cloning git://github.com/theislab/scanpy.git to /tmp/pip-2jry40l_-build; ```; and there was no more information and I have to stop it with ""ctrl+C"". third, I tried to download the zip and `cd` to that directory and used . ```; python setup.py build; ```. I got ouput as:. ```; importlib_metadata.PackageNotFoundError: scanpy; ```. after this, I tried . ```; pip install -e .; ```. I got ouput as:. ```; Command ""python setup.py egg_info"" failed with error code 1 in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/; ```. I searched the relative information in GitHub/Scanpy, but still have no solution for my situation. the following was another failed code. ``` ; pip install https://github.com/theislab/scanpy.git; ```. output:. ```; Collecting https://github.com/theislab/scanpy.git; Downloading https://github.com/theislab/scanpy.git; \ 143kB 442kB/s; Cannot unpack file /tmp/pip-chtzh_a9-unpack/scanpy.git (downloaded from /tmp/pip-xolhyav7-build, content-type: text/html; charset=utf-8); cannot detect archive format; Cannot determine archive format of /tmp/pip-xolhyav7-build; ```. and i also tried. ```; git clone --recursive git://github.com/theislab/scanpy.git; ```. output:. ```; Cloning into 'scanpy'...; remote: Enumerating objects: 122, done.; remote: Counting objects: 100% (122/122), done.; remote: Compressi",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/838#issuecomment-532985027:29,install,install,29,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838#issuecomment-532985027,3,['install'],['install']
Deployability,"@flying-sheep I got the similar result. ```python; >>> scanpy-master]$ ls; conftest.py CONTRIBUTING.md docs LICENSE MANIFEST.in pyproject.toml pytest.ini README.rst requirements.txt scanpy setup.py; >>> scanpy-master]$ git init; Reinitialized existing Git repository in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/.git/; >>> scanpy-master]$ git tag v1.4.5.dev0; fatal: Failed to resolve 'HEAD' as a valid ref.; >>> scanpy-master]$ pip install -e .; Obtaining file:///public-supool/home/wuhaoda/Scanpy/Download/scanpy-master; Complete output from command python setup.py egg_info:; Traceback (most recent call last):; File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 25, in <module>; from setuptools_scm import get_version; ModuleNotFoundError: No module named 'setuptools_scm'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""<string>"", line 1, in <module>; File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/setup.py"", line 11, in <module>; from scanpy import __author__, __email__; File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 29, in <module>; __version__ = version(__name__); File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/_utils.py"", line 29, in version; return version(package); File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 438, in version; return distribution(package).version; File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 411, in distribution; return Distribution.from_name(package); File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 184, in from_name; raise PackageNotFoundError(name); importlib_metadata.PackageNotFoundError: scanpy. -----------------------",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/838#issuecomment-533019090:449,install,install,449,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838#issuecomment-533019090,1,['install'],['install']
Deployability,"@flying-sheep I think the [code added in that PR](https://github.com/scverse/scanpy/pull/2816/files#diff-5d0e683154209be7830f09b5389551bf9700a4184d08e97c46c23e2e4beb54a0) is minimally relevant to what happened here. > when user specifies an order, we use that. Right, so here the issue is that the category ordering is used for the labelling but we were not imposing it on the data itself when the violin plots render (separate from the axis labels, as the actual violin plots are added row-by-row). > if not, we rely on the DataFrame order for plotting, we don’t store this implicit order explicitly. In some sense the above also applies. If we want to add some sort of user-facing part of the API to allow for ordering, that is fine, but I think that should be separate as it would go into the next minor release and this is a fairly large bug. I'm fine not testing this because I genuinely don't know how and I spent a few hours yesterday trying different things to no avail.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3196#issuecomment-2271132251:807,release,release,807,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3196#issuecomment-2271132251,1,['release'],['release']
Deployability,"@flying-sheep I tried running `pip install 'scanpy @ git+https://github.com/scverse/scanpy@modern-rng' ` in anaconda prompt and got ERROR: Invalid requirement: ""'scanpy"".",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3028#issuecomment-2085623955:35,install,install,35,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028#issuecomment-2085623955,1,['install'],['install']
Deployability,"@flying-sheep I'm thinking we should switch to using conda-forge for distributing scanpy. Right now, we're having trouble maintaining the bioconda builds. We already use conda-forge for anndata, so I think it would reduce the maintenance burden to consolidate our build systems. Also, I find conda-forge's tooling and documentation much easier to follow. I've started setting up a conda-forge recipe, which has gone pretty well. However I'm running into one issue with the tests. It looks like we don't bundle the `conftest.py` file at our project root with the rest of scanpy. This leads to the flaky internet tests being run when the conda package is built. Not sure how to deal with this at the moment. Update: Also `test_regress_out_ordinal` seems to hang forever when testing the build.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1169:706,Update,Update,706,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1169,1,['Update'],['Update']
Deployability,"@flying-sheep Thought it'd be minor enough to skip a release note, but I added one now. Thanks.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2798#issuecomment-1884401677:53,release,release,53,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2798#issuecomment-1884401677,1,['release'],['release']
Deployability,"@flying-sheep To answer your question. Honestly, I am not so familiar with Plotnine, Plotly or Altair. However, after a quick revision I would say that Altair seems quite interesting and possibly were I could had reused/extended some code. Yet, at the moment in scanpy we use matplotlib extensively and I didn't even think about the other APIs. Looking closely at Altair I realized that I have a lot to catch up regarding Vega, Vega-lite and the idiosyncrasies specific to Altair before I could start using it. . Thus, the current effort only integrates the idea of 'chaining' seen in Altair (or in other context in Pandas). In Plotly or Plotnine the 'chaining' is achieved differently but I don't find it as nice or straightforward:. **Plotly:**; ```PYTHON; import plotly.graph_objects as go; fig = go.Figure(; data=[go.Bar(x=[1, 2, 3], y=[1, 3, 2])],; layout=go.Layout(; title=go.layout.Title(text=""A Bar Chart""); ); ); fig.show(); ```; **Plotnine:**; ```PYTHON. from plotnine import ggplot, geom_point, aes, stat_smooth, facet_wrap; from plotnine.data import mtcars. (ggplot(mtcars, aes('wt', 'mpg', color='factor(gear)')); + geom_point(); + stat_smooth(method='lm'); + facet_wrap('~gear')); ```; **Altair:**; ```PYTHON; import altair as alt; from vega_datasets import data. source = data.cars(). alt.Chart(source).mark_circle(size=60).encode(; x='Horsepower',; y='Miles_per_Gallon',; color='Origin',; tooltip=['Name', 'Origin', 'Horsepower', 'Miles_per_Gallon']; ).interactive(); ```; The current solution, although using method chaining, is very *ad hoc* for a specific type of graphs that have predetermined features, like 'dendrogram' or totals for categories or 'brackets' to highlight features.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1127#issuecomment-607888729:543,integrat,integrates,543,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1127#issuecomment-607888729,1,['integrat'],['integrates']
Deployability,"@flying-sheep and anyone interested: I started putting the notebooks on `scanpy-tutorials`: https://github.com/theislab/scanpy-tutorials and https://scanpy.readthedocs.io/en/latest/tutorials.html now links to the docs generated from `scanpy-tutorials`. I'm doing it like this for now as it's quite a bit less work than getting everything to run on readthedocs, there might indeed be problems with the runtime for building the docs and I think this updated solution isn't so bad after all... . Opinions are welcome!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/302#issuecomment-447622248:448,update,updated,448,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/302#issuecomment-447622248,1,['update'],['updated']
Deployability,@flying-sheep do you need a release note here?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3328#issuecomment-2449687504:28,release,release,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3328#issuecomment-2449687504,1,['release'],['release']
Deployability,"@flying-sheep no worries! We'll steadily increase test coverage. I assume that almost no one should have run into the bug in the past 22 days. Among those that updated their version, only very few will have run the PCA with sparse data... @Koncopd, I'm very happy if you move forward with a proper sparse implementation of PCA! :smile:",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/393#issuecomment-447614569:160,update,updated,160,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/393#issuecomment-447614569,1,['update'],['updated']
Deployability,"@flying-sheep sorry for the trouble, I have updated my code and output.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/850#issuecomment-532633516:44,update,updated,44,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/850#issuecomment-532633516,1,['update'],['updated']
Deployability,"@flying-sheep, I see you're doing some updates here. Are you doing anything to narrow the scope of the PR as requested last go-around?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2235#issuecomment-1597177367:39,update,updates,39,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2235#issuecomment-1597177367,1,['update'],['updates']
Deployability,"@flying-sheep, figured out (part of) why I'm seeing the wrong version for the wheel, but the right version for the sdist via `flit build`. When the wheel is built, it hits this case:. https://github.com/theislab/scanpy/blob/3c7256560f53374ecf960bc329405912da8d6efe/scanpy/_metadata.py#L35-L41. Where it sees the currently installed version, which may not be aware of new tag (since I'm making the build in a clean directory). I imagine this is why using `python -m build` get's it right, since it's building everything in a fresh environment. However, getting this issue with the METADATA for the sdist generating warnings, but not having this problem with the wheel: . ```; $ twine check dist/*; Checking dist/scanpy-1.8.1-py3-none-any.whl: PASSED; Checking dist/scanpy-1.8.1.tar.gz: PASSED, with warnings; warning: `long_description_content_type` missing. defaulting to `text/x-rst`.; warning: `long_description` missing.; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1909#issuecomment-875415985:322,install,installed,322,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1909#issuecomment-875415985,1,['install'],['installed']
Deployability,"@flying-sheep, for this, were you thinking to update `adata.obs_vector` to throw errors with ambiguities , `sc.get.obsdf`, or both?. I'm wondering if there should be some period of deprecation warnings for that. I also think it's fair to consider it a bug.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1116#issuecomment-600108886:46,update,update,46,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1116#issuecomment-600108886,1,['update'],['update']
Deployability,"@flying-sheep, was this fixed by the recent update?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1011#issuecomment-1959463716:44,update,update,44,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1011#issuecomment-1959463716,1,['update'],['update']
Deployability,"@gatocor Thanks, for me it worked with `pip install --pre numba`, ; terminal output:; ```; Requirement already satisfied: numba in ./venv/lib/python3.9/site-packages (0.51.2); Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in ./venv/lib/python3.9/site-packages (from numba) (0.34.0); Requirement already satisfied: numpy>=1.15 in ./venv/lib/python3.9/site-packages (from numba) (1.20.1); Requirement already satisfied: setuptools in ./venv/lib/python3.9/site-packages (from numba) (54.0.0); ```. Went back into Python Console, re-do `import numba`, `numba.__version__` still gives `'0.51.2'`. How do you force it to load a different version?. Update: Also tried the `force-reinstall` tag: `Successfully installed llvmlite-0.36.0rc2 numba-0.53.0rc2 numpy-1.20.1 setuptools-54.0.0`, but in Python Console it's still stuck at `numba.__version__ '0.51.2'`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1652#issuecomment-789673344:44,install,install,44,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1652#issuecomment-789673344,3,"['Update', 'install']","['Update', 'install', 'installed']"
Deployability,"@gatocor just tried it, but it says `Successfully uninstalled numba-0.53.0rc2`, then `Successfully installed numba-0.53.0rc2`. So it looks like my system/terminal has the right `numba` version, but I can't get Python Console to also see the new version?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1652#issuecomment-789707448:99,install,installed,99,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1652#issuecomment-789707448,1,['install'],['installed']
Deployability,@giovp . I solved the problem its scvelo and I have installed the package and now it works fine. Thank you,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1433#issuecomment-704255621:52,install,installed,52,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1433#issuecomment-704255621,1,['install'],['installed']
Deployability,"@giovp I haven't been able to work around the issue. When I rebuild a container with different versions of scanorama, scanpy, numpy, scikit-learn I end up with errors. Most of the time it's this ValueError about the wrong shape. The only different error I noticed is when I tried scanorama 1.6 and there was an error about `concatenate()` not being an available function. . Whenever you find time to update the tutorial, that will be greatly appreciated.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2143#issuecomment-1054575633:400,update,update,400,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2143#issuecomment-1054575633,1,['update'],['update']
Deployability,@giovp I want to make correlation plot between cell types and the continuous variables stored in .obs,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1845#issuecomment-848077091:66,continuous,continuous,66,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1845#issuecomment-848077091,1,['continuous'],['continuous']
Deployability,@giovp do we have an update on merging this yet? Anything left on my end?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2296#issuecomment-1314154765:21,update,update,21,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2296#issuecomment-1314154765,1,['update'],['update']
Deployability,"@giovp looking at this again, it seems you drop the mixed up columns anyway (https://github.com/scverse/squidpy/blob/fb069ded7515e8a1386224d32344a8657cbecd2e/squidpy/read/_read.py#L100) so I'd suggest having one code path with the correct column names. Please let me know if you need more clarity and help getting this over the hump for release.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2296#issuecomment-1265541010:337,release,release,337,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2296#issuecomment-1265541010,1,['release'],['release']
Deployability,"@giovp, I'll merge this. I'm merging a couple other things first though. I'm not super happy with the logic flow here at the moment. Could we aim for separating out the code for scatter plots, and overlaying grids on-top of images in the next release cycle?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1217#issuecomment-630021238:243,release,release,243,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1217#issuecomment-630021238,1,['release'],['release']
Deployability,"@giovp, I've thought about this a bit more and think it should be treated as an image rather than a scatterplot. This is so future updates to the spatial plotting function (like plotting hexagons) won't require a special case here. If you can't find a scale factor, could we just say it's 1?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1149#issuecomment-628371370:131,update,updates,131,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1149#issuecomment-628371370,1,['update'],['updates']
Deployability,"@giovp, could you check the 1.8.0 release notes to make sure I got everyone's names?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1904:34,release,release,34,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1904,1,['release'],['release']
Deployability,"@giovp, how would you like to continue with this? We could either set an upper bound on `numba`, i.e. `numba<0.53.0`, or change how `umap-learn` is pinned. In the latter case, `umap-learn>=0.5.1` should work (see [here](https://github.com/lmcinnes/umap/releases/tag/0.5.1)). I think this approach would be best, since `numba>=0.53` supports `python>=3.9`.; Happy to open the PR if you agree. Would be good to decide on how to proceed ASAP as people keep running into issues when using `scvelo` or `cellrank`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1756#issuecomment-845723512:253,release,releases,253,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1756#issuecomment-845723512,1,['release'],['releases']
Deployability,"@giovp, that does seem bad, but we can consider that a separate issue, right?. Is the dendrogram bug important for the `squidgy` release?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1603#issuecomment-768033082:129,release,release,129,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1603#issuecomment-768033082,1,['release'],['release']
Deployability,@gokceneraslan - thanks for the fast response. This broke our (cellxgene) travis pipeline as well. Do you have any info on eta for a fix/workaround other than pinning the module version? TY!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/832#issuecomment-530530037:81,pipeline,pipeline,81,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/832#issuecomment-530530037,1,['pipeline'],['pipeline']
Deployability,@gokceneraslan . A fix is provided here https://github.com/theislab/scanpy/pull/1245. In the meanwhile until this PR is merged into a new release you can follow this https://github.com/dpeerlab/Palantir/issues/34#issuecomment-632933449,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1237#issuecomment-638408390:138,release,release,138,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1237#issuecomment-638408390,1,['release'],['release']
Deployability,"@gokceneraslan @ivirshup just checking in on this. Will this be part of the next release? Do you need anything else from me? It might be nice to note somewhere that when `batch_key` is not None, results aren't absolutely consistent with Seurat. > The problem appears to be due to the fact that many genes have the same normalized variance in a given batch and the merging method uses ranks. So I believe the difference is due to genes being sorted differently with the same normalized variance. Perhaps this merging scheme is not ideal.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1204#issuecomment-663879113:81,release,release,81,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1204#issuecomment-663879113,1,['release'],['release']
Deployability,"@gokceneraslan A few thoughts on this:. 1. In general, I don't like messing with global configurations for other packages.; 2. I generate many plots, but only a few are actually going to go to a manuscript. I'm not sure it's justified to increase all PDF sizes so that they're all editable. Maybe it should be opt-in? And do we need to mess with global settings to do this, or can we just make finding out about this easier for users?. What if there was an ""Plotting output options"" tutorial, which went over saving of figures? This could include a section on how to export for publication.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1720#issuecomment-792236673:88,configurat,configurations,88,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1720#issuecomment-792236673,1,['configurat'],['configurations']
Deployability,"@gokceneraslan Regarding the tests: yes, they are annoying particularly because is not possible to actually check why a test failed on the server while passes locally. I agree that this limits contribution because the mountain of work to get the tests working puts one off. For the particular question about the title difference: the test may be passing because of the 'threshold' used to call the images as different. Why we use a threshold? This is to avoid tests from failing due to small differences between matplotlib or other graphic libraries versions or fonts installed. However, sometimes the threshold may be masking some small problems, although in general I am quite happy because important differences not missed. . BTW: The image that you point out is clearly wrong but I updated it recently for other reason (PR #1584). Regarding the issue about adding `norm` as explicit parameter. I would suggest to add it if this just mean changing very few lines but I know this is lot of work (do we want tests for this?) for something that is already working. . Besides the very good review by Isaac I don't have much to add and will be happy to merge once some of the changes are taken care.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1551#issuecomment-761117523:568,install,installed,568,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551#issuecomment-761117523,2,"['install', 'update']","['installed', 'updated']"
Deployability,"@gokceneraslan Totally agree it's the user's responsibility. I would say that it's the devs responsibility to make it as easy as possible for the user. How about printing the absolute path of the data's destination on download?. @flying-sheep Would there necessarily be an error if space ran out? I could probably fit a few datasets in 2gb. From your previous depiction, I thought the older ones would just be deleted, right? If you had space for a couple datasets, wouldn't it be likely that installing a couple things with pip would clear these datasets on a system like we're describing? I'm not sure I find this behavior intuitive for this use case. Also here's the [docs](https://opus.nci.org.au/display/Help/Filesystems+User+Guide#FilesystemsUserGuide-DiskQuotaPolicy) for my HPCs filesystem. I don't have an `XDG_CACHE_HOME` variable set when I log in. I'm also not sure scanpy fits the app model. When I look in my `~/Library/Caches/` I see things like Illustrator, VSCode, and Slack. When I think about example datasets that are available through scientific computing packages I think of:. * `scikit-learn` – `~/scikit_learn_data`; * `seaborn` – `~/seaborn-data`; * `NLTK` – `~/nltk_data`; * `keras` and `tensorflow` – `~/.keras/datasets`; * `conda` – `~/miniconda3/`; * `intake` – `~/.intake/cache/` (specifically for caching feature); * CRAN and bioconductor data packages – same place as packages I think",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/558#issuecomment-476943448:493,install,installing,493,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-476943448,1,['install'],['installing']
Deployability,"@gokceneraslan. > I want the h5ad file to include absolutely everything, so that it can be simply used as a single file distribute the ""full dataset"". As a point about this, I don't think `raw` completley solves this problem. There's two reasons for this:. ### Only a different set of variables. Raw only differs from the main object by variables. But we just as often want to remove observations (doublet detection for example). To account for this, I think it makes sense to just have two different anndata objects. ### absolutely everything. I don't think we really can expect to have everything. There are always going to be analyses that require going back to the BAM. If ""single file"" is the issue, we could definitely allow something like:. ```python; with h5py.File(""analysis.h5"") as f:; processed = ad.read_h5ad(f[""processed""]); raw = ad.read_h5ad(f[""raw""]); ```. -----------------------------. @LuckyMD . > Integration works better with HVGs typically. I'm thinking of the case where I have a few datasets saved as `h5ad` that I want to integrate. What if a highly variable gene in one dataset just isn't present in another? Is it because it wasn't found in that dataset at all, or because it was only present in a few cells? If it was only present in a few cells, how can I be sure a particular cell type wasn't just poorly represented in that dataset?. I feel like it's helpful to have the all the measured genes present, so that when you do gather your datasets together you can select features from the full set. > > This does run into memory usage problems if want do a densifying transform on the data; > Don't understand this entirely... I was thinking about what happens if you do something like `sc.pp.scale`, where you don't have any 0s in your expression matrix anymore, so it has to be stored as a dense matrix. I believe this is why `raw` was even introduced originally, since the normalization workflow then was feature selection -> scale. It was wasteful to store the entire s",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1798#issuecomment-820902472:917,Integrat,Integration,917,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1798#issuecomment-820902472,1,['Integrat'],['Integration']
Deployability,"@hhhh1230511, this PR is not part of any release yet (the latest version `scanpy==1.6` was released August 15, 2020). If you want to have the latest version from GitHub you can follow the instructions for a developer installation [here](https://scanpy.readthedocs.io/en/stable/installation.html) in the documentation, for example. Once a new release is available on `pip`, you can install it via `pip install --upgrade scanpy`; In general, you should avoid modifying the code by e.g. simply copying and pasting. This will either easily cause conflicts when updating the package or cause problems when functions from other files which depend on the content you changed but were not updated accordingly. Hope this helped and clarified things.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1422#issuecomment-734460539:41,release,release,41,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1422#issuecomment-734460539,9,"['install', 'release', 'update', 'upgrade']","['install', 'installation', 'release', 'released', 'updated', 'upgrade']"
Deployability,@hl324 @glycoaddict can you try the fix here? https://github.com/scverse/scanpy/pull/3041. ```; pip install 'scanpy @ git+https://github.com/scverse/scanpy@modern-rng'; ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3028#issuecomment-2085152773:100,install,install,100,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028#issuecomment-2085152773,1,['install'],['install']
Deployability,"@hyjforesight no, that is a mess.; Could you try please 3 things:. 1. create fresh environment with python 3.8, install only pytables; `conda install pytables`; then run python and check; `import tables`; 2. create fresh environment with python 3.8, install only pytables from conda-forge; `conda install -c conda-forge pytables`; then run python and check; `import tables`; 3. create fresh environment with python 3.8 and install just scanpy (and nothing else); `conda install -c conda-forge scanpy`; then run python and check; `import scanpy`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2108#issuecomment-1013450589:112,install,install,112,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2108#issuecomment-1013450589,6,['install'],['install']
Deployability,@icml-compbio The `draw_graph` function calls out to `forceatlas2` if you have it installed. This does seem slower than using UMAP. @YubinXie I see some multithreading being used on my machine when I run `neighbors`. Is there none on yours? One thing I'd check first is to make sure UMAP is up to date and install `pynndescent`.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1242#issuecomment-632446507:82,install,installed,82,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1242#issuecomment-632446507,2,['install'],"['install', 'installed']"
Deployability,"@ilan-gold If you want to try it out, I give instructions for how to reproduce the error with a Docker container for Windows in the cross-referenced issue. I also have tried it on WSL, and the problem is *not* present on WSL, so this is a workaround for Windows users. However, I am organizing a Python workshop in a few weeks, and I think it would add some additional administrative burden/overhead to the workshop to coordinate installing and setting up WSL (as we see in #3041, Ruben had trouble installing WSL and others might as well.) So, for me, using WSL is a suboptimal workaround.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2969#issuecomment-2332444655:430,install,installing,430,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969#issuecomment-2332444655,2,['install'],['installing']
Deployability,"@ilan-gold turns out i cant install WSL on my laptop after all, so unfortunately i cant check this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3041#issuecomment-2090827588:28,install,install,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3041#issuecomment-2090827588,1,['install'],['install']
Deployability,"@ivirshup ""One issue with the enrichment as is, is that gprofiler-official import name conflicts with the previous unofficial wrapper. I'm worried that this will break peoples environments if they're not aware of this. @liiskolb, do you have any thoughts on this?"". I'm not really sure I got it right, but if new version of scanpy includes new version of gprofiler-official, then it should work well. If people have old version of scanpy that uses old version of gprofiler, then it should also work but with data from archived release of gprofiler. . With this kind of updates it is inevitable that some environments break (we have the experience as you can see;)), these just need to be solved case by case if people with problems start to contact. They could be advised to update their packages to solve these issues.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/467#issuecomment-484043323:527,release,release,527,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/467#issuecomment-484043323,3,"['release', 'update']","['release', 'update', 'updates']"
Deployability,"@ivirshup ; > * Could you show some examples of the new additions/ let me know where you are on tutorials?. I will do that once we are happy with the current code and naming conventions used. My goal was to update this tutorial https://scanpy-tutorials.readthedocs.io/en/latest/visualizing-marker-genes.html but suggestions are welcome. . > * Could you add tests for functionality where the underlying code is changing, but doesn't have coverage yet? I would mostly just like to see more tests of the plotting code. I will try to do that. > * What do you think about the idea of splitting up `_anndata.py` into a few more files? I think it's getting a bit too big, which can make reviewing difficult. We should to that. Currently, as I see it we have two types of plots: ; * embedding scatter plots which are separated already; * the type of plots in this PR that I would describe as `grouping` plots, because they visualize the AnnData matrix subdivided based on a .`obs` column. Any better name for this?. > * Could you run `black` over this?. Will do it at the end. Do we have some style policies for black or the defaults are fine?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1127#issuecomment-608262723:207,update,update,207,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1127#issuecomment-608262723,1,['update'],['update']
Deployability,"@ivirshup ; Hello ivirshup, thanks for the solution. I upgrade to py 3.8 and install scanpy 1.8.2, problem solved.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2045#issuecomment-963446967:55,upgrade,upgrade,55,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2045#issuecomment-963446967,2,"['install', 'upgrade']","['install', 'upgrade']"
Deployability,"@ivirshup ; Hello ivirshup, these error comes from the below environments. When I upgrade to py3.8 and use scanpy 1.8.2, everything works well. Thanks a lot!. <html xmlns:v=""urn:schemas-microsoft-com:vml""; xmlns:o=""urn:schemas-microsoft-com:office:office""; xmlns:x=""urn:schemas-microsoft-com:office:excel""; xmlns=""http://www.w3.org/TR/REC-html40"">. <head>. <meta name=ProgId content=Excel.Sheet>; <meta name=Generator content=""Microsoft Excel 15"">; <link id=Main-File rel=Main-File; href=""file:///C:/Users/Yuanjian/AppData/Local/Temp/msohtmlclip1/01/clip.htm"">; <link rel=File-List; href=""file:///C:/Users/Yuanjian/AppData/Local/Temp/msohtmlclip1/01/clip_filelist.xml"">; <style>; <!--table; 	{mso-displayed-decimal-separator:""\."";; 	mso-displayed-thousand-separator:""\,"";}; @page; 	{margin:.75in .7in .75in .7in;; 	mso-header-margin:.3in;; 	mso-footer-margin:.3in;}; tr; 	{mso-height-source:auto;; 	mso-ruby-visibility:none;}; col; 	{mso-width-source:auto;; 	mso-ruby-visibility:none;}; br; 	{mso-data-placement:same-cell;}; td; 	{padding-top:1px;; 	padding-right:1px;; 	padding-left:1px;; 	mso-ignore:padding;; 	color:black;; 	font-size:11.0pt;; 	font-weight:400;; 	font-style:normal;; 	text-decoration:none;; 	font-family:等线;; 	mso-generic-font-family:auto;; 	mso-font-charset:134;; 	mso-number-format:General;; 	text-align:general;; 	vertical-align:middle;; 	border:none;; 	mso-background-source:auto;; 	mso-pattern:auto;; 	mso-protection:locked visible;; 	white-space:nowrap;; 	mso-rotate:0;}; ruby; 	{ruby-align:left;}; rt; 	{color:windowtext;; 	font-size:9.0pt;; 	font-weight:400;; 	font-style:normal;; 	text-decoration:none;; 	font-family:等线;; 	mso-generic-font-family:auto;; 	mso-font-charset:134;; 	mso-char-type:none;; 	display:none;}; -->; </style>; </head>. <body link=""#0563C1"" vlink=""#954F72"">. Package | Version; -- | --; Anaconda | 2.1.0; Python | 3.6.13; anndata | 0.7.6; anyio | 2.2.0; argon2-cffi | 20.1.0; async-generator | 1.1; attrs | 21.2.0; Babel | 2.9.1; backcall | 0.2.0; ble",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2046#issuecomment-963453699:82,upgrade,upgrade,82,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2046#issuecomment-963453699,1,['upgrade'],['upgrade']
Deployability,"@ivirshup ; Yeah, it was the same data as the privious plot. I tried calling sc.tl.umap(sp, init_pos=""paga"") but meet an error. I just use the get_init_pos_from_paga function to solve this error as mention in #769 .Thanks!; ```; TypingError: Failed in nopython mode pipeline (step: nopython frontend); Invalid use of type(CPUDispatcher(<function rdist at 0x7f90e19f58c8>)) with parameters (array(float64, 1d, C), array(float64, 1d, C)); Known signatures:; * (array(float32, 1d, A), array(float32, 1d, A)) -> float32; * parameterized; [1] During: resolving callee type: type(CPUDispatcher(<function rdist at 0x7f90e19f58c8>)); [2] During: typing of call at /datc/dh_data/.conda_env/scrna/lib/python3.6/site-packages/umap/umap_.py (797). File ""../../../../.conda_env/scrna/lib/python3.6/site-packages/umap/umap_.py"", line 797:; def optimize_layout(; <source elided>. dist_squared = rdist(current, other); ^. This is not usually a problem with Numba itself but instead often caused by; the use of unsupported features or an issue in resolving types. To see Python/NumPy features supported by the latest release of Numba visit:; http://numba.pydata.org/numba-doc/latest/reference/pysupported.html; and; http://numba.pydata.org/numba-doc/latest/reference/numpysupported.html. For more information about typing errors and how to debug them visit:; http://numba.pydata.org/numba-doc/latest/user/troubleshoot.html#my-code-doesn-t-compile. If you think your code should work with Numba, please report the error message; and traceback, along with a minimal reproducer at:; https://github.com/numba/numba/issues/new",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/918#issuecomment-555516223:266,pipeline,pipeline,266,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/918#issuecomment-555516223,2,"['pipeline', 'release']","['pipeline', 'release']"
Deployability,"@ivirshup @dkobak I've fixed up this PR, so now it implements what I mentioned in my comment above. I've left a couple of comments on the code, commenting on anything noteworthy. The tests and everything will fail until I release a new version of openTSNE, which I'll do in the coming days. But please look through the changes and let me know if there's anything you'd like me to change, so we can get this merged. Also, I haven't updated the docstrings at all. The most glaring thing is `neighbors_tsne`. Over 90% of the code here is identical to `neighbors`. Really, the only difference is that I changed the `n_neighbors` parameter to `perplexity`. But there was no elegant way to incorporate that into `neighbors`. I've also tried refactoring the duplicated code that saves the settings into `adata.uns`, but doingt that would also make the code pretty messy. Obviously, it's not a good idea to have duplicated code like this. What do you think would be the best way to handle this?. Functionally, this now works as agreed. Let me know how you want to proceed.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1561#issuecomment-822033944:222,release,release,222,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561#issuecomment-822033944,2,"['release', 'update']","['release', 'updated']"
Deployability,"@ivirshup @fidelram ; updated, this should be ready for merge.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1391#issuecomment-703691873:22,update,updated,22,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1391#issuecomment-703691873,1,['update'],['updated']
Deployability,"@ivirshup @giovp I'm wondering whether you've had the time to look over this. If this PR is maybe too big a change, then perhaps it would make more sense to migrate to openTSNE in a more iterative approach. For instance, we could just replace the t-SNE implementation to openTSNE, ignoring the API discussion and ignoring the precomputed graphs. I think switching to openTSNE, regardless of integration, would make the t-SNE implementation faster. We could then go for tighter integration step by step. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1561#issuecomment-922497079:391,integrat,integration,391,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561#issuecomment-922497079,2,['integrat'],['integration']
Deployability,"@ivirshup @giovp i have updated the function, now it can process non-visium coordinates and have the number of rings option for visium.; https://github.com/theislab/spatial-tools/blob/graph/notebooks/build_spatial_graph.ipynb",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1383#issuecomment-693389468:24,update,updated,24,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1383#issuecomment-693389468,1,['update'],['updated']
Deployability,"@ivirshup @ilan-gold just got back to this, thought i could not install wsl as I am on a somewhat company restricted laptop, but turns out i can. installing it now (and probably using that from here on out). will run the tester in a bit and let you know",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2969#issuecomment-2039290843:64,install,install,64,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969#issuecomment-2039290843,2,['install'],"['install', 'installing']"
Deployability,@ivirshup Can we stick this in `1.10`? It seems small enough and IMO basically constitutes a breaking change anyway. then @theJasonFan can add a release note and we can merge if we don't notice anything else wrong here.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2889#issuecomment-1968612083:145,release,release,145,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2889#issuecomment-1968612083,1,['release'],['release']
Deployability,"@ivirshup I can also confirm the updated tutorial works, thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2143#issuecomment-1072908371:33,update,updated,33,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2143#issuecomment-1072908371,1,['update'],['updated']
Deployability,"@ivirshup I find it useful, since we're still changing our API a lot, so I don't forget to update the tutorials. Our main issue is just runtime of some functions.; I'm using https://github.com/chrisjsewell/pytest-notebook, which can compare expected output of certain cells (or completely) ignore them, but it's still a very small library. I haven't gotten around pushing the updates, since I figured if the notebooks run, it's fine if there are some small discrepencies in output (like images/printed stuff) - though maybe I will update this soon.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1357#issuecomment-670685026:91,update,update,91,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1357#issuecomment-670685026,3,['update'],"['update', 'updates']"
Deployability,"@ivirshup I hope that I caught all of your comments.; The flake8 configuration is now minimal and pretty much only contains black violations or what you requested. I added and then removed autopep8 again, because it has other opinions on formatting than the opinionated formatter black. Yes, even with the flake8 configuration file. Black formatted the code then autopep8 and this cycle continues forever.; Added TODOs to exceptions and noqas are still easily searchable and mention what rule they ignore anyways. I want to get this merged asap since the merge conflicts will just pile up.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1689#issuecomment-799425430:65,configurat,configuration,65,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1689#issuecomment-799425430,2,['configurat'],['configuration']
Deployability,"@ivirshup I think writing a file for uploading it to the web, for read caches, and for for checkpoints of a pipeline has different requirements. I think a `h5ad_compression` or even `hdf5_compression` setting could have its place, but separately from the `cache_compression`. We’ll have to think about naming though. Maybe we want to namespace our settings like matplotlib’s rcparams?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/847#issuecomment-532191481:108,pipeline,pipeline,108,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/847#issuecomment-532191481,1,['pipeline'],['pipeline']
Deployability,"@ivirshup Thank you for the feedback. I will add a release note soon. I also thought about the naming of the parameter. However, if we assume that also in the future it is mostly used to subset the number of PCs in PCA arrays stored under different names, it should be fine?. I can not comment further on what these changes may break, at least ideally they should make the use of n_pcs more consistent and as expected. Would you suggest, I implement some further, more comprehensive tests?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2179#issuecomment-1076393928:51,release,release,51,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2179#issuecomment-1076393928,1,['release'],['release']
Deployability,@ivirshup Thanks for letting me know. It will also update for me once 1.10.1 is out. I use the logic from scanpy for this.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2964#issuecomment-2021388747:51,update,update,51,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2964#issuecomment-2021388747,1,['update'],['update']
Deployability,"@ivirshup Thanks for pointing it up. I updated all to newest version, and it worked!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/942#issuecomment-560068082:39,update,updated,39,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/942#issuecomment-560068082,1,['update'],['updated']
Deployability,"@ivirshup This looks great! Thanks. The issue with the cropping of the labels is quite annoying and indeed `bbox_inches=""tight""` should help. However, I don't think is nice to add that line for each example, but, on the other hand, if we add this to the scanpy code, many figures will be affected and would need to be updated. The same issue also affects the test images which most are cropped.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1632#issuecomment-775750950:318,update,updated,318,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1632#issuecomment-775750950,1,['update'],['updated']
Deployability,"@ivirshup We estimate that the package will be released around 15th of April. So, in a month or so. ; If this is ok, then I'll let you know when it is out:)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/467#issuecomment-472857688:47,release,released,47,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/467#issuecomment-472857688,1,['release'],['released']
Deployability,@ivirshup We have updated gprofiler-official to version 1.0.0 that corresponds to the new API.; See the descriptions here: https://pypi.org/project/gprofiler-official/#description,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/467#issuecomment-481192068:18,update,updated,18,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/467#issuecomment-481192068,1,['update'],['updated']
Deployability,"@ivirshup coloring by boolean values `(True, False)` is now possible:. 1) The solution is based on casting the boolean columns to string columns, so that they can be colored in a categorical way. Actual columns in the anndata object are not modified. 2) I was thinking about the case where True is 1 and False is 0. Current behaviour: colorbar is plotted, since 0 and 1 are treated like continuous variables. Does it make sense to handle this case in scanpy?. 3) Tests fail due to new pandas version, they do not fail locally though. . What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2460#issuecomment-1500883671:387,continuous,continuous,387,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2460#issuecomment-1500883671,1,['continuous'],['continuous']
Deployability,"@ivirshup i see you opened the issue about graph initialization, though i haven't checked yet the things that were added. Do we wait for a new release of pynndescent and use the new features or we try to fix ingest with the current version of pynndescent (i have some code already that partially works)?. upd: ah, i see `init_graph` should work without hacks now.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1589#issuecomment-762495449:143,release,release,143,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1589#issuecomment-762495449,1,['release'],['release']
Deployability,"@ivirshup or @flying-sheep or any other active maintainers, if you get a chance, could you consider the associated PR for this issue? It'd be great to have this fixed in a future release.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2246#issuecomment-1196871672:179,release,release,179,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2246#issuecomment-1196871672,1,['release'],['release']
Deployability,"@ivirshup this one should be good to go now, right? Do you require release notes for such small things or do you manually add those later?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2231#issuecomment-1158926683:67,release,release,67,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2231#issuecomment-1158926683,1,['release'],['release']
Deployability,"@karlann yeah, conda environments can run into these problems, especially if you've installed some packages with `pip` and some with `conda`. I generally try to create fresh environments very frequently instead of updating old ones. `mamba` (faster conda) definitely makes this less painful. @OnlyBelter have you tried the same solution of trying a fresh environment?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1850#issuecomment-862972961:84,install,installed,84,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1850#issuecomment-862972961,1,['install'],['installed']
Deployability,@kaushalprasadhial We internal discussed adding `scikit-learn-intelex` as a dependency. We came to the conclusion that we dont want it as such. Since this a patch that the user can do regardless we think tath the best thing would be to have a notebook that would show the speedup of the patch. We could host this in a new notebook acceleration category.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3279#issuecomment-2429335571:157,patch,patch,157,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3279#issuecomment-2429335571,2,['patch'],['patch']
Deployability,"@ktpolanski I re-created a new conda env and installed scanpy so now it's working. I'm still not sure where the problem lies, though I did realize it starts jumping error after I install another package called stereopy, I'm guessing maybe that package updated something which got in conflict with normal scanpy setting.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2297#issuecomment-1451305928:45,install,installed,45,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297#issuecomment-1451305928,3,"['install', 'update']","['install', 'installed', 'updated']"
Deployability,"@ktpolanski I thought I had the newest anndata version, but turns out 0.8.0 is not in Ubuntu repositiories. I had to manually download and install Python 3.8, anndata 0.8.0 and h5py, now it works.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2297#issuecomment-1451566540:139,install,install,139,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297#issuecomment-1451566540,1,['install'],['install']
Deployability,@liiskolb The problem is that the `python-gprofiler` and `gprofiler-official` packages are both imported as `import gprofiler`. That means that someone who has installed one of them and then gets the other with scanpy won't know what they are importing if they just run `import gprofiler`. This is not ideal. I just experienced the same thing and decided to remove `python-gprofiler`. But we can't really mandate that everyone does this. @ivirshup maybe the solution is to detect which version people have and then parse according to their version? The format is quite similar. I've used both now and could probably convert inputs and outputs easily. And then I'd throw a warning if `python-gprofiler` is installed.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/467#issuecomment-504960614:160,install,installed,160,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/467#issuecomment-504960614,2,['install'],['installed']
Deployability,"@liiskolb, any chance you have an estimate of when the python package will be released? I'd like to have this PR merge with up-to-date results, and am trying to figure out if I should write a little client. @fidelram Sure!. Just a heads up to everyone, I'm pretty swamped this week and probably won't get around to updating this PR until at least this weekend.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/467#issuecomment-472269046:78,release,released,78,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/467#issuecomment-472269046,1,['release'],['released']
Deployability,"@liliblu `""louvain""` would work. @kleurless, sorry for such a late reponse to this! If you are still having this problem, does your `adata_2` have `.raw` set? `adata.raw.var_names` ca be different than `adata.var_names`, but is is used by default for plotting when available. Does your second call work with `sc.pl.dotplot(adata_2, adata_2.var_names[0:4], groupby='celltype', color_map = 'Reds', use_raw=False)`?. If this is the issue, we should at least have a more clear error in the next release (#1583).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1406#issuecomment-768012714:491,release,release,491,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1406#issuecomment-768012714,1,['release'],['release']
Deployability,@macros29 try `pip install anndata --force-reinstall` then import your packages again and try saving.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/515#issuecomment-469487061:19,install,install,19,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/515#issuecomment-469487061,1,['install'],['install']
Deployability,"@massonix Latest version is available on PyPI, so you can try installing via pip install.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/942#issuecomment-577689480:62,install,installing,62,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/942#issuecomment-577689480,2,['install'],"['install', 'installing']"
Deployability,"@maximilianh Sure! This [gist](https://gist.github.com/ivirshup/e7f0c435474d9b06b622c63d4221afe6) has a script to download a dataset and write it to a `.h5ad` file. I think having scanpy and tqdm installed should be sufficient to run it. Usage should be:. ```; python3 download_expression_atlas.py {accession}; ``` . where `accession` is something like: `E-EHCA-2` or `E-GEOD-98816`. . But what it does is just download and parse the expression `.zip` and ""Experiment design file"" from each dataset's download page ([example](https://www.ebi.ac.uk/gxa/sc/experiments/E-EHCA-2/downloads)). I think the experiment design files are a cleaned up version of the `.sdrf` file (some redundant fields are removed, field names can be less verbose).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/558#issuecomment-476613271:196,install,installed,196,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-476613271,1,['install'],['installed']
Deployability,"@michalk8 thanks for the extensive recommendations!. I think I'd like to keep the number of tools used small. It's the worst when you want to fix a bug, but instead have to learn about configuring a linter. More tools means more configurations people need to be familiar with, and the goal is reducing cognitive load. > Also fixing types for `mypy` takes a while, I'd do it as last. Yeah, I figured this would be the case. Does `mypy` allow partial typing these days? Also, I haven't found the numpy or pandas type stubs to always be great. Have you run into problems around this?. I think this would also need to wait at least until we can drop python 3.6 for `anndata`, since adding types there currently means circular dependencies. > `rstcheck` to check the syntax of .rst files. I would particularly like a linter for `rst`. I noticed you also had `doc8`, but you'd recommend `rstcheck` check over this? I'm a little worried, considering its last release was over a year ago. Spell check for prose in doc-strings could also be great, but I could see this being overzealous (is there a good way to notify about misspelled words, while not being annoying about technical terms?). I'm a little worried about some custom sphinx extensions we have, and conflicting with this, any experience here?. --------------------------------------------. @Koncopd, I think I agree with your concern, as I said above: it's the worst when you want to fix a bug, but instead have to learn about configuring a linter. I also think it's very easy to add new checks, so someone complaining about new ones is valuable. Per commit, this should always be an option with `git commit --no-verify`, though you could also just not install `pre-commit`. I would like to keep the required checks limited, ideally formatting tasks that can be automated as opposed ""this is poor style"" warnings. I also know these tools can be wrong (e.g. `black` when expression's have many operators, sometimes with chaining) so it would be goo",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1563#issuecomment-754352635:229,configurat,configurations,229,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1563#issuecomment-754352635,2,"['configurat', 'release']","['configurations', 'release']"
Deployability,"@mvdbeek does the solution from @fidelram solves the issue? if yes, would you be able to push updates to this PR?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1669#issuecomment-804067298:94,update,updates,94,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1669#issuecomment-804067298,1,['update'],['updates']
Deployability,"@mxposed It may be worth noting that scanpy's sc.pp.highly_variable_genes takes an argument `flavor` which defaults to the original [2015 Seurat paper](https://www.nature.com/articles/nbt.3192). To Obtain the same set of Highly Variable Genes as produced by modern versions of Seurat [2019 Stuart et al. paper](https://www.sciencedirect.com/science/article/pii/S0092867419305598), it is necessary to pass 'seurat_v3' for this value. You will need to install scikit-misc for this method to work:; ```sh; pip install --user scikit-misc; ```; But there is another wrinkle... the seurat3 algorithm needs count data. therefore it is necessary to rearrange the normalization in scanpy:; ```py; # find the highly variable genes...; # Since we are using seurat_v3 as the flavor,; # we have to do this before normalization; sc.pp.highly_variable_genes(sc96, flavor='seurat_v3', ; n_top_genes=2000). # Normalize and log transform (over all genes); sc.pp.normalize_total(sc96, target_sum=1e4); sc.pp.log1p(sc96). # it is necessary to do the Normalization before selecting; # to just the highly variable genes else our normalization ; # for reads will only be counting the subset. # now select the subset; sc96 = sc96[:,sc96.var.highly_variable]; ```; With these steps scanpy selects the exact same set of HGV and the Normalized log1p data in scanpy `sc96.X` is equal to `sc96$RNA@data)[VariableFeatures(object=sc96),]` in Seurat to about 6 decimal places in my dataset. And thanks for sharing your notebook link, I am trying to perform a similar comparison.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1531#issuecomment-1079775692:450,install,install,450,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1531#issuecomment-1079775692,2,['install'],['install']
Deployability,"@nahanoo ; Hi, there are 3 options for now:. 1. downgrading umap to 0.39; 2. installing scanpy from github; 3. waiting for a new release of scanpy.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1036#issuecomment-627837413:77,install,installing,77,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1036#issuecomment-627837413,2,"['install', 'release']","['installing', 'release']"
Deployability,"@ontsilla We can take a look at this, but I'm not sure if there will be a solution soon. Have you tried using [conda](https://conda.io/en/latest/miniconda.html) on this system? I think it might be your best bet here. @flying-sheep I can recreate with:. ```; conda create -yn testenv python=3.5.2; conda activate testenv; pip install scanpy; python -c ""import scanpy"" ; ```. It looks like there were a lot of bug fixes to python's `typing` module between v3.5.2 and v3.5.4 ([changelog](https://docs.python.org/3.5/whatsnew/changelog.html#python-3-5-4rc1)). I don't get this error with v3.5.4. Are pre-bugfix versions of python supported?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/561#issuecomment-476952168:325,install,install,325,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/561#issuecomment-476952168,1,['install'],['install']
Deployability,"@outlace Curiously, your change causes an error. Without your change I can run the tests correctly without a problem. I remember that I fixed a bug similar to this one that was recently integrated into master (see https://github.com/theislab/scanpy/pull/425/files#diff-b5175ed1415cdbf853646e523cbe8ae0L902). Could it be that you didn't have the latest pull from scanpy and that was causing the error?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/525#issuecomment-471592072:186,integrat,integrated,186,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/525#issuecomment-471592072,1,['integrat'],['integrated']
Deployability,@outlace I will check the problem with the test and integrate your changes in a new PR that addresses #512 and #524 if this is OK with you.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/525#issuecomment-471455638:52,integrat,integrate,52,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/525#issuecomment-471455638,1,['integrat'],['integrate']
Deployability,"@pati-ni ; I have the similar issue when installing CellRank as `conda install -c bioconda cellrank`. Problem is not all dependencies are on bioconda, some of them are on `conda-forge` - I've tested it and I have the same problem with scanpy.; Installing it as `conda install -c bioconda -c conda-forge scanpy` works. But @ivirshup is right, seems like conda issue.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1298#issuecomment-653900843:41,install,installing,41,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1298#issuecomment-653900843,4,"['Install', 'install']","['Installing', 'install', 'installing']"
Deployability,"@pinin4fjords the tests aren't running since scrublet isn't actually being installed (I'm surprised the build still worked, apparently this is just a warning?). From the travis logs:. ```; 203$ pip install .[dev,test,louvain,leiden,magic,scvi,harmony,skmisc,scrublet]; 204Processing /home/travis/build/theislab/scanpy; 205 Installing build dependencies ... done; 206 Getting requirements to build wheel ... done; 207 Preparing wheel metadata ... done; 208 WARNING: scanpy 0.1.dev67+g3918588 does not provide the extra 'scrublet'; ```. You'll need to add a scrublet entry to `extras_require` here: https://github.com/theislab/scanpy/blob/d56d6beacdd951a010bb6a93078db26e1ac904b0/setup.py#L31-L56",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1476#issuecomment-734643707:75,install,installed,75,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476#issuecomment-734643707,3,"['Install', 'install']","['Installing', 'install', 'installed']"
Deployability,@salwanbutrus This should be fixed from Scanpy version 1.4.5.1. You may need to update your Scanpy version.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1017#issuecomment-645824317:80,update,update,80,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1017#issuecomment-645824317,1,['update'],['update']
Deployability,"@scottgigante @flying-sheep, on current master the tests fail for me with a MAGIC not installed error. External tests should have some mark to make sure they don't get run if the required package isn't installed.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1001:86,install,installed,86,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1001,2,['install'],['installed']
Deployability,@sjfleming Is there a GIST or repo url to use this code? Might take time to integrate into scanpy/anndata but people can benefit from the code if it already lives somewhere...,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/950#issuecomment-1117994615:76,integrat,integrate,76,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/950#issuecomment-1117994615,1,['integrat'],['integrate']
Deployability,"@taopeng1100: This is a numba bug. Please report this there, but only if you use the newest numba version (otherwise install it and try to reproduce this with the newest version). Give them this link so they see the code that triggers their bug:. https://github.com/theislab/scanpy/blob/2f160ea403d124d237fc2138c0aa0d175fbad22a/scanpy/preprocessing/_qc.py#L402-L428. @team: We should include numba in the package versions list.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1341#issuecomment-666246043:117,install,install,117,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341#issuecomment-666246043,1,['install'],['install']
Deployability,"@tomwhite OK, I added this to the release notes (https://github.com/theislab/scanpy/commit/cee23dc13cf2b77d8e23ee0f91eb55fac0e35ed8, sorry confounded with some style change); it would be nice to have a link to your performance benchmarks... Let me know when we should announce it on twitter. I'm also happy to retweet...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/371#issuecomment-456647889:34,release,release,34,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/371#issuecomment-456647889,1,['release'],['release']
Deployability,"@vitkl now multiple samples are supported, see [here](https://scanpy-tutorials.readthedocs.io/en/latest/spatial/integration-scanorama.html) for description on how to use the new concat strategy",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1158#issuecomment-640496084:112,integrat,integration-scanorama,112,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1158#issuecomment-640496084,1,['integrat'],['integration-scanorama']
Deployability,"@vladie0, would you mind pulling again and checking if it works now?. @flying-sheep if at least four people can't install the package (including in a clean conda environment on a lab mate's machine), what do you call it? I don't think it's our fault, but I think there's a bug somewhere.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/601#issuecomment-482107875:114,install,install,114,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/601#issuecomment-482107875,1,['install'],['install']
Deployability,"@vtraag FWIW, `pip install leidenalg` worked without a hitch for me (CentOS 6.5, Python 3.6.6 in a relatively empty conda env: scanpy + scikit stack).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/350#issuecomment-437074497:19,install,install,19,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/350#issuecomment-437074497,1,['install'],['install']
Deployability,"@wniu721 We had similar issues, but everything seems to be solved by installing recent versions of UMAP. I have to say we were working with python 3.8 (IDK if 3.9 has other issues)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1840#issuecomment-844133832:69,install,installing,69,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1840#issuecomment-844133832,1,['install'],['installing']
Deployability,"@zappuf @ivirshup I think an update to the tutorial would be needed but don't have time right now, @zappuf did you manage to work around the issue?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2143#issuecomment-1053612098:29,update,update,29,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2143#issuecomment-1053612098,1,['update'],['update']
Deployability,"A description of the ""key"" argument is missing from the documentation for the rank_genes_groups plotting function located at https://scanpy.readthedocs.io/en/stable/api/scanpy.pl.rank_genes_groups.html#scanpy.pl.rank_genes_groups. Without this, it's unclear how to plot the results of an alternative differential expression analysis (which is not stored in uns.rank_genes_groups). Would be great to update the documentation to include it.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1292:399,update,update,399,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1292,1,['update'],['update']
Deployability,"A numba reimplementation of some of the metrics sounds pretty awesome actually. That's out of scope for `scIB` at the moment. We didn't bother with parallelization for most of the metrics (beyond what was already implemented in `sc.tl.louvain` and the sklearn dependencies) as the slowest ones were in R anyway (and now also C++ with our LISI update). Would really welcome that. I can help where I can, although not so familiar with numba.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/915#issuecomment-764146920:343,update,update,343,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/915#issuecomment-764146920,1,['update'],['update']
Deployability,A rough implementation of glmpca in python is now available here: https://github.com/willtownes/glmpca-py . I will try to get it organized as an installable package tomorrow and add unit tests. Issues/ pull requests welcome.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/868#issuecomment-541384867:145,install,installable,145,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/868#issuecomment-541384867,1,['install'],['installable']
Deployability,"A/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/scanpy/readwrite.py:569) if is_legacy or not gex_only:; [570](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/scanpy/readwrite.py:570) return adata. File ~\AppData\Roaming\Python\Python312\site-packages\scanpy\readwrite.py:594, in _read_10x_mtx(path, var_names, make_unique, cache, cache_compression, prefix, is_legacy); [588](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/scanpy/readwrite.py:588) suffix = """" if is_legacy else "".gz""; [589](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/scanpy/readwrite.py:589) adata = read(; [590](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/scanpy/readwrite.py:590) path / f""{prefix}matrix.mtx{suffix}"",; [591](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/scanpy/readwrite.py:591) cache=cache,; [592](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/scanpy/readwrite.py:592) cache_compression=cache_compression,; [593](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/scanpy/readwrite.py:593) ).T # transpose the data; --> [594](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/scanpy/readwrite.py:594) genes = pd.read_csv(; [595](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3214:6198,Pipeline,PipelineDevelope,6198,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3214,1,['Pipeline'],['PipelineDevelope']
Deployability,"AFAICT `ubuntu 16.04` is what they use in most of their examples. Considering many of our users will be on academic clusters, I think old-ish versions of linux are reasonable to test against. The alternative would probably be `ubuntu-18.04`, which we should switch to when `16` is out of support. [Here are the options](https://docs.microsoft.com/en-us/azure/devops/pipelines/agents/hosted?view=azure-devops&tabs=yaml#software).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1520#issuecomment-738557948:366,pipeline,pipelines,366,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1520#issuecomment-738557948,1,['pipeline'],['pipelines']
Deployability,"AFAIK networkx and python-igraph do the same thing, only that python-igraph is faster. We also need python-igraph anyway for louvain and so on, so maybe it would be good to get rid of networkx. Downside: python-igraph and louvain-igraph is currently deliberately an optional dependency since it’s hard to install on windows. People need to build it themselves (A task that even I didn’t manage by now, and I got *many* things to compile!) or use Christoph Grohlke’s unofficial builds ([here](https://www.lfd.uci.edu/~gohlke/pythonlibs/#python-igraph) and [here](https://www.lfd.uci.edu/~gohlke/pythonlibs/#louvain-igraph))",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/97:305,install,install,305,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/97,1,['install'],['install']
Deployability,"API for louvain 0.7+ has been updated to have the seed passed to the partition function, like in `leidenalg`. This PR makes our function work with the newer versions of `louvain`. Issue from louvain repo: https://github.com/vtraag/louvain-igraph/issues/54",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1197:30,update,updated,30,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1197,1,['update'],['updated']
Deployability,"About the API, I still think it makes sense for TSNE weighted neighbor calculation to be separate, especially if it is going to have multiple weighting options that depend on the `openTSNE` package. If it turns out these methods don't have much in the way of parameters, then it might be reasonable for this to be a part of `sc.pp.neighbors`. How about this, the implementation here should be well factored out into:. 1. Getting nearest neighbors; 2. Weighting the graph; 3. Computing the layout. Once the available parameters are clear I think it'll be easier to make an informed decision about whether neighbor weighting for tsne should occur through `sc.pp.neighbors`. Additionally, I think it'll be easier to integrate cleanly separated code than to separate integrated code. > The weights constructed by UMAP in neighbors are not normalized. So if you run neighbors() and then tsne() then t-SNE should do something in order to be able to use this graph. For passing the umap connectivity matrix to tsne layout, I think I would expect the weights to be used. Something like this should accomplish that:. ```python; class WrappedAffinities(openTSNE.affinity.Affinities):; def __init__(self, neighbors, symmetrize=True, verbose=False):; self.verbose = verbose; P = neighbors; if symmetrize:; P = (P + P.T) / 2; total = P.sum(); if not np.isclose(total, 1.):; P = P / total; self.P = P; ```. That said, I'm not too familiar with the assumptions of tsne, or if this would be appropriate. I think binarizing the edge weights is a bit of a strong assumption unless specifically requested though. With `umap`, we throw a warning if it looks like the passed graph didn't come from `umap`. You could do the same here?. > From an implementation standpoint, the sc.pp.tsne_negihbors will inevitably have to call the UMAP KNNG construction, since I can see that it's not split out in the code-base. I would like nearest neighbor calculation and graph weighting to be split out eventually. Since it's already d",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1561#issuecomment-761950200:713,integrat,integrate,713,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561#issuecomment-761950200,2,['integrat'],"['integrate', 'integrated']"
Deployability,"About the version: That’s because `__file__` in `get_version(root='..', relative_to=__file__)` is a path where no component is in a git repository. Therefore the `setuptools_scm` code fails, we enter the `else` branch, and the (stale) metadata is used. Something like the following could make the `_metadata` module figure out we’re in a dev installation after all. (Needs some more as `here.readlink()` returns a relative path. I’m against `resolve()` as we really just want that one link to be replaced and `resolve()` is a sledge hammer). ```py; file_resolved = str(here.readlink() / f'{__name__}.py') if here.is_symlink() else __file__; ```. But the real issue is that dev installs are a hack and scanpy’s package metadata is stale.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1527#issuecomment-777322129:342,install,installation,342,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527#issuecomment-777322129,2,['install'],"['installation', 'installs']"
Deployability,"According to [scanorama MemoryError](https://github.com/brianhie/scanorama/blob/master/scanorama/scanorama.py#L768-L775), I think `batch_size` parameter doesn't work for `sc.external.pp.scanorama_integrate`. ### Minimal code sample (that we can copy&paste without having any data). ```python; sc.external.pp.scanorama_integrate(adata, key=""datasetID"", batch_size=500); ```. ```pytb; WARNING: Out of memory, consider turning on batched computation with batch_size parameter.; Traceback (most recent call last):; File ""/lustre1/shiq//02_igt/py/1_igt_scanorama.py"", line 26, in <module>; sc.external.pp.scanorama_integrate(adata, key=""datasetID"", batch_size=500); File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanpy/external/pp/_scanorama_integrate.py"", line 121, in scanorama_integrate; integrated = scanorama.assemble(; File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 933, in assemble; bias = transform(curr_ds, curr_ref, ds_ind, ref_ind, sigma=sigma,; File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 762, in transform; avg_bias = batch_bias(curr_ds, match_ds, bias, sigma=sigma,; File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 723, in batch_bias; weights = rbf_kernel(curr_ds, match_ds, gamma=0.5*sigma); File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/metrics/pairwise.py"", line 1294, in rbf_kernel; X, Y = check_pairwise_arrays(X, Y); File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/metrics/pairwise.py"", line 155, in check_pairwise_arrays; X = check_array(; File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/utils/validation.py"", line 727, in check_array; warnings.warn(; FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2319:816,integrat,integrated,816,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2319,1,['integrat'],['integrated']
Deployability,"Actually I've always been using the conda package and never had any issues. ; Github releases are watched by the bioconda-bot, so it should never be out of date, either.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/851#issuecomment-533874424:85,release,releases,85,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/851#issuecomment-533874424,1,['release'],['releases']
Deployability,"Actually deploying this is probably blocked by correcting CPU affinities on the benchmarking machine, but writing the code for this should be manageable otherwise.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3013#issuecomment-2275866445:9,deploy,deploying,9,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3013#issuecomment-2275866445,1,['deploy'],['deploying']
Deployability,"Actually, I added two commits to my master branch and one was about the release notes. But then instead of pushing to my fork, I pushed these to the master branch of scanpy repo by mistake. Fortunately, there were just these two commits that I wanted to add to this PR, so everything should be all right. Sorry for the confusion.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/622#issuecomment-488295556:72,release,release,72,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/622#issuecomment-488295556,1,['release'],['release']
Deployability,Add 1.7.3 release notes,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1786:10,release,release,10,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1786,1,['release'],['release']
Deployability,Add DCA integration,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/186:8,integrat,integration,8,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/186,1,['integrat'],['integration']
Deployability,Add PHATE integration,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/136:10,integrat,integration,10,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/136,1,['integrat'],['integration']
Deployability,Add Scanorama integration to external API,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1332:14,integrat,integration,14,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1332,1,['integrat'],['integration']
Deployability,Add a release workflow,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2644:6,release,release,6,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2644,1,['release'],['release']
Deployability,Add azure pipelines plugin,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2111:10,pipeline,pipelines,10,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2111,1,['pipeline'],['pipelines']
Deployability,Add bioconda installation instructions.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/261:13,install,installation,13,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/261,1,['install'],['installation']
Deployability,Add check for release notes,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2569:14,release,release,14,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2569,1,['release'],['release']
Deployability,Add conda-forge install instructions,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1912:16,install,install,16,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1912,1,['install'],['install']
Deployability,Add instructions for conda dev install,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1377:31,install,install,31,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1377,1,['install'],['install']
Deployability,Add missing 1.9.6 release notes,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2691:18,release,release,18,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2691,1,['release'],['release']
Deployability,Add patch notes for 1.4.5.1,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1044:4,patch,patch,4,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1044,1,['patch'],['patch']
Deployability,Add release note for queries,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/845:4,release,release,4,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/845,1,['release'],['release']
Deployability,Add release notes section for 1.8.0,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1666:4,release,release,4,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1666,1,['release'],['release']
Deployability,Add release notes template for 1.8.3,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2039:4,release,release,4,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2039,1,['release'],['release']
Deployability,Add release workflow,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2720:4,release,release,4,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2720,1,['release'],['release']
Deployability,Add some straggling release notes for 1.7.1,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1683:20,release,release,20,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1683,1,['release'],['release']
Deployability,Add support for Harmony integration,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1306:24,integrat,integration,24,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1306,1,['integrat'],['integration']
Deployability,Add vcenter to release notes,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1743:15,release,release,15,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1743,1,['release'],['release']
Deployability,"Added DCA integration, as discussed in #142 . For denoising, uses can call:. `sc.pp.dca(adata)`. which replaces adata.X inplace. For latent representations:. `sc.pp.dca(adata, mode='latent')`. can be called, which adds 'X_dca' to adata.obsm. Fixes #142 . This integration uses new DCA API (>= 0.2.1). All DCA API arguments are exposed and usable in scanpy integration.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/186:10,integrat,integration,10,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/186,3,['integrat'],['integration']
Deployability,Added MiCV as a full pipeline in the external ecosystem docs. We recently built this tool and hope it will be useful to others trying to jump into this analysis space. Please let me know if there are any questions or issues with including this in the docs. Thank you for all that you're doing with this project!. For extra information:; https://micv.works; https://github.com/Cai-Lab-at-University-of-Michigan/MiCV; https://www.biorxiv.org/content/10.1101/2020.07.02.184549v2. <!-- ; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1577:21,pipeline,pipeline,21,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1577,1,['pipeline'],['pipeline']
Deployability,Added a bunch of stuff to the release notes.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1218:30,release,release,30,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1218,1,['release'],['release']
Deployability,"Added test for filter_genes_dispersion, updated docs",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/343:40,update,updated,40,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/343,1,['update'],['updated']
Deployability,"Added the ```n_components``` parameter in the tsne function, similar to the one in umap and updated docstring. This allows for 3D plotting requested by [https://github.com/scverse/scanpy/issues/460](https://github.com/scverse/scanpy/issues/460) and [https://github.com/scverse/scanpy/issues/1435](https://github.com/scverse/scanpy/issues/1435). ![tsne](https://github.com/scverse/scanpy/assets/48340051/6a2083d2-7506-4006-81f8-9779d3ce2b14)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2802:92,update,updated,92,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2802,1,['update'],['updated']
Deployability,"Addendum to #1583, realized some updates hadn't been propagated to `var_df` so I've added those. Made it harder to forget these in the future by sharing the code. Additionally cleaned up the `get` namespace.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1621:33,update,updates,33,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1621,1,['update'],['updates']
Deployability,Adding cell2location to the list of scRNA->spatial integration methods,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1574:51,integrat,integration,51,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1574,1,['integrat'],['integration']
Deployability,Adding new release notes for 1.9.2,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2223:11,release,release,11,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2223,1,['release'],['release']
Deployability,Adding section to start collecting 1.8.0 release notes in,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1666:41,release,release,41,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1666,1,['release'],['release']
Deployability,"Adds median as aggregation function to https://github.com/scverse/scanpy/blob/0f3161295dbf0cf568376c31eaa5c6e148dcf9f0/src/scanpy/get/_aggregated.py; In case of a sparse matrix, it will be converted to dense matrix before calculating median. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [ ] Closes #; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3180:427,release,release,427,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3180,2,"['Release', 'release']","['Release', 'release']"
Deployability,"Advantage of networkx is that it's easily installed... But yes, we should remove it in the future. I think with anaconda, one gets all the igraph and louvain stuff to work very easily without compiling. Without using Grohlke's binaries... One just needs to document this probably. At the latest when igraph and louvain are easily installed, networkx can be removed... PS: I'm currently preparing scanpy 1.0; there will be some slight changes to make the API less redundant... So for now, please no big changes...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/97#issuecomment-370144822:42,install,installed,42,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/97#issuecomment-370144822,2,['install'],['installed']
Deployability,"After @ilan-gold mentioned that scanpy’s tutorials are actually not reproducible, I made an issue for that: https://github.com/scverse/scanpy-tutorials/issues/79. Maybe we need to address that before the release, that’ll also get rid of the warnings. If you need to suppress them, I think this extension could be an acceptable solution: https://github.com/picnixz/sphinx-zeta-suppress",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2636#issuecomment-1904033065:204,release,release,204,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2636#issuecomment-1904033065,1,['release'],['release']
Deployability,After https://github.com/theislab/scanpy/pull/1156 I will update the function.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1213#issuecomment-630597880:58,update,update,58,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1213#issuecomment-630597880,1,['update'],['update']
Deployability,After my hard drive and computer crashed (which is why I respond so late) I was able to update my python env. So far it is working. Thanks a lot!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2121#issuecomment-1025090712:88,update,update,88,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2121#issuecomment-1025090712,1,['update'],['update']
Deployability,"After updating to the most recent version of scanpy, I had to separately update anndata, louvain, and leidenalg packages that are dependancies. Any dependent package updates of these types should just happen when the newest version is installed.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/518:73,update,update,73,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/518,3,"['install', 'update']","['installed', 'update', 'updates']"
Deployability,"Ah I see @aeisenbarth: https://github.com/scverse/scanpy/pull/2999 solved this, so this will be resolved in an upcoming release: https://github.com/scverse/scanpy/blob/main/docs/release-notes/1.10.2.md",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2865#issuecomment-2124170474:120,release,release,120,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2865#issuecomment-2124170474,2,['release'],"['release', 'release-notes']"
Deployability,"Ah I see. Sorry about the red herring with `sc.settings.n_jobs`, all those warnings seem to come directly from umap code. So according to @tomwhite, only umap 0.4 and pynndescent need to be installed and it should automatically be parallelized. Scanpy doesn’t effect this in any way. You should probably report this to the umap repo. Please write here once you openend an issue there. The only thing we can to is to call umap in a way that respects our settings once this is fixed.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/913#issuecomment-553087327:190,install,installed,190,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/913#issuecomment-553087327,1,['install'],['installed']
Deployability,"Ah I think I see the issue! Feature branches should be based off `master` and directing the pull request there! I think what's happening is that a pre-commit hook was installed, but the config only exists on the `master` branch. I think this should largely be manageable by rebasing onto master (e.g. `git rebase --onto master 1.7.x`) and changing the branch the PR is targeting via the github interface:. <img width=""300"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/110570131-9093e600-81a9-11eb-9223-5b7bc233d75c.png"">. --------------. Side note: We're considering separating the `highly_variable_genes` interface into multiple functions, since the arguments to the different methods don't always overlap in meaningful or intuitive ways. There's nothing you need to do about this right now, but just a heads up to keep the logic for this method separate from the main function.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1715#issuecomment-794790768:167,install,installed,167,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715#issuecomment-794790768,1,['install'],['installed']
Deployability,"Ah, looks like that might be it. I think your scanpy and numba installs might be old versions. Could you upgrade those and let me know if that works?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1164#issuecomment-614654094:63,install,installs,63,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1164#issuecomment-614654094,2,"['install', 'upgrade']","['installs', 'upgrade']"
Deployability,"Ah, my bad, I read the path wrong on my phone. In general, the most recent numba release cycle had a lot of deprecations, so many packages are throwing numba warnings.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1242#issuecomment-632470036:81,release,release,81,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1242#issuecomment-632470036,1,['release'],['release']
Deployability,"Ah, thanks for the update!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1605#issuecomment-766288497:19,update,update,19,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1605#issuecomment-766288497,1,['update'],['update']
Deployability,"Ah, yeah that can cause problems. I'm actually a little surprised you've gotten as far as ingest, so maybe the situation has improved. Do you have multiple installs of anndata if you `conda list | grep anndata`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2978#issuecomment-2037697731:156,install,installs,156,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2978#issuecomment-2037697731,1,['install'],['installs']
Deployability,"Ah, yeah we need to fix the visibility of the builds. Hmm, so you can’t see the build [here](https://icb-scanpy--1306.com.readthedocs.build/en/1306/external/scanpy.external.pp.harmony_integrate.html)?. It still has issues:. ![grafik](https://user-images.githubusercontent.com/291575/88098047-6dc0ad00-cb99-11ea-8c30-f11ee3a820fb.png). you need to add blank lines before the `>>>` i guess. Also ![grafik](https://user-images.githubusercontent.com/291575/88098511-30a8ea80-cb9a-11ea-987b-c2fa929f36d6.png) again. You need to either give us acess to WarrenLab/scanpy@harmony or continuously merge master until you pressing the “merge upstream changes” button and us hitting the “squash & merge” button happens fast enough. forcing up-to-date branches this way is a bit annoying, but it’s the only way to be sure conflicts in changes don’t break everything. (well, the only way without switching to [bors](https://bors.tech/))",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1306#issuecomment-662064808:575,continuous,continuously,575,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1306#issuecomment-662064808,1,['continuous'],['continuously']
Deployability,Aha okay. My problem was resolved when I updated the AnnData package for converting pandas dataframe into AnnData object using. '''adata = sc.AnnData(x)''',MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/435#issuecomment-475779409:41,update,updated,41,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/435#issuecomment-475779409,1,['update'],['updated']
Deployability,"All good, thanks for the update!; Glad to hear it works now as you'd expect it to :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2592#issuecomment-1743077209:25,update,update,25,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2592#issuecomment-1743077209,1,['update'],['update']
Deployability,"All right, fair points. > Poetry is great! But i remember two problems:; > ; > no good way to editably install into some env: python-poetry/poetry#34; > doesn’t support plugins yet so only hardcoded versions in static metadata: python-poetry/poetry#140; > . I also stumbled upon the editably install issue. This is not an issue that Poetry can solve at the moment as explained in the thread. I do however understand that this is an issue for scanpy (considering the strong anndata dependency etc). Regarding plugins - they are on the roadmap and should appear at some point. Considering that the community is very active whereas the main developer is not anymore this may solve the editable install with some hack as well. I agree with your points and Poetry is not yet the solution that we should currently use, but I think it is the proper solution that we should aim for. > I'd also be worried using poetry would hamper contributions from people unfamiliar with it, and I don't think bioinformaticians are going to be familiar with it. I don't think that anybody is familiar with flit either, but it is slightly less intrusive and does not fundamentally change so many things like Poetry does. However, many things that Poetry does change make a lot of sense and solve other issues that we did not discuss here yet. So yeah, I personally would wait for Poetry to get it's plugin system and for the editable install issue to get a proper PEP. But if you don't feel like waiting Flit might be fun :). Cheers",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1527#issuecomment-765253434:103,install,install,103,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527#issuecomment-765253434,4,['install'],['install']
Deployability,Allow JUST symlinking anndata installs,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1378:30,install,installs,30,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1378,1,['install'],['installs']
Deployability,Allow greater customizability and visibility when using dotplot by allowing the user to set the smallest dot size. This change updates the dots along with the dot size legend.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/524:127,update,updates,127,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/524,1,['update'],['updates']
Deployability,"Alright, I think I found the problem and hopefully fixed it, although I am not sure as I don't completely understand how the `_get_color_source_vector` function works. If you'd like to try my fix, it's in my fork:. ```; git clone https://github.com/WarrenLab/scanpy.git; cd scanpy; git checkout use_raw_fix; pip install .; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1277#issuecomment-703931637:312,install,install,312,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277#issuecomment-703931637,1,['install'],['install']
Deployability,Also looking forward to this update,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1552#issuecomment-1110180699:29,update,update,29,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1552#issuecomment-1110180699,1,['update'],['update']
Deployability,"Also running into this now with pertpy. . ```; -----; anndata 0.9.1; scanpy 1.9.3; -----; PIL 10.0.0; cffi 1.15.1; colorama 0.4.6; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; defusedxml 0.7.1; h5py 3.9.0; igraph 0.9.7; joblib 1.3.1; kiwisolver 1.4.4; leidenalg 0.10.0; llvmlite 0.40.1; matplotlib 3.7.2; mpl_toolkits NA; mpmath 1.3.0; natsort 8.4.0; numba 0.57.1; numpy 1.24.4; nvfuser NA; opt_einsum v3.3.0; packaging 23.1; pandas 2.0.3; psutil 5.9.5; pyarrow 12.0.1; pyparsing 3.0.9; pytz 2023.3; scipy 1.11.1; session_info 1.0.0; six 1.16.0; sklearn 1.3.0; sphinxcontrib NA; sympy 1.12; texttable 1.6.7; threadpoolctl 3.2.0; torch 2.0.1+cu117; tqdm 4.65.0; typing_extensions NA; wcwidth 0.2.6; yaml 6.0.1; -----; Python 3.10.9 (main, Jan 11 2023, 15:21:40) [GCC 11.2.0]; Linux-6.4.3-arch1-2-x86_64-with-glibc2.37; -----; Session information updated at 2023-07-19 12:57; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2341#issuecomment-1641870947:850,update,updated,850,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2341#issuecomment-1641870947,1,['update'],['updated']
Deployability,"Also since recently. Used to work like a charm previously, before I update some packages. I guess it has to do with the latter. Any solutions?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1407#issuecomment-690964260:68,update,update,68,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1407#issuecomment-690964260,1,['update'],['update']
Deployability,"Also, consider setting `flit >=3.4` for editable installs via [PEP 660](https://www.python.org/dev/peps/pep-0660/) 😃",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1776#issuecomment-959756849:49,install,installs,49,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1776#issuecomment-959756849,1,['install'],['installs']
Deployability,"Also, does the `enrich()` function run GProfiler as an ordered or unordered query? Can I toggle this using `gprofiler_kwargs`? (This question may be more appropriate for the gprofiler-official page, but I can't find one). Thanks again!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1901#issuecomment-869271735:89,toggle,toggle,89,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1901#issuecomment-869271735,1,['toggle'],['toggle']
Deployability,"An updated new release of [`PhenoGraph`](https://github.com/dpeerlab/PhenoGraph) package now supports `Leiden` algorithm for community detection. The suggested changes in `scanpy/external/tl/_phenograph.py` will make the new updates visible in Scanpy as well. Also, the suggested changes include a testing function in `scanpy/tests/external/test_phenograph.py`, and updated docs.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1080:3,update,updated,3,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1080,4,"['release', 'update']","['release', 'updated', 'updates']"
Deployability,"And in terms of the `sc.pp.highly_variable_genes` function. We typically don't use the `max_mean` and `disperson` based parametrization anymore, but instead just select `n_top_genes`, which avoids this problem altogether. That being said, there is a PR with the VST-based highly-variable genes implementation from Seurat that will be added into scanpy soon. If you would like to reproduce an updated pbmc3k tutorial from Seurat using scanpy functions, that would be very welcome of course!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1338#issuecomment-665746348:392,update,updated,392,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338#issuecomment-665746348,1,['update'],['updated']
Deployability,"And now I checked that the problem exists in the master branch. Versions used below:. <details><summary>Details</summary>; <p>. -----; anndata 0.9.1; scanpy 1.10.0.dev57+g08be4e9a; -----; PIL 9.4.0; asttokens NA; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; cffi 1.15.1; colorama 0.4.6; comm 0.1.3; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.6.7; decorator 5.1.1; executing 1.2.0; gmpy2 2.1.2; google NA; h5py 3.8.0; hypergeom_ufunc NA; igraph 0.10.4; invgauss_ufunc NA; ipykernel 6.22.0; ipywidgets 8.0.6; jedi 0.18.2; joblib 1.2.0; kiwisolver 1.4.4; leidenalg 0.9.1; llvmlite 0.39.1; matplotlib 3.7.1; matplotlib_inline 0.1.6; mpl_toolkits NA; mpmath 1.3.0; natsort 8.3.1; nbinom_ufunc NA; ncf_ufunc NA; nct_ufunc NA; ncx2_ufunc NA; numba 0.56.4; numpy 1.23.5; nvfuser NA; opt_einsum v3.3.0; packaging 23.1; pandas 2.0.1; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; platformdirs 3.5.0; prompt_toolkit 3.0.38; psutil 5.9.5; ptyprocess 0.7.0; pure_eval 0.2.2; pycparser 2.21; pydev_ipython NA; pydevconsole NA; pydevd 2.9.5; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.15.1; pynndescent 0.5.10; pyparsing 3.0.9; pytz 2023.3; scipy 1.10.1; session_info 1.0.0; setuptools 67.7.2; setuptools_scm NA; six 1.16.0; skewnorm_ufunc NA; sklearn 1.2.2; stack_data 0.6.2; sympy 1.11.1; texttable 1.6.7; threadpoolctl 3.1.0; torch 2.0.0; tornado 6.3; tqdm 4.65.0; traitlets 5.9.0; typing_extensions NA; umap 0.5.3; wcwidth 0.2.6; yaml 6.0; zmq 25.0.2; zoneinfo NA; -----; IPython 8.12.1; jupyter_client 8.2.0; jupyter_core 5.3.0; -----; Python 3.10.10 | packaged by conda-forge | (main, Mar 24 2023, 20:08:06) [GCC 11.3.0]; Linux-5.19.0-41-generic-x86_64-with-glibc2.36; -----; Session information updated at 2023-05-03 02:03. </p>; </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2480#issuecomment-1531836933:1753,update,updated,1753,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2480#issuecomment-1531836933,1,['update'],['updated']
Deployability,"And yes, should get a bug fix release note.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2231#issuecomment-1158944115:30,release,release,30,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2231#issuecomment-1158944115,1,['release'],['release']
Deployability,"AnnData(csr_matrix(np.random.poisson(1, size(100, 100)), dtype=np.float32)); rs = np.random.RandomState(1). sc.pp.pca(adata, random_state=rs); sc.pp.neighbors(adata, random_state=rs); sc.tl.leiden(adata, random_state=rs). ```. ```pytb; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/home/griffen/mambaforge/envs/scanpy-1.9.2/lib/python3.9/site-packages/scanpy/tools/_leiden.py"", line 144, in leiden; part = leidenalg.find_partition(g, partition_type, **partition_kwargs); File ""/home/griffen/mambaforge/envs/scanpy-1.9.2/lib/python3.9/site-packages/leidenalg/functions.py"", line 89, in find_partition; optimiser.set_rng_seed(seed); File ""/home/griffen/mambaforge/envs/scanpy-1.9.2/lib/python3.9/site-packages/leidenalg/Optimiser.py"", line 244, in set_rng_seed; _c_leiden._Optimiser_set_rng_seed(self._optimiser, value); TypeError: an integer is required (got type numpy.random.mtrand.RandomState); ```. #### Versions. <details>. -----; anndata 0.8.0; scanpy 1.9.2; -----; PIL 9.4.0; beta_ufunc NA; binom_ufunc NA; cffi 1.15.1; colorama 0.4.6; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; defusedxml 0.7.1; h5py 3.8.0; hypergeom_ufunc NA; igraph 0.10.4; importlib_resources NA; invgauss_ufunc NA; joblib 1.2.0; kiwisolver 1.4.4; leidenalg 0.9.1; llvmlite 0.39.1; matplotlib 3.7.0; mpl_toolkits NA; natsort 8.2.0; nbinom_ufunc NA; ncf_ufunc NA; nct_ufunc NA; ncx2_ufunc NA; numba 0.56.4; numpy 1.23.5; packaging 23.0; pandas 1.5.3; pkg_resources NA; psutil 5.9.4; pycparser 2.21; pynndescent 0.5.8; pyparsing 3.0.9; pytz 2022.7.1; scipy 1.10.1; session_info 1.0.0; setuptools 67.4.0; six 1.16.0; skewnorm_ufunc NA; sklearn 1.2.1; texttable 1.6.7; threadpoolctl 3.1.0; tqdm 4.64.1; typing_extensions NA; umap 0.5.3; wcwidth 0.2.6; yaml 6.0; zipp NA; zoneinfo NA; -----; Python 3.9.16 | packaged by conda-forge | (main, Feb 1 2023, 21:39:03) [GCC 11.3.0]; Linux-6.1.12-arch1-1-x86_64-with-glibc2.37; -----; Session information updated at 2023-02-25 19:07. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2431:2499,update,updated,2499,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2431,1,['update'],['updated']
Deployability,"Any ideas what's going on here? I can't do a ""pip3.6 install scanpy"" on our linux cluster:. <details>. ```; Collecting scanpy; Using cached scanpy-0.4.3.tar.gz; Requirement already up-to-date: anndata>=0.5 in /cluster/software/lib/python3.6/site-packages (from scanpy); Requirement already up-to-date: matplotlib==2.0.0 in /cluster/software/lib/python3.6/site-packages (from scanpy); Requirement already up-to-date: pandas>=0.21 in /cluster/software/lib/python3.6/site-packages (from scanpy); Requirement already up-to-date: scipy in /cluster/software/lib/python3.6/site-packages (from scanpy); Requirement already up-to-date: seaborn in /cluster/software/lib/python3.6/site-packages (from scanpy); Requirement already up-to-date: psutil in /cluster/software/lib/python3.6/site-packages (from scanpy); Requirement already up-to-date: h5py in /cluster/software/lib/python3.6/site-packages (from scanpy); Requirement already up-to-date: xlrd in /cluster/software/lib/python3.6/site-packages (from scanpy); Requirement already up-to-date: scikit-learn>=0.19.1 in /cluster/software/lib/python3.6/site-packages (from scanpy); Requirement already up-to-date: statsmodels in /cluster/software/lib/python3.6/site-packages (from scanpy); Requirement already up-to-date: networkx in /cluster/software/lib/python3.6/site-packages (from scanpy); Requirement already up-to-date: natsort in /cluster/software/lib/python3.6/site-packages (from scanpy); Requirement already up-to-date: joblib in /cluster/software/lib/python3.6/site-packages (from scanpy); Requirement already up-to-date: profilehooks in /cluster/software/lib/python3.6/site-packages (from scanpy); Requirement already up-to-date: cycler>=0.10 in /cluster/software/lib/python3.6/site-packages (from matplotlib==2.0.0->scanpy); Collecting python-dateutil (from matplotlib==2.0.0->scanpy); Using cached python_dateutil-2.6.1-py2.py3-none-any.whl; Collecting pytz (from matplotlib==2.0.0->scanpy); Using cached pytz-2018.3-py2.py3-none-any.whl; Requirem",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/90:53,install,install,53,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/90,1,['install'],['install']
Deployability,Any update on this ? I'm still getting the same error even with the development version.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2361#issuecomment-1944940981:4,update,update,4,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361#issuecomment-1944940981,1,['update'],['update']
Deployability,Any update on this? Can you add a test (probably reusing the example already in the method docstring)?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/812#issuecomment-537020598:4,update,update,4,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/812#issuecomment-537020598,1,['update'],['update']
Deployability,Any update on this? I can't figure out a way to run PCA on a specified layer & get the additional returns beyond the PCA plot.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1308#issuecomment-943177025:4,update,update,4,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1308#issuecomment-943177025,1,['update'],['update']
Deployability,Any update on this? I encountered the same issue,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1549#issuecomment-1739649092:4,update,update,4,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1549#issuecomment-1739649092,1,['update'],['update']
Deployability,Any update?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/637#issuecomment-495211738:4,update,update,4,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/637#issuecomment-495211738,1,['update'],['update']
Deployability,"Any update? I have the same issue with scanpy==1.8.1. The tutorial data has different row lengths and it works, so that can't be the problem",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2085#issuecomment-1103990647:4,update,update,4,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2085#issuecomment-1103990647,1,['update'],['update']
Deployability,Any updates here? I'd love to add this to an analysis tool UI I'm working on (and presenting at a conference this weekend). Very happy to promote scanpy there.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/72#issuecomment-363210986:4,update,updates,4,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/72#issuecomment-363210986,1,['update'],['updates']
Deployability,Any updates on this one @flying-sheep? I keep having the same issue.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/662#issuecomment-499112975:4,update,updates,4,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/662#issuecomment-499112975,1,['update'],['updates']
Deployability,Any updates on this thread?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/351#issuecomment-788017481:4,update,updates,4,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/351#issuecomment-788017481,1,['update'],['updates']
Deployability,Any updates on this? Has `correlation_matrix()` been removed?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/72#issuecomment-2271053765:4,update,updates,4,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/72#issuecomment-2271053765,1,['update'],['updates']
Deployability,"Any updates on this? scanpy=1.4.6 is still not to return matplotlib figure but still GridSpec even with ""show=False"". Or is there any other way to modify the figure/ax and save it after?; Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1069#issuecomment-624821926:4,update,updates,4,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1069#issuecomment-624821926,1,['update'],['updates']
Deployability,"Apologies for the late response @hawaiiki! I married and moved to the US with twin babies last week. And in between, I spilled something over my laptop... Yes, unfortunately, there were two half-cooked anndata releases out there. 😒 All these issues are fixed on GitHub and in anndata 0.6.10. anndata is now able to fully handle loom's layers, which it wasn't before and hence gained quite some additional functionality, thanks to @Koncopd and @VolkerBergen.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/247#issuecomment-418059347:210,release,releases,210,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/247#issuecomment-418059347,1,['release'],['releases']
Deployability,"Are celltypes really continuous? How does this variable look like?; for continuous you can do; `from scipy.stats import pearsonr`; `r, _ = pearsonr(adata.obs[""celltypes""], adata.obs[""age""])`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1845#issuecomment-849646102:21,continuous,continuous,21,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1845#issuecomment-849646102,2,['continuous'],['continuous']
Deployability,Are there any updates concerning this PR? scTransform functionality in scanpy would be much appreciated :),MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1271#issuecomment-694955289:14,update,updates,14,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1271#issuecomment-694955289,1,['update'],['updates']
Deployability,"Are you able to run `import tables` in this environment? If not, I think the issue will be with installation of the `pytables` package.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1284#issuecomment-646467845:96,install,installation,96,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1284#issuecomment-646467845,1,['install'],['installation']
Deployability,"Are you sure about numba 0.43? This very much looks like a bug in numba. > It seems that `top_segment_proportions_sparse_csr` is new for scanpy 1.4.5. What makes you think that? It’s been there since @ivirshup added `calculate_qc_metrics` in #316. A second way for this to fail is:. ```pytb; NotImplementedError: No definition for lowering UniTuple(int64 x 2).shape; ...; numba.errors.LoweringError: Failed in nopython mode pipeline (step: nopython mode backend); No definition for lowering UniTuple(int64 x 2).shape. File ""_qc_.py"", line 390:; def top_segment_proportions_sparse_csr(data, indptr, ns):; <source elided>; prev = 0; for j, n in enumerate(ns):; ^. [1] During: lowering ""$phi382.1_shape.158 = getattr(value=$380for_iter.2, attr=shape)"" at _qc.py (408); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/978#issuecomment-572698263:424,pipeline,pipeline,424,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/978#issuecomment-572698263,1,['pipeline'],['pipeline']
Deployability,"Are you sure that the genes are in `adata.var_names` in the gene symbol format that you are using to subset the object? In other words, is `'Ada' in adata.var_names` `True`? I'd just like to check whether you don't have e.g., Ensembl IDs as your variable names by chance. Regarding normalization... there are other normalization methods. I believe a method was recently added to scanpy to use only a particular fraction of genes to calculate size factors (avoiding genes that make up >5% of the total counts). Otherwise, we have recently compiled a best practices pipeline in the group, which uses Scran's pooling strategy to normalize the data. This is implemented in R, but can easily be used in a python-based workflow via [`anndata2ri`](www.github.com/flying-sheep/anndata2ri). A case study using the best practices (with scran and anndata2ri) is available [here](www.github.com/theislab/single-cell-tutorial).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/510#issuecomment-488011785:564,pipeline,pipeline,564,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510#issuecomment-488011785,1,['pipeline'],['pipeline']
Deployability,Are you sure you haven't set wxpython as the matplotlib backend somehow? Many of us use scanpy on macOS but I never manually installed wxpython...,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1302#issuecomment-653022657:125,install,installed,125,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1302#issuecomment-653022657,1,['install'],['installed']
Deployability,As a side-note: there isn't much harm in always returning the resulting object (rather than `None` when `copy=False`). It doesn't use memory (just another reference) and it allows for a more functional style of writing a processing pipeline.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/191#issuecomment-403163212:232,pipeline,pipeline,232,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/191#issuecomment-403163212,1,['pipeline'],['pipeline']
Deployability,"As an added note, it would be great to see this 'gene_symbol' argument used uniformly across the plotting functions. We've had to handle it in pretty hacky ways to make it work throughout the pipeline.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/380#issuecomment-443101144:192,pipeline,pipeline,192,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/380#issuecomment-443101144,1,['pipeline'],['pipeline']
Deployability,"As an alternative, I'd be up for just deprecating raw all together, as I think it causes more problems than it solves. I was talking about this recently with @falexwolf, who has come to a similar conclusion. This could be done on the `anndata` side, and just warn whenever `raw` is set. If no `raw` is present, then none of the weird behavior should come up. > I wonder how important it is to keep genes that are filtered out due to being expressed in too few cells anyway. Might be important for integration? But hopefully this could be solvable by just knowing what annotation was used so you can safely assume the missing values are 0. Also, what level of filtering are you doing here? I've tend to go `min_cells=1`. I think we do need to have a more general solution for having a ""feature-select-ed"" subset of the data, but think this can be done with `mask` argument. E.g. `sc.pp.pca(adata, mask=""highly_variable"")` (I believe we've talked about this before). This does run into memory usage problems if want do a densifying transform on the data, though I have doubts about whether this can be a good representation of the data. This can be technically solved by using a block sparse matrix type, but I'm not sure if any practically usable implementations of this are currently available.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1798#issuecomment-819998988:497,integrat,integration,497,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1798#issuecomment-819998988,1,['integrat'],['integration']
Deployability,"As an update, I've been using this helper function to consistently handle this:. ```python. def _choose_obs_rep(adata, *, use_raw=False, layer=None, obsm=None, obsp=None):; """"""; Choose array aligned with obs annotation.; """"""; is_layer = layer is not None; is_raw = use_raw is not False; is_obsm = obsm is not None; is_obsp = obsp is not None; choices_made = sum((is_layer, is_raw, is_obsm, is_obsp)); assert choices_made <= 1; if choices_made == 0:; return adata.X; elif is_layer:; return adata.layers[layer]; elif use_raw:; return adata.raw.X; elif is_obsm:; return adata.obsm[obsm]; elif is_obsp:; return adata.obsp[obsp]; else:; assert False, (; ""That was unexpected. Please report this bug at:\n\n\t""; "" https://github.com/theislab/scanpy/issues""; ); ```. This could use support for variable masks like `use_highly_variable`. Also the error message should be better. I think a collection of helper functions like this should go in to a utils module (`sc.utils.argutils`?) which could be public so it's easier to use in `scanpy`-like packages.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/828#issuecomment-560072919:6,update,update,6,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/828#issuecomment-560072919,1,['update'],['update']
Deployability,"As discussed on the last call, we'd like to be better about semantic versioning. The plan for this is to cut release branches which we can back port bug fixes onto, and keep new features for minor releases. We need to develop some processes for marking which PRs should get back ported, and for doing the back porting.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1399:109,release,release,109,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1399,2,['release'],"['release', 'releases']"
Deployability,"As discussed with @falexwolf this PR introduces a new Ingest class to process new small pieces of data. > sc.pp.neighbors(adata) # adata is huge with 1M observations; > ; > ingest = sc.Ingest(adata) # represents the existing data, learned annotations, structure and exposes it to functionality that allows to ingest new data very quickly; > ; > adata_small.obsm['X_model'] = model(adata_small.X); > ; > ingest.neighbors(adata_small) # adata_small with just 1000 observations; > ; > now, we have the updated neighbors graph with 1,001,000 observations; > we want to do the same things as always; > ; > by leveraging the neighbors of the new data within the old data, ; > map the new data into the embedding (umap), by just computing a correction to the existing embedding: a new data point gets the mean position of its k nearest neighbors; > ; > ingest.umap(adata_small); > ; > update the clustering (mapping the 1000 observations into the existing clusters): a new data point maps into a cluster if the majority of its neighbors is a member of the cluster ; > ; > ingest.louvain(adata_small)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/651:499,update,updated,499,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/651,2,['update'],"['update', 'updated']"
Deployability,"As discussed, @Koncopd will try to integrate this into scikit-learn itself and not into Scanpy. :smile:",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/403#issuecomment-456032298:35,integrat,integrate,35,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/403#issuecomment-456032298,1,['integrat'],['integrate']
Deployability,"As far as I can tell, #1527 still doesn't install all packages in a dev installation required to run the entire code base and tests.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1419#issuecomment-777252906:42,install,install,42,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1419#issuecomment-777252906,2,['install'],"['install', 'installation']"
Deployability,As it's scheduled to be removed in anndata 0.10.0. This will require a quick bug fix release. It may also require bumping the anndata dependency to >0.8.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2658:85,release,release,85,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2658,1,['release'],['release']
Deployability,"As noted in #1334, visium downloads were broken. Setting a header on downloads seems to fix them. This supersedes #1334 since that solution modifies global state around `urllib`, which is asking for trouble. This unfortunately means most of the method had to be reimplemented.; The new implementation is based on `urllib.requests.urlretrieve`, but with a modification to let us pass a header. I also included a couple minor fixes to existing dataset download stuff:. * We don't get a warning from using `@internet` test marker anymore; * One of the downloaded datasets changed, so the test got updated; * `_download` no longer creates all parent directories. That is handled upstream. @Mirkazemi @Koncopd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1344:594,update,updated,594,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1344,1,['update'],['updated']
Deployability,"As noted in [the installation docs](https://scanpy.readthedocs.io/en/stable/installation.html), scanpy is not distributed via bioconda. It should be installed with `conda install -c conda-forge scanpy`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2282#issuecomment-1160766533:17,install,installation,17,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2282#issuecomment-1160766533,4,['install'],"['install', 'installation', 'installed']"
Deployability,"As of now ; the package (at least in bioconda) is not fully functional and requieres some extra installation; steps if one wants to use certain functionalities provided. - [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### Minimal code sample (that we can copy&paste without having any data); ```bash; conda install -c bioconda scanpy; ````. ```python; import scanpy as sc; annot = sc.queries.biomart_annotations(""mmusculus"", [""ensembl_gene_id"", ""external_gene_name""]); ```; ```pytb; line 108, in biomart_annotations; return simple_query(org=org, attrs=attrs, host=host, use_cache=use_cache); File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/scanpy/queries/_queries.py"", line 64, in simple_query; ""This method requires the `pybiomart` module to be installed.""; ImportError: This method requires the `pybiomart` module to be installed.; ```. ```python; import scanpy as sc; adata = sc.datasets.pbmc3k(); adata.write_loom('dummy.loom'); ```; ```pytb; write_loom(filename, self, write_obsm_varm=write_obsm_varm); File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/anndata/_io/write.py"", line 112, in write_loom; from loompy import create; ModuleNotFoundError: No module named 'loompy'; ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.6; scanpy 1.7.2; sinfo 0.3.1; -----; PIL 8.3.1; anndata 0.7.6; beta_ufunc NA; binom_ufunc NA; bottleneck 1.3.2; cffi 1.14.6; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; dunamai 1.6.0; get_version 3.5; h5py 2.10.0; joblib 1.0.1; kiwisolver 1.3.1; legacy_api_wrap 0.0.0; llvmlite 0.36.0; matplotlib 3.4.2; mkl 2.4.0; mpl_toolkits NA; natsort 7.1.1; nbinom_ufunc NA; numba 0.53.1; numexpr 2.7.3; numpy 1.20.3; packaging 21.0; pandas 1.3.2; pkg_resource",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2000:1113,install,installed,1113,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2000,1,['install'],['installed']
Deployability,"As per the referencing issue, it looks like this should be fixed by the next bbknn release in a day or two. Thanks for the bug report @jipeifeng!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/632#issuecomment-490045550:83,release,release,83,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/632#issuecomment-490045550,1,['release'],['release']
Deployability,"As said: `pip install scanpy[leiden]`, and use `scanpy.tl.leiden()` instead. See here for how to install scanpy and its dependencies: https://scanpy.readthedocs.io/en/stable/installation.html",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1283#issuecomment-1638210248:14,install,install,14,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1283#issuecomment-1638210248,3,['install'],"['install', 'installation']"
Deployability,"As we are refactoring scvi, I'm wondering what the utility would be to spin off the i/o part of scanpy into it's own lightweight package that's more general for reading single cell pipeline outputs into anndata. For example, we'd like to use the scanpy read from 10x/visium functions, but don't necessarily want to have scanpy be a full requirement. It's also a bit confusing why something like `read_umi_tools` is in anndata but not `read_10x_h5`. The same goes for loom to some extent. I could imagine either moving such functionality to anndata or a standalone package that could be expanded to include support for other technologies like scATAC-seq. . This overall could be a big benefit to methods developers who would like to build on anndata.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1387:181,pipeline,pipeline,181,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1387,1,['pipeline'],['pipeline']
Deployability,"As you can see from the error output, this is an error within loompy. I assume you don't have the most recent version of loompy - there used to be a few bugs in it. Try with an update installation of loompy. I'm running 0.2.8 and never had any problem with it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/154#issuecomment-389513091:177,update,update,177,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/154#issuecomment-389513091,2,"['install', 'update']","['installation', 'update']"
Deployability,"Assuming you're on a debian based linux, please check the following:; - `echo $PATH` shows your PATH variable.; - `which git` shows you the location of your git installation. If nothing is shown, you need to install it.; - `apt install git` if you haven't installed it yet.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1257#issuecomment-636457516:161,install,installation,161,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1257#issuecomment-636457516,4,['install'],"['install', 'installation', 'installed']"
Deployability,"At first blush, this looks like an issue with spyder. I'd suggest trying to update your versions of installed packages (it looks like your scanpy and anndata are out of date) and trying again. If that fails, can you replicate in a different python environment?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1368#issuecomment-674649625:76,update,update,76,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1368#issuecomment-674649625,2,"['install', 'update']","['installed', 'update']"
Deployability,"At the moment scanpy seems to be compatible with only python >=3.7,<3.11, and it took me quite long to realise that the installation problem was due to having python 3.11 which is not yet compatible with scanpy. This appears as an error when running `pip install scanpy`, but not when running `conda install -c conda-forge scanpy`. Maybe compatibility with python versions could be mentioned on the installation manual, or be displayed as an error message when installing through conda.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2369:120,install,installation,120,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369,5,['install'],"['install', 'installation', 'installing']"
Deployability,"At the moment we're trying to clean up `scIB` that it becomes easier to use. We're still not certain how to best deal with metrics that rely on R and C++ code though. The current plan is to make a more usable pypi package where some metrics give you a warning on additional requirements/manual C++ compilation. Apologies for the usability mess that a package that also assesses usability has become ^^. I'd prefer to keep it separate for now to facilitate maintenance and citation though. That being said, maybe we could think about an optional requirement for scIB to integrate them? At least when we've cleaned up our side of things.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/915#issuecomment-763835114:569,integrat,integrate,569,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/915#issuecomment-763835114,1,['integrat'],['integrate']
Deployability,"At this point I'm not a big fan of moving back to bioconda either.; * anndata is not bio-specific and should go to conda-forge anyway; * it's debatable if it was a mistake to move scanpy, but moving it back causes confusion and more harm than good IMO. > Why have separate package registries for biology vs everything else?. probably because bioconda predates conda-forge? . > Just saw there's already a pr for this!; > ; > https://github.com/BioContainers/multi-package-containers/pull/2209. The only downside of this is that we need to update that file manually for every release of scanpy/anndata",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2281#issuecomment-1160571955:538,update,update,538,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281#issuecomment-1160571955,2,"['release', 'update']","['release', 'update']"
Deployability,"Awesome, thanks everyone. @ivirshup I added something to the release notes in the latest commit. I hope the formatting is okay -- let me know if there's some better way to do it. @LuckyMD I've seen your benchmarking preprint and admire the work! For the current API, I'm currently mooching off of tutorials made by others: one which is simpler and one (included in the scanpy tutorials) that is a little more advanced: https://github.com/brianhie/scanorama#full-tutorial. Should this get merged and included in the scanpy API, I promise I'll make a new notebook-based tutorial (probably in Google Colab) that shows off the new API and include a link to it from the Scanorama GitHub README.md. I also agree with shortening the default embedding to `'X_scanorama'` and have done that in the latest commit. @falexwolf Happy to make any changes to the tests if you think that will boost performance, if you'd like.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1332#issuecomment-665719954:61,release,release,61,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1332#issuecomment-665719954,1,['release'],['release']
Deployability,"Awesome, thanks for this! I've added something to the release notes, let me know if you'd like to say more.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1204#issuecomment-665509704:54,release,release,54,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1204#issuecomment-665509704,1,['release'],['release']
Deployability,BBKNN 1.3.2 obsoleted argument removal and docstring update,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/636:53,update,update,53,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/636,1,['update'],['update']
Deployability,Backport PR #1595 on branch 1.7.x (Update sam params),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1597:35,Update,Update,35,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1597,1,['Update'],['Update']
Deployability,Backport PR #1595: Update sam params,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1597:19,Update,Update,19,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1597,1,['Update'],['Update']
Deployability,Backport PR #1623 on branch 1.7.x (Release note for #1583 and update release date),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1624:35,Release,Release,35,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1624,3,"['Release', 'release', 'update']","['Release', 'release', 'update']"
Deployability,Backport PR #1623: Release note for #1583 and update release date,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1624:19,Release,Release,19,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1624,3,"['Release', 'release', 'update']","['Release', 'release', 'update']"
Deployability,Backport PR #1628 on branch 1.7.x (Release notes reorganization),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1665:35,Release,Release,35,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1665,1,['Release'],['Release']
Deployability,Backport PR #1628: Release notes reorganization,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1665:19,Release,Release,19,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1665,1,['Release'],['Release']
Deployability,Backport PR #1683 on branch 1.7.x (Update release notes for 1.7.1),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1686:35,Update,Update,35,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1686,2,"['Update', 'release']","['Update', 'release']"
Deployability,Backport PR #1683: Update release notes for 1.7.1,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1686:19,Update,Update,19,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1686,2,"['Update', 'release']","['Update', 'release']"
Deployability,Backport PR #1907 on branch 1.8.x (Start 1.8.1 release notes),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1911:47,release,release,47,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1911,1,['release'],['release']
Deployability,Backport PR #1907: Start 1.8.1 release notes,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1911:31,release,release,31,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1911,1,['release'],['release']
Deployability,Backport PR #1945 on branch 1.8.x (Start 1.8.2 release notes file),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1947:47,release,release,47,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1947,1,['release'],['release']
Deployability,Backport PR #1945: Start 1.8.2 release notes file,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1947:31,release,release,31,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1947,1,['release'],['release']
Deployability,Backport PR #2028 on branch 1.8.x (Update for cope with issue introduced in umap-learn 0.5.2),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2033:35,Update,Update,35,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2033,1,['Update'],['Update']
Deployability,Backport PR #2028: Update for cope with issue introduced in umap-learn 0.5.2,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2033:19,Update,Update,19,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2033,1,['Update'],['Update']
Deployability,Backport PR #2037 on branch 1.8.x (Prep 1.8.2 release),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2038:46,release,release,46,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2038,1,['release'],['release']
Deployability,Backport PR #2037: Prep 1.8.2 release,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2038:30,release,release,30,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2038,1,['release'],['release']
Deployability,Backport PR #2166 on branch 1.8.x (Update intersphinx links),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2167:35,Update,Update,35,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2167,1,['Update'],['Update']
Deployability,Backport PR #2166: Update intersphinx links,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2167:19,Update,Update,19,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2167,1,['Update'],['Update']
Deployability,Backport PR #2269 on branch 1.9.x (Update CellRank's metion in the ecosystem),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2279:35,Update,Update,35,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2279,1,['Update'],['Update']
Deployability,Backport PR #2269: Update CellRank's metion in the ecosystem,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2279:19,Update,Update,19,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2279,1,['Update'],['Update']
Deployability,Backport PR #2569 on branch 1.9.x (Add check for release notes),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2699:49,release,release,49,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2699,1,['release'],['release']
Deployability,Backport PR #2569: Add check for release notes,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2699:33,release,release,33,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2699,1,['release'],['release']
Deployability,Backport PR #2594 on branch 1.9.x (1.9.4 release notes),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2597:41,release,release,41,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2597,1,['release'],['release']
Deployability,Backport PR #2594: 1.9.4 release notes,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2597:25,release,release,25,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2597,1,['release'],['release']
Deployability,Backport PR #2639: Prepare 1.9.4 release,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2641:33,release,release,33,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2641,1,['release'],['release']
Deployability,Backport PR #2720 on branch 1.9.x (Add release workflow),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2722:39,release,release,39,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2722,1,['release'],['release']
Deployability,Backport PR #2720: Add release workflow,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2722:23,release,release,23,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2722,1,['release'],['release']
Deployability,Backport PR #2724 on branch 1.9.x (Prepare 1.9.6 release),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2725:49,release,release,49,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2725,1,['release'],['release']
Deployability,Backport PR #2724: Prepare 1.9.6 release,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2725:33,release,release,33,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2725,1,['release'],['release']
Deployability,Backport PR #2793: Update _docs.py,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2796:19,Update,Update,19,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2796,1,['Update'],['Update']
Deployability,Backport PR #2826 on branch 1.9.x (Prepare 1.9.7 release),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2827:49,release,release,49,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2827,1,['release'],['release']
Deployability,Backport PR #2826: Prepare 1.9.7 release,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2827:33,release,release,33,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2827,1,['release'],['release']
Deployability,"Backport PR #2832: Fix for _validate_palette for old numpy versions, prepare 1.9.8 hotfix release",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2833:83,hotfix,hotfix,83,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2833,2,"['hotfix', 'release']","['hotfix', 'release']"
Deployability,Backport PR #2834 on branch 1.9.x (Run ci on release branch),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2835:45,release,release,45,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2835,1,['release'],['release']
Deployability,Backport PR #2834: Run ci on release branch,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2835:29,release,release,29,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2835,1,['release'],['release']
Deployability,Backport PR #2888 on branch 1.10.x (Updated missing params in docstrings),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3091:36,Update,Updated,36,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3091,1,['Update'],['Updated']
Deployability,Backport PR #2888: Updated missing params in docstrings,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3091:19,Update,Updated,19,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3091,1,['Update'],['Updated']
Deployability,"Backport PR #2889 on branch 1.10.x (Fix for #2887, update Leiden and Louvain tools to write parameters to user specified key)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2924:51,update,update,51,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2924,1,['update'],['update']
Deployability,"Backport PR #2889: Fix for #2887, update Leiden and Louvain tools to write parameters to user specified key",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2924:34,update,update,34,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2924,1,['update'],['update']
Deployability,Backport PR #2942 on branch 1.10.x (updates sparse scale),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2985:36,update,updates,36,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2985,1,['update'],['updates']
Deployability,Backport PR #2942: updates sparse scale,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2985:19,update,updates,19,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2985,1,['update'],['updates']
Deployability,Backport PR #2951 on branch 1.10.x (Update leiden future warning),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2957:36,Update,Update,36,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2957,1,['Update'],['Update']
Deployability,Backport PR #2951: Update leiden future warning,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2957:19,Update,Update,19,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2957,1,['Update'],['Update']
Deployability,Backport PR #2994 on branch 1.10.x (Fix dev installs),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2997:44,install,installs,44,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2997,1,['install'],['installs']
Deployability,Backport PR #2994: Fix dev installs,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2997:27,install,installs,27,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2997,1,['install'],['installs']
Deployability,Backport PR #2996 on branch 1.10.x (Update coverage job),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3002:36,Update,Update,36,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3002,1,['Update'],['Update']
Deployability,Backport PR #2996: Update coverage job,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3002:19,Update,Update,19,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3002,1,['Update'],['Update']
Deployability,Backport PR #3001 on branch 1.10.x (Update marsilea tutorial to use group_ methods),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3003:36,Update,Update,36,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3003,1,['Update'],['Update']
Deployability,Backport PR #3001: Update marsilea tutorial to use group_ methods,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3003:19,Update,Update,19,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3003,1,['Update'],['Update']
Deployability,Backport PR #3121 on branch 1.10.x ((chore): prepare release notes for 0.10.2 release),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3123:53,release,release,53,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3123,2,['release'],['release']
Deployability,Backport PR #3121: (chore): prepare release notes for 0.10.2 release,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3123:36,release,release,36,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3123,2,['release'],['release']
Deployability,Backport PR #3122 on branch 1.10.x ((chore): add preparation-of-release documentation),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3132:64,release,release,64,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3132,1,['release'],['release']
Deployability,Backport PR #3122: (chore): add preparation-of-release documentation,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3132:47,release,release,47,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3132,1,['release'],['release']
Deployability,Backport PR #3172 on branch 1.10.x (Switch from using rubric in release notes),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3173:64,release,release,64,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3173,1,['release'],['release']
Deployability,Backport PR #3216 on branch 1.10.x (Update notebooks),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3222:36,Update,Update,36,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3222,1,['Update'],['Update']
Deployability,Backport PR #3216: Update notebooks,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3222:19,Update,Update,19,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3222,1,['Update'],['Update']
Deployability,Backport PR #3235 on branch main ((chore): generate 1.10.3 release notes),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3238:59,release,release,59,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3238,1,['release'],['release']
Deployability,Backport PR #3235: (chore): generate 1.10.3 release notes,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3238:44,release,release,44,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3238,1,['release'],['release']
Deployability,Backport PR #3239 on branch 1.10.x (Fix release note building and check),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3240:40,release,release,40,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3240,1,['release'],['release']
Deployability,Backport PR #3239: Fix release note building and check,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3240:23,release,release,23,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3240,1,['release'],['release']
Deployability,Backport PR #3285 on branch 1.10.x (Update `test_rank_genes_groups.py` reference),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3327:36,Update,Update,36,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3327,1,['Update'],['Update']
Deployability,Backport PR #3285: Update `test_rank_genes_groups.py` reference,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3327:19,Update,Update,19,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3327,1,['Update'],['Update']
Deployability,Backport PR #3287 on branch 1.10.x (Fix #3206’s release note),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3288:48,release,release,48,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3288,1,['release'],['release']
Deployability,Backport PR #3287: Fix #3206’s release note,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3288:31,release,release,31,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3288,1,['release'],['release']
Deployability,Backport PR #3298 on branch 1.10.x ((fix): correct anndata release for `io` usage),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3304:59,release,release,59,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3304,1,['release'],['release']
Deployability,Backport PR #3298: (fix): correct anndata release for `io` usage,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3304:42,release,release,42,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3304,1,['release'],['release']
Deployability,Backport PRs #2691 and #2660: Add missing 1.9.6 release notes,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2693:48,release,release,48,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2693,1,['release'],['release']
Deployability,"Based on [this conversation](https://discourse.scverse.org/t/scgen-generate-irreproducible-output/1622/3) on the scverse discourse site I found out that the behavior shown here does not happen if I install scanpy and pytorch (CUDA) from PyPI. It is however still happening if I install scanpy and pytorch (CUDA) using conda. I still do not know why this is happening but this shows it is not likely a problem with scanpy but some strange interaction. I will leave here the description of the packages installed in both cases for reference, and then close the issue:. 1. The behavior shown in this issue does not happen if I create an environment in conda with python installed, and then install all packages using pip like this:. ```; conda create -n scanpy_test1 python; pip install scanpy leidenalg scvi-tools; pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118; ```. This allows me to have GPU support with scvi-tools and different runs are reproducible. The packages in this environment:. <details><summary>Packages</summary>; <p>. # Name Version Build Channel; _libgcc_mutex 0.1 conda_forge conda-forge; _openmp_mutex 4.5 2_gnu conda-forge; absl-py 1.4.0 pypi_0 pypi; adjusttext 0.8 pypi_0 pypi; aiohttp 3.8.5 pypi_0 pypi; aiosignal 1.3.1 pypi_0 pypi; airr 1.4.1 pypi_0 pypi; anndata 0.9.1 pypi_0 pypi; anyio 3.7.1 pypi_0 pypi; arrow 1.2.3 pypi_0 pypi; asttokens 2.2.1 pyhd8ed1ab_0 conda-forge; async-timeout 4.0.2 pypi_0 pypi; attrs 23.1.0 pypi_0 pypi; awkward 2.3.1 pypi_0 pypi; awkward-cpp 21 pypi_0 pypi; backcall 0.2.0 pyh9f0ad1d_0 conda-forge; backoff 2.2.1 pypi_0 pypi; backports 1.0 pyhd8ed1ab_3 conda-forge; backports.functools_lru_cache 1.6.5 pyhd8ed1ab_0 conda-forge; beautifulsoup4 4.12.2 pypi_0 pypi; blessed 1.20.0 pypi_0 pypi; brotli-python 1.0.9 py311ha362b79_9 conda-forge; bzip2 1.0.8 h7f98852_4 conda-forge; ca-certificates 2023.7.22 hbcca054_0 conda-forge; certifi 2022.12.7 pypi_0 pypi; charset-normalizer 2.1.1 pypi_0 pypi; chex 0.1.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2480#issuecomment-1646783205:198,install,install,198,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2480#issuecomment-1646783205,7,['install'],"['install', 'installed']"
Deployability,Better handling of upstream releases,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1919:28,release,releases,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1919,1,['release'],['releases']
Deployability,Btw: I plan to release version 0.1 later today. Together with benchmarks and many examples for the 10x datasets. Any objections?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/16#issuecomment-298884393:15,release,release,15,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/16#issuecomment-298884393,1,['release'],['release']
Deployability,Bugfix for new release of ebi,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/741:15,release,release,15,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/741,1,['release'],['release']
Deployability,"Bumped so it's up to date, and added release note",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1936#issuecomment-961318640:37,release,release,37,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1936#issuecomment-961318640,1,['release'],['release']
Deployability,"Bumping matplotlib needs updating of google Colab's default matplotlib. As Colab imports matplotlib on start-up this means you have to restart the runtime after installing scanpy. For production I think it's fine, tutorials would require to restart after installing scanpy.; You can see this behavior in scverse tutorials using Colab, e.g. https://docs.scvi-tools.org/en/stable/tutorials/notebooks/api_overview.html",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2208#issuecomment-1089493597:161,install,installing,161,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2208#issuecomment-1089493597,2,['install'],['installing']
Deployability,But I am not sure about the readability and the order of operations. `a/b*c` is equal to `a/(b*c)` or `(a/b)*c`? . that why I did it with parenthesis.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1062#issuecomment-588356161:70,a/b,a/b,70,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1062#issuecomment-588356161,2,['a/b'],['a/b']
Deployability,"CCA does not have code in python, which will make it difficult to integrate, pySCENIC is probably easier but I would rather ask the developers. @falexwolf We should consider a way to facilitate scanpy 'plugins'. A quick search shows me that this could be possible: https://packaging.python.org/guides/creating-and-discovering-plugins/ but honestly I don't know how it works. Nevertheless, given the number of tools that continue to appear we should consider a scheme that facilitate how developers can take advantage of scanpy preprocessing, storing, analysis and visualization tools.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/265#issuecomment-423514211:66,integrat,integrate,66,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/265#issuecomment-423514211,1,['integrat'],['integrate']
Deployability,"CI is bugging us to upgrade this. It's also saying we aren't uploading anything, and we already have another task for uploading... I'm going to use this pr to. 1. try upgrading; 2. try removing. and seeing what the effects are.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2996:20,upgrade,upgrade,20,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2996,1,['upgrade'],['upgrade']
Deployability,"Came across this, and just want to add we are using poetry on scvi-tools and it's been pretty painless thus far. > no good way to editably install into some env:. If you look at our pyproject file, you can add one line that allows `pip -e .` type installation. I don't actually use poetry to create the development environment. The only issue that I haven't quite figured out is how to get the `scvi.__version__` to work on editable install.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1527#issuecomment-778296130:139,install,install,139,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527#issuecomment-778296130,3,['install'],"['install', 'installation']"
Deployability,"Can confirm that `tissue_positions.csv` is not properly detected in 1.9.3 installed off pip, but everything works fine in 1.10.0.dev87+gd08518f5 installed off GitHub.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2565#issuecomment-1651665498:74,install,installed,74,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2565#issuecomment-1651665498,2,['install'],['installed']
Deployability,Can confirm the updated tutorial works. Thanks!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2143#issuecomment-1072774695:16,update,updated,16,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2143#issuecomment-1072774695,1,['update'],['updated']
Deployability,"Can you call `del adata.uns['cell_ontology_class_colors']`? This should throw a better error message... I can do that soon, I wonder how you managed to produce the error... cannot be anything related to a recent update... Hm.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/363#issuecomment-439745461:212,update,update,212,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/363#issuecomment-439745461,1,['update'],['update']
Deployability,"Can you give a dict of deprecated functions and there new analogues? ; Then we can add f""Use {new_func[deprecated_func]} instead."" for raise FutureWarning. ; ; ; <!-- Please check (“- [x]”) and fill in the following boxes --> ; - [x] Closes #2505 ; - [x] Tests included or not required because: ; Didn't add decorator to any function(don't know which are deprecated) ; <!-- Only check the following box if you did not include release notes --> ; - [x] Release notes not necessary because: ; Too small issue",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2713:426,release,release,426,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2713,4,"['Release', 'release']","['Release', 'release']"
Deployability,"Can you give a dict of deprecated functions and there new analogues?; Then we can add f""Use {new_func[deprecated_func]} instead."" for raise FutureWarning. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [ x] Closes #2505 ; - [x ] Tests included or not required because:; Didn't add decorator to any function(don't know which are deprecated); <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because:; Too small issue",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2709:418,release,release,418,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2709,2,"['Release', 'release']","['Release', 'release']"
Deployability,"Can you give a dict of deprecated functions and there new analogues?; Then we can add f""Use {new_func[deprecated_func]} instead."" for raise FutureWarning. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Closes #2505 ; - [x] Tests included or not required because:; Didn't add decorator to any function(don't know which are deprecated); <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because:; Too small issue",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2710:416,release,release,416,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2710,4,"['Release', 'release']","['Release', 'release']"
Deployability,"Can you point to a package whose test organization you would like our tests to emulate?. I find pytests docs rather hard to navigate and would really prefer to see an example of what you're advocating for. From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py). -----------. > Would you accept a PR that simply moves the test utils into private submodules of scanpy.testing. I'd lean towards it, but I fully expect issues like #685 to come up. This is why I'd like to see a working example of what you want to work towards. ------------. > switches the import mode to (future default, drawback-less) importlib?. Is it definitely the future default? It looks like they are walking that back. Current versions of pytest docs say:. > [We intend to make importlib the default in future releases, depending on feedback.](https://docs.pytest.org/en/latest/explanation/pythonpath.html#import-modes). Where it previously said:. > [We intend to make importlib the default in future releases.](https://docs.pytest.org/en/6.2.x/pythonpath.html#import-modes)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2225#issuecomment-1096718863:888,release,releases,888,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225#issuecomment-1096718863,2,['release'],['releases']
Deployability,"Can you try using the `palette` argument? After 1.3.1, Scanpy's plotting underwent quite some fundamental changes due to @fidelram. The code base improved a lot, there might be a few small issues, though. I had both `cmap` and `palette` as argument as I wanted users to choose a default for both continuous and categorical annotation. So if someone passes a `cmap` this only affects the continuous annotation, but for categoricals the `rcParams` default is used. Does this make sense? It might stop making sense when you provide lists to `cmap` and/or `palette`; in order to plot two different categoricals with two different palettes (which should be the default behavior at some point). Happy to discuss, whether we should depricate the `palette` argument and have the default access via `cmap`, that can be provided as a list.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/286#issuecomment-430389498:296,continuous,continuous,296,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/286#issuecomment-430389498,2,['continuous'],['continuous']
Deployability,Can't install fa2 in Windows 10,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1256:6,install,install,6,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1256,1,['install'],['install']
Deployability,Can't install the spatial branch of `scanpy`,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1104:6,install,install,6,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1104,1,['install'],['install']
Deployability,"Cannot do ""pip3.6 install scanpy""",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/90:18,install,install,18,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/90,1,['install'],['install']
Deployability,Changeset:; * added new MAGIC parameter `knn_max`; * updated MAGIC default parameters to match KrishnaswamyLab/MAGIC; * added tests to check MAGIC implementation interacts with AnnData object correctly; * increased required version of `magic-impute` to 2.0,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/988:53,update,updated,53,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/988,1,['update'],['updated']
Deployability,"Changing the behavior of the `style()` methods to no longer reset everything to the default values means that the parameter defaults of that methods *shouldn’t* mention the instance defaults, because it will no longer have anything to do with them. Specifying defaults in text descriptions practically doesn’t work, because nobody remembers to update the defaults in 2 places. So unless there is a DRY solution, let’s not do that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1633#issuecomment-2283901014:344,update,update,344,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1633#issuecomment-2283901014,1,['update'],['update']
Deployability,"Check out scanpy’s optional features:. https://github.com/scverse/scanpy/blob/21ca328672646d7d0ba42b64eee2823babc2d2ed/pyproject.toml#L133-L145. as you can see `scanpy[louvain]` will install it, while `scanpy[leiden]` will install the successor.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1283#issuecomment-1637879203:183,install,install,183,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1283#issuecomment-1637879203,2,['install'],['install']
Deployability,"Checks if current axis is colorbar before trying to set the name, see #2681.; This might not be the best solution and does not yet integrate a unit test. <!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2682:131,integrat,integrate,131,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2682,1,['integrat'],['integrate']
Deployability,Clean up release notes for v1.6.0,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1339:9,release,release,9,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1339,1,['release'],['release']
Deployability,"Closing as:. * The original issue looks like a numba related problem, which I believe didn't work with python 3.9 at the time.; * We're past the 1.7 release series and aren't supporting it anymore",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1823#issuecomment-963435024:149,release,release,149,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1823#issuecomment-963435024,1,['release'],['release']
Deployability,"Closing in favor of #1116, where I integrated the commit",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1109#issuecomment-600094624:35,integrat,integrated,35,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1109#issuecomment-600094624,1,['integrat'],['integrated']
Deployability,Cluster content plot for integrated data,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1573:25,integrat,integrated,25,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1573,1,['integrat'],['integrated']
Deployability,"Completely agree, Gökcen!. How I just thought about dealing with this in the past couple of minutes: could we not make a submodule *rtools*? We could show the contained wrapper functions on an extra page of the API. All of the dependencies of this would be optional. In effect, this would be a very shallow wrapper that is only interesting for people who already have a working R installation etc. and use Scanpy along with R packages. As there are quite many of these people, this is definitely meaningful. The code would still look proper. Implementing tests for these wrappers is maybe not so important as these are only shallow interfaces. It would be easier to have this in the main scanpy repository than setting up a `scanpy-contrib`: I imagine less people will like to contribute and take the burden of maintaining another repository. PS: `anndata` is a different story. That's something that is meant to be so basic that it doesn't need a lot of maintenance an contributions. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/125#issuecomment-381984759:380,install,installation,380,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/125#issuecomment-381984759,1,['install'],['installation']
Deployability,Conda installation fails,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1298:6,install,installation,6,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1298,1,['install'],['installation']
Deployability,"Conda installation fails silently with no error. Installation command:; ```; conda install -c bioconda scanpy; ```. Output:; ```; Collecting package metadata (current_repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.; Collecting package metadata (repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: / ; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions; ```. Increasing the verbosity did not help. Using older python version did not helpeither.. It looks like the metadata are not correct but I am not able to validate this. I tried miniconda anaconda clean installs and I had no luck whatsoever. Pip install works fine.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1298:6,install,installation,6,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1298,5,"['Install', 'install']","['Installation', 'install', 'installation', 'installs']"
Deployability,"Conflict in the sphinx versions, manual backport of #2019. * pin sphinx<4.2; * update violin plots",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2020:79,update,update,79,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2020,1,['update'],['update']
Deployability,"Continuation from #805, cc @gokceneraslan @falexwolf . > Why do we change Matplotlib ""font.sans-serif"" anyway?. Alex started replacing fonts from the beginning:. https://github.com/theislab/scanpy/blob/c22e48abe45a6ccca5918bbf689637caa4b31250/scanpy/plotting.py#L605. He then updated them to the stack we have now:. https://github.com/theislab/scanpy/blob/6c68b8ba2821f27bd0b8f499a1d543dff9cc51b2/scanpy/plotting.py#L763-L767. There’s some known [metrically compatible](https://wiki.archlinux.org/index.php/Metric-compatible_fonts) fonts, but our stack doesn’t reflect that, as e.g. DejaVu Sans isn’t metrically compatible to Arial and Helvetica. Is the [default matplotlib stack](https://github.com/matplotlib/matplotlib/blob/90fba030f534b3d7068e536fcfc4a2dc8d459eeb/lib/matplotlib/rcsetup.py#L1125-L1129) better or can we at least gain inspiration from it? What would be a safe stack to use on most OSs (even if that means fiddling with our plots if we change the stack to not-Helvetica-like)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/897:276,update,updated,276,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/897,1,['update'],['updated']
Deployability,"Continuous color schemes are given with the `color_map` argument, categorical schemes are given with `palette`. All the scatter plots (`scatter`, `pca`, `tsne`, `umap`, etc...) share these arguments. Here's an example:. ```python; import scanpy as sc; import matplotlib as mpl; adata = sc.datasets.pbmc68k_reduced(); sc.pl.umap(adata, color=[""louvain"", ""HES4""]); sc.pl.umap(adata, color=[""louvain"", ""HES4""], palette=""Set2"", color_map=mpl.cm.Reds); ```. It's not that clearly documented for `umap`, and is pretty easy to miss.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/476#issuecomment-462582018:0,Continuous,Continuous,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/476#issuecomment-462582018,1,['Continuous'],['Continuous']
Deployability,"Copying using the `copy` module is a bit ill defined for `AnnData` objects currently. This has to do with some internals of how we do views of arrays. In general I'd recommend doing copies via `adata.copy()`, which performs a deep copy. But it looks like there might be another problem with the PCA not being exactly reproducible. After a fair amount of checking that it was exactly reproducible, it looks like we forgot to actually pass the random seed... There has been fixed, and there will be a bug-fix release soon (#1240). This still does not fix the issue of reproducibility if you've made a shallow copy of a AnnData view with `copy`. I'll have to look into this a bit more.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1239#issuecomment-631951443:507,release,release,507,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1239#issuecomment-631951443,1,['release'],['release']
Deployability,Could this get a notice in the docs/ something in the release notes?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1540#issuecomment-748754780:54,release,release,54,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1540#issuecomment-748754780,1,['release'],['release']
Deployability,"Could you give examples of how you'd like scanpy to work with MetaCell? It looks like a pretty comprehensive pipeline, so I'm a little unsure of at what point in an analysis you'd want to use scanpy with it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1016#issuecomment-583249005:109,pipeline,pipeline,109,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1016#issuecomment-583249005,1,['pipeline'],['pipeline']
Deployability,"Could you install the newest bugfix release of anndata and try again? Failing that, I'd recommend upgrading `h5py` and seeing if that works.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1850#issuecomment-846951987:10,install,install,10,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1850#issuecomment-846951987,2,"['install', 'release']","['install', 'release']"
Deployability,Could you please add a release note?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3220#issuecomment-2324786748:23,release,release,23,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3220#issuecomment-2324786748,1,['release'],['release']
Deployability,Could you pull the current version (0.2.7) from github or install it via pip? Everything should be back to normal now.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/32#issuecomment-324379251:58,install,install,58,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/32#issuecomment-324379251,1,['install'],['install']
Deployability,Could you update your scipy with `pip install -U scipy`?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1252#issuecomment-635084967:10,update,update,10,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252#issuecomment-635084967,2,"['install', 'update']","['install', 'update']"
Deployability,"Could you update your version of scanpy and see if the issue persists? I believe this issue was an incompatibility with the 1.3.0 release of pandas https://github.com/pandas-dev/pandas/issues/42376, which was fixed for scanpy 1.8.1 (#1917)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2008#issuecomment-946696084:10,update,update,10,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2008#issuecomment-946696084,2,"['release', 'update']","['release', 'update']"
Deployability,Critical updates to Palantir external tool wrapper. Includes updated DocString.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1245:9,update,updates,9,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1245,2,['update'],"['updated', 'updates']"
Deployability,"Current problems:. - [x] `flit install --pth-file --deps=production` doesn’t work with setuptools-scm (just in conda?); - [x] it needs `setuptools_scm`, which is in the `dev` extra. We need to document this.; - [x] circumvent pypa/setuptools#2531; - [x] flit doesn’t work if setup.py exists (still? where’s the issue?); - [x] `pip install -e` with the setup.py doesn’t install deps if the metadata is broken. Not a problem (to my knowledge), but because you mentioned it:. conda doesn’t identify flit installed distributions as `<develop>`. This is because flit installs a regular `.dist-info` directory instead of dumping an `.egg-info` into your dev directory and adding an `.egg-link` file to the `site-packages`; That needs to be fixed by conda, [I suggest they should parse symlinks](https://discuss.python.org/t/standardising-editable-mode-installs-runtime-layout-not-hooks/4098).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1527#issuecomment-760095883:31,install,install,31,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527#issuecomment-760095883,6,['install'],"['install', 'installed', 'installs', 'installs-runtime-layout-not-hooks']"
Deployability,"Currently matplotlibs colors maps are dealing with things, it's just their default ""bad color"" is often transparent. We currently don't do any handling of color maps, which makes dealing with continuous values a little more complicated.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1355#issuecomment-674744108:192,continuous,continuous,192,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1355#issuecomment-674744108,1,['continuous'],['continuous']
Deployability,"Currently there's an error being raised because the following images in don't match. path: `scanpy/tests/notebooks/_images_paga_paul15_subsampled/paga_path.png`. **Expected**; ![paga_path](https://user-images.githubusercontent.com/8322751/90666060-de033280-e21a-11ea-83f9-684908586f6e.png). **Actual**; ![paga_path](https://user-images.githubusercontent.com/8322751/90666074-e2c7e680-e21a-11ea-9f08-fc495d6762b0.png). **Diff**; ![paga_path-failed-diff](https://user-images.githubusercontent.com/8322751/90666089-e78c9a80-e21a-11ea-9e0c-4e7e6a80d140.png). I'm going to update expected to match actual, but I need some help to see if this is okay",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1382#issuecomment-676542244:568,update,update,568,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1382#issuecomment-676542244,1,['update'],['update']
Deployability,"Currently there's only a wrapper for `scanorama.integrate_scanpy`. From https://github.com/brianhie/scanorama: . > The function integrate_scanpy() will simply add an entry into adata.obsm called 'X_scanorama' for each adata in adatas. obsm['X_scanorama'] contains the low dimensional embeddings as a result of integration, which can be used for KNN graph construction, visualization, and other downstream analysis. ; > The function correct_scanpy() is a little more involved -- it will create new AnnData objects and replace adata.X with the Scanorama-transformed cell-by-gene matrix, while keeping the other metadata in adata as well.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2323:310,integrat,integration,310,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2323,1,['integrat'],['integration']
Deployability,DCA integration,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/142:4,integrat,integration,4,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/142,1,['integrat'],['integration']
Deployability,Dask update causing CI failures,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2902:5,update,update,5,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2902,1,['update'],['update']
Deployability,"Data.__init__(self, X, obs, var, uns, obsm, varm, layers, raw, dtype, shape, filename, filemode, asview, obsp, varp, oidx, vidx); 269 self._init_as_view(X, oidx, vidx); 270 else:; --> 271 self._init_as_actual(; 272 X=X,; 273 obs=obs,; 274 var=var,; 275 uns=uns,; 276 obsm=obsm,; 277 varm=varm,; 278 raw=raw,; 279 layers=layers,; 280 dtype=dtype,; 281 shape=shape,; 282 obsp=obsp,; 283 varp=varp,; 284 filename=filename,; 285 filemode=filemode,; 286 ). File /mnt/workspace/mambaforge/envs/scanpy-dev/lib/python3.11/site-packages/anndata/_core/anndata.py:501, in AnnData._init_as_actual(self, X, obs, var, uns, obsm, varm, varp, obsp, raw, layers, dtype, shape, filename, filemode); 498 self._clean_up_old_format(uns); 500 # layers; --> 501 self._layers = Layers(self, layers). File /mnt/workspace/mambaforge/envs/scanpy-dev/lib/python3.11/site-packages/anndata/_core/aligned_mapping.py:331, in Layers.__init__(self, parent, vals); 329 self._data = dict(); 330 if vals is not None:; --> 331 self.update(vals). File <frozen _collections_abc>:949, in update(self, other, **kwds). File /mnt/workspace/mambaforge/envs/scanpy-dev/lib/python3.11/site-packages/anndata/_core/aligned_mapping.py:199, in AlignedActualMixin.__setitem__(self, key, value); 198 def __setitem__(self, key: str, value: V):; --> 199 value = self._validate_value(value, key); 200 self._data[key] = value. File /mnt/workspace/mambaforge/envs/scanpy-dev/lib/python3.11/site-packages/anndata/_core/aligned_mapping.py:89, in AlignedMapping._validate_value(self, val, key); 83 dims = tuple((""obs"", ""var"")[ax] for ax in self.axes); 84 msg = (; 85 f""Value passed for key {key!r} is of incorrect shape. ""; 86 f""Values of {self.attrname} must match dimensions {dims} of parent. ""; 87 f""Value had shape {actual_shape} while it should have had {right_shape}.""; 88 ); ---> 89 raise ValueError(msg); 91 if not self._allow_df and isinstance(val, pd.DataFrame):; 92 name = self.attrname.title().rstrip(""s""). ValueError: Value passed for key 'mean' is ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2929:2568,update,update,2568,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2929,1,['update'],['update']
Deployability,Dear @jfnavarro . we recommend that you install the latest scanpy version from conda-forge. ; We are currently updating our installation instructions https://github.com/theislab/scanpy/pull/1974,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2000#issuecomment-920001620:40,install,install,40,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2000#issuecomment-920001620,2,['install'],"['install', 'installation']"
Deployability,"Dear Bo, sorry for the late response. I just became the father of twins a few days ago and couldn't respond earlier. If you still need an answer, I will look into this tomorrow. If you have `h5ls` installed on the command line, it would be great to show me the output of running `h5ls your_file.h5`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/56#issuecomment-354681849:197,install,installed,197,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/56#issuecomment-354681849,1,['install'],['installed']
Deployability,"Dear Davide, again sorry for the late response... I'll, of course, merge this and you can directly push such small things on the master... . In the meanwhile, I've made another release (see notes on https://scanpy.readthedocs.io). It would be cool to further work on the gene scoring with the small amendments (default gene list class, a small notebook with a use case) to get this in a new release. Also, in this context. I know think that `score_genes` instead of `score_gene_lists` would be better. The `_lists` does not contain actual information and is self-understood. It would also fit nicely with other functions (`cluster_genes`, e.g.). Until all of this is fixed, I removed this stuff from the API docs... Have a good start into the week!; Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/82#issuecomment-364915958:177,release,release,177,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/82#issuecomment-364915958,2,['release'],['release']
Deployability,"Dear There,. I recently re-installed the single cell environment. Then, the example code of sc.tl.marker_gene_overlap() on scanpy tutorial does not work. It give the same values to each cluster. Thanks for your help!. Lianyun. ```python; import scanpy as sc; adata = sc.datasets.pbmc68k_reduced(); sc.pp.pca(adata, svd_solver='arpack'); sc.pp.neighbors(adata); sc.tl.louvain(adata); sc.tl.rank_genes_groups(adata, groupby='louvain'); marker_genes = {'CD4 T cells': {'IL7R'},; 'CD14+ Monocytes': {'CD14', 'LYZ'},; 'B cells': {'MS4A1'},; 'CD8 T cells': {'CD8A'},; 'NK cells': {'GNLY', 'NKG7'},; 'FCGR3A+ Monocytes': {'FCGR3A', 'MS4A7'},; 'Dendritic Cells': {'FCER1A', 'CST3'},; 'Megakaryocytes': {'PPBP'}}; marker_matches = sc.tl.marker_gene_overlap(adata, marker_genes); ```. ```pytb; 	0	1	2	3	4	5	6; CD4 T cells	1.0	1.0	1.0	1.0	1.0	1.0	1.0; CD14+ Monocytes	1.0	1.0	1.0	1.0	1.0	1.0	1.0; B cells	1.0	1.0	1.0	1.0	1.0	1.0	1.0; CD8 T cells	1.0	1.0	1.0	1.0	1.0	1.0	1.0; NK cells	2.0	2.0	2.0	2.0	2.0	2.0	2.0; FCGR3A+ Monocytes	1.0	1.0	1.0	1.0	1.0	1.0	1.0; Dendritic Cells	2.0	2.0	2.0	2.0	2.0	2.0	2.0; Megakaryocytes	0.0	0.0	0.0	0.0	0.0	0.0	0.0; ![image](https://user-images.githubusercontent.com/57720451/92608724-029c7880-f2b6-11ea-9860-59c705183fb2.png). ```. #### Versions. <details>. -----; anndata 0.7.4; scanpy 1.6.0; sinfo 0.3.1; -----; PIL 7.2.0; anndata 0.7.4; backcall 0.2.0; cffi 1.14.1; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; decorator 4.4.2; get_version 2.1; h5py 2.10.0; igraph 0.8.2; ipykernel 5.3.4; ipython_genutils 0.2.0; jedi 0.15.2; joblib 0.16.0; kiwisolver 1.2.0; legacy_api_wrap 1.2; llvmlite 0.34.0; louvain 0.7.0; matplotlib 3.3.1; mpl_toolkits NA; natsort 7.0.1; numba 0.51.2; numexpr 2.7.1; numpy 1.19.1; packaging 20.4; pandas 1.1.1; parso 0.5.2; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.7; ptyprocess 0.6.0; pycparser 2.20; pygments 2.6.1; pyparsing 2.4.7; pytz 2020.1; scanpy 1.6.0; scipy 1.5.2; setuptools_scm NA; sinfo 0.3.1; six 1.15.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1411:27,install,installed,27,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1411,1,['install'],['installed']
Deployability,"Dear all; I would like to project my umap from scanpy in 3d but I have faced the following problem:. > ValueError: operands could not be broadcast together with remapped shapes [original->remapped]: (0,4) and requested shape (816,4). It's very strange because before I update some of my packages, I could run it it with no problem with the following packages:. > scanpy==1.4.1 anndata==0.6.19 numpy==1.16.3 scipy==1.2.1 pandas==0.23.4 scikit-learn==0.20.3 statsmodels==0.9.0 python-igraph==0.7.1+4.bed07760 louvain==0.6.1 . but after updating some of my packages it was not possible due to that error!. > scanpy==1.4.3 anndata==0.6.20 umap==0.3.8 numpy==1.16.3 scipy==1.2.1 pandas==0.23.4 scikit-learn==0.20.3 statsmodels==0.9.0 python-igraph==0.7.1+4.bed07760 louvain==0.6.1. Should I roll back to the previous version of annadata or scanpy? has anyone ran this feature with my package version with no problems?. Thanks a lot. Here are the packages I use",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/663:269,update,update,269,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/663,1,['update'],['update']
Deployability,"Dear author,. Can bbknn integrate multiple variables？such as Platform and Individual. Looking forward your reply; Siyu. >>> sc.external.pp.bbknn(mydata, batch_key=[""Platform"",""Individual_2""],n_pcs=50,set_op_mix_ratio=ratio). computing batch balanced neighbors; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/home/scCell2/miniconda3/lib/python3.8/site-packages/scanpy/external/pp/_bbknn.py"", line 134, in bbknn; return bbknn(; File ""/home/scCell2/miniconda3/lib/python3.8/site-packages/bbknn/__init__.py"", line 110, in bbknn; if batch_key not in adata.obs:; File ""/home/scCell2/miniconda3/lib/python3.8/site-packages/pandas/core/generic.py"", line 1721, in __contains__; return key in self._info_axis; File ""/home/scCell2/miniconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py"", line 4071, in __contains__; hash(key); TypeError: unhashable type: 'list",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2004:24,integrat,integrate,24,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2004,1,['integrat'],['integrate']
Deployability,"Dear people,. In our plotting functions, vmin and vmax are great arguments, we all love them. First of all, let's all hold our hands, close our eyes and thank matplotlib developers for implementing them. But when we jointly plot some continuous variables that are not on the exact same scale (e.g. some genes), it's not possible to specify a single vmin/vmax value that fits all variables especially if they have some outliers. This deeply saddens us and forces us to watch a few more episodes of Stranger Things and it certainly doesn't help :(. I would like to hear your thoughts about how to fix that. But before that, as a responsible person, I did some homework and I spent around 34 minutes to understand how color normalization works in matplotlib (https://matplotlib.org/3.1.1/tutorials/colors/colormapnorms.html) and tried to implement a custom normalization class (https://matplotlib.org/3.1.1/tutorials/colors/colormapnorms.html#custom-normalization-manually-implement-two-linear-ranges). . My idea is simply to specify vmin/vmax in terms of quantiles of the color vector which can be shared between variables instead of a specific value. One way, I thought, might be to pass a `norm` argument with a custom normalization object to our lovely `plot_scatter`. However, as far as I understand, it's not possible because in the quantile function in the custom normalization class requires the entire color vector for each continuous variable which is not super convenient because it's too much preprocessing to find different quantile values for each variable and pass a vmin/vmax vector to the plotting function. Not user-friendly and still requires modifications in the code :(. Instead, I added two ugly arguments named `vmin_quantile` and `vmax_quantile` to the `plot_scatter` function which allows me to specify a single quantile value for vmin/vmax which is then translated into real values separately for each variable:. ![image](https://user-images.githubusercontent.com/1140359/627204",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/775:234,continuous,continuous,234,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/775,1,['continuous'],['continuous']
Deployability,"Dear scanpy-team,. thank you very much for this great package!. Similar to issues [https://github.com/scverse/scanpy/issues/1435](url) and [https://github.com/scverse/scanpy/issues/460](url) I am interested in having an n_components parameter in the sc.tl.tsne function. . Apparently, the commit was made but no pull request was opened back in 2019. I added the necessary parameter to the arguments and passed them via the params_sklearn dict to the respective function. . Documentation is also updated. If you feel there is a need for a separate test, let me know, happy to include one. Best,; Tarik",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2671:495,update,updated,495,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2671,1,['update'],['updated']
Deployability,"Dear scverse authors (@flying-sheep, @LucaMarconato et al.), because of issues like these, maybe think about a sophisticated staging environment a la Bioconductor to ensure that packages are compatible with each other. If you do a `conda install scanpy` that finishes without any error, it cannot be that `import scanpy` fails with an error resulting from an incompatible matplotlib version.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3029#issuecomment-2362123395:238,install,install,238,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029#issuecomment-2362123395,1,['install'],['install']
Deployability,"Dear, . Is it possible to integrate scanpy with CCA and pyscenic?; CCA (canonical correlation analysis to alignment different datasets and batch effect correction):; https://satijalab.org/seurat/immune_alignment.html. pyscenic (single-cell regulatory network inference and clustering):; https://github.com/aertslab/pySCENIC",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/265:26,integrat,integrate,26,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/265,1,['integrat'],['integrate']
Deployability,"Dear,; Scanpy are winning more and more popularity since it's first release in single cell sequencing field. Now single molecule sequencing is growing fast, do you plan to develop a python package for single molecule sequencing analysis (both Nanopore and PacBio) ?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/607:68,release,release,68,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/607,1,['release'],['release']
Deployability,Dependency on `legacy-api-wrap` prevents 1.10 conda release,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2966:52,release,release,52,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2966,1,['release'],['release']
Deployability,Development install via conda does not work,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2144:12,install,install,12,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2144,1,['install'],['install']
Deployability,"Did you fix this already? The `CheckBuild` job’s task “Build & Twine check” looks fine to me:. For master:. ```; Installing collected packages: numpy, threadpoolctl, ...; Successfully installed anndata-0.7.6 cycler-0.10.0 ...; Checking dist/scanpy-1.9.0.dev2+gc9b59137-py3-none-any.whl: PASSED; Checking dist/scanpy-1.9.0.dev2+gc9b59137.tar.gz: PASSED, with warnings; warning: `long_description_content_type` missing. defaulting to `text/x-rst`.; warning: `long_description` missing.; ```. For the 1.8.x branch:. ```; Installing collected packages: numpy, threadpoolctl, ...; Successfully installed anndata-0.7.6 cycler-0.10.0 ...; Checking dist/scanpy-1.8.1.dev5+gbcbcbccf-py3-none-any.whl: PASSED; Checking dist/scanpy-1.8.1.dev5+gbcbcbccf.tar.gz: PASSED, with warnings; warning: `long_description_content_type` missing. defaulting to `text/x-rst`.; warning: `long_description` missing.; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1909#issuecomment-874177090:113,Install,Installing,113,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1909#issuecomment-874177090,4,"['Install', 'install']","['Installing', 'installed']"
Deployability,"Difficult to say something from the trace, it might be related to old setuptools version. You may try updating it. Alternatively, you can set up a [miniconda installation](https://scanpy.readthedocs.io/en/latest/installation.html#installing-miniconda) in your home folder to have more up-to-date packages.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/148#issuecomment-386885473:158,install,installation,158,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148#issuecomment-386885473,3,['install'],"['installation', 'installing-miniconda']"
Deployability,"Discovered in #1950. It looks like a recent networkx update generates slightly different plots, which breaks CI. The changes don't look particularly important to me. Here's the differences for a umap showing edges:. ![image](https://user-images.githubusercontent.com/8238804/127100302-a988dae5-385f-4e62-9edb-c97b6360247c.png); ![image](https://user-images.githubusercontent.com/8238804/127100323-1aa151aa-53c7-464f-908b-079c01e569bf.png). Diff:. ![image](https://user-images.githubusercontent.com/8238804/127100348-c662d8d0-4338-42b4-91f1-3e0550802b1c.png). Similar thing for PAGA:. ![image](https://user-images.githubusercontent.com/8238804/127100426-5fdcaf2b-132d-4b3f-9ed7-d69256c5135a.png). It looks like the coordinates are shifted. It would be nice to know if this meant you couldn't ""overlay"" images when using this, or if it's just shifting the window and the Axis' reference coordinates stay intact. If that isn't an issue, just updating the reference images would be fine. Possibly related to these changes in networkx: https://github.com/networkx/networkx/issues/4806",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1959:53,update,update,53,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1959,1,['update'],['update']
Deployability,"Do we know when UMAP 0.4 is due for a release? I wouldn't want to put too much effort into ensuring compatibility with something unstable. If it's really useful now, maybe it's worth it, but it could change again before something gets released.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/779#issuecomment-524177435:38,release,release,38,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/779#issuecomment-524177435,2,['release'],"['release', 'released']"
Deployability,Do you also mean minimal dependency versions? Because Rust’s cargo e.g. has `carg update -Z minimum-versions` which allows people to figure out if their minimum version bounds are truthful or lies (i.e. to be raised),MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2211#issuecomment-1088701942:82,update,update,82,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2211#issuecomment-1088701942,1,['update'],['update']
Deployability,"Do you mean that If I want to do use `scanpy.tl.louvain`, I can use `scanpy.tl.leiden` instead? I can `pip install scanpy[leiden]` but it will not change the error message in `scanpy.tl.louvain` with option `flavor='vtraag'`. When I try `pip install scanpy[louvain]`, it has the error `legacy-install-failure`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1283#issuecomment-1638255295:107,install,install,107,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1283#issuecomment-1638255295,3,['install'],"['install', 'install-failure']"
Deployability,Do you want to add a release note entry?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2733#issuecomment-1799255825:21,release,release,21,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2733#issuecomment-1799255825,1,['release'],['release']
Deployability,"Documenting `color_map` argument for scatter plots. This should reduce confusion about how to provide a continuous palette (#476). I'd also be up for having the arguments have names like `cont_palette` and `cat_palette`, which could be more clear.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/477:104,continuous,continuous,104,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/477,1,['continuous'],['continuous']
Deployability,Does pp.scale also update the raw expression matrix in the raw attribute?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1207:19,update,update,19,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1207,1,['update'],['update']
Deployability,Does pytest track their releases somewhere public? Curious what the timeline is here,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993#issuecomment-2050152233:24,release,releases,24,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993#issuecomment-2050152233,1,['release'],['releases']
Deployability,"Does running `pip install psutil --upgrade` help? If yes, I will update the requirements with a minimal version of psutil so that others don't run into the same problem.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/35#issuecomment-324465215:18,install,install,18,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35#issuecomment-324465215,3,"['install', 'update', 'upgrade']","['install', 'update', 'upgrade']"
Deployability,Doing `pip install --user scikit-misc` as the last line says should solve this issue - I hope it worked out!; Will close this as no more followups seen here.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2352#issuecomment-2090072902:11,install,install,11,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2352#issuecomment-2090072902,1,['install'],['install']
Deployability,"Don't know what this ""review"" process is , but basically it is ready. . De: ""Lukas Heumos"" ***@***.***> ; À: ""theislab/scanpy"" ***@***.***> ; Cc: ""Yves Le Feuvre"" ***@***.***>, ""Mention"" ***@***.***> ; Envoyé: Jeudi 6 Janvier 2022 20:11:35 ; Objet: Re: [theislab/scanpy] Pca loadings n points patch (PR #2075) . [ https://github.com/Yves33 | @Yves33 ] is this ready for review? . — ; Reply to this email directly, [ https://github.com/theislab/scanpy/pull/2075#issuecomment-1006847333 | view it on GitHub ] , or [ https://github.com/notifications/unsubscribe-auth/ACEYIQUT75OTZC3MUGVAT3DUUXSOPANCNFSM5JWG2IZQ | unsubscribe ] . ; Triage notifications on the go with GitHub Mobile for [ https://apps.apple.com/app/apple-store/id1477376905?ct=notification-email&mt=8&pt=524675 | iOS ] or [ https://play.google.com/store/apps/details?id=com.github.android&referrer=utm_campaign%3Dnotification-email%26utm_medium%3Demail%26utm_source%3Dgithub | Android ] . ; You are receiving this because you were mentioned. Message ID: ***@***.***>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2075#issuecomment-1007917047:293,patch,patch,293,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2075#issuecomment-1007917047,1,['patch'],['patch']
Deployability,Done with release 1.3.6 and the warning: https://github.com/theislab/scanpy/commit/35030d28bb4e1e4559449bfe41238523bee0e616,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/393#issuecomment-446377138:10,release,release,10,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/393#issuecomment-446377138,1,['release'],['release']
Deployability,"Dot sizes now work, this is ready to be merged... assuming you are happy with how I integrated it into the documentation (I added a separate ""density"" subsection for the plotting tools as I felt it shouldn't really be put in the same category as embeddings.)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/543#issuecomment-475595551:84,integrat,integrated,84,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/543#issuecomment-475595551,1,['integrat'],['integrated']
Deployability,"Duplicate of #2236, please follow there for updates",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3103#issuecomment-2413793255:44,update,updates,44,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3103#issuecomment-2413793255,1,['update'],['updates']
Deployability,"E.g. matplotlib is only necessary when plotting, and for e.g. Docker images, it would be useful to have a slim scanpy core. An idea would be to do it like Jupyter:. - A `scanpy-core` PyPI package with just the essentials.; - A `scanpy` metapackage, which depends on `scanpy-core` and most (or all) of the optional dependencies. Users doing `pip install scanpy` will get the full package, with no annoying runtime errors, and packagers needing flexibility get `scanpy-core` and can slim everything down as needed. cc @hensing",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/59:345,install,install,345,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/59,1,['install'],['install']
Deployability,"EGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/scanpy/readwrite.py:560) adata = _read_10x_mtx(; [561](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/scanpy/readwrite.py:561) path,; [562](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/scanpy/readwrite.py:562) var_names=var_names,; [563](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/scanpy/readwrite.py:563) make_unique=make_unique,; [564](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/scanpy/readwrite.py:564) cache=cache,; [565](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/scanpy/readwrite.py:565) cache_compression=cache_compression,; [566](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/scanpy/readwrite.py:566) prefix=prefix,; [567](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/scanpy/readwrite.py:567) is_legacy=is_legacy,; [568](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/scanpy/readwrite.py:568) ); [569](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/scanpy/readwrite.py:569) if is_legacy or not gex_only:; [570](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3214:4458,Pipeline,PipelineDevelope,4458,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3214,1,['Pipeline'],['PipelineDevelope']
Deployability,"EGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/scanpy/readwrite.py:564) cache=cache,; [565](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/scanpy/readwrite.py:565) cache_compression=cache_compression,; [566](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/scanpy/readwrite.py:566) prefix=prefix,; [567](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/scanpy/readwrite.py:567) is_legacy=is_legacy,; [568](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/scanpy/readwrite.py:568) ); [569](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/scanpy/readwrite.py:569) if is_legacy or not gex_only:; [570](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/scanpy/readwrite.py:570) return adata. File ~\AppData\Roaming\Python\Python312\site-packages\scanpy\readwrite.py:594, in _read_10x_mtx(path, var_names, make_unique, cache, cache_compression, prefix, is_legacy); [588](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/scanpy/readwrite.py:588) suffix = """" if is_legacy else "".gz""; [589](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/scanpy/readwrite.py:589) adata = read(; [590](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-pa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3214:5233,Pipeline,PipelineDevelope,5233,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3214,1,['Pipeline'],['PipelineDevelope']
Deployability,"Emm, the code is just from the scanpy tutorial.; https://scanpy-tutorials.readthedocs.io/en/latest/integrating-data-using-ingest.html. I run ingest on pbmc dataset, then meet this problem.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1951#issuecomment-883853578:99,integrat,integrating-data-using-ingest,99,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1951#issuecomment-883853578,1,['integrat'],['integrating-data-using-ingest']
Deployability,Error installing scanpy through pip,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/43:6,install,installing,6,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/43,1,['install'],['installing']
Deployability,Error pip installing,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/22:10,install,installing,10,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/22,1,['install'],['installing']
Deployability,Even cooler!. Do you recall whether the memory usage for a million cells was anything prohibitive?. I was actually thinking of utilizing distribution across machines as a way to scale out if memory usage started becoming an issue (or even just using the same batching strategy on one machine). This could be very useful for large scale dataset integration. Though I'm curious if using nn-descent could introduce some bias towards merging data.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/659#issuecomment-495306812:344,integrat,integration,344,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/659#issuecomment-495306812,1,['integrat'],['integration']
Deployability,"Every time I build the docs locally, they do a complete rebuild. This is painfully slow (especially with our examples that run on each build) and really discourages editing the docs. This is happening because the sphinx sees the config being modified. There are two causes of this:. * The version being set dynamically – at each commit the version string changes.; * `scanpydoc.elegant_typehints` sets some properties of the config after it's loaded. E.g.:. ```; updating environment: [config changed ('typehints_formatter')] 317 added, 0 changed, 0 removed; ```. ### Solution. Version being set dynamically does really add that much value for us, so I just removed that part of the version string. `scanpydoc.elegant_typehints` does make the doc-strings nicer, but it is not worth a five minute build to update the docs. Ideally it can be implemented in a way that doesn't make sphinx think the config has changed, but I am disabling it until then.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2199:805,update,update,805,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2199,1,['update'],['update']
Deployability,"Everything runs fine on the current master branch, I uploaded the current version of the notebook: https://nbviewer.jupyter.org/github/theislab/paga/blob/master/blood/paul15/paul15.ipynb. I'll release either 1.3.3 or 1.4 very soon and if there should have been a bug at some point, it seems to have been fixed at some point. Finally, PAGA is also in the continuous integration tests, so no bugs in the future anymore for this. ;)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/333#issuecomment-435728872:193,release,release,193,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/333#issuecomment-435728872,3,"['continuous', 'integrat', 'release']","['continuous', 'integration', 'release']"
Deployability,"Exactly, the error was introduced by some third party update or so. Therefore there was no need for 6e797fa, and it even is is wrong, the second line *needs* to be. ```py; colors = cmap(normalize(mean_flat)); ```. It’s both faster and necessary: `Normalize` determines vmin and vmax from the first time it’s called when they’re not set / set to `None`. And when you call it with `normalize(mean_flat[0])` (what happens in the list comprehension), vmin gets set to `min(mean_flat[0]) == mean_flat[0]` instead of `min(mean_flat)`. please do. ```sh; git reset --hard a4b3ccd88f0412461813838d5435ce0cc0b10883; git push -f; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/390#issuecomment-446104893:54,update,update,54,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/390#issuecomment-446104893,1,['update'],['update']
Deployability,"Excellent, thank you. I'll patch my code accordingly.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1176#issuecomment-617141601:27,patch,patch,27,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1176#issuecomment-617141601,1,['patch'],['patch']
Deployability,Extended gex_only function to visium. <!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Closes #3113; - [x] Tests included or not required because: It's a straightforward argument pass from visium to read_10x_h5; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: not a big change,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3278:525,release,release,525,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3278,2,"['Release', 'release']","['Release', 'release']"
Deployability,"Extracting it would be great. What triggered the test to fail on other branches, I'd assume a matplotlib update?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2235#issuecomment-1598724173:105,update,update,105,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2235#issuecomment-1598724173,1,['update'],['update']
Deployability,FIt-SNE integration?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/996:8,integrat,integration,8,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/996,1,['integrat'],['integration']
Deployability,"FWIW, I stumbled upon a related issue this morning where my kernel just crashes/restarts computing neighbors. . For me it appears to crop up when the number of neighbors is <15, metric doesn't appear to matter. I've been upgrading/downgrading various dependencies, and I'm fairly certain this has to do with the call to [`NNDescent` in `umap.umap_.py`](https://github.com/lmcinnes/umap/blob/b1223505ca56ae104feb35e4196227277d1e8058/umap/umap_.py#L328) as if I import that directly, it raises the same errors. Currently have `numba=0.52` `llvmlite=0.35.0` `scanpy=1.7.1` `pynndescent=0.5.2` `umap-learn=0.5.1`. Rebuilding my environment from scratch and will update with a complete package list.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1696#issuecomment-797603893:658,update,update,658,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1696#issuecomment-797603893,1,['update'],['update']
Deployability,Facing the same issue! Any guidance would be appreciated. Was trying to install using Anaconda Navigator for Windows but i guess I will try the Miniconda route,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/990#issuecomment-581828751:72,install,install,72,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/990#issuecomment-581828751,1,['install'],['install']
Deployability,Fail to install scanpy by pip,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/148:8,install,install,8,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148,1,['install'],['install']
Deployability,Failed in nopython mode pipeline,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/936:24,pipeline,pipeline,24,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/936,1,['pipeline'],['pipeline']
Deployability,"Feature selection refers to excluding uninformative genes such as those which exhibit no meaningful biological variation across samples. Since scRNA-Seq experiments usually examine cells within a single tissue, only a small fraction of genes are expected to be informative since many genes are biologically variable only across different tissues (adopted from https://genomebiology.biomedcentral.com/articles/10.1186/s13059-019-1861-6).; But, in fact some experimental design are very complex, such single-cell RNAseq of tissues from different development stage. The tissues can vary a log along the development timeline.; I find that the number of HVGs can affect data integration and batch effects correction. I've integrated seven cell samples collected at different development stage(1day, 2 day, 3 day, 4day, 5 day, 6 day, 7day after fertilization) with SCVI-tools, using 2000 HVGs, which then shows no ""batch effect"" (cells were mixed with no correlation among samples) left; on the other hand, using all genes, which shows still some extent of ""batch effect"" (some cells were clustered by time obviously) left. This could definitely affect the biological explaination, because the ""batch effect"" can be regarded as the difference of true biological difference at different development stage. The tissues are undergoing intensive differentiation process, so that the cell population are changing a lot during this process. Using only HVGs might lost these development process. ; In sum, HVGs are good for batch effect correction. The ""batch effects"" become less obvious when using less genes and more obvious when using more genes. However, more genes are good for discovery of new cell population. Does this make sense ?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1578#issuecomment-764494020:670,integrat,integration,670,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1578#issuecomment-764494020,2,['integrat'],"['integrated', 'integration']"
Deployability,"File ""/home/joyzheng/.local/lib/python3.8/site-packages/h5py/_hl/group.py"", line 183, in create_dataset; dsid = dataset.make_new_dset(group, shape, dtype, data, name, **kwds); File ""/home/joyzheng/.local/lib/python3.8/site-packages/h5py/_hl/dataset.py"", line 168, in make_new_dset; dset_id.write(h5s.ALL, h5s.ALL, data); File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper; File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper; File ""h5py/h5d.pyx"", line 280, in h5py.h5d.DatasetID.write; File ""h5py/_proxy.pyx"", line 145, in h5py._proxy.dset_rw; File ""h5py/_conv.pyx"", line 444, in h5py._conv.str2vlen; File ""h5py/_conv.pyx"", line 95, in h5py._conv.generic_converter; File ""h5py/_conv.pyx"", line 249, in h5py._conv.conv_str2vlen; TypeError: Can't implicitly convert non-string objects to strings. The above exception was the direct cause of the following exception:; Traceback (most recent call last):; File ""integration.py"", line 66, in <module>; adata.write_h5ad('Integrated.h5ad'); File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_core/anndata.py"", line 1918, in write_h5ad; _write_h5ad(; File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py"", line 98, in write_h5ad; write_elem(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs); File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper; return func(elem, key, val, *args, **kwargs); File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 175, in write_elem; _REGISTRY.get_writer(dest_type, t, modifiers)(f, k, elem, *args, **kwargs); File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper; result = func(g, k, *args, **kwargs); File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 514, in write_dataframe; write_elem(group, colname, series._values, dataset_kwargs=dataset_kwargs); File ""/home/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2432:3048,Integrat,Integrated,3048,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432,1,['Integrat'],['Integrated']
Deployability,Finalize release notes,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1904:9,release,release,9,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1904,2,['release'],['release']
Deployability,"First I installed scanpy using sudo and pip as any python package. But, now I followed your advice and installed it using Bioconda, and it solved the issue. Thank you.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/280#issuecomment-427037414:8,install,installed,8,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/280#issuecomment-427037414,2,['install'],['installed']
Deployability,"First reported by @lazappi, but now confirmed by me. Tests error during collection for a fresh dev install. ```; mamba create -yn scanpy-dev ""python=3.12""; conda activate scanpy-dev; pip install -e "".[dev,test]"" pytest-xdist # pytest-xdist isn't required, but makes this faster; conda deactivate scanpy-dev; conda activate scanpy-dev; pytest -n auto; ```. First everything fails since `dask-expr` isn't installed. This must be someone upstream pinning dask, but is easily solvable by adding dask-expr to the environment. ```; pip install dask-expr; pytest -n auto; ```. <details>; <summary> Failures </summary>. ```; FAILED scanpy/tests/test_score_genes.py::test_score_with_reference - TypeError: 'module' object is not callable; FAILED scanpy/tests/test_scrublet.py::test_scrublet[True-sparse] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet[True-dense] - ImportError: cannot import name '_paul15' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet[False-sparse] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet[False-dense] - ImportError: cannot import name '_paul15' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet_batched - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet_data - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet_simulate_doublets - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/external/test_harmony_integrate.py; ERROR scanpy/tests/external/test_harmony_timeseries.py; ERROR scanpy/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:99,install,install,99,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,4,['install'],"['install', 'installed']"
Deployability,Fix #3206’s release note,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3287:12,release,release,12,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3287,1,['release'],['release']
Deployability,Fix PYTHON_VERSION in travis installer,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/201:29,install,installer,29,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/201,1,['install'],['installer']
Deployability,Fix dev installs,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2994:8,install,installs,8,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2994,1,['install'],['installs']
Deployability,"Fix for #2887, update Leiden and Louvain tools to write parameters to user specified key",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2889:15,update,update,15,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2889,1,['update'],['update']
Deployability,"Fix for _validate_palette for old numpy versions, prepare 1.9.8 hotfix release",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2832:64,hotfix,hotfix,64,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2832,2,"['hotfix', 'release']","['hotfix', 'release']"
Deployability,Fix install,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1376:4,install,install,4,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1376,1,['install'],['install']
Deployability,"Fix is in unreleased code, thus no release notes",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3321:35,release,release,35,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3321,1,['release'],['release']
Deployability,Fix pip install statement in CONTRIBUTING.md,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1442:8,install,install,8,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1442,1,['install'],['install']
Deployability,Fix release note building and check,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3239:4,release,release,4,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3239,1,['release'],['release']
Deployability,"Fixed by reverting the change on pynndescent, so users should just get the new release when they install",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1931#issuecomment-875409508:79,release,release,79,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1931#issuecomment-875409508,2,"['install', 'release']","['install', 'release']"
Deployability,"Fixed in https://github.com/theislab/scanpy/commit/57161ec444eef7815e159037c6944ddcc75572d9. However, the version1 branch is not stable yet... another day or two... What made me believe that seaborn is still doing strange things, is this... one call to `seaborn.set_style` messes up the whole configuration... That's a bug, isn't it?; <img width=""207"" alt=""image"" src=""https://user-images.githubusercontent.com/16916678/37690247-05c2686e-2caa-11e8-8dc2-7365a90f8748.png"">",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/108#issuecomment-374805935:293,configurat,configuration,293,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/108#issuecomment-374805935,1,['configurat'],['configuration']
Deployability,Fixed in sphinx-autodoc-typehints [1.25.3](https://github.com/tox-dev/sphinx-autodoc-typehints/releases/tag/1.25.3),MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2829#issuecomment-1912294688:95,release,releases,95,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2829#issuecomment-1912294688,1,['release'],['releases']
Deployability,"Fixed, we've got a bit of custom plan with readthedocs and an update to their billing code broke that url.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1746#issuecomment-801541188:62,update,update,62,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1746#issuecomment-801541188,1,['update'],['update']
Deployability,"Fixes #1697. I'll leave any major backwards compatibility changes (i.e. updating to use python 3.7+ features) to the future. CI took a really long time to install the dependencies on the first run. Hopefully that will be cached? Not sure what triggers a saved cache. At the moment it looks like building `louvain` is taking a while, which we should actually just get around to deprecating.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1897:155,install,install,155,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1897,1,['install'],['install']
Deployability,"Fixes #1841. It would be nice to test this, but I'm not sure we're set up for that. E.g., we can test that it doesn't work in a python session, but I'm not sure if we can test that it does work in an ipython session. TODO:. - [x] Release note; - [ ] ~~Test?~~ Not so sure how to do this, and it's useful now.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1844:230,Release,Release,230,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1844,1,['Release'],['Release']
Deployability,"Fixes #1859. `igraph` uses python's random state, not numpy's. TODO:. - [x] Update saved examples for tests; - [x] Release note",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1922:76,Update,Update,76,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1922,2,"['Release', 'Update']","['Release', 'Update']"
Deployability,Fixes #1959. Updates plots to work with how edge plotting is handled in networkx>2.6. Also moves paga plotting tests to (i) their own module (ii) their own individual tests (so we don't just see the first one that fails).,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1960:13,Update,Updates,13,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1960,1,['Update'],['Updates']
Deployability,"Fixes #2211. I’ll first try with all removed. I expect the min_tests run to fail. Seeing what fails,. - If it’s not much, I’ll just refactor the fixtures a bit and so on; - Else I’ll move algorithms to the `test` extra. Then we can merge this PR and over time refactor our tests so more and more extras go from `tests` to `tests-full`. @ivirshup do you like the collection extras’ names (`io`, `speedups`, `algorithms`)? Should we add an extra named `all` that installs all the `-full` extras?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2222:461,install,installs,461,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2222,1,['install'],['installs']
Deployability,Fixes #762. Update to #764. Just adding a test to make sure the `use_raw` argument does something. I'm opening this a new pull request since git didn't me using other PRs branch name.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/790:12,Update,Update,12,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/790,1,['Update'],['Update']
Deployability,Fixes #769. Looks like I only tested my use case in #724. Not sure if this will still be needed once https://github.com/lmcinnes/umap/pull/261 is in a release.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/771:151,release,release,151,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/771,1,['release'],['release']
Deployability,"Fixes #849. This PR updates our tests so that they expect 3d plots to work if matplotlib 3.3.3 is installed. The plots also look a bit different than they used to:. Old:. ![master_3dprojection](https://user-images.githubusercontent.com/8238804/98928524-fb038500-252d-11eb-82b8-cfb84b28f821.png). New:. ![master_3dprojection](https://user-images.githubusercontent.com/8238804/98928485-f212b380-252d-11eb-8a17-0e2d7683e51a.png). It would be nice if the legend was even more visible, but I think I'll leave it for now.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1493:20,update,updates,20,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1493,2,"['install', 'update']","['installed', 'updates']"
Deployability,"Fixes #993. This is an approximate implementation of the Seurat v3 hvg method. The only difference should be the use of lowess instead of loess (which is not available in python as far as I know). This method takes the UMI counts as input. The way HVGs from batches are merged is also different from the other flavors. As such, I didn't see a straightforward way to integrate this in the existing HVG code.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1182:366,integrat,integrate,366,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1182,1,['integrat'],['integrate']
Deployability,"Follow up to #2420, which let the tests run, but didn't actually install anndata-dev. Current version was quoted due to my error in reading a `pre-commit` complaint about yaml syntax. Tbf, yaml syntax is complicated, and the pre-commit check gives bad error messages. ----. Additionally apply other fixes from yesterdays bug fix release to main branch",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2421:65,install,install,65,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2421,2,"['install', 'release']","['install', 'release']"
Deployability,"Follow up to https://github.com/scverse/scanpy/pull/3275#pullrequestreview-2392213666. I think that this woulda worked regardless because the `try` will define it initially anyways. However, it's best practice to only have code that can error in the `try` statement. I'll allow myself to skip a release note etc because this is minor and there hasn't been a release yet with this fix.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3315:295,release,release,295,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3315,2,['release'],['release']
Deployability,Following what nf-core did to all of their pipelines and tools.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2463:43,pipeline,pipelines,43,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2463,1,['pipeline'],['pipelines']
Deployability,"For all those asking whether this has been updated, I'm not a contributor to this repo but from reading the source code, it looks like this has indeed been updated in the latest version of scanpy. From what I can tell, . - `np.log2((expm1_func(mean_in_cluster) + 1e-9) / (expm1_func(mean_out_cluster) + 1e-9))` is now consistently used to calculate and filter fold changes, in `rank_genes_groups` and `filter_rank_genes_groups` respectively. ; - The default value for arg `min_fold_change=2` has also been changed from 2 to 1, which makes sense. i.e. won't filter out genes based on fold change unless the user explicitly asks it to; - Still no fix for the issue where negative fold changes get automatically filtered out in `filter_rank_genes_groups`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/863#issuecomment-776459742:43,update,updated,43,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/863#issuecomment-776459742,2,['update'],['updated']
Deployability,"For context, the option was added in #334, and I think the scope for other feature types was much more limited at the time. > Would it already be worth either making gex_only a required input?. I'm not sure the `gex_only` argument even entirely makes sense anymore. I think a `feature_type` argument would make more sense. Erroring if nothing is passed and there are multiple kinds sounds reasonable to me, as multimodality should be handled explicitly. For backwards compatibility I think deprecation warnings for a release cycle when either `gex_only` is used or nothing is passed and there are multiple feature types present could work. -----------. Moving the 10x reading functions had been discussed in: #1387",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1949#issuecomment-879616528:517,release,release,517,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1949#issuecomment-879616528,1,['release'],['release']
Deployability,"For continuous values I don't think we need to add anything to the color bar. If a dot color is not part of the colorbar then is assumed that is a NaN. I searched in matplotlib for a similar case in which a colorbar includes NaN values but could not find any example. If this feature is wanted, what we can do is to use the option for colorbar extension and use it for NaNs but we need to find a way to set the label for NaN. ```PYTHON; import numpy as np; import matplotlib.pyplot as plt. adata = sc.datasets.pbmc68k_reduced(); adata.obs['n_genes'].iloc[::4] = np.nan; cmap = plt.get_cmap('viridis'); cmap.set_under('lightgray'); cmap.set_bad('lightgray'). fig, ax = plt.subplots(); cax = ax.scatter(adata.obsm['X_umap'][:,0], adata.obsm['X_umap'][:,1], ; c=adata.obs['n_genes'], s=20, ; cmap=cmap, ; vmin=1000, ; vmax=2000, plotnonfinite=True); fig.colorbar(cax, extend='min', extendrect=True, extendfrac=0.1). plt.show(); ```; ![image](https://user-images.githubusercontent.com/4964309/90750699-7b22a180-e2d5-11ea-9a67-1ad7feb8a6a4.png)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1356#issuecomment-677477507:4,continuous,continuous,4,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356#issuecomment-677477507,1,['continuous'],['continuous']
Deployability,For me `pip install anndata --upgrade` did the trick. You could also do `pip install anndata==0.8.0` if that's the specific version you want to have.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1351#issuecomment-1378424295:12,install,install,12,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351#issuecomment-1378424295,3,"['install', 'upgrade']","['install', 'upgrade']"
Deployability,"For some context, this has come up in discussion with cellxgene before: (https://github.com/chanzuckerberg/cellxgene/issues/1152#issuecomment-604286306). I think I still feel the same way about this. Basically, a continuous colormap is defined by more than just the name of the colorspace. There are parameters like maximum value, minimum value, middle value (for divergent colormaps), scale, and binning. I'm not sure how useful it is to keep just the color scheme without any of these other values. Why this parameter, and not others?. I'm not sure it's the right solution for the use case. I think that use case would be better fit by being able to generate all the plots individually, then collect them into a figure. This way you would have complete control over how the colormaps were applied to each of the continuous variables separately. Unfortunately, this isn't particularly ergonomic to do with matplotlib since individuals plots have to know about the `Figure` when constructed. Side issue: We probably don't want to save separate color palettes for each gene.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1489#issuecomment-729531302:213,continuous,continuous,213,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1489#issuecomment-729531302,2,['continuous'],['continuous']
Deployability,"For this PR, I'm thinking I'm going to wait on a response from @flying-sheep to figure out what to do about the sklearn intersphinx problem, then clean it up for a merge. A new issue will be opened up with all the functions that need examples, and those can be added through separate PRs as the release progresses.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1632#issuecomment-775794535:295,release,release,295,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1632#issuecomment-775794535,1,['release'],['release']
Deployability,"Fresh install in a new env gives me the same error (jupyter kernel crashes):; ```; conda create --name squidpy python=3.8 seaborn scikit-learn statsmodels numba pytables; conda activate squidpy; conda install -c conda-forge leidenalg python-igraph; pip install scanpy squidpy imctools stardist; ```; And here's the `sc.logging.print_versions()`:; ```; -----; anndata 0.7.5; scanpy 1.7.1; sinfo 0.3.1; -----; PIL 8.1.2; anndata 0.7.5; asciitree NA; backcall 0.2.0; cairo 1.20.0; cffi 1.14.5; cmocean 2.0; constants NA; cycler 0.10.0; cython_runtime NA; dask 2021.03.0; dateutil 2.8.1; decorator 4.4.2; docrep 0.3.2; fasteners NA; get_version 2.1; h5py 2.10.0; highs_wrapper NA; igraph 0.8.3; imagecodecs 2020.12.24; imageio 2.9.0; ipykernel 5.5.0; ipython_genutils 0.2.0; ipywidgets 7.6.3; jedi 0.18.0; joblib 1.0.1; kiwisolver 1.3.1; legacy_api_wrap 1.2; leidenalg 0.8.3; llvmlite 0.35.0; matplotlib 3.3.4; mpl_toolkits NA; natsort 7.1.1; networkx 2.5; numba 0.52.0; numcodecs 0.7.3; numexpr 2.7.3; numpy 1.20.1; packaging 20.9; pandas 1.2.3; parso 0.8.1; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.17; ptyprocess 0.7.0; pycparser 2.20; pygments 2.8.1; pyparsing 2.4.7; pytz 2021.1; pywt 1.1.1; scanpy 1.7.1; scipy 1.6.0; seaborn 0.11.1; sinfo 0.3.1; six 1.15.0; skimage 0.18.1; sklearn 0.24.1; squidpy 1.0.0; statsmodels 0.12.2; storemagic NA; tables 3.6.1; texttable 1.6.3; tifffile 2021.3.5; tornado 6.1; traitlets 5.0.5; typing_extensions NA; wcwidth 0.2.5; xarray 0.17.0; yaml 5.4.1; zarr 2.6.1; zmq 22.0.3; -----; IPython 7.21.0; jupyter_client 6.1.11; jupyter_core 4.7.1; notebook 6.2.0; -----; Python 3.8.8 | packaged by conda-forge | (default, Feb 20 2021, 16:22:27) [GCC 9.3.0]; Linux-3.10.0-1062.1.2.el7.x86_64-x86_64-with-glibc2.10; 72 logical CPU cores, x86_64; -----; Session information updated at 2021-03-12 11:42; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1696#issuecomment-797629745:6,install,install,6,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1696#issuecomment-797629745,4,"['install', 'update']","['install', 'updated']"
Deployability,"From what I can gather, one goal here is to refactor the dotplot function and give it a complex heatmap layout, with a central heatmap using circle patches with a color and size aesthetic (= the dotplot) and one or more annotation heatmaps for rows and columns, which could be categorical or quantitative each. Potentially relevant features in codaplot are. - co.cross_plot is one high level possibility to construct complex heatmaps with the 'central data heatmap + annotation heatmaps' layout. Among other things, it can automatically cluster columns or rows based on the central data heatmap and apply the clustering to the annotation heatmaps. It can also plot dendrograms. This is an experimental function with some quirks, I did want to improve the concept soon-ish.; - co.heatmap is the base heatmap plotting function in codaplot. It provides a simple way to plot categorical heatmaps and add spacers within heatmaps. Both tasks are not trivial with matplotlib base plot functions. This would be helpful for adding categorical annotation heatmaps, even if you don't want to use co.cross_plot as it is right now.; - i have an alternative function to co.heatmap in my snippets library which is capable of creating heatmaps using rectangle or circle patches with size and color aesthetics, but i havent added it to codaplot yet. You can always create circle patch heatmaps with standard scatterplots, but this has drawbacks when you want to be able to add spacers within the plot or when you want full control of the circle patch sizes (so that they fit perfectly within the row at maximum size). From what I understand such a patch based function would be helpful, right?. I would be happy to contribute some base functionality for this issue by adding improvements to codaplot, ie provide the circle patch heatmap function and a better complex heatmap function than the currently available co.cross_plot. I do plan on maintaining codaplot for the foreseeable future and have been using it for my",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2194#issuecomment-1145123103:148,patch,patches,148,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2194#issuecomment-1145123103,1,['patch'],['patches']
Deployability,FuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100n-inftheta-noclip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[toarray-int64-100n-100theta-infclip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_embedding_plots.py::test_missing_values_categorical[pca-na_color.black_tup-na_in_legend.False-legend.on_data-groups.3] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-200n-100theta-30clip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[toarray-float32-100n-inftheta-noclip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_embedding_plots.py::test_missing_values_categorical[pca-na_color.black_tup-na_in_legend.False-legend.on_data-groups.all] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-200n-100theta-30clip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200n-inftheta-30clip-full] - NotImplementedError: Failed in nopython mo,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:36115,pipeline,pipeline,36115,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['pipeline'],['pipeline']
Deployability,Getting 1.10.1 ready for release,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2989:25,release,release,25,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2989,1,['release'],['release']
Deployability,Getting ready for 1.8.1 release,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1926:24,release,release,24,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1926,1,['release'],['release']
Deployability,"Getting the error: ""numba.errors.TypingError: Failed in nopython mode pipeline (step: nopython frontend)"" when running sc.tl.umap with init_pos='paga'",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/948:70,pipeline,pipeline,70,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/948,1,['pipeline'],['pipeline']
Deployability,Getting the same bug. What's the status on merging this fix into a release? Thanks!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/953#issuecomment-618739346:67,release,release,67,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/953#issuecomment-618739346,1,['release'],['release']
Deployability,Github install error,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/482:7,install,install,7,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/482,1,['install'],['install']
Deployability,"Glad that it worked, and thanks for reporting the issue. I realized that the requirement for scanpy was `matplotlib>=2.2.2`. I updated it to 3.0.0.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/480#issuecomment-463521833:127,update,updated,127,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/480#issuecomment-463521833,1,['update'],['updated']
Deployability,"Glad to hear it! We've just released `v1.4.4` which has this fix in it, so you can use that if you don't want to be on the development branch.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/731#issuecomment-513444766:28,release,released,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/731#issuecomment-513444766,1,['release'],['released']
Deployability,"Glad to see this discussion going on. Integrating openTSNE into scanpy should be fairly straightforward but may require some thought. I think Dmitry has already pointed out the most important things such as improved defaults, which other t-SNE implementations are lagging behind in. Apart from that, we package prebuilt binaries, so adding openTSNE as a dependency would be incredibly easy. The main thing we'd have to agree on is how to deal with the KNN graphs. UMAP by default calculates 15 nearest neighbors, and from what I can tell, louvain and leiden clustering both use those 15 neighbors as well by default. t-SNE, on the other hand, calculates 90 nearest neighbors by default. This is every single t-SNE implementation, not just openTSNE. Dmitry suggested using a uniform kernel with 15 neighbors, which would fit elegantly, but then again, this isn't truly t-SNE anymore, but rather something very close. The same goes for the `ingest` functionality. openTSNE does something similar to UMAP for adding new samples to existing embeddings, and then we'd again have to figure out how to calculate nearest neighbors from the new data to the reference data. I don't know how you do this currently for UMAP. I'm not exactly sure how these neighbors are meant to be used in scanpy, since there are several different algorithms that use them. Graph-based clustering uses the KNNG, UMAP uses it, forceatlas2 uses it, PAGA probably as well? Is relying on a single k=15 from UMAP for everything really ok? For example, seurat defaults to using 30 neighbors for clustering.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1233#issuecomment-637563724:38,Integrat,Integrating,38,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233#issuecomment-637563724,1,['Integrat'],['Integrating']
Deployability,Glad to see this is fixed in newer versions!. No worries about the changing install instructions.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2172#issuecomment-1063294721:76,install,install,76,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2172#issuecomment-1063294721,1,['install'],['install']
Deployability,"Goal:. Add `dask` use-cases to the scanpy benchmarks so we can understand performance changes. . Nice links:. 1. Example benchmark: https://github.com/scverse/scanpy/blob/main/benchmarks/benchmarks/preprocessing_counts.py; 2. Project we use for benchmarking: https://asv.readthedocs.io/projects/asv-runner/en/latest/index.html; 3. Dask local cluster: https://distributed.dask.org/en/stable/api.html#cluster; 4. Using scanpy and dask: https://scanpy.readthedocs.io/en/stable/tutorials/experimental/dask.html. NOTE: this `read_elem_as_dask` function in the notebook is with anndata 0.11 i.e., `pip install --pre anndata`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3013#issuecomment-2419644519:596,install,install,596,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3013#issuecomment-2419644519,1,['install'],['install']
Deployability,Going to implemented in future releases,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2982#issuecomment-2227468431:31,release,releases,31,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2982#issuecomment-2227468431,1,['release'],['releases']
Deployability,"Good point @ivirshup , by just asking around a bit it seems that no, that's not the case and it seems there is no prefix. From the space ranger [output](https://support.10xgenomics.com/spatial-gene-expression/software/pipelines/latest/output/overview) it seems there shouldn't be such prefix added. However, to be honest not super confident that this is not gonna happen in the future, since so far there are not do many visum datasets around.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1250#issuecomment-634537829:218,pipeline,pipelines,218,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1250#issuecomment-634537829,1,['pipeline'],['pipelines']
Deployability,Good to hear also positive installation results!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/350#issuecomment-437077960:27,install,installation,27,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/350#issuecomment-437077960,1,['install'],['installation']
Deployability,"Good, yes, in the meanwhile, test coverage should be high enough. I can't think of any major hole anymore. Still, it would be nice to briefly coordinate for Scanpy; at least, still these days. But yes, in this case, please make release 1.3.8!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/450#issuecomment-460614412:228,release,release,228,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/450#issuecomment-460614412,1,['release'],['release']
Deployability,Graph_tool library would be even better and it also implements SBM and many other things that may be useful in graph analysis of single cells. Unfortunately its installation is a painful experience.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/97#issuecomment-370161196:161,install,installation,161,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/97#issuecomment-370161196,1,['install'],['installation']
Deployability,"Great info about the figdir, thank you. I think it would be good to be able to access/save both plots, yes. I want this sort of pipeline script to be able to generate the same output for inspection as if the user were running the commands within Jupyter, and both display there. I don't think it's a critical thing though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/73#issuecomment-361946553:128,pipeline,pipeline,128,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/73#issuecomment-361946553,1,['pipeline'],['pipeline']
Deployability,"Great to hear from both of you. I'd really love to have better Dask integration with AnnData and am excited to see these progress!. @ryan-williams, it'd great if you could open an issue over on anndata about this! I think that'd be a good place to discuss design considerations.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1663#issuecomment-783235345:68,integrat,integration,68,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1663#issuecomment-783235345,1,['integrat'],['integration']
Deployability,"Great! :smile:. Sure, next Wednesday is fine. Also, we can always simply make 1.4.2. I just need to check one tiny thing before we actually make the release.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/543#issuecomment-475598355:149,release,release,149,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/543#issuecomment-475598355,1,['release'],['release']
Deployability,"Great! And indeed, it hasn’t been released yet, so if you don’t want one, we don’t need a release note.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2743#issuecomment-1805786269:34,release,released,34,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2743#issuecomment-1805786269,2,['release'],"['release', 'released']"
Deployability,"Great! I'll check it out when I have a chance. If this is close to ready, could it also start getting some tests?. Just to clarify, would a notebook with the pancreas integration stuff be useful to you?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/651#issuecomment-519798857:167,integrat,integration,167,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/651#issuecomment-519798857,1,['integrat'],['integration']
Deployability,"Great! I'm going to close this then, since the discussion seems to be more about installation issues now.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1154#issuecomment-614611920:81,install,installation,81,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1154#issuecomment-614611920,1,['install'],['installation']
Deployability,"Great! Yeah, coronavirus is pretty distracting. This last week has definitely felt like a month for me. So still to do:. * This should be rebased on master; * This should be the default, and this should be noted in the documentation; * Add this to the release notes!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1066#issuecomment-601744153:252,release,release,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1066#issuecomment-601744153,1,['release'],['release']
Deployability,"Great!. Yes, I would have expected that the adjacency matrix will differ slightly and hence, `test_paga_paul15` fails. We'll need to rerun and upload https://scanpy-tutorials.readthedocs.io/en/latest/paga-paul15.html with the new version in that case and also update the tests.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/576#issuecomment-479420690:260,update,update,260,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/576#issuecomment-479420690,1,['update'],['update']
Deployability,"Great, I think we may go for an experimental module as soon as next release (though, maybe the one after). If you form any strong opinions or have any cool use cases for the function, I'd definitely be interested in hearing about it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1619#issuecomment-831156546:68,release,release,68,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1619#issuecomment-831156546,1,['release'],['release']
Deployability,"Great, but not in a patch release. We should do a feature release really soon anyway. Please add a release note, then this can be merged.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2798#issuecomment-1882964041:20,patch,patch,20,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2798#issuecomment-1882964041,4,"['patch', 'release']","['patch', 'release']"
Deployability,"Great, it is. what if I want to add multiple obs_keys (such as lovain, cell_type et al.,), and, when will the new version scanpy be released?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/178#issuecomment-399032569:132,release,released,132,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/178#issuecomment-399032569,1,['release'],['released']
Deployability,"Great. Please ping me here when you upload the file to `scanpy_usage` and feel free to close the issue then. I'll update my script to link directly to `scanpy_usage`. > Regarding the result: the high PCs can change drastically depending on the platform and the random seed. I've seen clustering results changing completely after I became aware of it. . I don't have much experience with randomized PCA, but this is very disturbing, no? Was your feeling that the PCs themselves changed strongly (as measured, I don't know, by the %% of total captured variance, or maybe angle between subspaces, etc.), or is it rather that clustering outcome is dangerously sensitive to small changes in the data? I think this is something worth investigating.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/325#issuecomment-435797047:114,update,update,114,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/325#issuecomment-435797047,1,['update'],['update']
Deployability,"Guys, I'll merge this for now so that I can conveniently play around with it in practical settings and potentially improve. We don't need to advertise for now and the next release might be a bit ahead anyway. I'm reading the latest comments as you being essentially positive. ☺️",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/651#issuecomment-557132848:172,release,release,172,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/651#issuecomment-557132848,1,['release'],['release']
Deployability,"Had this issue again recently using python 3.7, and the solution above wasn't enough to solve it. Turns out I also needed to download the tables .whl file: `pip install .\h5py-2.10.0-cp37-cp37m-win_amd64.whl .\tables-3.6.1-cp37-cp37m-win_amd64.whl numpy==1.20.0 --user --force-reinstall`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/454#issuecomment-954032488:161,install,install,161,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454#issuecomment-954032488,1,['install'],['install']
Deployability,"Had this problem, followed the `scikit-misc` package [issue](https://github.com/has2k1/scikit-misc/issues/12) on a related problem and installed the recommended patch with ; ```; pip install -i https://test.pypi.org/simple/ ""scikit-misc==0.2.0rc1""; ```. Seems to work now for me.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2073#issuecomment-1489019996:135,install,installed,135,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2073#issuecomment-1489019996,3,"['install', 'patch']","['install', 'installed', 'patch']"
Deployability,"Hah, so I wasn't aware of the ecosystem page yet. This looks very cool, and could really be built upon nicely. I think a more clear tutorial integration into the page would be useful.... and I guess some tools don't really have any brief explanations there.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1443#issuecomment-703726683:141,integrat,integration,141,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1443#issuecomment-703726683,1,['integrat'],['integration']
Deployability,"Hahaha and of course after weeks of this bug, everything gets resolved the day I press the merge button. takluyver/flit#395 should fix the issues where. 1. `pip install scvelo` downgrades a `flit install -s` installed scanpy (now the `dist-info` dir name contains the correct version); 2. The wheel built by flit now corresponds to the freshly-changed spec’s [mangling rules](https://packaging.python.org/specifications/binary-distribution-format/#escaping-and-unicode). So we can remove the workarounds. No problem, `git blame` won’t be affected much, this almost exclusively deletes lines.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1702:161,install,install,161,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1702,3,['install'],"['install', 'installed']"
Deployability,"Happy new year! And thanks for opening this PR @pavlin-policar. -----------------. First a general question. What is the scope of this PR? Will this just be single dataset TSNE calculation, with integration/ `ingest` functionality happening separately, or would you like to do it all at once?. -----------------. In terms of workflow, I think I'd like it to look similar to UMAP. * One function for calculating the graph/ manifold; * One function for computing the embedding. If possible, I would like it if the user could specify an arbitrary manifold (e.g. the umap weighted one) to pass to the embedding step, but this is icing. > It would also make sense to add a tsne option to sc.pp.neighbors. I would prefer for this to be a separate function, maybe `neighbors_tsne`? This could use the entire neighbor calculating workflow from `openTSNE`. How different are the arguments to the various `affinity` methods? At first glance they look pretty similar. I'd like to have the option of choosing which one, but does it make sense to have all the methods available through one function?. > noticed that sc.tl.umap and now sc.tl.tsne add their parameters to adata.uns. ... Determining which affinity kernel to use would then be as simple as looking into adata.uns to find which parameter value sc.pp.neighbors was called with. +1. Do you need to know what the affinity method was if you're just calculating an embeddings? Or does that only become important when you want to add new data?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1561#issuecomment-758355448:195,integrat,integration,195,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561#issuecomment-758355448,1,['integrat'],['integration']
Deployability,"Happy to discuss what can be integrated from scvelo's `pl.scatter` into scanpy or how scvelo's codebase can be used.. just to mention some of the features that may also be interesting for scanpy:; - (`x`, `y`) is `str` key of (var_names, var_names), (var, var), (obs, obs), (array, array), (obs, var_names), where I find particularly passing arrays to be very convenient.; - `basis` from obsm (what is the reason for having an additional `pl.embedding`?) or var_names (on layer1 vs layer2, e.g. spliced vs. unspliced).; - `color` is `str` key of obs, var, layers or directly pass an array (which I find very convenient); while each of these can also be a list/tuple of `str` or arrays. . Further, we 'beautified' the colorbar, ticks etc. and added some functionality such as plotting a lin.reg line or polynomial fit of any degree directly on top of the scatterplot, show histogram/density along x and y axes, added `dpi` and `figsize` attributes and **kwargs for all other matplotlib-specific attributes such as `vmin`/`vmax`. ; Apart from these it entails all functionality of scanpy's `pl.scatter`. It turned out to be very convenient to have pretty much everything within one single `pl.scatter` module, not matter whether you want to visualize an embedding, any user-specified arrays colored by clusters, or visualize a gene trend along a pseudotime. I'd start of with the general question of whether incorporating some of these functionalities into scanpy's `pl.scatter` that may be useful, or whether re-implementing it based on scvelo's `pl.scatter` codebase makes more sense.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/617#issuecomment-553948802:29,integrat,integrated,29,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/617#issuecomment-553948802,1,['integrat'],['integrated']
Deployability,"Has anyone found a solution for this? I run into segfault with the same message when trying to run `sc.pp.calculate_qc_metrics` on my M2. Latest clean installation. I have the core dump as well, but I don't know how to get useful information from there.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2359#issuecomment-1345470076:151,install,installation,151,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359#issuecomment-1345470076,1,['install'],['installation']
Deployability,Has this been updated on the latest version of scanpy ?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/547#issuecomment-1164419928:14,update,updated,14,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/547#issuecomment-1164419928,1,['update'],['updated']
Deployability,"Have the same issue. Windows, Ubuntu for WSL, miniconda:. > conda install -c bioconda/label/cf201901 scanpy; Collecting package metadata (current_repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.; Collecting package metadata (repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: |; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed. > UnsatisfiableError: The following specifications were found; to be incompatible with the existing python installation in your environment:. > Specifications:. > - scanpy -> python[version='>=3.6,<3.7.0a0']. > Your python: python=3.7",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/990#issuecomment-582183368:66,install,install,66,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/990#issuecomment-582183368,2,['install'],"['install', 'installation']"
Deployability,"Have you rebooted the python after updating anndata? Can you paste the exact error you're seeing? Are you allowed to share the object you're having trouble loading?. OP's error is bizarre, e.g. the last part seems to be pointing to an empty line. Like the package was updated but the python was not restarted. I can't recreate the exact one he's seeing, but I've managed to get other disjoint errors along those lines by updating anndata to 0.8.0 in a second terminal while the python in question is still running.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2297#issuecomment-1450229185:268,update,updated,268,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297#issuecomment-1450229185,1,['update'],['updated']
Deployability,"Haven't tried again but I have a suggestion. Since umap (or pynndescent) is a critical component of scanpy, I think it'd be great to run our tests against both ""stable"" and ""development"" branches of umap. However in order for this to happen, umap needs proper naming for the development and stable branches. Right now, there are master, 0.3dev and 0.4dev, therefore the names are version-dependent. . Does it make sense to file a bug report in umap repo? It'd be a lot easier to run test against two major branches of umap without changing the names in every major release. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/779#issuecomment-524128498:565,release,release,565,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/779#issuecomment-524128498,1,['release'],['release']
Deployability,"Having the exact same problem. Windows machine, win10, 64 bit. Trying to install from miniconda. FWIW, I have installed scanpy successfully on two other windows machines (my home computer and my work computer) in the last three weeks. Now following identical steps on my laptop and having this tissue. . ```; conda install -c bioconda scanpy; Collecting package metadata (current_repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.; Collecting package metadata (repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: /; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed. UnsatisfiableError: The following specifications were found to be incompatible with each other:. Package pytables conflicts for:; scanpy -> pytables; Package pandas conflicts for:; scanpy -> pandas[version='>=0.21']; Package umap-learn conflicts for:; scanpy -> umap-learn[version='>=0.3.0']; Package h5py conflicts for:; scanpy -> h5py!=2.10.0; Package patsy conflicts for:; scanpy -> patsy; Package numba conflicts for:; scanpy -> numba[version='>=0.41.0']; Package anndata conflicts for:; scanpy -> anndata[version='>=0.6.10|>=0.6.22rc1']; Package seaborn conflicts for:; scanpy -> seaborn; Package setuptools conflicts for:; scanpy -> setuptools; Package python conflicts for:; scanpy -> python[version='>=3.6']; Package importlib-metadata conflicts for:; scanpy -> importlib-metadata; Package importlib_metadata conflicts for:; scanpy -> importlib_metadata[version='>=0.7']; Package scikit-learn conflicts for:; scanpy -> scikit-learn[version='>=0.21.2']; Package networkx conflicts for:; scanpy -> networkx; Package python-igraph conflicts for:; scanpy -> python-igraph; Package louvain conflicts for:; scanpy -> louvain;",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/990#issuecomment-575769824:73,install,install,73,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/990#issuecomment-575769824,3,['install'],"['install', 'installed']"
Deployability,"Hej,. I stumbled upon your issue. Test for my PR #1440:. ```; python3 -m venv venv; source venv/bin/activate; pip install -e . ; pip install ""anndata<=0.7.3""; python3 -c ""import scanpy as sc""; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1439#issuecomment-703157510:114,install,install,114,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1439#issuecomment-703157510,2,['install'],['install']
Deployability,"Hello ; I am also facing the same problem.; I would like to get gene name, log fold change, pval_adj, pts.pts_rest in a single output CSV file but i couldn't able to do that; ` ; sc.tl.rank_genes_groups(adata,""leiden_0.6"", method='t-test',pts=True,corr_method='benjamini-hochberg'); pd.DataFrame(adata.uns['rank_genes_groups']['names']); result = adata.uns['rank_genes_groups']; groups = result['names'].dtype.names; df= pd.DataFrame(; {group + '_' + key[:1]: result[key][group]; for group in groups for key in ['names','logfoldchanges','pts','pts_rest','pvals','pvals_adj']}); df.to_csv(""/home/Akila/integration/harmony/subset/celltype/find_markergenes.csv"")`; ; Any idea how to get in the single file along with pts??; ; Thanks; Akila",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1455#issuecomment-1164848375:601,integrat,integration,601,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1455#issuecomment-1164848375,1,['integrat'],['integration']
Deployability,"Hello @Koncopd ,; 1. New py3.8.12 environment; ```python; conda install pytables; import tables # pass; ```; 2. New py3.8.12 environment; ```python; conda install pytables; import tables # pass; ```; 3. New py3.8.12 environment; ```python; conda install -c conda-forge scanpy; import scanpy # pass; ```; I can run the Scanpy pipeline now. However, I'm wondering whether your team did some slight changes for pca, neighboring, leiden, umap functions (not big enough to introduce a new release) inside of Scanpy v1.8.2.; Because now I rerun my data and I get the UMAP like below,; ![image](https://user-images.githubusercontent.com/75048821/149594142-fcd6b1d1-7b9a-4713-9850-8b2d86a1ff61.png). but it looks like this one month ago, run by the same version of Scanpy v1.8.2 with the same coding.; ![image](https://user-images.githubusercontent.com/75048821/149593173-fc6caf3d-09e4-4b92-89ad-8cdfc1173f3c.png)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2108#issuecomment-1013511702:64,install,install,64,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2108#issuecomment-1013511702,5,"['install', 'pipeline', 'release']","['install', 'pipeline', 'release']"
Deployability,"Hello @Koncopd ,; Thanks for the response!. Step 1: I created a fresh new environment (py3.8.12); ```python; !pip install scanpy[leiden]. Successfully installed anndata-0.7.8 cycler-0.11.0 fonttools-4.28.5 h5py-3.6.0 igraph-0.9.9 joblib-1.1.0 kiwisolver-1.3.2 leidenalg-0.8.8 llvmlite-0.38.0 matplotlib-3.5.1 natsort-8.0.2 networkx-2.6.3 numba-0.55.0 numexpr-2.8.1 numpy-1.21.5 pandas-1.3.5 patsy-0.5.2 pillow-9.0.0 pynndescent-0.5.5 python-igraph-0.9.9 scanpy-1.8.2 scikit-learn-1.0.2 scipy-1.7.3 seaborn-0.11.2 sinfo-0.3.4 statsmodels-0.13.1 stdlib-list-0.8.0 tables-3.7.0 texttable-1.6.4 threadpoolctl-3.0.0 tqdm-4.62.3 umap-learn-0.5.2 xlrd-1.2.0. import numpy as np; import pandas as pd; import scanpy as sc; import scanpy.external as sce; import scipy; sc.settings.verbosity = 3; sc.logging.print_header(); sc.set_figure_params(dpi=100, dpi_save=600). ImportError Traceback (most recent call last); ~\AppData\Local\Temp/ipykernel_8256/1710492625.py in <module>; 1 import numpy as np; 2 import pandas as pd; ----> 3 import scanpy as sc; 4 import scanpy.external as sce; 5 import scipy. ~\.conda\envs\NewPy38\lib\site-packages\scanpy\__init__.py in <module>; 12 # (start with settings as several tools are using it); 13 from ._settings import settings, Verbosity; ---> 14 from . import tools as tl; 15 from . import preprocessing as pp; 16 from . import plotting as pl. ~\.conda\envs\NewPy38\lib\site-packages\scanpy\tools\__init__.py in <module>; 15 from ._leiden import leiden; 16 from ._louvain import louvain; ---> 17 from ._sim import sim; 18 from ._score_genes import score_genes, score_genes_cell_cycle; 19 from ._dendrogram import dendrogram. ~\.conda\envs\NewPy38\lib\site-packages\scanpy\tools\_sim.py in <module>; 21 from anndata import AnnData; 22 ; ---> 23 from .. import _utils, readwrite, logging as logg; 24 from .._settings import settings; 25 from .._compat import Literal. ~\.conda\envs\NewPy38\lib\site-packages\scanpy\readwrite.py in <module>; 8 import pandas as pd; 9 from ma",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2108#issuecomment-1012790841:114,install,install,114,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2108#issuecomment-1012790841,2,['install'],"['install', 'installed']"
Deployability,"Hello @davidhbrann ,; Sorry for the late response.; I tried again without typing the `--user` in the Anaconda Powershell. Please see below. Step1: install without force. Didn't work. Proceed to Step2.; ```python; (base) C:\WINDOWS\system32>conda activate Python38; (Python38) C:\WINDOWS\system32>pip install scikit-misc; Requirement already satisfied: scikit-misc in c:\users\park_lab\appdata\roaming\python\python38\site-packages (0.1.4); Requirement already satisfied: numpy in c:\users\park_lab\anaconda3\envs\python38\lib\site-packages (from scikit-misc) (1.20.3); ```; Step2: force install.; ```python; (Python38) C:\WINDOWS\system32>pip install scikit-misc --force; Collecting scikit-misc; Using cached scikit_misc-0.1.4-cp38-cp38-win_amd64.whl (142 kB); Collecting numpy; Downloading numpy-1.21.5-cp38-cp38-win_amd64.whl (14.0 MB); |████████████████████████████████| 14.0 MB 3.3 MB/s; Installing collected packages: numpy, scikit-misc; Attempting uninstall: numpy; Found existing installation: numpy 1.20.3; Uninstalling numpy-1.20.3:; Successfully uninstalled numpy-1.20.3; ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'C:\\Users\\Park_Lab\\anaconda3\\envs\\Python38\\Lib\\site-packages\\~umpy\\.libs\\libopenblas.GK7GX5KEQ4F6UYO3P26ULGBQYHGQO7J4.gfortran-win_amd64.dll'; Consider using the `--user` option or check the permissions.; ```; Step3: same errors.; ```python; sc.pp.highly_variable_genes(adata, n_top_genes=5000, flavor='seurat_v3'); sc.pl.highly_variable_genes(adata); ImportError Traceback (most recent call last); ~\anaconda3\envs\Python38\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, check_values, span, subset, inplace); 52 try:; ---> 53 from skmisc.loess import loess; 54 except ImportError:. ~\AppData\Roaming\Python\Python38\site-packages\skmisc\loess\__init__.py in <module>; 50 """"""; ---> 51 from ._loess import (loess, loess_model, loess_i",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2073#issuecomment-1000601342:147,install,install,147,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2073#issuecomment-1000601342,6,"['Install', 'install']","['Installing', 'install', 'installation']"
Deployability,"Hello @davidhbrann,; Thanks for the response.; I did pip install --user scikit-misc --force in the anaconda powershell, but this bug kept the same. Not solved.; Thanks!; Best,; YJ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2073#issuecomment-996241473:57,install,install,57,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2073#issuecomment-996241473,1,['install'],['install']
Deployability,Hello @giovp. I used pip for the installation,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2306#issuecomment-1210655230:33,install,installation,33,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2306#issuecomment-1210655230,1,['install'],['installation']
Deployability,"Hello @ivirshup , sorry for asking. Is there any update on this issue?; Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2114#issuecomment-1032179479:49,update,update,49,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2114#issuecomment-1032179479,1,['update'],['update']
Deployability,"Hello @ivirshup thanks for this!. Quick question (still very new to python). Upon following your suggestion I get this error:; AttributeError: module 'scanpy.api.tl' has no attribute '_utils'. I then proceeded to install utils (pip install utils), and then; import utils. But still doesn't work. I assume it's because I'm not loading it correctly into the environment for scanpy to use but I don't know how?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/769#issuecomment-519061562:213,install,install,213,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/769#issuecomment-519061562,2,['install'],['install']
Deployability,"Hello All, I am trying to learn and create single cell RNA seq pipeline for my project. When I was doing quality control, I met this problem. Can anyone help me? Thank you a lot.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1559:63,pipeline,pipeline,63,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1559,1,['pipeline'],['pipeline']
Deployability,"Hello Scanpy,; I reimaged my Windows from 20H2 to 21H1 today and reinstalled the environment for scanpy. However, in the new environment, when I run the official workflow of pbmc3k by just using the official pbmc3k notebook. The UMAP becomes different from the pbmc3k tutorial like below. But all other codings generate the same results and plots as the pbmc3k tutorial.; ![image](https://user-images.githubusercontent.com/75048821/140598534-5425f05c-4bb1-4bb7-97d9-d37a0ce1f9dc.png); ![image](https://user-images.githubusercontent.com/75048821/140598551-5cd98b37-48b9-44ba-bacb-b4b2ac155576.png). Then I run the same coding on my older computer, which installed scanpy one month ago, the UMAP is the same as the standard workflow.; ![image](https://user-images.githubusercontent.com/75048821/140632101-6536d00e-f180-407d-9cd1-a79991280e8a.png). **Is it because of the packages' problem or Windows 21H1? I list the packages information here. Could you please help me to solve this issue?**. <html xmlns:v=""urn:schemas-microsoft-com:vml""; xmlns:o=""urn:schemas-microsoft-com:office:office""; xmlns:x=""urn:schemas-microsoft-com:office:excel""; xmlns=""http://www.w3.org/TR/REC-html40"">. <head>. <meta name=ProgId content=Excel.Sheet>; <meta name=Generator content=""Microsoft Excel 15"">; <link id=Main-File rel=Main-File; href=""file:///C:/Users/Yuanjian/AppData/Local/Temp/msohtmlclip1/01/clip.htm"">; <link rel=File-List; href=""file:///C:/Users/Yuanjian/AppData/Local/Temp/msohtmlclip1/01/clip_filelist.xml"">; <style>; <!--table; 	{mso-displayed-decimal-separator:""\."";; 	mso-displayed-thousand-separator:""\,"";}; @page; 	{margin:.75in .7in .75in .7in;; 	mso-header-margin:.3in;; 	mso-footer-margin:.3in;}; .font5; 	{color:windowtext;; 	font-size:9.0pt;; 	font-weight:400;; 	font-style:normal;; 	text-decoration:none;; 	font-family:等线;; 	mso-generic-font-family:auto;; 	mso-font-charset:134;}; tr; 	{mso-height-source:auto;; 	mso-ruby-visibility:none;}; col; 	{mso-width-source:auto;; 	mso-ruby-visibility:non",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2045:653,install,installed,653,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2045,1,['install'],['installed']
Deployability,"Hello world!; I've read in many papers that when performing a re-clustering of some populations, like T cells or B cells, prior to the step of integration and so on, they re-calculate the HVGs but excluding the TCR- or BCR-related genes, because they are donor-specific, especially when talking about BCR. Can you help me how to remove the TCR- or BCR-related genes before computing the HVGs selection, but without removing them from the .var of the anndata, since I want to evaluate their expression during the step of cell annotation?. The code that I use to calculate the HVGs is the following:; sc.pp.highly_variable_genes(adata,; n_top_genes = 4000, flavor = ""seurat_v3"",; layer = ""raw"", batch_key = 'sample_id',; subset = False). Thanks a lot!; Paolo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2895:143,integrat,integration,143,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2895,1,['integrat'],['integration']
Deployability,Hello! I thought it might be useful to add [Scanorama ](https://github.com/brianhie/scanorama) to the set of integration methods in scanpy.external.pp. I've followed the example laid out in https://github.com/theislab/scanpy/pull/1306 pretty closely. I've also done some small scale integration testing on a local machine just to verify that batch effect correction indeed works when called with this API. Let me know what I can do to help get this merged!,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1332:109,integrat,integration,109,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1332,2,['integrat'],['integration']
Deployability,"Hello! I'm trying to recolor some categorical variables in the scanpy.api.pl.tsne function but am having some trouble. Specifically, with continuous data, I'm fine using the `color_map` key word to change between scales like ""viridis"" and ""Purples"" but when trying to pass the `palette` key word for categorical data (sample labels, louvain lables), it doesn't seem to update the colors in the plot. Perhaps I'm specifying the color palette incorrectly? Here are a few versions I've tried:. ```; sc.pl.tsne(adata, ; color=['louvain'], ; #palette=['C0', 'C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7', 'C8', 'C9'], ; #palette=['tab:blue', 'tab:orange', 'tab:green', 'tab:red', 'tab:purple', 'tab:brown', 'tab:pink', 'tab:gray', 'tab:olive', 'tab:cyan'],; #palette=""Set3"",; palette=sns.color_palette(""hls"", 15),; legend_fontsize=""20""); ```; ![image](https://user-images.githubusercontent.com/33738960/40148279-0b344502-5922-11e8-998c-4d5ece963253.png). But all of these attempts result in the same default cluster color scheme. Any suggestions?. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/156:138,continuous,continuous,138,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/156,2,"['continuous', 'update']","['continuous', 'update']"
Deployability,"Hello, . I have managed to get my Seurat object converted into Loom and then read into Scanpy. Now my main objective is to use the clusters identified using Seurat in order to create a PAGA trajectory map. I was able to do a similar thing for Seurat -> Monocle by integrating the Seurat clusters and allow Monocle to perform a trajectory analysis on them. . I have the following Scanpy object:; ![scanpy_adata](https://user-images.githubusercontent.com/11708268/58907732-7a075380-86d4-11e9-9f2a-4c539ea58c80.png). All the cluster information along with cell ids are present in the obs part of the Scanpy object. Is there anyway to use that information in order to perform a PAGA trajectory analysis?. Thank you,; Behram",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/680:264,integrat,integrating,264,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/680,1,['integrat'],['integrating']
Deployability,"Hello, could you write what version of sklearn you have installed?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1759#issuecomment-806685821:56,install,installed,56,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1759#issuecomment-806685821,1,['install'],['installed']
Deployability,"Hello, scanpy developers, ; Firstly, thank you so much for your pipeline scanpy. It is very useful to me. Secondly, I want to ask a question. Are you going to support Stimulated vs Control analysis? Thank you.; Sincerely yours,; Shangyu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/821:64,pipeline,pipeline,64,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/821,1,['pipeline'],['pipeline']
Deployability,"Hello,. I am a beginner in the bioinformatics field. I have been used scanpy for one year, and I really like it. But yesterday after I downloaded and installed the new developmental version from scanpy github, when I ran the first command ""import scanpy as sc"", it displayed errors :AttributeError: module 'tables' has no attribute 'which_lib_version'. I don't know how to deal with this error. Does the ""module 'tables' "" in the error message mean pytables? After I saw the message, I reinstalled both pytables and scanpy through conda channel. But the error is not fixed. I thus wish to get some suggestions. Thank you so much!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/853:150,install,installed,150,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/853,1,['install'],['installed']
Deployability,"Hello,. I am having the same issue as issue #1246 but my version of scipy being used with scanpy is not updating. I don't know if this is related to my using an ubuntu server or what's causing this but I was wondering if there is a workaround to make scanpy use a more updated version? I have scipy 1.4.1 installed when I check the version but for some reason scanpy is using 1.01 and I don't know how to change this. I'm a bit new to python so I'm sorry if this is a novice question. I appreciate any help you can offer. I am using an ubuntu server running python 3.6 with the following versions:; sc.logging.print_versions() ; scanpy==1.5.1 anndata==0.7.3 umap==0.4-dev numpy==1.15.0 scipy==1.0.1 pandas==0.23.3 scikit-learn==0.23.1 statsmodels==0.11.1. This is the error message:. ```pytb; computing tSNE; WARNING: You’re trying to run this on 16872 dimensions of `.X`, if you really want this, set `use_rep='X'`.; Falling back to preprocessing with `sc.pp.pca` and default params.; computing PCA; with n_comps=50; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-65-c244be664e51> in <module>(); ----> 1 sc.tl.tsne(adata, n_pcs = 50); 2 # UMAP, first with neighbor calculation; 3 sc.pp.neighbors(adata, n_pcs = 50, n_neighbors = 20); 4 sc.tl.umap(adata). ~/.local/lib/python3.6/site-packages/scanpy/tools/_tsne.py in tsne(adata, n_pcs, use_rep, perplexity, early_exaggeration, learning_rate, random_state, use_fast_tsne, n_jobs, copy); 78 start = logg.info('computing tSNE'); 79 adata = adata.copy() if copy else adata; ---> 80 X = _choose_representation(adata, use_rep=use_rep, n_pcs=n_pcs); 81 # params for sklearn; 82 params_sklearn = dict(. ~/.local/lib/python3.6/site-packages/scanpy/tools/_utils.py in _choose_representation(adata, use_rep, n_pcs, silent); 41 'Falling back to preprocessing with `sc.pp.pca` and default params.'; 42 ); ---> 43 X = pca(adata.X); 44 adata.obsm['X_pca'] = X[:, :n_pcs]; 45 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1252:269,update,updated,269,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252,2,"['install', 'update']","['installed', 'updated']"
Deployability,"Hello,. I am trying to use the SAM algorithm in my single-cell analysis. I run the SAM function like so:. ```py; sam_obj = sce.tl.sam(adata,inplace=True); ```. The function runs fine and appears to finish training however it crashes when computing the UMAP with the following error:. ```pytb; TypeError: a bytes-like object is required, not 'list'; ```. I'm not sure where this problem is coming from and I have spent the past day installing different versions of python and other dependencies to see if that solves the issue. Maybe naive but I know conda can sometimes be behind in their updates. I installed scanpy following the anaconda instructions here: https://scanpy.readthedocs.io/en/stable/installation.html; And I installed sam-algorithm using pip. Below is the entire output from the function call above. Below this I have included the output of ""conda list"" in case this information is helpful. . Any help would be greatly appreciated. Thank you, Hasan. ```pytb; Self-assembling manifold; Running SAM; RUNNING SAM; Iteration: 0, Convergence: 0.6008695832027542; /wynton/home/state/alkhairohr/miniconda3/envs/python_env/lib/python3.6/site-packages/samalg/__init__.py:1165: FutureWarning: This location for 'connectivities' is deprecated. It has been moved to .obsp[connectivities], and will not be accesible here in a future version of anndata.; self.adata.uns[""neighbors""][""connectivities""] = EDM; Iteration: 1, Convergence: 0.3743130193917588; /wynton/home/state/alkhairohr/miniconda3/envs/python_env/lib/python3.6/site-packages/samalg/__init__.py:1165: FutureWarning: This location for 'connectivities' is deprecated. It has been moved to .obsp[connectivities], and will not be accesible here in a future version of anndata.; self.adata.uns[""neighbors""][""connectivities""] = EDM; Iteration: 2, Convergence: 0.029142717058066172; /wynton/home/state/alkhairohr/miniconda3/envs/python_env/lib/python3.6/site-packages/samalg/__init__.py:1165: FutureWarning: This location for 'connectivities'",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1293:431,install,installing,431,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1293,5,"['install', 'update']","['installation', 'installed', 'installing', 'updates']"
Deployability,"Hello,. I'm having troubles with importing scanpy in my jupyter notebook. I am working on a server which has python 3.5.2 installed, and unfortunately I cannot update it. I am getting this issue:. ```pytb; import scanpy as sc; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-111-0074c9bc0b31> in <module>(); ----> 1 import scanpy as sc. ~/.local/lib/python3.5/site-packages/scanpy/__init__.py in <module>(); 29 ; 30 # the actual API; ---> 31 from . import tools as tl; 32 from . import preprocessing as pp; 33 from . import plotting as pl. ~/.local/lib/python3.5/site-packages/scanpy/tools/__init__.py in <module>(); 8 from ._rank_genes_groups import rank_genes_groups; 9 from ._dpt import dpt; ---> 10 from ._leiden import leiden; 11 from ._louvain import louvain; 12 from ._sim import sim. ~/.local/lib/python3.5/site-packages/scanpy/tools/_leiden.py in <module>(); 29 n_iterations: int = -1,; 30 partition_type: Optional[Type[MutableVertexPartition]] = None,; ---> 31 copy: bool = False,; 32 **partition_kwargs; 33 ) -> Optional[AnnData]:. /usr/lib/python3.5/typing.py in __getitem__(self, arg); 647 def __getitem__(self, arg):; 648 arg = _type_check(arg, ""Optional[t] requires a single type.""); --> 649 return Union[arg, type(None)]; 650 ; 651 . /usr/lib/python3.5/typing.py in __getitem__(self, parameters); 550 parameters = (parameters,); 551 return self.__class__(self.__name__, self.__bases__,; --> 552 dict(self.__dict__), parameters, _root=True); 553 ; 554 def __eq__(self, other):. /usr/lib/python3.5/typing.py in __new__(cls, name, bases, namespace, parameters, _root); 510 continue; 511 if any(isinstance(t2, type) and issubclass(t1, t2); --> 512 for t2 in all_params - {t1} if not isinstance(t2, TypeVar)):; 513 all_params.remove(t1); 514 # It's not a union if there's only one type left. /usr/lib/python3.5/typing.py in <genexpr>(.0); 510 continue; 511 if any(isinstance(t2, type) and issubclass(t",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/561:122,install,installed,122,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/561,2,"['install', 'update']","['installed', 'update']"
Deployability,"Hello,. I'm trying out the Graph abstraction and I get this error:; ```; SetKeyError Traceback (most recent call last); <ipython-input-12-928a85d4478e> in <module>(); ----> 1 sc.tl.tsne(adata); 2 sc.tl.draw_graph(adata, random_state=5) # random_state just makes a cosmetic change; 3 sc.write('krumsiek11_blobs', adata). ~/Downloads/scanpy/scanpy/tools/tsne.py in tsne(adata, n_pcs, perplexity, early_exaggeration, learning_rate, random_state, use_fast_tsne, recompute_pca, n_jobs, copy); 108 X_tsne = tsne.fit_transform(X); 109 # update AnnData instance; --> 110 adata.smp['X_tsne'] = X_tsne # annotate samples with tSNE coordinates; 111 logg.info(' finished', t=True, end=' '); 112 logg.info('and added\n'. ~/Downloads/scanpy/scanpy/data_structs/ann_data.py in __setitem__(self, keys, values); 382 # TODO: need to reallocate memory; 383 # or allow storing objects, or use pd.dataframes; --> 384 raise SetKeyError(k, v.dtype, self.dtype[k]); 385 super(BoundStructArray, self).__setitem__(k, v); 386 . SetKeyError: Currently you cannot implicitly reallocate memory:; Setting the array for key X_tsne001of002 with dtype float64 requires too much memory, you should init AnnData with a large enough data type from the beginning.; Probably you try to assign a string of length 8 although the array can only store strings of length 4.; ```. I'm using the latest git version of scanpy.; Any ideas?; Best wishes",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/40:530,update,update,530,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/40,1,['update'],['update']
Deployability,"Hello,. I've tried setting up your package via pip, as instructed. This crashed out very quickly:. 	mib111492i:~ kp9$ pip install scanpy; 	Collecting scanpy; 	 Downloading scanpy-0.2.9.1.tar.gz (208kB); 		100% |################################| 215kB 2.8MB/s ; 		Complete output from command python setup.py egg_info:; 		Traceback (most recent call last):; 		 File ""<string>"", line 1, in <module>; 		 File ""/private/tmp/pip-build-cx2i4lbu/scanpy/setup.py"", line 39, in <module>; 			readme = readme_f.read(); 		 File ""/Users/kp9/anaconda3/lib/python3.6/encodings/ascii.py"", line 26, in decode; 			return codecs.ascii_decode(input, self.errors)[0]; 		UnicodeDecodeError: 'ascii' codec can't decode byte 0xe2 in position 296: ordinal not in range(128); 	; 		----------------------------------------; 	Command ""python setup.py egg_info"" failed with error code 1 in /private/tmp/pip-build-cx2i4lbu/scanpy/. The offender seems to be the stylised README file, so I downloaded the source code, got rid of it, and proceeded with the installation. I'm unsure how representative the following encountered issues are of an ideal pip installation, but I figured I'd bring them to your attention anyway just in case they're relevant:. - h5py crashed out on account of not having hdf5 available. This was remedied via `brew install hdf5`, and it seems like the most likely of these issues to affect other users.; - The installer ignored my 2.1.0 setup of matplotlib, tried to install 2.0.0 in some weird way and crashed out. Installing 2.0.0 via pip (absolutely painlessly, mind you - what was that weird installer that crashed the thing out?) allowed the setup to proceed past this point. This might be an isolated incident, but it seemed weird enough to alert you of just in case.; - As is, louvain crashes immediately and uninformatively when attempts are made to pip it in. Installing from the GitHub source code still works fine though. I'll notify the louvain team of this situation, but this may be of relevan",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/49:122,install,install,122,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/49,2,['install'],"['install', 'installation']"
Deployability,"Hello,. Thank you for developing and maintaining such a useful tool!; I'm trying to integrate two data sets, they're replicates of the same condition. . ```; var_names = adata_002.var_names.intersection(adata_003.var_names); adata_002 = adata_002[:, var_names]; adata_003 = adata_003[:, var_names]. sc.pp.pca(adata_002); sc.pp.neighbors(adata_002); sc.tl.umap(adata_002). sc.tl.ingest(adata_003, adata_002, obs='louvain'); ```. And I got the following error:. ```; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-42-b3f5427509ba> in <module>; ----> 1 sc.tl.ingest(adata_003, adata_002, obs='louvain'). AttributeError: module 'scanpy.tools' has no attribute 'ingest'; ```. scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1. I've already tried installing the package both with conda and pip and I continue having the same issue. . I would really appreciate your comments and suggestions. . Sara",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1092:84,integrat,integrate,84,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1092,2,"['install', 'integrat']","['installing', 'integrate']"
Deployability,"Here are some updates:; - `_fuzzy_simplicial_set` from umap has been freshly exposed in the nightly version of cuml 22.06 (stable should be there in the coming weeks), so I did a quick implementation and now have a fully accelerated sc.pp.neighbors!; - I also used this opportunity to introduce `read_mtx_gpu` function, which includes a dask_cudf backend for out of vram memory mtx reading. I performed a speed comparison on a 100.000 cells dataset, running full simple pipeline from loading the mtx until UMAP/leiden:. ![image](https://user-images.githubusercontent.com/27488782/170506738-39eb95ac-9340-4790-ad0d-36ac07575b5f.png). The GPU accelerated code shows a 13X speedup compared to CPU based functions (tested on 12 CPU cores system)!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1533#issuecomment-1138619110:14,update,updates,14,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533#issuecomment-1138619110,2,"['pipeline', 'update']","['pipeline', 'updates']"
Deployability,"Here is a patch that fixes the above problem... import matplotlib.colors. #if user defined, then use the vmax, vmin keywords, else use data to generate them...; if ('vmax' in kwds) and ('vmin' in kwds):; _vmax = kwds['vmax']; _vmin = kwds['vmin']; else: ; _vmax = max(mean_flat); _vmin = min(mean_flat) . #normalize = matplotlib.colors.Normalize(vmin=min(mean_flat), vmax=max(mean_flat)) ; normalize = matplotlib.colors.Normalize(vmin=_vmin, vmax=_vmax). I'll submit a pull request.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/388#issuecomment-444339817:10,patch,patch,10,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/388#issuecomment-444339817,1,['patch'],['patch']
Deployability,"Here's a paper that compares various integration methods, with some nice figures showing which ones output corrected counts vs. corrected projections:. https://www.nature.com/articles/s41592-021-01336-8. You could use one of the methods that outputs corrected counts if you need corrected counts for some reason.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2314#issuecomment-1240118673:37,integrat,integration,37,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2314#issuecomment-1240118673,1,['integrat'],['integration']
Deployability,"Here's the commit that caused the issue: https://github.com/theislab/scanpy/commit/4cb8a61df2628f00ce7d1fff5a3b25dcbe2222ff. So the difference was switching from ColorBarBase to ColorBar, but also it looks like `ColorBarBase` only allows a single positional argument in the most recent `Matplotlib` release. Could do a conditional around matplotlib versions? Or could restrict which versions can be used?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2118#issuecomment-1020337090:299,release,release,299,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2118#issuecomment-1020337090,1,['release'],['release']
Deployability,"Hey @LouisFaure,. During the Hackathlon last week we talked again about this PR. For the time being we will keep GPU computing functionality out of scanpy and in rapids-singlecell. RSC is now tested with a CI solution. If you want to contribute to rapids-singlecell I would be very happy. Missing functions like Umap and Neighbors are currently getting updated and also ported to RSC.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1533#issuecomment-1671325998:353,update,updated,353,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533#issuecomment-1671325998,1,['update'],['updated']
Deployability,"Hey @atarashansky, what's your status with this? We're going for a larger release soon, and I'd really like to have this PR in it!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1066#issuecomment-600122843:74,release,release,74,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1066#issuecomment-600122843,1,['release'],['release']
Deployability,"Hey @esrice, thanks for the PR! Those tests are failing due to a recent umap release. This should be fixed on master now, so just merge master into this branch and they should be fixed.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2027#issuecomment-959614946:77,release,release,77,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2027#issuecomment-959614946,1,['release'],['release']
Deployability,"Hey @giovp !. Thanks for your review and sorry for the delay, but I think I addressed all requests now:; - code moved to experimental; - fixed broken column ordering when batch argument was used with HVG selection; - tests adapted to the new code location. I was not sure how the `highly_variable_genes()` should look like in its experimental version. For now, I removed everything that is not related Pearson residuals, including input arguments and docstring. I also left a note in non-experimental `highly_variable_genes()`'s docstring that mentions the experimental version with the additional Pearson flavor. Feel free to remove again if you don't like it. Regarding the tutorial: Sure, that would be nice! I can prepare a short demo notebook. Do you think we could start with a rather concise notebook now to package it with the initial release in `experimental` (basically demonstrating how to use it on some example data, and some theory/background info how it works / why it makes sense), and then prepare a longer later on? Then I'd just open a pull request (?) in your tutorial-github for that?. Let me know if there is more to do here :). Cheers, Jan",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1715#issuecomment-879988467:843,release,release,843,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715#issuecomment-879988467,1,['release'],['release']
Deployability,"Hey @gokceneraslan,. I'm surprised at how you describe the contents of `adata.var['highly_variable']` when `batch_key` is set. I wrote a function that does pretty much exactly the same thing building upon use of `batch_key` for our data integration benchmarking, as I thought this wasn't available in scanpy. I recall looking through the code and thinking this was missing. Maybe we can compare functions for that to see if we're doing exactly the same thing or not?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1032#issuecomment-616820714:237,integrat,integration,237,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1032#issuecomment-616820714,1,['integrat'],['integration']
Deployability,"Hey @ivirshup @giovp @LuckyMD & @dkobak ,. Is there any updates on this PR or the 1.9 timeline? I'll be off for a week now but once I'm back I'd be happy to work on any remaining tasks that are needed to get this merged! See my above posts for what I think is still left to do, mainly waiting on input from @ivirshup I think. I already posted a tutorial draft here: https://github.com/theislab/scanpy-tutorials/pull/43 and can also work on that if there is more feedback to address. Looking forward to finishing this up!; Cheers,; Jan",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1715#issuecomment-949761007:56,update,updates,56,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715#issuecomment-949761007,1,['update'],['updates']
Deployability,"Hey @sebpott. That feature was implemented after the 1.3.7 release, so it should work if you use the development version or wait until the next release.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/455#issuecomment-459584385:59,release,release,59,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/455#issuecomment-459584385,2,['release'],['release']
Deployability,"Hey @ywen1407!. The ideal case is that you don't pre-filter the gene sets before concatenating. Then, if you have aligned both sets of samples to the same genome, everything should be fine and you can filter out genes afterwards. Otherwise an outer join would only assume all values you filtered out were 0, which is probably not the way forward. That's why the only decent option you really have is an inner join. I assume you should have the unfiltered objects somewhere though. Regarding memory use: ComBat is something we (actually, this was thanks to @Marius1311) just re-implemented from python and R code that was flying around. We do not generally optimize methods that were published elsewhere. How much RAM are you using that it's crashing? I think Marius even made ComBat usable for sparse matrices, so it's already using less memory than it was before. 38K cells doesn't sound like something that would require more than 16GB RAM. I can run datsasets with 50k locally. You can of course always try other batch correction/data integration methods that are less memory intensive such as BBKNN or scVI. We tested scalability of data integration tools (also BBKNN and ComBat memory use) here: https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2. However, ComBat is one of the least memory intensive methods out there... so maybe there is little room for optimization here...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1431#issuecomment-698818414:1038,integrat,integration,1038,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1431#issuecomment-698818414,2,['integrat'],['integration']
Deployability,"Hey Dmitry, happy New Year's to you too!. > Can one use openTSNE code for computing perplexity-based weights or would one need to copy the binary search in here? [...] I noticed that you implemented `UniformAffinities ` in here, but isn't it part of openTSNE already?. No, I think we should be able to call the existing machinery. But we'd need to do something like I do with the Uniform affinities here. The reason I had to write separate classes is that the ones in openTSNE calculate the KNNG internally, and don't really offer a way to pass an existing KNNG. In openTSNE that makes sense, since otherwise, the API would be pretty complicated. But here, we have to deal with that. As you can see, it's a pretty trivial wrapper anyway. > How would tsne function know if it should use the uniform kernel or the weights constructed by the neighbors function?. I noticed that `sc.tl.umap` and now `sc.tl.tsne` add their parameters to `adata.uns`. I would imagine `sc.pp.neighbors` probably do the same, and if not, that seems like an easy addition, which is in line with the scanpy architecture. Determining which affinity kernel to use would then be as simple as looking into `adata.uns` to find which parameter value `sc.pp.neighbors` was called with. > I would definitely suggest to add `exaggeration=1` argument to `tsne()`. I added `exaggeration=None`, as is the default in openTSNE. But setting it to 1 instead of None is better, and I should change that in the next release.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1561#issuecomment-753617428:1472,release,release,1472,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561#issuecomment-753617428,1,['release'],['release']
Deployability,"Hey Phil! I'm still a bit hesitant to adopt this option. As discussed before, I'm mainly planning on integrating c++ extensions. Then doing everything via Cython seems overhead. Even the latest Cython distributions recommends **not** doing it. See [here](http://cython.readthedocs.io/en/latest/src/reference/compilation.html) and search for *distributing cython modules*. They provide a solution very similar to the one fom stackoverflow that we have adopted right now.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/20#issuecomment-304808803:101,integrat,integrating,101,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/20#issuecomment-304808803,1,['integrat'],['integrating']
Deployability,"Hey all,. I added scanpy as a bioconda package (https://github.com/bioconda/bioconda-recipes/pull/10863) along with installation instructions and a bioconda badge. The badge link on the README.rst doesn't work yet, it will 404 until the bioconda webpage gets auto-updated, but installing via bioconda does.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/261:116,install,installation,116,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/261,3,"['install', 'update']","['installation', 'installing', 'updated']"
Deployability,"Hey everyone, thanks for the discussion so far! I don't have much to add to what @dkobak said earlier, so let me summarize a bit from my perspective:. I am motivated to contribute the method here because people were interested to use it with scanpy after seeing the preprint, and scanpy devs reached out to us to implement it here. For that it does not matter if it ends up in `external` or `core`, but as @giovp mentioned, the code is easy to integrate into the existing normalize/hvg-selection workflow and the method itself is well connected to established workflows. @adamgayoso raised the question if new preprint methods should be allowed in `core` at all, had several suggestions how this PR could be handled (halt until peer review publication/put in `external` for now/extend method to support also e.g. deviance residuals and others), and some open questions about the exact workflow integration. I would like to clarify with everyone how to proceed now. @ivirshup @LuckyMD, could you help us a bit to decide how to move forward?. In terms of development, I answered all of your code review comments @giovp, so maybe you can briefly check & resolve those you are happy with..?! I am also ready to finally write tests once we are decided on where this PR is going.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1715#issuecomment-801883490:444,integrat,integrate,444,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715#issuecomment-801883490,2,['integrat'],"['integrate', 'integration']"
Deployability,"Hey everyone, thanks for your feedback! In the latest commit, I have tried to include all of your comments, including the more stylistic comments, the references, the numba integration, the unit tests and so on. Have a look and see what you think. I won't be able to work on this any more this year because I am going on holidays. Merry Christmas everyone!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/398#issuecomment-448304646:173,integrat,integration,173,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/398#issuecomment-448304646,1,['integrat'],['integration']
Deployability,"Hey guys, thanks for getting back to me. @flying-sheep `pip install -e` isn't working on the flit branch because it doesn't have a `setup.py` -- is there another way to install?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1496#issuecomment-730805437:60,install,install,60,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496#issuecomment-730805437,2,['install'],['install']
Deployability,"Hey sorry for the delay: . ```; -----; anndata 0.7.5; scanpy 1.9.0; -----; PIL 8.1.2; anyio NA; attr 20.3.0; babel 2.9.0; backcall 0.2.0; brotli NA; cairo 1.20.0; certifi 2020.12.05; cffi 1.14.5; chardet 4.0.0; cloudpickle 1.6.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2021.03.1; dateutil 2.8.1; decorator 4.4.2; fsspec 0.8.7; google NA; h5py 3.1.0; idna 2.10; igraph 0.8.3; ipykernel 5.5.0; ipython_genutils 0.2.0; jedi 0.18.0; jinja2 2.11.3; joblib 1.0.1; json5 NA; jsonschema 3.2.0; jupyter_server 1.4.1; jupyterlab_server 2.3.0; kiwisolver 1.3.1; leidenalg 0.8.3; llvmlite 0.34.0; louvain 0.7.0; markupsafe 1.1.1; matplotlib 3.3.4; mpl_toolkits NA; natsort 7.1.1; nbclassic NA; nbformat 5.1.2; numba 0.51.2; numpy 1.20.1; packaging 20.9; pandas 1.2.3; parso 0.8.1; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prometheus_client NA; prompt_toolkit 3.0.16; psutil 5.8.0; ptyprocess 0.7.0; pvectorc NA; pyarrow 0.16.0; pygments 2.8.0; pyparsing 2.4.7; pyrsistent NA; pytoml NA; pytz 2021.1; requests 2.25.1; ruamel NA; scipy 1.6.1; send2trash NA; session_info 1.0.0; setuptools_scm NA; six 1.15.0; sklearn 0.24.1; sniffio 1.2.0; socks 1.7.1; sphinxcontrib NA; storemagic NA; tblib 1.7.0; texttable 1.6.3; tlz 0.11.0; toolz 0.11.1; tornado 6.1; traitlets 5.0.5; typing_extensions NA; urllib3 1.26.3; wcwidth 0.2.5; yaml 5.3.1; zmq 22.0.3; -----; IPython 7.21.0; jupyter_client 6.1.11; jupyter_core 4.7.1; jupyterlab 3.0.9; notebook 6.2.0; -----; Python 3.8.8 | packaged by conda-forge | (default, Feb 20 2021, 16:22:27) [GCC 9.3.0]; Linux-4.15.0-112-generic-x86_64-with-glibc2.10; -----; Session information updated at 2022-04-08 14:58; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2203#issuecomment-1092960373:1647,update,updated,1647,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2203#issuecomment-1092960373,1,['update'],['updated']
Deployability,Hey! I looked at multiplex louvain a bit a few years ago (and put it in a grant that didn't get funded in the end ^^)... i guess one of the difficult things to actually using this is tuning the inter layer weight. I reckon this should actually be regarded as a new approach to multi-modal data integration. And it would require quite a bit of parameter tuning to understand how these edge weights need to be tuned. Hence I'm not sure if we just want to add it like this...,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1818#issuecomment-828389504:294,integrat,integration,294,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1818#issuecomment-828389504,1,['integrat'],['integration']
Deployability,"Hey! I was just getting back to this, and I'm not sure I agree with all the choices made in the updates. For example, I would probably rather have separate functions for different spatial neighbor strategies. Also this won't work if `coord_type` isn't `""visium""`. Should I be making changes to this PR, or are you relying on it?. # hexagonal connectivity. I would propose a separate function just for visium data, maybe called `visium_connectivity`. It works with the assumption of a hexagonal grid. This removes the `neigh`, `radius`, and `coord_type` arguments. I think if we have an argument for `n_rings` there should be some way to weight the connectivity graph by how many steps away each extra point is. Also I'm pretty sure the current implementation of `n_rings` is incorrect when `n_rings>2`. Without weighting, I think it should be more like this:. ```python; def walk_nsteps(adj, n):; """"""Expand adjacency matrix adj by walking out n steps from each node.""""""; adj = adj.astype(bool); cur_step = adj; result = adj.copy(); for i in range(n):; cur_step = adj @ cur_step; cur_step.setdiag(False); result = result + cur_step; return result; ```. <details>; <summary> An example showing this works </summary>. ```python; import networkx as nx; from scipy import sparse; from matplotlib import pyplot as plt; import numpy as np. def walk_nsteps(adj, n):; """"""Expand adjacency matrix adj by walking out n steps from each node.""""""; adj = adj.astype(bool); cur_step = adj; result = adj.copy(); for i in range(n):; cur_step = adj @ cur_step; cur_step.setdiag(False); result = result + cur_step; return result. # Test data (path graph). G = nx.Graph(); G.add_nodes_from([0,1,2,3]); G.add_edges_from([(0, 1), (1, 2), (2, 3), (3, 4)]); adj = nx.adjacency_matrix(G).astype(bool). fig, axes = plt.subplots(nrows=3); # Fixed circle layout; pos = {i: (np.cos(-np.pi + (np.pi * i) / 4), np.sin(-np.pi + (np.pi * i) / 4)) for i in range(5)}. for n, ax in enumerate(axes):; nx.draw(; nx.Graph(walk_nsteps(adj, n)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1383#issuecomment-701194608:96,update,updates,96,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1383#issuecomment-701194608,1,['update'],['updates']
Deployability,"Hey! Sorry for the late reply:; 1. Yes, a separate file, please.; 2. Put both in the same function. I wouldn't call it coexpression though. Something along the lines of `cell_selection_by_genes()` or just `cell_selection()`.; 3. There is a `sort_order` keyword for plotting which works for continuous covariates. I imagine that should work.; 4. That may be overkill... but it would definitely be interesting. I think MAGIC is in `sc.external` and DCA is also easily usable in this framework. They are not part of the core package though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/490#issuecomment-589225328:290,continuous,continuous,290,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/490#issuecomment-589225328,1,['continuous'],['continuous']
Deployability,"Hey! 😄 . I'd in principle happy if we move the default `scanpy.settings.cachedir` from `./cache/` to `appdirs.user_cache_dir()`. . However, if then any Scanpy installation breaks, as _the main hpc I'm on 1gb of space where appdirs would put these files_, I would probably not make this the default, but choose something like `~/cache-scanpy/`, that is, a visible directory in home (if we really want, `~/.scanpy/` is also fine). Under https://scanpy.readthedocs.io/en/latest/api/index.html#settings, we could also talk about other alternatives. I second Isaac's concern. Like many others, I'm computing on AWS these days and there, the canonical way of making data locally accessible is via EBS volumes. Hence, I'm used to setting the cachedir to that mount point with a visible name, knowing that this can hold a lot of data. I'd manually clean it if something that I don't use often takes too much space. So, I fear that `appdirs.user_cache_dir()` is not smart enough to figure out locations on a Linux system that hold the size of data that we're typically talking about. It would for sure be the right solution for laptops and work stations etc.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/558#issuecomment-476588843:159,install,installation,159,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-476588843,1,['install'],['installation']
Deployability,"Hey!. You used the data integration methods incorrectly as far as I can see. Please read the documentation for the functions first. `mnnpy.mnn_correct()` takes all the batches as separate anndata objects as positional argument. So you need to do:; `mnnpy.mnn_correct(adata_batch1, adata_batch2, adata_batch3,...)` to run it. For `sc.pp.combat()` you didn't specify where your batch information was stored. And I'm surprised BBKNN didn't work for you. Did you run a `sc.pp.pca()` first?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/873#issuecomment-542686602:24,integrat,integration,24,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/873#issuecomment-542686602,1,['integrat'],['integration']
Deployability,"Hey!; > * What methods/ tools?; I am mainly thinking about normalization and data integration methods. For example scran pooling, sctransform, scNorm, Seurat data integration, LIGER... etc. I have most of those already... But anyone is welcome to contribute for anything they regularly use. > * How would you handle R depencies?; So far I've been ignoring this problem and just assuming people have an R environment installed that has the relevant packages. You could just stick a `require(package)` in the function called by `rpy2` and then if would give you an `R` error you can interpret. The plan would be to make this a set of convenience functions, but not a cleanly installable module I guess... I'm not sure how you could get any python setup to install R dependencies for you... > * And (probably hard and definitely not necessary at first) could we use [arrow](https://arrow.apache.org/docs/python/) to speed up data transfer?; This looks interesting... but I don't entirely understand it... you'd have to have a a separate data structure that can move been languages, and be interpreted as an R data structure or `AnnData` depending on where it's used? Most methods are designed to run on a particular class of object. How would this help if you always have to convert to that type of object? So far I've just been using `anndata2ri` to ensure we have an `SCE` object which can be converted to other `R` data structures.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1068#issuecomment-590143256:82,integrat,integration,82,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1068#issuecomment-590143256,5,"['install', 'integrat']","['install', 'installable', 'installed', 'integration']"
Deployability,"Hey!; I just updated to latest master branch and I can no longer load scanpy. `import scanpy as sc` gives me the error:; ``` ---------------------------------------------------------------------------; PackageNotFoundError Traceback (most recent call last); <ipython-input-1-0074c9bc0b31> in <module>; ----> 1 import scanpy as sc. ~/new_scanpy/scanpy/scanpy/__init__.py in <module>; 25 __version__ = get_versions()['version']; 26 ; ---> 27 check_versions(); 28 del get_versions, check_versions; 29 . ~/new_scanpy/scanpy/scanpy/utils.py in check_versions(); 38 ; 39 anndata_version = version(""anndata""); ---> 40 umap_version = version(""umap-learn""); 41 ; 42 if anndata_version < LooseVersion('0.6.10'):. ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in version(package); 103 ""Version"" metadata key.; 104 """"""; --> 105 return distribution(package).version; 106 ; 107 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in distribution(package); 84 :return: A ``Distribution`` instance (or subclass thereof).; 85 """"""; ---> 86 return Distribution.from_name(package); 87 ; 88 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in from_name(cls, name); 50 return resolved; 51 else:; ---> 52 raise PackageNotFoundError(name); 53 ; 54 @staticmethod. PackageNotFoundError: umap-learn ; ```. I have `umap-learn` 0.3.9 installed. . Scanpy version: 1.4.3+115.g1aecabf; Anndata version: 0.6.22rc1. It seems to work with umap-learn 0.3.8, scanpy 1.4.3+105.gc748b35. and anndata 0.6.22.post1+1.g8dcc3cd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/739:13,update,updated,13,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/739,2,"['install', 'update']","['installed', 'updated']"
Deployability,"Hey!; I'm a member of g:Profiler (biit.cs.ut.ee/gprofiler) development team and was scanning through web to find services that might depend on us. . We recently went live with an extensive update which might break some of the previous pipelines and wrappers. . All the existing Python and R packages should work, however they are linking to an archived data version and they don't access the most up-to-date data from g:Profiler due to the new API etc. . We have already created a new R package that corresponds to the new API, Python package is still in the progress. . I just wanted to let you know and please feel free to contact me if I can be of any help. All the best,; Liis",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/467#issuecomment-466359205:189,update,update,189,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/467#issuecomment-466359205,2,"['pipeline', 'update']","['pipelines', 'update']"
Deployability,"Hey!; So one reason I can think of why it's important that `.obs` covariates are strings is that matplotlib will assume that numerical covariates lie on a continuous scale and thus colour this with a continuous colour scale and provide the corresponding colour bar. Typically that is not what you want for louvain clusters. These are inherently categorical, so the conversion to string is used to further convert to `pd.Categorical` via `sanitize_anndata()`. From my point of view the `.loc` and `.iloc` convention isn't particularly intuitive for new users, so I wouldn't be in favour of that setup. I'm not sure I see the issue with converting numerical values to strings if what you are using these as are labels, and thus categories (e.g. `obs_names` or other). Integers are after all values which have an inherent ordering and a defined distance, which is not a characteristic you would assign to an index.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1030#issuecomment-582648527:155,continuous,continuous,155,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1030#issuecomment-582648527,2,['continuous'],['continuous']
Deployability,"Hey, . I am trying to install scanpy through a Docker image. I get stuck in importing scanpy; It seems that the error has some link to numba but I am not sure!; ; ### Minimal code sample:. ```python; python -c ""from numba.caching import _UserProvidedCacheLocator; print(_UserProvidedCacheLocator(lambda x:x, 'string').get_cache_path())""; python -c ""import numba;print(numba.__version__)""; python -c ""import anndata;print(anndata.__version__)""; python -c ""import torch;print(torch.__version__)""; python -c ""import librosa;print(librosa.__version__)""; python -c ""import torch;print(torch.__version__)""; python -c ""import scanpy;print(scanpy.__version__)""; ```. ### errors:. ```python; /workspace; /opt/conda/bin/python; Traceback (most recent call last):; File ""<string>"", line 1, in <module>; ModuleNotFoundError: No module named 'numba.caching'; 0.53.1; 0.7.8; 1.10.1+cu102; Traceback (most recent call last):; File ""<string>"", line 1, in <module>; File ""/opt/conda/lib/python3.7/site-packages/librosa/__init__.py"", line 211, in <module>; from . import core; File ""/opt/conda/lib/python3.7/site-packages/librosa/core/__init__.py"", line 5, in <module>; from .convert import * # pylint: disable=wildcard-import; File ""/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py"", line 7, in <module>; from . import notation; File ""/opt/conda/lib/python3.7/site-packages/librosa/core/notation.py"", line 8, in <module>; from ..util.exceptions import ParameterError; File ""/opt/conda/lib/python3.7/site-packages/librosa/util/__init__.py"", line 83, in <module>; from .utils import * # pylint: disable=wildcard-import; File ""/opt/conda/lib/python3.7/site-packages/librosa/util/utils.py"", line 1848, in <module>; def __shear_dense(X, factor=+1, axis=-1):; File ""/opt/conda/lib/python3.7/site-packages/numba/core/decorators.py"", line 214, in wrapper; disp.enable_caching(); File ""/opt/conda/lib/python3.7/site-packages/numba/core/dispatcher.py"", line 812, in enable_caching; self._cache = FunctionCache(self",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2113:22,install,install,22,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2113,1,['install'],['install']
Deployability,"Hey, just wanted to comment here on why it's taken so long for a review. I'm personally not comfortable with having significant code in the package that we cannot test on CI. We're looking into this, but it's been slow going since it looks like we have to set this up and manage it on our own. As far as I can tell this process is:. * Put money into the azure account; * Set up containers; * Configure pipelines to use these containers (not sure if we can use the standard Tasks on ""self hosted"" containers) . @Zethson, since you're actually at the institute with the money you may have better luck moving the first step forward than I've had. Do you think you'd be able to look into this?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1533#issuecomment-815455859:402,pipeline,pipelines,402,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533#issuecomment-815455859,1,['pipeline'],['pipelines']
Deployability,"Hey, sorry for being slow here. upon looking into this again, it is the case that `read_10x_mtx` has to make strong assumptions on the files being generated by Cell Ranger. This is also reflected in the filenames this software outputs. Is there a widely used processing pipeline which does not adhere to this file naming?; If yes, scanpy should indeed be able to deal with this;; If no, custom workflows would actually be more reliably dealt with by using a small custom reading script as suggested by @flying-sheep above:. > Hi! That function is for reading the files output by [cellranger’s mex option](https://support.10xgenomics.com/single-cell-gene-expression/software/pipelines/latest/output/matrices). Your files have been renamed by someone in a way we can’t predict, and you should just adapt the little code needed to read them yourself:; > ; > https://github.com/theislab/scanpy/blob/e6e08e51d63c78581bb9c86fe6e302b80baef623/scanpy/readwrite.py#L324-L341; > ; > Took me 3 minutes:; > ; > ```python; > samples = []; > for sample in range(1, 10):; > s = read(; > path / f'{sample}.matrix.mtx',; > cache=cache,; > cache_compression=cache_compression,; > ).T; > genes = pd.read_csv(path / f'{sample}.genes.tsv', header=None, sep='\t'); > s.var_names = genes[0]; > s.var['gene_symbols'] = genes[1].values; > s.obs_names = pd.read_csv(path / f'{sample}.barcodes.tsv', header=None)[0]; > samples.append(s); > adata = AnnData.concatenate(samples); > ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/882#issuecomment-1759283694:270,pipeline,pipeline,270,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/882#issuecomment-1759283694,2,['pipeline'],"['pipeline', 'pipelines']"
Deployability,"Hey, thanks for your reply!. I looked a bit around, and here is what the Seurat 3.1.4 docs say:. > Choose the features to use when integrating multiple datasets. This function ranks features by the number of datasets they appear in, breaking ties by the median rank across datasets. It returns the highest features by this ranking. from https://www.rdocumentation.org/packages/Seurat/versions/3.1.4/topics/SelectIntegrationFeatures. From this, I'd conclude that the current docs are correct, but in the sorting order of `_highly_variable_genes_seurat_v3` has it the wrong way around. Also, the test for the `_highly_variable_genes_seurat_v3()` method seems to assume that the method sorts the other way around than it currently does:. From within the method:. https://github.com/theislab/scanpy/blob/ca07fc12bbcd87e4cf67da56f52525a1e519711b/scanpy/preprocessing/_highly_variable_genes.py#L139-L144. From the test:. https://github.com/theislab/scanpy/blob/ca07fc12bbcd87e4cf67da56f52525a1e519711b/scanpy/tests/test_highly_variable_genes.py#L138-L151. So from this it seems save to say that the sorting order should be reversed in `_highly_variable_genes_seurat_v3()`..?!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1733#issuecomment-802052402:131,integrat,integrating,131,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1733#issuecomment-802052402,1,['integrat'],['integrating']
Deployability,"Hey,. indeed there seems to be an [issue](https://github.com/mwaskom/seaborn/issues/3522) with our current usage of `seaborn`, not working with `seaborn 0.13.0`.; This has been fixed on the main branch [here](https://github.com/scverse/scanpy/pull/2661), and we'll eventually take over the newest `seaborn` version once this is cleared. For users running into this issue now ; - first check if you indeed have `seaborn 0.13.0`. If yes, then do; - `pip install seaborn==0.12.2` if using pip or; - `conda install seaborn=0.12.2` if using conda. this makes sure you are using the working version of seaborn. Hope this helps!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2680#issuecomment-1764383215:452,install,install,452,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680#issuecomment-1764383215,2,['install'],['install']
Deployability,"Hey,. we moved from conda-forge to Bioconda -> https://github.com/scverse/scanpy/issues/1169. Unfortunately, this comes at a cost which is highly relevant for pipeline building. nf-core wants to add support for scverse data structures: https://github.com/nf-core/scrnaseq/issues/68 The issue is that Bioconda autogenerates Docker & Singularity containers which Nextflow pipelines always use to provide support for all execution environments. conda-forge does not. The official Dockerhub is firstly stuck in an old version and, when used, it lacks the package `procps` that is used by nextflow to track execution. How serious are the Bioconda issues? Can we resolve them and move back? I'd avoid always having to manage also our own container releases and love the automated container building by Bioconda.; I was also made aware by @apeltzer that bio specific tools should live in bioconda. Choosing to put them in conda-forge is not really desired. @ivirshup @flying-sheep . CC @drpatelh @fmalmeida @apeltzer @grst",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2281:159,pipeline,pipeline,159,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281,3,"['pipeline', 'release']","['pipeline', 'pipelines', 'releases']"
Deployability,"Hey,; while writing tests for #1715 I noted the following behavior:. `output = sc.pp.highly_variable(adata,inplace=True,subset=False,n_top_genes=100)`; --> Returns nothing :heavy_check_mark: ; --> `adata.var` fields are updated but shape stays the same :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=True,subset=True,n_top_genes=100)`; --> Returns nothing :heavy_check_mark: ; --> `adata.var` fields are updated and shape is subsetted correctly :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=False,subset=False,n_top_genes=100)`; --> output is a dataframe with the original number of genes as rows :heavy_check_mark: ; --> `adata` is unchanged :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=False,subset=True,n_top_genes=100)`; --> Returns nothing :x: ; --> `adata` shape is changed an `var` fields are updated :x: . I think the last case is unexpected, assuming that `inplace=False` should protect `adata` from changes and results in an output. I think these parts of code are the cause (depending on the flavor):. https://github.com/theislab/scanpy/blob/4dd8de9e355ce8d59009c15522670a3d0970462c/scanpy/preprocessing/_highly_variable_genes.py#L148-L174. https://github.com/theislab/scanpy/blob/4dd8de9e355ce8d59009c15522670a3d0970462c/scanpy/preprocessing/_highly_variable_genes.py#L528-L553. To fix this, one could change `if subset or inplace:` to `if inplace:`. Then one would need to add another `if subet:` in the `else` block, like so (half-pseudocode):. ```; if inplace: ; ; #update adata; ; if batch_key is not None:; #drop batch related keys; if subset:; adata._inplace_subset_var(df['highly_variable'].values); else:; if batch_key is None:; #drop batch related keys; if subset: ; df=df.iloc[df.highly_variable.values,:]; ; return df; ```. I can make a quick PR if this is the intended behavior. :slightly_smiling_face: ; best, jan.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1867:220,update,updated,220,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1867,4,['update'],"['update', 'updated']"
Deployability,Hi . We have purchased the Nadia dolomite machine which is the automated version of dropseq. I am using the dropseqpipe pipeline for demultiplexing and generate count matrix. Analysis with Seurat is fine but how do you load a count matrix in scanpy?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/366:120,pipeline,pipeline,120,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/366,1,['pipeline'],['pipeline']
Deployability,"Hi . When attempting so simply read a h5 file with: . ```; Python version - 3.8.8; # results_file = path to 10X h5 file ; # adata = sc.read_10x_h5(results_file); ```. I get the following error which is fixed when rolling back to scanpy=1.8.2; ```pytb; ValueError Traceback (most recent call last); <ipython-input-3-8ddd0a13aab2> in <module>; 8 print(results_file); ----> 9 adata = sc.read_10x_h5(results_file); 10 adata.var_names_make_unique(); 11 adata.obs.index = meta.iloc[idx,2] + '-' + adata.obs.index. /opt/conda/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_h5(filename, genome, gex_only, backup_url); 181 v3 = '/matrix' in f; 182 if v3:; --> 183 adata = _read_v3_10x_h5(filename, start=start); 184 if genome:; 185 if genome not in adata.var['genome'].values:. /opt/conda/lib/python3.8/site-packages/scanpy/readwrite.py in _read_v3_10x_h5(filename, start); 266 try:; 267 dsets = {}; --> 268 _collect_datasets(dsets, f[""matrix""]); 269 ; 270 from scipy.sparse import csr_matrix. /opt/conda/lib/python3.8/site-packages/scanpy/readwrite.py in _collect_datasets(dsets, group); 254 for k, v in group.items():; 255 if isinstance(v, h5py.Dataset):; --> 256 dsets[k] = v[:]; 257 else:; 258 _collect_datasets(dsets, v). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). /opt/conda/lib/python3.8/site-packages/h5py/_hl/dataset.py in __getitem__(self, args, new_dtype); 767 if self.shape == ():; 768 fspace = self.id.get_space(); --> 769 selection = sel2.select_read(fspace, args); 770 if selection.mshape is None:; 771 arr = numpy.ndarray((), dtype=new_dtype). /opt/conda/lib/python3.8/site-packages/h5py/_hl/selections2.py in select_read(fspace, args); 99 """"""; 100 if fspace.shape == ():; --> 101 return ScalarReadSelection(fspace, args); 102 ; 103 raise NotImplementedError(). /opt/conda/lib/python3.8/site-packages/h5py/_hl/selections2.py in __init__(self, fspace, args); 84 self.mshape = (); 85 else:; ---> 86 raise ValueErro",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2203:213,rolling,rolling,213,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2203,1,['rolling'],['rolling']
Deployability,"Hi @ChineseBest, installing the following versions in google colab worked for me: `scanpy==1.7.1 pynndescent==0.4.8 numba==0.51.2`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1951#issuecomment-908461350:17,install,installing,17,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1951#issuecomment-908461350,1,['install'],['installing']
Deployability,"Hi @FADHLyemen,. You can export the raw count table (before calculating the percentage) into R for downstream analysis using `edgeR`. You can follow the following link to find further information: https://bioconductor.org/books/release/OSCA/multi-sample-comparisons.html#differential-abundance. Regards,; Mikhael",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1831#issuecomment-845906745:228,release,release,228,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1831#issuecomment-845906745,1,['release'],['release']
Deployability,"Hi @GouQiao - it's been a while since this specific incident so I don't 100% remember / have the code anymore. However, I have run into this problem in general when using AnnData and it's usually resolved by one of two paths:. 1. Check the version of `h5py` that you have installed and perhaps it is too new and an older version resolves the issue. ; 2. Some components of AnnData are not implemented in the function, `.write_h5ad()`. One example that comes to mind is the umap or pca transformer. These objects are not handled well by `.h5py` (at least natively in my experience) and are better off saved independently as dictionaries using `pickle`. That being said, I think there is probably a more robust solution I am not aware of - I know in several instances transformers are able to be saved (e.g., the Scanpy tutorials). . Does this help at all? Happy to be of further assistance if possible.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1275#issuecomment-996451713:272,install,installed,272,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1275#issuecomment-996451713,1,['install'],['installed']
Deployability,"Hi @IfSumia, that’s a very different problem, see the last line:. ```pytb; ImportError: cannot import name 'colormaps' from 'matplotlib' (/opt/conda/lib/python3.9/site-packages/matplotlib/__init__.py); ```. This probably means that you should update matplotlib and try again",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2173#issuecomment-1693549285:243,update,update,243,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2173#issuecomment-1693549285,1,['update'],['update']
Deployability,"Hi @KabitaBaral1 ,; You can update it using:; ```; pip install --upgrade scanpy; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1154#issuecomment-611324832:28,update,update,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1154#issuecomment-611324832,3,"['install', 'update', 'upgrade']","['install', 'update', 'upgrade']"
Deployability,"Hi @Koncopd I tried updating scanpy, but it does not let me update from 1.4.4.post1. How do I update it to 1.4.6 using conda?. Thank you",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1154#issuecomment-611273954:60,update,update,60,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1154#issuecomment-611273954,2,['update'],['update']
Deployability,"Hi @Koncopd, any idea when the new release will be out?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1285#issuecomment-660627731:35,release,release,35,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1285#issuecomment-660627731,1,['release'],['release']
Deployability,"Hi @LuckyMD ,; Any updates regarding this issue? I am fairly new to scanpy and I am working on implementing regress_out() and finding HVG in the best way possible. I keep wondering whether or not I should regress out and scale before or after finding HVG. Any tips/updates? Everything is welcome :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/722#issuecomment-1519822911:19,update,updates,19,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/722#issuecomment-1519822911,2,['update'],['updates']
Deployability,"Hi @LuckyMD - thanks for your reply! Yeah that makes sense. I'm performing these corrections using a subset of highly variable genes, so I guess to ""make up"" for the loss of ""true"" HVGs in the new subclusters of cells I could select a higher number of HVGs to perform the original alignment? As well as maybe using a larger number of components for downstream applications from the low-dimensional embedding outputted by the original alignment. Does that make sense to you?. One more question - when performing differential gene expression analysis, what is your preferred pipeline/method when using aligned datasets? I generally do not perform the correction on the gene expression matrix when aligning, and I think doing DE with corrected matrices is not as common. So maybe other methods that use batch as a covariate would be preferable (e.g. diffxpy or others?) Would really appreciate any suggestions here!. PS. many congratulations on the benchmarking integration paper in Nature Methods - excellent work and very useful resource for the field!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2162#issuecomment-1061085766:573,pipeline,pipeline,573,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2162#issuecomment-1061085766,2,"['integrat', 'pipeline']","['integration', 'pipeline']"
Deployability,"Hi @LuckyMD ; Thank you for the fast reply. Yes to FastMNN, as I understand from using align_cds – when you specify discretely what you want to remove e.g. sample-sample variation it calls FastMNN from batchelor. Thanks for the recommendation – I will check out Scanorama, been meaning to read the review on integration techniques. . > you will only get an integrated graph structure with this for scvelo, which may help a little, but won't remove the batch effect for RNA velocity calculation. scvelo doesn't currently have any batch removal in its pipeline as it is quite difficult to add as it works directly from the normalized count data and fits a model to these. Ahh okay, I misunderstood the process then – my understanding was that some of the mnn correction would be carried over when performing velocity analysis. I will check out the scvelo forum for info on comparing samples. . Thank you.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1289#issuecomment-735661916:308,integrat,integration,308,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289#issuecomment-735661916,3,"['integrat', 'pipeline']","['integrated', 'integration', 'pipeline']"
Deployability,"Hi @LuckyMD,. Sure, I'll work on it, as time allows. Before however, I have a couple of questions. . 1. Do you want it as a separate .py file in the tools module (similar to _dendrogram.py)?; 2. I also found interesting to look at exclusive expression of one gene and not the other. Would you be interested in adding a function for that as well and if so, should be a separate one or somehow integrated with coexpression?; 3. Turning values into categorical works, however now I have problem that the True (coexpressing) cells are not always plotted on top. Do you know how to do it in scanpy? I tried by setting `pd.Categorical(ordered = True)`, however, that doesn't help. ; 4. Could you elucidate on how you want to implement the imputation methods? I've never used them myself. Is there anything available in scanpy already?. And thanks @flying-sheep for showing how to remove the colourbar. I wanted to do it for some of my other plots, so that really helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/490#issuecomment-588132560:392,integrat,integrated,392,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/490#issuecomment-588132560,1,['integrat'],['integrated']
Deployability,"Hi @LuckyMD,. Thank you. Oddly, I went to sleep and tried installing 'python-igraph' again the next day and it worked just fine. I can only assume pip was being moody the first day. Thank you again.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/807#issuecomment-640195237:58,install,installing,58,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/807#issuecomment-640195237,1,['install'],['installing']
Deployability,"Hi @Pawan291, It seems `louvain` has not been properly installed in your environment. Could you post the output of `scanpy.logging.print_versions()` as suggested in the template? You should just need to `pip install louvain`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1566#issuecomment-753946626:55,install,installed,55,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1566#issuecomment-753946626,2,['install'],"['install', 'installed']"
Deployability,"Hi @YiweiNiu,. Please install `python-igraph` and not `igraph` via pip. So run `pip install python-igraph` and get rid of the `igraph` package. You may have to update you `pip` as well.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/807#issuecomment-534457495:22,install,install,22,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/807#issuecomment-534457495,3,"['install', 'update']","['install', 'update']"
Deployability,"Hi @Zethson,; I'm curious whether you have a status update on this. Would be really excited to have GPU-accelerated Leiden, but I understand the issues you mention here. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1793#issuecomment-1102829655:52,update,update,52,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1793#issuecomment-1102829655,1,['update'],['update']
Deployability,"Hi @Zethson,; Thank you so much for the response. Please let us know if any updates/changes are required to be done from our side in the above contribution, we will do them at the earliest. Also, please let us know if we need to do anything else for fixing the issues in the PR at the moment.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2409#issuecomment-1432748647:76,update,updates,76,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2409#issuecomment-1432748647,1,['update'],['updates']
Deployability,"Hi @all,; Thanks to develop the great tools,; I encounter a pecular problem on bbknn integrated data.; i follow the workflow code to run the data integrated,the code showing below,; #; sc.pp.highly_variable_genes(adata); adata = adata[:, adata.var['highly_variable']]; sc.tl.pca(adata, svd_solver='arpack'); sc.tl.tsne(adata); ///data integrated; sc.external.pp.bbknn(adata, batch_key='orig.ident'). sc.tl.umap(adata); adata; sc.pl.umap(adata, color=['orig.ident']); showing the well integrated, picture below,; ![image](https://user-images.githubusercontent.com/41668708/90249921-df74d980-de6d-11ea-8283-3830dd3c6ad2.png); But,when i want to see the tsne picture, the batch from different sample showing up on the tsne but umap like above picture; ,i runing ,; sc.tl.tsne(adata); sc.pl.tsne(adata, color=['orig.ident']); the picture show below, indicating that the integrated can not be worked on tsne.; ![image](https://user-images.githubusercontent.com/41668708/90250154-3c708f80-de6e-11ea-8d43-7a597c5693a2.png); So, why this tsne showing significantly different with the object just running over the integrated process.; any advice would be appreciated; Best,; hanhuihong",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1370:85,integrat,integrated,85,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1370,6,['integrat'],['integrated']
Deployability,"Hi @brianhie,. It's great that you're contributing to Scanpy to make the interoperability even easier (I guess it was already quite good given you built on `AnnData`). We have been evaluating data integration methods and in which Scanorama performed quite well (you may have seen the [preprint](https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2)). One aspect that would make it even easier to use the tool that we were missing in the comparison is a small tutorial. The example in the function docstring is already very helpful, but do you think it would be possible to add a quite jupyter notebook in this direction? This is obviously a request outside of this PR. On the topic of the PR, I wonder if `adata.obsm['X_pca_scanorama']` is a good default name for the generated embedding, and not just `adata.obsm['X_scanorama']` as the standard user may not have delved into the methodology as much.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1332#issuecomment-665592723:197,integrat,integration,197,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1332#issuecomment-665592723,1,['integrat'],['integration']
Deployability,"Hi @cartal!. I believe the spatial branch has been merged into master now. So you no longer need the `@spatial` in there. . @giovp could you update this in the tutorial, please?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1104#issuecomment-599203000:141,update,update,141,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1104#issuecomment-599203000,1,['update'],['update']
Deployability,"Hi @chansigit,; If you want to store the raw counts before filtering out cells/genes you can also do this in `adata.raw`. We're trying to reduce the use of this... but it will allow you to store data in a different dimension. @ivirshup I guess use of scaling is up in the air. Some people like it, some people don't. I find it can be helpful for data integration/batch correction.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1089#issuecomment-596466943:351,integrat,integration,351,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1089#issuecomment-596466943,1,['integrat'],['integration']
Deployability,"Hi @falexwolf, thanks a lot for the clarifications. This helps me a lot. In the example I provided yesterday, `louvain` found 5 clusters, so 0, 1, 2 made up only part of the data. I should have provided the output as well to make this clear right away. Concerning a PR for the documentation, I think I would wait until you will update the behaviour of `logreg`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/278#issuecomment-427339773:328,update,update,328,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/278#issuecomment-427339773,1,['update'],['update']
Deployability,"Hi @falexwolf, yes I will be making my method available. A [rough version](https://github.com/swolock/woublet) is already on github, and I also played around with adding it to my [scanpy fork](https://github.com/swolock/scanpy) (though not the right way -- I added it to `tl` rather than `pp`). I'll hopefully clean it up and release something more official when I have the chance.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/173#issuecomment-400090424:326,release,release,326,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/173#issuecomment-400090424,1,['release'],['release']
Deployability,"Hi @falexwolf,. 10X is releasing a new version of CellRanger that is changing the output format. This pull request makes Scanpy forward compatible with the new version. In particular, the following changes are made:. Updated `read_10x_h5`:; - Renamed the original `read_10x_h5` as `_read_legacy_10x_h5`;; - Added `_read_v3_10x_h5` to read the new Cell Ranger output format;; - The new `read_10x_h5` determines the version of HDF5 input by the presence of the matrix key, and wraps the above two functions. In addition, it takes a `gex_only` argument which filters out feature barcoding counts from the outcome object when it is True (default). Otherwise, the full matrix will be retained.; - For CR-v3, `feature_types` and `genome` were added into the outcome object as new attributes. Updated `read_10x_mtx`:; - Renamed the original `read_10x_mtx` as `_read_legacy_10x_mtx`;; - Added `_read_v3_10x_mtx` to read the new Cell Ranger output format;; - The new `read_10x_mtx` determines the version of matrix input by the presence of the `genes.tsv` file under the input directory, and wraps the above two functions. In addition, it takes a `gex_only` argument which filters out feature barcoding counts from the outcome object when it is `True` (default). Otherwise, the full matrix will be retained.; - For CR-v3, `feature_types` was added into the outcome object as a new attribute. Added small test datasets and code for the revised functions to verify the expected behavior. Note for the `genome` argument:; - There is a genome argument in Scanpy's `read_10x_h5` function but not in `read_10x_mtx` as the genome was already specified by the path of input directory. The outcome object of the two functions should be the same which always take one genome at a time.; - In this PR, when there are multiple genomes (e.g. Barnyard), `read_10x_mtx` always read them all, whereas `read_10x_h5` always need to specify one of them (mm10 by default). However, when `gex_only == False`, the `genome` argument ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/334:217,Update,Updated,217,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/334,2,['Update'],['Updated']
Deployability,"Hi @fidelram, good to see you :smile:. I was working on the Galaxy integration. I tested that with the `1.3.2` version from Bioconda. I tested with adata from krumsiek11. - For colors, I tried with `sc.pl.scatter(adata=adata, x='EKLF', y='Cebpa', color=['EgrNab', 'cJun']) and I got the error:. ```; ...; and (color is None or color in adata.obs.keys() or color in adata.var.index)):; File ""path/to/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 2035, in __contains__; hash(key); TypeError: unhashable type: 'list'; ```. - For components: the command was . ```; sc.pl.scatter(; adata=adata,; x='EKLF',; y='Cebpa',; color='EgrNab',; layers=('X', 'X', 'X'),; use_raw=False,; sort_order=True,; components='all',; projection='2d',; legend_loc='right margin',; legend_fontsize=1,; legend_fontweight='normal',; palette='viridis',; frameon=True,; right_margin=1.0,; size=1.0,; show=False,; save='.png'); ```; and the error:. ```; components = np.array(components).astype(int) - 1; ValueError: invalid literal for int() with base 10: 'all'; ```. Did I put the parameters in a wrong way?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/311#issuecomment-431284136:67,integrat,integration,67,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/311#issuecomment-431284136,1,['integrat'],['integration']
Deployability,"Hi @flying-sheep , I’m using Scanpy on an HPC system, and even though the administrator updated it to the latest version, I'm still encountering the same error. -----; anndata 0.9.2; scanpy 1.10.2; -----; PIL 9.5.0; asciitree NA; asttokens NA; astunparse 1.6.3; backcall 0.2.0; bottleneck 1.3.6; cffi 1.15.0; cloudpickle 2.2.1; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; cytoolz 0.12.2; dask 2024.5.2; dateutil 2.9.0.post0; debugpy 1.5.1; decorator 4.4.2; defusedxml 0.7.1; dill 0.3.8; dot_parser NA; entrypoints 0.4; executing 0.8.3; fasteners 0.18; google NA; h5py 3.8.0; igraph 0.10.8; ipykernel 6.9.1; ipython_genutils 0.2.0; ipywidgets 7.6.5; jedi 0.18.1; jinja2 3.1.2; joblib 1.4.0; jupyter_server 1.18.1; kiwisolver 1.4.2; legacy_api_wrap NA; leidenalg 0.10.1; llvmlite 0.42.0; louvain 0.8.2; lz4 4.3.2; markupsafe 2.1.1; matplotlib 3.6.0; mpl_toolkits NA; msgpack 1.0.5; natsort 8.4.0; numba 0.59.0; numcodecs 0.12.1; numexpr 2.8.4; numpy 1.23.5; packaging 21.3; pandas 2.1.0; parso 0.8.3; patsy 0.5.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; plotly 5.23.0; prompt_toolkit 3.0.20; psutil 5.9.1; ptyprocess 0.7.0; pure_eval 0.2.2; pyarrow 16.0.0; pydev_ipython NA; pydevconsole NA; pydevd 2.6.0; pydevd_concurrency_analyser NA; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pydot 1.4.2; pygments 2.16.1; pynvml NA; pyparsing 3.0.9; pytz 2022.1; ruamel NA; scipy 1.11.2; seaborn 0.13.2; session_info 1.0.0; setuptools 61.2.0; six 1.16.0; sklearn 1.3.2; sphinxcontrib NA; stack_data 0.2.0; statsmodels 0.14.0; tblib 2.0.0; texttable 1.6.7; threadpoolctl 2.2.0; tlz 0.12.2; toolz 0.11.2; torch 2.2.0+cu121; torchgen NA; tornado 6.1; tqdm 4.63.0; traitlets 5.1.1; typing_extensions NA; wcwidth 0.2.5; xxhash NA; yaml 6.0; zarr 2.15.0; zipp NA; zmq 22.3.0; zoneinfo NA; zope NA; -----; IPython 8.4.0; jupyter_client 7.1.2; jupyter_core 4.10.0; jupyterlab 3.4.4; notebook 6.4.12; -----; Python 3.9.12 (main, Apr 5 2022, 06:56:58) [GCC 7.5.0]; Linux-3.10.0-1160.99.1.e",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3215#issuecomment-2330378344:88,update,updated,88,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3215#issuecomment-2330378344,1,['update'],['updated']
Deployability,"Hi @flying-sheep @ilan-gold ,; Based on our previous discussion, we observed that applying and then removing a patch while fixing the seed causes the t-SNE output to change. In our experiment, we used 1.3 million data points to run t-SNE and compared the results of the patched and unpatched versions by examining the KL Divergence from both runs. The results are summarized in the table below. . In the above code use **USE_FIRST_N_CELLS** to set number of records and use sc.tl.tsne(adata, n_pcs=tsne_n_pcs, **use_fast_tsne=False**) to run optimized run with latest commit. You can get KL divergence numbers by logging [kl_divergence_](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html). ![image](https://github.com/scverse/scanpy/assets/1059402/ffef81b0-b0bf-461e-8ad3-b7ce9ba4c361)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3061#issuecomment-2122306265:111,patch,patch,111,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061#issuecomment-2122306265,2,['patch'],"['patch', 'patched']"
Deployability,"Hi @flying-sheep, just saw your updates here. I was slowly working on a re-structured scanpy-scripts that has a sub-command interface i.e `scanpy-cli read`, `scanpy-cli filter` etc and with some added functionality for convenience (https://github.com/ebi-gene-expression-group/scanpy-scripts/pull/40). I'll try change the interface back to make it compatible with yours.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/281#issuecomment-484475390:32,update,updates,32,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/281#issuecomment-484475390,1,['update'],['updates']
Deployability,"Hi @freeman-lab, we have now quite a number of modules:. https://github.com/ebi-gene-expression-group/scanpy-scripts. And, as our other seurat-scripts, sc3-scripts and scater-scripts, it is bioconda installable (or in the way to be). We would be happy to accept your module, although it would be good to see how much it overlaps or not with existing parts already there, to find the best way to integrate it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/281#issuecomment-431712261:199,install,installable,199,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/281#issuecomment-431712261,2,"['install', 'integrat']","['installable', 'integrate']"
Deployability,"Hi @geovp!. Yes, I mean the original image that was supplied to SpaceRanger pipeline.; It doesn't have to be a TIFF image - in my experience slide scanners save; JPEG images internally, so there is no value in converting that to TIFF.; Also, it would be cool to use sc.pl.spatial for other technologies - say to; overlay single cell spatial over the microscopy image image. Nice, I was using this hacky way before (if I remember correctly I also; changed spot size in the respective slot) - so it does work. I am wondering if you could add support for a fullres slot with size factor; 1 and explain which variables need to be set for it to work in the tutorial. On Thu, Oct 1, 2020 at 8:32 PM giovp <notifications@github.com> wrote:. > Hi @vitkl <https://github.com/vitkl> ,; > by fullres you mean the tiff image yes? This is not supported for now; > unfortunately, but we are working toward some extensions to make this; > possible (cc @hspitzer <https://github.com/hspitzer> ).; > One hacky way to go about this for now could be to:; >; > - assign the tiff to the hires slot in; > adata.uns['spatial]['library_id']['images']['hires']; > - change the hires scalefactor value to 1 in the respective slot; > This should work. also for plotting the spots in the right size. Of; > course, this is also possible if you replace the ""lowres"" instead.; > Let me know what you think about it and if it works.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/issues/1436#issuecomment-702351783>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AFMFTV5FBT2DB4GKUIZUVNTSITKMBANCNFSM4R5XDYSQ>; > .; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1436#issuecomment-702607732:76,pipeline,pipeline,76,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1436#issuecomment-702607732,1,['pipeline'],['pipeline']
Deployability,"Hi @giovp ,; I'm done from my side of things: I have re-worded some parts of the docstrings (hopefully to better readability ;) ), added the missing function to the release note and tried to make the `returns` sections of the docs a bit more consistent. Also, it seems that building the docs is failing again on github (locally it works with some warnings). Again I'm not sure why / if it is even related to my changes :thinking: . Let me know if I can help with fixing that or if anything else comes up!. Best, Jan.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1715#issuecomment-1065994090:165,release,release,165,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715#issuecomment-1065994090,1,['release'],['release']
Deployability,"Hi @giovp,; no worries, I hope you had a good TAC meeting! And thanks a lot for picking this up again, fixing the docs and also for starting the new issue on batch integration. I saw some of the github automated tests test are failing now, but I don't really understand the error messages tbh ;) Are they even related to the execution of the code provided by this PR?. If there is anything I should look into, let me know - I have some time for this next week!; Best, Jan",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1715#issuecomment-1049902277:164,integrat,integration,164,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715#issuecomment-1049902277,1,['integrat'],['integration']
Deployability,"Hi @grimwoo,. The data integration methods MNN and BBKNN are implemented in scanpy externals, which you can find [here](https://scanpy.readthedocs.io/en/stable/external/index.html#batch-effect-correction). You can also use combat correction, which is a simpler, linear batch effect correction approach implemented as `sc.pp.combat()`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/702#issuecomment-527337268:23,integrat,integration,23,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/702#issuecomment-527337268,1,['integrat'],['integration']
Deployability,"Hi @grst, I had a superficial look at the functionalities and setup and it does look very nice!. - BCR makes sense to add, there seems to be generally less happening in this space in single-cell though right now, compared to TCR. Would be good to have somebody on board who actually works on this data.; - [tcellmatch](https://github.com/theislab/tcellmatch)'s primary purpose is specificity prediction, this could be easily added ontop of this, I will look into your data structure and will think about the necessary changes. I am in the process of making this code public anyway, hopefully next week or so.; - You mentioned distance metrics, this is definitely an interesting and relevant area, in [tcellmatch](https://github.com/theislab/tcellmatch), we implicitly use 1. manhatten distances, 2. euclidian distances in BLOSUM embedding and 3. learned embedding distances, 2. and maybe 3. could be potentially integrated, would be worth discussing in any case.; - Integration with epitope data bases: I have data loaders for IEDB and VDJdb downloads, can you be a bit more specific how you would integrate that with exploratorive single-cell studies? I can only imagine searching for similar TCRs? These anticipated use cases would determine how and whether this makes sense i think.; - Potentially additionally relevant: An integration with dextramer counts to ""stain"" TCR specificity? There is the purely numeric, standard multi-modal single-cell, nature to this data that can be covered by standard scanpy work flows. This data is especially useful in the context of clonotypes etc which then would require additional functionalities, which could be built on what you have here. I have been looking into this type of analysis a lot in context of tcellmatch. Would be to contribute but also happy to see what other people do here, too!. Could you add a brief summary of how you use anndata to store the TCR data in the docs? That would be very helpful to design extension or custom workflows. Grea",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1163#issuecomment-613297254:912,integrat,integrated,912,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1163#issuecomment-613297254,1,['integrat'],['integrated']
Deployability,"Hi @grst,. We've been working on a best-practices workflow/tutorial for scRNA-sesq data for the past year. The tutorial is based on scanpy, but it also integrates tools from R. You can take a look at a case study which implements the workflow [here](https://github.com/theislab/single-cell-tutorial). The revised manuscript should be submitted this week as well, so I hope it will be out soon. If you like, I can send it to you, if you pass me your email address. Regarding regressing out covariates. @falexwolf has already mentioned that this is very dataset dependent. It is also dependent on the downstream analysis. This is especially true for the covariates you suggest. MT gene expression and cell cycle are both biological, rather than technical covariates. Regressing out biological covariates is generally done to isolate particular processes in the data that you are interested in, while losing global structure in the data. This is helpful especially for trajectory inference, but maybe less so for global exploratory analysis with clustering. For example, cell cycle stage can be a major determinant in the difference between two cell types (e.g. stem cells and proliferating cells like transit amplifying cells). Removing this effect, hides the distinction. MT gene expression is also a biological covariate (as well as a technical indicator of cell stress). Higher levels of MT gene expression can indicate increased respiration in e.g., asthmatic conditions. . An additional unwanted effect to regressing out biological covariates is that biological processes are not independent. Thus, regressing out one process, will partially remove effects of other, downstream processes as well. If you're interested, we can discuss this in more detail. Hope this helps a bit,",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/526#issuecomment-471488594:152,integrat,integrates,152,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/526#issuecomment-471488594,1,['integrat'],['integrates']
Deployability,"Hi @helios,. You will have to install scanpy from github to use the fix for this. The latest release (1.3.7) does not yet include the fix.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/450#issuecomment-460306375:30,install,install,30,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/450#issuecomment-460306375,2,"['install', 'release']","['install', 'release']"
Deployability,"Hi @hl324,. That argument is only available in scanpy 1.10, while you appear to have scanpy 1.9.8 installed. Could you try upgrading scanpy?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2981#issuecomment-2040195862:98,install,installed,98,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2981#issuecomment-2040195862,1,['install'],['installed']
Deployability,"Hi @honghh2018,. This might be an issue you have to raise with Seurat about their ReadH5AD function. From `AnnData` 0.7 the h5ad format has changed a little on disk, so maybe their function is not updated to this yet? Other ways you can go between Scanpy and Seurat are loom files or `anndata2ri` as shown [here](https://github.com/LuckyMD/Code_snippets/blob/master/Seurat_to_anndata.ipynb)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1198#issuecomment-623974282:197,update,updated,197,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1198#issuecomment-623974282,1,['update'],['updated']
Deployability,"Hi @ivirshup ,. just checked #1529 , that's a more general additions to `rank_genes_groups_matrixplot` and `rank_genes_groups_dotplot`, but does not address this bug of `violinplot` which has to do with sparse `adata.X`. This also adds a test for that case. Thanks for pointing it out.; I'll add release note and merge it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1669#issuecomment-827461688:296,release,release,296,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1669#issuecomment-827461688,1,['release'],['release']
Deployability,"Hi @ivirshup ,; It just fixed when I installed the library directly from pip. Since I was following the documentation for library installation, the command mentioned in the documentation is downloading an outdated version. . Thanks.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1334#issuecomment-733647903:37,install,installed,37,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1334#issuecomment-733647903,2,['install'],"['installation', 'installed']"
Deployability,"Hi @ivirshup ,; Thanks for your help.; Versions:; ```; In [1]: import numba; In [2]: numba.__version__; Out[2]: '0.45.0'; ```; I had to downgrade the original numba version in order to MNN_correct to work according to a Stackoverflow post.; Now I updated anndata through conda:; ```conda update anndata```; And ran this code (minus highly variable gene calculation):; ```; adataCombat = sc.read_h5ad(results_file); #Run combat:; # sc.pp.highly_variable_genes(adataCombat); sc.pp.pca(adataCombat, svd_solver='arpack'); sc.pp.combat(adataCombat, key='sample'); sc.pp.neighbors(adataCombat, n_pcs =50); ```; with even worse output:; ```; /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:269: NumbaWarning: ; Compilation is falling back to object mode WITH looplifting enabled because Function ""_it_sol"" failed type inference due to: Cannot unify array(float64, 2d, C) and array(float64, 1d, C) for 'sum2', defined at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py (311). File ""anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 311:; def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:; <source elided>; g_new = (t2*n*g_hat + d_old*g_bar) / (t2*n + d_old); sum2 = s_data - g_new.reshape((g_new.shape[0], 1)) @ np.ones((1, s_data.shape[1])); ^. [1] During: typing of assignment at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py (313). File ""anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 313:; def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:; <source elided>; sum2 = sum2 ** 2; sum2 = sum2.sum(axis=1); ^. @numba.jit; /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:269: NumbaWarning: ; Compilation is falling back to object mode WITHOUT looplifting enabled be",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1164#issuecomment-614594656:247,update,updated,247,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1164#issuecomment-614594656,2,['update'],"['update', 'updated']"
Deployability,"Hi @ivirshup ; I made some updates to PR #2055 . The column grouping argument was changed to a string/list argument 'col_groups'.; A few examples:; ```; pbmc = sc.datasets.pbmc3k_processed().raw.to_adata(); pbmc.obs[""sampleid""] = np.repeat([""s1"", ""s2""], pbmc.n_obs / 2); pbmc.obs[""condition""] = np.tile([""c1"", ""c2""], int(pbmc.n_obs / 2)). ## plot one gene, one column grouping variable; sc.pl.dotplot(pbmc, var_names='C1QA', groupby='louvain', col_groups='sampleid'); ```; ![image](https://user-images.githubusercontent.com/10910559/147171329-f5fafb2b-0695-41d9-b313-eac9ea218836.png); ```; ## plot two genes, one column grouping variable; sc.pl.dotplot(pbmc, var_names=['C1QA', 'CD19'], groupby='louvain', col_groups='sampleid'); ```; ![image](https://user-images.githubusercontent.com/10910559/147171410-45f77f03-3487-4b7f-86da-658284608b05.png); ```; ## plot two genes, tow column group variable; sc.pl.dotplot(pbmc, var_names=['C1QA', 'CD19'], groupby='louvain', col_groups=['sampleid', 'condition']); ```; ![image](https://user-images.githubusercontent.com/10910559/147171470-58df0907-a15b-4b7f-afa3-3578728177e0.png); ```; ## or we could use the same varaibles as y axis; sc.pl.dotplot(pbmc, var_names=['C1QA', 'CD19'], groupby=['sampleid', 'condition'], col_groups='louvain'); ```; ![image](https://user-images.githubusercontent.com/10910559/147171544-849a93f4-99cd-493e-9f2b-f5662f03e797.png). For the heatmap, I think you were referring to `sc.pl.matrixplot`. `sc.pl.heatmap` is a different function which plot a cell as a row and a gene as a column. `col_groups` was also added to `sc.pl.matrixplot`:; ```; ## plot two genes, tow column group variable; sc.pl.matrixplot(pbmc, var_names=['C1QA', 'CD19'], groupby='louvain', col_groups=['sampleid', 'condition']); ```; ![image](https://user-images.githubusercontent.com/10910559/147171604-183f7210-276c-4fdb-b173-477e00e636c0.png); For the `row_groups` you proposed in your hypothetical `sc.pl.heatmap` implementation, it is equivalent to the ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1876#issuecomment-999969049:27,update,updates,27,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1876#issuecomment-999969049,1,['update'],['updates']
Deployability,Hi @ivirshup we were hoping to completely remove scvi from external. Users received notice about it's deprecation in the 1.7.X releases. I suppose this can wait until 1.8,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1703#issuecomment-788515341:127,release,releases,127,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1703#issuecomment-788515341,1,['release'],['releases']
Deployability,"Hi @ivirshup!. We've discussed this in Aptos a couple of months ago. Adding an `interactive` parameter to all the scatter plots would be really useful for working with notebooks. Would you consider adding that functionality as you have a lot of experience with it? Importantly, it should be based on the restructured plotting code that @fidelram is currently working on in https://github.com/theislab/scanpy/pull/244 (we could move that branch to the scanpy repo?). Hence, this would be for post-Scanpy 1.3 and there is no great hurry. A solution that takes an `AnnData` and creates an interactive plot but totally ignores the current way scatter plots are generated and Fidel's restructured way would be what follows below (due to @NDKoehler). Hence, the task is to think about a good way of integrating this with how scatter plots are done in Scanpy (after Fidel's changes).; ```; from bokeh.plotting import figure, show, output_notebook, save#, output_file; from bokeh.models import HoverTool, value, LabelSet, Legend, ColumnDataSource; from bokeh.palettes import viridis; output_notebook(). import matplotlib as mpl. def plot_interactive(data):. colors = [; ""#%02x%02x%02x"" % (int(r), int(g), int(b)) for r, g, b, _ in 255*mpl.cm.viridis(mpl.colors.Normalize()(data.obs['CCS'].values)); ]. source = ColumnDataSource(dict(; x=data.obsm['X_umap'][:,0],; y=data.obsm['X_umap'][:,1],; color=colors,#data.obs['CCS'],; label=data.obs['Charge'],; #msize= p_df['marker_size'],; #topic_key= p_df['clusters'],; #title= p_df[u'Title'],; #content = p_df['Text_Rep']; seq=data.obs['seq'],; ccs=data.obs['CCS'],; charge=data.obs['Charge'],; )); #ax = sc.pl.umap(data, color=['Charge','CCS']); #sc.pl.umap(data, color=['CCS'], save='ccs'). title = 'T-SNE visualization of sequences'. plot_lda = figure(plot_width=800, plot_height=600,; title=title, tools=""pan,wheel_zoom,box_zoom,reset,hover,previewsave"",; x_axis_type=None, y_axis_type=None, min_border=1). plot_lda.scatter(x='x', y='y', legend='label', source=",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/253:793,integrat,integrating,793,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/253,1,['integrat'],['integrating']
Deployability,"Hi @ivirshup, ; I am part of Intel Labs and we are trying to accelerate the genomics pipeline. We are trying to push some changes into scanpy details about which are mentioned in the blog : [https://community.intel.com/t5/Blogs/Tech-Innovation/Artificial-Intelligence-AI/Intel-Labs-Accelerates-Single-cell-RNA-Seq-Analysis/post/1390715#:~:text=Intel%20Labs%20has%20accelerated%20a,of%20a%20single%20A100%20GPU.](url) ; We are facing some issues while pushing some changes in the leiden and louvain. The error states some issues with pca in the scanpy/tests/external/test_scrublet.py::test_scrublet_params when we have not made any changes for the same. Can you please help us to resolve this issue.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2409#issuecomment-1429441613:85,pipeline,pipeline,85,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2409#issuecomment-1429441613,1,['pipeline'],['pipeline']
Deployability,"Hi @ivirshup, it used to work 6 months ago. As discussed in https://github.com/saezlab/omnipath/issues/54#issuecomment-1950265944, it seems it was an error with the package `requests_cache`. Installing the latest version from GitHub solves the issue so I'll close this then, thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2861#issuecomment-1950276269:191,Install,Installing,191,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2861#issuecomment-1950276269,1,['Install'],['Installing']
Deployability,"Hi @mr-september , you have to install the prerelease version of Numba. pip install -pre numba",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1652#issuecomment-789672144:31,install,install,31,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1652#issuecomment-789672144,2,['install'],['install']
Deployability,"Hi @natalkon . If you mean to plot them as categories instead of a continuous scale, then the solution is to turn the values into `pd.Categorical` like LuckyMD mentioned. . ```; coex = (adata.raw[:,'{}'.format(gene1)].X.todense() > 0) &; (adata.raw[:,'{}'.format(gene2)].X.todense() > 0); coex_list = [item for sublist in coex.tolist() for item in sublist]; adata.obs['CoEx'] = pd.Categorical(coex_list, categories=[True, False]); ``` . Like I mentioned before, one problem is that the `True` (coexpressing) cells are not always plotted on top when plotting both categories with umap. A better way of visualising is to make use of the `groups` parameter:; ```; sc.pl.umap(adata, color='CoEx', groups=[True]); ```. It will then grey out all the `False` cells and put them in the background.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/490#issuecomment-768282049:67,continuous,continuous,67,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/490#issuecomment-768282049,1,['continuous'],['continuous']
Deployability,"Hi @pinin4fjords! I understand by integration, you mean access under the scanpy api. We try to advance the scanpy environment by modular extensions, which are packages with their own API, that also work on adata instances. This is currently what diffxpy is and there are no plans to collect all scanpy-related packages under `sc.*` as far as I am aware.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1955#issuecomment-884979935:34,integrat,integration,34,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1955#issuecomment-884979935,1,['integrat'],['integration']
Deployability,"Hi @r-reeves,; Maybe this is indeed a separate issue. `mnnpy` is indeed working on the gene expression matrix, and not on a low dimensional embedding like `FastMNN` (which is what I assume you might have been using?). You could try [Scanorama](https://github.com/brianhie/scanorama) which is a method similar to FastMNN, using a sped up algorithm and no iterative merging of batches, but a method they call ""panoramic stitching"". It has performed quite well in our [benchmark of data integration methods](https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2), and is in the scanpy ecosystem and therefore should work seamlessly in a Scanpy workflow. All of this being said, you will only get an integrated graph structure with this for scvelo, which may help a little, but won't remove the batch effect for RNA velocity calculation. scvelo doesn't currently have any batch removal in its pipeline as it is quite difficult to add as it works directly from the normalized count data and fits a model to these. @VolkerBergen has been thinking a bit about how to perform batch correction in an scvelo model, maybe he could chime in, or you could post an issue in the scvelo repo.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1289#issuecomment-734426157:484,integrat,integration,484,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289#issuecomment-734426157,3,"['integrat', 'pipeline']","['integrated', 'integration', 'pipeline']"
Deployability,"Hi @sygongcode,. Are you referring to differential expression testing between conditions? You can do that with `sc.tl.rank_genes_groups()` or in a more advanced way using `diffxpy`, which is easily integrated with `scanpy`. You can find it [here](https://github.com/theislab/diffxpy)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/821#issuecomment-529213147:198,integrat,integrated,198,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/821#issuecomment-529213147,1,['integrat'],['integrated']
Deployability,"Hi @vitkl !; that's a great idea yes, should be kept updated with most recent methods. ; Unfortuantely I don't have capacity now, do you mind opening an issue in https://github.com/theislab/scanpy-tutorials to keep as reminder? I will close this but of of course you could reference this in the tutorial repo.; Thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1574#issuecomment-757802073:53,update,updated,53,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1574#issuecomment-757802073,1,['update'],['updated']
Deployability,"Hi Alex, ; The psutil issue by updating it has apparently gone away, however later on when I call `sc.tl.louvain(adata_corrected, n_neighbors=10, resolution=1.3, recompute_graph=True)`; , I get the following error. The igraph I am using is V 0.1.11.; Many thanks; Hashem; `DeprecationWarning Traceback (most recent call last); <ipython-input-20-fb44185f2d28> in <module>(); 1 ; ----> 2 sc.tl.louvain(adata_corrected, n_neighbors=10, resolution=1.3, recompute_graph=True); 3 . /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/scanpy/tools/louvain.py in louvain(adata, n_neighbors, resolution, n_pcs, random_state, flavor, directed, recompute_pca, recompute_distances, recompute_graph, n_dcs, n_jobs, copy); 78 directed = False; 79 if not directed: logg.m(' using the undirected graph', v=4); ---> 80 g = utils.get_igraph_from_adjacency(adjacency, directed=directed); 81 if flavor == 'vtraag':; 82 import louvain. /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/scanpy/utils.py in get_igraph_from_adjacency(adjacency, directed); 41 def get_igraph_from_adjacency(adjacency, directed=None):; 42 """"""Get igraph graph from adjacency matrix.""""""; ---> 43 import igraph as ig; 44 sources, targets = adjacency.nonzero(); 45 weights = adjacency[sources, targets]. /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/igraph/__init__.py in <module>(); 6 __license__ = ""MIT""; 7 ; ----> 8 raise DeprecationWarning(""To avoid name collision with the igraph project, ""; 9 ""this visualization library has been renamed to ""; 10 ""'jgraph'. Please upgrade when convenient.""). DeprecationWarning: To avoid name collision with the igraph project, this visualization library has been renamed to 'jgraph'. Please upgrade when convenient.`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/35#issuecomment-324587457:1550,upgrade,upgrade,1550,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35#issuecomment-324587457,2,['upgrade'],['upgrade']
Deployability,"Hi Alex, thank you for your quick response! I contacted Sten over at loompy and he just pushed an update that allows for a little more flexibility when reading in loom files. It now works for me. The change he applied only applies to the loompy function `loompy.connect`, so I think I would still get this same problem when using scanpy function `read_loom`. I have the latest version of loompy. I don't think this is something that necessarily needs to be fixed on your end. It sounds like the loom format has changed a little bit, and maybe the people who made the loom file I was using did not follow all the rules when making the file. Thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/320#issuecomment-432491475:98,update,update,98,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/320#issuecomment-432491475,1,['update'],['update']
Deployability,"Hi Alex,. Thanks for fixing this promptly. I will eagerly wait for the update.; I have another query related to usage of this function but I'll create a new issue for that. Parashar",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/47#issuecomment-344538383:71,update,update,71,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/47#issuecomment-344538383,1,['update'],['update']
Deployability,"Hi Benedikt!. Yes, we could make this automatic. Let me briefly think whether this will have any unwanted side effects. There are some advantages of letting the user fully control the annotation dataframes. PS: you could also call `mammary.obs['CellType'].cat.remove_unused_categories(inplace=True)`.; PPS: The mouse atlas example has been written by a first-time-python user, according to what he stated. It can be written a lot more elegantly. We will soon update it...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/69#issuecomment-358298098:459,update,update,459,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/69#issuecomment-358298098,1,['update'],['update']
Deployability,"Hi Dan, . When you perform the umap calculation using sc.tl.umap, the default matrix used is adata.obsm['X_pca']. Given this, you wouldn't expect the same embedding the way you've done it. if instead you did this. `mapper = umap.UMAP().fit(adata.obsm['X_pca'])` . you'd likely find a very similar embedding to the ones you've shown scanpy producing. As such, I'm guessing there is problem with how you've preprocessed the data, such that the PCA space is not behaving as expected. . why don't you attempt running this notebook "" wget https://github.com/scverse/scanpy-tutorials/raw/master/pbmc3k.ipynb"" with your current installation, and let us know if you can reproduce the tutorial. Then I would suggest adding your data, changing else, and reporting back.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2386#issuecomment-1364246721:621,install,installation,621,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2386#issuecomment-1364246721,1,['install'],['installation']
Deployability,"Hi Davide,. I like the preprint and the blog post. I agree that differential expression testing deserves a classification perspective. Coincidentally, we (with @tcallies) were also working on a little paper that makes this point but used neither logistic regression nor TCCs as covariates... unfortunately, we still haven't updated our benchmarks, but I'd assume that what Lior Pachter does works best. :smile:. Anyways, yes, we should include it at some point but let's still collect some experience... Until then, people can use your two-line workaround. :wink:. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/95#issuecomment-369860454:324,update,updated,324,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/95#issuecomment-369860454,1,['update'],['updated']
Deployability,"Hi Developers,. I got the same issue when using seaborn==0.11, and fortunately I got the issue solved by replacing the annotate.py with the modified version. Howerver, I was wondering why I tried to use 'pip install scanpy' to update the scripts, it failed? Is there any other easier method to modify the script, not to locate the file and replace it?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1422#issuecomment-733442033:208,install,install,208,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1422#issuecomment-733442033,2,"['install', 'update']","['install', 'update']"
Deployability,"Hi Dylan,. This is an issue with the new h5py package, which @ivirshup already fixed on master (https://github.com/theislab/scanpy/commit/928d475a8e2d2901c5744c3afc75e2d5a1b65f29). For now, you can downgrade your h5py package to 2.9.0 using `pip install h5py==2.9.0` as a workaround.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/832#issuecomment-530529513:246,install,install,246,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/832#issuecomment-530529513,1,['install'],['install']
Deployability,"Hi Fidel,; Please note new pull request; dotplot can take vmin vmax arguments from user; <https://github.com/theislab/scanpy/pull/390>; Tim. On Tue, Dec 4, 2018 at 11:39 PM Fidel Ramirez <notifications@github.com>; wrote:. > The change is quite useful. Please go ahead and add a PR.; >; > On Wed, Dec 5, 2018 at 3:52 AM Tim Rand <notifications@github.com> wrote:; >; > > Here is a patch that fixes the above problem...; > >; > > import matplotlib.colors; > >; > > #if user defined, then use the vmax, vmin keywords, else use data to; > generate them...; > > if ('vmax' in kwds) and ('vmin' in kwds):; > > _vmax = kwds['vmax']; > > _vmin = kwds['vmin']; > > else:; > > _vmax = max(mean_flat); > > _vmin = min(mean_flat); > >; > > #normalize = matplotlib.colors.Normalize(vmin=min(mean_flat),; > vmax=max(mean_flat)); > > normalize = matplotlib.colors.Normalize(vmin=_vmin, vmax=_vmax); > >; > > I'll submit a pull request.; > >; > > —; > > You are receiving this because you are subscribed to this thread.; > > Reply to this email directly, view it on GitHub; > > <https://github.com/theislab/scanpy/issues/388#issuecomment-444339817>,; > > or mute the thread; > > <; > https://github.com/notifications/unsubscribe-auth/AEu_1WglYAlmHO-3DyNHUCRJwBtAOfskks5u1zT6gaJpZM4ZB23Z; > >; > > .; > >; >; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/issues/388#issuecomment-444388428>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AACez5ZEF7goRe3PYEixKaLT4f0cNthGks5u13gdgaJpZM4ZB23Z>; > .; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/388#issuecomment-444592024:381,patch,patch,381,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/388#issuecomment-444592024,1,['patch'],['patch']
Deployability,"Hi Guys,; Thanks for developing such a wonderful tool in python.; Do you mind to point me on how to install scanpy under anaconda environment? currently ""conda search scanpy"" doesn't find it?!; Thanks; Hashem",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/29:100,install,install,100,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/29,1,['install'],['install']
Deployability,Hi Gökcen: makes sense!. Hi Sidney: if I'm not completely mistaken: I don't think that the Jaccard metric makes sense at all for continuous ordinal variables. It would make sense if one had boolean gene expression or something like this... I guess this is the reason why you get a meaningless graph with it. I always only use euclidean distance. All other desired aspects of the metric are engineered in the preprocessing already.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/177#issuecomment-398688207:129,continuous,continuous,129,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/177#issuecomment-398688207,1,['continuous'],['continuous']
Deployability,"Hi I had this problem as well with 1.6.0 it was triggered by scanpy's test code. ```; scanpy.api (unittest.loader._FailedTest) ... ERROR. ======================================================================; ERROR: scanpy.api (unittest.loader._FailedTest); ----------------------------------------------------------------------; ImportError: Failed to import test module: scanpy.api; Traceback (most recent call last):; File ""/usr/lib/python3.9/unittest/loader.py"", line 470, in _find_test_path; package = self._get_module_from_name(name); File ""/usr/lib/python3.9/unittest/loader.py"", line 377, in _get_module_from_name; __import__(name); File ""/<<PKGBUILDDIR>>/.pybuild/cpython3_3.9_scanpy/build/scanpy/api/__init__.py"", line 27, in <module>; from . import pl; File ""/<<PKGBUILDDIR>>/.pybuild/cpython3_3.9_scanpy/build/scanpy/api/pl.py"", line 1, in <module>; from ..plotting._anndata import scatter, violin, ranking, clustermap, stacked_violin, heatmap, dotplot, matrixplot, tracksplot; ImportError: cannot import name 'stacked_violin' from 'scanpy.plotting._anndata' (/<<PKGBUILDDIR>>/.pybuild/cpython3_3.9_scanpy/build/scanpy/plotting/_anndata.py). ----------------------------------------------------------------------; Ran 1 test in 0.000s. ```. I ended up with this patch to get the tests to run successfully.; ```; --- a/scanpy/api/pl.py; +++ b/scanpy/api/pl.py; @@ -1,4 +1,7 @@; -from ..plotting._anndata import scatter, violin, ranking, clustermap, stacked_violin, heatmap, dotplot, matrixplot, tracksplot; +from ..plotting._anndata import scatter, violin, ranking, clustermap, heatmap, tracksplot; +from ..plotting._stacked_violin import stacked_violin; +from ..plotting._dotplot import dotplot; +from ..plotting._matrixplot import matrixplot; ; from ..plotting._preprocessing import filter_genes_dispersion, highly_variable_genes; ; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1397#issuecomment-765003952:1275,patch,patch,1275,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1397#issuecomment-765003952,1,['patch'],['patch']
Deployability,"Hi Ilan, thanks for your interest. One of the main advantages of Marsilea is the flexibility for layout plots and adding/removing components compared to the pre-defined visualization APIs in Scanpy. From my perspective, there could be two ways of integration: . 1) Reimplement some of the visualization APIs in scanpy using Marsilea, but we don't expose Marsilea to the user. You will always have a plot with known rendered size and fixed layout compared to directly using matplotlib. This could significantly reduce the code base complexities on the scanpy side, so less maintenance work. 2) Exposing the Marsilea API, we can create a visualization object that simulates the Marsilea API but is tailored specifically for `AnnData`. Maybe include some data transformation and aggregation functions that the user could directly apply during visualization. But this design doesn't make much difference compared to directly using Masilea as shown in the [notebook](https://scanpy.readthedocs.io/en/stable/how-to/plotting-with-marsilea.html).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2444#issuecomment-2352637693:247,integrat,integration,247,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2444#issuecomment-2352637693,1,['integrat'],['integration']
Deployability,"Hi Isaac, I've updated to v1.4.4 but I'm still getting this problem. I've finally produced a minimal test case:. ```; import scanpy as sc; sc.logging.print_versions(); #adata = sc.datasets.pbmc3k(); adata = sc.read(""orig/transpose_rsem_cell_by_gene.tsv.gz""); print(adata); adata = adata.T; print(adata); adata.raw = adata; print(adata); sc.pp.filter_cells(adata, min_genes=200); print(adata); adata = adata[adata.obs['n_genes'] < 5000, :]; print(adata); adata = adata[adata.obs['n_genes'] > 100, :]; print(adata); ```. output is:; ```. scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.3.9 numpy==1.16.4 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.10.0 python-igraph==0.7.1 ; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; Variable names are not unique. To make them unique, call `.var_names_make_unique`.; Variable names are not unique. To make them unique, call `.var_names_make_unique`.; Variable names are not unique. To make them unique, call `.var_names_make_unique`.; AnnData object with n_obs × n_vars = 60498 × 466 ; AnnData object with n_obs × n_vars = 466 × 60498 ; AnnData object with n_obs × n_vars = 466 × 60498 ; AnnData object with n_obs × n_vars = 466 × 60498 ; obs: 'n_genes'; View of AnnData object with n_obs × n_vars = 311 × 60498 ; obs: 'n_genes'; Traceback (most recent call last):; File ""/cluster/home/max/miniconda3/envs/py3/lib/python3.6/site-packages/pandas/core/series.py"", line 977, in _get_values; return self._constructor(self._data.get_slice(indexer),; File ""/cluster/home/max/miniconda3/envs/py3/lib/python3.6/site-packages/pandas/core/internals/managers.py"", line 1510, in get_slice; return self.__class__(self._block._slice(slobj),; File ""/cluster/home/max/miniconda3/envs/py3/lib/python3.6/site-packages/pandas/core/internals/blocks.py"", line 268, in _slice; return self.values[slicer]; IndexError: boolean index did not match indexed array along dimension 0; dimension is 466 but corresponding boolean di",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/728#issuecomment-516194235:15,update,updated,15,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/728#issuecomment-516194235,1,['update'],['updated']
Deployability,"Hi Jorvis! This should be very easy. Use the text file reader:; ```; adata = sc.read_text(filename).transpose(); ```; or use the general purpose reader that writes cache files automatically; ```; adata = sc.read(filename, ext='txt').transpose() # 'tab', 'data', 'tsv' mean the same; ```; see the [API docs](https://scanpy.readthedocs.io/en/latest/api/index.html). The 'tsv' file ending is not yet in the latest release, I just commited that: https://github.com/theislab/scanpy/commit/884c5f8a6a39c43aef27c7398ec9c195b977a3d3. Hope this helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/65#issuecomment-356956056:411,release,release,411,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/65#issuecomment-356956056,1,['release'],['release']
Deployability,"Hi Malte and Isaac, many thanks for this! Ah, yes that other issue was; opened after I opened this one. I did search for the error message before I; opened the ticket, but I didn't search again while the ticket was open. The easiest workaround for me is simply to not use .raw anymore, for a; pipeline, it's not really needed anyways. Yes, I can see why it's important for file backed data, I just cannot see a; use case for file backed mode either. Any useful operations on file backed; data will be too slow anyways for practical use, and anyone can get a; high-RAM machine these days on Amazon for a few hours, so I've always; wondered file backed mode exists. (sidenote: File backed data is again a; feature that sounds rather complicated to implement. As a user I love; libraries that are small, stable and don't change a lot, especially for; very foundational things like anndata. I guess it's a matter of development; philosophy here). Also, yes, it's because I don't use scanpy interactively; that I don't see the use case for views. anyhow, thanks again, also for all your work on Scanpy!. On Wed, Jul 31, 2019 at 6:27 AM Isaac Virshup <notifications@github.com>; wrote:. > I've just spent a while trying to replicate, before realizing I've seen; > this issue before over on AnnData (theislab/anndata#182; > <https://github.com/theislab/anndata/issues/182>). I've got some good and; > bad news about this. It's fixed on master, but that fix is slated to be; > release in v0.7, which has intentionally breaking changes.; >; > I find views very useful when dealing with large datasets interactively.; > They're also important for file backed data, since copies are extremely; > expensive in that case.; >; > Unlike numpy, AnnData objects should always return a view when subset. If; > you'd like to get copies, you could add a .copy() to the end of your; > subsetting statement.; >; > —; > You are receiving this because you modified the open/close state.; > Reply to this email directly, view ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/728#issuecomment-516740578:293,pipeline,pipeline,293,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/728#issuecomment-516740578,1,['pipeline'],['pipeline']
Deployability,"Hi Pawel, sorry for the confusion, yes, we just did a major revision. The package is still in the testing phase even though everything should work fine. Any comments from your side would be greatly appreciated!. Packaging will start soon. Development will happen on a development branch from now on. The notebooks are currently being migrated to another repo, links will be updated tomorrow or day after tomorrow.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/7#issuecomment-281458534:374,update,updated,374,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/7#issuecomment-281458534,1,['update'],['updated']
Deployability,"Hi Philipp,. I have updated accordingly, again no issue but the duplication and i; analysed most of them are from previous code. Regards,; Khalid. On Mon, May 20, 2019 at 5:23 PM Philipp A. <notifications@github.com> wrote:. > Hi, looks great!; >; > The only duplicated code left is that _prepare_weighted_dataframe is very; > similar to _prepare_dataframe. I think you can delete; > _prepare_weighted_dataframe and just change _prepare_dataframe so it does return; > categories, obs_tidy, categorical. Then you can change each line like categories,; > obs_tidy = _prepare_dataframe(…) to categories, obs_tidy, _ =; > _prepare_dataframe(…); >; > Other than that, there’s only few things left:; >; > 1.; >; > The tests without plots should contain assertions. I.e. in; > test_genes_ranking() you should do assert; > np.all(adata.uns['wilcoxon']['names'][:5] == ['Gene1, 'Gene2, ...]) or; > so!; > 2.; >; > For the plot tests, you need to add these lines to the test file:; >; >; > https://github.com/theislab/scanpy/blob/d979267f48607fd609954c96cd5c586b6135dc30/scanpy/tests/test_plotting.py#L3-L13; >; > And do each test like this (replace “xyz” with whatever you want):; >; > def test_xyz(image_comparer):; >; > save_and_compare_images = image_comparer(ROOT, FIGS, tol=15); >; > […]; >; > sc.pl.xyz(adata, …); >; > save_and_compare_images('xyz'); >; > This will make the tests save your plots to scanpy/tests/figures and; > compare them to the images in scanpy/test/_images. The tests will fail; > because scanpy/test/_images/xyz.png doesn’t exist. You need to copy; > the pngs from scanpy/tests/figures→scanpy/test/_images and git commit; > them.; > 3.; >; > This needs to be fixed: #644 (comment); > <https://github.com/theislab/scanpy/pull/644#discussion_r284652144>; > 4.; >; > I think the test data might be too large. @falexwolf; > <https://github.com/falexwolf> do we have a recommended size for new; > test data?; >; > @Khalid-Usman <https://github.com/Khalid-Usman> I’m sorry if you find; > ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/644#issuecomment-494098578:20,update,updated,20,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/644#issuecomment-494098578,1,['update'],['updated']
Deployability,"Hi Phillip,. I have removed issue from the pull request by the testing tool, now the; tools showed me duplications, which are mostly from other code and 1-2 from; my code. Please have a look into it. It's my first pull request and its; taking too much time :(. Thanks; Khalid. On Tue, May 14, 2019 at 9:28 PM khalid usman <khalid0491@gmail.com> wrote:. > Ok , thanks for letting me know. Please check the pull request. I have; > verified my code by keeping weights 1 and it has same values when; > observations has no weights or all weights equal to 1.; >; > I also suggest to update PCA for weighted sampled data.; >; > Thanks,; > Khalid Usman; >; > On Tue, May 14, 2019 at 7:53 PM Philipp A. <notifications@github.com>; > wrote:; >; >> You can just open a new one, I’ll close this one then 🙂; >>; >> —; >> You are receiving this because you authored the thread.; >> Reply to this email directly, view it on GitHub; >> <https://github.com/theislab/scanpy/pull/630?email_source=notifications&email_token=ABREGOFHXLS2NZRCDSLJHE3PVKR2ZA5CNFSM4HKUCBXKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGODVLHMMQ#issuecomment-492205618>,; >> or mute the thread; >> <https://github.com/notifications/unsubscribe-auth/ABREGOBMZBMFMNA6FCEMFULPVKR2ZANCNFSM4HKUCBXA>; >> .; >>; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/630#issuecomment-493836074:577,update,update,577,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/630#issuecomment-493836074,1,['update'],['update']
Deployability,"Hi Quentin,. When you plot a categorical variable for the first time, scanpy stores the colors for each category in adata.uns, that's why it is modifying your adata. For continuous variables (like your adata.X), it does not do that, hence there is no warning there.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2315#issuecomment-1256967526:170,continuous,continuous,170,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2315#issuecomment-1256967526,1,['continuous'],['continuous']
Deployability,"Hi Raphaël!. Thanks!. What do you mean with ""I just stumbled upon the same error, maybe due to the installation method."" - which error?. Regarding the typo: Hm, are you running Scanpy 0.4.4; if you run an early version, this was 'Phase' with a captical 'P'; since 0.4.3+7 it's 'phase'; like all the other annotations. Cheers,; Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/82#issuecomment-368964431:99,install,installation,99,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/82#issuecomment-368964431,1,['install'],['installation']
Deployability,"Hi Sarah,; thanks for the note and sorry about that; would you install a stable release from PyPi in the meanwhile `pip install scanpy`? I'm currently rewriting quite substantial parts and yes, this is clearly a bug I caused on the weekend; testing will also be more extensive in the future so that this stuff does happen anymore. This kind of stuff will also not happen on master branch in the future; but this rewriting goes along with building some [documentation](https://scanpy.readthedocs.io) and this builds from master... ; Cheers,; Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/32#issuecomment-324116498:63,install,install,63,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/32#issuecomment-324116498,3,"['install', 'release']","['install', 'release']"
Deployability,"Hi Scanpy devs. Sorry, this isn't an enhancement request, just wan't sure where this fitted. . Just a quick one- when's the next Scanpy release (1.6.0?) scheduled for?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1365:136,release,release,136,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1365,1,['release'],['release']
Deployability,"Hi Scanpy team!. After facing the issue with duplicated gene symbols again for the n-th time, I realised that one of the best solutions for renaming duplicates would likely be to do the following `'DuplicatedName-ENSEMBL_ID'` rather than just adding an order-dependent number `'DuplicatedName-1'` that can differ between dataset from different papers - preventing correct matching when integrating datasets which in turn essentially requires deleting duplicated genes. . What do you think in general?. Would it be possible to add support for this with interface like `var_names_make_unique(unique_column='ENSEMBL')`?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1719:386,integrat,integrating,386,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1719,1,['integrat'],['integrating']
Deployability,"Hi Scott,. sure, I remember! :smile: For some reason, I forgot to mention you personally in the [release notes](http://scanpy.readthedocs.io/en/latest/#version-1-1-may-31-2018), is now fixed. Sorry about that! . You could add MAGIC as a preprocessing similar to DCA in the imputation section: http://scanpy.readthedocs.io/en/latest/api/index.html#preprocessing-pp. In terms of code, I would also adapt the conventions of DCA: https://github.com/theislab/scanpy/blob/master/scanpy/preprocessing/dca.py. We had some discussions on how to do this best: https://github.com/theislab/scanpy/issues/142 and https://github.com/theislab/scanpy/pull/186. If you think you have better conventions, happy to adopt these. DCA is also not yet released... Best,; Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/187#issuecomment-402263798:97,release,release,97,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/187#issuecomment-402263798,2,['release'],"['release', 'released']"
Deployability,"Hi Sergei,. Thank you very much for your fast reply. Do you mean I can still use the latest version of scanpy but installing a lower version of umap?. I tried different versions of scanpy, including pastiest, stable, 1.4.5, 1.4.5post3, 1.4.4post1... They seem to either have different error messages or packages not compatible. Do you know which version of the scanpy has it fixed?. Thank you for your kind help. Best regards,. Lirong. 获取 Outlook for iOS<https://aka.ms/o0ukef>; ________________________________; 发件人: Sergei R. <notifications@github.com>; 发送时间: Wednesday, April 22, 2020 12:44:36 PM; 收件人: theislab/scanpy <scanpy@noreply.github.com>; 抄送: plrlhb12 <lrpeng@hotmail.com>; Mention <mention@noreply.github.com>; 主题: Re: [theislab/scanpy] Issue with ingest (#1181). Hi, @plrlhb12<https://github.com/plrlhb12> .; Yes, this is a known problem. The easiest fix for now is to use umap 0.3.9 instead of 0.4.1.; You can also install scanpy from github where it is fixed or just wait for a new scanpy release. ―; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://github.com/theislab/scanpy/issues/1181#issuecomment-617895856>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AKHCBZKH4TYT5672QNGFW33RN4NHJANCNFSM4MNX44PA>.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1181#issuecomment-617911861:114,install,installing,114,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1181#issuecomment-617911861,3,"['install', 'release']","['install', 'installing', 'release']"
Deployability,"Hi Sidney,. Thanks for the pull request. igraph and louvain are kind of heavy dependencies (e.g. takes long time to compile them and they're not easily available via PyPI for all platforms etc.), this is why they are excluded from requirements file. It's written in the [installation document](https://scanpy.readthedocs.io/en/latest/installation.html) that these need to be installed manually. Also, there should be proper error messages stating that these must be installed separately when their functionality is needed for a function in scanpy and cannot be found. Did you get any other error regarding these packages?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/176#issuecomment-397543101:271,install,installation,271,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/176#issuecomment-397543101,4,['install'],"['installation', 'installed']"
Deployability,"Hi Thank you for getting back to me. I updated it and now when I try to import scanpy as sc I get the following error:. LookupError Traceback (most recent call last); ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/anndata/__init__.py in <module>; 89 ; ---> 90 __version__ = get_version(root="".."", relative_to=__file__); 91 del get_version. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/setuptools_scm/__init__.py in get_version(root, version_scheme, local_scheme, write_to, write_to_template, relative_to, tag_regex, fallback_version, fallback_root, parse, git_describe_command); 142 config = Configuration(**locals()); --> 143 return _get_version(config); 144 . ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/setuptools_scm/__init__.py in _get_version(config); 146 def _get_version(config):; --> 147 parsed_version = _do_parse(config); 148 . ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/setuptools_scm/__init__.py in _do_parse(config); 117 ""https://github.com/user/proj/archive/master.zip ""; --> 118 ""use git+https://github.com/user/proj.git#egg=proj"" % config.absolute_root; 119 ). LookupError: setuptools-scm was unable to detect version for '/Users/kabitabaral/miniconda3/envs/scanpy/lib/python3.6/site-packages'. Make sure you're either building from a fully intact git repository or PyPI tarballs. Most other sources (such as GitHub's tarballs, a git checkout without the .git folder) don't contain the necessary metadata and will not work. For example, if you're using pip, instead of https://github.com/user/proj/archive/master.zip use git+https://github.com/user/proj.git#egg=proj. During handling of the above exception, another exception occurred:. ModuleNotFoundError Traceback (most recent call last); ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/anndata/compat.py in pkg_version(package); 56 try:; ---> 57 from importlib.metadata import version as v; 58 except ImportError:. ModuleNotFoundError: No module named 'importlib.metadata'. During handling of",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1154#issuecomment-611202845:39,update,updated,39,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1154#issuecomment-611202845,2,"['Configurat', 'update']","['Configuration', 'updated']"
Deployability,"Hi all!. I just wanted to jump in with @sophietr and say that implementing a cell cycle classification function like Seurat's [CellCycleScoring](https://github.com/satijalab/seurat/blob/master/R/scoring.R) function would be a nice addition to the preprocessing options. Would be valuable to keep an eye on in downstream exploration and could then be easily regressed out if needed. Also, do you guys have any opinions about the inclusion of imputation/smoothing strategies? I've been messing around with including it in analysis pipelines, but still haven't really settled on when to include them. If there's interest, [MAGIC](https://github.com/pkathail/magic) seems like a great option and is currently implemented in Python.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/45#issuecomment-356611882:529,pipeline,pipelines,529,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/45#issuecomment-356611882,1,['pipeline'],['pipelines']
Deployability,"Hi all, I have some pseudo counts data, which containing value like 0.5, and if I run sc.pp.filter_cells based on this dataset, the filtered number of cells is very low. I wonder if the codes of sc.pp.filter_cells are updated or not, and how to handle such pseudo counts scRNA-seq data based on scanpy. Thanks a lot. The dataset I used is https://portal.hubmapconsortium.org/browse/dataset/fd57a928d9f3cee7e95d284f1d5b9935",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2399:218,update,updated,218,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2399,1,['update'],['updated']
Deployability,"Hi all,. I am trying to use ScanPy for integrating multiple scRNA-Seq samples (~20). Doing so that I can look at RNA Velocity with SCVelo, and want to use MNN as I got good batch effect removal previously in monocle using MNN. Is it true - as stated above, that the current implementation of mnncorrect with ScanPy is only operating on expression values? I have run through a ScanPy MNN [tutorial ](https://nbisweden.github.io/workshop-scRNAseq/labs/compiled/scanpy/scanpy_03_integration.html) provided by NBI Sweden. The results are improved, but it doesn't appear to work as well as in monocle - some separation by batch is still going on. . I'm wondering what the difference might be? Whether it could be due to the difference in PCA (multi-batch), or the actual MNN / batch effect removal step. Alternatively, I could use the corrected expression matrix, and add the UMAP coordinates/clusters from monocle, although I wonder if this is advisable. . If you have any info please let me know, or if I should raise a separate issue etc.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1289#issuecomment-734319967:39,integrat,integrating,39,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289#issuecomment-734319967,1,['integrat'],['integrating']
Deployability,"Hi all,. I am trying to use `ingest` to integrate different datasets.; I found a couple of issues. - `ingest` requires that the `var_names` are the same in the reference and the new object. I can select the intersection between the datasets; however, it requires that the genes are in the same order `if not ref_var_names.equals(new_var_names)`. I think this `if` could be modified using `set` (e.g., `len(set(ref_var_names).difference(set(new_var_names))) == 0`). I tried to order the `.var` dataframe, but the `.X` remains the same. In such a way, the expression of the genes does not correspond to the correct one. I can generate a dataframe and recreate the `.X`, but it could be very nice that the `.X` will be modified according to `.var` or `.obs` modifications (i.e., ordering). . - although it is possible to set `embedding_method=umap`, `ingest` requires the PCA components. I used autoencoders instead of PCA, and I cannot run `ingest` only considering the UMAP. Can you fix it? . Thank you in advance.; Best,; Andrea",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1128:40,integrat,integrate,40,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1128,1,['integrat'],['integrate']
Deployability,"Hi all,. I have updated my scanpy to version 1.4 (was working on 1.3.7 before) and did not get the same filtering output using sc.pp.filter_ working with the same input dataset (10X). By running in sc1.3.7: sc.pp.filter_genes(adata, min_counts=2); -> 267 genes were filtered out and I was able to follow up on my analysis until the end. However, after switching to the new version, I could not get any filtering anymore. By scaling up, the first filtering I got was with a min of counts of 4 (sc.pp.filter_genes(adata, min_counts=4)); ""filtered out 655 genes that are detected in less than 4 counts"". Not sure what is going on there and which setting I should use then. Any feedback will be more than appreciated. Thank you",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/501:16,update,updated,16,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/501,1,['update'],['updated']
Deployability,"Hi all,. I recently installed the newest version of scanpy:; ```; scanpy==1.4.5.post1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.7.1+4.bed07760 louvain==0.6.1; ```. And after this, I could no longer run a tSNE, while this worked fine before (scanpy==1.4.4.post1). I have not changed anything in my data or my code. ```pytb; TypeError Traceback (most recent call last); <ipython-input-54-e62d5f8d460c> in <module>; ----> 1 sc.tl.tsne(adata). ~\Anaconda3\envs\UMCU\lib\site-packages\scanpy\tools\_tsne.py in tsne(adata, n_pcs, use_rep, perplexity, early_exaggeration, learning_rate, random_state, use_fast_tsne, n_jobs, copy); 108 if X_tsne is None:; 109 from sklearn.manifold import TSNE; --> 110 from . import _tsne_fix # fix by D. DeTomaso for sklearn < 0.19; 111 ; 112 # unfortunately, sklearn does not allow to set a minimum number. ~\Anaconda3\envs\UMCU\lib\site-packages\scanpy\tools\_tsne_fix.py in <module>; 32 verbose: int = 0,; 33 args: Iterable[Any] = (),; ---> 34 kwargs: Mapping[str, Any] = MappingProxyType({}),; 35 ) -> Tuple[np.ndarray, float, int]:; 36 """"""\. ~\Anaconda3\envs\UMCU\lib\typing.py in __getitem__(self, parameters); 1338 "" Got %.100r."" % (args,)); 1339 parameters = (tuple(args), result); -> 1340 return self.__getitem_inner__(parameters); 1341 ; 1342 @_tp_cache. ~\Anaconda3\envs\UMCU\lib\typing.py in inner(*args, **kwds); 680 except TypeError:; 681 pass # All real errors (not unhashable args) are raised below.; --> 682 return func(*args, **kwds); 683 return inner; 684 . ~\Anaconda3\envs\UMCU\lib\typing.py in __getitem_inner__(self, parameters); 1348 return super().__getitem__((_TypingEllipsis, result)); 1349 msg = ""Callable[[arg, ...], result]: each arg must be a type.""; -> 1350 args = tuple(_type_check(arg, msg) for arg in args); 1351 parameters = args + (result,); 1352 return super().__getitem__(parameters). ~\Anaconda3\envs\UMCU\lib\typing.py in <genexpr>(.0); 1348 return",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1067:20,install,installed,20,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1067,1,['install'],['installed']
Deployability,"Hi all,. Sorry I sent a PR(https://github.com/theislab/scanpy/pull/1271) without reading any of these, it's my bad. Some thoughts are as follows:. - I think it's fairly straightforward to check for R dependencies in runtime, please see the PR for more info. - For Travis, I used Ubuntu packages for base R installation and then rest of the R deps are installed by the Travis user in home directory, which is cached. apt-install R installation takes around a minute. This is really hard to reduce, I think. . - After the caching, the installation of sctransform itself take around 15-20sec. This can even be reduced to zero if I check whether it's already installed. See https://travis-ci.org/github/theislab/scanpy/jobs/697070834 for a better breakdown. You can compare this with an existing test run e.g. https://travis-ci.org/github/theislab/scanpy/jobs/696758553. - sctransform test overhead is around 30sec, which can also be reduced. Overall, it adds 4 minutes to the travis test time. I don't know exactly where the remaining difference comes from. - However, if we keep adding more Ubuntu and/or R packages in the scanpy travis, it can get a bit bloated. Even if things are cached, for some reason, there is a 45-50 second cache upload overhead which is not negligible.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1068#issuecomment-642835553:306,install,installation,306,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1068#issuecomment-642835553,6,['install'],"['install', 'installation', 'installed']"
Deployability,"Hi all,; I'm having a trouble in running a code: ; sc.tl.louvain(adata); So, when I try to run the code, it has an error saying that; ERROR: Failed building wheel for louvain; I tried to install louvain in anaconda prompt, and I can't install it.; When I use:; pip install louvain; to install louvain, I have an error that . ```pytb; ERROR: Command errored out with exit status 1:; 'c:\users\prince and jacky\anaconda3\python.exe' \; -u \; -c '; import sys, setuptools, tokenize; sys.argv[0] = "".../louvain/setup.py""; __file__="".../louvain/setup.py""; f=getattr(tokenize, ""open"", open)(__file__); code=f.read().replace(""\r\n"", ""\n""); f.close(); exec(compile(code, __file__, ""exec"")); ' \; install \; --record '.../install-record.txt' \; --single-version-externally-managed \; --compile; Check the logs for full command output.; ```. I also tried to install using different codes such as:. ```bash; conda install -c conda-forge louvain; ```. There's an error saying that:; PackagesNotFoundError: The following packages are not available from current channels:. - louvain. Can anyone help me with solving this issue? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/786:187,install,install,187,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/786,8,['install'],"['install', 'install-record']"
Deployability,"Hi all,; any update on this? I'm on version 1.4 and even if in the documentation the color parameter is defined as string or list of strings, I'm still unable to pass to the scatter method a list of strings as value.; Thanks",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/311#issuecomment-463299529:13,update,update,13,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/311#issuecomment-463299529,1,['update'],['update']
Deployability,"Hi all. I was looking through the `_rank_genes_groups` function and noticed that the fold-change calculations are based on the means calculated by `_get_mean_var`. The only problem with this is that (usually) the expression values at this point in the analysis are in log scale, so we are calculating the fold-changes of the log1p count values, and then further log2 transforming these fold changes. I know that different programs do it differently, but I think it's more intuitive to convert the matrix back to counts, calculate the fold change, and then report the log2 fold change. Any thoughts?. For the actual differential testing, I think it's ok to run the tests on the log1p transformed data, as that seems to be the norm for many pipelines using the types of tests we are using. However, some pipelines do use raw count data, which might be interesting to implement if we want. Either way, I think it's a little unintuitive to report a log2 fold change of log expression values. I can submit a pull request to implement this if this is something you agree with, and can add a parameter to let the user decide whether to use log-transformed or raw-count data. Let me know what you think!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/517:739,pipeline,pipelines,739,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517,2,['pipeline'],['pipelines']
Deployability,"Hi all.; I've been running into issues installing scanpy on M1 Mac (Apple Silicone) hardware. (It looks like something is wrong with numba?) I'm sure this is not new to you. I've seen a few issues on that here and there but it's not clear to me at this time:; 1. whether there is any workaround to getting this to work? (I'm using M1 homebrew); 2. where can I track the status of the fix for this? . The lack of scanpy is quite debilitating in my daily workflows, so it would be awesome if there is a way to get it to work even temporarily while waiting for the fix. Thanks ahead!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2237:39,install,installing,39,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2237,1,['install'],['installing']
Deployability,"Hi all:. it seems there is a problem on the batch correction with bbknn. It gives an error at the compute_connectivities_umap() step of bbknn. Version of packages:. ```; scanpy==1.4.2 anndata==0.6.19 umap==0.3.8 numpy==1.15.4 scipy==1.2.1; pandas==0.24.2 scikit-learn==0.20.3 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 ; ```. Cmds:. ```py; import scanpy.external as sce; sce.pp.bbknn(adata, batch_key='sample', copy=False); ```. Error info:. ```pytb; sce.pp.bbknn(adata, batch_key='sample', copy=False); computing batch balanced neighbors; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-34-5b7ebd13c9e6> in <module>; 1 # Correct; 2 #sc.pp.pca(adata, n_comps=50, svd_solver='arpack'); ----> 3 sce.pp.bbknn(adata, batch_key='sample', copy=False, n_pcs=15). ~/miniconda3/lib/python3.6/site-packages/scanpy/preprocessing/_bbknn.py in bbknn(adata, batch_key, save_knn, copy, **kwargs); 82 except ImportError:; 83 raise ImportError('Please install bbknn: `pip install bbknn`.'); ---> 84 return bbknn(**params, **kwargs). ~/miniconda3/lib/python3.6/site-packages/bbknn/__init__.py in bbknn(adata, batch_key, save_knn, copy, **kwargs); 215 batch_list = adata.obs[batch_key].values; 216 #call BBKNN proper; --> 217 bbknn_out = bbknn_pca_matrix(pca=pca,batch_list=batch_list,save_knn=save_knn,**kwargs); 218 #optionally save knn_indices; 219 if save_knn:. ~/miniconda3/lib/python3.6/site-packages/bbknn/__init__.py in bbknn_pca_matrix(pca, batch_list, neighbors_within_batch, n_pcs, trim, approx, n_trees, use_faiss, metric, bandwidth, local_connectivity, save_knn); 272 	dist, cnts = compute_connectivities_umap(knn_indices, knn_distances, knn_indices.shape[0], ; 273 knn_indices.shape[1], bandwidth=bandwidth,; --> 274 											 local_connectivity=local_connectivity); 275 #optional trimming; 276 if trim:. TypeError: compute_connectivities_umap() got an unexpected keyword argument 'bandwidth'; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/632:1036,install,install,1036,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/632,2,['install'],['install']
Deployability,"Hi and sorry for the very late response!. 1. Hm, this seems to be related to your matplolib version and I've never seen this before. The code for the plotting function is [here](https://github.com/theislab/scanpy/blob/a17e9f4bac124547fec1c373da8d12b679c84bcc/scanpy/plotting/preprocessing.py#L11-L46). Try installing matplotlib 2.0.0. 2. The warning can be ignored, in my experience. Soon, we'll catch that case explicitly.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/39#issuecomment-333509613:306,install,installing,306,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/39#issuecomment-333509613,1,['install'],['installing']
Deployability,"Hi everyone,. Seeing how many new single cell and spatial tools are being developed in Python, and how we are increasingly using it in general and scanpy in particular, at saezlab we decided to re-implement our tools to estimate pathways and Transcription factor (TF) activity ([Dorothea](https://saezlab.github.io/dorothea/) and [Progeny](https://saezlab.github.io/progeny/)) in it. Here's a first draft in Python of our tools:; https://github.com/saezlab/dorothea-py; https://github.com/saezlab/progeny-py. Our tools take gene expression as input and generate matrices of TF and pathway activities. They can be understood as: ; 1) Prior-knowledge dimensionality reduction methods (`obsm`). Examples of usage:; 	* Used as input for NN; 	* Used as input for integration methods; 2) New data assays (`X`). Examples of usage:; 	* Plot feature activities in projections such as PCA or UMAP; 	* Plot feature activities in heat-maps, clustermaps, violin plots, etc; 	* Differences between groups can be modeled to find significant differences. Because of this duality, the integration of our tools into scanpy is not straightforward. If we store the activities in `obsm` they can be used as a dimensonality reduction embedding but then we lose acces to all the fantastic plotting functions based on `X`. Then if we add add our activities to `X`, they have a very different distribution than gene expression plus there would be an overlap of names between genes and TFs. A solution to this would be to have a separate `.layer` to store this matrices but layers must contain the same dimensions as `X`. Another workaround would be to store it in `.raw` but then we force the user to use remove its previous contents, plus it is used in some methods as default which could cause problems. . What would be a smart solution to integrate our tools in your universe?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1724:758,integrat,integration,758,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1724,3,['integrat'],"['integrate', 'integration']"
Deployability,"Hi everyone,. a while back, @giovp asked me to create a pull request that integrates analytical Pearson residuals in scanpy. We already discussed a bit with @LuckyMD and @ivirshup over at berenslab/umi-normalization#1 how to structure it, and now I made a version that should be ready for review. As discussed earlier, this pull request implements two core methods:; - `sc.pp.normalize_pearson_residuals()`, which applies the method to `adata.X`. Overall, the function is very similar in structure to `sc.pp.normalize_total()` (support for layers, inplace operation etc).; - `sc.pp.highly_variable_genes(flavor='pearson_residuals')`, which selects genes based on Pearson residual variance. The ""inner"" function `_highly_variable_pearson_residuals()` is structured similarly to `_highly_variable_seurat_v3()` (support for multiple batches, median ranks for tie breaking). It includes the `chunksize` argument to allow for memory-efficient computation of the residual variance. We discussed quite a lot how to implement a third function that would bundle gene selection, normalization by analytical residuals and PCA. This PR includes the two options that emerged at the end of that discussion, so now we have to choose ;). - `sc.pp.recipe_pearson_residuals()` which does HVG selection and normalization both via Pearson residuals prior to PCA; - `sc.pp.normalize_pearson_residuals_pca()` which applies any HVG selection if the user previously added one to the `adata` object, and then normalizes via Pearson residuals and does PCA. Both functions retain the raw input counts as `adata.X` and add fields for PCA/Normalization/HVG selection results (or return them) as applicable, most importantly the `X_pca` in `adata.obsm['pearson_residuals_X_pca']`. I hope this addresses some of the issues we discussed over at the other repo in a scanpy-y way. Let me know what you think and where you think improvements are needed!. Cheers, Jan.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1715:74,integrat,integrates,74,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715,1,['integrat'],['integrates']
Deployability,"Hi everyone,; I am using pip3 to install scanpy, this is the error message:. <details>. ```pytb; File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 94, in find_data_files; TypeError: must be str, not list. ----------------------------------------; Failed building wheel for scanpy; Running setup.py clean for scanpy; Failed to build scanpy; Installing collected packages: scanpy, decorator; Running setup.py install for scanpy ... error; Complete output from command /global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/bin/python -u -c ""import setuptools, tokenize;__file__='/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /tmp/xs-ttgump/pip-record-v4z7bmhr/install-record.txt --single-version-externally-managed --compile --user --prefix=:; running install; running build; running build_py; creating build; creating build/lib; creating build/lib/scanpy; copying scanpy/logging.py -> build/lib/scanpy; copying scanpy/exporting.py -> build/lib/scanpy; copying scanpy/_version.py -> build/lib/scanpy; copying scanpy/utils.py -> build/lib/scanpy; copying scanpy/__init__.py -> build/lib/scanpy; copying scanpy/settings.py -> build/lib/scanpy; copying scanpy/readwrite.py -> build/lib/scanpy; creating build/lib/scanpy/tools; copying scanpy/tools/dpt.py -> build/lib/scanpy/tools; copying scanpy/tools/paga.py -> build/lib/scanpy/tools; copying scanpy/tools/louvain.py -> build/lib/scanpy/tools; copying scanpy/tools/_utils.py -> build/lib/scanpy/tools; copying scanpy/tools/pca.py -> build/lib/scanpy/tools; copying scanpy/tools/umap.py -> build/lib/scanpy/tools; copying scanpy/tools/sim.py -> build/lib/scanpy/tools; copying scanpy/tools/tsne.py -> build/lib/scanpy/tools; copying scanpy/tools/__init__.py -> build/lib/scanpy/tools; copyi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/148:33,install,install,33,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148,6,"['Install', 'install']","['Installing', 'install', 'install-', 'install-record']"
Deployability,"Hi guys, I've been following this thread and it's been quiet recently :) wondering if there's any updates on incorporating ScTransform on Scanpy. Thanks!! 🙏🏼",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1643#issuecomment-853445582:98,update,updates,98,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1643#issuecomment-853445582,1,['update'],['updates']
Deployability,"Hi guys,. I would like to filter cells by an arbitrary threshold set on the expression of a specific gene (elav) at the very begging of the pipeline. I am new to scanpy and relatively new to python. . this is what I do at the begining but I am having trouble getting it to work (see third command) with setting the corresponding threshold:. #filtering by n_genes and percent mito; adata = adata[adata.obs['n_genes'] < 3500, :]; adata = adata[adata.obs['percent_mito'] < 0.5, :]. #filtering by elav; adata = adata[adata.var['elav'] > 0.5, :]. This last part doesn't seem to work. All help appreciated!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/599:140,pipeline,pipeline,140,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/599,1,['pipeline'],['pipeline']
Deployability,"Hi guys,. Sorry I am new to github, I just posted this a comment on a closed thread (#530) and wasn't sure if that would be seen or not so I am just posting it up in as a new issue, just in case. I am having trouble running the rank_gene_groups test using wilcoxon, every time I try it throws a math domain error. I think this might be a duplicate of #566. As with the OP in #566 I have no trouble running the rank_genes_groups using t-test or logreg, the problem only arises when using method='wilcoxon'. For the example provided below `adata` is using one of our real data sets and I am using custom clusters but I have the same problem when replicating the tutorial workflow. My colleague has had the same experience when trying to work through the tutorial on his system, again using the most recent release of Scanpy. I've made sure 'log_transformed' was being applied to include the #519 fix provided by **a-munoz-rojas** in the hope that this might help but no such luck, I get the same error either way. Any ideas on how to solve this?. Here is what I ran:. ```; sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True); sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False); ```. And here is the resulting error:. ```; ValueError Traceback (most recent call last); <ipython-input-117-a5ba74ea872c> in <module>; ----> 1 sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True); 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ~\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, log_transfo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/706:804,release,release,804,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/706,1,['release'],['release']
Deployability,"Hi guys,. Sorry to re-open the thread but I am also getting the same error as described by the OP above with the latest release of Scanpy (v1.4.3). . As with #566 I have no trouble running the rank_genes_groups using t-test or logreg, the problem only arises when using method='wilcoxon'. For the example provided below `adata` is using one of our real data sets and I am using custom clusters but I have the same problem when replicating the tutorial workflow. My colleague has had the same experience when trying to work through the tutorial on his system, again using the most recent release of Scanpy. I've made sure 'log_transformed' was being applied to include the #519 fix provided by **a-munoz-rojas** in the hope that this might help but no such luck, I get the same error either way. Any ideas?. Here is what I ran:. ```; sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True); sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False); ```. And here is the resulting error:. ```; ValueError Traceback (most recent call last); <ipython-input-117-a5ba74ea872c> in <module>; ----> 1 sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True); 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ~\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, log_transformed, **kwds); 367 ; 368 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(; --> 369 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)); 370 scores[np.isnan(scores)] = 0; 371 pvals = 2 * stats.distribut",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/530#issuecomment-505305611:120,release,release,120,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/530#issuecomment-505305611,2,['release'],['release']
Deployability,"Hi scanpy team, any updates on reviewing this PR? Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1085#issuecomment-608561597:20,update,updates,20,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1085#issuecomment-608561597,1,['update'],['updates']
Deployability,"Hi thank you so much for you reply. Initially I didn't understand your former statement, but looking at the features table, I understand what you mean now, it's strange that cellranger mixed species alignment adds mm10 or GRCh38 infront of the gene symbols as well which wasn't letting it find the mito-genes on following the scanpy pipeline at the pre-filtering mito genes steps.; ![Screenshot 2023-01-05 at 15 41 09](https://user-images.githubusercontent.com/122033428/210822795-0eb1f9c8-cf9f-4949-a3cf-33dd07a20b03.png); ![Screenshot 2023-01-05 at 15 43 50](https://user-images.githubusercontent.com/122033428/210822805-3b292da8-35d0-4e4a-a600-12eeff38ac7b.png); .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2393#issuecomment-1372394524:333,pipeline,pipeline,333,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2393#issuecomment-1372394524,1,['pipeline'],['pipeline']
Deployability,"Hi there! Thanks for adding the ingest method to scanpy!; I was wondering what would be the suggested approach when the reference data contains batch effects that should be removed before actually performing the asymmetric integration with a query dataset. I tried to use the neighbors structure returned by BBKNN (which correctly adjusts for batch effects), but the 'metric' object is missing. Here the error:. ```; KeyError Traceback (most recent call last); <ipython-input-22-a805d117788e> in <module>; ----> 1 sc.tl.ingest(adata, adata_ref, obs='time', embedding_method='umap'). /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, inplace, **kwargs); 115 labeling_method = labeling_method * len(obs); 116 ; --> 117 ing = Ingest(adata_ref); 118 ing.fit(adata); 119 . /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in __init__(self, adata); 268 ; 269 if 'neighbors' in adata.uns:; --> 270 self._init_neighbors(adata); 271 ; 272 if 'X_umap' in adata.obsm:. /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in _init_neighbors(self, adata); 229 else:; 230 dist_args = (); --> 231 dist_func = named_distances[adata.uns['neighbors']['params']['metric']]; 232 self._random_init, self._tree_init = make_initialisations(dist_func, dist_args); 233 self._search = make_initialized_nnd_search(dist_func, dist_args). KeyError: 'metric'. ```; I'm running scanpy version 1.4.5.post2. Any help would be highly appreciated!! Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1108:223,integrat,integration,223,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1108,1,['integrat'],['integration']
Deployability,"Hi there! Thanks for such a great tool. We are working with a group of people at EBI, Sanger, U. of Freiburg, Earlham (Norwich), the US and Australia in trying to bring different single cell analysis tools to Galaxy and other workflow environments. For tools like Seurat, SC3 or Scanpy, which are normally used as libraries, we are writing an scripting layer for each of these to facilitate their use directly from the shell for well defined functionality (to be called then from whatever workflow environment people want to use). You can get an idea based on what we have here for Seurat for instance https://github.com/ebi-gene-expression-group/r-seurat-scripts. We normally make a conda package out of this called \<tool\>-scripts. This probably fits well in the initial development phase where we want to be agile in the generation of these, but in the mid and definitely longer term, we would really like to contribute those scripts to the main tool repos, so that they are distributed and installed with them. Would you welcome such contribution (a set of scripts for high level functionality that can be used as executables from a shell) in this git repo?. This is where we are discussing things a bit with this community:; https://github.com/galaxyproject/tools-iuc/issues/2057. Current WIP for scanpy scripts (see feature branches):; https://github.com/ebi-gene-expression-group/scanpy-scripts/tree/feature/read10x",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/281:995,install,installed,995,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/281,1,['install'],['installed']
Deployability,"Hi there!. I am having a similar issue when trying to install Scanpy using conda in Ubuntu. I have uninstalled and installed Anaconda so it is the newest version and still amb getting the same error. Pip install though works well. I was wondering if you could help me with the issue as it is vry interesting for me to install it with conda. The output when installing is the following one:. > Collecting package metadata (current_repodata.json): done; > Solving environment: failed with initial frozen solve. Retrying with flexible solve.; > Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.; > Collecting package metadata (repodata.json): done; > Solving environment: failed with initial frozen solve. Retrying with flexible solve.; > Solving environment: - ; > Found conflicts! Looking for incompatible packages.; > This can take several minutes. Press CTRL-C to abort.; > failed ; > ; > UnsatisfiableError: The following specifications were found to be incompatible with each other:; > ; > Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:; > ; > - feature:/linux-64::__glibc==2.31=0; > - feature:|@/linux-64::__glibc==2.31=0; > ; > Your installed version is: 2.31",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1298#issuecomment-1008789859:54,install,install,54,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1298#issuecomment-1008789859,6,['install'],"['install', 'installed', 'installing']"
Deployability,"Hi there, I am having the same issue as above. I have tried the fix that @Xparx has provided but it yields more problems. See the below error which I am now receiving:. ```; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); TypeError: float() argument must be a string or a number, not 'csc_matrix'. The above exception was the direct cause of the following exception:. ValueError Traceback (most recent call last); <ipython-input-48-abf5bf78cb77> in <module>; ----> 1 sc.pl.dpt_timeseries(adata_HVG). ~/.conda/envs/python3/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py in dpt_timeseries(adata, color_map, show, save, as_heatmap); 159 if as_heatmap:; 160 # plot time series as heatmap, as in Haghverdi et al. (2016), Fig. 1d; --> 161 timeseries_as_heatmap(; 162 adata.X[adata.obs['dpt_order_indices'].values],; 163 var_names=adata.var_names,. ~/.conda/envs/python3/lib/python3.8/site-packages/scanpy/plotting/_utils.py in timeseries_as_heatmap(X, var_names, highlights_x, color_map); 197 _, ax = pl.subplots(figsize=(1.5 * 4, 2 * 4)); 198 ax.imshow(; --> 199 np.array(X, dtype=np.float_),; 200 aspect='auto',; 201 interpolation='nearest',. ValueError: setting an array element with a sequence.; ```. I thought that this might be something to do with the fact that the `np.ones` object is a numpy array instead of a pandas series so I tried substituting this with the line `adata.uns['dpt_changepoints'] = pd.Series(np.ones(adata.obs['dpt_order_indices'].shape[0] - 1))` instead, but this still yielded the same error. Thanks in advance!. Update: I just tried to run this command having used `branching=1' in my analysis and not performing the above correction (even though I know it's inappropriate for my particular system, branching=0 is what I want to use) and it still yielded the same error. As such I think perhaps this could be something independent of the above issue.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/409#issuecomment-719627140:1627,Update,Update,1627,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/409#issuecomment-719627140,1,['Update'],['Update']
Deployability,"Hi there,. I was trying do dig down to understand the problem in #559 , and I found out that in my ```plotting/_anndata.py``` [these lines](https://github.com/theislab/scanpy/blob/f33924011f7d0a7924fada933e1a20d7b5ceaac3/scanpy/plotting/_anndata.py#L828-L837) and all the ones related to ```standard_scale``` are missing. So I created a new conda environment and tried to install a new version of scanpy, but this did not solve the issue (i.e. the problem is not with my old environment) as these lines are still missing. . When I tried to replace the file and re-run my heatmap I got a different error:. ```; ---------------------------------------------------------------------------; ModuleNotFoundError Traceback (most recent call last); <ipython-input-5-49e0357ed731> in <module>; ----> 1 sc.pl.matrixplot(pbmc, marker_genes, groupby='bulk_labels', dendrogram=True, standard_scale='var'). /anaconda3/envs/test/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in matrixplot(adata, var_names, groupby, use_raw, log, num_categories, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, standard_scale, swap_axes, show, save, **kwds); 1644 var_names=var_names,; 1645 var_group_labels=var_group_labels,; -> 1646 var_group_positions=var_group_positions); 1647 ; 1648 var_group_labels = dendro_data['var_group_labels']. /anaconda3/envs/test/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in _reorder_categories_after_dendrogram(adata, groupby, dendrogram, var_names, var_group_labels, var_group_positions); 2332 """"""; 2333 ; -> 2334 key = _get_dendrogram_key(adata, dendrogram, groupby); 2335 ; 2336 dendro_info = adata.uns[key]. /anaconda3/envs/test/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in _get_dendrogram_key(adata, dendrogram_key, groupby); 2406 ; 2407 if dendrogram_key not in adata.uns:; -> 2408 from ..tools._dendrogram import dendrogram; 2409 logg.warn(""dendrogram data not found (using key={}). Running `sc.tl.den",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/560:372,install,install,372,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/560,1,['install'],['install']
Deployability,"Hi there. Love the package. I was working in a google colab notebook, and installed scanpy as 'pip install scanpy'. Then when using the method: sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). I got this error:; ----------------------------------------------------------------------------------------; ImportError Traceback (most recent call last); <ipython-input-54-c0d016811ded> in <module>(); ----> 1 sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). 5 frames; /usr/local/lib/python3.6/dist-packages/statsmodels/distributions/edgeworth.py in <module>(); 5 import numpy as np; 6 from numpy.polynomial.hermite_e import HermiteE; ----> 7 from scipy.misc import factorial; 8 from scipy.stats import rv_continuous; 9 import scipy.special as special. ImportError: cannot import name 'factorial'; ----------------------------------------------------------------------------------------. Seems that scipy.misc.factorial is depreciated and is now under scipy.special.factorial. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/687:74,install,installed,74,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/687,2,['install'],"['install', 'installed']"
Deployability,"Hi to all, thanks for your interest in glmpca. I have been thinking of doing a python package now that the R package is finished and it would be an honor to have it included in scanpy. Can you give me a sense of how urgently you would need the package (ie what is the typical release cycle)? Also let me note a few caveats about the method:; * It does not handle zero inflation (which ZINB-WAVE does). However, we argue in our paper that despite large numbers of zeros, UMI data are not zero-inflated. We do not make any claim about the appropriateness of the glmpca model for non-UMI data (eg Smart-Seq read counts), which may actually be zero-inflated, although you could certainly run it with eg the negative binomial likelihood.; * glmpca is an alternative to PCA but not necessarily a replacement to PCA. For example, it is at least 10x slower than PCA and we are still working on the big data implementation for sparse matrices (in other words, we assume you can load the data matrix in dense form, which can be limiting).; * We describe a fast approximation to GLM-PCA in the paper which involves transforming raw counts to either Pearson or deviance residuals from a null model then applying standard PCA to that. This approach is just as fast as PCA as long as the null model can be computed in closed-form, which is what we have implemented here: https://github.com/willtownes/scrna2019/blob/master/util/functions.R#L164 . The idea is similar to the sctransform approach used by seurat, but the computation is simpler and faster.; * We also provide a deviance-based gene filtering method which is an alternative to using highly variable genes. This and the residuals functions will be available as an R package on bioconductor. I look forward to collaborating with you all to help make these methods available to a wider community!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/868#issuecomment-540672230:276,release,release,276,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/868#issuecomment-540672230,1,['release'],['release']
Deployability,"Hi! I am wondering why `loompy` and `pybiomart` are not in the list of dependencies. As of now ; the package (at least in bioconda) is not fully functional and requieres some extra installation; steps if one wants to use certain functionalities provided. - [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### Minimal code sample (that we can copy&paste without having any data); ```bash; conda install -c bioconda scanpy; ````. ```python; import scanpy as sc; annot = sc.queries.biomart_annotations(""mmusculus"", [""ensembl_gene_id"", ""external_gene_name""]); ```; ```pytb; line 108, in biomart_annotations; return simple_query(org=org, attrs=attrs, host=host, use_cache=use_cache); File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/scanpy/queries/_queries.py"", line 64, in simple_query; ""This method requires the `pybiomart` module to be installed.""; ImportError: This method requires the `pybiomart` module to be installed.; ```. ```python; import scanpy as sc; adata = sc.datasets.pbmc3k(); adata.write_loom('dummy.loom'); ```; ```pytb; write_loom(filename, self, write_obsm_varm=write_obsm_varm); File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/anndata/_io/write.py"", line 112, in write_loom; from loompy import create; ModuleNotFoundError: No module named 'loompy'; ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.6; scanpy 1.7.2; sinfo 0.3.1; -----; PIL 8.3.1; anndata 0.7.6; beta_ufunc NA; binom_ufunc NA; bottleneck 1.3.2; cffi 1.14.6; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; dunamai 1.6.0; get_version 3.5; h5py 2.10.0; joblib 1.0.1; kiwisolver 1.3.1; legacy_api_wrap 0.0.0; llvmlite 0.36.0; matplotlib 3.4.2; mkl 2.4.0; mpl_toolkits NA; natsort 7.1.1; nbinom_ufunc NA; n",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2000:181,install,installation,181,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2000,2,['install'],"['install', 'installation']"
Deployability,"Hi! I think we have a different focus here, and not all of what you stated as fact is correct, so I’ll do my best to clear this up:. 1. There is an advantage for type hints in common Scanpy usage. IPython should use Jedi to create autocompletions since this summer, but they forgot to reenable it. I sent them an issue to do so, ipython/ipython#11503 and a fix in ipython/ipython#11506. Jedi supports type hints, so with `c.Completer.use_jedi = True` now or by default in a month, people will profit from them. Furthermore, people are using scanpy in applications and scripts, not just in notebooks. When you use an IDE (or install the jedi extension in EMACS) you should profit from it. 2. The Jupyter shift-tab help being hard to read in the presence of type hints is what I consider a bug. I reported it in ipython/ipython#11504 and fixed it in ipython/ipython#11505. 3. The numpy is on it (see [here](https://github.com/numpy/numpy-stubs)) and will probably integrate it once there needs to be no Python 2 compat. e.g. scikit-learn waits for numpy: scikit-learn/scikit-learn#11170. I see your concern about entry hurdles, but I don’t agree. It’s super easy. `Union` is “or”, `Optional` is “or `None`”. If there’s questions, they can be answered. (or people click on the links in the docs and read like one sentence of explanation). 4. If you want we can change how all that is rendered. `Union[a, b]` could be done as ``` :class:`a` or :class:`b` ``` But it’s really not hard…. Honestly I think the `Callable[…]` is much better than the textual description that was there before: Until it was there, people (including me when i was writing that annotation) had to dive into the code to figure out what function signature is *really* expected there. Now they have to be able to parse what that `Callable[[a,b], c]` there means. If they have never encountered it before, they can click on it, read one sentence of explanation and know that `a` and `b` are parameters and `c` the return type. Done in",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/373#issuecomment-440619581:624,install,install,624,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/373#issuecomment-440619581,2,"['install', 'integrat']","['install', 'integrate']"
Deployability,"Hi! Thanks for the addition. In the release notes I guess something like ""Triku, a new feature selection method was added to our ecosystem"" would be fine. . As for committing to the master, sorry for that. I am eager to see it in the 1.8.0 release!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1722#issuecomment-793841669:36,release,release,36,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1722#issuecomment-793841669,2,['release'],['release']
Deployability,"Hi! Thanks for the answer. Installing and importing h5py helped. I think I got scanpy to run. However, I am stuck again at reading the .mtx file; ; Since I am new to scanpy I am just following your tutorial. I run the following comand and get the subsequent error bellow. . ```py; adata = sc.read_10x_mtx(; 'C:\\Users\\correap\\Documents\\03152019_scRNAseq\\filtered_feature_bc_matrix_1', # the directory with the `.mtx` file; var_names='gene_symbols', # use gene symbols for the variable names (variables-axis index); cache=True) # write a cache file for faster subsequent reading; ```; ```pytb; ---------------------------------------------------------------------------; FileNotFoundError Traceback (most recent call last); <ipython-input-17-e7dd3543f8df> in <module>(); 2 'C:\\Users\\correap\\Documents\\03152019_scRNAseq\\filtered_feature_bc_matrix_1', # the directory with the `.mtx` file; 3 var_names='gene_symbols', # use gene symbols for the variable names (variables-axis index); ----> 4 cache=True) # write a cache file for faster subsequent reading; 5 ; 6 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, gex_only); 244 else:; 245 adata = _read_v3_10x_mtx(path, var_names=var_names,; --> 246 make_unique=make_unique, cache=cache); 247 if not gex_only:; 248 return adata. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache); 277 Read mex from output from Cell Ranger v3 or later versions; 278 """"""; --> 279 adata = read(os.path.join(path, 'matrix.mtx.gz'), cache=cache).T # transpose the data; 280 genes = pd.read_csv(os.path.join(path, 'features.tsv.gz'), header=None, sep='\t'); 281 if var_names == 'gene_symbols':. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, **kwargs); 76 return _read(filename, backed=backed, ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/587#issuecomment-479994733:27,Install,Installing,27,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/587#issuecomment-479994733,1,['Install'],['Installing']
Deployability,"Hi! That function is for reading the files output by [cellranger’s mex option](https://support.10xgenomics.com/single-cell-gene-expression/software/pipelines/latest/output/matrices). Your files have been renamed by someone in a way we can’t predict, and you should just adapt the little code needed to read them yourself:. https://github.com/theislab/scanpy/blob/e6e08e51d63c78581bb9c86fe6e302b80baef623/scanpy/readwrite.py#L324-L341. Took me 3 minutes:. ```py; samples = []; for sample in range(1, 10):; s = read(; path / f'{sample}.matrix.mtx',; cache=cache,; cache_compression=cache_compression,; ).T; genes = pd.read_csv(path / f'{sample}.genes.tsv', header=None, sep='\t'); s.var_names = genes[0]; s.var['gene_symbols'] = genes[1].values; s.obs_names = pd.read_csv(path / f'{sample}.barcodes.tsv', header=None)[0]; samples.append(s); adata = AnnData.concatenate(samples); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/882#issuecomment-545433846:148,pipeline,pipelines,148,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/882#issuecomment-545433846,1,['pipeline'],['pipelines']
Deployability,"Hi! You shouldn’t need to try here: Read the documentation at https://scanpy.rtfd.io to figure out if what you want is in `scanpy` or `scanpy.external`. `scanpy.api` is deprecated, you should never use it. The code @ivirshup gave you will work in the next scanpy release, as scanpy 1.4.4 still has the bug #346. Please upgrade to scanpy from git master and try again. You can do that via:. ```bash; pip install git+https://github.com/theislab/scanpy.git; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/838#issuecomment-532633720:263,release,release,263,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838#issuecomment-532633720,3,"['install', 'release', 'upgrade']","['install', 'release', 'upgrade']"
Deployability,Hi! so when installing via pip this is not an issue... somehow with conda it doesnt work,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1166#issuecomment-614743174:12,install,installing,12,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1166#issuecomment-614743174,1,['install'],['installing']
Deployability,"Hi!. > > > for normalize_pearson_residual, i think it makes sense to keep normalize in, as it's not the same type of transformation compared to log1p.; > ; > > Isn't this quite similar to what log1p does though? In that it's a transformation of the matrix?; > ; > I think it should stay `normalize_pearson_residuals` because it mirrors `normalize_total`. I agree. > ; > for the rest, I think we are at a good stage, I'd ask @jlause to build docs locally `cd scanpy/docs` and then `make clean` and `make html` see https://scanpy.readthedocs.io/en/stable/dev/documentation.html#building-the-docs and check that:; > ; > * arguments and doc params match; > ; > * typo and other minor issues still present (e.g. difficult phrasing). I started doing that and will finish up tomorrow - there Qs in advance if you happen to look at this before:. - sometimes we have math expressions like var = mean * mean^2 etc. in the docs. Is there a convention for scanpy docs if those should be in `code` format or just plain text? e.g. in the adata docstring the matrix shape is described as `n_obs` x `n_var`, but elsewhere we say ""clipping is done by sqrt(n). I can consistently format them into `code` if you agree.; - I think the `.._pca` function is missing from the release note. should I add it there?; - The `..pca` function also did not use shared docs params yet. I started adding them and can commit tomorrow - is that okay if I just do it like that?. > ; > ; > if this gets approval, before merging to master todo:; > ; > * [x] add release note; > ; > * [ ] go over scanpy_tutorials and re run tutorial and merge. I've looked at that and commented in the respective github :). Very happy we are getting this wrapped up now :); Best! Jan",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1715#issuecomment-1065345395:1253,release,release,1253,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715#issuecomment-1065345395,2,['release'],['release']
Deployability,Hi!. I am wondering if you could add https://github.com/BayraktarLab/cell2location to your list of scRNA->spatial integration methods (https://scanpy-tutorials.readthedocs.io/en/latest/spatial/integration-scanorama.html). Thanks!,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1574:114,integrat,integration,114,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1574,2,['integrat'],"['integration', 'integration-scanorama']"
Deployability,"Hi!. I recently upgraded to scanpy 1.4 and did not encounter this issue in previous versions. I am trying to generate a heatmap using the following function:; sc.pl.rank_genes_groups_heatmap(adata, n_genes=4, use_raw=True, swap_axes=True). For some reason I am getting white margins on the right and left side which results in misalignment of the colormap identifying my clusters on the bottom and the above heatmap. ![image](https://user-images.githubusercontent.com/7358001/56063815-58c26080-5d3e-11e9-8935-258760c1b0eb.png). I get the same result if I just use sc.pl.heatmap and do a groupby with the clusters. . Any idea how to fix this issue would be most appreciated!. Thanks!!!. Eva. scanpy==1.4 anndata==0.6.19 numpy==1.15.4 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.19.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 ; matplotlib == 2.2.3. INSTALLED VERSIONS; ------------------; commit: None; python: 3.7.0.final.0; python-bits: 64; OS: Windows; OS-release: 8.1; machine: AMD64; processor: Intel64 Family 6 Model 69 Stepping 1, GenuineIntel; byteorder: little; LC_ALL: None; LANG: None; LOCALE: None.None. pandas: 0.23.4; pytest: 3.8.0; pip: 19.0.3; setuptools: 40.2.0; Cython: 0.28.5; numpy: 1.15.4; scipy: 1.1.0; pyarrow: None; xarray: None; IPython: 6.5.0; sphinx: 1.7.9; patsy: 0.5.0; dateutil: 2.7.3; pytz: 2018.5; blosc: None; bottleneck: 1.2.1; tables: 3.4.4; numexpr: 2.6.8; feather: None; matplotlib: 2.2.3; openpyxl: 2.5.6; xlrd: 1.1.0; xlwt: 1.3.0; xlsxwriter: 1.1.0; lxml: 4.2.5; bs4: 4.6.3; html5lib: 1.0.1; sqlalchemy: 1.2.11; pymysql: None; psycopg2: None; jinja2: 2.10; s3fs: None; fastparquet: None; pandas_gbq: None; pandas_datareader: None",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/606:16,upgrade,upgraded,16,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/606,3,"['INSTALL', 'release', 'upgrade']","['INSTALLED', 'release', 'upgraded']"
Deployability,Hi!. If you used a neural network approach you could use scArches to leverage transfer learning to map things across without re-integrating (only minimal additional training done there). You could also map into the embedded space using `sc.tl.ingest` for example. But there is always the danger that there is a residual batch effect that cannot be removed without de-novo integration.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2162#issuecomment-1055535384:128,integrat,integrating,128,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2162#issuecomment-1055535384,2,['integrat'],"['integrating', 'integration']"
Deployability,Hi!; Could you finally solve the issue of removing colorbar from the figure? I have tried with the legend_loc=None and legend_loc='none' and they don't remove continuous colorbars. I have tried to fix this issue myself but couldn't find the exact place in the code to do that. Any help would be more than welcome!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1821#issuecomment-895935559:159,continuous,continuous,159,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1821#issuecomment-895935559,1,['continuous'],['continuous']
Deployability,"Hi!; Could you finally solve this issue? I am trying to remove a continuous colorbar from a umap and I cannot make it.; Thanks,. Lídia",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1821#issuecomment-939952451:65,continuous,continuous,65,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1821#issuecomment-939952451,1,['continuous'],['continuous']
Deployability,"Hi!; Sorry for the late response. Release 0.3 comes today or tomorrow, with many improvements.; Is the following OK for you?; From http://scanpy.readthedocs.io/en/latest/api/scanpy.api.AnnData.html; ```; >>> adata1 = AnnData(np.array([[1, 2, 3], [4, 5, 6]]),; >>> {'smp_names': ['s1', 's2'],; >>> 'anno1': ['c1', 'c2']},; >>> {'var_names': ['a', 'b', 'c']}); >>> adata2 = AnnData(np.array([[1, 2, 3], [4, 5, 6]]),; >>> {'smp_names': ['s3', 's4'],; >>> 'anno1': ['c3', 'c4']},; >>> {'var_names': ['b', 'c', 'd']}); >>> adata3 = AnnData(np.array([[1, 2, 3], [4, 5, 6]]),; >>> {'smp_names': ['s5', 's6'],; >>> 'anno2': ['d3', 'd4']},; >>> {'var_names': ['b', 'c', 'd']}); >>>; >>> adata = adata1.concatenate([adata2, adata3]); >>> adata.X; [[ 2. 3.]; [ 5. 6.]; [ 1. 2.]; [ 4. 5.]; [ 1. 2.]; [ 4. 5.]]; >>> adata.smp; anno1 anno2 batch; s1 c1 NaN 0; s2 c2 NaN 0; s3 c3 NaN 1; s4 c4 NaN 1; s5 NaN d3 2; s6 NaN d4 2; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/44#issuecomment-344124406:34,Release,Release,34,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/44#issuecomment-344124406,1,['Release'],['Release']
Deployability,"Hi!; Thank you for tutorials, they're very helpful. ; Do you have a spatial/sc-rna seq integrative analysis tutorial? . Thanks in advance!. ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1386:87,integrat,integrative,87,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1386,1,['integrat'],['integrative']
Deployability,"Hi, . First of all, I would like to thank the developers for this awesome tool! I am new to Scanpy. I am migrating from Seurat to Scanpy as I would like to perform trajectory analysis in my data. I have single cell sequencing data from 12 samples and 3 treatments (so 4 samples per treatment). I merged the samples from the same treatment in a single matrix using ‘cellranger’ software from 10x Genomics (so I have 3 matrixes from 3 different treatments to import to Scanpy). . In ‘Seurat’, I can read the data from my three treatments separated, do quality control, and then integrate them using ‘FindIntegrationAnchors’ and ‘IntegrateData’ functions. Then, I perform cluster analysis in the integrated dataset, and test the effect of treatment on the transcriptome of each cluster. . Is there a similar function in ‘Scanpy’ to integrate different datasets which are labeled in order to perform cluster analyses in the integrated dataset and test for the effect of treatment in the transcriptome of identified cell types? If so, is there a tutorial for that?. In ‘Scanpy’ I am able to import the data and perform quality control and cluster analysis. Thus, if there was a way of integrating the 3 different matrixes in one single object that would be helpful. Any suggestions on how I should proceed to integrate my data and perform differential gene expression analysis according to treatment and cell type?. Thank you very much!. Joao",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/859:576,integrat,integrate,576,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/859,7,"['Integrat', 'integrat']","['IntegrateData', 'integrate', 'integrated', 'integrating']"
Deployability,"Hi, . I also met this problem. I am using Scanpy 1.7.2, and could you please suggest which version of BBKNN I should use if I don't want to update Scanpy to 1.8.0. Thanks,; Min",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1873#issuecomment-872823146:140,update,update,140,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1873#issuecomment-872823146,1,['update'],['update']
Deployability,"Hi, . I just stumbled upon the same error, maybe due to the installation method.; Anyway, I got it fixed but since my package was outdated and it's been a while since I used python maybe the next point as already been solved:. -typo issue in the notebook examples (phase instead of Phase); at In [8] when you call the pca.scatter function with color 'phase'. > ValueError: ""phase"" is invalid! specify valid sample annotation, one of ['n_genes', 'percent_mito', 'n_counts', 'dropouts', 'complexity', 'S_score', 'G2M_score', 'Phase', 'X_diffmap0', 'louvain_groups']. Very nice package and notebooks BTW,; Raphaël",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/82#issuecomment-368930312:60,install,installation,60,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/82#issuecomment-368930312,1,['install'],['installation']
Deployability,"Hi, . I updated the pipeline to use [this singularity container](https://github.com/icbi-lab/borst2021/releases/download/containers-0.2.0/vanderburg_edger.sif). The problem persists.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2014#issuecomment-944868481:8,update,updated,8,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2014#issuecomment-944868481,3,"['pipeline', 'release', 'update']","['pipeline', 'releases', 'updated']"
Deployability,"Hi, . Thank you for your interest in scanpy and for raising your question here!. It looks like you are interested in getting the results of `sc.tl.rank_genes_groups`.; For this, we recommend using `sc.get.rank_genes_groups` - you can find more about scanpy’s getters [here](https://scanpy.readthedocs.io/en/stable/api.html#module-scanpy.get). This might look for example like this:. ```py; import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(); sc.tl.rank_genes_groups(pbmc, groupby=""louvain"", pts=True, use_raw=True). dedf = sc.get.rank_genes_groups_df(pbmc, group=""0""); ```. By accessing the `.uns` as you outlined, just using the ordering of the pts column might not match the ordering of the sorted genes.; This behaviour is subject to updates in the future - in any case `sc.get.rank_genes_groups` is the way to go here :). I hope this helps?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2628#issuecomment-1742964494:744,update,updates,744,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2628#issuecomment-1742964494,1,['update'],['updates']
Deployability,"Hi, . Thank you!. 1. I've installed scanpy's git version and set ctrl_as_ref=True with the same results, it does not fix https://github.com/scverse/scanpy/issues/3169. 2. I am not entirely sure what you mean here, would you mind elaborating? This bug fix is specific to the way score_genes() ranks the genes into bins & when there's a lot of zero expression in cells, I'm a bit unsure how this connects to ctrl_as_ref and what you would like me to do. . Thanks again",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3167#issuecomment-2263791635:26,install,installed,26,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3167#issuecomment-2263791635,1,['install'],['installed']
Deployability,"Hi, . Thanks for the awesome tool!. May I know in which version can I find [`sc.export_to.spring_project`](https://scanpy.readthedocs.io/en/stable/external/scanpy.external.exporting.spring_project.html)? I have tried scanpy==1.6.0, 1.0.3, 1.1a1 but faced this error . ![image](https://user-images.githubusercontent.com/26448066/100419830-47b79600-30c0-11eb-9e08-b3ae1e18ea1b.png). [This tutorial](https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/171111_SPRING_export/SPRING_export.ipynb) indicates that it worked in scanpy==1.0.4, however, I failed to fix the bug to install version 1.0.4. Any help will be great! . Many thanks, ; Justine",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1510:588,install,install,588,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1510,1,['install'],['install']
Deployability,"Hi, . This is a minor point. Thanks for linking to the scVI repo in your ecosystem page. However, would it be possible to put scVI in another category than ""data integration"" ? Since scVI can also do differential expression for example. . Thanks, ; Romain; <!--; ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠; If you want to know about design decisions and the like, please ask below:; -->; ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1072:162,integrat,integration,162,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1072,1,['integrat'],['integration']
Deployability,"Hi, . we developed [scirpy](https://github.com/icbi-lab/scirpy), a scanpy extension to analyse single-cell TCR data. You can learn more about the project in our [preprint](https://www.biorxiv.org/content/10.1101/2020.04.10.035865v1), the [apidocs](https://icbi-lab.github.io/scirpy/api.html) and the [tutorial](https://icbi-lab.github.io/scirpy/tutorials/tutorial_3k_tcr.html). . Since I heard that some people around here (@davidsebfischer, @b-schubert) are really interested in this topic, I created this issue to coordinate efforts. I would love to work together with you guys to take this to the next level. . Currently, some ideas of mine are; * extension to BCR data; * integration with @davidsebfischer's [tcellmatch](https://github.com/theislab/tcellmatch) as a distance metric for clonotype networks; * integration with epitope databases. Let me know what you think! . Best, ; Gregor . CC @ffinotello, @szabogtamas, @mlist",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1163:676,integrat,integration,676,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1163,2,['integrat'],['integration']
Deployability,"Hi, ; I am using weighted sampling data as input of . > scanpy , but i didn't find any help when i have a distinct weight for each observation. So I modified few of the . > scanpy. files. . `use_weights` is a boolean parameter either your data is weighted or not, if weighted then it will calculated weighted mean and weighted variance, in other case it will be same as previous. `Default is False`. `weights` is a 1D weight vector, where each row is weight of observation in original matrix. `Default is None`. I have attached the updated files and tested with well. But you can test again for adding into your tool. . Thanks; [Weighted_Sampling.zip](https://github.com/theislab/scanpy/files/3134213/Weighted_Sampling.zip)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/627:532,update,updated,532,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/627,1,['update'],['updated']
Deployability,"Hi, ; I faced the same problem. I solved it by using the development version of scanpy : ; git clone https://github.com/theislab/scanpy; cd scanpy; pip install -e . For bbknn i just pip installed it . Then : ; bbknn.bbknn(adata_bbknn, batch_key=""Batches""). Hope this can help,",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/770#issuecomment-521728652:152,install,install,152,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/770#issuecomment-521728652,2,['install'],"['install', 'installed']"
Deployability,"Hi, ; I'm having similar issues in using sc.tl.ingest(adata, adata_ref, obs='louvain').; I have updated my Scanpy 1.4.6 and anndata to 0.7.1.; I'm getting the following error message.; ```pytb; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-71-27e22cc8f823> in <module>; ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain'). ~/opt/anaconda3/lib/python3.7/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, inplace, **kwargs); 119 ; 120 for method in embedding_method:; --> 121 ing.map_embedding(method); 122 ; 123 if obs is not None:. ~/opt/anaconda3/lib/python3.7/site-packages/scanpy/tools/_ingest.py in map_embedding(self, method); 407 """"""; 408 if method == 'umap':; --> 409 self._obsm['X_umap'] = self._umap_transform(); 410 elif method == 'pca':; 411 self._obsm['X_pca'] = self._pca(). ~/opt/anaconda3/lib/python3.7/site-packages/scanpy/tools/_ingest.py in _umap_transform(self); 396 ; 397 def _umap_transform(self):; --> 398 return self._umap.transform(self._obsm['rep']); 399 ; 400 def map_embedding(self, method):. ~/opt/anaconda3/lib/python3.7/site-packages/umap/umap_.py in transform(self, X); 2006 try:; 2007 # sklearn pairwise_distances fails for callable metric on sparse data; -> 2008 _m = self.metric if self._sparse_data else self._input_distance_func; 2009 dmat = pairwise_distances(; 2010 X, self._raw_data, metric=_m, **self._metric_kwds. AttributeError: 'UMAP' object has no attribute '_input_distance_func'; ```. Appreciate your comments.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1092#issuecomment-623064541:96,update,updated,96,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1092#issuecomment-623064541,1,['update'],['updated']
Deployability,"Hi, ; Thank you very much for such a detailed explanation. It really helps. I've two more questions: . 1). Can we do this gene subsetting with Logistic regression (where no multiple testing correction is involved)? . 2). Since you nicely pointed out sc.tl_rank_genes_groups doesn't tell about the contribution of genes in the clustering- are there tools that can be integrated with ScanPy to do this job? (for example, diffxpy or MAST). I'm really interested in the differential gene testing to predict the markers (from a gene subset used for clustering). . I shall be grateful if you can suggest a method.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/748#issuecomment-515114575:366,integrat,integrated,366,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/748#issuecomment-515114575,1,['integrat'],['integrated']
Deployability,"Hi, ; we want to add SCALEX, an online integration method that integrate different single-cell experiments including scRNA-seq and scATAC-seq, which also enable accurate projecting new incoming datasets onto the existing cell space. This method is published on Nature Communications. SCALEX is developed based-on scanpy. We appreciate and will be honored to contribute to the scanpy community. Thank you!; Lei . <!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2353:39,integrat,integration,39,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2353,2,['integrat'],"['integrate', 'integration']"
Deployability,"Hi, @AlejandraRodelaRo ; It was fixed on github master. You can wait for a new release or install scanpy from github.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1285#issuecomment-650102141:79,release,release,79,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1285#issuecomment-650102141,2,"['install', 'release']","['install', 'release']"
Deployability,"Hi, @KabitaBaral1. These happens because of changes in umap 0.4. Please update scanpy to solve this problem.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1154#issuecomment-610787898:72,update,update,72,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1154#issuecomment-610787898,1,['update'],['update']
Deployability,"Hi, @cakirb ; Try installing `loompy` using `pip install -U loompy`, and make sure you are not using version 2.0.2.; see ; https://github.com/theislab/scvelo/issues/20#issuecomment-442186279. **EDITED**: I am encountering the same problem as yours. > Exception: Data must be 1-dimensional",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/598#issuecomment-493666985:18,install,installing,18,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/598#issuecomment-493666985,2,['install'],"['install', 'installing']"
Deployability,"Hi, @plrlhb12 .; Yes, this is a known problem. The easiest fix for now is to use umap 0.3.9 instead of 0.4.1.; You can also install scanpy from github where it is fixed or just wait for a new scanpy release.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1181#issuecomment-617895856:124,install,install,124,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1181#issuecomment-617895856,2,"['install', 'release']","['install', 'release']"
Deployability,"Hi, @sarajimenez ; there is no ingest in scanpy 1.4.4.post1. You need to update scanpy to 1.4.5 and anndata to 0.7 to use ingest.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1092#issuecomment-597292098:73,update,update,73,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1092#issuecomment-597292098,1,['update'],['update']
Deployability,"Hi, Alex, . Fantastic package! As a python guy, I have become such a huge fan of Scanpy. . I'm encountering an issue when trying to add further annotation to a subset, what I'm doing is basically:. ```; adata = sc.read(filename); adata.var_names = pd.read_csv('genes.tsv'); adata.obs_names = pd.read_csv('barcodes.tsv'). adata_subset = adata[ list_of_barcodes,:]; anno = pd.read_csv(filename_sample_annotation); adata_subset.obs = anno; ```. But unfortunately _**adata_subset.obs**_ didn't get updated (I checked the index of _**anno**_ and it's consistent with _**adata_subset.obs_names**_). . It works only if I add the annotation column by column (In my case there are too many columns so it won't be ideal), e.g. `adata_subset.obs['cell_groups'] = anno['cell_groups']`. Could you please help me figure it out? Many thanks!. Huidong",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/165:494,update,updated,494,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/165,1,['update'],['updated']
Deployability,"Hi, I am trying to use palantir. I've updated by `pip install git+https://github.com/theislab/scanpy.git`. when I try to import scanpy I get the following error: ; ModuleNotFoundError: No module named 'scanpy.external._tools'. I'm fairly new to python packaging. Apologies if this is an issue with my install method. also not an expert with github project managment. Will gladly post this elsewhere if better. . Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/493#issuecomment-477674448:38,update,updated,38,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/493#issuecomment-477674448,3,"['install', 'update']","['install', 'updated']"
Deployability,"Hi, I cloned this repo, switched to `modern-rng`, and installed it with `pip`. I was able to reproduce the same error.; ```; Exception ignored in: <class 'ValueError'>; Traceback (most recent call last):; File ""numpy\random\_generator.pyx"", line 622, in numpy.random._generator.Generator.integers; File ""numpy\random\_bounded_integers.pyx"", line 2881, in numpy.random._bounded_integers._rand_int32""; ValueError: high is out of bounds for int32; ```; I am using numpy 1.26, which is the numpy version required by this branch.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3041#issuecomment-2332066283:54,install,installed,54,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3041#issuecomment-2332066283,1,['install'],['installed']
Deployability,"Hi, I have a Seruat processed dataset, of which I wanted to use scVI for integration. I stored the raw count and cell information then assembled them in scanpy as anndata via method mentioned: `https://smorabit.github.io/tutorials/8_velocyto/`. . So I could get batch HVG function to work without specifying flavor, however, I couldn't get it to work with specifying `flavor=""seurat_v3""`, I wonder how important it is to set this parameter and why does it not work for me?. Thanks a lot!. ```; adata; AnnData object with n_obs × n_vars = 73998 × 13639; obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'barcode', 'Celltype2', 'Clusters', 'Sample'; uns: 'log1p'; layers: 'counts'. for i in adatas:; i.layers['counts'] = i.X; adata = ad.concat(adatas); adata.obs_names_make_unique; sc.pp.log1p(adata); sc.pp.highly_variable_genes(; adata,; flavor=""seurat_v3"",; layer=""counts"",; batch_key=""Sample"",; subset=True; ); ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); Cell In [197], line 1; ----> 1 sc.pp.highly_variable_genes(; 2 adata_new,; 3 flavor=""seurat_v3"",; 4 layer=""counts"",; 5 batch_key=""Sample"",; 6 subset=True; 7 ); 8 adata_new. File ~/.local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:422, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values); 416 raise ValueError(; 417 '`pp.highly_variable_genes` expects an `AnnData` argument, '; 418 'pass `inplace=False` if you want to return a `pd.DataFrame`.'; 419 ); 421 if flavor == 'seurat_v3':; --> 422 return _highly_variable_genes_seurat_v3(; 423 adata,; 424 layer=layer,; 425 n_top_genes=n_top_genes,; 426 batch_key=batch_key,; 427 check_values=check_values,; 428 span=span,; 429 subset=subset,; 430 inplace=inplace,; 431 ); 433 if batch_key is None:; 434 df = _highly_variable_genes_single_batch(; 435 adata,; 436 layer=layer,; (...); 443",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2427:73,integrat,integration,73,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2427,1,['integrat'],['integration']
Deployability,"Hi, I just tried install a higher version of scipy, and it works now.; ```; pip install scipy==1.2.1; ```; Refer to: https://www.scipy.org",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/643#issuecomment-492050558:17,install,install,17,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/643#issuecomment-492050558,2,['install'],['install']
Deployability,"Hi, I left an issue to seurat repository as well, but it might be of interest for scanpy:. https://github.com/satijalab/seurat/issues/604#issue-339640125. In my systems, as long as it has `Seurat` and `scanpy` (or `anndata` to be more specific) installed, the above one-liner command to convert a merged seurat object to anndata fails within the anndata python code (with the index out of range error), in the `convert_dictionary_to_structured_array` module. I am not sure whether it is an issue with `Seurat` or `anndata`, but leaving here a link as well (actually curious whether the issue reproduces to anyone using the `scanpy`)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/196:245,install,installed,245,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/196,1,['install'],['installed']
Deployability,"Hi, I think the problem is caused by the two different versions of anndata used. We had similar issues when using anndata 0.7 and 0.8 together. Try to upgrade the version to 0.8. Best; Florian",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2310#issuecomment-1221390668:151,upgrade,upgrade,151,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2310#issuecomment-1221390668,1,['upgrade'],['upgrade']
Deployability,"Hi, I was doing a dataset integration on quite some datasets. . ```py; adatas = [AT1,AT2,AT3,AT4,AT5,AT6,AT7] #each is an adata object from scRNA-seq. for i in adatas:; i.layers['counts'] = i.X. adatas = [AT1,AT2,AT3,AT4,AT5,AT6,AT7]. adata = ad.concat(adatas); adata.obs_names_make_unique. sc.pp.log1p(adata); sc.pp.highly_variable_genes(; adata,; layer=""logcounts"",; batch_key=""Sample"",; subset=True; ). scvi.model.SCVI.setup_anndata(adata, layer=""counts"", batch_key=""Sample""). vae = scvi.model.SCVI(adata, n_hidden=256); vae.train(); adata.obsm[""X_scVI""] = vae.get_latent_representation(); sc.pp.neighbors(adata, use_rep=""X_scVI""); from scvi.model.utils import mde; import pymde; adata.obsm[""X_mde""] = mde(adata.obsm[""X_scVI""]); adata.obsm[""X_normalized_scVI""] = vae.get_normalized_expression(); adata.write_h5ad('Integrated.h5ad'); ```. So I did use make obs names unique after ad.concat(adatas). However, after I was finished with the integration and moving on to write_h5ad, it returns the following errors and tells me they can't write my h5ad cuz I have duplicated rows:. ```pytb; Feb 26 11:20:39 PM: Your dataset appears to contain duplicated items (rows); when embedding, you should typically have unique items.; Feb 26 11:20:39 PM: The following items have duplicates [60449 60452 60455 ... 70783 70784 70785]; Traceback (most recent call last):; File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper; return func(elem, key, val, *args, **kwargs); File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 171, in write_elem; _REGISTRY.get_writer(dest_type, (t, elem.dtype.kind), modifiers)(; File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper; result = func(g, k, *args, **kwargs); File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 346, in write_vlen_string_array; f.create_dataset(k, data=elem.astype(st",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2432:26,integrat,integration,26,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432,3,"['Integrat', 'integrat']","['Integrated', 'integration']"
Deployability,"Hi, I was just trying to use the package but it seems that somebody is working on the master branch right now. Would it be possible to set up a development branch and maybe add a few tags for the working versions so that people could download a particular release instead of an in-progress master branch? I also noticed that the notebooks disappeared right after I cloned the repository. It seems like there are some big changes going on, so sorry if the timing for this issue is not right and you are just cleaning up the repository.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/7:256,release,release,256,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/7,1,['release'],['release']
Deployability,"Hi, I worked over the docs completely once but still need to do a few small things (release note, final spell check) but need to leave my desk now - will do the final bits either later today or tomorrow!; Best jan",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1715#issuecomment-1065878828:84,release,release,84,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715#issuecomment-1065878828,1,['release'],['release']
Deployability,"Hi, I'm having trouble exporting a PAGA graph as gexf format. I did a manual fix in my own installation of scanpy but it seems like a version issue with networkx2.6.2 (which is the latest of this date).; Minimal working example:; ```python; import scanpy as sc; paul15 = sc.datasets.paul15(); sc.pp.recipe_zheng17(paul15); sc.pp.neighbors(paul15, n_neighbors=4, n_pcs=20); sc.tl.paga(paul15, groups='paul15_clusters'); sc.pl.paga(paul15, labels=None, color='paul15_clusters'). gexf=sc.pl.paga(paul15, labels=None, color='paul15_clusters', export_to_gexf=True). ```. ```pytb. File ""anaconda3\lib\site-packages\scanpy\plotting\_tools\paga.py"", line 860, in _paga_graph; nx_g_solid.node[count]['label'] = str(node_labels[count]). AttributeError: 'Graph' object has no attribute 'node'```. ```; #### Versions; scanpy 1.8.1; networkx 2.6.2; matplotlib 3.4.3. <details>. sc.logging.print_versions(); WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.6; scanpy 1.8.1; sinfo 0.3.1; -----; PIL 8.0.1; PyQt5 NA; anndata 0.7.6; autoreload NA; backcall 0.2.0; bottleneck 1.3.2; bs4 4.9.3; cairo 1.20.1; cffi 1.14.3; chardet 3.0.4; cloudpickle 1.6.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2.30.0; dateutil 2.8.1; decorator 4.4.2; h5py 2.10.0; html5lib 1.1; igraph 0.9.6; ipykernel 5.3.4; ipython_genutils 0.2.0; jedi 0.17.1; joblib 1.0.1; kiwisolver 1.3.0; leidenalg 0.8.7; llvmlite 0.34.0; lxml 4.6.1; matplotlib 3.4.3; mpl_toolkits NA; natsort 7.1.1; networkx 2.6.2; nt NA; ntsecuritycon NA; numba 0.51.2; numexpr 2.7.1; numpy 1.20.3; packaging 20.4; pandas 1.3.2; parso 0.7.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.8; psutil 5.7.2; pyarrow 0.16.0; pycparser 2.20; pygments 2.7.2; pynndescent 0.5.2; pyparsing 2.4.7; pythoncom NA; pytz 2020.1; pywintypes NA; scanpy 1.8.1; scipy 1.5.2; sinfo 0.3.1; sip NA; six 1.15.0; sklearn 0.23.2; soupsieve 2.0.1; sphinxcontrib NA; spyder 4.1.5; spyder_kernels 1.9.4; spydercustomize NA; s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1997:91,install,installation,91,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1997,1,['install'],['installation']
Deployability,"Hi, I've now implemented many scanpy plots using Marsilea in the notebook. Please let me know what you think of it and if you have any further questions or requests that could be useful for the community. Looking forward to integrating this!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2444#issuecomment-2084906007:224,integrat,integrating,224,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2444#issuecomment-2084906007,1,['integrat'],['integrating']
Deployability,"Hi, I've recently been searching for the functionalities listed above and came across this issue from 2020. Are there any updates on when these functions might potentially be available? :) Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1133#issuecomment-1739825913:122,update,updates,122,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1133#issuecomment-1739825913,1,['update'],['updates']
Deployability,"Hi, after release 1.6 this is now partially possible. If you set the parameter `return_fig=True` then you have access to the `style()` method (see: https://scanpy.readthedocs.io/en/stable/api/scanpy.pl.DotPlot.style.html#scanpy.pl.DotPlot.style). ```PYTHON; adata = sc.datasets.pbmc68k_reduced(); marker_genes = ['S100A8', 'GNLY', 'NKG7', 'KLRB1', 'FCGR3A', 'FCER1A', 'CST3']; ax_dict = sc.pl.dotplot(adata,marker_genes,groupby='bulk_labels', return_fig=True).style(grid=True).show(); ```; ![image](https://user-images.githubusercontent.com/4964309/90759033-2a647600-e2e0-11ea-86e4-2a0e060955ad.png). What is not possible is to change the linewidth.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1371#issuecomment-677516048:10,release,release,10,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1371#issuecomment-677516048,1,['release'],['release']
Deployability,"Hi, first thanks for sharing this analysis tool. I prefer Python much more to R, though most Bioinformatics tools are written in R. Here I want to ask a question about data processing before we feed it as _adata_ into _dpt_ for _pseudotime_ ordering. . As the DPT algorithm can accept multiple types of data, such as the most commonly single-cell qPCR (Ct values) and RNA-Seq (FPKM/TPM) data, is the data processing procedure identical with each other? Since I have also checked the Monocle 2 algorithm, it seems much more complicated in Monocle 2. For instance, in the 4th page of its document [link](http://www.bioconductor.org/packages/release/bioc/vignettes/monocle/inst/doc/monocle-vignette.pdf), it asks you to specify different _expressionFamily_, i.e., the proper distribution of the data, for different kinds of data. Then, how about the _dpt_ function in scanpy? Does it take all kinds of data the same way?. According to my understanding, ; - For qPCR data, we should provide delta_Ct=LOD-Ct values to _dpt_ (LOD: limit of detection);; - For RNA-Seq data, we should offer log2(FPKM+1) to _dpt_.; Is it right?. Any help is appreciated.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/26:639,release,release,639,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/26,1,['release'],['release']
Deployability,"Hi, how did you install everything? With conda or pip? Does reinstalling MulticoreTSNE and/or scikit-learn help?. This is most certainly not scanpy’s problem, we don’t have any compiled code.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/874#issuecomment-544246058:16,install,install,16,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/874#issuecomment-544246058,1,['install'],['install']
Deployability,"Hi, if you use conda, try `conda install pytables`.; If you don't, try installing from the corresponding wheel here https://www.lfd.uci.edu/~gohlke/pythonlibs/#pytables",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1468#issuecomment-716156261:33,install,install,33,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1468#issuecomment-716156261,2,['install'],"['install', 'installing']"
Deployability,"Hi, just wanted to ask again if there was any update on this. Thanks in advance!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2780#issuecomment-1892069618:46,update,update,46,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2780#issuecomment-1892069618,1,['update'],['update']
Deployability,"Hi, please give me a reproducible example that uses only public data or better manually typed data. (`np.array([...])`). Also make sure you updated to numpy 0.47 (not 0.46) and llvmlite 0.31 before trying to reproduce the bug.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/974#issuecomment-572765359:140,update,updated,140,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/974#issuecomment-572765359,1,['update'],['updated']
Deployability,"Hi, sorry for getting back so late, I was alternatingly really busy and sick. This looks nice! One more thing:. > This is also missing release notes in 1.11.0.md",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3180#issuecomment-2348356839:135,release,release,135,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3180#issuecomment-2348356839,1,['release'],['release']
Deployability,"Hi, sorry! deep was nonfunctional, I fixed it in 1.4.4.post1 (just released)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/746#issuecomment-515971919:67,release,released,67,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/746#issuecomment-515971919,1,['release'],['released']
Deployability,"Hi, thanks for developing Scanpy. Here, I encountered the error, `ImportError: cannot import name 'sparsefuncs'`. To solve this problem, I re-installed ""sklearn.utils"" and ""sklearn"". However, I still get this error when importing Scanpy. The Scanpy runs correctly in my linux system, but it cannot be imported corrected in my windows 10 system. **Here is the code and error information:**. `>>> import sklearn.utils`; `>>> import sklearn`; `>>> import scanpy`; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\__init__.py"", line 15, in <module>; from . import tools as tl; File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\tools\__init__.py"", line 1, in <module>; from ..preprocessing import pca; File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\__init__.py"", line 1, in <module>; from ._recipes import recipe_zheng17, recipe_weinreb17, recipe_seurat; File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\_recipes.py"", line 11, in <module>; from ._normalization import normalize_total; File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\_normalization.py"", line 6, in <module>; from sklearn.utils import sparsefuncs; ImportError: cannot import name 'sparsefuncs'",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2165:142,install,installed,142,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2165,1,['install'],['installed']
Deployability,"Hi, thanks for the contribution!. The converting to dense is quite iffy, we should probably add real support for sparse here. [We could use this as a base](https://github.com/scikit-learn/scikit-learn/blob/45cf8ec555a026c4263e8bef12850755a83df10e/sklearn/utils/sparsefuncs.py#L685). Do you think you can do that or should we help?. This is also missing release notes in 1.11.0.md",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3180#issuecomment-2262820449:353,release,release,353,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3180#issuecomment-2262820449,1,['release'],['release']
Deployability,"Hi, thanks for this great library!. I was playing around with data simulated from the `toggleswitch` model and was very much surprised to see the result of running the `dpt` on my simulated data. The script I am running is the following:; ```python; adata = sc.tl.sim('toggleswitch',; nrRealizations=5,; tmax=200,; branching=False). sc.pl.sim(adata). sc.pp.neighbors(adata); sc.tl.louvain(adata); sc.tl.diffmap(adata); adata.uns['iroot'] = 0; sc.tl.dpt(adata). sc.tl.umap(adata); sc.pl.umap(adata,; edges=True,; edges_width=1,; color=['louvain', 'dpt_pseudotime'],; legend_loc='on data'); ```. In short, I am simulating five realizations of the two-genes `toggleswitch` model with 200 time steps in each realization and allowing to have multiple realizations from the same branch (otherwise there would be only two possible realizations). The problem I face is that the result of the pseudo-time computation seems (and is, since I know how the data was generated) wrong. Here are the plots displayed when running this script:; ![image](https://user-images.githubusercontent.com/6624306/65698989-b0028600-e07d-11e9-94ec-1ef5ac690658.png); and ; ![image](https://user-images.githubusercontent.com/6624306/65698967-a6791e00-e07d-11e9-9202-8603e49c4675.png). As you can see, for some reason, there is like a ""jump"" being made between the two steady states of the system, resulting in a final time (t=1) being somewhere between the starting point and one steady state. Running the same simulation with `branching=True` and only two realizations doesn't seem to have this issue. Since I'm a working student at the ICB, I talked to some people here about it, and we found out the following:; - using `method='gauss'` in the `neighbors` call did help in some situations, but playing with more random datasets later on invalidated this hypothesis.; - using less data points (time steps per realization), the intuition was that the high density of points in similar region could have an impact, did work to some",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/854:87,toggle,toggleswitch,87,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/854,3,['toggle'],['toggleswitch']
Deployability,"Hi, that certainly seems like an improvement! I took the liberty to split out two bugs: #3168 and #3169. We had a similar fix #2875, which is hidden behind a `ctrl_as_ref` flag. I think since that fix is not yet released, we should rename the flag and unify both fixes behind it. Could you please; 1. check if issue #3169 is already fixed by installing scanpy’s git version and setting `ctrl_as_ref=True`; 2. Our backwards compatibility means that changes to the scoring need to be optional. This is why `tests/test_score_genes.py::test_score_with_reference` is failing here, and that’s what `ctrl_as_ref` is for. 	So since that option is not yet released and in order to fix the test, we should probably change that option to incorporate both improvements. We can rename it to reflect the two things it does.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3167#issuecomment-2252216712:212,release,released,212,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3167#issuecomment-2252216712,3,"['install', 'release']","['installing', 'released']"
Deployability,"Hi, try installing python-igraph from the wheel here - https://www.lfd.uci.edu/~gohlke/pythonlibs/#python-igraph; And after that install louvain via pip",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/786#issuecomment-522249082:8,install,installing,8,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/786#issuecomment-522249082,2,['install'],"['install', 'installing']"
Deployability,"Hi,. Even when we set `sc.settings.set_figure_params(transparent=False)` the scatter plot for **CATEGORYCAL** data is transparented.; (ex. `sc.pl.umap(adata, color='louvain')` ); Continuous data goes well, so I think it is a bug. When you switch Jupyterlab's theme into dark, it will be easy to check. Best,; Yoshiaki",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/473:179,Continuous,Continuous,179,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/473,1,['Continuous'],['Continuous']
Deployability,"Hi,. First, the error that you are reporting has to do with series types of the dataframes. Howerver, it's very difficult to provide inputs, because it's unclear what `database` and `groupA` are. Can you report a reproducible example? Also, can you update to scanpy 1.6?. Thank you",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1426#issuecomment-706535883:249,update,update,249,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1426#issuecomment-706535883,1,['update'],['update']
Deployability,"Hi,. I am having trouble installing scanpy on 5.12 Manjaro with Python 3.10. I believe it is because llvmlite currently [does not support python 3.10](https://github.com/numba/llvmlite/issues/804#issuecomment-1002971267). Is there a way I can install scanpy with an older version of llvmlite? . ```python; pip install --user scanpy; ```. ```pytb. ERROR: Command errored out with exit status 1:; command: /usr/bin/python -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/setup.py'""'""'; __file__='""'""'/tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' install --record /tmp/pip-record-j38v6hmh/install-record.txt --single-version-externally-managed --user --prefix= --compile --install-headers /home/ube/.local/include/python3.10/llvmlite; cwd: /tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/; Complete output (29 lines):; running install; running build; got version from file /tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/llvmlite/_version.py {'version': '0.34.0', 'full': 'c5889c9e98c6b19d5d85ebdd982d64a03931f8e2'}; running build_ext; /usr/bin/python /tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/ffi/build.py; LLVM version... Traceback (most recent call last):; File ""/tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/ffi/build.py"", line 105, in main_posix; out = subprocess.check_output([llvm_config, '--version']); File ""/usr/lib/python3.10/subprocess.py"", line 420, in check_output; return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,; File ""/usr/lib/python3.10/subprocess.py"", line 501, in run; with Popen(*popenargs, **kwargs) as process:; File ""/usr/lib/python3.10/subprocess.py"", line 966, in __init__; self._execute_child(arg",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2105:25,install,installing,25,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2105,8,['install'],"['install', 'install-', 'install-headers', 'install-record', 'installing']"
Deployability,"Hi,. I am testing `sc.pl.stacked_violin` and I had an issue with running it on an AnnData variable that is imported from a `h5ad` file. I explain. If I run:. ```; >>> import scanpy.api as sc; >>> adata = sc.datasets.krumsiek11(); >>> sc.pl.stacked_violin(adata, adata.var_names, 'cell_type', use_raw=False, color='blue', show=False); ```. No problem, but if I run:. ```; >>> import scanpy.api as sc; >>> adata = sc.datasets.krumsiek11(); >>> adata.write('anndata.h5ad'); >>> adata = sc.read_h5ad('anndata.h5ad'); >>> sc.pl.stacked_violin(adata, adata.var_names, 'cell_type', use_raw=False, color='blue', show=False); ```. then I got the error:. ```; Traceback (most recent call last):; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/anndata.py"", line 896, in stacked_violin; orient='vertical', scale=scale, ax=ax, **kwds); File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 2387, in violinplot; color, palette, saturation); File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 562, in __init__; self.establish_variables(x, y, hue, data, orient, order, hue_order); File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 155, in establish_variables; raise ValueError(err); ValueError: Could not interpret input 'variable'; ```. I tested it with versions 1.3.1 and 1.3.2, installed with bioconda. Any idea?. Bérénice",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/318:1474,install,installed,1474,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/318,1,['install'],['installed']
Deployability,"Hi,. I am testing the `scanpy.api.tl.sandbag` and `scanpy.api.tl.cyclone` functions, after installing the latest version of `pypairs`. . 1. I got an error: `TypeError: 'module' object is not callable`. It seems that it could be solved by calling `pypairs.cyclone.cyclone` or `pypairs.sandbag.sandbag`. 2. In `sandbag`: the argument `fraction` is not used to call the `pypairs` `sandbag` function; 3. In `cyclone` and `sandbag`, `gene_names` and `sample_names` should not be `None`. I can fix these issues in a PR. Bérénice",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/310:91,install,installing,91,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/310,1,['install'],['installing']
Deployability,"Hi,. I am trying to run the Preprocessing and clustering example pipeline in our 10x dataset and when I reach to the point of plotting the UMAP -> sc.pl.umap(adata) I started observing the following error. Traceback (most recent call last):; File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/IPython/core/interactiveshell.py"", line 3331, in run_code; exec(code_obj, self.user_global_ns, self.user_ns); File ""<ipython-input-32-ccd41cdd9550>"", line 3, in <module>; sc.pl.umap(adata); File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 524, in umap; return embedding(adata, 'umap', **kwargs); File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 133, in embedding; data_points, components_list = _get_data_points(adata, basis, projection, components); File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 646, in _get_data_points; f""Could not find entry in `obsm` for '{basis}'.\n""; KeyError: ""Could not find entry in `obsm` for 'umap'.\nAvailable keys are: ['X_pca']."". our data structure is the following . adata; Out[34]: ; AnnData object with n_obs × n_vars = 1858 × 366 ; obs: 'n_genes', 'percent_mito', 'n_counts', 'leiden'; var: 'gene_ids', 'feature_types', 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'; uns: 'log1p', 'pca', 'neighbors', 'leiden'; obsm: 'X_pca'; varm: 'PCs'. ![image](https://user-images.githubusercontent.com/17010046/76561178-23a41e00-6479-11ea-85d5-ec6982f0bd59.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1095:65,pipeline,pipeline,65,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1095,1,['pipeline'],['pipeline']
Deployability,"Hi,. I am working on a project with a labmate and we are using the same dataset. We have found that, when running the same pipeline on the same adata the neighbors / bbknn + UMAP + leiden results, even with the same seed, the clustering solution and UMAP are considerably different. This renders the analysis _unreproducible_ and makes the downstream analysis far more difficult to do, since I have to map my clustering solutions and UMAP plots with hers using markers, and it is quite impractical. We have the same versions of scanpy, leiden, umap, and bbknn on the two computers:. - `scanpy==1.4.5.post2`; - `umap-learn==0.3.10`; - `leidenalg==0.7.0`; - `bbknn==1.3.6`. To try to reproduce the issue, we have created a random matrix with the same seed (10), and create one annData with `sc.pp.neighbours`, and another one with `bbknn`. We have made the adatas to have two batches, so that we can use bbknn. ```; seed = 10; np.random.seed(seed); a = np.random.rand(100, 100); b = np.random.rand(100, 100); print(np.sum(a), np.sum(b)). adata = sc.AnnData.concatenate(sc.AnnData(X=a), sc.AnnData(X=b), batch_categories=['a', 'b']); sc.tl.pca(adata); sce.pp.bbknn(adata, metric='angular'); sc.tl.umap(adata, random_state=seed); sc.tl.leiden(adata, resolution=0.5, random_state=seed); sc.pl.umap(adata, color=['batch', 'leiden'], alpha=0.3); print(adata.uns['neighbors']['connectivities'].sum()). adata_neigh = adata.copy(); sc.pp.neighbors(adata_neigh, metric='cosine', random_state=seed); sc.tl.umap(adata_neigh, random_state=seed); sc.tl.leiden(adata_neigh, resolution=0.6, random_state=seed); sc.pl.umap(adata_neigh, color=['batch', 'leiden'], alpha=0.3); print(adata_neigh.uns['neighbors']['connectivities'].sum()); ```. Our matrices are the same (the sums are 4918.370372081173 and 5005.088472351332), so the random generation works, but then the UMAPs and clustering solutions are different. For the adata run with `sc.pp.neighbors` (left are batches and right are `leiden` cluster labels):; Mine;",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1009:123,pipeline,pipeline,123,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1009,1,['pipeline'],['pipeline']
Deployability,"Hi,. I am writing the Galaxy integration for `pl.paga_path`. From the documentation, I understand that if we can provide an annotation (other than `dpt_pseudotime`) that are keys of `adata.obs`.; I tested with a dataset in which `dpt_pseudotime` is not a key of `adata.obs` and I got the error:. ```; Traceback (most recent call last):; File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/scanpy/plotting/tools/paga.py"", line 930, in paga_path; idcs_group = np.argsort(adata.obs['dpt_pseudotime'].values[; File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/frame.py"", line 2688, in __getitem__; return self._getitem_column(key); File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/frame.py"", line 2695, in _getitem_column; return self._get_item_cache(key); File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/generic.py"", line 2489, in _get_item_cache; values = self._data.get(item); File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/internals.py"", line 4115, in get; loc = self.items.get_loc(item); File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 3080, in get_loc; return self._engine.get_loc(self._maybe_cast_indexer(key)); File ""pandas/_libs/index.pyx"", line 140, in pandas._libs.index.IndexEngine.get_loc; File ""pandas/_libs/index.pyx"", line 162, in pandas._libs.index.IndexEngine.get_loc; File ""pandas/_libs/hashtable_class_helper.pxi"", line 1492, in pandas._libs.hashtable.PyObjectHashTable.get_item; File ""pandas/_libs/hashtable_class_helper.pxi"", line 1500, i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/328:29,integrat,integration,29,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/328,1,['integrat'],['integration']
Deployability,"Hi,. I found that in some tutorial documents, they does not use sc.pp.scale before sc.tl.pca. https://scanpy-tutorials.readthedocs.io/en/latest/integrating-data-using-ingest.html. But for some documents, they used. https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html. This thing also happened in several tools' analysis codes. https://docs.scvi-tools.org/en/stable/tutorials/notebooks/api_overview.html. Therefore, I wonder if the scale function is a key step for PCA analysis or not. Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2164:144,integrat,integrating-data-using-ingest,144,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2164,1,['integrat'],['integrating-data-using-ingest']
Deployability,"Hi,. I think it would help if you updated anndata to 0.6.19. there was a change in 0.6.18 that wrote unordered categoricals, where before categoricals were changed to ordered by default. Hope that helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/645#issuecomment-492292184:34,update,updated,34,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/645#issuecomment-492292184,1,['update'],['updated']
Deployability,"Hi,. If you solely `pip install scanpy` it will use the latest versions of both, Scanpy and umap-learn. These are certainly compatible. Scanpy 1.7.2 not being perfectly compatible with the latest umap-learn package is an artifact of us not pinning the dependencies too hard and being more on the lenient side. I'd suggest to simply use the latest versions of both packages and you should not run into any problems.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2101#issuecomment-1005944568:24,install,install,24,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2101#issuecomment-1005944568,1,['install'],['install']
Deployability,"Hi,. In scanpy 1.1, sc.pl.pca() and sc.tl.tsne() output changes (but still very similar) if they are executed more than once over an object. I have already set random_state value. I've tested that behavior in different installations in different operating systems. Is there a reason for that? I find that behavior baffling and I don't know which output should be trusted: the first time the functions are run or the following?. Thanks for your time.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/203:219,install,installations,219,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/203,1,['install'],['installations']
Deployability,"Hi,. Since the update I get this TypeError when running `sc.pp.normalize_total`. ```python; import scanpy as sc; adata = sc.datasets.pbmc3k(); sc.pp.normalize_total(adata, target_sum=1e4); ```. ```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); Input In [4], in <cell line: 3>(); 1 import scanpy as sc; 2 adata = sc.datasets.pbmc3k(); ----> 3 sc.pp.normalize_total(adata, target_sum=1e4). File ~/my-conda-envs/sc2022-multiomics/lib/python3.10/site-packages/scanpy/preprocessing/_normalization.py:200, in normalize_total(adata, target_sum, exclude_highly_expressed, max_fraction, key_added, layer, layers, layer_norm, inplace, copy); 197 if key_added is not None:; 198 adata.obs[key_added] = counts_per_cell; 199 _set_obs_rep(; --> 200 adata, _normalize_data(X, counts_per_cell, target_sum), layer=layer; 201 ); 202 else:; 203 # not recarray because need to support sparse; 204 dat = dict(; 205 X=_normalize_data(X, counts_per_cell, target_sum, copy=True),; 206 norm_factor=counts_per_cell,; 207 ). File ~/my-conda-envs/sc2022-multiomics/lib/python3.10/site-packages/scanpy/preprocessing/_normalization.py:25, in _normalize_data(X, counts, after, copy); 23 if issubclass(X.dtype.type, (int, np.integer)):; 24 X = X.astype(np.float32) # TODO: Check if float64 should be used; ---> 25 if isinstance(counts, DaskArray):; 26 counts_greater_than_zero = counts[counts > 0].compute_chunk_sizes(); 27 else:. TypeError: isinstance() arg 2 must be a type, a tuple of types, or a union; ```. I've checked that obs_names, var_names, obs columns names are all unique. Any clue how to solve?. Thanks!. #### Versions. <details>. -----; anndata 0.7.8; scanpy 1.9.0; -----; PIL 9.1.0; asttokens NA; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.5.1; decorator 5.1.1; entrypoints 0.4; executing 0.8.3; google NA; h5py 3.6.0; hypergeom_ufunc NA; ipykernel 6.12.1; jedi 0.18.1; job",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2210:15,update,update,15,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2210,1,['update'],['update']
Deployability,"Hi,. Thank you for the great tool. I think this is not a bug. . Recently I upgraded some packages and found my results were different from the previous runs. I figured out that it is caused by different versions of `pynndescent` (0.4.7 vs 0.5.1), which is recommended to use in UMAP. So I think `pynndescent` should be included in the output of `sc.logging.print_header()`. #### Versions. <details>. -----; anndata 0.7.5; scanpy 1.6.1; sinfo 0.3.1; -----; PIL 8.1.0; anndata 0.7.5; constants NA; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; get_version 2.1; h5py 3.1.0; highs_wrapper NA; igraph 0.8.3; joblib 1.0.0; kiwisolver 1.3.1; legacy_api_wrap 1.2; leidenalg 0.8.3; llvmlite 0.35.0; louvain 0.7.0; matplotlib 3.3.3; mpl_toolkits NA; natsort 7.1.1; numba 0.52.0; numexpr 2.7.2; numpy 1.19.5; packaging 20.8; pandas 1.2.1; pkg_resources NA; pynndescent 0.5.1; pyparsing 2.4.7; pytz 2020.5; scanpy 1.6.1; scipy 1.6.0; setuptools_scm NA; sinfo 0.3.1; six 1.15.0; sklearn 0.24.1; statsmodels 0.12.1; tables 3.6.1; texttable 1.6.3; umap 0.4.6; -----; Python 3.8.5 (default, Sep 4 2020, 07:30:14) [GCC 7.3.0]; Linux-3.10.0-1160.11.1.el7.x86_64-x86_64-with-glibc2.10; 40 logical CPU cores, x86_64. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1613:75,upgrade,upgraded,75,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1613,1,['upgrade'],['upgraded']
Deployability,"Hi,. UMAP gives me nice embeddings when the cell types are mostly continuous. But I couldn't get it to work well on a dataset with more discrete cell types. When I use smaller min_dist to separate the clusters better, the clusters tend to become very tiny and distant. When I set larger min_dist to make the clusters occupy more space, the spatial separation between coarse clusters is gone. Adjusting other parameters such as n_neighbors, spread, gamma doesn't give me good results either. . This issue is somewhat similar to the first two UMAP plots in this notebook before doing special initialization: https://github.com/theislab/paga/blob/master/planaria/planaria.ipynb. `min_dist=0.2, n_neighbor=15`: Clear separation between coarse clusters, but clusters become tiny with too much white space. The clusters on the left seem to be repelling those on the right. ; <img src=https://user-images.githubusercontent.com/5046690/41402335-46cf92c4-6f7f-11e8-9b72-48d23d553356.png width=50%>. `min_dist=0.4`: The coarse-level clusters on the right are intermingled (the continuity between cluster 4 and 6 is now broken); <img src=https://user-images.githubusercontent.com/5046690/41402348-57054968-6f7f-11e8-8e24-696ad4afb243.png width=50%>. `min_dist=0.6`: Cells are distributed more smoothly, but the separation between coarse clusters are much less obvious. ; <img src=https://user-images.githubusercontent.com/5046690/41402394-7252b00c-6f7f-11e8-9ffb-2d09a03fc131.png width=50%>. t-SNE in this case gives me more evenly distributed clusters; <img src=https://user-images.githubusercontent.com/5046690/41403178-8257e722-6f81-11e8-9b64-be274e82eadc.png width=50%>. Is there a way to make the UMAP look more intuitive in this kind of situations? Thanks!. (I changed the original question as I feel that this one is more important.)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/174:66,continuous,continuous,66,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/174,1,['continuous'],['continuous']
Deployability,"Hi,. You are correct that DE testing should be performed on raw or normalized data, but not on batch-corrected data. `sc.tl.rank_genes_groups()` doesn't let you include covariates, but there are plenty of methods that do. You could look into `diffxpy` for this, which is also based on AnnData and is easily integrated into a scanpy script. Otherwise, I have a case study for a best practices workflow, which uses MAST. You could reuse code from there as well. You can find the case study [here](https://www.github.com/theislab/single-cell-tutorial).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/669#issuecomment-497118928:307,integrat,integrated,307,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/669#issuecomment-497118928,1,['integrat'],['integrated']
Deployability,"Hi,. didn't see this being tracked here yet. Hope I didn't miss it.; Our PAGA implementation uses Forceatlas2, but unfortunately Forceatlas2 is not really maintained anymore and it does not yet support Python 3.9+. Well the latest release at least. The master branch may work. Sources: ; - https://github.com/bhargavchippada/forceatlas2/issues/34; - https://github.com/bhargavchippada/forceatlas2/issues/35. @gokceneraslan I saw that you contributed some code. Do you still have a connection to the maintainer?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2067:231,release,release,231,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2067,1,['release'],['release']
Deployability,"Hi,. thank you for your PR. Could you please:; 1. Update the body of your PR to introduce and explain what, why and if required how you are doing things.; 2. Why do you think that the volcano plot should go into external? It could go into our core plotting functions, no?; 3. Please try to hardcode as few things as possible. Also, please use the scanpy settings object for plots (e.g. the figure size)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2241#issuecomment-1105162468:50,Update,Update,50,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2241#issuecomment-1105162468,1,['Update'],['Update']
Deployability,"Hi,. which umap package did you install? Which version is it?; Do you know whether the umap package already has support for Apple M1?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1978#issuecomment-898340541:32,install,install,32,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1978#issuecomment-898340541,1,['install'],['install']
Deployability,"Hi,; I am using umap in 3d. I want to plot all 3 components, so I use the `components='all'` parameter.; However, I get this error:. ```python. > sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components='all'). ---------------------------------------------------------------------------; IndexError Traceback (most recent call last); in ; 1 #%%; ----> 2 sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components='all'). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs); 282 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it.; 283 """"""; --> 284 return plot_scatter(adata, 'umap', **kwargs); 285 ; 286 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs); 191 if projection == '3d':; 192 cax = ax.scatter(; --> 193 _data_points[:, 0], _data_points[:, 1], _data_points[:, 2],; 194 marker=""."", c=color_vector, rasterized=settings._vector_friendly,; 195 **kwargs,. IndexError: index 2 is out of bounds for axis 1 with size 2; ```. I was able to plot in 3d by changing it to the following method signature:; ```python; > sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components=['1,2,3']); ```. Probably the documentation should be updated.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/677:1701,update,updated,1701,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/677,1,['update'],['updated']
Deployability,"Hi,; I converted the obs and values in string and it worked.; Thanks. On Mon, 29 Jul 2019 at 06:59, Isaac Virshup <notifications@github.com>; wrote:. > Hi. I just tried running that, and wasn't able to reproduce that error.; > Here's what I ran:; >; > import scanpy as sc; >; > adata = sc.datasets.pbmc3k(); > sc.pp.filter_genes(adata, min_counts=1); > sc.pp.log1p(adata); > sc.pp.highly_variable_genes(adata, min_mean=0.0001, max_mean=3, min_disp=0.5); > sc.pl.highly_variable_genes(adata); > adata = adata[:, adata.var['highly_variable']]; >; > Could you update to the latest releases (scanpy 1.4.4, anndata 0.6.22); > and try that?; >; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/issues/747?email_source=notifications&email_token=ACPDY4U77PLSKFM4ZNQRBYLQBZ2LBA5CNFSM4IG2HWJ2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOD27SWAA#issuecomment-515844864>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ACPDY4VLMX7TXWMWLRDBTPLQBZ2LBANCNFSM4IG2HWJQ>; > .; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/747#issuecomment-516115061:557,update,update,557,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/747#issuecomment-516115061,2,"['release', 'update']","['releases', 'update']"
Deployability,"Hi,; I have some problems running Louvain clustering.; The first time I tried to run, it complains about missing library `igraph`.; I installed `igraph` but now this same library throws a `DeprecationWarning` when calling Louvain clustering. ```; ---------------------------------------------------------------------------; DeprecationWarning Traceback (most recent call last); <ipython-input-17-329d7c2ac26c> in <module>(); ----> 1 sc.tl.louvain(adata). ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/scanpy/tools/louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, n_jobs, copy); 79 directed = False; 80 if not directed: logg.m(' using the undirected graph', v=4); ---> 81 g = utils.get_igraph_from_adjacency(adjacency, directed=directed); 82 if flavor == 'vtraag':; 83 import louvain. ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/scanpy/utils.py in get_igraph_from_adjacency(adjacency, directed); 92 def get_igraph_from_adjacency(adjacency, directed=None):; 93 """"""Get igraph graph from adjacency matrix.""""""; ---> 94 import igraph as ig; 95 sources, targets = adjacency.nonzero(); 96 weights = adjacency[sources, targets]. ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/igraph/__init__.py in <module>(); 6 __license__ = ""MIT""; 7 ; ----> 8 raise DeprecationWarning(""To avoid name collision with the igraph project, ""; 9 ""this visualization library has been renamed to ""; 10 ""'jgraph'. Please upgrade when convenient.""). DeprecationWarning: To avoid name collision with the igraph project, this visualization library has been renamed to 'jgraph'. Please upgrade when convenient.; ```. I can work on a PR and change line 94 of `scanpy/utils.py` to:. ```; import jgraph as ig; ```. This should solve the issue afaik (and `jgraph` should be listed in the dependencies I think). Let me know if you accept PRs. Thanks,; Francesco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/138:134,install,installed,134,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/138,3,"['install', 'upgrade']","['installed', 'upgrade']"
Deployability,"Hi,; I was trying to run the quick example described in the magic api cmd using datasets.paul15 but it keeps on giving me the same error. See below the code I used and the error it gives. . import numpy as np; import pandas as pd; import scanpy.api as sc; import matplotlib.pyplot as pl; import phate; import magic. sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3); sc.settings.set_figure_params(dpi=80) # low dpi (dots per inch) yields small inline figures; sc.logging.print_version_and_date(); # we will soon provide an update with more recent dependencies; sc.logging.print_versions_dependencies_numerics(). Running Scanpy 1.2.2+72.gbc6661c on 2018-07-18 19:40.; Dependencies: anndata==0.6.5 numpy==1.14.3 scipy==1.1.0 pandas==0.23.0 scikit-learn==0.19.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 . adata = sc.datasets.paul15(). WARNING: In Scanpy 0.*, this returned logarithmized data. Now it returns non-logarithmized data.; ... storing 'paul15_clusters' as categorical. sc.pp.normalize_per_cell(adata); sc.pp.sqrt(adata); adata_magic = sc.pp.magic(adata, name_list=['Mpo', 'Klf1', 'Ifitm1'], k=5); adata_magic.shape. computing PHATE. ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-79-129f35d34dbd> in <module>(); 2 sc.pp.normalize_per_cell(adata); 3 sc.pp.sqrt(adata); ----> 4 adata_magic = sc.pp.magic(adata.X, name_list=['Mpo', 'Klf1', 'Ifitm1'], k=5); 5 adata_magic.shape. ~/software/scanpy/scanpy/preprocessing/magic.py in magic(adata, name_list, k, a, t, n_pca, knn_dist, random_state, n_jobs, verbose, copy, **kwargs); 131 n_jobs=n_jobs,; 132 verbose=verbose,; --> 133 **kwargs).fit_transform(adata,; 134 genes=name_list); 135 logg.info(' finished', time=True,. TypeError: 'module' object is not callable",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/208:558,update,update,558,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/208,1,['update'],['update']
Deployability,"Hi,; Is it necessary to use only high variable genes for the downstream analysis ?; If an examperiment includes many batches, then each batch will give a different set of high variable genes, how to determine the shared high variable genes (intersection or union) when integrating the batches ? Does scany have any fucntion to get the shared genes ?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1578:269,integrat,integrating,269,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1578,1,['integrat'],['integrating']
Deployability,"Hi,; Thanks for providing an amazing platform for single-cell data analysis. ; I was trying to use palantir in scanpy and I just reran the example data. However, ; d = sce.tl.palantir(adata) ; always return None for any kind of data. Could you please comment on this?; I am using scanpy 1.5 and have updated Palantir to 0.2.6; Thanks in advance,; Zeinab",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1237:300,update,updated,300,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1237,1,['update'],['updated']
Deployability,"Hi,; Would it be possible to create a panel of plots using both rows and columns when plotting tsne?; I did something similar to this:; ![tsne markers](https://user-images.githubusercontent.com/697622/39486721-19f44a02-4d4b-11e8-986e-d78079a06e0c.png). Basically the code calls the matplotlib subplots method based on the number of plots:. ```py; def _build_subplots(n):; '''; Build subplots grid; n: number of subplots; '''; nrow = int(np.sqrt(n)); ncol = int(np.ceil(n / nrow)); fig, axs = plt.subplots(nrow, ncol, dpi=100, figsize=(ncol*5, nrow*5)). return fig, axs, nrow, ncol; ```. Then the plots are drawn:. ```py; genes = [...list of gene symbols...]; fig, axs, nrow, ncol = _build_subplots(len(genes)). if type(axs) != np.ndarray:; axs = [axs]; else:; axs = axs.ravel(). for i in range(nrow*ncol):; if i < len(genes):; gene = genes[i]; # df is the numpy array containing tSNE; axs[i].scatter(df[:, 0], df[:, 1], ...); ```. Is it something that is already done, planned or that you don't want to integrate?. Thanks,; Francesco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/137:1003,integrat,integrate,1003,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/137,1,['integrat'],['integrate']
Deployability,"Hi,; thanks for fixing this task so quickly! When would you estimate that a new release comes (to pypi) which allows for seaborn>=0.13.0?. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2680#issuecomment-1812184578:80,release,release,80,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680#issuecomment-1812184578,1,['release'],['release']
Deployability,"Hi,; we want to add SCALEX, an online integration method that integrate different single-cell experiments including scRNA-seq and scATAC-seq, which also enable accurate projecting new incoming datasets onto the existing cell space. This method is published on Nature Communications. SCALEX is developed based-on scanpy. We appreciate and will be honored to contribute to the scanpy community. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2355:38,integrat,integration,38,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2355,2,['integrat'],"['integrate', 'integration']"
Deployability,"Hi,; we want to add SCALEX, an online integration method that integrate different single-cell experiments including scRNA-seq and scATAC-seq, which also enable accurate projecting new incoming datasets onto the existing cell space. This method is published on Nature Communications. SCALEX is developed based-on scanpy. We appreciate and will be honored to contribute to the scanpy community. Thank you!; Lei",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2354:38,integrat,integration,38,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2354,2,['integrat'],"['integrate', 'integration']"
Deployability,"Hi. After I performed ingest, I need to concatenate the two datasets. But when followed the tutorial, used concatenated but this function doesn't;t concatenate the .obsm, therefore the UMAP coordinates are not merged. How did you manage to performed UMAP on the integrated/concatenated dataset?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/985:262,integrat,integrated,262,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/985,1,['integrat'],['integrated']
Deployability,"Hi. I have a question. I am using the scanorama for integrating multiple datasets. In my use-case, I will have a new dataset again. The question is, is there any way to transfer the results of scanorama to the new dataset? Or should I retrain everything again. This is also important if one has a train and test set. Ideally, you do not want to use the test set to use in the data integration training and only use the already trained transformation on the test data. . I am wondering if there is a solution for these use-cases? Would you please help us with that. Cheers; Ali",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2162:52,integrat,integrating,52,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2162,2,['integrat'],"['integrating', 'integration']"
Deployability,"Hi. I have successfully installed scanpy but ; ImportError Traceback (most recent call last); <ipython-input-5-99fcf407c387> in <module>; ----> 1 import scvelo as scv; 2 import scanpy as sc; 3 import numpy as np. ~/anaconda3/lib/python3.7/site-packages/scvelo/__init__.py in <module>; 14 del version; 15 ; ---> 16 from .read_load import AnnData, read, read_loom, load, read_csv, get_df, DataFrame; 17 from .preprocessing.neighbors import Neighbors; 18 from .tools.run import run_all, test. ~/anaconda3/lib/python3.7/site-packages/scvelo/read_load.py in <module>; 10 from scipy.sparse import issparse; 11 from anndata import AnnData; ---> 12 from scanpy import read, read_loom; 13 ; 14 . ImportError: cannot import name 'read' from 'scanpy' (unknown location). Would you please help me to fix this problem. Thank you",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1433:24,install,installed,24,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1433,1,['install'],['installed']
Deployability,"Hi. I just tried running that, and wasn't able to reproduce that error. Here's what I ran:. ```python; import scanpy as sc. adata = sc.datasets.pbmc3k(); sc.pp.filter_genes(adata, min_counts=1); sc.pp.log1p(adata); sc.pp.highly_variable_genes(adata, min_mean=0.0001, max_mean=3, min_disp=0.5); sc.pl.highly_variable_genes(adata); adata = adata[:, adata.var['highly_variable']]; ```. Could you update to the latest releases (scanpy `1.4.4`, anndata `0.6.22`) and try that?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/747#issuecomment-515844864:393,update,update,393,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/747#issuecomment-515844864,2,"['release', 'update']","['releases', 'update']"
Deployability,"Hi. Maybe I can help a little as well. Typically batch correction or data integration methods would be used to obtain good clustering of the data, however once differential testing is performed it is still unclear whether the corrected data can or should be used (no batch correction method is perfect and may overcorrect). The standard strategy would be to correct for batch, and any other covariates that you are not interested in for the clustering process. Once you have the clusters, it is standard practice to go back to the raw data and use a differential testing algorithm that allows you to account for batch and other technical covariates in the model (e.g. MAST).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/168#issuecomment-395726806:74,integrat,integration,74,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/168#issuecomment-395726806,1,['integrat'],['integration']
Deployability,"Hi. So @vals `gprofiler` and `gprofiler-official` are different packages, and having them both installed could cause an issue like this. Is this the case here?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1896#issuecomment-866565353:95,install,installed,95,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1896#issuecomment-866565353,1,['install'],['installed']
Deployability,"Hi. This is unlikely to be a scanpy issue. You probably don’t have enough memory or there’s some problem with your Jupyter configuration. But in any case, we need more information to tell which one it is. Please share the logs that `jupyter lab` created, especially any stack traces around “kernel died, restarting”",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2675#issuecomment-1750301889:123,configurat,configuration,123,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2675#issuecomment-1750301889,1,['configurat'],['configuration']
Deployability,"Hi. While @flying-sheep is right that this is a question for the discourse group, I have a quick response here. Check out the tutorials here:; https://scanpy.readthedocs.io/en/stable/tutorials.html. You can merge anndata objects with `anndata.concatenate()`, and if you're looking for data integration methods, there are a couple of them in `scanpy.external`. For example MNN (works better in `mnnpy` though), and BBKNN. Scanorama also has a nice scanpy interface... and I think `SCVI` also has a scanpy integration tutorial (but can be harder to use than scanorama).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/859#issuecomment-545962554:290,integrat,integration,290,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/859#issuecomment-545962554,2,['integrat'],['integration']
Deployability,"Hi.; I have a problem to install fa2 (pip install fa2) in windows 10 operating system and I am using python 3.7 version? . Using Conda env . **sc.tl.draw_graph(ds, init_pos='paga'),**; **drawing single-cell graph using layout 'fa'; WARNING: Package 'fa2' is not installed, falling back to layout 'fr'.To use the faster and better ForceAtlas2 layout, install package 'fa2' (`pip install fa2`).**. installation error. Collecting fa2; Using cached fa2-0.3.5.tar.gz (435 kB); Requirement already satisfied: numpy in c:\programdata\miniconda3\envs\jayalal_2_miniconda\lib\site-packages (from fa2) (1.18.4); Requirement already satisfied: scipy in c:\programdata\miniconda3\envs\jayalal_2_miniconda\lib\site-packages (from fa2) (1.4.1); Requirement already satisfied: tqdm in c:\programdata\miniconda3\envs\jayalal_2_miniconda\lib\site-packages (from fa2) (4.46.0); Building wheels for collected packages: fa2; Building wheel for fa2 (setup.py) ... error; ERROR: Command errored out with exit status 1:; command: 'C:\ProgramData\Miniconda3\envs\Jayalal_2_Miniconda\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""'; __file__='""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d 'C:\Users\xkalaj\AppData\Local\Temp\pip-wheel-yjh93oit'; cwd: C:\Users\xkalaj\AppData\Local\Temp\pip-install-golo7r_8\fa2\; Complete output (30 lines):; Installing fa2 package (fastest forceatlas2 python implementation). >>>> Cython is installed?; Yes. >>>> Starting to install!. running bdist_wheel; running build; running build_py; creating build; creating build\lib.win-amd64-3.6; creating build\lib.win-amd64-3.6\fa2; copying fa2\fa2util.py -> build\lib.win-amd64-3.6\fa2; copying fa2\forceatlas2.py -> build\li",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1256:25,install,install,25,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1256,6,['install'],"['install', 'installation', 'installed']"
Deployability,"Hi; I am trying to concatenate two anndata objects(adata = adata1.concatenate(adata3, join='inner')), but get an error message informing me that concatenate is not found. Any idea what might cause this behavior? Here is what I have installed:scanpy==1.4.3 anndata==0.6.22.post1 umap==0.3.9 numpy==1.16.2 scipy==1.2.1 pandas==0.24.2 scikit-learn==0.20.3 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1. and here is the error:; AttributeError Traceback (most recent call last); <ipython-input-187-32c3eda3cdc8> in <module>; ----> 1 adata = adata1.concatenate(adata3, join='inner'). ~/anaconda3/envs/scenv/lib/python3.6/site-packages/scipy/sparse/base.py in __getattr__(self, attr); 687 return self.getnnz(); 688 else:; --> 689 raise AttributeError(attr + "" not found""); 690 ; 691 def transpose(self, axes=None, copy=False):. AttributeError: concatenate not found; Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/760:232,install,installed,232,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/760,1,['install'],['installed']
Deployability,Hi; I'm facing an installation issue. The issues are explained below; I got failed to install **louvain and bioconductor-rhdf5lib** from paga_project_environment.yml (See file contents below). Using Window 10 . > conda env create -f .\sc_tutorial_environment.yml** ; error **CondaEnvException: Pip failed**. Please find .yml file from here https://github.com/theislab/single-cell-tutorial,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1220:18,install,installation,18,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1220,2,['install'],"['install', 'installation']"
Deployability,"Hm, PyTorch 1.12.1 doesn’t seem to be available, otherwise I was able to install all package versions you specified. I created an attempt at a reproducer here, but it just runs in less than a second for me: https://github.com/flying-sheep/scanpy-2531. No idea how to further debug this. Looks like you’re on macOS. one of the new M1 or M2 ones?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2531#issuecomment-1609286107:73,install,install,73,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2531#issuecomment-1609286107,1,['install'],['install']
Deployability,"Hm, yes it's nice that things are simpler now, but the point of the script before was to use the fast installation of the conda binaries... . Before your commit: 3 min 46 s test time (https://travis-ci.org/theislab/scanpy/builds/454438531?utm_source=github_status&utm_medium=notification). After your commit: 6 min 46 s test time (https://travis-ci.org/theislab/scanpy/builds/454487170?utm_source=github_status&utm_medium=notification). While the 3 min 46 s are way too long, there is still a good chance that you realize that your commit broke everything. After almost 7 min, you're almost always doing something else already. I also feel kind of bad about travis's servers. ;)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/360#issuecomment-439746463:102,install,installation,102,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/360#issuecomment-439746463,1,['install'],['installation']
Deployability,"Hm. the conda package doesn’t list availability for windows: https://anaconda.org/bioconda/scanpy, just “conda install linux-64 v1.3.7, osx-64 v1.3.7”",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/454#issuecomment-462259888:111,install,install,111,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454#issuecomment-462259888,1,['install'],['install']
Deployability,"Hmm, I'm having trouble reproducing using the same release. Could be an issue with an underlying library? I'm using a slightly newer scipy. <details>; <summary> My environment </summary>. ```; -----; anndata 0.7.5; scanpy 1.7.1; sinfo 0.3.1; -----; IPython 7.21.0; PIL 8.1.0; anndata 0.7.5; backcall 0.2.0; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; decorator 4.4.2; get_version 2.1; h5py 3.1.0; ipython_genutils 0.2.0; jedi 0.17.2; joblib 1.0.1; kiwisolver 1.3.1; legacy_api_wrap 1.2; llvmlite 0.35.0; matplotlib 3.3.4; mpl_toolkits NA; natsort 7.1.1; numba 0.52.0; numexpr 2.7.2; numpy 1.20.1; packaging 20.9; pandas 1.2.2; parso 0.7.0; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.8; ptyprocess 0.7.0; pygments 2.8.1; pyparsing 2.4.7; pytz 2021.1; scanpy 1.7.1; scipy 1.6.1; sinfo 0.3.1; six 1.15.0; sklearn 0.24.1; storemagic NA; tables 3.6.1; traitlets 5.0.5; wcwidth 0.2.5; -----; Python 3.8.5 (default, Sep 4 2020, 02:22:02) [Clang 10.0.0 ]; macOS-10.15.7-x86_64-i386-64bit; 16 logical CPU cores, i386; -----; Session information updated at 2021-03-20 16:27; ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1749#issuecomment-803253215:51,release,release,51,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1749#issuecomment-803253215,2,"['release', 'update']","['release', 'updated']"
Deployability,"Hmm, Maybe they have another scanpy version installed or some other weird broken setup. why not?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/603#issuecomment-482103939:44,install,installed,44,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/603#issuecomment-482103939,1,['install'],['installed']
Deployability,"Hmm, it’s in the source package and the wheel, but maybe it doesn’t get installed? Maybe `include_package_data=True` needs to be restored. How did you install from the source package anyway? Pip always uses wheels if possible, right?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/995#issuecomment-574587706:72,install,installed,72,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/995#issuecomment-574587706,2,['install'],"['install', 'installed']"
Deployability,"Hmm, there was a recent release of marplotlib that seemed to mess with a lot of our plots. Could you post an example of what you're getting and let us know your scanpy and matplotlib versions?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1098#issuecomment-599163401:24,release,release,24,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1098#issuecomment-599163401,1,['release'],['release']
Deployability,"Hmm, you're right. I think it must have been the that the ordering of cells in the `adata` object was also non-random. We had this quite a bit in the benchmarking data integration project while plotting batch. In several methods (e.g., scanorama), individual batch anndata objects are concatenated to generate the final output, which results in batch-ordered anndata objects. . Maybe instead of just having `sort_order=False` it would be better to have randomized ordering for plotting categorical variables? Unless it is an ordered categorical I guess.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1588#issuecomment-760249638:168,integrat,integration,168,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1588#issuecomment-760249638,1,['integrat'],['integration']
Deployability,Hmm. Did your original object already have a pca computed on it? I'm not sure if the values in `obsm` would have been updated when you made a shallow copy with `copy`.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1239#issuecomment-631984912:118,update,updated,118,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1239#issuecomment-631984912,1,['update'],['updated']
Deployability,"Hmm. I'm not able to replicate the exact error, but I get a different one. Could you try running:. ```python; adata = adata.copy(); ```. right before `normalize_total` and see if that works?. ----------------------. Update: tried on a different machine and could replicate your error. The issue is that `normalize_total` doesn't make sure the anndata object isn't a view before assigning to it. As a work-around, you can just run `adata = adata.copy()` before `sc.pp.normalize_total(adata)`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1183#issuecomment-621000991:216,Update,Update,216,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1183#issuecomment-621000991,1,['Update'],['Update']
Deployability,"Hmm...I must admit I don't understand why a ""view"" exists. Views are often tricky to get right, especially in a complex datastructure like anndata. They also slow down processing, especially if users may not be aware that the object they have is a view of something else. I don't see a good use case for views in my pipeline at least. Is there a way to switch off all views in anndata and just return a copy when slicing?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/728#issuecomment-516291062:316,pipeline,pipeline,316,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/728#issuecomment-516291062,1,['pipeline'],['pipeline']
Deployability,Hmmm. I am getting this error with scipy 1.4.1. New install of phenograph so I don't have an older version to roll back to. Hopefully they fix this soon!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1407#issuecomment-699501883:52,install,install,52,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1407#issuecomment-699501883,1,['install'],['install']
Deployability,"Hope that's what you mean by a release note @ivirshup , let me know if it needs anything else.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2025#issuecomment-987736310:31,release,release,31,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2025#issuecomment-987736310,1,['release'],['release']
Deployability,"Hopefully last update on this PR. What I did:; - I noticed a regression on the method `rank_genes_groups_violin`, therefore I reverted back the code to the original one and I added an additional method `genes_groups_violin` which should be used if we want to pass the list of genes directly to the violin plot. The code is just a POC, but maybe it can be integrated; - Within the same method `rank_genes_groups_violin`, I found a bug: the ax variable was overwritten for each group (I don't know if it gave you error before). In my case, all the plots were merged into a single figure, every one on top of the previous ones; - Additionally, the parameters `gene_symbols` and `computed_distribution` were not defined within the method `rank_genes_groups_violin`. I added a default parameter (`None`) for `gene_symbols`, since it was defined in the docstring. With `computed_distribution` I didn't know what you wanted to do so I temporarily commented the line that used it",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/141#issuecomment-387106636:15,update,update,15,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/141#issuecomment-387106636,2,"['integrat', 'update']","['integrated', 'update']"
Deployability,"Hotfix for rapids nn:. * fixes bug with `random_state` for `RapidsKNNTransformer.__init__`; * now return distance matrix with `self.nn.kneighbors_graph(X_contiguous, mode=""distance"")`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2648:0,Hotfix,Hotfix,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2648,1,['Hotfix'],['Hotfix']
Deployability,"How I save plots is:. ```python; from matplotlib import pyplot as plt. with plt.rc_context(): # Use this to set figure params like size and dpi; sc.pl.plotting_function(..., show=False); plt.savefig(""path/to/file.extension"", bbox_inches=""tight""); ```. I think how this argument works is one of the things we would change in a major API breaking release. @fidelram, would you add anything to this?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1508#issuecomment-734657400:345,release,release,345,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1508#issuecomment-734657400,1,['release'],['release']
Deployability,How did you install scanpy? What conda command did you use?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2173#issuecomment-1063418303:12,install,install,12,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2173#issuecomment-1063418303,1,['install'],['install']
Deployability,"How did you installed scanpy?. Try:. conda install --file requirements.txt. this may install all the right versions of the packages that you need. On Thu, Oct 4, 2018 at 2:26 AM ar-baya <notifications@github.com> wrote:. > Hi, I am reproducing this tutorial; > https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170503_zheng17/zheng17.ipynb; >; > the line sc.pp.neighbors(adata) produces the following error:; >; > Inconsistency detected by ld.so: dl-version.c: 205:; > _dl_check_map_versions: Assertion `needed != NULL' failed!; >; > Ubuntu 18.04; > Python 3.6.6; >; > scanpy==1.3.1 anndata==0.6.10 numpy==1.15.2 scipy==1.1.0 pandas==0.23.4; > scikit-learn==0.19.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1; >; > Can you help me? Thank You; >; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/issues/280>, or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AEu_1Sgm2UxCRL2y2-EGlah7YmtIrmmeks5uhVXGgaJpZM4XHKo6>; > .; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/280#issuecomment-426896350:12,install,installed,12,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/280#issuecomment-426896350,3,['install'],"['install', 'installed']"
Deployability,"How is this work going? We'd love to integrate Scrublet into our workflows, which are currently quite Scanpy-centric.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/173#issuecomment-545010991:37,integrat,integrate,37,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/173#issuecomment-545010991,1,['integrat'],['integrate']
Deployability,"How pandas does this: there's branch for a minor version, e.g. `1.1.x`. Bugfixes get back ported to this branch, and releases are tagged here. There is automation of back porting through [meeseeksbox](https://meeseeksbox.github.io). We might have to request access for this?. Julia does something pretty similar, except it looks like all back ports are done at once in a PR, instead of continuously. This is a bit more manual, but requires less setup. Both of these systems use tags to mark which PRs need back porting.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1399#issuecomment-685401364:117,release,releases,117,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1399#issuecomment-685401364,2,"['continuous', 'release']","['continuously', 'releases']"
Deployability,How to integrate the snRNA seq data generated by `scanpy` with the snATAC seq data generated by `ArchR` ?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3273:7,integrat,integrate,7,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3273,1,['integrat'],['integrate']
Deployability,How to update obs-column only for subset of cells?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/612:7,update,update,7,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/612,1,['update'],['update']
Deployability,"Howdy y'all, working on a tool to convert packages to JSON and noticed there were some functions missing their parameters in the docstring. I've updated a few that were missing for better pydoc accessibility. All param descriptions were either copied from other similar param or made based on their functionality. - [x] Tests included or not required because:. Docstring updates only. - [x] Release notes not necessary because:. No changes to logic",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2888:145,update,updated,145,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2888,3,"['Release', 'update']","['Release', 'updated', 'updates']"
Deployability,"Huh weird, it gets detected, but it doesn’t seem to help to call the non-parallel version lol. If I replace the `warn` with a `print`, it’s clear that the correct (non-parallel) function is called from Dask’s thread. Seems like calling numba from a `ThreadPoolExecutor` isn’t supported at all, even if it comes from dask. ```console; $ hatch test tests/test_utils.py::test_is_constant_dask[csr_matrix-0] --capture=no; Numba function called from a non-threadsafe context. Try installing `tbb`.; Numba function called from a non-threadsafe context. Try installing `tbb`. Numba workqueue threading layer is terminating: Concurrent access has been detected. - The workqueue threading layer is not threadsafe and may not be accessed concurrently by multiple threads. Concurrent access typically occurs through a nested parallel region launch or by calling Numba parallel=True functions from multiple Python threads.; - Try using the TBB threading layer as an alternative, as it is, itself, threadsafe. Docs: https://numba.readthedocs.io/en/stable/user/threading-layer.html. Fatal Python error: Aborted. Thread 0x000000016fd2f000 (most recent call first):; File ""~/Dev/scanpy/src/scanpy/_compat.py"", line 133 in wrapper; File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 109 in _; File ""<venv>/lib/python3.12/functools.py"", line 909 in wrapper; File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 30 in func; File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task; File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 157 in get; File ""<venv>/lib/python3.12/site-packages/dask/optimization.py"", line 1001 in __call__; File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task; File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 225 in execute_task; File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 239 in batch_execute_tasks; File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", li",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3335#issuecomment-2457625478:475,install,installing,475,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335#issuecomment-2457625478,2,['install'],['installing']
Deployability,"Huh, I can't reproduce but can look into this a bit more. Could you share the results of:. ```python; from importlib.metadata import version as v. v(""anndata""); ```. and. ```python; import anndata. anndata.__version__; ```. ?. Also, anything extra you can tell us about your environment? E.g. did you install with pip or conda? `uv`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2978#issuecomment-2037230309:301,install,install,301,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2978#issuecomment-2037230309,1,['install'],['install']
Deployability,"Huh. It sounds like `pip` is installing to a different environment than the one you're using for scanpy. How are you starting the relevant python session? Also, are you sure you're restarted that session after updating scipy?. To check to see if you're in the same environment, these commands should tell you where scipy is installed:. ```sh; pip show scipy. python -c ""import scipy; print(scipy.__file__)""; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1252#issuecomment-635099440:29,install,installing,29,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252#issuecomment-635099440,2,['install'],"['installed', 'installing']"
Deployability,"Huh. This is really weird, since it looks like it's almost entirely due to scipy sparse indexing. Must have something to do with versions. Two things:. * If you upgrade scipy, do you still run into this error?; * Could you get the version info from an environment where you've only imported scanpy and run this command?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1670#issuecomment-783074166:161,upgrade,upgrade,161,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1670#issuecomment-783074166,1,['upgrade'],['upgrade']
Deployability,I added a test and a release node,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2589#issuecomment-1666905237:21,release,release,21,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2589#issuecomment-1666905237,1,['release'],['release']
Deployability,"I addressed some of the points in your review already and will finish latest on Monday :). > > tests that check if combinations of input arguments lead to expected output (in terms of returned shapes/columns/...) and don't break the function; > > tests that check if warnings/errors are raised for ""common mistakes"" (inappropriate data, nonsense input argument combinations..); > ; > yes both makes sense, it would also be useful to come up with a dummy example for which the actual output could be tested against. This is done in seurat_v3 for instance, but in that case it's kind of straightforward because the ""expected"" is the output computed with original implementation (and as you catched in #1732 it's still might not be enough smile ).; > another random thing that comes to mind re this specific case is to make sure that indexing etc. is consistent and robust, as you seem to have to sort and resort a fair bit in the hvg implementation. Sounds good, thanks for the input! I will prepare some tests early next week.; ; > on another note, I was thinking if it makes sense to also release a short tutorial together with the PR (that would be on theislab/scanpy_tutorials) ? I think that for a lot of people the term ""pearson residuals"" could be alienating, and so they'd rather stick to `normalize_total` for comfort (but they shouldn't!). So maybe just something easy like pearson res norm + umap and hvg plots ? curious to hear what you and the others @ivirshup @LuckyMD think about it. I think that would be really nice - I'd very happy prepare to some examples if everyone agrees that this would be useful to have :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1715#issuecomment-797689998:1089,release,release,1089,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715#issuecomment-797689998,1,['release'],['release']
Deployability,"I agree that using the intersection is too harsh if the only data integration/batch correction you do is this HVG filtering, but for `mnn_correct` for example you only use these HVGs to calculate the technical batch vector. In that case you ideally don't want to capture the biological variation between batch samples. For that I reckon having an option of getting the intersection would be good. And for point 2... definitely agreed... but again, a different use case for me. The same approach (intersection of HVGs) is suggested for the new CCA in Seurat v3 btw.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/614#issuecomment-485875031:66,integrat,integration,66,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/614#issuecomment-485875031,1,['integrat'],['integration']
Deployability,"I agree with Phil, but it's not a priority right now. The installation of both igraph and louvain has to be done only once... these packages don't evolve much. So I think it's OK for people to have this little inconvenience as it's only once in the beginning.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/176#issuecomment-398686980:58,install,installation,58,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/176#issuecomment-398686980,1,['install'],['installation']
Deployability,"I also encountered this h5py dll error on a Windows 10 machine when trying to install scanpy. Fixed following these instructions, followed by `pip install numpy==1.20` due to a subsequent numpy version conflict with numba. > > In case anyone has this error again, here is what worked for me:; > > ; > > * go to https://www.lfd.uci.edu/~gohlke/pythonlibs/ and download a .whl file for h5py. For python 3.6 on a 64bit windows OS this is the file h5py‑2.10.0‑cp36‑cp36m‑win_amd64.whl; > > * with your conda environment activated, install that wheel file using `python -m pip install --user --force-reinstall h5py‑2.10.0‑cp36‑cp36m‑win_amd64.whl` (change the file name to the one you downloaded).; > > * scanpy should work now; > > ; > > This worked on mine and also on a colleagues windows laptop.; > > I guess the problem is that you need a C++ compiler to build the necessary H5DF libraries. This works fine in UNIX based OS (Mac and Linux), but in windows you would need to download the most recent C++ compiler from some microsoft build tools website or alongside Visual Studio. So installing a prebuildt wheel for windows circumwents that problem. I wonder when h5py people will ever fix this for us poor Windows users.; > ; > this helped me out as well",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/454#issuecomment-1018430040:78,install,install,78,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454#issuecomment-1018430040,5,['install'],"['install', 'installing']"
Deployability,"I also have the same problem and I tried to use `pip install louvain`, but I cannot install the package and it says `legacy-install-failure`. The GitHub for the [louvain](https://github.com/vtraag/louvain-igraph/tree/master) says,. > Warning; > ; > This package has been superseded by the [leidenalg](https://github.com/vtraag/leidenalg) package and will no longer be maintained.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1283#issuecomment-1637853756:53,install,install,53,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1283#issuecomment-1637853756,3,['install'],"['install', 'install-failure']"
Deployability,I also installed DCA and tensorflow in the meantime... Maybe it has to do with different backend functions being used?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/246#issuecomment-416565579:7,install,installed,7,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/246#issuecomment-416565579,1,['install'],['installed']
Deployability,"I also just found this: https://docs.pytest.org/en/stable/pythonpath.html#import-modes. > `importlib`: new in pytest-6.0, this mode uses importlib to import test modules.; > […]; > makes test modules non-importable by each other.; > […]; > ; > **We intend to make importlib the default in future releases.**",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1528#issuecomment-741748332:296,release,releases,296,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528#issuecomment-741748332,1,['release'],['releases']
Deployability,I also ran into this issue when using scanpy==1.4.2 and scipy==1.3.0 (which are the versions installed when I install using conda). Enforcing scipy==1.2.1 in my conda environment file fixed it.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/643#issuecomment-494058404:93,install,installed,93,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/643#issuecomment-494058404,2,['install'],"['install', 'installed']"
Deployability,"I also recently encountered this issue. I've dug into the problem a little bit and for me the cause seems to be that the sc.pp.scale function introduces the NaN values. This occurs for columns which show very little variance and are almost constant. According to the current documentation this should not be the current expected behaviour though and should only (possibly) occur in future versions: . `Variables (genes) that do not display any variation (are constant across all observations) are retained and (for zero_center==True) set to 0 during this operation. In the future, they might be set to NaNs.`. So I'm not sure if this is a bug or if the documentation has not been updated yet. . I've currently circumvented the issue by scaling in sklearn (which retains 0s instead of NaNs) and manually loading the scaled results into my adata object as this is the behaviour I would like for my dataset. In case my example dataset would be helpful let me know then I can share it with you.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2163#issuecomment-2191634706:680,update,updated,680,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2163#issuecomment-2191634706,1,['update'],['updated']
Deployability,"I am also currently trying to figure out how to get around this. I am getting this error when calling `sc.pl.rank_genes_groups_violin` using a ""gene_symbols"" parameter (this function works when that parameter is omitted but the x-axis labels are not what I desire). In my case, `adata.uns[""rank_genes_groups""][""names""]` content is set to `adata.var_names` (where the index column is separate from what is being passed to the ""gene_symbols"" parameter outlined earlier). I am running anndata==0.7.8 and scanpy==1.8.2 so this issue has been around for a couple release versions.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2256#issuecomment-1131777861:558,release,release,558,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2256#issuecomment-1131777861,1,['release'],['release']
Deployability,"I am also getting the error `RuntimeWarning: invalid value encountered in log; dispersion = np.log(dispersion)` when running `sc.pp.highly_variable_genes(adata, min_mean=1.7, max_mean=5, min_disp=0.5, flavor='seurat')` on log scale data in the adata.X slot with mean=0 and max=16.336065. Any ideas?. Update: I just noticed that my adata.X contains a numpy array instead of a sparse matrix. Perhaps that's the issue? Will try updating to a sparse matrix and will report back",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/391#issuecomment-718294561:300,Update,Update,300,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/391#issuecomment-718294561,1,['Update'],['Update']
Deployability,"I am also getting the error when running. sc.pp.neighbors(). AssertionError: Storing i64 to ptr of i32 ('dim'). FE type int32. I tried pip uninstall numba and pip install numba==0.52.0 and numba==0.51.0, but nothing works. I had umap-learn 0.4.6, and updating it resolved the issue for me:; conda install -c conda-forge umap-learn",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1799#issuecomment-867004309:163,install,install,163,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799#issuecomment-867004309,2,['install'],['install']
Deployability,"I am also unable to install scanpy on mac OS. I tried using python 3.8.x . 3.7.x and 3.6.x. ```; (base) $ conda activate SCA. (SCA) $ conda --version; conda 4.8.2. (SCA) $ python --version; Python 3.6.10 :: Anaconda, Inc. (SCA) $ conda install -c bioconda scanpy; Collecting package metadata (repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: \ ; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1142#issuecomment-609514112:20,install,install,20,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1142#issuecomment-609514112,2,['install'],['install']
Deployability,"I am closing the issue because it was my mistake: I ran the script that I saved several years ago instead of the updated, current one at https://scanpy.readthedocs.io/en/stable/_sources/tutorials/basics/clustering-2017.ipynb; (where the argument rotation is omitted)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3140#issuecomment-2206318149:113,update,updated,113,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3140#issuecomment-2206318149,1,['update'],['updated']
Deployability,I am facing the same issue. I have recently updated my scanpy to the latest version.; I think that it was working before that. Here is rest of my software versions; scanpy==1.4.6 anndata==0.7.1 umap==0.3.9 numpy==1.17.4 scipy==1.3.1 pandas==0.25.3 scikit-learn==0.22 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1237#issuecomment-632650992:44,update,updated,44,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1237#issuecomment-632650992,1,['update'],['updated']
Deployability,"I am getting the same highly variable genes between the two runs. The discrepancy is introduced at the PCA step which generates slightly different results between the two runs. The biological interpretation ends up essentially the same in my case but the clusterings are subtly different, making it hard to automate my annotation. I would like the overall pipeline to be reproducible across platforms if possible. I can dig a bit into the PCA code... it seems like this might be an issue on the scikit-learn end.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1187#issuecomment-620866096:356,pipeline,pipeline,356,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187#issuecomment-620866096,1,['pipeline'],['pipeline']
Deployability,"I am getting this error when I run scanpy.pp.neighbors(adata); As far as I know, I have the latest packages mentioned here.; anndata 0.7.6 pypi_0 pypi; louvain 0.7.0 py38h9dedd22_1 conda-forge; pandas 1.1.3 py38hb1e8313_0; python-igraph 0.9.1 py38h3dab7cd_0 conda-forge; scanpy 1.7.2 pypi_0 pypi; scikit-learn 0.23.2 py38h959d312_0; scipy 1.6.3 py38h431c0a8_0 conda-forge; statsmodels 0.12.0 py38haf1e3a3_0; umap-learn 0.5.1 py38h50d1736_0 conda-forge. Is there probably another package that is outdated?. **EDIT: Not sure what module I updated but now it works. I use 'conda update --all' and others to do that.** . thanks",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1154#issuecomment-835038994:537,update,updated,537,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1154#issuecomment-835038994,2,['update'],"['update', 'updated']"
Deployability,"I am getting this same error, namely when I run `sc.pl.umap(adata, color='pid')` I see `UserWarning: No data for colormapping provided via 'c'. Parameters 'cmap' will be ignored` and then `adata.uns['pid_colors']` all gets set to gray, and my whole UMAP plot looks gray instead of being color by 'pid.'. I am using scanpy 1.9.1 and matplotlib 3.6.3. Can someone advise me what I need to upgrade to avoid this error, or how I can work around it with my current package versions? I see that #2212 upped the required matplotlib to 3.4, but since I'm at 3.6.3 I thought I should be okay. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2208#issuecomment-1477955919:387,upgrade,upgrade,387,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2208#issuecomment-1477955919,1,['upgrade'],['upgrade']
Deployability,"I am having lots of trouble installing scanpy on my M1 Macbook Pro. After installing the arm64 version of Miniforge 3 and creating a virtual environment on Python 3.9.4, I followed the documentation for conda installation. However, I got build errors when running the pip commands. Has anyone discovered a workaround to this?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1840:28,install,installing,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1840,3,['install'],"['installation', 'installing']"
Deployability,"I am having the same problem,however pip install anndata --upgrade didn't work for me. pip said it is already the latest version: Requirement already satisfied: anndata in d:\python3.10.9\lib\site-packages (0.9.1), then I really don't know what to do. Could you guys help me with that? [crying]",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1351#issuecomment-1627431509:41,install,install,41,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351#issuecomment-1627431509,2,"['install', 'upgrade']","['install', 'upgrade']"
Deployability,"I am having this same problem. I updated:; anndata 0.7.5; scanpy 1.6.0. It did not fix the problem for me. . I can try with the pbmc data set, what should I use for the groupby?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1406#issuecomment-767855186:33,update,updated,33,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1406#issuecomment-767855186,1,['update'],['updated']
Deployability,"I am more and more convinced about having a single package for the reasons @adamgayoso mentioned. To address a few concerns from above: . ---. > > Who manages the sub-packages?; > ; > Scverse (also it's one package not many). We are talking about 5-15 readers that have been touched a handful of times in 4-5 years. I don't think this is a complicated package to maintain. Agree that one person needs to take the lead on releases (probably very infrequent). Scverse core developers could take turns (e.g. every 6 months) in being ""lead maintainer"", i.e. in charge of releases and first-responders to issues (delegating them to the most appropriate people). This has the additional advantage that everything needs to be documented to a point that there can't be a single point of failure. . ---. > Also it's nice when you install a package call a function and it works, less nice to have to start mucking around with dependencies. ```; pip install scio[all]; ```. could be broadly advertised in the README. Packages could still use the slimmer version, e.g. in scirpy, I could depend on ; `scio[vdj]`. . ---. > I think there are formats where there isn't one obvious ""right way"" to represent them as an AnnData object (e.g. visium), so having a canonical reading/ writing function is difficult. I think we should aim at having one obvious ""right way"" to represent something with AnnData and MuData. A common `scio` package could be a way to achieve that. . > I know squidpy will be changing its representation and I think muon should have changes to the ATAC representation. Also muon and scvi-tools read in different things from 10x atac data. A solution to that would be versioned schemata. E.g. whatever squidpy uses now is the ""spatial schema `v1`"". When we come up with a better way it becomes the ""spatial schema `v2`"". Old schemata will be deprecated but can stick around for a while. If a schema is experimental and subject to active changes it can be `v0.1`. . ```python; scio.spatial.read_vis",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1387#issuecomment-1059727261:421,release,releases,421,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1387#issuecomment-1059727261,4,"['install', 'release']","['install', 'releases']"
Deployability,I am not sure what --add does or -c . The following is probably a cleaner way to install. It should not have any unforeseen 'channels' related side effects. . This worked for me on MacOS Catalina; ```; $ conda create --name SCA python=3.8.2; (base) $ conda activate SCA; (SCA) $ conda install scanpy --channel conda-forge --channel bioconda; ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/990#issuecomment-609560683:81,install,install,81,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/990#issuecomment-609560683,2,['install'],['install']
Deployability,"I am partial color blind as well. So I second any initiative in this; direction. On Tue, Dec 4, 2018 at 7:03 PM Alex Wolf <notifications@github.com> wrote:. > We're using a custom color map in scanpy by default, anyways:; > https://github.com/theislab/scanpy/blob/master/scanpy/plotting/palettes.py#L22; > .; >; > It would, of course, be easy to change this, but then everything changes; > for everyone and many people will wonder why everything looks different now; > (""where is my green cluster?""). If we do it, we only exchange green with; > another color, so that at least all other colors will be unaffected...; >; > I would have liked to wait until a major update, because I consider this; > breaking backward consistency, though...; >; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/issues/387#issuecomment-444197487>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AEu_1aBQoQxEiqx5gNfgpj2-tJvQZ2Ssks5u1rjXgaJpZM4ZA5qf>; > .; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/387#issuecomment-444388795:663,update,update,663,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/387#issuecomment-444388795,1,['update'],['update']
Deployability,"I am running into the same issue and unfortunately running the steps as described here https://github.com/theislab/scanpy/issues/1567#issuecomment-968181500 does not solve my problem. My kernel systematically dies when I run `sc.pp.neighbors` (even with only 1,000 cells). What I am also confused about is that this used to work - I am guessing I updated a package somewhere that broke everything but I cannot identify what. This is my config:; - MacBook Pro (13-inch, M1, 2020) - macOS Big Sur 11.5.2; - python 3.8.8; - numpy 1.20.0; - numba 0.51.2; - umap-learn 0.5.2. I have tried running the following code in Jupyter and then in a script to see if I could get more info on the bug:; ```; unhealthy_cells = sc.read_h5ad(""path/to/file""). unhealthy_cells.layers[""counts""] = unhealthy_cells.X.copy(). sc.pp.normalize_total(unhealthy_cells,target_sum=10000). sc.pp.log1p(unhealthy_cells). sc.pp.scale(unhealthy_cells). sc.tl.pca(unhealthy_cells). sc.pp.neighbors(unhealthy_cells); ```; When I run it as a python script, I get the following error when getting to `sc.pp.neighbors` (everything else works): ; `zsh: illegal hardware instruction`. Is there anything I could do? ; Thank you for your help!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1567#issuecomment-1024104927:347,update,updated,347,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1567#issuecomment-1024104927,1,['update'],['updated']
Deployability,"I am trying to follow the pbmc3k tutorial. I pushed through the regres_out error mentioned in #1010 , but now it fails at line: . ```python; sc.tl.leiden(adata); ```; with error : . ```pytb; running Leiden clustering. ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-46-a9ad6348435f> in <module>; ----> 1 sc.tl.leiden(adata). ~/miniconda3/envs/i529/lib/python3.7/site-packages/scanpy/tools/_leiden.py in leiden(adata, resolution, restrict_to, random_state, key_added, adjacency, directed, use_weights, n_iterations, partition_type, copy, **partition_kwargs); 138 adata.obs[key_added] = pd.Categorical(; 139 values=groups.astype('U'),; --> 140 categories=natsorted(np.unique(groups).astype('U')),; 141 ); 142 # store information on the clustering parameters. ~/miniconda3/envs/i529/lib/python3.7/site-packages/pandas/core/arrays/categorical.py in __init__(self, values, categories, ordered, dtype, fastpath); 383 ; 384 else:; --> 385 codes = _get_codes_for_values(values, dtype.categories); 386 ; 387 if null_mask.any():. ~/miniconda3/envs/i529/lib/python3.7/site-packages/pandas/core/arrays/categorical.py in _get_codes_for_values(values, categories); 2574 _, cats = _get_data_algo(categories); 2575 t = hash_klass(len(cats)); -> 2576 t.map_locations(cats); 2577 return coerce_indexer_dtype(t.lookup(vals), cats); 2578 . pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.StringHashTable.map_locations(). TypeError: Expected unicode, got numpy.str_. ```. #### Versions:; scanpy __version__ is 1.4.4.post1, everything was installed using conda in a freshly created environment.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1028:1624,install,installed,1624,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1028,1,['install'],['installed']
Deployability,"I am trying to get clustering labels from Louvain. I followed the Seurat-like notebook (https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb). I am able to run the clustering and visualize it on tSNE, with:. ```python; >>> sc.tl.louvain(adata); running Louvain clustering; using the ""louvain"" package of Traag (2017); finished (0:00:00.11) --> found 8 clusters and added; 'louvain', the cluster labels (adata.obs, categorical); >>> sc.pl.tsne(adata, color='louvain'); ```. However, I cannot find the clustering labels under adata:. ```; AnnData object with n_obs × n_vars = 1320 × 5014 ; uns: 'pca'; obsm: 'X_pca', 'X_tsne'; varm: 'PCs'; ```. I tried looking directly into obs, obsm etc., but I didn't find any label. But the plots work out correctly. How is it possible?. I have the default louvain parameters, so it should be updated in-place.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/144:872,update,updated,872,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/144,1,['update'],['updated']
Deployability,"I am trying to import scanpy but I am running into an error:. Also, a bit of a noob to python in general, but I think I have most required things installed. ```python; import scanpy as sc; ```; I am using Python 3.7 in a virtual environment (potato37); The above code gives me the following error:. ```pytb; InvalidVersion Traceback (most recent call last); /tmp/ipykernel_4345/4007328772.py in <module>; ----> 1 import scanpy as sc; 2 import anndata; 3 from scipy import io; 4 from scipy.sparse import coo_matrix, csr_matrix; 5 import numpy as np. /data/personal_folders/user/potato37/lib/python3.7/site-packages/scanpy/__init__.py in <module>; 12 # (start with settings as several tools are using it); 13 from ._settings import settings, Verbosity; ---> 14 from . import tools as tl; 15 from . import preprocessing as pp; 16 from . import plotting as pl. /data/personal_folders/user/potato37/lib/python3.7/site-packages/scanpy/tools/__init__.py in <module>; 15 from ._leiden import leiden; 16 from ._louvain import louvain; ---> 17 from ._sim import sim; 18 from ._score_genes import score_genes, score_genes_cell_cycle; 19 from ._dendrogram import dendrogram. /data/personal_folders/user/potato37/lib/python3.7/site-packages/scanpy/tools/_sim.py in <module>; 21 from anndata import AnnData; 22 ; ---> 23 from .. import _utils, readwrite, logging as logg; 24 from .._settings import settings; 25 from .._compat import Literal. /data/personal_folders/user/potato37/lib/python3.7/site-packages/scanpy/readwrite.py in <module>; 8 import pandas as pd; 9 from matplotlib.image import imread; ---> 10 import tables; 11 import anndata; 12 from anndata import (; ; /data/personal_folders/user/potato37/lib/python3.7/site-packages/tables/__init__.py in <module>; 51 from .unimplemented import UnImplemented, Unknown; 52 from .expression import Expr; ---> 53 from .tests import print_versions, test; 54 ; 55 ; ; /data/personal_folders/user/potato37/lib/python3.7/site-packages/tables/tests/__init__.py in <mod",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2138:146,install,installed,146,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2138,1,['install'],['installed']
Deployability,I am using 1.4.3. I tried to upgrade to 1.4.4 but I was having a lot of problem with dependencies. Wonder it 1.4.3 is recent enough? Thank you so much.; scanpy 1.4.3 py_0 bioconda,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/871#issuecomment-544294477:29,upgrade,upgrade,29,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/871#issuecomment-544294477,1,['upgrade'],['upgrade']
Deployability,"I am using a Docker container, but from the settings it seems like the first `anndata` install was with conda.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2978#issuecomment-2037684581:87,install,install,87,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2978#issuecomment-2037684581,1,['install'],['install']
Deployability,"I am using the latest M1 macbook pro with python 3.10.3. For some reason if you clone the repository then compile it works in python 3.9+; I cannot explain why the release tarball has issues. As per some other documentation, it is because [tp_print has been removed from type objects for python 3.9+.](https://docs.python.org/3/c-api/typeobj.html) See below. So, if you clone the repository using git and then install it works! (I am sure there is an explanation). ```; test@mac ~/PythonPackages/forceatlas2$ git pull; Already up to date.; test@mac ~/PythonPackages/forceatlas2$ pip3 install . --user; Processing /Users/test/PythonPackages/forceatlas2; Preparing metadata (setup.py) ... done; Requirement already satisfied: numpy in /Users/test/.local/lib/python3.10/site-packages (from fa2==0.3.5) (1.21.5); Requirement already satisfied: scipy in /Users/test/.local/lib/python3.10/site-packages (from fa2==0.3.5) (1.8.0); Requirement already satisfied: tqdm in /Users/test/.local/lib/python3.10/site-packages (from fa2==0.3.5) (4.63.0); Building wheels for collected packages: fa2; Building wheel for fa2 (setup.py) ... done; Created wheel for fa2: filename=fa2-0.3.5-cp310-cp310-macosx_12_0_x86_64.whl size=155419 sha256=23d907bfec5df0e9d0d522865d1c288b1f8894134bd61b6c5a02467128dfd102; Stored in directory: /private/var/folders/0s/67yn6b6n3lx4882xx_86ps2m0000gp/T/pip-ephem-wheel-cache-i69s_t3j/wheels/51/1c/a5/5a9ef4f0bc9387d300190bc15adbb98dbda9d90c6da9c2da04; Successfully built fa2; Installing collected packages: fa2; Successfully installed fa2-0.3.5 ; test@mac ~/PythonPackages/forceatlas2$; ```. However, if you try to install the release version you get an error:. ```; test@mac ~/PythonPackages$ wget https://github.com/bhargavchippada/forceatlas2/archive/refs/tags/v0.3.5.tar.gz; --2022-03-24 02:54:21-- https://github.com/bhargavchippada/forceatlas2/archive/refs/tags/v0.3.5.tar.gz; Resolving github.com (github.com)... 140.82.114.3; Connecting to github.com (github.com)|140.82.114.3|:",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2067#issuecomment-1077457096:164,release,release,164,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2067#issuecomment-1077457096,3,"['install', 'release']","['install', 'release']"
Deployability,"I believe the issues are related. I think pip is trying to get the version of the wheel by parsing it's name instead. For example, I just ran into this with where scanpy's version was being reported as: `1.8.0.dev34-g8d8039d9` – which I don't think is a valid version. I then `pip install -e`'d and got a version of `1.8.0.dev29+gc8309488` (different branches) and it worked fine.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1527#issuecomment-784973197:281,install,install,281,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527#issuecomment-784973197,1,['install'],['install']
Deployability,"I calculated `sc.tl.paga(adata, groups='cell_ontology_class')` without problems but I couldn't run `sc.tl.paga_expression_entropies(adata)`. I've modified the original code and it now runs - if this looks good you can perhaps update the original code? also, if it doesn't let me know so I don't carry over the mistakes!. ```; from scipy.stats import entropy; groups_order, groups_masks = sc.utils.select_groups(tiss, key=tiss.uns['paga']['groups']); entropies = []; for mask in groups_masks:; X_mask = tiss.X[mask].todense(); x_median = np.nanmedian(X_mask, axis=1,overwrite_input=True); x_probs = (x_median - np.nanmin(x_median)) / (np.nanmax(x_median) - np.nanmin(x_median)); entropies.append(entropy(x_probs)); entropies; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/367:226,update,update,226,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/367,1,['update'],['update']
Deployability,"I can confirm this as a working workaround. Thank you @michalk8 . > @pati-ni; > I have the similar issue when installing CellRank as `conda install -c bioconda cellrank`. Problem is not all dependencies are on bioconda, some of them are on `conda-forge` - I've tested it and I have the same problem with scanpy.; > Installing it as `conda install -c bioconda -c conda-forge scanpy` works. But @ivirshup is right, seems like conda issue.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1298#issuecomment-662450011:110,install,installing,110,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1298#issuecomment-662450011,4,"['Install', 'install']","['Installing', 'install', 'installing']"
Deployability,"I can recover the previous behavior, i.e., different runs of the notebook give identical UMAP and leiden clusters, by downgrading to scanpy version 1.9.2 (and also pandas to version 1.5.3). I do this in conda and in this environment other relevant installed package versions are numpy 1.23.5, scipy 1.10.1 and scikit-learn 1.2.2.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2480#issuecomment-1531696555:248,install,installed,248,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2480#issuecomment-1531696555,1,['install'],['installed']
Deployability,"I can reproduce from the full tutorial. The issue here is that `scanorama` has updated it's API since this tutorial was written. Now `scanorama.correct_scanpy` returns AnnData objects. @giovp, where should this tutorial live?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2143#issuecomment-1049184473:79,update,updated,79,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2143#issuecomment-1049184473,1,['update'],['updated']
Deployability,"I can reproduce the problem. Very strange. I will submit a PR to fix it. On Wed, Nov 21, 2018 at 5:03 AM Andreas <notifications@github.com> wrote:. > I upgraded to 1.3.3 and the bug persists.; >; > PS: I accidentally closed the issue for some reason.; >; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/issues/370#issuecomment-440522061>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AEu_1b3a4RVAX6v4o3oY_e3a1sh1Rnq2ks5uxNCCgaJpZM4YrmLi>; > .; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/370#issuecomment-440556607:152,upgrade,upgraded,152,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/370#issuecomment-440556607,1,['upgrade'],['upgraded']
Deployability,"I can reproduce this plotting issue with matplotlib `v3.1.1`. I think upgrading to `v3.1.3` should fix your problem, i.e. `pip3 install ""matplotlib==3.1.3""`. Unfortunately there's another bug in heatmaps introduced by `3.2.0` that just got fixed on scanpy master (#1090), and hasn't been in a release yet.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1098#issuecomment-599167801:128,install,install,128,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1098#issuecomment-599167801,2,"['install', 'release']","['install', 'release']"
Deployability,"I can understand your thought process behind facilitating the integration of anndata into the broader ecosystem and I can also understand the frustration. I don't think the integration is quite as bad as you suggest though. `adata.X` is still a `numpy.ndarray` and can be used as such, exactly as `adata.var` and `adata.obs` are dataframes. The only issue is when you require the object to work as a whole data structure in a particular function. I'm not the most experienced `numpy` user, but from what I've seen, you would typically expect any `numpy` function that you apply to an `anndata` object to be applied to `adata.X` and don't require information in other parts of the object. Or am I missing a use case here? So the only change would then be that `adata = np.srqt(adata)` would need to become `adata.X = np.sqrt(adata.X)`. Furthermore, it's not entirely clear what a `numpy` function applied to an `AnnData` object should do. `np.min()` could be on `adata.X` or any column in `.obs` or `.var`. You can call it on the columns in the `pandas` dataframes already via `pandas` conventions... which makes a bit more sense to me. Regarding the slicing conventions... @ivirshup has mentioned a few reasons why things are sliced as they are in `scanpy`. What would your suggestion look like? `loc` and `iloc` work for `adata.obs` and `adata.var` atm. Would you forbid an `adata['Cell A',:]`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1030#issuecomment-584118922:62,integrat,integration,62,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1030#issuecomment-584118922,2,['integrat'],['integration']
Deployability,"I can't install MulticoreTSNE, and it may not even work on python >3.6. Since we want to drop 3.6 support (#1697), it would be good to stop recommending it, and pass the n_jobs parameter to sklearn's tsne. This PR attempts to do that, along with a bunch of deprecation warnings. I've also bumped the sklearn dependency to make sure TSNE is multithreaded. Metric was added to test if n_jobs was working. Either way, it seems to be using all the cpu on my laptop. Not sure what's up with that. ## TODO:. - ~~[ ] Figure out how to get n_jobs to actually limit cpu usage~~ Leaving this up to sklearn; - [x] Test metric; - [x] Test deprecations",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1854:8,install,install,8,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1854,1,['install'],['install']
Deployability,"I cannot install scanpy successfully. (conda v. 4.7.12). $ conda create -n scanpy_scRNA -c bioconda scanpy ; Collecting package metadata (current_repodata.json): done; Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.; Collecting package metadata (repodata.json): done; Solving environment: / ; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Package numba conflicts for:; scanpy -> numba[version='>=0.41.0']; Package matplotlib conflicts for:; scanpy -> matplotlib[version='3.0.*|>=2.2']; Package h5py conflicts for:; scanpy -> h5py!=2.10.0; Package networkx conflicts for:; scanpy -> networkx; Package scipy conflicts for:; scanpy -> scipy[version='<1.3|>=1.3']; Package scikit-learn conflicts for:; scanpy -> scikit-learn[version='>=0.21.2']; Package joblib conflicts for:; scanpy -> joblib; Package natsort conflicts for:; scanpy -> natsort; Package seaborn conflicts for:; scanpy -> seaborn; Package setuptools conflicts for:; scanpy -> setuptools; Package pytables conflicts for:; scanpy -> pytables; Package anndata conflicts for:; scanpy -> anndata[version='>=0.6.10|>=0.6.22rc1']; Package importlib-metadata conflicts for:; scanpy -> importlib-metadata; Package importlib_metadata conflicts for:; scanpy -> importlib_metadata[version='>=0.7']; Package tqdm conflicts for:; scanpy -> tqdm; Package pandas conflicts for:; scanpy -> pandas[version='>=0.21']; Package umap-learn conflicts for:; scanpy -> umap-learn[version='>=0.3.0']; Package patsy conflicts for:; scanpy -> patsy; Package louvain conflicts for:; scanpy -> louvain; Package python conflicts for:; scanpy -> python[version='>=3.6|>=3.6,<3.7.0a0']; Package python-igraph conflicts for:; scanpy -> python-igraph; Package statsmodels conflicts for:; scanpy -> statsmodels[version='>=0.10.0rc2']",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/990:9,install,install,9,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/990,1,['install'],['install']
Deployability,I checked #1468. Tried conda install pytables. But it did not work.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2173#issuecomment-1063426953:29,install,install,29,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2173#issuecomment-1063426953,1,['install'],['install']
Deployability,"I confirmed that setting the PYTHONHASHSEED environmental variable to 0 did not change the results. The code run below (in jupyter notebook) gave the same results as before while confirming that the PYTHONHASHSEED variable was set to 0 before running the pipeline. ```; # First run on a machine on with 8 CPUs; %env PYTHONHASHSEED=0; import numpy as np; import pandas as pd; import scanpy as sc; adata = sc.read_10x_mtx(; './data/filtered_gene_bc_matrices/hg19/', ; var_names='gene_symbols',; cache=True) . sc.pp.filter_cells(adata, min_genes=200); sc.pp.filter_genes(adata, min_cells=3); sc.pp.normalize_total(adata, target_sum=1e4); sc.pp.log1p(adata); adata = adata.copy(); sc.pp.scale(adata, max_value=10); sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5); adata = adata[:, adata.var.highly_variable]; sc.tl.pca(adata, svd_solver='arpack', random_state=14); sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14); sc.write('test8.h5ad', adata); sc.tl.pca(adata, svd_solver='randomized', random_state=14); sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14); sc.write('test8_randomized.h5ad', adata); ! echo $PYTHONHASHSEED. # Then run on a machine on with 16 CPUs; %env PYTHONHASHSEED=0; import numpy as np; import pandas as pd; import scanpy as sc; adata = sc.read_10x_mtx(; './data/filtered_gene_bc_matrices/hg19/', ; var_names='gene_symbols',; cache=True) . sc.pp.filter_cells(adata, min_genes=200); sc.pp.filter_genes(adata, min_cells=3); sc.pp.normalize_total(adata, target_sum=1e4); sc.pp.log1p(adata); adata = adata.copy(); sc.pp.scale(adata, max_value=10); sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5); adata = adata[:, adata.var.highly_variable]; sc.tl.pca(adata, svd_solver='arpack', random_state=14); sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14); sc.write('test16.h5ad', adata); sc.tl.pca(adata, svd_solver='randomized', random_state=14); sc.pp.neighbors(adata, n_neighbors=10, ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1187#issuecomment-620841409:255,pipeline,pipeline,255,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187#issuecomment-620841409,1,['pipeline'],['pipeline']
Deployability,"I did figure out what's going on. I worked on a view of an AnnData object, where the original AnnData object did not have the X_pca field and it could not be added only in the view. I updated to the latest scanpy and anndata version; > scanpy==1.4+18.gaabe446 anndata==0.6.18+3.g3e93ed7 numpy==1.15.4 scipy==1.2.1 pandas==0.24.1 scikit-learn==0.20.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 . this is my AnnData object:; ```; adata; print(adata); ```; > AnnData object with n_obs × n_vars = 14775 × 25386 ; > obs: 'sample', 'n_genes', 'percent_mito', 'n_counts'; > var: 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. if I now filter my AnnData object for highly variable genes I only got a ""View"" of my AnnData object; ```; adata2 = adata[:, adata.var['highly_variable']]; print(adata2); print(adata); ```. > View of AnnData object with n_obs × n_vars = 14775 × 1999 ; > obs: 'sample', 'n_genes', 'percent_mito', 'n_counts'; > var: 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. > AnnData object with n_obs × n_vars = 14775 × 25386 ; > obs: 'sample', 'n_genes', 'percent_mito', 'n_counts'; > var: 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. then on adata2, I cannot add the X_pca field; `sc.tl.pca(adata2, svd_solver='arpack')`. > ---------------------------------------------------------------------------; > ValueError Traceback (most recent call last); > <ipython-input-25-05be375bfc24> in <module>; > 5 print(adata); > 6 print(adata2); > ----> 7 sc.tl.pca(adata2, svd_solver='arpack'); > 8 print(adata2); > ; > ~/miniconda3/lib/python3.7/site-packages/scanpy-1.4+18.gaabe446-py3.7.egg/scanpy/preprocessing/_simple.py in pca(data, n_comps, zero_center, svd_solver, random_state, return_info, use_highly_variable, dtype, copy, chunked, chunk_size); > 504 ; > 505 if data_is_AnnData:; > --> 506 adata.obsm['X_pca'] = X_pca; > 507 if use_highly_variable:; > 508 adata.varm['PCs'] = np.zeros(shape=(adata",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/504#issuecomment-467361094:184,update,updated,184,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/504#issuecomment-467361094,1,['update'],['updated']
Deployability,"I did, and then I realized that we have the `import scanpy as sc` change and more features, so I called it 1.4. Btw: could you please add me as owner to scanpy and anndata on PyPI? then I can manage releases and delete files on PyPI.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/450#issuecomment-460625486:199,release,releases,199,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/450#issuecomment-460625486,1,['release'],['releases']
Deployability,I didn't add release note yet because I'm not sure if this should already go into 1.10.4,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3295#issuecomment-2421911169:13,release,release,13,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3295#issuecomment-2421911169,1,['release'],['release']
Deployability,"I didn't keep perfect track of the steps that I took to solve this or the exact versions of everything that I used but I'll try outlining what I did. First I tried to upgrade numba and umap as suggested by the other individuals in the thread:; ```bash; pip install --upgrade numba; pip install --upgrade umap-learn; ```. Then I essentially reinstalled scanpy using the steps in their installation docs. ```bash; conda install seaborn scikit-learn statsmodels numba pytables; conda install -c conda-forge python-igraph leidenalg; pip install scanpy; ```. I think I then ended up with a version of numpy that was incompatible with numba so I ran. ```bash; pip install numpy==1.20; ```. After each step, you should be able to run the code from above to check if your installations worked, which I used to pinpoint what still needed work in my environment:; ```bash; python3 -c ""import numpy as np; import umap; umap.UMAP().fit_transform(np.random.randn(10_000, 20))""; ```. This seemed to fix my problems; I hope it's able to help others!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1567#issuecomment-968181500:167,upgrade,upgrade,167,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1567#issuecomment-968181500,11,"['install', 'upgrade']","['install', 'installation', 'installations', 'upgrade']"
Deployability,"I didn't use any filtering before the pipeline, but I read the barcode and gene names from index and columns of the data frame. and i have a cuff-off of the cell for my own. update——————————————; The calculation is depends on module ""patsy"" and it is not in the dependency list of scanpy or I have some problems with installing that package. ; After I reinstalled and updated ""pasty"", problem fixed",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/212#issuecomment-407454918:38,pipeline,pipeline,38,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/212#issuecomment-407454918,4,"['install', 'pipeline', 'update']","['installing', 'pipeline', 'update', 'updated']"
Deployability,"I don't have `pytest` installed locally (will change that), and the plan was to emulate the Travis python 3.5 environment, but I'm not sure what versions of all the dependencies are in there. I've been debugging in a notebook, but it always works there... at least with python 3.6. I'll try just creating a conda python 3.5 env to see what happens when I do that. Chances are it will always work locally as well though... hence my remote debugging. Sorry for that... Previous print statements have shown that the order of covariates is just different sometimes in the recarrays. So I thought it would all be fixed with 5b602f5.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/583#issuecomment-479462140:22,install,installed,22,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/583#issuecomment-479462140,1,['install'],['installed']
Deployability,"I don't have a lot to add. As far as I know there's no native Python implementation of clustering trees. If you want to use the R **{clustree}** package you will need to transfer your data from R to Python in some way. Using straight **{reticulate}** to read a `.h5ad` file like you have here is one option but there are packages that will do it for you including [**{zellkonverter}**](https://bioconductor.org/packages/release/bioc/html/zellkonverter.html), [**{anndata}**](https://cran.r-project.org/web/packages/anndata/index.html) and [**{SeuratDisk}**](https://github.com/mojaveazure/seurat-disk). Once you have a `SingleCellExperiment` or `Seurat` you can plug that directly into **{clustree}**. It should also be possible to call **{clustree}** from Python using [**anndata2ri**](https://github.com/theislab/anndata2ri) but I'm not sure of the details of how to do that. If you only want a basic clustering tree you could just transfer the clustering assignments (by saving to CSV for example). That would probably be easier/quicker than transferring the whole dataset but you would lose the opportunity to overlay other information such as marker gene expression (which is often really helpful). Unless you plan ahead and append that to whatever you save to disk. Sorry, that was longer than I thought 😸! Hope it helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/670#issuecomment-785722015:420,release,release,420,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/670#issuecomment-785722015,1,['release'],['release']
Deployability,"I don't know when it's due, but if it's released tomorrow scanpy will stop working and that scares me 😑",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/779#issuecomment-524178694:40,release,released,40,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/779#issuecomment-524178694,1,['release'],['released']
Deployability,I don't think `igraph` or `louvain` are actually being installed on readthedocs. . I think you'll need to modify the `.readthedocs.yml` for this. But not calling `louvain` could also work.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1811#issuecomment-827747018:55,install,installed,55,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1811#issuecomment-827747018,1,['install'],['installed']
Deployability,I don't think i saw changes without version updates. The only thing I noticed there are the diffmap coordinates occasionally being mirrored.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1363#issuecomment-678257370:44,update,updates,44,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1363#issuecomment-678257370,1,['update'],['updates']
Deployability,"I don't think this is a segfault, but a `TypeError`. I believe this is due to using an out of date version of `numba`. Could you update that and let me know if the error persists?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1193#issuecomment-622662852:129,update,update,129,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193#issuecomment-622662852,1,['update'],['update']
Deployability,I don't think we need to test against 3.8 until a stable release is out. I'm thinking we can just drop that from travis and merge?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/704#issuecomment-506145082:57,release,release,57,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/704#issuecomment-506145082,1,['release'],['release']
Deployability,I downloaded the folder from GitHub and then installed Scanpy and it worked for me.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/544#issuecomment-475911257:45,install,installed,45,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/544#issuecomment-475911257,1,['install'],['installed']
Deployability,"I downloaded the github source archive at the 1.8.2 tag. The build process applies a few patches viewable [here](https://salsa.debian.org/med-team/python-scanpy/-/tree/master/debian/patches). One is a small change to some R code, and the other is I marked several more tests as needs internet because the Debian builds in an environment without network access and those ultimately tried to download something. (And it's really unclear if we can legally redistributed the 10x pbmc3k dataset.). The Debian build file is (here)[https://salsa.debian.org/med-team/python-scanpy/-/blob/master/debian/rules] though mostly it lets you see what tests I was skipping because of missing dependencies. Also if I set a color like in_tissue, or array_row the data shows up. I can paste the full build log if you'd like but this is the dependencies installed and the environment variables. . ```; Build-Origin: Debian; Build-Architecture: amd64; Build-Date: Sun, 14 Nov 2021 20:11:26 +0000; Build-Path: /<<PKGBUILDDIR>>; Installed-Build-Depends:; adduser (= 3.118),; adwaita-icon-theme (= 41.0-1),; autoconf (= 2.71-2),; automake (= 1:1.16.5-1),; autopoint (= 0.21-4),; autotools-dev (= 20180224.1+nmu1),; base-files (= 12),; base-passwd (= 3.5.52),; bash (= 5.1-3.1),; binutils (= 2.37-8),; binutils-common (= 2.37-8),; binutils-x86-64-linux-gnu (= 2.37-8),; blt (= 2.5.3+dfsg-4.1),; bsdextrautils (= 2.37.2-4),; bsdutils (= 1:2.37.2-4),; build-essential (= 12.9),; bzip2 (= 1.0.8-4),; ca-certificates (= 20211016),; coreutils (= 8.32-4.1),; cpp (= 4:11.2.0-2),; cpp-11 (= 11.2.0-10),; dash (= 0.5.11+git20210903+057cd650a4ed-3),; dbus (= 1.12.20-3),; dbus-bin (= 1.12.20-3),; dbus-daemon (= 1.12.20-3),; dbus-session-bus-common (= 1.12.20-3),; dbus-system-bus-common (= 1.12.20-3),; dbus-user-session (= 1.12.20-3),; dconf-gsettings-backend (= 0.40.0-2),; dconf-service (= 0.40.0-2),; debconf (= 1.5.79),; debhelper (= 13.5.2),; debianutils (= 5.5-1),; dh-autoreconf (= 20),; dh-python (= 5.20211105),; dh-strip-no",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2048#issuecomment-969885616:89,patch,patches,89,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2048#issuecomment-969885616,4,"['Install', 'install', 'patch']","['Installed-Build-Depends', 'installed', 'patches']"
Deployability,"I experienced the same issue, but none of fixes proposed here worked.; Eventually I re-installed Anaconda, immediately set up the channels, and made a new environment:. ```; conda config --add channels default; conda config --add channels bioconda; conda config --add channels bioconda. #create a new environment; conda create --name <environment name>; #activate your environment ; conda activate <environment name>; ```. Now that I had a new environment (which is easier to work with if you're working on multiple projects; easy switch between environments!), I tried to install scanpy again. Did not work, but then I tried it again, this time with the version number of Python, and that did the trick for me!. `conda install -c bioconda scanpy python=3.7`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/990#issuecomment-584658003:87,install,installed,87,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/990#issuecomment-584658003,3,['install'],"['install', 'installed']"
Deployability,"I feel like the `np.min(adata)` is more emblematic of the issue at hand here, which is how hard we should work to integrate with the rest of the python ML/data science ecosystem, e.g. `matplotlib.pyplot.scatter`. My personal view is nothing that works with a pandas DataFrame shouldn't work with an `AnnData` object; if you make it harder for people to work with AnnData than the most obvious competing data structure, they will simply use that other object.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1030#issuecomment-584219033:114,integrat,integrate,114,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1030#issuecomment-584219033,1,['integrat'],['integrate']
Deployability,"I figured the one-item-thing out: The emitted code is:. ```rst; :param copy: If an :class:`~anndata.AnnData` is passed, determines whether a copy; is returned.; :type copy: `bool`, optional (default: `False`). :returns: AnnData, None; Depending on `copy` returns or updates `adata` with the corrected data matrix.; ```. And since `:returns:` is part of a field list, and field lists are defined by the indentation of the *block starting in the second line*, the additional indentation of the second line is ignored. So yes, only numpydoc-style sections with one item are affected.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/610#issuecomment-484050694:266,update,updates,266,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/610#issuecomment-484050694,1,['update'],['updates']
Deployability,"I first understood the warning that the default will be switched so that we have to be explicit (`flavor=""leidenalg""`) if the old default works for us. But the warning persists, maybe suggesting that we should switch to `flavor=""igraph""`. When switching to `igraph`, we get a deprecation warning `resolution_parameter keyword argument is deprecated, use resolution=... instead` which has been deprecated in igraph some years ago ([7848bcb](https://github.com/igraph/python-igraph/commit/7848bcbc8b81fa248362f56d5593d366836deb1f#diff-cba05fe79beed98bcc3a46ca51cc58e92142b971ce1caebb8c23895101fde8dcR467-R469)). Scanpy has not yet updated the parameter since the [initial](https://github.com/scverse/scanpy/commit/9fa4c0f9abf4b050f6e347565dff24f9b317cb32) leiden implementation, or the deprecation was not noticed. Can users ignore the warning, or should users put an upper cap on the igraph version to be safe?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2865#issuecomment-2112993599:629,update,updated,629,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2865#issuecomment-2112993599,1,['update'],['updated']
Deployability,I fixed the bug: https://github.com/theislab/scanpy/commit/15593d532fbaa696bf1ea328d1991d31b334e175. . And I'll immediately make a new release and put a warning on the webpage... @Koncopd: Thank you for adding the tests!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/393#issuecomment-446373823:135,release,release,135,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/393#issuecomment-446373823,1,['release'],['release']
Deployability,I fixed this issue!. It should be all good in SAM version 0.7.2. Please update SAM using either pip or github. Let me know if there are still any other problems.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1157#issuecomment-615359662:72,update,update,72,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1157#issuecomment-615359662,1,['update'],['update']
Deployability,"I found a workaround that does not require downloading the `.whl` file for `numpy=1.19.5`. ; By default, MKL is included when you install numpy with conda. It's good to do this in a new environment.; ```; conda create -n scanpy_env; conda activate scanpy_env; conda install numpy=1.19; conda install seaborn scikit-learn statsmodels numba pytables; conda install -c conda-forge python-igraph leidenalg; pip install scanpy==1.8.1; ```; Now I can run `sc.pp.highly_variable_genes()` with no problem.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2073#issuecomment-1020416116:130,install,install,130,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2073#issuecomment-1020416116,5,['install'],['install']
Deployability,"I get an error trying to merge multiples slides using the code in the tutorial. Is it possible to install the scanpy version the tutorial is using?. ```python; adata = adata.concatenate(; list(slides.values()),; batch_key=""sample"",; uns_merge=""unique"",; batch_categories=list(sample_data['sample_name'].values), ; index_unique=None; ); ```. ```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-4-fe8a54a66c17> in <module>; 40 uns_merge=""unique"",; 41 batch_categories=list(sample_data['sample_name'].values),; ---> 42 index_unique=None; 43 ); 44 . TypeError: concatenate() got an unexpected keyword argument 'uns_merge'; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1254#issuecomment-635702014:98,install,install,98,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1254#issuecomment-635702014,1,['install'],['install']
Deployability,"I got an error doing `pip3 install -e .`:. > clang -Wno-unused-result -Wsign-compare -Wunreachable-code -fno-common -dynamic -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/usr/local/include -I/usr/local/opt/openssl/include -I/usr/local/opt/sqlite/include -I/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/include/python3.6m -c scanpy/cython/utils_cy.c -o build/temp.macosx-10.11-x86_64-3.6/scanpy/cython/utils_cy.o; > scanpy/cython/utils_cy.c:435:10: fatal error: 'numpy/arrayobject.h' file not found; > #include ""numpy/arrayobject.h""; > ^; > 1 error generated.; > error: command 'clang' failed with exit status 1; > ; > ----------------------------------------; > Command ""/usr/local/opt/python3/bin/python3.6 -c ""import setuptools, tokenize;__file__='/Users/jyhung/Documents/scanpy/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" develop --no-deps"" failed with error code 1. It worked after I installed cython: `pip3 install cython`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/22:27,install,install,27,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/22,3,['install'],"['install', 'installed']"
Deployability,"I had a false alarm related to this just now (I thought I was on recent anndata+scanpy versions, but a defunct older clone of anndata was sneaking onto my `$PYTHONPATH`). Confirming it's fixed:. **Dockerfile:**; ```Dockerfile; FROM python:3.8.5; ARG anndata; ARG scanpy; RUN pip install anndata==${anndata} scanpy==${scanpy}; ENTRYPOINT [""python"",""-c"",""import scanpy""]; ```. **Works:**; ```bash; docker build --build-arg anndata=0.7.5 --build-arg scanpy=1.7.1 -t scanpy . && docker run scanpy # ✅; ```; **Fails:**; ```bash; docker build --build-arg anndata=0.7.3 --build-arg scanpy=1.6.1 -t scanpy . && docker run scanpy # ❌; # Traceback (most recent call last):; # File ""<string>"", line 1, in <module>; # File ""/usr/local/lib/python3.8/site-packages/scanpy/__init__.py"", line 41, in <module>; # from anndata import AnnData, concat; # ImportError: cannot import name 'concat' from 'anndata' (/usr/local/lib/python3.8/site-packages/anndata/__init__.py); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1439#issuecomment-835827799:279,install,install,279,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1439#issuecomment-835827799,1,['install'],['install']
Deployability,"I had a look at scanpy's [setup file](https://github.com/theislab/scanpy/blob/master/setup.py) `setup.py` and realised that running. ```bash; pip install -e .; pip install "".[dev]""; ```. does neither install all packages used within Scanpy's code base nor packages required for documentation or testing. IMO, these packages should be installed in a _developer installation_ as they are all part of the development cycle. Adding a file `requirements-dev.txt` including all needed packages would be an option to allow for an easy _developer installation_ via. ```bash; pip install -e .; pip install -r requirements-dev.txt; ```. Any thoughts on this?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1419#issuecomment-703124876:146,install,install,146,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1419#issuecomment-703124876,6,['install'],"['install', 'installed']"
Deployability,"I had a same issue. My environment is; ```; windows10; python3.8.8 (conda env); ```. scanpy installation ; `conda install -c conda-forge -c bioconda scanpy`. It looks work well on command prompt, but it wasn't work on jupyterlab(3.0). To solve this, I just installed all packages using pip, not conda.; here is my install procedure. ```; conda create -n test python=3.8; pip install ipykernel; pip install jupyterlab; pip install scanpy; pip install python-igraph; pip install leidenalg; pip install fa2; ```. I tired a lot of install and environment combination, but always there was a problem with conda.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/454#issuecomment-814856541:92,install,installation,92,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454#issuecomment-814856541,11,['install'],"['install', 'installation', 'installed']"
Deployability,"I had the exact same issue and error message at that step in the tutorial. I installed scanpy using pip, because installing with conda was not working.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1010#issuecomment-578570558:77,install,installed,77,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1010#issuecomment-578570558,2,['install'],"['installed', 'installing']"
Deployability,"I had the issue trying to install it in a new environment when python itself wasn't installed there yet. After having installed python, it worked though. However, uing scanpy within a script doesn't work properly after the installation. I'll have a closer look at that now.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1142#issuecomment-608270536:26,install,install,26,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1142#issuecomment-608270536,4,['install'],"['install', 'installation', 'installed']"
Deployability,I had the same issue using ; `pip3 install git+https://github.com/jacoblevine/phenograph.git` that gave version 1.5.2; but it worked using ; `pip install Phenograph==1.5.7`,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1407#issuecomment-932815914:35,install,install,35,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1407#issuecomment-932815914,2,['install'],['install']
Deployability,"I had the same issue, and it turns out setting up channels solves the problem as follows:; ```; conda config --add channels defaults; conda config --add channels bioconda; conda config --add channels conda-forge; ```; Ref: ; https://bioconda.github.io/recipes/scanpy/README.html; https://bioconda.github.io/user/install.html#set-up-channels",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/990#issuecomment-583508242:312,install,install,312,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/990#issuecomment-583508242,1,['install'],['install']
Deployability,I had this problem importing `import scanpy as sc`.; I'll update you if this problem persists.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/585#issuecomment-479515587:58,update,update,58,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/585#issuecomment-479515587,1,['update'],['update']
Deployability,"I have added source code for weighted sampled data. I have already preprocessed data and found the top few PC's and then input to `scanpy `to find `louvain `communities , `marker genes` and later variety of plots like `dotPlot`, `violinPlot `and `heatmap`. I have updated `scanpy `for `weighted `sampled data where each row has its weight, but this support for clustering and plotting. We can further update` sparse PCA` as well to support weighted data points.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/630:264,update,updated,264,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/630,2,['update'],"['update', 'updated']"
Deployability,"I have an idea. We provide a base `scanpy` command here. It works the same as the `jupyter` binary, i.e. it searches for commands named `scanpy-something` in the `$PATH`. Once one installs `scanpy-scripts`, there will be many commands like `scanpy-filter-genes` (without `.py`, I can assist in making that happen via entry-points and publishing it to PyPI). Calling `scanpy` without arguments will then list all those commands, and `scanpy filter-genes` (note the space) will call the respective command.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/281#issuecomment-436977469:180,install,installs,180,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/281#issuecomment-436977469,1,['install'],['installs']
Deployability,"I have followed these instructions to install scanpy into my miniconda environment:; [](https://scanpy.readthedocs.io/en/latest/installation.html). Whether I try to import scanpy straight from terminal, it keeps giving me an error:; ```; Python 3.5.5 |Anaconda, Inc.| (default, Mar 12 2018, 23:12:44); [GCC 7.2.0] on linux; Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.; >>> import scanpy.api as sc; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>; import anndata; File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>; from .base import AnnData, _MAIN_NARRATIVE; File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287; return f'Backing file manager of file {self._filename}.'; ^; SyntaxError: invalid syntax; >>>; ```. I also get the error when I try to use it with jupyter notebook:. ```; import scanpy.api as sc. Traceback (most recent call last):. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/IPython/core/interactiveshell.py"", line 2910, in run_code; exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-1-4a13c503728c>"", line 1, in <module>; import scanpy.api as sc. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>; import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>; from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287; return f'Backing file manager of file {self._filename}.'; ^; SyntaxError: invalid syntax; ```. What is the issue? How can I get over this? . Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/160:38,install,install,38,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/160,2,['install'],"['install', 'installation']"
Deployability,"I have just managed to install successfully (kind of, more details on things going wrong to come in the other repository) with pip without actually doing any of this, so I'm not sure what was actually going on here. One way or the other, this seems to have gone away now somehow on its own.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/49#issuecomment-345195949:23,install,install,23,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/49#issuecomment-345195949,1,['install'],['install']
Deployability,I have matplotlib 2.2.2. . Update!; I just updated my matplotlib to the latest version and it works well there is no misalignment any more! . thanks again,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/480#issuecomment-463308380:27,Update,Update,27,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/480#issuecomment-463308380,2,"['Update', 'update']","['Update', 'updated']"
Deployability,"I have problem installing and importing scrublet on windows please can you help me; Here is my code !pip install scrublet; PackagesNotFoundError: The following packages are not available from current channels:. - annoy. Current channels:. - https://conda.anaconda.org/conda-forge/win-64; - https://conda.anaconda.org/conda-forge/noarch; - https://repo.anaconda.com/pkgs/main/win-64; - https://repo.anaconda.com/pkgs/main/noarch; - https://repo.anaconda.com/pkgs/r/win-64; - https://repo.anaconda.com/pkgs/r/noarch; - https://repo.anaconda.com/pkgs/msys2/win-64; - https://repo.anaconda.com/pkgs/msys2/noarch; - https://conda.anaconda.org/pytorch/win-64; - https://conda.anaconda.org/pytorch/noarch. To search for alternate channels that may provide the conda package you're; looking for, navigate to. https://anaconda.org/. and use the search bar at the top of the page.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/173#issuecomment-1755962194:15,install,installing,15,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/173#issuecomment-1755962194,2,['install'],"['install', 'installing']"
Deployability,"I have replicated the error using local installation with 'pip3 install scanpy'; When I run the regress_out code on a jupyter notebook, same error appears.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/687#issuecomment-502349575:40,install,installation,40,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/687#issuecomment-502349575,2,['install'],"['install', 'installation']"
Deployability,"I have several plotting functions that allow to compare any two categorical columns in `.obs` to achieve similar output but never found the time to integrate them into scanpy. Is really quite some effort to add proper tests, documentation and code standards. I will be happy to share the code if other people is willing to help. . One problem with the stacked bar plot is that with lot of samples it is difficult to compare the fractions. To solve this I had used the dot plot with good results, see for example a comparison of the `louvain` clusters and the `bulk labels` annotation from `sc.datasets.pbmc68k_reduced()`:. ![image](https://user-images.githubusercontent.com/4964309/104466204-3e718280-55b5-11eb-9b87-ac3860af7979.png). and . ![image](https://user-images.githubusercontent.com/4964309/104466234-49c4ae00-55b5-11eb-92c8-45140de9e107.png). The dot plot also computes enrichment with respect to random expectations and sorts the rows and columns.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1573#issuecomment-759496093:148,integrat,integrate,148,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1573#issuecomment-759496093,1,['integrat'],['integrate']
Deployability,I have the same issue. I am eager to hear if there are any updates.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2442#issuecomment-1520632755:59,update,updates,59,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2442#issuecomment-1520632755,1,['update'],['updates']
Deployability,"I have the same problem. I am using macOS catalina 10.15.2. $ conda install -c bioconda scanpy. Collecting package metadata (current_repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.; Collecting package metadata (repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: | ; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Package natsort conflicts for:; scanpy -> natsort; Package louvain conflicts for:; scanpy -> louvain; Package patsy conflicts for:; scanpy -> patsy; Package importlib_metadata conflicts for:; scanpy -> importlib_metadata[version='>=0.7']; Package zlib conflicts for:; python=3.7 -> zlib[version='>=1.2.11,<1.3.0a0']; Package libcxx conflicts for:; python=3.7 -> libcxx[version='>=4.0.1']; Package scikit-learn conflicts for:; scanpy -> scikit-learn[version='>=0.21.2']; Package matplotlib conflicts for:; scanpy -> matplotlib[version='3.0.*|>=2.2']; Package statsmodels conflicts for:; scanpy -> statsmodels[version='>=0.10.0rc2']; Package numba conflicts for:; scanpy -> numba[version='>=0.41.0']; Package readline conflicts for:; python=3.7 -> readline[version='>=7.0,<8.0a0']; Package importlib-metadata conflicts for:; scanpy -> importlib-metadata; Package setuptools conflicts for:; scanpy -> setuptools; Package tqdm conflicts for:; scanpy -> tqdm; Package libffi conflicts for:; python=3.7 -> libffi[version='>=3.2.1,<4.0a0']; Package scipy conflicts for:; scanpy -> scipy[version='<1.3|>=1.3']; Package anndata conflicts for:; scanpy -> anndata[version='>=0.6.10|>=0.6.22rc1']; Package pip conflicts for:; python=3.7 -> pip; Package seaborn conflicts for:; scanpy -> ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/990#issuecomment-580295241:68,install,install,68,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/990#issuecomment-580295241,1,['install'],['install']
Deployability,"I have yet to install the most latest `scanpy` and I do not have CPUs to test for this specific case, but I had some issue of reproducing `leiden` results from `scanpy` from a published paper, and found that running `leiden` 10 times (per `n_iteration` option) resolved any discrepancy. Wonder whether it adds to the discussion.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2014#issuecomment-946665831:14,install,install,14,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2014#issuecomment-946665831,1,['install'],['install']
Deployability,I hope that solves all workflow woes! @ivirshup?. - Users still only need `pip` and can do `pip install scanpy[extras]`; - Installation from source happens via `pip install .[extras]` or `flit install --deps`/`--extras`; - Dev mode install is nonstandard and therefore happens by simply `ln -s scanpy path/to/env/site-packages/` or flit:. ![grafik](https://user-images.githubusercontent.com/291575/90508913-c8c5cf80-e158-11ea-802a-2e0e47578bd6.png). PS: we could also mention `--pth-file` for the 3 windows users who refuse to update to win10 and therefore can’t create symlinks.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1377:96,install,install,96,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1377,6,"['Install', 'install', 'update']","['Installation', 'install', 'update']"
Deployability,"I input pip show scipy I get:. Name: scipy; Version: 1.4.1; Summary: SciPy: Scientific Library for Python; Home-page: https://www.scipy.org; Author: None; Author-email: None; License: BSD; Location: /home/ubuntu/.local/lib/python3.6/site-packages; Requires: numpy; Required-by: umap-learn, statsmodels, scikit-learn, scanpy, xgboost, seaborn, mnnpy, loompy, Keras, Keras-Preprocessing, ggplot, gensim, anndata; You are using pip version 18.0, however version 20.2b1 is available.; You should consider upgrading via the 'pip install --upgrade pip' command. Typing in pip show scanpy returns:; Name: scanpy; Version: 1.5.1; Summary: Single-Cell Analysis in Python.; Home-page: http://github.com/theislab/scanpy; Author: Alex Wolf, Philipp Angerer, Fidel Ramirez, Isaac Virshup, Sergei Rybakov, Gokcen Eraslan, Tom White, Malte Luecken, Davide Cittaro, Tobias Callies, Marius Lange, Andrés R. Muñoz-Rojas; Author-email: f.alex.wolf@gmx.de, philipp.angerer@helmholtz-muenchen.de; License: BSD; Location: /home/ubuntu/.local/lib/python3.6/site-packages; Requires: packaging, h5py, joblib, legacy-api-wrap, tqdm, seaborn, setuptools-scm, statsmodels, numba, matplotlib, scipy, patsy, networkx, tables, natsort, pandas, umap-learn, scikit-learn, importlib-metadata, anndata; Required-by: ; You are using pip version 18.0, however version 20.2b1 is available.; You should consider upgrading via the 'pip install --upgrade pip' command. I have to use !pip install scanpy --user; when starting my session to have it work properly so I thought maybe it was an issue of being in a different directory but based on the location of each package when I look them up that doesn't appear to be the case? I tried using !pip install scipy -U --user but it tells me that the updated version is already present. sc.logging.print_versions() still shows scipy 1.0.1 as the version so I'm a bit confused. Is scanpy somehow defaulting to a different version for some reason? Is there a way to make it use the correct version?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1252#issuecomment-635681942:1401,install,install,1401,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252#issuecomment-635681942,5,"['install', 'update', 'upgrade']","['install', 'updated', 'upgrade']"
Deployability,"I installed GProfiler using conda, then went to run `sc.queries.enrich(my_adata)` and got the error below. I get a similar error if I try to run `from gprofiler import GProfiler` myself, and it's resolved if I remove the capitalization (`from gprofiler import gprofiler`), as suggested [here](https://github.com/vals/python-gprofiler/issues/9). Do you know why the enrich function uses capitalization, and how I can get my gprofiler compatible with it? Versions listed below. Thanks. ```pytb; ImportError Traceback (most recent call last); /anaconda3/envs/mm_singlecell_v2/lib/python3.6/site-packages/scanpy/queries/_queries.py in enrich(container, org, gprofiler_kwargs); 264 try:; --> 265 from gprofiler import GProfiler; 266 except ImportError:. ImportError: cannot import name 'GProfiler'. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last); <ipython-input-383-c1b09359d1a1> in <module>; 14 ; 15 #get gene set enrichment; ---> 16 print(sc.queries.enrich(this_adata, org='hsapiens', group='malignant', key='malignantvshealthy', pval_cutoff=0.01, log2fc_min=np.log2(1.5))); 17 ; 18 #plot volcano (makes a sep df along the way, should consolidate with above). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/functools.py in wrapper(*args, **kw); 805 '1 positional argument'); 806 ; --> 807 return dispatch(args[0].__class__)(*args, **kw); 808 ; 809 funcname = getattr(func, '__name__', 'singledispatch function'). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/site-packages/scanpy/queries/_queries.py in _enrich_anndata(adata, group, org, key, pval_cutoff, log2fc_min, log2fc_max, gene_symbols, gprofiler_kwargs); 305 else:; 306 gene_list = list(de[""names""].dropna()); --> 307 return enrich(gene_list, org=org, gprofiler_kwargs=gprofiler_kwargs). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/functools.py in wrapper(*args, **kw); 805 '1 positional argument'); 806 ; --> 807 return dispatch(args[0].__class__)(*args, **kw); 808 ; 809 f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1896:2,install,installed,2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1896,1,['install'],['installed']
Deployability,I installed again louvain with this command (although i already tried this command 3 times) and it work for me now. Thank you very much for the help.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1566#issuecomment-753962579:2,install,installed,2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1566#issuecomment-753962579,1,['install'],['installed']
Deployability,I installed it now but still have the issue of HTTP Error 403.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1334#issuecomment-733637978:2,install,installed,2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1334#issuecomment-733637978,1,['install'],['installed']
Deployability,I installed leidenalg through conda today and encountered the same error.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2341#issuecomment-1265542125:2,install,installed,2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2341#issuecomment-1265542125,1,['install'],['installed']
Deployability,I installed the latest Scanpy 1.9.1 `conda install -c conda-forge scanpy python-igraph leidenalg`. And the bug was gone!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2265#issuecomment-1137289422:2,install,installed,2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2265#issuecomment-1137289422,2,['install'],"['install', 'installed']"
Deployability,"I installed these packages on PC1, UMAP still not consistent with others.; <html xmlns:v=""urn:schemas-microsoft-com:vml""; xmlns:o=""urn:schemas-microsoft-com:office:office""; xmlns:x=""urn:schemas-microsoft-com:office:excel""; xmlns=""http://www.w3.org/TR/REC-html40"">. <head>. <meta name=ProgId content=Excel.Sheet>; <meta name=Generator content=""Microsoft Excel 15"">; <link id=Main-File rel=Main-File; href=""file:///C:/Users/hyjfo/AppData/Local/Temp/msohtmlclip1/01/clip.htm"">; <link rel=File-List; href=""file:///C:/Users/hyjfo/AppData/Local/Temp/msohtmlclip1/01/clip_filelist.xml"">; <style>; <!--table; 	{mso-displayed-decimal-separator:""\."";; 	mso-displayed-thousand-separator:""\,"";}; @page; 	{margin:.75in .7in .75in .7in;; 	mso-header-margin:.3in;; 	mso-footer-margin:.3in;}; tr; 	{mso-height-source:auto;; 	mso-ruby-visibility:none;}; col; 	{mso-width-source:auto;; 	mso-ruby-visibility:none;}; br; 	{mso-data-placement:same-cell;}; td; 	{padding-top:1px;; 	padding-right:1px;; 	padding-left:1px;; 	mso-ignore:padding;; 	color:black;; 	font-size:11.0pt;; 	font-weight:400;; 	font-style:normal;; 	text-decoration:none;; 	font-family:等线;; 	mso-generic-font-family:auto;; 	mso-font-charset:134;; 	mso-number-format:General;; 	text-align:general;; 	vertical-align:middle;; 	border:none;; 	mso-background-source:auto;; 	mso-pattern:auto;; 	mso-protection:locked visible;; 	white-space:nowrap;; 	mso-rotate:0;}; .xl65; 	{font-size:10.0pt;; 	font-family:""Var\(--jp-code-font-family\)"", sans-serif;; 	mso-font-charset:0;; 	text-align:center;}; .xl66; 	{text-align:center;}; .xl67; 	{color:red;; 	font-size:10.0pt;; 	font-weight:700;; 	font-family:""Var\(--jp-code-font-family\)"", sans-serif;; 	mso-font-charset:0;; 	text-align:center;}; .xl68; 	{color:red;; 	font-weight:700;; 	text-align:center;}; .xl69; 	{color:red;; 	font-size:10.0pt;; 	font-weight:700;; 	font-family:""Var\(--jp-code-font-family\)"", sans-serif;; 	mso-font-charset:0;; 	text-align:center;; 	background:yellow;; 	mso-pattern:black none;}; ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2114#issuecomment-1016078802:2,install,installed,2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2114#issuecomment-1016078802,1,['install'],['installed']
Deployability,"I just did a quick comparison between louvain and leiden algorithms using the pbmc68k_reduced dataset:. ```PYTHON; adata = sc.datasets.pbmc68k_reduced(); sc.pp.neighbors(adata); leiden(adata, use_weights=True); sc.tl.louvain(adata, use_weights=True); sc.pl.umap(adata, color=['louvain', 'leiden'], s=50, alpha=0.6, ncols=2); ```; ![image](https://user-images.githubusercontent.com/4964309/48210096-fb814800-e376-11e8-9cbc-b16490c9ead9.png). The results are almost identical. However, while in the `louvain` results some cells appear in the wrong cluster (red circle) this is not the case for the `leiden` method. I should note that the installation of `leidenalg` didn't go smooth and took me a while to set it up.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/350#issuecomment-437046926:636,install,installation,636,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/350#issuecomment-437046926,1,['install'],['installation']
Deployability,"I just encountered the same issue, using scanpy 1.9.1 and matplotlib 3.5.3. I think it's a recent update to matbplotlib which broke something here. When I rolled back matplotlib to 3.5.2, it ran fine.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2318#issuecomment-1273295202:98,update,update,98,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2318#issuecomment-1273295202,1,['update'],['update']
Deployability,"I just found a small mistake in the documentation of `scanorama_integrate`:; **kwargs are passed to assemble, not integrate. <!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2647:114,integrat,integrate,114,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2647,1,['integrat'],['integrate']
Deployability,"I just got the same error with a similar situation. . I get umap coordinates from a collaborator, which I store in `adata.obs`. Before the last update this worked:; `sc.pl.scatter(adata, x='UMAP1', y='UMAP2', color='cell_type_class')`; Now, this produces a `IndexError: Key ""UMAP1"" is not valid observation/variable name/index.` error. Now I need to run this for the same plot:; `sc.pl.scatter(adata, x='UMAP1', y='UMAP2', color='cell_type_class', use_raw=False)`. These covariates are all in `adata.obs.keys()`. It seems that `use_raw` is taking precendence over `x` and `y` being from `adata.obs`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/728#issuecomment-512184351:144,update,update,144,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/728#issuecomment-512184351,1,['update'],['update']
Deployability,I just had the same issue because I downgraded my matplotlib elsewhere.; So it should work if you upgrade your matplotlib.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2332#issuecomment-1254363045:98,upgrade,upgrade,98,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2332#issuecomment-1254363045,1,['upgrade'],['upgrade']
Deployability,"I just made an update in the PR #1210 that will solve the issue. Now you can do:. ```PYTHON; adata = sc.datasets.pbmc68k_reduced(); # make a heatmap with all the 765 genes in the dataset, highlight each 50th gene; ax_dict = sc.pl.heatmap(adata, adata.var_names, groupby='louvain', show=False, show_gene_labels=True, figsize=(7,4)); ax_dict['heatmap_ax'].set_xticks(range(len(adata.var_names))[::50]); ax_dict['heatmap_ax'].set_xticklabels(adata.var_names[::50]) ; ```. ![image](https://user-images.githubusercontent.com/4964309/85733220-4db5df00-b6fc-11ea-9c5c-d657ebb136c8.png)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1235#issuecomment-649557649:15,update,update,15,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1235#issuecomment-649557649,1,['update'],['update']
Deployability,I just noticed that matplotlib 3.1.1 is installed when using conda to install scanpy 1.4.4.; In your requirements you state that this breaks the scatter plot.; In the repodata from bioconda however it seems like there are very old dependencies that were not changed when new scanpy versions were included. So still the dependency there ist matplotlib>=2.2.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/876:40,install,installed,40,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/876,2,['install'],"['install', 'installed']"
Deployability,"I just noticed that the reply I sent Saturday bounced due to ‘unknown error’. I thought I should provide an update in case other Windows users encounter something similar. After identifying the correct version of the several on the link below, I noticed that it was also necessary to install Pycairo. I then found I needed to install the Louvain algorithm to resolve the issue. The vtraag website indicates this algorithm has been superseded by the Leiden algorithm, which I installed with no problem. Thanks much for your reply within hours, on a weekend no less. From: Koncopd [mailto:notifications@github.com]; Sent: Saturday, May 25, 2019 2:15 PM; To: theislab/scanpy <scanpy@noreply.github.com>; Cc: Moos, Malcolm <Malcolm.Moos@fda.hhs.gov>; Mention <mention@noreply.github.com>; Subject: Re: [theislab/scanpy] igraph problems (#138). @RicedeKrispy<https://github.com/RicedeKrispy>; Hi, if you are using Windows, you can try to install python-igraph from the wheel here; https://www.lfd.uci.edu/~gohlke/pythonlibs/#python-igraph. —; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://github.com/theislab/scanpy/issues/138?email_source=notifications&email_token=AMEIEFZ2OGJSDDXGY4TRK4TPXF62HA5CNFSM4E5ZJQRKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGODWHWUII#issuecomment-495938081>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AMEIEFZFWYPQB7BP5HHCM23PXF62HANCNFSM4E5ZJQRA>.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/138#issuecomment-502908611:108,update,update,108,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/138#issuecomment-502908611,5,"['install', 'update']","['install', 'installed', 'update']"
Deployability,"I just updated scanpy and reran a script which is now giving different outputs. The clustering has changed slightly, and that has downstream effects on the results. The first place I noticed a difference is where the results of `sc.pp.filter_genes_dispersion()` are plotted. . In scanpy version 1.2.2+73.g1812406 and AnnData version 0.6.4 I get the following output:; ![screen shot 2018-08-28 at 14 05 53](https://user-images.githubusercontent.com/13019956/44722232-bade9600-aacc-11e8-88c6-3f4c17fd4e07.png). And with scanpy version 1.2.2+166.g6c1daba with Anndata version 0.6.9, I get higher dispersions:; ![screen shot 2018-08-28 at 14 06 15](https://user-images.githubusercontent.com/13019956/44722316-fda06e00-aacc-11e8-940f-1295b36eacf6.png). Previous results look the same, and the only two scanpy functions that were run in between were `sc.pp.log1p()` and `sc.pp.filter_genes_dispersion()`. I also ran ComBat, but that was not updated and can't really have changed on my system. I see sc.pp.log1p was changed in between, but it doesn't seem to have been anything can could have changed this... Or was there a change to the plotting that may have changed the plots I see?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/246:7,update,updated,7,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/246,2,['update'],['updated']
Deployability,"I just updated the notebook linked at the top of the PR. I have a PR at pymde to improve the initialization speed using the GPU (https://github.com/cvxgrp/pymde/pull/55). Using these changes, pymde takes 20 seconds and umap takes around 200 seconds (150k cells). Most of the time of pymde I believe is from the initial pynndescent call. Therefore, if implemented well here and therefore using a precomputed neighbors graph, pymde would take no more than a few seconds for most use cases.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2154#issuecomment-1051311781:7,update,updated,7,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2154#issuecomment-1051311781,1,['update'],['updated']
Deployability,"I just wanted to update that this issue does not depend on scvelo at all, but I can recreate it by just using scanpy. I suspect it is an issue with running umap. I'm using version '0.4.6'. Any help would be much appreciated:. ### Minimal code sample (that we can copy&paste without having any data). ```python; import os; import scanpy as sc; import numpy as np; import pandas as pd; import copy; import anndata; import matplotlib.pyplot as plt; adata_pbmc3k = sc.datasets.pbmc3k_processed(); #del adata_pbmc3k.obsm['X_pca']; #del adata_pbmc3k.obsm['X_umap']; del adata_pbmc3k.obsp['distances']; del adata_pbmc3k.obsp['connectivities']; #sc.pp.pca(adata_pbmc3k, n_comps=50); sc.pp.neighbors(adata_pbmc3k); ```. ```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); TypeError: expected dtype object, got 'numpy.dtype[float32]'. The above exception was the direct cause of the following exception:. SystemError Traceback (most recent call last); /hps/scratch/lsf_tmpdir/hl-codon-13-02/ipykernel_2124423/1009160698.py in <module>; ----> 1 sc.pp.neighbors(adata_pbmc3k). /hps/software/users/marioni/Leah/miniconda3/envs/scvelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy); 137 adata._init_as_actual(adata.copy()); 138 neighbors = Neighbors(adata); --> 139 neighbors.compute_neighbors(; 140 n_neighbors=n_neighbors,; 141 knn=knn,. /hps/software/users/marioni/Leah/miniconda3/envs/scvelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds); 806 # we need self._distances also for method == 'gauss' if we didn't; 807 # use dense distances; --> 808 self._distances, self._connectivities = _compute_connectivities_umap(; 809 knn_indices,; 810 knn_distances,. /hps/software/users/",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1983#issuecomment-903666863:17,update,update,17,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1983#issuecomment-903666863,1,['update'],['update']
Deployability,"I kicked out `save_knn` from BBKNN as it doesn't really accomplish anything, and that ended up breaking the scanpy wrapper for it. Took it out, and took the opportunity to update the docstring.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/636:172,update,update,172,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/636,1,['update'],['update']
Deployability,"I know this (quite ancient) pull request has been open (#403), but I wasn't sure on its status. I think the consensus was to wait for sklearn to integrate the necessary changes? If that's still the case, then please feel free to remove this PR. Here I make use of scipy's extremely nifty [LinearOperator](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.LinearOperator.html) class to customize the dot product functions for an input sparse matrix. In this case, the 'custom' dot product performs implicit mean centering. In my benchmarks, performing implicit mean centering in this way does not affect the runtime whatsoever. However, this approach has to use [svds](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.svds.html), for which randomized SVD is not implemented. So we have to use 'arpack', which can be significantly slower (but not intractably so.... in my hands, I could still do PCA on datasets of 200k+ cells in minutes, and it sure beats densifying the data, if you want more thorough benchmarks I am happy to generate them!). The way I incorporated this functionality into scanpy/preprocessing/_simple.py might be questionable, and would love any suggestions or advice on how to better integrate this if there is interest in pushing this PR through. Let me know!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1066:145,integrat,integrate,145,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1066,2,['integrat'],['integrate']
Deployability,"I let you know as soon as there is a stable release back on github. 0.2.5 should be stable [as well](https://github.com/theislab/scanpy_usage), but has some other drawbacks. Things are still progressing fast.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/34#issuecomment-324338365:44,release,release,44,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/34#issuecomment-324338365,1,['release'],['release']
Deployability,"I like the `calculateQCMetrics` function from [`scater`](https://bioconductor.org/packages/release/bioc/html/scater.html), and have had a half finished python version drifting between my notebooks for a while. Is there is interest in adding this to scanpy?. I'm aiming to mostly copy the interface of `calculateQCMetrics` while being memory efficient, since this is likely run before filtering. # Todo. - [x] Figure out how I want to deal with more types of sparse matrix; - [x] Add `feature_control` argument, possibly `variable_control`; - [x] Clean up and expand tests; - [x] Expand documentation. # Questions. * What's up with sparse matrix choice in scanpy? Is `adata.X` expected to be any of the matrix types, or is it more limited? Just trying to figure out how much effort I should put into that.; * Are there any additional metrics that could be useful?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/316:91,release,release,91,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/316,1,['release'],['release']
Deployability,"I like the new behaviour. Maybe a parameter like na_colors could be used to specify a different na color if needed. ; Also, should the NaN and its colour be added to the legend (if categorical) or besides it (if continuous)?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1356#issuecomment-675307040:212,continuous,continuous,212,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356#issuecomment-675307040,1,['continuous'],['continuous']
Deployability,"I looked into that, but I'm not sure it actually makes this any less complicated. The issue is getting the `tqdm` thing to update, and requests would need all of the same logic to do that as far as I can tell. Plus, at that point it's copying from stack overflow vs. copying from python's stdlib. You'd think this would be a convenience function somewhere. Or you'd think that `urlretrieve` could take a `Request` object.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1344#issuecomment-666336406:123,update,update,123,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1344#issuecomment-666336406,1,['update'],['update']
Deployability,"I managed to get past the error by adding; ```; RUN locale-gen en_US.UTF-8; ENV LC_ALL en_US.UTF-8; ```; to the [Dockerfile](https://gist.github.com/pwl/a26726fda94ac7f4cbfb57e4fe98bf28). Before that the default locale was set to `POSIX`, which caused all of these problems. This is a weird choice of defaults as clearly python code doesn't work as expected. Thanks for helping out @flying-sheep!. EDIT: just to clarify, this dockerfile is not an example of how to install scanpy, it's just a demonstration of how to circumvent the issues with locales. In particular, several libraries are missing and scanpy does not complete the installation. Feel free to update this Dockerfile or add one to the scanpy repository.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/43#issuecomment-344235559:465,install,install,465,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/43#issuecomment-344235559,3,"['install', 'update']","['install', 'installation', 'update']"
Deployability,"I mean any smFISH or highly-multiplexed protein technology. The plot I have in mind is this:; This visualisation is implemented in our package (in active development - we haven't released yet): https://cell2location.readthedocs.io/en/latest/cell2location.plt.html#cell2location.plt.mapping_video.plot_spatial; ![download-20](https://user-images.githubusercontent.com/22567383/95405951-0ea94380-0911-11eb-84bf-6f712da7875c.png). I agree that the original images can be quite large so it is probably better to not load them by default. However, it is useful to have an option to load. For the Visium data, the utility of using fullres depends on image quality and the goals. Generally, cell diameter in highres images is just 1-4 pixels meaning that a cropped image with, say 10*10 spots will look pixelated and may not be enough to recognise small structures like a gland or a blood vessel, not mentioning cell morphologies or staining (e.g. eosinophils containing red granules).; For single-cell resolution data, it is often useful to zoom in to see if only cells of specific morphology express the gene, like Agt below.; ![download-19](https://user-images.githubusercontent.com/22567383/95405958-12d56100-0911-11eb-9a9b-3a2faa3fa660.png)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1436#issuecomment-705283276:179,release,released,179,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1436#issuecomment-705283276,1,['release'],['released']
Deployability,"I mean like milestones or projects for upcoming releases. It look like the change that fixes the issue got marked as an improvement, so we'd be waiting on 8.2.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993#issuecomment-2051712645:48,release,releases,48,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993#issuecomment-2051712645,1,['release'],['releases']
Deployability,"I mean, @vtraag is is the person I’d believe when asked which algorithm is superior, so we could. 1. add `sc.tl.leiden` as an alternative that doesn’t have a flavour argument.; 2. make `leidenalg` a dependency and `louvain-igraph` an optional one.; 3. when calling `sc.tl.louvain` (no matter the flavor used), emit a ``DeprecationWarning('We recommend to use `sc.tool.leiden` instead. Refer to its documentation for details')``. This meets the following goals:. - education: people will learn why we recommend the new function; - ease of use: no weird errors pop up suddenly; - reproducibility: If `louvain-igraph` is installed, the code works exactly as before (with an added warning), else it crashes. we could do the following within `sc.tl.louvain` to help users:. ```py; try:; import louvain; except ImportError:; raise ImportError(; 'The package “louvain-igraph“ is not installed. '; 'Try using `sc.tl.leiden` in case you do not need '; 'to reproduce results produced using `sc.tl.louvain`'; ); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/350#issuecomment-437039831:618,install,installed,618,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/350#issuecomment-437039831,2,['install'],['installed']
Deployability,"I meet the same problem when I want to install scanpy on my new laptop.; I run the same commands as I used to do on my old computer , but failed to import scanpy.; I've tried re-install of pytables and it still doesn't work.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2138#issuecomment-1047645794:39,install,install,39,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2138#issuecomment-1047645794,2,['install'],['install']
Deployability,I meet the same problem. You could use:. pip install matplotlib==2.2.3. I tried just. And it done.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1227#issuecomment-659856395:45,install,install,45,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1227#issuecomment-659856395,1,['install'],['install']
Deployability,I merged a bunch of PRs and we shouldn't forget to update the release notes.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2416:51,update,update,51,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2416,2,"['release', 'update']","['release', 'update']"
Deployability,"I merged it into master now. You can try a regular `pip install .` or `flit install -s` for an editable install (after installing flit) as described here: https://scanpy.readthedocs.io/en/latest/installation.html#development-version. Pip says that btw if you try `pip install -e .`. > A ""pyproject.toml"" file was found, but editable mode currently requires a setup.py based build.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1496#issuecomment-737558274:56,install,install,56,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496#issuecomment-737558274,6,['install'],"['install', 'installation', 'installing']"
Deployability,I met the same problem one day ago. I run the following: ; conda install pytorch torchvision torchaudio cudatoolkit=11.3 -c pytorch ; conda install scvi-tools -c conda-forge; conda install -c conda-forge scanpy python-igraph leidenalg ; It works fine now.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2073#issuecomment-1259069261:65,install,install,65,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2073#issuecomment-1259069261,3,['install'],['install']
Deployability,"I might also have a corrupted install of anndata, let me reboot my system and see if the error persists.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2978#issuecomment-2035502211:30,install,install,30,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2978#issuecomment-2035502211,1,['install'],['install']
Deployability,"I might have overextended the old environment a bit too much indeed, so I'll just continue with a fresh one. If it's of any help to you, then before the problems started I wanted to try out some of the newer additions to scanpy ecosystem by installing triku, dorothea and progeny. Thanks for your help!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1850#issuecomment-848678562:241,install,installing,241,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1850#issuecomment-848678562,1,['install'],['installing']
Deployability,"I never used spatial data (so far), are they organized as separate `AnnData` objects? If everything that could be integrated is a single `AnnData` then the function would be easy, like. ```python; def leiden_multiplex(adata: Sequence[AnnData], use_computed: bool = False, weights: None):. adj_list = [x.uns['neighbors']['connectivities'] for x in adata]; G_list = [sc._utils.get_igraph_from_adjacency(x) for x in adj_list] #also add the `restrict_to` step. if use_computed:; part_list = [get_partitions_from_adata.obs] or [recalculate_partitions_with_neighbors_params]; # then run the optimizer; else:; membership, improv = la.find_partitions_multiplex(**params). for a in adata:; a.obs['multiplex'] = pd.Categorical(membership). ```; where `adata` is a list of `AnnData` objects, `use_computed` switches between recalculate partitions (`False`) or optimize partitions already calculated (`True`). Weights can be specified to give more or less importance to a specific view. Note that, by default, if set to `None` it is set to a list of ones by `leidenalg`.; Other options, in addition to the usual `copy = False` should be the `leidenalg` type of partitioning (`CPMVertexPartition`, `RBConfigurationVertexPartition`...)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1107#issuecomment-600076328:114,integrat,integrated,114,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1107#issuecomment-600076328,1,['integrat'],['integrated']
Deployability,I noticed I'm on scanpy 1.9.3 and upgraded to scanpy 1.9.4 as well and tried again and have the same issue,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2645#issuecomment-1701530406:34,upgrade,upgraded,34,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2645#issuecomment-1701530406,1,['upgrade'],['upgraded']
Deployability,I noticed now that the library is `python-igraph` and not `igraph` as explained in https://scanpy.readthedocs.io/en/latest/installation.html .; I am closing this issue since I've solved through the steps in the documentation.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/138#issuecomment-385764640:123,install,installation,123,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/138#issuecomment-385764640,1,['install'],['installation']
Deployability,"I noticed that 10x has released some new spatial gene expression datasets. Could you include them? It should be a simple change in this line [https://github.com/theislab/scanpy/blob/ab9247bdf8b7a3decc34a15b26fec813ea8fba0d/scanpy/datasets/_datasets.py#L323](url). Also, I've encounter errors when using `scanpy.datasets.visium_sge`. It seems that the url is outdated. The link to the datasets is changed to be; `; https://support.10xgenomics.com/spatial-gene-expression/datasets/{version_id}/{sample_id}; `. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1475:23,release,released,23,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1475,1,['release'],['released']
Deployability,I noticed that matplotlib v. 3 is being installed in travis. This may be the reason why some tests not related to the changes are now failing. I am updating my matplotlib version to update de tests.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/244#issuecomment-425947033:40,install,installed,40,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/244#issuecomment-425947033,2,"['install', 'update']","['installed', 'update']"
Deployability,"I only can advice you on your second part of questions there is no rule of thumb for that. I also don't know what do you exactly mean by best suggestion resolution and how did you assess that. This is a general problem for many supervised clustering methods such as k-mean that user has to provide number of clusters or in this case the resolution which determines the number of clusters. Although there are some indirect ways to assess the clustering quality for example silhouette coefficient which gives you a score between -1 to 1 that tell you how similar your point in each clusters are. The other possibility is that you already expect the number of clusters so you can optimize the resolution based on your previous knowledge. ; @falexwolf Out of curiosity, can we integrate such methods like silhouette coefficient inside scanpy? that would be cool!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/670#issuecomment-498046271:773,integrat,integrate,773,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/670#issuecomment-498046271,1,['integrat'],['integrate']
Deployability,"I ran `pip3 install scanpy[doc]`, as instructed by that page, and the doc seems to have built fine locally. ![image](https://user-images.githubusercontent.com/14993986/122047761-cbc53700-cde0-11eb-8fb2-5a180d306554.png). The only fishy thing is the `function` is not clickable, while the other two are, but it built. Also, line 28 is `trim: Optional[int] = None,`, which was there previously already. It's the metric change that's causing this - your argument renaming PR did not hiccup.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1868#issuecomment-861433547:12,install,install,12,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1868#issuecomment-861433547,1,['install'],['install']
Deployability,"I readded cython to the requirements: https://github.com/theislab/scanpy/commit/2ae826b71c1eefa16b165d4ff85de9f76fc9e62d. I thought it would be unnecessary when directly installing from the .c files, but evidently, it is not. Anyhow, this should fix it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/22#issuecomment-307050792:170,install,installing,170,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/22#issuecomment-307050792,1,['install'],['installing']
Deployability,"I recently installed the [miniforge3](https://github.com/conda-forge/miniforge) distribution on my Apple with M1 and both `sc.pp.neighbors` and `sc.pp.calculate_qc_metrics` work nice and quiet. Not sure if that helps with the issue here, but might be worth a try. ; My versions:; ```; -----; anndata 0.9.1; scanpy 1.9.3; -----; PIL 9.5.0; anndata2ri 1.2.dev11; appnope 0.1.3; asttokens NA; backcall 0.2.0; backports NA; beta_ufunc NA; binom_ufunc NA; cffi 1.15.1; colorama 0.4.6; comm 0.1.3; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.6.7; decorator 5.1.1; defusedxml 0.7.1; executing 1.2.0; h5py 3.8.0; hypergeom_ufunc NA; igraph 0.10.4; importlib_resources NA; ipykernel 6.22.0; ipython_genutils 0.2.0; ipywidgets 8.0.6; jedi 0.18.2; jinja2 3.1.2; joblib 1.2.0; kiwisolver 1.4.4; leidenalg 0.9.1; llvmlite 0.39.1; markupsafe 2.1.2; matplotlib 3.7.1; mpl_toolkits NA; natsort 8.3.1; nbinom_ufunc NA; ncf_ufunc NA; numba 0.56.4; numpy 1.22.0; packaging 23.1; pandas 1.2.5; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; platformdirs 3.2.0; prompt_toolkit 3.0.38; psutil 5.9.5; ptyprocess 0.7.0; pure_eval 0.2.2; pydev_ipython NA; pydevconsole NA; pydevd 2.9.5; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.15.1; pyparsing 3.0.9; pytz 2023.3; pytz_deprecation_shim NA; rpy2 3.5.11; scipy 1.9.1; scrublet NA; seaborn 0.12.2; session_info 1.0.0; six 1.16.0; sklearn 1.2.2; stack_data 0.6.2; statsmodels 0.13.5; texttable 1.6.7; threadpoolctl 3.1.0; tornado 6.3; traitlets 5.9.0; typing_extensions NA; tzlocal NA; wcwidth 0.2.6; yaml 6.0; zipp NA; zmq 25.0.2; -----; IPython 8.12.0; jupyter_client 8.2.0; jupyter_core 5.3.0; notebook 6.5.4; -----; Python 3.8.16 | packaged by conda-forge | (default, Feb 1 2023, 16:01:13) [Clang 14.0.6 ]; macOS-13.2.1-arm64-arm-64bit; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2359#issuecomment-1518690218:11,install,installed,11,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359#issuecomment-1518690218,1,['install'],['installed']
Deployability,"I second this initiative. I had used the code from Brent and works quite; well. Naturally, having it integrated into Scanpy would be great. On Mon, Dec 17, 2018 at 2:18 PM Marius Lange <notifications@github.com>; wrote:. > *@Marius1311* commented on this pull request.; > ------------------------------; >; > In scanpy/preprocessing/combat.py; > <https://github.com/theislab/scanpy/pull/398#discussion_r242142511>:; >; > > @@ -0,0 +1,161 @@; > +import numpy as np; > +from scipy.sparse import issparse; > +import pandas as pd; > +import sys; > +from numpy import linalg as la; > +import patsy; > +; > +def design_mat(mod, batch_levels):; > + # require levels to make sure they are in the same order as we use in the; > + # rest of the script.; > + design = patsy.dmatrix(""~ 0 + C(batch, levels=%s)"" % str(batch_levels),; >; > thanks, did that!; >; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/pull/398#discussion_r242142511>, or mute; > the thread; > <https://github.com/notifications/unsubscribe-auth/AEu_1fZSO-j8m0NwemluQp-0wNEGDHJ9ks5u55mlgaJpZM4ZTmeq>; > .; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/398#issuecomment-447896676:101,integrat,integrated,101,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/398#issuecomment-447896676,1,['integrat'],['integrated']
Deployability,"I see that it can process arrays now, i should check if it better to replace the custom implementation with the updated `stats.mannwhitneyu`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1892#issuecomment-864860024:112,update,updated,112,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1892#issuecomment-864860024,1,['update'],['updated']
Deployability,I see that some functions have been deprecated and replaced by new ones. What is the simplest way to update Scanpy using conda?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/537:101,update,update,101,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/537,1,['update'],['update']
Deployability,"I see! File looks like this:. ```csv; barcode,in_tissue,array_row,array_col,pxl_row_in_fullres,pxl_col_in_fullres; GTCACTTCCTTCTAGA-1,0,0,0,-1567,2629; CACGGTCTCCTTACGA-1,0,0,2,-1569,2811; ATAGCTGCGGATAAGA-1,0,0,4,-1571,2993; GTCAGTATGTCCGGCG-1,0,0,6,-1573,3174; ...; ```. @RaphaelBuzzi you mean `read_visium`, right? There is no `read_spatial` in scanpy. That one seems to assume that; - if the file is called `tissue_positions.csv`, it has a header on the second row (index 1), and; - if it is called `tissue_positions_list.csv`, it has no header line:. https://github.com/scverse/scanpy/blob/692c9e536ab1d3b0a7d16e9c2c6e7d53390f9b5a/scanpy/readwrite.py#L461-L465. The only thing that looks weird about that is the index 1 instead of 0, otherwise it looks identical to the PR by 10x: https://github.com/satijalab/seurat/pull/6208/files. So the question is: why is there a file called `tissue_positions_list.csv` that has a header? That doesn’t seem like what 10x’s pipeline does.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2499#issuecomment-1607076461:967,pipeline,pipeline,967,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2499#issuecomment-1607076461,1,['pipeline'],['pipeline']
Deployability,"I see, [densmap](https://umap-learn.readthedocs.io/en/latest/densmap_demo.html). Hmm, I think that `method='densmap'` and `method_kwds={...}` would be a better API for us (which would then be translated into `densmap=True, densmap_kwds=method_kwds`). This also needs tests and a release note. Also we probably should just remove the umap 0.4 compatibility code, what do you think @ivirshup?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2684#issuecomment-1764564449:279,release,release,279,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2684#issuecomment-1764564449,1,['release'],['release']
Deployability,I solved the problem after installing with this command:. pip install scipy==1.4.1 --use-feature=2020-resolver,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1407#issuecomment-734388537:27,install,installing,27,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1407#issuecomment-734388537,2,['install'],"['install', 'installing']"
Deployability,"I somehow missed the documentation section, my bad. I didn't install the dev packages because I only needed a minimal setup to recreate the bug, scanpy actually fails to install without the dev packages, as expected, but that comes later on, after the initial bug.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/43#issuecomment-344294567:61,install,install,61,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/43#issuecomment-344294567,2,['install'],['install']
Deployability,"I still don't see 100% why the submodule `rtools` would be so much worse than `scanpy-contrib`. The submodule would be separate from the rest of the package and we could write something on top of its API overview page like: interfaces for R tools, address the maintainers of these tools for help... We need to keep some structure so that things remain clean, but yeah, additions will always be somewhat arbitrary. If someone suggests a ""meaningful addition"", we will accept it, if someone suggests something that does not seem to be of good quality, we will reject it. But this is not a problem only for `rtools` but for wrappers of python packages as well... see, for instance, https://github.com/theislab/scanpy/pull/126. So, I would set up the `rtools` submodule to save us the work of maintaining a different repo and the user the work of installing a `scanpy-contrib` package and figuring out which namespaces to use so that notebooks don't get completely messed up. So, if you don't mind, I'd set up the ""rtools"" submodule...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/125#issuecomment-382344299:843,install,installing,843,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/125#issuecomment-382344299,1,['install'],['installing']
Deployability,"I suspect Elisabetta's concern was more about the general differences in documentation standards between Python packages and R packages (at least within genomics). It can definitely make the transition from R to Python more difficult (I can attest, as I'm going through it right now :P). R packages just tend to come with very thorough vignettes, documenting how the package is supposed to be used end-to-end, highlighting special use-cases, etc. I think [Seurat](http://satijalab.org/seurat/get_started.html), [Monocle](http://cole-trapnell-lab.github.io/monocle-release/), or really any Bioconductor package (eg. [Scater](https://bioconductor.org/packages/release/bioc/vignettes/scater/inst/doc/vignette-intro.html)) are great examples. Jupyter notebooks are fantastic for helping get an idea of how to use a package, but sometimes the documentation within them is lacking, making it hard to understand what's going on at each step without having to dive into source code. I find Scanpy's straight forward to follow though. I really appreciate the modular design of Scanpy. At least if you're familiar with single-cell analysis, you can recognize the steps quite easily and just string together the appropriate functions for your analysis pipeline. Some other packages are bit trickier. For example, I found Velocyto (which I love btw) incredibly hard to navigate. There are functions that are used in some analysis notebooks but not all of them, so it becomes unclear what the standard analysis pipeline with it should be. Obviously you can dive into the paper, understand the statistical guts of the method, go through all the source code and see what's there, but then it starts becoming a barrier to newer users adapting it. . Anyway, this is just a general thing I also noticed moving from R to Python. Not saying that it's something that necessarily needs changing, but it does create a little bit of friction to newer users, so it may be worth thinking about as a community. I suspect this wi",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/74#issuecomment-363820657:564,release,release,564,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74#issuecomment-363820657,2,['release'],['release']
Deployability,"I tested myself and obtained exactly the same results. :). You probably don't have the FA2 package installed, that's why your graph look different... :). I'm merging this! Awesome work!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/576#issuecomment-487797746:99,install,installed,99,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/576#issuecomment-487797746,1,['install'],['installed']
Deployability,"I tested this in a couple of machine and the pipeline works fine there. However, I just re-installed `leidenalg` and this is now resolved! . Thanks a lot for the feedback.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1410#issuecomment-689637466:45,pipeline,pipeline,45,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1410#issuecomment-689637466,2,"['install', 'pipeline']","['installed', 'pipeline']"
Deployability,"I think I find the reason. When run sc.tl.louvain(adata), louvain_colors will be saved in adata.uns, sc.pl.paga will use louvain_colors. But, when run sc.tl.louvain(adata) again with another resolution and then rerun sc.tl.paga, louvain_colors will not be updated, and the error occurs!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/381#issuecomment-456264112:256,update,updated,256,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/381#issuecomment-456264112,1,['update'],['updated']
Deployability,"I think I found a way around it. The issue here is the error is thrown when the new louvain groups are created by the adata.obs['louvain_colors'] are not updated until the plotting sc.pl function is run. Therefore, when you try to slice anything, it throws out an index out of bounds error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/833#issuecomment-531440165:154,update,updated,154,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/833#issuecomment-531440165,1,['update'],['updated']
Deployability,"I think I got the docs right, let me know if there are any issues. I'm noticing some conflict with convention for metric names. I'm copying `scater`, and using labels like `total_counts` and `total_features_by_counts`. `filter_genes`, `filter_cells`, `spring_project`, and a couple of the recipes use `n_counts` or `n_cells`. My preference is for the `scater ` way, since formatting allows it to be bit more flexible. It'd be nice for there to be a consistent default key for these features. For example, while updating the clustering tutorial, I ended up with both `n_counts` and `total_counts` in the same `adata.obs`. As changing the defaults could break some code, what's the right path forward? When `scater` updated their metric names, I think they used both the old and new keys with a deprecation warning. They talk about it a bit under the documentation for `scatter::calcuateQCMetrics`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/316#issuecomment-434172473:714,update,updated,714,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/316#issuecomment-434172473,1,['update'],['updated']
Deployability,I think I have the most recent version of python-graph installed ( python-igraph 0.7.1.post6 ).; pip install python-igraph doesnt solve the issue since it is already updated.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/35#issuecomment-324590937:55,install,installed,55,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35#issuecomment-324590937,3,"['install', 'update']","['install', 'installed', 'updated']"
Deployability,"I think I see the issue here. The bioconda distribution of scanpy is out of date and unsupported, please install it from condo-forge instead:. https://scanpy.readthedocs.io/en/latest/installation.html#anaconda",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2178#issuecomment-1068920599:105,install,install,105,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2178#issuecomment-1068920599,2,['install'],"['install', 'installation']"
Deployability,"I think `flavor='taynaud'` should [still work](https://github.com/theislab/scanpy/blob/a9ee39f5152d167f1aeb784ffbdd0a6e3dc1409a/scanpy/tools/louvain.py#L142), but is really only meant as a last resort. AFAIK the networkx modules don't even provide a resolution parameter, but most importantly, they don't scale. I think I even was satisfied with convergence of the results and comparisons with, e.g., Seurat. Scanpy can even be installed using bioconda, so there should be no problem with igraph installation these days. Did you checkout https://scanpy.readthedocs.io/en/latest/installation.html?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/97#issuecomment-440389136:428,install,installed,428,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/97#issuecomment-440389136,3,['install'],"['installation', 'installed']"
Deployability,"I think `obs_values` is fine. But maybe, `aggregate_obs` is even better, as this describes what it does (aggregating annotations of observations with partial (projections of) observations). It's no problem at all to make the next Scanpy release depend on the current AnnData release, both in the requirements and the minimal version check upon importing Scanpy.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/619#issuecomment-487916208:237,release,release,237,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/619#issuecomment-487916208,2,['release'],['release']
Deployability,I think autoreload does indeed do more than importlib.reload:. https://ipython.readthedocs.io/en/stable/config/extensions/autoreload.html#caveats. > Functions and classes imported via ‘from xxx import foo’ are upgraded to new versions when ‘xxx’ is reloaded.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/468#issuecomment-462133529:210,upgrade,upgraded,210,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/468#issuecomment-462133529,1,['upgrade'],['upgraded']
Deployability,I think it is ok to merge now. . I also updated some of the plotting functions to accept a `gene_symbol` column: . ![image](https://user-images.githubusercontent.com/4964309/52279718-85cb4f00-295a-11e9-99e9-f9b8648609a6.png). What is missing is `sc.pl.rank_genes_groups` and `sc.pl.violin` any volunteers?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/425#issuecomment-460657479:40,update,updated,40,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/425#issuecomment-460657479,1,['update'],['updated']
Deployability,I think it makes sense to deprecate and then remove `sc.read_visium`. and `sc.pl.spatial` since I don't plan to maintain it here anymore and updated versions are present in Squidpy. What do you think @ivirshup ?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2331:141,update,updated,141,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2331,1,['update'],['updated']
Deployability,"I think it was a bugged `uv` release, but seems to be fixed now.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2942#issuecomment-2026135676:29,release,release,29,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2942#issuecomment-2026135676,1,['release'],['release']
Deployability,"I think it's very likely people will hit this bug, because 1) they typically don't update packages like scipy very often 2) most pipelines use sparse datasets + PCA. I think it deserves a new release.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1247#issuecomment-636059236:83,update,update,83,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1247#issuecomment-636059236,3,"['pipeline', 'release', 'update']","['pipelines', 'release', 'update']"
Deployability,"I think maybe i found a solution to solve this problem.; Maybe this problem is caused by the version of scikit—misc，when you use pip install --user scikit-misc or pip install scikit-misc，the system will install scikit-misc==0.1.4.; so,i try to install another verion of scikit-misc,you can use install -i https://test.pypi.org/simple/ ""scikit-misc==0.2.0rc1.; In addition, this line of command needs to be used when python is greater than or equal to 3.8.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2073#issuecomment-1738603497:133,install,install,133,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2073#issuecomment-1738603497,5,['install'],['install']
Deployability,"I think our initially identified bottleneck with using sparse arrays was this here https://github.com/cupy/cupy/issues/2359. The analysis workflows usually have very clear computational bottlenecks, so the translation to GPU should take this into consideration: Is it feasible in terms of available code to keep the array on GPU and actually perform all operations there or will this stay a CPU centric library that deploys particular steps to GPU. In[batchglm / diffxpy](https://github.com/theislab/batchglm) we took the first approach, we build ontop of (a CPU centric scanpy and) deployed GLM fitting to GPU via tensorflow2, we also use estimation code in dask in the same package that we could in principle use with cupy, right now this just sits ontop of numpy. . Happy to be involved with this stuff, I spent some time thinking about this with @quasiben already. I think it is really crucial to figure out where it makes sense to invest time to build pipelines that can be end-to-end be executed on GPU: because of the large number of tools this will not be the entire scanpy tool environment for a long time, so mixed workflows will be necessary. . 1. I would for example restrict all efforts to the submodule `sc.tl` for now because this contains most potential bottlenecks I think that are frequently used. ""end-to-end"" doesnt need to go all the way up to analysis graph leaves, such as plotting, in my opinion, as their is little performance gain there.; 2. Nice to have for non-core functionalities would then be some examples of how GPU-based arrays can be used within anndata so that 3rd parties can modify their tools to directly operate on the GPU array rather then starting to copy arrays. I think this is not really clear for most people right now (I have never done that either) and documenting this properly / improving this would help a lot.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1177#issuecomment-618890788:416,deploy,deploys,416,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1177#issuecomment-618890788,3,"['deploy', 'pipeline']","['deployed', 'deploys', 'pipelines']"
Deployability,"I think that correlation matrix is only in the latest master version. You can install it using:; ```; pip install git+https://github.com/theislab/scanpy.git; ```. Also, be sure to load scanpy as 'import scanpy as sc'. If you use the old method (`import scanpy.api as sc`) it will not work.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/544#issuecomment-475183206:78,install,install,78,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/544#issuecomment-475183206,2,['install'],['install']
Deployability,"I think that might be due to the dense array being to large to fit in memory on your machine. Just to be sure, how large is your dataset? And how much memory do you have?. For the current release, you could either try using the incremental PCA, using a subset of the data, or using a machine with more memory. In the next scanpy release, there will be a much more memory efficient PCA implementation.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1193#issuecomment-622666255:188,release,release,188,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193#issuecomment-622666255,2,['release'],['release']
Deployability,"I think that the `all_data.uns['leiden_colors']` list is only updated if the new number of clusters is bigger than the previous cluster number as the goal is to avoid missing colors. . In you use the the `palette` argument, the color list will always be updated.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/420#issuecomment-453067108:62,update,updated,62,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/420#issuecomment-453067108,2,['update'],['updated']
Deployability,I think that the updated docstring is much better.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/424#issuecomment-454026591:17,update,updated,17,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/424#issuecomment-454026591,1,['update'],['updated']
Deployability,"I think that there is no up to date Conda installation. Only Pip. The current version is 1.3.7. . > On 4 Feb 2019, at 10:26, Bérénice Batut <notifications@github.com> wrote:; > ; > right_margin and left_margin are still listed as parameters for pl.scatter:; > ; > https://github.com/theislab/scanpy/blob/c15a5e8763097082c82cd8ef6fee697954c487dc/scanpy/plotting/_anndata.py#L49; > ; > And ncols, wspace and hspace are not accepted (with the current version on conda) 😟; > ; > —; > You are receiving this because you commented.; > Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/458#issuecomment-460351011:42,install,installation,42,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/458#issuecomment-460351011,1,['install'],['installation']
Deployability,"I think the PR is now good as is. I will be quite busy for some time, therefore I won't have time for further discussions. Please feel free to close, update or merge it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/819#issuecomment-557824199:150,update,update,150,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819#issuecomment-557824199,1,['update'],['update']
Deployability,"I think the current approach - a very simple interface as in `scanpy/tools/phate.py` and a bunch of others is the easiest way to go for the developer. So, I'd say we make a submodule `.ext` with the `.tools`, `.plotting`, `.preprocessing` substructure in it. We move things like `phate.py` into `scanpy/ext/tools`. We maintain backwards compat by still reexporting it in `scanpy.api`. The canonical way of calling these extension will be by importing `import scanpy.ext as sce` and people can use that extension namespace and call everything in the same way that they are used to. Users can look up extension tools on docs site like [this](https://scanpy.readthedocs.io/en/latest/api/index.html). It will also be clear to users that these extensions will require installing additional packages, which don't come with the default scanpy. Of course, all of this needs none of the ""extension mechanisms"" mentioned above. But people really don't want to write actual ""scanpy extensions""; they want to write their own packages and have them interface with scanpy so that convenient calls are enabled without the need to adapt to new conventions. For the scanpy users, the cool things is that a large number of tools can be quickly tested out. If you don't mind, @fidelram and @flying-sheep, @Koncopd would go along and make this modest change.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/271#issuecomment-431634492:763,install,installing,763,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/271#issuecomment-431634492,1,['install'],['installing']
Deployability,"I think the disconnected communities in Louvain should have less of an effect in KNN graphs as the degree distribution is a lot more regular. This issue appears to occur a lot more frequently when the node degrees in a community are quite different (or at least this is what I found on PPI networks). Nonetheless, it's a good idea to upgrade I reckon.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/350#issuecomment-437812546:334,upgrade,upgrade,334,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/350#issuecomment-437812546,1,['upgrade'],['upgrade']
Deployability,"I think the issue here is that BBKNN only generates an integrated graph, while the tsne computation creates a new graph from some matrix representation of the data. There has been the suggestion of allowing a tsne layout (#1233) to be generated from a precomputed connectivity matrix, but that hasn't been implemented here yet.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1370#issuecomment-678131279:55,integrat,integrated,55,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1370#issuecomment-678131279,1,['integrat'],['integrated']
Deployability,"I think the issue might be with the version of python, since that snippet works fine for me with a fresh python 3.6 conda environment (v3.6.8) and seems to be working in our builds (v3.6.7). Are you able to upgrade to one of those?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/734#issuecomment-509619333:207,upgrade,upgrade,207,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/734#issuecomment-509619333,1,['upgrade'],['upgrade']
Deployability,"I think the spring export function currently fails because it only checks whether each column in `adata.obs` is a pandas categorical variable (`not is_categorical(adata.obs[obs_name])`) and, if not, assumes it's a continuous variable and then tries to join a str with an integer. . If you look at your file `data.obs` contains a number of categorical variables that are currently numpy objects; ```pytb; data.obs.dtypes; ClusterID int32; ClusterName object; RNA_snn_res_0_5 object; nCount_RNA float32; nFeature_RNA int32; orig_ident object; percent_mt float32; seurat_clusters object; louvain category; dtype: object; ```. As a quick fix, I think you can do something like this:; ```python; adata = data.copy(); obj_cols = adata.obs.columns[adata.obs.dtypes == np.object]; adata.obs[obj_cols] = adata.obs[obj_cols].astype('category') ; sce.exporting.spring_project(adata, './pbmc3k', 'draw_graph', subplot_name='force1', overwrite=True); ```; Not sure what's the best way to fix it for the future: check for other dtypes or uses f-strings to avoid the str concatenation errors?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/889#issuecomment-590643431:214,continuous,continuous,214,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/889#issuecomment-590643431,1,['continuous'],['continuous']
Deployability,"I think this has to do with us relying on UMAP. You can check this yourself in UMAP, but you'll actually end up with n-1 neighbors per node. I believe this has to do with each point being it's own nearest neighbor, but I forget if that's important for nearest neighbor descent algorithm (prevent node from adding itself by already having it in the heap) or UMAP (simplexes??). If I can find a link to where I read this, I'll share it here. Two considerations:. * This is the behaviour of UMAP, which we are fairly integrated with; * This has always been the behavior. I was definitely surprised when I read about this recently, and would be open to changing the behavior. It would effect reproducibility for everyone though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1706#issuecomment-788812203:514,integrat,integrated,514,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1706#issuecomment-788812203,1,['integrat'],['integrated']
Deployability,"I think this is a really good idea. Definitely a good hold over until a real GroupBy object is worked out. I'll review in depth later but have a few thoughts:. * How about `split_by`? Rhymes with `group_by` which this is quite like.; * I would like to be able to do this along the `var` axis; * What do you think about including some of the grouping options from [`_prepare_dataframe`](https://github.com/theislab/scanpy/blob/d072abd05bda07f280ea91f5e7e4a84f9782c118/scanpy/plotting/_anndata.py#L1842)? E.g. grouping by multiple keys, binning by continuous values? It would be nice if this could be used in place of `_prepare_dataframe`. The features would not have to be implemented in this PR, but it would be good to think about what the API for them would be and making sure it could be added elegantly.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1939#issuecomment-876054434:546,continuous,continuous,546,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1939#issuecomment-876054434,1,['continuous'],['continuous']
Deployability,"I think this is an important conversation to have not just for imputation, but also for other analysis methods like visualization and batch effect correction. Every algorithm makes some assumptions and biases, and it is possible to misinterpret for misuse almost any machine learning algorithm. . For example, t-SNE, often used for visualization, is also used as dimensionality reduction for clustering. However, most clustering algorithms assume that global distances in a dataset are relevant. This assumption is broken with t-SNE, as evidenced by the inconsistency of t-SNE embeddings on the same data and inability for t-SNE to capture some global trends in a dataset (especially with continuous data, leading to the popularity of graph-based visualizations). . On top of this, each clustering algorithm makes assumptions that data is in fact distributed in clusters, but this is often not the case in single cell data. I agree that it's important to warn users about the limitations of imputation methods, and make them aware that their decision on which algorithm to run can affect their output. However, it seems to me that this conversation could be much broader in scope. We don't currently have a system for unified benchmarking and standardization of single cell analysis methods, so all approaches should be used with some caution.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/189#issuecomment-413591251:689,continuous,continuous,689,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/189#issuecomment-413591251,1,['continuous'],['continuous']
Deployability,"I think this is currently bugged by: https://github.com/numba/numba/issues/6774. It's a weird bug: some code just doesn't execute, unless I swap out a `prange` with a `range`, in which case it errors. Unless I add an expression that does nothing. Then it can work, except it's doing the expensive computation again 🤯. It looks like this won't be solved by the next numba release, so working around it will be necessary for timely inclusion.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/915#issuecomment-788791783:371,release,release,371,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/915#issuecomment-788791783,1,['release'],['release']
Deployability,"I think this is getting to a good place for an initial addition. Parts that definitely need expanding include:. * Code guidelines; * These are pretty minimal at the moment.; * Documentation; * Information on restructured text ; * sphinx extensions we use; * More on the structure of a doc-string; * Updated examples (I took these from the existing `CONTRIBUTING.md`). I think these can be expanded at a later date. The main goal here was to make sure there was some base organization for a contributing guide and dev-docs. . I'm probably also not the best person to expand on the documentation, since I still barely understand sphinx :wink:.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1544#issuecomment-748856865:299,Update,Updated,299,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1544#issuecomment-748856865,1,['Update'],['Updated']
Deployability,I think this is not a bug. You have to update to latest version of scanpy,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3026#issuecomment-2078034967:39,update,update,39,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3026#issuecomment-2078034967,1,['update'],['update']
Deployability,"I think this is now ready for review. . ## Legends. I've decided to leave showing the null value in continuous legends for another PR, since I don't have an obvious solution now. I have added an argument for specifying whether the na value should show up in the legend, `na_in_legend`. It defaults to `True`. Here's an example:. ```python; sc.pl.umap(brain, color=""leiden"", groups=[""0"", ""1""]); sc.pl.umap(brain, color=""leiden"", groups=[""0"", ""1""], na_in_legend=False); ```. <details>; <summary> Images </summary>. ![image](https://user-images.githubusercontent.com/8238804/90855448-fd3cc400-e3c2-11ea-9e01-6e8266ab6d10.png); ![image](https://user-images.githubusercontent.com/8238804/90855459-0332a500-e3c3-11ea-8b7b-0ba997664f93.png). </details>. The current default of true is a bit weird for ""on data"":. ```python; sc.pl.umap(brain, color=""leiden"", groups=[""0"", ""1""], legend_loc=""on data""); sc.pl.umap(brain, color=""leiden"", groups=[""0"", ""1""], legend_loc=""on data"", na_in_legend=False); ```. <details>; <summary> Images </summary>. ![image](https://user-images.githubusercontent.com/8238804/90855740-a8e61400-e3c3-11ea-99fa-d9cdcd3320ed.png); ![image](https://user-images.githubusercontent.com/8238804/90855745-abe10480-e3c3-11ea-88fd-9c794c95773d.png). </details>. ## Missing color. The missing color can now be specified with `na_color`. This defaults to transparent for spatial plots, and light gray for all other embedding based plots. ```python; with plt.rc_context({""figure.dpi"": 150}):; sc.pl.spatial(brain, color=[""leiden_missing"", ""Bc1_missing""]); sc.pl.spatial(brain, color=[""leiden_missing"", ""Bc1_missing""], na_color=(.8, .8, .8, .2)); ```. <details>; <summary> Images </summary>. ![image](https://user-images.githubusercontent.com/8238804/90855677-894eeb80-e3c3-11ea-91a5-51049080af45.png); ![image](https://user-images.githubusercontent.com/8238804/90855880-05493380-e3c4-11ea-878b-492872198b7f.png). </details>. ## Tests. I've added a parameterized regression test around a perhaps-too",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1356#issuecomment-678052238:100,continuous,continuous,100,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356#issuecomment-678052238,1,['continuous'],['continuous']
Deployability,"I think this may be already implemented in https://scanpy.readthedocs.io/en/stable/generated/scanpy.tl.ingest.html, however, this function contains extra integration and label transfer steps that are not needed for all applications. It would be great if this could be disentangled to make the umap transform available as a separate function on scanpy umaps. Also, it seems that this function does not use scanpy umap to calculate umap so changes may be needed in how scanpy umap is currently calculated.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2259#issuecomment-1237340704:154,integrat,integration,154,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2259#issuecomment-1237340704,1,['integrat'],['integration']
Deployability,"I think this was happening because of confusion between igraph and python-igraph, by un-installing both and reinstalling just python-igraph, the issue was solved. Interesting enough installation with conda didnt work, only installation with pip worked.; thanks again.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/35#issuecomment-324615579:88,install,installing,88,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35#issuecomment-324615579,3,['install'],"['installation', 'installing']"
Deployability,"I think we can work without this particular fix, we probably only need to update the test data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1669#issuecomment-799447066:74,update,update,74,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1669#issuecomment-799447066,1,['update'],['update']
Deployability,"I think with a recent numpy or Pandas update, an if clause in sc.tl.dendrogram no longer works properly. . ```python; import numpy as np; import pandas as pd; import scanpy as sc. # Use pbmc3k dataset; adata = sc.datasets.pbmc3k(); sc.pp.filter_genes(adata, min_counts=1); sc.pp.log1p(adata); sc.pp.normalize_total(adata); sc.pp.highly_variable_genes(adata); sc.tl.pca(adata); sc.pp.neighbors(adata); sc.tl.leiden(adata); sc.tl.rank_genes_groups(adata, groupby='leiden'). # Save the ranks.; results_dict = dict(); for cluster_i in adata.uns['rank_genes_groups']['names'].dtype.names:; # print(cluster_i); # Get keys that we want from the dataframe.; data_keys = list(; set(['names', 'scores', 'logfoldchanges', 'pvals', 'pvals_adj']) &; set(adata.uns['rank_genes_groups'].keys()); ); # Build a table using these keys.; key_i = data_keys.pop(); results_dict[cluster_i] = pd.DataFrame(; row[cluster_i] for row in adata.uns['rank_genes_groups'][key_i]; ); results_dict[cluster_i].columns = [key_i]; for key_i in data_keys:; results_dict[cluster_i][key_i] = [; row[cluster_i] for row in adata.uns['rank_genes_groups'][key_i]; ]; results_dict[cluster_i]['cluster'] = cluster_i; marker_df = pd.concat(results_dict, ignore_index=True). marker_df = marker_df.sort_values(by=['scores'], ascending=False); # Make dataframe of the top 3 markers per cluster; marker_df_plt = marker_df.groupby('cluster').head(3); ; # here sc.tl.dendrogram will fail; _ = sc.pl.dotplot(; adata,; var_names=marker_df_plt['names'],; groupby='leiden',; dendrogram=True,; use_raw=False,; show=False,; color_map='Blues'; save='{}.png'.format('test'); ); ```. ```pytb; /lib/python3.6/site-packages/scanpy/tools/_dendrogram.py in dendrogram(adata, groupby, n_pcs, use_rep, var_names, use_raw, cor_method, linkage_method, optimal_ordering, key_added, inplace); 130 corr_matrix, method=linkage_method, optimal_ordering=optimal_ordering; 131 ); --> 132 dendro_info = sch.dendrogram(z_var, labels=categories, no_plot=True); 133; 134 # order o",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1300:38,update,update,38,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1300,1,['update'],['update']
Deployability,"I think you could get better help on Stackoverflow or https://discuss.scverse.org/. If `pip` reports “Requirement already satisfied” but scanpy can’t import it, then the environment you run `pip` on is not the same you run scanpy in (or the environment is broken and something caused the metadata to be there while the actual package isn’t). If you run `pip --version`, it should tell you its location. That location will probably be different from `/opt/miniconda3/envs/scanpyenvt/`, so you need to make sure you use the correct pip, either by doing. ```py; /opt/miniconda3/envs/scanpyenvt/bin/pip install ...; ```. or by activating it. As said, if you have questions, please go to one of the forums that have a lot of people who can help you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3144#issuecomment-2214155826:599,install,install,599,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144#issuecomment-2214155826,1,['install'],['install']
Deployability,I think you'll want to update your version of anndata for that.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1254#issuecomment-635750301:23,update,update,23,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1254#issuecomment-635750301,1,['update'],['update']
Deployability,"I think your issue here is due to having multiple versions of various packages in your path. In general, that will cause problems. I think I can only recommend creating an isolated environment using something like `conda` or `virtualenv` and say that installing with `pip` tends to have the fewest problems.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1273#issuecomment-651518306:251,install,installing,251,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273#issuecomment-651518306,1,['install'],['installing']
Deployability,"I thought about adding that functionality. Probably is useful when the; second obs_key has few categories because the second category subdivides; the first category. A quick hack is to add a new observation that is the; combination of the first and second keys. Eg. For 4 clusters, and 2 cell; types, the new observation would be cluster_1_cell_type_1,; cluster_1_cell_type_2, cluster_2_cell_type_1 etc. On Thu, Jun 21, 2018 at 5:11 AM wangjiawen2013 <notifications@github.com>; wrote:. > Great, it is. what if I want to add multiple obs_keys (such as lovain,; > cell_type et al.,), and, when will the new version scanpy be released?; >; > —; > You are receiving this because you commented.; >; >; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/issues/178#issuecomment-399032569>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AEu_1a4oPw4zOxr4mLTDh7__Q5BsB5dUks5t-2NAgaJpZM4Uq06H>; > .; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/178#issuecomment-399261667:624,release,released,624,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/178#issuecomment-399261667,1,['release'],['released']
Deployability,I thought you had mentioned moving this to squidpy? Which is fine to me to do whenever you want. Might be good to do ahead of the next visium releases?. Not sure if another package will happen or a timeline if so.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2170#issuecomment-1061645321:142,release,releases,142,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2170#issuecomment-1061645321,1,['release'],['releases']
Deployability,"I too have the exact same issue with scanpy.tl.rank_genes_groups(). Is this something to do with anndata 0.7.5 requires pandas version >=1.0, yet, pandas coming along with installing scanpy with 'pip install scanpy' is in version 0.23.4?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1478#issuecomment-735364926:172,install,installing,172,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1478#issuecomment-735364926,2,['install'],"['install', 'installing']"
Deployability,"I tried seveal times in both win and linux， python2 can not install scany, si there a solution for python2, thanks a lot",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/285:60,install,install,60,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/285,1,['install'],['install']
Deployability,"I tried to collect in one file the code used for plotting functions that use matplotlib scatter like `sc.pl.tsne`, `sc.pl.pca` and `sc.pl.umap` and others. Also, I tried to annotate the code and improve the readability. . Currently, the code is on a separate file called `scatter.py` and not integrated into the API as this facilitates comparison with previous code. . Besides readability the proposed code can:; * Plot a large number of plots in multiple columms (instead of a long row of plots); * Pass arguments directly to `matplotlib.pyplot.scatter` like vmax and vmin to adjust the color scale. When plotting multiple plots, this is useful to have a consistent range of values). See cells 15 and 15 in this example: https://gist.github.com/fidelram/8b43f786e7519bcfb7ffc0d5ccdbb0fe ; If the admins would like to merge these changes I can replaced the previous functions. An example on how to use the code:. ```python; import scanpy.plotting.tools.scatter as spl; spl.tsne(adata, color='louvain'); ```. ![image](https://user-images.githubusercontent.com/4964309/44652273-c908b580-a9eb-11e8-86fa-aa1b55fa9b0a.png). Further examples [here](https://gist.github.com/fidelram/8b43f786e7519bcfb7ffc0d5ccdbb0fe)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/244:292,integrat,integrated,292,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/244,1,['integrat'],['integrated']
Deployability,I tried to install louvain through conda; `conda install -c vtraag louvain`; but got error message:; Solving environment: failed. PackagesNotFoundError: The following packages are not available from current channels:. - louvain; - python-igraph[version='>=0.7.1.0']. However I could install it by; `conda install -c conda-forge louvain`. Can you please update it on the webpage. Thanks!; [https://scanpy.readthedocs.io/en/latest/installation.html](url),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/143:11,install,install,11,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/143,6,"['install', 'update']","['install', 'installation', 'update']"
Deployability,I uninstalled and then installed scanpy. This resolves the issue.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2438#issuecomment-1474040127:23,install,installed,23,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2438#issuecomment-1474040127,1,['install'],['installed']
Deployability,I uninstalled umap and made sure umap-learn was installed but it did not change anything. . I would guess that the problem comes from modules dependency as I managed to make it work on pycharm.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1978#issuecomment-898539219:48,install,installed,48,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1978#issuecomment-898539219,1,['install'],['installed']
Deployability,"I updated anndata to 0.8.0 and was not able to load my scanpy 1.8.2 properly. Any ideas?. ```; ---------------------------------------------------------------------------; ModuleNotFoundError Traceback (most recent call last); /tmp/ipykernel_31935/912249142.py in <module>; ----> 1 import scanpy as sc. ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/__init__.py in <module>; 12 # (start with settings as several tools are using it); 13 from ._settings import settings, Verbosity; ---> 14 from . import tools as tl; 15 from . import preprocessing as pp; 16 from . import plotting as pl. ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/__init__.py in <module>; 15 from ._leiden import leiden; 16 from ._louvain import louvain; ---> 17 from ._sim import sim; 18 from ._score_genes import score_genes, score_genes_cell_cycle; 19 from ._dendrogram import dendrogram. ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_sim.py in <module>; 21 from anndata import AnnData; 22 ; ---> 23 from .. import _utils, readwrite, logging as logg; 24 from .._settings import settings; 25 from .._compat import Literal. ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/readwrite.py in <module>; 8 import pandas as pd; 9 from matplotlib.image import imread; ---> 10 import tables; 11 import anndata; 12 from anndata import (. ModuleNotFoundError: No module named 'tables'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2264:2,update,updated,2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2264,1,['update'],['updated']
Deployability,I updated it to python 3.6.8 and it gets past that error point. ; Thank you very much for all your help.; Cheers.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/734#issuecomment-509622325:2,update,updated,2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/734#issuecomment-509622325,1,['update'],['updated']
Deployability,"I updated release notes and added a test for this specific case. I did not write many tests before, so I looked at the other tests and tried to stick to what I saw there. I noted something unexpected when writing the test: When used `np.mean` and `np.var(.., ddof=1)` to compare against the test failed because some of the variances were off. The current version of the test uses `sc.pp._utils._get_mean_var()` (thats what `highly_variable_genes()` uses internally...), and does not fail.. Is it ok to use that instead? Is it expected that numpy and `_get_mean_var()` are slightly different here?. Test code with numpy ground truth:; ```; def test_seurat_v3_mean_var_output_with_batchkey_vs_numpy():; pbmc = sc.datasets.pbmc3k(); pbmc.var_names_make_unique(); n_cells = pbmc.shape[0]; batch = np.zeros((n_cells), dtype=int); batch[1500:] = 1; pbmc.obs[""batch""] = batch. true_mean = np.mean(pbmc.X.toarray(), axis=0); true_var = np.var(pbmc.X.toarray(), axis=0, ddof=1). result_df = sc.pp.highly_variable_genes(; pbmc, batch_key='batch', flavor='seurat_v3', n_top_genes=4000, inplace=False; ); np.testing.assert_allclose(true_mean, result_df['means'], rtol=2e-05, atol=2e-05); np.testing.assert_allclose(true_var, result_df['variances'], rtol=2e-05, atol=2e-05); ```; Test output:; ```; E AssertionError: ; E Not equal to tolerance rtol=2e-05, atol=2e-05; E ; E Mismatched elements: 172 / 32738 (0.525%); E Max absolute difference: 0.01117667; E Max relative difference: 0.00013328; E x: array([0., 0., 0., ..., 0., 0., 0.], dtype=float32); E y: array([0., 0., 0., ..., 0., 0., 0.]). tests/test_highly_variable_genes.py:279: AssertionError; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1732#issuecomment-797052072:2,update,updated,2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1732#issuecomment-797052072,2,"['release', 'update']","['release', 'updated']"
Deployability,"I updated scanpy:. ```; pip install git+https://github.com/theislab/scanpy.git; pip install spatialde; ```. ```; Successfully built scanpy; Installing collected packages: scanpy; Attempting uninstall: scanpy; Found existing installation: scanpy 1.4.5.2.dev38+gae88b949; Uninstalling scanpy-1.4.5.2.dev38+gae88b949:; Successfully uninstalled scanpy-1.4.5.2.dev38+gae88b949; Successfully installed scanpy-1.4.7.dev47+gf6a49e81; ```. Now I'm not able to generate a spatial plot at all. ```; ----> 5 sc.pl.spatial(adata, img_key=""hires"", color=""clusters"", size=1.5). ~/opt/anaconda3/envs/scanpy/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in spatial(adata, img_key, library_id, crop_coord, alpha_img, bw, **kwargs); 763 """"""; 764 if library_id is _empty:; --> 765 library_id = next((i for i in adata.uns['spatial'].keys())); 766 else:; 767 if library_id not in adata.uns['spatial'].keys():. KeyError: 'spatial'. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1158#issuecomment-614676325:2,update,updated,2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1158#issuecomment-614676325,6,"['Install', 'install', 'update']","['Installing', 'install', 'installation', 'installed', 'updated']"
Deployability,"I updated the commits, making bioservices optional.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/141#issuecomment-386815219:2,update,updated,2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/141#issuecomment-386815219,1,['update'],['updated']
Deployability,I updated the export function `sc.export_to.spring_project` to work with our new version of SPRING (currently at https://github.com/allonkleinlab/spring_dev).,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/157:2,update,updated,2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/157,1,['update'],['updated']
Deployability,"I updated the rank_genes_groups function to output p-values for t-tests and the wilcoxon rank-sum test, as discussed with @falexwolf in #159. ; The changes are outlined below:; - The t-test in the original file used a Welch t-test. I kept this, calculated the relevant degrees of freedom for a Welch test and then extracted the corresponding two-tailed p-value for the t-statistic (score). ; - The Wilcoxon test was originally done in chunks. To get the p-values I had to simplify this approach and use the ranksums function in scipy.stats. This caused me to loop through all of the genes being tested, which was fine for my dataset, but might need to be optimized for larger datasets.; - The adjusted p-values (pvals_adj) were calculated with a standard Bonferroni correction.; - All p-values are outputted and sorted the same way as 'names' or 'scores'. The only difference is that the p-values recarrays use float64 as a datatype to avoid converting a lot of the very small p-values to 0. Hope this is helpful!. Andrés",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/270:2,update,updated,2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/270,1,['update'],['updated']
Deployability,I updated to 1.3.3 but the error still persists. One important thing I didnt mention before: I am running python/scanpy on a Windows machine. @Donovan-CG do you also use Windows?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/333#issuecomment-435784820:2,update,updated,2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/333#issuecomment-435784820,1,['update'],['updated']
Deployability,"I upgrade `scanpy` to `1.9.1`, and now `sc.tl.umap` works as expected:. ![image](https://user-images.githubusercontent.com/33963919/209405851-2798000b-0e90-4b3f-982c-f0de196489c5.png). Thanks",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2386#issuecomment-1364339487:2,upgrade,upgrade,2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2386#issuecomment-1364339487,1,['upgrade'],['upgrade']
Deployability,"I upgraded anndata to 0.8.0 and couldn't load my scanpy 1.8.2 anymore. Error:. ```; ---------------------------------------------------------------------------; ModuleNotFoundError Traceback (most recent call last); /tmp/ipykernel_31935/912249142.py in <module>; ----> 1 import scanpy as sc. ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/__init__.py in <module>; 12 # (start with settings as several tools are using it); 13 from ._settings import settings, Verbosity; ---> 14 from . import tools as tl; 15 from . import preprocessing as pp; 16 from . import plotting as pl. ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/__init__.py in <module>; 15 from ._leiden import leiden; 16 from ._louvain import louvain; ---> 17 from ._sim import sim; 18 from ._score_genes import score_genes, score_genes_cell_cycle; 19 from ._dendrogram import dendrogram. ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_sim.py in <module>; 21 from anndata import AnnData; 22 ; ---> 23 from .. import _utils, readwrite, logging as logg; 24 from .._settings import settings; 25 from .._compat import Literal. ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/readwrite.py in <module>; 8 import pandas as pd; 9 from matplotlib.image import imread; ---> 10 import tables; 11 import anndata; 12 from anndata import (. ModuleNotFoundError: No module named 'tables'. ```. The messages when updating anndata:; ```; The following packages will be REMOVED:. pytables-3.6.1-py38h9f153d1_1. The following packages will be UPDATED:. anndata 0.7.6-py38h578d9bd_0 --> 0.8.0-py38h578d9bd_0; ca-certificates pkgs/main::ca-certificates-2022.4.26-~ --> conda-forge::ca-certificates-2022.5.18.1-ha878542_0; h5py 2.10.0-nompi_py38h513d04c_102 --> 3.6.0-nompi_py38hfbb2109_100; hdf5 1.10.5-nompi_h5b725eb_1114 --> 1.12.1-nompi_h2750804_100. The following packages will be SUPERSEDED by a higher-priority channel:. certifi pkgs/main::certifi-2022.5.18.1-py38h0~ --> conda-forge::certifi-2022.5",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2265:2,upgrade,upgraded,2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2265,1,['upgrade'],['upgraded']
Deployability,I upgraded loompy and scanpy as well but now I am getting an other error. ![screen shot 2018-08-29 at 19 21 34](https://user-images.githubusercontent.com/42487820/44782019-db881800-abc0-11e8-8948-90aa0b0c20a1.png). ![screen shot 2018-08-29 at 19 14 14](https://user-images.githubusercontent.com/42487820/44782040-eb076100-abc0-11e8-961e-75b4ba0c8ec7.png),MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/247#issuecomment-416903663:2,upgrade,upgraded,2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/247#issuecomment-416903663,1,['upgrade'],['upgraded']
Deployability,I upgraded to 1.3.3 and the bug persists. . PS: I accidentally closed the issue for some reason.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/370#issuecomment-440522061:2,upgrade,upgraded,2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/370#issuecomment-440522061,1,['upgrade'],['upgraded']
Deployability,I used `bioconda` as it was the recommended installation method according to the Scanpy documentation site last time I checked (october 2021). My bad then. I only installed `scanpy` through `bioconda` so the version I got (and you see in the Details of the previous post) are from there. `anndata2ri` version in there is from `pip`. If I try with conda-forge channel for both scanpy and anndata2ri the issue is solved.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2172#issuecomment-1063103340:44,install,installation,44,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2172#issuecomment-1063103340,2,['install'],"['installation', 'installed']"
Deployability,"I used the following code once in a time . however , no visible different could be found in the result (`sc.pl.umap(adata, color='batch')`). ```; sc.pp.combat(adata). sce.pp.bbknn(adata, batch_key='batch'). from itertools import cycle; sce.pp.mnn_correct(adata, var_index=None, var_subset=None, batch_key='batch', index_unique='-', batch_categories=None, k=20, sigma=1.0, cos_norm_in=True, cos_norm_out=True, svd_dim=None, var_adj=True, compute_angle=False, mnn_order=None, svd_mode='rsvd', do_concatenate=True, save_raw=False, n_jobs=None); #OR; import mnnpy; mnnpy.mnn_correct(adata). sce.pp.magic(adata). sce.tl.phate(adata); ```. Here，I attach the Integrate result from seurat based on same data. we can that most of the sample 001, 002，and 009 were grouped together on left , most part of sample 003 was on the right. ; ![20191016EVE_UMAP_Integrate](https://user-images.githubusercontent.com/49429496/66911577-5f11fc00-f043-11e9-8be2-742a4ffaa7a3.png). or this way (split by batch); ![20191016EVE_UMAP_Integrate_SplitByPatient](https://user-images.githubusercontent.com/49429496/66911623-79e47080-f043-11e9-8d5d-7769437831da.png)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/873#issuecomment-542637756:652,Integrat,Integrate,652,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/873#issuecomment-542637756,1,['Integrat'],['Integrate']
Deployability,"I want to start off by mentioning how much I love scanpy. I recommend this package to everyone I know who is doing single cell sequencing. I love how PAGA and UMAP can be integrated together. PAGA makes appreciation of data topology so simple. In addition, it's so easy to do velocity analysis with the scvelo integration. Installing scanpy as well as hdf5/loom compatibility is remarkably easier on python than in R, which gives scanpy users an obvious advantage. . I've learned so much using this package and it has allowed me to display my data in a simple and intuitive way. Truly, from the bottom of my heart, thank you, this package is awesome and I deeply appreciate all the work the scanpy team and Theis lab has put into it. . With that said, I find myself wanting to do things with scanpy that aren't currently supported. . (1) Clustering cells based on a restricted set of genes as opposed to principle components: I understand that this is a biased approach, but I find myself wanting to do this to explore datasets and how genes vary together. I believe it would aid in understanding data topology to reduce the dimensionality of the dataset by looking at a subset of key genes that are picked by an expert who has domain knowledge. I think this is best integrated with a separate sc.pp.neighbors-like function that uses a gene list, as opposed to PCs. Integration into downstream plotting can be done with separate functions that have a similar name (sc.tl.umap_genelist or sc.tl.umap_sparse; sc.tl.paga_genelist or sc.tl.paga_sparse). . I envision that this would also be a nice stepping stone towards multi-modal analysis with CITE-seq. . (2) I want to use PAGA and UMAP to display my CytOF data as well as integrate scRNA-seq/CytOF data together. I saw a pre-print on bioRxiv that indicated that you are working on this aspect of PAGA/scanpy. This was very exciting to me and I am glad that this is being developed. Is it possible to access the current version of this software? . I t",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/510:171,integrat,integrated,171,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510,3,"['Install', 'integrat']","['Installing', 'integrated', 'integration']"
Deployability,"I wanted to take a look at the slide image, without doing any computation, to pick a pretty example. This leads to an `AttributeError`:. ```python; import scanpy as sc. adata = sc.datasets.visium_sge(""V1_Mouse_Brain_Sagittal_Posterior""); sc.pl.spatial(adata); ```. ```pytb; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-3-1ffa4586cef4> in <module>; ----> 1 sc.pl.spatial(adata). ~/github/scanpy/scanpy/plotting/_tools/scatterplots.py in spatial(adata, img_key, library_id, crop_coord, alpha_img, bw, **kwargs); 785 bw=bw,; 786 library_id=library_id,; --> 787 **kwargs,; 788 ); 789 . ~/github/scanpy/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs); 397 c=color_vector,; 398 rasterized=settings._vector_friendly,; --> 399 **kwargs,; 400 ); 401 . ~/github/scanpy/scanpy/plotting/_utils.py in circles(x, y, s, ax, marker, c, vmin, vmax, **kwargs); 1127 patches = [Circle((x_, y_), s_) for x_, y_, s_ in zipped]; 1128 collection = PatchCollection(patches, **kwargs); -> 1129 if c is not None and np.issubdtype(c.dtype, np.number):; 1130 collection.set_array(c); 1131 collection.set_clim(vmin, vmax). AttributeError: 'str' object has no attribute 'dtype'; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1225:1387,patch,patches,1387,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1225,3,"['Patch', 'patch']","['PatchCollection', 'patches']"
Deployability,"I was able to set up a dev environment with a little work. I think it works? Ran into some other issues though. <details>; <summary> Roughly what I ran </summary>. ```sh; mamba create -yn ""numba-0.55.0rc1-pip"" -c conda-forge python=3.10 pip; conda activate numba-0.55.0rc1-pip; pip install ""numba== 0.55.0rc1-pip""; pip install flit_core setuptools_scm; cd ~/github/anndata; pip install -e "".[dev,doc,test]""; cd ~/github/scanpy; pip install -e --no-build-isolation "".[dev,doc,test]""; ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2105#issuecomment-1010919911:282,install,install,282,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2105#issuecomment-1010919911,4,['install'],['install']
Deployability,"I was eventually able to contact the maintainer and he's looking into making a new release. Will see what happens. Nevertheless, it might not be a bad idea to simplify the code and to only support `igraph`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2067#issuecomment-995647980:83,release,release,83,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2067#issuecomment-995647980,1,['release'],['release']
Deployability,"I was following the documentation and kept getting failures when I tried to pass additional args to violin() via kwargs, and found that kwargs was only [added to violin 6 days ago](https://github.com/theislab/scanpy/blame/master/scanpy/plotting/anndata.py#L347). Yay (and thanks) for the updates)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/85#issuecomment-371026156:288,update,updates,288,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/85#issuecomment-371026156,1,['update'],['updates']
Deployability,I was having the same problem. **conda update anndata** solved my problem.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2297#issuecomment-1434409733:39,update,update,39,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297#issuecomment-1434409733,1,['update'],['update']
Deployability,"I was just trying to run the [1.3 million cell clustering example](https://github.com/theislab/scanpy_usage/tree/master/170522_visualizing_one_million_cells), but have come across some strange behavior. When loading in the `hdf5` file from 10x to an AnnData object, the whole process uses about 30gb. If I write that AnnData object to disk with `adata.write`, then try to load that file (with `sc.read`) I end up using all the memory on the machine (~60g) before segfault-ing. I'd think that any dataset I wrote from memory, I should be able to read back into memory. I've put the full scripts to reproduce on my system in [this gist](https://gist.github.com/ivirshup/42e70a745704b8c71d78e57dd43e3b0b), but essentially I've run:. ```python; # gen_h5ad.py; import scanpy.api as sc; adata = sc.read_10x_h5(""{DATAPTH}/1M_neurons_filtered_gene_bc_matrices_h5.h5"") # Uses about 30gb; adata.write(""./write/1M_neurons.h5ad""); ```; ```python; # load_anndata.py; import scanpy.api as sc; adata = sc.read(""./write/1M_neurons.h5ad"") # Ends with segfault; ```. I'm running `scanpy` installed with conda with the following versions:. ```; scanpy==1.0.4 anndata==0.6 numpy==1.14.2 scipy==1.0.1 pandas==0.22.0 scikit-learn==0.19.1 statsmodels==0.8.0; ```. Thanks for the great package! Let me know if you'd like any more details on my setup.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/146:1070,install,installed,1070,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/146,1,['install'],['installed']
Deployability,"I was just wondering if you guys have any plans for scATAC data analysis pipelines and especially integration with scRNA-seq? . cheers,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/725:73,pipeline,pipelines,73,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/725,2,"['integrat', 'pipeline']","['integration', 'pipelines']"
Deployability,"I was recently directed to the [RStudio tutorial for setting up Python/R with {reticulate}](https://t.co/DjbnfZmjQn?amp=1). After this it worked successfully for me; hope it helps. First, source the `virtualenv` and install the package only to the directory/project your working on ([similar concept to `{packrat}`](https://rstudio.github.io/packrat/)); ![image](https://user-images.githubusercontent.com/5749465/73144449-d0663f80-4073-11ea-85d2-2277fb049342.png). *Voila!*. ![image](https://user-images.githubusercontent.com/5749465/73144482-20450680-4074-11ea-9374-6dac81968f89.png)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/990#issuecomment-578560517:216,install,install,216,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/990#issuecomment-578560517,1,['install'],['install']
Deployability,"I was thinking more like:. ```python; sc.pl.dotplot(; ...,; var_ticklabels_kwargs={; ""fontstyle"": ""italic"",; ... ; },; ); ```. With an internal:. ```python; var_ticklabels_params = {""rotation"": 90, ""ha"": 'center', ""minor"": False}; var_ticklabels_params.update(var_ticklabels_kwargs}. dot_ax.set_xticklabels(var_names, **var_ticklabels_params); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1913#issuecomment-872712326:253,update,update,253,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1913#issuecomment-872712326,1,['update'],['update']
Deployability,"I was thinking we could go a bit further. We could add `sinfo` as a dependency and make `print_versions` just call: `sinfo.sinfo(dependencies=True)` which will always be comprehensive. <details>; <summary> Example output: </summary>. ```; -----; IPython 7.16.1; scanpy 1.5.2.dev38+g6728bdab; sinfo 0.3.1; -----; IPython 7.16.1; PIL 7.2.0; anndata 0.7.5.dev0+g58886f0.d20200729; asciitree NA; backcall 0.2.0; cffi 1.14.0; cloudpickle 1.5.0; colorama 0.4.3; cycler 0.10.0; cython_runtime NA; dask 2.21.0; dateutil 2.8.1; decorator 4.4.2; fasteners NA; get_version 2.1; google NA; h5py 2.10.0; igraph 0.8.2; ipython_genutils 0.2.0; jedi 0.17.2; joblib 0.16.0; kiwisolver 1.2.0; legacy_api_wrap 1.2; leidenalg 0.8.1; llvmlite 0.33.0; louvain 0.7.0; matplotlib 3.3.0; monotonic NA; mpl_toolkits NA; msgpack 1.0.0; natsort 7.0.1; numba 0.50.1; numcodecs 0.6.4; numexpr 2.7.1; numpy 1.19.0; packaging 20.4; pandas 1.0.5; parso 0.7.0; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.5; psutil 5.7.0; ptyprocess 0.6.0; pygments 2.6.1; pyparsing 2.4.7; pytz 2020.1; scanpy 1.5.2.dev38+g6728bdab; scipy 1.5.1; sinfo 0.3.1; sitecustomize NA; six 1.15.0; sklearn 0.23.1; sphinxcontrib NA; storemagic NA; tables 3.6.1; tblib 1.6.0; texttable 1.6.2; tlz 0.10.0; toolz 0.10.0; traitlets 4.3.3; typing_extensions NA; wcwidth 0.2.5; yaml 5.3.1; zarr 2.4.0; -----; Python 3.8.5 (default, Jul 23 2020, 15:50:11) [Clang 11.0.3 (clang-1103.0.32.62)]; macOS-10.15.6-x86_64-i386-64bit; 16 logical CPU cores, i386; -----; Session information updated at 2020-07-30 19:28; ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1343#issuecomment-666257831:1540,update,updated,1540,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1343#issuecomment-666257831,1,['update'],['updated']
Deployability,"I was trying some integration methods between the two pbmc datasets. Maybe, could you add a sc.datasets.pbmc68k_full() where the whole transcriptome is included?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1762#issuecomment-808189078:18,integrat,integration,18,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1762#issuecomment-808189078,1,['integrat'],['integration']
Deployability,"I was wondering if we could deprecate the scvi external wrapper as we now have `scvi-tools`. I could also update the wrapper to have minimal functionality, but I think it would be better for people to use our API now that it's tightly integrated with scanpy anyway.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1443:106,update,update,106,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1443,2,"['integrat', 'update']","['integrated', 'update']"
Deployability,"I wasn't aware that you could run `sc.pp.scale` without obtaining mean 0 at the end. Would that just scale the variance per gene then?. As for your question on HVG selection after `sc.pp.regress_out` vs in batches... I think that's an interesting question, but I reckon the two scenarios are actually not that related. I normally wouldn't use `sc.pp.regress_out` to remove batch effects, but rather to regress out continuous covariates like cell cycle scores. Batch effect removal is probably best done with methods that account for the variance contribution of the batch effect as well, such as Combat... or more complex data integration methods (Seuart, MNN, scanorama). Either way, it would be an interesting comparison... just with a caveat ^^.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/722#issuecomment-509687449:414,continuous,continuous,414,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/722#issuecomment-509687449,2,"['continuous', 'integrat']","['continuous', 'integration']"
Deployability,"I welcome @VolkerBergen ideas about plot scatter. I have used the scvelo version of scatter and works quite well and always thought that we could integrate this. Our comprehensive collection of tests related to embeddings should facilitate the recreation of the current functionality using a scatter module. As @flying-sheep points out we have a mess with respect to `pl.scatter` and `pl.embeddings` and would be great to unify the code. Currently, `pl.scatter` is used to plot two genes or any two variables like in `sc.pl.highly_variable_genes`. `pl.embedding` takes x,y (and z if 3D) from `.obsm` while adjusting color and size depending on given parameters. When I started working on the plotting functions I didn't touch `pl.scatter` which remains quite convoluted and hard to follow.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/617#issuecomment-554257192:146,integrat,integrate,146,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/617#issuecomment-554257192,1,['integrat'],['integrate']
Deployability,"I went through the PRs and we actually did a good job (at least for the backported ones): Nothing missing!. Regarding the new 1.9.5.md: Even if 1.9.5 will probably not happen, we should just keep the file and fill it as expected, and if we release 1.10 first, we just migrate the by-then-merged changes over and delete the 1.9.5.md. Better to stick to a clean process than improvising and making things confusing.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2639:240,release,release,240,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2639,1,['release'],['release']
Deployability,I will certainly update my new stuff today at least once (probably more often ) and change the name / add the documentation ; and then let you know as soon as the name has changed,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/72#issuecomment-361899845:17,update,update,17,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/72#issuecomment-361899845,1,['update'],['update']
Deployability,"I will close this issue because there is an external solution available. We may think about integrating this specific plot into Scanpy at some point, but I don't see it happening anytime soon.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1824#issuecomment-953646449:92,integrat,integrating,92,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1824#issuecomment-953646449,1,['integrat'],['integrating']
Deployability,"I will take a look later to see how we can integrate better the visualizations, the tests and the documentation. I will put back `kwds` also. . Have you consider adding another dataset to the repository? This will be good for showing examples.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/207#issuecomment-405505301:43,integrat,integrate,43,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/207#issuecomment-405505301,1,['integrat'],['integrate']
Deployability,"I would just like to add that the issue with `normalize_total` can arise not only from the `downsample_counts` function. . In my case, I am working on `.loom` files generated with *velocyto* - I want to be able to estimate RNA velocity in the end. That means I have 'spliced' and 'unspliced' layers in my anndata object. I wanted to use `normalize_total` on all the layers, which should be possible by setting parameter `layers='all'`. However, I was getting a TypeError, as in #435 . The workaround described at the end of that issue solved it for me. My point is just that fixing only `downsample_counts` is not enough and functions that work on layers should accept integer data. I think that my case is not that uncommon and will happen more often as people use scVelo with velocyto pipelines. . Alternatively, you should warn people about it in the tutorials and make them convert everything to float.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/865#issuecomment-552929823:787,pipeline,pipelines,787,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/865#issuecomment-552929823,1,['pipeline'],['pipelines']
Deployability,I would like to do this for the next release series.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1169#issuecomment-833182712:37,release,release,37,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1169#issuecomment-833182712,1,['release'],['release']
Deployability,"I would like to get an opinion from @gokceneraslan, @adamgayoso (who implemented this originally), or someone else more familiar in hvg selection here. I feel like we should probably have multiple methods for this, which we expose via a kwarg. I'm not confident median rank makes sense as a value here. I think there are assumptions about what kinds of values a rank can have that get broken by taking the median. Is the method for aggregating hvgs from multiple batches here reasonable? For reference, a similar code block can be found in `_highly_variable_genes_seurat_v3`, which says this is the method used in `SelectIntegrationFeatures` from Seurat. _Originally posted by @ivirshup in https://github.com/theislab/scanpy/pull/1715#discussion_r736690390_. @jlause commented:; I agree that exposing multiple options could make sense here. Any opinion @gokceneraslan and @adamgayoso which ones we should implement / which one should be the default?. I just copied this part from the seurat_v3 batch integration, so I don't have an expert opinion - but if I remember correctly, the other flavors use dispersions_norm to break ties instead of using the median rank. If I read the code correctly, this is the within-batch dispersion averaged over batches. We could also do something similar here: Compute residual variance within each batch, take the average across batches, and use that to break ties instead of using median rank.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2151:1000,integrat,integration,1000,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2151,1,['integrat'],['integration']
Deployability,"I would recommend creating fresh conda environments frequently, especially if you mix `conda` and `pip` installation. Upgrading them in finicky, and often results in a broken state.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1567#issuecomment-968903708:104,install,installation,104,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1567#issuecomment-968903708,1,['install'],['installation']
Deployability,"I would say this is not a scanpy question.; It is not clear what do you mean by correlation of a categorical variable with multiple categories and a continuous variable. ; If you have a binary categorical variable, you can calculate Point Biserial Correlation, but for a multicategorical variable you would have to discretize your continuous variable and calculate Chi-squared test. You can also try ANOVA. If you think you know what variables are dependent and independent you can use logistic regression and look at its coefficients or try ANCOVA.; some additional information with examples; https://datascience.stackexchange.com/questions/893/how-to-get-correlation-between-two-categorical-variable-and-a-categorical-variab",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1845#issuecomment-848101984:149,continuous,continuous,149,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1845#issuecomment-848101984,2,['continuous'],['continuous']
Deployability,"I'd argue a janky dependency is an issue with scanpy's code, as there are interfaces to BioMart which are better behaved. Here's a proof of concept:. ```python; def mitochondrial_genes(org, attrname=""external_gene_name"", host=""www.ensembl.org""):; """"""Mitochondrial gene symbols for specific organism through BioMart. Parameters; ----------; org : {{""hsapiens"", ""mmusculus"", ""drerio""}}; Organism to query. Must be an organism in ensembl biomart.; fieldname : `str`, optional (default: ""external_gene_name""); Biomart attribute field to return. Possible values include ; ""external_gene_name"", ""ensembl_gene_id"", ""hgnc_symbol"", ""mgi_symbol"",; and ""zfin_id_symbol"".; host : {{""www.ensembl.org"", ...}}; A valid BioMart host URL. Returns; -------; An `np.array` containing identifiers for mitochondrial genes.; """"""; try:; from pybiomart import Server; except ImportError:; raise ImportError(; ""You need to install the `pybiomart` module.""); server = Server(host); dataset = (server.marts[""ENSEMBL_MART_ENSEMBL""]; .datasets[""{}_gene_ensembl"".format(org)]); res = dataset.query(; attributes=[attrname], ; filters={""chromosome_name"": [""MT""]},; use_attr_names=True; ); return res[attrname].values; ```. Running it:. ```python; >>> mitochondrial_genes(""hsapiens""); array(['MT-TF', 'MT-RNR1', 'MT-TV', 'MT-RNR2', 'MT-TL1', 'MT-ND1',; 'MT-TI', 'MT-TQ', 'MT-TM', 'MT-ND2', 'MT-TW', 'MT-TA', 'MT-TN',; 'MT-TC', 'MT-TY', 'MT-CO1', 'MT-TS1', 'MT-TD', 'MT-CO2', 'MT-TK',; 'MT-ATP8', 'MT-ATP6', 'MT-CO3', 'MT-TG', 'MT-ND3', 'MT-TR',; 'MT-ND4L', 'MT-ND4', 'MT-TH', 'MT-TS2', 'MT-TL2', 'MT-ND5',; 'MT-ND6', 'MT-TE', 'MT-CYB', 'MT-TT', 'MT-TP'], dtype=object); >>> mitochondrial_genes(""hsapiens"", host=""asia.ensembl.org""); array(['MT-TF', 'MT-RNR1', 'MT-TV', 'MT-RNR2', 'MT-TL1', 'MT-ND1',; 'MT-TI', 'MT-TQ', 'MT-TM', 'MT-ND2', 'MT-TW', 'MT-TA', 'MT-TN',; 'MT-TC', 'MT-TY', 'MT-CO1', 'MT-TS1', 'MT-TD', 'MT-CO2', 'MT-TK',; 'MT-ATP8', 'MT-ATP6', 'MT-CO3', 'MT-TG', 'MT-ND3', 'MT-TR',; 'MT-ND4L', 'MT-ND4', 'MT-TH', 'MT-TS2', '",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/242#issuecomment-457039514:898,install,install,898,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/242#issuecomment-457039514,1,['install'],['install']
Deployability,"I'd be happy with whatever, but it needs to go somewhere!. How about ""Demultiplexing/ Doublet detection"", so it can go with scrublet (#1476) in the next release, and potentially get split out later if more demultiplexing methods are added?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1483#issuecomment-726001024:153,release,release,153,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1483#issuecomment-726001024,1,['release'],['release']
Deployability,"I'd definitely make a new function `tl.leiden`; then @vtraag 's package can also be taken credit of in an appropriate way, using the reference to the recent arxiv. . Also, backwards compat is guaranteed and @flying-sheep's two other points (eduction and ease-of-use) are met, too. So, @ktpolanski, would you make a PR for a function `tl.leiden`? Of course, it would be nice if didn't duplicate all code in the louvain function, but that's up to you. I would not yet make the `leidenalg` package a at this stage, but transition to that either in Scanpy `1.4` or later. People can definitely achieve decent results with the current setup and we don't want everyone to change everything. After the PR, those who want can slowly transition to the new clustering algorithm. After a major release, we can broadly advertise the package. @vtraag: Great to see your new preprint and package. I thought that your Louvain implementation already yielded very well-connected communities and even made a remark on that [here](https://doi.org/10.1101/208819) in the first version more than a year ago. But great, in hard cases, I'd expect better results using your new algorithm for partitioning the graph...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/350#issuecomment-437728767:783,release,release,783,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/350#issuecomment-437728767,1,['release'],['release']
Deployability,"I'd like to integrate DCA with scanpy and I need to ask some questions regarding that. . There are two use cases for DCA so far. One is denoising as a preprocessing step and using denoised matrix in downstream analyses, especially in the ones that require original feature space such as differential expression. This seems to be a better fit for the `preprocessing` package i.e. `sc.pp.dca(adata)` which overwrites `adata.X` with the denoised matrix. Users can use `copy=True` to keep adata.X of original matrix unchanged. The other use case is the low dimensional representations of cells produced by the encoder. This can also be used for the downstream analyses that do not require original feature space e.g. clustering, and visualization. This is more like `sc.tl.dca(adata)` which stores the new representation into `adata.obsm['X_dca']`. Optionally it can store dropout probabilities (pi matrix) and the dispersion, as well. However, having both sc.tl.dca and sc.pp.dca might be confusing for the users. Any suggestions?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/142:12,integrat,integrate,12,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/142,1,['integrat'],['integrate']
Deployability,"I'd like to start using [pre-commit](https://pre-commit.com) with scanpy and anndata. Pre-commit is essentially a tool that manages scripts we'd like to run before each commit, e.g. linting and formatting, so it becomes essentially impossible to forget these. I think this can allow PRs to progress faster since it gives us a way to codify formatting requirements – so we don't have to remember them – and have these checks happen locally – so we don't have to wait on CI. Of course, having these checks run depends on developers installing pre-commit, so we can also run these checks on CI ([example ci script](https://github.com/pandas-dev/pandas/blob/master/.github/workflows/pre-commit.yml), [example run](https://github.com/pandas-dev/pandas/pull/38745/checks?check_run_id=1624558250)). There is a question of what things we'd like to add here. For sure: `black`. I think import checks (e.g. no unused imports) and `flake8` would be good too. We can also add custom checks for things like slow imports. I think this would be a good time to run `black` over the whole codebase so we don't have exempted files any more. My questions for the dev team:. * Does this sound good?; * Do you have more ideas for checks/ tools?. @michalk8, I saw you added this to [`squidpy`](https://github.com/theislab/squidpy/pull/203). How's the experience been there – that is, any major foot guns we should look out for? Also, are there any tools you're using (beyond the basic `black`, `isort`, `flake8`) you'd especially recommend?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1563:530,install,installing,530,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1563,1,['install'],['installing']
Deployability,I'd love to have scVI integration! :),MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/520#issuecomment-470977867:22,integrat,integration,22,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/520#issuecomment-470977867,1,['integrat'],['integration']
Deployability,"I'm a little late to the party, but here's my 0.02$. > What is the scope of this PR? Will this just be single dataset TSNE calculation, with integration/ ingest functionality happening separately, or would you like to do it all at once?. I think we can split it into two PRs, since they're going to touch different parts of the code base, and it should be easier to review them individually. > How different are the arguments to the various affinity methods?. So, if we use the KNNG provided by `sc.pp.neighbors`, these parameters become unnecessary. Both `perplexity` and `k` specify the number of k-nearest neighbors when constructing the KNNG. Here, we assume that the KNNG exists from before, so there is no need for this parameter. > Do you need to know what the affinity method was if you're just calculating an embeddings? Or does that only become important when you want to add new data?. Yes, the affinity model will have to be somehow kept, since when we call `transform`, we need to find the nearest neighbors in the index. I haven't checked how your UMAP functionality does this, but I'm guessing it's similar. Regarding the whole API, I have a few comments. I very much dislike the API `sc.pp.neighbors_tsne(adata)`. scanpy is nice because it's easy to use and the API is dead simple. I can just call `sc.pp.neighbors` followed by clustering, visualization, and whatever else I want using simple function calls. If we went this route, this would mean changing `sc.pp.neighbors` to `sc.pp.umap_neighbors`, and then splitting of yet another `sc.pp.gauss_neighbors`. This would not only make things confusing, it would mean re-calculating the KNNG at each call, which we would inevitably have to do if we wanted different visualizations. It then also becomes quite unclear what to do when I want to do Louvain clustering. Should there be a `sc.pp.louvain_neighbors` as well? Which neighbors should I use there? (As an aside, I don't understand why using UMAP connectivites is the default for",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1561#issuecomment-759374009:141,integrat,integration,141,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561#issuecomment-759374009,1,['integrat'],['integration']
Deployability,"I'm adding that expression atlas downloader now (#489), and wondering where the files should go. `pbmc68k_reduced` and `toggleswitch` put the datasets relative to where scanpy is installed (via `__file__`). All other functions place the data relative to where the python process was started. While I like not storing the same files all over a filesystem, I'm not sure in the `scanpy` installation directory is the right place to be storing data. Thoughts?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/558:120,toggle,toggleswitch,120,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558,3,"['install', 'toggle']","['installation', 'installed', 'toggleswitch']"
Deployability,"I'm afraid it's the bioconda CI that generates them. . Switching back to bioconda has another caveat I think: The conda-forge channel is supposed to have a higher channel priority than the bioconda one. AFAIK if a more recent version of scanpy was on bioconda, it would still be the older conda-forge version that gets installed (unless the newer version is requested explicitly)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2281#issuecomment-1160313163:319,install,installed,319,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281#issuecomment-1160313163,1,['install'],['installed']
Deployability,"I'm also interested in this since I'll be analyzing some HTO data soon. . As I wrote [here](https://github.com/theislab/scanpy/pull/797/files/8bcee13537d6353399f1722bac7f60bc943a482f#r335664372), I think we should also discuss the I/O and storage procedures for ADT/HTOs. . @wflynny it makes a lot of sense to use `adata.obsm[""X_adt""]` and `adata.obsm[""X_hto""]` for ADT and HTO counts. One caveat is that we cannot store ADT/HTO barcode strings in `adata.obsm` but I don't know how important this is. For I/O, we can define a `sc.read_antibody_tags(filename)` that reads HTO/ADTs into the `adata.obsm['X_hto']`. Then a simple `sc.pp.classify_hashtags()` method can determine classes and creates new fields like HTO_class in `adata.obs`. @wflynny @njbernstein what do you think? @wflynny what else do you think is needed for a nice HTO/ADT pipeline?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/351#issuecomment-542879027:839,pipeline,pipeline,839,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/351#issuecomment-542879027,1,['pipeline'],['pipeline']
Deployability,"I'm assuming that the `n_jobs` parameter is supposed to control the number of simultaneously threads used in calculating clusters. However, no matter what I set this parameter to the process will spawn as many threads as their are cores on the machine running it. The offending bit of code seems to be a call to `graph.update.diffmap()` in `add_or_update_graph_in_adata` as far as I can tell. I need to be able to control the number of threads used to use scanpy on a farm. How can I do this?. Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/101:319,update,update,319,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/101,1,['update'],['update']
Deployability,"I'm getting the same error from RStudio with reticulate:. From the console:. ```; py_install('scanpy'); Collecting package metadata (current_repodata.json): ...working... done; Solving environment: ...working... done. # All requested packages already installed. Collecting package metadata (current_repodata.json): ...working... done; Solving environment: ...working... failed with initial frozen solve. Retrying with flexible solve.; Collecting package metadata (repodata.json): ...working... done; Solving environment: ...working... failed with initial frozen solve. Retrying with flexible solve. PackagesNotFoundError: The following packages are not available from current channels:. - scanpy. Current channels:. - https://conda.anaconda.org/conda-forge/linux-64; - https://conda.anaconda.org/conda-forge/noarch; - https://repo.anaconda.com/pkgs/main/linux-64; - https://repo.anaconda.com/pkgs/main/noarch; - https://repo.anaconda.com/pkgs/r/linux-64; - https://repo.anaconda.com/pkgs/r/noarch. To search for alternate channels that may provide the conda package you're; looking for, navigate to. https://anaconda.org. and use the search bar at the top of the page. Error: one or more Python packages failed to install [error code 1]; ```. If I switch to the terminal and try `pip` or `conda` I get:. ```; pip install scanpy; ```. ```; Requirement already satisfied: scanpy in /home/tsundoku/anaconda3/lib/python3.7/site-packages (1.4.5.post2); Requirement already satisfied: setuptools-scm in /home/tsundoku/anaconda3/lib/python3.7/site-packages (from scanpy) (3.3.3); Requirement already satisfied: scipy>=1.3 in /home/tsundoku/anaconda3/lib/python3.7/site-packages (from scanpy) (1.3.2); Requirement already satisfied: pandas>=0.21 in /home/tsundoku/anaconda3/lib/python3.7/site-packages (from scanpy) (0.25.3); Requirement already satisfied: packaging in /home/tsundoku/anaconda3/lib/python3.7/site-packages (from scanpy) (19.2); Requirement already satisfied: natsort in /home/tsundoku/anacond",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/990#issuecomment-575281452:251,install,installed,251,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/990#issuecomment-575281452,1,['install'],['installed']
Deployability,"I'm getting the same error using the CellBender tutorial output. Attaching the file to make it easier to reproduce. [tiny_10x_pbmc_filtered.h5.zip](https://github.com/scverse/scanpy/files/8766499/tiny_10x_pbmc_filtered.h5.zip). `sc.logging.print_versions()`. ```; -----; anndata 0.7.8; scanpy 1.9.1; -----; PIL 9.0.1; asttokens NA; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; cffi 1.15.0; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.6.0; decorator 5.1.1; defusedxml 0.7.1; doubletdetection 4.2; entrypoints 0.4; executing 0.8.3; google NA; h5py 3.6.0; hypergeom_ufunc NA; igraph 0.9.9; ipykernel 6.10.0; ipython_genutils 0.2.0; ipywidgets 7.7.0; jedi 0.18.1; joblib 1.1.0; kiwisolver 1.4.2; leidenalg 0.8.9; llvmlite 0.38.0; louvain 0.7.1; matplotlib 3.5.1; matplotlib_inline NA; mkl 2.4.0; mpl_toolkits NA; mudata 0.1.1; muon 0.1.2; natsort 8.1.0; nbinom_ufunc NA; numba 0.55.1; numexpr 2.8.1; numpy 1.21.2; organize_metadata NA; packaging 21.3; pandas 1.4.1; parso 0.8.3; pexpect 4.8.0; phenograph 1.5.7; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.28; psutil 5.9.0; ptyprocess 0.7.0; pure_eval 0.2.2; pycparser 2.21; pydev_ipython NA; pydevconsole NA; pydevd 2.8.0; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.11.2; pynndescent 0.5.6; pyparsing 3.0.7; pytz 2022.1; scikits NA; scipy 1.8.0; seaborn 0.11.2; session_info 1.0.0; setuptools 62.0.0; setuptools_scm NA; six 1.16.0; sklearn 1.0.2; stack_data 0.2.0; statsmodels 0.13.2; tables 3.7.0; texttable 1.6.4; threadpoolctl 3.1.0; tornado 6.1; tqdm 4.63.1; traitlets 5.1.1; typing_extensions NA; umap 0.5.2; wcwidth 0.2.5; yaml 6.0; zipp NA; zmq 22.3.0; -----; IPython 8.2.0; jupyter_client 7.1.2; jupyter_core 4.9.2; notebook 6.4.10; -----; Python 3.9.11 (main, Mar 28 2022, 10:10:35) [GCC 7.5.0]; Linux-4.15.0-142-generic-x86_64-with-glibc2.27; -----; Session information updated at 2022-05-24 15:05; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2203#issuecomment-1136479284:1885,update,updated,1885,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2203#issuecomment-1136479284,1,['update'],['updated']
Deployability,"I'm getting this too. This could be a problem with numpy's random: ; https://github.com/DLR-RM/stable-baselines3/issues/1579 ; https://github.com/SimonBlanke/Gradient-Free-Optimizers/issues/11. I'm seeing if I can specify explicitly the random state or seed. Found where the problem happens:. _leiden.py; Line 185 ; `part = g.community_leiden(**clustering_args)`. calls the following. community.py; Line 442; ```; membership, quality = GraphBase.community_leiden(; graph,; edge_weights=weights,; node_weights=node_weights,; resolution=resolution,; normalize_resolution=(objective_function == ""modularity""),; beta=beta,; initial_membership=initial_membership,; n_iterations=n_iterations,; ); ```. The debugger doesn't step into the `Graphbase.community_leiden` function any further, but this is where the loop with the error occurs. https://igraph.org/python/doc/api/igraph.Graph.html#community_leiden. **Update:**; Funnily enough, the Leiden clustering still executes correctly (took about 1 hour for me). How I did it was to create a simple .py file that loads the h5ad, just runs the leiden clustering, then writes a new h5ad, then ends. Ran that from a powershell window and just let it throw the warnings (which do not break the code execution). What I found is that I cannot run the leiden clustering in a notebook because the output gets overwhelmed and hangs VSCode.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3028#issuecomment-2078897575:904,Update,Update,904,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028#issuecomment-2078897575,1,['Update'],['Update']
Deployability,"I'm glad you all are considering adding this. I updated the implementation to work with sparse counts. . ```python; def seurat_v3_highly_variable_genes(; adata, n_top_genes: int = 4000, batch_key: str = ""batch""; ):; """""" An adapted implementation of the ""vst"" feature selection in Seurat v3. The major differences are that we use lowess insted of loess. For further details of the sparse arithmetic see https://www.overleaf.com/read/ckptrbgzzzpg. :param n_top_genes: How many variable genes to return; :param batch_key: key in adata.obs that contains batch info. If None, do not use batch info. """""". from scanpy.preprocessing._utils import _get_mean_var; from scanpy.preprocessing._distributed import materialize_as_ndarray. lowess = sm.nonparametric.lowess. if batch_key is None:; batch_correction = False; batch_key = ""batch""; adata.obs[batch_key] = pd.Categorical(np.zeros((adata.X.shape[0])).astype(int)); else:; batch_correction = True. norm_gene_vars = []; for b in np.unique(adata.obs[batch_key]):. mean, var = materialize_as_ndarray(; _get_mean_var(adata[adata.obs[batch_key] == b].X); ); not_const = var > 0; estimat_var = np.zeros((adata.X.shape[1])). y = np.log10(var[not_const]); x = np.log10(mean[not_const]); # output is sorted by x; v = lowess(y, x, frac=0.15); estimat_var[not_const][np.argsort(x)] = v[:, 1]. # get normalized variance; reg_std = np.sqrt(10 ** estimat_var); batch_counts = adata[adata.obs[batch_key] == b].X.copy(); # clip large values as in Seurat; N = np.sum(adata.obs[""batch""] == b); vmax = np.sqrt(N); clip_val = reg_std * vmax + mean; # could be something faster here; for g in range(batch_counts.shape[1]):; batch_counts[:, g][batch_counts[:, g] > vmax] = clip_val[g]. if sp_sparse.issparse(batch_counts):; squared_batch_counts_sum = np.array(batch_counts.power(2).sum(axis=0)); batch_counts_sum = np.array(batch_counts.sum(axis=0)); else:; squared_batch_counts_sum = np.square(batch_counts).sum(axis=0); batch_counts_sum = batch_counts.sum(axis=0). norm_gene_var",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/993#issuecomment-615304326:48,update,updated,48,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/993#issuecomment-615304326,1,['update'],['updated']
Deployability,"I'm going through it right now :P). R packages just tend to come with very thorough vignettes, documenting how the package is supposed to be used end-to-end, highlighting special use-cases, etc. I think [Seurat](http://satijalab.org/seurat/get_started.html), [Monocle](http://cole-trapnell-lab.github.io/monocle-release/), or really any Bioconductor package (eg. [Scater](https://bioconductor.org/packages/release/bioc/vignettes/scater/inst/doc/vignette-intro.html)) are great examples. Jupyter notebooks are fantastic for helping get an idea of how to use a package, but sometimes the documentation within them is lacking, making it hard to understand what's going on at each step without having to dive into source code. I find Scanpy's straight forward to follow though. I really appreciate the modular design of Scanpy. At least if you're familiar with single-cell analysis, you can recognize the steps quite easily and just string together the appropriate functions for your analysis pipeline. Some other packages are bit trickier. For example, I found Velocyto (which I love btw) incredibly hard to navigate. There are functions that are used in some analysis notebooks but not all of them, so it becomes unclear what the standard analysis pipeline with it should be. Obviously you can dive into the paper, understand the statistical guts of the method, go through all the source code and see what's there, but then it starts becoming a barrier to newer users adapting it. . Anyway, this is just a general thing I also noticed moving from R to Python. Not saying that it's something that necessarily needs changing, but it does create a little bit of friction to newer users, so it may be worth thinking about as a community. I suspect this will improve as the genomics user-base of Python increases, and as all these packages have more time to develop. Also, I understand that this is more of a ""community"" chat and may not belong in the scanpy/issues page anymore, so feel free to close it ;)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/74#issuecomment-363820657:1498,pipeline,pipeline,1498,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74#issuecomment-363820657,1,['pipeline'],['pipeline']
Deployability,I'm going to close this since no more information was provided. I'd be happy to re-open this if @ yuxiaokang-source updates.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1136#issuecomment-614491704:116,update,updates,116,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1136#issuecomment-614491704,1,['update'],['updates']
Deployability,"I'm going to use this PR to test some modifications to the azure pipelines. First off, can we lint in the same job as running tests.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1517:65,pipeline,pipelines,65,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1517,1,['pipeline'],['pipelines']
Deployability,I'm guessing this should also be added to the release notes @Koncopd?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1472#issuecomment-719667764:46,release,release,46,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1472#issuecomment-719667764,1,['release'],['release']
Deployability,I'm having trouble installing tables into a conda environment. Now may be the time to pull the trigger on this,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2064#issuecomment-987881759:19,install,installing,19,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2064#issuecomment-987881759,1,['install'],['installing']
Deployability,I'm having trouble reproducing this error. Could you share what versions you have installed (ideally also try updating these to the latest releases) and see if you can replicate the issue on one of the datasets in `sc.datasets`?. I think you should probably do differential expression plots using the same values you used to compute the differential expression in most cases.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2046#issuecomment-963259525:82,install,installed,82,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2046#issuecomment-963259525,2,"['install', 'release']","['installed', 'releases']"
Deployability,"I'm not able to reproduce this. Here's what I tried. * Made a conda environment with `conda create -yn torch-scanpy ""python=3.8""`, and activated it `conda activate torch-scanpy`; * Installed: `pip install scanpy torch`; * Imported: `python3 -c ""import torch; import scanpy""`. IIRC, there has been an issue with the order of importing numba and pytorch due to how they require their LLVM dependency. I would make sure your version of pytorch and numba are up to date (I believe your pytorch is a few versions old) and trying again. If the issue persists, could you check if you run into problems with this?. ```python; import torch; import numba; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1286#issuecomment-646456990:181,Install,Installed,181,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1286#issuecomment-646456990,2,"['Install', 'install']","['Installed', 'install']"
Deployability,I'm pretty sure none of you are having the same issue as the original one reported here. Compare @abuchin 's error message of `KeyError: 'dict'` to the original poster's error of `OSError: Can't read data`. The thing you're seeing is a new one stemming from an update to anndata. You're trying to read in a `h5ad` file created with a newer version of the package with your older one. I think the cutoff point is 0.8.0 but I could be mistaken. Upgrade your anndata and you should be ok.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1351#issuecomment-1198015945:261,update,update,261,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351#issuecomment-1198015945,2,"['Upgrade', 'update']","['Upgrade', 'update']"
Deployability,"I'm sorry, I wasn't aware I had used so much of my private webspace for Scanpy all these years back. I migrated from some legacy infra a week ago, without trackers to links to external resources. I'll fix this current instance by fixing the URLs and make a PR to have a copy of these images in the static folder in the docs, effective for the next release.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2132#issuecomment-1034760467:348,release,release,348,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2132#issuecomment-1034760467,1,['release'],['release']
Deployability,"I'm trying to install scanpy through `pip install scanpy` but I'm getting this weird error; ```; $ pip install scanpy; Collecting scanpy; Downloading scanpy-0.2.9.1.tar.gz (208kB); Complete output from command python setup.py egg_info:; Traceback (most recent call last):; File ""<string>"", line 1, in <module>; File ""/tmp/pip-build-lbk_t73k/scanpy/setup.py"", line 39, in <module>; readme = readme_f.read(); File ""/opt/conda/lib/python3.6/encodings/ascii.py"", line 26, in decode; return codecs.ascii_decode(input, self.errors)[0]; UnicodeDecodeError: 'ascii' codec can't decode byte 0xe2 in position 296: ordinal not in range(128); ```. That's with pip version `9.0.1` and python 3.6. I'm getting similar errors for older versions of scanpy, including 0.2.1. Perhaps this is a bug in pip but I'm not sure, I installed a bunch of other unrelated packages without any issues.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/43:14,install,install,14,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/43,4,['install'],"['install', 'installed']"
Deployability,"I'm wondering if we can come to some agreement on a slight modification to this proposal. > > How does this impact users vs. developers?; >; > user none, as the analysis package would ofc have the IO as dep. developer would be impacted by a leaner dep tree. This seems good. > > Who manages the sub-packages?; >; > the IO subpackage? everyone 😅. 😅 indeed. > For instance, for modality-specific formats we'd have to rely on specific external libraries which would then have to be lazily imported (as pointed out before). Would this create the premise of exponential growing of modality-specific lazy import libraries? probably yes. Is this best practice? I don't know. I feel like complicated dependency management was what we were trying to avoid here. Also it's nice when you install a package call a function and it works, less nice to have to start mucking around with dependencies. --------------. ## An alternative: project specific IO. `squidpy_io`, `muon_io`. Packages which read in package specific formats with a minimal set of dependencies. We can keep `muon.read_10x_atac`, so nothing changes for users. We skip out on complicated ownership and complicated dependencies. This should be very low overhead.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1387#issuecomment-1059537650:777,install,install,777,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1387#issuecomment-1059537650,1,['install'],['install']
Deployability,"I've been trying to export my data to SPRING using the external export feature. I do all my processing in Seurat and then export a loom file to be read in scanpy and export to SPRING. I've been however getting the below error. The notebook with the code and the loom file can be found here: https://github.com/tejas-j/seurat2spring. Is there a better way to achieve what I'm trying to do (data -> Seurat -> scanpy -> SPRING) . ```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-13-3b0044b18ade> in <module>; 1 import time; 2 t0 = time.time(); ----> 3 sce.exporting.spring_project(data, './pbmc3k', 'draw_graph', subplot_name='force1', overwrite=True); 4 print(time.time() - t0). ~/miniconda2/envs/py36/lib/python3.6/site-packages/scanpy/_exporting.py in spring_project(adata, project_dir, embedding_method, subplot_name, cell_groupings, custom_color_tracks, total_counts_key, overwrite); 157 # Write continuous colors; 158 continuous_extras['Uniform'] = np.zeros(E.shape[0]); --> 159 write_color_tracks(continuous_extras, subplot_dir / 'color_data_gene_sets.csv'); 160 ; 161 # Create and write a dictionary of color profiles to be used by the visualizer. ~/miniconda2/envs/py36/lib/python3.6/site-packages/scanpy/_exporting.py in write_color_tracks(ctracks, fname); 301 out = []; 302 for name,score in ctracks.items():; --> 303 line = name + ',' + ','.join(['%.3f' %x for x in score]); 304 out += [line]; 305 out = sorted(out,key=lambda x: x.split(',')[0]). ~/miniconda2/envs/py36/lib/python3.6/site-packages/scanpy/_exporting.py in <listcomp>(.0); 301 out = []; 302 for name,score in ctracks.items():; --> 303 line = name + ',' + ','.join(['%.3f' %x for x in score]); 304 out += [line]; 305 out = sorted(out,key=lambda x: x.split(',')[0]). TypeError: must be real number, not numpy.str_; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/889:995,continuous,continuous,995,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/889,1,['continuous'],['continuous']
Deployability,"I've decided to split the baby a bit here, and now we make sure `ipywidgets` before import `tqdm.auto`. If it's not present, we just use `tqdm`. Unfortunately, I think this can still result in bad progress bars in Jupyterlab unless appropriate extensions are installed.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1130#issuecomment-634565246:259,install,installed,259,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1130#issuecomment-634565246,1,['install'],['installed']
Deployability,"I've got two main reasons for thinking they should be more visible:. 1. If I'm trying to find what tools are available through scanpy for a certain task, it should be very obvious where that might be available. For example, if I want to know what's available for batch correction, I (the user) am probably not too fussed about whether it's in the scanpy codebase or not.; 2. As a method developer, it'd encourage me to integrate my method if I saw it'd be highly visible and that other people were doing it. Right now there are links, but users still have to go to see the notes with those links, go to a separate page, and scroll for a bit to see any particular method. . Another strategy could be a top level `External API` heading underneath the `API` heading? Then there could be an expandable table of contents (how I typically navigate the site) to get an idea of what's there.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/588#issuecomment-479739101:419,integrat,integrate,419,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/588#issuecomment-479739101,1,['integrat'],['integrate']
Deployability,I've had better luck integrating data from multiple experiments using [Harmony](https://portals.broadinstitute.org/harmony/) than the current integration methods in scanpy.external.pp. This PR adds a wrapper for Harmony to the external API.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1306:21,integrat,integrating,21,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1306,2,['integrat'],"['integrating', 'integration']"
Deployability,"I've just find out there's a little bug in the scoring function used to calculate cell cycle score. The random genes should be chosen from the same bins of gene_list, but now they are chosen from the whole dataset. The patch to make it work properly:. ```; --- a/scanpy/tools/score_gene_lists.py; +++ b/scanpy/tools/score_gene_lists.py; @@ -79,7 +79,7 @@ def score_gene_list(; control_genes = set(); ; # now pick 100 genes from every cut; - for cut in np.unique(obs_cut):; + for cut in np.unique(obs_cut.loc[gene_list]):; r_genes = np.array(obs_cut[obs_cut == cut].index); np.random.shuffle(r_genes); control_genes.update(set(r_genes[:ctrl_size])) # if ctrl_size > len(r_genes) is not a problem for numpy...; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/78:219,patch,patch,219,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/78,2,"['patch', 'update']","['patch', 'update']"
Deployability,"I've just merged initial pre-commit stuff via #1684 (just black). Once the doc builds propagate, there will be a section under: ""Getting set up"" in the dev docs on how to install. I would like to see a `flake8` PR, though it might take a bit of time to hash out configuration. Maybe @giovp or @Zethson would be interested in looking into this?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1563#issuecomment-784875825:171,install,install,171,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1563#issuecomment-784875825,2,"['configurat', 'install']","['configuration', 'install']"
Deployability,"I've just pushed 1.6.1 (pinning umap), but you can get the release candidate for 1.7.0 with `pip install ""scanpy==1.7.0rc1""`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1579#issuecomment-760127465:59,release,release,59,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1579#issuecomment-760127465,2,"['install', 'release']","['install', 'release']"
Deployability,"I've just spent a while trying to replicate, before realizing I've seen this issue before over on AnnData (https://github.com/theislab/anndata/issues/182). I've got some good and bad news about this. It's fixed on master, but that fix is slated to be release in `v0.7`, which has intentionally breaking changes. I find views very useful when dealing with large datasets interactively. They're also important for file backed data, since copies are extremely expensive in that case. Unlike numpy, AnnData objects should always return a view when subset. If you'd like to get copies, you could add a `.copy()` to the end of your subsetting statement.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/728#issuecomment-516689711:251,release,release,251,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/728#issuecomment-516689711,1,['release'],['release']
Deployability,I've made a small update to add a `tissue_image_path` parameter to `read_visium` that you can use to specify the tissue image path to put in `adata.uns`,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1506#issuecomment-735881272:18,update,update,18,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506#issuecomment-735881272,1,['update'],['update']
Deployability,"I've managed to fix this up a bit. Missing (or masked - for `groups`) values in categorical arrays are now always plotted on bottom and use a default color. For spatial plots this default color is transparent. This has led to some code simplification. Surprisingly, this didn't break any tests locally, so a bunch of new tests are probably needed. Continuous values are still a little weird. Right now the points don't show up on embedding plots, and mess up all the colors for spatial plots.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1356#issuecomment-674738421:348,Continuous,Continuous,348,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356#issuecomment-674738421,1,['Continuous'],['Continuous']
Deployability,"I've played around a bit with `version()` from `importlib_metadata`, and it tells me the version of scanpy and anndata, but never finds `umap` or `umap-learn`. I can however do; ```; In [3]: import umap ; In [4]: umap.__version__ ; Out[4]: '0.3.9'; ```. But, `version(""umap"")` or `version(""umap-learn"")` doesn't work. Any ideas? I've not installed anything manually, but everything via conda's pip. Does this have to do with package names and import names being different? It also doesn't work with `gprofiler-official`, which is imported as `import gprofiler`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/739#issuecomment-512166181:338,install,installed,338,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/739#issuecomment-512166181,1,['install'],['installed']
Deployability,"I've punted on this issue for getting the expression atlas downloader added. I think it'd be worth changing the default data directory at the same time as dealing with configuration more generally, so related breaking changes can happen together. I was writing up how I'd like configuration to work when I realized the implementation could be getting complicated enough it might be worth just using a library. [Everett](https://everett.readthedocs.io/en/latest/index.html) seems nice, but maybe a little immature. I like the ability to use context managers (making testing easier) and the auto documentation features. Generally, I think there should be a longer planning discussion about how configuration works. But that could be multiple issues. For example:. * Could we not change global state for plotting? We could shift over to using the `pyplot.rc_context` manager internally.; * What's the appropriate way to set logging level? It seems to keep changing and breaking things; * What's the appropriate precedence for config setting? I'd think `set in session > environment variable > config file > defaults`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/558#issuecomment-478214932:168,configurat,configuration,168,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-478214932,3,['configurat'],['configuration']
Deployability,"I've ran into this before (`sc.read_10x_mtx()` has the same default of course). One possible issue with defaulting to `gex_only=False` is that someone might accidentally run a 'regular pipeline' with multi-modal data, e.g. log-normalizing RNA+protein+cell hashing counts together without first subsetting the adata based on `.var[""feature_types""]`. By contrast, anyone who know they have multi-modal data would hopefully notice the missing the data with `gex_only=True`. Either way, logging warnings sounds good.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1949#issuecomment-879247652:185,pipeline,pipeline,185,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1949#issuecomment-879247652,1,['pipeline'],['pipeline']
Deployability,"I've talked to some other people who had trouble with this. If there's a better way to install it, I think we should mention it in the docs.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/786#issuecomment-522896826:87,install,install,87,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/786#issuecomment-522896826,1,['install'],['install']
Deployability,"I've update the code to ; - test that the file is actually a tiff image; - automatically add the path to the image to `adata.uns['spatial'][library_id]['metadata']['tissue_image_path']`. It's looking for a tiff or jpeg file with the name `""image""` or `library_id""_image""`. This should cover most cases hopefully?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1506#issuecomment-734405082:5,update,update,5,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506#issuecomment-734405082,1,['update'],['update']
Deployability,"I've updated the code to store the image path in `adata.uns['spatial'][sample_id]['tif_image_path']`. The test now also checks whether the image file exists. . I can also test whether the image file is a valid tiff image, but for this we'd need to add a tiff reading library like `pillow` as a test dependency to scanpy. If that is ok, I'll update the PR with an additional test.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1506#issuecomment-733605592:5,update,updated,5,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506#issuecomment-733605592,2,['update'],"['update', 'updated']"
Deployability,I've updated the docs a little and am going to go ahead and merge this. Thanks for the feedback @fidelram!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/730#issuecomment-511274129:5,update,updated,5,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/730#issuecomment-511274129,1,['update'],['updated']
Deployability,"I've written up a demo of how to run parallel NN and UMAP here: https://github.com/theislab/scanpy_usage/pull/17. The trick for NN is to a) install pyndescent and b) call the NN algortihm from within a joblib parallel context manager:. ```python; from joblib import parallel_backend; with parallel_backend('threading', n_jobs=16):; sc.pp.neighbors(adata); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/913#issuecomment-553392140:140,install,install,140,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/913#issuecomment-553392140,1,['install'],['install']
Deployability,"IPython/core/formatters.py in __call__(self, obj); ... FileNotFoundError: [Errno 2] No such file or directory: '/Users/name/.matplotlib/fontlist-v310.json.matplotlib-lock'. ```. #### Versions. <details>. ```; -----; anndata 0.7.6; scanpy 1.7.2; sinfo 0.3.4; -----; 0294638c8bf50491b025b096f3dba0a1 NA; absl NA; anyio NA; appnope 0.1.0; astunparse 1.6.3; attr 19.3.0; babel 2.9.0; backcall 0.2.0; brotli 1.0.9; certifi 2020.06.20; cffi 1.14.5; chardet 3.0.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; decorator 4.4.2; gast NA; get_version 2.2; google NA; h5py 2.10.0; idna 2.10; igraph 0.8.3; ipykernel 5.3.3; ipython_genutils 0.2.0; ipywidgets 7.5.1; jedi 0.17.2; jinja2 2.11.2; joblib 0.16.0; json5 NA; jsonschema 3.2.0; jupyter_server 1.2.2; jupyterlab_server 2.1.2; keras_preprocessing 1.1.2; kiwisolver 1.2.0; legacy_api_wrap 1.2; llvmlite 0.36.0; markupsafe 1.1.1; matplotlib 3.2.1; mpl_toolkits NA; natsort 7.1.1; nbclassic NA; nbformat 5.0.7; numba 0.53.1; numexpr 2.7.3; numpy 1.19.0; opt_einsum v3.3.0; packaging 20.4; pandas 1.2.4; parso 0.7.0; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prometheus_client NA; prompt_toolkit 3.0.5; psutil 5.8.0; ptyprocess 0.6.0; pycparser 2.20; pygments 2.6.1; pynndescent 0.5.2; pyparsing 2.4.7; pyrsistent NA; pytz 2019.3; requests 2.24.0; scipy 1.4.1; seaborn 0.10.0; send2trash NA; six 1.14.0; sklearn 0.23.1; sniffio 1.2.0; statsmodels 0.12.2; storemagic NA; swig_runtime_data4 NA; tables 3.6.1; tensorboard 2.2.2; tensorflow 2.2.0; termcolor 1.1.0; texttable 1.6.3; tornado 6.1; traitlets 4.3.3; typing_extensions NA; umap 0.5.1; urllib3 1.25.10; wcwidth 0.2.5; wrapt 1.12.1; yaml 5.3.1; zipp NA; zmq 19.0.1; -----; IPython 7.16.1; jupyter_client 6.1.6; jupyter_core 4.6.3; jupyterlab 3.0.5; notebook 6.0.3; -----; Python 3.7.7 (v3.7.7:d7c567b08f, Mar 10 2020, 02:56:16) [Clang 6.0 (clang-600.0.57)]; Darwin-20.2.0-x86_64-i386-64bit; 4 logical CPU cores, i386; -----; Session information updated at 2021-05-26 22:36. ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1857:2713,update,updated,2713,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1857,1,['update'],['updated']
Deployability,"If I understand correctly, pandas > 1.2.0 `plot.add_totals(sort='descending')` returns a different sorting compared to previous version. However, most of the categories have the same number of cells and thus a different sorting is equally valid. ![image](https://user-images.githubusercontent.com/4964309/104478840-0a9d5980-55c3-11eb-94b0-b0e2092c55c3.png). My suggestion is to use other dataset in which the number of cells per category is different and update the image.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1562#issuecomment-759557571:455,update,update,455,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1562#issuecomment-759557571,1,['update'],['update']
Deployability,"If anyone is stuck waiting for the new release, you can edit your `.../lib/python3.7/site-packages/scanpy/tools/_louvain.py` with these changes:. Add: `partition_kwargs[""seed""] = random_state` ; Remove: `louvain.set_rng_seed(random_state)`. From:; https://github.com/theislab/scanpy/pull/1197/commits/b54d67b9d6b41269c1612df0242210d1279ede85",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1191#issuecomment-630174509:39,release,release,39,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1191#issuecomment-630174509,1,['release'],['release']
Deployability,"If it's what I suspect it to be, it should be fixed with anndata 0.5.9. `pip install anndata==0.5.9`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/123#issuecomment-381746375:77,install,install,77,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/123#issuecomment-381746375,1,['install'],['install']
Deployability,"If someone figures out a simple workaround and submits a PR, we'll merge it, but we only support the newest bugfix releases ourselves. You should definitely tell your sysadmin to update to Python 3.5.4, there are security holes in your version as well.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/561#issuecomment-477128825:115,release,releases,115,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/561#issuecomment-477128825,2,"['release', 'update']","['releases', 'update']"
Deployability,"If the issue is continuous color maps, that can be specified with the `cmap` parameter.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/521#issuecomment-766287782:16,continuous,continuous,16,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/521#issuecomment-766287782,1,['continuous'],['continuous']
Deployability,"If the problem is windows, it's possible it will be solved by numpy 2.0. Not sure how easy the upgrade path to numpy 2.0 will be, however. * https://numpy.org/devdocs/numpy_2_0_migration_guide.html#windows-default-integer",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2969#issuecomment-2034657597:95,upgrade,upgrade,95,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969#issuecomment-2034657597,1,['upgrade'],['upgrade']
Deployability,"If this is the case, then why does the tutorial work with scanorama=1.7? I'll try again with an even earlier release scanorama when I have a moment though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2143#issuecomment-1051048349:109,release,release,109,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2143#issuecomment-1051048349,1,['release'],['release']
Deployability,If we have arpack i can also update the PR with randomized svd approach. Is it needed?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1066#issuecomment-590349532:29,update,update,29,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1066#issuecomment-590349532,1,['update'],['update']
Deployability,"If we need multiple tools in the same container the place to add it would be [BioContainers/multi-package-containers](https://github.com/BioContainers/multi-package-containers) as opposed to [BioContainers/mulled](https://github.com/BioContainers/mulled). This is what I meant by adding a mulled container above and that would go some way to solving the problem because we would be able to get a Docker/Singularity Biocontainer. However, in the long term, it's always nicer if these containers come directly via recipe updates from the Bioconda community. The other alternative is that the package is eventually updated and maintained on Bioconda organically like with most other tools there but that's kinda out of our control unless we add it ourselves. Always makes sense to reach out to the tool developers first! 😎 . > I'm pretty against moving back to bioconda. Curious to know why and if it's something that can be overcome? I did see https://github.com/scverse/scanpy/issues/1169",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2281#issuecomment-1160442532:519,update,updates,519,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281#issuecomment-1160442532,2,['update'],"['updated', 'updates']"
Deployability,"If we pinned `umap-learn>=0.5.1`.1 it would be impossible to install scvelo, since [it pins umap<0.5](https://github.com/theislab/scvelo/blob/1659cc8e00a45fcf87cd80a7013aae5531744613/requirements.txt#L9). We can ban umap 0.5.0 specifically. It's generally important that scanpy has a broad-ish range of versions it's comparable with, since there's a lot downstream. I'd be happy bump umap to above 0.4 though, since it has been a while for that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1756#issuecomment-846949206:61,install,install,61,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1756#issuecomment-846949206,1,['install'],['install']
Deployability,"If you try to color a scatter plot by gene expression in a layer, but the layer is sparse, an error is thrown. This occurs on both current release and master. Code to reproduce:. ```python; import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(); pbmc.layers[""sparse""] = pbmc.raw.X; sc.pl.pca(pbmc, color=[""HES4""], layer=""sparse"") ; ```. <details>; <summary> Traceback: </summary>. ```python; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-1-89244dc07987> in <module>; 3 pbmc = sc.datasets.pbmc68k_reduced(); 4 pbmc.layers[""sparse""] = pbmc.raw.X; ----> 5 sc.pl.pca(pbmc, color=[""HES4""], layer=""sparse""). ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs); 410 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it.; 411 """"""; --> 412 return plot_scatter(adata, 'pca', **kwargs); 413 ; 414 . ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs); 199 _data_points[:, 0], _data_points[:, 1],; 200 marker=""."", c=color_vector, rasterized=settings._vector_friendly,; --> 201 **kwargs,; 202 ); 203 . ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/matplotlib/__init__.py in inner(ax, data, *args, **kwargs); 1587 def inner(ax, *args, data=None, **kwargs):; 1588 if data is None:; -> 1589 return func(ax, *map(sanitize_sequence, args), **kwargs); 1590 ; 1591 bound = new_sig.bind(ax, *args, **kwargs). ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/matplotlib/axes/_axes.py in scatter(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidth",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/700:139,release,release,139,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/700,1,['release'],['release']
Deployability,"If you update to more recent releases, you won't be able to access elements of `obsm` or `varm` like an attribute. It should all be through `.__getitem__` (e.g. `adata.obsm[""X_tsne""]`).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/778#issuecomment-522895754:7,update,update,7,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/778#issuecomment-522895754,2,"['release', 'update']","['releases', 'update']"
Deployability,"If you want to extract it in python, you can load the h5ad file using `adata = sc.read(filename)` and then use `adata.X`, which is the expression matrix. To extract the matrix into R, you can use the `rhdf5` library. That's a bit more complicated as there was a recent update to this library I believe. Note that you need to transpose the expression matrix from python into R due to different conventions (R expects a genes x cells matrix, python a cells x genes matrix). An alternative to the `rhdf5` library is to just save the expression matrix via `numpy.savetxt()` to save it, for example, as a space-delimited file. I hope this helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/262#issuecomment-421082246:269,update,update,269,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/262#issuecomment-421082246,1,['update'],['update']
Deployability,Import error when old version of tqdm is installed,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1244:41,install,installed,41,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1244,1,['install'],['installed']
Deployability,ImportError: Please install skmisc package via `pip install --user scikit-misc,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2352:20,install,install,20,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2352,2,['install'],['install']
Deployability,"In any case, running: `$ pip install anndata -U --no-deps` solves the problem, as then the problematic part of utils.py is not run.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/482#issuecomment-463285227:29,install,install,29,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/482#issuecomment-463285227,1,['install'],['install']
Deployability,"In case anyone has this error again, here is what worked for me:. - go to https://www.lfd.uci.edu/~gohlke/pythonlibs/ and download a .whl file for h5py. For python 3.6 on a 64bit windows OS this is the file h5py‑2.10.0‑cp36‑cp36m‑win_amd64.whl; - with your conda environment activated, install that wheel file using `python -m pip install --user --force-reinstall h5py‑2.10.0‑cp36‑cp36m‑win_amd64.whl` (change the file name to the one you downloaded).; - scanpy should work now. This worked on mine and also on a colleagues windows laptop. I guess the problem is that you need a C++ compiler to build the necessary H5DF libraries. This works fine in UNIX based OS (Mac and Linux), but in windows you would need to download the most recent C++ compiler from some microsoft build tools website or alongside Visual Studio. So installing a prebuildt wheel for windows circumwents that problem. I wonder when h5py people will ever fix this for us poor Windows users.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/454#issuecomment-828487442:286,install,install,286,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454#issuecomment-828487442,3,['install'],"['install', 'installing']"
Deployability,"In case this helps, all gpu accelerated code implemented in scanpy use rapids related packages, which can be easily deployed by using their [docker images](https://hub.docker.com/r/rapidsai/rapidsai-core) and are updated on a regular basis! There is the choice of multiple os and python versions, although windows is not present.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1793#issuecomment-816682033:116,deploy,deployed,116,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1793#issuecomment-816682033,2,"['deploy', 'update']","['deployed', 'updated']"
Deployability,In case you're still looking to use MAST or integrate other `R` tools into a scanpy pipeline. That works quite well via [anndata2ri](www.github.com/flying-sheep/anndata2ri). An example of how you can do this can be found in the case study notebook [here](https://github.com/theislab/single-cell-tutorial/blob/master/latest_notebook/Case-study_Mouse-intestinal-epithelium_1904.ipynb).,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/625#issuecomment-487553407:44,integrat,integrate,44,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/625#issuecomment-487553407,2,"['integrat', 'pipeline']","['integrate', 'pipeline']"
Deployability,"In different time course, the batch effect and true biological variation will be entangled. . Batch effects, which occur because measurements are affected by laboratory conditions,reagent lots and personnel differences. This becomes a major problem when batch effects are correlated with an outcome of interest and lead to incorrect conclusions. However, in single cell RNAseq, different datasets should be integrated with suitable algorithm (such as mnn, CCA, bbknn, harmony, scvi et al.), even no batch effect exists.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/265#issuecomment-471808354:407,integrat,integrated,407,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/265#issuecomment-471808354,1,['integrat'],['integrated']
Deployability,"In my preprocessing pipeline, I filtered for the most variable genes and also regress out n_counts and cell cycle. However, it seems like every time I restart my Jupyter notebook and rerun the preprocessing pipeline, I get a different neighborhood graph and UMAP, and therefore different clustering. If I use the same preprocessed data, I can reproduce the same PCA (using svd_solver='arpack'), UMAP, and clusters. So I was wondering if there is randomness introduced during filtering process or regress_out methods? What should I do to ensure reproducibility?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/313:20,pipeline,pipeline,20,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/313,2,['pipeline'],['pipeline']
Deployability,In order to make the learning rate of accessible from scanpy it will be needed to update the dca; version once https://github.com/theislab/dca/pull/27 is merged. Indeed the default learning rate is very high and the training diverges a lot on the tabula muris dataset.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/793:82,update,update,82,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/793,1,['update'],['update']
Deployability,"In some edge cases, the control gene selection retrieves the same gene(s) that are also in the gene_list used for scoring.; As a result, when the following line is called, we end up with an empty control gene set, causing the downstream error in #2153; https://github.com/scverse/scanpy/blob/383a61b2db0c45ba622f231f01d0e7546d99566b/scanpy/tools/_score_genes.py#L173. <!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Closes #2153 ; - [x] Tests included; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2875:767,release,release,767,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2875,2,"['Release', 'release']","['Release', 'release']"
Deployability,"In the ""requirement already satisfied"" it looks like ""scikit-misc"" is installed in a different location and not within the `site-packages` folder of the anaconda env listed on the line below for `numpy`. From within the `py38` env you could try to reinstall it with `pip install --user scikit-misc --force` and also delete the other one or remove it from your `$PYTHONPATH`? Installing things in the jupyter notebook might be using a different version of pip than the one in the environment (depending on how your kernels are set up) so I think it's sometimes safer to do these things from the command line.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2073#issuecomment-989974912:70,install,installed,70,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2073#issuecomment-989974912,3,"['Install', 'install']","['Installing', 'install', 'installed']"
Deployability,"In the current release, we check for the counts being integer valued. kallisto can assign partial counts, (e.g a gene can have 1.5 counts) which triggers the check, triggering an error. For the next bugfix release we've softened consequences of this check failing to a warning, and the check can be skipped. See discussion in #1642 and #1679 for details.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1782#issuecomment-814591832:15,release,release,15,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1782#issuecomment-814591832,2,['release'],['release']
Deployability,"In the error it looks like numba requires numpy < 1.20, so you could try installing the `numpy‑1.19.5+mkl` whl from https://www.lfd.uci.edu/~gohlke/pythonlibs/#numpy before installing the scikit-misc one from https://www.lfd.uci.edu/~gohlke/pythonlibs/#scikit-misc? . When you get the `Requirement already satisfied` error from `pip install`, you might need to first do `pip uninstall <pkg>` before installing",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2073#issuecomment-1000950644:73,install,installing,73,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2073#issuecomment-1000950644,4,['install'],"['install', 'installing']"
Deployability,"In your heat map the lines are separating categorical groups right? In other words genes are rows. . In your command you are doing a selection over a larger dataset. Have you tried to make a copy of the adata object?. adata = Mouse10Xdata[NewIndex3,:].copy(). I ask in case the categories reported in the selection that you are doing create a mismatch, which may be solved by doing a copy. . > On 15 May 2019, at 11:24, brianpenghe <notifications@github.com> wrote:; > ; > There was a similar report not so long ago but I have not been able to reproduce the issue. Seems to be related with the matplotlib version used. Maybe you can try to update to the latest version.; > …; > On 10 May 2019, at 01:38, brianpenghe @.***> wrote: I ran this: ax=sc.pl.heatmap(Mouse10Xdata[NewIndex3,:], sorted_unique_marker_genes, groupby='ident', use_raw=False, vmin=-3, vmax=3, cmap='bwr',show=True,swap_axes=True,figsize=(10,7), var_group_rotation=0, dendrogram=True, save='ClusterMap.png') But the image has something weird. Here are the snapshot: The lines don't align well with the heatmap. Additionally, the lines don't align well with the group ID colors, either And the ID colors seem to be not aligned well with the heatmap either. Any thoughts? — You are receiving this because you are subscribed to this thread. Reply to this email directly, view it on GitHub, or mute the thread.; > ; > I have been using matplotlib 3.0.3 and I believe it's the latest version already. My Scanpy version was 1.4.1.; > Can it be an issue about duplicated gene names/make unique?; > ; > —; > You are receiving this because you commented.; > Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/637#issuecomment-492700214:640,update,update,640,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/637#issuecomment-492700214,1,['update'],['update']
Deployability,Incorrect dpt on dense toggle-switch,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/854:23,toggle,toggle-switch,23,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/854,1,['toggle'],['toggle-switch']
Deployability,Incorrect pip install statement in documentation for contributors,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1441:14,install,install,14,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1441,1,['install'],['install']
Deployability,"Indeed scanpy 1.9.6 required `seaborn!=0.13.0`, while newer releases have been update to require `seaborn>=0.13.0` (when you look here on GitHub, you will find this updated requirement as you mentioned). If you want to use scanpy 1.9.6 for a specific reason, your environment should use a seaborn version that is not 0.13.x, e.g. the latest 0.12 version. Does upgrading to the latest scanpy version resolve this issue for you?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2791#issuecomment-1952249236:60,release,releases,60,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2791#issuecomment-1952249236,3,"['release', 'update']","['releases', 'update', 'updated']"
Deployability,Indeed this is an issue related to an older version of AnnData. Once AnnData is updated the problem is gone.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1151#issuecomment-616673759:80,update,updated,80,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1151#issuecomment-616673759,1,['update'],['updated']
Deployability,Ingest won't integrate datasets of different lengths,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2085:13,integrat,integrate,13,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2085,1,['integrat'],['integrate']
Deployability,Install Issue: AttributeError: module 'igraph' has no attribute 'VertexClustering',MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/961:0,Install,Install,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/961,1,['Install'],['Install']
Deployability,"Install it, it’s an optional dependency.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1369#issuecomment-673987048:0,Install,Install,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1369#issuecomment-673987048,1,['Install'],['Install']
Deployability,Install old louvain package will solve the problem: pip install louvain==0.6.1,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1191#issuecomment-659515808:0,Install,Install,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1191#issuecomment-659515808,2,"['Install', 'install']","['Install', 'install']"
Deployability,Install packages necessary to run distributed tests.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/485:0,Install,Install,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/485,1,['Install'],['Install']
Deployability,Installation issue tbb,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2706:0,Install,Installation,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2706,1,['Install'],['Installation']
Deployability,Installing scanpy on M1 Apple Silicone,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1840:0,Install,Installing,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1840,1,['Install'],['Installing']
Deployability,Integrate data from different treatments and perform differential gene expression analysis according to treatment and cell type,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/859:0,Integrat,Integrate,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/859,1,['Integrat'],['Integrate']
Deployability,"Integrated [Shannon Component Analysis](https://www.biorxiv.org/content/10.1101/2021.01.19.427303v2.full) into the external API, with full documentation and references. SCA operates like PCA, storing a lower-dimensional representation of `adata.X` (or the chosen `layer`) in `adata.obsm[key_added]`. . Like PCA and ICA, SCA is linear; however, we have found SCA representations better than PCA or ICA at separating true cell types, yielding better clusters downstream. The source repository can be found [here](https://github.com/bendemeo/shannonca) and installed using `pip`. If you decide you'd like to integrate this into the main API (i.e. as `sc.tl.sca`), I would be happy to assist.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1780:0,Integrat,Integrated,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1780,3,"['Integrat', 'install', 'integrat']","['Integrated', 'installed', 'integrate']"
Deployability,Integration across SmartSeq2 and 10X Datasets,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2662:0,Integrat,Integration,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2662,1,['Integrat'],['Integration']
Deployability,Integration of Marsilea to create Heatmap from AnnData,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2512:0,Integrat,Integration,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2512,1,['Integrat'],['Integration']
Deployability,Integration of dorothea and progeny,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1724:0,Integrat,Integration,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1724,1,['Integrat'],['Integration']
Deployability,"Interestingly, I can't seem to reproduce this even with `pip` on-top of a conda install:. <details>; <summary> me trying </summary>. ```python; isaac@Mimir:~/tmp/genomic-features-docs; $ mamba create -n test-2978 ""anndata==0.9.0"" ipython scanpy; [ ... ]; isaac@Mimir:~/tmp/genomic-features-docs; $ conda activate test-2978 ; (test-2978) isaac@Mimir:~/tmp/genomic-features-docs; $ ipython; from scanpy._compat imPython 3.12.2 | packaged by conda-forge | (main, Feb 16 2024, 21:00:12) [Clang 16.0.6 ]; Type 'copyright', 'credits' or 'license' for more information; IPython 8.22.2 -- An enhanced Interactive Python. Type '?' for help.; [ ... ]. In [3]: from scanpy._compat import pkg_version. In [4]: pkg_version(""anndata""); Out[4]: <Version('0.9.0')>. In [5]: quit(); (test-2978) isaac@Mimir:~/tmp/genomic-features-docs; $ pip install -U anndata; Requirement already satisfied: anndata in /Users/isaac/miniforge3/envs/test-2978/lib/python3.12/site-packages (0.9.0); Collecting anndata; Downloading anndata-0.10.6-py3-none-any.whl.metadata (6.6 kB); [ ... ]; Downloading anndata-0.10.6-py3-none-any.whl (122 kB); ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 122.1/122.1 kB 2.1 MB/s eta 0:00:00; Downloading array_api_compat-1.6-py3-none-any.whl (36 kB); Installing collected packages: array-api-compat, anndata; Attempting uninstall: anndata; Found existing installation: anndata 0.9.0; Uninstalling anndata-0.9.0:; Successfully uninstalled anndata-0.9.0; Successfully installed anndata-0.10.6 array-api-compat-1.6; (test-2978) isaac@Mimir:~/tmp/genomic-features-docs; $ conda list | grep anndata; anndata 0.10.6 pypi_0 pypi; (test-2978) isaac@Mimir:~/tmp/genomic-features-docs; $ ipython; imPython 3.12.2 | packaged by conda-forge | (main, Feb 16 2024, 21:00:12) [Clang 16.0.6 ]; Type 'copyright', 'credits' or 'license' for more information; IPython 8.22.2 -- An enhanced Interactive Python. Type '?' for help. In [1]: from scanpy._compat import pkg_version. In [2]: pkg_version(""anndata""); Out[2]: <Versio",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2978#issuecomment-2039433757:80,install,install,80,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2978#issuecomment-2039433757,2,['install'],['install']
Deployability,"Is because we changed dot edge the defaults shortly before the release. Time to add a test for this. I will make a fix but meanwhile you can trigger the dynamic coloring by setting `dot_edge_color` and `dot_edge_lw` as `None`:. ```PYTHON; sc.pl.dotplot(adata, markers, groupby='bulk_labels', return_fig=True)\; .style(color_on='square', dot_edge_color=None, dot_edge_lw=None).show(); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1210#issuecomment-682371282:63,release,release,63,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1210#issuecomment-682371282,1,['release'],['release']
Deployability,"Is it possible to have one figure pf spatial gene expression stack over (superimpose) another? The following function will give me two subplots instead of an integrated one ; `sc.pl.spatial(ada, img_key=""hires"", color=[""Gene1"", ""Gene2""]); `",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2284:158,integrat,integrated,158,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2284,1,['integrat'],['integrated']
Deployability,Is there any update on the progress of this?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1301#issuecomment-943977687:13,update,update,13,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1301#issuecomment-943977687,1,['update'],['update']
Deployability,Is there anything like [clustree](https://github.com/lazappi/clustree) in python that integrates nicely with scanpy?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/670#issuecomment-776593368:86,integrat,integrates,86,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/670#issuecomment-776593368,1,['integrat'],['integrates']
Deployability,Is this issue still relevant? Did you install scikit-misc?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2352#issuecomment-1370858567:38,install,install,38,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2352#issuecomment-1370858567,1,['install'],['install']
Deployability,Is this using the development version? The fix hasn't been in a release yet.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1326#issuecomment-661826106:64,release,release,64,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1326#issuecomment-661826106,1,['release'],['release']
Deployability,Issues with conda installation,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1142:18,install,installation,18,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1142,1,['install'],['installation']
Deployability,It appears this was an issue related to anndata2ri- scipy 1.0.1 was being installed when installing anndata2ri. Installing scanpy first prevented this issue. ; I use pip install --user for scanpy because otherwise I receive an error message: ; Cannot uninstall 'llvmlite'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.; My workaround has been to use --user as a directory and add a path to import scanpy.; I'm sorry for the trouble thank you for the help.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1252#issuecomment-636118302:74,install,installed,74,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252#issuecomment-636118302,5,"['Install', 'install']","['Installing', 'install', 'installed', 'installing']"
Deployability,"It doesn't look like I can make the install process a matrix expansion, so this only tests against one version of python for now.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1005:36,install,install,36,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1005,1,['install'],['install']
Deployability,"It doesn’t. We could also. 1. wait to merge this until `skmisc` has a new release or; 2. throw a special error when people try to use seurat v3 with numpy 2. Sadly(?) Python doesn’t allow packages to add constraint to other packages’ dependencies, else we could tell the resolver that all currently release skmisc versions are incompatible with numpy 2",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3115#issuecomment-2182602501:74,release,release,74,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3115#issuecomment-2182602501,2,['release'],['release']
Deployability,"It is possible that you are installing it in a python pathway different than the one you are using to execute your code. I advise you to create a virtual environment (loot it up somewhere), and execute your single cell projects from it to make sure of the packages you have installed in each place.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1652#issuecomment-789711337:28,install,installing,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1652#issuecomment-789711337,2,['install'],"['installed', 'installing']"
Deployability,"It looks like the new release breaks most of our usage from (at least) a change in arguments to `simplicial_set_embedding` (ping @Koncopd). <details>; <summary> Example error </summary>. ```pytb; n_epochs = 0 if maxiter is None else maxiter; > X_umap = simplicial_set_embedding(; X,; neighbors['connectivities'].tocoo(),; n_components,; alpha,; a,; b,; gamma,; negative_sample_rate,; n_epochs,; init_coords,; random_state,; neigh_params.get('metric', 'euclidean'),; neigh_params.get('metric_kwds', {}),; verbose=settings.verbosity > 3,; E TypeError: simplicial_set_embedding() missing 3 required positional arguments: 'densmap', 'densmap_kwds', and 'output_dens'; ```. </details>. It looks like there is also a lot of cool stuff in the new release!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1509#issuecomment-743966308:22,release,release,22,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1509#issuecomment-743966308,2,['release'],['release']
Deployability,"It looks like the underlying issue (`np.zeros` was being called with a heterogeneous `shape` tuple) has been marked to be resolved in the next numba release. We could implement a workaround here where we force the dtype, though numba does have a pretty fast release cadence. @fkoegel, if we implemented a fix here would you be able to test it for us on master branches?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/843#issuecomment-532086499:149,release,release,149,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/843#issuecomment-532086499,2,['release'],['release']
Deployability,"It looks like you've got an outdated version of scanpy (1.5.0), this should be fixed in more recent releases by #1334.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1714#issuecomment-790279213:100,release,releases,100,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1714#issuecomment-790279213,1,['release'],['releases']
Deployability,"It looks to me like the sklearn dependency was update more due to bugs in earlier 0.21.* releases series, see 7716bfdec3cb9bd19923a91180dabc35ffd7709a. We don't promise compatibility with older versions of sklearn, so downgrading is not a good long-term solution. @Koncopd might also be able to give some advice on this, as I believe he has been using pytorch with scanpy, though I'm not sure if this is via conda environments.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1121#issuecomment-604799158:47,update,update,47,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1121#issuecomment-604799158,2,"['release', 'update']","['releases', 'update']"
Deployability,"It makes sense to use AND logic, because the function keeps genes that satisfy all three conditions. ; 1) Fraction of cells inside the cluster expressing the gene must be greater than `min_in_group_fraction`; 2) Fractions of cells outside the cluster expressing the gene must be less than `max_out_group_fraction`; 3) Fold change must be greater than `min_fold_change`. But there are remaining issues (calculation of fold change and using the absolute value of the fold change) in this function that needs to be updated #863",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1213#issuecomment-629970781:512,update,updated,512,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1213#issuecomment-629970781,1,['update'],['updated']
Deployability,"It seems this is of some relevance to users, as shown by it showing up twice independently over the course of the past week. For some reason, my tweaks have killed off ReadTheDocs, and I can't check why as upon pressing the ""details"" button I get the 404 equivalent :) I am now importing `types` so I can correctly define `metric` as also including `types.FunctionType`. This is probably what is causing whatever hiccup is happening. @giovp , some assistance with getting the ball rolling on this? The changes are a result of me expanding BBKNN with pynndescent on your recommendation.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1868#issuecomment-861393180:481,rolling,rolling,481,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1868#issuecomment-861393180,1,['rolling'],['rolling']
Deployability,"It seems to be a pytables problem. What happens if you install pytables in a fresh python 3.8 environment?; If `import tables` fails, you could also try uninstalling pytables and installing the package from conda-forge.; `conda install -c conda-forge pytables.`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2108#issuecomment-1012719981:55,install,install,55,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2108#issuecomment-1012719981,3,['install'],"['install', 'installing']"
Deployability,It should work if you install from github.; https://github.com/theislab/scanpy/commit/fe2580cb58e2ad6312ea989b0c9a40351510051a,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/631#issuecomment-489690557:22,install,install,22,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/631#issuecomment-489690557,1,['install'],['install']
Deployability,"It still does not work for me, even in a virtualenv. I always get:; ```. #Using legacy setup.py install for umap-learn, since package 'wheel' is not installed.; #ERROR: umap-learn 0.4.6 has requirement scipy>=1.3.1, but you'll have scipy 1.2.3 which is incompatible. cd /usr/common/lib/python3.6/Envs; rm -rf ~/.cache/pip #make download clearer; python3 -m venv scanpy_scripts; source scanpy_scripts/bin/activate; python -m pip install -U pip; python -m pip install scanpy_scripts; #same error; python -m pip install -U setuptools #39.2 -> 47.3.1; python -m pip install scanpy_scripts; #same error; python -m pip install -U wheel; python -m pip install scanpy_scripts; #same error; echo $PYTHONPATH; #is blank. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1273#issuecomment-653279039:96,install,install,96,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273#issuecomment-653279039,8,['install'],"['install', 'installed']"
Deployability,"It will be included in the next release, don't worry :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2460#issuecomment-1693979810:32,release,release,32,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2460#issuecomment-1693979810,1,['release'],['release']
Deployability,"It worked! I guess when I installed pyvdj, I got 3.1.1. Many thx!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1098#issuecomment-599168621:26,install,installed,26,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1098#issuecomment-599168621,1,['install'],['installed']
Deployability,"It works now by changing umap to 0.3.9. Thanks a lot!. Best regards,. Lirong. 获取 Outlook for iOS<https://aka.ms/o0ukef>; ________________________________; 发件人: Sergei R. <notifications@github.com>; 发送时间: Wednesday, April 22, 2020 12:44:36 PM; 收件人: theislab/scanpy <scanpy@noreply.github.com>; 抄送: plrlhb12 <lrpeng@hotmail.com>; Mention <mention@noreply.github.com>; 主题: Re: [theislab/scanpy] Issue with ingest (#1181). Hi, @plrlhb12<https://github.com/plrlhb12> .; Yes, this is a known problem. The easiest fix for now is to use umap 0.3.9 instead of 0.4.1.; You can also install scanpy from github where it is fixed or just wait for a new scanpy release. ―; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://github.com/theislab/scanpy/issues/1181#issuecomment-617895856>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AKHCBZKH4TYT5672QNGFW33RN4NHJANCNFSM4MNX44PA>.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1181#issuecomment-617940220:572,install,install,572,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1181#issuecomment-617940220,2,"['install', 'release']","['install', 'release']"
Deployability,It works when I update the scanpy version from 1.9.8 to 1.10.1,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3026#issuecomment-2143892864:16,update,update,16,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3026#issuecomment-2143892864,1,['update'],['update']
Deployability,"It would be nice if we had a better way of handling upstream releases. E.g. when pandas makes a release it would be good that we had tested against their release candidates, or if we had a good process for dealing with bugs if they do occur. One think we could do, is defensively pin dependencies to below their current release series. I don't like doing this since I think it's pretty restrictive when most of the time we don't have issues. Maybe we could do this for breaking releases, but that wouldn't have prevented issues like #1917. It would be nice to automate the process of testing against upstream release candidates. Basically, when something comes out, we build against it so we can report issues early and don't have to deal with it in live releases. I'm not sure how to do this with `pip search` not working anymore.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1919:61,release,releases,61,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1919,7,['release'],"['release', 'releases']"
Deployability,"It would probably good to see how important the `n_iterations` parameter is for our data. Hopefully after the first couple iterations it's only a few points of the million shuffling around per iteration. I'll try to take a closer when I can, but basically need to try something like:. ```python; def iterativley_cluster(; g: igraph.Graph,; *,; n_iterations: int = 10,; random_state: int = 0,; leiden_kwargs: dict = {}; ) -> list:; import random; random.seed(random_state). _leiden_kwargs = {""objective_function"": ""modularity"", ""weights"": ""weight""}; _leiden_kwargs.update(leiden_kwargs). partition = g.community_leiden(n_iterations=1, **_leiden_kwargs). steps = [partition]; for _ in range(n_iterations-1):; partition = g.community_leiden(n_iterations=1, initial_membership=partition.membership, **_leiden_kwargs); steps.append(partition). return steps; ```. My suspicion (and hope) would be that unstable clusters / points are the ones that drag on the optimization process. E.g. groups that aren't maintained when you change the random seed also aren't maintained through later iterations.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1053#issuecomment-1040854081:564,update,update,564,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1053#issuecomment-1040854081,1,['update'],['update']
Deployability,It'd be good to make sure everything works with umap 0.5 before it get's released.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1509:73,release,released,73,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1509,1,['release'],['released']
Deployability,"It's also possible to attach files as assets to github releases. That's what I do for scirpy, e.g. ; https://github.com/icbi-lab/scirpy/releases/tag/d0.1.0",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2124#issuecomment-1025946640:55,release,releases,55,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2124#issuecomment-1025946640,2,['release'],['releases']
Deployability,"It's definitely a problem that you are seeing all of these version restrictions at once. This may be related to having too many entries in your PYTHONPATH environment variable. `PYTHONPATH` should probably just be empty, since python already knows to look where pip installs packages.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1273#issuecomment-654682532:266,install,installs,266,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273#issuecomment-654682532,1,['install'],['installs']
Deployability,"It's possible this was fixed in pandas 1.4.1, released on Friday https://github.com/pandas-dev/pandas/issues/45640",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2129#issuecomment-1039247646:46,release,released,46,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2129#issuecomment-1039247646,1,['release'],['released']
Deployability,"It's the right function, but those docs are out of date (current version is `v1.10.1`). There's an up to date PDF on their bioconductor page, but I don't think I can link to the function from there. How about this: <details>; <summary>Updated docstring</summary>. ```python; def calculate_qc_metrics(adata, expr_type=""counts"", var_type=""genes"", qc_vars=(),; percent_top=(50, 100, 200, 500), inplace=False):; """"""; Calculate quality control metrics. Calculates a number of qc metrics for an AnnData object, see section ; Returns for specifics. Largely based on `calculateQCMetrics` from scater; [McCarthy17]_. Currently is most efficient on a sparse CSR or dense matrix. Parameters; ----------; adata : :class:`~anndata.AnnData`; Annotated data matrix.; expr_type : `str`, optional (default: `""counts""`); Name of kind of values in X.; var_type : `str`, optional (default: `""genes""`); The kind of thing the variables are.; qc_vars : `Container`, optional (default: `()`); Keys for boolean columns of `.var` which identify variables you could ; want to control for (e.g. ""ERCC"" or ""mito"").; percent_top : `Container[int]`, optional (default: `(50, 100, 200, 500)`); Which proportions of top genes to cover. If empty or `None` don't; calculate.; inplace : bool, optional (default: `False`); Whether to place calculated metrics in `.obs` and `.var`. Returns; -------; Union[NoneType, Tuple[pd.DataFrame, pd.DataFrame]]; Depending on `inplace` returns calculated metrics (`pd.DataFrame`) or; updates `adata`'s `obs` and `var`. Observation level metrics include:. * `total_{var_type}_by_{expr_type}`; E.g. ""total_genes_by_counts"". Number of genes with positive counts ; in a cell.; * `total_{expr_type}`; E.g. ""total_counts"". Total number of counts for a cell.; * `pct_{expr_type}_in_top_{n}_{var_type}` - for `n` in `percent_top`; E.g. ""pct_counts_in_top_50_genes"". Cumulative percentage of counts ; for 50 most expressed genes in a cell.; * `total_{expr_type}_{qc_var}` - for `qc_var` in `qc_vars`; E.g. ""to",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/424#issuecomment-454024688:235,Update,Updated,235,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/424#issuecomment-454024688,1,['Update'],['Updated']
Deployability,"Its an issue with numba. See here https://github.com/jmschrei/apricot/blob/98693788ca315ceceeb2eb0f4ce8526f40e0049b/README.md. *Update* Quoting from the REAME above. > If you get an error that looks like; > ; > Inconsistency detected by ld.so: dl-version.c: 224: _dl_check_map_versions: Assertion `needed != NULL' failed!; > ; > or a segmentation fault when importing apricot for the first time then you should try reinstalling numba through conda using; > ; > conda install numba.; > ; > or; > ; > pip install numba==0.39.0; > ; > The issue appears to be with the most recent verson of numba, v0.40.0. Downgrading to numba v0.39.0 should solve the issue. ; > . That means numba should be frozen to v0.39.0 .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/280#issuecomment-427364460:128,Update,Update,128,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/280#issuecomment-427364460,3,"['Update', 'install']","['Update', 'install']"
Deployability,It’s actually still unreleased. We should release 1.9.3 soon!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2499#issuecomment-1607223772:42,release,release,42,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2499#issuecomment-1607223772,1,['release'],['release']
Deployability,"I’ll take a look if you update your issue with a code block that I can copy, that will download the dataset and then reproduce the error without me having to go to any website and download anything manually.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2819#issuecomment-1906406640:24,update,update,24,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2819#issuecomment-1906406640,1,['update'],['update']
Deployability,"I’m not a fan of duplicating things. We already install optional requirements via the list of extras here:. https://github.com/theislab/scanpy/blob/f428848ece1d7a4794090eb70a34a3b8f1953dee/.travis.yml#L8. so we should simply add them to the `test` extra:. https://github.com/theislab/scanpy/blob/f428848ece1d7a4794090eb70a34a3b8f1953dee/setup.py#L35. or add more extras (e.g. `dask=['dask[array]'],`) and add them to the list of extras to be installed in .travis.yml",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/439#issuecomment-457915041:48,install,install,48,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/439#issuecomment-457915041,2,['install'],"['install', 'installed']"
Deployability,"I’m quite sure it has a resolution parameter, but at this point I’m also quite sure I’m messing up with modules and dependencies, both in this thread and on my local installation... about conda, I guess I’m one of the last around who hasn’t adopted it yet",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/97#issuecomment-440443151:166,install,installation,166,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/97#issuecomment-440443151,1,['install'],['installation']
Deployability,"I’m really happy that they’re finally adding a resolver. Without officially having a resolver, it technically wasn’t a bug that incompatible stuff got installed, but instead just a missing (if very vital) feature.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1320#issuecomment-661004708:151,install,installed,151,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1320#issuecomment-661004708,1,['install'],['installed']
Deployability,"I’ve only found this problem in the wild when people tried to create a figure with a dimension of size 0. It implies that either matplotlib passes some faulty instructions to libpng or that your libpng installation is broken. It’s very unlikely that it’s a problem with scanpy. Does something simple with matplotlib work? Just `pyplot.scatter([0,1], [0,1])` or so?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/852#issuecomment-534002026:202,install,installation,202,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/852#issuecomment-534002026,1,['install'],['installation']
Deployability,"Jumping in on this conversation to ask a related question - I'm using Scanorama to integrate some datasets and generate an aligned low-dimensional embedding. I then subset the data to only look at specific clusters and want to re-make the UMAP/t-SNE plot. Do you usually re-do the integration to generate a new low-dimensional embedding matrix with Scanorama for the subsetted data? I know you can technically subset the original low-dimensional embedding matrix, but I thought it's preferable to re-do the embedding when you have a different subset of cells to capture more of the variance between those cells (re-select HVGs, etc). Any advice would be welcome - thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2162#issuecomment-1059551919:83,integrat,integrate,83,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2162#issuecomment-1059551919,2,['integrat'],"['integrate', 'integration']"
Deployability,"Just a heads up, there is a remaining issue on anndata master where reading older files with h5py 2.10.0 results in bytestring indexes. > On Sep 12, 2019, at 05:28, Bruce Martin <notifications@github.com> wrote:; > ; > @gokceneraslan - thanks for the fast response. This broke our (cellxgene) travis pipeline as well. Do you have any info on eta for a fix/workaround other than pinning the module version? TY!; > ; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/832#issuecomment-530659556:300,pipeline,pipeline,300,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/832#issuecomment-530659556,1,['pipeline'],['pipeline']
Deployability,"Just an extra idea... In case you have docker installed, you could use a dockerized scanpy. The guys running SCENIC have a dockerized version of it in their workflow. Maybe you could ask them nicely for their docker image?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/561#issuecomment-477595971:46,install,installed,46,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/561#issuecomment-477595971,1,['install'],['installed']
Deployability,"Just an update, I've got the PR mostly done, but I'm having trouble keeping the arguments to `sc.queries.gene_coordinates` simple. Could someone who uses that function show me their use case? Is it that common to want the coordinates for only one gene, but also want to limit the coordinates to particular coordinates? . Would it be reasonable to replace this function with something more simple and open ended? I'm thinking just letting the user specify an organism and the fields they'd like. <details>; <summary>Here's a doc-string for what I'm thinking:</summary>. ```python; def biomart_annotations(org, attrs, host=""www.ensembl.org""):; """"""; Retrieve gene annotations from ensembl biomart. Parameters; ----------; org : `str`; Organism to query. Must be an organism in ensembl biomart. ""hsapiens"",; ""mmusculus"", ""drerio"", etc.; attrs : `List[str]`; Attributes to query biomart for.; host : `str`, optional (default: ""www.ensembl.org""); A valid BioMart host URL. Alternative values include archive urls (like; ""grch37.ensembl.org"") or regional mirrors (like ""useast.ensembl.org""). Returns; -------; A `pd.DataFrame` containing annotations. Examples; --------; Retrieve genes coordinates and chromosomes. >>> annot = sc.query.biomart_annotations(; ""hsapiens"",; [""ensembl_gene_id"", ""start_position"", ""end_position"", ""chromosome_name""],; ).set_index(""ensembl_gene_id""); >>> adata.var[annot.columns] = annot; ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/242#issuecomment-460865434:8,update,update,8,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/242#issuecomment-460865434,1,['update'],['update']
Deployability,"Just as an updated thought on this, I don't think using the connectivity graph is the most straightforward way to approach this. We don't really care about closeness of points on the manifold, we care about closeness of the points on the plot. I think you'd want to constrain color assignment by points on the plot. This has the side benefit of being more widely applicable, since it doesn't require the plot to be connected to some graph representation.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1366#issuecomment-761937197:11,update,updated,11,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1366#issuecomment-761937197,1,['update'],['updated']
Deployability,"Just came across this - is this still relevant @FionaMoon, or has this been resolved with the updated scanpy versions? :); Glad to hear it worked out in your case @molecularsensei!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2138#issuecomment-1798995383:94,update,updated,94,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2138#issuecomment-1798995383,1,['update'],['updated']
Deployability,"Just came across this - is this still relevant?; Scanpy as is does not feature a neat solution integrating with interactive interfaces which would allow to manually tag/select individual points from a plot - for such tasks, [holoviz](https://holoviz.org/) tools might be considered.; As sidenote, a heads-up about considering 2D representations with caution e.g. [here](https://www.sciencedirect.com/science/article/pii/S2405471223002090?via%3Dihub) - considering metrics instead of visual low-dimensional representations to detect or remove outliers might be considered as a viable alternative here in many cases :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1992#issuecomment-1798949475:95,integrat,integrating,95,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1992#issuecomment-1798949475,1,['integrat'],['integrating']
Deployability,"Just checked using this dockerfile, works flawlessly:. ```dockerfile; FROM continuumio/miniconda. RUN conda install python=3.8; RUN pip install flit>=3.1; RUN git clone https://github.com/theislab/scanpy.git; WORKDIR /scanpy; # Go to the mainline-pip branch if it hasn’t been merged into master yet; RUN git checkout mainline-pip || true; RUN FLIT_ROOT_INSTALL=1 flit install -s --dep=develop # Make development install of scanpy; # Make sure the dist-info folder has a plus in its name; RUN SCANPY_VERSION=$(python -c 'from importlib.metadata import version; print(version(""scanpy""))') && \; echo $SCANPY_VERSION | grep '+' &&; test -d /opt/conda/lib/python3.8/site-packages/scanpy-$SCANPY_VERSION.dist-info; # Install project that depends on scanpy; RUN pip install scvelo; # Make sure it’s still a dev install; RUN test -L /opt/conda/lib/python3.8/site-packages/scanpy; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1702#issuecomment-788200617:108,install,install,108,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1702#issuecomment-788200617,7,"['Install', 'install']","['Install', 'install']"
Deployability,Just checked.. same thing applies for windows. It returns an error until you `conda install pytables`.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/454#issuecomment-462140641:84,install,install,84,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454#issuecomment-462140641,1,['install'],['install']
Deployability,"Just checking back on this, it's concerning if you are getting null values unexpectedly, but it's difficult for me to figure out why that could be happening without more information. It would be great if you're able to give us any update on this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1701#issuecomment-788489841:231,update,update,231,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1701#issuecomment-788489841,1,['update'],['update']
Deployability,"Just figured it out. It is because I have both `umap` and `umap-learn` installed, but even if I do `pip uninstall umap`, it doesn't totally remove `umap` for whatever reason. I had to uninstall both `umap` and `umap-learn` first, and then re-install `umap-learn` to get it to work.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2045#issuecomment-963533994:71,install,installed,71,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2045#issuecomment-963533994,2,['install'],"['install', 'installed']"
Deployability,"Just my 2cents: ; I made really good experiences with Github actions.; * I find them easy to set-up and they run many (20-40?) jobs in parallel. ; * Really good integration with Github (e.g. upload to PyPI on release) ; * windows testing works well, but it is a pain to setup pycairo, see [here](https://github.com/icbi-lab/scirpy/blob/725664a22e6265643633d89a7f38ea3383ccab48/.github/workflows/test.yml#L34) and [here](https://github.com/pygobject/pycairo/issues/19#issuecomment-638716293). . Here's the [github actions script for scirpy](https://github.com/icbi-lab/scirpy/blob/master/.github/workflows/test.yml).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1358#issuecomment-674834154:161,integrat,integration,161,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1358#issuecomment-674834154,2,"['integrat', 'release']","['integration', 'release']"
Deployability,"Just pushing the updates now @LuckyMD 😄. One issue with the enrichment as is, is that `gprofiler-official` import name conflicts with the previous unofficial wrapper. I'm worried that this will break peoples environments if they're not aware of this. @liiskolb, do you have any thoughts on this?. Otherwise, I think this should be alright. I'd like to know if there'd be any interest in moving the utility function `rank_genes_groups_df` (added here) into a more central place. I personally use it anytime I use scanpys differential expression.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/467#issuecomment-483199474:17,update,updates,17,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/467#issuecomment-483199474,1,['update'],['updates']
Deployability,"Just to add to @ivirshup's points. There are several examples of lower PCs containing batch effects rather than higher PCs. I've seen this many times, but this has also been report for e.g., ATAC data in the [SCALE paper](https://www.nature.com/articles/s41467-019-12630-7). > Is it correct to say that the each embedded PC is given equal weight in the neighbourhood graph?. I'm not entirely sure, but I don't think you can say this... higher PCs that explain less variance will contribute less to the total variance if you use them as an input to e.g., UMAP, t-SNE, or a kNN graph building algorithm. This is because the variance of the loadings is proportional to the total variance explained (unless a rescaling is used in scanpy by default?). Thus, the contribution of higher PCs to the distance calculations will be less discriminative between points. Putting these two aspects together, you can see exactly why you need batch integration methods. These effects affect leading PCs, and therefore contribute a lot to any distance calculation based on an embedding. You can't just remove the effects by filtering for only leading PCs.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/872#issuecomment-822621611:932,integrat,integration,932,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/872#issuecomment-822621611,1,['integrat'],['integration']
Deployability,"Just to clarify, are you referring to 3 plots in the middle (PCA loading plots)? In new scanpy release, we render both positive and negative genes.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/991#issuecomment-573925992:95,release,release,95,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/991#issuecomment-573925992,1,['release'],['release']
Deployability,"Just to follow-up because I also had a similar question to the OP. Here's one way to plot several marker genes in different colors on the same UMAP plot. The trick is to make different colormaps that have an alpha gradient so that cells with NA expression appear transparent. Then just use matplot axes to merge the images. The only issue is that Scanpy doesn't yet allow you to remove colorbars for continuous variables, so the multiple colorbars can throw off the scaling, which you can work around by changing the figure parameters. ```; #make red colormap; colors2 = plt.cm.Reds(np.linspace(0, 1, 128)); colorsComb = np.vstack([colors2]); mymap = colors.LinearSegmentedColormap.from_list('my_colormap', colorsComb); my_cmap = mymap(np.arange(mymap.N)); my_cmap[:,-1] = np.linspace(0, 1, mymap.N); my_cmap = colors.ListedColormap(my_cmap). sc.pl.umap(adata, color=['AIF1'], use_raw=True, color_map=my_cmap, show=False, frameon=False); ```; ![image](https://user-images.githubusercontent.com/56206488/126086651-df0d46c9-5f1d-4b64-8109-f82cd1feb9cb.png). ```; #make blue colormap; colors2 = plt.cm.Blues(np.linspace(0, 1, 128)); colorsComb = np.vstack([colors2]); mymap = colors.LinearSegmentedColormap.from_list('my_colormap', colorsComb); my_cmap2 = mymap(np.arange(mymap.N)); my_cmap2[:,-1] = np.linspace(0, 1, mymap.N); my_cmap2 = colors.ListedColormap(my_cmap2). sc.pl.umap(adata, color=['CD3E'], use_raw=True, color_map=my_cmap2, show=False, frameon=False, vmax=3); ```; ![image](https://user-images.githubusercontent.com/56206488/126086666-a0828d86-d943-47b8-8207-eb42aeb32e4b.png). ```; #make green colormap; colors2 = plt.cm.Greens(np.linspace(0, 1, 128)); colorsComb = np.vstack([colors2]); mymap = colors.LinearSegmentedColormap.from_list('my_colormap', colorsComb); my_cmap3 = mymap(np.arange(mymap.N)); my_cmap3[:,-1] = np.linspace(0, 1, mymap.N); my_cmap3 = colors.ListedColormap(my_cmap3). sc.pl.umap(adata, color=['CD79A'], use_raw=True, color_map=my_cmap3, show=False, frameon=False)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/532#issuecomment-882140601:400,continuous,continuous,400,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/532#issuecomment-882140601,1,['continuous'],['continuous']
Deployability,Just updated the readme https://github.com/theislab/scanpy_usage/blob/master/170522_visualizing_one_million_cells/.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/511#issuecomment-470050921:5,update,updated,5,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/511#issuecomment-470050921,1,['update'],['updated']
Deployability,"Just updated to scanpy 1.8.2, but the problem persists.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1579#issuecomment-1062411153:5,update,updated,5,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1579#issuecomment-1062411153,1,['update'],['updated']
Deployability,"Just want to leave a comment here that the relevant matplotlib parameter to change is ""patch.edgecolor"". The following should fix the missing grouping lines. ```python; matplotlib.rcParams['patch.edgecolor'] = 'black'; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/998#issuecomment-913395778:87,patch,patch,87,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/998#issuecomment-913395778,2,['patch'],['patch']
Deployability,"Kinda related, I was about to open an issue on the memory usage of this function. The current implementation can double the memory usage of a program, I believe due to intermediate arrays in the current code. I'd come up with a slower but fewer allocation method for dense arrays (which could probably be sped up with a little `numba`):. ```python; def lessalloc_dense(X):; mean = X.mean(axis=0); mean_sq = np.apply_along_axis(lambda x: np.square(x).mean(), 0, X); var = (mean_sq - mean**2) * ((X.shape[0]/(X.shape[0]-1))); return mean, var; ```. And looked at memory usage using [`memory_profiler`](https://github.com/pythonprofilers/memory_profiler/releases), including @fidelram 's method:. ![mean_var_memory](https://user-images.githubusercontent.com/8238804/40597918-eacd8764-6287-11e8-98ff-017e697b350d.png). [Full script for benchmark here.](https://gist.github.com/ivirshup/a6facfa1ace5b356ea2d18ff3ffe0cb9)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/163#issuecomment-392421567:651,release,releases,651,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/163#issuecomment-392421567,1,['release'],['releases']
Deployability,Kinda? This is waiting on https://github.com/theislab/anndata/pull/144 and a following AnnData point release. But I think that PR is ready to go.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/619#issuecomment-493013715:101,release,release,101,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/619#issuecomment-493013715,1,['release'],['release']
Deployability,"LGTM! . Don't worry about the test failures, those are due to a networkx update changing how plots look, which we'll deal with.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1950#issuecomment-887218018:73,update,update,73,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1950#issuecomment-887218018,1,['update'],['update']
Deployability,"Legacy pass in use""). ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs); 30 def _acquire_compile_lock(*args, **kwargs):; 31 with self:; ---> 32 return func(*args, **kwargs); 33 return _acquire_compile_lock; 34 . ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in _runPass(self, index, pss, internal_state); 300 mutated |= check(pss.run_initialization, internal_state); 301 with SimpleTimer() as pass_time:; --> 302 mutated |= check(pss.run_pass, internal_state); 303 with SimpleTimer() as finalize_time:; 304 mutated |= check(pss.run_finalizer, internal_state). ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in check(func, compiler_state); 273 ; 274 def check(func, compiler_state):; --> 275 mangled = func(compiler_state); 276 if mangled not in (True, False):; 277 msg = (""CompilerPass implementations should return True/False. "". ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state); 405 ; 406 # TODO: Pull this out into the pipeline; --> 407 NativeLowering().run_pass(state); 408 lowered = state['cr']; 409 signature = typing.signature(state.return_type, *state.args). ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state); 347 lower = lowering.Lower(targetctx, library, fndesc, interp,; 348 metadata=metadata); --> 349 lower.lower(); 350 if not flags.no_cpython_wrapper:; 351 lower.create_cpython_wrapper(flags.release_gil). ~\anaconda3\lib\site-packages\numba\lowering.py in lower(self); 193 if self.generator_info is None:; 194 self.genlower = None; --> 195 self.lower_normal_function(self.fndesc); 196 else:; 197 self.genlower = self.GeneratorLower(self). ~\anaconda3\lib\site-packages\numba\lowering.py in lower_normal_function(self, fndesc); 246 # Init argument values; 247 self.extract_function_arguments(); --> 248 entry_block_tail = self.lower_function_body(); 249 ; 250 # Close tail of entry block. ~\anaconda3\lib\site-packages\numba\lowering.py in lower_function_body(self",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1147:10862,pipeline,pipeline,10862,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147,1,['pipeline'],['pipeline']
Deployability,"Leland replied that the parallelization isn't fully implement even in umap 0.4 but that a temporary work around is as below (which is what I'm doing in my local installation):. If you just want to make use of 16 cores then the other option is in umap/umap_.py where it calls pynndescent add an extra option n_jobs=-1, which will turn on the (slightly memory intensive) threaded implementation of nndescent that exists in pynndescent v0.3.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/913#issuecomment-553195318:161,install,installation,161,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/913#issuecomment-553195318,1,['install'],['installation']
Deployability,"Let’s coordinate here and come up with what we think is the best strategy:. - @grst and me thought both are fine solutions, that’s why we closed https://github.com/scverse/scanpy-tutorials/issues/64, let’s update that one with what we come up with; - I think the main discussion should happen in https://github.com/scverse/cookiecutter-scverse/issues/40, then we close this issue when we implemented that for scanpy",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2636#issuecomment-1691508076:206,update,update,206,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2636#issuecomment-1691508076,1,['update'],['update']
Deployability,"Like you say, the difference between this and `ingest` is joint PCA calculation vs asymmetric batch integration. This function is the first step in the `fastMNN` function, which I have found in some cases yields very sensible batch correction results. It would be awesome to see `multiBatchPCA` +/- `fastMNN` available in scanpy. I am aware of the python implementation of `mnncorrect`, but I think this still operates on expression values rather than a PCA representation (correct me if I am wrong..). Without going all the way the batch correction, `multiBatchPCA` is useful where different experiments have very different numbers of cells.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1289#issuecomment-671228353:100,integrat,integration,100,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289#issuecomment-671228353,1,['integrat'],['integration']
Deployability,"Likewise, I just ran `pip install leidenalg` on an OSX machine which already had scanpy and louvain on it, and it set up effortlessly.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/350#issuecomment-437075453:26,install,install,26,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/350#issuecomment-437075453,1,['install'],['install']
Deployability,"Log PCA time at info level, like other steps in the pipeline (recipes…",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/623:52,pipeline,pipeline,52,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/623,1,['pipeline'],['pipeline']
Deployability,"Look at the virtualenv example - PYTHONPATH was empty. The johnnydep application does not actually do an install, it just downloads all the pieces a package calls for and looks at all the listed requirements - and it gives the same version restriction conflict as an actual installation attemp.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1273#issuecomment-659028734:105,install,install,105,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273#issuecomment-659028734,2,['install'],"['install', 'installation']"
Deployability,"Looking at the commits page I can see that the tests has been failing for some days already. . First was a problem with a notebook test (test_pbmc3k) that seems innocuous but should be addressed. This is related to release 1.4.3 (https://github.com/theislab/scanpy/commit/85acb6c8949d43d08a26437dceab4fa5db79e246). The commits are unrelated to the failing test so I assume that some dependency was updated . However, after this commit https://github.com/theislab/scanpy/commit/115d635bf950354509053d976b90c1db518bcffe more errors are found. But again, I don't see any relevant changes that will cause the problems. One of the errors is that statsmodels is using a deprecated module from scipy.misc:. ```; > from scipy.misc import factorial; E ImportError: cannot import name 'factorial'; ../../../virtualenv/python3.6.7/lib/python3.6/site-packages/statsmodels/distributions/edgeworth.py:7: ImportError; ```. This was introduced after scipy 1.3 was recently updated (https://github.com/statsmodels/statsmodels/issues/5759). It seems that currently, the only solution is to install statsmodels directly from the master branch. Or downgrade scipy.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/661#issuecomment-495552166:215,release,release,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/661#issuecomment-495552166,4,"['install', 'release', 'update']","['install', 'release', 'updated']"
Deployability,Looking forward to this update or is there any other way to achieve this?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1552#issuecomment-1435832592:24,update,update,24,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1552#issuecomment-1435832592,1,['update'],['update']
Deployability,"Looks like the same error hit in #585, as well as https://github.com/theislab/scanpy/pull/493#issuecomment-477674448. @flying-sheep I haven't been able to reproduce, but maybe we should just throw an `__init__.py` in there, since it fixes this for @fbrundu, before the `v1.4.1` release?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/601#issuecomment-482069731:278,release,release,278,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/601#issuecomment-482069731,1,['release'],['release']
Deployability,Looks like there is a release out for the `scikit-misc`: https://github.com/has2k1/scikit-misc/compare/v0.4.0...main. Hopefully this fixes it,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3115#issuecomment-2202419517:22,release,release,22,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3115#issuecomment-2202419517,1,['release'],['release']
Deployability,Looks like this fix was made in a 2021 release - thanks! Will close the issue,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1325#issuecomment-1662404711:39,release,release,39,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1325#issuecomment-1662404711,1,['release'],['release']
Deployability,"Looks like this is not available for python yet ([docs](https://docs.microsoft.com/en-us/azure/devops/pipelines/test/codecoverage-for-pullrequests?view=azure-devops#prerequisites)). > While you can collect and publish code coverage results for many different languages using Azure Pipelines, the code coverage for pull requests feature discussed in this document is currently available only for .NET and .NET core projects using the Visual Studio code coverage results format (file extension .coverage). Support for other languages and coverage formats will be added in future milestones.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1576#issuecomment-758366276:102,pipeline,pipelines,102,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1576#issuecomment-758366276,2,"['Pipeline', 'pipeline']","['Pipelines', 'pipelines']"
Deployability,Looks like this was solved on master last month. Any chance we could get a bugfix release?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1579#issuecomment-758850929:82,release,release,82,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1579#issuecomment-758850929,1,['release'],['release']
Deployability,"Looks very good to me, thank you very much!. Would you mind adding an option to select for the correction type that defaults to 'benjamini-hochberg' and can be set to 'bonferroni'?. In the best of all world's, you'd also extend the tests for rank_genes_groups so that the p values are tested and not messed up by pull requests in the future. We want people to get the same p values again and again. And as the whole module sort of involves a lot of custom code as the scipy alternatives are not there for mult-dimensional and sparse data, it's easy to mess this up in the future. Thank you so much for the awesome addition @a-munoz-rojas , I'll add you both to the Scanpy author list and to the release notes.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/289#issuecomment-429445105:695,release,release,695,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/289#issuecomment-429445105,1,['release'],['release']
Deployability,Louvain installation is being difficult,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2065:8,install,installation,8,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2065,1,['install'],['installation']
Deployability,"Louvain is being difficult to build since a new setuptools release dropped any python2 compatibility https://github.com/vtraag/louvain-igraph/issues/57. We've largely worked around this in #2063, by making louvain dependent tests optional. However, the paul15 PAGA test is difficult to extract louvian from. It checks hardcoded values based on the results of a louvain clustering. To adapt this test to use leiden, we would have to redo the tutorial and create new results. Or louvain building could be fixed, but the package is deprecated anyways.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2065:59,release,release,59,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2065,1,['release'],['release']
Deployability,LoweringError: Failed in nopython mode pipeline (step: nopython mode backend),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1756:39,pipeline,pipeline,39,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1756,1,['pipeline'],['pipeline']
Deployability,"MAGIC API modelled off the DCA API. A couple of comments:. - I changed `threads` to `n_jobs` to match `sc.tl` API; - I use `sc.settings.verbosity` rather than `False` for `verbose` default; - I updated the PHATE API while I was here; - I'm open to suggestions on how to handle `name_list`. Re: `name_list`: MAGIC accepts both gene names and column indices. I've set it up currently to return to adata.obsm['X_magic'] if genes are specified as the number of columns is reduced from the original data, and to adata.X if all genes are returned. However, adata.obsm['X_magic'] now has no information about the order of the genes, unless I return it from MAGIC as a `pandas.DataFrame`, or as an AnnData object in its own right. What do you think?. P.S. MAGIC handling `genes` on AnnData input is currently on the dev branch, but will be merged to master once we settle on an API.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/193:194,update,updated,194,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/193,1,['update'],['updated']
Deployability,MAGIC in external causes test failures if its not installed,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1001:50,install,installed,50,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1001,1,['install'],['installed']
Deployability,"MNN does take fairly long. There is a faster version of it, which runs on PCA I think though, but it's not in scanpy external. Before you didn't integrated anything, as the function thought you just have 1 batch the way you ran it. I would report your issue with bbknn on the BBKNN github repo directly. You may get better suggestions there.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/873#issuecomment-543582157:145,integrat,integrated,145,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/873#issuecomment-543582157,1,['integrat'],['integrated']
Deployability,"Make sure you are searching the `conda-forge` channel, too. ; Either `conda install -c conda-forge -c bioconda scanpy` or [configure the default channels](https://bioconda.github.io/user/install.html?highlight=conda%20forge#set-up-channels).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1142#issuecomment-613475004:76,install,install,76,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1142#issuecomment-613475004,2,['install'],['install']
Deployability,"Malte, don't you have `pytest` installed locally? Debugging using all these `added prints` etc. commits doesn't help maintain a clean git history. :wink:. Is it possible that there is any ambiguity regarding floating point precision? It's a bit hard for me to debug this. In case you don't have python 3.5 installed. Simply do `conda create -n py35 python=3.5`. Calling `pytest scanpy/tests/marker_gene_overlap.py` should rapidly reveal what's going on. Or simply debugging this in a notebook. Thank you and sorry that this causes trouble!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/583#issuecomment-479387950:31,install,installed,31,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/583#issuecomment-479387950,2,['install'],['installed']
Deployability,"Matplotlib 3.2 seems to have broken a number of our tests. This is me trying to update them, though I've had trouble reproducing figures compared with travis in the past. # Heatmaps. For heatmaps, the update was real bad:. ![blurry_heatmap](https://user-images.githubusercontent.com/8238804/76190007-23651200-6230-11ea-9912-d42dbbe76eb9.png). # Violin plots. Violin plots have changed as well, but I think it's for the better. They seem less likely to show density where there are no data points. In practice, where `n_genes` < 1000 was used as a cutoff, this looks like:. ![new_violin](https://user-images.githubusercontent.com/8238804/76190453-1eed2900-6231-11ea-9a6b-880ebda71a88.png). Axis ticks also changed due to this. # Everything else. For everything else that changed, I couldn't tell the difference. I think plots just moved up or down a bit, and that made them report as changed.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1090:80,update,update,80,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1090,2,['update'],['update']
Deployability,"Matplotlib 3.4 has dropped 3.6 support. Since matplotlib is our most painful dependency (reliably causes test failures when it updates), it's a great time to drop 3.6.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1697#issuecomment-809011473:127,update,updates,127,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1697#issuecomment-809011473,1,['update'],['updates']
Deployability,"Matplotlib list!)"" % (label_namer, func.__name__),; 1809 RuntimeWarning, stacklevel=2); -> 1810 return func(ax, *args, **kwargs); 1811 ; 1812 inner.__doc__ = _add_data_doc(inner.__doc__,. ~\AppData\Local\conda\conda\envs\Scanpy\lib\site-packages\matplotlib\axes\_axes.py in pcolor(self, alpha, norm, cmap, vmin, vmax, *args, **kwargs); 5773 kwargs.setdefault('snap', False); 5774 ; -> 5775 collection = mcoll.PolyCollection(verts, **kwargs); 5776 ; 5777 collection.set_alpha(alpha). ~\AppData\Local\conda\conda\envs\Scanpy\lib\site-packages\matplotlib\collections.py in __init__(self, verts, sizes, closed, **kwargs); 931 %(Collection)s; 932 """"""; --> 933 Collection.__init__(self, **kwargs); 934 self.set_sizes(sizes); 935 self.set_verts(verts, closed). ~\AppData\Local\conda\conda\envs\Scanpy\lib\site-packages\matplotlib\collections.py in __init__(self, edgecolors, facecolors, linewidths, linestyles, capstyle, joinstyle, antialiaseds, offsets, transOffset, norm, cmap, pickradius, hatch, urls, offset_position, zorder, **kwargs); 164 ; 165 self._path_effects = None; --> 166 self.update(kwargs); 167 self._paths = None; 168 . ~\AppData\Local\conda\conda\envs\Scanpy\lib\site-packages\matplotlib\artist.py in update(self, props); 914 ; 915 with cbook._setattr_cm(self, eventson=False):; --> 916 ret = [_update_property(self, k, v) for k, v in props.items()]; 917 ; 918 if len(ret):. ~\AppData\Local\conda\conda\envs\Scanpy\lib\site-packages\matplotlib\artist.py in <listcomp>(.0); 914 ; 915 with cbook._setattr_cm(self, eventson=False):; --> 916 ret = [_update_property(self, k, v) for k, v in props.items()]; 917 ; 918 if len(ret):. ~\AppData\Local\conda\conda\envs\Scanpy\lib\site-packages\matplotlib\artist.py in _update_property(self, k, v); 910 func = getattr(self, 'set_' + k, None); 911 if not callable(func):; --> 912 raise AttributeError('Unknown property %s' % k); 913 return func(v); 914 . AttributeError: Unknown property standard_scale; ```; Any idea of what I'm missing here?. Thanks",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/565:2179,update,update,2179,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/565,2,['update'],['update']
Deployability,Maybe I could throw in another ID mapping tool. [BED](https://f1000research.com/articles/7-195/v1) is pretty good. More comprehensive than Biomart and quicker too. It is however a local implementation that runs in a docker container. The image is updated every month or so. At the moment I run a container internally here... but maybe we could make a webserver out of this which can be directly integrated with scanpy?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/242#issuecomment-458065068:247,update,updated,247,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/242#issuecomment-458065068,2,"['integrat', 'update']","['integrated', 'updated']"
Deployability,Maybe downgrade numba for the time being? IDK to which version though. @stuartarchibald has more insight here. Please follow numba/numba#5955 for updates!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1341#issuecomment-670189681:146,update,updates,146,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341#issuecomment-670189681,1,['update'],['updates']
Deployability,"Maybe it's release 1.3.2 - I wouldn't have made that release if I hadn't been asked to, I expected the new plotting backend to still have several bugs. The current master has several fixes. Do you think we should move forward with another release, @fidelram, @ivirshup; or are there still a few striking bugs in the scatter plots that I'm not aware of? It seems like a lot has been fixed in the past week.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/286#issuecomment-430659918:11,release,release,11,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/286#issuecomment-430659918,3,['release'],['release']
Deployability,"Maybe it's the upgrade to version 1.5.1 that leads to this bug, I can run this piece of code under 1.4.6.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1246#issuecomment-633443990:15,upgrade,upgrade,15,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1246#issuecomment-633443990,1,['upgrade'],['upgrade']
Deployability,Method cugraph.add_adj_list is replaced in RAPIDS v0.16 with from_cudf_adjlist.; This patch will check for existence of 'add_adj_list' in the object before; calling it.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1494:86,patch,patch,86,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1494,1,['patch'],['patch']
Deployability,"Mmh, very strange. Graph abstraction will be in the next Scanpy release and is not stable yet... Are you simply running the [minimal example](https://github.com/theislab/graph_abstraction/blob/master/minimal_examples/minimal_examples.ipynb)? Maybe reread and reload your data? At some point a few months ago, the format for AnnData files changed. Also, the master branch on Github doesn't have all tests on all notebooks yet, I'd recommend to wait until the release that is scheduled for the next week. Cheers,; alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/40#issuecomment-333528844:64,release,release,64,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/40#issuecomment-333528844,2,['release'],['release']
Deployability,Modifications to azure pipeline,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1517:23,pipeline,pipeline,23,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1517,1,['pipeline'],['pipeline']
Deployability,Move paga path bugfix note to 1.8.0 release,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1784:36,release,release,36,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1784,1,['release'],['release']
Deployability,"Much of the spatial data is stored in `uns`, which does not get combined by default. There is an example of concatenating visium datasets [in the tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/spatial/integration-scanorama.html#Data-integration) and more information on concatenating `.uns` [in the latest anndata docs](https://anndata.readthedocs.io/en/latest/concatenation.html#merging-uns).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1254#issuecomment-635107317:214,integrat,integration-scanorama,214,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1254#issuecomment-635107317,2,['integrat'],"['integration', 'integration-scanorama']"
Deployability,My coworker and I had the same issue as @ttgump. Upgrading setuptools fixed it. Maybe it's worth adding a note to the installation troubleshooting documentation?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/148#issuecomment-391375544:118,install,installation,118,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148#issuecomment-391375544,1,['install'],['installation']
Deployability,"My priority are intuitive semantics so people can add or bump dependencies without 100% understanding the algorithm of the minimum dependency script. So I can think of options:. 1. Each version must be fully specified (`>=1.2.0`, not `>=1.2`). The script installs exactly the specified minimum version. Implementation: Would be quickly done now, just check the job run and change `matplotlib>=3.6` to `matplotlib>=3.6.3` and so on. Effect: whenever we bump something, we probably need to bump more things, which might sometimes be painful. The minimum versions will be more accurate, as we know that the exact versions specified successfully run out test suite. 4. We maintain a list of all dependencies we have together with data about which version segment denotes the patch version (i.e. for semver it’s the third, for calendar ver, it’s nothing), then modify versions based on that knowledge (e.g. semver `>=1.2.3` → `>=1.2.3, <1.3`). Implementation: Each newly added dependency needs to be added to that list. Effect: This would be basically a more powerful (able to specify minimum patch) and obvious version of what you’re doing now (explicit data instead of the presence of a patch version indicating if something is semver or not). In both versions, there’s no hidden semantics in `>=1.2` that would distinguish it from `>=1.2.0`, which is what I’m after. What does your experience while implementing this so far say to these? Any other ideas?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1943497240:255,install,installs,255,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1943497240,4,"['install', 'patch']","['installs', 'patch']"
Deployability,"My thinking on this right now is that:. * The code for masking logic (pre this PR) is kind of a mess; * This PR doesn't make the code nicer. But the performance benefit is quite good, and for sure the operation `X[mask_obs, :] = scale_rv` is something we don't want to do with sparse matrices. I also think we could get even faster, plus a bit cleaner if we instead modified scale array to use something like what I suggest [here](https://github.com/scipy/scipy/issues/20169#issuecomment-1973335172) to accept a `row_mask` argument:. ```python; from scipy import sparse; import numpy as np; from operator import mul, truediv. def broadcast_csr_by_vec(X, vec, op, axis):; if axis == 0:; new_data = op(X.data, np.repeat(vec, np.diff(X.indptr))); elif axis == 1:; new_data = op(X.data, vec.take(X.indices, mode=""clip"")); return X._with_data(new_data); ```. Which *I think* would be something like:. ```python; def broadcast_csr_by_vec(X, vec, op, axis, row_mask: None | np.ndarray):; if row_mask is not None:; vec = np.where(row_mask, vec, 1); if axis == 0:; new_data = op(X.data, np.repeat(vec, np.diff(X.indptr))); elif axis == 1:; new_data = op(X.data, vec.take(X.indices, mode=""clip"")); return X._with_data(new_data); ```. Or, since we're doing numba already we could do just write out the operation with a check to see if we're on a masked row (which *should* be even faster since we're not allocating anything extra). I think either of these solutions would be simpler since we do the masking all in one place, and don't have to have a second update step.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2942#issuecomment-2024951345:1546,update,update,1546,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2942#issuecomment-2024951345,1,['update'],['update']
Deployability,My too. I had loompy version 2.0.17 and now I installed the version 2.0.16 and still I'm getting the same issue.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/598#issuecomment-493887143:46,install,installed,46,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/598#issuecomment-493887143,1,['install'],['installed']
Deployability,"My version of scanpy:; scanpy 1.8.1 pyhd8ed1ab_0 conda-forge; I'm working on a linux system based server, and uses miniconda3 for environment management.; After some changes in my environment, I tried to run the routine process of my analysis.; But when running sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40), I encountered the following error: . > Traceback (most recent call last):; File ""/data1/exhaustT/process.py"", line 118, in <module>; sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40); File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 139, in neighbors; neighbors.compute_neighbors(; File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 808, in compute_neighbors; self._distances, self._connectivities = _compute_connectivities_umap(; File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 387, in _compute_connectivities_umap; from umap.umap_ import fuzzy_simplicial_set; File ""/data1/exhaustT/umap.py"", line 48, in <module>; sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40); File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 139, in neighbors; neighbors.compute_neighbors(; File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 808, in compute_neighbors; self._distances, self._connectivities = _compute_connectivities_umap(; File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 387, in _compute_connectivities_umap; from umap.umap_ import fuzzy_simplicial_set; ModuleNotFoundError: No module named 'umap.umap_'; 'umap' is not a package. I've tried to re-install umap-learn from conda-forge, and/or simply pip install umap, neither worked for me. #update, the problem found to be that I named my own script umap.py, even though it's in a different direction, it still caused trouble.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1987:1740,install,install,1740,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1987,3,"['install', 'update']","['install', 'update']"
Deployability,"NA/~/AppData/Roaming/Python/Python312/site-packages/scanpy/readwrite.py:594) genes = pd.read_csv(; [595](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/scanpy/readwrite.py:595) path / f""{prefix}{'genes' if is_legacy else 'features'}.tsv{suffix}"",; [596](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/scanpy/readwrite.py:596) header=None,; [597](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/scanpy/readwrite.py:597) sep=""\t"",; [598](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/scanpy/readwrite.py:598) ); [599](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/scanpy/readwrite.py:599) if var_names == ""gene_symbols"":; [600](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/scanpy/readwrite.py:600) var_names_idx = pd.Index(genes[1].values). File ~\AppData\Roaming\Python\Python312\site-packages\pandas\io\parsers\readers.py:1026, in read_csv(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_opt",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3214:8006,Pipeline,PipelineDevelope,8006,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3214,1,['Pipeline'],['PipelineDevelope']
Deployability,"NA; astunparse 1.6.3; attr 23.2.0; attrs 23.2.0; babel 2.14.0; certifi 2024.02.02; cffi 1.16.0; charset_normalizer 3.3.2; cloudpickle 3.0.0; comm 0.2.2; cycler 0.12.1; cython_runtime NA; dask 2024.5.2; dateutil 2.9.0.post0; debugpy 1.8.1; decorator 5.1.1; defusedxml 0.7.1; exceptiongroup 1.2.1; executing 2.0.1; fastjsonschema NA; fqdn NA; google NA; h5py 3.11.0; idna 3.7; igraph 0.11.4; ipykernel 6.29.4; isoduration NA; jedi 0.19.1; jinja2 3.1.3; joblib 1.4.0; json5 0.9.25; jsonpointer 2.4; jsonschema 4.21.1; jsonschema_specifications NA; jupyter_events 0.10.0; jupyter_server 2.14.0; jupyterlab_server 2.27.0; kiwisolver 1.4.5; legacy_api_wrap NA; leidenalg 0.10.2; llvmlite 0.42.0; markupsafe 2.1.5; matplotlib 3.8.4; mpl_toolkits NA; mpmath 1.3.0; natsort 8.4.0; nbformat 5.10.4; numba 0.59.1; numpy 1.26.4; nvfuser NA; opt_einsum v3.3.0; overrides NA; packaging 24.0; pandas 1.5.3; parso 0.8.4; platformdirs 4.2.0; plotly 5.22.0; prometheus_client NA; prompt_toolkit 3.0.43; psutil 5.9.8; pure_eval 0.2.2; pyarrow 13.0.0; pydev_ipython NA; pydevconsole NA; pydevd 2.9.5; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.17.2; pyparsing 3.1.2; pythonjsonlogger NA; pytz 2024.1; referencing NA; requests 2.31.0; rfc3339_validator 0.1.4; rfc3986_validator 0.1.1; rpds NA; scipy 1.13.0; send2trash NA; session_info 1.0.0; six 1.16.0; sklearn 1.4.2; sniffio 1.3.1; socks 1.7.1; stack_data 0.6.3; sympy 1.12.1; tblib 3.0.0; texttable 1.7.0; threadpoolctl 3.4.0; tlz 0.12.1; toolz 0.12.1; torch 2.0.0+cu117; tornado 6.4; tqdm 4.66.2; traitlets 5.14.3; typing_extensions NA; uri_template NA; urllib3 1.26.18; wcwidth 0.2.13; webcolors 1.13; websocket 1.7.0; yaml 6.0.1; zipp NA; zmq 26.0.2; zoneinfo NA; -----; IPython 8.23.0; jupyter_client 8.6.1; jupyter_core 5.7.2; jupyterlab 4.1.6; -----; Python 3.10.14 (main, Apr 30 2024, 04:10:16) [GCC 13.2.1 20240417]; Linux-6.9.7-arch1-1-x86_64-with-glibc2.39; -----; Session information updated at 2024-07-12 14:59; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3152:3067,update,updated,3067,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3152,1,['update'],['updated']
Deployability,"New version of `uns` as discussed in https://github.com/theislab/anndata/issues/295#issuecomment-596164456. The reason for setting a dummy `library_id` (as ""0"" for instance) is:; * The `library_id` information is in the molecule_info file [explained here](https://support.10xgenomics.com/spatial-gene-expression/software/pipelines/latest/output/molecule_info). Recover it would require to input an additional file path; * All the 10x data I had a look at, both from the same tissue (so 2 slides from same tissue slice) and from different tissues, have `library_id` entry set to ""0"". So I am not really sure how space ranger set that value but it does not appear to be unique (and therefore not a natural `batch_key` value).; * I think it would be more useful if this value is set according to user choice. Only in the context of `adata.concatenate` it should be modified according to `batch_key`. This is also the only point in the analysis where the `library_id` entry matter.; * I agree with respect to maintaining the tree structure before and after concatenation, so the reason for keeping the `library_id` entry and setting it to a dummy variable by default. Looking forward to hear what you think @ivirshup and if agree I'll go on with PRs for `anndata.concatenate`. . Also, let's keep this `spatial` branch open until we really have (almost) everything up and running for spatial analysis.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1105:321,pipeline,pipelines,321,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1105,1,['pipeline'],['pipelines']
Deployability,"Nice! But may I ask why you’re still importing everything from umap instead of from pynndescent?. I’d assume if we’d do that we’d be more robust to further umap updates, no?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1038#issuecomment-584787583:161,update,updates,161,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1038#issuecomment-584787583,1,['update'],['updates']
Deployability,"Nice! Thanks!. On Mon, 8 Jun 2020, 10:46 giovp, <notifications@github.com> wrote:. > @vitkl <https://github.com/vitkl> now multiple samples are supported, see; > here; > <https://scanpy-tutorials.readthedocs.io/en/latest/spatial/integration-scanorama.html>; > for description on how to use the new concat strategy; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/issues/1158#issuecomment-640496084>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AFMFTVZVVWII7Z7Q34ZPTQ3RVSXOVANCNFSM4MEXUAPQ>; > .; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1158#issuecomment-640632513:229,integrat,integration-scanorama,229,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1158#issuecomment-640632513,1,['integrat'],['integration-scanorama']
Deployability,"No problem! . Also, this will go into the 1.7.2 release, but all changes should be made to master while only some get back ported to the current release branch.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1722#issuecomment-794836848:48,release,release,48,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1722#issuecomment-794836848,2,['release'],['release']
Deployability,"No problem!. * `features` sounds more natural to me, but `variables` is fine. Maybe we could do `vars` instead of `variables` for reduced verbosity?; * `expr_type` would work. Maybe `vars_type`?; * How about `n_genes_by_{exprs_type/vars_type}`? `n` works great for this, since it's integer valued. I might like `vars` over `genes` since the variables could be transcripts or surface markers, but I'm not sure on this. I like the `by_{vars_type}` convention for a couple reasons, which also apply to your last point:; * It allows recording at multiple steps in the process. You could imagine: `n_{vars/genes}_by_counts` and `n_{vars/genes}_by_imputed_counts` or `n_{vars/genes}_by_normed_expression`; * The convention allows for multi-omic measurements on a gene, `n_{vars/genes}_by_fluorescence` for example. This is a case where `genes` makes more sense than `vars`.; * `control_variables` does sound more natural. I'd possibly like to replace `control` as well, since these aren't necessarily controlled variables.; * Largely similar thoughts as the third point, e.g.; * Recording at multiple steps: `n_cells_by_counts` and `n_cells_by_imputed_counts`; * Multi-omic measurements: `n_cells_by_fluorescence`. I think `total` can be more widely used than `n`, allowing more consistency. To me, `total_cells` or `total_vars` make sense while `n_fluorescence` or `n_log_counts` don't. It's also totally fine to have a mix. Yeah, I figured I didn't want to make a whole copy of the object if I didn't want update or add all the metrics. About places in the codebase where naming would need to change, I'd argue the default shouldn't be to use a pre-computed value. I hadn't realized that `n_counts` fields were being stored or used until I started looking around. Since summing over a matrix is likely a pretty light computation compared to what follows, I don't think there's a strong performance argument for keeping it as the default.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/316#issuecomment-436161904:1502,update,update,1502,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/316#issuecomment-436161904,1,['update'],['update']
Deployability,"No problem, thanks!. I think conflicts in release note are going to be common. Maybe those commits could be separate from the PR?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/615#issuecomment-489859578:42,release,release,42,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/615#issuecomment-489859578,1,['release'],['release']
Deployability,"No recent version of legacy-api-wrap has been uploaded to conda. So, we can't make a conda release of scanpy 1.10. * https://github.com/conda-forge/scanpy-feedstock/pull/15. Since it's a single file with a single function, I'm very up for vendor-ing it:. * https://github.com/scverse/anndata/issues/1301. cc: @flying-sheep",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2966:91,release,release,91,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2966,1,['release'],['release']
Deployability,"No release notes are needed, but milestones are needed for this to get back-ported. Also the check for the release notes is actually checking the box in the PR template.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2972#issuecomment-2031877808:3,release,release,3,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2972#issuecomment-2031877808,2,['release'],['release']
Deployability,"No vendored versioneer.py anymore, no setup.cfg! This is vastly simpler. Could you please check if my logic holds?. Package metadata and content will be correctly derived from the git repo’s status. 1. before building, `setuptools_scm` will be installed through `setup_requires=['setuptools_scm']` or `[build-requires]`.; 2. during building, due to `use_scm_version=True`, it will populate the package metadata with a proper version from git. (Looks like `scanpy-1.4.5.dev60+g0adf706`). `scanpy.__version__` will be the version of scanpy you’re currently developing (if applicable) or the installed one:. 1. scanpy tries to use `setuptools_scm.get_version`; 2. if `setuptools_scm` can’t be imported or we’re not in a git repo, it will just use the version from package metadata (like `check_versions` does for other installed packages)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/798:244,install,installed,244,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/798,3,['install'],['installed']
Deployability,No worries and thank you for usually very prompt suggestions.; The idea that scanpy can handle many cells efficiently is great and therefore I have been trying it in a computing cluster (and not my local machine) for the future usage. This in turn makes configuration just a bit more difficult. ; Looking forward to a more stable version with more added function.; Thank you; Hashem,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/35#issuecomment-324641466:254,configurat,configuration,254,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35#issuecomment-324641466,1,['configurat'],['configuration']
Deployability,"No worries, I would have done this for the next release... . Btw: cool that you made your actual `fit_transform` accept `AnnData` objects... Would not have been necessary, but nice! :wink:",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/139#issuecomment-386320788:48,release,release,48,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/139#issuecomment-386320788,1,['release'],['release']
Deployability,"No worries. . Right now I'm just thinking of whether this should be called `n_dims` now, and trying to figure out why I have the sneaking suspicion that this broke something last time I looked at it. One last thing from you, could you add a release note to `docs/release-notes/1.9.0.md`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2179#issuecomment-1076261309:241,release,release,241,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2179#issuecomment-1076261309,2,['release'],"['release', 'release-notes']"
Deployability,"No, there should not be any reason that is associated with a small number of genes per se. In the moignard15 example, everything works for 40 genes; in the toggleswitch, everything works for 2 genes. Does your PCA look meaningful? Try supplying a very small number of PCs to DPT (`n_pcs=3` or so). If you do not find significant genes with `filter_genes_dispersion`, you have to adapt the parameters [e.g. set `min_disp` to a lower value](https://github.com/theislab/scanpy/blob/2cea8341e28eb8d0658f62d010631f77465e16d7/scanpy/preprocessing/simple.py#L132-L177). See the example [here](https://github.com/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb). Alternatively, you can simply select the `n_top_genes` highest variabale genes by setting `flavor` to `'cell_ranger'`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/25#issuecomment-313320910:156,toggle,toggleswitch,156,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/25#issuecomment-313320910,1,['toggle'],['toggleswitch']
